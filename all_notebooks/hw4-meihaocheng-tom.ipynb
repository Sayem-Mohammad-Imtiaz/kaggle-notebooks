{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# default libraries\nimport numpy as np\nimport pandas as pd\n\n# for data preprocessing\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\n# for classifier models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import KFold, cross_val_score\nimport xgboost as xgb\n\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\n# matplotlib inline\n\n# for models evaluation\nfrom sklearn.metrics import confusion_matrix, accuracy_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ingest"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/eating-health-module-dataset/ehresp_2014.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning and exploration\n"},{"metadata":{},"cell_type":"markdown","source":"### Clean"},{"metadata":{"trusted":true},"cell_type":"code","source":"def init_check(df):\n    \"\"\"\n    A function to make initial check for the dataset including the name, data type, \n    number of null values and number of unique varialbes for each feature.\n    \n    Parameter: dataset(DataFrame)\n    Output : DataFrame\n    \"\"\"\n    columns = df.columns    \n    lst = []\n    for feature in columns : \n        dtype = df[feature].dtypes\n        num_null = df[feature].isnull().sum()\n        num_unique = df[feature].nunique()\n        lst.append([feature, dtype, num_null, num_unique])\n    \n    check_df = pd.DataFrame(lst)\n    check_df.columns = ['feature','dtype','num_null','num_unique']\n    check_df = check_df.sort_values(by='dtype', axis=0, ascending=True)\n    \n    return check_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"init_check(df=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def categorical_encoding(df, categorical_cloumns, encoding_method):\n    \"\"\"\n    A function to encode categorical features to a one-hot numeric array (one-hot encoding) or \n    an array with value between 0 and n_classes-1 (label encoding).\n    \n    Parameters:\n        df (pd.DataFrame) : dataset\n        categorical_cloumns  (string) : list of features \n        encoding_method (string) : 'one-hot' or 'label'\n    Output : pd.DataFrame\n    \"\"\"\n    \n    if encoding_method == 'label':\n        print('You choose label encoding for your categorical features')\n        encoder = LabelEncoder()\n        encoded = df[categorical_cloumns].apply(encoder.fit_transform)\n        return encoded\n    \n    elif encoding_method == 'one-hot':\n        print('You choose one-hot encoding for your categorical features') \n        encoded = pd.DataFrame()\n        for feature in categorical_cloumns:\n            dummies = pd.get_dummies(df[feature], prefix=feature)\n            encoded = pd.concat([encoded, dummies], axis=1)\n        return encoded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = data.select_dtypes(include=['float64']).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded=categorical_encoding(df=data,categorical_cloumns=categorical_columns, encoding_method='label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(columns=categorical_columns, axis=1)\ndata = pd.concat([data, encoded], axis=1)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.hist(bins = 10, figsize=(18, 16), color=\"#2c5af2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for a in ['eufinlwgt','erbmi','ertpreat','ertseat','euwgt']:\n    ax=plt.subplots(figsize=(6,3))\n    ax=sns.distplot(data[a])\n    title=\"Histogram of \" + a\n    ax.set_title(title, fontsize=12)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Feature engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndata_scaled=pd.DataFrame(scaler.fit_transform(data))\ndata_scaled.columns=data.columns\ndata_scaled.index=data.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_scaled.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{},"cell_type":"markdown","source":"### PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nn_components=37\npca = PCA(n_components=n_components)\npca.fit(data_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(10,8))\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('number of components')\nplt.ylabel('cumulative explained variance');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explained_variance_ratio = pca.explained_variance_ratio_ \ncum_explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\nlst = []\nfor i in range (0, n_components):\n  lst.append([i+1, round(explained_variance_ratio[i],6), cum_explained_variance_ratio[i]])\n\npca_predictor = pd.DataFrame(lst)\npca_predictor.columns = ['Component', 'Explained Variance', 'Cumulative Explained Variance']\npca_predictor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=8)\npca.fit(data_scaled)\nexplained_variance_ratio = pca.explained_variance_ratio_\nsingular_values = pca.singular_values_    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_transformed = pca.fit_transform(data_scaled)\ndata_transformed.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_transformed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  K-Means"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(10,8))\nplt.scatter(data_transformed[:,[0]], data_transformed[:,[1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nn_clusters = 10\nkmeans = KMeans(n_clusters=n_clusters, random_state=123)\nkmeans.fit(data_transformed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_labels = kmeans.labels_\ncluster_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax=plt.subplots(figsize=(10,5))\nax=sns.countplot(cluster_labels)\ntitle=\"Histogram of Cluster Counts\"\nax.set_title(title, fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['X'] = data_transformed[:,[0]]\ndata['Y'] = data_transformed[:,[1]]\ndata['cluster'] = cluster_labels\nax=plt.subplots(figsize=(10,10))\nax = sns.scatterplot(x='X', y='Y',hue='cluster', legend=\"full\", palette=\"Set1\", data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Although I have retained 8 dimensions, after categorization, only two dimensions of the scatter plot can still see the points of different classes come together, so I kept the code for my wrong visualization process."},{"metadata":{},"cell_type":"markdown","source":"# GMM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.mixture import GaussianMixture\ngmm = GaussianMixture(n_components=8).fit(data_transformed)\nlabels = gmm.predict(data_transformed)\nplt.scatter(data_transformed[:, 0],data_transformed[:, 1], c=labels, s=40, cmap='viridis');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Comparison of clusters' stats"},{"metadata":{"trusted":true},"cell_type":"code","source":"def cluster_stats(columns):\n    output = pd.DataFrame({'cluster':[ i for i in range(n_clusters)]})\n    for column in columns:\n        lst = []\n        for i in range(n_clusters):\n            mean = data[data['cluster'] == i].describe()[column]['mean']\n            lst.append([i, round(mean,2)])\n        df = pd.DataFrame(lst)\n        df.columns = ['cluster', column]\n        output = pd.merge(output, df, on='cluster', how='outer')\n    return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns =data_scaled.columns\ncluster_stats(columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"1. Using  PCA and K-Means methods can effectively classify data.\n2. By comparison of clusters' stats, I am able to find out the differences between the categories.\n3. Although it is only when the dimension is reduced to 2 or 3 dimensions, the visualization can be well achieved. However, I found that when I can't drop to such a low dimension, I can only see the distribution of the data in these two dimensions."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}