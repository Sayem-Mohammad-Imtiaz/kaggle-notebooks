{"cells":[{"metadata":{},"cell_type":"markdown","source":"# PREDICT THE RED WINE QUALITY\n## A Simple Regression"},{"metadata":{},"cell_type":"markdown","source":"### Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\n\nDATA_PATH = '../input/red-wine-quality-cortez-et-al-2009/'\nFILE_NAME = 'winequality-red.csv'\ndef load_wine_data(data_path=DATA_PATH, file_name=FILE_NAME):\n    csv_path = os.path.join(data_path, file_name)\n    return pd.read_csv(csv_path)\n\nwines = load_wine_data()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### View Data and Informations"},{"metadata":{"trusted":true},"cell_type":"code","source":"wines.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wines.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wines.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nwines.hist(bins=50, figsize=(20,15), color=\"orange\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split Dataset\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_set, test_set = train_test_split(wines, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare the Data"},{"metadata":{},"cell_type":"markdown","source":"#### Get the Labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"wines_train_set = train_set.drop('quality', axis=1)\ntrain_set_labels = train_set['quality'].copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Data Transformations"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\n\nnumerical_pipeline = Pipeline([\n        ('std_scaler', StandardScaler()),\n    ])\n\ncols = list(wines_train_set)\npipeline = ColumnTransformer([\n        (\"numerical_attributes\", numerical_pipeline, cols),\n    ])\n\nprepared_train_set = pipeline.fit_transform(wines_train_set)\nprepared_train_set.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training"},{"metadata":{},"cell_type":"markdown","source":"#### Model: Linear Regression "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cross-Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\nlin_scores = cross_val_score(lin_reg, prepared_train_set, train_set_labels,\n                             scoring=\"neg_mean_squared_error\", cv = 10)\nlin_scores_rmse = np.sqrt(-lin_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_cv_scores(scores):\n    print(\"Scores:\\t\", scores)\n    print(\"Mean:\\t\", scores.mean())\n    print(\"Std:\\t\", scores.std())\n\ndisplay_cv_scores(lin_scores_rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fine-Tune the Model"},{"metadata":{},"cell_type":"markdown","source":"#### Grid Search"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {'copy_X':[True,False], 'fit_intercept':[True,False], 'normalize':[True,False]}\n]\n\ngrid_search = GridSearchCV(lin_reg, param_grid, cv=10, scoring='neg_mean_squared_error')\ngrid_search.fit(prepared_train_set, train_set_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluate the Best Model on Test Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model = grid_search.best_estimator_\n\nX_test = test_set.drop('quality', axis=1)\ny_test = test_set['quality'].copy()\n\nX_test_prepared = pipeline.transform(X_test)\n\nfinal_predictions = final_model.predict(X_test_prepared)\n\nfinal_mse = mean_squared_error(y_test, final_predictions)\nfinal_rmse = np.sqrt(final_mse)\n\nprint('RMSE:',final_rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_predictions[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Note\nFrom the obtained result we explicitly note explicitly that the model is underfitting the data.\n\nLet's see if regularized models can do better.\n"},{"metadata":{},"cell_type":"markdown","source":"## Regularized Models"},{"metadata":{},"cell_type":"markdown","source":"### Ridge Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\nridge_reg = Ridge(alpha=1)\n\n#Cross_validation\nridge_scores = cross_val_score(ridge_reg, prepared_train_set, train_set_labels,\n                             scoring=\"neg_mean_squared_error\", cv = 10)\nridge_scores_rmse = np.sqrt(-ridge_scores)\n\nprint('Cross-validation mean RMSE:', ridge_scores_rmse.mean())\n\n#Grid Search\nrr_param_grid = [\n    {'alpha':[0.001, 0.01, 0.1, 1, 10, 100, 1000],\n     \"solver\": ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}\n]\n\nrr_grid_search = GridSearchCV(ridge_reg, rr_param_grid, cv=10, scoring='neg_mean_squared_error')\nrr_grid_search.fit(prepared_train_set, train_set_labels)\n\n#Evaluate on Test Set\nrr_final_model = rr_grid_search.best_estimator_\n\nrr_final_predictions = rr_final_model.predict(X_test_prepared)\n\nrr_final_mse = mean_squared_error(y_test, rr_final_predictions)\nrr_final_rmse = np.sqrt(rr_final_mse)\n\nprint('\\nRidge Regression RMSE:', rr_final_rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lasso Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso\n\nlasso_reg = Lasso(alpha=0.1)\n\nlasso_scores = cross_val_score(lasso_reg, prepared_train_set, train_set_labels,\n                             scoring=\"neg_mean_squared_error\", cv = 10)\nlasso_scores_rmse = np.sqrt(-lasso_scores)\n\nprint('Cross-validation mean RMSE:', lasso_scores_rmse.mean())\n\n#Grid Search\nlr_param_grid = [\n    {'alpha':[0.001, 0.01, 0.1, 1, 10, 100, 1000],\n    }\n]\n\nlr_grid_search = GridSearchCV(lasso_reg, lr_param_grid, cv=10, scoring='neg_mean_squared_error')\nlr_grid_search.fit(prepared_train_set, train_set_labels)\n\n#Evaluate on Test Set\nlr_final_model = lr_grid_search.best_estimator_\n\nlr_final_predictions = lr_final_model.predict(X_test_prepared)\n\nlr_final_mse = mean_squared_error(y_test, lr_final_predictions)\nlr_final_rmse = np.sqrt(lr_final_mse)\n\nprint('\\nLasso Regression RMSE:', lr_final_rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ElasticNet Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import ElasticNet\n\nen_reg = ElasticNet(alpha=0.1, l1_ratio=0.5)\n\nen_scores = cross_val_score(en_reg, prepared_train_set, train_set_labels,\n                             scoring=\"neg_mean_squared_error\", cv = 10)\nen_scores_rmse = np.sqrt(-en_scores)\n\nprint('Cross-validation mean RMSE:', en_scores_rmse.mean())\n\n#Grid Search\nen_param_grid = [\n    {'alpha':[0.001, 0.01, 0.1, 1, 10, 100, 1000],\n     'l1_ratio':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n    }\n]\n\nen_grid_search = GridSearchCV(en_reg, en_param_grid, cv=10, scoring='neg_mean_squared_error')\nen_grid_search.fit(prepared_train_set, train_set_labels)\n\n#Evaluate on Test Set\nen_final_model = en_grid_search.best_estimator_\n\nen_final_predictions = en_final_model.predict(X_test_prepared)\n\nen_final_mse = mean_squared_error(y_test, en_final_predictions)\nen_final_rmse = np.sqrt(en_final_mse)\n\nprint('\\nElasticNet Regression RMSE:', en_final_rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusions\nAgain, the models achieved a high Root-Mean-Square Error.\n\nTo avoid undefitting we have two main possibilities:\n\n- Increase the instances of the dataset,\n- Use a more complex model;\n\nIn this case, since there are relatively few instances in the data set, the first approach could be preferred.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":4}