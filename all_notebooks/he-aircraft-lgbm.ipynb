{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nimport seaborn as sns\nimport time\n\nfrom math import sqrt\nfrom numpy import loadtxt\nfrom itertools import product\nfrom tqdm import tqdm\nfrom numpy import loadtxt\n\nimport gc\nfrom sklearn import preprocessing \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error,f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom catboost import CatBoostClassifier\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" \n    iterate through all the columns of a dataframe and \n    modify the data type to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print(('Memory usage of dataframe is {:.2f}' \n                     'MB').format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        print(str(col_type))\n        if str(col_type) == \"datetime64[ns]\":\n            continue\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max <\\\n                  np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max <\\\n                   np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max <\\\n                   np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max <\\\n                   np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            elif str(col_type) != \"Timestamp\":\n                if c_min > np.finfo(np.float16).min and c_max <\\\n                   np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max <\\\n                   np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n    end_mem = df.memory_usage().sum() / 1024**2\n    print(('Memory usage after optimization is: {:.2f}' \n                              'MB').format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \n                                             / start_mem))\n    \n    return df\ndef df_info(df):\n    print(\"----------Top-5- Record----------\")\n    print(df.head(5))\n    print(\"-----------Information-----------\")\n    print(df.info())\n    print(\"-----------Data Types-----------\")\n    print(df.dtypes)\n    print(\"----------Missing value-----------\")\n    print(df.isnull().sum())\n    print(\"----------Null value-----------\")\n    print(df.isna().sum())\n    print(\"----------Shape of Data----------\")\n    print(df.shape)\n    print(\"----------description of Data----------\")\n    print(df.describe())\n    print(\"----------Uniques of Data----------\")\n    print(df.nunique())\n    print(\"------------Columns in data---------\")\n    print(df.columns)\n\ndef downcast_dtypes(df):\n    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n    int_cols = [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n    df[float_cols] = df[float_cols].astype(np.float32)\n    df[int_cols] = df[int_cols].astype(np.int16)\n    return df\ndef model_performance_sc_plot( predictions, labels, title ):\n    min_val = max(max(predictions), max(labels))\n    max_val = min(min(predictions), min(labels))\n    \n    performance_df = pd.DataFrame({\"Labels\": labels})\n    performance_df[\"Predictions\"] = predictions\n    sns.jointplot(y = \"Labels\", x = \"Predictions\", data = performance_df,kind = \"reg\")\n    plt.plot([min_val,max_val],[min_val, max_val],\"m--\")\n    plt.title(title)\n    plt.show()\n    \ndef calculate_counts(column_name, ref_sets, extension_set):\n    ref_sets_ids = [set(ref[column_name]) for ref in ref_sets]\n    ext_ids = set(extension_set[column_name])\n    \n    refs_union = reduce(lambda s1, s2: s1 | s2, ref_sets_ids)\n    \n    ref_counts = [len(ref) for ref in ref_sets_ids]\n    ext_count = len(ext_ids)\n    union_count = len(refs_union)\n    intersection_count = len(ext_ids & refs_union)\n    \n    all_counts = ref_counts + [union_count, ext_count, intersection_count]\n    res_index = [\"Ref {}\".format(i) for i in range(1, len(ref_sets) + 1)] +\\\n        ['Refs Union', 'Extension', 'Union x Extension']\n    \n    return pd.DataFrame({'Count': all_counts},\n                        index=res_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = \"/kaggle/input/airplane-accidents-severity-dataset/train.csv\"\ntest_path = \"/kaggle/input/airplane-accidents-severity-dataset/test.csv\"\nsubmission_path = \"/kaggle/input/airplane-accidents-severity-dataset/sample_submission.csv\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(train_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_info(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set\ndef ecdf(data):\n    \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\"\n    # Number of data points: n\n    n = len(data)\n\n    # x-data for the ECDF: x\n    x = np.sort(data)\n\n    # y-data for the ECDF: y\n    y = np.arange(1, n+1) / n\n\n    return x, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Severity\"].replace(\"Minor_Damage_And_Injuries\", 0 ,inplace= True)\ntrain[\"Severity\"].replace(\"Significant_Damage_And_Fatalities\", 1 ,inplace= True)\ntrain[\"Severity\"].replace(\"Significant_Damage_And_Serious_Injuries\", 2 ,inplace= True)\ntrain[\"Severity\"].replace(\"Highly_Fatal_And_Damaging\", 3 ,inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accident type code mean wrt control metric, Severity, Turbulence, Maxelevation, Adverse Weatehr"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"Control_Metric\"] = train[\"Control_Metric\"].clip(25,100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"means_accident_code = train.groupby([\"Accident_Type_Code\"]).agg({\"Severity\": \"mean\",\"Safety_Score\": \"mean\", \"Days_Since_Inspection\": \"mean\", \"Total_Safety_Complaints\" :\"mean\", \"Control_Metric\": \"mean\", \"Turbulence_In_gforces\" :\"mean\", \"Cabin_Temperature\": \"mean\", \"Max_Elevation\" :\"mean\",\"Violations\": \"mean\", \"Adverse_Weather_Metric\" : \"mean\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"means_accident_code = means_accident_code.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = list(means_accident_code.columns)\nfor i in range(1,len(cols)):\n    cols[i] = cols[i] + \"_mean\"\nprint(cols)\nmeans_accident_code.columns = cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train = train.merge(means_accident_code, on = [\"Accident_Type_Code\"], how = \"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby([\"Accident_Type_Code\"])[\"Accident_ID\"].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train.groupby([\"Accident_Type_Code\", \"Severity\"])[\"Severity\"].agg({\"no\" : \"count\"})\nmask = df.groupby(level=0).agg('idxmax')\ndf_count = df.loc[mask['no']]\ndf_count[\"no\"] = df_count[\"no\"]/ train.groupby([\"Accident_Type_Code\"])[\"Accident_ID\"].nunique()\n# df_count.drop([\"no\"], axis = 1, inplace= True)\ndf_count = df_count.reset_index()\ndf_count.columns = [\"Accident_Type_Code\", \"Severity_max\",\"Severity_count\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.merge(df_count, on = [\"Accident_Type_Code\"], how = \"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop([\"Accident_Type_Code\"], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop([\"Severity\", \"Accident_ID\"], axis = 1)\nY = train[\"Severity\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l_quan = ['Safety_Score','Control_Metric','Turbulence_In_gforces','Cabin_Temperature','Max_Elevation','Adverse_Weather_Metric','Total_Safety_Complaints','Severity_count']\nl_cato = [\"Violations\" , \"Days_Since_Inspection\", \"Severity_max\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for a in l_quan:\n    sns.distplot(X[a])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for a in l_cato:\n    sns.countplot(X[a])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for a in l_quan:\n    x1,y1 = ecdf(X[a])\n    x2,y2 = ecdf( np.random.normal( np.mean(X[a]), np.std(X[a]),size = 10000 ) )\n    plt.plot(x1,y1,marker = \"+\", linestyle = None)\n    plt.xlabel(a)\n    plt.plot(x2,y2)\n    plt.legend([\"real\", \"theory\"])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X[\"Total_Safety_Complaints\"] = np.log(X[\"Total_Safety_Complaints\"] + 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = \"Total_Safety_Complaints\"\nx1,y1 = ecdf(X[a])\nx2,y2 = ecdf( np.random.normal( np.mean(X[a]), np.std(X[a]),size = 10000 ) )\nplt.plot(x1,y1,marker = \"+\", linestyle = None)\nplt.xlabel(a)\nplt.plot(x2,y2)\nplt.legend([\"real\", \"theory\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"log+1 [\"Total_Safety_Complaints\"]"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nss = StandardScaler().fit(X[l_quan])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_quan = pd.DataFrame(ss.transform(X[l_quan]),columns = l_quan, index = X.index )\nX[l_quan] = x_quan\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(test_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test = test.merge(means_accident_code, on = [\"Accident_Type_Code\"], how = \"left\")\ntest = test.merge(df_count, on = [\"Accident_Type_Code\"], how = \"left\")\ntest.drop([\"Accident_Type_Code\"], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = test.drop([\"Accident_ID\"], axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test[\"Total_Safety_Complaints\"] = np.log(x_test[\"Total_Safety_Complaints\"] + 1)\nx_test_quan = pd.DataFrame(ss.transform(x_test[l_quan]), columns = l_quan, index = x_test.index)\nx_test[l_quan] = x_test_quan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# corr = X.corr(train[\"Severity\"])\n# plt.figure(1,(50,16))\n# ax = sns.heatmap(\n#     corr, \n# )\n# ax.set_xticklabels(\n#     ax.get_xticklabels(),\n#     rotation=45,\n#     horizontalalignment='right'\n# )\n# ax.set_yticklabels(\n#     ax.get_yticklabels(),\n#     rotation=0,\n#     horizontalalignment='right'\n# )\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sns.countplot(Y)\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cb = CatBoostClassifier()\n# from xgboost import XGBClassifier\n# xgbRegressor = XGBClassifier()\n# from sklearn.model_selection import RandomizedSearchCV\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# params_xgb = {\n#     \"num_rounds\" : [100,200,400,],\n#     \"eta\" : [0.05, 0.1,0.15, 0.2, 0.25, 0.30],\n#     \"learning_rate\" : [0.28, 0.23, 0.25, 0.30],\n#     \"min_child_weight\" : [1,3,5,7,10],\n#     \"gamma\" : [0.05, 0.1,0.2, 0.3, 0.4],\n#     \"colsample_bytree\" : [0.5,0.7, 0.8,0.9],\n#     \"subsample\" : [0.8,0.9,0.5,0.7],\n#     \"max_depth\" : [6,7,9,11,13],\n#     \"n_estimators\" : [450, 350, 400, 550, 500],\n# }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cb = CatBoostClassifier(iterations = 1500,\n#                        max_ctr_complexity = 10,\n#                        random_seed =  0,\n#                        od_type = \"Iter\", \n#                        od_wait = 50,\n#                        verbose = 100,\n#                        depth  = 12,\n#                        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import KFold\n\n# from collections import Counter\n# n_splits = 5\n# kf = KFold(n_splits = n_splits, shuffle = True)\n# y_pred = np.zeros((Y.shape[0],4))\n# test_pred_cb = np.zeros((test.shape[0], 4))\n# sums_score = 0\n# cat_features = l_cato\n# for train_index, test_index in kf.split(X):\n#     x_train, y_train = X.loc[train_index,:] , Y[train_index]\n#     x_val, y_val = X.loc[test_index,:] , Y[test_index]\n#     cb.fit(x_train , y_train ,cat_features = cat_features)\n#     y_pred_cb = cb.predict_proba(x_val)\n#     y_pred[test_index] += y_pred_cb/n_splits\n#     test_pred_cb += cb.predict_proba(x_test)/n_splits\n#     y_pred_cb = cb.predict(x_val)\n#     print(\"F1_Score val1 : \", f1_score(y_val, y_pred_cb,average='weighted'))  \n#     sums_score +=  f1_score(y_val, y_pred_cb,average='weighted')\n# print(\"CV_mean: \", sums_score / n_splits)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# xgbRegressor = XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import KFold\n\n# n_splits = 5\n# kf = KFold(n_splits = n_splits, shuffle = True)\n# y_pred_xg = np.zeros((Y.shape[0],4))\n# sums_score = 0\n# test_pred_xg = np.zeros((test.shape[0], 4))\n# for train_index, test_index in kf.split(X):\n#     x_train, y_train = X.loc[train_index,:] , Y[train_index]\n#     x_val, y_val = X.loc[test_index,:] , Y[test_index]\n    \n   \n#     xgbRegressor.fit(x_train , y_train, verbose = 100)\n#     y_pred_x = xgbRegressor.predict_proba(x_val)\n#     print(y_pred_x.shape)\n#     y_pred_xg[test_index] += y_pred_x.reshape(-1,4)/n_splits\n#     y_pred_x = xgbRegressor.predict(x_val)\n#     test_pred_xg += xgbRegressor.predict_proba(x_test)/n_splits\n#     print(\"F1_Score val1 : \", f1_score(y_train, xgbRegressor.predict(x_train),average='weighted'))\n#     print(\"F1_Score val1 : \", f1_score(y_val, y_pred_x,average='weighted'))\n#     sums_score +=  f1_score(y_val, y_pred_x,average='weighted')\n# print(\"CV_mean: \", sums_score / n_splits)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def learning_rate_010_decay_power_099(current_iter):\n#     base_learning_rate = 0.1\n#     lr = base_learning_rate  * np.power(.99, current_iter)\n#     return lr if lr > 1e-3 else 1e-3\n\n# def learning_rate_010_decay_power_0995(current_iter):\n#     base_learning_rate = 0.1\n#     lr = base_learning_rate  * np.power(.995, current_iter)\n#     return lr if lr > 1e-3 else 1e-3\n\n# def learning_rate_005_decay_power_099(current_iter):\n#     base_learning_rate = 0.05\n#     lr = base_learning_rate  * np.power(.99, current_iter)\n#     return lr if lr > 1e-3 else 1e-3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\n# param_test ={\n#     'boost': 'gbdt',\n#     'learning_rate': 0.01,\n#     \"num_leaves\" : 80,\n#     \"min_data_in_leaf\" : 50,\n#     \"max_depth\" : 13,\n#     'min_sum_hessian_in_leaf': 10.0,\n#     'num_threads': 8,\n#     'tree_learner': 'serial',\n#     'objective': 'multiclass', \n#     'verbosity': -1,\n#     \"num_classes\" : 4\n    \n# }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import StratifiedKFold, KFold\n# import lightgbm as lgb\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import KFold\n# num_folds = 5\n# features = [c for c in train.columns if c not in ['Accident_ID', 'Severity']]\n\n# folds = KFold(n_splits=num_folds, random_state=2319)\n# oof = np.zeros((len(X),4))\n# getVal = np.zeros((len(X), 4))\n# predictions = np.zeros((len(test),4))\n# feature_importance_df = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_pred_lgb = np.zeros((Y.shape[0],4))\n# sums_score = 0\n# for train_index, test_index in folds.split(X):\n#     x_train, y_train = X.iloc[train_index][features] , Y[train_index]\n#     x_val, y_val = X.iloc[test_index][features] , Y[test_index]\n    \n#     train_data = lgb.Dataset(x_train , label = y_train)\n#     val_data = lgb.Dataset(x_val, label = y_val)\n    \n#     param = {\n#     'boost': 'gbdt',\n#     'learning_rate': 0.01,\n#     \"min_data_in_leaf\" : 50,'num_leaves':100, 'objective':'multiclass', 'num_class':4, 'metric':'multi_logloss', 'seed':7}\n#     num_round = 3000\n    \n#     clf = lgb.train(param, train_data, num_round, valid_sets=[val_data], early_stopping_rounds=120, verbose_eval=False, categorical_feature = l_cato)\n#     oof[test_index] = clf.predict(train.iloc[test_index][features], num_iteration=clf.best_iteration)\n#     getVal[test_index]+= clf.predict(train.iloc[test_index][features], num_iteration=clf.best_iteration) / folds.n_splits\n    \n#     fold_importance_df = pd.DataFrame()\n#     fold_importance_df[\"feature\"] = features\n#     fold_importance_df[\"importance\"] = clf.feature_importance()\n#     fold_importance_df[\"fold\"] = sums_score + 1\n#     feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n#     sums_score+=1\n#     predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n#     print(\"CV : \", f1_score(y_val, oof[test_index].argmax(axis = 1), average = \"weighted\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cols = (feature_importance_df[[\"feature\", \"importance\"]]\n#         .groupby(\"feature\")\n#         .mean()\n#         .sort_values(by=\"importance\", ascending=False)[:1000].index)\n# best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n\n# plt.figure(figsize=(14,26))\n# sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\n# plt.title('LightGBM Features (averaged over folds)')\n# plt.tight_layout()\n# plt.savefig('lgbm_importances.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# f_imps = {}\n# for i in range(len(X.columns)):\n#     f_imps[X.columns[i]] = xgbRegressor.feature_importances_[i]\n# f_imps = {k: v for k, v in sorted(f_imps.items(), key=lambda item: item[1])}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list(f_imps.keys())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"['Violations',\n 'Max_Elevation',\n 'Cabin_Temperature',\n 'Total_Safety_Complaints',\n 'Control_Metric_mean',\n 'Cabin_Temperature_mean',\n 'Turbulence_In_gforces_mean',\n 'Adverse_Weather_Metric',\n 'Turbulence_In_gforces',\n 'Violations_mean',\n 'Control_Metric',\n 'Safety_Score',\n 'Total_Safety_Complaints_mean',\n 'Days_Since_Inspection',\n 'Adverse_Weather_Metric_mean',\n 'Severity_mean',\n 'Max_Elevation_mean',\n 'Safety_Score_mean',\n 'Days_Since_Inspection_mean',\n 'Severity_max']"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.figure(1,(50,16))\n# sns.barplot(x =list(f_imps.keys()), y = list(f_imps.values()), )\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# first_level = pd.DataFrame(y_pred, columns = [\"catboost_0\",\"catboost_1\",\"catboost_2\",\"catboost_3\"])\n# # first_level[[\"XGB_0\",\"XGB_1\",\"XGB_2\",\"XGB_3\"]] =  y_pred_xg \n# first_level[\"XGB_0\"] = y_pred_xg[:,0]\n# first_level[\"XGB_1\"] = y_pred_xg[:,1]\n# first_level[\"XGB_2\"] = y_pred_xg[:,2]\n# first_level[\"XGB_3\"] = y_pred_xg[:,3]\n# first_level[\"LGBM_0\"] = getVal[:,0]\n# first_level[\"LGBM_1\"] = getVal[:,1]\n# first_level[\"LGBM_2\"] = getVal[:,2]\n# first_level[\"LGBM_3\"] = getVal[:,3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# first_level_test = pd.DataFrame(test_pred_cb, columns = [\"catboost_0\",\"catboost_1\",\"catboost_2\",\"catboost_3\"])\n# first_level_test[\"XGB_0\"] = test_pred_xg[:,0]\n# first_level_test[\"XGB_1\"] = test_pred_xg[:,1]\n# first_level_test[\"XGB_2\"] = test_pred_xg[:,2]\n# first_level_test[\"XGB_3\"] = test_pred_xg[:,3]\n# first_level_test[\"LGBM_0\"] = predictions[:,0]\n# first_level_test[\"LGBM_1\"] = predictions[:,1]\n# first_level_test[\"LGBM_2\"] = predictions[:,2]\n# first_level_test[\"LGBM_3\"] = predictions[:,3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# np.save(\"first_level.npy\",first_level)\n# np.save(\"Y.npy\",Y)\n# np.save(\"first_level_test.npy\",first_level_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# first_level_train, first_level_val , y_train, y_val = train_test_split(first_level, Y, test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# params_xgb = {\n#     \"num_rounds\" : [100,200,400],\n#     \"eta\" : [0.05, 0.1,0.15, 0.2, 0.25, 0.30],\n#     \"learning_rate\" : [0.28, 0.23, 0.25, 0.2,0.1],\n#     \"min_child_weight\" : [1,3,5,7,10],\n#     \"gamma\" : [0.05, 0.1,0.2, 0.3, 0.4],\n#     \"colsample_bytree\" : [0.5,0.7, 0.8,0.9],\n#     \"subsample\" : [0.8,0.9,0.5,0.7],\n#     \"max_depth\" : [6,7,9,11,13],\n#     \"n_estimators\" : [25,50,100,75],\n# }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# random_search = RandomizedSearchCV(estimator = xgbRegressor, param_distributions = params_xgb, scoring = \"f1_weighted\", n_jobs = -1, cv = 5, verbose = 3, n_iter=200, )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# random_search.fit(first_level,Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# random_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# random_search.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# metamodel = random_search.best_estimator_\n# from sklearn.linear_model import RidgeClassifierCV\n# # metamodel = RidgeClassifierCV(cv = 5, scoring = \"f1_weighted\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# metamodel.fit(first_level, Y, eval_set = [(first_level_train,y_train),(first_level_val, y_val)], verbose = 20, early_stopping_rounds = 20)\n# metamodel.fit(first_level, Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ensemble_pred = metamodel.predict(first_level_val)\n# test_pred = metamodel.predict(first_level_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(\"Val F1-Score :\", f1_score(y_val, ensemble_pred, average = \"weighted\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model_performance_sc_plot(ensemble_pred, y_val, \"Validation\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# from imblearn.over_sampling import SMOTE\n# sm = SMOTE(strategy = \"not majority\", random_state = 42)\n# x_res,y_res = sm.fit_resample(X,Y)\n# xgbRegressor.fit(x_res, y_res, eval_set = [(X,Y),(x_val1, y_val1)], verbose = 20, early_stopping_rounds = 120)\n# test_pred = xgbRegressor.predict(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(train_path)\ntest = pd.read_csv(test_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = []\nfor i in train.columns:\n    if i in [\"Accident_ID\" , \"Severity\"]:\n        continue\n    features.append(i)\ntarget = [\"Severity\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame()\ntrain[\"type\"] = \"train\"\ntest[\"type\"] = \"test\"\ndf = pd.concat([df,train,test],axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats = [\"Days_Since_Inspection\", \"Total_Safety_Complaints\", \"Accident_Type_Code\", \"Violations\"]\nfor cat in cats:\n    one_hot = pd.get_dummies(df[cat], prefix = str(cat))\n    train.drop(cat, axis = 1, inplace= True)\n    test.drop(cat,axis = 1, inplace= True)\n    train = train.join(one_hot.loc[df[\"type\"]==\"train\",:])\n    test = test.join(one_hot.loc[df[\"type\"]==\"test\",:])\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in train.columns:\n    if col not in test.columns:\n        print(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop([\"type\"],axis = 1, inplace= True)\ntest.drop([\"type\"],axis = 1, inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop([\"Severity\"],axis = 1)\nY = train[\"Severity\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nxgbRegressor = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.7, eta=0.05, gamma=0.3,\n              learning_rate=0.23, max_delta_step=0, max_depth=9,\n              min_child_weight=1, missing=None, n_estimators=650, n_jobs=-1,\n              nthread=None, num_rounds=200, objective='multi:softprob',\n              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n              seed=None, silent=None, subsample=0.8, verbosity=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in X.columns:\n    if col not in x_test:\n        print(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nn_splits = 5\nkf = KFold(n_splits = n_splits, shuffle = True)\ny_pred_xg = np.zeros((Y.shape[0],4))\nsums_score = 0\ntest_pred_xg = np.zeros((test.shape[0], 4))\nfor train_index, test_index in kf.split(X):\n    x_train, y_train = X.loc[train_index,:] , Y[train_index]\n    x_val, y_val = X.loc[test_index,:] , Y[test_index]\n    xgbRegressor.fit(x_train , y_train, verbose = 100)\n    y_pred_x = xgbRegressor.predict_proba(x_val)\n    print(y_pred_x.shape)\n    y_pred_xg[test_index] += y_pred_x.reshape(-1,4)/n_splits\n    y_pred_x = xgbRegressor.predict(x_val)\n    test_pred_xg += xgbRegressor.predict_proba(x_test)/n_splits\n    print(\"F1_Score val1 : \", f1_score(y_train, xgbRegressor.predict(x_train),average='weighted'))\n    print(\"F1_Score val1 : \", f1_score(y_val, y_pred_x,average='weighted'))\n    sums_score +=  f1_score(y_val, y_pred_x,average='weighted')\nprint(\"CV_mean: \", sums_score / n_splits)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgbRegressor.fit(X,Y)\ntest_pred = xgbRegressor.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = test_pred\ny_pred = y_pred.astype(np.int32)\ny_pred = lb.inverse_transform(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = []\nfor i in range(test.shape[0]):\n    ids.append(test.loc[i,\"Accident_ID\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame(ids, columns= [\"Accident_ID\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub[\"Severity\"] = y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"Submission.csv\",index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}