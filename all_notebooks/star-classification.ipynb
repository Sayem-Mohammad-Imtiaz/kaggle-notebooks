{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport pandas_profiling as pro\nimport missingno as msno","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/star-type-classification/Stars.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(msno.bar(df))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pro.ProfileReport(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###########################\n# Data is well balanced\n###########################\nsns.countplot(df['Type'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#######################\n# Let's Split the data:\n\nx = df.iloc[:,:-1]\ny = df.iloc[:,-1:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import category_encoders as ce\nimport pandas as pd\n  \n# Define catboost encoder\ncbe_encoder = ce.cat_boost.CatBoostEncoder()\n  \n# Fit encoder and transform the features\ncbe_encoder.fit_transform(x, y)\ntrain_cbe = cbe_encoder.transform(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_cbe","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split as tts\n\nx_train, x_test, y_train, y_test = tts(train_cbe,y, test_size=0.5, random_state=13)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score\nfrom sklearn.preprocessing import LabelBinarizer\nfrom mlxtend.plotting import plot_confusion_matrix\nimport matplotlib.pyplot as plt\n\ndef evaluator(y_test, y_pred):    \n    \n    # Accuracy:\n    print('Accuracy is: ', accuracy_score(y_test,y_pred))\n    print('')\n    # Classification Report:\n    print('Classification Report: \\n',classification_report(y_test,y_pred))\n\n    # Area Under The Curve Score:\n\n    lb = LabelBinarizer()\n    y_test1 = lb.fit_transform(y_test)\n    y_pred1 =lb.transform(y_pred)\n    print('AUC_ROC Score: ',roc_auc_score(y_test1,y_pred1,average='macro'),'\\n\\n')\n\n    print('Confusion Matrix: \\n\\n')\n    plt.style.use(\"ggplot\")\n    cm = confusion_matrix(y_test,y_pred)\n    plot_confusion_matrix(conf_mat = cm,figsize=(8,6),show_normed=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier as rfc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_classifier = rfc()\nrf_classifier.fit(x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_rf = rf_classifier.predict(x_test)\n\nevaluator(y_test, pred_rf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"important_features = pd.DataFrame({'Features': x.columns, \n                                   'Importance': rf_classifier.feature_importances_})\n\n# sort the dataframe in the descending order according to the feature importance\nimportant_features = important_features.sort_values('Importance', ascending = False)\n\n# create a barplot to visualize the features based on their importance\nsns.barplot(x = 'Importance', y = 'Features', data = important_features)\n\n# add plot and axes labels\n# set text size using 'fontsize'\nplt.title('Feature Importance', fontsize = 15)\nplt.xlabel('Importance', fontsize = 15)\nplt.ylabel('Features', fontsize = 15)\n\n# display the plot\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking for overfitting:","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom matplotlib import pyplot\n# define lists to collect scores\ntrain_scores, test_scores = list(), list()\n# define the tree depths to evaluate\nvalues = [i for i in range(1, 21)]\n# evaluate a decision tree for each depth\nfor i in values:\n    # configure the model\n    model = DecisionTreeClassifier(max_depth=i)\n    # fit model on the training dataset\n    model.fit(x_train, y_train)\n    # evaluate on the train dataset\n    train_yhat = model.predict(x_train)\n    train_acc = accuracy_score(y_train, train_yhat)\n    train_scores.append(train_acc)\n    # evaluate on the test dataset\n    test_yhat = model.predict(x_test)\n    test_acc = accuracy_score(y_test, test_yhat)\n    test_scores.append(test_acc)\n    # summarize progress\n    print('>%d, train: %.3f, test: %.3f' % (i, train_acc, test_acc))\n# plot of train and test scores vs tree depth\npyplot.plot(values, train_scores, '-o', label='Train')\npyplot.plot(values, test_scores, '-o', label='Test')\npyplot.legend()\npyplot.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nk = 10\nkf = KFold(n_splits=k, shuffle = True)\nr_classifier = rfc()\n \nacc_score = []\n \nfor train_index , test_index in kf.split(x):\n    x_train,x_test, y_train, y_test = tts(train_cbe,y, test_size = 0.3)\n     \n    r_classifier.fit(x_train,y_train)\n    pred_values = model.predict(x_test)\n     \n    acc = accuracy_score(pred_values , y_test)\n    acc_score.append(acc)\n     \navg_acc_score = sum(acc_score)/k\n \nprint('accuracy of each fold - {}'.format(acc_score))\nprint('Avg accuracy : {}'.format(avg_acc_score))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Author: Avinash Bagul\n\n### Note: please comment mistakes if any...","metadata":{}},{"cell_type":"markdown","source":"#","metadata":{}}]}