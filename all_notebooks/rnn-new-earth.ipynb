{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # 导入NumPy\nimport pandas as pd # 导入Pandas\ndf_train = pd.read_csv('../input/new-earth/exoTrain.csv') # 导入训练集\ndf_test = pd.read_csv('../input/new-earth/exoTest.csv') # 导入测试集\nprint(df_train.head()) # 输入头几行数据\nprint(df_train.info()) # 输出训练集信息","metadata":{"execution":{"iopub.status.busy":"2021-06-18T10:37:18.021462Z","iopub.execute_input":"2021-06-18T10:37:18.021804Z","iopub.status.idle":"2021-06-18T10:37:23.09963Z","shell.execute_reply.started":"2021-06-18T10:37:18.021773Z","shell.execute_reply":"2021-06-18T10:37:23.098615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import shuffle # 导入乱序工具\ndf_train = shuffle(df_train) # 乱序训练集\ndf_test = shuffle(df_test)  # 乱序测试集","metadata":{"execution":{"iopub.status.busy":"2021-06-18T10:37:23.101485Z","iopub.execute_input":"2021-06-18T10:37:23.101994Z","iopub.status.idle":"2021-06-18T10:37:23.177404Z","shell.execute_reply.started":"2021-06-18T10:37:23.101955Z","shell.execute_reply":"2021-06-18T10:37:23.176515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = df_train.iloc[:, 1:].values # 构建特征集（训练）\ny_train = df_train.iloc[:, 0].values # 构建标签集（训练）\nX_test = df_test.iloc[:, 1:].values # 构建特征集（测试）\ny_test = df_test.iloc[:, 0].values # 构建标签集（测试）\ny_train = y_train - 1 # 标签转换成惯用的(0，1)分类\ny_test = y_test - 1 # 标签转换成惯用的(0，1)分类\nprint (X_train) # 打印训练集中的特征\nprint (y_train) # 打印训练集中的标签","metadata":{"execution":{"iopub.status.busy":"2021-06-18T10:37:32.674586Z","iopub.execute_input":"2021-06-18T10:37:32.674909Z","iopub.status.idle":"2021-06-18T10:37:32.726925Z","shell.execute_reply.started":"2021-06-18T10:37:32.674877Z","shell.execute_reply":"2021-06-18T10:37:32.725353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.expand_dims(X_train, axis=2) # 张量升阶，以满足序列数据集的要求\nX_test = np.expand_dims(X_test, axis=2) # 张量升阶，以满足序列数据集的要求","metadata":{"execution":{"iopub.status.busy":"2021-06-18T10:22:02.419562Z","iopub.execute_input":"2021-06-18T10:22:02.419887Z","iopub.status.idle":"2021-06-18T10:22:02.424733Z","shell.execute_reply.started":"2021-06-18T10:22:02.419859Z","shell.execute_reply":"2021-06-18T10:22:02.423598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(len(X_train))\nprint(X_test.shape)\nprint(len(X_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-18T10:22:03.443047Z","iopub.execute_input":"2021-06-18T10:22:03.443404Z","iopub.status.idle":"2021-06-18T10:22:03.450381Z","shell.execute_reply.started":"2021-06-18T10:22:03.443373Z","shell.execute_reply":"2021-06-18T10:22:03.449336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential # 导入序贯模型\nfrom keras import layers # 导入所有类型的层\nfrom keras.optimizers import Adam # 导入优化器\nmodel = Sequential() # 序贯模型\nmodel.add(layers.Conv1D(32, kernel_size=10, strides=4,\n          input_shape=(3197, 1))) # 1D CNN层\nmodel.add(layers.MaxPooling1D(pool_size=4, strides=2)) # 池化层\nmodel.add(layers.GRU(256, return_sequences=True)) # 关键，GRU层够要大\nmodel.add(layers.Flatten()) # 展平\nmodel.add(layers.Dropout(0.5)) # Dropout层\nmodel.add(layers.BatchNormalization()) # 批标准化   \nmodel.add(layers.Dense(1, activation='sigmoid')) # 分类输出层\nopt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01) # 设置优化器\nmodel.compile(optimizer=opt, # 优化器\n              loss = 'binary_crossentropy', # 交叉熵\n              metrics=['accuracy']) # 准确率","metadata":{"execution":{"iopub.status.busy":"2021-06-18T10:24:37.706071Z","iopub.execute_input":"2021-06-18T10:24:37.706466Z","iopub.status.idle":"2021-06-18T10:24:45.179915Z","shell.execute_reply.started":"2021-06-18T10:24:37.706433Z","shell.execute_reply":"2021-06-18T10:24:45.179179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train,y_train, # 训练集\n                    validation_split = 0.2, # 部分训练集数据拆分成验证集\n                    batch_size = 128, # 批量大小\n                    epochs = 4, # 训练轮次\n                    shuffle = True) # 乱序","metadata":{"execution":{"iopub.status.busy":"2021-06-18T10:25:09.048086Z","iopub.execute_input":"2021-06-18T10:25:09.048431Z","iopub.status.idle":"2021-06-18T10:25:20.228044Z","shell.execute_reply.started":"2021-06-18T10:25:09.048398Z","shell.execute_reply":"2021-06-18T10:25:20.227294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report # 分类报告\nfrom sklearn.metrics import confusion_matrix # 混淆矩阵\ny_prob = model.predict(X_test) # 对测试集进行预测\ny_pred =  np.where(y_prob > 0.5, 1, 0) #将概率值转换成真值\ncm = confusion_matrix(y_pred, y_test)\nprint('Confusion matrix:\\n', cm, '\\n')\nprint(classification_report(y_pred, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-18T10:26:02.235474Z","iopub.execute_input":"2021-06-18T10:26:02.235834Z","iopub.status.idle":"2021-06-18T10:26:02.813823Z","shell.execute_reply.started":"2021-06-18T10:26:02.235803Z","shell.execute_reply":"2021-06-18T10:26:02.813131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(len(y_prob)):\n#      if y_prob[i] >= 0.5: \n#         y_pred[i] = 1\n#      else:\n#         y_pred[i] = 0\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred =  np.where(y_prob > 0.2, 1, 0) # 进行阈值调整\ncm = confusion_matrix(y_pred, y_test) \nprint('Confusion matrix:\\n', cm, '\\n')\nprint(classification_report(y_pred, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-18T10:26:55.405217Z","iopub.execute_input":"2021-06-18T10:26:55.405544Z","iopub.status.idle":"2021-06-18T10:26:55.419978Z","shell.execute_reply.started":"2021-06-18T10:26:55.405515Z","shell.execute_reply":"2021-06-18T10:26:55.418968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred =  np.where(y_prob > 0.15, 1, 0) # 进行阈值调整\ncm = confusion_matrix(y_pred, y_test) \nprint('Confusion matrix:\\n', cm, '\\n')\nprint(classification_report(y_pred, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-18T10:27:13.456936Z","iopub.execute_input":"2021-06-18T10:27:13.457281Z","iopub.status.idle":"2021-06-18T10:27:13.473022Z","shell.execute_reply.started":"2021-06-18T10:27:13.457251Z","shell.execute_reply":"2021-06-18T10:27:13.471637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**下面是两个函数式API的构建代码段，请读者自行研究如何使用函数式API建构更灵活的模型。**","metadata":{}},{"cell_type":"code","source":"from keras import layers # 导入各种层\nfrom keras.models import Model # 导入模型\nfrom keras.optimizers import Adam # 导入Adam优化器\ninput = layers.Input(shape=(3197, 1)) # Input\n# 通过函数式API构建模型\nx = layers.Conv1D(32, kernel_size=10, strides=4)(input)\nx = layers.MaxPooling1D(pool_size=4, strides=2)(x)\nx = layers.GRU(256, return_sequences=True)(x)\nx = layers.Flatten()(x)\nx = layers.Dropout(0.5)(x)\nx = layers.BatchNormalization()(x)\noutput = layers.Dense(1, activation='sigmoid')(x) # Output\nmodel = Model(input, output) \nmodel.summary() # 显示模型的输出\nopt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01) # 设置优化器\nmodel.compile(optimizer=opt, # 优化器\n              loss = 'binary_crossentropy', # 交叉熵\n              metrics=['accuracy']) # 准确率","metadata":{"execution":{"iopub.status.busy":"2021-06-18T10:28:55.739574Z","iopub.execute_input":"2021-06-18T10:28:55.739925Z","iopub.status.idle":"2021-06-18T10:28:55.978958Z","shell.execute_reply.started":"2021-06-18T10:28:55.739893Z","shell.execute_reply":"2021-06-18T10:28:55.977528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_rev = [X[::-1] for X in X_train]\nX_test_rev = [X[::-1] for X in X_test]\nX_train = np.expand_dims(X_train, axis=2)\nX_train_rev = np.expand_dims(X_train_rev, axis=2)\nX_test = np.expand_dims(X_test, axis=2)\nX_test_rev = np.expand_dims(X_test_rev, axis=2)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T10:37:46.082523Z","iopub.execute_input":"2021-06-18T10:37:46.082898Z","iopub.status.idle":"2021-06-18T10:37:46.185019Z","shell.execute_reply.started":"2021-06-18T10:37:46.082858Z","shell.execute_reply":"2021-06-18T10:37:46.184114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train_rev.shape)\nprint(y_train.shape)\nprint(y_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T10:44:27.544627Z","iopub.execute_input":"2021-06-18T10:44:27.544973Z","iopub.status.idle":"2021-06-18T10:44:27.550627Z","shell.execute_reply.started":"2021-06-18T10:44:27.54494Z","shell.execute_reply":"2021-06-18T10:44:27.54948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 构建正向网络\ninput_1 = layers.Input(shape=(3197, 1))\nx = layers.GRU(32, return_sequences=True)(input_1)\nx = layers.Flatten()(x)\nx = layers.Dropout(0.5)(x)\n# 构建逆向网络\ninput_2 = layers.Input(shape=(3197, 1))\ny = layers.GRU(32, return_sequences=True)(input_2)\ny = layers.Flatten()(y)\ny = layers.Dropout(0.5)(y)\n# 连接两个网络\nz = layers.concatenate([x, y])\noutput = layers.Dense(1, activation='sigmoid')(z)\nmodel = Model([input_1,input_2], output)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-18T10:44:38.217655Z","iopub.execute_input":"2021-06-18T10:44:38.217978Z","iopub.status.idle":"2021-06-18T10:44:38.574477Z","shell.execute_reply.started":"2021-06-18T10:44:38.217947Z","shell.execute_reply":"2021-06-18T10:44:38.57338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01) # 设置优化器\nmodel.compile(optimizer=opt, # 优化器\n              loss = 'binary_crossentropy', # 交叉熵\n              metrics=['accuracy']) # 准确率","metadata":{"execution":{"iopub.status.busy":"2021-06-18T10:44:40.819815Z","iopub.execute_input":"2021-06-18T10:44:40.820157Z","iopub.status.idle":"2021-06-18T10:44:40.832509Z","shell.execute_reply.started":"2021-06-18T10:44:40.820126Z","shell.execute_reply":"2021-06-18T10:44:40.831607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"histroy = model.fit([X_train, X_train_rev],y_train,\n                   validation_split = 0.2,\n                   batch_size = 128,\n                   epochs = 1,\n                   shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T10:44:50.710305Z","iopub.execute_input":"2021-06-18T10:44:50.710617Z","iopub.status.idle":"2021-06-18T10:45:02.140975Z","shell.execute_reply.started":"2021-06-18T10:44:50.710587Z","shell.execute_reply":"2021-06-18T10:45:02.139962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}