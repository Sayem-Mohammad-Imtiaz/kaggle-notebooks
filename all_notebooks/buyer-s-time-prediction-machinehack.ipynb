{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Problem\nBuyers spend a significant amount of time surfing an e-commerce store, since the pandemic the e-commerce has seen a boom in the number of users across the domains. In the meantime, the store owners are also planning to attract customers using various algorithms to leverage customer behavior patterns.\n\nTracking customer activity is also a great way of understanding customer behavior and figuring out what can actually be done to serve them better. Machine learning and AI has already played a significant role in designing various recommendation engines to lure customers by predicting their buying patterns.\n\n`In this competition provided the visitor's session data, we are challenging the Machinehack community to come up with a regression algorithm to predict the time a buyer will spend on the platform.`\n\n#### What is the Metric In this competition?\nThe submission will be evaluated using the RMSLE metric. \n\nOne can use np.sqrt(mean_squared_log_error(actual, predicted)) to calculate the same."},{"metadata":{},"cell_type":"markdown","source":"## In this notebook\n1. Basic EDA with comments and cleaning of data with feature removing and feature extraction.\n2. Use four techniques namely - `linear regression`, `xg boost`, `decision tree` and `random forest` to predict the time and also display the RMSLE of train data.\n3. To check your RMSLE of test data, click [here](https://www.machinehack.com/hackathons/buyers_time_prediction_challenge/submission)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing the libraries\n\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_style('darkgrid')\n\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xg\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.metrics import r2_score, mean_squared_error,mean_squared_log_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\nfrom scipy.stats import uniform, randint\n\n# filter the warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading the train data and looking top 5 rows\n\ndf = pd.read_csv('/kaggle/input/buyers-time-prediction-challenge/ParticipantData_BTPC/Train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking for null values in columns\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# looking for big picture of the data\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Note:\n- most of the independent variables are type object and few are binary. It means when we do cleaning and transformation of type object variables they also converted into binary variables.\n- date is not in right data type. currently it is an object and should be changed to datetime.\n- client_agent has 160 missing values."},{"metadata":{},"cell_type":"markdown","source":"---\n#### session id\nUnique identifier for every row"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.session_id.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n#### session number\nSession type identifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.session_number.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\n\nplt.subplot(1,2,1)\nsns.scatterplot(x=df.session_number, y=df.time_spent)\nplt.title('session number vs time spent', size=14)\n\nplt.subplot(1,2,2)\nsns.scatterplot(x=df[(df.session_number<2000)&(df.time_spent<15000)]['session_number'], \n                y=df[(df.session_number<2000)&(df.time_spent<15000)]['time_spent'])\nplt.title('zooming in first plot where session number < 2000 and time spent < 15000', size=14)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Note:<br>\nIt is been observed that there is no such correlation between the two i.e. session number is not a significant variables in predicting the time. The points are distributed randomly and make no sense. **So we will drop this variable.** "},{"metadata":{},"cell_type":"markdown","source":"---\n#### device details\nClient-side software details"},{"metadata":{"trusted":true},"cell_type":"code","source":"# looking for count\ndf.device_details.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# looking the mean time spent from each device\ndf.groupby('device_details')['time_spent'].mean().round(2).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the columns into the two and removing the white spaces\ndf[['device','browser']] = df['device_details'].str.split('-',expand=True)\ndf['device'] = df['device'].str.strip()\ndf['browser'] = df['browser'].str.strip()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### device\nCreated from device_details column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the mean time spent from each device\ndf.groupby('device')['time_spent'].mean().round(2).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device_index = df.groupby('device')['time_spent'].mean().sort_values(ascending=False).index\ndevice_value = df.groupby('device')['time_spent'].mean().sort_values(ascending=False).values\n\nplt.figure(figsize=(10,5))\nsns.barplot(y=device_index, x=device_value, color='pink')\nplt.xlabel('Time spent (in seconds)', size=12)\nplt.yticks(size=12)\nplt.ylabel('')\nplt.title('Mean time spent by users from their device',size=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Note:<br>\nIt is been observed that people using **desktop** and **ipad** spent most time on the website followed by android phone and iphone. "},{"metadata":{"trusted":true},"cell_type":"code","source":"desktop = df[df.device=='Desktop'].groupby('browser')['time_spent'].mean().round(2).sort_values()\nplt.figure(figsize=(10,5))\ndesktop.plot(kind='bar',color='green',alpha=0.4)\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xticks(size=12,rotation=45)\nplt.xlabel('')\nplt.title(f'Mean time spent from different desktop\\n{desktop}',size=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Note:<br>\nWithin the desktop we see that people use four type of browser among which **firefox** has the highest mean time spent. **So it is been seen that people who login from desktop and uses firefox browser are the one who spent most time.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\n\nipad = df[df.device=='iPad'].groupby('browser')['time_spent'].mean().round(2).sort_values()\niphone = df[df.device=='iPhone'].groupby('browser')['time_spent'].mean().round(2).sort_values()\n\nplt.subplot(1,2,1)\nipad.plot(kind='bar',color='green',alpha=0.4)\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xticks(size=12,rotation=45)\nplt.xlabel('')\nplt.title(f'Mean time spent from different ipad\\n{ipad}',size=12)\n\nplt.subplot(1,2,2)\niphone.plot(kind='bar',color='green',alpha=0.4)\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xticks(size=12,rotation=45)\nplt.xlabel('')\nplt.title(f'Mean time spent from different iphone\\n{iphone}',size=12)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Note:\n- Within the ipad people who uses iOS i.e. app of the website spent most of the time.\n- Within iphone also people using the application spent the most time.\n- But the point note to be that ipad people spent more time on website from app than the iphone people who uses app. The difference is of 190 seconds i.e. more than 3 minutes."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\n\nandroid_phone = df[df.device=='Android Phone'].groupby('browser')['time_spent'].mean().round(2).sort_values()\nandroid_tablet = df[df.device=='Android Tablet'].groupby('browser')['time_spent'].mean().round(2).sort_values()\n\nplt.subplot(1,2,1)\nandroid_phone.plot(kind='bar',color='green',alpha=0.4)\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xticks(size=12,rotation=45)\nplt.xlabel('')\nplt.title(f'Mean time spent from different android phone\\n{android_phone}',size=12)\n\nplt.subplot(1,2,2)\nandroid_tablet.plot(kind='bar',color='green',alpha=0.4)\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xticks(size=12,rotation=45)\nplt.xlabel('')\nplt.title(f'Mean time spent from different android tablet\\n{android_tablet}',size=12)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Note:\n- Within the android phone people who uses android i.e. app of the website downloaded from app store spent most of the time.\n- Within android tablet also people using the application spent the most time.\n- The mobileweb was second highest in phone and lowest in tablet (graphically) but if we observed then we see that time spent from both the device using mobileweb was not very far from each other. The difference between them is 33 seconds."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['device','purchased'])['time_spent'].mean().unstack().plot(kind='bar',figsize=(12,5),color=['grey','red'],alpha=0.7)\nplt.xticks(rotation=45,size=12)\nplt.xlabel('')\nplt.ylabel('mean time spent (in seconds)',size=12)\nplt.title('mean time spent by peoples who purchased using different devices', size=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Note:<br>\nThis graph shows that the peoples who purchased spent three times more time from the one who dosn't purchase."},{"metadata":{"trusted":true},"cell_type":"code","source":"# merging the categories into 4 - phone, tablet, desktop and other\n\ndf['device'] = df['device'].replace(('Android Phone','Android Tablet','Unknown','iPad','iPhone'),\n                                   ('Phone','Tablet','Other','Tablet','Phone'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### browser\nCreated from device_details column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the mean time spent from different browser\ndf.groupby('browser')['time_spent'].mean().round(2).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"browser_index = df.groupby('browser')['time_spent'].mean().sort_values(ascending=False).index\nbrowser_value = df.groupby('browser')['time_spent'].mean().sort_values(ascending=False).values\n\nplt.figure(figsize=(10,5))\nsns.barplot(x=browser_index, y=browser_value, color='pink')\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xlabel('')\nplt.xticks(size=12,rotation=45)\nplt.title('Time spent by users on the website coming from different browser',size=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['browser','purchased'])['time_spent'].mean().unstack().plot(kind='bar',figsize=(12,5),color=['grey','red'],alpha=0.7)\nplt.xticks(rotation=45,size=12)\nplt.xlabel('')\nplt.title('mean time spent by peoples who purchased using different browsers', size=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['browser'] = df['browser'].replace(('Android','Chrome','Firefox','IE','MobileWeb','Other','Safari','Web','iOS'),\n                                     ('App','Web','Web','Web','Web','Other','Web','Web','App'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n#### date\nDatestamp of the session"},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting to datetime\ndf['date'] = pd.to_datetime(df['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Minimum date in the data:',min(df['date']))\nprint('Maximum date in the data:',max(df['date']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# extracting the month, day, weekday and week from the date\ndf['month'] = df['date'].dt.month_name()\ndf['day'] = df['date'].dt.day\ndf['weekday'] = df['date'].dt.day_name()\ndf['week'] = (df.day - 1) // 7 + 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### month"},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean time spent in each month\ndf.groupby('month')['time_spent'].mean().round(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"month_index = df.groupby('month')['time_spent'].mean().sort_values(ascending=False).index\nmonth_value = df.groupby('month')['time_spent'].mean().sort_values(ascending=False).values\n\nplt.figure(figsize=(12,5))\nsns.barplot(x=month_index, y=month_value, color='pink')\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xlabel('')\nplt.xticks(size=11,rotation=45)\nplt.title('Mean time spent on website each month',size=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# created new columns based upon time spent\ndf['is_september'] = df['month'].apply(lambda x: 1 if x=='September' else 0)\ndf['is_apr_may_july'] = df['month'].apply(lambda x: 1 if (x=='April' or x=='May' or x=='July') else 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### weekday"},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean time spent on each day of week\ndf.groupby('weekday')['time_spent'].mean().round(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"week_index = df.groupby('weekday')['time_spent'].mean().sort_values(ascending=False).index\nweek_value = df.groupby('weekday')['time_spent'].mean().sort_values(ascending=False).values\n\nplt.figure(figsize=(10,5))\nsns.barplot(x=week_index, y=week_value, color='pink')\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xlabel('')\nplt.ylim(500,800)\nplt.title('Mean time spent on website on each day of week',size=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# created new column\ndf['is_friday'] = df['weekday'].apply(lambda x: 1 if x=='Friday' else 0)\ndf['is_mon_tue_sat'] = df['weekday'].apply(lambda x: 1 if (x=='Monday' or x=='Tuesday' or x=='Saturday') else 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### day"},{"metadata":{"trusted":true},"cell_type":"code","source":"day_index = df.groupby('day')['time_spent'].mean().index\nday_value = df.groupby('day')['time_spent'].mean().values\n\nplt.figure(figsize=(15,5))\nplt.plot(day_index, day_value, color='purple')\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xlabel('Number of days', size=12)\nplt.xlim(1,31)\nplt.hlines(y=round(df.time_spent.mean(),2), xmin=1,xmax=31,linestyles='dashed',label='mean time')\nplt.title('Mean time spent on website on each day throughout the year',size=15)\nplt.legend(loc='center',fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Note:<br>\nFrom the above line plot it is seen that from 5th to 18th the time spent on the website is more than mean time and any number of conclusion can be made from this like offer in that period or arrival of new stock in the webiste or purchasing power in that peroid is high, etc."},{"metadata":{"trusted":true},"cell_type":"code","source":"dayp_index = df.groupby('day')['purchased'].count().index\ndayp_value = df.groupby('day')['purchased'].count().values\n\nplt.figure(figsize=(15,5))\nsns.lineplot(x=dayp_index, y=dayp_value, color='purple')\nplt.ylabel('Number of purchases', size=12)\nplt.xlabel('Number of days', size=12)\nplt.xlim(1,31)\nplt.ylim(50,250)\nplt.vlines(5, ymin=50,ymax=250,linestyles='dashed')\nplt.vlines(18, ymin=50,ymax=250,linestyles='dashed')\nplt.title('Number of purchases on website on each day throughout the year',size=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### week of months"},{"metadata":{"trusted":true},"cell_type":"code","source":"week_index = df.groupby('week')['time_spent'].mean().index\nweek_value = df.groupby('week')['time_spent'].mean().values\n\nplt.figure(figsize=(15,5))\nsns.lineplot(x=week_index, y=week_value, color='purple')\nplt.ylabel('Time spent (in seconds)', size=12)\nplt.xlabel('Week number', size=12)\nplt.xlim(1,5)\nplt.hlines(y=round(df.time_spent.mean(),2),xmin=1,xmax=5,linestyles='dashed',label='mean time')\nplt.title('Mean time spent on website on each week of month',size=15)\nplt.legend(loc='center',fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n#### purchased\nBinary value for any purchase done"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.purchased.value_counts(normalize=True).round(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('purchased')['time_spent'].mean().round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n#### added in cart\nBinary value for cart activity"},{"metadata":{"trusted":true},"cell_type":"code","source":"# proportion of rows\ndf.added_in_cart.value_counts(normalize=True).round(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean time spent\ndf.groupby('added_in_cart')['time_spent'].mean().round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n#### checked out\nBinary value for checking out successfully"},{"metadata":{"trusted":true},"cell_type":"code","source":"# proportion of rows\ndf.checked_out.value_counts(normalize=True).round(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean time spent\ndf.groupby('checked_out')['time_spent'].mean().round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n#### time spent\nTotal time spent in seconds (Target Column)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.time_spent.describe(percentiles=[0.25,0.5,0.75,0.9,0.95,0.99])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\n\nsns.distplot(df.time_spent)\nplt.xlabel('Time spent(in seconds)', size=12)\nplt.title('Distribution of time spent on website', size=15)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\n\nplt.subplot(1,2,1)\nsns.boxplot(np.log(df.time_spent))\nplt.title('Log distribution of time spent', size=15)\n\nplt.subplot(1,2,2)\nsns.boxplot(np.sqrt(df.time_spent))\nplt.title('Squre root distribution of time spent', size=15)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting the time with log distribution\ndf['time_spent'] = np.log(df['time_spent'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n#### client agent\nClient-side software details"},{"metadata":{"trusted":true},"cell_type":"code","source":"# created a function to find out the platform the user used\n\ndef platform(x):\n    if x.find('Product')!=-1:\n        return 'Product'\n    elif x.find('Chrome')!=-1:\n        return 'Chrome'\n    elif x.find('Safari')!=-1:\n        return 'Safari'\n    elif x.find('Mozilla')!=-1:\n        return 'Mozilla'\n    else:\n        return 'Other'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# created a function to find out the device used by the user\n\nimport re\ndef device_used(x):\n    if x.lower().find('windows')!=-1:\n        return 'windowns'\n    elif x.lower().find('iphone')!=-1:\n        return 'iphone'\n    elif x.lower().find('ipad')!=-1:\n        return 'ipad'\n    elif x.lower().find('android')!=-1:\n        return 'android'\n    elif x.lower().find('macintosh')!=-1:\n        return 'macintosh'\n    elif x.lower().find('linux')!=-1:\n        return 'linux'\n    elif len(re.findall(\"cfnetwork|cros\", x.lower())) > 0:\n        return 'apple_device'\n    else:\n        return 'unknown'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# applying the above two functions on client_agent column\n\ndf['platform'] = df['client_agent'].apply(lambda x: platform(str(x)))\ndf['server'] = df['client_agent'].apply(lambda x: device_used(str(x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.platform.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.server.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping the unnecessary columns\n\ndf.drop(['session_number','client_agent','device_details','platform','server','date','day',\n         'weekday','month','week','checked_out'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making the dummy variables for platform and server\n\ndevicepd = pd.get_dummies(df.device,drop_first=True,prefix='device')\nbrowserpd = pd.get_dummies(df.browser,drop_first=True,prefix='browser')\ndf = pd.concat([df,devicepd,browserpd], axis=1)\ndf.drop(['device','browser'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('session_id', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[['time_spent', 'purchased', 'added_in_cart', 'is_september',\n       'is_apr_may_july', 'is_friday', 'is_mon_tue_sat',\n       'device_Other', 'device_Phone', 'device_Tablet', 'browser_Other','browser_Web']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# looking for the correlation matrix\n\nplt.figure(figsize=(15,10))\nsns.heatmap(df.iloc[:,1:].corr().round(2), annot=True, cmap=\"YlGnBu\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# a high correlation between device_other and browser_other\n# droping one of the variables \n\ndf.drop('device_Other',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the data into train and test\ndf_train, df_test = train_test_split(df, train_size = 0.7, test_size = 0.3, random_state = 444)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using min-max scaler to transform time spent as all the other variables are between 0-1\ndf_train[['time_spent']] = scaler.fit_transform(df_train[['time_spent']])\n\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the x's and y\ny_train = df_train.pop('time_spent')\nX_train = df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# only transform the test time spent column\n\ndf_test[['time_spent']] = scaler.transform(df_test[['time_spent']])\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the x's and y\ny_test = df_test.pop('time_spent')\nX_test = df_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test Data\n- The data on which the actual prediction has to be done and whose result is to submitted for final evaluation.\n- `All the changes that has been done on train data should also be done on test data`. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('/kaggle/input/buyers-time-prediction-challenge/ParticipantData_BTPC/Test.csv')\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['platform'] = df1['client_agent'].apply(lambda x: platform(str(x)))\ndf1['server'] = df1['client_agent'].apply(lambda x: device_used(str(x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1[['device','browser']] = df1['device_details'].str.split('-',expand=True)\ndf1['device'] = df1['device'].str.strip()\ndf1['browser'] = df1['browser'].str.strip()\ndf1['device'] = df1['device'].replace(('Android Phone','Android Tablet','Unknown','iPad','iPhone'),\n                                   ('Phone','Tablet','Other','Tablet','Phone'))\ndf1['browser'] = df1['browser'].replace(('Android','Chrome','Firefox','IE','MobileWeb','Other','Safari','Web','iOS'),\n                                     ('App','Web','Web','Web','Web','Other','Web','Web','App'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['date'] = pd.to_datetime(df1['date'])\ndf1['month'] = df1['date'].dt.month_name()\ndf1['day'] = df1['date'].dt.day\ndf1['weekday'] = df1['date'].dt.day_name()\ndf1['week'] = (df1.day - 1) // 7 + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['is_september'] = df1['month'].apply(lambda x: 1 if x=='September' else 0)\ndf1['is_apr_may_july'] = df1['month'].apply(lambda x: 1 if (x=='April' or x=='May' or x=='July') else 0)\ndf1['is_friday'] = df1['weekday'].apply(lambda x: 1 if x=='Friday' else 0)\ndf1['is_mon_tue_sat'] = df1['weekday'].apply(lambda x: 1 if (x=='Monday' or x=='Tuesday' or x=='Saturday') else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"devicepd1 = pd.get_dummies(df1.device,drop_first=True,prefix='device')\nbrowserpd1 = pd.get_dummies(df1.browser,drop_first=True,prefix='browser')\ndf1 = pd.concat([df1,devicepd1,browserpd1], axis=1)\ndf1.drop(['device','browser'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.drop(['session_id','session_number','client_agent','device_details','checked_out','date','month','day','week',\n          'weekday','platform','server'], axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.drop(['device_Other'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### I. Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running the linear model \nlm1 = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n\n# Looking for summary\nprint(lm1.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking again the VIFs\n\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# deleting the variable 'is_apr_may_july' as it is insignificant \nX_train = X_train.drop(['is_apr_may_july'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running the linear model \nlm2 = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n\n# Looking for summary\nprint(lm2.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking again the VIFs\n\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# deleting the variable 'device_Tablet' as it is insignificant \nX_train = X_train.drop(['device_Tablet'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running the linear model \nlm3 = sm.OLS(y_train,sm.add_constant(X_train)).fit()\n\n# Looking for summary\nprint(lm3.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking again the VIFs\n\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Note:<br>\nAs all the variables comes significant and VIF < 3. So we will stop here and these are our final columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting on train data\ny_train_time = lm3.predict(sm.add_constant(X_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the histogram of the error terms\n\nfig = plt.figure()\nsns.distplot((y_train - y_train_time), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)               \nplt.xlabel('Errors', fontsize = 18)                         \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse = mean_squared_error(y_train, y_train_time)\nmsle = mean_squared_log_error(y_train,y_train_time)\nr_squared = r2_score(y_train,y_train_time)\n\nprint('RMSE:',np.sqrt(mse))\nprint('RMSLE:',np.sqrt(msle))\nprint('R-squared value:',r_squared)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The final columns are:')\nfcol = list(X_train.columns)\nprint(fcol)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Including only those variables which are selected by third model in training set \n\nX_test = X_test[fcol]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making prediction using the third model on test data\ny_test_time = lm3.predict(sm.add_constant(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse = mean_squared_error(y_test, y_test_time)\nmsle = mean_squared_log_error(y_test,y_test_time)\nr_squared = r2_score(y_train,y_train_time)\n\nprint('RMSE:',np.sqrt(mse))\nprint('RMSLE:',np.sqrt(msle))\nprint('R-squared value:',r_squared)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Prediction on test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test_lr = lm3.predict(sm.add_constant(df1[fcol])) # using only selected columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_final_lr = np.array(pred_test_lr).reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using inverse transform and exponential function to get back the actual seconds predicted\ny_final_lr = scaler.inverse_transform(y_final_lr)\ny_final_lr = np.exp(y_final_lr)\ny_final_lr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# storing it into the dataframe\n\ndf_lr = pd.DataFrame(y_final_lr)\ndf_lr.rename(columns={0:'time_spent_lr'},inplace=True)\ndf_lr = df_lr.round(4)\ndf_lr.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### II. XG Boost"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiation \nxgb_r = xg.XGBRegressor(objective ='reg:linear', n_estimators = 10, seed = 123) \n  \n# Fitting the model \nxgb_r.fit(X_train, y_train) \n  \n# Predict the model \npred = xgb_r.predict(X_test)\n\nmse = mean_squared_error(y_test, pred)\nr_squared = r2_score(y_test, pred)\n\nprint('RMSE:',np.sqrt(mse))\nprint('R-squared value:',r_squared)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# running the cross validation\n\ndef display_scores(scores):\n    print(\"Scores: {0}\\nMean: {1:.3f}\\nStd: {2:.3f}\".format(scores, np.mean(scores), np.std(scores)))\n\nxg_model = xg.XGBRegressor(objective=\"reg:linear\", random_state=42)\n\nscores = cross_val_score(xg_model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=5)\n\ndisplay_scores(np.sqrt(-scores))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def report_best_scores(results, n_top=3):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results['rank_test_score'] == i)\n        for candidate in candidates:\n            print(\"Model with rank: {0}\".format(i))\n            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n                  results['mean_test_score'][candidate],\n                  results['std_test_score'][candidate]))\n            print(\"Parameters: {0}\".format(results['params'][candidate]))\n            print(\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use randomizedsearchcv to find the parameters\n\nxgb_model = xg.XGBRegressor()\n\nparams = {\n    \"colsample_bytree\": uniform(0.7, 0.3),\n    \"gamma\": uniform(0, 0.5),\n    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n    \"max_depth\": randint(2, 6), # default 3\n    \"n_estimators\": randint(100, 150), # default 100\n    \"subsample\": uniform(0.6, 0.4)\n}\n\nsearch = RandomizedSearchCV(xgb_model, param_distributions=params, random_state=42, n_iter=200, cv=3, verbose=1, \n                            n_jobs=1, return_train_score=True)\n\nsearch.fit(X_train, y_train)\n\nreport_best_scores(search.cv_results_, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiation \nxgb_model1 = xg.XGBRegressor(objective ='reg:linear', n_estimators = 144,seed = 123) \n  \n# Fitting the model \nxgb_model1.fit(X_train, y_train) \n  \n# Predict the model \npred = xgb_model1.predict(X_train)\n\nmse = mean_squared_error(y_train, pred)\nmsle = mean_squared_log_error(y_train, pred)\nr_squared = r2_score(y_train, pred)\n\nprint('RMSE:',np.sqrt(mse))\nprint('RMSLE:',np.sqrt(msle))\nprint('R-squared value:',r_squared)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model1.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the histogram of the error terms\n\nfig = plt.figure()\nsns.distplot((y_train - pred), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20) \nplt.xlabel('Errors', fontsize = 18)                         \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making prediction on test data\npred_test = xgb_model1.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse = mean_squared_error(y_test, pred_test)\nmsle = mean_squared_log_error(y_test, pred_test)\nr_squared = r2_score(y_test, pred_test)\n\nprint('RMSE:',np.sqrt(mse))\nprint('RMSLE:',np.sqrt(msle))\nprint('R-squared value:',r_squared)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Prediction on test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test_xgb = xgb_model1.predict(df1[fcol])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_final_xgb = np.array(pred_test_xgb).reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using inverse transform and exponential function to get back the actual seconds predicted\ny_final_xgb = scaler.inverse_transform(y_final_xgb)\ny_final_xgb = np.exp(y_final_xgb)\ny_final_xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# storing in the dataframe\ndf_xgb = pd.DataFrame(y_final_xgb)\ndf_xgb.rename(columns={0:'time_spent_xgb'},inplace=True)\ndf_xgb = df_xgb.round(4)\ndf_xgb.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_xgb.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### III. Decision Tree Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtr = DecisionTreeRegressor()\ndtr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# depth of the decision tree\nprint('Depth of the Decision Tree: ', dtr.get_depth())\n\n#checking the training score\nprint('Accuracy on training: ',dtr.score(X_train, y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Implementing grid search\n\nparameter_grid = {\n    'max_depth' : [24,25,26,27,28,29,30],\n    'max_features': [0.3, 0.5, 0.7]\n    }\n\ngridsearch = GridSearchCV(estimator=dtr, param_grid=parameter_grid, scoring='neg_mean_squared_error', cv=5)\n\ngridsearch.fit(X_train, y_train)\n\nprint(gridsearch.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Implementing random search\n\nparameter_grid = {\n    'max_depth' : [24,25,26,27,28,29,30],\n    'max_features': [0.3, 0.5, 0.7,0.9]\n    }\n\nrandomsearch = RandomizedSearchCV(estimator=dtr, param_distributions=parameter_grid, n_iter= 10, cv=5)\nrandomsearch.fit(X_train, y_train)\n\nprint(randomsearch.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# final model\ndtr1 = DecisionTreeRegressor(max_depth=27, max_features=0.5 ,random_state=10)\n\n# fitting the model\ndtr1.fit(X_train, y_train)\n\n# Training score\nprint(dtr1.score(X_train, y_train).round(4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\n\nfig = plt.figure(figsize=(15,10))\n_ = tree.plot_tree(dtr1, feature_names=X_train.columns, max_depth=2, filled=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtr1.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict the model \npred_dt = dtr1.predict(X_train)\n\nmse = mean_squared_error(y_train, pred_dt)\nmsle = mean_squared_log_error(y_train, pred_dt)\nr_squared = r2_score(y_train, pred_dt)\n\nprint('RMSE:',np.sqrt(mse))\nprint('RMSLE:',np.sqrt(msle))\nprint('R-squared value:',r_squared)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the histogram of the error terms\n\nfig = plt.figure()\nsns.distplot((y_train - pred_dt), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20) \nplt.xlabel('Errors', fontsize = 18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making prediction on test data\npred_test_dt = dtr1.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse = mean_squared_error(y_test, pred_test_dt)\nmsle = mean_squared_log_error(y_test, pred_test_dt)\nr_squared = r2_score(y_test, pred_test_dt)\n\nprint('RMSE:',np.sqrt(mse))\nprint('RMSLE:',np.sqrt(msle))\nprint('R-squared value:',r_squared)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Prediction on test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test_dt = dtr1.predict(df1[fcol])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_final_dt = np.array(pred_test_dt).reshape(-1,1)\n\n# using inverse transform and exponential function to get back the actual seconds predicted\ny_final_dt = scaler.inverse_transform(y_final_dt)\ny_final_dt = np.exp(y_final_dt)\ny_final_dt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dt = pd.DataFrame(y_final_dt)\ndf_dt.rename(columns={0:'time_spent_dt'},inplace=True)\ndf_dt = df_dt.round(4)\ndf_dt.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### IV. Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr = RandomForestRegressor()\nrfr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the training score\nprint('Accuracy on training: ',rfr.score(X_train, y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Implementing grid search\n\nparameter_grid = {\n    'max_depth' : [24,25,26,27,28,29,30],\n    'max_features': [0.3, 0.5, 0.7]\n    }\n\ngridsearch = GridSearchCV(estimator=rfr, param_grid=parameter_grid, scoring='neg_mean_squared_error', cv=5)\n\ngridsearch.fit(X_train, y_train)\n\nprint(gridsearch.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Implementing random search\n\nparameter_grid = {\n    'max_depth' : [24,25,26,27,28,29,30],\n    'max_features': [0.3, 0.5, 0.7,0.9]\n    }\n\nrandomsearch = RandomizedSearchCV(estimator=rfr, param_distributions=parameter_grid, n_iter= 10, cv=5)\nrandomsearch.fit(X_train, y_train)\n\nprint(randomsearch.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr1 = RandomForestRegressor(max_depth=26, max_features=0.7)\nrfr1.fit(X_train, y_train)\n\n#checking the training score\nprint('Accuracy on training: ',rfr1.score(X_train, y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr1.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict the model \npred_rf = rfr1.predict(X_train)\n\nmse = mean_squared_error(y_train, pred_rf)\nmsle = mean_squared_log_error(y_train, pred_rf)\nr_squared = r2_score(y_train, pred_rf)\n\nprint('RMSE:',np.sqrt(mse))\nprint('RMSLE:',np.sqrt(msle))\nprint('R-squared value:',r_squared)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the histogram of the error terms\n\nfig = plt.figure()\nsns.distplot((y_train - pred_rf), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)              \nplt.xlabel('Errors', fontsize = 18)                     \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making prediction on test data\npred_test_rf = rfr1.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse = mean_squared_error(y_test, pred_test_rf)\nmsle = mean_squared_log_error(y_test, pred_test_rf)\nr_squared = r2_score(y_test, pred_test_rf)\n\nprint('RMSE:',np.sqrt(mse))\nprint('RMSLE:',np.sqrt(msle))\nprint('R-squared value:',r_squared)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Prediction on test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test_rf = rfr1.predict(df1[fcol])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_final_rf = np.array(pred_test_rf).reshape(-1,1)\n\n# using inverse transform and exponential function to get back the actual seconds predicted\ny_final_rf = scaler.inverse_transform(y_final_rf)\ny_final_rf = np.exp(y_final_rf)\ny_final_rf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_rf = pd.DataFrame(y_final_rf)\ndf_rf.rename(columns={0:'time_spent_rf'},inplace=True)\ndf_rf = df_rf.round(4)\ndf_rf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Thank you!**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}