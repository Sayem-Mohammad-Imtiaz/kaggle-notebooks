{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!git clone https://github.com/dronedeploy/dd-ml-segmentation-benchmark.git\n    \nimport sys\nsys.path.append('./dd-ml-segmentation-benchmark')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\n\nfrom libs.config import train_ids, val_ids, test_ids, LABELMAP, INV_LABELMAP\n\nsize   = 300\nstride = 300\n\ndef color2class(orthochip, img):\n    ret = np.zeros((img.shape[0], img.shape[1]), dtype='uint8')\n    ret = np.dstack([ret, ret, ret])\n    colors = np.unique(img.reshape(-1, img.shape[2]), axis=0)\n\n    # Skip any chips that would contain magenta (IGNORE) pixels\n    seen_colors = set( [tuple(color) for color in colors] )\n    IGNORE_COLOR = LABELMAP[0]\n    if IGNORE_COLOR in seen_colors:\n        return None, None\n\n    for color in colors:\n        locs = np.where( (img[:, :, 0] == color[0]) & (img[:, :, 1] == color[1]) & (img[:, :, 2] == color[2]) )\n        ret[ locs[0], locs[1], : ] = INV_LABELMAP[ tuple(color) ] - 1\n\n    return orthochip, ret\n\ndef image2tile(inp, out, scene, dataset, orthofile, elevafile, labelfile, windowx=size, windowy=size, stridex=stride, stridey=stride):\n\n    ortho = cv2.imread(orthofile)\n    label = cv2.imread(labelfile)\n\n    # Not using elevation in the sample - but useful to incorporate it ;)\n    eleva = cv2.imread(elevafile, -1)\n\n    assert(ortho.shape[0] == label.shape[0])\n    assert(ortho.shape[1] == label.shape[1])\n\n    shape = ortho.shape\n\n    xsize = shape[1]\n    ysize = shape[0]\n    print(f\"converting {dataset} image {orthofile} {xsize}x{ysize} to chips ...\")\n\n    counter = 0\n\n    for xi in range(0, shape[1] - windowx, stridex):\n        for yi in range(0, shape[0] - windowy, stridey):\n\n            orthochip = ortho[yi:yi+windowy, xi:xi+windowx, :]\n            labelchip = label[yi:yi+windowy, xi:xi+windowx, :]\n\n            orthochip, classchip = color2class(orthochip, labelchip)\n\n            if classchip is None:\n                continue\n\n            orthochip_filename = os.path.join(out, 'image-chips', scene + '-' + str(counter).zfill(6) + '.png')\n            labelchip_filename = os.path.join(out, 'label-chips', scene + '-' + str(counter).zfill(6) + '.png')\n\n            with open(f\"{out}/{dataset}\", mode='a') as fd:\n                fd.write(scene + '-' + str(counter).zfill(6) + '.png\\n')\n\n            cv2.imwrite(orthochip_filename, orthochip)\n            cv2.imwrite(labelchip_filename, classchip)\n            counter += 1\n\n\ndef get_split(scene):\n    if scene in train_ids:\n        return \"train.txt\"\n    if scene in val_ids:\n        return 'valid.txt'\n    if scene in test_ids:\n        return 'test.txt'\n\ndef run(inp, out):\n\n    open(out + '/train.txt', mode='w').close()\n    open(out + '/valid.txt', mode='w').close()\n    open(out + '/test.txt', mode='w').close()\n\n    if not os.path.exists( os.path.join(out, 'image-chips') ):\n        os.mkdir(os.path.join(out, 'image-chips'))\n\n    if not os.path.exists( os.path.join(out, 'label-chips') ):\n        os.mkdir(os.path.join(out, 'label-chips'))\n\n\n    lines = [ line for line in open(f'{inp}/index.csv') ]\n    num_images = len(lines) - 1\n    print(f\"converting {num_images} images to chips - this may take a few minutes but only needs to be done once.\")\n\n    for lineno, line in enumerate(lines):\n\n        line = line.strip().split(' ')\n        scene = line[1]\n        dataset = get_split(scene)\n\n        if dataset == 'test.txt':\n            print(f\"not converting test image {scene} to chips, it will be used for inference.\")\n            continue\n\n        orthofile = os.path.join(inp, 'images',     scene + '-ortho.tif')\n        elevafile = os.path.join(inp, 'elevations', scene + '-elev.tif')\n        labelfile = os.path.join(inp, 'labels',     scene + '-label.png')\n\n        if os.path.exists(orthofile) and os.path.exists(labelfile):\n            image2tile(inp, out, scene, dataset, orthofile, elevafile, labelfile)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"inp = '../input/drone-deploy-medium-dataset/dataset-medium'\nout = './chips/'\n!mkdir {out}\n\nimage_chips = f'{inp}/image-chips'\nlabel_chips = f'{inp}/label-chips'\nrun(inp, out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}