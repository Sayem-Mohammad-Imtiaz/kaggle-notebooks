{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Car Price Prediction"},{"metadata":{},"cell_type":"markdown","source":"### Objective \n<p>To build suitable Machine Learning Model for Car Price Prediction on the bellow data set.</p>"},{"metadata":{},"cell_type":"markdown","source":"<h1>Table of contents</h1>\n\n<div class=\"alert alert-info alert-info\" style=\"margin-top: 20px\">\n\n1. [Importing Libraries and Dataset](#1)<br>\n2. [Exploratory Data Analysis](#2)<br>\n3. [Feature Engineering](#3)<br>\n4. [Data Vizualization](#4)<br>\n5. [Model Building](#5)<br>\n6. [Model Evaluation](#6)<br>    \n\n<hr>"},{"metadata":{},"cell_type":"markdown","source":"<h2>Importing Libraries and Dataset</h2><a id=\"1\"></a>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# importing required libraries\nimport numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load the Car dataset\nThis dataset contains information about used cars listed on <a href='www.cardekho.com'><u>website</u></a>\nThis data can be used for a lot of purposes such as price prediction to exemplify the use of linear regression in Machine Learning.\nThe columns in the given dataset are as follows:\n\n| Column name    | Description                                         |\n| ------------   | --------------------------------------------------- |\n| Car_Name       | Name of Car sold                                    |\n| company        | Car making company                                  |\n| Year           | Year in which car was bought                        |\n| Selling_Price  | Price at which car sold                             |\n| Present_Price  | Price of same car model in current year             |\n| Kms_Driven     | Number of Kilometers Car driven before it is sold   |\n| Fuel_Type      | Type of fuel Car uses                               |\n| Seller_Type    | Type of seller                                      |\n| Transmission   | Gear transmission of the car (Automatic/Manual)     |\n| Owner          | Number of previous owners                           |   "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading Dataset\ndf = pd.read_csv('../input/car-dekho-data/car data.csv')\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Exploratory Data Analysis</h2><a id=\"2\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The size of Dataframe is: ', df.shape)\nprint('\\n')\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 'Selling_Price' is our Target variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"# To find total_missing_values in different columns of data and their percentage\ndef missing_data(data):\n    \"\"\"\n    This will take in a dataframe and \n    finds the total_missing_values as well as percentage of the value counts\n    \"\"\"\n    total = data.isnull().sum().sort_values(ascending = False)\n    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)\n    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_data(data= df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As from above dataframe, my observation on missing data are: \n<UL>\n   <li>There is no missing values in our dataset.\n   <li>Therefore there is no need of data cleaning.\n</UL>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"'Fuel_Type' variable have {} unique category : {}\\n\".format(df['Fuel_Type'].nunique(), df['Fuel_Type'].unique()))\nprint(\"'Seller_Type' variable have {} unique category : {}\\n\".format(df['Seller_Type'].nunique(), \\\n                                                                     df['Seller_Type'].unique()))\nprint(\"'Transmission' variable have {} unique category : {}\\n\".format(df['Transmission'].nunique(), \\\n                                                                    df['Transmission'].unique()))\nprint(\"'Owner' variable have {} unique category : {}\".format(df['Owner'].nunique(), df['Owner'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Owner'].replace(to_replace=3, value=2, inplace= True)\nprint(\"'Owner' variable have {} unique category : {}\".format(df['Owner'].nunique(), df['Owner'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include= 'object')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Feature Engineering</h3><a id=\"3\"></a>\nHere, I'll derive new feature from feature 'Year'."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see all column names\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, I'll derive new feature from 'Year' to calculate how many year old the car is."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's create a new variable 'Current_Year'\ndf['Current_Year'] = 2020\n\n# To Calculate how old the car is, I created new feature \"No_of_Years\"\ndf['No_of_Years'] = df['Current_Year'] - df['Year']\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Remove features"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df = df.copy()            # Creating copy of created dataframe\nfinal_df.drop(labels= ['Car_Name','company','Year', 'Current_Year'], axis= 1, inplace= True)          #droping unnecessary features\n\nfinal_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Data Visualization</h2><a id=\"4\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data= final_df, hue= 'Fuel_Type', diag_kind= 'kde')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see the distribution of the two variable from our data\nfig = plt.figure(figsize=(20,20)) # create figure\n\nsns.set(font_scale= 1)\nsns.set_style('darkgrid')\n\nax0 = fig.add_subplot(2, 2, 1) # add subplot 1 (2 row, 2 columns, first plot)\nax1 = fig.add_subplot(2, 2, 2) # add subplot 2 (2 row, 2 columns, second plot)\nax2 = fig.add_subplot(2, 2, 3) # add subplot 1 (2 row, 2 columns, third plot)\nax3 = fig.add_subplot(2, 2, 4) # add subplot 1 (2 row, 2 columns, fourth plot)\n\n# Subplot 1: Distplot of 'Selling_Price' feature\nk1 = sns.distplot(a = final_df['Selling_Price'], bins= 25, ax=ax0) # add to subplot 1\nax0.set_title('Distribution of Selling Price', fontsize=16)\nax0.set(xlabel= 'Selling Price', ylabel= 'Density')\n\n# Subplot 2: Distplot of 'Present_Price' feature\nk2 = sns.distplot(a = final_df['Present_Price'], bins= 25, ax=ax1) # add to subplot 2           \nax1.set_title('Distribution of Present Price', fontsize=16)\nax1.set(xlabel= 'Present Price', ylabel= 'Density')\n\n# Subplot 3: Distplot of 'Kms_Driven' feature\nk1 = sns.distplot(a = final_df['Kms_Driven'], bins= 25, ax=ax2) # add to subplot 3\nax2.set_title('Distribution of Kilometers Driven', fontsize=16)\nax2.set(xlabel= 'Kilometers Driven', ylabel= 'Density')\n\n# Subplot 4: Distplot of 'No_of_Years' feature\nk1 = sns.distplot(a = final_df['No_of_Years'], bins= 15, ax=ax3) # add to subplot 4\nax3.set_title('Distribution of Number of Years', fontsize=16)\nax3.set(xlabel= 'Number of Years', ylabel= 'Density')\n\nplt.show()\n#fig.savefig(\"Distributionplot.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"'No_of_Years' variable have {} unique category : {}\".format(final_df['No_of_Years'].nunique(), \n                                                                   final_df['No_of_Years'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see categorical feature value counts\nfig = plt.figure(figsize=(16,16)) # create figure\n\nsns.set(font_scale= 1)\nsns.set_style('darkgrid')\n\nax0 = fig.add_subplot(2, 2, 1) # add subplot 1 (2 row, 2 columns, first plot)\nax1 = fig.add_subplot(2, 2, 2) # add subplot 2 (2 row, 2 columns, second plot)\nax2 = fig.add_subplot(2, 2, 3) # add subplot 1 (2 row, 2 columns, third plot)\nax3 = fig.add_subplot(2, 2, 4) # add subplot 1 (2 row, 2 columns, fourth plot)\n\n# Subplot 1: Countplot of 'Fuel_Type' feature\nk1 = sns.countplot(data = final_df, x = 'Fuel_Type', ax= ax0) # add to subplot 1\nax0.set_title('Fuel_Type Value Counts', fontsize=16)\nax0.set(xlabel= 'Fuel_Type', ylabel= 'Count')\n\n# Subplot 2: Countplot of 'Seller_Type' feature\nk2 = sns.countplot(data = final_df, x = 'Seller_Type', ax= ax1) # add to subplot 2           \nax1.set_title('Seller_Type Value Counts', fontsize=16)\nax1.set(xlabel= 'Seller_Type', ylabel= 'Count')\n\n# Subplot 3: Countplot of 'Transmission' feature\nk1 = sns.countplot(data = final_df, x = 'Transmission', ax= ax2) # add to subplot 3\nax2.set_title('Transmission Value Counts', fontsize=16)\nax2.set(xlabel= 'Transmission', ylabel= 'Count')\n\n# Subplot 4: Countplot of 'Owner' feature\nk1 = sns.countplot(data = final_df, x = 'Owner', ax= ax3) # add to subplot 4\nax3.set_title('Owner Value Counts', fontsize=16)\nax3.set(xlabel= 'Owner', ylabel= 'Count')\n\nplt.show()\n#fig.savefig(\"Distributionplot.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.countplot(data= final_df, x= 'No_of_Years')\nplt.xlabel('Number of Years', fontsize=14)\nplt.ylabel('Counts', fontsize=14)\nplt.title('Number of Years Value Counts', fontsize=18)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Convert Categorical variable into numerical\nHere, I am using One Hot Encoding / get_dummies to convert categorical variables to numerical."},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df = pd.get_dummies(final_df, drop_first=True)\nfinal_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.heatmap(data = final_df.corr().round(2), annot= True, cmap= 'plasma', vmin= -1 , vmax= 1, linecolor='white', linewidths=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check data types of variables\nfinal_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting the datatypes of variables as of required datatype\nfinal_df['Fuel_Type_Diesel'] = final_df['Fuel_Type_Diesel'].astype('int64')\nfinal_df['Fuel_Type_Petrol'] = final_df['Fuel_Type_Petrol'].astype('int64')\nfinal_df['Seller_Type_Individual'] = final_df['Seller_Type_Individual'].astype('int64')\nfinal_df['Transmission_Manual'] = final_df['Transmission_Manual'].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = final_df.iloc[:, 1:]            # Feature matrix (independent variables)\ny = final_df.iloc[:, 0]             # Target variable (dependent variable)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To check important feature\nfrom sklearn.ensemble import ExtraTreesRegressor\n\nmodel = ExtraTreesRegressor()\nmodel.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot graph of feature importances for better visualization\n\nimp_feature = pd.Series(model.feature_importances_, index = X.columns)\nimp_feature.nlargest(7).plot(kind = 'barh', color='red')\nplt.title('Important Features', fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"But in this project, we will use all features for prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Model Building</h2><a id=\"5\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Hyperparameters \n# number of trees\nn_estimators = [int(x) for x in np.linspace(start=100, stop=1200, num=12)]\n\n# number of features\nmax_features = ['auto', 'sqrt']\n\n# max number of levels in tree\nmax_depth = [int(x) for x in np.linspace(start= 5, stop= 30, num= 6)]\n\n# min. number of sample required to split a node\nmin_samples_split = [2,5,10,15,100]\n\n# min. number of samples required at each leaf node\nmin_samples_leaf = [1,2,5,10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the random grid\nrandom_grid= {'n_estimators': n_estimators, \n              'max_features' : max_features,\n              'max_depth' : max_depth,\n              'min_samples_split' : min_samples_split,\n              'min_samples_leaf' : min_samples_leaf}\nprint(random_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nregressor_random = RandomizedSearchCV(estimator=  regressor, param_distributions=  random_grid, scoring= 'neg_mean_squared_error', \\\n                                      n_iter = 10, cv=5, verbose = 2, random_state=42, n_jobs=1)\nregressor_random.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predictions = regressor_random.predict(X_test)\ny_predictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting Test Data by visualizing\n*Now that I've fit and trained the model, I need to evaluate its performance by predicting the test values and visualize the results.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7,5))\nplt.scatter(x= y_test, y= y_predictions)\nplt.xlabel('Y Test (True values)')\nplt.ylabel('Predicted Values')\nplt.title('True value Vs Predicted values of Selling Price', fontsize=14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Residuals\n\n*Next, I explore the residuals to make sure everything was okay with the data (i.e. it is Normally distributed).*"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(y_test - y_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score\n\nprint('Mean Absolute Error: ', mean_absolute_error(y_test, y_predictions))\nprint('Mean Squareed Error: ', mean_squared_error(y_test, y_predictions))\nprint('Root Mean Square Error: ', np.sqrt(mean_squared_error(y_test, y_predictions)))\nprint('\\nExplaned Variance Score: ', explained_variance_score(y_true= y_test, y_pred= y_predictions))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}