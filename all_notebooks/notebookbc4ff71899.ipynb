{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport glob\nimport os\nimport cv2\nimport time\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import SGD\nfrom keras.layers.normalization import BatchNormalization\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-28T20:36:08.916386Z","iopub.execute_input":"2021-06-28T20:36:08.916785Z","iopub.status.idle":"2021-06-28T20:36:15.800435Z","shell.execute_reply.started":"2021-06-28T20:36:08.916696Z","shell.execute_reply":"2021-06-28T20:36:15.798961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"names = pd.read_csv('../input/stanford-car-dataset-images-in-224x224/stanford-car-dataset-by-classes-folder-224/names.csv')\nnames = names.values\nnp.random.shuffle(names)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T20:36:33.340119Z","iopub.execute_input":"2021-06-28T20:36:33.340387Z","iopub.status.idle":"2021-06-28T20:36:33.374328Z","shell.execute_reply.started":"2021-06-28T20:36:33.340363Z","shell.execute_reply":"2021-06-28T20:36:33.372832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nr_cars = 15\nidx_to_name = {x : names[x][0] for x in np.arange(nr_cars)}\nname_to_idx = {x:i for i,x in enumerate(idx_to_name.values())}\nidx_to_name","metadata":{"execution":{"iopub.status.busy":"2021-06-28T20:36:58.797749Z","iopub.execute_input":"2021-06-28T20:36:58.798048Z","iopub.status.idle":"2021-06-28T20:36:58.807049Z","shell.execute_reply.started":"2021-06-28T20:36:58.798024Z","shell.execute_reply":"2021-06-28T20:36:58.805988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = '../input/stanford-car-dataset-images-in-224x224/stanford-car-dataset-by-classes-folder-224/car_data/train/'\ntest_path = '../input/stanford-car-dataset-images-in-224x224/stanford-car-dataset-by-classes-folder-224/car_data/test/'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data(path):\n    train = []\n    for i, name in enumerate(name_to_idx.keys()):\n        new_path = path + name + \"/\"\n        [train.append([i, cv2.resize(cv2.imread(img), (244,244), interpolation = cv2.INTER_AREA)]) for img in glob.glob(new_path + \"*.jpg\")]\n    return np.array(train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = get_data(train_path)\ntest = get_data(test_path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_tr = np.concatenate(train[:,1], axis=0).reshape(len(train), 244, 244, 3)\nX_tr = X_tr / 255.0\nX_tr = X_tr.astype('float32')\ny_tr = train[:,0]\ny_tr = np.eye(len(idx_to_name))[list(y_tr)]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(X_tr, y_tr, test_size = 0.15, random_state = 42)\nprint(\"x_train shape = \",x_train.shape)\nprint(\"y_train shape = \",y_train.shape)\nprint(\"x_val shape = \",x_val.shape)\nprint(\"y_val shape = \",y_val.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Sequential(name=\"Alexnet\")\n#1 layer (conv + pool + batchnorm)\nmodel.add(Conv2D(filters=96,kernel_size=(11,11),strides=(4,4),padding=\"valid\",activation=\"relu\",input_shape=(227,227,3)))\nmodel.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\nmodel.add(BatchNormalization())\n#2 layer (conv + pool + batchnorm)\nmodel.add(Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),padding=\"valid\",activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\nmodel.add(BatchNormalization())\n#3 layer (conv + batchnorm)\nmodel.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\nmodel.add(BatchNormalization())\n#4 layer (conv + batchnorm)\nmodel.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\nmodel.add(BatchNormalization())\n#5 layer (conv + pool + batchnorm)\nmodel.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\n#1 dense layer\nmodel.add(Dense(4096,input_shape=(227,227,3),activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n#2 dense layer\nmodel.add(Dense(4096,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n#3 dense layer\nmodel.add(Dense(1000,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n#output layer\nmodel.add(Dense(15,activation=\"softmax\"))\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reduce learning rate by 0.1 when the validation error plateaus\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1))\n \n# set the SGD optimizer with lr of 0.01 and momentum of 0.9\noptimizer = SGD(lr = 0.01, momentum = 0.9)\n \n# compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train the model\n# call the reduce_lr value using callbacks in the training method\nhistory = model.fit(x_train, y_train, epochs=20, validation_data=(x_val, y_val))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.gca().set_ylim(0, 100) # set the vertical range to [0-1]\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from functools import partial\nDefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, strides=1,\n padding=\"SAME\", use_bias=False)\nclass ResidualUnit(keras.layers.Layer):\n def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n     super().__init__(**kwargs)\n     self.activation = keras.activations.get(activation)\n     self.main_layers = [\n         DefaultConv2D(filters, strides=strides),\n         keras.layers.BatchNormalization(),\n         self.activation,\n         DefaultConv2D(filters),\n         keras.layers.BatchNormalization()]\n     self.skip_layers = []\n     if strides > 1:\n         self.skip_layers = [\n             DefaultConv2D(filters, kernel_size=1, strides=strides),\n             keras.layers.BatchNormalization()]\ndef call(self, inputs):\n    Z = inputs\n    for layer in self.main_layers:\n         Z = layer(Z)\n    skip_Z = inputs\n    for layer in self.skip_layers:\n         skip_Z = layer(skip_Z)\n    return self.activation(Z + skip_Z)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T20:43:29.083647Z","iopub.execute_input":"2021-06-28T20:43:29.083937Z","iopub.status.idle":"2021-06-28T20:43:29.095269Z","shell.execute_reply.started":"2021-06-28T20:43:29.083914Z","shell.execute_reply":"2021-06-28T20:43:29.094574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = keras.models.Sequential(name=\"Resnet34\")\nmodel2.add(DefaultConv2D(64, kernel_size=7, strides=2,\n input_shape=[224, 224, 3]))\nmodel2.add(keras.layers.BatchNormalization())\nmodel2.add(keras.layers.Activation(\"relu\"))\nmodel2.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"))\nprev_filters = 64\nfor filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n strides = 1 if filters == prev_filters else 2\n model2.add(ResidualUnit(filters, strides=strides))\n prev_filters = filters\nmodel2.add(keras.layers.GlobalAvgPool2D())\nmodel2.add(keras.layers.Flatten())\nmodel2.add(keras.layers.Dense(15, activation=\"softmax\"))\nmodel2.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T20:43:36.162546Z","iopub.execute_input":"2021-06-28T20:43:36.162806Z","iopub.status.idle":"2021-06-28T20:43:36.422926Z","shell.execute_reply.started":"2021-06-28T20:43:36.162782Z","shell.execute_reply":"2021-06-28T20:43:36.421457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reduce learning rate by 0.1 when the validation error plateaus\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1))\n \n# set the SGD optimizer with lr of 0.01 and momentum of 0.9\noptimizer = SGD(lr = 0.001, momentum = 0.9)\n # compile the model\nmodel2.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\nhistory = model2.fit(x_train, y_train,\n validation_data=(x_val, y_val),\n epochs=20)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\npd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.gca().set_ylim(0, 10) # set the vertical range to [0-1]\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}