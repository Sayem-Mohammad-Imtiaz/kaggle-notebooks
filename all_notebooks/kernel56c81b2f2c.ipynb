{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\nfrom tensorflow.python.keras.layers.normalization import BatchNormalization\nfrom tensorflow.python.keras.optimizer_v2.adam import Adam\nfrom tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n#from tensorflow.python.keras import optimizers\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\nimport copy","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/train-test-data/train_sensor.csv')\ndf2 = pd.read_csv('../input/train-test-data/test_sensor.csv')\ndf = df.drop(['timestamp','sensor_15','sensor_50','Unnamed: 0','machine_status'],axis=1)\ndf2 = df2.drop(['timestamp','sensor_15','sensor_50','Unnamed: 0','machine_status'],axis=1)\ndf =df.fillna(value=0)\ndf2 =df2.fillna(value=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(train2):\n  for i in train2:\n    max11=valueList[i][0]\n    min11=valueList[i][1]\n    mean11=valueList[i][2]\n    train2[i][train2[i]>max11]=max11\n    train2[i][train2[i]<min11]=min11\n    train2[i]= train2[i].apply(lambda x: (x - mean11) / (max11 - min11))\n  #train_norm = train.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n  return train2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unnormalize(train):\n  train2 = copy.deepcopy(train) \n  for i in range(len(train)):\n      train2[i]=train[i]*(valueList['time_left'][0]-valueList['time_left'][1])+valueList['time_left'][2]\n  return train2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_normalize(df):\n    ValueList=copy.deepcopy(df[:][:3])\n    for i in df:\n        max1=np.max(df[i][:])\n        min1=np.min(df[i][:])\n        mean1=np.mean(df[i][:])\n        ValueList[i][0]=max1\n        ValueList[i][1]=min1\n        ValueList[i][2]=mean1\n    ValueList.to_csv('./ValueList.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def splitData(X,Y,rate):\n  X_train = X[int(X.shape[0]*rate):]\n  Y_train = Y[int(Y.shape[0]*rate):]\n  X_val = X[:int(X.shape[0]*rate)]\n  Y_val = Y[:int(Y.shape[0]*rate)]\n  return X_train, Y_train, X_val, Y_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def buildTrain(train):\n  X_train, Y_train = [], []\n  train2=train.drop(['time_left'],axis=1)\n  X_train=np.array(train2.iloc[:][:]).tolist()\n  Y_train=np.array(train.iloc[:][\"time_left\"]).tolist()\n  return np.array(X_train), np.array(Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def shuffle(X,Y):\n  np.random.seed(10)\n  randomList = np.arange(X.shape[0])\n  np.random.shuffle(randomList)\n  return X[randomList], Y[randomList]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"time_left\"]=df[\"time_left\"]/60/24\ndf2[\"time_left\"]=df2[\"time_left\"]/60/24","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_normalize(df)\nvalueList= pd.read_csv('./ValueList.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_norm = normalize(df)\ntrain_norm2 = normalize(df2)\nX_train, Y_train = buildTrain(train_norm)\nX_val, Y_val = buildTrain(train_norm2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, Y_train = shuffle(X_train, Y_train)\nX_val, Y_val = shuffle(X_val, Y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train[:,np.newaxis]\nX_val = X_val[:,np.newaxis]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def buildOneToOneModel(shape):\n  model = Sequential()\n  model.add(LSTM(128, input_length=shape[1], input_dim=shape[2],return_sequences=True))\n  model.add(Dropout(0.2))\n  model.add(LSTM(128, return_sequences=True))\n  model.add(Dropout(0.2))\n  model.add(LSTM(128, return_sequences=True))\n  model.add(Dropout(0.2))\n  model.add(TimeDistributed(BatchNormalization()))\n  #model.add(LSTM(10, input_length=shape[1], input_dim=shape[2],return_sequences=True))\n  #model.add(LSTM(10, input_length=shape[1], input_dim=shape[2],return_sequences=True))\n  #model.add(Dense(1))\n  model.add(TimeDistributed(Dense(1)))    # or use model.add(Dense(1))\n  #sgd = optimizers.SGD(lr = 0.1, decay = 1e-6, momentum = 0.9, nesterov = True)\n  model.compile(loss='mse', optimizer=\"adam\")\n  model.summary()\n  return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot1(history):\n     N = np.arange(0, len(history['loss']))\n     fig=plt.figure()\n     fig.set_size_inches(18.5, 10.5)\n     plt.plot(N, history['loss'], label = \"train_loss\")\n     plt.plot(N, history['val_loss'], label = \"val_loss\")\n     plt.xlabel(\"Epoch #\")\n     plt.ylabel(\"Loss\")\n     plt.legend()\n     plt.savefig('loss.png', dpi=100)\n     plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = buildOneToOneModel(X_train.shape)\n#model=load_model(\"LSTM_result_batch256_epoch128_per96_random2.h5\")\ncallback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(X_train, Y_train, epochs=100, batch_size=256, validation_data=(X_val, Y_val), callbacks=[callback])\n#plot1(history.history)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction=model.predict(X_val)\ncount=0\nprediction1=prediction\nfor i in range(prediction1.shape[0]):\n    prediction1[i]=unnormalize(prediction[i])\nY_val1=unnormalize(Y_val)\n\nfor i in range(len(Y_val)):\n    if prediction1[i][0][0]<=Y_val1[i]+0.5 and prediction1[i][0][0]>=Y_val1[i]-0.5:\n        count=count+1\nprint(count/len(Y_val1)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}