{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom pprint import pprint\nfrom six import BytesIO\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\nimport tensorflow_hub as hub\nfrom PIL import Image, ImageColor, ImageDraw, ImageFont, ImageOps\nfrom tqdm import tqdm\nimport glob\n\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_prediction_string(image_id, result):\n    prediction_strings = []\n    box_s = 0\n    score = 0\n    flag = 0\n    \n    for i in range(len(result['detection_scores'])):\n        if result['detection_class_entities'][i].decode(\"ascii\")=='Insect':\n            class_name = result['detection_class_entities'][i].decode(\"ascii\")\n            YMin,XMin,YMax,XMax = result['detection_boxes'][i]\n            box_s = box_s + (YMax-YMin)*(XMax-XMin)\n            score = score+result['detection_scores'][i]\n            prediction_strings.append(\n                f\"{class_name} {score} {XMin} {YMin} {XMax} {YMax}\"\n                )\n            flag = 1\n        if flag == 0:\n            class_name = 'null'\n    prediction_string = \" \".join(prediction_strings)\n\n    return {\n        \"ImageID\": image_id,\n        #\"PredictionString\": prediction_string\n        \"class_name\":class_name,\n        \"box_s\":box_s,\n        \"score\":score\n    }\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_image(image):\n    fig = plt.figure(figsize=(20, 15))\n    plt.grid(False)\n    plt.axis('off')\n    plt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_bounding_box_on_image(image,\n                               ymin,\n                               xmin,\n                               ymax,\n                               xmax,\n                               color,\n                               font,\n                               thickness=4,\n                               display_str_list=()):\n    \"\"\"Adds a bounding box to an image.\"\"\"\n    draw = ImageDraw.Draw(image)\n    im_width, im_height = image.size\n    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n                                  ymin * im_height, ymax * im_height)\n    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n               (left, top)],\n              width=thickness,\n              fill=color)\n\n    # If the total height of the display strings added to the top of the bounding\n    # box exceeds the top of the image, stack the strings below the bounding box\n    # instead of above.\n    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n    # Each display_str has a top and bottom margin of 0.05x.\n    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n\n    if top > total_display_str_height:\n        text_bottom = top\n    else:\n        text_bottom = bottom + total_display_str_height\n    # Reverse list and print from bottom to top.\n    for display_str in display_str_list[::-1]:\n        text_width, text_height = font.getsize(display_str)\n        margin = np.ceil(0.05 * text_height)\n        draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n                        (left + text_width, text_bottom)],\n                       fill=color)\n        draw.text((left + margin, text_bottom - text_height - margin),\n                  display_str,\n                  fill=\"black\",\n                  font=font)\n        text_bottom -= text_height - 2 * margin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n    \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n    colors = list(ImageColor.colormap.values())\n\n    try:\n        font = ImageFont.truetype(\n            \"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n            25)\n    except IOError:\n        print(\"Font not found, using default font.\")\n        font = ImageFont.load_default()\n\n    for i in range(min(boxes.shape[0], max_boxes)):\n        if scores[i] >= min_score:\n            ymin, xmin, ymax, xmax = tuple(boxes[i].tolist())\n            display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n                                           int(100 * scores[i]))\n            color = colors[hash(class_names[i]) % len(colors)]\n            image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n            draw_bounding_box_on_image(\n                image_pil,\n                ymin,\n                xmin,\n                ymax,\n                xmax,\n                color,\n                font,\n                display_str_list=[display_str])\n            np.copyto(image, np.array(image_pil))\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_image_path = \"../input/a-figure/A_figure/ATT10_67EAF187-B59C-4F5F-BAAC-9F76E06A96D6.jpg\"\n\nwith tf.Graph().as_default():\n    # Create our inference graph\n    image_string_placeholder = tf.placeholder(tf.string)\n    decoded_image = tf.image.decode_jpeg(image_string_placeholder)\n    decoded_image_float = tf.image.convert_image_dtype(\n        image=decoded_image, dtype=tf.float32\n    )\n    # Expanding image from (height, width, 3) to (1, height, width, 3)\n    image_tensor = tf.expand_dims(decoded_image_float, 0)\n\n    # Load the model from tfhub.dev, and create a detector_output tensor\n    model_url = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\"\n    detector = hub.Module(model_url)\n    detector_output = detector(image_tensor, as_dict=True)\n    \n    # Initialize the Session\n    init_ops = [tf.global_variables_initializer(), tf.tables_initializer()]\n    sess = tf.Session()\n    sess.run(init_ops)\n\n    # Load our sample image into a binary string\n    with tf.gfile.Open(sample_image_path, \"rb\") as binfile:\n        image_string = binfile.read()\n\n    # Run the graph we just created\n    result_out, image_out = sess.run(\n        [detector_output, decoded_image],\n        feed_dict={image_string_placeholder: image_string}\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_with_boxes = draw_boxes(\n    np.array(image_out), result_out[\"detection_boxes\"],\n    result_out[\"detection_class_entities\"], result_out[\"detection_scores\"]\n)\ndisplay_image(image_with_boxes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(image_string_placeholder)\nprint(decoded_image)\nprint(decoded_image_float)\nprint(image_tensor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pprint(detector_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"result_out keys:\", result_out.keys())\nprint(\"First 10 detection scores:\", result_out['detection_scores'][:10])\nname = result_out[\"detection_class_entities\"][0].decode('ascii')\nprint(\"First 10 detection types:\", result_out[\"detection_class_entities\"][:10])\nprint(\"Shape of image_out\", image_out.shape)\nprint(\"Type of image_out:\", type(image_out))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sample_submission_df = pd.read_csv('../input/sample_submission.csv')\n#image_ids = sample_submission_df['ImageId']\nWSI_MASK_PATH = '../input/a-figure/A_figure/'#存放图片的文件夹路径\npaths = glob.glob(os.path.join(WSI_MASK_PATH, '*.jpg'))\npaths.sort()\npredictions = []\n\nfor image_path in paths:\n#for image_id in tqdm(image_ids):\n    # Load the image string\n    #image_path = f'../input/test/{image_id}.jpg'\n    with tf.gfile.Open(image_path, \"rb\") as binfile:\n        image_string = binfile.read()\n    \n    # Run our session\n    result_out = sess.run(\n        detector_output,\n        feed_dict={image_string_placeholder: image_string}\n    )\n    predictions.append(format_prediction_string(image_path, result_out))\n\nsess.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df = pd.DataFrame(predictions)\npred_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}