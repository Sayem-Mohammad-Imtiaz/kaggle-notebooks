{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom warnings import simplefilter\nsimplefilter(action='ignore', category = FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FILE_PATH = '/kaggle/input/gender-classification/Transformed Data Set - Sheet1.csv'\ndata = pd.read_csv(FILE_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = data['Favorite Color'].value_counts()\ncolor = c.index\nc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mg = data['Favorite Music Genre'].value_counts()\ngenre = mg.index\nmg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"b = data['Favorite Beverage'].value_counts()\nbeverage = b.index\nb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = data['Favorite Soft Drink'].value_counts()\nsoft = s.index\ns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = data['Gender'].value_counts()\ngender = g.index\ng","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Manual Encoding","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(color)):\n    data['Favorite Color'].replace(color[i], i, inplace = True)\n\nfor i in range(len(genre)):\n    data['Favorite Music Genre'].replace(genre[i], i, inplace = True)\n\nfor i in range(len(beverage)):\n    data['Favorite Beverage'].replace(beverage[i], i, inplace = True)\n    \nfor i in range(len(soft)):\n    data['Favorite Soft Drink'].replace(soft[i], i, inplace = True)\n    \nfor i in range(len(gender)):\n    data['Gender'].replace(gender[i], i, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Successfully encoded! :)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data['Gender']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['Favorite Color', 'Favorite Music Genre', 'Favorite Beverage', 'Favorite Soft Drink']\nX = data[features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test 1: Using the entire dataset as both the train and test sets without splitting into separate train and test sets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression\nlog_model = LogisticRegression()\nlog_model.fit(X, y)\nprint(\"Logistic Regression:\", log_model.score(X, y).round(3))\n\n# Linear Discriminant Analysis\nlda_model = LinearDiscriminantAnalysis()\nlda_model.fit(X, y)\nprint(\"Linear Discriminant Analysis:\", lda_model.score(X, y).round(3))\n\n# K-Nearest Neigbors\nknn_model = KNeighborsClassifier()\nknn_model.fit(X, y)\nprint(\"K-Nearest Neigbors:\", knn_model.score(X, y).round(3))\n\n# Classification and Regression Trees\ncart_model = DecisionTreeClassifier()\ncart_model.fit(X, y)\nprint(\"Classification and Regression Trees:\", cart_model.score(X, y).round(3))\n\n# Gaussian Naive Bayes\ngnb_model = GaussianNB()\ngnb_model.fit(X, y)\nprint(\"Gaussian Naive Bayes:\", gnb_model.score(X, y).round(3))\n\n# Support Vector Machines\nsvm_model = SVC(gamma = 'auto')\nsvm_model.fit(X, y)\nprint(\"Support Vector Machines:\", svm_model.score(X, y).round(3))\n\n# Random Forest Classifier\nrfc_model = RandomForestClassifier()\nrfc_model.fit(X, y)\nprint(\"Random Forest Classifier:\", rfc_model.score(X, y).round(3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In this test, both CART and RFC scored the highest at 95.5% predictive accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test 2: Splitting the dataset into separate train and test sets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression\nlog_model = LogisticRegression()\nlog_model.fit(X_train, y_train)\nprint(\"Logistic Regression:\", log_model.score(X_test, y_test).round(3))\n\n# Linear Discriminant Analysis\nlda_model = LinearDiscriminantAnalysis()\nlda_model.fit(X_train, y_train)\nprint(\"Linear Discriminant Analysis:\", lda_model.score(X_test, y_test).round(3))\n\n# K-Nearest Neigbors\nknn_model = KNeighborsClassifier()\nknn_model.fit(X_train, y_train)\nprint(\"K-Nearest Neigbors:\", knn_model.score(X_test, y_test).round(3))\n\n# Classification and Regression Trees\ncart_model = DecisionTreeClassifier()\ncart_model.fit(X_train, y_train)\nprint(\"Classification and Regression Trees:\", cart_model.score(X_test, y_test).round(3))\n\n# Gaussian Naive Bayes\ngnb_model = GaussianNB()\ngnb_model.fit(X_train, y_train)\nprint(\"Gaussian Naive Bayes:\", gnb_model.score(X_test, y_test).round(3))\n\n# Support Vector Machines\nsvm_model = SVC(gamma = 'auto')\nsvm_model.fit(X_train, y_train)\nprint(\"Support Vector Machines:\", svm_model.score(X_test, y_test).round(3))\n\n# Random Forest Classifier\nrfc_model = RandomForestClassifier()\nrfc_model.fit(X_train, y_train)\nprint(\"Random Forest Classifier:\", rfc_model.score(X_test, y_test).round(3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the set showed a drastic decrease in predictive accuracy among all the models, which was to be expected\n# In this test, KNN did the best, scoring at 50%","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analyzing the accuracy of CART and RFC, the highest scorers, in the first test (which, as you may recall, was the test\n# in which the data was not split):","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating accuracy metrics for CART\ncart_model.fit(X, y)\ncart_pred = cart_model.predict(X)\n\nprint('Accuracy Metrics for CART:\\n')\nprint(accuracy_score(y, cart_pred).round(5), '\\n')\nprint(confusion_matrix(y, cart_pred), '\\n')\nprint(classification_report(y, cart_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating accuracy metrics for RFC\nrfc_model.fit(X, y)\nrfc_pred = rfc_model.predict(X)\n\nprint('Accuracy Metrics for RFC:\\n')\nprint(accuracy_score(y, rfc_pred).round(5), '\\n')\nprint(confusion_matrix(y, rfc_pred), '\\n')\nprint(classification_report(y, rfc_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Conclusion: Both CART (Classification and Regression Trees) and RFC (Random Forest Classifier) had 95.5% accuracy\n# and scored the highest out of all the models! This outcome makes sense because of the relationship between the two\n# models (decision trees and random forests). Thank you for reading!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}