{"cells":[{"metadata":{"_uuid":"d6996868a117c237300d06626ac7cff0507e3819"},"cell_type":"markdown","source":"# Forecast bitcoin based on Polarity using LSTM"},{"metadata":{"_uuid":"169a3c4a4d0e07b978c38cd8035721c5897db5fb"},"cell_type":"markdown","source":"I will copy previous author boilerplate to get necessary dataframe."},{"metadata":{"trusted":true,"_uuid":"e777e8fcb088070e8264d936b82cfbf74d91e6a8"},"cell_type":"code","source":"import pandas as pd\nimport re \nfrom matplotlib import pyplot\nimport seaborn as sns\nimport numpy as np\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07abc867e57ccf5d705cafa32e4a8b45b6072351"},"cell_type":"markdown","source":"# Data Pre-processing"},{"metadata":{"trusted":true,"_uuid":"bd4ae8de3e746a9f1114ba28b8089ba269d26e02","_kg_hide-input":true},"cell_type":"code","source":"notclean = pd.read_csv('../input/bitcoin-tweets-14m/cleanprep.csv', delimiter=',', error_bad_lines=False,engine = 'python',header = None)\nnotclean.columns =['dt', 'name','text','polarity','sensitivity']\nnotclean =notclean.drop(['name','text'], axis=1)\nnotclean['dt'] = pd.to_datetime(notclean['dt'])\nnotclean['DateTime'] = notclean['dt'].dt.floor('h')\nvdf = notclean.groupby(pd.Grouper(key='dt',freq='H')).size().reset_index(name='tweet_vol')\nvdf.index = pd.to_datetime(vdf.index)\nvdf=vdf.set_index('dt')\nnotclean.index = pd.to_datetime(notclean.index)\nvdf['tweet_vol'] =vdf['tweet_vol'].astype(float)\ndf = notclean.groupby('DateTime').agg(lambda x: x.mean())\ndf = df.drop(df.index[0])\nbtcDF = pd.read_csv('../input/btc-price/btcSave2.csv', error_bad_lines=False,engine = 'python')\nbtcDF['Timestamp'] = pd.to_datetime(btcDF['Timestamp'])\nbtcDF = btcDF.set_index(pd.DatetimeIndex(btcDF['Timestamp']))\nbtcDF = btcDF.drop(['Timestamp'], axis=1)\nFinal_df = pd.merge(df,btcDF, how='inner',left_index=True, right_index=True)\nFinal_df=Final_df.drop(['Weighted Price'],axis=1 )\nprint(list(Final_df))\nFinal_df.columns = ['Polarity', 'Sensitivity', 'Open','High','Low', 'Close_Price', 'Volume_BTC', 'Volume_Dollar']\nFinal_df = Final_df[['Polarity', 'Sensitivity', 'Open','High','Low', 'Volume_BTC', 'Volume_Dollar', 'Close_Price']]\nFinal_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bb6608bcdefc640277bd64341527c20fafd2c16"},"cell_type":"markdown","source":"## Simple metrics study"},{"metadata":{"trusted":true,"_uuid":"e9f1b7ab590a30e592ec115f0ece7edd4a4102ca"},"cell_type":"code","source":"df = Final_df\ndf['Polarity'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eee525ab830dbf497e3c88e5f2879cba645341a0"},"cell_type":"code","source":"df['Sensitivity'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1799d963513c7ec653ef0c51842d54baf0593fd1"},"cell_type":"code","source":"df['Close_Price'].describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad2a81834cbfddd30f013074c206c2cc35f88289"},"cell_type":"markdown","source":"## Detecting outliers / sudden spikes in our close prices"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"9cba591ecadc49ce9f8f348ffc156d5f3b435ab9"},"cell_type":"code","source":"def detect(signal,treshold=2.0):\n    detected = []\n    for i in range(len(signal)):\n        if np.abs(signal[i]) > treshold:\n            detected.append(i)\n    return detected","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"500893914858a91b0803569a53e122c74104cc04"},"cell_type":"code","source":"signal = np.copy(df['Close_Price'].values)\nstd_signal = (signal - np.mean(signal)) / np.std(signal)\ns = pd.Series(std_signal)\ns.describe(percentiles=[0.25,0.5,0.75,0.95])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08d587190a634de292f21ba01e46c567702364dc"},"cell_type":"markdown","source":"From 0.95, I will take 1.3"},{"metadata":{"trusted":true,"_uuid":"1a118bdc17054787b51b5724c033bc9130e98e62"},"cell_type":"code","source":"outliers = detect(std_signal, 1.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"629c376db992511bd057940d3125ddc5141249be"},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17060981a88c0acef70a71c25608418da43eb36e"},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nplt.plot(np.arange(len(signal)), signal)\nplt.plot(np.arange(len(signal)), signal, 'X', label='outliers',markevery=outliers, c='r')\nplt.xticks(np.arange(len(signal))[::15], df.index[::15], rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d87b59118569bf56202241c867b8210d23311bcb"},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nminmax = MinMaxScaler().fit(df[['Polarity','Sensitivity','Close_Price']])\nscaled = minmax.transform(df[['Polarity','Sensitivity','Close_Price']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38a229c315d025bd40856988b06e4fdc61e66ab1"},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nplt.plot(np.arange(len(signal)), scaled[:,0], label = 'Scaled polarity')\nplt.plot(np.arange(len(signal)), scaled[:,1], label = 'Scaled sensitivity')\nplt.plot(np.arange(len(signal)), scaled[:,2], label = 'Scaled closed price')\nplt.plot(np.arange(len(signal)), scaled[:,0], 'X', label='outliers polarity based on close', markevery=outliers, c='r')\nplt.plot(np.arange(len(signal)), scaled[:,1], 'o', label='outliers polarity based on close', markevery=outliers, c='r')\nplt.xticks(np.arange(len(signal))[::15], df.index[::15], rotation='vertical')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11f736f98696ba7ca8a61f0b1b304b2668da519e"},"cell_type":"markdown","source":"Doesnt show much from trending, how about covariance correlation?"},{"metadata":{"_uuid":"48574c5f07d60ff05d859ec940839ab8150298da"},"cell_type":"markdown","source":"## Pearson correlation"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"97810e3d1e201bf2e06146d9e107a957aca282d8"},"cell_type":"code","source":"colormap = plt.cm.RdBu\nplt.figure(figsize=(15,7))\nplt.title('pearson correlation', y=1.05, size=16)\n\nmask = np.zeros_like(df.corr())\nmask[np.triu_indices_from(mask)] = True\n\nsns.heatmap(df.corr(), mask=mask, linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"2f7ed3965211685028419f8af4c8677cfc7dbb79"},"cell_type":"code","source":"def df_shift(df,lag=0, start=1, skip=1, rejected_columns = []):\n    df = df.copy()\n    if not lag:\n        return df\n    cols ={}\n    for i in range(start,lag+1,skip):\n        for x in list(df.columns):\n            if x not in rejected_columns:\n                if not x in cols:\n                    cols[x] = ['{}_{}'.format(x, i)]\n                else:\n                    cols[x].append('{}_{}'.format(x, i))\n    for k,v in cols.items():\n        columns = v\n        dfn = pd.DataFrame(data=None, columns=columns, index=df.index)    \n        i = 1\n        for c in columns:\n            dfn[c] = df[k].shift(periods=i)\n            i+=1\n        df = pd.concat([df, dfn], axis=1, join_axes=[df.index])\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d76e28ed6c3133340f7fc7bd888445dd2b6e1320"},"cell_type":"code","source":"df_new = df_shift(df, lag=42, start=7, skip=7)\ndf_new.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db54332271d99795e31e7c5ede3998901a74b72b"},"cell_type":"code","source":"colormap = plt.cm.RdBu\nplt.figure(figsize=(30,20))\nax=plt.subplot(111)\nplt.title('42 hours correlation', y=1.05, size=16)\nselected_column = [col for col in list(df_new) if any([k in col for k in ['Polarity','Sensitivity','Close']])]\n\nsns.heatmap(df_new[selected_column].corr(), ax=ax, linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7fdda4d85571b64515e4a595364a4923902d8a07"},"cell_type":"markdown","source":"This is cross-correlation, I am actually just interested with Close_Price and Polarity_X"},{"metadata":{"_uuid":"949f7c7904f6012a8babb9474b94a1053f362144"},"cell_type":"markdown","source":"## How about we check trends from moving average? i chose 7, 14, 30 hours"},{"metadata":{"_uuid":"ec4b74bc4293c5433118093486272cbfb310e078"},"cell_type":"markdown","source":" i think i had too much playing with daily trending data"},{"metadata":{"trusted":true,"_uuid":"5836394703626aa5ceed0ca184d607be6c1714c1"},"cell_type":"code","source":"def moving_average(signal, period):\n    buffer = [np.nan] * period\n    for i in range(period,len(signal)):\n        buffer.append(signal[i-period:i].mean())\n    return buffer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64d83ee6b967725e26aca03b71b8705bf95fc20b"},"cell_type":"code","source":"signal = np.copy(df['Close_Price'].values)\nma_7 = moving_average(signal, 7)\nma_14 = moving_average(signal, 14)\nma_30 = moving_average(signal, 30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e4be50ad661fa592ad44ce6b881d7e091b92851"},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nplt.plot(np.arange(len(signal)), signal, label='real signal')\nplt.plot(np.arange(len(signal)), ma_7, label='ma 7')\nplt.plot(np.arange(len(signal)), ma_14, label='ma 14')\nplt.plot(np.arange(len(signal)), ma_30, label='ma 30')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba57617fef502a1f3a499e3bf02dd5b8544e5100"},"cell_type":"markdown","source":"## Now deep learning LSTM"},{"metadata":{"trusted":true,"_uuid":"15cd4d2dc5c670e9539c74c531d89e39554ca94d"},"cell_type":"code","source":"num_layers = 1\nlearning_rate = 0.005\nsize_layer = 128\ntimestamp = 5\nepoch = 500\ndropout_rate = 0.6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f706b6cbb85a5063f02bb32329f5ebb2a8107070"},"cell_type":"code","source":"dates = pd.to_datetime(df.index).tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7087489e097ba23ad3646e04268ed4af5dba7fd6"},"cell_type":"code","source":"class Model:\n    def __init__(self, learning_rate, num_layers, \n                 size, size_layer, forget_bias = 0.8):\n        \n        def lstm_cell(size_layer):\n            return tf.nn.rnn_cell.LSTMCell(size_layer, state_is_tuple = False)\n        rnn_cells = tf.nn.rnn_cell.MultiRNNCell([lstm_cell(size_layer) for _ in range(num_layers)], \n                                                state_is_tuple = False)\n        self.X = tf.placeholder(tf.float32, (None, None, size))\n        self.Y = tf.placeholder(tf.float32, (None, size))\n        drop = tf.contrib.rnn.DropoutWrapper(rnn_cells, output_keep_prob = forget_bias)\n        self.hidden_layer = tf.placeholder(tf.float32, \n                                           (None, num_layers * 2 * size_layer))\n        self.outputs, self.last_state = tf.nn.dynamic_rnn(drop, self.X, \n                                                          initial_state = self.hidden_layer, \n                                                          dtype = tf.float32)\n        self.logits = tf.layers.dense(self.outputs[-1],size,\n                       kernel_initializer=tf.glorot_uniform_initializer())\n        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self.cost)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64013a1d4f0bf61a9978c23e27ba428cb4071c5f"},"cell_type":"code","source":"minmax = MinMaxScaler().fit(df[['Polarity','Sensitivity','Close_Price']].astype('float32'))\ndf_scaled = minmax.transform(df[['Polarity','Sensitivity','Close_Price']].astype('float32'))\ndf_scaled = pd.DataFrame(df_scaled)\ndf_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36176ba2545262265f50e96d2f7b61831e0d4a51"},"cell_type":"code","source":"tf.reset_default_graph()\nmodelnn = Model(learning_rate, num_layers, df_scaled.shape[1], size_layer, dropout_rate)\nsess = tf.InteractiveSession()\nsess.run(tf.global_variables_initializer())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e22f5d85328b996eca9cc52cfec1536833c0156"},"cell_type":"code","source":"for i in range(epoch):\n    init_value = np.zeros((1, num_layers * 2 * size_layer))\n    total_loss = 0\n    for k in range(0, (df_scaled.shape[0] // timestamp) * timestamp, timestamp):\n        batch_x = np.expand_dims(df_scaled.iloc[k: k + timestamp].values, axis = 0)\n        batch_y = df_scaled.iloc[k + 1: k + timestamp + 1].values\n        last_state, _, loss = sess.run([modelnn.last_state, \n                                        modelnn.optimizer, \n                                        modelnn.cost], feed_dict={modelnn.X: batch_x, \n                                                                  modelnn.Y: batch_y, \n                                                                  modelnn.hidden_layer: init_value})\n        init_value = last_state\n        total_loss += loss\n    total_loss /= (df.shape[0] // timestamp)\n    if (i + 1) % 100 == 0:\n        print('epoch:', i + 1, 'avg loss:', total_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a7a20475cbaf5a915d067718ce5b7fa910988fb","_kg_hide-input":true},"cell_type":"code","source":"def predict_future(future_count, df, dates, indices={}):\n    date_ori = dates[:]\n    cp_df = df.copy()\n    output_predict = np.zeros((cp_df.shape[0] + future_count, cp_df.shape[1]))\n    output_predict[0, :] = cp_df.iloc[0]\n    upper_b = (cp_df.shape[0] // timestamp) * timestamp\n    init_value = np.zeros((1, num_layers * 2 * size_layer))\n    for k in range(0, (df.shape[0] // timestamp) * timestamp, timestamp):\n        out_logits, last_state = sess.run(\n            [modelnn.logits, modelnn.last_state],\n            feed_dict = {\n                modelnn.X: np.expand_dims(\n                    cp_df.iloc[k : k + timestamp], axis = 0\n                ),\n                modelnn.hidden_layer: init_value,\n            },\n        )\n        init_value = last_state\n        output_predict[k + 1 : k + timestamp + 1] = out_logits\n    out_logits, last_state = sess.run(\n        [modelnn.logits, modelnn.last_state],\n        feed_dict = {\n            modelnn.X: np.expand_dims(cp_df.iloc[upper_b:], axis = 0),\n            modelnn.hidden_layer: init_value,\n        },\n    )\n    init_value = last_state\n    output_predict[upper_b + 1 : cp_df.shape[0] + 1] = out_logits\n    cp_df.loc[cp_df.shape[0]] = out_logits[-1]\n    date_ori.append(date_ori[-1] + timedelta(hours = 1))\n    if indices:\n        for key, item in indices.items():\n            cp_df.iloc[-1,key] = item\n    for i in range(future_count - 1):\n        out_logits, last_state = sess.run(\n            [modelnn.logits, modelnn.last_state],\n            feed_dict = {\n                modelnn.X: np.expand_dims(cp_df.iloc[-timestamp:], axis = 0),\n                modelnn.hidden_layer: init_value,\n            },\n        )\n        init_value = last_state\n        output_predict[cp_df.shape[0], :] = out_logits[-1, :]\n        cp_df.loc[cp_df.shape[0]] = out_logits[-1, :]\n        date_ori.append(date_ori[-1] + timedelta(hours = 1))\n        if indices:\n            for key, item in indices.items():\n                cp_df.iloc[-1,key] = item\n    return {'date_ori': date_ori, 'df': cp_df.values}    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15358157b6efc92d1da00ccc8f8ff342e4d056ed"},"cell_type":"markdown","source":"Define some smoothing, using previous value as an anchor"},{"metadata":{"trusted":true,"_uuid":"984982b501d0a83a029ec25c098a3ca45a1728d5"},"cell_type":"code","source":"def anchor(signal, weight):\n    buffer = []\n    last = signal[0]\n    for i in signal:\n        smoothed_val = last * weight + (1 - weight) * i\n        buffer.append(smoothed_val)\n        last = smoothed_val\n    return buffer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d88e7e0d97391288ac6250e5c85a93383c7293df"},"cell_type":"code","source":"predict_30 = predict_future(30, df_scaled, dates)\npredict_30['df'] = minmax.inverse_transform(predict_30['df'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3326b6babfdb3e783f0e4a035f7070c08dfd1894"},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nplt.plot(np.arange(len(predict_30['date_ori'])), anchor(predict_30['df'][:,-1],0.5), label='predict signal')\nplt.plot(np.arange(len(signal)), signal, label='real signal')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ef8db173956f30c6301ce9566ca2613a9d3a161"},"cell_type":"markdown","source":"## What happen if polarity is double from the max? Polarity is first index"},{"metadata":{"trusted":true,"_uuid":"bae4cff5b27fcdef9cbc51651ae8e8327a43efc0"},"cell_type":"code","source":"scaled_polarity = (minmax.data_max_[0] * 2 - minmax.data_min_[0]) / (minmax.data_max_[0] - minmax.data_min_[0])\nscaled_polarity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ae12b915fd9a3d90bd48c2d6e6831570af455fb"},"cell_type":"code","source":"plt.figure(figsize=(15,7))\n\nfor retry in range(3):\n    plt.subplot(3, 1, retry + 1)\n    predict_30 = predict_future(30, df_scaled, dates, indices = {0:scaled_polarity})\n    predict_30['df'] = minmax.inverse_transform(predict_30['df'])\n    plt.plot(np.arange(len(predict_30['date_ori'])), anchor(predict_30['df'][:,-1],0.5), label='predict signal')\n    plt.plot(np.arange(len(signal)), signal, label='real signal')\n    plt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45e62bded88d285fa7ff846ffe974f24b59c50c6"},"cell_type":"markdown","source":"I retried for 3 times just to study how fitted our model is, if every retry has big trend changes, so we need to retrain again."},{"metadata":{"_uuid":"278692e716bfab67bad80400ac91cf99e1d84abd"},"cell_type":"markdown","source":"## What happen if polarity is quadriple from the max? Polarity is first index"},{"metadata":{"trusted":true,"_uuid":"2ffde6254cb5315ac98435166534efd6527d2897"},"cell_type":"code","source":"scaled_polarity = (minmax.data_max_[0] * 4 - minmax.data_min_[0]) / (minmax.data_max_[0] - minmax.data_min_[0])\nscaled_polarity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c63e1a9828947f41723d8d14aae138a48a05cd3"},"cell_type":"code","source":"plt.figure(figsize=(15,7))\n\nfor retry in range(3):\n    plt.subplot(3, 1, retry + 1)\n    predict_30 = predict_future(30, df_scaled, dates, indices = {0:scaled_polarity})\n    predict_30['df'] = minmax.inverse_transform(predict_30['df'])\n    plt.plot(np.arange(len(predict_30['date_ori'])), anchor(predict_30['df'][:,-1],0.5), label='predict signal')\n    plt.plot(np.arange(len(signal)), signal, label='real signal')\n    plt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"178f1dec8de55b9c3505cdb4dc76780ad4c05f50"},"cell_type":"markdown","source":"## What happen if polarity is quadriple from the min? polarity is first index"},{"metadata":{"trusted":true,"_uuid":"556016233f9a472e765ad3e04789c35139faac22"},"cell_type":"code","source":"scaled_polarity = (minmax.data_min_[0] / 4 - minmax.data_min_[0]) / (minmax.data_max_[0] - minmax.data_min_[0])\nscaled_polarity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddfe975db03514a9bb5ff2c623b600bd2fe63ec1"},"cell_type":"code","source":"plt.figure(figsize=(15,7))\n\nfor retry in range(3):\n    plt.subplot(3, 1, retry + 1)\n    predict_30 = predict_future(30, df_scaled, dates, indices = {0:scaled_polarity})\n    predict_30['df'] = minmax.inverse_transform(predict_30['df'])\n    plt.plot(np.arange(len(predict_30['date_ori'])), anchor(predict_30['df'][:,-1],0.5), label='predict signal')\n    plt.plot(np.arange(len(signal)), signal, label='real signal')\n    plt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a80660c372089e33e0df39d91497fa9309a5c7a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}