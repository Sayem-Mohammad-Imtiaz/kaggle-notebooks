{"cells":[{"cell_type":"markdown","metadata":{},"source":"The focus of the analysis, is to identify the main factors, for a person to decide to date someone, after only few minutes of interaction. \nTherefore, it is focus on the variable \"dec\" (willines to see the person again) rather than \"match\" both agreed to meet again \n\n##  Work in Progress \n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"\nimport numpy as np # linear algebra\nimport pandas as pandas # data processing, CSV file I/O (e.g. pd.read_csv)\n#########\nimport seaborn as sns\n\nimport matplotlib\n\nimport numpy as numpy\nimport pandas as pandas\nimport statsmodels.api\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\n\nimport statsmodels.stats.multicomp as multi \n\nimport scipy\nimport matplotlib.pyplot as plt\nimport warnings \n\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report\nimport sklearn.metrics\nfrom sklearn.ensemble import ExtraTreesClassifier\n\nwarnings.simplefilter(action = \"ignore\", category = FutureWarning) \nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#Reading the data\ndata1 = pandas.read_csv(\"../input/Speed Dating Data.csv\", encoding=\"ISO-8859-1\")\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"##Selecting Only the Relevant Variables for the Analysis\ntemp1=data1[['iid','gender','pid','samerace','age_o','race_o','dec_o','attr_o','sinc_o','intel_o','fun_o','amb_o','shar_o','like_o','prob_o','age','field_cd','race','imprace','imprelig','from','date','go_out','dec','attr','sinc','intel','fun','amb','shar','like','prob']]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"###################################################################################################\n# The next lines are to have on the same raw all the relevant information from both the partners.##\n####################################################################################################\n\n#Creation DataSet for Merging Missing Variables\ntemp2=temp1[['iid','field_cd','imprace','imprelig','from','date','go_out']]\n#Rename the variables to avoid confusion with the two data frames...\ntemp2.columns = ['pid','field_cd_o','imprace_o','imprelig_o','from_0','date_0','go_out_o']\n#Merge the two datasets to have all the variables for both the partners.\nBothGenders=pandas.merge(temp1,temp2,on='pid')\n\nBothGenders=BothGenders.drop('iid',1)\nBothGenders=BothGenders.drop('pid',1)\nBothGenders=BothGenders.dropna()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"###############################################################\n#Creation New Features to further analysis potential patterns##\n###############################################################\n#Difference of the age between the parther instead of the \"absolute\" age.  \nBothGenders['Delta_Age']=BothGenders['age'] - BothGenders['age_o']\n#Same field of career\nBothGenders['SameField']=BothGenders['field_cd'] == BothGenders['field_cd_o']\n#Provenience from the state.\nBothGenders['SameState']=BothGenders['from'] == BothGenders['from_0']\nBothGenders=BothGenders.drop('from',1)\nBothGenders=BothGenders.drop('from_0',1)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#Subset the dataframe for the two genders From now on we will use only these two datasets.\nFemales=BothGenders.loc[BothGenders['gender'] == 0]\nMales=BothGenders.loc[BothGenders['gender'] == 1]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#Average for all the Features Group by 'dec' factor\n#Females\nFemales[Females.columns[:]].groupby(Females['dec']).mean().round(2)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#Males\nMales[Males.columns[:]].groupby(Males['dec']).mean().round(2)"},{"cell_type":"markdown","metadata":{},"source":"##ANOVA Analysis"},{"cell_type":"markdown","metadata":{},"source":"Females"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"\nmodel1 = smf.ols(formula='dec ~ C(samerace)+age_o+C(race_o)+dec_o+attr_o+sinc_o+intel_o+fun_o+amb_o+shar_o+like_o+prob_o+imprace+imprelig+date+go_out+attr+sinc+intel+fun+amb+shar+like+prob+age+age_o+Delta_Age+go_out_o+date_0+C(race)', data=Females)\nresults1 = model1.fit()\n\ntable = sm.stats.anova_lm(results1, typ=2) \n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"FeaturesImportance=sorted(zip(table.F,table.index),reverse=True)\ndfFemales = pandas.DataFrame(FeaturesImportance, columns=['Model.Feature_Importances_Based_on_F', 'predictors.columns'])\nprint(\"Top 10 Features with the highest F value\") \nprint(dfFemales.head(10).round(2))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"ax0=sns.barplot(y=\"predictors.columns\", x=\"Model.Feature_Importances_Based_on_F\", data=dfFemales,\n             palette=\"Blues\")\nax0.set(ylabel='Predictors', xlabel='F value',title=\"Female Group, F values for each Predictor\")\nplt.show()"},{"cell_type":"markdown","metadata":{},"source":"Below few BoxPlots to visualize few of the top variables on the two codition of \"dec\""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"Females.boxplot(column=['like','attr','attr_o','shar','prob'], by=['dec'])"},{"cell_type":"markdown","metadata":{},"source":"In the letterature there are many reference on the Race for the decision of the partner, so further exploration \nhave been made..."},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(\"if the partner are from the same race are more keen to go for a date?\")\npandas.crosstab(Females.samerace,Females.dec).apply(lambda r: r/r.sum(), axis=1).round(2)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"print(\"what are the cross selections from the different races \")\npandas.crosstab([Females.race,Females.race_o],Females.dec).apply(lambda r: r/r.sum(), axis=1).round(2)"},{"cell_type":"markdown","metadata":{},"source":"Black/African American 1, European/Caucasian-American 2, Latino/Hispanic American 3, Asian/Pacific Islander/Asian-American 4, Native American 5, Other 6"},{"cell_type":"markdown","metadata":{},"source":"The Same analysis for the Males"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"model1 = smf.ols(formula='dec ~ C(samerace)+age_o+C(race_o)+dec_o+attr_o+sinc_o+intel_o+fun_o+amb_o+shar_o+like_o+prob_o+imprace+imprelig+date+go_out+attr+sinc+intel+fun+amb+shar+like+prob+age+age_o+Delta_Age+go_out_o+date_0+C(race)', data=Males)\nresults1 = model1.fit()\n\ntable = sm.stats.anova_lm(results1, typ=2)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"FeaturesImportance=sorted(zip(table.F,table.index),reverse=True)\ndfMales = pandas.DataFrame(FeaturesImportance, columns=['Model.Feature_Importances_Based_on_F', 'predictors.columns'])\nprint(\"Top 10 Features with the highest F value\") \nprint(dfMales.head(10))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"ax1=sns.barplot(y=\"predictors.columns\", x=\"Model.Feature_Importances_Based_on_F\", data=dfMales,palette=\"Blues\")\nax1.set(ylabel='Predictors', xlabel='F value',title=\"Male Group, F values for each Predictor\")\nplt.show()"},{"cell_type":"markdown","metadata":{},"source":"Below few BoxPlots to visualize few of the top variables on the two codition of \"dec\""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"Males.boxplot(column=['like','attr','attr_o','shar','prob'], by=['dec'])"},{"cell_type":"markdown","metadata":{},"source":"Similar comparison for Races on the Males group"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"pandas.crosstab(Males.samerace,Males.dec).apply(lambda r: r/r.sum(), axis=1).round(2)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"pandas.crosstab([Males.race,Males.race_o],Males.dec ).apply(lambda r: r/r.sum(), axis=1).round(2)"},{"cell_type":"markdown","metadata":{},"source":"It appears that the race is more relevant in the Female Group, than the Male group.\nFor the male group the race is irrilevant  "},{"cell_type":"markdown","metadata":{},"source":"#Tree Classification Analysis"},{"cell_type":"markdown","metadata":{},"source":"How a simple decision tree deal with with this desision/classificaion problem?"},{"cell_type":"markdown","metadata":{},"source":"##for the Female"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"predictorsF = Females.drop('dec',1)\npredictorsF = predictorsF.drop('gender',1)\ntargetsF = Females.dec\npred_trainF, pred_testF, tar_trainF, tar_testF  =   train_test_split(predictorsF, targetsF, test_size=.4)\n    \nclassifierF=DecisionTreeClassifier(max_depth=4)\nclassifierF=classifierF.fit(pred_trainF,tar_trainF)\n   \npredictionsF=classifierF.predict(pred_testF)\nprint\nprint(\"Confusion Matrix\")\nprint(sklearn.metrics.confusion_matrix(predictionsF,tar_testF))\nprint(\"Accuracy Score\")\nprint(sklearn.metrics.accuracy_score(predictionsF,tar_testF))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn import tree\n\n######################\nfrom sklearn.externals.six import StringIO\nwith open(\"Female.dot\", 'w') as f:\n     f = tree.export_graphviz(classifierF, out_file=f,\n                             feature_names=predictorsF.columns,\n                             filled=True, rounded=True,special_characters=True)\n        #     dot -Tpng \"C:\\Users\\enzo7311\\Dropbox\\Public\\dataAnalysis\\capstone\\Female.dot\" > c:\\temp\\Female.png\n        \n      #As Soon As i understand how to visualize image saved externally I will include the Class Tree picture  "},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn import metrics\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.cross_validation import train_test_split\n \nfpr, tpr, _ = metrics.roc_curve(tar_testF, predictionsF)\n\nroc_auc = auc(fpr, tpr)\nprint ('ROC AUC: %0.2f' % roc_auc)\nplt.figure()\nplt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#from IPython.display import Image\n#Image(filename='c:/temp/female.png')"},{"cell_type":"markdown","metadata":{},"source":"Males"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"predictorsM = Males.drop('dec',1)\npredictorsM = predictorsM.drop('gender',1)\n\ntargetsM = Males.dec\npred_trainM, pred_testM, tar_trainM, tar_testM  =   train_test_split(predictorsM, targetsM, test_size=.4)\n    \nclassifierM=DecisionTreeClassifier(max_depth=4)\nclassifierM=classifierM.fit(pred_trainM,tar_trainM)\n   \npredictionsM=classifierM.predict(pred_testM)\nprint\n   \nprint(\"Confusion Matrix\")\nprint(sklearn.metrics.confusion_matrix(predictionsM,tar_testM))\nprint(\"Accuracy Score\")\nprint(sklearn.metrics.accuracy_score(predictionsM,tar_testM))\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"with open(\"Males.dot\", 'w') as f:\n     f = tree.export_graphviz(classifierM, out_file=f,\n                             feature_names=predictorsM.columns,\n                             filled=True, rounded=True,special_characters=True)\n                             #class_names=targets.columns)\n##\n#dot -Tpng \"C:\\Users\\enzo7311\\Dropbox\\Public\\dataAnalysis\\capstone\\Males.dot\" > c:\\temp\\Males.png\n##     "},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn import metrics\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.cross_validation import train_test_split\n \nfpr, tpr, _ = metrics.roc_curve(tar_testM, predictionsM)\n\nroc_auc = auc(fpr, tpr)\nprint ('ROC AUC: %0.2f' % roc_auc)\nplt.figure()\nplt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#Image(filename='c:/temp/males.png')"},{"cell_type":"markdown","metadata":{},"source":"## Random Forest Classification"},{"cell_type":"markdown","metadata":{},"source":" Female"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.ensemble import RandomForestClassifier\n\nclassifierF=RandomForestClassifier(n_estimators=25)\nclassifierF=classifierF.fit(pred_trainF,tar_trainF)\n\npredictionsF=classifierF.predict(pred_testF)\n\nsklearn.metrics.confusion_matrix(tar_testF,predictionsF)\nsklearn.metrics.accuracy_score(tar_testF, predictionsF)\n\n\n# fit an Extra Trees model to the data\nmodelF = ExtraTreesClassifier()\nmodelF.fit(pred_trainF,tar_trainF)\nprint(\"Confusion Matrix\")\nprint(sklearn.metrics.confusion_matrix(predictionsF,tar_testF))\nprint(\"Accuracy Score\")\nprint(sklearn.metrics.accuracy_score(predictionsF,tar_testF))\n\nFeaturesImportanceF=sorted(zip( modelF.feature_importances_,predictorsF.columns))\ndfFemales = pandas.DataFrame(FeaturesImportanceF, columns=['model.feature_importances_', 'predictors.columns'])\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"ax3=sns.barplot(y=\"predictors.columns\", x=\"model.feature_importances_\", data=dfFemales,\n             palette=\"Blues\")\nax3.set(ylabel='Predictors', xlabel='Importance Attribute',title=\"Female Group, Importance for each Predictor\")\nplt.show(ax3)"},{"cell_type":"markdown","metadata":{},"source":"##  Males"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"\nclassifierM=RandomForestClassifier(n_estimators=25)\nclassifierM=classifierM.fit(pred_trainM,tar_trainM)\n\npredictionsM=classifierM.predict(pred_testM)\n\nsklearn.metrics.confusion_matrix(tar_testM,predictionsM)\nsklearn.metrics.accuracy_score(tar_testM, predictionsM)\n\n\n# fit an Extra Trees model to the data\nmodelM = ExtraTreesClassifier()\nmodelM.fit(pred_trainM,tar_trainM)\nprint(\"Confusion Matrix\")\nprint(sklearn.metrics.confusion_matrix(predictionsM,tar_testM))\nprint(\"Accuracy Score\")\nprint(sklearn.metrics.accuracy_score(predictionsM,tar_testM))\n\nFeaturesImportanceM=sorted(zip( modelM.feature_importances_,predictorsM.columns))\ndfMales = pandas.DataFrame(FeaturesImportanceM, columns=['model.feature_importances_', 'predictors.columns'])\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"ax4=sns.barplot(y=\"predictors.columns\", x=\"model.feature_importances_\", data=dfMales, palette=\"Blues\")\nax4.set(ylabel='Predictors', xlabel='Importance Attribute',title=\"Males Group, Importance for each Predictor\")\nplt.show(ax4)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}