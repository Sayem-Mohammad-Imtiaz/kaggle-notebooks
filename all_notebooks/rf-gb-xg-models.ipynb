{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"id":"FRlQf2bss8hM","outputId":"c34c66ce-05c9-4393-a47a-d4a19ef30f39","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"id":"q4dwF8_E5cOH","trusted":true},"cell_type":"code","source":"# Variable\tDefinition\n# User_ID\tUser ID\n# Product_ID\tProduct ID\n# Gender\tSex of User\n# Age\tAge in bins\n# Occupation\tOccupation (Masked)\n# City_Category\tCategory of the City (A,B,C)\n# Stay_In_Current_City_Years\tNumber of years stay in current city\n# Marital_Status\tMarital Status\n# Product_Category_1\tProduct Category (Masked)\n# Product_Category_2\tProduct may belongs to other category also (Masked)\n# Product_Category_3\tProduct may belongs to other category also (Masked)\n# Purchase\tPurchase Amount (Target Variable)","execution_count":null,"outputs":[]},{"metadata":{"id":"x2wBOK8Cvriq","trusted":true},"cell_type":"code","source":"data= pd.read_csv(\"/kaggle/input/black-friday/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"id":"JwJofMMbv4r4","outputId":"2d16d7f5-e74b-471f-a442-3244adaeeb5f","trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"OzZwPWnuxBFp","outputId":"ffe9bbef-b160-4f25-ec9c-e9f5704e9a30","trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"ar_vynT7xDpK","trusted":true},"cell_type":"code","source":" # Target-- Purchase\n\n # Data understanding and cleaning\n # EDA\n # Base Model\n # Feature Selection - ANOVA, CHI-SQUARE\n # Try different models\n # Parametric Tuning    - RMSE","execution_count":null,"outputs":[]},{"metadata":{"id":"w1KsA3ae0Imn","outputId":"ce2e4ee8-75e3-43ba-9c63-52f41dd46f82","trusted":true},"cell_type":"code","source":"# Checking\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"BXUuoqwZzqqp","outputId":"389baae5-ee73-4708-aae2-d581809da276","trusted":true},"cell_type":"code","source":"# Checking the null values in the dataset\ndata.isnull().sum()/data.shape[0] *100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Only product_category_1 and product_category_2 have null values\n# Denoting none of the customers have purchased the product- Let's replace that with '0'\ndata['Product_Category_2'].fillna(0,inplace=True)\ndata['Product_Category_3'].fillna(0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()/data.shape[0] *100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### User_ID                       \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Total number of USER_ID: \", data['User_ID'].nunique())\n# It seems a repeadted purchases on the same user id as it near to 6000 while the data is for 5 lakhs\n# Other possiblitity only 1% have a unique user_id\ndata['User_ID'].value_counts().plot(kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby(['User_ID'])['Purchase'].sum().sort_values(ascending=False)[:10].plot(kind='bar')\nplt.xlabel(\"User_ID\")\nplt.ylabel(\"sum purchase in millions\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We need to target the user-ID \"1004277\" for more increase in the sales","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Product_ID","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Product_ID\nprint(\"Total number of product_id :\",data['Product_ID'].nunique())\ndata['Product_ID'].value_counts().plot(kind='hist')  # Only certain Product are contributing more","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss= data['Product_ID'].value_counts()[:10]\nss.plot(kind='bar')# Count wise product_id \nplt.xlabel(\"Product_id\")\nplt.ylabel(\"Count_of_Id\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby(['Product_ID'])['Purchase'].sum().plot(kind='hist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby(['Product_ID'])['Purchase'].sum().sort_values(ascending=False)[:10].plot(kind='bar')\nplt.xlabel(\"Product_id\")\nplt.ylabel(\"sum purchase in millions\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference:\n\n-Our focus is to increase the price of sales not interest in the count so we need to focus on specific product_id contributing more to the purchases.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Gender","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_Sex = data.groupby('Gender')['Gender'].count()\ndata_Sex = pd.DataFrame({'Sex':data_Sex.index, 'Count':data_Sex.values})\nplt.pie(data_Sex['Count'],labels = data_Sex['Sex'],autopct='%1.1f%%',shadow=True);\nplt.title('Gender Split in data');\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.groupby(['Gender'])['Purchase'].sum())\ndata_GP=data.groupby(['Gender'])['Purchase'].sum()\nplt.pie(data_GP,autopct='%1.1f%%',labels=['Female','Male'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['Gender'],hue=data[\"Age\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count of Male and Purchase sum is high  --- so we need to focus on them more","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Age","execution_count":null},{"metadata":{"id":"JMyopu1C4v6g","outputId":"ce4e0189-4b11-458c-e13f-c6de76492034","trusted":true},"cell_type":"code","source":"sns.countplot(data['Age'])\nplt.title(\"Age distribution\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_Age = data.groupby('Age')['Age'].count()\ndata_Age = pd.DataFrame({'Age':data_Age.index, 'Count':data_Age.values})\nplt.pie(data_Age['Count'],labels = data_Age['Age'],autopct='%1.1f%%',shadow=True);\nplt.title('Age split in data');\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('Age')['Purchase'].mean().plot()\nplt.xlabel('Age group')\nplt.ylabel('Average_Purchase amount in $')\nplt.title('Age group vs average amount spent')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### If you observe here the puchase in the age group of 51-55 is comparatively higher with only 7%","execution_count":null,"outputs":[]},{"metadata":{"id":"vDg-DXX6oKdb","outputId":"697e0519-4744-4f70-8471-d08c454e3146","trusted":true},"cell_type":"code","source":"sns.countplot(data['Age'],hue=data[\"Marital_Status\"])\n# 1 married and 0 unmarried","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['Age'],hue=data[\"Gender\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference:\n- 26-35 age group where they contribute around 40% and sum of their purchases are more even though they are small- (Unmarried)\n- While Unmarried are more in the contribution","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### City Category","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"City wise Contribution\", data['City_Category'].value_counts(normalize=True) *100)\nsns.countplot(data['City_Category'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('City_Category')['Purchase'].mean().plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference:\n- Even the number of count in the city b is more, purchase wise City C is contributing more.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Occupation                  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Occupation'].value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OS= data.groupby(['Occupation'])['Purchase'].mean()\nplt.plot(OS.index,OS.values,'ro-')\nplt.xticks(OS.index)\nplt.xlabel('Occupation types')\nplt.ylabel('Average purchase amount in $')\nplt.title('Average amount of purchase for each Occupation')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inference\n# Number of more counts in occuptation doesn't contribute more in the purchase amount\n# Mean value of purchase value for occuptation 8 & 15 is more compartievly to the number of counts(Heavy Spenders)\n# More effort on the less occupation (8&15) coulld generate more purchases\n# Occupation 11 to 18 looks like a target are to focus in terms of raising puchases\n# On other hand We can concentrate is there a possiblity of increasing the more count occupation to contribute to purchase","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[12,8])\nsns.countplot(data['Occupation'],hue=data[\"Age\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference\n- Occupation 4 which is of more count as more number of youngsters- We can focus on the product of their interest in relation to their occupation\n- Age group\"26-35\" are almost high in every categories as they contribute 40% of the total ages, yet the puchase amount is less if we can attract them we can surely increase the sales by 5-10%","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Stay_In_Current_City_Years","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Stay_In_Current_City_Years'].value_counts().plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1= data.groupby('Stay_In_Current_City_Years')['Purchase'].sum().reset_index()\ndata2= data['Stay_In_Current_City_Years'].value_counts()\ndata2=pd.DataFrame({\"Stay_In_Current_City_Years\":data2.index, \"Count\":data2.values})\nnw_data = pd.merge(data1,data2,left_on='Stay_In_Current_City_Years',right_on='Stay_In_Current_City_Years',how = 'left');\n\nnw_data = nw_data.sort_values(['Stay_In_Current_City_Years'],ascending=False)[0:10];\nnw_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    \nplt.figure(figsize=(16,6));\nplt.grid();\nplt.plot(nw_data['Stay_In_Current_City_Years'],nw_data['Purchase'],'o-');\nplt.xlabel('Stay_In_Current_City_Years');\nplt.ylabel('Total amount it was purchased in 10\\'s of Million $');\nplt.title('Stay wise connection with purchases');\nfor a,b,c in zip(nw_data['Stay_In_Current_City_Years'], nw_data['Purchase'], nw_data['Count']): \n    plt.text(a, b+100000, str(c))  \nplt.show();\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference\n- Here you can observe that the person staying 1 year are on the exploration state\n- As the stay increases the purchase amount decreases maybe they have got all the stuff needed are we need to understand there requirements","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Marital_Status","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby(['Gender','Marital_Status'])['Purchase'].count().plot(kind='pie',figsize=(8,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Count of martial_status\", data.groupby(['Marital_Status'])['Purchase'].count())\nprint(\"Average purchase amount\", data.groupby(['Gender','Marital_Status'])['Purchase'].mean())\ndata.groupby(['Marital_Status'])['Purchase'].mean().plot(kind='bar')\ndata.groupby(['Gender','Marital_Status'])['Purchase'].mean().unstack().plot(kind='bar')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference\n\n- Unmarried count is more with both Male and Female genders - Overall purchase amount is same\n- No special concentration required, show equal importance","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Product_Categories","execution_count":null},{"metadata":{"id":"UdjzlbIH6jBb","outputId":"b072c519-179a-4cab-84d1-c99ab7c17f73","trusted":true},"cell_type":"code","source":"data['Product_Category_1'].value_counts().plot(kind= 'bar', figsize=(16,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PC1= data.groupby('Product_Category_1')['Purchase'].mean()\nplt.figure(figsize=(12,8))\nplt.plot(PC1.index,PC1.values,'ro-')\nplt.xticks(PC1.index)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference:\n- Product_catergory_1 ranges from (1000-20000)\n- In product catergory 1 --> Count wise (5,1,8) contributes to the most, Purchase Amount wise(10,9,7,6) contribues more\n- It may its a costly item ","execution_count":null},{"metadata":{"id":"eDNuQVE569eX","outputId":"bf717ecb-6561-4764-8f9d-5e7d4c9ed39b","trusted":true},"cell_type":"code","source":"data['Product_Category_2'].value_counts().plot(kind= 'bar', figsize=(16,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PC2= data.groupby('Product_Category_2')['Purchase'].mean()\nplt.figure(figsize=(12,8))\nplt.plot(PC2.index,PC2.values,'ro-')\nplt.xticks(PC2.index)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference:\n- Product_catergory_2 ranges from (7000-16000)\n- In product_2 category \"10\" contributes the wide range of purchase amount","execution_count":null},{"metadata":{"id":"71z50N3xklLQ","outputId":"2e8b7d38-01c4-42aa-af6f-76b446c31f46","trusted":true},"cell_type":"code","source":"data['Product_Category_3'].value_counts().plot(kind= 'bar', figsize=(16,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PC3= data.groupby('Product_Category_3')['Purchase'].mean()\nplt.figure(figsize=(12,8))\nplt.plot(PC3.index,PC3.values,'ro-')\nplt.xticks(PC3.index)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference:\n- Product_catergory_3 ranges from (9000-14000)\n- Product_categor_3 have a diverese range of product with the least contribution on \"12\" check on that.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Purchases","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Purchase'].plot(kind='hist')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inference- \n- Purchase peak is arround 5000 and 10000 more in relation to the count","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"WFed1-o3_yz8"},"cell_type":"markdown","source":"As we can observe there is multicollinearity between product_Catory 1 ,2 and 3","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Preparing the data for the model","execution_count":null},{"metadata":{"id":"JxLoMJPG4YFG","trusted":true},"cell_type":"code","source":"# For the base level -- Creating a copy droping the null values\ndf= data.copy(deep=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"A-KFxKO137mX","outputId":"5ecd1bc2-6536-4058-d317-206e9c649582","trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Product_categories are int\n#df[['Product_Category_2','Product_Category_3']]=df[['Product_Category_2','Product_Category_3']].astype('int')\n# Stay_in_city\ndf['Stay_In_Current_City_Years'].replace({'4+':4},inplace=True)\n# df['Stay_In_Current_City_Years']=df['Stay_In_Current_City_Years'].astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gender\ndf['Gender'].replace({\"M\":1,\"F\":0},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Age\ndef map_age(age):\n    if age == '0-17':\n        return 0\n    elif age == '18-25':\n        return 1\n    elif age == '26-35':\n        return 2\n    elif age == '36-45':\n        return 3\n    elif age == '46-50':\n        return 4\n    elif age == '51-55':\n        return 5\n    else:\n        return 6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Age']=df['Age'].apply(map_age)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['Product_Category_2'].describe())\nprint(\"--------------------------------\")\nprint(df['Product_Category_3'].describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mean and Median are some _what close to each other\n# Hence filling the null values with the mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Product_Category_2']=df['Product_Category_2'].fillna(9.0).astype(int)\ndf['Product_Category_3']=df['Product_Category_3'].fillna(13.0).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['City_Category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mapping the City_Category \n\ndf['City_Category']=df['City_Category'].map({\"B\":1,\"A\":2,\"C\":3})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['City_Category']= df['City_Category'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Stay_In_Current_City_Years']= df['Stay_In_Current_City_Years'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Making a copy if these needs to included again\n\nddf=df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop([\"User_ID\",\"Product_ID\"],axis=1)\n# As it contains more number of unique values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modelling & Validating","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# X and Y split -- train_test_split\n\nfrom sklearn.model_selection import train_test_split\nX = df.drop(\"Purchase\",axis=1)\ny = df['Purchase']\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Base Model- Decision Tree\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtr= DecisionTreeRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtr.fit(X_train,y_train)\nd_predict= dtr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"RMSE score for Decision Tree : \", np.sqrt(mean_squared_error(y_test,d_predict)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Trying Other models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc=RandomForestRegressor(n_estimators=150)\ngbr=GradientBoostingRegressor()\nxg=XGBRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc.fit(X_train, y_train)\nr_predict= rfc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbr.fit(X_train,y_train)\ng_predict= gbr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg.fit(X_train, y_train)\nxg_predict= xg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Performance check","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"RMSE score for Random_Forest : \", np.sqrt(mean_squared_error(y_test,r_predict)))\nprint(\"RMSE score for Gradient Boosting : \", np.sqrt(mean_squared_error(y_test,g_predict)))\nprint(\"RMSE score for Gradient Boosting : \", np.sqrt(mean_squared_error(y_test,xg_predict)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's try feature selection to check if there is a improvement in the performance of the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Backward Elimination\ncols = list(X.columns)\npmax = 1\nwhile (len(cols)>0):\n    p= []\n    X_1 = X[cols]\n    X_1 = sm.add_constant(X_1)\n    model = sm.OLS(y,X_1).fit()\n    p = pd.Series(model.pvalues.values[1:],index = cols)      \n    pmax = max(p)\n    feature_with_p_max = p.idxmax()\n    if(pmax>0.04):\n        cols.remove(feature_with_p_max)\n    else:\n        break\nselected_features_BE = cols\nprint(selected_features_BE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Back_ward Elimination is predicting all as an important features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RFE method of feature selection","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc=RandomForestRegressor()\ngbr=GradientBoostingRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initializing RFE model\nrfe = RFE(rfc, 7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transforming data using RFE\nX_rfe = rfe.fit_transform(X,y)  \n#Fitting the data to model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfe.fit(X_rfe,y)\nprint(rfe.support_)\nprint(rfe.ranking_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X= df[['Gender', 'Age', 'Occupation', 'City_Category', 'Stay_In_Current_City_Years', 'Marital_Status', 'Product_Category_1']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc.fit(X_train, y_train)\nr_predict= rfc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"RMSE score for Random_Forest : \", np.sqrt(mean_squared_error(y_test,r_predict)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbr.fit(X_train,y_train)\ng_predict= gbr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"RMSE score for Gradient Boosting : \", np.sqrt(mean_squared_error(y_test,g_predict)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg.fit(X_train, y_train)\nxg_predict= xg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"RMSE score for XG Boosting : \", np.sqrt(mean_squared_error(y_test,xg_predict)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Performance level have been improvised with the RFE feature selection without including the product_catergory 2 & 3\n### But thats the worst thing to do and the best thing to do if you want only product category 1 to be compared","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Futher Analysis","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# We have removed the user_id and product_id entirely\n# Lets try to map the frequent used and products rather than eliminating all\n# Reference to other kaggle notebooks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mapping the User_ID based on the importance for the top 20 rather than excluding them totally\nuser_ids=ddf['User_ID']\ncounts=user_ids.value_counts().index[:19]\n# important_counts=set(counts.index[:19])\n# user_ids=user_ids.map(lambda user_id:user_id if user_id  in important_counts else 0)\n#from sklearn.preprocessing import OneHotEncoder\n#user_id_encoder=OneHotEncoder(categories ='auto')\n#user_id_encoder.fit(user_ids.values.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ddf['User_ID']=ddf['User_ID'].map(lambda user_id:user_id if user_id  in counts else 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"def user_id_transform(ddf):\n    uid=ddf['User_ID'].map(lambda user_id:user_id if user_id  in important_counts else 0).values.reshape(-1,1)\n    uid=user_id_encoder.transform(uid).toarray()\n    for index,category in enumerate(user_id_encoder.categories_[0]):\n        ddf[str(category)]= uid[:,index]\n    ddf.drop(columns=['User_ID'],inplace=True)\n    return ddf","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Product_ID\nproduct_means=ddf.groupby([\"Product_ID\"])[\"Purchase\"].mean()\ntotal_mean=ddf['Purchase'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"product_means.sort_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pid=product_means.sort_values(ascending=False).index[:19]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ddf['Product_ID']=ddf['Product_ID'].map(lambda product_id:product_id if product_id  in pid else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ddf['User_ID']=ddf['User_ID'].astype('object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nddf= pd.get_dummies(ddf,drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=nddf.drop(['Purchase'],1)\ny=nddf['Purchase']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.3,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc=RandomForestRegressor()\ngbr=GradientBoostingRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc.fit(X_train, y_train)\nr_predict= rfc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbr.fit(X_train,y_train)\ng_predict= gbr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trying XGboost for the many sparse matrix- tree algorithm don't perform the best\nfrom xgboost import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg=XGBRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg.fit(X_train, y_train)\nxg_predict= xg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Performance check","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"RMSE score for Random_Forest : \", np.sqrt(mean_squared_error(y_test,r_predict)))\nprint(\"RMSE score for Gradient Boosting : \", np.sqrt(mean_squared_error(y_test,g_predict)))\nprint(\"RMSE score for XG Boosting : \", np.sqrt(mean_squared_error(y_test,xg_predict)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Testing ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## From the normal way of labelling, feature selection and top_20 user_id and product_id\n## We got the best score with respect to validation from --> Normal Labeling the model without user_id and product_id rather than taking dummies on the top 20\n## Hence we use that particular set for training and predicting on the test_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Checking the test_data\ntest= pd.read_csv(\"/kaggle/input/black-friday/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\" Product _category_2 \\n \" ,test['Product_Category_2'].describe())\nprint(\" Product _category_3 \\n \" ,test['Product_Category_3'].describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Similary Meand and median are colse by.\n# taking a mid range to fill the null values\ntest['Product_Category_2']=test['Product_Category_2'].fillna(9.0).astype(int)\ntest['Product_Category_3']=test['Product_Category_3'].fillna(13.0).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stay_In_Current_City_Years\ntest['Stay_In_Current_City_Years']=test['Stay_In_Current_City_Years'].replace({'4+':4})\ntest['Stay_In_Current_City_Years']=test['Stay_In_Current_City_Years'].astype(int)\n# Age\ntest['Age']=test['Age'].apply(map_age)\n# Gender\ntest['Gender'].replace({\"M\":1,\"F\":0},inplace=True)\n# Mapping the City_Category \ntest['City_Category']=test['City_Category'].map({\"B\":1,\"A\":2,\"C\":3})\ntest['City_Category']=test['City_Category'].astype(int)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop(['User_ID','Product_ID'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choosing df --> Where USER_ID,PRODUCT_ID are dropped\nfrom sklearn.model_selection import train_test_split\nX = df.drop(\"Purchase\",axis=1)\ny = df['Purchase']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model that performed the best is XG_Boost\nxg.fit(X,y)\ntest_predict=xg.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['Purchase']=test_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Purchase distribution for the test data\", sns.distplot(test['Purchase']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Final prediction for the test data \\n \")\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- USer_ID and product_ID plays a important part in the domain but the performance of the model was better without them(seems confusing)\n- As a future scope we can analyse the bias and the varaince error of the model with respect to different CrossVallidation for choosing the model\n- Increase the number of USER_ID,Product_id give it a another shot\n- Perform hyper tuning of the model to improvise the performance of the XG_Boost and other models","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}