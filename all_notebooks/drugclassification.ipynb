{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Drug Classification\n### Zaquin - 27 Jun 2021","metadata":{}},{"cell_type":"markdown","source":"This analysis will build a classification model to prescribe patients with the correct pharmaceutical. The data set was retrieved from https://www.kaggle.com/pablomgomez21/drugs-a-b-c-x-y-for-decision-trees.","metadata":{}},{"cell_type":"markdown","source":"# Contents\n***\n<ol>\n    <li><a href=\"#Introduction\"> Introduction </a></li>\n    <li><a href=\"#Setup\"> Environment Setup </a></li>   \n    <li><a href=\"#ExploratoryDataAnalysis\"> Exploratory Data Analysis </a></li>\n    <ul style=\"list-style-type:circle;\">\n        <li><a href=\"#Plots\"> Exploratory Plots </a></li>\n        <li><a href=\"#CTabs\"> Cross-Tab Tables </a></li>\n        <li><a href=\"#Corr\"> Correlation Matrix </a></li></ul>\n    <li><a href=\"#Classification\"> Classification Models </a></li>\n    <ul style=\"list-style-type:circle;\">\n        <li><a href=\"#Logistic\"> Logistic Regression </a></li>\n        <li><a href=\"#KNN\"> K-Nearest Neighbors </a></li>\n        <li><a href=\"#NB\"> Naive-Bayes </a></li>\n        <li><a href=\"#Tree\"> Decision Tree </a></li></ul>\n    <li><a href=\"#Results\"> Results </a></li>\n    <li><a href=\"#REF\"> References </a></li>\n</ol>","metadata":{}},{"cell_type":"markdown","source":"# 1. Introduction <a id=\"Introduction\"></a>\n***\nAs technology advances, scientists are able to discover new pharmacetucals to help treat or cure diseases that previosuly were thought to be fatal. But with the rise in new treatments raises another challenge; which treatment is the best for the patient? Most drugs have side effects, or unintended reactions which could occur after taking the drug. These side effects, depending on the patient's health and medical history, could cause serious health concerns in the patient. The doctor needs to consider these factors when prescribing a drug to a patient, however doctors are people too, meaning they are subject to human error. In fact, according to a 2014 Harvard study, newly approved prescription medication has a 20% chance to cause serious side effects [1].\n\nThis analysis will explore various classification models in order to accurately prescribe patients with the correct pharmaceutical. Each model created will be analyzed for accuracy by using a confusion matrix. The types of classification models are as follows: \n\n1. Logistic Regression   \n2. K-Nearest Neighbors (KNN)   \n3. Naive-Bayes   \n4. Decision Tree   \n\nGaussian Naive-Bayes classification will be used to build the Naive-Bayes model. Each classification model's accuracy and confusion matrix will be compared, and the best performing model based on these criteria will be selected. \n\nExploratory data analysis will be performed prior to building the classification models. Various plots will be generated to understand the attribute distributions and relationships. Data cleaning and preprocessing will be performed as part of exploratory data analysis.","metadata":{}},{"cell_type":"markdown","source":"# 2. Environment Setup <a id=\"Setup\"></a>\n***","metadata":{}},{"cell_type":"code","source":"# Import modules\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport pydot\nimport graphviz\nfrom matplotlib import pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\n# Load data\ndrugdf = pd.read_csv(\"../input/drugs-a-b-c-x-y-for-decision-trees/drug200.csv\")\nalabs = drugdf.Drug.unique()\ndrugdf.tail()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:24.474634Z","iopub.execute_input":"2021-07-04T18:35:24.47525Z","iopub.status.idle":"2021-07-04T18:35:26.03472Z","shell.execute_reply.started":"2021-07-04T18:35:24.475159Z","shell.execute_reply":"2021-07-04T18:35:26.033588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Exploratory Data Analysis <a id=\"ExploratoryDataAnalysis\"></a>\n***","metadata":{}},{"cell_type":"code","source":"# Descriptive Statistics\ndrugdf.describe(include=\"all\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:26.036901Z","iopub.execute_input":"2021-07-04T18:35:26.037273Z","iopub.status.idle":"2021-07-04T18:35:26.08813Z","shell.execute_reply.started":"2021-07-04T18:35:26.037239Z","shell.execute_reply":"2021-07-04T18:35:26.087001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The range of the patient age is 15-74, with over half the patients being male. Over 1/3 of the patients have high blood pressure, and over half have high cholesterol. The sodium potassium ratio's average is below optimal, which is between 30-35. The sodium potassium ratio is an indicator of cardiovascular disease, and a low sodium potassium ratio can indicate chronic stress. Chronic stress causes increased cortisol production, which is a hormone responsible for cell and tissue decomposition. Low sodium potassium ratios could indicate catabolism, where the body breaks down tissues faster than it regenerates them [2]. It would be interesting to see how blood pressure and cholesterol affect the sodium potassium ratio, as high blood pressure and cholesterol are often associated with high stress levels. It seems that drugY has the highest prescription frequency of 91 (45.5%). ","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Exploratory Plots <a id=\"Plots\"></a>\n***","metadata":{}},{"cell_type":"code","source":"# Histograms\n# Age\n%matplotlib inline\nplt.hist(drugdf[\"Age\"], bins=15, alpha=0.85)\nplt.xlabel(\"Patient Age\")\nplt.ylabel(\"Count\")\nplt.title(\"Histogram of Patient Age\")\nplt.grid(True)\nplt.show()\n\n# Na_to_K\nplt.hist(drugdf[\"Na_to_K\"], bins=15, alpha=0.85)\nplt.xlabel(\"Patient Na:K Ratio\")\nplt.ylabel(\"Count\")\nplt.title(\"Histogram of Patient Na:K Ratio\")\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:26.089803Z","iopub.execute_input":"2021-07-04T18:35:26.090157Z","iopub.status.idle":"2021-07-04T18:35:26.530746Z","shell.execute_reply.started":"2021-07-04T18:35:26.090123Z","shell.execute_reply":"2021-07-04T18:35:26.529679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The age variable has a relatively uniform distribution, with a few spikes. The sodium potassium ratio distribution is positively skewed.","metadata":{}},{"cell_type":"code","source":"# Pie Charts\n# Sex\nfig1, ax1 = plt.subplots()\nax1.pie(drugdf[\"Sex\"].value_counts(), labels=drugdf[\"Sex\"].unique(), autopct=\"%1.1f%%\")\nax1.axis(\"equal\")\nax1.set_title(\"Patient Sex Breakdown\")\n\n# BP\nfig1, ax1 = plt.subplots()\nax1.pie(drugdf[\"BP\"].value_counts(), labels=drugdf[\"BP\"].unique(), autopct=\"%1.1f%%\")\nax1.axis(\"equal\")\nax1.set_title(\"Patient Blood Pressure Breakdown\")\n\n# Cholesterol\nfig1, ax1 = plt.subplots()\nax1.pie(drugdf[\"Cholesterol\"].value_counts(), labels=drugdf[\"Cholesterol\"].unique(), autopct=\"%1.1f%%\")\nax1.axis(\"equal\")\nax1.set_title(\"Patient Cholesterol Breakdown\")\n\n# Drug\nfig1, ax1 = plt.subplots()\nax1.pie(drugdf[\"Drug\"].value_counts(), labels=drugdf[\"Drug\"].unique(), autopct=\"%1.1f%%\")\nax1.axis(\"equal\")\nax1.set_title(\"Drug Perscription Rate\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:26.532022Z","iopub.execute_input":"2021-07-04T18:35:26.532423Z","iopub.status.idle":"2021-07-04T18:35:26.954383Z","shell.execute_reply.started":"2021-07-04T18:35:26.532381Z","shell.execute_reply":"2021-07-04T18:35:26.953534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The patients are roughly evenly split between male and female, with a slight female majority. Over 2/3 of the patients have abnormal blood pressure and nearly 40% of the patients have high blood pressure. Over half of the patients have high cholesterol as well. DrugY is the most commonly prescribed to the patients.","metadata":{}},{"cell_type":"markdown","source":"## 3.2 Cross-Tab Tables <a id=\"CTabs\"></a>\n***\nCross tabulation tables (cross-tab tables) provide another method to uncover relationships in the data set. ","metadata":{}},{"cell_type":"markdown","source":"### Average Age by Drug and Sex","metadata":{}},{"cell_type":"code","source":"# Avg Age\ndsa = pd.crosstab(drugdf.Drug, drugdf.Sex, values=drugdf.Age, aggfunc=\"mean\")\ndsa","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:26.956892Z","iopub.execute_input":"2021-07-04T18:35:26.95733Z","iopub.status.idle":"2021-07-04T18:35:26.989102Z","shell.execute_reply.started":"2021-07-04T18:35:26.957298Z","shell.execute_reply":"2021-07-04T18:35:26.987983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The table above shows an interesting realationship between the age and the prescribed drug. It would appear that drugA is prescribed to younger patients on average. DrugC, X, and Y are prescribed to middle-aged patients, and drugB is prescribed to more senior patients, on average. It would be interesting to see what other medication the patients are prescribed, as medications can interact and cause serious side effects. It's quite possible that drugB is assigned to pateints taking another type of drug to avoid said serious side effects. ","metadata":{}},{"cell_type":"markdown","source":"### Average Sodium Potassium Ratio by Drug and Sex","metadata":{}},{"cell_type":"code","source":"# Avg NaK\ndsnak = pd.crosstab(drugdf.Drug, drugdf.Sex, values=drugdf.Na_to_K, aggfunc=\"mean\")\ndsnak","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:26.991579Z","iopub.execute_input":"2021-07-04T18:35:26.991899Z","iopub.status.idle":"2021-07-04T18:35:27.020661Z","shell.execute_reply.started":"2021-07-04T18:35:26.99187Z","shell.execute_reply":"2021-07-04T18:35:27.019436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"DrugY, on average, is precribed to patients with a higher sodium potassium ratio. The patients prescibed to drugY have an average sodium potassium ratio closest to the nominal range, while the patients prescribed to the other drugs have a much lower average ratio.","metadata":{}},{"cell_type":"markdown","source":"## 3.3 Correlation Matrix <a id=\"Corr\"></a>\n***\nPrior to creating the correlation matrix, the categorical variables must be converted to numeric. This will serve as the preprocessing for the classification models as well.","metadata":{}},{"cell_type":"code","source":"# Create preprocessed df\nle = LabelEncoder()\ndrug_pp = drugdf\ndrug_pp[\"Sex\"] = le.fit_transform(drug_pp[\"Sex\"])\ndrug_pp[\"BP\"] = le.fit_transform(drug_pp[\"BP\"])\ndrug_pp[\"Cholesterol\"] = le.fit_transform(drug_pp[\"Cholesterol\"])\ndrug_pp[\"Drug\"] = le.fit_transform(drug_pp[\"Drug\"])\ndrug_pp.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:27.022176Z","iopub.execute_input":"2021-07-04T18:35:27.02248Z","iopub.status.idle":"2021-07-04T18:35:27.040288Z","shell.execute_reply.started":"2021-07-04T18:35:27.022452Z","shell.execute_reply":"2021-07-04T18:35:27.039157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create and display corr matrix\n%matplotlib inline\ncor_mat = drug_pp.corr()\nsns.heatmap(cor_mat, annot=True)\nplt.title(\"Correlation Matrix\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:27.042389Z","iopub.execute_input":"2021-07-04T18:35:27.042851Z","iopub.status.idle":"2021-07-04T18:35:27.465547Z","shell.execute_reply.started":"2021-07-04T18:35:27.042794Z","shell.execute_reply":"2021-07-04T18:35:27.464696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The correlation matrix shows that the sodium potassium ratio and blood pressure have the strongest impact on the prescribed drug.","metadata":{}},{"cell_type":"markdown","source":"# 4. Classification Models <a id=\"Classification\"></a>\n***\nThe data will be split into a training and test set using scikit-learn's train_test_split function. The training and test sets will be used to build each model in this analysis. ","metadata":{}},{"cell_type":"code","source":"# Separate target\nx = drug_pp.iloc[:, :-1].values\ny = drug_pp.iloc[:, -1].values\n\n# Create test and train sets\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:27.466821Z","iopub.execute_input":"2021-07-04T18:35:27.467115Z","iopub.status.idle":"2021-07-04T18:35:27.474949Z","shell.execute_reply.started":"2021-07-04T18:35:27.467086Z","shell.execute_reply":"2021-07-04T18:35:27.473882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.1 Logisitic Regression <a id=\"Logistic\"></a>\n***","metadata":{}},{"cell_type":"code","source":"# Create model\nlgr = LogisticRegression(random_state=0, max_iter=2000).fit(x_train, y_train)\n\n# Predict with test set\nlgr_pred = lgr.predict(x_test)\nprint(\"Accuracy Score = {}%\".format(round(accuracy_score(y_test, lgr_pred)*100,2)))","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:27.476372Z","iopub.execute_input":"2021-07-04T18:35:27.476754Z","iopub.status.idle":"2021-07-04T18:35:28.191663Z","shell.execute_reply.started":"2021-07-04T18:35:27.476724Z","shell.execute_reply":"2021-07-04T18:35:28.190528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\n%matplotlib inline\ncmat = confusion_matrix(y_test, lgr_pred)\nfig, ax = plt.subplots()\nsns.heatmap(cmat, annot=True, cmap=\"BuPu\")\nax.set_xticklabels(alabs)\nax.set_yticklabels(alabs)\nplt.title(\"Logistic Regression Confusion Matrix\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:28.193509Z","iopub.execute_input":"2021-07-04T18:35:28.193902Z","iopub.status.idle":"2021-07-04T18:35:28.512867Z","shell.execute_reply.started":"2021-07-04T18:35:28.193869Z","shell.execute_reply":"2021-07-04T18:35:28.512132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print classification report\nprint(\"Classification Report:\"+\"\\n\",classification_report(y_test, lgr_pred), sep=\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:28.513965Z","iopub.execute_input":"2021-07-04T18:35:28.51439Z","iopub.status.idle":"2021-07-04T18:35:28.524597Z","shell.execute_reply.started":"2021-07-04T18:35:28.514359Z","shell.execute_reply":"2021-07-04T18:35:28.523713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The logisitic regression model performed very well overall, with an accruacy score of 95%. The logisitc regression model miscategorized 2 instances of drugC as drugX. This is shown in the classification report. The precision for row 1 (drugC) is 50%, while the recall for row 2 (durgX) is also 50%, indicating that the model miscategorized 2 instaces of drugX as drugC.","metadata":{}},{"cell_type":"markdown","source":"## 4.2 K-Nearest Neighbors <a id=\"KNN\"></a>\n***\n10-fold cross validation will be performed to determine the optimal value for K. To perform the cross validation, models will be generated with K=1 to K=50. 10-fold cross validation will be performed for each model, and the average accuracy score of all 10 folds will be recorded. The average misclassification error (1 - accuracy) will be plotted vs the K values. The K value(s) with the lowest misclassification error will be created, and the model with the highest accuracy will be selected as the KNN model.","metadata":{}},{"cell_type":"code","source":"# Create list to store scores\ncv_scores = []\nks = list(range(1,51,1))\n\n# Perform CV\nfor k in ks:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    cscore = cross_val_score(knn, x_train, y_train, cv=10, scoring='accuracy')\n    cv_scores.append(cscore.mean())\n\n# changing to misclassification error\nMSE = [1 - x for x in cv_scores]\n\nplt.figure()\nplt.figure(figsize=(15,10))\nplt.title(\"Optimal number of neighbors\", fontsize=20, fontweight='bold')\nplt.xlabel(\"K\", fontsize=15)\nplt.ylabel(\"Misclassification Error\", fontsize=15)\nplt.plot(ks, MSE)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:28.525804Z","iopub.execute_input":"2021-07-04T18:35:28.526151Z","iopub.status.idle":"2021-07-04T18:35:30.401943Z","shell.execute_reply.started":"2021-07-04T18:35:28.526112Z","shell.execute_reply":"2021-07-04T18:35:30.401087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on the cross validation results, K = 3 and K = 4 yield the lowest average misclassification error. A model with 3 and 4 neighbors will be generated, with the model with the highest accuracy being selected as the KNN model.","metadata":{}},{"cell_type":"markdown","source":"### KNN with K = 3\n***","metadata":{}},{"cell_type":"code","source":"# KNN (K=3)\n# Create model\nknn_3 = KNeighborsClassifier(n_neighbors=3).fit(x_train, y_train)\n\n# Predict with test set\nknn_3_pred = knn_3.predict(x_test)\nprint(\"Accuracy Score = {}%\".format(round(accuracy_score(y_test, knn_3_pred)*100,2)))","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:30.40303Z","iopub.execute_input":"2021-07-04T18:35:30.403447Z","iopub.status.idle":"2021-07-04T18:35:30.41433Z","shell.execute_reply.started":"2021-07-04T18:35:30.403415Z","shell.execute_reply":"2021-07-04T18:35:30.413018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\n%matplotlib inline\ncmat = confusion_matrix(y_test, knn_3_pred)\nfig, ax = plt.subplots()\nsns.heatmap(cmat, annot=True, cmap=\"BuPu\")\nax.set_xticklabels(alabs)\nax.set_yticklabels(alabs)\nplt.title(\"KNN (K=3) Confusion Matrix\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:30.415945Z","iopub.execute_input":"2021-07-04T18:35:30.41647Z","iopub.status.idle":"2021-07-04T18:35:30.727752Z","shell.execute_reply.started":"2021-07-04T18:35:30.416433Z","shell.execute_reply":"2021-07-04T18:35:30.726702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print classification report\nprint(\"Classification Report:\"+\"\\n\",classification_report(y_test, knn_3_pred), sep=\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:30.729126Z","iopub.execute_input":"2021-07-04T18:35:30.729415Z","iopub.status.idle":"2021-07-04T18:35:30.741353Z","shell.execute_reply.started":"2021-07-04T18:35:30.729387Z","shell.execute_reply":"2021-07-04T18:35:30.740132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### KNN with K = 4\n***","metadata":{}},{"cell_type":"code","source":"# KNN (K=4)\n# Create model\nknn_4 = KNeighborsClassifier(n_neighbors=4).fit(x_train, y_train)\n\n# Predict with test set\nknn_4_pred = knn_4.predict(x_test)\nprint(\"Accuracy Score = {}%\".format(round(accuracy_score(y_test, knn_4_pred)*100,2)))","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:30.74261Z","iopub.execute_input":"2021-07-04T18:35:30.742923Z","iopub.status.idle":"2021-07-04T18:35:30.75769Z","shell.execute_reply.started":"2021-07-04T18:35:30.742893Z","shell.execute_reply":"2021-07-04T18:35:30.756407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\n%matplotlib inline\ncmat = confusion_matrix(y_test, knn_4_pred)\nfig, ax = plt.subplots()\nsns.heatmap(cmat, annot=True, cmap=\"BuPu\")\nax.set_xticklabels(alabs)\nax.set_yticklabels(alabs)\nplt.title(\"KNN (K=4) Confusion Matrix\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:30.760954Z","iopub.execute_input":"2021-07-04T18:35:30.761437Z","iopub.status.idle":"2021-07-04T18:35:31.088076Z","shell.execute_reply.started":"2021-07-04T18:35:30.761386Z","shell.execute_reply":"2021-07-04T18:35:31.086544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print classification report\nprint(\"Classification Report:\"+\"\\n\",classification_report(y_test, knn_4_pred), sep=\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:31.089736Z","iopub.execute_input":"2021-07-04T18:35:31.0901Z","iopub.status.idle":"2021-07-04T18:35:31.105095Z","shell.execute_reply.started":"2021-07-04T18:35:31.090051Z","shell.execute_reply":"2021-07-04T18:35:31.10429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The KNN model, with K=3, had a higher accuracy score than the K=4 model, thus the selected KNN model is the model with K=3. The K=3 model is not the best. The accuracy score is only 67.5%. DrugX was not correctly categorized in either KNN model, and DrugA had the most incorrect classifications in both models. ","metadata":{}},{"cell_type":"markdown","source":"## 4.3 Naive-Bayes <a id=\"NB\"></a>\n***","metadata":{}},{"cell_type":"code","source":"# Create model\ngnb = GaussianNB().fit(x_train, y_train)\n\n# Predict with test set\ngnb_pred = gnb.predict(x_test)\nprint(\"Accuracy Score = {}%\".format(round(accuracy_score(y_test, gnb_pred)*100,2)))","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:31.106156Z","iopub.execute_input":"2021-07-04T18:35:31.106584Z","iopub.status.idle":"2021-07-04T18:35:31.115594Z","shell.execute_reply.started":"2021-07-04T18:35:31.106553Z","shell.execute_reply":"2021-07-04T18:35:31.114774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\n%matplotlib inline\ncmat = confusion_matrix(y_test, gnb_pred)\nfig, ax = plt.subplots()\nsns.heatmap(cmat, annot=True, cmap=\"BuPu\")\nax.set_xticklabels(alabs)\nax.set_yticklabels(alabs)\nplt.title(\"Naive-Bayes Confusion Matrix\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:31.116666Z","iopub.execute_input":"2021-07-04T18:35:31.117129Z","iopub.status.idle":"2021-07-04T18:35:31.475972Z","shell.execute_reply.started":"2021-07-04T18:35:31.117088Z","shell.execute_reply":"2021-07-04T18:35:31.474883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print classification report\nprint(\"Classification Report:\"+\"\\n\",classification_report(y_test, gnb_pred), sep=\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:31.477461Z","iopub.execute_input":"2021-07-04T18:35:31.478052Z","iopub.status.idle":"2021-07-04T18:35:31.489857Z","shell.execute_reply.started":"2021-07-04T18:35:31.478003Z","shell.execute_reply":"2021-07-04T18:35:31.488579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Naive-Bayes classification model had some issues classifying drugB. The accuracy of the model is 87.5%.","metadata":{}},{"cell_type":"markdown","source":"## 4.4 Decision Tree <a id=\"Tree\"></a>\n***","metadata":{}},{"cell_type":"code","source":"# Create model\ndtree = DecisionTreeClassifier().fit(x_train, y_train)\n\n# Predict with test set\ndtree_pred = dtree.predict(x_test)\nprint(\"Accuracy Score = {}%\".format(round(accuracy_score(y_test, dtree_pred)*100,2)))","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:31.491718Z","iopub.execute_input":"2021-07-04T18:35:31.492173Z","iopub.status.idle":"2021-07-04T18:35:31.504868Z","shell.execute_reply.started":"2021-07-04T18:35:31.492127Z","shell.execute_reply":"2021-07-04T18:35:31.503787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\n%matplotlib inline\ncmat = confusion_matrix(y_test, dtree_pred)\nfig, ax = plt.subplots()\nsns.heatmap(cmat, annot=True, cmap=\"BuPu\")\nax.set_xticklabels(alabs)\nax.set_yticklabels(alabs)\nplt.title(\"Decision Tree Confusion Matrix\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:31.506384Z","iopub.execute_input":"2021-07-04T18:35:31.506707Z","iopub.status.idle":"2021-07-04T18:35:31.88359Z","shell.execute_reply.started":"2021-07-04T18:35:31.506676Z","shell.execute_reply":"2021-07-04T18:35:31.882492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print classification report\nprint(\"Classification Report:\"+\"\\n\",classification_report(y_test, dtree_pred), sep=\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:31.884971Z","iopub.execute_input":"2021-07-04T18:35:31.885304Z","iopub.status.idle":"2021-07-04T18:35:31.899147Z","shell.execute_reply.started":"2021-07-04T18:35:31.885274Z","shell.execute_reply":"2021-07-04T18:35:31.898034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The decision tree model was able to 100% correctly classify the test set. Below is a visualization of the decision tree.","metadata":{}},{"cell_type":"code","source":"# Export decision tree to file\nexport_graphviz(dtree, out_file=\"decis_tree.dot\", feature_names=drugdf.columns[:-1], class_names=alabs)\n\n# Create png of decision tree\n(graph,) = pydot.graph_from_dot_file(\"decis_tree.dot\")\ngraph.write_png(\"DecisTree.png\")\n\n# Show decision tree\nwith open(\"decis_tree.dot\") as f:\n    dot_graph = f.read()\ngraphviz.Source(dot_graph)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:35:31.900675Z","iopub.execute_input":"2021-07-04T18:35:31.901052Z","iopub.status.idle":"2021-07-04T18:35:32.678577Z","shell.execute_reply.started":"2021-07-04T18:35:31.901019Z","shell.execute_reply":"2021-07-04T18:35:32.677316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Results <a id=\"Results\"></a>\n***\n\nComparing each of the models, the decision tree was the best performing classifier, with an accuracy of 100%. Logisitc regression was a close second with an accuracy of 95% percent. The KNN model and the logisitc regression model had misclassification errors when classifying drugX. This might be due to the fact that patients prescirbed to drugX had a very similar average sodium potassium ratio and age compared to other patients prescribed to drugC. The Naive-Bayes model struggled to classify drugB, which could be due to the fact that the patients prescribed to drugs A, B, C, and X all had similar average sodium potassium ratios.\n\nIt would be interesting to get additional data about the patients and the drugs themselves. As stated previously, drugs can interact with each other and cause serious side effects. Other medications the patients are taking could drastically affect the model results. Also, the medical history of the patients, such as cardiovascualr issues, cancer diagnoses, and kidney or liver problems, will affect physician's decisions on which medication to prescribe to their patients. This additional information could help fine tune the models to ensure patient safety. Information about the side effects of each drug will also help to fine tune the models. ","metadata":{}},{"cell_type":"markdown","source":"# 6. References <a id=\"REF\"></a>\n***\n\n[1] \tW. L. Donald, \"New Prescription Drugs: A Major Health Risk With Few Offsetting Advantages,\" 27 June 2014. [Online]. Available: https://ethics.harvard.edu/blog/new-prescription-drugs-major-health-risk-few-offsetting-advantages. [Accessed 27 June 2021].      \n[2] \tD. Weatherby, \"Know Your Biomarkers: Sodium Potassium Ratio,\" OptimalDX, 20 may 2019. [Online]. Available: https://www.optimaldx.com/blog/sodium-potassium-ratio/. [Accessed 27 June 2021].\n\n","metadata":{}}]}