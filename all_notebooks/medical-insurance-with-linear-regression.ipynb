{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-27T17:10:19.854654Z","iopub.execute_input":"2021-06-27T17:10:19.855023Z","iopub.status.idle":"2021-06-27T17:10:20.932371Z","shell.execute_reply.started":"2021-06-27T17:10:19.854944Z","shell.execute_reply":"2021-06-27T17:10:20.93144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reading the data","metadata":{}},{"cell_type":"code","source":"df_insurance = pd.read_csv('../input/insurance/insurance.csv')\ndf_insurance.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:20.934321Z","iopub.execute_input":"2021-06-27T17:10:20.934714Z","iopub.status.idle":"2021-06-27T17:10:20.990712Z","shell.execute_reply.started":"2021-06-27T17:10:20.934677Z","shell.execute_reply":"2021-06-27T17:10:20.989657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_insurance.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:20.991691Z","iopub.execute_input":"2021-06-27T17:10:20.99197Z","iopub.status.idle":"2021-06-27T17:10:20.998213Z","shell.execute_reply.started":"2021-06-27T17:10:20.991943Z","shell.execute_reply":"2021-06-27T17:10:20.99729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_insurance.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:20.999385Z","iopub.execute_input":"2021-06-27T17:10:20.999784Z","iopub.status.idle":"2021-06-27T17:10:21.035577Z","shell.execute_reply.started":"2021-06-27T17:10:20.999757Z","shell.execute_reply":"2021-06-27T17:10:21.034651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_insurance.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:21.038194Z","iopub.execute_input":"2021-06-27T17:10:21.038433Z","iopub.status.idle":"2021-06-27T17:10:21.057242Z","shell.execute_reply.started":"2021-06-27T17:10:21.038412Z","shell.execute_reply":"2021-06-27T17:10:21.056116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## looking for the missing value in dataset","metadata":{}},{"cell_type":"code","source":"# check for null values in dataset\ndf_insurance.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:21.060399Z","iopub.execute_input":"2021-06-27T17:10:21.060709Z","iopub.status.idle":"2021-06-27T17:10:21.076821Z","shell.execute_reply.started":"2021-06-27T17:10:21.060681Z","shell.execute_reply":"2021-06-27T17:10:21.076122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for dupliacte row in dataset\ndf_insurance.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:21.078443Z","iopub.execute_input":"2021-06-27T17:10:21.078819Z","iopub.status.idle":"2021-06-27T17:10:21.095779Z","shell.execute_reply.started":"2021-06-27T17:10:21.078791Z","shell.execute_reply":"2021-06-27T17:10:21.094655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation:\n 1. no missing values in data \n 2. In the given dataset there is 1 duplicate row which we need to treat before procceding ahead","metadata":{}},{"cell_type":"code","source":"# treating duplictaes value of dataset\ndf_insurance.drop_duplicates(inplace = True)\ndf_insurance.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:21.097137Z","iopub.execute_input":"2021-06-27T17:10:21.09743Z","iopub.status.idle":"2021-06-27T17:10:21.112771Z","shell.execute_reply.started":"2021-06-27T17:10:21.097399Z","shell.execute_reply":"2021-06-27T17:10:21.110969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking for outliers","metadata":{}},{"cell_type":"code","source":"# We found via data that having numeric column has not differ values\n# To get the better understanding we can impute these columns\ncol = list(df_insurance.columns)\nfor i in col:\n    if df_insurance[i].value_counts().shape[0] < 10:\n        df_insurance[i] = df_insurance[i].astype(str)\ndf_insurance.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:21.116301Z","iopub.execute_input":"2021-06-27T17:10:21.116615Z","iopub.status.idle":"2021-06-27T17:10:21.137423Z","shell.execute_reply.started":"2021-06-27T17:10:21.116588Z","shell.execute_reply":"2021-06-27T17:10:21.136223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Univariate analysis of the dataset","metadata":{}},{"cell_type":"code","source":"# columns in dataset\n# columns in dataset\n# Univariate categorical analysis\n# check for the cols having categorical type\nnum_col = list(df_insurance._get_numeric_data().columns)\ncat_col = list(set(col)- set(num_col))\ncat_col","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:21.139174Z","iopub.execute_input":"2021-06-27T17:10:21.139541Z","iopub.status.idle":"2021-06-27T17:10:21.146983Z","shell.execute_reply.started":"2021-06-27T17:10:21.139512Z","shell.execute_reply":"2021-06-27T17:10:21.145861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a func to plot graphs for univariate categorical analysis\ndef plot_cat(df,catColumns):\n    fig,axes = plt.subplots(2,2, figsize = (24,12), sharey = True)\n    plt.suptitle('Univariate Categorical Analysis',color ='brown',fontsize = 20,fontweight='bold')\n    index = 0\n    for i in range(2):\n        for j in range(2):\n            ax= sns.boxplot(data = df , x = catColumns[index],y = 'charges',ax = axes[i][j])\n            ax.title.set_text(f'Graph for {catColumns[index]}')\n            index = index+1\nplot_cat(df_insurance, cat_col)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:21.148108Z","iopub.execute_input":"2021-06-27T17:10:21.148363Z","iopub.status.idle":"2021-06-27T17:10:21.888841Z","shell.execute_reply.started":"2021-06-27T17:10:21.148339Z","shell.execute_reply":"2021-06-27T17:10:21.887721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observations:\n1. We can clearly see prices are very high for smokers","metadata":{}},{"cell_type":"code","source":"# create a func to plot graphs for univariate numeric analysis\nsns.pairplot(df_insurance)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:21.890146Z","iopub.execute_input":"2021-06-27T17:10:21.890421Z","iopub.status.idle":"2021-06-27T17:10:23.770871Z","shell.execute_reply.started":"2021-06-27T17:10:21.890393Z","shell.execute_reply":"2021-06-27T17:10:23.76989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observation\n1. We can see bmi has some sort of linear relationship with charges","metadata":{}},{"cell_type":"markdown","source":"#### Data preperation for regression\n","metadata":{}},{"cell_type":"code","source":"#For categorical columns\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor colName in ['sex','smoker']:\n    le.fit(df_insurance[colName].drop_duplicates())\n    df_insurance[colName] = le.transform(df_insurance[colName])\n# for region field\nregions = pd.get_dummies(df_insurance['region'])\ndf_insurance = pd.concat([df_insurance,regions],axis = 1 )\ndf_insurance.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:23.77211Z","iopub.execute_input":"2021-06-27T17:10:23.772384Z","iopub.status.idle":"2021-06-27T17:10:24.132127Z","shell.execute_reply.started":"2021-06-27T17:10:23.772355Z","shell.execute_reply":"2021-06-27T17:10:24.131247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets drop extra col\ndf_insurance.drop(columns = ['region','northeast'], axis = 1, inplace = True)\ndf_insurance .head()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:24.133587Z","iopub.execute_input":"2021-06-27T17:10:24.13394Z","iopub.status.idle":"2021-06-27T17:10:24.150956Z","shell.execute_reply.started":"2021-06-27T17:10:24.133902Z","shell.execute_reply":"2021-06-27T17:10:24.150104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Check for correlation","metadata":{}},{"cell_type":"code","source":"sns.heatmap(df_insurance.corr(),annot = True , cmap = 'Greens')\ncorr_df = df_insurance.corr()\ncorr_df = corr_df.where(np.triu(np.ones(corr_df.shape), k =1).astype(np.bool)).unstack().reset_index()\ncorr_df = corr_df.sort_values(by = 0 ,ascending = False)\ncorr_df = corr_df[corr_df['level_0'] == 'charges']\ncorr_df.dropna(inplace = True)\ncorr_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:24.152343Z","iopub.execute_input":"2021-06-27T17:10:24.15274Z","iopub.status.idle":"2021-06-27T17:10:24.6636Z","shell.execute_reply.started":"2021-06-27T17:10:24.152704Z","shell.execute_reply":"2021-06-27T17:10:24.662424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"clearly we can see the highest correlation is smoking followed by age and bmi","metadata":{}},{"cell_type":"markdown","source":"#### SPLIT Data into TEST and TRAIN data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndf_train ,df_test = train_test_split(df_insurance,test_size = .70,random_state = 100)\nprint(df_train.shape)\nprint(df_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:24.664762Z","iopub.execute_input":"2021-06-27T17:10:24.665032Z","iopub.status.idle":"2021-06-27T17:10:24.751684Z","shell.execute_reply.started":"2021-06-27T17:10:24.665006Z","shell.execute_reply":"2021-06-27T17:10:24.749809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### scalling of the data\n1. Standardisation : normalize data to have mean and standard deviation 0 and 1 respectively\n2. MinMax : normalize value between 0 to 1\n#### preffered MInMax as it will make the dataset independent of outliers","metadata":{}},{"cell_type":"code","source":"# Check for variables scaling\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndf_train[['age','bmi']]=scaler.fit_transform(df_train[['age','bmi']])\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:24.753178Z","iopub.execute_input":"2021-06-27T17:10:24.753535Z","iopub.status.idle":"2021-06-27T17:10:24.777192Z","shell.execute_reply.started":"2021-06-27T17:10:24.753468Z","shell.execute_reply":"2021-06-27T17:10:24.775912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### let's start model building via train data","metadata":{}},{"cell_type":"code","source":"y_train = df_train.pop('charges')\nX_train = df_train\nX_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:24.77853Z","iopub.execute_input":"2021-06-27T17:10:24.778837Z","iopub.status.idle":"2021-06-27T17:10:24.80105Z","shell.execute_reply.started":"2021-06-27T17:10:24.778808Z","shell.execute_reply":"2021-06-27T17:10:24.799698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add a constant\nimport statsmodels.api as sm\nX_train_sm = sm.add_constant(X_train)\nX_train_sm.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:24.802347Z","iopub.execute_input":"2021-06-27T17:10:24.802582Z","iopub.status.idle":"2021-06-27T17:10:25.700388Z","shell.execute_reply.started":"2021-06-27T17:10:24.802558Z","shell.execute_reply":"2021-06-27T17:10:25.699491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a model\nlr = sm.OLS(y_train,X_train_sm.astype(float))\nlr_model = lr.fit()\nprint(lr_model.params)\nprint(lr_model.summary())\np_values = pd.DataFrame()\np_values['Features'] = X_train_sm.columns\np_values['Pvalue'] = [round(lr_model.pvalues[i],2) for i in X_train_sm.columns]","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:25.701312Z","iopub.execute_input":"2021-06-27T17:10:25.701557Z","iopub.status.idle":"2021-06-27T17:10:25.734874Z","shell.execute_reply.started":"2021-06-27T17:10:25.701521Z","shell.execute_reply":"2021-06-27T17:10:25.733971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### find the inverse variance Factor","metadata":{}},{"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\ndef vif_func(X_train_sm):\n    vif = pd.DataFrame()\n    vif['Features'] = X_train_sm.columns\n    vif['VIF'] = [variance_inflation_factor(X_train_sm.astype(float).values,i) for i in range(X_train_sm.astype(float).shape[1])]\n    vif['VIF'] = round(vif['VIF'],2)\n    vif = vif.sort_values(by = 'VIF',ascending = False)\n    return vif\n#call vif function\nvif = vif_func(X_train_sm)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:25.73793Z","iopub.execute_input":"2021-06-27T17:10:25.738162Z","iopub.status.idle":"2021-06-27T17:10:25.760227Z","shell.execute_reply.started":"2021-06-27T17:10:25.738138Z","shell.execute_reply":"2021-06-27T17:10:25.759076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# concat p_value and VIF dataframe\np_vif_df = pd.DataFrame()\np_vif_df = vif.merge(p_values , how = 'inner')\n# drop for constance variable\np_vif_df.drop(index = 0, axis = 0)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:25.762703Z","iopub.execute_input":"2021-06-27T17:10:25.763017Z","iopub.status.idle":"2021-06-27T17:10:25.783544Z","shell.execute_reply.started":"2021-06-27T17:10:25.762984Z","shell.execute_reply":"2021-06-27T17:10:25.782739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### now we need to follow reverse method approch to find best fit model\n1. If V factor and p value is above 0.5 drop that column\n2. If Vfactor and P value same than irst drop column having high P value than see whether its affecting V factor","metadata":{}},{"cell_type":"code","source":"# function to improvise model\ncol_name = []\ndef model_improvise(p_vif_df,y_train,X_train_sm):\n    # check for highest p value as data is already soted accross Pvalue\n    for i in range(p_vif_df.shape[0]):\n        if p_vif_df.loc[i,'Pvalue'] > 0.05:\n            col_name.append(p_vif_df.loc[i,'Features'])\n    X_train_sm.drop(columns = col_name,axis = 1 , inplace = True)\nmodel_improvise(p_vif_df,y_train,X_train_sm)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:25.784434Z","iopub.execute_input":"2021-06-27T17:10:25.784764Z","iopub.status.idle":"2021-06-27T17:10:25.796438Z","shell.execute_reply.started":"2021-06-27T17:10:25.784731Z","shell.execute_reply":"2021-06-27T17:10:25.795884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### check again VF","metadata":{}},{"cell_type":"code","source":"#call vif function\nvif_func(X_train_sm)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:25.797504Z","iopub.execute_input":"2021-06-27T17:10:25.797992Z","iopub.status.idle":"2021-06-27T17:10:25.819333Z","shell.execute_reply.started":"2021-06-27T17:10:25.79796Z","shell.execute_reply":"2021-06-27T17:10:25.818609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Observations:\n1. Models looks good with low VIF and P value less than .5","metadata":{}},{"cell_type":"code","source":"# build a linear model with left columns\nlr = sm.OLS(y_train,X_train_sm.astype(float))\nlr_model = lr.fit()\nlr_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:25.820457Z","iopub.execute_input":"2021-06-27T17:10:25.820915Z","iopub.status.idle":"2021-06-27T17:10:25.840845Z","shell.execute_reply.started":"2021-06-27T17:10:25.820883Z","shell.execute_reply":"2021-06-27T17:10:25.839471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Observation:\nModel looks significant with P value less than .5 and R square .74 ","metadata":{}},{"cell_type":"code","source":"y_train_pred = lr_model.predict(X_train_sm.astype(float))\n# calculating residual\nres_train = y_train - y_train_pred\n# plot distribution of residual\nsns.distplot(res_train)\n# lets check efficency of model of train sample\nfrom sklearn.metrics import r2_score\nr2_score(y_true = y_train,y_pred = y_train_pred )","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:25.842213Z","iopub.execute_input":"2021-06-27T17:10:25.842561Z","iopub.status.idle":"2021-06-27T17:10:26.100006Z","shell.execute_reply.started":"2021-06-27T17:10:25.842529Z","shell.execute_reply":"2021-06-27T17:10:26.098823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for variables scaling\ndf_test[['age','bmi']]=scaler.transform(df_test[['age','bmi']])\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:26.102313Z","iopub.execute_input":"2021-06-27T17:10:26.102604Z","iopub.status.idle":"2021-06-27T17:10:26.124992Z","shell.execute_reply.started":"2021-06-27T17:10:26.102577Z","shell.execute_reply":"2021-06-27T17:10:26.124391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets check for test data does the model holds good\ny_test = df_test.pop('charges')\nX_test = df_test\n# adding a constant\nX_test_sm = sm.add_constant(X_test)\n# drop columns as in train data\nX_test_sm.drop(columns = col_name , axis =1 ,inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:26.125847Z","iopub.execute_input":"2021-06-27T17:10:26.126033Z","iopub.status.idle":"2021-06-27T17:10:26.13668Z","shell.execute_reply.started":"2021-06-27T17:10:26.126013Z","shell.execute_reply":"2021-06-27T17:10:26.135461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# building train model\ny_test_pred = lr_model.predict(X_test_sm.astype(float))\n# calculating residual\nres_test = y_test - y_test_pred\n# plot distribution of residual\nsns.distplot(res_test)\n#efficency of test model\nr2_score(y_true = y_test,y_pred = y_test_pred )","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:26.137709Z","iopub.execute_input":"2021-06-27T17:10:26.137986Z","iopub.status.idle":"2021-06-27T17:10:26.392472Z","shell.execute_reply.started":"2021-06-27T17:10:26.137954Z","shell.execute_reply":"2021-06-27T17:10:26.391054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Comparing the actual output values with the predicted values\ndf = pd.DataFrame({'Actual': y_test, 'Predicted': y_test_pred})\ndf.tail(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:26.393895Z","iopub.execute_input":"2021-06-27T17:10:26.394115Z","iopub.status.idle":"2021-06-27T17:10:26.408822Z","shell.execute_reply.started":"2021-06-27T17:10:26.394093Z","shell.execute_reply":"2021-06-27T17:10:26.40793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot for ytest and yPred\nplt.scatter(y_test,y_test_pred)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:26.411031Z","iopub.execute_input":"2021-06-27T17:10:26.411249Z","iopub.status.idle":"2021-06-27T17:10:26.550629Z","shell.execute_reply.started":"2021-06-27T17:10:26.411228Z","shell.execute_reply":"2021-06-27T17:10:26.549571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## for both train and test data the R2_score is .74 and .75 respectively which is good sign that indicates whatever we have predict for train data holds good with test data","metadata":{}},{"cell_type":"markdown","source":"#### Another approach for Recurssive Feature ","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train,y_train)\nrfe = RFE(lr,9)\nrfe = rfe.fit(X_train,y_train)\nlist(zip(X_train.columns,rfe.support_,rfe.ranking_))","metadata":{"execution":{"iopub.status.busy":"2021-06-27T17:10:26.553445Z","iopub.execute_input":"2021-06-27T17:10:26.553725Z","iopub.status.idle":"2021-06-27T17:10:26.779281Z","shell.execute_reply.started":"2021-06-27T17:10:26.553702Z","shell.execute_reply":"2021-06-27T17:10:26.778705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}