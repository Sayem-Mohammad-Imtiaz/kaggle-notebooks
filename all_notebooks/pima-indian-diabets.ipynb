{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Pima Indian Diabets Prediction\n* Evaluation measure including Precision, Accuracy, recall, F1 Score, ROC_AUC,","metadata":{}},{"cell_type":"markdown","source":"## Feature Description\n- Pregnancies : 임신 횟수\n- Blood Pressure : 혈압\n- Glucose : 포도당 부하 수치검사\n- Skin Thickness : 팔 삼두근 뒷쪽의 피하지방 측정값(mm)\n- Insulin : 혈청 인슐린(mu U/ml)\n- BMI : 체질량 지수(체중(kg) / 키(m)^2)\n- DiabetesPediggreeFunctions : 당뇨 내력 가중치\n- Age: 나이\n- Outcome : 클래스 결정 값(0 또는 1)","metadata":{}},{"cell_type":"markdown","source":"## Package load","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# split dataset into train and test\nfrom sklearn.model_selection import train_test_split\n\n# eval(accuracy_score, precision_score, recall_score, roc_auc_score,f1_score, confusion_matrix, precision_recall_curve,roc_curve)\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve\n\n# 정규분포를 이용한 전처리 \nfrom sklearn.preprocessing import StandardScaler\n\n# 회귀분석\nfrom sklearn.linear_model import LogisticRegression","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA(Exploratory Data Access)","metadata":{}},{"cell_type":"code","source":"diabets_data = pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")\ndiabets_data.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diabets_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Technical statistics","metadata":{}},{"cell_type":"code","source":"# zero value should be replace into some extent of value. e.g) mean, median\n# median() should be acceptible.\ndiabets_data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### distribution of Label class - feature `Outcome`","metadata":{}},{"cell_type":"code","source":"diabets_data['Outcome'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get Accuracy, Precision, recall ","metadata":{}},{"cell_type":"code","source":"def get_clf_eval(y_test, pred=None, pred_proba=None):\n    '''\n    Accuracy, Precision, Recall \n    '''\n    eval_dict = {}\n    confusion = confusion_matrix( y_test, pred)\n    accuracy = accuracy_score(y_test , pred)\n    precision = precision_score(y_test , pred)\n    recall = recall_score(y_test , pred)\n    f1 = f1_score(y_test,pred)\n    \n    # ROC-AUC \n    roc_auc = roc_auc_score(y_test, pred_proba)\n    \n    print('confusion matrix')\n    print(confusion)\n    \n    # ROC-AUC print \n    print('accuracy: {0:.4f}, precision: {1:.4f}, recall: {2:.4f},F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))   \n    eval_dict['Accuracy'] = accuracy\n    eval_dict['Precision'] = precision\n    eval_dict['Recall'] = recall\n    eval_dict['F1'] = f1\n    eval_dict['ROC AUC'] = roc_auc\n    return eval_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualization for Precision and Recall","metadata":{}},{"cell_type":"code","source":"def precision_recall_curve_plot(y_test=None, pred_proba_c1=None):\n    \"\"\"\n    threshold ndarray와 이 threslhold에 따른 정밀도, 재현율 추출 후 시각화 \n    \"\"\"\n    precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)\n    \n    plt.figure(figsize = (8, 6))\n    threshold_boundary = thresholds.shape[0]\n    plt.plot(thresholds, precisions[0: threshold_boundary], linestyle = '--', label = 'Precision', color='red')\n    plt.plot(thresholds, recalls[0:threshold_boundary], label = 'Recall', color='blue')\n    \n    start, end = plt.xlim() # 0 과 1을 X-axis, Y-axis\n    \n    plt.xticks(np.round(np.arange(start, end, 0.1), 2))\n    plt.xlabel(\"threshold\")\n    plt.ylabel(\"Precision and Recall\")\n    plt.legend()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model build for Logistic Regression\n- split datasests into train, test\n- fit\n- predict\n- predict_proba","metadata":{}},{"cell_type":"code","source":"X = diabets_data.iloc[:, :-1]\ny = diabets_data.iloc[:,-1]\n\nX_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=.2, random_state=2021)\n\nlr_clf = LogisticRegression()\nlr_clf.fit(X_train, y_train) # train\n\npreds = lr_clf.predict(X_test)\npred_proba = lr_clf.predict_proba(X_test)[:,1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ","metadata":{}},{"cell_type":"markdown","source":"### Accuracy, Precision, Recall","metadata":{}},{"cell_type":"code","source":"get_clf_eval(y_test, preds, pred_proba)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Precision-Recall Curve","metadata":{}},{"cell_type":"code","source":"# precision recall curve\nprecision_recall_curve_plot(y_test, pred_proba)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We should have to find the solution to enhance the recall ratio,thus reconsidering the following\n* Find the solution to replace zero into some meaningful value","metadata":{}},{"cell_type":"markdown","source":"### Distribution for Zero features","metadata":{}},{"cell_type":"code","source":"zero_features = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n\ndef show_hist_zero_feature(zero_features,df):\n    '''\n    Show histogram for zero features\n    '''\n    for zero_feature in zero_features:\n        plt.figure(figsize=(8, 6))\n        plt.hist(diabets_data[zero_feature], bins = 10)\n        plt.title(zero_feature)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_hist_zero_feature(zero_features, diabets_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zero_features = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\ndef get_zero_features_rate(zero_features):\n    \"\"\"\n    Return DataFrame which have two feature \n    cnt, ratio\n    \"\"\"\n    result = {}\n    total_count = diabets_data['Glucose'].count()\n    \n    for zero_feature in zero_features:\n        zero_count = diabets_data[diabets_data[zero_feature]==0][zero_feature].count()\n        percent = np.round(100 * zero_count / total_count, 2)\n        result[zero_feature] = [zero_count, percent]\n    result_df = pd.DataFrame(data = result.values(), index = result.keys(), columns = ['Feature Value_0_cnt', 'Feature Value_0_Ratio'])\n    return result_df\n\nget_zero_features_rate(zero_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## post-processing for zero feature","metadata":{}},{"cell_type":"code","source":"# 위의 평균값보다는 중앙값(median)으로 대치\nmedian_zero_features = [diabets_data[zero_features].median()]\nmedian_zero_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diabets_data[zero_features]=diabets_data[zero_features].replace(0, diabets_data[zero_features].median())\ndisplay(diabets_data.head(), diabets_data.tail())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diabets_data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## feature Scaling\n* StandardScaler -> fit, transform -> train_test_split -> Logistic Regression","metadata":{}},{"cell_type":"code","source":"X = diabets_data.iloc[:, :-1]\ny = diabets_data.iloc[:, -1]\n\nscaler = StandardScaler()\nscaler.fit(X)\nX_scaled = scaler.transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=.2, random_state=2021, stratify=y)\nlr_clf = LogisticRegression()\nlr_clf.fit(X_train, y_train)\n\npred = lr_clf.predict(X_test)\npred_proba = lr_clf.predict_proba(X_test)[:, 1]\nget_clf_eval(y_test, pred, pred_proba)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Recall enhancement through threshold ","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import Binarizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_eval_by_threshold(y_test, preds, pred_proba, thresholds):\n    '''\n    Evaluation value enhancement using threshold value\n    '''\n    result = {}\n    for customer_threshold in thresholds:\n        binarizer = Binarizer(threshold = customer_threshold)\n        binarizer.fit(pred_proba)\n        # Binarizer은 일차원의 ndarray타입을 인자로 받아야 하기 때문에 앞단에서 .reshape(-1,1)\n        customer_predict = binarizer.transform(pred_proba)\n        result[customer_threshold] = get_clf_eval(y_test, customer_predict, pred_proba)\n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"thresholds = [0.3, 0.33, 0.36, 0.39, 0.42, 0.45, 0.48, 0.50]\npd.DataFrame(get_eval_by_threshold(y_test, pred, pred_proba.reshape(-1, 1), thresholds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}