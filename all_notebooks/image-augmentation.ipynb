{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import json\nimport math, re, os, random\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport albumentations as A\nimport cv2\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import Dense, BatchNormalization, GlobalAveragePooling2D, Flatten, Input, Activation, Conv2D, Add\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.initializers import TruncatedNormal\nfrom tensorflow.keras.regularizers import l1, l2, l1_l2\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n\nfrom sklearn.model_selection import KFold\n\nBASE_DIR = \"/kaggle/input/cassava-leaf-disease-classification/\"\nTRAIN_DIR = \"/kaggle/input/cassava-leaf-disease-classification/train_images/\"\nTEST_DIR = \"/kaggle/input/cassava-leaf-disease-classification/test_images/\"\n\nsub = pd.read_csv(f'{BASE_DIR}sample_submission.csv')\ntrain = pd.read_csv(f'{BASE_DIR}train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = list(train[train['label'] == 0].iloc[:2]['image_id'].values)\nl.extend(list(train[train['label'] == 1].iloc[:2]['image_id'].values))\nl.extend(list(train[train['label'] == 2].iloc[:2]['image_id'].values))\nl.extend(list(train[train['label'] == 3].iloc[:2]['image_id'].values))\nl.extend(list(train[train['label'] == 4].iloc[:2]['image_id'].values))\n\nims = np.empty((10,600,800,3), dtype=np.float32)\n\nfor index, image_id in enumerate(l):\n    ims[index] = plt.imread(f'{TRAIN_DIR}{image_id}') / 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 4))\nsns.countplot(y=\"label\", data=train);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Augmentation\n- Label 3 has 60% percent of the data\n- The currently trained model is not focused on predicting labels 0 and 1, hence they are going to be the main focus\n- Label == 0 should have a huge augmentation where the data should be 8 folded\n- The labels 1,2,4 have the same amount and it would be usefull to 4fold them\n\n## Procedure\n- The image_ids will be obtained from the train df and a pre-defined quantity will be chosen from each label:\n    - 200 for labels 2,3,4, 25 for label 0, 50 for label 1\n    - The list containing the image ids will be shuffled to diversify the tfrec file.\n    \n- Use transforms, augmentate, write to the file."},{"metadata":{"trusted":true},"cell_type":"code","source":"transform1 = A.Compose([\n    A.Blur(blur_limit=3, always_apply=True),\n    A.HorizontalFlip(always_apply=True)\n])\n\ntransform2 = A.Compose([\n    A.ChannelDropout(fill_value=10, p=1),\n    A.HorizontalFlip(always_apply=True),\n])\n\ntransform3 = A.Compose([\n    A.Blur(blur_limit=3),\n    A.CoarseDropout(max_holes=500, max_height=5, max_width=5, \n                    min_holes=150, min_height=5, min_width=5, \n                    fill_value=[100,250,100], always_apply=True)\n])\n\ntransform4 = A.Compose([\n    A.GaussNoise(var_limit=(1e-1, 2e-1), mean=0, always_apply=True),\n    A.HorizontalFlip(p=1),\n])\n\ntransform5 = A.Compose([\n    A.RandomBrightnessContrast(p=1, brightness_limit=0.2, contrast_limit=0.5),\n    A.HorizontalFlip(p=0.51),\n])\n\ntransform6 = A.Compose([\n    A.Blur(blur_limit=2, always_apply=True),\n    A.RandomRain(slant_lower=-1, slant_upper=1, \n                 drop_length=2, drop_width=2,\n                 drop_color=(150, 150, 150), \n                 blur_value=2,\n                 brightness_coefficient=0.9,\n                 rain_type=None, always_apply=True),\n    A.HorizontalFlip(p=0.5),\n])\n\ntransform7 = A.Compose([\n    A.Blur(blur_limit=5, always_apply=True),\n    A.Downscale(scale_min=0.65, scale_max=0.9, interpolation=0, always_apply=True),\n    A.HorizontalFlip(p=1),\n])\n\ntransform8 = A.Compose([\n    A.RandomBrightnessContrast(p=1,brightness_limit=0.5,contrast_limit=0.7),\n    A.HorizontalFlip(p=0.51),\n])\n    \n\ntransformers = [\n    transform1, transform2, transform3, transform4, transform5, transform6, transform7, transform8\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utilities\n- Some of these utilites and techniques have been copied from <a href='https://www.tensorflow.org/tutorials/load_data/tfrecord#walkthrough_reading_and_writing_image_data'>here</a>\n- Rest of the functions have been written based on the Augmentation procedure used in this notebook"},{"metadata":{"trusted":true},"cell_type":"code","source":"def _bytes_feature(value):\n  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n  if isinstance(value, type(tf.constant(0))):\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n  \"\"\"Returns a float_list from a float / double.\"\"\"\n  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef serialize(image, target):\n    \"\"\" Creates a tf.train.Example message ready to be written to a file. \"\"\"\n    feature = {\n          'image': _bytes_feature(image),\n          'target': _int64_feature(target),\n    }\n\n    # Create a Features message using tf.train.Example.\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    \n    return example_proto.SerializeToString()\n    \ntfrecord_format = {\n    \"image\": tf.io.FixedLenFeature([], tf.string),\n    \"target\": tf.io.FixedLenFeature([], tf.int64)\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_aug_df(iter_num, label_quantity={\"0\": 25, \"1\": 50, \"2\": 200, \"3\": 200, \"4\": 200}):\n    \n    aug_df = pd.concat([train[train['label'] == int(label)].iloc[q*(iter_num-1):q*(iter_num)] \n                        for label, q in label_quantity.items()]\n                      ).sample(frac=1)\n\n    aug_df.reset_index(drop=True, inplace=True)\n    \n    return aug_df\n\ndef augmentate(df, tfrec_name, transformers=transformers):\n    if len(df) == 0: print('Dataframe is empty')\n    with tf.io.TFRecordWriter(f'/kaggle/working/{tfrec_name}.tfrec') as writer:\n        for _, (image_id, label) in df.iterrows():\n            img = cv2.imread(f'{TRAIN_DIR}{image_id}')\n            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n            \n            \n            if label == 0:\n                transform_agents = transformers\n            elif label == 1:\n                transform_agents = random.sample(transformers, 4)\n            else:\n                transform_agents = [random.choice(transformers)]\n                \n#             print(f'Image_id: {image_id}, Label: {label}, # of agents: {len(transform_agents)}')\n\n            for transformer in transform_agents:\n                aug_img = transformer(image=img)['image']\n                aug_img = cv2.imencode('.jpg', aug_img, (cv2.IMWRITE_JPEG_QUALITY, 94))[1].tostring()\n\n                example = serialize(aug_img, label)\n                \n                writer.write(example)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Goal\n- The goal is augmentate the first 500 images with labels == 0.\n- At each iteration \n    - 25 label 0's are chosen and eight folded\n    - 50 label 1's  chosen and four folded\n    - 200 label 2,3,4's are chosen and transformed only once"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1,9):\n    aug_df = get_aug_df(i, label_quantity={\"0\": 125})\n    augmentate(aug_df, f'cassava_aug0_{i}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = tf.data.TFRecordDataset([f'/kaggle/working/cassava_Aug_0.tfrec'])\nimgs = np.empty((30, 600,800,3))\nfor index, raw_record in enumerate(dataset.take(30)):\n    example = tf.io.parse_single_example(raw_record, tfrecord_format)\n    image = tf.image.decode_jpeg(example['image'], channels=3)\n#     print(example['target'], end='')\n    image = tf.cast(image, tf.float32) / 255.0\n    imgs[index] = tf.reshape(image, [600, 800, 3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(imgs[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nn_row, n_col = 5,6\n#subplot(r,c) provide the no. of rows and columns\nfig, axarr = plt.subplots(n_row,n_col,figsize=(20,20)) \n\nfig.tight_layout()\n# use the created array to output your multiple images. In this case I have stacked 4 images vertically\nfor row in range(n_row):\n    for col in range(n_col):\n        axarr[row, col].imshow(imgs[row * n_col + col])\n        \nplt.subplots_adjust(left=0.125  , bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.2)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}