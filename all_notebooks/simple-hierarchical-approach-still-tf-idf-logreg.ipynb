{"cells":[{"metadata":{"_uuid":"cb01ca96934e5c83a36a2308da9645b87a9c52a0"},"cell_type":"markdown","source":"## <center> Classifying amazon product reviews with logistic regression\n## <center> Simple hierarchical approach"},{"metadata":{},"cell_type":"markdown","source":"Here we train one level 1 model and several level 2 models (as many as there are level 1 classes). At prediction time, we first pick up level 1 model, make a level 1 prediction, and then pick up the corresponding level 2 model based on level 1 prediction. \n\n**Results:**\n\n**Results:**\n\nF1 micro (=accuracy):\n- Level 1: **0.945**\n- Level 2: **0.809**\n\nA bit worse than in case of [\"flat\" classification](https://www.kaggle.com/kashnitsky/flat-hierarchical-tf-idf-logreg-baseline) where we trained a single model for all level 2 classes."},{"metadata":{"_uuid":"ffa03aec57ab6150f9bec0fa56cd3a5791a3e6f4","trusted":true},"cell_type":"code","source":"# some necessary imports\nimport os\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport time\nimport pickle\nfrom contextlib import contextmanager\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.base import BaseEstimator\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%config InlineBackend.figure_format = 'retina'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# nice way to report running times\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    yield\n    print(f'[{name}] done in {time.time() - t0:.0f} s')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH_TO_DATA = Path('../input/hierarchical-text-classification/')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b23e4fc7a1973d60e0c6da8bd60f3d921542a856","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(PATH_TO_DATA / 'train_40k.csv').fillna(' ')\nval_df = pd.read_csv(PATH_TO_DATA / 'val_10k.csv').fillna(' ')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4dc7b3787afa46c7eb0d0e33b0c41ab9821c4a27","trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Example of a review"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[0, 'Text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.loc[0, 'Cat1'], train_df.loc[0, 'Cat2']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d51637ee70dca7693737ad0da1dbb8c6ce9230b"},"cell_type":"markdown","source":"Distribution of Cat1 classes"},{"metadata":{"_uuid":"addd77c640423d30fd146c8d3a012d3c14481e11","trusted":true},"cell_type":"code","source":"train_df['Cat1'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Cat1_Cat2'] = train_df['Cat1'] + '/' + train_df['Cat2']\nval_df['Cat1_Cat2'] = val_df['Cat1'] + '/' + val_df['Cat2']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"416321f19f5a27290bc5622e8b3384b7bbbd28c6"},"cell_type":"markdown","source":"## Defining the model"},{"metadata":{"_uuid":"3048a070a56b08eb4e5fe2c54b6d14905031e74a","trusted":true},"cell_type":"code","source":"# put a limit on maximal number of features and minimal word frequency\ntf_idf = TfidfVectorizer(max_features=50000, min_df=2)\n# multinomial logistic regression a.k.a softmax classifier\nlogit = LogisticRegression(C=1e2, n_jobs=4, solver='lbfgs', \n                           random_state=17, verbose=0, \n                           multi_class='multinomial',\n                           fit_intercept=True)\n# sklearn's pipeline\nbase_model = Pipeline([('tf_idf', tf_idf), \n                       ('logit', logit)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TfIdfLogitPipelineHierarchical(BaseEstimator):\n    \n    def __init__(self, \n                 base_model, \n                 model_store_path,\n                 class_separator = '/',\n                 min_size_to_train=50\n                ):\n        \"\"\"\n\n        :param base_model: Sklearn model to train, one instance for level 1,\n                           and several instances for level 2 \n        :param model_store_path: where to store models as pickle files\n        :param class_separator: separator between level 1 and level 2 class names\n        :param min_size_to_train: do not train a model with less data\n        \"\"\"\n        self.base_model = base_model\n        self.model_store_path = Path(model_store_path)\n        self.class_separator = class_separator\n        self.min_size_to_train = min_size_to_train\n        \n        self.model_store_path.mkdir(exist_ok=True)\n        \n    def fit(self, X, y):\n        \n        lev1_classes = [label.split(self.class_separator)[0]\n                        for label in y]\n        \n        with timer('Training level 1 model'):\n            self.base_model.fit(X, lev1_classes)\n            \n            \n            with open(self.model_store_path / 'level1_model.pkl', 'wb') as f:\n                pickle.dump(self.base_model, f)\n        \n        \n        for lev1_class in np.unique(lev1_classes):\n            \n            with timer(f'Training level 2 model for class: {lev1_class}'):\n                curr_X = X.loc[y.str.startswith(lev1_class)]\n                curr_y = y.loc[y.str.startswith(lev1_class)].apply(lambda s: s.split(self.class_separator)[1])\n                \n                if len(curr_X) < self.min_size_to_train:\n                    print(f\"Skipped class {lev1_class.replace(' ', '_')} due to a too small dataset size: {len(curr_X)}\")\n                    continue\n                    \n                self.base_model.fit(curr_X, curr_y)\n                \n                model_name = f\"level2_model_{lev1_class.replace(' ', '_')}.pkl\"\n                \n                with open(self.model_store_path / model_name, 'wb') as f:\n                    pickle.dump(self.base_model, f)\n    \n    def predict(self, X):\n        \n        model_name =  'level1_model.pkl'\n        with open(self.model_store_path / model_name, 'rb') as f:\n            level1_model = pickle.load(f)\n        \n        level1_preds = level1_model.predict(X)\n            \n        level2_preds = np.zeros_like(level1_preds)\n            \n        for lev1_class in np.unique(level1_preds):\n            \n            idx = level1_preds == lev1_class\n            curr_X = X.iloc[idx]\n            \n            model_name = f\"level2_model_{lev1_class.replace(' ', '_')}.pkl\"\n            \n            if Path(self.model_store_path / model_name).exists():\n            \n                with open(self.model_store_path / model_name, 'rb') as f:\n                    level2_model = pickle.load(f)\n\n                curr_level2_preds = level2_model.predict(curr_X)\n                level2_preds[idx] = curr_level2_preds\n            \n            else:\n                level2_preds[idx] = lev1_class\n                \n        return level1_preds, level2_preds    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = TfIdfLogitPipelineHierarchical(\n    base_model=base_model,\n    model_store_path='models'\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are training our model only with review titles, a couple of experiments show that it works better than with review text. "},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_df['Title'], train_df['Cat1_Cat2'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"level1_pred, level2_pred = model.predict(val_df['Title'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_score(y_true=val_df['Cat1'], y_pred=level1_pred, average='micro').round(3),\\\nf1_score(y_true=val_df['Cat1'], y_pred=level1_pred, average='weighted').round(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8f93efc3db12910eaa6d7944feebb2418714203","trusted":true},"cell_type":"code","source":"f1_score(y_true=val_df['Cat2'], y_pred=level2_pred, average='micro').round(3),\\\nf1_score(y_true=val_df['Cat2'], y_pred=level2_pred, average='weighted').round(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(\n    y_true=val_df['Cat1'], \n    y_pred=level1_pred)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can further analyze confusion matrices for each level 1, but not much insight there."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}