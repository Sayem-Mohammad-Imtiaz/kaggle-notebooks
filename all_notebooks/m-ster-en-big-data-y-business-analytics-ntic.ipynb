{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Trabajo fin de máster: Santander Bikes (análisis y predicción)\n\nEste notebook contiene todo el código realizado, del cual se obtienen los gráficos y las métricas incluidas en el informe en PDF. Dado que no se ha seleccionado una semilla, los resultados pueden variar sensiblemente, pero nunca de manera que alteren las conclusiones, pues el trabajo se ha ejecutado varias veces y las salidas apenas han diferido por unas pocas cifras decimales. El código está comentado y se explica sucintamente la utilidad de la mayoría de las celdas. Sin embargo, la explicación detallada de las salidas y la interpretación se encuentran únicamente en el informe. Sirva esto, pues, como anexo."},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\nimport pandas as pd\nimport numpy as np\nimport sys\nimport matplotlib.pyplot as plt\nimport datetime\nimport os\nfrom pandas_profiling import ProfileReport\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import RandomizedSearchCV\nimport collections","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# os.chdir(\"E:/pythonProject\") he seleccionado este directorio de trabajo. Comentar celda si no es necesario usarla","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cargamos el archivo y renombramos las columnas para mayor claridad en la interpretación:"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw = pd.read_csv(\"../input/london-bike-sharing-dataset/london_merged.csv\")\nraw = raw.rename(columns = {'cnt': 'Count', 't1': 'Temperature', 't2': 'Feels Like', 'hum': 'Humidity', 'wind_speed': 'Wind Speed',\n                           'weather_code':'Weather Code', 'is_holiday':'Holiday', 'is_weekend':'Weekend', 'season':'Season'})\nraw = raw.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cambiamos los valores de las variables que son categóricas:"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# raw['Holiday'] = raw['Holiday'].replace(0, False)\n# raw['Holiday'] = raw['Holiday'].replace(1, True)\n# raw['Holiday'] = raw['Holiday'].astype('bool')\n\n# raw['Weekend'] = raw['Weekend'].replace(0, False)\n# raw['Weekend'] = raw['Weekend'].replace(1, True)\n# raw['Weekend'] = raw['Weekend'].astype('bool')\n\nraw['Season'] = raw['Season'].replace({0: 'Spring', 1: 'Summer', 2: 'Autumn', 3: 'Winter'})\nraw['Weather Code'] = raw['Weather Code'].replace({1: 'Clear', 2: 'Few Clouds', 3: 'Broken Clouds', 4: 'Cloudy',\n                                                  7: 'Light Rain', 10: 'Thunderstorm', 26: 'Snowfall', 94: 'Freezing Fog'})\n\nraw['timestamp'] = pd.to_datetime(raw['timestamp'])\nraw.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aquí extraigo nuevas variables a partir de \"timestamp\": año, mes, día, tramo horario (mañana, tarde, noche)"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw['hour'] = raw['timestamp'].apply(lambda time: time.hour) \nraw['month'] = raw['timestamp'].apply(lambda time: time.month)\nraw['day_of_week'] = raw['timestamp'].apply(lambda time: time.dayofweek)\n\n# Renombramos los días de la semana\ndate_names = {0: 'Mon', 1: 'Tue', 2: 'Wed', 3: 'Thu', 4: 'Fri', 5: 'Sat', 6: 'Sun'} \nraw['day_of_week'] = raw['day_of_week'].map(date_names)\n\nraw.drop('timestamp', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hacemos un análisis inicial de los datos usando ProfileReport:"},{"metadata":{"trusted":true},"cell_type":"code","source":"profile = ProfileReport(raw)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profile","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Creación del dataset bueno\n\nlondon = raw.join(pd.get_dummies(raw['Weather Code']), on = raw['df_index']).drop(columns = ['Weather Code'])\\\n.join(pd.get_dummies(raw['Season']), on = raw['df_index']).drop(columns = ['Season'])\\\n.join(pd.get_dummies(raw['day_of_week']), on = raw['df_index']).drop(columns = ['day_of_week'])\\\n.drop(columns = ['df_index'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = london['Count'] #variable objetivo\nfeatures = london.drop(columns = ['Count']) #variables independientes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(features, results, test_size = 0.20, shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### REGRESIÓN LINEAL"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LinearRegression()\nlr.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr.score(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(\"regresión lineal: \", mean_absolute_error(lr.predict(x_test), y_test),\n      \"\\nPrediciendo la media: \", mean_absolute_error(np.ones([y_test.shape[0]]) * np.mean(y_test), y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_lr = y_test - lr.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(error_lr, bins = np.arange(-2000, 2000, 50)) #error sin normalizar\n\nplt.title('Error regresión lineal (en núm. bicis)')\nplt.xlabel('Error')\nplt.ylabel('Frecuencia')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nuestra regresión lineal parece ligeramente mejor que predecir únicamente la media para todas las observaciones test, pero no es un gran avance. Probemos con otros modelos."},{"metadata":{},"cell_type":"markdown","source":"#### SVR"},{"metadata":{"trusted":true},"cell_type":"code","source":"stdscl = StandardScaler()\nstd_x_train = stdscl.fit_transform(x_train.values)\nstd_x_test = stdscl.fit_transform(x_test.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svr = SVR()\nsvr.fit(std_x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(\"SVR: \", mean_absolute_error(svr.predict(std_x_test), y_test),\n      \"\\nPrediciendo la media: \", mean_absolute_error(np.ones([y_test.shape[0]]) * np.mean(y_test), y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_svr = y_test - svr.predict(std_x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(error_svr, bins = np.arange(-1000, 4600, 50)) #error sin normalizar\n\nplt.title('Error SVR (en núm. bicis)')\nplt.xlabel('Error')\nplt.ylabel('Frecuencia')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prácticamente el mismo resultado."},{"metadata":{},"cell_type":"markdown","source":"#### NB"},{"metadata":{"trusted":true},"cell_type":"code","source":"brr = BayesianRidge()\nbrr.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(\"Naive Bayes: \", mean_absolute_error(brr.predict(x_test), y_test),\n      \"\\nPrediciendo la media: \", mean_absolute_error(np.ones([y_test.shape[0]]) * np.mean(y_test), y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_brr = y_test - brr.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(error_brr, bins = np.arange(-2000, 4600, 50)) #error sin normalizar\n\nplt.title('Error NB (en núm. bicis)')\nplt.xlabel('Error')\nplt.ylabel('Frecuencia')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seguimos sin hacer progresos."},{"metadata":{},"cell_type":"markdown","source":"#### RF"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"rf = RandomForestRegressor()\nrf.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.score(x_test, y_test) #En realidad, esta métrica no es muy importante, aunque una puntuación alta es alentadora.","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(\"Random Forest: \", mean_absolute_error(rf.predict(x_test), y_test),\n      \"\\nPrediciendo la media: \", mean_absolute_error(np.ones([y_test.shape[0]]) * np.mean(y_test), y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"london['Count'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(london['Count'], bins = np.arange(0, 6500, 100))\n\nplt.title('Distribución de la variable objetivo')\nplt.xlabel('Valor')\nplt.ylabel('Frecuencia')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"rf.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error = y_test - rf.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(error, bins = np.arange(-1500, 1500, 50)) #error sin normalizar\n\nplt.title('Distribución del error de la predicción (RF)')\nplt.xlabel('Error')\nplt.ylabel('Frecuencia')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error.mean(), error.std() #no está mal pero tenemos mucha desviación estándar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_norm = error/y_test\nerror_norm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(error_norm, bins = np.arange(-3, error_norm.max(), 0.1))\n\nplt.title('Distribución del error normalizado de la predicción (RF)')\nplt.xlabel('Error')\nplt.ylabel('Frecuencia')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_norm.mean(), error_norm.std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_test, error_norm) #el modelo se equivoca algo más cuanto más pequeño es el número de bicis que se cogen\n\nplt.title('Error normalizado vs Número de bicis')\nplt.xlabel('Número de bicis')\nplt.ylabel('Error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(rf.predict(x_test), y_test, alpha = 0.5)\nplt.plot(y_test, y_test, color = 'magenta')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parece un modelo bastante bueno cuando hay muchas bicis pero \"no tan bueno\" cuando hay pocas. Centrémonos ahora en las observaciones con pocas bicis:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test[y_test < 1000]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"rf.predict(x_test)[y_test < 1000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_pequeño = y_test[y_test < 1000] - rf.predict(x_test)[y_test < 1000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_pequeño.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(y_test[y_test < 1000] - y_test[y_test < 1000].mean()).mean() #en recuentos pequeños parece \"mucho\" mejor predecir la media","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_test[y_test < 1000], rf.predict(x_test)[y_test < 1000])\n\nplt.xlabel('Número de bicis real')\nplt.ylabel('Predicción')\nplt.title('Predicción Random Forest vs Valores reales')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_test[y_test < 1000], error_pequeño)\n\nplt.xlabel('Número de bicis')\nplt.ylabel('Error')\nplt.title('Error Random Forest a lo largo de las observaciones')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Estas predicciones han sido hechas a partir de un Random Forest sin ningún tuneo. Descubramos sus parámetros para ver si es posible tunear alguno de ellos y mejorar la precisión del modelo."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"rf.get_params() #base para ver qué puedo tunear","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"rf.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = rf.feature_importances_\nindices = np.argsort(importances)\nfeature_names = features.keys()\n\nplt.title('Importancia de variables')\nplt.barh(range(len(indices)), importances[indices], color = 'magenta', align = 'center')\nplt.yticks(range(len(indices)), [feature_names[i] for i in indices])\nplt.xlabel('Importancia relativa')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parece que la hora es la variable más importante con mucha diferencia. ¿Es eso verdad? Puede que nuestro modelo no esté ponderando correctamente. Para ver si el modelo funciona bien, vamos a añadir una variable aleatoria que llamaremos \"random\" y que, como cabe esperar, no aportará absolutamente nada al modelo. Si el modelo está bien construido, esta variable tendrá una importancia nula o casi nula."},{"metadata":{"trusted":true},"cell_type":"code","source":"# añado una columna random\n\nlondon['random'] = np.random.random(london['Clear'].size) #que tenga la misma longitud que las otras columnas!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_2 = london['Count'] #variable objetivo\nfeatures_2 = london.drop(columns = ['Count']) #variables independientes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_2, x_test_2, y_train_2, y_test_2 = train_test_split(features_2, results_2, test_size = 0.20, shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_2 = RandomForestRegressor()\nrf_2.fit(x_train_2, y_train_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_2.score(x_test_2, y_test_2)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"print(\"Random Forest: \", mean_absolute_error(rf_2.predict(x_test_2), y_test_2),\n      \"\\nPrediciendo la media: \", mean_absolute_error(np.ones([y_test.shape[0]]) * np.mean(y_test_2), y_test_2))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"importances_2 = rf_2.feature_importances_\nindices_2 = np.argsort(importances_2)\nfeature_names_2 = features_2.keys()\n\nplt.title('Importancia de variables')\nplt.barh(range(len(indices_2)), importances_2[indices_2], color = 'magenta', align = 'center')\nplt.yticks(range(len(indices_2)), [feature_names_2[i] for i in indices_2])\nplt.xlabel('Importancia relativa')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hemos visto que la hora parece muy importante, y que muchas variables no aportan ninguna información. ¿Podríamos construir un modelo más simple sin perder información? Veamos si haciendo una selección de variables podemos conseguirlo."},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_no_ordenado = dict(zip(rf.feature_importances_, x_train.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ordered = collections.OrderedDict(sorted(dict_no_ordenado.items()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ordered","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_features = np.array(list(ordered.values()))[-1:-15:-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.fit(x_train.loc[:,selected_features], y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf.score(x_test.loc[:, selected_features], y_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(\"Random Forest: \", mean_absolute_error(rf.predict(x_test.loc[:,selected_features]), y_test),\n      \"\\nPrediciendo la media: \", mean_absolute_error(np.ones([y_test.shape[0]]) * np.mean(y_test), y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parece que eliminar todas esas variables no afecta de manera significativa al modelo. Veamos a continuación una distribución de nuestra variable objetivo en función de la hora:"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.scatter(london['hour'], london['Count'])\n\nplt.xlabel('Hora')\nplt.ylabel('Número de bicis')\nplt.title('Número de bicis vs Hora del día')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No parece haber una relación muy lineal entre la hora y el número de bicis (casi todo al ir a trabajar o al salir del trabajo), pero se observa claramente que existe una razón para que esta variable sea tan importante."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest con tuneo de parámetros\n# Número de árboles\nn_estimators = [int(x) for x in np.linspace(start = 50, stop = 1000, num = 10)]\n# Tuneamos el número de variables a usar en cada caso\nmax_features = ['auto', 'sqrt']\n# Máximo número de niveles en cada árbol\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Sampsize mínimo para cada nodo\nmin_samples_split = [2, 5, 10]\n# Sampsize mínimo para cada hoja del árbol\nmin_samples_leaf = [1, 2, 4]\n# Método de selección\nbootstrap = [True, False]\n# Creamos la rejilla con los valores de arriba\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nprint(random_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_3 = RandomForestRegressor()\n# Búsqueda aleatoria de parámetros con validación cruzada, \n# buscamos entre muchas combinaciones distintas.\nrf_random = RandomizedSearchCV(estimator = rf_3, param_distributions = random_grid,\n                               n_iter = 100, cv = 3, verbose = 3,\n                               n_jobs = 5) #n_jobs = número de núcleos del procesador (cambiar en función del ordenador)\nrf_random.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Random Forest tuneado: \", mean_absolute_error(rf_random.predict(x_test), y_test),\n      \"\\nPrediciendo la media: \", mean_absolute_error(np.ones([y_test.shape[0]]) * np.mean(y_test), y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_random.best_params_","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"rf_random.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_random = y_test - rf_random.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(error_random, bins = np.arange(-1500, 1500, 50)) #error sin normalizar\n\nplt.title('Distribución del error de la predicción (RF)')\nplt.xlabel('Error')\nplt.ylabel('Frecuencia')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_random.mean(), error_random.std() #seguimos con mucha desviación estándar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_random_norm = error_random/y_test\nerror_random_norm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(error_random_norm, bins = np.arange(-3, error_random_norm.max(), 0.1))\n\nplt.title('Distribución del error normalizado de la predicción (RF)')\nplt.xlabel('Error')\nplt.ylabel('Frecuencia')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_random_norm.mean(), error_random_norm.std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_test, error_random_norm, alpha = 0.3)\n\nplt.title('Error normalizado vs Número de bicis')\nplt.xlabel('Número de bicis')\nplt.ylabel('Error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(rf_random.predict(x_test), y_test, alpha = 0.5)\nplt.plot(y_test, y_test, color = 'magenta') #de momento parece que el tuneo no está siendo exitoso","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Parece un modelo bastante bueno cuando hay muchas bicis pero \"no tan bueno\" cuando hay pocas. Centrémonos ahora en las observaciones con pocas bicis:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test[y_test < 1000]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"rf_random.predict(x_test)[y_test < 1000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_pequeño_random = y_test[y_test < 1000] - rf_random.predict(x_test)[y_test < 1000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_pequeño_random.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(y_test[y_test < 1000] - y_test[y_test < 1000].mean()).mean() #Sigue siendo mejor predecir la media en recuentos pequeños","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_test[y_test < 1000], rf_random.predict(x_test)[y_test < 1000])\nplt.plot(y_test[y_test < 1000], y_test[y_test < 1000], color = \"magenta\")\n\nplt.xlabel('Número de bicis real')\nplt.ylabel('Predicción')\nplt.title('Predicción Random Forest vs Valores reales')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_test[y_test < 1000], error_pequeño_random)\nplt.axhline(y=0, color='m', linestyle='-')\n\nplt.xlabel('Número de bicis')\nplt.ylabel('Error')\nplt.title('Error Random Forest a lo largo de las observaciones')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ideas de mejora para el futuro:\n\n#### - mejorar los datos (hacer más features que estén mejor) O mejorar los modelos (tunear parámetros del RF)\n\n#### - probar a entrenar el modelo con pocos datos e ir subiendo: ¿a partir de qué punto el aprendizaje del modelo \"se estanca\"?\n\n#### - buscar más\"métricas de calidad\" para ver si mi modelo es bueno en las cosas que importan\n\n#### - probar una red neuronal y entrenarla con datos en vivo"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}