{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Following problem is based on a hackathon conducted by Analytics Vidhya where the objective was to predict Customers intrested in taking Credit Card. In the code you will find the following:**\n\n* EDA of the continous and categorical variable\n* Weight of Evidence(WOE) and Information value(IV) for continous and Categorical Feature\n* Modelling using Boosting techniques and WOE transformed features\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestClassifier\nimport pandas.core.algorithms as algos\nfrom pandas import Series\nimport scipy.stats.stats as stats\nimport re\nimport string\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-07T09:55:45.894425Z","iopub.execute_input":"2021-06-07T09:55:45.894744Z","iopub.status.idle":"2021-06-07T09:55:45.90608Z","shell.execute_reply.started":"2021-06-07T09:55:45.894717Z","shell.execute_reply":"2021-06-07T09:55:45.905026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(r'/kaggle/input/jobathon-may-2021-credit-card-lead-prediction/train.csv')\ntest = pd.read_csv(r'/kaggle/input/jobathon-may-2021-credit-card-lead-prediction/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:46.286497Z","iopub.execute_input":"2021-06-07T09:55:46.286829Z","iopub.status.idle":"2021-06-07T09:55:46.733564Z","shell.execute_reply.started":"2021-06-07T09:55:46.286802Z","shell.execute_reply":"2021-06-07T09:55:46.732566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**EDA**","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:47.681525Z","iopub.execute_input":"2021-06-07T09:55:47.68185Z","iopub.status.idle":"2021-06-07T09:55:47.696206Z","shell.execute_reply.started":"2021-06-07T09:55:47.681822Z","shell.execute_reply":"2021-06-07T09:55:47.69561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot countplots \ncat_col = ['Occupation','Channel_Code','Credit_Product']\nplt.figure(figsize=(14, 12), dpi=100)\nfor i, feature in enumerate(cat_col):\n    plt.subplot(3, 3, i+1)\n    sns.countplot(data=train, x=feature)\n    \nsns.despine()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:48.070003Z","iopub.execute_input":"2021-06-07T09:55:48.071896Z","iopub.status.idle":"2021-06-07T09:55:48.886963Z","shell.execute_reply.started":"2021-06-07T09:55:48.071854Z","shell.execute_reply":"2021-06-07T09:55:48.886037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(train[\"Avg_Account_Balance\"]) # highly positively skewed \n# we will use WOE transformation to transform the variable","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:48.888068Z","iopub.execute_input":"2021-06-07T09:55:48.888286Z","iopub.status.idle":"2021-06-07T09:55:50.198123Z","shell.execute_reply.started":"2021-06-07T09:55:48.888264Z","shell.execute_reply":"2021-06-07T09:55:50.19745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# features to plot in the count plots\n\n\n# plot countplots \ncat_col = ['Gender','Region_Code','Occupation','Channel_Code','Credit_Product','Is_Active']\nplt.figure(figsize=(14, 12), dpi=100)\nfor i, feature in enumerate(cat_col):\n    plt.subplot(3, 3, i+1)\n    sns.countplot(data=train, x=feature, hue='Is_Lead')\n    \nsns.despine()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:50.199373Z","iopub.execute_input":"2021-06-07T09:55:50.199748Z","iopub.status.idle":"2021-06-07T09:55:52.234132Z","shell.execute_reply.started":"2021-06-07T09:55:50.199719Z","shell.execute_reply":"2021-06-07T09:55:52.233444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Weight of Evidence(WOE) and Information value (IV)**\n\nThe weight of evidence tells the predictive power of an independent variable in relation to the dependent variable. Since it evolved from credit scoring world, it is generally described as a measure of the separation of good and bad customers.\n\n                         WOE  = ln(Distribution of Goods/ Distribution of Bads)\n                         \n                         Distribution of Goods : % of good customer in a particular group\n                         Distribution of Bads  : % of bad customer in a particular group\n                         ln : Natural log\n                         \n                         ","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"max_bin = 20\nforce_bin = 3\n\n# Binning Function for continous variables\ndef mono_bin(Y, X, n = max_bin):\n    \n    df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n    justmiss = df1[['X','Y']][df1.X.isnull()]\n    notmiss = df1[['X','Y']][df1.X.notnull()]\n    r = 0\n    while np.abs(r) < 1:\n        try:\n            d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.qcut(notmiss.X, n)})\n            d2 = d1.groupby('Bucket', as_index=True)\n            r, p = stats.spearmanr(d2.mean().X, d2.mean().Y)\n            n = n - 1 \n        except Exception as e:\n            n = n - 1\n\n    if len(d2) == 1:\n        n = force_bin         \n        bins = algos.quantile(notmiss.X, np.linspace(0, 1, n))\n        if len(np.unique(bins)) == 2:\n            bins = np.insert(bins, 0, 1)\n            bins[1] = bins[1]-(bins[1]/2)\n        d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.cut(notmiss.X, np.unique(bins),include_lowest=True)}) \n        d2 = d1.groupby('Bucket', as_index=True)\n    \n    d3 = pd.DataFrame({},index=[])\n    d3[\"MIN_VALUE\"] = d2.min().X\n    d3[\"MAX_VALUE\"] = d2.max().X\n    d3[\"COUNT\"] = d2.count().Y\n    d3[\"EVENT\"] = d2.sum().Y\n    d3[\"NONEVENT\"] = d2.count().Y - d2.sum().Y\n    d3=d3.reset_index(drop=True)\n    \n    if len(justmiss.index) > 0:\n        d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n        d4[\"MAX_VALUE\"] = np.nan\n        d4[\"COUNT\"] = justmiss.count().Y\n        d4[\"EVENT\"] = justmiss.sum().Y\n        d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n        d3 = d3.append(d4,ignore_index=True)\n    \n    d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n    d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n    d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n    d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n    d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n    d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n    d3[\"VAR_NAME\"] = \"VAR\"\n    d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]       \n    d3 = d3.replace([np.inf, -np.inf], 0)\n    d3.IV = d3.IV.sum()\n    \n    return(d3)\n\n# Binning Function for Categorical variables\ndef char_bin(Y, X):\n        \n    df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n    justmiss = df1[['X','Y']][df1.X.isnull()]\n    notmiss = df1[['X','Y']][df1.X.notnull()]    \n    df2 = notmiss.groupby('X',as_index=True)\n    \n    d3 = pd.DataFrame({},index=[])\n    d3[\"COUNT\"] = df2.count().Y\n    d3[\"MIN_VALUE\"] = df2.sum().Y.index\n    d3[\"MAX_VALUE\"] = d3[\"MIN_VALUE\"]\n    d3[\"EVENT\"] = df2.sum().Y\n    d3[\"NONEVENT\"] = df2.count().Y - df2.sum().Y\n    \n    if len(justmiss.index) > 0:\n        d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n        d4[\"MAX_VALUE\"] = np.nan\n        d4[\"COUNT\"] = justmiss.count().Y\n        d4[\"EVENT\"] = justmiss.sum().Y\n        d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n        d3 = d3.append(d4,ignore_index=True)\n    \n    d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n    d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n    d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n    d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n    d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n    d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n    d3[\"VAR_NAME\"] = \"VAR\"\n    d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]      \n    d3 = d3.replace([np.inf, -np.inf], 0)\n    d3.IV = d3.IV.sum()\n    d3 = d3.reset_index(drop=True)\n    \n    return(d3)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:52.235212Z","iopub.execute_input":"2021-06-07T09:55:52.235558Z","iopub.status.idle":"2021-06-07T09:55:52.255375Z","shell.execute_reply.started":"2021-06-07T09:55:52.235532Z","shell.execute_reply":"2021-06-07T09:55:52.254496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef comb_category(woe,threshold):\n    \n    count = 0\n    similar_col = dict()\n    col = []\n    columns1 = woe['MIN_VALUE'].unique()\n    columns2 = woe['MIN_VALUE'].unique()\n    for cat1 in columns1 :\n        if cat1 in col: continue\n        woe1 = float(woe[woe['MIN_VALUE'] == cat1]['WOE'].values[0])\n        col1 = []\n\n        for cat in woe['MIN_VALUE'].unique():\n            if cat1 == cat: continue\n            if cat in col: continue\n            woe2 = float(woe[woe['MIN_VALUE'] == cat]['WOE'].values[0])\n\n            if (woe2 - woe1) >0.0 and (woe2 - woe1)<threshold:\n                col1.append(cat)\n                col.append(cat)\n        col.append(cat1)\n\n        similar_col[cat1] = col1\n        \n        if len(col1)>0:\n            count+=1\n    \n    return(similar_col,count)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:52.257297Z","iopub.execute_input":"2021-06-07T09:55:52.257675Z","iopub.status.idle":"2021-06-07T09:55:52.271528Z","shell.execute_reply.started":"2021-06-07T09:55:52.257636Z","shell.execute_reply":"2021-06-07T09:55:52.270661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef data_vars(df1,target,test,cat_threshold):\n    \n    \n    \n    x = df1.dtypes.index\n    count = -1\n    replace = {}\n    \n    for i in x:\n        \n        if np.issubdtype(df1[i], np.number) and len(Series.unique(df1[i])) > 2:\n            conv = mono_bin(target, df1[i])\n            conv[\"VAR_NAME\"] = i\n            count = count + 1\n        else:\n            cat_replace = []\n            conv = char_bin(target, df1[i])\n            conv = conv.sort_values('WOE')\n            similar_col,var_count = comb_category(conv,cat_threshold)\n            cat_replace.append(similar_col)\n\n            while var_count>0:\n\n                for x,y in zip(similar_col.keys(),similar_col.values()):\n                    df1.loc[df1[i].isin(y),i] = x\n                    test.loc[test[i].isin(y),i] = x\n                conv = char_bin(target, df1[i])\n                conv = conv.sort_values('WOE')\n                similar_col,var_count = comb_category(conv,cat_threshold)\n                cat_replace.append(similar_col)\n            replace[i] = cat_replace\n            conv[\"VAR_NAME\"] = i            \n            count = count + 1\n\n        if count == 0:\n            iv_df = conv\n        else:\n            iv_df = iv_df.append(conv,ignore_index=True)\n    \n    iv = pd.DataFrame({'IV':iv_df.groupby('VAR_NAME').IV.max()})\n    iv = iv.reset_index()\n    return(iv_df,iv,df1,test,replace)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:52.273175Z","iopub.execute_input":"2021-06-07T09:55:52.27344Z","iopub.status.idle":"2021-06-07T09:55:52.287547Z","shell.execute_reply.started":"2021-06-07T09:55:52.273415Z","shell.execute_reply":"2021-06-07T09:55:52.286432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_copy = train.copy()\ntest_copy  = test.copy()\n\ntrain_copy.drop('ID',axis =1,inplace = True)\ntrain_copy['Credit_Product'].fillna('NA',inplace = True)\n\ntest_copy.drop('ID',axis =1,inplace = True)\ntest_copy['Credit_Product'].fillna('NA',inplace = True)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:52.28971Z","iopub.execute_input":"2021-06-07T09:55:52.290805Z","iopub.status.idle":"2021-06-07T09:55:52.357516Z","shell.execute_reply.started":"2021-06-07T09:55:52.290764Z","shell.execute_reply":"2021-06-07T09:55:52.356637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Calculating WOE and IV values\nfinal_iv, IV,new_train,new_test,cat_replace = data_vars(train_copy,train_copy.Is_Lead,test_copy,cat_threshold = 0.1)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:52.358735Z","iopub.execute_input":"2021-06-07T09:55:52.359242Z","iopub.status.idle":"2021-06-07T09:55:55.298557Z","shell.execute_reply.started":"2021-06-07T09:55:52.359211Z","shell.execute_reply":"2021-06-07T09:55:55.297706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_iv.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:55.299918Z","iopub.execute_input":"2021-06-07T09:55:55.300284Z","iopub.status.idle":"2021-06-07T09:55:55.316274Z","shell.execute_reply.started":"2021-06-07T09:55:55.300246Z","shell.execute_reply":"2021-06-07T09:55:55.315262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Replacing features with WOE values**","metadata":{}},{"cell_type":"code","source":"def woe_replacement(train,transform_vars_list,transform_prefix):\n    for var in transform_vars_list:\n        print(var)\n        \n        small_train = final_iv[final_iv['VAR_NAME'] == var]\n        transform_dict = dict(zip(small_train.MAX_VALUE,small_train.WOE))\n        replace_cmd = ''\n        replace_cmd1 = ''\n        \n        for i in sorted(transform_dict.items()):\n            replace_cmd = replace_cmd + str(i[1]) + str(' if x <= ') + str(i[0]) + ' else '\n            replace_cmd1 = replace_cmd1 + str(i[1]) + str(' if x == \"') + str(i[0]) + '\" else '\n        replace_cmd = replace_cmd + '0'\n        replace_cmd1 = replace_cmd1 + '0'\n        \n        if replace_cmd != '0':\n            try:\n                train[transform_prefix + var] = train[var].apply(lambda x: eval(replace_cmd))\n            except:\n                train[transform_prefix + var] = train[var].apply(lambda x: eval(replace_cmd1))\n                \n    return(train)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:55.318495Z","iopub.execute_input":"2021-06-07T09:55:55.318929Z","iopub.status.idle":"2021-06-07T09:55:55.328942Z","shell.execute_reply.started":"2021-06-07T09:55:55.318885Z","shell.execute_reply":"2021-06-07T09:55:55.327919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform_vars_list = new_train.columns.difference(['Is_Lead'])\ntransform_prefix = 'new_'\n\nnew_train = woe_replacement(new_train,transform_vars_list,transform_prefix)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:55:55.330259Z","iopub.execute_input":"2021-06-07T09:55:55.330517Z","iopub.status.idle":"2021-06-07T09:56:34.437437Z","shell.execute_reply.started":"2021-06-07T09:55:55.330491Z","shell.execute_reply":"2021-06-07T09:56:34.43656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform_vars_list = new_test.columns\n\nnew_test = woe_replacement(new_test,transform_vars_list,transform_prefix)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:56:34.438721Z","iopub.execute_input":"2021-06-07T09:56:34.439087Z","iopub.status.idle":"2021-06-07T09:56:51.012938Z","shell.execute_reply.started":"2021-06-07T09:56:34.439049Z","shell.execute_reply":"2021-06-07T09:56:51.011838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:56:51.01447Z","iopub.execute_input":"2021-06-07T09:56:51.014857Z","iopub.status.idle":"2021-06-07T09:56:51.034722Z","shell.execute_reply.started":"2021-06-07T09:56:51.014818Z","shell.execute_reply":"2021-06-07T09:56:51.033748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Modelling (Boosting Algorithm)**","metadata":{}},{"cell_type":"code","source":"#Function for running cross validation\ndef boosting(clf, fit_params, train, test, features):\n    N_SPLITS = 10\n    oofs = np.zeros(len(train))\n    preds = np.zeros((len(test)))\n\n    folds = StratifiedKFold(n_splits = N_SPLITS)\n\n    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train, train[TARGET_COL])):\n        print(f'\\n------------- Fold {fold_ + 1} -------------')\n\n        ### Training Set\n        X_trn, y_trn = train[features].iloc[trn_idx], train[TARGET_COL].iloc[trn_idx]\n\n        ### Validation Set\n        X_val, y_val = train[features].iloc[val_idx], train[TARGET_COL].iloc[val_idx]\n\n        ### Test Set\n        X_test = test[features]\n\n        #print(X_trn)\n        #exit(0)\n\n        _ = clf.fit(X_trn, y_trn, eval_set = [(X_val, y_val)], **fit_params)\n\n        ### Instead of directly predicting the classes we will obtain the probability of positive class.\n        preds_val = clf.predict_proba(X_val)[:, 1]\n        preds_test = clf.predict_proba(X_test)[:, 1]\n\n        roc_score = roc_auc_score(y_val,preds_val)\n        print(\"ROC for validation set is {}\".format(roc_score))\n\n        oofs[val_idx] = preds_val\n        preds += preds_test / N_SPLITS\n\n\n    oofs_score = roc_auc_score(train[TARGET_COL], oofs.round())\n    print('ROC score for oofs is {}'.format(oofs_score))\n\n\n    return oofs, preds","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:56:51.036744Z","iopub.execute_input":"2021-06-07T09:56:51.037135Z","iopub.status.idle":"2021-06-07T09:56:51.045848Z","shell.execute_reply.started":"2021-06-07T09:56:51.037094Z","shell.execute_reply":"2021-06-07T09:56:51.045064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#catboost model training\nclf = CatBoostClassifier(n_estimators = 3000,\n                       learning_rate = 0.02,\n                       rsm = 0.4, ## Analogous to colsample_bytree\n                       random_state=2054,\n                       \n                       )\n\nfit_params = {'verbose': 200, 'early_stopping_rounds': 300}\n\nfeatures = ['new_Age', 'new_Avg_Account_Balance', 'new_Channel_Code',\n       'new_Credit_Product', 'new_Gender', 'new_Is_Active', 'new_Occupation',\n       'new_Region_Code', 'new_Vintage']\n\nTARGET_COL = 'Is_Lead'\n\ncb_oofs, cb_preds = boosting(clf, fit_params,new_train,new_test,features)\n\noptimized_roc = roc_auc_score(new_train[TARGET_COL], (cb_oofs  * 1))\nprint(f'Optimized ROC is {optimized_roc}')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T09:56:51.046933Z","iopub.execute_input":"2021-06-07T09:56:51.047276Z","iopub.status.idle":"2021-06-07T10:04:21.090855Z","shell.execute_reply.started":"2021-06-07T09:56:51.047247Z","shell.execute_reply":"2021-06-07T10:04:21.089859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training LightGBM model \nclf = LGBMClassifier(n_estimators = 200,\n                        learning_rate = 0.05,\n                        colsample_bytree = 0.5,\n                        )\nfit_params = {'verbose': 100, 'early_stopping_rounds': 100}\n\nlgb_oofs, lgb_preds = boosting(clf, fit_params,new_train,new_test,features)\n\n\noptimized_roc = roc_auc_score(new_train[TARGET_COL], (lgb_oofs * 1))\nprint(f'Optimized ROC is {optimized_roc}')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T10:04:21.092097Z","iopub.execute_input":"2021-06-07T10:04:21.092341Z","iopub.status.idle":"2021-06-07T10:04:49.172129Z","shell.execute_reply.started":"2021-06-07T10:04:21.092317Z","shell.execute_reply":"2021-06-07T10:04:49.171191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training XGB Classifier\nclf = XGBClassifier(n_estimators = 1000,\n                    max_depth = 6,\n                    learning_rate = 0.05,\n                    colsample_bytree = 0.5,\n                    random_state=1452,\n                    )\n\nfit_params = {'verbose': 200, 'early_stopping_rounds': 200}\n\nxgb_oofs, xgb_preds = boosting(clf, fit_params,new_train,new_test,features)\n\n\noptimized_f1 = roc_auc_score(new_train[TARGET_COL], (xgb_oofs * 1))\nprint(f'Optimized F1 is {optimized_f1}')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T10:06:15.270306Z","iopub.execute_input":"2021-06-07T10:06:15.270652Z","iopub.status.idle":"2021-06-07T10:10:10.7474Z","shell.execute_reply.started":"2021-06-07T10:06:15.270621Z","shell.execute_reply":"2021-06-07T10:10:10.746441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}