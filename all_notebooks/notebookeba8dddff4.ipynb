{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-26T16:02:46.442502Z","iopub.execute_input":"2021-07-26T16:02:46.442898Z","iopub.status.idle":"2021-07-26T16:02:46.455367Z","shell.execute_reply.started":"2021-07-26T16:02:46.442863Z","shell.execute_reply":"2021-07-26T16:02:46.453968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt \nfrom sklearn.metrics import plot_confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:02:46.457465Z","iopub.execute_input":"2021-07-26T16:02:46.457913Z","iopub.status.idle":"2021-07-26T16:02:46.472801Z","shell.execute_reply.started":"2021-07-26T16:02:46.457878Z","shell.execute_reply":"2021-07-26T16:02:46.47191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\ndata.describe()\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:02:46.474441Z","iopub.execute_input":"2021-07-26T16:02:46.47494Z","iopub.status.idle":"2021-07-26T16:02:46.527008Z","shell.execute_reply.started":"2021-07-26T16:02:46.474885Z","shell.execute_reply":"2021-07-26T16:02:46.525956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isna().sum()\n#changing the 0s to the mean value of the values in the columns to fix missing data issue\nX= data.replace(0, np.NaN)\nX= data.fillna(data.mean(), inplace=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:02:46.528635Z","iopub.execute_input":"2021-07-26T16:02:46.529237Z","iopub.status.idle":"2021-07-26T16:02:46.544547Z","shell.execute_reply.started":"2021-07-26T16:02:46.529188Z","shell.execute_reply":"2021-07-26T16:02:46.543277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking at the data there are no null values but there are 0s where there should be actual values such as in insulin\n#first lets split the data\nX= data.drop(['Outcome'], axis=1)\nX= X.drop([0], axis=0)\ny= data['Outcome']\ny= y.drop([0], axis=0)\nprint(X.shape)\nprint(y.shape)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:02:49.770434Z","iopub.execute_input":"2021-07-26T16:02:49.770916Z","iopub.status.idle":"2021-07-26T16:02:49.780771Z","shell.execute_reply.started":"2021-07-26T16:02:49.770883Z","shell.execute_reply":"2021-07-26T16:02:49.779113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#splitting data into training and test sets \nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.33, random_state=42) #scaling the data \nscaler = MinMaxScaler(feature_range=(0, 1)) \nrescaledX_train = scaler.fit_transform(X_train) \nrescaledX_test = scaler.transform(X_test) \n#creating knn classifier \nknn = KNeighborsClassifier(algorithm= 'brute') \nparams= {'n_neighbors':[4,5,6,7], 'leaf_size':[1,3,5], 'n_jobs':[-1]}\ndiabetic1= GridSearchCV(knn, params,cv=5)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:02:49.789269Z","iopub.execute_input":"2021-07-26T16:02:49.789616Z","iopub.status.idle":"2021-07-26T16:02:49.808472Z","shell.execute_reply.started":"2021-07-26T16:02:49.789586Z","shell.execute_reply":"2021-07-26T16:02:49.80763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diabetic_cv= diabetic1.fit(X_train, y_train)\ny_pred= diabetic1.predict(X_test)\nscore = diabetic1.score(X_test, y_test)\n\nprint(\"Accuracy: {}\".format(score))\nprint(\"Tuned Model Parameters: {}\".format(diabetic1.best_params_))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:02:49.809703Z","iopub.execute_input":"2021-07-26T16:02:49.810124Z","iopub.status.idle":"2021-07-26T16:02:56.97412Z","shell.execute_reply.started":"2021-07-26T16:02:49.810082Z","shell.execute_reply":"2021-07-26T16:02:56.973363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#testing with rescaled data\ndiabetic_cv2= diabetic1.fit(rescaledX_train, y_train)\ny_pred2= diabetic1.predict(rescaledX_test)\nscore2 = diabetic1.score(rescaledX_test, y_test)\n\nprint(\"Accuracy: {}\".format(score))\nprint(\"Tuned Model Parameters: {}\".format(diabetic1.best_params_))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:02:56.975667Z","iopub.execute_input":"2021-07-26T16:02:56.976069Z","iopub.status.idle":"2021-07-26T16:03:03.827437Z","shell.execute_reply.started":"2021-07-26T16:02:56.976038Z","shell.execute_reply":"2021-07-26T16:03:03.826062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We observed that both the scaled and unscaled version of the model gives a 75.98% accuracy score hence using either version will give similar results\n#plotting the confusion matrix\nplot_confusion_matrix(diabetic_cv2, rescaledX_test, y_test)  \nplt.show()  \n#The confusion matrix shows that the model performs fairly well with decent recall and percision with a large amount of true positives and true negatives","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:03:03.829975Z","iopub.execute_input":"2021-07-26T16:03:03.83047Z","iopub.status.idle":"2021-07-26T16:03:04.128024Z","shell.execute_reply.started":"2021-07-26T16:03:03.830418Z","shell.execute_reply":"2021-07-26T16:03:04.127033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Though the model performs fairly well there is still room for improvement let's test if another classifiaction algorithm fits the data better\n\nlogreg= LogisticRegression()\n#parameters for the model\nc_space = np.logspace(-5, 8, 15)\nparams_log = {'C': c_space}\n#tuning the model\nlogreg_cv= GridSearchCV(logreg, params_log,cv=5)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:03:04.129485Z","iopub.execute_input":"2021-07-26T16:03:04.129807Z","iopub.status.idle":"2021-07-26T16:03:04.136821Z","shell.execute_reply.started":"2021-07-26T16:03:04.129774Z","shell.execute_reply":"2021-07-26T16:03:04.135493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diabetic3= logreg_cv.fit(rescaledX_train, y_train)\ny_pred3= logreg_cv.predict(rescaledX_test)\nR2 = logreg_cv.score(rescaledX_test, y_test)\n\nprint(\"Accuracy: {}\".format(R2))\nprint(\"Tuned Model Parameters: {}\".format(diabetic3.best_params_))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:03:04.138118Z","iopub.execute_input":"2021-07-26T16:03:04.138413Z","iopub.status.idle":"2021-07-26T16:03:04.746586Z","shell.execute_reply.started":"2021-07-26T16:03:04.138384Z","shell.execute_reply":"2021-07-26T16:03:04.745233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the Logistc regression model has a 79% accuraccy score meaning it fits the data better than the knn model\nplot_confusion_matrix(diabetic3, rescaledX_test, y_test)  \nplt.show() \n#The confusion matrix shows that the logreg model has higher percision but lower recall which is actually better for this type of data","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:03:04.748384Z","iopub.execute_input":"2021-07-26T16:03:04.748806Z","iopub.status.idle":"2021-07-26T16:03:04.929212Z","shell.execute_reply.started":"2021-07-26T16:03:04.748763Z","shell.execute_reply":"2021-07-26T16:03:04.927873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#best model for the data\n\nbest_tuned= LogisticRegression(C= 268.2695795279727)\nbest_tuned.fit(rescaledX_train, y_train)\nbest_pred= best_tuned.predict(rescaledX_test)\nprint('the predictions are {}'.format(best_pred))\nprint('the actual results are {}'.format(y_test))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:03:04.930605Z","iopub.execute_input":"2021-07-26T16:03:04.930905Z","iopub.status.idle":"2021-07-26T16:03:04.955763Z","shell.execute_reply.started":"2021-07-26T16:03:04.930876Z","shell.execute_reply":"2021-07-26T16:03:04.954391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the predictions are fairly accurate\npredictions = pd.DataFrame( best_pred).value_counts()\nanswers= pd.DataFrame(y_test).value_counts()\n#comparing predictions and actual answers with a bar graph\npredictions.plot(kind= 'bar', color='b', xlabel='outcome', title= 'predictions')\nplt.grid(linewidth=1)\nplt.show()\nanswers.plot(kind='bar', color='g', xlabel= 'outcome', title= 'True outcome')\nplt.grid(linewidth=1)\n#The graphs show that there are some wrong predictions but not a large amount of them, which coincides with the testing of the model\n#in conclusion this model is fairly accurate at predicting whether a patient has diabetes or not given the data provided","metadata":{"execution":{"iopub.status.busy":"2021-07-26T16:03:04.957906Z","iopub.execute_input":"2021-07-26T16:03:04.958248Z","iopub.status.idle":"2021-07-26T16:03:05.320644Z","shell.execute_reply.started":"2021-07-26T16:03:04.958212Z","shell.execute_reply":"2021-07-26T16:03:05.319412Z"},"trusted":true},"execution_count":null,"outputs":[]}]}