{"cells":[{"metadata":{},"cell_type":"markdown","source":"****Handwritten Digit Recognition using Keras and Python****"},{"metadata":{},"cell_type":"markdown","source":"This Notebook follows the below pipeline:\n\n1. Analyze the dataset\n2. Prepare the dataset\n3. Create the model\n4. Compile the model\n5. Fit the model\n6. Evaluate the model\n7. Summary"},{"metadata":{},"cell_type":"markdown","source":"***1. Analyze the dataset***"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Load libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n\n# Set the random seed\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 5 # Number of iterations needed for the network to minimize the loss function\nbatch_size = 128 \nnum_classes = 10 # Total number of class labels (0-9 digits)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the data\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data exploration\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data exploration\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*2. Prepare the dataset*"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"],axis = 1) \n\n# Frequency histogram of numbers in training data\nlabel_count = sns.countplot(Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Value counts\nunique, counts = np.unique(Y_train, return_counts=True)\ndata=dict(zip(unique, counts))\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Free some space\ndel train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalizing the data\nX_train = np.array(X_train / 255.0)\ntest = np.array(test / 255.0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reshape image in 3 dimensions\nX_train_view = X_train.reshape(X_train.shape[0], 28, 28)\n\n# Displaying some data from the train set\nplt.figure(figsize=(10, 10))\nplt.subplots_adjust(top=0.5)\n\nfor i in range(10):\n    plt.subplot(2, 5, (i+1))\n    plt.imshow(X_train_view[i])\n    plt.title('label:{}'.format(Y_train[i]));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.reshape(-1,28,28,1)\ntest = test.reshape(-1,28,28,1)\nY_train_data = Y_train\n\n# One-hot vector as a label (binarize the label)\nY_train = to_categorical(Y_train, num_classes = 10)\n\n# Split the train and the validation set for the fitting\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying some data from the test set\nX_test = np.reshape(np.array(test), (-1, 28, 28, 1))\nplt.figure(figsize=(10,10))\nplt.subplots_adjust(top=0.5)\nfor i in range(10):\n    plt.subplot(2, 5, i + 1)\n    plt.imshow(X_val[i].reshape(28, 28))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***3. Create the model***"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building a linear stack of layers with the sequential model\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***4. Compile the model***"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Improves parameters to minimise the loss\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# With data augmentation to prevent overfitting\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***5. Fit the model***"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),verbose = 2, \n                              steps_per_epoch=X_train.shape[0] // batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***6. Evaluate the model***"},{"metadata":{"trusted":true},"cell_type":"code","source":"history.history.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate the model\nscores = model.evaluate(X_val, Y_val, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history plot for accuracy\nplt.plot(history.history[\"acc\"])\nplt.plot(history.history[\"val_acc\"])\nplt.title(\"Model Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend([\"Training accuracy\", \"Test accuracy\"], loc=\"upper left\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history plot for accuracy\nplt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"val_loss\"])\nplt.title(\"Model Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend([\"Training loss\", \"Test loss\"], loc=\"upper left\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test loss:\", scores[0])\nprint(\"Test accuracy:\", scores[1])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix\ndef plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    plt.figure()\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Displaying errors*"},{"metadata":{"trusted":true},"cell_type":"code","source":"correct_indices = np.nonzero(Y_pred_classes == Y_true)[0]\nincorrect_indices = np.nonzero(Y_pred_classes != Y_true)[0]\nprint()\nprint(\"Classified correctly: \", len(correct_indices))\nprint(\"Classified incorrectly: \", len(incorrect_indices))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adapt figure size to accomodate 12 subplots\nplt.rcParams['figure.figsize'] = (7,14)\n\nfigure_evaluation = plt.figure()\n\n# plot 6 correct predictions\nfor i, correct in enumerate(correct_indices[:6]):\n    plt.subplot(6,3,i+1)\n    plt.imshow(X_val[correct].reshape(28,28))\n    plt.title(\n      \"Predicted: {}, Actual: {}\".format(Y_pred_classes[correct],\n                                        Y_true[correct]))\n    plt.xticks([])\n    plt.yticks([])\n\n# plot 6 incorrect predictions\nfor i, incorrect in enumerate(incorrect_indices[:6]):\n    plt.subplot(6,3,i+10)\n    plt.imshow(X_val[incorrect].reshape(28,28))\n    plt.title(\n      \"Predicted {}, Actual: {}\".format(Y_pred_classes[incorrect], \n                                       Y_true[incorrect]))\n    plt.xticks([])\n    plt.yticks([])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ***7. Summary***\nI have noticed that increasing the number of epochs improved accuracy of the model. In this notebook, the model reached 98.9% accuracy on the validation dataset after 5 epochs. The accuracy was computed on the 8400 testing examples and I used the model.evaluate() method to compute loss while compiling the model.  \n\nThe confusion matrix represents the relationship of misclassified digits. In this project, the most difficult digits to recognize are 4 and 9. \n\nAmong 8400 testing examples, 8308 were classified correcly and 92 incorrectly."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}