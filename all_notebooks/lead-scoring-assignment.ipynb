{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Lead Scoring Assignment","metadata":{}},{"cell_type":"markdown","source":"### Data Sourcing\n\n* We will import all libraries used in the entire assignment.\n* We will import the file in dataframe.\n* We will try to check basic information.","metadata":{}},{"cell_type":"markdown","source":"#### Importing libraries","metadata":{}},{"cell_type":"code","source":"# Importing basic libraries\nimport numpy as np\nimport pandas as pd\n\n# Importing libraries for data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Importing libraries for model preparing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Importing library for model building\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn import metrics\nfrom sklearn.metrics import recall_score\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.metrics import precision_recall_curve","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:47.228085Z","iopub.execute_input":"2021-08-12T05:41:47.228661Z","iopub.status.idle":"2021-08-12T05:41:49.465066Z","shell.execute_reply.started":"2021-08-12T05:41:47.228535Z","shell.execute_reply":"2021-08-12T05:41:49.463892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing libraries for removing warnings\nimport warnings as warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:49.466705Z","iopub.execute_input":"2021-08-12T05:41:49.467084Z","iopub.status.idle":"2021-08-12T05:41:49.471975Z","shell.execute_reply.started":"2021-08-12T05:41:49.467049Z","shell.execute_reply":"2021-08-12T05:41:49.470785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Sourcing File","metadata":{}},{"cell_type":"code","source":"# Importing the file\nleads_df = pd.read_csv(\"../input/leads-dataset/Leads.csv\")\nleads_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:49.474523Z","iopub.execute_input":"2021-08-12T05:41:49.474998Z","iopub.status.idle":"2021-08-12T05:41:49.756446Z","shell.execute_reply.started":"2021-08-12T05:41:49.474953Z","shell.execute_reply":"2021-08-12T05:41:49.755347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Checking information","metadata":{}},{"cell_type":"code","source":"# Checking Shape\nleads_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:49.758362Z","iopub.execute_input":"2021-08-12T05:41:49.758814Z","iopub.status.idle":"2021-08-12T05:41:49.765782Z","shell.execute_reply.started":"2021-08-12T05:41:49.758769Z","shell.execute_reply":"2021-08-12T05:41:49.764777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking other values\nleads_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:49.767194Z","iopub.execute_input":"2021-08-12T05:41:49.767606Z","iopub.status.idle":"2021-08-12T05:41:49.816509Z","shell.execute_reply.started":"2021-08-12T05:41:49.767561Z","shell.execute_reply":"2021-08-12T05:41:49.815224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking columns details\nleads_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:49.818106Z","iopub.execute_input":"2021-08-12T05:41:49.818536Z","iopub.status.idle":"2021-08-12T05:41:49.865618Z","shell.execute_reply.started":"2021-08-12T05:41:49.818493Z","shell.execute_reply":"2021-08-12T05:41:49.864654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Cleaning\n- We will try to change 'Select' values of the columns to <i>NAN</i>.\n- We will try to drop columns having 35% missing values.\n- We will try to drop rows having 70% missing values\n- We will try to merge unique categories if they are multiples.\n- We will impute the missing values\n    * Categorical with mode value\n    * Continuous with median value\n- We will compare orginal with cleaned data","metadata":{}},{"cell_type":"markdown","source":"#### Dropping Duplicates & Basic Cleaning","metadata":{}},{"cell_type":"code","source":"# Calculating the shape after removing duplicates\nleads_modified_df = leads_df.drop_duplicates(keep = 'first')\nleads_modified_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:49.867Z","iopub.execute_input":"2021-08-12T05:41:49.867291Z","iopub.status.idle":"2021-08-12T05:41:49.916318Z","shell.execute_reply.started":"2021-08-12T05:41:49.867264Z","shell.execute_reply":"2021-08-12T05:41:49.915182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Note :-</b> No duplicate values found.","metadata":{}},{"cell_type":"code","source":"# Removing columns of no significance\nleads_modified_df.drop(['Prospect ID', 'Lead Number'], axis=1, inplace=True)\nleads_modified_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:49.918782Z","iopub.execute_input":"2021-08-12T05:41:49.91911Z","iopub.status.idle":"2021-08-12T05:41:49.930501Z","shell.execute_reply.started":"2021-08-12T05:41:49.919081Z","shell.execute_reply":"2021-08-12T05:41:49.929684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Change the mapping of a column\nleads_modified_df['A free copy of Mastering The Interview'] = leads_modified_df['A free copy of Mastering The Interview'].map({'Yes':1, 'No':0})\nleads_modified_df['A free copy of Mastering The Interview'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:49.932336Z","iopub.execute_input":"2021-08-12T05:41:49.932875Z","iopub.status.idle":"2021-08-12T05:41:49.951091Z","shell.execute_reply.started":"2021-08-12T05:41:49.932832Z","shell.execute_reply":"2021-08-12T05:41:49.949961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Handle the “Select” level that is present in many of the categorical variables.","metadata":{}},{"cell_type":"code","source":"# Replacing the 'Select' with NaN\nleads_modified_df.replace('Select', np.NAN, inplace=True)\nleads_modified_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:49.952552Z","iopub.execute_input":"2021-08-12T05:41:49.95289Z","iopub.status.idle":"2021-08-12T05:41:50.006637Z","shell.execute_reply.started":"2021-08-12T05:41:49.952861Z","shell.execute_reply":"2021-08-12T05:41:50.005603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Drop columns that are having high percentage of missing values.","metadata":{}},{"cell_type":"code","source":"# Calculating % of missing values\nround(leads_modified_df.isnull().sum() * 100 / len(leads_modified_df), 2)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:50.008054Z","iopub.execute_input":"2021-08-12T05:41:50.008459Z","iopub.status.idle":"2021-08-12T05:41:50.065284Z","shell.execute_reply.started":"2021-08-12T05:41:50.008427Z","shell.execute_reply":"2021-08-12T05:41:50.064112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to remove the columns having more than threshold values\ndef rmissingvaluecol(dff, threshold):\n    col = []\n    col = list(dff.drop(dff.loc[:,list((100*(dff.isnull().sum()/len(dff.index)) >= threshold))].columns, 1).columns.values)\n    print(\"Columns having more than %s percent missing values: \"%threshold, (dff.shape[1] - len(col)))\n    print(\"Columns to be dropped                             : \", list(set(list((dff.columns.values))) - set(col)))\n    return col\n\n# Removing columns having 40% missing values\ncol = rmissingvaluecol(leads_modified_df, 40)\nleads_modified_df = leads_modified_df[col]\nleads_modified_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:50.06648Z","iopub.execute_input":"2021-08-12T05:41:50.066872Z","iopub.status.idle":"2021-08-12T05:41:50.1483Z","shell.execute_reply.started":"2021-08-12T05:41:50.066773Z","shell.execute_reply":"2021-08-12T05:41:50.14732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Note :-</b> 7 columns removed.","metadata":{}},{"cell_type":"markdown","source":"#### Drop rows that are having high percentage of missing values.","metadata":{}},{"cell_type":"code","source":"# Deleting rows containing either 70% or more than 70% NaN Values\nperc = 70.0 # Here N is 70\nmin_count =  int(((100-perc)/100)*leads_modified_df.shape[1] + 1)\nleads_modified_df = leads_modified_df.dropna(axis=0, thresh=min_count)\nleads_modified_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:50.149497Z","iopub.execute_input":"2021-08-12T05:41:50.149784Z","iopub.status.idle":"2021-08-12T05:41:50.184258Z","shell.execute_reply.started":"2021-08-12T05:41:50.149758Z","shell.execute_reply":"2021-08-12T05:41:50.183064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Note :-</b> No rows deleted.","metadata":{}},{"cell_type":"markdown","source":"####  Check the number of unique categories in each categorical column.","metadata":{}},{"cell_type":"code","source":"# Checking the unique categories\ncolumns_not_to_be_considered = ['Converted', 'TotalVisits', 'Total Time Spent on Website', 'Page Views Per Visit'] #Continous Values\ncolumn_names = leads_modified_df.columns\ncolumn_names = column_names.drop(columns_not_to_be_considered)\n\nfor column_name in column_names:\n    print(\"Column Name        :\", column_name)\n    print(\"------------------------------------------\")\n    print(leads_modified_df[column_name].value_counts(normalize=True, dropna=False)*100)\n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:50.185562Z","iopub.execute_input":"2021-08-12T05:41:50.18588Z","iopub.status.idle":"2021-08-12T05:41:50.311009Z","shell.execute_reply.started":"2021-08-12T05:41:50.185852Z","shell.execute_reply":"2021-08-12T05:41:50.309818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing columns of highly skewed data\nskewed_columns_to_be_dropped = ['Do Not Email', 'Do Not Call', 'Search', 'Magazine', 'Newspaper Article', 'X Education Forums',\n                                'Newspaper', 'Digital Advertisement', 'Through Recommendations', \n                                'Receive More Updates About Our Courses', 'Update me on Supply Chain Content',\n                                'Get updates on DM Content', 'I agree to pay the amount through cheque' ]\n\nleads_modified_df.drop(skewed_columns_to_be_dropped, axis=1, inplace=True)\nleads_modified_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:50.312272Z","iopub.execute_input":"2021-08-12T05:41:50.312558Z","iopub.status.idle":"2021-08-12T05:41:50.322124Z","shell.execute_reply.started":"2021-08-12T05:41:50.312531Z","shell.execute_reply":"2021-08-12T05:41:50.321151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Note :-</b> A few columns are removed as they may skew the model.","metadata":{}},{"cell_type":"markdown","source":"#### For the columns with less percentage of missing, use some imputation technique.","metadata":{}},{"cell_type":"code","source":"# Listing down categorical columns with missing values\ncategorical_column_names = ['Lead Source', 'Last Activity', 'Country',  'City',\n                'What is your current occupation', 'What matters most to you in choosing a course']\n\nfor column_name in categorical_column_names:\n    print(\"Column Name        :\", column_name)\n    print(\"------------------------------\")\n    print(\"Unique Values      : \", leads_modified_df[column_name].unique())\n    \n    values_to_be_imputed = leads_modified_df[column_name].isnull().sum()\n    print(\"Any Null (Before)  :\", values_to_be_imputed)\n    \n    leads_modified_df[column_name].fillna(leads_modified_df[column_name].mode()[0], inplace=True)\n    print(values_to_be_imputed, \" values imputed with mode values of the column.\")\n    \n    print(\"Null Values (After):\", leads_modified_df[column_name].isnull().sum())\n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:50.324413Z","iopub.execute_input":"2021-08-12T05:41:50.324725Z","iopub.status.idle":"2021-08-12T05:41:50.385633Z","shell.execute_reply.started":"2021-08-12T05:41:50.324696Z","shell.execute_reply":"2021-08-12T05:41:50.382147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imputing the 'NAN' of 'Specialization' with 'Unspecified' \n\nprint(\"Values to be imputed : \", leads_modified_df.Specialization.isnull().sum())\n\nleads_modified_df.Specialization.fillna(\"Unspecified\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:50.387475Z","iopub.execute_input":"2021-08-12T05:41:50.387973Z","iopub.status.idle":"2021-08-12T05:41:50.39868Z","shell.execute_reply.started":"2021-08-12T05:41:50.387926Z","shell.execute_reply":"2021-08-12T05:41:50.397638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the unique categories\ncolumns_not_to_be_considered = ['Converted', 'TotalVisits', 'Total Time Spent on Website', 'Page Views Per Visit']\ncolumn_names = leads_modified_df.columns\ncolumn_names = column_names.drop(columns_not_to_be_considered)\n\nfor column_name in column_names:\n    print(\"Column Name        :\", column_name)\n    print(\"-----------------------------------------------------\")\n    print(leads_modified_df[column_name].value_counts(normalize=True, dropna=False)*100)\n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:50.400077Z","iopub.execute_input":"2021-08-12T05:41:50.400363Z","iopub.status.idle":"2021-08-12T05:41:50.466518Z","shell.execute_reply.started":"2021-08-12T05:41:50.400334Z","shell.execute_reply":"2021-08-12T05:41:50.46321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing columns of highly skewed data\nskewed_columns_to_be_dropped = ['Country', 'What is your current occupation', 'What matters most to you in choosing a course']\n\nleads_modified_df.drop(skewed_columns_to_be_dropped, axis=1, inplace=True)\nleads_modified_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:50.468124Z","iopub.execute_input":"2021-08-12T05:41:50.468561Z","iopub.status.idle":"2021-08-12T05:41:50.479137Z","shell.execute_reply.started":"2021-08-12T05:41:50.468517Z","shell.execute_reply":"2021-08-12T05:41:50.477966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Changing categories with lesser percentage to 'others'\n\ndef change_to_others(x, value_counts_df):\n    for key, val in value_counts_df.to_dict().items():\n        if key == x and val < 10:\n            return 'others'\n    return x\n\ncolumns_to_be_changed = ['Lead Origin', 'Lead Source', 'Last Activity', 'Specialization', 'City',\n                         'A free copy of Mastering The Interview', 'Last Notable Activity']\n\nfor column_name in columns_to_be_changed:\n    print(\"Column Name : \", column_name)\n    print(\"-----------------------------------------\")\n\n    value_counts_df = leads_modified_df[column_name].value_counts(normalize=True) * 100\n    print(\"Before :\")\n    print(value_counts_df)\n    print('\\n')\n\n    leads_modified_df[column_name] = leads_modified_df[column_name].apply(lambda x:change_to_others(x, value_counts_df))\n    value_counts_df = leads_modified_df[column_name].value_counts(normalize=True) * 100\n    print(\"After :\")\n    print(value_counts_df)\n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:50.480826Z","iopub.execute_input":"2021-08-12T05:41:50.481453Z","iopub.status.idle":"2021-08-12T05:41:51.411087Z","shell.execute_reply.started":"2021-08-12T05:41:50.481405Z","shell.execute_reply":"2021-08-12T05:41:51.40983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Listing down continuos columns with missing values\ncategorical_column_names = ['TotalVisits', 'Page Views Per Visit']\n\nfor column_name in categorical_column_names:\n    print(\"Column Name        :\", column_name)\n    print(\"------------------------------\")\n    values_to_be_imputed = leads_modified_df[column_name].isnull().sum()\n    print(\"Any Null (Before)  :\", values_to_be_imputed)\n    \n    leads_modified_df[column_name].fillna(leads_modified_df[column_name].median(), inplace=True)\n    print(values_to_be_imputed, \" values imputed with mode values of the column.\")\n    \n    print(\"Null Values (After):\", leads_modified_df[column_name].isnull().sum())\n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:51.412276Z","iopub.execute_input":"2021-08-12T05:41:51.412578Z","iopub.status.idle":"2021-08-12T05:41:51.425996Z","shell.execute_reply.started":"2021-08-12T05:41:51.412549Z","shell.execute_reply":"2021-08-12T05:41:51.424749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Changing the datatype of a column\nleads_modified_df['TotalVisits'] = leads_modified_df['TotalVisits'].astype(int)\nleads_modified_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:51.427192Z","iopub.execute_input":"2021-08-12T05:41:51.427504Z","iopub.status.idle":"2021-08-12T05:41:51.449623Z","shell.execute_reply.started":"2021-08-12T05:41:51.427473Z","shell.execute_reply":"2021-08-12T05:41:51.448723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping a few more columns\nleads_modified_df.drop(['Last Activity', 'Last Notable Activity', 'Tags'], axis=1, inplace=True)\nleads_modified_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:51.454656Z","iopub.execute_input":"2021-08-12T05:41:51.455325Z","iopub.status.idle":"2021-08-12T05:41:51.46427Z","shell.execute_reply.started":"2021-08-12T05:41:51.45529Z","shell.execute_reply":"2021-08-12T05:41:51.46326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verifying various parameters after cleaning\nprint(\"Before Cleaning Data\")\nprint(\"*********************************\")\nprint(\"Shape: \", leads_df.shape)\nprint(\"Missing:\")\nprint(\"-----------------------\")\nprint(round(leads_df.isnull().sum()*100/len(leads_df), 2))\n\nprint('\\n')\nprint(\"After Cleaning Data\")\nprint(\"*********************************\")\nprint(\"Shape: \", leads_modified_df.shape)\nprint(\"Missing:\")\nprint(\"-----------------------\")\nprint(round(leads_modified_df.isnull().sum()*100/len(leads_modified_df), 2))","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:51.46988Z","iopub.execute_input":"2021-08-12T05:41:51.470182Z","iopub.status.idle":"2021-08-12T05:41:51.51995Z","shell.execute_reply.started":"2021-08-12T05:41:51.470152Z","shell.execute_reply":"2021-08-12T05:41:51.518721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Analysis\n- Analyzing a few continuous columns\n- Analyzing a few categorical columns","metadata":{}},{"cell_type":"code","source":"# Visualizing continuous data\nplt.figure(figsize=(20,15))\n\nplt.subplot(2,1,1)\nplt.title(\"Total Visits\", fontsize=25)\ngraph1 = sns.countplot(x='TotalVisits', data=leads_modified_df)\ngraph1.set(xlabel=None)\n\nplt.subplot(2,1,2)\nplt.title(\"Total Time Spent on Website\", fontsize=25)\ngraph2 = sns.distplot(leads_modified_df['Total Time Spent on Website'], bins=100)\ngraph2.set(xlabel=None)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:51.521313Z","iopub.execute_input":"2021-08-12T05:41:51.521606Z","iopub.status.idle":"2021-08-12T05:41:52.604101Z","shell.execute_reply.started":"2021-08-12T05:41:51.521562Z","shell.execute_reply":"2021-08-12T05:41:52.602975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing catgorical data\nplt.figure(figsize=(15,6))\n\nplt.subplot(1,2,1)\nplt.title(\"Lead Source vs Total Visits\", fontsize=15)\ngrpah1 = sns.boxplot(x=\"Lead Source\", y=\"TotalVisits\", data=leads_modified_df)\ngraph1.set(xlabel=None)\n\nplt.subplot(1,2,2)\nplt.title(\"Lead Source vs Total Time Spent on Website\", fontsize=15)\ngrpah2 = sns.boxplot(x=\"Lead Source\", y=\"Total Time Spent on Website\", data=leads_modified_df)\ngraph2.set(xlabel=None)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:52.60542Z","iopub.execute_input":"2021-08-12T05:41:52.605763Z","iopub.status.idle":"2021-08-12T05:41:53.040348Z","shell.execute_reply.started":"2021-08-12T05:41:52.605729Z","shell.execute_reply":"2021-08-12T05:41:53.038944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Preparation\n- We will create dummies for categorical columns.\n- We will split data into train-test set.\n- We will perform scaling.","metadata":{}},{"cell_type":"markdown","source":"#### Create dummies for all categorical columns.","metadata":{}},{"cell_type":"code","source":"# Imputing season as categorical 'season' values\ncolumn_names = ['Lead Source', 'Lead Origin', 'Specialization', 'City']\n\nfor column_name in column_names:\n    dummies = pd.get_dummies(leads_modified_df[column_name])\n    dummies.drop('others', axis=1, inplace=True)\n    leads_modified_df = pd.concat([leads_modified_df, dummies], axis=1)\n    leads_modified_df.drop(column_name, axis=1, inplace=True)\n    print(\"Dummies created for: \", column_name)\n\nleads_modified_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:53.041815Z","iopub.execute_input":"2021-08-12T05:41:53.04226Z","iopub.status.idle":"2021-08-12T05:41:53.088222Z","shell.execute_reply.started":"2021-08-12T05:41:53.042219Z","shell.execute_reply":"2021-08-12T05:41:53.087362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Splitting the data into train-test set","metadata":{}},{"cell_type":"code","source":"# Putting feature variable to X\nX = leads_modified_df.drop('Converted', axis=1)\n\nX.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:53.08946Z","iopub.execute_input":"2021-08-12T05:41:53.089782Z","iopub.status.idle":"2021-08-12T05:41:53.106054Z","shell.execute_reply.started":"2021-08-12T05:41:53.089752Z","shell.execute_reply":"2021-08-12T05:41:53.105359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Putting response variable to y\ny = leads_modified_df.Converted\n\ny.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:53.107044Z","iopub.execute_input":"2021-08-12T05:41:53.107444Z","iopub.status.idle":"2021-08-12T05:41:53.114752Z","shell.execute_reply.started":"2021-08-12T05:41:53.107416Z","shell.execute_reply":"2021-08-12T05:41:53.113875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the data into train and test on a ratio of 70-30\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:53.115936Z","iopub.execute_input":"2021-08-12T05:41:53.116207Z","iopub.status.idle":"2021-08-12T05:41:53.12917Z","shell.execute_reply.started":"2021-08-12T05:41:53.11618Z","shell.execute_reply":"2021-08-12T05:41:53.12843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Scaling the continuous data","metadata":{}},{"cell_type":"code","source":"# Initializing the scaler and scaling the data\nscaler = StandardScaler()\n\ncolumns_to_be_scaled = ['TotalVisits','Total Time Spent on Website','Page Views Per Visit']\nX_train[columns_to_be_scaled] = scaler.fit_transform(X_train[columns_to_be_scaled])\n\nX_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:53.130266Z","iopub.execute_input":"2021-08-12T05:41:53.130704Z","iopub.status.idle":"2021-08-12T05:41:53.169041Z","shell.execute_reply.started":"2021-08-12T05:41:53.130675Z","shell.execute_reply":"2021-08-12T05:41:53.168325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the Converted Rate\nconverted = round((sum(leads_modified_df['Converted'])/len(leads_modified_df['Converted'].index))*100, 2)\nconverted","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:53.169999Z","iopub.execute_input":"2021-08-12T05:41:53.1704Z","iopub.status.idle":"2021-08-12T05:41:53.177785Z","shell.execute_reply.started":"2021-08-12T05:41:53.170371Z","shell.execute_reply":"2021-08-12T05:41:53.176634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's see the correlation matrix \nplt.figure(figsize = (20,10))        # Size of the figure\nsns.heatmap(leads_modified_df.corr(), annot = True, cmap=\"Blues\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:53.179031Z","iopub.execute_input":"2021-08-12T05:41:53.179331Z","iopub.status.idle":"2021-08-12T05:41:54.419306Z","shell.execute_reply.started":"2021-08-12T05:41:53.179303Z","shell.execute_reply":"2021-08-12T05:41:54.418032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Building\n- We will try to build our first.\n- We will use RFE to know how much parameters can be considered.\n- We will iteratively remove columns either having high <b>p</b> or <b>VIF</b>.","metadata":{}},{"cell_type":"markdown","source":"#### Building our first model ","metadata":{}},{"cell_type":"code","source":"# Logistic regression model\nlogm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\nlogm1.fit().summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:54.421126Z","iopub.execute_input":"2021-08-12T05:41:54.421616Z","iopub.status.idle":"2021-08-12T05:41:54.517814Z","shell.execute_reply.started":"2021-08-12T05:41:54.421547Z","shell.execute_reply":"2021-08-12T05:41:54.516345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Running RFE to check parameter significance","metadata":{}},{"cell_type":"code","source":"# Initializing LogisticRegression\nlogreg = LogisticRegression()\n\n# Running RFE with 12 variables as output\nrfe = RFE(logreg, 12)             \nrfe = rfe.fit(X_train, y_train)\n\n# Listing the columns\nlist(zip(X_train.columns, rfe.support_, rfe.ranking_))","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:54.519709Z","iopub.execute_input":"2021-08-12T05:41:54.520373Z","iopub.status.idle":"2021-08-12T05:41:54.685993Z","shell.execute_reply.started":"2021-08-12T05:41:54.520325Z","shell.execute_reply":"2021-08-12T05:41:54.684921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Listing down the columns important for building a model\ncol = X_train.columns[rfe.support_]\n\n# Listing down the columns not important\nX_train.columns[~rfe.support_]","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:54.68762Z","iopub.execute_input":"2021-08-12T05:41:54.688262Z","iopub.status.idle":"2021-08-12T05:41:54.697545Z","shell.execute_reply.started":"2021-08-12T05:41:54.688217Z","shell.execute_reply":"2021-08-12T05:41:54.696475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Note:</b> Since we have 13 columns remaining and we chose to find RFE on 12, that's why we have one column to be discarded i.e <i>Mumbai</i>. ","metadata":{}},{"cell_type":"markdown","source":"#### Building our second model","metadata":{}},{"cell_type":"code","source":"# Building our second model\nX_train_sm = sm.add_constant(X_train[col])\nlogm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm2.fit()\nres.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:54.69947Z","iopub.execute_input":"2021-08-12T05:41:54.700311Z","iopub.status.idle":"2021-08-12T05:41:54.78577Z","shell.execute_reply.started":"2021-08-12T05:41:54.700247Z","shell.execute_reply":"2021-08-12T05:41:54.784702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting the predicted values on the train set\ny_train_pred = res.predict(X_train_sm).values.reshape(-1)\ny_train_pred[:10]","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:54.787466Z","iopub.execute_input":"2021-08-12T05:41:54.788194Z","iopub.status.idle":"2021-08-12T05:41:54.801778Z","shell.execute_reply.started":"2021-08-12T05:41:54.788146Z","shell.execute_reply":"2021-08-12T05:41:54.800509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Forming prediction table \ny_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Converted_Prob':y_train_pred})\ny_train_pred_final['LeadId'] = y_train.index\ny_train_pred_final.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:54.803508Z","iopub.execute_input":"2021-08-12T05:41:54.804573Z","iopub.status.idle":"2021-08-12T05:41:54.824448Z","shell.execute_reply.started":"2021-08-12T05:41:54.804523Z","shell.execute_reply":"2021-08-12T05:41:54.823437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred_final['Predicted'] = y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.5 else 0)\n\n# Let's see the head\ny_train_pred_final.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:54.826108Z","iopub.execute_input":"2021-08-12T05:41:54.826799Z","iopub.status.idle":"2021-08-12T05:41:54.85421Z","shell.execute_reply.started":"2021-08-12T05:41:54.826752Z","shell.execute_reply":"2021-08-12T05:41:54.85316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted)\nprint(confusion)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:54.856146Z","iopub.execute_input":"2021-08-12T05:41:54.856893Z","iopub.status.idle":"2021-08-12T05:41:54.886059Z","shell.execute_reply.started":"2021-08-12T05:41:54.856841Z","shell.execute_reply":"2021-08-12T05:41:54.884949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check the overall report.\nprint(metrics.classification_report(y_train_pred_final.Converted, y_train_pred_final.Predicted))","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:54.887835Z","iopub.execute_input":"2021-08-12T05:41:54.888642Z","iopub.status.idle":"2021-08-12T05:41:54.918625Z","shell.execute_reply.started":"2021-08-12T05:41:54.888571Z","shell.execute_reply":"2021-08-12T05:41:54.917787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train[col].columns\nvif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:54.919942Z","iopub.execute_input":"2021-08-12T05:41:54.92046Z","iopub.status.idle":"2021-08-12T05:41:55.057205Z","shell.execute_reply.started":"2021-08-12T05:41:54.920425Z","shell.execute_reply":"2021-08-12T05:41:55.05595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping a column which is least impactful\ncol = col.drop('Direct Traffic', 1)\ncol","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.059409Z","iopub.execute_input":"2021-08-12T05:41:55.060373Z","iopub.status.idle":"2021-08-12T05:41:55.070691Z","shell.execute_reply.started":"2021-08-12T05:41:55.060308Z","shell.execute_reply":"2021-08-12T05:41:55.069448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Building our third model","metadata":{}},{"cell_type":"code","source":"# Let's re-run the model using the selected variables\nX_train_sm = sm.add_constant(X_train[col])\nlogm3 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm3.fit()\nres.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.072761Z","iopub.execute_input":"2021-08-12T05:41:55.073682Z","iopub.status.idle":"2021-08-12T05:41:55.157Z","shell.execute_reply.started":"2021-08-12T05:41:55.073624Z","shell.execute_reply":"2021-08-12T05:41:55.155832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred = res.predict(X_train_sm).values.reshape(-1)\ny_train_pred[:10]","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.158696Z","iopub.execute_input":"2021-08-12T05:41:55.1594Z","iopub.status.idle":"2021-08-12T05:41:55.173915Z","shell.execute_reply.started":"2021-08-12T05:41:55.159348Z","shell.execute_reply":"2021-08-12T05:41:55.172796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred_final['Converted_Prob'] = y_train_pred\n\n# Creating new column 'predicted' with 1 if Churn_Prob > 0.5 else 0\ny_train_pred_final['Predicted'] = y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.5 else 0)\ny_train_pred_final.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.175797Z","iopub.execute_input":"2021-08-12T05:41:55.176733Z","iopub.status.idle":"2021-08-12T05:41:55.204674Z","shell.execute_reply.started":"2021-08-12T05:41:55.176672Z","shell.execute_reply":"2021-08-12T05:41:55.203541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted)\nprint(confusion)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.206544Z","iopub.execute_input":"2021-08-12T05:41:55.207356Z","iopub.status.idle":"2021-08-12T05:41:55.233681Z","shell.execute_reply.started":"2021-08-12T05:41:55.207302Z","shell.execute_reply":"2021-08-12T05:41:55.232501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check the overall accuracy.\nprint(metrics.classification_report(y_train_pred_final.Converted, y_train_pred_final.Predicted))","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.235545Z","iopub.execute_input":"2021-08-12T05:41:55.236346Z","iopub.status.idle":"2021-08-12T05:41:55.271186Z","shell.execute_reply.started":"2021-08-12T05:41:55.236293Z","shell.execute_reply":"2021-08-12T05:41:55.269689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train[col].columns\nvif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.273348Z","iopub.execute_input":"2021-08-12T05:41:55.274306Z","iopub.status.idle":"2021-08-12T05:41:55.39565Z","shell.execute_reply.started":"2021-08-12T05:41:55.274225Z","shell.execute_reply":"2021-08-12T05:41:55.394359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping a column which is least significant\ncol = col.drop('Page Views Per Visit', 1)\ncol","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.397766Z","iopub.execute_input":"2021-08-12T05:41:55.398713Z","iopub.status.idle":"2021-08-12T05:41:55.409221Z","shell.execute_reply.started":"2021-08-12T05:41:55.398654Z","shell.execute_reply":"2021-08-12T05:41:55.407942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Building our fourth model","metadata":{}},{"cell_type":"code","source":"# Let's re-run the model using the selected variables\nX_train_sm = sm.add_constant(X_train[col])\nlogm4 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm4.fit()\nres.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.411366Z","iopub.execute_input":"2021-08-12T05:41:55.412339Z","iopub.status.idle":"2021-08-12T05:41:55.49666Z","shell.execute_reply.started":"2021-08-12T05:41:55.412266Z","shell.execute_reply":"2021-08-12T05:41:55.495455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred = res.predict(X_train_sm).values.reshape(-1)\ny_train_pred[:10]","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.498717Z","iopub.execute_input":"2021-08-12T05:41:55.499684Z","iopub.status.idle":"2021-08-12T05:41:55.5142Z","shell.execute_reply.started":"2021-08-12T05:41:55.499625Z","shell.execute_reply":"2021-08-12T05:41:55.512715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred_final['Converted_Prob'] = y_train_pred\n\n# Creating new column 'predicted' with 1 if Churn_Prob > 0.5 else 0\ny_train_pred_final['Predicted'] = y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.5 else 0)\ny_train_pred_final.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.516543Z","iopub.execute_input":"2021-08-12T05:41:55.517524Z","iopub.status.idle":"2021-08-12T05:41:55.547072Z","shell.execute_reply.started":"2021-08-12T05:41:55.517468Z","shell.execute_reply":"2021-08-12T05:41:55.545944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted)\nprint(confusion)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.549004Z","iopub.execute_input":"2021-08-12T05:41:55.54986Z","iopub.status.idle":"2021-08-12T05:41:55.57793Z","shell.execute_reply.started":"2021-08-12T05:41:55.549795Z","shell.execute_reply":"2021-08-12T05:41:55.576688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check the overall accuracy.\nprint(metrics.classification_report(y_train_pred_final.Converted, y_train_pred_final.Predicted))","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.580209Z","iopub.execute_input":"2021-08-12T05:41:55.581174Z","iopub.status.idle":"2021-08-12T05:41:55.619518Z","shell.execute_reply.started":"2021-08-12T05:41:55.581114Z","shell.execute_reply":"2021-08-12T05:41:55.618327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train[col].columns\nvif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.621146Z","iopub.execute_input":"2021-08-12T05:41:55.621668Z","iopub.status.idle":"2021-08-12T05:41:55.725295Z","shell.execute_reply.started":"2021-08-12T05:41:55.621633Z","shell.execute_reply":"2021-08-12T05:41:55.724051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping one more column which is least significant\ncol = col.drop('Finance Management', 1)\ncol","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.727393Z","iopub.execute_input":"2021-08-12T05:41:55.728363Z","iopub.status.idle":"2021-08-12T05:41:55.738642Z","shell.execute_reply.started":"2021-08-12T05:41:55.728304Z","shell.execute_reply":"2021-08-12T05:41:55.737416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Building our fifth model","metadata":{}},{"cell_type":"code","source":"# Let's re-run the model using the selected variables\nX_train_sm = sm.add_constant(X_train[col])\nlogm5 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm5.fit()\nres.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.740753Z","iopub.execute_input":"2021-08-12T05:41:55.74167Z","iopub.status.idle":"2021-08-12T05:41:55.819107Z","shell.execute_reply.started":"2021-08-12T05:41:55.741611Z","shell.execute_reply":"2021-08-12T05:41:55.817792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred = res.predict(X_train_sm).values.reshape(-1)\ny_train_pred[:10]","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.821646Z","iopub.execute_input":"2021-08-12T05:41:55.822713Z","iopub.status.idle":"2021-08-12T05:41:55.837612Z","shell.execute_reply.started":"2021-08-12T05:41:55.822638Z","shell.execute_reply":"2021-08-12T05:41:55.836169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred_final['Converted_Prob'] = y_train_pred\n\n# Creating new column 'predicted' with 1 if Churn_Prob > 0.5 else 0\ny_train_pred_final['Predicted'] = y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.5 else 0)\ny_train_pred_final.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.839957Z","iopub.execute_input":"2021-08-12T05:41:55.840983Z","iopub.status.idle":"2021-08-12T05:41:55.872956Z","shell.execute_reply.started":"2021-08-12T05:41:55.840916Z","shell.execute_reply":"2021-08-12T05:41:55.871758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted)\nprint(confusion)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.878304Z","iopub.execute_input":"2021-08-12T05:41:55.881621Z","iopub.status.idle":"2021-08-12T05:41:55.912323Z","shell.execute_reply.started":"2021-08-12T05:41:55.881529Z","shell.execute_reply":"2021-08-12T05:41:55.911019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check the overall accuracy.\nprint(metrics.classification_report(y_train_pred_final.Converted, y_train_pred_final.Predicted))","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.918056Z","iopub.execute_input":"2021-08-12T05:41:55.921301Z","iopub.status.idle":"2021-08-12T05:41:55.955363Z","shell.execute_reply.started":"2021-08-12T05:41:55.921212Z","shell.execute_reply":"2021-08-12T05:41:55.954065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train[col].columns\nvif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:55.95692Z","iopub.execute_input":"2021-08-12T05:41:55.95734Z","iopub.status.idle":"2021-08-12T05:41:56.058168Z","shell.execute_reply.started":"2021-08-12T05:41:55.957298Z","shell.execute_reply":"2021-08-12T05:41:56.056646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping one more column which is least significant\ncol = col.drop('Organic Search', 1)\ncol","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:56.06427Z","iopub.execute_input":"2021-08-12T05:41:56.064805Z","iopub.status.idle":"2021-08-12T05:41:56.081983Z","shell.execute_reply.started":"2021-08-12T05:41:56.064758Z","shell.execute_reply":"2021-08-12T05:41:56.080755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Building our sixth model","metadata":{}},{"cell_type":"code","source":"# Let's re-run the model using the selected variables\nX_train_sm = sm.add_constant(X_train[col])\nlogm6 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm6.fit()\nres.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:56.086318Z","iopub.execute_input":"2021-08-12T05:41:56.090601Z","iopub.status.idle":"2021-08-12T05:41:56.164799Z","shell.execute_reply.started":"2021-08-12T05:41:56.090514Z","shell.execute_reply":"2021-08-12T05:41:56.163692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred = res.predict(X_train_sm).values.reshape(-1)\ny_train_pred[:10]","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:56.17842Z","iopub.execute_input":"2021-08-12T05:41:56.18201Z","iopub.status.idle":"2021-08-12T05:41:56.197357Z","shell.execute_reply.started":"2021-08-12T05:41:56.181936Z","shell.execute_reply":"2021-08-12T05:41:56.196208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred_final['Converted_Prob'] = y_train_pred\n\n# Creating new column 'predicted' with 1 if Churn_Prob > 0.5 else 0\ny_train_pred_final['Predicted'] = y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.5 else 0)\ny_train_pred_final.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:56.204037Z","iopub.execute_input":"2021-08-12T05:41:56.207033Z","iopub.status.idle":"2021-08-12T05:41:56.240199Z","shell.execute_reply.started":"2021-08-12T05:41:56.206962Z","shell.execute_reply":"2021-08-12T05:41:56.239036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted)\nprint(confusion)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:56.245907Z","iopub.execute_input":"2021-08-12T05:41:56.249014Z","iopub.status.idle":"2021-08-12T05:41:56.280584Z","shell.execute_reply.started":"2021-08-12T05:41:56.248943Z","shell.execute_reply":"2021-08-12T05:41:56.279426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check the overall report.\nprint(metrics.classification_report(y_train_pred_final.Converted, y_train_pred_final.Predicted))","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:56.286419Z","iopub.execute_input":"2021-08-12T05:41:56.289763Z","iopub.status.idle":"2021-08-12T05:41:56.318895Z","shell.execute_reply.started":"2021-08-12T05:41:56.289688Z","shell.execute_reply":"2021-08-12T05:41:56.31781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train[col].columns\nvif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:56.320387Z","iopub.execute_input":"2021-08-12T05:41:56.321052Z","iopub.status.idle":"2021-08-12T05:41:56.40157Z","shell.execute_reply.started":"2021-08-12T05:41:56.321009Z","shell.execute_reply":"2021-08-12T05:41:56.400503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping one more column which is least significant\ncol = col.drop('Google', 1)\ncol","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:56.403238Z","iopub.execute_input":"2021-08-12T05:41:56.403975Z","iopub.status.idle":"2021-08-12T05:41:56.412786Z","shell.execute_reply.started":"2021-08-12T05:41:56.403928Z","shell.execute_reply":"2021-08-12T05:41:56.411761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Building our final model","metadata":{}},{"cell_type":"code","source":"# Let's re-run the model using the selected variables\nX_train_sm = sm.add_constant(X_train[col])\nlogm7 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm7.fit()\nres.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:56.414441Z","iopub.execute_input":"2021-08-12T05:41:56.415195Z","iopub.status.idle":"2021-08-12T05:41:56.488246Z","shell.execute_reply.started":"2021-08-12T05:41:56.415133Z","shell.execute_reply":"2021-08-12T05:41:56.487116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred = res.predict(X_train_sm).values.reshape(-1)\ny_train_pred[:10]","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:56.48984Z","iopub.execute_input":"2021-08-12T05:41:56.490564Z","iopub.status.idle":"2021-08-12T05:41:56.501855Z","shell.execute_reply.started":"2021-08-12T05:41:56.490513Z","shell.execute_reply":"2021-08-12T05:41:56.500655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred_final['Converted_Prob'] = y_train_pred\n\n# Creating new column 'predicted' with 1 if Churn_Prob > 0.5 else 0\ny_train_pred_final['Predicted'] = y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.5 else 0)\ny_train_pred_final.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:56.503714Z","iopub.execute_input":"2021-08-12T05:41:56.50446Z","iopub.status.idle":"2021-08-12T05:41:56.539876Z","shell.execute_reply.started":"2021-08-12T05:41:56.504409Z","shell.execute_reply":"2021-08-12T05:41:56.538714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted)\nprint(confusion)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:56.545494Z","iopub.execute_input":"2021-08-12T05:41:56.548424Z","iopub.status.idle":"2021-08-12T05:41:56.578889Z","shell.execute_reply.started":"2021-08-12T05:41:56.548356Z","shell.execute_reply":"2021-08-12T05:41:56.577706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check the overall report.\nprint(metrics.classification_report(y_train_pred_final.Converted, y_train_pred_final.Predicted))","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:56.584739Z","iopub.execute_input":"2021-08-12T05:41:56.587859Z","iopub.status.idle":"2021-08-12T05:41:56.621453Z","shell.execute_reply.started":"2021-08-12T05:41:56.587787Z","shell.execute_reply":"2021-08-12T05:41:56.620653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train[col].columns\nvif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:56.623961Z","iopub.execute_input":"2021-08-12T05:41:56.624427Z","iopub.status.idle":"2021-08-12T05:41:56.700909Z","shell.execute_reply.started":"2021-08-12T05:41:56.62438Z","shell.execute_reply":"2021-08-12T05:41:56.699402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Assessment\n- We will draw ROC curve.\n- We will create data with different probabilities.\n- We will plot a graph for 'accuracy','sensitivity' and 'specificity'.","metadata":{}},{"cell_type":"markdown","source":"#### Drawing ROC Curve.","metadata":{}},{"cell_type":"code","source":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:56.706859Z","iopub.execute_input":"2021-08-12T05:41:56.707398Z","iopub.status.idle":"2021-08-12T05:41:56.724669Z","shell.execute_reply.started":"2021-08-12T05:41:56.707351Z","shell.execute_reply":"2021-08-12T05:41:56.72313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Converted, y_train_pred_final.Converted_Prob, drop_intermediate = False )","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:56.726647Z","iopub.execute_input":"2021-08-12T05:41:56.72745Z","iopub.status.idle":"2021-08-12T05:41:56.741262Z","shell.execute_reply.started":"2021-08-12T05:41:56.727393Z","shell.execute_reply":"2021-08-12T05:41:56.740036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_roc(y_train_pred_final.Converted, y_train_pred_final.Converted_Prob)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:56.742964Z","iopub.execute_input":"2021-08-12T05:41:56.743718Z","iopub.status.idle":"2021-08-12T05:41:56.936922Z","shell.execute_reply.started":"2021-08-12T05:41:56.743662Z","shell.execute_reply":"2021-08-12T05:41:56.935971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Creating columns with different probabilities","metadata":{}},{"cell_type":"code","source":"# Let's create columns with different probability cutoffs \nnumbers = [float(x)/10 for x in range(10)]\nfor i in numbers:\n    y_train_pred_final[i]= y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > i else 0)\ny_train_pred_final.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:56.937995Z","iopub.execute_input":"2021-08-12T05:41:56.938432Z","iopub.status.idle":"2021-08-12T05:41:57.008131Z","shell.execute_reply.started":"2021-08-12T05:41:56.9384Z","shell.execute_reply":"2021-08-12T05:41:57.007358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])/total1\n    \n    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:57.009519Z","iopub.execute_input":"2021-08-12T05:41:57.009859Z","iopub.status.idle":"2021-08-12T05:41:57.147854Z","shell.execute_reply.started":"2021-08-12T05:41:57.009828Z","shell.execute_reply":"2021-08-12T05:41:57.146683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Plotting graph for 'accuracy','sensitivity' and 'specificity'","metadata":{}},{"cell_type":"code","source":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:57.149091Z","iopub.execute_input":"2021-08-12T05:41:57.149388Z","iopub.status.idle":"2021-08-12T05:41:57.350245Z","shell.execute_reply.started":"2021-08-12T05:41:57.14936Z","shell.execute_reply":"2021-08-12T05:41:57.349394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred_final['final_predicted'] = y_train_pred_final.Converted_Prob.map( lambda x: 1 if x > 0.3 else 0)\n\ny_train_pred_final.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:57.351855Z","iopub.execute_input":"2021-08-12T05:41:57.352551Z","iopub.status.idle":"2021-08-12T05:41:57.378199Z","shell.execute_reply.started":"2021-08-12T05:41:57.352505Z","shell.execute_reply":"2021-08-12T05:41:57.377154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.Predicted)\nprint(confusion)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:57.379699Z","iopub.execute_input":"2021-08-12T05:41:57.380393Z","iopub.status.idle":"2021-08-12T05:41:57.399412Z","shell.execute_reply.started":"2021-08-12T05:41:57.380349Z","shell.execute_reply":"2021-08-12T05:41:57.398298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check the overall accuracy.\nprint(metrics.classification_report(y_train_pred_final.Converted, y_train_pred_final.Predicted))","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:57.400843Z","iopub.execute_input":"2021-08-12T05:41:57.401518Z","iopub.status.idle":"2021-08-12T05:41:57.425437Z","shell.execute_reply.started":"2021-08-12T05:41:57.401475Z","shell.execute_reply":"2021-08-12T05:41:57.424366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics.recall_score(y_train_pred_final.Converted, y_train_pred_final.Predicted)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:57.426954Z","iopub.execute_input":"2021-08-12T05:41:57.427608Z","iopub.status.idle":"2021-08-12T05:41:57.439475Z","shell.execute_reply.started":"2021-08-12T05:41:57.427547Z","shell.execute_reply":"2021-08-12T05:41:57.43854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p, r, thresholds = precision_recall_curve(y_train_pred_final.Converted, y_train_pred_final.Converted_Prob)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:57.440957Z","iopub.execute_input":"2021-08-12T05:41:57.44154Z","iopub.status.idle":"2021-08-12T05:41:57.447704Z","shell.execute_reply.started":"2021-08-12T05:41:57.441505Z","shell.execute_reply":"2021-08-12T05:41:57.446813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(thresholds, p[:-1], \"g-\")\nplt.plot(thresholds, r[:-1], \"r-\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:57.448948Z","iopub.execute_input":"2021-08-12T05:41:57.449553Z","iopub.status.idle":"2021-08-12T05:41:57.74399Z","shell.execute_reply.started":"2021-08-12T05:41:57.449521Z","shell.execute_reply":"2021-08-12T05:41:57.7429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Evaluation\n- We will scale test dataset.\n- We will predict 'Converted' on it.\n- We will read the report and check the <b>sensitivity</b>.","metadata":{}},{"cell_type":"markdown","source":"#### Scaling the test dataset","metadata":{}},{"cell_type":"code","source":"columns_to_be_scaled = ['TotalVisits','Total Time Spent on Website','Page Views Per Visit']\nX_test[columns_to_be_scaled] = scaler.transform(X_test[columns_to_be_scaled])\nX_test = X_test[col]\nX_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:57.746408Z","iopub.execute_input":"2021-08-12T05:41:57.746731Z","iopub.status.idle":"2021-08-12T05:41:57.771004Z","shell.execute_reply.started":"2021-08-12T05:41:57.746701Z","shell.execute_reply":"2021-08-12T05:41:57.769999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### Predicting the model on test dataset","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:57.772208Z","iopub.execute_input":"2021-08-12T05:41:57.772509Z","iopub.status.idle":"2021-08-12T05:41:57.77673Z","shell.execute_reply.started":"2021-08-12T05:41:57.772482Z","shell.execute_reply":"2021-08-12T05:41:57.775667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_sm = sm.add_constant(X_test)\ny_test_pred = res.predict(X_test_sm)\ny_test_pred[:10]","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:57.777932Z","iopub.execute_input":"2021-08-12T05:41:57.778238Z","iopub.status.idle":"2021-08-12T05:41:57.80101Z","shell.execute_reply.started":"2021-08-12T05:41:57.778211Z","shell.execute_reply":"2021-08-12T05:41:57.799803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting y_pred to a dataframe which is an array\ny_pred_1 = pd.DataFrame(y_test_pred)\n\n# Let's see the head\ny_pred_1.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:57.802423Z","iopub.execute_input":"2021-08-12T05:41:57.802925Z","iopub.status.idle":"2021-08-12T05:41:57.822887Z","shell.execute_reply.started":"2021-08-12T05:41:57.802879Z","shell.execute_reply":"2021-08-12T05:41:57.820918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting y_test to dataframe\ny_test_df = pd.DataFrame(y_test)\n\n# Putting CustID to index\ny_test_df['LeadId'] = y_test_df.index\n\n# Removing index for both dataframes to append them side by side \ny_pred_1.reset_index(drop=True, inplace=True)\ny_test_df.reset_index(drop=True, inplace=True)\n\n# Appending y_test_df and y_pred_1\ny_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)\n\ny_pred_final.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:57.825898Z","iopub.execute_input":"2021-08-12T05:41:57.830076Z","iopub.status.idle":"2021-08-12T05:41:57.86361Z","shell.execute_reply.started":"2021-08-12T05:41:57.830008Z","shell.execute_reply":"2021-08-12T05:41:57.86204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Renaming the column \ny_pred_final= y_pred_final.rename(columns={ 0 : 'Converted_Prob'})\n\n# Rearranging the columns\ny_pred_final = y_pred_final.reindex(['LeadId','Converted','Converted_Prob'], axis=1)\n\n# Let's see the head of y_pred_final\ny_pred_final.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:57.870792Z","iopub.execute_input":"2021-08-12T05:41:57.871313Z","iopub.status.idle":"2021-08-12T05:41:57.902828Z","shell.execute_reply.started":"2021-08-12T05:41:57.871269Z","shell.execute_reply":"2021-08-12T05:41:57.90136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_final['final_predicted'] = y_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.3 else 0)\n\ny_pred_final.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:57.908463Z","iopub.execute_input":"2021-08-12T05:41:57.908822Z","iopub.status.idle":"2021-08-12T05:41:57.925893Z","shell.execute_reply.started":"2021-08-12T05:41:57.908793Z","shell.execute_reply":"2021-08-12T05:41:57.92468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics.confusion_matrix(y_pred_final.Converted, y_pred_final.final_predicted)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:57.927129Z","iopub.execute_input":"2021-08-12T05:41:57.927471Z","iopub.status.idle":"2021-08-12T05:41:57.942035Z","shell.execute_reply.started":"2021-08-12T05:41:57.927441Z","shell.execute_reply":"2021-08-12T05:41:57.940887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Checking the overall report","metadata":{}},{"cell_type":"code","source":"# Let's check the overall report.\nprint(metrics.classification_report(y_pred_final.Converted, y_pred_final.final_predicted))","metadata":{"execution":{"iopub.status.busy":"2021-08-12T05:41:57.94361Z","iopub.execute_input":"2021-08-12T05:41:57.944055Z","iopub.status.idle":"2021-08-12T05:41:57.962611Z","shell.execute_reply.started":"2021-08-12T05:41:57.944008Z","shell.execute_reply":"2021-08-12T05:41:57.961437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <b>It seems that the model can predict with sensitivity 77%.</b>","metadata":{}}]}