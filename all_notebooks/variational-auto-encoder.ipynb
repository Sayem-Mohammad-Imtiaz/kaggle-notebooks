{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Variational Auto-Encoder**","metadata":{}},{"cell_type":"code","source":"import gc\nimport psutil\nimport multiprocessing as mp\nimport copy\nmp.cpu_count()\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport keras\nfrom keras import Input,Sequential, initializers, optimizers, callbacks, layers, models\nfrom keras.models import Model,Sequential\nfrom keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,BatchNormalization,Lambda,Activation,Input,Flatten,Reshape,Conv2DTranspose\nimport keras.backend as K\nfrom keras.layers.merge import add\nfrom sklearn.model_selection import train_test_split\nimport os\nimport glob\nfrom time import time,asctime\nfrom random import randint as r\nimport random","metadata":{"id":"n7Qcr3BWuXNc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs = glob.glob(\"../input/celeba-dataset/img_align_celeba/img_align_celeba/*.jpg\")\nimgs[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trai data ","metadata":{}},{"cell_type":"code","source":"train_y = []\ntrain_y2 = []\nfor _ in range(0,100000):\n  if _%20000 == 0:\n    print(\"{} / 100000\".format(_))\n  img = cv2.imread(imgs[_])\n  img = cv2.resize(img,(32,32))\n  train_y.append(img.astype(\"float32\")/255.0)\nfor _ in range(100000,200000):\n  if _%20000 == 0:\n    print(\"{} / 200000\".format(_))\n  img = cv2.imread(imgs[_])\n  img = cv2.resize(img,(32,32))\n  train_y2.append(img.astype(\"float32\")/255.0)\ntrain_y = np.array(train_y)\ntrain_y2 = np.array(train_y2)\nY_data = np.vstack((train_y,train_y2))\nprint(psutil.virtual_memory())\ndel train_y,train_y2\ngc.collect()\nprint(psutil.virtual_memory())","metadata":{"id":"TbCYhpWPCIB7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test data","metadata":{"id":"FwZ3vkCpEciP"}},{"cell_type":"code","source":"test_Y = []\nfor _ in range(200000,202599):\n    if _%2000 == 0:\n        print(\"{} / 202599\".format(_))\n    img = cv2.imread(imgs[_])\n    img = cv2.resize(img,(32,32))\n    test_Y.append(img.astype(\"float32\")/255.0)\ntest_Y = np.array(test_Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sampler function\n**Variational Auto Encoder has a sampler In VAE, the encoder outputs two vectors.one is mean and the other is standard_deviation.sample from these two are taken as a final vector that can be done using the sampler function.**","metadata":{}},{"cell_type":"code","source":"def sample_z(layers):\n    std_norm = K.random_normal(shape=(K.shape(layers[0])[0], latent_dim), mean=0, stddev=1)\n    return layers[0] + layers[1]*std_norm","metadata":{"id":"orb_K5T77-7U","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encoder part","metadata":{"id":"yJMas-okFD-n"}},{"cell_type":"code","source":"latent_dim = 50\ntotal_epoch = 50\nbatch_size = 32\nimg_dim = (32, 32)\n\nencoder_inputs = keras.Input(shape=(*img_dim, 3))\n\nx = layers.Conv2D(32, kernel_size=(5,5), padding='SAME')(encoder_inputs)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2D(32, kernel_size=(5,5), strides=(2,2),padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2D(64, kernel_size=(5,5), strides=(2,2),padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2D(64, kernel_size=(5,5), strides=(1,1), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2D(128, kernel_size=(5,5), strides=(1,1), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(128, activation=\"relu\")(x)\n\nx = layers.Dense(64, activation=\"relu\")(x)\n\nmu = layers.Dense(latent_dim)(x)\nlog_sigma = layers.Dense(latent_dim)(x)\n\nz = layers.Lambda(sample_z)([mu, log_sigma])\n\nencoder = keras.Model(encoder_inputs,z)\n\nencoder.summary()\n","metadata":{"id":"cERc9buwBaTB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decoder part","metadata":{"id":"uIuoo_-eFJXl"}},{"cell_type":"code","source":"latent_inputs = keras.Input(shape=(latent_dim,))\nx = layers.Dense(8 * 8 * 128, activation=\"relu\")(latent_inputs)\nx = layers.Reshape((8, 8, 128))(x)\n\nx = layers.Conv2D(128, kernel_size=(5,5), strides=(1,1), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2DTranspose(64, kernel_size=(5,5),strides=(1,1), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\nx = layers.Conv2DTranspose(64, kernel_size=(5,5),strides=(2,2), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2DTranspose(32, kernel_size=(5,5),strides=(2,2),padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2DTranspose(32, kernel_size=(5,5), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\ndecoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\ndecoder = keras.Model(latent_inputs, decoder_outputs)\ndecoder.summary()","metadata":{"id":"u7qUl9JfBaQz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LOSS FUNCTIONS","metadata":{}},{"cell_type":"code","source":"def reconstruction_loss(y_true, y_pred):\n    return K.mean(K.square(y_true - y_pred))\n\ndef kl_loss(y_true, y_pred):\n    kl_loss = K.abs(keras.losses.KLD(y_true, y_pred))\n    return kl_loss\n\ndef vae_loss(y_true, y_pred):\n    return reconstruction_loss(y_true, y_pred)+0.25*kl_loss(y_true, y_pred)","metadata":{"id":"i8KbxzMxBaOI","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Connecting the Encoder and Decoder to make the **Auto Encoder**","metadata":{"id":"9-6BNcyaFRji"}},{"cell_type":"code","source":"vae = keras.Model(encoder_inputs, decoder(encoder(encoder_inputs)))","metadata":{"id":"aHGAu5oGBaMZ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vae.compile(optimizer = \"adam\",loss = vae_loss,metrics = [kl_loss,reconstruction_loss])","metadata":{"id":"E2R5_XH6BaKV","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the VAE","metadata":{"id":"Rm6u84OSF1OW"}},{"cell_type":"code","source":"vae.fit(Y_data,Y_data,batch_size = 32,epochs = total_epoch)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Displaying result","metadata":{}},{"cell_type":"code","source":"pred = vae.predict(test_Y)","metadata":{"id":"5O_1hWqzBaGJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = r(0,2599)\nprint(temp)\nplt.subplot(1,2,1)\nplt.imshow(test_Y[temp])\nplt.subplot(1,2,2)\nplt.imshow(pred[temp])","metadata":{"id":"hTqpsXWbBaD_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generating a new face by passing a random normal sample of size (32,32,3) and observing the output","metadata":{"id":"QTeMxYm6F99-"}},{"cell_type":"code","source":"gen =np.random.uniform(0, 1, size = (1,32,32,3))\ngen_sample = vae.predict(gen)\nplt.subplot(1,2,1)\nplt.imshow(gen[0])\nplt.subplot(1,2,2)\nplt.imshow(gen_sample[0])","metadata":{"id":"EVpaLlSbB9UQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_l=[]\nimg_path =(\"../input/someface/14997843405964e4941e4293.64533925.jpg\")\nimg = cv2.imread(img_path)\nimg = cv2.resize(img,(32,32))\nimg=np.array(img.astype(\"float32\")/255.0)\nimg_l.append(img)\nimg=np.array(img_l)\nimg_sample = vae.predict(img)\nplt.subplot(1,2,1)\nplt.imshow(img[0])\nplt.subplot(1,2,2)\nplt.imshow(img_sample[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_l=[]\nimg_path =(\"../input/someface2/depositphotos.jpg\")\nimg = cv2.imread(img_path)\nimg = cv2.resize(img,(32,32))\nimg=np.array(img.astype(\"float32\")/255.0)\nimg_l.append(img)\nimg=np.array(img_l)\nimg_sample = vae.predict(img)\nplt.subplot(1,2,1)\nplt.imshow(img[0])\nplt.subplot(1,2,2)\nplt.imshow(img_sample[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}