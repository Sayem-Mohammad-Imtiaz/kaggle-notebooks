{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n!cp ../input/rapids/rapids.0.16.0 /opt/conda/envs/rapids.tar.gz\n!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport re, jieba, requests, json, time, random\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.feature_extraction.text import CountVectorizer \nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import HashingVectorizer\n\nfrom xgboost import XGBClassifier \n#import cudf\nfrom cuml.ensemble import RandomForestClassifier\n#from cuml.svm import SVC\n#from cuml.naive_bayes import MultinomialNB\n\nfrom sklearn.naive_bayes import BernoulliNB\n#from sklearn.ensemble import RandomForestClassifier \nfrom sklearn.svm import SVC\n\nfrom shutil import copyfile \n#!pip install googletrans\n#from googletrans import Translator\n#copyfile(src = '../input/law-text/useful_tools.py', dst = '../working/useful_tools.py')\n#from useful_tools import * ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set = pd.read_csv('../input/law-text/TestSet.csv',encoding='gb18030')\n\ntest_set['content'] = test_set['content'].astype(str)\ntest_set['content'] = test_set['content'].apply(lambda x: x.replace('\\u3000','') \\\n                                                      .replace('\\n','') \\\n                                                      .replace('\\r','') \\\n                                                      .strip()) \ntest_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train = pd.read_csv('../input/law-text/train.csv')\ntrain[train['class']=='使用者要求/运营者要求'] = '使用者要求'\ntrain[train['class']=='运营者要求/使用者要求'] = '运营者要求'\ntrain[train['class']=='使用者要求（运营者）'] = '使用者要求'\ntrain[train['class']=='职责区分/违规处理'] = '职责区分'\ntrain.dropna(inplace=True)\ntrain['content'] = train['content'].astype(str)\ntrain['content'] = train['content'].apply(lambda x: x.replace('\\u3000','') \\\n                                                      .replace('\\n','') \\\n                                                      .replace('\\r','') \\\n                                                      .strip()) \nle = LabelEncoder()\ny1 = le.fit_transform(train['class'])\ntrain['label'] = y1\nprint('train has {} rows and {} columns'.format(train.shape[0], train.shape[1]))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test = train.sample(n=380, weights=y1, random_state=786)\ntest.sort_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_augment = pd.read_csv('../input/law-text/train_augment.csv')\nprint('train_augment has {} rows and {} columns'.format(train_augment.shape[0], train_augment.shape[1]))\ntrain_augment.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_vectorize(wordlist,vector = 'CountVectorizer',feats =150):\n    '''得到特征X矩阵\n    '''\n    if vector == 'CountVectorizer':\n        cv = CountVectorizer(max_features = feats,token_pattern='[\\u4e00-\\u9fa5_a-zA-Z0-9]{1,}')\n        cv_fit = cv.fit_transform(wordlist).toarray()\n        colnames = cv.get_feature_names()\n        word_matrix = pd.DataFrame(cv_fit, columns=colnames)   \n        return word_matrix\n    elif vector == 'TfidfVectorizer':\n        cv = TfidfVectorizer(max_features = feats,token_pattern='[\\u4e00-\\u9fa5_a-zA-Z0-9]{1,}')\n        cv_fit = cv.fit_transform(wordlist).toarray()\n        colnames = cv.get_feature_names()\n        word_matrix = pd.DataFrame(cv_fit, columns=colnames)   \n        return word_matrix\n    elif vector == 'HashingVectorizer':\n        cv =  HashingVectorizer(n_features = feats)\n        cv_fit = cv.fit_transform(wordlist).toarray()\n        word_matrix = pd.DataFrame(cv_fit)\n        return word_matrix\n    \nstopword_list = [k.strip() for k in open('../input/english-and-chinese-stopwords/stopwords.txt', encoding='utf8').readlines() if k.strip() != '']\n\ndef get_cutword(string):\n    '''jieba分词,正则替换数字\n    '''\n    string = re.sub(\"[0-9]\",\" \",string) # 正则替换数字\n    cutWords = [k for k in jieba.cut(string) if k != '' if k not in stopword_list]\n    combined = ' '.join(cutWords)\n    return combined","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cutword_series = train_augment['content'].apply(lambda x: get_cutword(x)) # 得到的是pandas series\nx_train = get_vectorize(cutword_series,feats = 100)\n\ncutword_series = test['content'].apply(lambda x: get_cutword(x)) # 得到的是pandas series\nx_test = get_vectorize(cutword_series,feats = 100)\n\ncutword_series = test_set['content'].apply(lambda x: get_cutword(x)) # 得到的是pandas series\ntest_set = get_vectorize(cutword_series,feats = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"x_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train = train_augment['label']\ny_test = test['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def consist_train_test(test, train_col):\n    '''使得测试集列名顺序与训练集一致\n    '''\n    new_df = pd.DataFrame()\n    for i in train_col:\n        if i in test.columns:\n            new_df[i] = test[i]\n        else:\n            new_df[i] = 0\n    new_df.fillna(0, inplace = True)\n    order = train_col\n    new_df[order]\n    return new_df\n\nx_test = consist_train_test(x_test,x_train.columns)\ntest_set = consist_train_test(test_set,x_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluating(test_pred):\n    voted_test_pred = test_pred.mode(axis=1)[0].astype(int)\n    acc_test = accuracy_score(y_test, voted_test_pred)\n    print('pseudo test set accuracy:{:.5f}'.format(acc_test))\n\ndef vote(test_pred):\n    voted_test_pred = test_pred.mode(axis=1)[0].astype(int)\n    recode =  {0 : '使用者要求', 1 : '名词解释',2 : '服务监督', 3 : '法规倡议', \n           4 : '法规目的',5 : '职责区分', 6 : '运营者要求', 7 : '违规处理'}\n    y_pred = pd.Series(voted_test_pred).map(recode)\n    return voted_test_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\n#for i, t in enumerate(label_cols):\n#    print(t)\n#    y = train_df.loc[:, [t]].values.reshape(-1)\ndef run_crossval_xgb(x_train, y_train, x_test): \n    '''交叉验证'''\n    x_train = x_train.astype('float32')\n    y_train = y_train.astype('float32')\n    x_test = x_test.astype('float32')\n    folds = StratifiedKFold(n_splits=5)\n    val_score = []\n    test_pred = []\n    test_pred_set = []\n    #pred_test = np.zeros((len(test_X), len(label_cols)))\n    print('start training xgboost ... ')\n    for fold, (trn_idx, val_idx) in enumerate(folds.split(x_train, y_train)):\n        print(f'Training fold {fold + 1}')\n        x_trn, x_val = x_train.iloc[trn_idx], x_train.iloc[val_idx]\n        y_trn, y_val = y_train.iloc[trn_idx], y_train.iloc[val_idx]\n        #model = LogisticRegression(C=9.0, class_weight='balanced')\n        #model = LogisticRegression(C=9.0)\n        model = XGBClassifier(n_estimators = 250 ,\n                      max_depth = 6, \n                      learning_rate = 0.2,\n                      min_child_weight = 10, \n                      colsample_bytree = 0.7, \n                      subsample = 0.8,\n                      random_state=233,\n                      eval_metric='merror',\n                      tree_method='gpu_hist')\n        model.fit(x_trn, y_trn)\n        pred_train = model.predict(x_trn)\n        acc_train = accuracy_score(y_trn, pred_train)\n        pred_val = model.predict(x_val)\n        acc_val = accuracy_score(y_val, pred_val)\n        val_score.append(acc_val)\n        \n        pred_test = model.predict(x_test)\n        test_pred.append(pred_test)\n        \n        pred_test_set = model.predict(test_set)\n        test_pred_set.append(pred_test_set)\n        #pred_val = model.predict(xval)\n        #pred_test[:, i] += model.predict(test)\n        print('val accuracy:{:.5f}, train accuracy:{:.5f}'.format(acc_val, acc_train))\n    print('-' * 50)\n    print('OOF val accuracy:{:.5f}'.format(np.array(val_score).mean()))\n    return pd.DataFrame(np.array(test_pred).T), pd.DataFrame(np.array(test_pred_set).T)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_crossval_rf(x_train, y_train, x_test): \n    '''交叉验证'''\n    x_train = x_train.astype('float32')\n    y_train = y_train.astype('float32')\n    x_test = x_test.astype('float32')\n    folds = StratifiedKFold(n_splits=5)\n    val_score = []\n    test_pred = []\n    test_pred_set = []\n    print('start training random forests ... ')\n    for fold, (trn_idx, val_idx) in enumerate(folds.split(x_train, y_train)):\n        print(f'Training fold {fold + 1}')\n        x_trn, x_val = x_train.iloc[trn_idx], x_train.iloc[val_idx]\n        y_trn, y_val = y_train.iloc[trn_idx], y_train.iloc[val_idx]\n        #model = LogisticRegression(C=9.0, class_weight='balanced')\n        #model = LogisticRegression(C=9.0)\n        model = RandomForestClassifier(n_estimators=250,\n                                       rows_sample = 0.7,\n                                       max_depth=8,\n                                       max_features=75)\n        model.fit(x_trn, y_trn)\n        pred_train = model.predict(x_trn)\n        acc_train = accuracy_score(y_trn, pred_train)\n        pred_val = model.predict(x_val)\n        acc_val = accuracy_score(y_val, pred_val)\n        val_score.append(acc_val)\n        \n        pred_test = model.predict(x_test)\n        test_pred.append(pred_test)\n        \n        pred_test_set = model.predict(test_set)\n        test_pred_set.append(pred_test_set)\n        #pred_val = model.predict(xval)\n        #pred_test[:, i] += model.predict(test)\n        print('val accuracy:{:.5f}, train accuracy:{:.5f}'.format(acc_val, acc_train))\n    print('-' * 50)\n    print('OOF val accuracy:{:.5f}'.format(np.array(val_score).mean()))\n    return pd.DataFrame(np.array(test_pred).T), pd.DataFrame(np.array(test_pred_set).T)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def run_crossval_svm(x_train, y_train, x_test): \n    '''交叉验证'''\n    x_train = x_train.astype('float32')\n    y_train = y_train.astype('float32')\n    x_test = x_test.astype('float32')\n    folds = StratifiedKFold(n_splits=5)\n    val_score = []\n    test_pred = []\n    test_pred_set = []\n    print('start training svm ... ')\n    for fold, (trn_idx, val_idx) in enumerate(folds.split(x_train, y_train)):\n        print(f'Training fold {fold + 1}')\n        x_trn, x_val = x_train.iloc[trn_idx], x_train.iloc[val_idx]\n        y_trn, y_val = y_train.iloc[trn_idx], y_train.iloc[val_idx]\n        #model = LogisticRegression(C=9.0, class_weight='balanced')\n        #model = LogisticRegression(C=9.0)\n        model = SVC(gamma='auto')\n        model.fit(x_trn, y_trn)\n        pred_train = model.predict(x_trn)\n        acc_train = accuracy_score(y_trn, pred_train)\n        pred_val = model.predict(x_val)\n        acc_val = accuracy_score(y_val, pred_val)\n        val_score.append(acc_val)\n        \n        pred_test = model.predict(x_test)\n        test_pred.append(pred_test)\n        \n        pred_test_set = model.predict(test_set)\n        test_pred_set.append(pred_test_set)\n        #pred_val = model.predict(xval)\n        #pred_test[:, i] += model.predict(test)\n        print('val accuracy:{:.5f}, train accuracy:{:.5f}'.format(acc_val, acc_train))\n    print('-' * 50)\n    print('OOF val accuracy:{:.5f}'.format(np.array(val_score).mean()))\n    return pd.DataFrame(np.array(test_pred).T), pd.DataFrame(np.array(test_pred_set).T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_crossval_nb(x_train, y_train, x_test): \n    '''交叉验证'''\n    x_train = x_train.astype('float32')\n    y_train = y_train.astype('float32')\n    x_test = x_test.astype('float32')\n    folds = StratifiedKFold(n_splits=5)\n    val_score = []\n    test_pred = []\n    test_pred_set = []\n    #pred_test = np.zeros((len(test_X), len(label_cols)))\n    print('start training naive bayes ...')\n    for fold, (trn_idx, val_idx) in enumerate(folds.split(x_train, y_train)):\n        print(f'Training fold {fold + 1}')\n        x_trn, x_val = x_train.iloc[trn_idx], x_train.iloc[val_idx]\n        y_trn, y_val = y_train.iloc[trn_idx], y_train.iloc[val_idx]\n        #model = LogisticRegression(C=9.0, class_weight='balanced')\n        #model = LogisticRegression(C=9.0)\n        model = BernoulliNB()\n        model.fit(x_trn, y_trn)\n        pred_train = model.predict(x_trn)\n        acc_train = accuracy_score(y_trn, pred_train)\n        pred_val = model.predict(x_val)\n        acc_val = accuracy_score(y_val, pred_val)\n        val_score.append(acc_val)\n        \n        pred_test = model.predict(x_test)\n        test_pred.append(pred_test)\n        \n        pred_test_set = model.predict(test_set)\n        test_pred_set.append(pred_test_set)\n        #pred_val = model.predict(xval)\n        #pred_test[:, i] += model.predict(test)\n        print('val accuracy:{:.5f}, train accuracy:{:.5f}'.format(acc_val, acc_train))\n    print('-' * 50)\n    print('OOF val accuracy:{:.5f}'.format(np.array(val_score).mean()))\n    return pd.DataFrame(np.array(test_pred).T), pd.DataFrame(np.array(test_pred_set).T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_pred, test_pred_set = run_crossval_xgb(x_train, y_train, x_test)\nevaluating(test_pred)\ntest_pred_xgb = vote(test_pred_set)\n\ntest_pred, test_pred_set = run_crossval_rf(x_train, y_train, x_test)\nevaluating(test_pred)\ntest_pred_rf = vote(test_pred_set)\n\ntest_pred, test_pred_set = run_crossval_svm(x_train, y_train, x_test)\nevaluating(test_pred)\ntest_pred_svm = vote(test_pred_set)\n\ntest_pred, test_pred_set = run_crossval_nb(x_train, y_train, x_test)\nevaluating(test_pred)\ntest_pred_nb = vote(test_pred_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set = pd.read_csv('../input/law-text/TestSet.csv',encoding='gb18030')\n\ndef get_submission(y_pred, name):\n    submission = pd.DataFrame({'content': test_set['content'], 'class': y_pred})\n    filename = name + '.csv'\n    submission.to_csv(filename, index = False)\n\nget_submission(test_pred_xgb, 'xgb_pred')\n\nget_submission(test_pred_rf, 'rf_pred')\n\nget_submission(test_pred_svm, 'svm_pred')\n\nget_submission(test_pred_nb, 'naive_bayes_pred')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}