{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This function is useful to classify a single sport. For example if you have multiple images of the sport you want to classify, say 10 images of basketball, store those images in a directory. In this case the images are stored in the  images to predict directory. It has  17 basketball image and one bowling image. The function uses a trained model in this case  EfficientNetB1-sports-99.17.h5 and the class_dict.csv file. Predictions are made using model.predict and the results are averaged to product a composite class prediction along with its averaged probability. If there is only a single image in the directory the predicted class and probability is returned.\n\n","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2 as cv2\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nfrom tensorflow.keras.models import Model, load_model\nimport logging\nlogging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\nimport logging\nlogging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\npd.set_option('display.max_columns', 80)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T03:09:03.375875Z","iopub.execute_input":"2021-07-04T03:09:03.376343Z","iopub.status.idle":"2021-07-04T03:09:03.385139Z","shell.execute_reply.started":"2021-07-04T03:09:03.37631Z","shell.execute_reply":"2021-07-04T03:09:03.383313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classify(sdir, csv_path,  model_path, name):\n    # read in the csv file\n    class_df=pd.read_csv(csv_path)    \n    img_height=int(class_df['height'].iloc[0])\n    img_width =int(class_df['width'].iloc[0])\n    img_size=(img_height, img_width)\n    scale=float(class_df['scale by'].iloc[0])\n    path_list=[]\n    paths=os.listdir(sdir)\n    for f in paths:\n        path_list.append(os.path.join(sdir,f))\n    model=load_model(model_path)\n    image_count=len(path_list)    \n    index_list=[] \n    prob_list=[]\n    for i in range (image_count):       \n        img=plt.imread(path_list[i]) \n        img=cv2.resize(img, img_size) \n        img=img * scale\n        img=np.expand_dims(img, axis=0)\n        p= np.squeeze (model.predict(img))           \n        index=np.argmax(p)         \n        prob=p[index]\n        index_list.append(index)\n        prob_list.append(prob)\n    if image_count==1:\n        class_name= class_df['class'].iloc[index_list[0]]\n        probability= prob_list[0]\n        imgpath=path_list[0]\n        print (imgpath)\n        img=plt.imread(imgpath)/255\n        plt.title(class_name, color='yellow', fontsize=16)\n        plt.imshow(img)\n        return class_name, probability\n    most=0\n    for i in range (len(index_list)-1):\n        key= index_list[i]\n        keycount=0\n        for j in range (i+1, len(index_list)):\n            nkey= index_list[j]            \n            if nkey == key:\n                keycount +=1                \n        if keycount> most:\n            most=keycount\n            isave=i             \n    best_index=index_list[isave]    \n    psum=0\n    bestsum=0\n    for i in range (len(index_list)):\n        psum += prob_list[i]\n        if index_list[i]==best_index:\n            bestsum += prob_list[i]  \n    imgpath=path_list[isave]\n    img=plt.imread(imgpath)/255\n    class_name=class_df['class'].iloc[best_index]\n    plt.title(class_name, color='yellow', fontsize=16)\n    plt.imshow(img)\n    return class_name, bestsum/image_count","metadata":{"execution":{"iopub.status.busy":"2021-07-04T03:09:03.38734Z","iopub.execute_input":"2021-07-04T03:09:03.387669Z","iopub.status.idle":"2021-07-04T03:09:03.406838Z","shell.execute_reply.started":"2021-07-04T03:09:03.387638Z","shell.execute_reply":"2021-07-04T03:09:03.405369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Example of use","metadata":{}},{"cell_type":"code","source":"predict_dir=r'../input/sports-classification/images to predict'  # where the files are stored\nname='sport' # string name you want to use - \nmloc=r'../input/sports-classification/EfficientNetB1-sports-99.17.h5'# path th trained model\ncsvloc=r'../input/sports-classification/class_dict.csv' # path to class dict.csv\nresult, probability=classify(predict_dir, csvloc,mloc, name) # call the classifier result is the class name\nprint (f' {name} is predicted as being {result} with a probability of {probability * 100:5.2f} %') # print the result","metadata":{"execution":{"iopub.status.busy":"2021-07-04T03:09:03.409886Z","iopub.execute_input":"2021-07-04T03:09:03.410441Z","iopub.status.idle":"2021-07-04T03:09:15.649901Z","shell.execute_reply.started":"2021-07-04T03:09:03.410388Z","shell.execute_reply":"2021-07-04T03:09:15.648735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### another example of use using images from test/baseball 5 baseball images","metadata":{}},{"cell_type":"code","source":"predict_dir=r'../input/sports-classification/test/baseball'\nresult, probability=classify(predict_dir, csvloc,mloc, name) # call the classifier result is the class name\nprint (f' {name} is predicted as being {result} with a probability of {probability * 100:5.2f} %') # print the result","metadata":{"execution":{"iopub.status.busy":"2021-07-04T03:09:15.653548Z","iopub.execute_input":"2021-07-04T03:09:15.654086Z","iopub.status.idle":"2021-07-04T03:09:24.727899Z","shell.execute_reply.started":"2021-07-04T03:09:15.654Z","shell.execute_reply":"2021-07-04T03:09:24.726724Z"},"trusted":true},"execution_count":null,"outputs":[]}]}