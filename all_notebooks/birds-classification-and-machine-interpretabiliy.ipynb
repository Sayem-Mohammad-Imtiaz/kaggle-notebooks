{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# inspired in https://www.kaggle.com/kritidoneria/responsible-ai-model-explainability\n# inspired in https://www.kaggle.com/databeru/fruit-and-vegetable-classification","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:04:29.287927Z","iopub.execute_input":"2021-06-24T04:04:29.288361Z","iopub.status.idle":"2021-06-24T04:04:29.292755Z","shell.execute_reply.started":"2021-06-24T04:04:29.288317Z","shell.execute_reply":"2021-06-24T04:04:29.291556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport os.path\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n# Create a list with the filepaths for training and testing\ntrain_dir = Path('../input/100-bird-species/train')\ntrain_filepaths = list(train_dir.glob(r'**/*.jpg'))\n\nval_dir = Path('../input/100-bird-species/valid')\nval_filepaths = list(val_dir.glob(r'**/*.jpg'))\n\ntest_dir = Path('../input/100-bird-species/test')\ntest_filepaths = list(test_dir.glob(r'**/*.jpg'))","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:04:29.294335Z","iopub.execute_input":"2021-06-24T04:04:29.294677Z","iopub.status.idle":"2021-06-24T04:04:53.963411Z","shell.execute_reply.started":"2021-06-24T04:04:29.294643Z","shell.execute_reply":"2021-06-24T04:04:53.962501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def proc_img(filepath):\n\n    labels = [str(filepath[i]).split('/')[-2] for i in range(len(filepath))]\n    filepath = pd.Series(filepath, name='Filepath').astype(str)\n    labels = pd.Series(labels, name='Label')\n\n    df = pd.concat([filepath, labels], axis=1)\n\n    # Shuffle the DataFrame and reset index\n    df = df.sample(frac=1).reset_index(drop = True)\n\n    return df\n\ntrain_df = proc_img(train_filepaths)\nval_df = proc_img(val_filepaths)\ntest_df = proc_img(test_filepaths)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:04:53.965284Z","iopub.execute_input":"2021-06-24T04:04:53.965607Z","iopub.status.idle":"2021-06-24T04:04:54.089104Z","shell.execute_reply.started":"2021-06-24T04:04:53.965573Z","shell.execute_reply":"2021-06-24T04:04:54.088263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:04:54.092254Z","iopub.execute_input":"2021-06-24T04:04:54.092507Z","iopub.status.idle":"2021-06-24T04:04:54.109194Z","shell.execute_reply.started":"2021-06-24T04:04:54.092482Z","shell.execute_reply":"2021-06-24T04:04:54.108275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a DataFrame with one Label of each category\ndf_unique = train_df.copy().drop_duplicates(subset=[\"Label\"]).reset_index()\n\n# Display some pictures of the dataset\nfig, axes = plt.subplots(nrows=6, ncols=6, figsize=(12, 12),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df_unique.Filepath[i]))\n    ax.set_title(df_unique.Label[i], fontsize = 12, color = 'white')\nplt.tight_layout(pad=0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:04:54.110833Z","iopub.execute_input":"2021-06-24T04:04:54.111247Z","iopub.status.idle":"2021-06-24T04:04:56.866146Z","shell.execute_reply.started":"2021-06-24T04:04:54.111209Z","shell.execute_reply":"2021-06-24T04:04:56.865245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:04:56.867391Z","iopub.execute_input":"2021-06-24T04:04:56.867756Z","iopub.status.idle":"2021-06-24T04:04:56.873433Z","shell.execute_reply.started":"2021-06-24T04:04:56.86772Z","shell.execute_reply":"2021-06-24T04:04:56.872732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=0,\n    rotation_range=30,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)\n\nval_images = train_generator.flow_from_dataframe(\n    dataframe=val_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=0,\n    rotation_range=30,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)\n\ntest_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:04:56.876262Z","iopub.execute_input":"2021-06-24T04:04:56.876896Z","iopub.status.idle":"2021-06-24T04:05:19.50775Z","shell.execute_reply.started":"2021-06-24T04:04:56.876858Z","shell.execute_reply":"2021-06-24T04:05:19.506889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the pretained model\n\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n\npretrained_model = MobileNetV2(\n    input_shape=(224, 224, 3),\n    include_top=False,\n#     weights='../input/tf-keras-pretrained-model-weights/No Top/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_192_no_top.h5',\n    weights='imagenet',\n    pooling='avg'\n)\n\n# pretrained_model = tf.keras.applications.MobileNetV2(\n#     input_shape=(224, 224, 3),\n#     include_top=False,\n#     weights='imagenet',\n#     pooling='avg'\n# )\npretrained_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:05:19.509581Z","iopub.execute_input":"2021-06-24T04:05:19.51009Z","iopub.status.idle":"2021-06-24T04:05:23.11722Z","shell.execute_reply.started":"2021-06-24T04:05:19.51005Z","shell.execute_reply":"2021-06-24T04:05:23.116377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = pretrained_model.input\n\n# transfer learning\n\nx = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n# x = tf.keras.layers.Dense(128, activation='relu')(x)\n\noutputs = tf.keras.layers.Dense(275, activation='softmax')(x) # 275\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:05:23.118449Z","iopub.execute_input":"2021-06-24T04:05:23.118816Z","iopub.status.idle":"2021-06-24T04:05:23.149393Z","shell.execute_reply.started":"2021-06-24T04:05:23.118765Z","shell.execute_reply":"2021-06-24T04:05:23.148646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils.vis_utils import plot_model\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# model.summary()\n\n# plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:05:23.150621Z","iopub.execute_input":"2021-06-24T04:05:23.150964Z","iopub.status.idle":"2021-06-24T04:05:23.226627Z","shell.execute_reply.started":"2021-06-24T04:05:23.15093Z","shell.execute_reply":"2021-06-24T04:05:23.225891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_images,\n    validation_data=val_images,\n    batch_size = 32,\n    epochs=6,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=2,\n            restore_best_weights=True\n        )\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:05:23.227915Z","iopub.execute_input":"2021-06-24T04:05:23.22835Z","iopub.status.idle":"2021-06-24T04:20:21.025519Z","shell.execute_reply.started":"2021-06-24T04:05:23.228312Z","shell.execute_reply":"2021-06-24T04:20:21.024577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()\nplt.title(\"Accuracy\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:20:21.027107Z","iopub.execute_input":"2021-06-24T04:20:21.027419Z","iopub.status.idle":"2021-06-24T04:20:21.190555Z","shell.execute_reply.started":"2021-06-24T04:20:21.027389Z","shell.execute_reply":"2021-06-24T04:20:21.189503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history)[['loss','val_loss']].plot()\nplt.title(\"Loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:20:21.191819Z","iopub.execute_input":"2021-06-24T04:20:21.19216Z","iopub.status.idle":"2021-06-24T04:20:21.3383Z","shell.execute_reply.started":"2021-06-24T04:20:21.192122Z","shell.execute_reply":"2021-06-24T04:20:21.337541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"# Predict the label of the test_images\npred = model.predict(test_images)\npred = np.argmax(pred,axis=1)\n\n# Map the label\nlabels = (train_images.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred = [labels[k] for k in pred]\n\ny_test = [labels[k] for k in test_images.classes]","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:20:21.339428Z","iopub.execute_input":"2021-06-24T04:20:21.339753Z","iopub.status.idle":"2021-06-24T04:20:31.710932Z","shell.execute_reply.started":"2021-06-24T04:20:21.339718Z","shell.execute_reply":"2021-06-24T04:20:31.710053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nacc = accuracy_score(y_test, pred)\nprint(f'Accuracy on the test set: {100*acc:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:20:31.712343Z","iopub.execute_input":"2021-06-24T04:20:31.712697Z","iopub.status.idle":"2021-06-24T04:20:32.275789Z","shell.execute_reply.started":"2021-06-24T04:20:31.712661Z","shell.execute_reply":"2021-06-24T04:20:32.274991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ncf_matrix = confusion_matrix(y_test, pred, normalize='true')\nplt.figure(figsize = (15,10))\nsns.heatmap(cf_matrix, \n            annot=False, \n            xticklabels = sorted(set(y_test)),\n            yticklabels = sorted(set(y_test)),\n            )\nplt.title('Normalized Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:20:32.278689Z","iopub.execute_input":"2021-06-24T04:20:32.278953Z","iopub.status.idle":"2021-06-24T04:20:41.859368Z","shell.execute_reply.started":"2021-06-24T04:20:32.278926Z","shell.execute_reply":"2021-06-24T04:20:41.858474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display some pictures of the dataset with their labels and the predictions\nfig, axes = plt.subplots(nrows=3, ncols=3, figsize=(8, 8),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(test_df.Filepath.iloc[i]))\n    ax.set_title(f\"True: {test_df.Label.iloc[i]}\\nPredicted: {pred[i]}\",color='white')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:20:41.860769Z","iopub.execute_input":"2021-06-24T04:20:41.861295Z","iopub.status.idle":"2021-06-24T04:20:42.506961Z","shell.execute_reply.started":"2021-06-24T04:20:41.861255Z","shell.execute_reply":"2021-06-24T04:20:42.505986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/kritidoneria/responsible-ai-model-explainability\nfrom keras.applications.mobilenet_v2 import decode_predictions,preprocess_input\nfrom keras.preprocessing.image import load_img, img_to_array\n\npath = '../input/100-bird-species/test/FLAMINGO/1.jpg'\n\n# input_shape=(224, 224, 3),\n\nimage_raw = load_img(path, target_size=(224,224,3))\nimage_raw","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:20:42.508518Z","iopub.execute_input":"2021-06-24T04:20:42.508885Z","iopub.status.idle":"2021-06-24T04:20:42.538596Z","shell.execute_reply.started":"2021-06-24T04:20:42.508848Z","shell.execute_reply":"2021-06-24T04:20:42.537648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to numpy array, reshape and preprocess\nimage = img_to_array(image_raw)\n\nimage = image.reshape(\n    (1, image.shape[0], image.shape[1], image.shape[2])\n)\n# print(image.shape)\n\nimage = preprocess_input(image).astype('double')\n# print(image.shape)\n\npredictions = model.predict(image)\n\nprint(predictions.shape)\n# print(predictions)\n\n# decode_predictions(predictions)\n\nmodel.predict(image).argsort()[0, -5:][::-1]\n\n# model.predict(image).argsort()[0, -5:][::-1]","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:22:37.720661Z","iopub.execute_input":"2021-06-24T04:22:37.721012Z","iopub.status.idle":"2021-06-24T04:22:37.806239Z","shell.execute_reply.started":"2021-06-24T04:22:37.720981Z","shell.execute_reply":"2021-06-24T04:22:37.805476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lime.lime_image import LimeImageExplainer\nexplainer = LimeImageExplainer()\n\nexplanation = explainer.explain_instance(image[0], \n                                         model.predict, \n                                         top_labels=2, \n                                         num_samples=100,\n                                         random_seed=42\n                                        )\n\nfrom skimage.segmentation import mark_boundaries\nfrom matplotlib import pyplot as plt\n\ntemp, mask = explanation.get_image_and_mask(100,\n                                            positive_only=True, \n                                            num_features=5, \n                                            hide_rest=True)\n# plot image and mask together\nplt.imshow(mark_boundaries(temp , mask))","metadata":{"execution":{"iopub.status.busy":"2021-06-24T04:24:08.870056Z","iopub.execute_input":"2021-06-24T04:24:08.870377Z","iopub.status.idle":"2021-06-24T04:24:10.67189Z","shell.execute_reply.started":"2021-06-24T04:24:08.870347Z","shell.execute_reply":"2021-06-24T04:24:10.671116Z"},"trusted":true},"execution_count":null,"outputs":[]}]}