{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nimport cv2\nimport numpy as np\nimport skimage\nimages = [cv2.cvtColor(cv2.imread(file),cv2.COLOR_BGR2RGB) for file in glob.glob(\"../input/blood-cell-detection-dataset/images/*.png\")]\nimages = np.array(images)\nimport matplotlib.pyplot as plt\nplt.imshow(images[3,:,:,:])\nplt.show()\nimage = images[3,:,:,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"norm_img = image.copy()\nfor i in range(image.shape[0]):\n    for j in range(image.shape[1]):\n        for k in range(image.shape[2]):\n            norm_img[i,j,k] = (image[i,j,k]/np.sum(image[i,j,:]))*255\nplt.imshow(norm_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-----Converting image to LAB Color model----------------------------------- \nlab = cv2.cvtColor(norm_img.copy(), cv2.COLOR_RGB2LAB)\nplt.imshow(lab)\nplt.show()\n#-----Splitting the LAB image to different channels-------------------------\nl, a, b = cv2.split(lab.copy())\nplt.imshow(l ,'gray')\nplt.show()\nplt.imshow(a ,'gray')\nplt.show()\nplt.imshow(b ,'gray')\nplt.show()\n#-----Applying CLAHE to L-channel-------------------------------------------\nclahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\ncl = clahe.apply(l.copy())\nplt.imshow(cl)\nplt.show()\n#-----Merge the CLAHE enhanced L-channel with the a and b channel-----------\nlimg = cv2.merge((cl.copy(),a.copy(),b.copy()))\nplt.imshow(limg.copy())\nplt.show()\n#-----Converting image from LAB Color model to RGB model--------------------\nfinal = cv2.cvtColor(limg.copy(), cv2.COLOR_LAB2RGB)\nplt.imshow(final)\nplt.show()\n#_____END_____#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"invert_contrast_img = cv2.bitwise_not(final.copy())\nplt.imshow(invert_contrast_img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = ['RED','GREEN','BLUE']\nfor i in range(3):\n    print(a[i])\n    plt.imshow(invert_contrast_img[:,:,i],'gray')\n    plt.axis('off')\n    plt.show()\nred_channel_img = invert_contrast_img[:,:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(red_channel_img,'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"histogram_data = np.array(np.unique(red_channel_img, return_counts=True))\nindices = list(histogram_data[0])\nvalues = list(histogram_data[1])\nbins = range(256)\nhist_values = []\nfor i in range(256):\n    if i in indices:\n        hist_values.append(values[indices.index(i)])\n    else:\n        hist_values.append(0)\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.bar(bins,hist_values)\nplt.title('RED CHANNEL COLOR HISTOGRAM')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_px = np.sum(np.multiply(indices, values))//np.sum(values)\nprint('avg = ',avg_px)\nT = np.sum(np.multiply(indices[indices.index(avg_px):],values[indices.index(avg_px):]))//np.sum(values[indices.index(avg_px):])\nprint('T = ',T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"frgnd_enhanced = red_channel_img.copy()\nplt.imshow(frgnd_enhanced, 'gray')\nplt.show()\nfor i in range(frgnd_enhanced.shape[0]):\n    for j in range(frgnd_enhanced.shape[1]):\n        if frgnd_enhanced[i,j]<=T:\n            frgnd_enhanced[i,j] //= red_channel_img[i,j]\n        else:\n            frgnd_enhanced[i,j] = 0\nplt.imshow(frgnd_enhanced, 'gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gray_img = frgnd_enhanced.copy()\nplt.imshow(gray_img,'gray')\n\nblur_img = cv2.medianBlur(gray_img.copy(),5)\n\nret,th1 = cv2.threshold(blur_img,127,255,cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nth2 = cv2.adaptiveThreshold(blur_img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n            cv2.THRESH_BINARY,11,2)\nth3 = cv2.adaptiveThreshold(blur_img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n            cv2.THRESH_BINARY,11,2)\n\ntitles = ['Original Image', 'Global Thresholding (v = 127)',\n            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\nimages = [blur_img, th1, th2, th3]\n\nfor i in range(4):\n    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n    plt.title(titles[i])\n    plt.xticks([]),plt.yticks([])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"invert_binary_img = cv2.bitwise_not(th1.copy())\nplt.imshow(invert_binary_img, 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"indices[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nannots = pd.read_csv('../input/blood-cell-detection-dataset/annotations.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def augment_colors(im):\n    for i in range(im.shape[0]):\n        for j in range(im.shape[1]):\n            if(im[i,j,1]!=np.max(im[i,j,:])):\n                if im[i,j,0]>im[i,j,2]:\n                    im[i,j,2]/=im[i,j,0]\n                elif im[i,j,0]<im[i,j,2]:\n                    im[i,j,0]/=im[i,j,2]\n            else:\n                im[i,j,:] = [255,255,255]\n    \n    return im","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aug_img = augment_colors(image.copy())\nplt.imshow(aug_img)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gray_img = cv2.cvtColor(aug_img.copy(),cv2.COLOR_BGR2GRAY)\nplt.imshow(gray_img,'gray')\n\nblur_img = cv2.medianBlur(gray_img.copy(),5)\n\nret,th1 = cv2.threshold(blur_img,127,255,cv2.THRESH_BINARY)\nth2 = cv2.adaptiveThreshold(blur_img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n            cv2.THRESH_BINARY,11,2)\nth3 = cv2.adaptiveThreshold(blur_img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n            cv2.THRESH_BINARY,11,2)\n\ntitles = ['Original Image', 'Global Thresholding (v = 127)',\n            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\nimages = [blur_img, th1, th2, th3]\n\nfor i in range(4):\n    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n    plt.title(titles[i])\n    plt.xticks([]),plt.yticks([])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"border_min_img = cv2.bitwise_not(max_img.copy())\nplt.imshow(border_min_img, 'gray')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"border_img_2 = cv2.bitwise_not(th2.copy())\nplt.imshow(border_img_2, 'gray')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_img = border_img_2.copy()\nmax_img = border_img_2.copy()\nmin_img = border_img_2.copy()\nfor i in range(border_img_2.shape[0]):\n    for j in range(border_img_2.shape[1]):\n        avg_img[i,j] = (border_img_3[i,j]+border_img_2[i,j])//2\n        max_img[i,j] = max(border_img_3[i,j],border_img_2[i,j])\n        min_img[i,j] = min(border_img_3[i,j],border_img_2[i,j])\nplt.imshow(avg_img, 'gray')\nplt.show()\nplt.imshow(max_img, 'gray')\nplt.show()\nplt.imshow(min_img, 'gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gray = min_img.copy() # convert to grayscale\nblur = cv2.blur(gray, (3, 3)) # blur the image\nret, thresh = cv2.threshold(blur, 50, 255, cv2.THRESH_BINARY)\nim2, contours = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 1\nwhile i < 9:\n    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(i,i))\n    closing = cv2.morphologyEx(border_img.copy(), cv2.MORPH_CLOSE, kernel)\n    plt.imshow(closing)\n    plt.axis('off')\n    plt.show()\n    i+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(np.subtract(cv2.cvtColor(image.copy(),cv2.COLOR_BGR2GRAY),th3.copy()), 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_w_border = image.copy()\nfor i in range(image.shape[0]):\n    for j in range(image.shape[1]):\n        if img_w_border[i,j,1] != max(img_w_border[i,j,:]) and :\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hsv_im = cv2.cvtColor(aug_img.copy(), cv2.COLOR_BGR2HSV)\nh,s,v = cv2.split(hsv_im)\nplt.imshow(h,'gray')\nplt.show()\nplt.imshow(s,'gray')\nplt.show()\nplt.imshow(v,'gray')\nplt.show()\n(threshx, binary_img) = cv2.threshold(gray_img, 127, 0, cv2.THRESH_BINARY)\nplt.imshow(binary_img,'gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\ngradient = cv2.morphologyEx(gray,cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5)))\nplt.imshow(gradient)\nplt.show()\nplt.imshow(gray)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(gradient.shape[0]):\n    for j in range(gradient.shape[1]):\n        if gradient[i,j,1] == np.max(gradient[i,j,:]):\n            gradient[i,j,1]*=2\n            gradient[i,j,0]/=2\n            gradient[i,j,2]/=2\n        if gradient[i,j,0] == np.max(gradient[i,j,:]):\n            gradient[i,j,0]*=2\n            gradient[i,j,1]/=2\n            gradient[i,j,2]/=2\n\nplt.imshow(gradient)\nplt.imshow(np.subtract(gradient, image))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import skimage.morphology\nplt.imshow(skimage.morphology.diameter_closing(image, diameter_threshold=8, connectivity=2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1,6):\n    increase_contrast(image.copy(),i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def increase_contrast(image):\n    img = image.copy()\n    lab= cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n    l, a, b = cv2.split(lab)\n    f, axarr = plt.subplots(3,6)\n    axarr[0,0].imshow(img)\n    axarr[0,1].imshow(lab)\n    axarr[0,2].imshow(l)\n    axarr[0,3].imshow(a)\n    axarr[0,4].imshow(b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def trial_grads(im):\n    for i in range(im.shape[0]):\n        for j in range(im.shape[1]):\n            if(im[i,j,1]!=np.max(im[i,j,:])):\n                if im[i,j,0]>im[i,j,2]:\n                    im[i,j,2]/=im[i,j,0]\n                elif im[i,j,0]<im[i,j,2]:\n                    im[i,j,0]/=im[i,j,2]\n            else:\n                im[i,j,:] = [0,0,0]\n    return im","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_im(image):\n    im = image\n    for i in range(im.shape[0]):\n        for j in range(im.shape[1]):\n            if(im[i,j,1]!=np.max(im[i,j,:])):\n                if im[i,j,0]<im[i,j,2]:\n                    im[i,j,:] = [255,255,255]\n                elif im[i,j,0]>im[i,j,2]:\n                    im[i,j,:] = [0,0,0]\n            else:\n                im[i,j,:] = [0,0,0]\n    return im","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(trial_grads(image))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(binars_img,'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"erosion_copy = binars_img.copy()\ndilation_copy = binars_img.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dilation_copy.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamond = np.array([[0,0,1,0,0],[0,1,1,1,0],[1,1,1,1,1],[0,1,1,1,0],[0,0,1,0,0]])\ndiamond.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"square= np.array([[0,1,0],[1,1,1],[0,1,0]])\nplt.imshow(cv2.dilate(dilation_copy,np.ones((2,2),int), iterations = 1),'gray')\nplt.show()\ndilated_img = cv2.dilate(dilation_copy,np.ones((2,2),int), iterations = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hsv_im = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\nh,s,v = cv2.split(hsv_im)\nplt.imshow(s,'gray')\nplt.show()\n(threshx, binaryx) = cv2.threshold(s, 127, 0, cv2.THRESH_BINARY)\nplt.imshow(binaryx,'gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(s,'gray')\nplt.show()\nplt.imshow(np.subtract(preprocess_im(image),s),'gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im = preprocess_im(image)\ngray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n(thresh, binary) = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\nplt.imshow(binary, 'gray')\nplt.show()\nkernel = np.ones((5,5), np.uint8) \nimg_dilation = cv2.dilate(binary, kernel, iterations=1) \nplt.imshow(img_dilation, 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_img(im):\n    for i in range(im.shape[0]):\n        for j in range(im.shape[1]):\n            try:\n                if np.mean(im[i-2:i,j-2:j+2,:])>np.mean(im[i,j-2:j+2,:]) and np.mean(im[i+1:i+3,j-2:j+2,:])>np.mean(im[i,j-2:j+2,:]):\n                   im[i+1:i+3,j-2:j+2,:] = im[i+1:i+3,j-2:j+2,:]*int(np.mean(im[i,j-2:j+2,:]))\n            except:\n                continue\n    plt.imshow(im,'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gray = cv2.cvtColor(gradient, cv2.COLOR_BGR2GRAY)\n(thresh, binary) = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\nplt.imshow(binary, 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n# draw all contours\nnew_image = cv2.drawContours(gradient, contours, -1, (0, 255, 0), 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(new_image,'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n  \n# Find Canny edges \nedged = cv2.Canny(gray, 30, 200) \ncv2.waitKey(0) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = new_image.copy()\ngray = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY) \ncircles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1.2, 100)\n# ensure at least some circles were found\nif circles is not None:\n    # convert the (x, y) coordinates and radius of the circles to integers\n    circles = np.round(circles[0, :]).astype(\"int\")\n    # loop over the (x, y) coordinates and radius of the circles\n    for (x, y, r) in circles:\n        # draw the circle in the output image, then draw a rectangle\n        # corresponding to the center of the circle\n        cv2.circle(output, (x, y), r, (0, 255, 0), 4)\n        cv2.rectangle(output, (x - 5, y - 5), (x + 5, y + 5), (0, 128, 255), -1)\n    # show the output image\n    cv2.imshow(output, np.hstack([image, output]))\n    cv2.waitKey(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nret, thresh1 = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY + \n                                            cv2.THRESH_OTSU)      \nplt.imshow(edged,'gray')\nplt.imshow(np.add(gray, edged),'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Finding Contours \n# Use a copy of the image e.g. edged.copy() \n# since findContours alters the image \ncontours, hierarchy = cv2.findContours(edged,  \n    cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n  \ncv2.imshow('Canny Edges After Contouring', edged) \ncv2.waitKey(0) \n  \nprint(\"Number of Contours found = \" + str(len(contours))) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n  \n# Draw all contours \n# -1 signifies drawing all contours \ncv2.drawContours(image, contours, -1, (0, 255, 0), 3) \n  \ncv2.imshow('Contours', image) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"  \n# Draw all contours \n# -1 signifies drawing all contours \ncv2.drawContours(image, contours, -1, (0, 255, 0), 3) \n  \ncv2.imshow('Contours', image) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\ngrayimg = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n\nplt.imshow(grayimg,'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel = np.ones((2,1),int)\nequ = cv2.morphologyEx(image, cv2.MORPH_GRADIENT, kernel)\n#gradient = cv2.equalizeHist(equ)\nplt.imshow(equ)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image[:,:,0])\nplt.show()\nplt.imshow(image[:,:,1])\nplt.show()\nplt.imshow(image[:,:,2])\nplt.show()\nplt.imshow(image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = cv2.cvtColor(image, cv2.COLOR_GRAY2BINARY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.ndimage\nkernel = np.array([[-1,0,-1],[-2,0,2],[-1,0,1]])\ngradient = cv2.morphologyEx(image,cv2.MORPH_GRADIENT, kernel)\nplt.imshow(gradient)\nplt.show()\nplt.imshow(image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lap_kernel = np.array([[0,-1,0],[-1,4,-1],[0,-1,0]])\nlap_kernel.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c,i = 0,0\nprevfile = ''\nd = Dict()\nfor file in annots['image']:\n    im = cv2.imread('../input/blood-cell-detection-dataset/images/'+file)\n    label = annots.loc[i,'label']\n    if prevfile == file:\n        c+=1\n    else:\n        c = 0\n    [_,xmin,ymin, xmax, ymax, _] = annots.loc[annots['image']==file,:].loc[c]\n    [xmin, ymin, xmax, ymax] = [int(x) for x in [xmin, ymin, xmax, ymax]]\n    if label in d.keys():\n        d[label].append(im[xmin:xmax, ymin:ymax])\n    else:\n        d[label] = im[xmin:xmax, ymin:ymax]\n    prevfile = file\n    i+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"[_,xmin,ymin, xmax, ymax, _] = annots.loc[annots['image']=='image-100.png',:].loc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}