{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/flight-delays/flights.csv')\ndf = df.iloc[:75000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['DATE'] = pd.to_datetime(df[['YEAR','MONTH', 'DAY']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\ndef format_heure(chaine):\n    if pd.isnull(chaine):\n        return np.nan\n    else:\n        if chaine == 2400: chaine = 0\n        chaine = \"{0:04d}\".format(int(chaine))\n        heure = datetime.time(int(chaine[0:2]), int(chaine[2:4]))\n        return heure\n\ndef combine_date_heure(x):\n    if pd.isnull(x[0]) or pd.isnull(x[1]):\n        return np.nan\n    else:\n        return datetime.datetime.combine(x[0],x[1])\n\ndef create_flight_time(df, col):    \n    liste = []\n    for index, cols in df[['DATE', col]].iterrows():    \n        if pd.isnull(cols[1]):\n            liste.append(np.nan)\n        elif float(cols[1]) == 2400:\n            cols[0] += datetime.timedelta(days=1)\n            cols[1] = datetime.time(0,0)\n            liste.append(combine_date_heure(cols))\n        else:\n            cols[1] = format_heure(cols[1])\n            liste.append(combine_date_heure(cols))\n    return pd.Series(liste)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['SCHEDULED_DEPARTURE2'] = create_flight_time(df, 'SCHEDULED_DEPARTURE')\ndf['SCHEDULED_ARRIVAL2'] = create_flight_time(df, 'SCHEDULED_ARRIVAL')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport math\ndef last_arr_delay(x):\n    delay_list = []\n    for index, row in x.iterrows():\n        cadi = x[(x.DESTINATION_AIRPORT == row.ORIGIN_AIRPORT) \n                 & (x.SCHEDULED_ARRIVAL2 < row.SCHEDULED_DEPARTURE2)\n                 & ((row.SCHEDULED_DEPARTURE2 - x.SCHEDULED_ARRIVAL2) < pd.Timedelta('2 hours'))\n                ]\n        last_time_delay = 0\n        if len(cadi) > 0 :\n            last_time_delay = (cadi.loc[cadi['SCHEDULED_ARRIVAL2'].idxmax()]).ARRIVAL_DELAY\n        delay_list.append(last_time_delay)\n\n    return(delay_list)  \n\ndef last_dep_delay(x):\n    delay_list = []\n    for index, row in x.iterrows():\n        cadi = x[(x.ORIGIN_AIRPORT == row.ORIGIN_AIRPORT) \n                 & (x.SCHEDULED_DEPARTURE2 < row.SCHEDULED_DEPARTURE2)\n                 & ((row.SCHEDULED_DEPARTURE2 - x.SCHEDULED_DEPARTURE2) < pd.Timedelta('2 hours'))\n                ]\n\n        last_time_delay = 0\n        if len(cadi) > 0 :\n            last_time_delay = (cadi.loc[cadi['SCHEDULED_DEPARTURE2'].idxmax()]).DEPARTURE_DELAY\n        delay_list.append(last_time_delay)\n\n    return(delay_list) \n\n\nstart_time = time.time()\ndf['last_arr_delay'] = last_arr_delay(df)\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\n\nstart_time = time.time()\ndf['last_dep_delay'] = last_dep_delay(df)\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df = df.iloc[:10000,:]\ndf = df[ df.CANCELLED != 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df = df.sample(frac=0.01, replace=True, random_state=1)  # 50k","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# เนื่องจากไม่ได้ใช้ข้อมูล cancelled และข้อมูลมีมากไม่เหมาะการทำ onehot \ndf = df.drop(columns=['CANCELLATION_REASON', 'CANCELLED','ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', \n                      'TAIL_NUMBER', 'ARRIVAL_TIME', 'FLIGHT_NUMBER','DIVERTED',\n                      'ELAPSED_TIME','AIR_TIME','WHEELS_ON','TAXI_IN','AIR_SYSTEM_DELAY', \n                      'SECURITY_DELAY','AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.dropna()\ndf= df.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#เปลี่ยนคอลัมน์ให้เป็น classification\ndf['FLIGHT_DELAY'] = np.where(df['ARRIVAL_DELAY'] > 0, 1,0)\ndel df['ARRIVAL_DELAY']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('FLIGHT_DELAY').size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Day of month\ndf2 = df[df['FLIGHT_DELAY'] ==1]\n\nday_tmp = []\nfor n in  df2['DAY'].tolist() :\n    if n < 11 :\n        day_tmp.append(\"begin\")\n    elif n < 21:\n        day_tmp.append(\"middle\")\n    else:\n         day_tmp.append(\"end\")\n\ndf2['DAY_CLASS'] = day_tmp\ndf2['DAY_CLASS'].value_counts()   \n\nplt.bar(df2['DAY_CLASS'].value_counts().index.tolist(),\ndf2['DAY_CLASS'].value_counts().values.tolist(),\ncolor=['blue'])\nplt.title(\"Class label distribution\")\nplt.ylabel('Frequency')\nplt.xlabel('Class label')\nplt.tight_layout()\n#เนื่องจาก การ plotค่าของ day_tmpที่แบ่งclass เป็น 3 ช่วง พบว่าไม่มีความแตกต่างกันอย่างมีนัยสำคัญ ซึ่งจะถูกดรอปออกในภายหลัง","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Day of week\nplt.bar(df2['DAY_OF_WEEK'].value_counts().index.tolist(),\ndf2['DAY_OF_WEEK'].value_counts().values.tolist(),\ncolor=['blue'])\nplt.title(\"Class label distribution\")\nplt.ylabel('Frequency')\nplt.xlabel('Class label')\nplt.tight_layout()\n\n# 3 class 4,5= d_high, 1,2,3,7=d_medium  6= d_low","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"day_tmp = []\nfor n in  df['DAY_OF_WEEK'].tolist() :\n    if n in [4,5] :\n        day_tmp.append('d_high')\n    elif n in [1, 2, 3, 7]  :\n        day_tmp.append('d_medium')\n    else: \n        day_tmp.append('d_low')\n    \n\ndf['day_delay'] = day_tmp\ndf['day_delay'].value_counts()   \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(df2['MONTH'].value_counts().index.tolist(),\ndf2['MONTH'].value_counts().values.tolist(),\ncolor=['blue'])\nplt.title(\"Class label distribution\")\nplt.ylabel('Frequency')\nplt.xlabel('Class label')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"month_tmp = []\nfor n in  df['MONTH'].tolist() :\n    if n in [9,10,11] :\n        month_tmp.append('M_low')\n    elif n in [2,4,5] :\n        month_tmp.append('M_medium')\n    else: \n        month_tmp.append('M_high')\n        \ndf['month_class'] = month_tmp\ndf['month_class'].value_counts()   \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SCHEDULED_DEPARTURE\ndef time_to_string(n):\n    if n  < 100 :\n        return('0')\n    elif n < 200 :\n        return('1')\n    elif n < 300 :\n        return('2')\n    elif n < 400 :\n        return('3')    \n    elif n < 500 :\n        return('4')        \n    elif n < 600 :\n        return('5')\n    elif n < 700 :\n        return('6')\n    elif n < 800 :\n        return('7')\n    elif n < 900 :\n        return('8')    \n    elif n < 1000 :\n        return('9')\n    elif n < 1100 :\n        return('10')\n    elif n < 1200 :\n        return('11')\n    elif n < 1300 :\n        return('12')\n    elif n < 1400 :\n        return('13')\n    elif n < 1500 :\n        return('14')    \n    elif n < 1600 :\n        return('15')        \n    elif n < 1700 :\n        return('16')\n    elif n < 1800 :\n        return('17')\n    elif n < 1900 :\n        return('18')\n    elif n < 2000 :\n        return('19')    \n    elif n < 2100 :\n        return('20')\n    elif n < 2200 :\n        return('21')\n    elif n < 2300 :\n        return('22')\n    else: \n        return('23')\n    \ntime_tmp = []\nfor n in  df2['SCHEDULED_DEPARTURE'].tolist() :\n        time_tmp.append(time_to_string(n))\n\n        \ndf2['time_tmp'] = time_tmp\ndf2['time_tmp'].value_counts()   \n\nplt.bar(df2['time_tmp'].value_counts().index.tolist(),\ndf2['time_tmp'].value_counts().values.tolist(),\ncolor=['blue'])\nplt.title(\"Class label distribution\")\nplt.ylabel('Frequency')\nplt.xlabel('Class label')\nplt.tight_layout()\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hour_tmp = []\nfor n in  df['SCHEDULED_DEPARTURE'].tolist() :\n    n = time_to_string(n)\n    if n in ['17','15', '19', '18', '16', '13'] :\n        hour_tmp.append('H_high')\n    elif n in ['14', '12', '11', '10'] :\n        hour_tmp.append('H_medium')\n    elif n in ['8', '20', '9', '7','6', '21'] :\n        hour_tmp.append('H_low')\n    else: \n        hour_tmp.append('H_lowest')\n        \ndf['hour_class'] = hour_tmp\ndf['hour_class'].value_counts()   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"clean data ก่อนทำ OnehotEncoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop year, month, day, day of week, airline  เพราะว่าเราทำเป็นclass แล้ว\ndf = df.drop(columns=['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'AIRLINE'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape\n#ทำ object type ให้เป็นอยู่ในรูปแบบ onehot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from  sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder(categories='auto')\nfeature_arr = ohe.fit_transform(df[['month_class', 'hour_class','day_delay']]).toarray() # list of one-hot-encoder\n#print(feature_arr)\nfeature_labels = ohe.categories_  # list of new column name  \n#print(feature_labels)\n#feature_labels = np.array(feature_labels).ravel() # no effect\nfeature_labels =  np.concatenate((feature_labels), axis=None)\n#print(feature_labels)\nfeatures = pd.DataFrame(feature_arr, columns=feature_labels)\ndf = pd.concat([features,df], axis=1, sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n%matplotlib inline\n\n# calculate the correlation matrix\ncorr = df.corr()\n\n# plot the heatmap\nsns.heatmap(corr, \n        xticklabels=corr.columns,\n        yticklabels=corr.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_cols = ['SCHEDULED_DEPARTURE','DEPARTURE_TIME','DEPARTURE_DELAY',\n                'TAXI_OUT','WHEELS_OFF','SCHEDULED_TIME',\n                'DISTANCE','SCHEDULED_ARRIVAL']\n\nfor col in numeric_cols:\n    df[col] = pd.to_numeric(df[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor col in numeric_cols:\n    print(\"Column name:  \" + col)\n    q1= df[col].quantile(0.25)\n    q3 = df[col].quantile(0.75)\n    iqr = q3-q1\n    lower_bound = q1 -(1.5 * iqr)\n    upper_bound = q3 +(1.5 * iqr)\n    print('q1 = {}'.format(q1))\n    print('q3 = {}'.format(q3))\n    print('iqr = {}'.format(iqr))\n    print('lower bound = {}, upper bound = {}'.format(lower_bound, upper_bound))\n    outlier_row_indice = df[(df[col] < lower_bound) | (df[col]>upper_bound)].index\n    print('number of outliers = {}'.format(len(outlier_row_indice)))\n    print('indices of outliers = ', outlier_row_indice.to_list())\n    print(\"######################################\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(numeric_cols)\nfig, axes = plt.subplots(figsize=(18, 10), nrows=3, ncols=3, squeeze=0)\ni=0\nfor ax, col in zip(axes.reshape(-1), numeric_cols):\n      ax.boxplot(df[col], labels=[col], sym='k.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['FLIGHT_DELAY'].tolist()\n\ndel df['FLIGHT_DELAY']\ndel df['month_class']\ndel df['hour_class']\ndel df['day_delay']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df['DATE']\ndel df['SCHEDULED_DEPARTURE2']\ndel df['SCHEDULED_ARRIVAL2']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df = pd.concat([df,features], axis=1)\nX = df.iloc[:, :].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"can't use feature selection because \"Input X must be non-negative.\""},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Scaler**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**การสร้าง model เพื่อทำนายผลลัพธ์ของความ delay โดย DecisionTreeClassifier  **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ทำนายผลของ decisionTree model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**แสดงค่า Accurency precision recall **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nprint(\"Performance:\")\nprint(\" >accuracy = \" + str(accuracy))\nprint(\" >precision = \" + str(precision))\nprint(\" >recall = \" + str(recall))\nprint(\" >f1 = \" + str(f1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**find best learning rate from GradientBoostingClassifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n\nlr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n\nfor learning_rate in lr_list:\n    gb_clf = GradientBoostingClassifier(n_estimators=10, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n    gb_clf.fit(X_train, y_train)\n\n    print(\"Learning rate: \", learning_rate)\n    print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n    print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test, y_test)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**นำค่า learning rate ที่ได้ค่า Accurency สูงสุดมาสร้าง model และประมวลผล**"},{"metadata":{},"cell_type":"markdown","source":"**GradientBoostingClassifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_clf2 = GradientBoostingClassifier(n_estimators=20, learning_rate=0.75, max_features=2, max_depth=2, random_state=0)\ngb_clf2.fit(X_train, y_train)\npredictions = gb_clf2.predict(X_test)\n\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, predictions))\n\nprint(\"Classification Report\")\nprint(classification_report(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**k-Nearest Neighbors (k-NN)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\n#create new a knn model\nknn = KNeighborsClassifier()\n#create a dictionary of all values we want to test for n_neighbors\nparams_knn = {'n_neighbors': np.arange(1, 5)}\n#use gridsearch to test all values for n_neighbors\nknn_gs = GridSearchCV(knn, params_knn, cv=5)\n#fit model to training data\nknn_gs.fit(X_train, y_train)\n\n#save best model\nknn_best = knn_gs.best_estimator_\n#check best n_neigbors value\nprint(knn_gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n#create a new random forest classifier\nrf = RandomForestClassifier()\n#create a dictionary of all values we want to test for n_estimators\nparams_rf = {'n_estimators': [100, 200]}\n#use gridsearch to test all values for n_estimators\nrf_gs = GridSearchCV(rf, params_rf, cv=5)\n#fit model to training data\nrf_gs.fit(X_train, y_train)\n\n#save best model\nrf_best = rf_gs.best_estimator_\n#check best n_estimators value\nprint(rf_gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**LogisticRegression with GridSearchCV **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'penalty':['l2'], # l1 is Lasso, l2 is Ridge\n    'class_weight' : ['dict', 'balanced'],\n    'C': [0.01,0.10,0.25,0.50,0.75,1.0],#np.linspace(0.00002,1,100),\n    'solver' : ['newton-cg', 'lbfgs',  'sag', 'saga']\n}\n\nlr = LogisticRegression()\nlr_gs = GridSearchCV(lr, params, cv=3, verbose=1).fit(X_train, y_train)\n\nprint (\"Best Params\", lr_gs.best_params_)\nprint (\"Best Score\", lr_gs.best_score_)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_best = LogisticRegression(C= 0.75, class_weight = 'dict', penalty = 'l2', solver = 'lbfgs')\nlr_best.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** show score **"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('knn: {}'.format(knn_best.score(X_test, y_test)))\nprint('rf: {}'.format(rf_best.score(X_test, y_test)))\nprint('log_reg: {}'.format(lr_best.score(X_test, y_test)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SVM**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nclf = SVC(gamma='auto')\nclf.fit(X_train, y_train) \nclf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Voting Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n#create a dictionary of our models\nestimators=[('gb', gb_clf2), ('clf', clf), ('log_reg', lr_best)]\n#create our voting classifier, inputting our models\nensemble = VotingClassifier(estimators, voting='hard')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit model to training data\nensemble.fit(X_train, y_train)\n#test our model on the test data\nensemble.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\n\nparams = {'loss_function':'Logloss', # objective function\n          'eval_metric':'AUC', # metric\n          'verbose': 200, # output to stdout info about training process every 200 iterations\n          'random_seed': 1\n         }\nclassifier = CatBoostClassifier(**params)\nclassifier.fit(X_train, y_train, # data to train on (required parameters, unless we provide X as a pool object, will be shown below)\n          eval_set=(X_valid, y_valid), # data to validate on\n          use_best_model=True, # True if we don't want to save trees created after iteration with the best validation score\n          plot=True # True for visualization of the training process (it is not shown in a published kernel - try executing this code)\n         );","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting the Test Set results\ny_pred = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred.round())\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nprint(\"Performance:\")\nprint(\" >accuracy = \" + str(accuracy))\nprint(\" >precision = \" + str(precision))\nprint(\" >recall = \" + str(recall))\nprint(\" >f1 = \" + str(f1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# X_train, X_test, y_train, y_test = train_test_split(X_opt, y, test_size = 0.2, random_state = 0)\n# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from catboost import CatBoostClassifier\n\n# params = {'loss_function':'Logloss', # objective function\n#           'eval_metric':'AUC', # metric\n#           'verbose': 200, # output to stdout info about training process every 200 iterations\n#           'random_seed': 1\n#          }\n# classifier = CatBoostClassifier(**params)\n# classifier.fit(X_train, y_train, # data to train on (required parameters, unless we provide X as a pool object, will be shown below)\n#           eval_set=(X_valid, y_valid), # data to validate on\n#           use_best_model=True, # True if we don't want to save trees created after iteration with the best validation score\n#           plot=True # True for visualization of the training process (it is not shown in a published kernel - try executing this code)\n#          );","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Predicting the Test Set results\n# y_pred = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.metrics import confusion_matrix\n# cm = confusion_matrix(y_test, y_pred.round())\n# print(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n# accuracy = accuracy_score(y_test, y_pred)\n# precision = precision_score(y_test, y_pred)\n# recall = recall_score(y_test, y_pred)\n# f1 = f1_score(y_test, y_pred)\n\n# print(\"Performance:\")\n# print(\" >accuracy = \" + str(accuracy))\n# print(\" >precision = \" + str(precision))\n# print(\" >recall = \" + str(recall))\n# print(\" >f1 = \" + str(f1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\ndef find_last_fligt(x):\n    fl_list = []\n    for index, row in x.iterrows():\n        cadi = x[(x.ORIGIN_AIRPORT == row.ORIGIN_AIRPORT) | (x.DESTINATION_AIRPORT == row.ORIGIN_AIRPORT)]\n        cadi = cadi.drop( index = index) # remove itsefe from cadidate\n        #print(cadi.shape)\n        #print(row.SCHEDULED_DEPARTURE)\n        tmp = [ x.loc[[index]] for index, item in cadi.iterrows() if item.SCHEDULED_DEPARTURE2 < row.SCHEDULED_DEPARTURE2 \n               or item.SCHEDULED_ARRIVAL2 < row.SCHEDULED_DEPARTURE2]\n        if tmp != []:\n          #print(tmp[0].SCHEDULED_DEPARTURE, tmp[0].SCHEDULED_ARRIVAL, row.SCHEDULED_DEPARTURE)\n          #print(len(tmp), row.SCHEDULED_DEPARTURE )\n          #print(tmp[0].ORIGIN_AIRPORT, tmp[0].DESTINATION_AIRPORT, tmp[0].index )\n          closest_time = (tmp[0].SCHEDULED_DEPARTURE2.tolist())[0]\n          closest_row = tmp[0]\n          for n in tmp :\n            tmp_time = (n.SCHEDULED_DEPARTURE2.tolist())[0]\n            if closest_time < tmp_time :\n                closest_time = tmp_time\n                closest_row = n\n       #   fl_list.append(closest_row.ARRIVAL_DELAY)\n          last_time_delay = (closest_row.ARRIVAL_DELAY.tolist())[0]\n          if math.isnan(last_time_delay):\n            fl_list.append(0)\n          else:\n            fl_list.append(last_time_delay)\n          \n        else:\n            fl_list.append(0)\n    #print(fl_list)\n    return(fl_list)  \n        ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}