{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\ntotal_files = 0\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    total_files += len(filenames)\n    # for filename in filenames:\n    #    print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Citing for ScispaCy\nNeumann, Mark et al. “ScispaCy: Fast and Robust Models for Biomedical Natural Language Processing.” BioNLP@ACL (2019)."},{"metadata":{},"cell_type":"markdown","source":"**Inspired from other sources such as** [this](https://towardsdatascience.com/how-to-get-started-analyzing-covid-19-data-808822437c32). The idea of this approach is to convert the abstracts to vectors and analyse the cosine similarity (to get a sense of the direction of the abstracts)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print(\"COVID-19 Research Analysis - checksum, total files = \" + str(total_files))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Expected output = COVID-19 Research Analysis - checksum, total files = 52101 (as of 4/4/2020)"},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata = pd.read_csv('/kaggle/input/CORD-19-research-challenge/metadata.csv')\nmetadata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Count of all the unique publication journals"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(metadata.journal.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install scispacy\n!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_lg-0.2.4.tar.gz","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plan of action\n**1.Dataset analysis - similarity/pcs/t-sne. No supervision in this stage.**\n> 1. Vectorize abstracts - currently trying scispaCy en_core_sci_sm/en_core_sci_lg models.\n> 2. First trying out cosine similarity between abstract vectors.\n> 3. Later on visualize by PCA and t-SNE.\n> 4. Eventually, I want to get the SHA from these abstracts so I can focus on the relevant (to my tasks) papers.\n> 5. So feed through softmax to classify into categories.\n\n**2.Train**\n> 1. Pick m abstracts to train, .2 * m to test.\n> 2. Model == pre-trained scispacy + softmax layer\n> 3. Train the softmax layer\n> 4. Generate stats\n\n**3. Test**\n> 1. Test on .2 * m abstracts\n> 2. Generate stats\n\n**4. Predict**\n> 1. The output of this stage is that SHAs predicted by the model are appropriate for my task(s).\n\n**5. NEXT -> can I develop a question and answer system on the papers with SHAs from the above step? Maybe like ADAM qas**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scispacy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cosine_similarity(u, v):\n    \"\"\"\n    Coded this as part of deeplearning.ai sequence modeling course\n    Cosine similarity reflects the degree of similariy between u and v\n        \n    Arguments:\n        u -- a word vector of shape (n,)          \n        v -- a word vector of shape (n,)\n\n    Returns:\n        cosine_similarity -- the cosine similarity between u and v defined by the formula above.\n    \"\"\"\n    \n    distance = 0.0\n\n    # Compute the dot product between u and v (≈1 line)\n    dot = np.dot(u, v)\n    # Compute the L2 norm of u (≈1 line)\n    norm_u = np.sqrt(np.sum(u * u))\n    \n    # Compute the L2 norm of v (≈1 line)\n    norm_v = np.sqrt(np.sum(v * v))\n    # Compute the cosine similarity defined by formula (1) (≈1 line)\n    cosine_similarity = dot / (norm_u * norm_v)\n    \n    return cosine_similarity","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test Large sci model\n> 1. Small model gave highly unsatisfactory results. Let's try large model that is trained on large body of corpora.\n> 2. A thought, if I can use a query formed by creating sentences with similar meaning as the original query, will it retrieve relevant results.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp_lg = spacy.load(\"en_core_sci_lg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vector_dict_lg = {}\nfor sha, abstract in tqdm(metadata[[\"sha\",\"abstract\"]].values):\n    if isinstance(abstract, str):\n        vector_dict_lg[sha] = nlp_lg(abstract).vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keys_lg = list(vector_dict_lg.keys())\nvalues_lg = list(vector_dict_lg.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"top 5 keys = {keys}, and values = {values}\".format(keys = keys_lg[0:5], values = values_lg[0:5]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valarray_lg = np.asarray(values_lg, dtype=np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cosine_sim_matrix_lg = cosine_similarity(valarray_lg, valarray_lg.T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(cosine_sim_matrix_lg))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# same SHA as before\ninput_sha = \"aecbc613ebdab36753235197ffb4f35734b5ca63\"\nn_sim_articles = 5\n\n\nsha_index_lg = keys_lg.index(input_sha)\nsim_indexes_lg = np.argsort(cosine_sim_matrix_lg[sha_index_lg])[::-1][1:n_sim_articles+1]\nsim_shas_lg = [keys_lg[i] for i in sim_indexes_lg]\nmeta_info_lg = metadata[metadata.sha.isin(sim_shas_lg)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"=====QUERY ABSTRACT=====\")\nprint(metadata[metadata.sha == input_sha][\"abstract\"].values[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"=====TOP {n_sim_articles} SIMILAR ABSTRACTS USING LARGE MODEL=====\")\nfor abst in meta_info_lg.abstract.values:\n    print(abst)\n    print(\"=======\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's try to use a more natural query statement"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_return = 5\nnl_query_statement = \"Studies showing discrepancy between humoral and cellular immunity in genetically similar subjects may be significant in the pathogenesis of systemic lupus erythematosus (SLE).\"\nquery_vector_lg = nlp_lg(nl_query_statement).vector\ncosine_sim_matrix_query_lg = cosine_similarity(valarray_lg, query_vector_lg)\nquery_sim_indexes_lg = np.argsort(cosine_sim_matrix_query_lg.reshape(1,-1)[0])[::-1][:n_return]\nquery_shas_lg = [keys_lg[i] for i in query_sim_indexes_lg]\nmeta_info_query_lg = metadata[metadata.sha.isin(query_shas_lg)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"=====QUERY ABSTRACT=====\" + nl_query_statement)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"=====TOP {n_sim_articles} SIMILAR ABSTRACTS USING LARGE MODEL=====\")\nfor abst in meta_info_query_lg.abstract.values:\n    print(abst)\n    print(\"=======\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Query: Immunity in genetically similar subjects"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_return = 5\ngn_query_statement = \"Effectiveness of drugs being developed and tried to treat COVID-19 patients.\"\ngn_query_vector = nlp_lg(gn_query_statement).vector\ngn_cosine_sim_matrix_query = cosine_similarity(valarray_lg, gn_query_vector)\ngn_query_sim_indexes = np.argsort(gn_cosine_sim_matrix_query.reshape(1,-1)[0])[::-1][:n_return]\ngn_query_shas = [keys_lg[i] for i in gn_query_sim_indexes]\ngn_meta_info_query = metadata[metadata.sha.isin(gn_query_shas)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"=====QUERY ABSTRACT=====\" + gn_query_statement)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"=====TOP {n_sim_articles} SIMILAR ABSTRACTS USING LARGE MODEL=====\")\nfor sha, abst in zip(gn_query_shas, gn_meta_info_query.abstract.values):\n    print(\"sha: \" + sha)\n    print(\"abstract:\" + abst)\n    print(\"=======\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization\n### t-SNE and clustering"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.manifold import TSNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_sne = TSNE(verbose=1, perplexity=5)\nabstractsvec = t_sne.fit_transform(valarray_lg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Clustering plot\n> ### Use MiniBatchKMeans for speed (as it turns out KMeans is not vastly different) "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import MiniBatchKMeans\n\nk = 10\nmini_batch_kmeans = MiniBatchKMeans(n_clusters=k)\ncat_pred = mini_batch_kmeans.fit_predict(valarray_lg)\ncat = cat_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\nimport random \n\n# seaboarn settings\nsns.set(color_codes=True)\nsns.set(rc={'figure.figsize':(12,12), 'axes.facecolor':'0.25'})\n\ncolors = sns.hls_palette(10, l = .5, s = .75)\nrandom.shuffle(colors)\n\n# plot\nsns.scatterplot(abstractsvec[:,0], abstractsvec[:,1], hue = cat, legend = 'full', palette = colors)\nplt.title(\"Plot of the clusterings of the abstracts from COVID-19 challenge dataset (wordvec model = scispaCy large, Clustering = MiniBatchKMeans )\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}