{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Agrupando e manipulando dados com Pandas\n\nÉ muito comum em Data Science nós termos de responder perguntas como:\n- 'Qual a média salarial **por sexo**?'\n- 'Qual a média salarial **por região do Brasil**?'\n- 'Qual a nota máxima do ENEM **por ano**?'\n\n\nEntre muitas outras similares.\n\nVemos que todas essas perguntas possuem uma similaridade, que é a parte do final: 'por sexo', 'por cor', 'por região', 'por idade', 'por cargo', 'por ano'...\nEm geral, queremos avaliar uma métrica de acordo com cada **categoria** ou **grupo**.\n\nPara responder esse tipo de pergunta, precisamos **agrupar** nossos dados de acordo com cada categoria.\n\nO *pandas* possui uma funcionalidade muito bacana para nos ajudar, que é a função *groupby*."},{"metadata":{},"cell_type":"markdown","source":"![img](https://github.com/Giatroo/BeeData_GroupBy-in-Pandas/blob/main/split-apply-combine.jpeg?raw=true)"},{"metadata":{},"cell_type":"markdown","source":"Primeiro, importamos o pandas, nosso foco hoje, e o numpy, que vai nos ser útil mais para frente."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Antes de mais nada, as versões do numpy e pandas que utilizei para fazer esse notebook são, respectivamente, 1.19.2 e 1.2.3.\n\nIsso é importante, pois bibliotecas costumam mudar conforme o tempo e algo que eu mostrar aqui pode ficar ultrapassado no futuro."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'A versão do numpy é : {np.__version__}')\nprint(f'A versão do pandas é : {pd.__version__}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vamos agora importar nossa tabela.\n\nVou utilizar uma tabela do censo americado de 2010 a 2015."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/census/census.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"São 100 colunas ao todo, então vamos remover as que não nos interessam e manter apenas os nascimentos de cada ano e estimativa da população. Além disso, vou manter apenas as linhas onde o *sumarrary level* é *50*, pois essas são as linhas que se referem ao census de cada cidade."},{"metadata":{"trusted":true},"cell_type":"code","source":"colunas = ['STNAME', 'CTYNAME', 'BIRTHS2010', 'BIRTHS2011', 'BIRTHS2012', 'BIRTHS2013', 'BIRTHS2014',\n          'BIRTHS2015', 'POPESTIMATE2010', 'POPESTIMATE2011', 'POPESTIMATE2012', 'POPESTIMATE2013', \n          'POPESTIMATE2014', 'POPESTIMATE2015']\ndf = df[df['SUMLEV'] == 50]\ndf = df[colunas]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Formas de agrupar dados\n\nVamos agora entender como agrupar esses dados **por estado**. Suponha por exemplo, que queremos saber a média da população em cada estado, ou então a soma, ou mesmo os valores máximos e mínimos de cada cidade por estado.\n\nPara começar a fazer essas análises, precisamos, antes de mais nada, agrupar essas 3142 linhas de acordo com os estados."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['STNAME'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aqui vemos que a coluna *STNAME* possui todos os estados dos EUA, mas que várias linhas são referente ao Alabama, várias linhas são referentes à Florida e assim por diante. A primeira forma que veremos de agrupar é justamente colocar no mesmo grupo aquelas linhas que têm o mesmo valor para uma determinada coluna."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Utilizamos a função groupby passando o nome da coluna que queremos usar para agrupar\ng = df.groupby('STNAME')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Se tentarmos mostrar a variável g, vemos que ela é um objeto do tipo pandas.core.groupby.generic.DataFrameGroupBy\n# Mas ainda não conseguimos entender o que realmente aconteceu com o nosso DataFrame\ng","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A variável `g` é um **objeto** como vários outro do *pandas* (e.g. uma `Series` ou um `DataFrame`). Isso significa que temos várias funções e atributos dentro desse objeto que nós podemos usar.\n\nPor exemplo, o método `describe` vai nos gerar várias informações, como em um `DataFrame` normal, mas de forma agrupada por estado."},{"metadata":{"trusted":true},"cell_type":"code","source":"g.describe().head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veja que, para cada coluna, temos várias informações. Por exemplo, temos a média, desvio padrão, máximo, mínimo, mediana para a população de 2015:"},{"metadata":{"trusted":true},"cell_type":"code","source":"g.describe()['POPESTIMATE2015'].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Importante:** note que, depois de aplicarmos a função `describe`, o resultado é um `DataFrame`. Ou seja, podemos usar tudo aquilo que já sabemos sobre `DataFrame`'s (como acessar uma coluna, igual eu fiz acima)."},{"metadata":{"trusted":true},"cell_type":"code","source":"type(g.describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O `describe` nos traz muitas informações, mas podemos também aplicar outras funções para ter apenas aquilo que desejamos (e de forma mais rápida):"},{"metadata":{"trusted":true},"cell_type":"code","source":"g.mean().head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"g.max().head()\n# Observe que quando uma função não pode ser aplicada a uma coluna, essa coluna não aparece no resultado final.\n# Nesse caso, 'max' pode ser aplicada a CTYNAME utilizando a ordem lexográfica.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g.count().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A lista completa de operações pode ser encontrada [aqui](https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html#computations-descriptive-stats)."},{"metadata":{},"cell_type":"markdown","source":"# Acessando grupos\n\nEm muitos casos, nós precisamos acessar um grupo específico ou mesmo iterar sobre nossos grupos. "},{"metadata":{},"cell_type":"markdown","source":"Para acessar um grupo específico, usamos a função `get_group` e passamos o grupo desejado."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"g.get_group('California').head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note novamente que o resultado é um `DataFrame`. Nesse caso, todos os valores da coluna *STNAME* são 'California'.\n\nO resultado é exatamente o mesmo que quando fazemos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['STNAME'] == 'California'].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A diferença é que `g` possui muitos outros grupos e é muito mais prático, como já vimos."},{"metadata":{},"cell_type":"markdown","source":"Para iterar pelos grupos, podemos usar um `for`."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Para iterar é como se fosse um dicionário com a chave do grupo e o DataFrame\nfor chave, grupo in g:\n    print(f'O nome do grupo é {chave} e o shape é {grupo.shape}.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Espero que agora esteja começando a ficar claro quais são as funcionalidade desse tipo de objeto."},{"metadata":{},"cell_type":"markdown","source":"Para terminar essa primeira parte, vale a pena dizer que podemos indexar colunas de um objeto `groupby`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"g['BIRTHS2013'].max().head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g[['BIRTHS2010','BIRTHS2011','BIRTHS2012','POPESTIMATE2014','POPESTIMATE2015']].mean().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Outras formas de se agrupar\n\nAgora que já entendemos alguns usos básicos de um agrupamento. Vamos voltar um pouco para a função `groupby` e ver rapidamente outras formas de utiliza-la."},{"metadata":{},"cell_type":"markdown","source":"### Várias colunas\nA primeira forma é passando um array de colunas ao invés de uma única coluna."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos criar um dataframe menor para ajudar na visualização:\ndf1 = pd.DataFrame({'col1' : [1, 1, 2, 2, 2, 3],\n                  'col2' : ['no', 'yes', 'no', 'no', 'yes', 'no'],\n                  'col_val1' : np.random.rand(6),\n                  'col_val2' : np.random.randn(6)*10})\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.groupby(['col1', 'col2']).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Perceba que agora temos um `DataFrame` com um `MultiIndex` onde o nível externo é *'col1'* e o interno é *'col2'*. E note que não há uma linha `(3, 'yes')` porque essa combinação não existe."},{"metadata":{},"cell_type":"markdown","source":"**Obs.:** podemos passar uma lista com quantas colunas nós quisermos, não precisa parar em duas."},{"metadata":{},"cell_type":"markdown","source":"### Por nível em um MultiIndex\nFalando em `MultiIndex`, outra forma de agrupar é informando o nível em um `MultiIndex`."},{"metadata":{"trusted":true},"cell_type":"code","source":"colunas = pd.MultiIndex.from_arrays([['US']*3 +['BR']*2,\n                                     [1, 3, 5, 1, 3]],\n                                    names=['pais', 'num'])\nhier_df = pd.DataFrame(np.random.randn(4, 5), columns=colunas)\nhier_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# groupby aceita os keyword arguments level e axis\nhier_df.groupby(level='pais', axis='columns').max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Obs.:** como queremos agrupar pelos países (que são 'US' e 'BR') e eles são colunas, precisamos definir `axis='columns'`. Se tivéssemos um `MultiIndex` nas linhas e quisessemos agrupar nas linhas, varíamos `axis='index'` ou simplesmente não falaríamos nada (pois, `axis='index'` é o padrão). [Aqui](https://stackoverflow.com/questions/22149584/what-does-axis-in-pandas-mean) tem umas discussão interessante sobre a diferença entre os *eixos* (axis)."},{"metadata":{},"cell_type":"markdown","source":"### Usando uma função\n\nPodemos também agrupar utilizando uma função (criada por nós ou não). \n\nA função vai receber o *índice de cada linha* e deve devolver um valor que pode ser comparável. Então vamos criar os grupos de acordo com os resultados iguais da função."},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = pd.DataFrame({'nome' : ['João', 'Cláudia', 'Mariana', 'Mario', 'Joana', 'Lucas', 'Marcos'],\n                   'nota1' : np.random.randint(0, 11, size=7),\n                   'nota2' : np.random.randint(0, 11, size=7)})\ndf2 = df2.set_index('nome') # É importante que o índice seja os nomes, pois a função vai receber esses nomes\ndf2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos criar uma função que recebe uma string e retorna suas primeiras duas letras\ndef duas_letras(s):\n    # Sempre que tiver dúvida quanto a o que a função está recebendo, experimente printar o valor ou seu tipo\n    #print(s)\n    #print(type(s))\n    return s[:2]\n\n# Passamos nossa função para groupby \ndf2.groupby(duas_letras).max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veja como nós agrupamos as pessoas de acordo com as duas primeiras letras de seu nome.\n\nPoderíamos usar também funções do Python, como a função `len`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.groupby(len).max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se quisermos ver quem percente a cada grupo, uma forma prática é utilizando o *atributo* `groups` do nosso objeto `groupby`."},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.groupby(len).groups","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Agregações\n\nVamos agora passar para as principais aplicações e utilizades dos agrupamentos:\n- Gerar agregações\n- Gerar transformações\n- Filtrar grupos\n\nComeçando com as agregações.\n\nSempre que temos uma lista e geramos um número com base naquela lista, estamos gerando uma agregação. Ou seja, uma agregação é sempre uma operação que transforma uma lista de valores em um único valor. Exemplos de agregação são soma, média, mediana, desvio padrão, máximo, mínimo, produto, entre outras agregações que nós mesmos podemos criar (agregações não se restringem a números).\n\nQuando se trata de grupos, as agregações vão ser feitas dentro de cada grupo. Ou seja, se utilizamos uma média, vamos ter a média dos valores de cada grupo.\n\nNo pandas, as funções `agg` ou `aggregate` são utilizadas para fazer agregações (não existe diferença nenhuma entre elas, `agg` é um *alias* para *aggregate*)."},{"metadata":{},"cell_type":"markdown","source":"![image](https://github.com/Giatroo/BeeData_GroupBy-in-Pandas/blob/main/split-apply-combine2.jpg?raw=true)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos voltar ao nosso banco de dados do censo\ng.agg(np.mean).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note que isso é exatamente o que já fizemos anteriormente:"},{"metadata":{"trusted":true},"cell_type":"code","source":"g.mean().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mas então qual a diferença? Fazer apenas `.mean()` parece muito mais fácil.\n\nA diferença é que a função `agg` nos permite fazer muitos mais. E é isso que vamos ver agora:"},{"metadata":{},"cell_type":"markdown","source":"### Várias agregações\nCom `agg` podemos passar quantas funções de agregação nós quisermos e vamos gerar um DataFrame com colunas hierarquicas com os nomes dessas funções:"},{"metadata":{"trusted":true},"cell_type":"code","source":"g.agg([np.mean, np.sum]).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Agregações customizáveis\nAlém disso, podemos passar nossas próprias funções para a `agg`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# O exemplo é besta, mas em muitos casos nós precisamos definir nossas próprias funções para gerar agregações \n# exatamente como desejamos\n\ndef meia_media(s):\n    return s.mean() / 2\ndef soma_mais_10(s):\n    return s.sum() + 10\n\ng.agg([meia_media, soma_mais_10]).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observe** que a função passada para `agg` recebe como parâmetro uma `Series` que corresponde a uma coluna do agrupamento. Vamos provar isso com `DataFrame` menor:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def verifica_tipo(s):\n    print(type(s))\n    print(s)\n    print('-' * 100, end='\\n\\n')\n    if s.shape[0] > 1:\n        return 1000\n    else:\n        return 0\n    \ndf2.groupby(duas_letras).agg(verifica_tipo)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veja como cada grupo aparece duas vezes, um para cada coluna do `DataFrame` original."},{"metadata":{},"cell_type":"markdown","source":"### Nomear agregações\nPodemos, agora, querer renomear os nomes que aparecem em cada coluna da tabela agregada. Veja como podemos ter alguns casos em que renomar as colunas é bastante desejável:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def uma_funcao_com_um_nome_desnecessariamente_grande(s):\n    return s.mean() / 2\n\ng.agg([uma_funcao_com_um_nome_desnecessariamente_grande,\n       lambda x : x.sum(),\n       lambda x : x.max() - x.min()]).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veja que temos uma função com um nome gigante e duas funções lambda (funções sem nome) que acabam não dando um resultado muito desejável. \n\nPodemos, entretanto, passar nomes para nossas colunas através da função `agg`. \n\nAo invés de passar uma lista de funções, passamos uma lista de tuplas onde o primeiro elemento é o nome e o segundo,a função:"},{"metadata":{"trusted":true},"cell_type":"code","source":"g.agg([('meia_soma', uma_funcao_com_um_nome_desnecessariamente_grande),\n       ('soma', lambda x : x.sum()),\n       ('amplitude', lambda x : x.max() - x.min())]).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Existem outras formas de nomear, mas elas são muito mais complexas e eu acho que não vale a pena aprender.\n\nEntretanto, recomendo você dar uma [olhada](https://pandas.pydata.org/docs/user_guide/groupby.html#named-aggregation)."},{"metadata":{},"cell_type":"markdown","source":"### Agregações diferentes para colunas diferentes\nPara finalizar as agregações, outra coisas que a função `agg` nos permite é aplicar agregações por coluna.\n\nNote que eu passei três funções para `agg` e elas foram aplicadas em todas as colunas numéricas do meu `DataFrame`. Muitas vezes, não queremos isso. Pode ser que eu queira a soma dos nascimentos e a média e amplitude da quantidade de população (diferentes agregações para diferentes colunas). \n\nPodemos fazer isso passando um dicionário para `agg`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"minhas_agg = {'BIRTHS2013' : np.sum,\n              'BIRTHS2014' : np.sum,\n              'BIRTHS2015' : np.sum,\n              'POPESTIMATE2013' : [np.mean, lambda x : x.max() - x.min()],\n              'POPESTIMATE2014' : [np.mean, lambda x : x.max() - x.min()],\n              'POPESTIMATE2015' : [np.mean, lambda x : x.max() - x.min()]}\ng.agg(minhas_agg).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veja como obtivemos apenas as somas para os nascimentos e apenas a média e a amplitude para a quantidade de populão.\n\nAlém disso, perceba como apenas as colunas que eu informei apareceram (as colunas de 2010, 2011 e 2012 foram ignoradas).\n\nPor fim, note que para ter mais de uma função por coluna, novamente usamos uma lista, como fazíamos antes.\n\nMas novamente tivemos um problema: a função lambda está sem nome. Será que você consegue resolver isso? \n\n**Exercício:** \n*Pegue tudo o que já aprendemos e crie uma agregação similar a anterior, mas com nomes 'soma', 'media' e 'amplitude'.*"},{"metadata":{},"cell_type":"markdown","source":"# Transformações\n\nVamos passar agora para o segundo tópico das nossas aplicações.\n\nAo contrário de uma agregação, a transformação é uma operação que retorna uma tabela de mesmo tamanho (`shape`) que a tabela original.\n\nPor exemplo, suponha que eu tenho uma tabela e que eu quero dividir todos os valores por dois. Isso é uma transformação, pois a tabela resultante vai ter o mesmo número de linha e colunas da original."},{"metadata":{},"cell_type":"markdown","source":"Utilizamos a função `transform` para transformar nossos grupos."},{"metadata":{"trusted":true},"cell_type":"code","source":"df2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.groupby(duas_letras).get_group('Ma')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.groupby(duas_letras).transform(np.max)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![image](https://github.com/Giatroo/BeeData_GroupBy-in-Pandas/blob/main/groupby-transform.jpg?raw=true)"},{"metadata":{},"cell_type":"raw","source":"Observe o que aconteceu.\nJoão e Joana agora têm a mesma nota nas duas provas. A nota1 de ambos é a maior nota que algum deles tinha tirado, assim como a nota2.\nO mesmo aconteceu com Mariana, Mario e Marcos. \nCláudia e Lucas não tiveram suas notas alteradas, pois estão sozinhos em seus respectivos grupos."},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.groupby(duas_letras).groups","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lidar com valores nulos\n\nUma aplicação legal do transform é preencher valores nulos com agregações de cada grupo.\n\nPor exemplo, suponha que eu tenha uma tabela de produtos de vários tipos: carros, motos, bicicletas e aviões. E que o preço de um determinado carro está faltando (é `NaN`). Uma opção seria tirar a média dos preços e usar esse valor no lugar do preço faltando. Entranto, isso parece um pouco confuso, pois temos veículos bem diferentes (bicicletas que custam muito menos e aviões que custam muito mais) e a média de tudo talvez não seja um valor ideal.\n\nO que nós podemos fazer, então, é tirar a média apenas dos carros (agrupando-os) e usar essa média no lugar o valor faltando. \n\nVamos ver essa aplicação na prática:"},{"metadata":{"trusted":true},"cell_type":"code","source":"precos = np.concatenate((((np.random.randn(6) * 5000) + 40000),\n                         ((np.random.randn(4) * 2000) + 30000),\n                         ((np.random.randn(3) * 300) + 2000), \n                         ((np.random.randn(7) * 10000) + 1000000))).astype(int)\nveiculos_dict = {\n    'id' : list(map(lambda x : 'id_' + str(x), range(20))),\n    'tipo' : ['Carro']*6 + ['Moto']*4 + ['Bicicleta']*3 + ['Avião']*7,\n    'preço' : precos \n}\n\nveiculos = pd.DataFrame(veiculos_dict)\nveiculos.loc[0, 'preço'] = np.nan\nveiculos.loc[6, 'preço'] = np.nan\nveiculos.loc[13, 'preço'] = np.nan\nveiculos","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veja como ficaria se preenchesemos com a média de todos os veículos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"veiculos.fillna(int(veiculos['preço'].mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fill_by_group(x):\n    # Importante!!! \n    # x é uma coluna!\n    # Como a coluna id não suporta a operação 'mean', ela não será retornada\n    return x.fillna(int(x.mean()))\n\n# Observe que apenas a coluna preço é retornada, pois não existe média dos ids e \n# a coluna tipo foi utilizada para agrupar \nveiculos.groupby('tipo').transform(fill_by_group)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Agora os preços fazem muito mais sentido."},{"metadata":{},"cell_type":"markdown","source":"### Normalização e padronização (normalization e standardization)\n\nDois processos muito comuns em Machine Learning, normalizar e padronizar os dados significa subtrair a média e dividir pelo desvio padrão."},{"metadata":{"trusted":true},"cell_type":"code","source":"veiculos.groupby('tipo').transform(lambda x : (x - x.mean()) / x.std())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veja que todas essas ferramentas que estamos utilizando são tão poderosas que nos permitem fazer tudo em uma única linha.\n\n**Exercício:**\n*Podemos ir além e primeiro preencher os valores nulos com a transformação anterior e depois aplicar a transformação de normalização e padronização. Tente fazer isso =)*"},{"metadata":{},"cell_type":"markdown","source":"### Filtragem\n\nPara nossa última aplicação, vamos demostrar como podemos usar a função `filter` para manter apenas grupos nos quais estamos interassados. Suponha que temos um banco de dados de vários cursos com as notas de cada aluno daquele curso e que queremos manter apenas os cursos nos quais os alunos tiveram uma média acima de 5."},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = np.random.choice(range(10000000, 20000000), size=120)\nnotas = np.random.randint(11, size=120)\ncursos = pd.DataFrame({\n    'ids' : ids,\n    'curso' : ['Programação I']*30 + ['Cálculo']*30 + ['Probabilidade']*30 + ['Programação II']*30,\n    'notas' : notas\n})\ncursos.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A função `filter` recebe o grupo inteiro (diferente de antes, que eram as colunas) e deve retornar `True` ou `False`. Se o grupo retornar `True`, ele será mantido."},{"metadata":{"trusted":true},"cell_type":"code","source":"def media_maior(df):\n    # df é um DataFrame!\n    #print(type(df))\n    media = df['notas'].mean()\n    nome = df['curso'].iloc[0]\n    print(f'A média do curso {nome} é {media}.')\n    return media > 5\n\ncursos.groupby('curso').filter(media_maior).sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusão e aprofundamento\n\nPor hoje é tudo =)\n\nEspero que você tenha gostado e aprendido bastante. \n\nConcluímos que a função `groupby` é incrivelmente útil e poderosa, resolvendo diversos problemas diferentes. \n\nVimos que existem muitas formas de se realizar um agrupamento com ela. \n\nDepois, vimos a utilidade da função `agg` e as diferentes formas de se trabalhar com ela.\n\nPor fim, vimos exemplos de outras duas funções utilizadas com agrupamentos: `transform` e `filter`. \n\n<br>\n\nCaso queira se aprofundar e treinar um pouco o que vimos hoje, seguem alguns materiais adicionais:\n\n\n[Documentação groupby](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) <br>\n[Documentação agg](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html) <br>\n[Documentação transform](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html) <br>\n[Documentação filter](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.filter.html) <br>\n\n[Guia do usuário sobre groupby](https://pandas.pydata.org/docs/user_guide/groupby.html)\n\nAlém disso, recomendo fortemente o livro *Python for Data Analysis* do Wes McKinney, criador do `pandas`. Ele foi um guia muito bom para eu aprender **muito** sobre a biblioteca e tem um capítulo só para agrupamentos.\n\nPor fim, tem dois cursos que eu recomendo: <br>\n[Kaggle](https://www.kaggle.com/learn/pandas) <br>\n[Introdution to Data Science in Python](https://www.coursera.org/learn/python-data-analysis) <br>\n"},{"metadata":{},"cell_type":"markdown","source":"**~Lucas Paiolla , 16/03/2021**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}