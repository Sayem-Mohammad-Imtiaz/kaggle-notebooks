{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nfrom nltk.corpus import stopwords\nimport re #regex\nfrom textblob import TextBlob #sentimate analysis\nfrom nltk.probability import FreqDist\n\n#graphs\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nimport plotly.graph_objects as go","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data importation\ntdf= pd.read_csv('/kaggle/input/us-election-2020-tweets/hashtag_donaldtrump.csv', lineterminator='\\n')#trump df\nbdf=pd.read_csv('/kaggle/input/us-election-2020-tweets/hashtag_joebiden.csv', lineterminator='\\n')#biden df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"created_at: Date and time of tweet creation\ntweet_id: Unique ID of the tweet\ntweet: Full tweet text\nlikes: Number of likes\nretweet_count: Number of retweets\nsource: Utility used to post tweet\nuser_id: User ID of tweet creator\nuser_name: Username of tweet creator\nuser_screen_name: Screen name of tweet creator\nuser_description: Description of self by tweet creator\nuser_join_date: Join date of tweet creator\nuser_followers_count: Followers count on tweet creator\nuser_location: Location given on tweet creator's profile\nlat: Latitude parsed from user_location\nlong: Longitude parsed from user_location\ncity: City parsed from user_location\ncountry: Country parsed from user_location\nstate: State parsed from user_location\nstate_code: State code parsed from user_location\ncollected_at: Date and time tweet data was mined from twitter*"},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>data analysis</h1>"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"bdf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bdf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>data cleaning</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop useles columns\nbdf=bdf.drop(columns=['tweet_id','collected_at','user_description','collected_at'])\ntdf=tdf.drop(columns=['tweet_id','collected_at','user_description','collected_at'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding a collumn\nbdf.loc[:,'condidat'] = 'Biden'\ntdf.loc[:,'condidat'] = 'trump'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tdf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#concat both datasets\ndata = pd.concat([bdf,tdf])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sort_values(by='created_at').info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>tweet count for each country</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# wee look for the rows of specific condidat then we remove the rows that has nan in country \n#then we group by avec country then we get the count then we sort  from big to low\n\n#for biden\ny = data.query('(condidat == \"Biden\") ').dropna(subset=['country']).groupby(by='country').count().tweet.sort_values(ascending=False)\nx = data.query('(condidat == \"Biden\") ').dropna(subset=['country']).groupby(by='country').count().tweet.sort_values(ascending=False).index\n#for trump\ny2 = data.query('(condidat == \"trump\") ').dropna(subset=['country']).groupby(by='country').count().tweet.sort_values(ascending=False)\nx2 = data.query('(condidat == \"trump\")').dropna(subset=['country']).groupby(by='country').count().tweet.sort_values(ascending=False).index\n\nfig = go.Figure([go.Bar(x=x, y=y, name='joe Biden'),\n                 go.Bar(x=x2, y=y2, name='donald Trump')])\n\n\nfig.update_layout(title_text='tweets count for each countries')\nfig.update_xaxes(title='countries')\nfig.update_yaxes(title='tweet count')\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>tweet count for each country usa not included</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# wee look for the rows of specific condidat then we remove the rows that has nan in country \n#then we group by avec country then we get the count then we sort  from big to low\n\n#for biden\ny = data.query('(condidat == \"Biden\")& (country != \"United States\")& (country != \"United States of America\") ').dropna(subset=['country']).groupby(by='country').count().tweet.sort_values(ascending=False)\nx = data.query('(condidat == \"Biden\")& (country != \"United States\")& (country != \"United States of America\") ').dropna(subset=['country']).groupby(by='country').count().tweet.sort_values(ascending=False).index\n#for trump\ny2 = data.query('(condidat == \"trump\")& (country != \"United States\")& (country != \"United States of America\") ').dropna(subset=['country']).groupby(by='country').count().tweet.sort_values(ascending=False)\nx2 = data.query('(condidat == \"trump\")& (country != \"United States\")& (country != \"United States of America\")').dropna(subset=['country']).groupby(by='country').count().tweet.sort_values(ascending=False).index\n\nfig = go.Figure([go.Bar(x=x, y=y, name='joe Biden'),\n                 go.Bar(x=x2, y=y2, name='donald Trump')])\n\n\nfig.update_layout(title_text='tweets count for each country usa not included')\nfig.update_xaxes(title='countries')\nfig.update_yaxes(title='tweet count')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>tweet count for each state</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# wee look for the rows of specific condidat then we remove the rows that has nan in country \n#then we group by avec country then #AmineAbouothmane we get the count then we sort  from big to low\n\n#for biden\ny = data.query('(condidat == \"Biden\")& (country == \"United States of America\") ').dropna(subset=['state']).groupby(by='state').count().tweet.sort_values(ascending=False)\nx = data.query('(condidat == \"Biden\")& (country == \"United States of America\") ').dropna(subset=['state']).groupby(by='state').count().tweet.sort_values(ascending=False).index\n#for trump\ny2 = data.query('(condidat == \"trump\")& (country == \"United States of America\") ').dropna(subset=['state']).groupby(by='state').count().tweet.sort_values(ascending=False)\nx2 = data.query('(condidat == \"trump\")& (country == \"United States of America\")').dropna(subset=['state']).groupby(by='state').count().tweet.sort_values(ascending=False).index\n\nfig = go.Figure([go.Bar(x=x, y=y, name='joe Biden'),\n                 go.Bar(x=x2, y=y2, name='donald Trump')])\n\n\nfig.update_layout(title_text='tweets count for each state')\nfig.update_xaxes(title='states')\nfig.update_yaxes(title='tweet count')\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>tweet likes </h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data.groupby('condidat').likes.count()\ny.plot(x='condidate',y=\"likes\",kind='bar',title='tweet likes')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>top 5 sources</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data.query('(condidat == \"Biden\") ').groupby(by='source').count().tweet.sort_values(ascending=False)[:5]\nx = data.query('(condidat == \"Biden\") ').groupby(by='source').count().tweet.sort_values(ascending=False)[:5].index\ny2 = data.query('(condidat == \"trump\") ').groupby(by='source').count().tweet.sort_values(ascending=False)[:5]\nx2 = data.query('(condidat == \"trump\") ').groupby(by='source').count().tweet.sort_values(ascending=False)[:5].index\nfig = go.Figure([go.Bar(x=x, y=y, name='Biden'),go.Bar(x=x2, y=y2, name='trump')])\n\n# Customize aspect\nfig.update_layout(title_text='top 5 sources')\nfig.update_xaxes(title='sources')\nfig.update_yaxes(title='tweets count')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>tweet count in country \"morocco\" </h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"country=\"Morocco\"\na=data[data.country==country].groupby('condidat').tweet.count()\na.plot(x='condidate',y=\"tweet\",kind='bar',title=\"tweet count in country 'morocco'\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a.plot(x='condidate',y=\"tweet\",kind='pie',title=\"tweet count in country 'morocco'\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>example of word tokenz</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import word_tokenize\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nnltk.download('punkt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nexample_sent = \"This is a sample words sentence, showing off the stop words filtration sentence.\"\n\n\nstop_words = set(stopwords.words('english'))\n\nword_tokens = word_tokenize(example_sent)\n\nfiltered_sentence = [w for w in word_tokens if not w in stop_words]\n\nfiltered_sentence = []\n\nfor w in word_tokens:\n    if w not in stop_words:\n        filtered_sentence.append(w)\n#AmineAbouothmane\nprint(word_tokens)\nprint(filtered_sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.probability import FreqDist\nfdist=FreqDist()\nfor word in filtered_sentence:\n    fdist[word.lower()]+=1\nfdist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Tokenization(text):\n    stop_words = set(stopwords.words('english'))\n\n    word_tokens = word_tokenize(text)\n\n    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n\n    filtered_sentence = []\n\n    for w in word_tokens:\n        if w not in stop_words:\n            filtered_sentence.append(w)\n    fdist=FreqDist()\n    for word in filtered_sentence:\n        fdist[word.lower()]+=1\n    return fdist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#regular expression\nimport re\n\nt='@fazf hello !! https://pythonprogramming.net/ ohmygod ??, '\ndef cleanText(text):\n    try:\n        # remove @name and links and retweet and hashtags and symbols in the tweet\n        text=re.sub(r'@[A-Za-z0-9]+','',text)\n        text=re.sub(r'#','',text)\n        text=re.sub(r'RT[\\s]+','',text)\n        text=re.sub(r'https?:\\/\\/\\S+','',text)\n        text=re.sub(r'[^\\w]', ' ', text)\n    except:\n        pass\n    return text\nprint(cleanText(t))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1> Sentiment Analysis</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#get the tweets from depends on condidat and number of tweets \n#we choose the United States of America to make sure that the langauge is english for the sentiment analysis to work\n\ndef getTweet(condidat,nb):#condidat[trump,Biden]  nb nomver of tweets we want\n    tweets = data.query('condidat == \"'+condidat+'\"').sort_values('user_followers_count',ascending=False).drop_duplicates(['user_name'])[['tweet','country']]\n    #return nb tweets and removing nan \n    tweets = tweets.dropna().loc[tweets.country=='United States of America'][:nb]\n    return tweets\n\n#get the tweets \nnb=1000\ndd=getTweet('trump',nb)\n\n#reset the index\ndd.reset_index(inplace=True, drop=True)\n#apply the function on tweets and stor results to a new column\ndd['ClearTweet']=dd['tweet'].apply(cleanText)\n#AmineAbouothmane\ndd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>The sentiment function of textblob returns two properties, polarity, and subjectivity. ... Subjective sentences generally refer to personal opinion, emotion or judgment</h3><br>\n<h3>The key aspect of sentiment analysis is to analyze a body of text for understanding the opinion expressed by it. Typically, we quantify this sentiment with a positive or negative value, called polarity</h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#create fuction to get the subjectivity and polarity\ndef getSubjectivity(text):\n    return TextBlob(text).sentiment.subjectivity\ndef getPolarity(text):\n    return TextBlob(text).sentiment.polarity\ndef getAnalysis(score):\n    if score<0:\n        return 'negative'\n    elif score==0:\n        return 'neutral'\n    else:\n        return 'positive'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding columns and applying the functionss \ndd['subjectivity']=dd['ClearTweet'].apply(getSubjectivity)\ndd['polarity']=dd['ClearTweet'].apply(getPolarity)\ndd['analysis']=dd['polarity'].apply(getAnalysis)\ndd.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>word cloud</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot the word cloud\nallwords=' '.join( [twts for twts in dd['ClearTweet']] )\nwordcloud=WordCloud(width=500,height=300,random_state=21,max_font_size=119).generate(allwords)\n\nplt.imshow(wordcloud,interpolation='bilinear')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>visualisation</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot the polarity and subjectivity\n\nplt.figure(figsize=(8,6))\nfor i in range(0,nb):\n    p=dd['polarity'][i]\n    if p<0:\n        plt.scatter(dd['polarity'][i],dd['subjectivity'][i],color='red', marker = '*')\n    elif p==0:\n        plt.scatter(dd['polarity'][i],dd['subjectivity'][i],color='green', marker = 'o')\n    else:\n        plt.scatter(dd['polarity'][i],dd['subjectivity'][i],color='blue', marker = '+')\nplt.xlabel('polarity')\nplt.ylabel('subjectivity')\nplt.title('sentimat analysis')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"o=dd.groupby('analysis').analysis.count()\nneu=dd[dd['analysis']=='neutral'].ClearTweet.count()\npo=dd[dd['analysis']=='positive'].ClearTweet.count()\nneg=dd[dd['analysis']=='negative'].ClearTweet.count()\n\nfig = go.Figure(data=[go.Pie(labels=[\"positivity\",\"negativity\",\"neutrality\"], values=[po,neg,neu])])\nfig.update_layout(title_text='sentimat analysis of tweets (#trump)')\nfig.show()\no.plot(x='analysis',kind='bar',ylabel=\"counts\",title=\"sentimat analysis of tweets (#trump)\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>sentimal analysis #Biden tweets</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"ddb=getTweet('Biden',1000)\n#reset the index\nddb.reset_index(inplace=True, drop=True)\n#apply the function on tweets and stor results to a new column\nddb['ClearTweet']=ddb['tweet'].apply(cleanText)\n#adding columns and applying the functionss \nddb['subjectivity']=ddb['ClearTweet'].apply(getSubjectivity)\nddb['polarity']=ddb['ClearTweet'].apply(getPolarity)\nddb['analysis']=ddb['polarity'].apply(getAnalysis)\nddb.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot the word cloud\nallwords=' '.join( [twts for twts in ddb['ClearTweet']] )\nwordcloud=WordCloud(width=500,height=300,random_state=21,max_font_size=119).generate(allwords)\n\nplt.imshow(wordcloud,interpolation='bilinear')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"o=ddb.groupby('analysis').analysis.count()\nneu=ddb[ddb['analysis']=='neutral'].ClearTweet.count()\npo=ddb[ddb['analysis']=='positive'].ClearTweet.count()\nneg=ddb[ddb['analysis']=='negative'].ClearTweet.count()\n\nfig = go.Figure(data=[go.Pie(labels=[\"positivity\",\"negativity\",\"neutrality\"], values=[po,neg,neu])])\nfig.update_layout(title_text='sentimat analysis of tweets (#Biden)')\nfig.show()\no.plot(x='analysis',kind='bar',ylabel=\"counts\",title=\"sentimat analysis of tweets (#Biden)\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}