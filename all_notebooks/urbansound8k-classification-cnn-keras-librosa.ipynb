{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import wave\nimport gc\nimport librosa\nimport librosa.display\nimport IPython\nimport numpy as np\nimport tensorflow as tf\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.python.client import device_lib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#configs\ntqdm.pandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device_lib.list_local_devices()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/urbansound8k/UrbanSound8K.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading and displaying some audio files"},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_audio_file(audio_file_path):\n    y, sr = librosa.load(audio_file_path)\n    \n    plt.figure(figsize=(14,7))\n    \n    plt.subplot(2, 2, 1)\n    spectrogram = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n    librosa.display.specshow(spectrogram, y_axis='linear')\n    \n    signal_plot = plt.subplot(2, 2, 2)\n    signal_plot.plot(y, color=\"c\")\n    IPython.display.display(IPython.display.Audio(audio_file_path))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_audio_file('../input/urbansound8k/fold8/103076-3-1-0.wav')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_audio_file('../input/urbansound8k/fold8/106905-5-0-1.wav')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_audio_file('../input/urbansound8k/fold5/100852-0-0-12.wav')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_audio_file('../input/urbansound8k/fold2/102871-8-0-1.wav')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating and saving spectrograms in png files"},{"metadata":{"trusted":true},"cell_type":"code","source":"audio_data_directory = \"../input/urbansound8k/\"\nspectrograms_directory = \"/kaggle/temp/spectrograms/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_spectrograms(row):\n\n    audio_class = row[\"classID\"]\n    spect_directory = \"class_\" + str(audio_class)\n    audio_file_name_without_extension = row[\"slice_file_name\"][:-4]\n    \n    y, sr = librosa.load(audio_data_directory + \"fold\" + str(row[\"fold\"]) + \"/\" + row[\"slice_file_name\"])\n    \n    spectrogram = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n    librosa.display.specshow(spectrogram, y_axis='linear')\n    \n    plt.savefig(spectrograms_directory + spect_directory + \"/\" + audio_file_name_without_extension + \".png\")\n\n    plt.clf() \n    plt.close('all')\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the classes directories\nfor i in range(0,10):\n    Path(spectrograms_directory + \"class_\" + str(i)).mkdir(parents=True, exist_ok=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.progress_apply(generate_spectrograms, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = tf.keras.preprocessing.image_dataset_from_directory(spectrograms_directory,validation_split = 0.225,\n                                                              subset = \"training\", seed=7)\nX_test = tf.keras.preprocessing.image_dataset_from_directory(spectrograms_directory,validation_split = 0.225,\n                                                             subset=\"validation\", seed=7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating and training the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential([\n    \n    layers.experimental.preprocessing.Rescaling(1./255,  input_shape=(256, 256, 3)),\n    \n    layers.Conv2D(32, 7, strides = 4, padding=\"same\"),\n    layers.BatchNormalization(),\n    layers.Activation(\"relu\"),\n    \n    layers.MaxPooling2D((4,4)),\n    \n    layers.Conv2D(128, 3, padding=\"same\"),\n    layers.BatchNormalization(),\n    layers.Activation(\"relu\"),\n\n    layers.Flatten(),\n    \n    layers.Dense(256),\n    layers.BatchNormalization(),\n    layers.Activation(\"relu\"),\n    \n    layers.Dense(10, activation='softmax')\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_history = model.fit(X_train, validation_data=X_test, epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\n\nplt_loss = plt.subplot(121)\nplt_loss.plot(model_history.history[\"loss\"])\nplt_loss.plot(model_history.history[\"val_loss\"])\n# plt.title(\"\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Training\", \"Validation\"], loc=\"upper right\")\n\nplt_accuracy = plt.subplot(122)\nplt_accuracy.plot(model_history.history[\"accuracy\"])\nplt_accuracy.plot(model_history.history[\"val_accuracy\"])\n# plt.title(\"\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Training\", \"Validation\"], loc=\"lower right\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = tf.keras.preprocessing.image.load_img(\"/kaggle/temp/spectrograms/class_3/103076-3-1-0.png\", target_size=(256, 256))\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nprint(img_array.shape)\nimg_array = tf.expand_dims(img_array, 0)\nprint(img_array.shape)\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\nprint( \"class : \"+ str(np.argmax(score)) +\" ; Probability = \"+ str(np.max(score)))\nscore","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}