{"cells":[{"metadata":{},"cell_type":"markdown","source":"> ## All models are wrong but some are useful - George E.P box\n\nThis model will by no means predict the price of Google stock in future. In fact we can never predict the stock price as it is independent of the past values.\n\nBut we sure can find some trends in the Google stocks.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":" # Data Preprocessing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Importing the libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing the training set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_train = pd.read_csv('../input/google-stock-price/Google_Stock_Price_Train.csv')\ntraining_set = dataset_train.iloc[:, 1:2].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_set.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Scaling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalizing the inputs instead of Standardizing\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nsc = MinMaxScaler(feature_range = (0, 1))\ntraining_set_scaled = sc.fit_transform(training_set)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Creating a data structure with 120 timesteps and 1 output.**\n\n* Therefore the memory of our RNN will be of past 120 days of stock observation. We will predict next day opening based on this past 120 days observations.\n\n* However we are not doing that right now. In this section we are just creating X_train and y_train such that :\n1. X_train is a numpy array of past 120 days (6 months - as only 20 days are working days in a month) opening prices and this is done everyday till the end of training_set date.\n2. y_train is a numpy array (vector) consisting of only 121st day price. We will then eventually compare our y_train with the predicted values (y_pred)\n\n* 120 timestamps is an arbritarty value choosen. Many more values were tried manually but 120 was giving me the best results.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = []\ny_train = []\nfor i in range(120, 1258):                               # Starting from 120 as we can analyse only after first 120 days. 1258 - Index of the last date\n    X_train.append(training_set_scaled[i-120:i, 0])      # So it goes like 0-120 ,1-121,2-122....1198-1138\n    y_train.append(training_set_scaled[i, 0])            # Just the 121st observation \nX_train, y_train = np.array(X_train), np.array(y_train)  # Converting to numpy arrays","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Just showing the data **","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# So it has 1138 rows and 120 columns\n\nX_train[0:2] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_train has 1138 rows and 1 column\ny_train[0:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reshaping**\n\n* RNN model expects our model in this particular 3D shape.\n\n* If we want we can use this step to add the number of predictors. We can use this step to predict and add additional dimensions to further improve our predictions.\n\n* In our case we are using only past 120 days of 'Open' values and predicting the next day's 'Open' values. Using this step we can improve our predictions by adding other columns that are present in our dataset as our predictors as well.\n\n* However, be wary of 'Garbage in Garbage out' principle.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# RNN expects input in the form of a 3D tensor with shape [batch(rows), timesteps(columns), feature(1 if only 1 predictor, you can add more predictors here)]\n# Refer Keras docs : https://keras.io/api/layers/recurrent_layers/lstm/ and see the 'input'\n\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building and Training the RNN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.__version__","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing the Keras libraries and packages","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dropout # To prevent overfitting","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Initialising the RNN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initializing RNN as a sequence of layers as opposed of Computation Graphs. \n# Note to self - I will be using Computational Graphs (Dynamic Graphs) using Pytorch in future as it is much more powerful.\n\nregressor = Sequential()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adding the first LSTM layer and some Dropout regularisation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# units = no of cells in this layer. Since predicting the stock price is a pretty complex problem we need a pretty high 'units'.\n\n# return_sequences = Signifies if there is another LSTM layer after this (True / False(default)). \n#                    If there is no LSTM layer after current layer don't mention this arg as by default the value is 'False'\n#                    If we have multiple LSTM's in our network it is also called 'Stacked LSTMS'\n\n# input_shape = Exactly same as Reshaping . Just mention the last 2 dimensions i.e timesteps and features as the first (batch) is automatically taken in account.\n\nregressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\nregressor.add(Dropout(0.2)) # To prevent overfitting - 0.2 is just a classic value. You can tweak it.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adding a second LSTM layer and some Dropout regularisation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# No need to specify any input_shape this time.\n\nregressor.add(LSTM(units = 50, return_sequences = True))\nregressor.add(Dropout(0.2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adding a third LSTM layer and some Dropout regularisation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor.add(LSTM(units = 50, return_sequences = True))\nregressor.add(Dropout(0.2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adding a fourth LSTM layer and some Dropout regularisation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here return_sequences = 'False' as there is no LSTM layer after that. \n\nregressor.add(LSTM(units = 50))\nregressor.add(Dropout(0.2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adding the output layer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since it is a regression problem the output layer will always be a single neuron.\n\nregressor.add(Dense(units = 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compiling the RNN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# loss = 'mean_squared_error' as this is a regression problem.\n\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fitting the RNN to the Training set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Note - The data provided is not a lot. It is just a 5 years data. If maybe i can go to Yahoo Finance and scrape some data i can get more data and make better model.\n\nregressor.fit(X_train, y_train, epochs = 100, batch_size = 32) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making the predictions and visualising the results","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Getting the real stock price of Jan 2017","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_test = pd.read_csv('../input/google-stock-price/Google_Stock_Price_Test.csv')\nreal_stock_price = dataset_test.iloc[:, 1:2].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is the REAL Google stock price for Jan 2017 we will compare this with predicted stock price.\nreal_stock_price","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Getting the predicted stock price of Jan 2017**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# To predict we first need inputs of last 120 days data everyday of the month Jan 2017. This data stretches to both training and test data. \n# For that we need to concatinate both the training set and the test set data.\n# However we will not concat the training_set and real_stock_price as we should never touch the actual test set.\n# So we will concat the dataframes on vertical axis (axis = 0)\n\ndataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_total","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We need the inputs of past 120 days of every day of Jan 17.\n# The lower bound of the input will be first working day of Jan - 120. First working day of Jan = len(dataset_total) - len(dataset_test)\n# Upper bound will be the last value of Jan 17\n\ninputs = dataset_total[len(dataset_total) - len(dataset_test) - 120 :].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Formatting the input . Since we didn't use iloc we didn't get the normal format.\n\ninputs = inputs.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling the inputs using the same scaler\n\ninputs = sc.transform(inputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making X_test the same way made X_train in data preprocessing by making a data structure with 120 timestamps.\n\nX_test = []\n\nfor i in range(120, 140):                    # 140 - Index of the last date of 'inputs'\n    X_test.append(inputs[i-120:i, 0])        # So it goes like 0-120 ,1-121,2-122....20-140\n\nX_test = np.array(X_test) # Converting to numpy arrays","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting X_test to a 3D tensor format (same as we did for X_train)\n\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# THE PREDICT STEP\n\npredicted_stock_price = regressor.predict(X_test)\npredicted_stock_price = sc.inverse_transform(predicted_stock_price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the predicted values\n\npredicted_stock_price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Again we have to compare it with real_stock_price.\n# Note as i said before we can't predict the stock prices but we are trying to find out if our model predicted the trend correctly or not.\n# We can see that using plots.\n\nreal_stock_price","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualising the results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 8), dpi= 80, facecolor='w', edgecolor='k')\nplt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\nplt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\nplt.title('Google Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Google Stock Price')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Our model predicted the continious growth trend well. The various spikes cannot be predicted as future spikes are independent of the past. \nHowever,our model reacts well to smooth changes on upward and downward trends.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}