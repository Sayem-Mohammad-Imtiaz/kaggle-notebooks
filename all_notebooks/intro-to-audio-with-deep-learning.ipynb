{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport sys\nimport librosa , librosa.display\nimport matplotlib.pyplot as plt\nimport numpy as np\nsys.path.append('../input/audio-data/wild.wmv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Waveform"},{"metadata":{"trusted":true},"cell_type":"code","source":"file = '../input/audio-data/wild.wmv'\nSignal , sr = librosa.load(file , sr = 22050) # n_samples = 2.6 * 60 * 22050\nlibrosa.display.waveplot(Signal , sr = sr)\nplt.xlabel('Time')\nplt.ylabel('Amplitude')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fast Fourier Transform"},{"metadata":{"trusted":true},"cell_type":"code","source":"fft = np.fft.fft(Signal) \nfft # there are complex numbers in fft array so we should extract the magnitudes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"magnitude = np.abs(fft)\nmagnitude # These magnitudes represent the contribution of each frequency within the sound","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"frequency = np.linspace(0 , sr , len(magnitude))\nfrequency","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(frequency,magnitude)\nplt.xlabel('Frequency')\nplt.ylabel('Magnitude')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"left_frequency = frequency[:int(len(frequency)/2)]\nleft_magnitude = magnitude[:int(len(frequency)/2)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(left_frequency,left_magnitude)\nplt.xlabel('Frequency')\nplt.ylabel('Magnitude')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STFT"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_fft = 2048 # the window\nhop_length = 512 # the amount of shifting the window to the right\nstft = librosa.core.stft(Signal , hop_length = hop_length , n_fft = n_fft)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spectogram = np.abs(stft)\nlog_spectogram = librosa.amplitude_to_db(spectogram)\nlibrosa.display.specshow(log_spectogram , sr = sr , hop_length = hop_length)\nplt.xlabel('Time')\nplt.ylabel('Frequency')\nplt.colorbar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MFCCs"},{"metadata":{"trusted":true},"cell_type":"code","source":"MFCCs = librosa.feature.mfcc(Signal , n_fft = n_fft , hop_length = hop_length , n_mfcc = 13)\nlibrosa.display.specshow(MFCCs , sr = sr , hop_length = hop_length)\nplt.xlabel('Time')\nplt.ylabel('MFCC')\nplt.colorbar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Music Genre Classification\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport os\nimport math\nimport librosa\n\nDATASET_PATH = \"../input/gtzan-dataset-music-genre-classification/Data/genres_original\"\nJSON_PATH = \"./data_10.json\"\nSAMPLE_RATE = 22050\nTRACK_DURATION = 30 # measured in seconds\nSAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\nnot_allowed = \"../input/gtzan-dataset-music-genre-classification/Data/genres_original/jazz/jazz.00054.wav\"\n\ndef save_mfcc(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n    \"\"\"Extracts MFCCs from music dataset and saves them into a json file along witgh genre labels.\n\n        :param dataset_path (str): Path to dataset\n        :param json_path (str): Path to json file used to save MFCCs\n        :param num_mfcc (int): Number of coefficients to extract\n        :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples\n        :param hop_length (int): Sliding window for FFT. Measured in # of samples\n        :param: num_segments (int): Number of segments we want to divide sample tracks into\n        :return:\n        \"\"\"\n\n    # dictionary to store mapping, labels, and MFCCs\n    data = {\n        \"mapping\": [],\n        \"labels\": [],\n        \"mfcc\": []\n    }\n    \n    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n\n    # loop through all genre sub-folder\n    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n\n        # ensure we're processing a genre sub-folder level\n        if dirpath is not dataset_path:\n\n            # save genre label (i.e., sub-folder name) in the mapping\n            semantic_label = dirpath.split(\"/\")[-1]\n            data[\"mapping\"].append(semantic_label)\n            print(\"\\nProcessing: {}\".format(semantic_label))\n\n            # process all audio files in genre sub-dir\n            for f in filenames:\n               \n\t\t# load audio file\n                file_path = os.path.join(dirpath, f)\n                if file_path != not_allowed :\n                    signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n\n                # process all segments of audio file\n                    for d in range(num_segments):\n\n                    # calculate start and finish sample for current segment\n                        start = samples_per_segment * d\n                        finish = start + samples_per_segment\n\n                    # extract mfcc\n                        mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n                        mfcc = mfcc.T\n\n                    # store only mfcc feature with expected number of vectors\n                        if len(mfcc) == num_mfcc_vectors_per_segment:\n                            data[\"mfcc\"].append(mfcc.tolist())\n                            data[\"labels\"].append(i-1)\n                            print(\"{}, segment:{}\".format(file_path, d+1))\n\n    # save MFCCs to json file\n    with open(json_path, \"w\") as fp:\n        json.dump(data, fp, indent=4)\n        \n        \n        \nif __name__ == \"__main__\":\n    save_mfcc(DATASET_PATH, JSON_PATH, num_segments=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import losses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport numpy as np\nDATASET_PATH = \"./data_10.json\"\ndef load_data(dataset_path):\n    with open(dataset_path,\"r\") as fp:\n        data = json.load(fp)\n    inputs = np.array(data[\"mfcc\"])  \n    targets = np.array(data[\"labels\"])   \n    \n    return inputs , targets\n\ninputs,targets = load_data(DATASET_PATH)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport tensorflow.keras  as keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs_train,inputs_test,targets_train,targets_test = train_test_split(inputs,targets,test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.Sequential([\n    keras.layers.Flatten(input_shape=(inputs.shape[1],inputs.shape[2])),\n    \n    keras.layers.Dense(512,activation=\"relu\"),\n    keras.layers.Dense(256,activation=\"relu\"),\n    keras.layers.Dense(64,activation=\"relu\"),\n    \n    keras.layers.Dense(10,activation=\"softmax\"),\n\n    \n])\n\noptimizer = keras.optimizers.Adam(learning_rate = 0.0001)\nmodel.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(inputs_train,targets_train,validation_data=(inputs_test,targets_test),epochs=50,batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_history(history):\n    \n    fig,axs = plt.subplots(2)\n    axs[0].plot(history.history[\"accuracy\"],label=\"train accuracy\")\n    axs[0].plot(history.history[\"val_accuracy\"],label=\"test accuracy\")\n    axs[0].set_ylabel(\"Accuracy\")\n    axs[0].legend(loc='lower right')\n    axs[0].set_title(\"Accuracy eval\")\n    \n    axs[1].plot(history.history[\"loss\"],label=\"train error\")\n    axs[1].plot(history.history[\"val_loss\"],label=\"test error\")\n    axs[1].set_ylabel(\"Error\")\n    axs[1].set_xlabel(\"Epoch\")\n    axs[1].legend(loc='upper right')\n    plt.show()\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.Sequential([\n    keras.layers.Flatten(input_shape=(inputs.shape[1],inputs.shape[2])),\n    \n    keras.layers.Dense(512,activation=\"relu\",kernel_regularizer=keras.regularizers.l2(0.001)),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(256,activation=\"relu\",kernel_regularizer=keras.regularizers.l2(0.001)),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(64,activation=\"relu\",kernel_regularizer=keras.regularizers.l2(0.001)),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(10,activation=\"softmax\"),\n\n    \n])\n\noptimizer = keras.optimizers.Adam(learning_rate = 0.0001)\nmodel.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(inputs_train,targets_train,validation_data=(inputs_test,targets_test),epochs=50,batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CNN "},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_PATH = \"./data_10.json\"\n\ndef load_dataset(data_path):\n    \n    with open(data_path,\"r\") as fp:\n        data = json.load(fp)\n        \n    X = np.array(data[\"mfcc\"])\n    y = np.array(data[\"labels\"])\n    return X , y    \n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef prepare_datasets(test_size,val_size):\n    \n    X , y = load_dataset(DATA_PATH)\n    X_train,X_test,y_train,y_test = train_test_split(X , y , test_size = test_size)\n    X_train,X_validation,y_train,y_validation = train_test_split(X_train , y_train , test_size = val_size)\n    #from 2d-(130,13) to 3d-(130,13,1) \n    X_train = X_train[...,np.newaxis] # (num_samples,130,13,1)\n    X_validation = X_validation[...,np.newaxis] \n    X_test = X_test[...,np.newaxis]\n    \n    return X_train,X_validation,X_test,y_train,y_validation,y_test \n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_validation,X_test,y_train,y_validation,y_test = prepare_datasets(0.25,0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.keras as keras\n\n\ndef build_model(input_shape):\n    model = keras.Sequential()\n    model.add(keras.layers.Conv2D(32 , (3,3) ,activation = 'relu', input_shape=input_shape))\n    model.add(keras.layers.MaxPooling2D((3,3),strides=(2,2),padding='same'))\n    model.add(keras.layers.BatchNormalization())\n\n    model.add(keras.layers.Conv2D(64 , (3,3) ,activation = 'relu'))\n    model.add(keras.layers.MaxPooling2D((3,3),strides=(2,2),padding='same'))\n    model.add(keras.layers.BatchNormalization())\n    \n    model.add(keras.layers.Conv2D(120 , (2,2) ,activation = 'relu'))\n    model.add(keras.layers.MaxPooling2D((2,2),strides=(2,2),padding='same'))\n    model.add(keras.layers.BatchNormalization())\n    \n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(64,activation = 'relu'))\n    model.add(keras.layers.Dropout(0.3))\n    model.add(keras.layers.Dense(10,activation='softmax'))\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (X_train.shape[1],X_train.shape[2],X_train.shape[3])\nmodel = build_model(input_shape)\noptimizer =  keras.optimizers.Adam(learning_rate=0.001)\nmodel.compile(optimizer = optimizer ,loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,y_train,validation_data=(X_validation,y_validation),batch_size=32,epochs=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_error , test_accuracy = model.evaluate(X_test,y_test,verbose=1)\nprint(\"Accuracy on test is {}\".format(test_accuracy))\nprint(\"Test error is {}\".format(test_error))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(model , X , y):\n    X = X[np.newaxis,...]\n    prediction = model.predict(X)\n    predicted_index = np.argmax(prediction , axis = 1)\n    print(\"Expected index : {} predicted index : {}\".format(y,predicted_index[0]))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X_test[100]\ny = y_test[100]\npredict(model , X , y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef prepare_datasets(test_size,val_size):\n    \n    X , y = load_dataset(DATA_PATH)\n    X_train,X_test,y_train,y_test = train_test_split(X , y , test_size = test_size)\n    X_train,X_validation,y_train,y_validation = train_test_split(X_train , y_train , test_size = val_size)\n\n    return X_train,X_validation,X_test,y_train,y_validation,y_test \n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_validation,X_test,y_train,y_validation,y_test = prepare_datasets(0.25,0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(input_shape):\n    model = keras.Sequential()\n    # 64 represnets the number of units NOT cells\n    # the number of cells equal to the numper of steps which is 130 here\n    model.add(keras.layers.LSTM(64,input_shape=input_shape,return_sequences=True))\n    model.add(keras.layers.LSTM(64))\n    model.add(keras.layers.Dense(64,activation='relu'))\n    model.add(keras.layers.Dropout(0.3))\n    model.add(keras.layers.Dense(10,activation='softmax'))\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (X_train.shape[1],X_train.shape[2])\nmodel = build_model(input_shape)\noptimizer =  keras.optimizers.Adam(learning_rate=0.001)\nmodel.compile(optimizer = optimizer ,loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,y_train,validation_data=(X_validation,y_validation),batch_size=32,epochs=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_error , test_accuracy = model.evaluate(X_test,y_test,verbose=1)\nprint(\"Accuracy on test is {}\".format(test_accuracy))\nprint(\"Test error is {}\".format(test_error))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}