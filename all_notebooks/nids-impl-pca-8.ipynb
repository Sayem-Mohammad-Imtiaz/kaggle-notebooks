{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Modelling Intrusion Detection: Analysis of a Feature Selection Mechanism\n\n## Method Description\n\n### Step 1: Data preprocessing:\nAll features are made numerical using one-Hot-encoding. The features are scaled to avoid features with large values that may weigh too much in the results.\n\n### Step 2: Feature Selection:\nEliminate redundant and irrelevant data by selecting a subset of relevant features that fully represents the given problem.\nUnivariate feature selection with ANOVA F-test. This analyzes each feature individually to detemine the strength of the relationship between the feature and labels. Using SecondPercentile method (sklearn.feature_selection) to select features based on percentile of the highest scores. \nWhen this subset is found: Recursive Feature Elimination (RFE) is applied.\n\n### Step 4: Build the model:\nDecision tree model is built.\n\n### Step 5: Prediction & Evaluation (validation):\nUsing the test data to make predictions of the model.\nMultiple scores are considered such as:accuracy score, recall, f-measure, confusion matrix.\nperform a 10-fold cross-validation."},{"metadata":{},"cell_type":"markdown","source":"## Version Check"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sys\nimport sklearn\nprint(pd.__version__)\nprint(np.__version__)\nprint(sys.version)\nprint(sklearn.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load the Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# attach the column names to the dataset\ncol_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\"]\n\n# KDDTrain+_2.csv & KDDTest+_2.csv are the datafiles without the last column about the difficulty score\n# these have already been removed.\ndf = pd.read_csv(\"../input/kddddd/KDDTrain_2.csv\", header=None, names = col_names)\ndf_test = pd.read_csv(\"../input/kddtttttt/KDDTest_2.csv\", header=None, names = col_names)\n\n# shape, this gives the dimensions of the dataset\nprint('Dimensions of the Training set:',df.shape)\nprint('Dimensions of the Test set:',df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sample view of the training dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# first five rows\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Statistical Summary"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Label Distribution of Training and Test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Label distribution Training set:')\nprint(df['label'].value_counts())\nprint()\nprint('Label distribution Test set:')\nprint(df_test['label'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 1: Data preprocessing:\nOne-Hot-Encoding (one-of-K) is used to to transform all categorical features into binary features. \nRequirement for One-Hot-encoding:\n\"The input to this transformer should be a matrix of integers, denoting the values taken on by categorical (discrete) features. The output will be a sparse matrix where each column corresponds to one possible value of one feature. It is assumed that input features take on values in the range [0, n_values).\"\n\nTherefore the features first need to be transformed with LabelEncoder, to transform every category to a number."},{"metadata":{},"cell_type":"markdown","source":"## Identify categorical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# colums that are categorical and not binary yet: protocol_type (column 2), service (column 3), flag (column 4).\n# explore categorical features\nprint('Training set:')\nfor col_name in df.columns:\n    if df[col_name].dtypes == 'object' :\n        unique_cat = len(df[col_name].unique())\n        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n\n#see how distributed the feature service is, it is evenly distributed and therefore we need to make dummies for all.\nprint()\nprint('Distribution of categories in service:')\nprint(df['service'].value_counts().sort_values(ascending=False).head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test set\nprint('Test set:')\nfor col_name in df_test.columns:\n    if df_test[col_name].dtypes == 'object' :\n        unique_cat = len(df_test[col_name].unique())\n        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion: Need to make dummies for all categories as the distribution is fairly even. In total: 3+70+11=84 dummies.\n### Comparing the results shows that the Test set has fewer categories (6), these need to be added as empty columns."},{"metadata":{},"cell_type":"markdown","source":"# LabelEncoder"},{"metadata":{},"cell_type":"markdown","source":"### Insert categorical features into a 2D numpy array"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder,OneHotEncoder\ncategorical_columns=['protocol_type', 'service', 'flag']\n# insert code to get a list of categorical columns into a variable, categorical_columns\ncategorical_columns=['protocol_type', 'service', 'flag'] \n # Get the categorical values into a 2D numpy array\ndf_categorical_values = df[categorical_columns]\ntestdf_categorical_values = df_test[categorical_columns]\ndf_categorical_values.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Make column names for dummies"},{"metadata":{"trusted":true},"cell_type":"code","source":"# protocol type\nunique_protocol=sorted(df.protocol_type.unique())\nstring1 = 'Protocol_type_'\nunique_protocol2=[string1 + x for x in unique_protocol]\n# service\nunique_service=sorted(df.service.unique())\nstring2 = 'service_'\nunique_service2=[string2 + x for x in unique_service]\n# flag\nunique_flag=sorted(df.flag.unique())\nstring3 = 'flag_'\nunique_flag2=[string3 + x for x in unique_flag]\n# put together\ndumcols=unique_protocol2 + unique_service2 + unique_flag2\nprint(dumcols)\n\n#do same for test set\nunique_service_test=sorted(df_test.service.unique())\nunique_service2_test=[string2 + x for x in unique_service_test]\ntestdumcols=unique_protocol2 + unique_service2_test + unique_flag2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transform categorical features into numbers using LabelEncoder()"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_categorical_values_enc=df_categorical_values.apply(LabelEncoder().fit_transform)\nprint(df_categorical_values_enc.head())\n# test set\ntestdf_categorical_values_enc=testdf_categorical_values.apply(LabelEncoder().fit_transform)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# One-Hot-Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"enc = OneHotEncoder()\ndf_categorical_values_encenc = enc.fit_transform(df_categorical_values_enc)\ndf_cat_data = pd.DataFrame(df_categorical_values_encenc.toarray(),columns=dumcols)\n# test set\ntestdf_categorical_values_encenc = enc.fit_transform(testdf_categorical_values_enc)\ntestdf_cat_data = pd.DataFrame(testdf_categorical_values_encenc.toarray(),columns=testdumcols)\n\ndf_cat_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Add 6 missing categories from train set to test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"trainservice=df['service'].tolist()\ntestservice= df_test['service'].tolist()\ndifference=list(set(trainservice) - set(testservice))\nstring = 'service_'\ndifference=[string + x for x in difference]\ndifference","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in difference:\n    testdf_cat_data[col] = 0\n\ntestdf_cat_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Join encoded categorical dataframe with the non-categorical dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"newdf=df.join(df_cat_data)\nnewdf.drop('flag', axis=1, inplace=True)\nnewdf.drop('protocol_type', axis=1, inplace=True)\nnewdf.drop('service', axis=1, inplace=True)\n# test data\nnewdf_test=df_test.join(testdf_cat_data)\nnewdf_test.drop('flag', axis=1, inplace=True)\nnewdf_test.drop('protocol_type', axis=1, inplace=True)\nnewdf_test.drop('service', axis=1, inplace=True)\nprint(newdf.shape)\nprint(newdf_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split Dataset into 4 datasets for every attack category\n## Rename every attack label: 0=normal, 1=DoS, 2=Probe, 3=R2L and 4=U2R.\n## Replace labels column with new labels column\n## Make new datasets\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# take label column\nlabeldf=newdf['label']\nlabeldf_test=newdf_test['label']\n# change the label column\nnewlabeldf=labeldf.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\nnewlabeldf_test=labeldf_test.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n# put the new label column back\nnewdf['label'] = newlabeldf\nnewdf_test['label'] = newlabeldf_test\nprint(newdf['label'].head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to_drop_DoS = [2,3,4]\nto_drop_Probe = [1,3,4]\nto_drop_R2L = [1,2,4]\nto_drop_U2R = [1,2,3]\nDoS_df=newdf[~newdf['label'].isin(to_drop_DoS)];\nProbe_df=newdf[~newdf['label'].isin(to_drop_Probe)];\nR2L_df=newdf[~newdf['label'].isin(to_drop_R2L)];\nU2R_df=newdf[~newdf['label'].isin(to_drop_U2R)];\n\n#test\nDoS_df_test=newdf_test[~newdf_test['label'].isin(to_drop_DoS)];\nProbe_df_test=newdf_test[~newdf_test['label'].isin(to_drop_Probe)];\nR2L_df_test=newdf_test[~newdf_test['label'].isin(to_drop_R2L)];\nU2R_df_test=newdf_test[~newdf_test['label'].isin(to_drop_U2R)];\nprint('Train:')\nprint('Dimensions of DoS:' ,DoS_df.shape)\nprint('Dimensions of Probe:' ,Probe_df.shape)\nprint('Dimensions of R2L:' ,R2L_df.shape)\nprint('Dimensions of U2R:' ,U2R_df.shape)\nprint('Test:')\nprint('Dimensions of DoS:' ,DoS_df_test.shape)\nprint('Dimensions of Probe:' ,Probe_df_test.shape)\nprint('Dimensions of R2L:' ,R2L_df_test.shape)\nprint('Dimensions of U2R:' ,U2R_df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 2: Feature Scaling:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split dataframes into X & Y\n# assign X as a dataframe of feautures and Y as a series of outcome variables\nX_DoS = DoS_df.drop('label',1)\nY_DoS = DoS_df.label\nX_Probe = Probe_df.drop('label',1)\nY_Probe = Probe_df.label\nX_R2L = R2L_df.drop('label',1)\nY_R2L = R2L_df.label\nX_U2R = U2R_df.drop('label',1)\nY_U2R = U2R_df.label\n# test set\nX_DoS_test = DoS_df_test.drop('label',1)\nY_DoS_test = DoS_df_test.label\nX_Probe_test = Probe_df_test.drop('label',1)\nY_Probe_test = Probe_df_test.label\nX_R2L_test = R2L_df_test.drop('label',1)\nY_R2L_test = R2L_df_test.label\nX_U2R_test = U2R_df_test.drop('label',1)\nY_U2R_test = U2R_df_test.label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save a list of feature names for later use (it is the same for every attack category). Column names are dropped at this stage."},{"metadata":{"trusted":true},"cell_type":"code","source":"colNames=list(X_DoS)\ncolNames_test=list(X_DoS_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Use StandardScaler() to scale the dataframes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nscaler1 = preprocessing.StandardScaler().fit(X_DoS)\nX_DoS=scaler1.transform(X_DoS) \nscaler2 = preprocessing.StandardScaler().fit(X_Probe)\nX_Probe=scaler2.transform(X_Probe) \nscaler3 = preprocessing.StandardScaler().fit(X_R2L)\nX_R2L=scaler3.transform(X_R2L) \nscaler4 = preprocessing.StandardScaler().fit(X_U2R)\nX_U2R=scaler4.transform(X_U2R) \n# test data\nscaler5 = preprocessing.StandardScaler().fit(X_DoS_test)\nX_DoS_test=scaler5.transform(X_DoS_test) \nscaler6 = preprocessing.StandardScaler().fit(X_Probe_test)\nX_Probe_test=scaler6.transform(X_Probe_test) \nscaler7 = preprocessing.StandardScaler().fit(X_R2L_test)\nX_R2L_test=scaler7.transform(X_R2L_test) \nscaler8 = preprocessing.StandardScaler().fit(X_U2R_test)\nX_U2R_test=scaler8.transform(X_U2R_test) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check that the Standard Deviation is 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_DoS.std(axis=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Probe.std(axis=0);\nX_R2L.std(axis=0);\nX_U2R.std(axis=0);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 3: Feature Selection:"},{"metadata":{},"cell_type":"markdown","source":"# 1. Univariate Feature Selection using ANOVA F-test"},{"metadata":{"trusted":true},"cell_type":"code","source":"#univariate feature selection with ANOVA F-test. using secondPercentile method, then RFE\n#Scikit-learn exposes feature selection routines as objects that implement the transform method\n#SelectPercentile: removes all but a user-specified highest scoring percentage of features\n#f_classif: ANOVA F-value between label/feature for classification tasks.\n# from sklearn.feature_selection import SelectPercentile, f_classif\n# np.seterr(divide='ignore', invalid='ignore');\n# selector=SelectPercentile(f_classif, percentile=10)\n# X_newDoS = selector.fit_transform(X_DoS,Y_DoS)\n# X_newDoS.shape\n# Applying PCA function on training \n# and testing set of X component \nfrom sklearn.decomposition import PCA \n\npca = PCA(n_components = 8) \n\nX_newDoS = pca.fit_transform(X_DoS) \n# X_test = pca.transform(X_test) \nX_newDoS.shape\n\nexplained_variance = pca.explained_variance_ratio_ \nX_newDoS.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get the features that were selected: DoS"},{"metadata":{"trusted":true},"cell_type":"code","source":"# true=selector.get_support()\nnewcolindex_DoS=[i for i, x in enumerate(explained_variance) if x]\nnewcolname_DoS=list( colNames[i] for i in newcolindex_DoS )\nnewcolname_DoS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_newProbe = selector.fit_transform(X_Probe,Y_Probe)\nX_newProbe = pca.fit_transform(X_Probe)\nX_newProbe.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get the features that were selected: Probe"},{"metadata":{"trusted":true},"cell_type":"code","source":"# true=selector.get_support()\nnewcolindex_Probe=[i for i, x in enumerate(explained_variance) if x]\nnewcolname_Probe=list( colNames[i] for i in newcolindex_Probe )\nnewcolname_Probe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_newR2L = selector.fit_transform(X_R2L,Y_R2L)\nX_newR2L = pca.fit_transform(X_R2L)\nX_newR2L.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get the features that were selected: R2L"},{"metadata":{"trusted":true},"cell_type":"code","source":"# true=selector.get_support()\nnewcolindex_R2L=[i for i, x in enumerate(explained_variance) if x]\nnewcolname_R2L=list( colNames[i] for i in newcolindex_R2L)\nnewcolname_R2L","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_newU2R = selector.fit_transform(X_U2R,Y_U2R)\nX_newU2R = pca.fit_transform(X_U2R)\nX_newU2R.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get the features that were selected: U2R"},{"metadata":{"trusted":true},"cell_type":"code","source":"# true=selector.get_support()\nnewcolindex_U2R=[i for i, x in enumerate(explained_variance) if x]\nnewcolname_U2R=list( colNames[i] for i in newcolindex_U2R)\nnewcolname_U2R","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Summary of features selected by Univariate Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Features selected for DoS:',newcolname_DoS)\nprint()\nprint('Features selected for Probe:',newcolname_Probe)\nprint()\nprint('Features selected for R2L:',newcolname_R2L)\nprint()\nprint('Features selected for U2R:',newcolname_U2R)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The authors state that \"After obtaining the adequate number of features during the univariate selection process, a recursive feature elimination (RFE) was operated with the number of features passed as parameter to identify the features selected\". This either implies that RFE is only used for obtaining the features previously selected but also obtaining the rank. This use of RFE is however very redundant as the features selected can be obtained in another way (Done in this project). One can also not say that the features were selected by RFE, as it was not used for this. The quote could however also imply that only the number 13 from univariate feature selection was used. RFE is then used for feature selection trying to find the best 13 features. With this use of RFE one can actually say that it was used for feature selection. However the authors obtained different numbers of features for every attack category, 12 for DoS, 15 for Probe, 13 for R2L and 11 for U2R. This concludes that it is not clear what mechanism is used for feature selection. \n\n## To procede with the data mining, the second option is considered as this uses RFE. From now on the number of features for every attack category is 13."},{"metadata":{},"cell_type":"markdown","source":"# 2. Recursive Feature Elimination for feature ranking (Option 1: get importance from previous selected)"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''from sklearn import preprocessing\nfrom sklearn import utils\n\nlab_enc = preprocessing.LabelEncoder()\nencoded = lab_enc.fit_transform(Y_DoS) '''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(utils.multiclass.type_of_target(Y_DoS))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(utils.multiclass.type_of_target(Y_DoS.astype('int')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(utils.multiclass.type_of_target(encoded))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_DoS=Y_DoS.astype('int')\nY_Probe=Y_Probe.astype('int')\nY_R2L=Y_R2L.astype('int')\nY_U2R=Y_U2R.astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_newDoS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom sklearn.tree import DecisionTreeClassifier\n# Create a decision tree classifier. By convention, clf means 'classifier'\nclf = DecisionTreeClassifier(random_state=0)\n\n#rank all features, i.e continue the elimination until the last one\nrfe = RFE(clf, n_features_to_select=1)\nrfe.fit(X_newDoS, Y_DoS)\nprint (\"DoS Features sorted by their rank:\")\nprint (sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), newcolname_DoS)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfe.fit(X_newProbe, Y_Probe)\nprint (\"Probe Features sorted by their rank:\")\nprint (sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), newcolname_Probe)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfe.fit(X_newR2L, Y_R2L)\n \nprint (\"R2L Features sorted by their rank:\")\nprint (sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), newcolname_R2L)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfe.fit(X_newU2R, Y_U2R)\n \nprint (\"U2R Features sorted by their rank:\")\nprint (sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), newcolname_U2R)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Recursive Feature Elimination, select 13 features each of 122 (Option 2: get 13 best features from 122 from RFE)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\nclf = DecisionTreeClassifier(random_state=0)\nrfe = RFE(estimator=clf, n_features_to_select=8, step=1)\nrfe.fit(X_DoS, Y_DoS)\nX_rfeDoS=rfe.transform(X_DoS)\ntrue=rfe.support_\nrfecolindex_DoS=[i for i, x in enumerate(true) if x]\nrfecolname_DoS=list(colNames[i] for i in rfecolindex_DoS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfe.fit(X_Probe, Y_Probe)\nX_rfeProbe=rfe.transform(X_Probe)\ntrue=rfe.support_\nrfecolindex_Probe=[i for i, x in enumerate(true) if x]\nrfecolname_Probe=list(colNames[i] for i in rfecolindex_Probe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfe.fit(X_R2L, Y_R2L)\nX_rfeR2L=rfe.transform(X_R2L)\ntrue=rfe.support_\nrfecolindex_R2L=[i for i, x in enumerate(true) if x]\nrfecolname_R2L=list(colNames[i] for i in rfecolindex_R2L)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfe.fit(X_U2R, Y_U2R)\nX_rfeU2R=rfe.transform(X_U2R)\ntrue=rfe.support_\nrfecolindex_U2R=[i for i, x in enumerate(true) if x]\nrfecolname_U2R=list(colNames[i] for i in rfecolindex_U2R)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Summary of features selected by RFE"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Features selected for DoS:',rfecolname_DoS)\nprint()\nprint('Features selected for Probe:',rfecolname_Probe)\nprint()\nprint('Features selected for R2L:',rfecolname_R2L)\nprint()\nprint('Features selected for U2R:',rfecolname_U2R)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_rfeDoS.shape)\nprint(X_rfeProbe.shape)\nprint(X_rfeR2L.shape)\nprint(X_rfeU2R.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 4: Build the model:\n### Classifier is trained for all features and for reduced features, for later comparison.\n#### The classifier model itself is stored in the clf variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"# all features\nclf_DoS=DecisionTreeClassifier(random_state=0)\nclf_Probe=DecisionTreeClassifier(random_state=0)\nclf_R2L=DecisionTreeClassifier(random_state=0)\nclf_U2R=DecisionTreeClassifier(random_state=0)\nclf_DoS.fit(X_DoS, Y_DoS)\nclf_Probe.fit(X_Probe, Y_Probe)\nclf_R2L.fit(X_R2L, Y_R2L)\nclf_U2R.fit(X_U2R, Y_U2R)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# selected features\nclf_rfeDoS=DecisionTreeClassifier(random_state=0)\nclf_rfeProbe=DecisionTreeClassifier(random_state=0)\nclf_rfeR2L=DecisionTreeClassifier(random_state=0)\nclf_rfeU2R=DecisionTreeClassifier(random_state=0)\nclf_rfeDoS.fit(X_rfeDoS, Y_DoS)\nclf_rfeProbe.fit(X_rfeProbe, Y_Probe)\nclf_rfeR2L.fit(X_rfeR2L, Y_R2L)\nclf_rfeU2R.fit(X_rfeU2R, Y_U2R)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 5: Prediction & Evaluation (validation):"},{"metadata":{},"cell_type":"markdown","source":"# Using all Features for each category"},{"metadata":{},"cell_type":"markdown","source":"# Confusion Matrices\n## DoS"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply the classifier we trained to the test data (which it has never seen before)\nclf_DoS.predict(X_DoS_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# View the predicted probabilities of the first 10 observations\nclf_DoS.predict_proba(X_DoS_test)[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_DoS_pred=clf_DoS.predict(X_DoS_test)\n# Create confusion matrix\npd.crosstab(Y_DoS_test, Y_DoS_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Probe"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_Probe_pred=clf_Probe.predict(X_Probe_test)\n# Create confusion matrix\npd.crosstab(Y_Probe_test, Y_Probe_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## R2L"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_R2L_pred=clf_R2L.predict(X_R2L_test)\n# Create confusion matrix\npd.crosstab(Y_R2L_test, Y_R2L_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## U2R"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_U2R_pred=clf_U2R.predict(X_U2R_test)\n# Create confusion matrix\npd.crosstab(Y_U2R_test, Y_U2R_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cross Validation: Accuracy, Precision, Recall, F-measure"},{"metadata":{},"cell_type":"markdown","source":"## DoS"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\naccuracy = cross_val_score(clf_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\nprecision = cross_val_score(clf_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='precision')\nprint(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\nrecall = cross_val_score(clf_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='recall')\nprint(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\nf = cross_val_score(clf_DoS, X_DoS_test, Y_DoS_test, cv=10, scoring='f1')\nprint(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Probe"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\nprecision = cross_val_score(clf_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='precision_macro')\nprint(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\nrecall = cross_val_score(clf_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='recall_macro')\nprint(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\nf = cross_val_score(clf_Probe, X_Probe_test, Y_Probe_test, cv=10, scoring='f1_macro')\nprint(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## R2L"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\nprecision = cross_val_score(clf_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='precision_macro')\nprint(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\nrecall = cross_val_score(clf_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='recall_macro')\nprint(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\nf = cross_val_score(clf_R2L, X_R2L_test, Y_R2L_test, cv=10, scoring='f1_macro')\nprint(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## U2R"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\nprecision = cross_val_score(clf_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='precision_macro')\nprint(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\nrecall = cross_val_score(clf_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='recall_macro')\nprint(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\nf = cross_val_score(clf_U2R, X_U2R_test, Y_U2R_test, cv=10, scoring='f1_macro')\nprint(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RFECV for illustration"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(__doc__)\n\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.model_selection import StratifiedKFold\n\n# Create the RFE object and compute a cross-validated score.\n# The \"accuracy\" scoring is proportional to the number of correct\n# classifications\nrfecv_DoS = RFECV(estimator=clf_DoS, step=1, cv=10, scoring='accuracy')\nrfecv_DoS.fit(X_DoS_test, Y_DoS_test)\n# Plot number of features VS. cross-validation scores\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.title('RFECV DoS')\nplt.plot(range(1, len(rfecv_DoS.grid_scores_) + 1), rfecv_DoS.grid_scores_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfecv_Probe = RFECV(estimator=clf_Probe, step=1, cv=10, scoring='accuracy')\nrfecv_Probe.fit(X_Probe_test, Y_Probe_test)\n# Plot number of features VS. cross-validation scores\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.title('RFECV Probe')\nplt.plot(range(1, len(rfecv_Probe.grid_scores_) + 1), rfecv_Probe.grid_scores_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfecv_R2L = RFECV(estimator=clf_R2L, step=1, cv=10, scoring='accuracy')\nrfecv_R2L.fit(X_R2L_test, Y_R2L_test)\n# Plot number of features VS. cross-validation scores\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.title('RFECV R2L')\nplt.plot(range(1, len(rfecv_R2L.grid_scores_) + 1), rfecv_R2L.grid_scores_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfecv_U2R = RFECV(estimator=clf_U2R, step=1, cv=10, scoring='accuracy')\nrfecv_U2R.fit(X_U2R_test, Y_U2R_test)\n# Plot number of features VS. cross-validation scores\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.title('RFECV U2R')\nplt.plot(range(1, len(rfecv_U2R.grid_scores_) + 1), rfecv_U2R.grid_scores_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using 13 Features for each category"},{"metadata":{},"cell_type":"markdown","source":"# Confusion Matrices\n## DoS"},{"metadata":{"trusted":true},"cell_type":"code","source":"# reduce test dataset to 13 features, use only features described in rfecolname_DoS etc.\nX_DoS_test2=X_DoS_test[:,rfecolindex_DoS]\nX_Probe_test2=X_Probe_test[:,rfecolindex_Probe]\nX_R2L_test2=X_R2L_test[:,rfecolindex_R2L]\nX_U2R_test2=X_U2R_test[:,rfecolindex_U2R]\nX_U2R_test2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_DoS_pred2=clf_rfeDoS.predict(X_DoS_test2)\n# Create confusion matrix\npd.crosstab(Y_DoS_test, Y_DoS_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Probe"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_Probe_pred2=clf_rfeProbe.predict(X_Probe_test2)\n# Create confusion matrix\npd.crosstab(Y_Probe_test, Y_Probe_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## R2L"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_R2L_pred2=clf_rfeR2L.predict(X_R2L_test2)\n# Create confusion matrix\npd.crosstab(Y_R2L_test, Y_R2L_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## U2R"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_U2R_pred2=clf_rfeU2R.predict(X_U2R_test2)\n# Create confusion matrix\npd.crosstab(Y_U2R_test, Y_U2R_pred2, rownames=['Actual attacks'], colnames=['Predicted attacks'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cross Validation: Accuracy, Precision, Recall, F-measure"},{"metadata":{},"cell_type":"markdown","source":"## DoS"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=10, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\nprecision = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=10, scoring='precision')\nprint(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\nrecall = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=10, scoring='recall')\nprint(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\nf = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=10, scoring='f1')\nprint(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Probe"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=10, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\nprecision = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=10, scoring='precision_macro')\nprint(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\nrecall = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=10, scoring='recall_macro')\nprint(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\nf = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=10, scoring='f1_macro')\nprint(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## R2L"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=10, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\nprecision = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=10, scoring='precision_macro')\nprint(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\nrecall = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=10, scoring='recall_macro')\nprint(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\nf = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=10, scoring='f1_macro')\nprint(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## U2R"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=10, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))\nprecision = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=10, scoring='precision_macro')\nprint(\"Precision: %0.5f (+/- %0.5f)\" % (precision.mean(), precision.std() * 2))\nrecall = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=10, scoring='recall_macro')\nprint(\"Recall: %0.5f (+/- %0.5f)\" % (recall.mean(), recall.std() * 2))\nf = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=10, scoring='f1_macro')\nprint(\"F-measure: %0.5f (+/- %0.5f)\" % (f.mean(), f.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stratified CV => Stays the same"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\naccuracy = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=StratifiedKFold(10), scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=StratifiedKFold(10), scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=StratifiedKFold(10), scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=StratifiedKFold(10), scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CV 2, 5, 10, 30, 50 fold"},{"metadata":{},"cell_type":"markdown","source":"## DoS"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=2, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=5, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=10, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=30, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeDoS, X_DoS_test2, Y_DoS_test, cv=50, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Probe"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=2, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=5, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=10, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=30, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeProbe, X_Probe_test2, Y_Probe_test, cv=50, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## R2L"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=2, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=5, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=10, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=30, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeR2L, X_R2L_test2, Y_R2L_test, cv=50, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## U2R"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=2, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=5, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=10, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=30, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = cross_val_score(clf_rfeU2R, X_U2R_test2, Y_U2R_test, cv=50, scoring='accuracy')\nprint(\"Accuracy: %0.5f (+/- %0.5f)\" % (accuracy.mean(), accuracy.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nKDDTest_2 = pd.read_csv(\"../input/kddtttttt/KDDTest_2.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nKDDTrain_2 = pd.read_csv(\"../input/kddddd/KDDTrain_2.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":1}