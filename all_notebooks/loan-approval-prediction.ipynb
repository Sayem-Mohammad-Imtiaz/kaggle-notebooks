{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hi all, I have tried to use decision tree classification to predict if someone should be given loan or not. I have also used XGboost feature importance, which can be seen further below. The whole purpose of this was to check that if data preprocessing steps make any improvement in our models or not. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.impute import SimpleImputer\nimport numpy as np\nfrom  sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import tree\nfrom sklearn import model_selection\nimport seaborn as sns\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance\nnp.random.seed(0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"file=pd.read_csv(\"../input/loan-data-set/loan_data_set.csv\")\ndata=file\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see there are some features that have missing values, so I will impute those missing values with the most frequent of the values in their respective column."},{"metadata":{"trusted":true},"cell_type":"code","source":"impute_missing=SimpleImputer(missing_values=np.NaN, strategy='most_frequent')\nimpute_missing.fit(data)\ndata=impute_missing.transform(data)\ndata=pd.DataFrame(data=data,columns=file.columns)\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoding=OrdinalEncoder()\nX=data\nX=encoding.fit_transform(X)\nX=pd.DataFrame(data=X,columns=file.columns)\nY=X[\"Loan_Status\"]\nX=X.loc[:,X.columns!=\"Loan_Status\"]\ncopy=X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=DecisionTreeClassifier()\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25,random_state=0)\nmodel.fit(X_train,Y_train)\nplt.figure(figsize=(20,20))\ntree.plot_tree(model.fit(X_train,Y_train))\nprint(\"Decision tree accuracy:::::\",model.score(X_test,Y_test)*100,\"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here i have done only 2 preprocessing steps,** missing value imputation** and **categorical to numnerical encoding**. Still the decision tree is giving a good accuracy. Now we will try to do some more preprocessing and we shall check if there is any improvement or not."},{"metadata":{},"cell_type":"markdown","source":"**Standardizing the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Scaler=StandardScaler()\nstandard_data=Scaler.fit_transform(X)\nX=pd.DataFrame(data=standard_data,columns=copy.columns)\nX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=DecisionTreeClassifier()\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25,random_state=0)\nmodel.fit(X_train,Y_train)\nprint(model.score(X_test,Y_test)*100,\"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As we can see that there no increase in the accuracy after standardizing the data, rather there is a decrease!"},{"metadata":{},"cell_type":"markdown","source":"**Checking for outliers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(17,17))\nsns.boxplot(data=pd.DataFrame(X))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No significant outliers can be seen! We wouldn't deal with the outliers for now as they are very small in number"},{"metadata":{},"cell_type":"markdown","source":"**Feature selection**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1=XGBClassifier()\nmodel1.fit(X,Y)\nplot_importance(model1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the feature importance plot we can see that there are some features which are not that important than others, so we would remove some of the features while training our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"sort=model1.get_booster().get_score()\nprint(sort)\nselected_features=[\"Dependents\",\"Married\",\"Loan_Amount_Term\",\"Credit_History\",\"Property_Area\",\"CoapplicantIncome\",\"LoanAmount\",\"ApplicantIncome\"]\n## removed --Gender,education and loan id\nX=X[selected_features]\nX\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25,random_state=0)\nmodel.fit(X_train,Y_train)\nprint(model.score(X_test,Y_test)*100,\"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Again it can be seen that accuracy did not increased using feature selection**"},{"metadata":{},"cell_type":"markdown","source":"So in totality, the accuracy we are getting is above 70 percent and our model is working pretty okay! But it can be concluded that data preprocessing steps are making significant changes positive or negative in the prediction.! It is not necessary that all the preprocessing steps increase the accuracy. We need to be carefull while thinking on what steps should be done and which ones should not be done."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}