{"cells":[{"metadata":{},"cell_type":"markdown","source":"**<center><font size=6>Titanic - Machine Learning from Disaster</font></center>**\n***\n\n**date**: 07.01.2021\n\n**Table of Contents**\n- <a href='#read'>1. Reading the data</a> \n- <a href='#understand'>2. Understanding and preparing the data</a>\n    - <a href='#describe'>2.1. Describing and planning the data</a>\n    - <a href='#group'>2.2. Grouping and transforming</a>\n    - <a href='#norm'>2.3. Normalising</a>\n- <a href='#split'>3. Splitting the data</a>\n- <a href='#fit'>4. Fitting and validating the models</a>\n    - <a href='#fitLinSVC'>4.1. Fitting the Linear SupportVectorClassifier (LinSVC) and GridSearchCV</a>\n        - <a href='#fitLinSVCcgscv'>4.1.1. LinSVC and GridSearchCV</a>\n        - <a href='#fitLinSVCparam'>4.1.2. Fitting the LinSVC, GridSearchCV parameters</a>\n        - <a href='#valiLinSVC'>4.1.3. Validating the LinSVC</a>\n    - <a href='#fitRBFSVC'>4.2. Fitting the RBF SupportVectorClassifier (RBF SVC) and GridSearchCV</a>\n        - <a href='#fitRBFSVCgscv'>4.2.1. RBF SVC and GridSearchCV</a>\n        - <a href='#fitRBFSVCparam'>4.2.2. Fitting the RBF SVC, GridSearchCV parameters</a>\n        - <a href='#valiRBFSVC'>4.2.3. Validating the RBF SVC</a>\n    - <a href='#fitDT'>4.3. Fitting the DecisionTreeClassifier (DT) and GridSearchCV</a>\n        - <a href='#fitDTgscv'>4.3.1. DT and GridSearchCV</a>\n        - <a href='#fitDTparam'>4.3.2. Fitting the DT, GridSearchCV parameters</a>\n        - <a href='#valiDT'>4.3.3. Validating the DT</a>\n    - <a href='#fitRF'>4.4. Fitting the RandomForestClassifier (RF)</a>\n        - <a href='#fitRFgscv'>4.4.1. RF and GridSearchCV</a>\n        - <a href='#fitRFparam'>4.4.2. Fitting the RF, GridSearchCV parameters</a>\n        - <a href='#valiRF'>4.4.3. Validating the RF</a>\n    - <a href='#fitKNN'>4.5. Fitting the K-Nearest-Neighbours (KNN)</a>  \n        - <a href='#fitKNNgscv'>4.5.1. KNN and GridSearchCV</a>\n        - <a href='#fitKNNparam'>4.5.2. Fitting the KNN, GridSearchCV parameters</a>\n        - <a href='#valiKNN'>4.5.3. Validating the KNN</a> \n    - <a href='#fitLgR'>4.6. Fitting the Logistic Regression (LgR)</a>\n        - <a href='#valiLgR'>4.6.1. Validating the LgR</a>    \n    - <a href='#fitPCA-LgR'>4.7. Fitting the Principal Component Analysis (PCA) and Logistic Regression (LgR)</a>\n        - <a href='#valiPCA-LgR'>4.7.1. Validating the PCA LgR</a> \n    - <a href='#fitOLS'>4.8. Fitting the Ordinary Least Squares Linear Regression (OLS)</a>\n        - <a href='#valiOLS'>4.8.1. Validating the OLS</a> \n    - <a href='#valiARP'>4.9. Accuracy, Recall, Precision: validation set truth vs. predicted values</a>\n    - <a href='#fitsummary'>4.10. Fitting and validating summary</a>\n- <a href='#perd'>5. Predicting</a>\n    - <a href='#predlinsvc'>5.1. Predicting with LinSVC</a>\n    - <a href='#predrbfsvc'>5.2. Predicting with RBF SVC</a>\n    - <a href='#predRF'>5.3. Predicting with DT</a>\n    - <a href='#predRF'>5.4. Predicting with RF</a>\n    - <a href='#predKNN'>5.5. Predicting with KNN</a>\n    - <a href='#predLgR'>5.6. Predicting with LgR</a>\n    - <a href='#predPCA-LgR'>5.7. Predicting with PCA and LgR</a>\n    - <a href='#predOLS'>5.8. Predicting with OLS</a>\n    - <a href='#predARP'>5.9. Accuracy, Recall, Precision: example set truth vs. test set predictions</a>\n    - <a href='#predsummary'>5.10. Prediction summary</a>\n- <a href='#submit'>6. Submitting the data</a>"},{"metadata":{},"cell_type":"markdown","source":"# <a id='read'>1. Reading the data</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Matplotlib config\n%matplotlib inline\n%config InlineBackend.figure_formats = ['svg']\n%config InlineBackend.rc = {'figure.figsize': (5.0, 4.0)}\n\nimport pandas as pd\nimport numpy as np\nimport csv\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import plot_tree\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, plot_confusion_matrix\nfrom sklearn.model_selection import GridSearchCV, RepeatedKFold, train_test_split\n\nfrom sklearn.svm import SVC\nfrom sklearn.svm import LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.decomposition import PCA\nimport statsmodels.api as sm\n\ninput_file = \"../input/titanic/train.csv\"\ndf = pd.read_csv(input_file, header = 0, sep = ',', quotechar='\"')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='understand'>2. Understanding and preparing the data</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib\ndf.info()\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation with the \"Survived\"\n\ndf.corr()[\"Survived\"].abs().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='describe'>2.1. Describing and planning the data</a>"},{"metadata":{},"cell_type":"markdown","source":"| Variable orig | not missing values | Type | Ranges/Values | Describing | Preparing/Transforming | New Variable | New Ranges/New Values |\n| :- | --- | :- | :- | :- | :- | :- | :- |\n| PassengerId | 891 | int64 | 1-891 | | | | \n| Survived | 891 | int64 | 0/1 | 0=died, 1=survived | | | \n| Pclass | 891 | int64 | 1/2/3 | 1=1st class, 2=2nd class, 3=3rd class | normalising | Pclass_norm| 0-1 | \n| Name | 891 | object | text | | | | \n| Sex | 891 | object | female/male | female=0, male=1 | categories as numbers | Sex_ord | 0/1 |\n| Age | 714 | float64 | 0.42-80 Years | | grouping, than splitting age-groups in 5 variables | Age_Group; Age_Infant; Age_Kid; Age_Young; Age_Adults; Age_Elderly; Age_norm | Infant(0-5)/Kid(5-14)/Young(14-25)/Adult(25-55)/Elderly(55-80); 0/1; 0/1; 0/1; 0/1; 0/1; 0-1 |\n| SibSp | 891 | int64 | 0-8 | Sibling = brother, sister, stepbrother, stepsister / Spouse = husband, wife | as 0=alone, 1=not alone| SibORParch | 0/1 |\n| Parch | 891 | int64 | 0-6 | Parent = mother, father / Child = daughter, son, stepdaughter, stepson |as 0=alone, 1=not alone| SibORParch | 0/1 |\n| Ticket | 891 | object | Letters and Numbers | | | |\n| Fare | 891 | float64 | 0-512.3292 Dolars | | normalising | Fare_norm | 0-1 | \n| Cabin | 204 | object | Letters and Numbers | | | |\n| Embarked | 889 | object | C/Q/S | C = Cherbourg, Q = Queenstown, S = Southampton | categories as numbers (C=0, Q=1, S=2) and than also as 3 single variables 0/1 | Embarked_ord; Embk_Cherbourg; Embk_Queenstown; Embk_Southampton | 0/1/2; 0/1; 0/1; 0/1 |"},{"metadata":{},"cell_type":"markdown","source":"## <a id='group'>2.2. Grouping and transforming: Age, SibSp, Parch, Sex, Embarked</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Age: Age grouped in categories Age_Group = ['Infant','Kid','Young','Adult','Elderly']. Then Age-groups get splitted in 5 single variables, with values 0/1\n\nbins_Age_Group= [0,4.9999,13.9999,24.9999,54.9999,100]\nlabels_Age_Group = ['Infant','Kid','Young','Adult','Elderly']\ndf['Age_Group'] = pd.cut(df['Age'], bins=bins_Age_Group, labels=labels_Age_Group, right=False)\ndf['Age_Group_ord'] = pd.Categorical(df.Age_Group).codes\n\nbins_Age_Infant = [5,13.9999]\nlabels_Age_Infant = ['Infant']\ndf['Age_Infant'] = pd.cut(df['Age'], bins =bins_Age_Infant, labels =labels_Age_Infant, right=False)\ndf['Age_Infant'] = df['Age_Infant'].notna().astype('int')\n\nbins_Age_Kid = [5,13.9999]\nlabels_Age_Kid = ['Kid']\ndf['Age_Kid'] = pd.cut(df['Age'], bins =bins_Age_Kid, labels =labels_Age_Kid, right=False)\ndf['Age_Kid'] = df['Age_Kid'].notna().astype('int')\n\nbins_Age_Young = [14,24.9999]\nlabels_Age_Young = ['Young']\ndf['Age_Young'] = pd.cut(df['Age'], bins =bins_Age_Young, labels =labels_Age_Young, right=False)\ndf['Age_Young'] = df['Age_Young'].notna().astype('int')\n\nbins_Age_Adult = [25,54.9999]\nlabels_Age_Adult = ['Adult']\ndf['Age_Adult'] = pd.cut(df['Age'], bins =bins_Age_Adult, labels =labels_Age_Adult, right=False)\ndf['Age_Adult'] = df['Age_Adult'].notna().astype('int')\n\nbins_Age_Elderly = [55,100]\nlabels_Age_Elderly = ['Elderly']\ndf['Age_Elderly'] = pd.cut(df['Age'], bins =bins_Age_Elderly, labels =labels_Age_Elderly, right=False)\ndf['Age_Elderly'] = df['Age_Elderly'].notna().astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SibSp and Parch: get aggregated in one 0/1 single variable SibORParch, which means alone/not alone on board.\n\nbins_SibORParch = [1,20]\nlabels_SibORParch = ['notalone']\ndf['SibORParch'] = pd.cut(df['SibSp']+df['Parch'], bins =bins_SibORParch, labels =labels_SibORParch, right=False)\ndf['SibORParch'] = df['SibORParch'].notna().astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sex: categories as numbers, numerical variable 0/1 (0 = female, 1 = male)\n\ndf['Sex_ord'] = pd.Categorical(df.Sex).codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Embarked: Embarked [C = Cherbourg, Q = Queenstown, S = Southampton], categories as numbers, as a numerical variable Embarked_ord 0/1/2, than Embarked get splitted in 3 single variables, with values 0/1\n\n#C=0, Q=1, S=2\ndf['Embarked_ord'] = pd.Categorical(df.Embarked).codes\n\n#Cherbourg\nbins_Embk_Cherbourg = [0,0.9999]\nlabels_Embk_Cherbourg = ['Embk_Cherbourg']\ndf['Embk_Cherbourg'] = pd.cut(df['Embarked_ord'], bins =bins_Embk_Cherbourg, labels =labels_Embk_Cherbourg, right=False)\ndf['Embk_Cherbourg'] = df['Embk_Cherbourg'].notna().astype('int')\n\n#Queenstown\nbins_Embk_Queenstown = [1,1.9999]\nlabels_Embk_Queenstown = ['Embk_Queenstown']\ndf['Embk_Queenstown'] = pd.cut(df['Embarked_ord'], bins =bins_Embk_Queenstown, labels =labels_Embk_Queenstown, right=False)\ndf['Embk_Queenstown'] = df['Embk_Queenstown'].notna().astype('int')\n\n#Southampton\nbins_Embk_Southampton = [2,2.9999]\nlabels_Embk_Southampton = ['Embk_Southampton']\ndf['Embk_Southampton'] = pd.cut(df['Embarked_ord'], bins =bins_Embk_Southampton, labels =labels_Embk_Southampton, right=False)\ndf['Embk_Southampton'] = df['Embk_Southampton'].notna().astype('int')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='norm'>2.3. Normalising: Fare, Age, Pclass</a>"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Normalise Fare as new variable 0-1\ndf['Fare_norm'] = df['Fare']/np.max(df['Fare'])\n\n#Normalise Age as new variable 0-1\n\ndf['Age_norm'] = df['Age']/np.max(df['Age'])\n\n#Normalise Pclass as new variable 0-1\ndf['Pclass_norm'] = df['Pclass']/np.max(df['Pclass'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#All the new variavles correlated with the \"Survived\"\n\ndf.corr()[\"Survived\"].abs().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation Matrix\n\n#sns.heatmap(df.corr());","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='split'>3. Splitting the data</a>"},{"metadata":{},"cell_type":"markdown","source":"Splitting the data in training and validation sets in new csv files.\n\n| Kaggle set | | Splitted sets |need for | | | | | \n| :- | --- | :- | :- | :- | :- | :- | :- |\n| train set | 80% | training set | fitting the model| | | \n| train set | 20% | validation set | validating the model| | | |  \n| test set | 100%| |predicting the data| | | | |\n| | | | | | | | "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Write the actual dataframe df in a new csv\ndf.to_csv (r'train_new.csv', index = False, header=True)\n\n#Splitt randomly the new csv in training set (80% of rows) und validation set (20% of rows) csv \nimport random\n\nwith open('train_new.csv') as data:\n    with open('train_training.csv', 'w') as test:\n        with open('train_validation.csv', 'w') as train:\n            header = next(data)\n            train.write(header)\n            test.write(header)\n            \n            for line in data:\n                if random.random() > 0.80:\n                    train.write(line)\n                else:\n                    test.write(line)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='fit'>4. Fitting and validating the models</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read the training set (80% der data)\ninput_training_file = \"./train_training.csv\"\ndf_training = pd.read_csv(input_training_file, header = 0, sep = ',', quotechar='\"')\n#df_training.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read the validation set\ninput_validation_file = \"./train_validation.csv\"\ndf_validation = pd.read_csv(input_validation_file, header = 0, sep = ',', quotechar='\"')\n#df_validation.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib\ndf_training.info()\ndf_training.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_training.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='fitLinSVC'>4.1. Fitting the Linear SupportVectorClassifier (LinSVC) and GridSearchCV</a>"},{"metadata":{},"cell_type":"markdown","source":"### <a id='fitLinSVCgscv'>4.1.1. LinSVC and GridSearchCV</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Attention! This code needs long time to run! \n\nX_linsvcgscv_training = df_training[['Sex_ord', 'SibORParch', 'Fare', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\ny_linsvcgscv_training = df_training[\"Survived\"]\n\nX_linsvcgscv_validation = df_validation[['Sex_ord', 'SibORParch', 'Fare', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\ny_linsvcgscv_validation = df_validation[\"Survived\"]\n\nsc_linsvcgscv = StandardScaler()\nsc_linsvcgscv_training = sc_linsvcgscv.fit(X_linsvcgscv_training)\nsc_linsvcgscv_validation = sc_linsvcgscv.fit(X_linsvcgscv_validation)\n\nX_linsvcgscv_training_scalar = sc_linsvcgscv_training.transform(X_linsvcgscv_training)\nX_linsvcgscv_validation_scalar = sc_linsvcgscv_validation.transform(X_linsvcgscv_validation)\n\nmodel_linsvcgscv = GridSearchCV(LinearSVC(), param_grid = {\n    \"C\": [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1], \n    \"max_iter\": [1000000]\n}, cv = RepeatedKFold())\n\nmodel_linsvcgscv_training = model_linsvcgscv.fit(X_linsvcgscv_training_scalar, y_linsvcgscv_training)\nmodel_linsvcgscv_validation = model_linsvcgscv.fit(X_linsvcgscv_validation_scalar, y_linsvcgscv_validation)\n\nprint('Best model parameter: ' + str(model_linsvcgscv_training.best_params_))\nprint('Best model score: ' + str(model_linsvcgscv_training.best_score_))\n\nprint('Model score: ' + str(model_linsvcgscv_training.score(X_linsvcgscv_training, y_linsvcgscv_training)))\nprint('Model score testing new data: ' + str(model_linsvcgscv_validation.score(X_linsvcgscv_validation, y_linsvcgscv_validation)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='fitLinSVCparam'>4.1.2. Fitting the LinSVC, GridSearchCV parameters</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.svm import LinearSVC\n\nX_linsvc_training = df_training[['Sex_ord', 'SibORParch', 'Fare', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\ny_linsvc_training = df_training[\"Survived\"]\n\nsc_linsvc = StandardScaler()\nsc_linsvc_training = sc_linsvc.fit(X_linsvc_training)\n\nX_linsvc_training_scale = sc_linsvc_training.transform(X_linsvc_training)\n\nmodel_linsvc = LinearSVC(max_iter = 1000000, C = 0.01)\nmodel_linsvc.fit(X_linsvc_training_scale, y_linsvc_training)\n\n#print(model_linsvc.score(X_linsvc_training_scale, y_linsvc_training))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_linsvc, X_linsvc_training, y_linsvc_training, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='valiLinSVC'>4.1.3. Validating the LinSVC</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_linsvc_validation = df_validation[['Sex_ord', 'SibORParch', 'Fare', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\ny_linsvc_validation = model_linsvc.predict(X_linsvc_validation)\n\n#Add new column with the values predicted with the Linear SVC\ndf_validation['Survived_linsvc_validation']=y_linsvc_validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_linsvc, X_linsvc_validation, y_linsvc_validation, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion matrix: the true values from the validation set vs. LinearSVC predicted values for the validation set\n\ny_linsvc_true = df_validation['Survived']\ny_linsvc_pred = df_validation['Survived_linsvc_validation']\n\nlinsvc_validation_cm = confusion_matrix(y_linsvc_true, y_linsvc_pred, normalize = \"all\")\nlinsvc_validation_score = accuracy_score(y_linsvc_true, y_linsvc_pred, normalize = \"all\")\n\nlinsvc_validation_cm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('LinSVC training score: ' + str(model_linsvc.score(X_linsvc_training, y_linsvc_training)))\nprint('LinSVC validation score: ' + str(linsvc_validation_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='fitRBFSVC'>4.2. Fitting the RBF SVM (RBF SVM) and GridSearchCV</a>"},{"metadata":{},"cell_type":"markdown","source":"### <a id='fitRBFSVCgscv'>4.2.1. RBF SVM and GridSearchCV</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.svm import SVC\n#from sklearn.preprocessing import StandardScaler\n\nX_rbfsvcgscv_training = df_training[['Sex_ord', 'SibORParch', 'Fare', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\ny_rbfsvcgscv_training = df_training[\"Survived\"]\n\nX_rbfsvcgscv_validation = df_validation[['Sex_ord', 'SibORParch', 'Fare', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\ny_rbfsvcgscv_validation = df_validation[\"Survived\"]\n\n#Use scalar or PCA for optimizing\nsc_rbfsvcgscv = StandardScaler()\nsc_rbfsvcgscv_training = sc_rbfsvcgscv.fit(X_rbfsvcgscv_training)\nsc_rbfsvcgscv_validation = sc_rbfsvcgscv.fit(X_rbfsvcgscv_validation)\n\nX_rbfsvcgscv_training_scalar = sc_rbfsvcgscv_training.transform(X_rbfsvcgscv_training)\nX_rbfsvcgscv_validation_scalar = sc_rbfsvcgscv_validation.transform(X_rbfsvcgscv_validation)\n\nmodel_rbfsvcgscv = GridSearchCV(SVC(), param_grid = {\n    \"kernel\": [\"rbf\"], \n    \"C\": [20, 25, 30, 35, 40], \n    \"gamma\": [0.0005, 0.001, 0.005, 0.01, 0.05]\n}, cv = RepeatedKFold(), n_jobs = 8)\n\nmodel_rbfsvcgscv_training = model_rbfsvcgscv.fit(X_rbfsvcgscv_training_scalar, y_rbfsvcgscv_training)\nmodel_rbfsvcgscv_validation = model_rbfsvcgscv.fit(X_rbfsvcgscv_validation_scalar, y_rbfsvcgscv_validation)\n\nprint('Best model parameter: ' + str(model_rbfsvcgscv_training.best_params_))\nprint('Best model score: ' + str(model_rbfsvcgscv_training.best_score_))\n\nprint('Model score: ' + str(model_rbfsvcgscv_training.score(X_rbfsvcgscv_training, y_rbfsvcgscv_training)))\nprint('Model score testing new data: ' + str(model_rbfsvcgscv_validation.score(X_rbfsvcgscv_validation, y_rbfsvcgscv_validation)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='fitRBFSVCparam'>4.2.2. Fitting the RBF SVM, GridSearchCV parameters</a>"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#from sklearn.svm import SVC\n\nX_rbfsvc_training = df_training[['Sex_ord', 'SibORParch', 'Fare', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\ny_rbfsvc_training = df_training[\"Survived\"]\n\nsc_rbfsvc = StandardScaler()\nsc_rbfsvc_training = sc_rbfsvc.fit(X_rbfsvc_training)\n\nX_rbfsvc_training_scale = sc_rbfsvc_training.transform(X_rbfsvc_training)\n\nmodel_rbfsvc = SVC(kernel = \"rbf\", C = 40, gamma = 0.01)\nmodel_rbfsvc.fit(X_rbfsvc_training_scale, y_rbfsvc_training)\n\n#print(model_rbfsvc.score(X_rbfsvc_training_scale, y_rbfsvc_training))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_linsvc, X_rbfsvc_training, y_rbfsvc_training, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='valiRBFSVC'>4.2.3. Validating the RBF SVM</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_rbfsvc_validation = df_validation[['Sex_ord', 'SibORParch', 'Fare', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\ny_rbfsvc_validation = model_rbfsvc.predict(X_rbfsvc_validation)\n\n#Add new column with the values predicted with the Linear SVC\ndf_validation['Survived_rbfsvc_validation']=y_rbfsvc_validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_linsvc, X_rbfsvc_validation, y_rbfsvc_validation, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion matrix: the true values from the validation set vs. rbfSVC predicted values for the validation set\n\ny_rbfsvc_true = df_validation['Survived']\ny_rbfsvc_pred = df_validation['Survived_linsvc_validation']\n\nrbfsvc_validation_cm = confusion_matrix(y_rbfsvc_true, y_rbfsvc_pred, normalize = \"all\")\nrbfsvc_validation_score = accuracy_score(y_rbfsvc_true, y_rbfsvc_pred, normalize = \"all\")\n\nrbfsvc_validation_cm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('RBF SVC training score: ' + str(model_rbfsvc.score(X_rbfsvc_training, y_rbfsvc_training)))\nprint('RBF SVC validation score: ' + str(rbfsvc_validation_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='fitDT'>4.3. Fitting the DecisionTreeClassifier (DT) and GridSearchCV</a>"},{"metadata":{},"cell_type":"markdown","source":"### <a id='fitDTgscv'>4.3.1. DT and GridSearchCV</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#test some parameters with GridSearchCV for the DecisionTreeClassifier\n\n#from sklearn.tree import DecisionTreeClassifier\n\nfeatures_dt = ['Fare', 'SibORParch', 'Sex_ord', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]\nX_dtgscv_training = pd.get_dummies(df_training[features_dt])\ny_dtgscv_training = df_training[\"Survived\"]\nX_dtgscv_validation = pd.get_dummies(df_validation[features_dt])\ny_dtgscv_validation = df_validation[\"Survived\"]\n\nmodel_dtgscv = GridSearchCV(DecisionTreeClassifier(), param_grid = {\n    'max_depth': [23, 24, 25, 26, 27, 28, 29, 30, 31, 32],\n    'min_samples_leaf': [2, 3, 4, 5, 6, 7]\n}, cv = RepeatedKFold())\n\nmodel_dtgscv.fit(X_dtgscv_training, y_dtgscv_training)\n\nprint('Best model parameters: ' + str(model_dtgscv.best_params_))\nprint('Best model score: ' + str(model_dtgscv.best_score_))\n\nprint('Model score: ' + str(model_dtgscv.score(X_dtgscv_training, y_dtgscv_training)))\nprint('Model score testing new data: ' + str(model_dtgscv.score(X_dtgscv_validation, y_dtgscv_validation)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pd.DataFrame(model_dtgscv.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='fitDTparam'>4.3.2. Fitting the DT, GridSearchCV parameters</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model DecisionTreeClassifier: Train a DecisionTreeClassifier with the training set\n\n#from sklearn.tree import DecisionTreeClassifier\n\n#features_dt = ['Fare', 'SibORParch', 'Sex_ord', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]\nX_dt_training = pd.get_dummies(df_training[features_dt])\ny_dt_training = df_training[\"Survived\"]\n\n#set the best parameters for the decision tree\nmodel_dt = DecisionTreeClassifier(max_depth=32, min_samples_leaf = 6)\nmodel_dt.fit(X_dt_training, y_dt_training)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Print the DecisionTree\n#from sklearn.tree import plot_tree\n#import matplotlib.pyplot as plt\n\nplot_tree(model_dt, \n          feature_names = ['Fare', 'SibORParch', 'Sex_ord', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ], \n          class_names = [\"not survived\", \"survived\"],\n          filled = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_dt, X_dt_training, y_dt_training, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='valiDT'>4.3.3. Validating the DT</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model DecisionTreeClassifier: Validate the fitted DecisionTreeClassifier\n#Predict the validation set with the fitted DecisionTreeClassifier\n\nX_dt_validation = pd.get_dummies(df_validation[features_dt])\ny_dt_validation = model_dt.predict(X_dt_validation)\n\n#Add new column with the values predicted with the DecisionTreeClassifier\ndf_validation['Survived_dt_validation']=y_dt_validation\n#df_validation.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_dt, X_dt_validation, y_dt_validation, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion matrix: the true values from the validation set vs. DecisionTreeClassifier predicted values for the validation set\n\ny_dt_true = df_validation['Survived']\ny_dt_pred = df_validation['Survived_dt_validation']\n\ndt_validation_cm = confusion_matrix(y_dt_true, y_dt_pred, normalize = \"all\")\ndt_validation_score = accuracy_score(y_dt_true, y_dt_pred, normalize = \"all\")\n\ndt_validation_cm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('DT training score: ' + str(model_dt.score(X_dt_training, y_dt_training)))\nprint('DT validation score: ' + str(dt_validation_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='fitRF'>4.4. Fitting the RandomForestClassifier (RF) and GridSearchCV</a>"},{"metadata":{},"cell_type":"markdown","source":"### <a id='fitRFgscv'>4.4.1. RF and GridSearchCV</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#test some parameters with GridSearchCV for the RandomForestClassifier\n\n#from sklearn.ensemble import RandomForestClassifier\n\nfeatures_rf = ['Fare', 'SibORParch', 'Sex_ord', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]\nX_rfgscv_training = pd.get_dummies(df_training[features_rf])\ny_rfgscv_training = df_training[\"Survived\"]\nX_rfgscv_validation = pd.get_dummies(df_validation[features_rf])\ny_rfgscv_validation = df_validation[\"Survived\"]\n\nmodel_rfgscv = GridSearchCV(RandomForestClassifier(), param_grid = {\n    'max_depth': [11, 12, 13, 14, 15],\n    'min_samples_leaf': [1, 2, 3]\n}, cv = RepeatedKFold())\n\nmodel_rfgscv.fit(X_rfgscv_training, y_rfgscv_training)\n\nprint('Best model parameter: ' + str(model_rfgscv.best_params_))\nprint('Best model score: ' + str(model_rfgscv.best_score_))\n\nprint('Model score: ' + str(model_rfgscv.score(X_rfgscv_training, y_rfgscv_training)))\nprint('Model score testing new data: ' + str(model_rfgscv.score(X_rfgscv_validation, y_rfgscv_validation)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='fitRFparam'>4.4.2. Fitting the RF, GridSearchCV parameters</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model RandomForestClassifier: Train a RandomForestClassifier model with the training set\n\n#from sklearn.ensemble import RandomForestClassifier\n\n#features_rf = ['Fare', 'SibORParch', 'Sex_ord', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]\nX_rf_training = pd.get_dummies(df_training[features_rf])\ny_rf_training = df_training[\"Survived\"]\n\nmodel_rf = RandomForestClassifier(n_estimators=100, max_depth=13, min_samples_leaf = 2)\nmodel_rf.fit(X_rf_training, y_rf_training)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_rf, X_rf_training, y_rf_training, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='valiRF'>4.4.3. Validating the RF</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model RandomForestClassifier: Validate the fitted RandomForestClassifier model\n#Predict the validation set with the fitted RandomForestClassifier model\n\nX_rf_validation = pd.get_dummies(df_validation[features_rf])\ny_rf_validation = model_rf.predict(X_rf_validation)\n\n#Add new column with the values predicted with the RandomForestClassifier model\ndf_validation['Survived_rf_validation']=y_rf_validation\n#df_validation.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_rf, X_rf_validation, y_rf_validation, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion matrix: the true values from the validation set vs. RandomForestClassifier model predicted values for the validation set\n\ny_rf_true = df_validation['Survived']\ny_rf_pred = df_validation['Survived_rf_validation']\n\nrf_validation_cm = confusion_matrix(y_rf_true, y_rf_pred, normalize = \"all\")\nrf_validation_score = accuracy_score(y_rf_true, y_rf_pred, normalize = \"all\")\n\nrf_validation_cm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('RF training score: ' + str(model_rf.score(X_rf_training, y_rf_training)))\nprint('RF validation score: ' + str(rf_validation_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='fitKNN'>4.5. Fitting the K-Nearest-Neighbours (KNN)</a>"},{"metadata":{},"cell_type":"markdown","source":"### <a id='fitKNNparam'>4.5.1. KNN and GridSearchCV</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.neighbors import KNeighborsClassifier\n\nX_knngscv_training = df_training[['Sex_ord', 'SibORParch', 'Fare', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\ny_knngscv_training = df_training[\"Survived\"]\n\nX_knngscv_validation = df_validation[['Sex_ord', 'SibORParch', 'Fare', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\ny_knngscv_validation = df_validation[\"Survived\"]\n\nsc_knngscv = StandardScaler()\nsc_knngscv_training = sc_knngscv.fit(X_knngscv_training)\nsc_knngscv_validation = sc_knngscv.fit(X_knngscv_validation)\n\nX_knngscv_training_scalar = sc_knngscv_training.transform(X_knngscv_training)\nX_knngscv_validation_scalar = sc_knngscv_validation.transform(X_knngscv_validation)\n\n#manhattan_distance (p=1) and euclidean_distance (p=2)\nmodel_knngscv = GridSearchCV(KNeighborsClassifier(), param_grid = {\n    'n_neighbors': [5, 6, 7, 8, 9, 10, 15, 20, 25, 35, 50, 75],\n    'p': [1, 2], \n    #'weights': ['uniform', 'distance']\n}, cv = RepeatedKFold())\n\nmodel_knngscv_training = model_knngscv.fit(X_knngscv_training_scalar, y_knngscv_training)\nmodel_knngscv_validation = model_knngscv.fit(X_knngscv_validation_scalar, y_knngscv_validation)\n\nprint('Best model parameter: ' + str(model_knngscv_training.best_params_))\nprint('Best model score: ' + str(model_knngscv_training.best_score_))\n\nprint('Model score: ' + str(model_knngscv_training.score(X_knngscv_training, y_knngscv_training)))\nprint('Model score testing new data: ' + str(model_knngscv_validation.score(X_knngscv_validation, y_knngscv_validation)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='fitKNNparam'>4.5.2. Fitting the KNN, GridSearchCV parameters</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.neighbors import KNeighborsClassifier\n\nX_knn_training = df_training[['Sex_ord', 'SibORParch', 'Fare', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\ny_knn_training = df_training[\"Survived\"]\n\nsc_knn = StandardScaler()\nsc_knn.fit(X_knn_training)\n\nX_knn_training_scaled = sc_knn.transform(X_knn_training)\n\n#manhattan distance p=1\nmodel_knn = KNeighborsClassifier(n_neighbors = 25, p = 2)\nmodel_knn.fit(X_knn_training_scaled, y_knn_training)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(model_knn.predict_proba(X_knn_training_scaled))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_knn, X_knn_training_scaled, y_knn_training, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='valiKNN'>4.5.3. Validating the KNN</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_knn_validation = df_validation[['Sex_ord', 'SibORParch', 'Fare', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\nX_knn_validation_scaled = sc_knn.transform(X_knn_validation)\ny_knn_validation = model_knn.predict(X_knn_validation_scaled)\n\ndf_validation['Survived_knn_validation']=y_knn_validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_knn, X_knn_validation_scaled, y_knn_validation, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion matrix: the true values from the validation set vs. KNN model predicted values for the validation set\n\ny_knn_true = df_validation['Survived']\ny_knn_pred = df_validation['Survived_knn_validation']\n\nknn_validation_cm = confusion_matrix(y_knn_true, y_knn_pred, normalize = \"all\")\nknn_validation_score = accuracy_score(y_knn_true, y_knn_pred, normalize = \"all\")\n\nknn_validation_cm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('KNN training score: ' + str(model_knn.score(X_knn_training_scaled, y_knn_training)))\nprint('KNN validation score: ' + str(knn_validation_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='fitLgR'>4.6. Fitting the Logistic Regression (LgR)</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.linear_model import LogisticRegression\n\nX_lgr_training = df_training[['Fare', 'SibORParch', 'Sex_ord', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\ny_lgr_training = df_training[['Survived']]\n\nmodel_lgr = LogisticRegression(class_weight = \"balancend\")\nmodel_lgr.fit(X_lgr_training, y_lgr_training)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_lgr, X_lgr_training, y_lgr_training, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='valiLgR'>4.6.1. Validating the LgR</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_lgr_validation = df_validation[['Fare', 'SibORParch', 'Sex_ord', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\n\ny_lgr_validation = model_lgr.predict(X_lgr_validation)\ndf_validation['Survived_lgr_validation']=y_lgr_validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_lgr, X_lgr_validation, y_lgr_validation, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion matrix: the true values from the validation set vs. Logistic Regression model predicted values for the validation set\n\ny_lgr_true = df_validation['Survived']\ny_lgr_pred = df_validation['Survived_lgr_validation']\n\nlgr_validation_cm = confusion_matrix(y_lgr_true, y_lgr_pred, normalize = \"all\")\nlgr_validation_score = accuracy_score(y_lgr_true, y_lgr_pred, normalize = \"all\")\n\nlgr_validation_cm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('LgR training score: ' + str(model_lgr.score(X_lgr_training, y_lgr_training)))\nprint('LgR validation score: ' + str(lgr_validation_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='fitPCA-LgR'>4.7. Fitting the Principal Component Analysis and Logistic Regression (PCA LgR)</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.decomposition import PCA\n\nX_pca_lgr_training = df_training[['Sex_ord', 'SibORParch', 'Fare', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\ny_pca_lgr_training = df_training[\"Survived\"]\n\npca = PCA(n_components = 2)\n\n# pca.fit(X_pca_lgr_training)\n# X_pca_lgr_training_transformed = pca.transform(X_pca_lgr_training)\n\nX_pca_lgr_training_transformed = pca.fit_transform(X_pca_lgr_training)\n\nmodel_pca_lgr = LogisticRegression(class_weight = \"balancend\")\nmodel_pca_lgr.fit(X_pca_lgr_training_transformed, y_pca_lgr_training)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(X_pca_lgr_training_transformed[:, 0], X_pca_lgr_training_transformed[:, 1], hue = df_training[\"Survived\"]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_pca_lgr, X_pca_lgr_training_transformed, y_pca_lgr_training, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='valiPCA-LgR'>4.7.1. Validating the PCA LgR</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dimension reduction and Logistic Regression\n\nX_pca_lgr_validation = df_validation[['Fare', 'SibORParch', 'Sex_ord', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\nX_pca_lgr_validation_transformed = pca.transform(X_pca_lgr_validation)\n\ny_pca_lgr_validation = model_pca_lgr.predict(pca.transform(X_pca_lgr_validation))\ndf_validation['Survived_pca_lgr_validation'] = y_pca_lgr_validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(X_pca_lgr_validation_transformed[:, 0], X_pca_lgr_validation_transformed[:, 1], hue = df_validation[\"Survived\"]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_pca_lgr, X_pca_lgr_validation_transformed, y_pca_lgr_validation, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion matrix: the true values from the validation set vs. PCA Logistic Regression model predicted values for the validation set\n\ny_pca_lgr_true = df_validation['Survived']\ny_pca_lgr_pred = df_validation['Survived_pca_lgr_validation']\n\npca_lgr_validation_cm = confusion_matrix(y_pca_lgr_true, y_pca_lgr_pred, normalize = \"all\")\npca_lgr_validation_score = accuracy_score(y_pca_lgr_true, y_pca_lgr_pred, normalize = \"all\")\n\npca_lgr_validation_cm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('PCA LgR training score: ' + str(model_pca_lgr.score(X_pca_lgr_training_transformed, y_pca_lgr_training)))\nprint('PCA LgR validation score: ' + str(pca_lgr_validation_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='fitOLS'>4.8. Fitting the Ordinary Least Squares (OLS)</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model OLS: Train an OLS model with the training set\n\n#import statsmodels.api as sm\n\nX_ols_training = df_training[['Fare', 'SibORParch', 'Sex_ord', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\ny_ols_training = df_training[['Survived']]\n\nX1_ols_training = sm.add_constant(X_ols_training)\nmodel_ols = sm.OLS(y_ols_training, X1_ols_training).fit()\n\n#summary\nmodel_ols.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='valiOLS'>4.8.1. Validating the OLS</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model OLS: Validate the fitted OLS model\n#Predict the validation set with the fitted OLS model\n\nX_ols_validation = df_validation[['Fare', 'SibORParch', 'Sex_ord', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\nX1_ols_validation = sm.add_constant(X_ols_validation)\n\ny_ols_validation =  model_ols.predict(X1_ols_validation)\ny_ols_validation =  round(y_ols_validation)\n\n#Add new column with the values predicted with the OLS model\ndf_validation['Survived_ols_validation']=y_ols_validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion matrix: the true values from the validation set vs. OLS model predicted values for the validation set\n\ny_ols_true = df_validation['Survived']\ny_ols_pred = df_validation['Survived_ols_validation']\n\nols_validation_cm = confusion_matrix(y_ols_true, y_ols_pred, normalize = \"all\")\nols_validation_score = accuracy_score(y_ols_true, y_ols_pred, normalize = \"all\")\n\nols_validation_cm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('OLS validation score: ' + str(ols_validation_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='valiARP'>4.9. Accuracy, Recall, Precision: validation set truth vs. validation set predictions</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Accuracy\n\nA_linsvc = accuracy_score(y_linsvc_true, y_linsvc_pred)\nA_rbfsvc = accuracy_score(y_rbfsvc_true, y_rbfsvc_pred)\nA_dt = accuracy_score(y_dt_true, y_dt_pred)\nA_rf = accuracy_score(y_rf_true, y_rf_pred)\nA_knn = accuracy_score(y_knn_true, y_knn_pred)\nA_lgr = accuracy_score(y_lgr_true, y_lgr_pred)\nA_pca_lgr = accuracy_score(y_pca_lgr_true, y_pca_lgr_pred)\nA_ols = accuracy_score(y_ols_true, y_ols_pred)\n\nprint(\"Accuracy LinSVC = \" + str(A_linsvc))\nprint(\"Accuracy RBF SVC = \" + str(A_rbfsvc))\nprint(\"Accuracy DT = \" + str(A_dt))\nprint(\"Accuracy RF = \" + str(A_rf))\nprint(\"Accuracy KNN = \" + str(A_knn))\nprint(\"Accuracy LgR = \" + str(A_lgr))\nprint(\"Accuracy PCA LgR = \" + str(A_pca_lgr))\nprint(\"Accuracy OLS = \" + str(A_ols))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Recall\n\nR_linsvc = recall_score(y_linsvc_true, y_linsvc_pred)\nR_rbfsvc = recall_score(y_rbfsvc_true, y_rbfsvc_pred)\nR_dt = recall_score(y_dt_true, y_dt_pred)\nR_rf = recall_score(y_rf_true, y_rf_pred)\nR_knn = recall_score(y_knn_true, y_knn_pred)\nR_lgr = recall_score(y_lgr_true, y_lgr_pred)\nR_pca_lgr = recall_score(y_pca_lgr_true, y_pca_lgr_pred)\nR_ols = recall_score(y_ols_true, y_ols_pred)\n\nprint(\"Recall LinSVC = \" + str(R_linsvc))\nprint(\"Recall RBF SVC = \" + str(R_rbfsvc))\nprint(\"Recall DT = \" + str(R_dt))\nprint(\"Recall RF = \" + str(R_rf))\nprint(\"Recall KNN = \" + str(R_knn))\nprint(\"Recall LgR = \" + str(R_lgr))\nprint(\"Recall PCA LgR = \" + str(R_pca_lgr))\nprint(\"Recall OLS = \" + str(R_ols))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Precision\n\nP_linsvc = precision_score(y_linsvc_true, y_linsvc_pred)\nP_rbfsvc = precision_score(y_rbfsvc_true, y_rbfsvc_pred)\nP_dt = precision_score(y_dt_true, y_dt_pred)\nP_rf = precision_score(y_rf_true, y_rf_pred)\nP_knn = precision_score(y_knn_true, y_knn_pred)\nP_lgr = precision_score(y_lgr_true, y_lgr_pred)\nP_pca_lgr = precision_score(y_pca_lgr_true, y_pca_lgr_pred)\nP_ols = precision_score(y_ols_true, y_ols_pred)\n\nprint(\"Precision LinSVC = \" + str(P_linsvc))\nprint(\"Precision RBF SVC = \" + str(P_rbfsvc))\nprint(\"Precision DT = \" + str(P_dt))\nprint(\"Precision RF = \" + str(P_rf))\nprint(\"Precision KNN = \" + str(P_knn))\nprint(\"Precision LgR = \" + str(P_lgr))\nprint(\"Precision PCA_LgR = \" + str(P_pca_lgr))\nprint(\"Precision OLS = \" + str(P_ols))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='fitsummary'>4.10. Fitting and validating summary</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"relevant_metrics = pd.DataFrame({\n    'Model': ['LinearSVC', 'RBF SVC', 'Decision Tree', 'Random Forest', 'K-Nearest-Neighbours', 'Logistic Regression', 'PCA Logistic Regression', 'Ordinary Least Squares Linear Regression'],\n    'Accuracy, A': [A_linsvc, A_rbfsvc, A_dt, A_rf, A_knn, A_lgr, A_pca_lgr, A_ols],\n    'Recall, R': [R_linsvc, R_rbfsvc, R_dt, R_rf, R_knn, R_lgr, R_pca_lgr, R_ols],\n    'Precision, P': [P_linsvc, P_rbfsvc, P_dt, P_rf, P_knn, P_lgr, P_pca_lgr, P_ols]})\nbest_model =relevant_metrics.sort_values(by='Accuracy, A', ascending=False)\nbest_model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='pred'>5. Predicting</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read the test set\ninput_test_file = \"../input/titanic/test.csv\"\ndf_test = pd.read_csv(input_test_file, header = 0, sep = ',', quotechar='\"')\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Open the example set (with 100% accuracy) for comparison\n\ninput_example_file = \"../input/titanic-leaked/titanic.csv\"\ndf_example = pd.read_csv(input_example_file, header = 0, sep = ',', quotechar='\"')\ndf_example.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Age\nimport numpy as np\n\nbins_Age_Group= [0,4.9999,13.9999,24.9999,54.9999,100]\nlabels_Age_Group = ['Infant','Kid','Young','Adult','Elderly']\ndf_test['Age_Group'] = pd.cut(df_test['Age'], bins=bins_Age_Group, labels=labels_Age_Group, right=False)\n#df['Age_Group_ord'] = pd.Categorical(df.Age_Group).codes\n\nbins_Age_Infant = [5,13.9999]\nlabels_Age_Infant = ['Infant']\ndf_test['Age_Infant'] = pd.cut(df_test['Age'], bins =bins_Age_Infant, labels =labels_Age_Infant, right=False)\ndf_test['Age_Infant'] = df_test['Age_Infant'].notna().astype('int')\n\nbins_Age_Kid = [5,13.9999]\nlabels_Age_Kid = ['Kid']\ndf_test['Age_Kid'] = pd.cut(df_test['Age'], bins =bins_Age_Kid, labels =labels_Age_Kid, right=False)\ndf_test['Age_Kid'] = df_test['Age_Kid'].notna().astype('int')\n\nbins_Age_Young = [14,24.9999]\nlabels_Age_Young = ['Young']\ndf_test['Age_Young'] = pd.cut(df_test['Age'], bins =bins_Age_Young, labels =labels_Age_Young, right=False)\ndf_test['Age_Young'] = df_test['Age_Young'].notna().astype('int')\n\nbins_Age_Adult = [25,54.9999]\nlabels_Age_Adult = ['Adult']\ndf_test['Age_Adult'] = pd.cut(df_test['Age'], bins =bins_Age_Adult, labels =labels_Age_Adult, right=False)\ndf_test['Age_Adult'] = df_test['Age_Adult'].notna().astype('int')\n\nbins_Age_Elderly = [55,100]\nlabels_Age_Elderly = ['Elderly']\ndf_test['Age_Elderly'] = pd.cut(df_test['Age'], bins =bins_Age_Elderly, labels =labels_Age_Elderly, right=False)\ndf_test['Age_Elderly'] = df_test['Age_Elderly'].notna().astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#SibSp and Parch\n\nbins_SibORParch = [1,20]\nlabels_SibORParch = ['notalone']\ndf_test['SibORParch'] = pd.cut(df_test['SibSp']+df_test['Parch'], bins =bins_SibORParch, labels =labels_SibORParch, right=False)\ndf_test['SibORParch'] = df_test['SibORParch'].notna().astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sex\ndf_test['Sex_ord'] = pd.Categorical(df_test.Sex).codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Embarked\n\n#C=0, Q=1, S=2\ndf_test['Embarked_ord'] = pd.Categorical(df_test.Embarked).codes\n\n#Cherbourg\nbins_Embk_Cherbourg = [0,0.9999]\nlabels_Embk_Cherbourg = ['Embk_Cherbourg']\ndf_test['Embk_Cherbourg'] = pd.cut(df_test['Embarked_ord'], bins =bins_Embk_Cherbourg, labels =labels_Embk_Cherbourg, right=False)\ndf_test['Embk_Cherbourg'] = df_test['Embk_Cherbourg'].notna().astype('int')\n\n#Queenstown\nbins_Embk_Queenstown = [1,1.9999]\nlabels_Embk_Queenstown = ['Embk_Queenstown']\ndf_test['Embk_Queenstown'] = pd.cut(df_test['Embarked_ord'], bins =bins_Embk_Queenstown, labels =labels_Embk_Queenstown, right=False)\ndf_test['Embk_Queenstown'] = df_test['Embk_Queenstown'].notna().astype('int')\n\n#Southampton\nbins_Embk_Southampton = [2,2.9999]\nlabels_Embk_Southampton = ['Embk_Southampton']\ndf_test['Embk_Southampton'] = pd.cut(df_test['Embarked_ord'], bins =bins_Embk_Southampton, labels =labels_Embk_Southampton, right=False)\ndf_test['Embk_Southampton'] = df_test['Embk_Southampton'].notna().astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalise Fare\ndf_test['Fare'] = df_test['Fare'].fillna(0.0)\ndf_test['Fare_norm'] = df_test['Fare']/np.max(df_test['Fare'])\n#df_test['Fare_norm'] = df_test['Fare_norm'].fillna(0.0)\n\n#Normalise Age\ndf_test['Age_norm'] = df_test['Age']/np.max(df_test['Age'])\n\n#Normalise Pclass\ndf_test['Pclass_norm'] = df_test['Pclass']/np.max(df_test['Pclass'])\n\ndf_test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='predLlinSVC'>5.1. Predicting with LinSVC</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_linsvc_test = df_test[['Sex_ord', 'SibORParch', 'Fare', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\n\nsc_linsvc = StandardScaler()\nsc_linsvc_test = sc_linsvc.fit(X_linsvc_test)\nX_linsvc_test_scaled = sc_linsvc.transform(X_linsvc_test)\n\ny_linsvc_test = model_linsvc.predict(X_linsvc_test_scaled)\n\ndf_test['Survived_linsvc_test']=y_linsvc_test\n\n#print(model_linsvc.score(X_linsvc_test_scaled, y_linsvc_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_linsvc, X_linsvc_test_scaled, y_linsvc_test, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix: Compare the example as the truth vs. my predicted values with the KNN model\n\ny_example_true = df_example['Survived']\ny_example_vs_linsvc_pred = y_linsvc_test\n\nexample_vs_linsvc_test_cm = confusion_matrix(y_example_true, y_example_vs_linsvc_pred, normalize = \"all\")\nexample_vs_linsvc_test_score = accuracy_score(y_example_true, y_example_vs_linsvc_pred, normalize = \"all\")\n\nprint(example_vs_linsvc_test_cm)\nprint('LinSVC test score: ' + str(example_vs_linsvc_test_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='predRBFSVC'>5.2. Predicting with RBF SVC</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_rbfsvc_test = df_test[['Sex_ord', 'SibORParch', 'Fare', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\n\nsc_rbfsvc = StandardScaler()\nsc_rbfsvc_test = sc_rbfsvc.fit(X_rbfsvc_test)\nX_rbfsvc_test_scaled = sc_rbfsvc.transform(X_rbfsvc_test)\n\ny_rbfsvc_test = model_rbfsvc.predict(X_rbfsvc_test_scaled)\n\ndf_test['Survived_rbfsvc_test']=y_rbfsvc_test\n\n#print(model_rbfsvc.score(X_rbfsvc_test_scaled, y_rbfsvc_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_rbfsvc, X_rbfsvc_test_scaled, y_rbfsvc_test, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix: Compare the example as the truth vs. my predicted values with the KNN model\n\ny_example_true = df_example['Survived']\ny_example_vs_rbfsvc_pred = y_rbfsvc_test\n\nexample_vs_rbfsvc_test_cm = confusion_matrix(y_example_true, y_example_vs_rbfsvc_pred, normalize = \"all\")\nexample_vs_rbfsvc_test_score = accuracy_score(y_example_true, y_example_vs_rbfsvc_pred, normalize = \"all\")\n\nprint(example_vs_rbfsvc_test_cm)\nprint('RBF SVC test score: ' + str(example_vs_rbfsvc_test_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='predDT'>5.3. Predicting with DT</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model DecisionTree: Predicting the test set with the fitted DecisionTree model\n\nX_dt_test = pd.get_dummies(df_test[features_dt])\n\ny_dt_test = model_dt.predict(X_dt_test)\n\n#Add new column with the values predicted with the RandomForestClassifier model\ndf_test['Survived_dt_test']=y_dt_test\n\n#print(model_dt.score(X_dt_test, y_dt_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_dt, X_dt_test, y_dt_test, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix: Compare the example as the truth vs. my predicted values with the DecisionTreeClassifier model\n#from sklearn.metrics import confusion_matrix\n\ny_example_true = df_example['Survived']\ny_example_vs_dt_pred = y_dt_test\n\nexample_vs_dt_test_cm = confusion_matrix(y_example_true, y_example_vs_dt_pred, normalize = \"all\")\nexample_vs_dt_test_score = accuracy_score(y_example_true, y_example_vs_dt_pred, normalize = \"all\")\n\nprint(example_vs_dt_test_cm)\nprint('DT test score: ' + str(example_vs_dt_test_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='predRF'>5.4. Predicting with RF</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model RandomForestClassifier: Predicting the test set with the fitted RandomForestClassifier model\n\nX_rf_test = pd.get_dummies(df_test[features_rf])\n\ny_rf_test = model_rf.predict(X_rf_test)\n\n#Add new column with the values predicted with the RandomForestClassifier model\ndf_test['Survived_rf_test']=y_rf_test\n\n#print(model_rf.score(X_rf_test, y_rf_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_rf, X_rf_test, y_rf_test, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix: Compare the example as the truth vs. my predicted values with the RandomForestClassifier model\n#from sklearn.metrics import confusion_matrix\n\ny_example_true = df_example['Survived']\ny_example_vs_rf_pred = y_rf_test\n\nexample_vs_rf_test_cm = confusion_matrix(y_example_true, y_example_vs_rf_pred, normalize = \"all\")\nexample_vs_rf_test_score = accuracy_score(y_example_true, y_example_vs_rf_pred, normalize = \"all\")\n\nprint(example_vs_rf_test_cm)\nprint('RF test score: ' + str(example_vs_rf_test_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='predKNN'>5.5. Predicting with KNN</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_knn_test = df_test[['Sex_ord', 'SibORParch', 'Fare', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\n\nsc = StandardScaler()\nsc.fit(X_knn_test)\nX_knn_test_scaled = sc.transform(X_knn_test)\n\ny_knn_test = model_knn.predict(X_knn_test_scaled)\n\ndf_test['Survived_knn_test']=y_knn_test\n\n#print(model_knn.score(X_knn_test_scaled, y_knn_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_knn, X_knn_test_scaled, y_knn_test, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix: Compare the example as the truth vs. my predicted values with the KNN model\n\ny_example_true = df_example['Survived']\ny_example_vs_knn_pred = y_knn_test\n\nexample_vs_knn_test_cm = confusion_matrix(y_example_true, y_example_vs_knn_pred, normalize = \"all\")\nexample_vs_knn_test_score = accuracy_score(y_example_true, y_example_vs_knn_pred, normalize = \"all\")\n\nprint(example_vs_knn_test_cm)\nprint('KNN test score: ' + str(example_vs_knn_test_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='predLgR'>5.6. Predicting with LgR</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_lgr_test = df_test[['Fare', 'SibORParch', 'Sex_ord', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\n\ny_lgr_test = model_lgr.predict(X_lgr_test)\ndf_test['Survived_lgr_test']=y_lgr_test\n\n#print(model_lgr.score(X_lgr_test_transformed, y_lgr_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_lgr, X_lgr_test, y_lgr_test, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix: Compare the example as the truth vs. my predicted values with the Logistic Regression model\n#from sklearn.metrics import confusion_matrix\n\ny_example_true = df_example['Survived']\ny_example_vs_lgr_pred = y_lgr_test\n\nexample_vs_lgr_test_cm = confusion_matrix(y_example_true, y_example_vs_lgr_pred, normalize = \"all\")\nexample_vs_lgr_test_score = accuracy_score(y_example_true, y_example_vs_lgr_pred, normalize = \"all\")\n\nprint(example_vs_lgr_test_cm)\nprint('LgR test score: ' + str(example_vs_lgr_test_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='predPCA-LgR'>5.7. Predicting with PCA - LgR</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_pca_lgr_test = df_test[['Fare', 'SibORParch', 'Sex_ord', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\n\nX_pca_lgr_test_transformed = pca.transform(X_pca_lgr_test)\n\ny_pca_lgr_test = model_pca_lgr.predict(X_pca_lgr_test_transformed)\ndf_test['Survived_pca_lgr_test']=y_pca_lgr_test\n\n#print(model_pca_lgr.score(X_pca_lgr_test_transformed, y_pca_lgr_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_pca_lgr, X_pca_lgr_test_transformed, y_pca_lgr_test, normalize = \"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confusion Matrix: Compare the example as the truth vs. my predicted values with the PCA Logistic Regression model\n#from sklearn.metrics import confusion_matrix\n\ny_example_true = df_example['Survived']\ny_example_vs_pca_lgr_pred = y_pca_lgr_test\n\nexample_vs_pca_lgr_test_cm = confusion_matrix(y_example_true, y_example_vs_pca_lgr_pred, normalize = \"all\")\nexample_vs_pca_lgr_test_score = accuracy_score(y_example_true, y_example_vs_pca_lgr_pred, normalize = \"all\")\n\nprint(example_vs_pca_lgr_test_cm)\nprint('PCA LgR test score: ' + str(example_vs_pca_lgr_test_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='predOLS'>5.8. Predicting with OLS</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model OLS: Predicting the test set with the fitted OLS model\n\n#import statsmodels.api as sm\n\nX_ols_test = df_test[['Fare', 'SibORParch', 'Sex_ord', 'Pclass', 'Embk_Cherbourg', 'Embk_Queenstown', 'Embk_Southampton', 'Age_Infant', 'Age_Kid', 'Age_Young', 'Age_Adult', 'Age_Elderly' ]]\nX1_ols_test = sm.add_constant(X_ols_test)\n\ny_ols_test =  model_ols.predict(X1_ols_test)\ny_ols_test =  round(y_ols_test)\n\n#Add new column with the values predicted with the OLS model\ndf_test['Survived_ols_test']=y_ols_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_example_true = df_example['Survived']\ny_example_vs_ols_pred = y_ols_test\n\nexample_vs_ols_test_cm = confusion_matrix(y_example_true, y_example_vs_ols_pred, normalize = \"all\")\nexample_vs_ols_test_score = accuracy_score(y_example_true, y_example_vs_ols_pred, normalize = \"all\")\n\nprint(example_vs_ols_test_cm)\nprint('OLS test score: ' + str(example_vs_ols_test_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='predARP'>5.9. Accuracy, Recall, Precision: example settruth vs. test set predictions</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Accuracy\n#from sklearn.metrics import accuracy_score\n\nA_example_vs_linsvc = accuracy_score(y_example_true, y_example_vs_linsvc_pred)\nA_example_vs_rbfsvc = accuracy_score(y_example_true, y_example_vs_rbfsvc_pred)\nA_example_vs_dt = accuracy_score(y_example_true, y_example_vs_dt_pred)\nA_example_vs_rf = accuracy_score(y_example_true, y_example_vs_rf_pred)\nA_example_vs_knn = accuracy_score(y_example_true, y_example_vs_knn_pred)\nA_example_vs_lgr = accuracy_score(y_example_true, y_example_vs_lgr_pred)\nA_example_vs_pca_lgr = accuracy_score(y_example_true, y_example_vs_pca_lgr_pred)\nA_example_vs_ols = accuracy_score(y_example_true, y_example_vs_ols_pred)\n\nprint(\"Accuracy example vs. LinSVC = \" + str(A_example_vs_linsvc))\nprint(\"Accuracy example vs. rbfSVC = \" + str(A_example_vs_rbfsvc))\nprint(\"Accuracy example vs. DT = \" + str(A_example_vs_dt))\nprint(\"Accuracy example vs. RF = \" + str(A_example_vs_rf))\nprint(\"Accuracy example vs. KNN = \" + str(A_example_vs_knn))\nprint(\"Accuracy example vs. LgR = \" + str(A_example_vs_lgr))\nprint(\"Accuracy example vs. PCA LgR = \" + str(A_example_vs_pca_lgr))\nprint(\"Accuracy example vs. OLS = \" + str(A_example_vs_ols))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Recall\n#from sklearn.metrics import recall_score\n\nR_example_vs_linsvc = recall_score(y_example_true, y_example_vs_linsvc_pred)\nR_example_vs_rbfsvc = recall_score(y_example_true, y_example_vs_rbfsvc_pred)\nR_example_vs_dt = recall_score(y_example_true, y_example_vs_dt_pred)\nR_example_vs_rf = recall_score(y_example_true, y_example_vs_rf_pred)\nR_example_vs_knn = recall_score(y_example_true, y_example_vs_knn_pred)\nR_example_vs_lgr = recall_score(y_example_true, y_example_vs_lgr_pred)\nR_example_vs_pca_lgr = recall_score(y_example_true, y_example_vs_pca_lgr_pred)\nR_example_vs_ols = recall_score(y_example_true, y_example_vs_ols_pred)\n\nprint(\"Recall example vs. LinSVC = \" + str(R_example_vs_linsvc))\nprint(\"Recall example vs. rbfSVC = \" + str(R_example_vs_rbfsvc))\nprint(\"Recall example vs. DT = \" + str(R_example_vs_dt))\nprint(\"Recall example vs. RF = \" + str(R_example_vs_rf))\nprint(\"Recall example vs. KNN = \" + str(R_example_vs_knn))\nprint(\"Recall example vs. LgR = \" + str(R_example_vs_lgr))\nprint(\"Recall example vs. PCA LgR = \" + str(R_example_vs_pca_lgr))\nprint(\"Recall example vs. OLS = \" + str(R_example_vs_ols))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Precision\n#from sklearn.metrics import precision_score\n\nP_example_vs_linsvc = precision_score(y_example_true, y_example_vs_linsvc_pred)\nP_example_vs_rbfsvc = precision_score(y_example_true, y_example_vs_rbfsvc_pred)\nP_example_vs_dt = precision_score(y_example_true, y_example_vs_dt_pred)\nP_example_vs_rf = precision_score(y_example_true, y_example_vs_rf_pred)\nP_example_vs_knn = precision_score(y_example_true, y_example_vs_knn_pred)\nP_example_vs_lgr = precision_score(y_example_true, y_example_vs_lgr_pred)\nP_example_vs_pca_lgr = precision_score(y_example_true, y_example_vs_pca_lgr_pred)\nP_example_vs_ols = precision_score(y_example_true, y_example_vs_ols_pred)\n\nprint(\"Precision example vs. LinSVC = \" + str(P_example_vs_linsvc))\nprint(\"Precision example vs. rbfSVC = \" + str(P_example_vs_rbfsvc))\nprint(\"Precision example vs. DT = \" + str(P_example_vs_dt))\nprint(\"Precision example vs. RF = \" + str(P_example_vs_rf))\nprint(\"Precision example vs. KNN = \" + str(P_example_vs_knn))\nprint(\"Precision example vs. LgR = \" + str(P_example_vs_lgr))\nprint(\"Precision example vs. PCA LgR = \" + str(P_example_vs_pca_lgr))\nprint(\"Precision example vs. OLS = \" + str(P_example_vs_ols))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='predsummary'>5.10. Prediction summary</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"relevant_metrics_pred = pd.DataFrame({\n    'Model': ['LinSVC', 'RBFSVC', 'Decision Tree', 'Random Forest', 'K-Nearest-Neighbours', 'Logistic Regression', 'PCA Logistic Regression', 'OLS'],\n    'Accuracy, A': [A_example_vs_linsvc, A_example_vs_rbfsvc, A_example_vs_dt, A_example_vs_rf, A_example_vs_knn, A_example_vs_lgr, A_example_vs_pca_lgr, A_example_vs_ols],\n    'Recall, R': [R_example_vs_linsvc, R_example_vs_rbfsvc, R_example_vs_dt, R_example_vs_rf, R_example_vs_knn, R_example_vs_lgr, R_example_vs_pca_lgr, R_example_vs_ols],\n    'Precision, P': [P_example_vs_linsvc, P_example_vs_rbfsvc, P_example_vs_dt, P_example_vs_rf, P_example_vs_knn, P_example_vs_lgr, P_example_vs_pca_lgr, P_example_vs_ols]})\nbest_model_pred =relevant_metrics_pred.sort_values(by='Accuracy, A', ascending=False)\nbest_model_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='submit'>6. Submitting the data</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {}\nd['PassengerId']=df_test['PassengerId']\nd['Survived']=df_test['Survived_rbfsvc_test']\n\ndf_rbfsvc_submission = pd.DataFrame(d)\n\ndf_rbfsvc_submission.to_csv (r'titanic_data_submission_RBFSVC_new.csv', index = False, header=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}