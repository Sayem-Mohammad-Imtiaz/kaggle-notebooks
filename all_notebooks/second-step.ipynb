{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"from matplotlib import pyplot as plt\nfrom nltk.tokenize import sent_tokenize\nimport pandas as pd\nfrom nltk.corpus import stopwords \nstop_words = stopwords.words('english')\nimport numpy as np\nfrom gensim.corpora import Dictionary\nfrom gensim.models import TfidfModel\nfrom gensim.models import WordEmbeddingSimilarityIndex\nfrom gensim.similarities import SparseTermSimilarityMatrix\nfrom gensim.similarities import SoftCosineSimilarity\nfrom sklearn.metrics.pairwise import cosine_similarity","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#df=pd.read_csv('results1.csv')\ndf=pd.read_csv('incubationperiod.csv')\n\nsumm=df.head(100)\nsumm.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print( postprocessing(summ.summary[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def remove_stopwords(sen):     \n    sen_new = \" \".join([i for i in sen if i not in stop_words])          \n    return sen_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"i=1\nsentences = [] \nfor s in summ['summary']: \n     if i<5:              \n        for x in(sent_tokenize(s)) :\n            sentences.append(sent_tokenize(x))\n        i=i+1\nprint(sentences)    \ncorpus = [y for x in sentences for y in x ]\n#print(corpus)\n\n\nclean_sentences = pd.Series(corpus).str.replace(\"[^a-zA-Z]\", \" \") \n        # make alphabets lowercase \n\nclean_sentences = [s.lower() for s in clean_sentences]\n#clean_sentences = [remove_stopwords(r.split()) for r in corpus]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\n# Extract word vectors \nword_embeddings = {} \nf = open(r\"C:\\meriem\\MÃ©moire\\glove6b\\glove.6B.100d.txt\", encoding='utf-8') \nfor line in f: \n    values = line.split() \n    word = values[0] \n    coefs = np.asarray(values[1:], dtype='float32')    \n    word_embeddings[word] = coefs \nf.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sentence_vectors = [] \nfor i in clean_sentences: \n    if len(i) != 0: \n        v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001) \n    else: \n        v = np.zeros((100,)) \n    sentence_vectors.append(v)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sim_mat = np.zeros([len(corpus), len(corpus)])\nfor i in range(len(corpus)): \n      for j in range(len(corpus)): \n        if i != j: \n              sim_mat[i][j] = cosine_similarity (sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print( sim_mat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import networkx as nx \nimport matplotlib.pyplot as plt\n\nnx_graph = nx.from_numpy_array(sim_mat) \nnx.draw(nx_graph,with_labels=True)\nscores = nx.pagerank(nx_graph)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\nranked_sentences = sorted(((scores[i],s) for i,s in \n                           enumerate(corpus)), reverse=True)\n# Extract top 10 sentences as the summary \nfor i in range(12): \n      print(ranked_sentences[i][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import re\ndef postprocessing(text):\n    # capitalize the text\n    text = text.capitalize()\n    # '2 , 3' -> '2,3'\n    text = re.sub(r'(\\d) \\, (\\d)', \"\\g<1>,\\g<2>\", text)\n    # full stop\n    text = re.sub(r' (\\.|\\!|\\?) (\\w)', lambda pat: pat.groups()[0]+\" \"+pat.groups()[1].upper(), text)\n    # full stop at the end\n    text = re.sub(r' (\\.|\\!|\\?)$', \"\\g<1>\", text)\n    # comma\n    text = re.sub(r' (\\,|\\;|\\:) (\\w)', \"\\g<1> \\g<2>\", text)\n    # - | \\ / @ and _ (e.g. 2 - 3  -> 2-3)\n    text = re.sub(r'(\\w) (\\-|\\||\\/|\\\\|\\@\\_) (\\w)', \"\\g<1>\\g<2>\\g<3>\", text)\n    # parenthesis\n    text = re.sub(r'(\\(|\\[|\\{) ([^\\(\\)]+) (\\)|\\]|\\})', \"\\g<1>\\g<2>\\g<3>\", text)\n    # \"\" e.g. \" word \"  -> \"word\"\n    text = re.sub(r'(\\\") ([^\\\"]+) (\\\")', \"\\g<1>\\g<2>\\g<3>\", text)\n    # apostrophe  e.g. l ' a  -> l'a\n    text = re.sub(r'(\\w) (\\') (\\w)', \"\\g<1>\\g<2>\\g<3>\", text)\n    # '3 %' ->  '3%'\n    text = re.sub(r'(\\d) \\%', \"\\g<1>%\", text)\n    # '# word'  -> '#word'\n    text = re.sub(r'\\# (\\w)', \"#\\g<1>\", text)\n    # https and doi\n    text = re.sub(r'(https|doi) : ', \"\\g<1>:\", text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\n#ranked_sentences = sorted(((scores[i],s) for i,s in  enumerate(corpus)), reverse=True)\n# Extract top 10 sentences as the summary \nfor i in range(12): \n      print(postprocessing(ranked_sentences[i][1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}