{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Jobs analytics"},{"metadata":{},"cell_type":"markdown","source":"EasyApply Bot is a bot that helps you to apply to EasyApply offers on LinkedIn. Here is the project in case you are interested: https://github.com/nicolomantini/LinkedIn-Easy-Apply-Bot\n\nOnce you run this program every attempt to apply to a job gets recorded in a CSV file. I've been using the bot for a time and now I want to make some analytics in order to learn something new.\n\nI set up the bot to look for jobs of data scientist, data engineer, data analyst, business intelligence and python."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"my_filepath = \"../input/jobs-applied-in-linkedin-with-easyapplybot/jobs.csv\"\n\nmy_data = pd.read_csv(my_filepath,encoding='latin1')\n\nmy_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since there are some offers that will be constantly visited I will drop all the offers already seen."},{"metadata":{"trusted":true},"cell_type":"code","source":"non_duplicated = my_data.drop_duplicates(['jobID'])\n\nprint(\"Jobs found: \", len(non_duplicated['result']))\nprint(\"Successfully sent applications: \", non_duplicated['result'].value_counts()[1])\nprint(\"Failed applications: \", non_duplicated['result'].value_counts()[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we create two new columns from timestamp column."},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nnon_duplicated['date'] = non_duplicated.apply(lambda x: datetime.datetime.strptime(x['timestamp'], '%Y-%m-%d %H:%M:%S.%f').date(), axis = 1)\nnon_duplicated['time'] = non_duplicated.apply(lambda x: datetime.datetime.strptime(x['timestamp'], '%Y-%m-%d %H:%M:%S.%f').time(), axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can drop timestamp column since it is already useless."},{"metadata":{"trusted":true},"cell_type":"code","source":"non_duplicated = non_duplicated.drop('timestamp', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can create some other columns related to date. They may be useful in the future."},{"metadata":{"trusted":true},"cell_type":"code","source":"non_duplicated['day'] = non_duplicated.apply(lambda x: x['date'].day, axis = 1)\nnon_duplicated['weekday'] = non_duplicated.apply(lambda x: x['date'].weekday(), axis = 1)\nnon_duplicated['month'] = non_duplicated.apply(lambda x: x['date'].month, axis = 1)\nnon_duplicated['week'] = non_duplicated.apply(lambda x: x['date'].isocalendar()[1], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I decided to transform 'attempted' and 'result' fields to be able to plot some graphs."},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_result(row):\n    if row.result == True:\n        row.result = 1\n    else:\n        row.result = 0\n    return row\n\ndef convert_att(row):\n    if row.attempted == True:\n        row.attempted = 1\n    else:\n        row.attempted = 0\n    return row\n\nnon_duplicated = non_duplicated.apply(convert_result, axis = 1)\nnon_duplicated = non_duplicated.apply(convert_att, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_duplicated.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now I group the data per day, counting every attempt and every successful submitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"group = non_duplicated[['date','attempted', 'result']].groupby(['date']).sum()\n\ngroup.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(37,10))\nplt.title(\"Attempts per day\")\n\nsns.barplot(x=group.index, y=group['attempted'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(37,10))\nplt.title(\"Submitted applications per day\")\n\nsns.barplot(x=group.index, y=group['result'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group2 = non_duplicated[['weekday','attempted', 'result']].groupby(['weekday']).sum()\n\ngroup2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(17,6))\nplt.title(\"Attempts per weekday\")\n\nsns.barplot(x=group2.index, y=group2['attempted'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(17,6))\nplt.title(\"Submitted applications per weekday\")\n\nsns.barplot(x=group2.index, y=group2['result'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"failed = group2['attempted'] - group2['result']\n\nplt.figure(figsize=(17,6))\n\nplt.title(\"Failed attemps per weekday\")\n\nsns.barplot(x=failed.index, y=failed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that there are more available jobs in the middle of the week (Wednesday, Thursday, and Friday)."},{"metadata":{},"cell_type":"markdown","source":"I create another column with the dates when they called me (if so, 'nan' otherwise).\n\nI can take the jobID from the url, so I look for the id of the row in order to change the date_call from 'nan' to the corresponding date of the call."},{"metadata":{"trusted":true},"cell_type":"code","source":"#2019339369\nnon_duplicated['date_call'] = np.nan\n\nprint(non_duplicated.query('jobID == 2019339369')['date_call']) # id is equal to 92\nnon_duplicated.loc[92,'date_call'] = datetime.date(2020, 9, 14)\nprint(non_duplicated.query('jobID == 2164722520')['date_call']) # id is equal to 950\nnon_duplicated.loc[950,'date_call'] = datetime.date(2020, 10, 8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can see how many job applications have a response."},{"metadata":{"trusted":true},"cell_type":"code","source":"call = non_duplicated['date_call'].notnull().sum()\nd_call = non_duplicated['result'].value_counts()[1] - call\n\np_call = call*100/d_call\np_dcall = 100 - p_call\n\n# Creating dataset \nlabels = \"Did call\", \"Didn't call\"\n  \ndata = [p_call, p_dcall]\n  \n# Creating plot \nfig = plt.figure(figsize =(12, 8)) \nplt.pie(data, labels = labels, autopct='%1.1f%%', startangle=90) \n  \n# show plot \nplt.show() \n\npd.DataFrame({'Total applications':[non_duplicated['result'].value_counts()[1]], 'Number of calls':[call]}).head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see how it looks the applications per week."},{"metadata":{"trusted":true},"cell_type":"code","source":"per_week = non_duplicated[['attempted', 'result', 'week']].groupby(['week']).sum()\nprint(per_week)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Week 37 was the first one and the bot wasn't run every day, and week 42 was run just one day, so we'll ignore both of them."},{"metadata":{"trusted":true},"cell_type":"code","source":"per_week.loc[(per_week.index > 37) & (per_week.index < 42)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have to take into account that within week 38 I added new settings to look for more types of jobs. So the increment of attempts is normal, yet the results are more or less the same.\n\nNonetheless, on week 41 we notice a huge increment of attempts and submitted applications. It seems that during that week more job positions were offered on LinkedIn. I can confirm that since I received way more offers during this week from other websites."},{"metadata":{},"cell_type":"markdown","source":"# Conclusions"},{"metadata":{},"cell_type":"markdown","source":"Finally, I achieved my goal, but unfortunately, it wasn't thanks to the bot.\n\nMy conclusions about the tool are the following:\n\n1. There are a lot of job offers without an easy apply button (the obvious conclusion).\n\n2. There are job offers with specific forms. If they weren't previously fulfilled the application will not be submitted.\n\n3. Most of the jobs ask for experience. The bot doesn't care about that. A possible solution could be to add a new setting to include the seniority level, but there are a lot of inconsistent offers (they ask for a certain level of experience but the filter reflects a different level of seniority). This would mean a loss of potential jobs, so it's better if the bot sends as most applications as possible, even if the vast majority of the companies don't respond. \n\n4. The program fails whenever it reads a strange character. \n\n5. Just 1% of the applications were responded to, so it seems this bot isn't very useful (at least for entry-level engineers in Madrid).\n\n6. October is a good month to search for a job. \n\nAnd that's all folks. I won't be updating this anymore since I already have a job. I hope you've enjoyed this little project. I also hope you're luckier than me if you plan to use this bot. \n\nYou can see this whole project in GitHub, with some extra visualizations using Qlik: [https://github.com/manuelalfredocolladocenteno/Jobs-analytics](http://)\n\nIn case you're curious I'll tell you how many applications I submitted (approximately):\n\n* LinkedIn (EasyApply button: bot + manual): 288\n\n* Infojobs: 74\n\n* Other websites: 17\n \n* Company websites: Sadly, I didn't keep track of these, but they were at least 10. Anyway, I'm not counting them. \n\nSo I sent a minimum of 379 applications and I was contacted by 15 companies (I'm just counting the contacts via phone call or video call).\n\nThanks for reading. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}