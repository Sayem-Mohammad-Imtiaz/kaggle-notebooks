{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting 2021 COVID cases using Time-Series for Telangana"},{"metadata":{},"cell_type":"markdown","source":"### Context\n\nCoronaviruses are a large family of viruses which may cause illness in animals or humans. In humans, several coronaviruses are known to cause respiratory infections ranging from the common cold to more severe diseases such as Middle East Respiratory Syndrome (MERS) and Severe Acute Respiratory Syndrome (SARS). The most recently discovered coronavirus causes coronavirus disease COVID-19 - World Health Organization\nThe number of new cases are increasing day by day around the world. This dataset has information from the states and union territories of India at daily level.\n\n\nI use Time series analysis to understand the data better and to answer many questions which may arise."},{"metadata":{},"cell_type":"markdown","source":"So what is Time Series?\n\n1. A time series is a series of data points indexed (or listed or graphed) in time order. Most commonly, a time series is a sequence taken at successive equally spaced points in time. Thus it is a sequence of discrete-time data.\n2. An observed time series can be decomposed into three components:\n   * the trend (long term direction)\n   * the seasonal (systematic, calendar related movements) \n   * the irregular (unsystematic, short term fluctuations).\n3. Time series analysis is a statistical technique that deals with time series data, or trend analysis. Time series data means that data is in a series of particular time periods or intervals."},{"metadata":{},"cell_type":"markdown","source":"How to do a time series analysis?\n\n* Step 1: Visualize the Time Series.It is essential to analyze the trends prior to building any kind of time series model.\n* Step 2: Stationarize/Decompose the Series.\n* Step 3: Find Optimal Parameters.\n* Step 4: Build ARIMA Model.\n* Step 5: Make Predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd                      \nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/covid19-in-india/covid_19_india.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.shape)\ndf.head(5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.iloc[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data wrangling/preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['Cured'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['State/UnionTerritory'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df['State/UnionTerritory'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### you see that we have so many dublicates that ending with '***' , we can drop or replace them if we want\n### I'm droping "},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df['State/UnionTerritory'].iteritems():\n    if i[1][-3:]==\"***\":\n        df.drop(i[0],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['State/UnionTerritory'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df['State/UnionTerritory'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### In above we can also notice \"Telenagana\" and \"Telangana\" which both are same state ,but just a spelling mistake.\n### so we can replace all the name with \"Telengana\" to \"Telangana\" so our visualization will be more accurate."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.replace(to_replace =\"Telengana\", value =\"Telangana\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['State/UnionTerritory'].unique()\n\n#now u can see \"Telangana\" is replaced with \"Telangana\" in the row, that why u cant see \"Telangana\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df['State/UnionTerritory'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Cured'].plot(alpha=0.8)\ndf['Deaths'].plot(alpha=0.3)\ndf['Confirmed'].plot(alpha=0.5)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('State/UnionTerritory')['Confirmed'].plot()\nplt.show()\ndf.groupby('State/UnionTerritory')['Deaths'].plot()\nplt.show()\ndf.groupby('State/UnionTerritory')['Cured'].plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##adding data and time and creating a new column \"Datetime\" for our convinience for better visualization\ndf['Datetime'] = df['Date']+' '+df['Time']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = df.groupby('State/UnionTerritory')\ncurrent = l.last()\nprint(current)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig ,ax = plt.subplots(figsize= (12,8))\nplt.title('Top 10 Contaminated States')\ncurrent1 = current.sort_values(\"Confirmed\",ascending=False)\np = sns.barplot(ax=ax, x=current1.index, y=current1['Confirmed'])\np.set_xticklabels(labels=current1.index, rotation=90)\np.set_yticklabels(labels=(p.get_yticks()*1).astype(int))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig ,ax = plt.subplots(figsize= (15,15))\nplt.title('Contaminated States in side bar')\n\nP = sns.barplot(ax=ax,y= current1.index, x=current1['Confirmed'])\nP.set_yticklabels(labels=current1.index)\nP.set_xticklabels(labels=(P.get_xticks()*1).astype(int))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### now we will only see top 10 contaminated "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig ,ax = plt.subplots(figsize= (12,8))\nplt.title('Top 10 Contaminated States')\n\ncurrent2 = current.sort_values(\"Confirmed\", ascending=False)[:10]\n\np = sns.barplot(ax=ax, x=current2.index, y=current2['Confirmed'])\np.set_xticklabels(labels=current2.index, rotation=90)\np.set_yticklabels(labels=(p.get_yticks()*1).astype(int))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### now we will only see top 10 states with cured ppl"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,8))\nplt.title(\"Top 10 states with cured ppl\")\ncurrent3 = current.sort_values(\"Cured\", ascending=False)[:10]\n\np1 = sns.barplot(ax=ax, x=current3.index, y=current3[\"Cured\"])\np1.set_xticklabels(labels=current3.index, rotation=90)\np1.set_yticklabels(labels=(p1.get_yticks()*1).astype(int))\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### now we will only see top 10 states with dead ppl"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,8))\nplt.title(\"Top 10 states with dead ppl\")\ncurrent4 = current.sort_values(\"Deaths\", ascending=False)[:10]\n\np1 = sns.barplot(ax=ax, x=current4.index, y=current4[\"Deaths\"])\np1.set_xticklabels(labels=current4.index, rotation=90)\np1.set_yticklabels(labels=(p1.get_yticks()*1).astype(int))\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* so from above we can conclude that Maharashtra is 1st in confirmed cases , cured and deaths.\n* we can also see that \"Andhra Pradesh\" is 3nd in confirmed cases but it is at 2nd place in cured and 7th     place in deaths which is actuallyimpressive.\n* we can also see that orisa is doing better rajastan with less deaths."},{"metadata":{},"cell_type":"markdown","source":"## Time Series Analysis For 'Telangana' State"},{"metadata":{"trusted":true},"cell_type":"code","source":"TS = df.loc[df['State/UnionTerritory'] == 'Telangana' ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TS.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TS.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TS.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TS['Date'] = pd.to_datetime(TS['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TS.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TS.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### dropping all the unneccesry columns except confirmed and datetime"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['Sno', 'Time', 'State/UnionTerritory',\n       'ConfirmedIndianNational', 'ConfirmedForeignNational', 'Cured',\n       'Deaths', 'Date']\nTS.drop(cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TS= TS.sort_values('Datetime')\nTS.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TS.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n* converting datatime column type(if it is a 'string type' it will convert to 'datetime' type) and \n* setting date as our index"},{"metadata":{"trusted":true},"cell_type":"code","source":"TS.Datetime = pd.to_datetime(df.Datetime)\nTS.set_index('Datetime', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### converting daily data into weekly data"},{"metadata":{"trusted":true},"cell_type":"code","source":"TS=TS.resample('W').mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TS.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TS.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TS.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TS.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TS.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now lets plot a graph showing the increasing trend and seasonality in the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_ts = TS.plot(figsize=(14,8))\n\nplot_ts.set_yticklabels(labels=(plot_ts.get_yticks()*1).astype(int))\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now lets plot the Decomposition Plot which shows :\n\n* orignal data\n* Trend in the data\n* Seasonality\n* Residual\n\n\n### But why do we decompose time series?\nWhen we decompose a time series into components, we usually combine the trend and cycle into a single trend-cycle component (sometimes called the trend for simplicity). Often this is done to help improve understanding of the time series, but it can also be used to improve forecast accuracy.\n\n\n### Types of decomposition :\n* Multiplicative : The components multiply together to make the time series. If you have an increasing        trend, the amplitude of seasonal activity increases. Everything becomes more exaggerated.\n* Additive : In an additive time series, the components add together to make the time series.\n  (Here we used Additive)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pylab import rcParams\nimport statsmodels.api as sm\n\nrcParams['figure.figsize'] = 18, 16\ndecomposition = sm.tsa.seasonal_decompose(TS['Confirmed'], freq = 20, model='additive')\nfig = decomposition.plot()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Implementing SARIMAx"},{"metadata":{},"cell_type":"markdown","source":"(We used SARIMAX)\n\n-> Seasonal AutoRegressive Integrated Moving Averages:\n\n     One of the methods available in Python to model and predict future points of a time series is known as SARIMAX, which stands for Seasonal AutoRegressive Integrated Moving Averages with eXogenous regressors\n\n-> What does an Arima model do?\n\n    Autoregressive Integrated Moving Average Model. An ARIMA model is a class of statistical models for    analyzing and forecasting time series data. It explicitly caters to a suite of standard structures in time series data, and as such provides a simple yet powerful method for making skillful time series forecasts.\n\n-> How to select perfect ARIMA model?\n\n    Rules for identifying ARIMA models. General seasonal models: ARIMA (0,1,1)x(0,1,1) etc. Identifying the order of differencing and the constant: If the series has positive autocorrelations out to a high number of lags (say, 10 or more), then it probably needs a higher order of differencing."},{"metadata":{},"cell_type":"markdown","source":"* we are using order=(p, d, q)=(1,1,1) becaz usally (1,1,1) or (0,1,1) both will give best results.\n\n* In seasional order we are use extxa value \"4\" becaze we are comparing a season ,where here it is 4 weeks\n"},{"metadata":{},"cell_type":"markdown","source":"## Preparing Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\n\nmodel = sm.tsa.statespace.SARIMAX(TS['Confirmed'], order = (1,1,1), seasonal_order=(1,1,1,4))\nresults = model.fit()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ### testing our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"TS['forecast'] = results.predict(start=44, end =50, dynamic=True)\nax = TS[['Confirmed','forecast']].plot(figsize=(16,8))\n\nax.set_yticklabels(labels=(ax.get_yticks()*1).astype(int))\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## preparing  DATA Future prediction"},{"metadata":{},"cell_type":"markdown","source":"### Here we created a new \"future_data_ts\" which has weekly dates of 2021"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.tseries.offsets import DateOffset\n\n\nfuture_dates = [ TS.index[-1]+DateOffset(weeks=x) for x in range(0,53) ]\nfuture_data_TS = pd.DataFrame(index=future_dates[1:], columns = TS.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"future_data_TS.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now coombine \"future_data_TS\" with \"TS\" to get a new \"future_TS\" data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"future_TS = pd.concat([TS, future_data_TS])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"future_TS.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"future_TS.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"future_TS['forecast'] = results.predict(start=44, end = pd.to_datetime('2021-12-12'), dynamic=True)\n\n\nax = future_TS[['Confirmed','forecast']].plot(figsize=(16,8))\nplt.title(\"Prediction of covid19 cases of 2021 for Telangana State\")\nax.set_yticklabels(labels=(ax.get_yticks()*1).astype(int))\t\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}