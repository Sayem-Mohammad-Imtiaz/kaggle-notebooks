{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"### Problem Statement\n\nIn this project, we're going to build up a supervised learning model based on “mushroom classification dataset” from UCI Machine Learning repository. Then make evaluation on this model to see is it effectively classifies whether the mushrooms are **“edible”** or **“poisonous”**, that means this would be a **binary classification** problem.\n\n---\n\n### Outline\n\nWe break the notebook into separate steps.  Outline and nevigation as below.\n\n* [Step 0](#step0): Set Enviroment \n* [Step 1](#step1): Data Exploration\n* [Step 2](#step2): Data Pre-processing\n* [Step 3](#step3): Feature Importance Analysis\n* [Step 4](#step4): Models\n* [Step 5](#step5): Optimization\n* [Step 6](#step6): Conclusion\n\n\n<a id='step0'></a>\n## Step 0: Set Enviroment\n\n- Python\n- Numpy\n- Pandas\n- Matplotlib\n- Seaborn\n- SciKit Learn\n\n- Math \n- OS\n- Time\n- Collections"},{"metadata":{"trusted":true,"_uuid":"02c9158bc4bce092c178dc4c18eb450493b770a9"},"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\nimport os\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nfrom time import time\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression as LGR\nfrom sklearn.neural_network import MLPClassifier as MLP\nfrom sklearn import tree\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer\nfrom collections import OrderedDict\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"178478f59abfab152ad65aa2afaa41672c93cf8d"},"cell_type":"markdown","source":"---\n<a id='step1'></a>\n## Step 1: Data Exploration\n\n### Import Mushroom Dataset\nList below are the descriptions for each columns in the data. The goal is to demonstrate some different supervised learning models and find a best one to classify mushrooms effectively. Also, we want to realize whats the critical features to indicate mushroom edibility.\n\n\nAttribute Information: (classes: edible=e, poisonous=p)\n\n- **cap-shape**: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\n- **cap-surface**: fibrous=f,grooves=g,scaly=y,smooth=s\n- **cap-color**: brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y\n- **bruises**: bruises=t,no=f\n- **odor**: almond=a,anise=l,creosote=c,fishy=y,foul=f,musty=m,none=n,pungent=p,spicy=s\n- **gill-attachment**: attached=a,descending=d,free=f,notched=n\n- **gill-spacing**: close=c,crowded=w,distant=d\n- **gill-size**: broad=b,narrow=n\n- **gill-color**: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y\n- **stalk-shape**: enlarging=e,tapering=t\n- **stalk-root**: bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r,missing=?\n- **stalk-surface-above-ring**: fibrous=f,scaly=y,silky=k,smooth=s\n- **stalk-surface-below-ring**: fibrous=f,scaly=y,silky=k,smooth=s\n- **stalk-color-above-ring**: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n- **stalk-color-below-ring**: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n- **veil-type**: partial=p,universal=u\n- **veil-color**: brown=n,orange=o,white=w,yellow=y\n- **ring-number**: none=n,one=o,two=t\n- **ring-type**: cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z\n- **spore-print-color**: black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y\n- **population**: abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y\n- **habitat**: grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d"},{"metadata":{"trusted":true,"_uuid":"1313adccaa9a028d009161d1a2df5ec77b94231e"},"cell_type":"code","source":"data = pd.read_csv(\"../input/mushrooms.csv\")\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b65f4b525be9f73ef1b07bbbd1fd2cc9174b3e2f"},"cell_type":"markdown","source":"### Dataset Information\n8124 rows x 23 columns with no any null values.<p>\nAll 22 features and 1 column for specifying class."},{"metadata":{"trusted":true,"_uuid":"1aac77be0cd9ab92d9ddc5b11d671c27a8e82307"},"cell_type":"code","source":"# check null values\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6a1b2277b64a0ec9606d0966632ca96a0cf54e4"},"cell_type":"markdown","source":"### Dataset Check - Balance\nIt shows quite good balance to the class by checking the 'poisonous-to-edible' ratio as below:"},{"metadata":{"trusted":true,"_uuid":"f89d4d7ac414cf2ae5633b9859153919e8a4f726"},"cell_type":"code","source":"### Check input data balance\n# \"poisonous\"-to-\"edible\" ratio\nedible_cnt = data[data[\"class\"] == \"e\"][\"class\"].count()\npoisonus_cnt = data[data[\"class\"] == \"p\"][\"class\"].count() \np_e_ratio = poisonus_cnt/float(edible_cnt)\nprint(\"\\n'poisonous'-to-'edible' ratio: {}\\npoisonus_cnt: {}, edible_cnt: {}\"\n      .format(p_e_ratio.round(2),poisonus_cnt,edible_cnt))\n\n\n# visulalize \"e\" vs \"p\" balance\nsns.set(style=\"ticks\", color_codes=True)\nplt.title(\"Balance Checking for input class in Mushroom Dataset\",fontsize=14)\nsns.countplot(x = data[\"class\"], data = data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25ea9c1370ba0c50942f06b9332f105860128e7b"},"cell_type":"markdown","source":"### Dataset Check - Unique Values\n1. 'veil-type' has only one unique value 'p', which means it doesn't relate to the classification result and can be dropped.\n2. 'stalk-root' has 2480 '?' values. (~30% data), should be careful about this when doing learning."},{"metadata":{"trusted":true,"_uuid":"a725e514db4bab1283508dc852f17fc8a930b8ea"},"cell_type":"code","source":"# unique value for each feature\ncolumns = data.columns.values\nfor column in columns:\n    print(\"{0}: {1}\".format(column, data[column].unique()))\n    \n# check number of \"?\" values for \"stalk-root\", which means N/A for the feature.\nprint(\"\\n There are {} '?' values in the feature 'stalk-root'.\".format(data[data[\"stalk-root\"] == \"?\"][\"stalk-root\"].count()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c7984bdc3e4053aae60ca8fdef01aaf240fb241"},"cell_type":"markdown","source":"---\n<a id='step2'></a>\n## Step 2: Data Pre-processing\n\n### Drop Feature 'veil-type'\nAs just analysis, 'veil-type' is trivial to classification result since it's single type, so let's drop it now:"},{"metadata":{"trusted":true,"_uuid":"2d9befb7e44c77a49152aa90f98fdfac95609ac1"},"cell_type":"code","source":"# drop \"veil-type\" since it has only one unique value, numbers of features reduced to 21 columns now.\ndata = data.drop(\"veil-type\", axis = 1)\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a4b41e2c08436e170931f97bd965bbf8eb9ddcc"},"cell_type":"markdown","source":"### Data Encoding\nSince the expected inputs for the learning algorithms should be numerical, we now transform the string type dataset into numerical type by one-hot encoder."},{"metadata":{"trusted":true,"_uuid":"1cb0964acaa73b26e7472761511b7381e83cb50d"},"cell_type":"code","source":"# Use one-hot encoder to encode the data\ndata_onehot = pd.get_dummies(data)\n\n# Since we are dealing with a binary classification problem, \n#we can simply drop \"class_e\" and only use \"class_p\" for the indicator \ndata_onehot = data_onehot.drop(['class_e'], axis=1)\n\n# print the name and number of features after one-hot encoding\nencoded = list(data_onehot.columns[1:])\nprint (\"{} total features after one-hot encoding.\".format(len(encoded)))\nprint (encoded)\n\ndata_onehot.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9cff97cfc6adc57c123a0da7621c3a11f99d6af"},"cell_type":"markdown","source":"### Split Features and Labels"},{"metadata":{"trusted":true,"_uuid":"1fb4a87ba29dc3ca1012446c2a5c0f22d3713895"},"cell_type":"code","source":"y_onehot = data_onehot['class_p']\nX_onehot = data_onehot.drop(['class_p'], axis=1)\nX_onehot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09e56a8d01dd91b9be93e328fddb140c892b38ec"},"cell_type":"code","source":"y_onehot.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d210334f3c1799a72b18857e5523bfbfc8f2022d"},"cell_type":"markdown","source":"---\n<a id='step3'></a>\n## Step 3: Feature Importance Analysis\n\n### Visualization for Feature Distribution\nCheck class distribution plot by grouping for the features:"},{"metadata":{"trusted":true,"_uuid":"b24ff1f1395d18ea4654aba83ffcb9494df89ee8"},"cell_type":"code","source":"feature_columns = data.columns[1:]\nsns.set(style=\"darkgrid\", color_codes=True)\nfig, axes = plt.subplots(nrows= 3, ncols=7,figsize=(35, 15))\n#fig, axes = plt.subplots(nrows= 7, ncols=3,figsize=(15, 35))\ndata['id'] = np.arange(1, data.shape[0] + 1)\n\nfor f, ax in zip(feature_columns, axes.ravel()):\n    data.groupby(['class', f])['id'].count().unstack(f).plot(kind='bar', ax=ax, legend=True, grid=True,fontsize = 16)\n    #ax.set_ylabel('Actual label', style='italic')\n    ax.set_title(f, style='oblique', size=24)\n    ax.set_xlabel(' \\n', style='italic', size=18)\n    ax.legend(fontsize=14)   #for 3*7 change to 14\ndata = data.drop(\"id\",axis = 1) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"113c1f5a027eb6f4bb6b2c8a273b85dfb6c0730d"},"cell_type":"markdown","source":"### Feature - Class Correlation\nHere we perform correlation between features and classes. Together with the distribution plot above, we find few things about feature importance:\n<p>  1. In poisonous mushrooms, about 96.9% of them do not belong to \"odor type n\".\n<p>  2. About 55.2% of the poisonous mushrooms belong to \"odor type f\". From 1,2 and distribution plot, we can see that odor type is a significant  feature on mushroom classification.\n<p>  3. About 55.8% of poisonous mushrooms have gill-color_b, and from distribution plot we can also see there is few edible mushrooms with gill-color_b.\n<p>  4. About 55.2% of poisonous mushrooms belong to \"stalk-surface-below-ring_k type\", and from distribution plot we can also see there is few edible mushrooms belong to \"stalk-surface-below-ring_k type\".\n"},{"metadata":{"trusted":true,"_uuid":"02c783143ef185cde09df90f584b7208de611ca6"},"cell_type":"code","source":"# Calculate correlation by pd.corr()\ncorr = data_onehot.corr().loc[:,'class_p']\ntop_10_corr =corr.abs().sort_values(ascending=False).head(n=11).iloc[1:]\nprint ('Top-10 features to class_p correlation:','\\n\\n',top_10_corr)\n\ntop_10_corr_ratio = pd.DataFrame(index=range(2))\nfor feature in top_10_corr.index:\n    feature_grouped = data_onehot[['class_p',feature]].groupby([feature])\n    top_10_corr_ratio.loc[:,feature] = 100*feature_grouped.sum()/(poisonus_cnt)\n\nprint ('\\n\\nTop-10 features-class_p poisonus mushrooms ratio:')\ntop_10_corr_ratio","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82cc94af9f2bc1ef1461b9b1f1a882bc2646287b"},"cell_type":"code","source":"print (\"Visualize Top-10 features to class_p correlation: \")\ntop_10_corr.plot(kind='bar', grid=True,fontsize = 12)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5db634e613584f6ebf748a56e58570667ed671b7"},"cell_type":"markdown","source":"### PCA (Primary Components Analysis)\nHere we perform PCA to find the components which explanin the variance of data most. Explained Variance & Accumulated Ratio by components are drawn as below:\n\n"},{"metadata":{"trusted":true,"_uuid":"5145611ab722af80166fb94152cc9dbaf2899cce"},"cell_type":"code","source":"# Setup PCA to one-hot encoded features dataset\npca = PCA()\npca.fit(X_onehot)\n\n# Calculate explained_variance and explained_variance_ratio\nexplained_variance = pca.explained_variance_.round(4)\nexplained_variance_ratio_ = pca.explained_variance_ratio_.round(4)\n\n# Calculate accumulated explained_variance_ratio\nratio_accm_num=0\nratio_accm=[]\nfor ratio in explained_variance_ratio_:\n    ratio_accm_num += ratio\n    ratio_accm.append(ratio_accm_num)\n\n# Print values of explained_variance and accumulated explained_variance_ratio\nprint (\"explained_variance:\\n\",explained_variance)\nprint (\"\\n\\naccumulated explained_variance_ratio:\\n\",np.array(ratio_accm),\"\\n\\n\")\n\n\n# Make plot of explained_variance and accumulated explained_variance_ratio\navl_style_list = plt.style.available\nstyle = avl_style_list[15]\nwith plt.style.context(style):\n    \n## plot individual explained variance by components\n    plt.figure(figsize=(12, 4))\n    plt.bar(range(len(X_onehot.columns)),explained_variance, alpha=0.5, align='center', label='individual explained variance')\n\n## plot accumulated explained variance ratio by components\n    plt.bar(range(len(X_onehot.columns)),ratio_accm, alpha=0.5, align='center', label='accumulated explained variance ratio')\n    plt.ylabel('Values')\n    plt.xlabel('Principal components')\n    plt.legend(loc='best')\n    plt.title(\"Explained Variance & Accumulated Ratio by Components\",fontsize=14)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dcfc659a6139e023f379c47ec7e3f975646db10c"},"cell_type":"markdown","source":"### Reduction of Dimension by PCA\nWe make a new features dataset **\"X_onehot_pca\"** by choosing the minimum number of principal components such that **60% of the variance is retained**, and the corresponding number of components **n=8**."},{"metadata":{"trusted":true,"_uuid":"cb9f90354f6fa39c67544b487b54ad6d08183ffd"},"cell_type":"code","source":"def X_PCA(data,n):\n    pca = PCA(n)\n    pca.fit(X_onehot)\n    X_pca_ = pca.transform(data)\n\n    column_head=[]\n    for i in range(X_pca_.shape[1]):\n        column_head.append(\"dimension_\"+str(i+1))\n\n    X_pca_ = pd.DataFrame(X_pca_, columns=column_head)\n    return X_pca_\n\nX_onehot_pca = X_PCA(X_onehot,n=.6)\nX_onehot_pca.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9fd0cdfdf689e827ad9317a6b733396ee82ec8f8"},"cell_type":"markdown","source":"---\n<a id='step4'></a>\n## Step 4: Models\n\n### Split Dataset\nNow it's time to build up models, let's split the dataset into training set(70%) & testing set(30%), random seed set to 42.<p>\nAnd we're going to setup 2 kinds of learning data. One is X_onehot, which is original 116 columns of features, and anothor one is X_onehot_pca, which is transformed by PCA with only 8 dimensions.(60% coverage of explained-variance)"},{"metadata":{"trusted":true,"_uuid":"7489ea00d47700e5aa357d01b1159db81a7571ea"},"cell_type":"code","source":"### Split X_onehot (Without PCA transformation) ###\nX_train, X_test, y_train, y_test = train_test_split(X_onehot,y_onehot,test_size = 0.3,random_state = 42)\n\nprint ('X_train Shape:', X_train.shape)\nprint ('X_test Shape:', X_test.shape)\nprint ('y_train Shape:', y_train.shape)\nprint ('y_test Shape:', y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94ef10abb53d34062cee080103e14eaa5b13685a"},"cell_type":"code","source":"### Split X_onehot (With PCA transformation s.t. 60% of the variance is retained, n=8) ###\nX_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_onehot_pca,y_onehot,test_size = 0.3,random_state = 42)\n\nprint ('X_train_pca Shape:', X_train_pca.shape)\nprint ('X_test_pca Shape:', X_test_pca.shape)\nprint ('y_train_pca Shape:', y_train_pca.shape)\nprint ('y_test_pca Shape:', y_test_pca.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c26112fb3eaf62b7733124d8c84e0a01cbfb94b0"},"cell_type":"markdown","source":"### Define Helper Sub-Functions\nWe define some sub-functions here for the convinience to compare different algorithms by run time, accuracy, F1 score, precision, recall."},{"metadata":{"trusted":true,"_uuid":"01bb0cca2339a94ae8ee4bf586ceb982d5d30c3d"},"cell_type":"code","source":"###### define helper functions for training and prediction\n\n### Train model and calculate t_train\ndef train_classifier(clf, X_train, y_train, printer):\n    '''Fits a classifier to the training data'''\n    # Check train time\n    start = time()\n    clf.fit(X_train, y_train)\n    end = time()\n    t_train = end - start\n    if printer:\n        print (\"Trained model in {:.4f} seconds!\".format(t_train))\n    return t_train\n    \n### Calculate cv scores and calculate t_cv\ndef train_cv_(clf, X, y, cv_fold, printer):\n    '''n-fold CV to the choosen algorithm & training data'''\n    # Check cv time\n    start = time()\n    y_cv = cross_val_predict(clf, X, y, cv=cv_fold)\n    end = time()\n    t_cv = end - start\n    if printer:\n        print (\"Made {}-fold CV in {:.4f} seconds!\".format(cv_fold, t_cv))\n    \n    # Calculate cv scores\n    f1_ = f1_score(y, y_cv)\n    precision_ = precision_score(y, y_cv)\n    recall_ = recall_score(y, y_cv)\n    accuracy_ = accuracy_score(y, y_cv)\n    \n    # Summary CV score\n    if printer:\n        print (\"\\n-------------------CV Score Summary (WITH {}-fold CV)--------------------\".format(cv_fold))\n        print (\"F1 score for cv set: {:.2f}% , Accuracy score for cv set: {:.2f}%.\".format(\n        f1_*100 , accuracy_*100))\n\n        print(\"Precision score for cv set: {:.2f}% , Recall score for cv set: {:.2f}%.\".format(\n        precision_*100 , recall_*100))\n        print (\"-------------------------------------------------------------------------\".format(cv_fold))\n    return t_cv, f1_, precision_, recall_, accuracy_\n\n### Calculate test scores and confusion matrix calculate t_test   \ndef predict_labels(clf, X, y, printer):\n    '''Make predictions using a fit classifier'''\n    # Check predict time\n    start = time()\n    y_predicted = clf.predict(X)\n    end = time()\n    t_predict = end - start\n    \n    if printer:\n        print (\"Made predictions in {:.4f} seconds!\".format(t_predict))\n    \n    # Return predict score / confusion matrix\n    f1_ = f1_score(y, y_predicted)\n    precision_ = precision_score(y, y_predicted)\n    recall_ = recall_score(y, y_predicted)\n    accuracy_ = accuracy_score(y, y_predicted)\n    conf_matrix = confusion_matrix(y, y_predicted)\n    \n    return t_predict, f1_, precision_, recall_, accuracy_, conf_matrix  \n    \n\n### Core to call train/cv/test for clfs    \ndef train_predict(clf, X_train, X_test, y_train, y_test, printer, cv=True, cv_fold=10, clf_remark=None):\n    ''' Train and predict using a classifer based on F1 score/Accuracy score without cv'''\n    \n    # Indicate the classifier and the training set size\n    clf_name = clf.__class__.__name__\n    if printer:\n        print (\">>> Training/predcting a {} model now... <<<\\n\".format(clf_name))\n    \n    # Train the classifier\n    t_train = train_classifier(clf, X_train, y_train, printer=printer)\n    \n    # Make CV on training set\n    if cv:\n        t_cv, f1_cv, precision_cv, recall_cv, accuracy_cv = train_cv_(clf, X_train, y_train, cv_fold, printer=printer)\n    \n       \n    # Calculate score\n    #print \"\\nPredicting on training set...\"\n    #f1_score_train, precision_score_train, recall_score_train, accuracy_score_train = predict_labels(clf, X_train, y_train)\n    \n    t_predict, f1_test, precision_test, recall_test, accuracy_test, conf_matrix = predict_labels(clf, X_test, y_test, printer=printer)\n    \n    if printer:\n        print (\"\\nPredicting on testing set...\")\n    t_predict, f1_test, precision_test, recall_test, accuracy_test\n    \n    # Summary score\n    if printer:\n        print (\"\\n---------------------- Testing Score Summary -------------------------------------\")  \n        print (\"F1 score for test set: {:.2f}% , Accuracy score for test set: {:.2f}%.\".format(\n        f1_test*100 , accuracy_test*100))\n\n        print (\"Precision score for test set: {:.2f}% , Recall score for test set: {:.2f}%.\".format(\n        precision_test*100 , recall_test*100))\n        print (\"\\n===============================End of this clf ===============================\\n\")\n        print (\"\\n------------------------------------------------------------------------------\\n\")\n    \n    ### out put values ###\n        \n    if not cv:        \n        return clf_name, t_train, t_predict, f1_test, precision_test, recall_test, accuracy_test, conf_matrix \n    \n    return clf_name, t_train, t_cv, t_predict, f1_cv, precision_cv, recall_cv, accuracy_cv, f1_test, precision_test, recall_test, accuracy_test, conf_matrix\n\n\n### Summary table for the result of train_predict()\ndef clf_summary(clfs, X_train, X_test, y_train, y_test, printer=True, cv=True, cv_fold=10, clfs_rename=None):\n    '''Return a summary table about train/test/cv time & scores for given data and a list of classifiers. '''\n    result_non_cv = {'Clf_Name':[], 'Time_Train':[], 'Time_Test':[], 'Test_F1':[],\n                 'Test_Precision':[], 'Test_Recall':[], 'Test_Accuracy':[], 'Confusion_Matrix':[]}\n\n    result_cv = {'Clf_Name':[], 'Time_Train':[], 'Time_CV':[], 'Time_Test':[], 'CV_F1':[],\n             'CV_Precision':[], 'CV_Recall':[], 'CV_Accuracy':[], 'Test_F1':[], \n             'Test_Precision':[], 'Test_Recall':[], 'Test_Accuracy':[], 'Confusion_Matrix':[]}\n\n    if clfs_rename and len(clfs_rename) != len(clfs):\n        raise Exception(\"rename list length error!\")\n    for ii in range(len(clfs)):\n        result_time = []\n        result_score = [] \n        result = train_predict(clfs[ii], X_train, X_test, y_train, y_test, printer=printer, cv=cv, cv_fold=cv_fold)\n\n        if cv:\n            for i in range(1,4):\n                result_time.append(str(round(result[i],2))+'s')   \n            for i in range(4,12):\n                result_score.append(str(round(100*result[i],2))+'%')\n\n            if clfs_rename:\n                result_cv['Clf_Name'].append(clfs_rename[ii])\n            else: result_cv['Clf_Name'].append(result[0])\n            result_cv['Time_Train'].append(result_time[0])\n            result_cv['Time_CV'].append(result_time[1])\n            result_cv['Time_Test'].append(result_time[2])\n            result_cv['CV_F1'].append(result_score[0])\n            result_cv['CV_Precision'].append(result_score[1])\n            result_cv['CV_Recall'].append(result_score[2])\n            result_cv['CV_Accuracy'].append(result_score[3])\n            result_cv['Test_F1'].append(result_score[4])\n            result_cv['Test_Precision'].append(result_score[5])\n            result_cv['Test_Recall'].append(result_score[6])\n            result_cv['Test_Accuracy'].append(result_score[7])\n            result_cv['Confusion_Matrix'].append(result[12])\n\n\n        else:\n            for i in range(1,3):\n                result_time.append(str(round(result[i],2))+'s')    \n            for i in range(3,7):\n                result_score.append(str(round(100*result[i],2))+'%')\n\n            if clfs_rename:\n                result_non_cv['Clf_Name'].append(clfs_rename[ii])\n            else: result_non_cv['Clf_Name'].append(result[0])\n            result_non_cv['Time_Train'].append(result_time[0])\n            result_non_cv['Time_Test'].append(result_time[1])\n            result_non_cv['Test_F1'].append(result_score[0])\n            result_non_cv['Test_Precision'].append(result_score[1])\n            result_non_cv['Test_Recall'].append(result_score[2])\n            result_non_cv['Test_Accuracy'].append(result_score[3])\n            result_non_cv['Confusion_Matrix'].append(result[7])\n    \n    if cv:\n        #print result_cv\n        clf0_summary_ = pd.DataFrame(result_cv)\n        clf0_summary = clf0_summary_.set_index('Clf_Name')\n    else:\n        clf0_summary_ = pd.DataFrame(result_non_cv)\n        clf0_summary = clf0_summary_.set_index('Clf_Name')\n    \n    return clf0_summary\n\n\n### Confusion matrix subplot function\n'''Plot Confusion Matrix for the result of clf_summary by input clf_summary_['Confusion_Matrix']'''\ndef confusion_matrix_plot(clf_conf_list):\n    n_clf = len(clf_conf_list)\n\n    name_clf = []\n    Confusion_Matrix_list = []\n    for matrix, index_ in zip(clf_conf_list,clf_conf_list.index):\n        name_clf.append(index_)\n        Confusion_Matrix_list.append(matrix)\n\n    sns.set(style=\"white\", color_codes=True)\n    rows_ = int(math.ceil(n_clf/5.0))\n    cols_ = 5\n    fig_x = 18\n    if n_clf < 6:\n        cols_ = n_clf\n        fig_x = n_clf*(18.0/5.0)\n    \n    fig, axn = plt.subplots(nrows= rows_, ncols=cols_, figsize=(fig_x, 6*math.ceil(n_clf/5.0)))\n    for i, ax in zip(range(n_clf), axn.ravel()):    \n        sns.heatmap(Confusion_Matrix_list[i], ax=ax, annot=True,\n                    fmt=\".0f\", linewidths=.5, square = True, cmap = 'Greens')\n        ax.set_title('{}\\nConfusion Matrix:'.format(name_clf[i]), size = 12, weight='semibold')\n        ax.set_ylabel('Actual label', style='italic')\n        ax.set_xlabel('Predicted label', style='italic')\n        \n        \n        \n########################\n\n## Show detail of GS by different scoring\ndef Grid_reporter(clf,X_train,y_train,scores,params_,cv=5):\n    #g_clfs_dic={}\n    g_clfs_dic = OrderedDict()\n    i=0\n    for score in scores:\n        i += 1\n        print(\"# Tuning hyper-parameters for %s\" % score)\n        print (\"\")\n\n        g_clf = GridSearchCV(clf, params_, cv=cv,\n                           scoring=score)\n        g_clf.fit(X_train, y_train)\n\n        print (\"Best parameters set found on development set:\")\n        print (g_clf.best_params_)\n        print (\"\")\n        print (\"Grid scores on development set:\")\n        means = g_clf.cv_results_['mean_test_score']\n        stds = g_clf.cv_results_['std_test_score']\n        for mean, std, params in zip(means, stds, g_clf.cv_results_['params']):\n            print(\"%0.3f (+/-%0.03f) for %r\"\n                  % (mean, std * 2, params))\n        g_clfs_dic[str(i)+\"_\"+score] = g_clf.best_estimator_\n    return g_clfs_dic\n\n\n## Summary of GS by different scoring\ndef clf_summary_gs(clfs_grid_score,X_train, X_test, y_train, y_test,gs_str):\n    clfs = []\n    clfs_rename = []\n    for key in clfs_grid_score:\n        clfs_rename.append(key+gs_str)\n        clfs.append(clfs_grid_score[key])\n    clf_summary_ = clf_summary(clfs, X_train, X_test, y_train, y_test, \n                               cv=True, cv_fold=10, printer=False, clfs_rename=clfs_rename)\n    return clf_summary_.drop('Confusion_Matrix', axis=1).transpose(),clf_summary_['Confusion_Matrix']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88f438bb6bc85b7d605f95485cab8e4d9be30692"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a5304d391d48eb9fd8d0dfceaee4943d454cae6"},"cell_type":"markdown","source":"### Basic Model Performance\nHere we choose 4 famous and classic supervised learning model(LogisticRegression, SVC, DecisionTreeClassifier, BernoulliNB), and a MLP model (all models with default parameters) to make train/cv/test by the corresponding splitting sets(after PCA) to get a baseline of the basic model.<p>\nThe comparison result of train/cv/test time, scores and confusion matrix between the algorithms are shown as table below. As the result, the MLP seems doing little better than others, but if consider to the train/cv time, so in overall speaking, DecisionTreeClassifier is more faster in train/cv/test, also has good scores: "},{"metadata":{"trusted":true,"_uuid":"2414579b34d2206a02a8b4582d0f70308a26082d"},"cell_type":"code","source":"clfs = [LGR(random_state=42,solver='lbfgs'),SVC(random_state=42,gamma='auto'),\n        tree.DecisionTreeClassifier(random_state=42),GaussianNB(), MLP(random_state=42,max_iter=1000)]\nclf_summary_ = clf_summary(clfs, X_train_pca, X_test_pca, y_train_pca, y_test_pca, cv=True, cv_fold=10, printer=False)\nclf_summary_.drop('Confusion_Matrix', axis=1).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0250d37bd71e9ee9e7367378776fb2cd535d5ccb"},"cell_type":"code","source":"confusion_matrix_plot(clf_summary_['Confusion_Matrix'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6fa397b2dad3e0e588fa457a1866d93233d6bd17"},"cell_type":"markdown","source":"---\n<a id='step5'></a>\n## Step 5: Optimization\n\n\n### Grid Search\n\nLet's try grid search for parameter optimization on the classifiers. We will focus on each algorithm by optimizing different kind of scoring functions.\n\n### Logistic Regression\n\nFor LGR, we choose to tune type of solve,class_weight, war_start ; and value of C, max_iter. But the result shows no any improvement on accuracy."},{"metadata":{"trusted":true,"_uuid":"93a01edaa1e6098bc246b040e40e40d178f3bf7c"},"cell_type":"code","source":"parameters = {'C': [0.1,1.0,10.0,100.0] ,'solver': ['newton-cg','lbfgs','liblinear','sag'],\n             'max_iter': [100,300],'class_weight':['balanced', None],'warm_start':[True,False]}\nclf = LGR(random_state=42)\nscores_list = ['accuracy', 'f1', 'precision', 'recall']\n\n# report a dict of best clf with different kind of cv score(default fold number of cv=5)\nclfs_grid_score = Grid_reporter(clf,X_train_pca,y_train_pca,scores_list,parameters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43e3743f96e26dd69e5589581223073ab7a5dd22","scrolled":true},"cell_type":"code","source":"clfs_grid_score['5_default'] = LGR(random_state=42,solver='lbfgs')\nclfs_grid_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be48fa9e8a1804ff963c9c4f572727669e6ece47"},"cell_type":"code","source":"clf_summary_ , confusion_matrix_ = clf_summary_gs(clfs_grid_score, X_train_pca, X_test_pca, y_train_pca, y_test_pca,\n                                                  gs_str=\"_LGR_GS\")\n\nclf_summary_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e893e395673913dce79646e3967ac3ca40d50e0d"},"cell_type":"code","source":"confusion_matrix_plot(confusion_matrix_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e0d85a2a570a54e2db32289177535422fc894364"},"cell_type":"markdown","source":"### SVC\nFor SVC, we choose to tune type of kernel ; and value of C, gamma. Tuned accuracy score achieve to 100%."},{"metadata":{"trusted":true,"_uuid":"93ae2558aabf36c39955242ba7bf1cf96cd58e79"},"cell_type":"code","source":"parameters = [{'kernel': ['rbf'],\n               'gamma': [1e-4, 1e-3, 0.01, 0.1, 0.2, 0.5],\n                'C': [1, 10, 100, 1000]},\n              {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\nclf = SVC(random_state=42)\nscores_list = ['accuracy', 'f1', 'precision', 'recall']\n\n# report a dict of best clf with different kind of cv score(default fold number of cv=5)\nclfs_grid_score = Grid_reporter(clf,X_train_pca,y_train_pca,scores_list,parameters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96fd5cc0141eabab532eaa506f1d232f262dac8f"},"cell_type":"code","source":"clfs_grid_score['5_default'] = SVC(random_state=42,gamma='auto')\nclfs_grid_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5739ff66eb5f3968bf4639f20bcd1e613bc74fe1"},"cell_type":"code","source":"clf_summary_ , confusion_matrix_ = clf_summary_gs(clfs_grid_score, X_train_pca, X_test_pca, y_train_pca, y_test_pca,\n                                                  gs_str=\"_SVC_GS\")\nclf_summary_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45a2b0e681a3da24b29cd6c72ebaa6525f6cd0a1"},"cell_type":"code","source":"confusion_matrix_plot(confusion_matrix_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"096f444b833a58c7a0533f6f7fb77b8860289440"},"cell_type":"markdown","source":"### Decision Tree\nFor decision tree, we choose to tune type of criterion and value of max_depth, min_sample_leaf, max_features. It shows slightly improvement on accuracy score. "},{"metadata":{"trusted":true,"_uuid":"7029a713bd23066e2b4930cc89a346a90e60e069"},"cell_type":"code","source":"parameters = {'max_depth': [None,6,7,10,11,12,13,14], 'min_samples_leaf': [1,2], \n              'max_features':[None,3,4,5,6,7,8],'criterion':['gini','entropy']}\nclf = tree.DecisionTreeClassifier(random_state=42)\nscores_list = ['accuracy', 'f1', 'precision', 'recall']\n\n# report a dict of best clf with different kind of cv score(default fold number of cv=5)\nclfs_grid_score = Grid_reporter(clf,X_train_pca,y_train_pca,scores_list,parameters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"272e05d3980d97d8cee0a4bf083fe1ddbb7e2107"},"cell_type":"code","source":"clfs_grid_score['5_default'] = tree.DecisionTreeClassifier(random_state=42)\nclfs_grid_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6561f0c6016052d6f43ec171573425899552fd69"},"cell_type":"code","source":"clf_summary_ , confusion_matrix_ = clf_summary_gs(clfs_grid_score, X_train_pca, X_test_pca, y_train_pca, y_test_pca,\n                                                  gs_str=\"_DeciTree_GS\")\nclf_summary_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8acd8da56be68861b41eda2fc0d437b7ebb31f2"},"cell_type":"code","source":"confusion_matrix_plot(confusion_matrix_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5da0d7188a4ee3ac2a54df55fee3eee3b8605b96"},"cell_type":"markdown","source":"### Gaussian NB\nFor GNB there's only 1 parameter one can tune: priors. As the result, it's not really helping on the scores, but only change the tend of classifier to guess which label is more likely to be. "},{"metadata":{"trusted":true,"_uuid":"73cceca9ad515689de463f5322be03ae518fb7c1"},"cell_type":"code","source":"parameters = {'priors': [None,[0.5,0.5],[0.4,0.6],[0.6,0.4],[0.3,0.7],[0.7,0.3],\n                         [0.2,0.8],[0.8,0.2],[0.9,0.1],[0.1,0.9],[0.95,0.05],[0.05,0.95],[0.999,0.001],[0.001,0.999]]}\nclf = GaussianNB()\nscores_list = ['accuracy', 'f1', 'precision', 'recall']\n\n# report a dict of best clf with different kind of cv score(default fold number of cv=5)\nclfs_grid_score = Grid_reporter(clf,X_train_pca,y_train_pca,scores_list,parameters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3799f7669d8b5a97f021f0717a70468e5f8f65ff"},"cell_type":"code","source":"clfs_grid_score['5_default'] = GaussianNB()\nclfs_grid_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa3cbc706ffb4f4ebccdf718c25663a29cbe34e5"},"cell_type":"code","source":"clf_summary_ , confusion_matrix_ = clf_summary_gs(clfs_grid_score, X_train_pca, X_test_pca, y_train_pca, y_test_pca,\n                                                  gs_str=\"_GNB_GS\")\nclf_summary_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0edbc7aa1ead56a09370687d902636b4a9e8c94"},"cell_type":"code","source":"confusion_matrix_plot(confusion_matrix_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0bc2aa4fd00f9761e7d0d1c0dabed5ed21bf8346"},"cell_type":"markdown","source":"### MLP\nFor MLP, we choose to tune value of alpha and size/number of hidden layers. Actually the default setting is already excellent, only 1 FN. With larger hidden layer size and numbers (200,4), the accuracy achieves 100%."},{"metadata":{"trusted":true,"_uuid":"13afc7c4fdec7560183458c2f57714bd52ee4da6"},"cell_type":"code","source":"alpha_range = 10.0 ** -np.arange(2, 5)\nparameters = {'alpha': alpha_range,\n              'hidden_layer_sizes': [(8,),(7,7,),(42,3,),(81,4,),(150,5,),(200,4)]}\nclf = MLP(random_state=42,max_iter=1000)\nscores_list = ['accuracy', 'f1', 'precision', 'recall']\n#scores_list = ['accuracy']\n\n# report a dict of best clf with different kind of cv score(default fold number of cv=5)\nclfs_grid_score = Grid_reporter(clf,X_train_pca,y_train_pca,scores_list,parameters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af55fdf403f4222f60c25bc415affe5060ba2f37"},"cell_type":"code","source":"clfs_grid_score['5_default'] = MLP(random_state=42,max_iter=1000)\nclfs_grid_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bbff64f178cb8062f50ed5db488648999d465cd"},"cell_type":"code","source":"clf_summary_ , confusion_matrix_ = clf_summary_gs(clfs_grid_score, X_train_pca, X_test_pca, y_train_pca, y_test_pca,\n                                                  gs_str=\"_MLP_GS\")\nclf_summary_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3a97a7523c7faa1d39b432d4279496852d867fa"},"cell_type":"code","source":"confusion_matrix_plot(confusion_matrix_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9460f5fcf05502ea3dbaa3bb27f28dabeeebf6d"},"cell_type":"markdown","source":"---\n<a id='step6'></a>\n## Step 6: Conclusion\n\n### Overall Result\nIn Step.5 Optimization we have performed 5 classifiers by plenty combinations of parameters, with 60% explanined variance ratio PCA dimension reduction(n=8). Finally, 2 of them are tuned to achieve 100% accuracy(MLP and SVC). Let's summary 5 classifiers with best accuracy below:"},{"metadata":{"trusted":true,"_uuid":"4eb2729a99c89bbc1a19c39ebfc4c8913bdf88a7"},"cell_type":"code","source":"clfs_best = [LGR(C=1.0, class_weight='balanced', dual=False,\n                        fit_intercept=True, intercept_scaling=1, max_iter=100,\n                        multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,\n                        solver='newton-cg', tol=0.0001, verbose=0, warm_start=True),\n        SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n                decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',\n                max_iter=-1, probability=False, random_state=42, shrinking=True,\n                tol=0.001, verbose=False),\n        tree.DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n                          max_features=None, max_leaf_nodes=None,\n                          min_impurity_decrease=0.0, min_impurity_split=None,\n                          min_samples_leaf=1, min_samples_split=2,\n                          min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n                          splitter='best'),\n        GaussianNB(priors=[0.1, 0.9]),\n        MLP(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n                     beta_2=0.999, early_stopping=False, epsilon=1e-08,\n                     hidden_layer_sizes=(200, 4), learning_rate='constant',\n                     learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n                     nesterovs_momentum=True, power_t=0.5, random_state=42, shuffle=True,\n                     solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n                     warm_start=False)]\n\n\nclfs_rename_best = ['LGR_Best','SVC_Best','DT_Best','GNB_Best','MLP_Best']\nclf_summary_ = clf_summary(clfs_best, X_train_pca, X_test_pca, y_train_pca, y_test_pca, \n                           cv=True, cv_fold=10, printer=False, clfs_rename=clfs_rename_best)\n\nclf_summary_best = clf_summary_.drop('Confusion_Matrix', axis=1).transpose()\n\n# ---Over all tuned parameters list---\n# LGR_parameters = {'C': [0.1,1.0,10.0,100.0] ,'solver': ['newton-cg','lbfgs','liblinear','sag'],\n#             'max_iter': [100,300],'class_weight':['balanced', None],'warm_start':[True,False]}\n#\n# SVC_parameters = [{'kernel': ['rbf'],\n#               'gamma': [1e-4, 1e-3, 0.01, 0.1, 0.2, 0.5],\n#                'C': [1, 10, 100, 1000]},\n#              {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n#\n# DT_parameters = {'max_depth': [None,6,7,10,11,12,13,14], 'min_samples_leaf': [1,2], \n#              'max_features':[None,3,4,5,6,7,8],'criterion':['gini','entropy']}\n#\n# parameters = {'priors': [None,[0.5,0.5],[0.4,0.6],[0.6,0.4],[0.3,0.7],[0.7,0.3],\n#                         [0.2,0.8],[0.8,0.2],[0.9,0.1],[0.1,0.9],[0.95,0.05],[0.05,0.95],[0.999,0.001],[0.001,0.999]]}\n#\n# parameters = {'alpha': 10.0 ** -np.arange(2, 5),\n#              'hidden_layer_sizes': [(8,),(7,7,),(42,3,),(81,4,),(150,5,),(200,4)]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fbdcab2b14d0118ab2b544a15173a8e39d59bf15"},"cell_type":"code","source":"clf_summary_best","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03476008e14453d7fb1dc30d0aab1c32a0e4405f"},"cell_type":"code","source":"confusion_matrix_plot(clf_summary_['Confusion_Matrix'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c48c739ec4177499037c4c1e2268d1b4c40f55ed"},"cell_type":"markdown","source":"### Learning Curve\nTo check the models are overfitting or not, here we perform learning curve plot for the clfs with best parameters.\n\nAs the result, "},{"metadata":{"trusted":true,"_uuid":"ee6a58662a33b2ec7ef298b9ba4e2b63194da329"},"cell_type":"code","source":"### Built the helper function for plotting learning curve\n\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"\n    Generate a simple plot of the test and training learning curve.\n\n    Parameters\n    ----------\n    estimator : object type that implements the \"fit\" and \"predict\" methods\n        An object of that type which is cloned for each validation.\n\n    title : string\n        Title for the chart.\n\n    X : array-like, shape (n_samples, n_features)\n        Training vector, where n_samples is the number of samples and\n        n_features is the number of features.\n\n    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n        Target relative to X for classification or regression;\n        None for unsupervised learning.\n\n    ylim : tuple, shape (ymin, ymax), optional\n        Defines minimum and maximum yvalues plotted.\n\n    cv : int, cross-validation generator or an iterable, optional\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n          - None, to use the default 3-fold cross-validation,\n          - integer, to specify the number of folds.\n          - An object to be used as a cross-validation generator.\n          - An iterable yielding train/test splits.\n\n        For integer/None inputs, if ``y`` is binary or multiclass,\n        :class:`StratifiedKFold` used. If the estimator is not a classifier\n        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validators that can be used here.\n\n    n_jobs : integer, optional\n        Number of jobs to run in parallel (default 1).\n    \"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b9dda97c26e31d1abc16e95e87eb552fa525b48"},"cell_type":"code","source":"# title = \"Learning Curves\"\n# Cross validation with 100 iterations to get smoother mean test and train\n# score curves, each time with 20% data randomly selected as a validation set.\n\n\ncv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\nfor i in range(5):\n    plot_learning_curve(estimator=clfs_best[i], title=clfs_rename_best[i]+'_Learning Curve', X=X_onehot_pca,\n                        y=y_onehot, ylim=(0.7, 1.01), cv=cv, n_jobs=4, train_sizes=np.linspace(.002, 0.2, 30))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01a564816154ee5f93bb4670750c2c9a6e192c71"},"cell_type":"markdown","source":"### Result without PCA dimension reduction\nFinally, we also perform training/test on the original data(with onehot encoder and without PCA) by the 5 classifiers with default parameters. As the result shown below, the accuracy scores are almost perfect, 3 of them achieve 100% accuracy.<p>So for this problem, the additional dimensionality reduction with PCA is actually not necessary. LGR and Decision Tree with default parameters are already do their great job and the speeds are also very quick. <p>Anyway, in the opinion of practicing, this whole procedure is really helped for understanding about machine learning."},{"metadata":{"trusted":true,"_uuid":"6af5ec2dda11b03dd487b8666f85256954c0f91d"},"cell_type":"code","source":"clfs_basic = [LGR(random_state=42),SVC(random_state=42),tree.DecisionTreeClassifier(random_state=42),\n              GaussianNB(), MLP(random_state=42)]\nclf_summary_ori = clf_summary(clfs_basic, X_train, X_test, y_train, y_test, \n                           cv=True, cv_fold=10, printer=False)\nclf_summary_original = clf_summary_ori.drop('Confusion_Matrix', axis=1).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"106cd5e4e730affd995304bfc6fddc956d52c818"},"cell_type":"code","source":"clf_summary_original","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fdb9b66cb3fb996f6b9f59b437536235950183e"},"cell_type":"code","source":"confusion_matrix_plot(clf_summary_ori['Confusion_Matrix'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c22a583bb0bd1b6b5fb483c1df0e9980c6219bc9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}