{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About this Notebook\n\n\n<h3> Dataset </h3>\nIn the following notebook, I tried to analyze the attached dataset and explore it more to find the relationship between different features.\nThen I applied the EDA, PCA, and feature engineering.\n\n<h4> EDA </h4>\n\n<h3> Model Selection </h3>\nFo modeling the dataset, I considered the Boosted Tree Classifier from the TensorFlow library. \n\n<h4> Metrics </h4>\nThe metric I used to measure the model performance is the accuracy of the classifier.\n\n<h4> DFCs </h4>\nIn this NoteBook, after training the model, I tried to move on to have more detail about the trained model by applying directional feature contributions (DFCs).\n\n</br>\n\n<img src=\"https://miro.medium.com/max/3798/1*RbBwF9pMlxQm45cVjDch4w.jpeg\" alt=\"Travel\" width=\"500\" height=\"600\">\n\n<hr>\nI tried to explain each cell in a markdown cell above.\n\n\n<h5>If you are interested in this problem and detailed analysis, you can copy this Notebook as follows</h5>\n\n<img src=\"https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1101107%2F8187a9b84c9dde4921900f794c6c6ff9%2FScreenshot%202020-06-28%20at%201.51.53%20AM.png?generation=1593289404499991&alt=media\" alt=\"Copyandedit\" width=\"300\" height=\"300\" class=\"center\">","metadata":{}},{"cell_type":"markdown","source":"# Importing Libs","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np \nimport pandas as pd \nimport tensorflow as tf\nfrom tensorflow.estimator import Estimator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom tensorflow_estimator.python.estimator.mode_keys import ModeKeys","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-04T10:43:13.527371Z","iopub.execute_input":"2021-09-04T10:43:13.527765Z","iopub.status.idle":"2021-09-04T10:43:13.532538Z","shell.execute_reply.started":"2021-09-04T10:43:13.527731Z","shell.execute_reply":"2021-09-04T10:43:13.531893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing the dataset","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        data = pd.read_csv(os.path.join(dirname, filename))\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:43:13.816567Z","iopub.execute_input":"2021-09-04T10:43:13.81707Z","iopub.status.idle":"2021-09-04T10:43:13.861622Z","shell.execute_reply.started":"2021-09-04T10:43:13.817038Z","shell.execute_reply":"2021-09-04T10:43:13.860978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data info","metadata":{}},{"cell_type":"code","source":"data.describe().T.style.bar()","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:43:14.146393Z","iopub.execute_input":"2021-09-04T10:43:14.147005Z","iopub.status.idle":"2021-09-04T10:43:14.208842Z","shell.execute_reply.started":"2021-09-04T10:43:14.146966Z","shell.execute_reply":"2021-09-04T10:43:14.208148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:43:14.295731Z","iopub.execute_input":"2021-09-04T10:43:14.296294Z","iopub.status.idle":"2021-09-04T10:43:14.320951Z","shell.execute_reply.started":"2021-09-04T10:43:14.296248Z","shell.execute_reply":"2021-09-04T10:43:14.319898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('We have', data.shape[0], 'Rows and', data.shape[1], 'features')","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:44:11.362419Z","iopub.execute_input":"2021-09-04T10:44:11.36302Z","iopub.status.idle":"2021-09-04T10:44:11.368514Z","shell.execute_reply.started":"2021-09-04T10:44:11.36297Z","shell.execute_reply":"2021-09-04T10:44:11.367554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = data.copy()\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:44:11.553108Z","iopub.execute_input":"2021-09-04T10:44:11.553605Z","iopub.status.idle":"2021-09-04T10:44:11.560036Z","shell.execute_reply.started":"2021-09-04T10:44:11.553576Z","shell.execute_reply":"2021-09-04T10:44:11.55915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = df['ProdTaken']\ndf = df.drop(['ProdTaken', 'CustomerID', 'TypeofContact'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:44:11.776441Z","iopub.execute_input":"2021-09-04T10:44:11.776823Z","iopub.status.idle":"2021-09-04T10:44:11.78351Z","shell.execute_reply.started":"2021-09-04T10:44:11.776793Z","shell.execute_reply":"2021-09-04T10:44:11.782241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check the missing values","metadata":{}},{"cell_type":"code","source":"df.isnull().sum(axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:44:15.251537Z","iopub.execute_input":"2021-09-04T10:44:15.251965Z","iopub.status.idle":"2021-09-04T10:44:15.265614Z","shell.execute_reply.started":"2021-09-04T10:44:15.251892Z","shell.execute_reply":"2021-09-04T10:44:15.264503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h5> To deal with the <span style='background:yellow'> missing values </span> as we have to different feature types, I considered two different scenarios, the average for numerical missed values and high frequency used values for the categorical ones. </h5>\n","metadata":{}},{"cell_type":"code","source":"df.fillna(df.mean(), inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:44:18.549742Z","iopub.execute_input":"2021-09-04T10:44:18.550127Z","iopub.status.idle":"2021-09-04T10:44:18.588869Z","shell.execute_reply.started":"2021-09-04T10:44:18.550091Z","shell.execute_reply":"2021-09-04T10:44:18.588017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_cl = [ 'Occupation',  'Gender',\n                  'ProductPitched', 'MaritalStatus',  'Designation']\n\n\nfor i in categorical_cl:\n    le = LabelEncoder()\n    n = str(i)+'_n'\n    df[n] = le.fit_transform(df[i])\n    del df[i]","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:44:22.706788Z","iopub.execute_input":"2021-09-04T10:44:22.707188Z","iopub.status.idle":"2021-09-04T10:44:22.729675Z","shell.execute_reply.started":"2021-09-04T10:44:22.707154Z","shell.execute_reply":"2021-09-04T10:44:22.728412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Normalizing the input","metadata":{}},{"cell_type":"code","source":"scale = StandardScaler()\nscale.fit(df)\ndf = scale.transform(df)\ndf = pd.DataFrame(df)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:45:03.776741Z","iopub.execute_input":"2021-09-04T10:45:03.777089Z","iopub.status.idle":"2021-09-04T10:45:03.783541Z","shell.execute_reply.started":"2021-09-04T10:45:03.77706Z","shell.execute_reply":"2021-09-04T10:45:03.782675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building Model","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:12:32.149796Z","iopub.execute_input":"2021-09-04T10:12:32.150344Z","iopub.status.idle":"2021-09-04T10:12:32.185175Z","shell.execute_reply.started":"2021-09-04T10:12:32.150295Z","shell.execute_reply":"2021-09-04T10:12:32.18408Z"}}},{"cell_type":"markdown","source":"## Feature engineering","metadata":{}},{"cell_type":"markdown","source":"Replace the header with String value ","metadata":{}},{"cell_type":"code","source":"feature = []\nfor i in range(len(df.columns)):\n  feature.append(str(i))\n\ncol_rename = {i:j for i,j in zip(df.columns, feature)}\ndf = df.rename(columns=col_rename, inplace=False)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:45:06.375559Z","iopub.execute_input":"2021-09-04T10:45:06.375903Z","iopub.status.idle":"2021-09-04T10:45:06.405657Z","shell.execute_reply.started":"2021-09-04T10:45:06.375871Z","shell.execute_reply":"2021-09-04T10:45:06.404687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:45:10.227478Z","iopub.execute_input":"2021-09-04T10:45:10.228192Z","iopub.status.idle":"2021-09-04T10:45:10.233138Z","shell.execute_reply.started":"2021-09-04T10:45:10.228143Z","shell.execute_reply":"2021-09-04T10:45:10.231824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dftrain, dfeval, y_train, y_eval = train_test_split(\n    X, y, test_size=0.3, random_state=2)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:45:11.004448Z","iopub.execute_input":"2021-09-04T10:45:11.004891Z","iopub.status.idle":"2021-09-04T10:45:11.012988Z","shell.execute_reply.started":"2021-09-04T10:45:11.004848Z","shell.execute_reply":"2021-09-04T10:45:11.011941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Changing datatype to be compatible with the model","metadata":{}},{"cell_type":"code","source":"dftrain = dftrain.astype(\"int64\")\ny_train = y_train.astype(\"int64\")\ndfeval = dfeval.astype(\"int64\")\ny_eval = y_eval.astype(\"int64\")","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:45:13.237507Z","iopub.execute_input":"2021-09-04T10:45:13.237845Z","iopub.status.idle":"2021-09-04T10:45:13.243973Z","shell.execute_reply.started":"2021-09-04T10:45:13.237817Z","shell.execute_reply":"2021-09-04T10:45:13.242862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_EXAMPLES = len(y_train)\n\n\ndef make_input_fn(X, y, n_epochs=None, shuffle=True):\n    def input_fn():\n        dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\n        if shuffle:\n            dataset = dataset.shuffle(NUM_EXAMPLES)\n\n        dataset = dataset.repeat(n_epochs)\n\n        dataset = dataset.batch(NUM_EXAMPLES)\n        return dataset\n    return input_fn","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:45:13.782496Z","iopub.execute_input":"2021-09-04T10:45:13.782895Z","iopub.status.idle":"2021-09-04T10:45:13.78934Z","shell.execute_reply.started":"2021-09-04T10:45:13.782865Z","shell.execute_reply":"2021-09-04T10:45:13.788254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training input functions","metadata":{}},{"cell_type":"code","source":"train_input_fn = make_input_fn(dftrain, y_train)\neval_input_fn = make_input_fn(dfeval, y_eval, shuffle=False, n_epochs=1)\n\n\nNUMERIC_COLUMNS = featuer\n\n\nfeature_columns = []\n\n\nfor feature_name in NUMERIC_COLUMNS:\n    feature_columns.append(tf.feature_column.numeric_column(feature_name,\n                                                            dtype=tf.float32))\n\n\nest = tf.estimator.BoostedTreesClassifier(feature_columns,\n                                          n_batches_per_layer=1,\n                                          n_classes=2,\n                                          n_trees=100,\n                                          max_depth=10,\n                                          learning_rate=0.1,\n                                          center_bias=True)\n\nest.train(train_input_fn, max_steps=100)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:45:15.003675Z","iopub.execute_input":"2021-09-04T10:45:15.00408Z","iopub.status.idle":"2021-09-04T10:45:34.907321Z","shell.execute_reply.started":"2021-09-04T10:45:15.004045Z","shell.execute_reply":"2021-09-04T10:45:34.905971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"history = est.evaluate(eval_input_fn)","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:45:34.908996Z","iopub.execute_input":"2021-09-04T10:45:34.909381Z","iopub.status.idle":"2021-09-04T10:45:36.676116Z","shell.execute_reply.started":"2021-09-04T10:45:34.909341Z","shell.execute_reply":"2021-09-04T10:45:36.675108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"items = list(history.items())\narray = np.array(items)\nprint('Accuracy:', '{0:.0f}%'.format(array[0, 1].astype('float64') * 100))","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:45:36.677787Z","iopub.execute_input":"2021-09-04T10:45:36.678102Z","iopub.status.idle":"2021-09-04T10:45:36.684401Z","shell.execute_reply.started":"2021-09-04T10:45:36.678071Z","shell.execute_reply":"2021-09-04T10:45:36.683501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DFCs","metadata":{}},{"cell_type":"code","source":"pred_dicts = list(est.experimental_predict_with_explanations(eval_input_fn))","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:45:36.68563Z","iopub.execute_input":"2021-09-04T10:45:36.685929Z","iopub.status.idle":"2021-09-04T10:45:37.333118Z","shell.execute_reply.started":"2021-09-04T10:45:36.685903Z","shell.execute_reply":"2021-09-04T10:45:37.331881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = y_eval.values\nprobs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\ndf_dfc = pd.DataFrame([pred['dfc'] for pred in pred_dicts])\ndf_dfc.describe().T","metadata":{"execution":{"iopub.status.busy":"2021-09-04T10:45:37.334858Z","iopub.execute_input":"2021-09-04T10:45:37.335375Z","iopub.status.idle":"2021-09-04T10:45:37.414557Z","shell.execute_reply.started":"2021-09-04T10:45:37.335323Z","shell.execute_reply":"2021-09-04T10:45:37.413564Z"},"trusted":true},"execution_count":null,"outputs":[]}]}