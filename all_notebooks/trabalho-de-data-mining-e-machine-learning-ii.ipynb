{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Trabalho final da disciplina Data Mining e Machine Learning II\n## Prof: Marcos Guimarães\n## Aluno: Walter Soares Malta"},{"metadata":{},"cell_type":"markdown","source":"## Introdução"},{"metadata":{},"cell_type":"markdown","source":"O objeto de nossa análise consiste em verificar a base de dados de clientes com o propósito de automatizar o processo de tomada de decisão para aprovação das linhas de crédito. Torna-se necessário criar um modelo de pontuação de crédito baseado em dados coletados de solicitantes recentes de crédito.\n\nUtilizaremos ferramentas de modelagem preditiva, entretnato o modelo deverá ser interpretável, de forma a permitir que se explique de forma comprovada eobjetiva e se tenha subsidios para uma rejeição ao crédito.\n\nA base de dados de Home Equity (HMEQ) contém informações de desempenho de empréstimos para 5.960 clientes. A nossa variável resposta (BAD) é uma variável binária que indica se o requerente é inadimplente ou não. Casos de clientes inadimplentes ocorreram em 1.189 casos (20%). Para cada cliente, foram registradas 12 variáveis descritas abaixo:\n\n* BAD 1 = cliente inadimplente no empréstimo 0 = empréstimo reembolsado\n* LOAN Montante do pedido de empréstimo\n* MORTDUE Montante devido na hipoteca existente\n* VALUE Valor da propriedade atual\n* REASON DebtCon = consolidação da dívida HomeImp = melhoria da casa\n* JOB Categorias profissionais JOBSix\n* YOJ Anos no emprego atual\n* DEROG Número de principais relatórios depreciativos\n* DELINQ Número de linhas de crédito inadimplentes\n* CLAGE Idade da linha comercial mais antiga em meses\n* NINQ Número de linhas de crédito recentes\n* CLNO Número de linhas de crédito\n* DEBTINC Razão Dívida / Renda\n"},{"metadata":{},"cell_type":"markdown","source":"## Desenvolvimento"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# IMportação das bibliotecas basicas\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\n# Abaixo listamos os arquivos da base\n\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Leitura do arquivo\ndf = pd.read_csv('/kaggle/input/hmeq-data/hmeq.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Abaixo poemos veriricar o conteúdo da base\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verificamos agora os tipos de dados\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os valores nulos\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observamos que a base contém muitos valores nulos. Para que possamos prosseguir com o nosso trabalho de construir um modelo é necessário corrigir a base preenchendo as informações faltantes.\n\nAbaixoi a definição dos valores a serem inseridos para cada variável:\n\nMORTDUE-  Montante devido na hipoteca existente - Assumido como 0\nVALUE - Valor da propriedade atual -  Assumido como 0\nREASON DebtCon = consolidação da dívida HomeImp = melhoria da casa - 'Other' (Outro)\nJOB Categorias profissionais JOBSix = 'None' (Nenhum)\nYOJ Anos no emprego atual - Assumido 0\nDEROG Número de principais relatórios depreciativos - Assumido como 0\nDELINQ Número de linhas de crédito inadimplentes - Assumido como 0\nCLAGE Idade da linha comercial mais antiga em meses - Assumido como 0\nNINQ Número de linhas de crédito recentes - Assumido como 0\nCLNO Número de linhas de crédito - Assumido como 0\nDEBTINC Razão Dívida / Renda - Assumido como 0\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Imputação de dados nas colunas\ndf.loc[df['MORTDUE'].isnull(),'MORTDUE'] = 0\ndf.loc[df['VALUE'].isnull(),'VALUE'] = 0\ndf.loc[df['JOB'].isnull(),'JOB'] = 'None'\ndf.loc[df['REASON'].isnull(),'REASON'] = 'Other'\ndf.loc[df['YOJ'].isnull(),'YOJ'] = 0\ndf.loc[df['DEROG'].isnull(),'DEROG'] = 0\ndf.loc[df['DELINQ'].isnull(),'DELINQ'] = 0\ndf.loc[df['CLAGE'].isnull(),'CLAGE'] = 0\ndf.loc[df['NINQ'].isnull(),'NINQ'] = 0\ndf.loc[df['CLNO'].isnull(),'CLNO'] = 0\ndf.loc[df['DEBTINC'].isnull(),'DEBTINC'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Listagem das classes de JOB\ndf['JOB'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Listagem das classes de REASON\ndf['REASON'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Definição da função para transformar a informação textual da coluna REASON em codificacao numerica\ndef REASONN (row):\n   if row['JOB'] == 'Other':\n      return 0\n   if row['JOB'] == 'HomeImp':\n      return 1\n   if row['JOB'] == 'DebtCon':\n      return 2\n   return 3\ndf['REASONN'] = df.apply (lambda row: REASONN(row), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Definição da função para transformar informar textual da coluna JOB em codificacao numerica\ndef JOBN (row):\n   if row['JOB'] == 'Other':\n      return 0\n   if row['JOB'] == 'Office':\n      return 1\n   if row['JOB'] == 'Sales':\n      return 2\n   if row['JOB'] == 'Mgr':\n      return 3\n   if row['JOB'] == 'ProfExe':\n      return 4\n   if row['JOB'] == 'Self':\n      return 5\n   return 6\ndf['JOBN'] = df.apply (lambda row: JOBN(row), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Contagem de valores nulos na base\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Podemos veriricar que a base se encontra livre de espaços vazios. \nVamos agora excluir as colunas que não serão utilzadas em nosso modelo.\nA variavel resposta - BAD - também será removida porque iremos separar as variáveis de entrada, ou seja, as variaveis independentes.\nUtilizaremos as variáveis numericas e excluiremos as variaveis com innformação textual."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separando as colunas para a construção do modelo\nfeats = [c for c in df.columns if c not in ['BAD','REASON','JOB']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Conteudo da base de dados\ndf.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dividindo a base em treino e teste\nfrom sklearn.model_selection import train_test_split\n\ntrain,test = train_test_split(df, test_size=0.20, random_state=42)\n\ntrain.shape,valid.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instanciando o random forest classifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_jobs=-1, n_estimators=200, oob_score=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Aplicando o RandomForest à base\nrf.fit(train[feats], train['BAD'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prevendo o BAD de teste usando o modelo treinado\ny_test_pred = rf.predict(test[feats]).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importação do pacote para aferição d acuracia\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Medida da acurácia\naccuracy_score(test['BAD'], y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pudemos observar que o nosso modelo comporta-se muito bem pois obteve uma medida de acurácia elevada.\nPara corroborar os nossos resultdos é conveniente utiliar também uma outra medida, a da área sob a curva ROC."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Vamos usar agora um método de medida mais confiável - AUROC - Area sob a curva ROC\n#Geramos as probabilidades das classes na previsão (necessário para a rotina de medida AUROC)\ny_test_prob = rf.predict_proba(test[feats])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pega so uma coluna para efetuar o teste\ny_test_prob = [p[1] for p in y_test_prob]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importando o pacote para a medida da acuracia AUROC\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Medida da acurácia  usando a area sob a curva ROC - AUROC\nroc_auc_score(test['BAD'], y_test_prob) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A medida de acurácia calculada com base na área sob a curva ROC obteve um resultado melhor ainda.\nAbaixo podemos verificar graficamente o formato da curva ROC que explica esse valor de acurácia elevada."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importação de paaotes para plotagem de graficos\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Curva ROC para os dados originais\n\n\nfpr, tpr, threshold = metrics.roc_curve(test['BAD'], y_test_prob)\nroc_auc = metrics.auc(fpr, tpr)\n\n# method I: plt\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n\n#plt.plot(np.linspace(0,1,10), np.linspace(0,1,10), label=\"diagonal\")\n    \nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Para completar a nossa análise, construiremos agora a nossa matriz confusão, ela também permite aferir a qualidade da resposta do modelo."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prevendo os dados para a matriz de confusão\ncnf_matrix = metrics.confusion_matrix(test['BAD'], y_test_pred)\ncnf_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import required modules\n# is scikit's classifier.predict() using 0.5 by default?\n\n#In probabilistic classifiers, yes. It's the only sensible threshold from a mathematical viewpoint, as others have explained.\nimport seaborn as sns \n\n%matplotlib inline\nfig, ax = plt.subplots()\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Matriz Confusão', y=1.1)\nplt.ylabel('Real')\nplt.xlabel('Predito')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Por ultimo geramos o relatorio com medidas da qualidade das predições\nclassific = metrics.classification_report(test['BAD'], y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No relatório abaixo temos mais algumas informações sobre o nosso modelo.\n\nO relatório mostra as principais métricas de classificação com base nas classes de resposta. Ele dá uma percepção mais global sobre a acurácia do modelo e dexa mais claro se ele tem uma performance menor para classes minoritárias."},{"metadata":{},"cell_type":"markdown","source":"Abaixo descrevemos as medidas do relatório:\n\nPrecision - é a habilidade do modelo em não prever um resultado positivo se o valor é realmente negativo. Em cada classe ele é definido como a razão entre os poditivos verdadeiros e a soma dos positivos verdadeiros e falsos.\n\nRecall - é a habilidade do classificador encontrar todas as instancias positivas. Em cada classe é definido como a razão entre os postivos verddeiros e asoma dos verdadeiros positivos e falsos negativos.\n\nF1 score - é a medida harmonica de precision e recall tal que o melhor score é 1.0 e o pior 0.0. Normalmente, F1 score é menor que a acuracia medida pois combina precision e recall. É util para comparar modelos, não como medida global de acuracia.\n\nSupport - número de ocorrencias da classe na base. Desbalanceamento no treinamento da bse pode levar a fraquezas no modelo não reveladas pelo score de acuracia, o que pode justificar uma amostragem estratificada, igualando a proporção de classes  e rebalanceamento. O suporte não muda com o modelo mas dá um diagnostico do processo de avaliação do processo."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classific)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Novamente os nossos resultados se mostraram satisfatórios. A medida \"support\" indica um desbalanceamento.\nAbaixo efetuaremos uma ramostrgem utilziando a rotina SMOTE, que efetua uma interpolação para inserir novas linha d eforma a igualar as classes."},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importação da biblioteca para reamostragem\nfrom imblearn.over_sampling import SMOTE, ADASYN   #reamostragem com a rotina SMOTE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_resampled, y_resampled = SMOTE().fit_resample(train[feats], train['BAD'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_resampled.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nrf2 = RandomForestClassifier(n_jobs=-1, n_estimators=200, oob_score=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Aplicando o RandomForest à base\nrf2.fit(X_resampled, y_resampled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prevendo o BAD para a base com reamostragem SMOTE\ny_test_pred_2 = rf2.predict(test[feats]).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Medida da acurácia\naccuracy_score(test['BAD'], y_test_pred_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos observar uma melhora na medida de acuracia."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Vamos usar agora um método de medida mais confiável - AUROC - Area sob a curva ROC\n#Geramos as probabilidades das classes na previsão (necessário para a rotina de medida AUROC)\ny_test_prob_2 = rf2.predict_proba(test[feats])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pega so uma coluna para efetuar o teste\ny_test_prob_2 = [p[1] for p in y_test_prob_2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Medida da acurácia  usando a area sob a curva ROC - AUROC\nroc_auc_score(test['BAD'], y_test_prob_2) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A medida baseada na area da curva ROC também melhorou."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Curva ROC para os dados reamostrados\n\n\nfpr, tpr, threshold = metrics.roc_curve(test['BAD'], y_test_prob_2)\nroc_auc = metrics.auc(fpr, tpr)\n\n# method I: plt\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n\n#plt.plot(np.linspace(0,1,10), np.linspace(0,1,10), label=\"diagonal\")\n    \nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ao comparar os grafico percebemos algumas pequenas diferencas. A linha da curva se afasta mais cedo do eixo vertical nesse ultimo gráfico, porém a curva se aproxima mais rapidamente do limite superior.\nAS área da curva é ligeiramente superior."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prevendo os dados para a matriz de confusão\ncnf_matrix = metrics.confusion_matrix(test['BAD'], y_test_pred_2)\ncnf_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nfig, ax = plt.subplots()\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Matriz Confusão', y=1.1)\nplt.ylabel('Real')\nplt.xlabel('Predito')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Percebemos que a reamostragem não efetuou grandes mudanças no modelo mas podemos perceber algumas diferenças.\nA quantidade de negativos verdadeiros, celula em azul, teve uma ligeira queda, mas compesnada pelo aumento de verdadeiros positivos."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Geramos o relatorio com medidas da qualidade das predições\nclassific = metrics.classification_report(test['BAD'], y_test_pred_2)\nprint(classific)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusão\n\n\n\nO modelo construido utilizando RandomForest mostrou-se bastate eficaz para o caso. De fato conseguimos obter uma grande acurácia, seja pelo método comum, seja pelo método da área da curva ROC, indicado para classes desbalanceadas.\nPercebemos que, ainda que pequena, a reamostragem efetuada utilzando o método SMOTE, que insere linhas com dados caculados por interpolação, provocou algumas mudanças na performance do modelo.\nA acurácia pelo método comum que verifica a razão de acertos teve uma ligeira melhora. Entretanto, a área sob a curva ROC foi ligeiramente menor. Ao observar os resultados do relatório de classificao, percebemos que caso se queira um maior rigor na concessão de crédito, o segundo modelo se mostra mais adequado, pois a medida \"precision\" é ligeiramente superior, 0.86 contra 0.82, para o caso de clientes com historico ruim quanto ao crédito, o que indica que ele melhor prevê esses casos. O lado negativo é que a previsibilidade de bons clientes piora, 0.92 contra 0.94 do modelo sem reamostragem, o que pode levar a perda de oportunidde de oferecer credito a alguns clientes bons pagadores.\nPor fim, concluimos que os resultados obtidos com o nosso modelo viabilizam a sua utilização como medida para disponibilização de credito ao cliente."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}