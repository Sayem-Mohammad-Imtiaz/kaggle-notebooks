{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://software.intel.com/sites/default/files/managed/fc/32/expanding-possibilities-computer-vision-with-ai-wallpaper.jpg)"},{"metadata":{},"cell_type":"markdown","source":"**Hello Everyone !**\n\n**This is a gentle introductory kernel meant to be a starter's guide to the field of Computer Vision and Image processing in particular.**\n\n**A brief listing of the things we are going to cover in the following kernel -**\n\n**----  Section A  ----**\n\n**1.How images are stored in systems and why they are stored the way they are.**\n\n**2.How to read images and view their sizes,view the images etc.**\n\n**3.How to resize the images in order to fit in specific requirements for training purposes.**\n\n**----  Section B  ----**\n\n**1.The Basics of kernel transformation and multiplication.**\n\n**2.We came across terms like Kernel, Filter and Padding.**\n\n**3.We had an idea about wha Convolutions actually are and how they take place**\n\n**4.We got an idea about how the number of channels of any image can be altered for the purpose of learning important features.**\n\n**----  Section C  ----**\n\n**1.We learn about making a really basic Computer Vision model architecture.**\n\n**2.We then move forward to training the model for the classification problem.**"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"**---- SECTION A ----**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport cv2\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        (os.path.join(dirname, filename));\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/flower-recognition-he/he_challenge_data/data/train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**IMAGES**"},{"metadata":{},"cell_type":"markdown","source":"The way we see the images and the way machines store images in their memories are very different.\n\nAn image is basically a **collection of various pixels** (Picture Elements), which are the smallest parts and which collectively make up the image as we see it."},{"metadata":{},"cell_type":"markdown","source":"**Primary Colours** - Red, Green and Blue"},{"metadata":{},"cell_type":"markdown","source":"![](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c2/AdditiveColor.svg/2000px-AdditiveColor.svg.png)"},{"metadata":{},"cell_type":"markdown","source":"The most common way of storing these images are in form of **arrays of numbers**, where these numbers represent the different levels of activations of the primary colours,i.e, Red, Green and Blue (RGB).\n\nThe images are usually stored in the **RGB format** because these are the primary colours and any colour can then be generated from these colours by varying the activations of these colours.\n\nIn a nutshell, **there are 3 different 2D arrays, each corresponding to one colour out of RGB.**\n\nPS: There are other ways of storing/representing an image too, which we can consider while going into the depths of image processing."},{"metadata":{},"cell_type":"markdown","source":"**Reading an Image**"},{"metadata":{},"cell_type":"markdown","source":"Here we use the **OpenCV library** to read in the images and then view them and we try to make small tweaks and manipulations to it."},{"metadata":{"trusted":true},"cell_type":"code","source":"img=cv2.imread('../input/flower-recognition-he/he_challenge_data/data/train/12.jpg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets have a look at the **shape** of the image."},{"metadata":{"trusted":true},"cell_type":"code","source":"img.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So the image we have here is of the shape **(500,500,3)** , which means, there are **three 2D matrices of size (500,500)** , each for every colour from Red, Green and Blue."},{"metadata":{},"cell_type":"markdown","source":"Lets have a look at the image."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we can **resize** the images as per our own needs using the resize() function of OpenCV.\n\nThe **bigger the size of the images, more is the level of detailing** in them and hence, more is the computational expense required to process these images.\n\nThus, due to resource limitations, generally we work with images of sizes below (300,300) and images bigger than these sizes are resized to fit the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(cv2.resize(img, (50,50)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is the same image which has been aggressively scaled down to a lower size, leading to huge **information/detail loss** as is clearly visible from the image above."},{"metadata":{},"cell_type":"markdown","source":"Just a recap of what we have already covered -\n\n1.How images are stored in systems and why they are stored the way they are.\n\n2.How to read images and view their sizes,view the images etc.\n\n3.How to resize the images in order to fit in specific requirements for training purposes.\n\n\nNow, we will move forward to making a very basic Convolution architecture for training on these images and to get going towards solving a classification problem."},{"metadata":{},"cell_type":"markdown","source":"**---- SECTION B ----**"},{"metadata":{},"cell_type":"markdown","source":"**CNN Basics**"},{"metadata":{},"cell_type":"markdown","source":"Now, before diving right into making a model and classifying the images, lets have a brief idea about how CNN models actually work."},{"metadata":{},"cell_type":"markdown","source":"So, as we have discussed above, there are 2D matrices which we are going to refer to as '**channels**' from here forth.\n\nNow, every channel undergoes an affine transformation using a kernel which is another 2D matrix of a smaller size. \n\n**The steps of the transformation are as follows -** \n\n1.The kernel gets **multiplied with a matrix** of the same size from the channel, giving **one scalar value** as output. \n\n2.This kernel then **shifts sidewards/downwards** to another set of numbers from the channel of the same size as the kernel and **another scalar is generated.**\n\n3.This repeatedly takes place until all such possible smaller matrices are multiplied with the kernel to produce a **new matrix** made from the scalars generated.\n\nA visual representation of the entire procedure is shown below -"},{"metadata":{},"cell_type":"markdown","source":"![](https://mlnotebook.github.io/img/CNN/convExample.png)"},{"metadata":{},"cell_type":"markdown","source":"A complete animated visual of the process for clearer understanding is given below.\n"},{"metadata":{},"cell_type":"markdown","source":"![](https://miro.medium.com/max/526/1*GcI7G-JLAQiEoCON7xFbhg.gif)"},{"metadata":{},"cell_type":"markdown","source":"**Gentle Introduction to the Concept of 'Padding' - **"},{"metadata":{},"cell_type":"markdown","source":"The most obvious observation here is that the **size of the resulting matrix is smaller than the matrix we started out with**.\n\nWe started out with a (5,5) matrix and ended up having a (3,3) matrix as output after the operation.\n\nThis leads to some **information loss** and here comes into the picture a technique known as \"**Padding**\", which is used to conserve the size of the original matrix.\n\nWhat padding does is it adds additional cells across the border of the original matrix so that when the kernel multiplication takes place, we still end up with the same size of output matrix.\n\nA visual representation of the padding concept is given below - \n"},{"metadata":{},"cell_type":"markdown","source":"![](http://deeplearning.net/software/theano_versions/dev/_images/same_padding_no_strides.gif)"},{"metadata":{},"cell_type":"markdown","source":"So, now we have a matrix of the same size as our input matrix."},{"metadata":{},"cell_type":"markdown","source":"**Extending this knowledge to multiple channels**"},{"metadata":{},"cell_type":"markdown","source":"Moving forward to the next most important thing, we discussed above the way one particular channel undergoes the matrix multiplication process to generate an output channel.\n\nNow, as we know, an image is generally consists of more than one channels ( unless it is a greyscale image, in which case it has 1 channel only ).\n\nSo, now we need to extend the above knowledge of kernel multiplication to Three and greater dimensions."},{"metadata":{},"cell_type":"markdown","source":"**Introduction to Filters**"},{"metadata":{},"cell_type":"markdown","source":"Here comes another term known as 'Filter', which is quite frequently used with the term 'kernel'.\n\nFor clarification, the multiple kernels combine to form what is known as a 'filter'.\n\nSo, for the processing of say a matrix which has 3 channels, we would need 3 kernels, one for each.\n\nNow, these 3 kernels collectively make One Filter."},{"metadata":{},"cell_type":"markdown","source":"Lets look at the entire process and break them step wise."},{"metadata":{},"cell_type":"markdown","source":"**Step 1 -\n**\n\nThese 3 kernels act on the 3 different channels of the image, giving out 3 matrices as output as shown in the representation below -"},{"metadata":{},"cell_type":"markdown","source":"![](https://miro.medium.com/max/1166/1*8dx6nxpUh2JqvYWPadTwMQ.gif)"},{"metadata":{},"cell_type":"markdown","source":"**Step 2 -**\n\nAll the elements in the layers formed now are added up to give one channel "},{"metadata":{},"cell_type":"markdown","source":"![](https://jie-tao.com/wp-content/uploads/2019/02/stardard-convolution-multi-channel2.gif)"},{"metadata":{},"cell_type":"markdown","source":"Thus, as we can see, **one filter yields us one channel**.\n\nSo, in case we want a Nf number of output channels, all we need to do is, take an image with say Ni input channels, and make Nf filters each consisting of multiple kernels."},{"metadata":{},"cell_type":"markdown","source":"One last thing before we move forward to making our first model, since in our case we are trying to classify the images into 102 clases, we would want our model to finally give us out 102 values which we would then give as an input to the **SoftMax**^ layer, which would then give as output the probabilities of the image belonging to each class.\n\n**^** - For now, we can see the SoftMax layer as being a layer which takes as input the numbers generated from the model and converts them into **probabilities** of each of the classes."},{"metadata":{},"cell_type":"markdown","source":"**Beore going any further, lets have a recap of what we have discussed in this section of the kernel -**\n\n1.The Basics of kernel transformation and multiplication.\n\n2.We came across terms like Kernel, Filter and Padding.\n\n3.We had an idea about wha Convolutions actually are and how they take place\n\n4.We got an idea about how the number of channels of any image can be altered for the purpose of learning important features."},{"metadata":{},"cell_type":"markdown","source":"**---- SECTION C ----**"},{"metadata":{},"cell_type":"markdown","source":"**GETTING OUR HANDS DIRTY MAKING A VERY BASIC MODEL**"},{"metadata":{},"cell_type":"markdown","source":"Making a very simple model using FastAI"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing the libraries\nfrom fastai.vision import *\nfrom fastai.vision.models import *\nfrom fastai.vision.learner import model_meta","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, the parameters represent these in the same order - \n\n1.Number of input channels\n\n2.Number of Output Channels\n\n3.Kernel Size (3,3 or 5,5 are the general used sizes)\n\n4.Stride (We haven't discussed this yet, so we can consider this to be a default parameter )\n\n5.Padding."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = nn.Sequential(\n        nn.Conv2d(3,8,kernel_size=3,stride=2,padding=2), #8*250*250\n        nn.BatchNorm2d(8),\n        nn.ReLU(),\n        \n        nn.Conv2d(8,16,kernel_size=3,stride=2,padding=2), #16*125*125\n        nn.BatchNorm2d(16),\n        nn.ReLU(),\n        \n        nn.Conv2d(16,32,kernel_size=3,stride=2,padding=2), #32*63*63\n        nn.BatchNorm2d(32),\n        nn.ReLU(),\n    \n        nn.Conv2d(32,64,kernel_size=3,stride=2,padding=2), #64*32*32\n        nn.BatchNorm2d(64),\n        nn.ReLU(),\n    \n        nn.Conv2d(64,128,kernel_size=3,stride=2,padding=2), #128*16*16\n        nn.BatchNorm2d(128),\n        nn.ReLU(),\n            \n        nn.Conv2d(128,256,kernel_size=3,stride=2,padding=2), #256*8*8\n        nn.BatchNorm2d(256),\n        nn.ReLU(),\n    \n        nn.Conv2d(256,128,kernel_size=3,stride=2,padding=2), #128*4*4\n        nn.BatchNorm2d(128),\n        nn.ReLU(),\n        \n        nn.Conv2d(128,102,kernel_size=3,stride=2,padding=2), #102*2*2\n        nn.BatchNorm2d(102),\n        nn.ReLU(),\n    \n        nn.Conv2d(102,102,kernel_size=3,stride=2,padding=2), #102*1*1\n        nn.BatchNorm2d(102),\n        Flatten()        \n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets have a look at the model..."},{"metadata":{"trusted":true},"cell_type":"code","source":"model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Setting up the path to the images folder and initialising the ImageDataBunch.\n\nNow, as we know the images are stored in a separate folder and the labels are stored separately in a CSV named 'train.csv'.\n\n**So, the prime function of the ImageDataBunch class is to -**\n\n1.Read the rows from the train.csv\n\n2.Pick up the image corresponding to the name in the train.csv from the train images directory and send it to the model for training purposes.\n\n3.Once an epoch is complete, it again restarts the epoch and keeps on providing the model a continued flow of images throughout."},{"metadata":{"trusted":true},"cell_type":"code","source":"path = pathlib.Path('../input/flower-recognition-he/he_challenge_data/data/');path.ls()\nnp.random.seed(20)\ndata = ImageDataBunch.from_csv(path, folder='train', csv_labels='train.csv',suffix='.jpg',\n                               valid_pct=0.15, test='test',\n                               size=128,bs = 64)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Parameters - \n**\n\n1.'**valid_pct**' represents that we are making 15% of our total train set as our validation set.\n\n2.**Size** corresponds to the size of the input images.\n\nThe image is **scaled** to the mentioned size before passing it into the model for training purposes.\n\n3.**bs is the Batch Size**, i.e, how many number of images go into the model for training at once.\n\nSince due to computational resources limitation, the model can't work on all the images at once, so, we have **batches** of images which are sequentially generated by the ImageDataBunch class and sent to the model for training purposes.\n"},{"metadata":{},"cell_type":"markdown","source":"Defining a learner object in order to train the model and giving it the Data and the Model to work with and giving it a metric for evaluation purposes."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = Learner(data,model,metrics=[accuracy])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here's a summary of the model we are going to train on the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training the Model...**"},{"metadata":{},"cell_type":"markdown","source":"Now we can finally call the fit() function in order to start training the model on our images.\n\nWe can see the performance of our model using the \"**Validation Loss**\" as well as the \"**Accuracy**\" column in the training report generated."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus, this was all about the basics of the functioning of CNN and making a very basic CNN model for Image Classification."},{"metadata":{},"cell_type":"markdown","source":"**Now that we have reached the end of the kernel, I am assuming you liked the kernel, since you didnt close it mid-way.**\n\n**If you did like it, please UPVOTE the kernel. That keeps me going !**\n\n**Any suggestions and criticism are welcome.**\n\n**Also, feel free to ask for clarifications in case some part of the kernel is not clear as you might want it to be**\n\n**Cheers !**"},{"metadata":{},"cell_type":"markdown","source":"**PS: After going through this basic tutorial, MNIST dataset would be a really great place to start off for beginners.**"},{"metadata":{},"cell_type":"markdown","source":"**PPS: For a more advanced approach towards Image classification and using State of the Art techniques do have a look at this kernel -\n**\n\nhttps://www.kaggle.com/sandeeppat/ship-classification-top-3-5-kernel"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}