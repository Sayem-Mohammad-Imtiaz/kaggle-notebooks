{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/judicial-expenditures-across-all-50-states/jeee16t08.csv',index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(df.index[0],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns = ['Population_2016','Total_justice_system_PC','Police_Protection_PC','Judicial_and_legal_PC','Corrections_PC','Total_justice_system_Employment','police_protection_Total_Employment','police_protection_Sworn_only_Employment','Judicial_and_legal_Employment','Corrections_Employment']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='Total_justice_system_PC',y='Population_2016',data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\ndf_scaled = scaler.fit_transform(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA()\npca.fit(df_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_ratio_.round(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nplt.plot(range(1,11),pca.explained_variance_ratio_.cumsum(),marker='o',linestyle='--')\nplt.title(\"Explained Variance by components\")\nplt.xlabel(\"Number of components\")\nplt.ylabel(\"cumulative explained variance\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The graph shows the amount of variance captured (on the y-axis) depending on the number of components we include (the x-axis). A rule of thumb is to preserve around 80 % of the variance. So, in this instance, we decide to keep 3 components."},{"metadata":{},"cell_type":"markdown","source":"For our data set, that means 3 principal components:"},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.fit(df_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.transform(df_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_pca = pca.transform(df_scaled)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We’ll incorporate the newly obtained PCA scores in the K-means algorithm. That’s how we can perform segmentation based on principal components scores instead of the original features."},{"metadata":{},"cell_type":"markdown","source":"#### Determine no of clusters for K means"},{"metadata":{},"cell_type":"markdown","source":"we run the algorithm with a different number of clusters. Then, we determine the Within Cluster Sum of Squares or WCSS for each solution. Based on the values of the WCSS and an approach known as the Elbow method, we make a decision about how many clusters we’d like to keep."},{"metadata":{},"cell_type":"markdown","source":"#### K Means Clustering using PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"wcss = []\nfor i in range(1,21):\n    kmeans_pca = KMeans(n_clusters=i,init='k-means++',random_state=42)\n    kmeans_pca.fit(scores_pca)\n    wcss.append(kmeans_pca.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nplt.plot(range(1,21),wcss,marker='o',linestyle='--')\nplt.xlabel('no of clusters')\nplt.ylabel('WCSS')\nplt.title('Kmeans with PCA Clustering')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And from this graph, we determine the number of clusters we’d like to keep. To that effect, we use the Elbow-method. The approach consists of looking for a kink or elbow in the WCSS graph. Usually, the part of the graph before the elbow would be steeply declining, while the part after it – much smoother. In this instance, the kink comes at the 4 clusters mark. So, we’ll be keeping a four-cluster solution."},{"metadata":{"trusted":true},"cell_type":"code","source":"# no of clusters =4\nkmeans_pca = KMeans(n_clusters=4,init='k-means++',random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans_pca.fit(scores_pca)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KMeans Clustering with PCA results"},{"metadata":{"trusted":true},"cell_type":"code","source":"#We create new dataframe with original Features and PCA scores and assigned clusters\ndf_pca_seg_Kmeans = pd.concat([df.reset_index(drop=True),pd.DataFrame(scores_pca)],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pca_seg_Kmeans.columns.values[-3:] = ['component_1','component_2','component_3']\ndf_pca_seg_Kmeans['Segment_KMeans_PCA'] =kmeans_pca.labels_ ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pca_seg_Kmeans['Segment'] = df_pca_seg_Kmeans['Segment_KMeans_PCA'].map({0:'First',1:'Second',2:'Third',3:'Fourth'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing the components"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_axis = df_pca_seg_Kmeans['component_2']\ny_axis = df_pca_seg_Kmeans['component_1']\n\nplt.figure(figsize=(12,8))\nsns.scatterplot(x_axis,y_axis,hue=df_pca_seg_Kmeans['Segment'],palette=['g','r','c','m'])\nplt.title('Clusters by PCA Components')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"when we employ PCA prior to using K-means we can visually separate almost the entire data set. That was one of the biggest goals of PCA – to reduce the number of variables by combining them into bigger, more meaningful features.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.copy()\ndf1.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pca_seg_Kmeans['State'] = df1['State']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pca_seg_Kmeans[df_pca_seg_Kmeans['Segment']=='First']['State']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pca_seg_Kmeans[df_pca_seg_Kmeans['Segment']=='Second']['State']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pca_seg_Kmeans[df_pca_seg_Kmeans['Segment']=='Third']['State']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pca_seg_Kmeans[df_pca_seg_Kmeans['Segment']=='Fourth']['State']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='Total_justice_system_PC',y='Population_2016',hue='Segment',data=df_pca_seg_Kmeans)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}