{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". format(sys.version))\n\nimport pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\nprint(\"pandas version: {}\". format(pd.__version__))\n\nimport matplotlib as mpl #collection of functions for scientific and publication-ready visualization\nprint(\"matplotlib version: {}\". format(mpl.__version__))\n\nimport numpy as np #foundational package for scientific computing\nprint(\"NumPy version: {}\". format(np.__version__))\n\nimport scipy as sp #collection of functions for scientific computing and advance mathematics\nprint(\"SciPy version: {}\". format(sp.__version__)) \n\nimport pandas_profiling as pp #utility to autoprofile the dataset\nprint(\"Pandas Profiling version: {}\". format(pp.__version__)) \n\nimport seaborn as sns #ultimate utility for visualizations\nprint(\"Seaborn version: {}\". format(sns.__version__)) \n\nimport IPython\nfrom IPython import display #pretty printing of dataframes in Jupyter notebook\nprint(\"IPython version: {}\". format(IPython.__version__)) \n\nimport sklearn #collection of machine learning algorithms\nprint(\"scikit-learn version: {}\". format(sklearn.__version__))\n\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n#misc libraries\nfrom pandas import Series,DataFrame\nimport matplotlib.pyplot as plt\nimport random\nfrom datetime import datetime, timedelta\n\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nprint('-'*80)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Configure the defaults for the Notebook\nfrom IPython.core.interactiveshell import InteractiveShell  \nInteractiveShell.ast_node_interactivity = \"all\"\n\n#Configure Visualization Defaults\n%matplotlib inline \nmpl.style.use('ggplot')\nsns.set_style('ticks')\npd.set_option('display.max_rows',20000, 'display.max_columns',100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the data block, change the input DIR and work on loading the data\ninput_DIR ='../input/20200306-01'\n\nimport os\n\nfor dirname, _, filenames in os.walk(input_DIR):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        #print(\"{}=pd.read_csv('{}')\".format(filename.split(\"_\")[-1].split(\".\")[0],os.path.join(dirname, filename)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the Raw Data from \nimport json\nimport urllib\n\ndef loadRawData(url,node):\n    operUrl = urllib.request.urlopen(url)\n    if(operUrl.getcode()==200):\n       data = operUrl.read()\n       jsonData = json.loads(data)\n       to_return=pd.DataFrame(data=jsonData[node],dtype='object')\n    else:\n       print(\"Error receiving data\", operUrl.getcode())\n    return to_return\n\nrawData=loadRawData(\"https://raw.githubusercontent.com/covid19india/api/master/raw_data.json\",\"raw_data\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rawData.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Clean up the Raw Data \n#rawData.columns\nrawData=rawData[['patientnumber', 'statepatientnumber', 'agebracket','detecteddistrict','detectedcity', \n        'detectedstate', 'currentstatus','statuschangedate', 'dateannounced',\n       'estimatedonsetdate', 'gender', 'nationality','contractedfromwhichpatientsuspected', \n        'source1', 'source2', 'source3',\n        'notes']]\n\nrawData.index=rawData['patientnumber']\n\nif 'patientnumber' in rawData.columns:\n    rawData.drop('patientnumber', axis='columns',inplace=True)\n\nrawData=rawData.replace(\"\",np.nan)\n\nrawData.drop(index=rawData[rawData.detectedstate.isna()].index,inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rawData.rename({'statepatientnumber':'PatientId','agebracket':'Age','detecteddistrict':'District','detectedcity':'City','detectedstate':'State/UT','currentstatus':'Status','dateannounced':'AnnouncedDate',\n               'estimatedonsetdate':'OnsetDate','gender':'Gender','nationality':'Nationality','contractedfromwhichpatientsuspected':'SourcePatient','statuschangedate':'StatusChangeDate'}, axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#List all records where district is null\nrawData.AnnouncedDate=pd.to_datetime(rawData.AnnouncedDate, format='%d/%m/%Y')\nrawData.OnsetDate=pd.to_datetime(rawData.OnsetDate, format='%d/%m/%Y')\nrawData.StatusChangeDate=pd.to_datetime(rawData.StatusChangeDate, format='%d/%m/%Y')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Validate that there are no issues with RawData for the dates conversion\nfrom datetime import datetime \nrawData[rawData.AnnouncedDate >= datetime.now()]\nrawData[rawData.AnnouncedDate.isna()]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Statewise data\ndCases=rawData.groupby(by=['State/UT','AnnouncedDate'],as_index=False)['Status'].count()\ndCases.rename({'Status':'Reported'},axis=1,inplace=True)\ntmp=rawData[rawData.Status=='Recovered']\ndCasesRecovered=tmp.groupby(by=['State/UT','StatusChangeDate'],as_index=False)['Status'].count()\ndCasesRecovered.rename({'Status':'Recovered'},axis=1,inplace=True)\ntmp=rawData[rawData.Status=='Deceased']\ndCasesDeceased=tmp.groupby(by=['State/UT','StatusChangeDate'],as_index=False)['Status'].count()\ndCasesDeceased.rename({'Status':'Deceased'},axis=1,inplace=True)\n\ntmp=dCases.merge(dCasesRecovered,left_on=['State/UT','AnnouncedDate'],right_on=['State/UT','StatusChangeDate'],how='outer',indicator=True)\n \ntmp['AnnouncedDate']=tmp.apply((lambda x: (x['AnnouncedDate']) if (x['AnnouncedDate'] is not pd.NaT) else (x['StatusChangeDate'])),axis=1)\n\ndCases=tmp[['State/UT', 'AnnouncedDate', 'Reported', 'Recovered']]\n\ntmp=dCases.merge(dCasesDeceased,left_on=['State/UT','AnnouncedDate'],right_on=['State/UT','StatusChangeDate'],how='outer',indicator=True)\ntmp['AnnouncedDate']=tmp.apply((lambda x: (x['AnnouncedDate']) if (x['AnnouncedDate'] is not pd.NaT) else (x['StatusChangeDate'])),axis=1)\n\ndCases=tmp[['State/UT', 'AnnouncedDate', 'Reported', 'Recovered','Deceased']]\n\ndCases.replace(to_replace=np.nan, value=0,inplace=True)\n\nprint(\"Check - Reported:{} Recovered:{} Deceased:{}\".format(dCases.Reported.sum(),dCases.Recovered.sum(),dCases.Deceased.sum()))\ndCases","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dCases=dCases.sort_values(by=['State/UT','AnnouncedDate']).reset_index(drop=True)\ndCases['TotalReported']=dCases['TotalRecovered']=dCases['TotalDeceased']=0\nfor i in dCases.index:\n    if(i==0):\n        dCases.loc[i,'TotalReported']=dCases.loc[i,'Reported']\n        dCases.loc[i,'TotalRecovered']=dCases.loc[i,'Recovered']\n        dCases.loc[i,'TotalDeceased']=dCases.loc[i,'Deceased']\n        \n    elif( dCases.loc[i,'State/UT']==dCases.loc[i-1,'State/UT']):\n        dCases.loc[i,'TotalReported']=dCases.loc[i-1,'TotalReported'] + dCases.loc[i,'Reported']\n        dCases.loc[i,'TotalRecovered']=dCases.loc[i-1,'TotalRecovered'] + dCases.loc[i,'Recovered']\n        dCases.loc[i,'TotalDeceased']=dCases.loc[i-1,'TotalDeceased'] + dCases.loc[i,'Deceased']\n    \n    else:\n        dCases.loc[i,'TotalReported']=dCases.loc[i,'Reported']\n        dCases.loc[i,'TotalRecovered']=dCases.loc[i,'Recovered']\n        dCases.loc[i,'TotalDeceased']=dCases.loc[i,'Deceased']\n\ndCases['TotalActive']=dCases.TotalReported - dCases.TotalRecovered - dCases.TotalDeceased \n\nprint(\"Check - Reported:{} Recovered:{} Deceased:{}\".format(dCases.Reported.sum(),dCases.Recovered.sum(),dCases.Deceased.sum()))\nprint(\"Check - Reported:{} Recovered:{} Deceased:{}\".format(\n                                        dCases.groupby(by=['State/UT'])['TotalReported'].max().sum(),\n                                        dCases.groupby(by=['State/UT'])['TotalRecovered'].max().sum(),\n                                        dCases.groupby(by=['State/UT'])['TotalDeceased'].max().sum(),\n                                        ))\ndCases","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t=dCases[['State/UT', 'AnnouncedDate', 'TotalReported', 'TotalRecovered', 'TotalDeceased', 'TotalActive']]\nlstdf=[]\nfor eachStateUT in t['State/UT'].unique():\n    tmp0=t[t['State/UT']==eachStateUT]\n    minDate=tmp0.AnnouncedDate.min()\n    maxDate=datetime.now()\n    df=pd.DataFrame(np.arange(minDate,maxDate, timedelta(days=1)),columns=['AnnouncedDate'])\n    tmp1= pd.merge_ordered(left=df,right=tmp0,on='AnnouncedDate', how='outer',fill_method='ffill')\n    lstdf+=[tmp1]\ndfTotals=pd.concat(lstdf, ignore_index=True)\n\nprint(\"Check - Reported:{} Recovered:{} Deceased:{}\".format(\n                                        t.groupby(by=['State/UT'])['TotalReported'].max().sum(),\n                                        t.groupby(by=['State/UT'])['TotalRecovered'].max().sum(),\n                                        t.groupby(by=['State/UT'])['TotalDeceased'].max().sum(),\n                                        ))\n#dfTotals.groupby(by=['AnnouncedDate'])['TotalReported','TotalRecovered','TotalDeceased','TotalActive'].sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Accomodate for the reporting model changed by Covid19India.org from 29th of March 2020\ndfTemp=pd.read_csv('../input/20200414dr01/20200414dr01.csv',dtype='object')\ndfTemp.Date=pd.to_datetime(dfTemp.Date,format='%d-%m-%Y')\ndfTemp.fillna(0,inplace=True)\ndfTemp['Recovered']=dfTemp['Recovered'].astype(str).astype(int)\ndfTemp['Deceased']=dfTemp['Deceased'].astype(str).astype(int)\ndfTemp=dfTemp.sort_values(by=['State','Date']).reset_index(drop=True)\ndfTemp['TotalRecovered']=dfTemp['TotalDeceased']=0\nfor i in dfTemp.index:\n    if(i==0):\n        dfTemp.loc[i,'TotalRecovered']=dfTemp.loc[i,'Recovered']\n        dfTemp.loc[i,'TotalDeceased']=dfTemp.loc[i,'Deceased']\n    elif( dfTemp.loc[i,'State']==dfTemp.loc[i-1,'State']):\n        dfTemp.loc[i,'TotalRecovered']=dfTemp.loc[i-1,'TotalRecovered'] + dfTemp.loc[i,'Recovered']\n        dfTemp.loc[i,'TotalDeceased']=dfTemp.loc[i-1,'TotalDeceased'] + dfTemp.loc[i,'Deceased']\n    else:\n        dfTemp.loc[i,'TotalRecovered']=dfTemp.loc[i,'Recovered']\n        dfTemp.loc[i,'TotalDeceased']=dfTemp.loc[i,'Deceased']\nprint(\"Check - Recovered:{} Deceased:{}\".format(dfTemp.Recovered.sum(),dfTemp.Deceased.sum()))\nprint(\"Check - Recovered:{} Deceased:{}\".format(\n                                        dfTemp.groupby(by=['State'])['TotalRecovered'].max().sum(),\n                                        dfTemp.groupby(by=['State'])['TotalDeceased'].max().sum(),\n                                        ))\nt=dfTemp[['State','Date','TotalRecovered','TotalDeceased']]\nlstdf=[]\nfor eachStateUT in t['State'].unique():\n    tmp0=t[t['State']==eachStateUT]\n    minDate=tmp0.Date.min()\n    maxDate=dfTotals.AnnouncedDate.max() + timedelta(days=1)\n    #print(\"minDate:{} maxDate:{}\".format(minDate,maxDate))\n    df=pd.DataFrame(np.arange(minDate,maxDate, timedelta(days=1)),columns=['Date'])\n    tmp1= pd.merge_ordered(left=df,right=tmp0,on='Date', how='outer',fill_method='ffill')\n    lstdf+=[tmp1]\ndfTemp=pd.concat(lstdf, ignore_index=True)\ndfTemp=dfTemp.sort_values(by=['State','Date']).reset_index(drop=True)\nprint(\"Check - Recovered:{} Deceased:{}\".format(\n                                        dfTemp.groupby(by=['State'])['TotalRecovered'].max().sum(),\n                                        dfTemp.groupby(by=['State'])['TotalDeceased'].max().sum(),\n                                        ))\ntmp=dfTotals.merge(right=dfTemp,left_on=['AnnouncedDate','State/UT'],right_on=['Date','State'],indicator=True,how='outer')\ntmp.TotalRecovered_x=tmp.apply((lambda x:x['TotalRecovered_y'] if (x['TotalRecovered_y'] >0) else (x['TotalRecovered_x'])),axis=1)\ntmp.TotalDeceased_x=tmp.apply((lambda x:x['TotalDeceased_y'] if (x['TotalDeceased_y'] >0) else (x['TotalDeceased_x'])),axis=1)\n#tmp[tmp.TotalRecovered_y.notna()].TotalRecovered_x = tmp[tmp.TotalRecovered_y.notna()].TotalRecovered_y\n#tmp\nprint(\"Check - Recovered:{} Deceased:{}\".format(\n                                        tmp.groupby(by=['State/UT'])['TotalRecovered_x'].max().sum(),\n                                        tmp.groupby(by=['State/UT'])['TotalDeceased_x'].max().sum(),\n                                        ))\n\ntmp.rename({'TotalRecovered_x':'TotalRecovered','TotalDeceased_x':'TotalDeceased'},axis=1,inplace=True)\ndfTotals=tmp[['AnnouncedDate', 'State/UT', 'TotalReported', 'TotalRecovered','TotalDeceased']]\ndfTotals['TotalActive']=dfTotals.TotalReported - dfTotals.TotalRecovered - dfTotals.TotalDeceased\nprint(\"Check - Reported:{} Recovered:{} Deceased:{}\".format(\n                                        dfTotals.groupby(by=['State/UT'])['TotalReported'].max().sum(),\n                                        dfTotals.groupby(by=['State/UT'])['TotalRecovered'].max().sum(),\n                                        dfTotals.groupby(by=['State/UT'])['TotalDeceased'].max().sum(),\n                                        ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(ncols=2,nrows=1,figsize=(16,4))\nax[0].title.set_text('Linear Plat Cases vs Time')\ndfTotals.groupby(by=['AnnouncedDate'])['TotalReported','TotalRecovered','TotalDeceased','TotalActive'].sum().plot(ax=ax[0])\nax[1].set_yscale('log')\ndfTotals.groupby(by=['AnnouncedDate'])['TotalReported','TotalRecovered','TotalDeceased','TotalActive'].sum().plot(ax=ax[1])\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The above graph shows that if data after 9th of March is considered then from there onwards Corona Cases in India follow a log-linear pattern i.e. almost a straight line. Let us take note of it, validate with one or two more states data and then try to predict cases using Log-Linear Regression\n**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Total Cases Datewise \nfig = px.bar(dfTotals, y='TotalReported', x='AnnouncedDate',hover_data =['State/UT','TotalActive','TotalRecovered','TotalDeceased'], color='TotalReported',height=600)\nfig.update_layout(\n    title='Total Cases Datewise in India')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp=dfTotals[(dfTotals['State/UT']=='Maharashtra') & (dfTotals.AnnouncedDate >= '2020-03-09')]\nfig, ax = plt.subplots(ncols=2,nrows=1,figsize=(16,4))\nax[0].title.set_text('Maharashtra: Linear Plot Cases vs Time')\ntmp.groupby(by=['AnnouncedDate'])['TotalReported','TotalRecovered','TotalDeceased','TotalActive'].sum().plot(ax=ax[0])\nax[1].set_yscale('log')\nax[1].title.set_text('Maharashtra: Log-Linear Plot Cases vs Time')\ntmp.groupby(by=['AnnouncedDate'])['TotalReported','TotalRecovered','TotalDeceased','TotalActive'].sum().plot(ax=ax[1])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp=dfTotals[(dfTotals['State/UT']=='Kerala') & (dfTotals.AnnouncedDate >= '2020-03-09')]\nfig, ax = plt.subplots(ncols=2,nrows=1,figsize=(16,4))\nax[0].title.set_text('Kerala: Linear Plot Cases vs Time')\ntmp.groupby(by=['AnnouncedDate'])['TotalReported','TotalRecovered','TotalDeceased','TotalActive'].sum().plot(ax=ax[0])\nax[1].set_yscale('log')\nax[1].title.set_text('Kerala: Log-Linear Plot Cases vs Time')\ntmp.groupby(by=['AnnouncedDate'])['TotalReported','TotalRecovered','TotalDeceased','TotalActive'].sum().plot(ax=ax[1])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(ncols=2,nrows=1,figsize=(16,4))\nax[0].title.set_text('All States : Linear Plot Cases vs Time')\ntmp=dfTotals[dfTotals.AnnouncedDate >= '2020-03-09']\nsns.lineplot(data=tmp,x='AnnouncedDate',y='TotalReported', hue='State/UT', ax=ax[0],legend=False)\nax[1].set_yscale('log')\nax[1].title.set_text('All States : Log-Linear Plot Cases vs Time')\nsns.lineplot(data=tmp,x='AnnouncedDate',y='TotalReported', hue='State/UT', ax=ax[1],legend=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1. First Predictor - LogLinear Regressor to predict number of Reported Cases in next say 10 days \nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\n\ndtp=10 #next number of days to predict\nminDate='2020-03-09'\ntmp=dfTotals[dfTotals.AnnouncedDate >= minDate ]\ntmp=tmp.groupby(by=['AnnouncedDate'])['TotalReported','TotalRecovered','TotalDeceased','TotalActive'].sum()\n\n#Number of days for the data\nx=np.linspace(1,tmp.shape[0],tmp.shape[0]).reshape(-1,1)\nx_next10=np.linspace(tmp.shape[0] + 1,tmp.shape[0] + dtp,dtp).reshape(-1,1)\n\nyReported=np.log10(tmp.TotalReported.to_numpy())\n\nX_train, X_test, y_trainReported, y_testReported = train_test_split(x, yReported, test_size=0.33, random_state=1)\n\n# Create linear regression object\nregr = linear_model.LinearRegression()\n\n# Train the model using the training sets\nnull=regr.fit(X_train, y_trainReported)\n\n# Make predictions using the testing set\ny_predReported = regr.predict(X_test)\n\ny_next10 = regr.predict(x_next10)\n\n# The coefficients\nprint('Coefficients: \\n', regr.coef_)\n# The mean squared error\nprint('Mean squared error: %.2f'\n      % mean_squared_error(y_testReported, y_predReported))\n# The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n      % r2_score(y_testReported, y_predReported))\n\n# Plot outputs\nfig, ax = plt.subplots(ncols=2,nrows=1,figsize=(16,4))\n\nnull=ax[0].title.set_text('India : Reported Cases on LogLinear Scale')\nnull=ax[0].scatter(x, yReported,  color='black')\nnull=ax[0].scatter(X_test, y_predReported, color='blue')\nnull=ax[0].plot(x_next10, y_next10,  color='red',linewidth=3)\n\nnull=ax[1].title.set_text('India : Reported Cases on Linear Scale')\nnull=ax[1].scatter(x,tmp.TotalReported,color='black')\nnull=ax[1].scatter(X_test, 10**y_predReported, color='blue')\nnull=ax[1].plot(x_next10, 10**y_next10,  color='red',linewidth=3)\n\nplt.show()\nprint(\"Black  - Training Set, Blue - Testing Set, Red - Prediction Set\")\nprint(\"Coefficient of determination: = 0.99 ~ 1 => Perfect Log Linear Relationship, cannot have been better\")\n\nminDate=datetime.strptime(minDate,\"%Y-%m-%d\") + timedelta(days= tmp.shape[0]) \nmaxDate=minDate + timedelta(days=dtp)\n\npredictDf=pd.DataFrame({'PredictionForDate':np.arange(minDate,maxDate, timedelta(days=1)),'Total No. Cases Predicted':10**y_next10})\npredictDf['Total No. Cases Predicted']=predictDf['Total No. Cases Predicted'].round()\npredictDf\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fitting Sigmoid Function to Indian Data\n\n\n                        y = a/(1 + exp(-(days - b)/c))\n\n* a => maximum number of estimated Confirmed Cases that we might expect\n* b => inflection point on the curve that is at the 50th percentile\n* c => slope in the initial phase of Confirmed Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Sigmoid fitting of Indian Data\nfrom scipy import integrate, optimize\nfrom scipy.optimize import curve_fit\n\ndataDf=dfTotals[['AnnouncedDate','TotalReported','TotalDeceased']]\ndataDf=dataDf.groupby(by=['AnnouncedDate'],as_index=False)['TotalReported','TotalDeceased'].sum()\ndataDf['NumDays'] = list(range(1,len(dataDf)+1))\n\n# Mortality Rate using ployfit\nm,b = np.polyfit(dataDf.TotalReported, dataDf.TotalDeceased,1) \nprint('Mortality Rate={:.2f}'.format(m*100))\n\ndef myFunc(days, InfPop, Inflection, c):\n    y = (InfPop/(1+np.exp(-(days-Inflection)/c)))      \n    return y\n\n#fit the data, return the best fit parameters and the covariance matrix\npopt, pcov = curve_fit(myFunc, dataDf['NumDays'], dataDf['TotalReported'])\n\nprint()\nprint(\"Fit parameters:\")\nprint(\"   Max Infected Populatuion =\", popt[0])\nprint(\"   Inflection point in days = \", popt[1])\nprint(\"   c =\" , popt[2])\n\nminDate=dataDf.AnnouncedDate.min()\nprojectionsDf=pd.DataFrame(data=None,columns=tmp.columns)\nprojectionsDf['NumDays'] = list(range(dataDf.NumDays.max() + 1,int(popt[1] * 2 +5),1))\nprojectionsDf.AnnouncedDate= projectionsDf.NumDays.map(lambda x:minDate + timedelta(days=(x-1)))\nprojectionsDf.TotalReported= myFunc(projectionsDf.NumDays, popt[0], popt[1], popt[2])\nprojectionsDf.TotalDeceased= projectionsDf.TotalReported * m\n\nfig=plt.figure(1,figsize=(8, 6))\n\nnull=plt.plot(dataDf.NumDays, dataDf.TotalReported, linewidth=3,label ='Confirmed Cases', color=\"red\" )\nnull=plt.plot(dataDf.NumDays, dataDf.TotalDeceased, linewidth=3,label ='Confirmed Deaths',color='purple')\n\n#overplot the best fit curve\nnull=plt.plot(projectionsDf.NumDays, projectionsDf.TotalReported, \"rs\", label ='Sigmoid Fit',linestyle='dashed')\nnull=plt.plot(projectionsDf.NumDays, projectionsDf.TotalDeceased, linewidth=3,label ='Estimated Deaths' , color='purple', linestyle='dashed')\n\nfor xt,yt in zip(projectionsDf.NumDays[0::10], projectionsDf.TotalDeceased[0::10]):\n    label = \"{:.0f}\".format(yt)\n    null=plt.annotate(label, # this is the text\n                 (xt,yt), # this is the point to label\n                 textcoords=\"offset points\", # how to position the text\n                 xytext=(0,10), # distance from text to points (x,y)\n                 ha='center') # horizontal alignment can be left, right or center\n\nnull= plt.plot(popt[1],popt[0]/2, label ='Inflection Point', marker='o',markerfacecolor='blue', markersize=12)\n#Calculate rate of change in Confirmed Cases\nydiff = np.hstack((0,np.diff(dataDf.TotalReported)*10))\nnull= plt.bar(dataDf.NumDays, ydiff,align='center', alpha=1, color='green', label ='Confirmed Cases Rate of change')\n\nnull= plt.annotate('Inflection Point', color='blue', xy=(popt[1],popt[0]/2),  xycoords='data',\n            xytext=(0.3, 0.6), textcoords='axes fraction',\n            arrowprops=dict(facecolor='blue', shrink=0.05),\n            horizontalalignment='right', verticalalignment='top',\n            )\nnull= plt.annotate('Rate of Change (x10)', color='green', xy=(popt[1],popt[0]/3 ),  xycoords='data',\n            xytext=(0.1, 0.3), textcoords='axes fraction',\n            )\n\nnull=plt.xlim(0,projectionsDf.NumDays.max())\n#plt.ylim(0,max(myFunc(x, popt[0], popt[1], popt[2]))+3000)\nnull=plt.ylim(0,projectionsDf.TotalReported.max()+1000)\nnull=plt.legend(loc='upper left')\nplt.grid(True)\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp=dfTotals.groupby(by=['AnnouncedDate'])['TotalReported','TotalRecovered','TotalDeceased'].sum()\n#DataFrame.pct_change(self: ~FrameOrSeries, periods=1, fill_method='pad', limit=None, freq=None, **kwargs) →\ntmp['%Change']=tmp.TotalReported.pct_change(periods=1) * 100\ntmp['ReportedBy100']= tmp.TotalReported/100\ntmp.drop(labels=['TotalReported','TotalRecovered','TotalDeceased'], axis=1,inplace=True)\ntmp.iloc[59:,:].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the Raw Data from \nimport json\nimport urllib\n\ndef loadRawData(url,node):\n    operUrl = urllib.request.urlopen(url)\n    if(operUrl.getcode()==200):\n       data = operUrl.read()\n       jsonData = json.loads(data)\n       to_return=pd.DataFrame(data=jsonData[node],dtype='object')\n    else:\n       print(\"Error receiving data\", operUrl.getcode())\n    return to_return\n \nstates_daily=loadRawData(\"https://api.covid19india.org/states_daily.json\",\"states_daily\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstColumns = list(states_daily.columns)\nlstColumns.remove(\"date\")\nlstColumns.remove(\"status\")\nlstdf=[]\nprint(lstColumns)\nfor eachCol in lstColumns:\n    tmp=states_daily[[eachCol,'status','date']]\n    tmp['State']=eachCol\n    tmp[eachCol]=tmp[eachCol].replace(to_replace='', value=0)\n    tmp.rename({eachCol:'Count','date':'AnnouncedDate'}, axis=1,inplace=True)\n    tmp.Count=tmp.Count.astype(str).astype(int)\n    tmpConf=tmp[tmp.status=='Confirmed']\n    tmpDece=tmp[tmp.status=='Deceased']\n    tmpReco=tmp[tmp.status=='Recovered']\n    \n    tmpConf.rename({'Count':'Confirmed'}, axis=1,inplace=True)\n    tmpDece.rename({'Count':'Deceased'}, axis=1,inplace=True)\n    tmpReco.rename({'Count':'Recovered'}, axis=1,inplace=True)\n\n    tmp1=tmpConf.merge(right=tmpReco,on='AnnouncedDate',indicator=True,suffixes=('_c', '_r'))\n    tmp1.drop(labels=[\"status_c\",\"status_r\",\"State_r\",\"_merge\"],axis=1,inplace=True)\n    tmp2=tmp1.merge(right=tmpDece,on='AnnouncedDate',indicator=True)\n    tmp2.drop(labels=[\"State_c\",\"status\",\"_merge\"],axis=1,inplace=True)\n    lstdf+=[tmp2]\n    \ndf1=pd.concat(lstdf, ignore_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df1[df1.State!='tt']\ndf1['Confirmed'].sum()\ndf1['Recovered'].sum()\ndf1['Deceased'].sum()\ndf1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}