{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv(\"/kaggle/input/creditcardfraud/creditcard.csv\")\ndata.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data[\"Class\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\ndata['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(['Time','Amount'],axis=1)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#下采样\nX = data.iloc[:, data.columns != 'Class']\ny = data.iloc[:, data.columns == 'Class']\n\n# 得到所有异常样本的索引\nnumber_records_fraud = len(data[data.Class == 1])\nfraud_indices = np.array(data[data.Class == 1].index)\n\n# 得到所有正常样本的索引\nnormal_indices = data[data.Class == 0].index\n\n# 在正常样本中随机采样出指定个数的样本，并取其索引\nrandom_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = False)\nrandom_normal_indices = np.array(random_normal_indices)\n\n# 有了正常和异常样本后把它们的索引都拿到手\nunder_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n\n# 根据索引得到下采样所有样本点\nunder_sample_data = data.iloc[under_sample_indices,:]\n\nX_undersample = under_sample_data.iloc[:, under_sample_data.columns != 'Class']\ny_undersample = under_sample_data.iloc[:, under_sample_data.columns == 'Class']\n\n# 下采样 样本比例\nprint(\"正常样本所占整体比例: \", len(under_sample_data[under_sample_data.Class == 0])/len(under_sample_data))\nprint(\"异常样本所占整体比例: \", len(under_sample_data[under_sample_data.Class == 1])/len(under_sample_data))\nprint(\"下采样策略总体样本数量: \", len(under_sample_data))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\ng = sns.FacetGrid(under_sample_data, col='Class')\ng.map(plt.hist, 'V1', bins=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(under_sample_data, col='Class')\ng.map(plt.hist, 'V9', bins=20) #Cabin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# 整个数据集进行划分\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)\n\nprint(\"原始训练集包含样本数量: \", len(X_train))\nprint(\"原始测试集包含样本数量: \", len(X_test))\nprint(\"原始样本总数: \", len(X_train)+len(X_test))\n\n# 下采样数据集进行划分\nX_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample\n                                                                                                   ,y_undersample\n                                                                                                   ,test_size = 0.2\n                                                                                                   ,random_state = 0)\nprint(\"\")\nprint(\"下采样训练集包含样本数量: \", len(X_train_undersample))\nprint(\"下采样测试集包含样本数量: \", len(X_test_undersample))\nprint(\"下采样样本总数: \", len(X_train_undersample)+len(X_test_undersample))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\noversampler=SMOTE(random_state=0)\nos_features,os_labels=oversampler.fit_sample(X_train,y_train)\nos_features = pd.DataFrame(os_features)\nos_labels = pd.DataFrame(os_labels)\nprint(os_features.shape)\nprint(os_labels.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score, recall_score\nfrom sklearn.metrics import roc_auc_score, recall_score,precision_score\nfrom time import time \nimport datetime\nfrom sklearn.tree import DecisionTreeClassifier\ntimes=time()\n#clf = DecisionTreeClassifier().fit(os_features,os_labels.values.ravel())\nclf = LogisticRegression().fit(X_train,y_train.values.ravel())\nresult = clf.predict(X_test)\nscore = clf.score(X_test,y_test.values.ravel())\nrecall = recall_score(y_test.values.ravel(), result)\nprecision=precision_score(y_test.values.ravel(), result)\nprint(\"testing accuracy %f, recall is %f, precision is %f'\" % (score,recall,precision))\nprint(datetime.datetime.fromtimestamp(time()-times).strftime(\"%M:%S:%f\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, recall_score,f1_score,precision_score\nfrom time import time \nimport datetime\nclf = LogisticRegression(class_weight={1:11}).fit(X_train, y_train.values.ravel())\nresult = clf.predict(X_test)\nscore1 = clf.score(X_test,y_test.values.ravel())\nrecall1 = recall_score(y_test.values.ravel(), result)\nprecision1 = precision_score(y_test.values.ravel(), result)\nf11=f1_score(y_test.values.ravel(), result)\nprint(\"testing accuracy %f, recall is %f,  f1 is %f ,  precision is %f\" % (score1,recall1,f11,precision1))\n#testing accuracy 0.999245, recall is 0.831683,  f1 is 0.796209","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, recall_score\nfrom time import time \nimport datetime\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GridSearchCV,cross_val_score,StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\n#设置kfold，交叉采样法拆分数据集\nkfold=StratifiedKFold(n_splits=10)\ntimes=time()\nsolver = ['liblinear','lbfgs','newton-cg','sag','saga']#返回在对数刻度上均匀间隔的数字\nrange1=range(0,len(solver),1)\nscore = []\nrecall=[]\nroc_auc=[]\nprecision=[]\nf1=[]\nfor i in solver:\n    print(i)\n    clf = LogisticRegression(class_weight={1:11},solver=i)\n    recall.append(cross_val_score(clf,X_train,y_train.values.ravel(),\n                                          scoring='recall',cv=kfold,n_jobs=-1).mean())\n    f1.append(cross_val_score(clf,X_train,y_train.values.ravel(),\n                                          scoring='f1',cv=kfold,n_jobs=-1).mean()) \n    print(datetime.datetime.fromtimestamp(time()-times).strftime(\"%M:%S:%f\"))\n\nplt.plot(range1,recall,c=\"blue\",label=\"recall\")\nplt.plot(range1,f1,c=\"yellow\",label=\"f1\")\nplt.legend(fontsize=\"x-large\")\nplt.show()\nprint(datetime.datetime.fromtimestamp(time()-times).strftime(\"%M:%S:%f\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,recall_score\nfrom sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score\nmatrix = confusion_matrix(y_test, result,labels=[1,0])\nprint(\"混淆矩阵:\\n\", matrix)\nprint(\"精度:\", precision_score(y_test, result))\nprint(\"召回率:\", recall_score(y_test, result))\nprint(\"f1分数:\", f1_score(y_test,result))\nprint(\"准确率\",accuracy_score(y_test, result))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve as ROC\nimport matplotlib.pyplot as plt\nFPR, Recall, thresholds = ROC(y_test,clf.predict_proba(X_test)[:,1],pos_label=1)\narea = roc_auc_score(y_test,clf.predict_proba(X_test)[:,1])\nplt.figure()\nplt.plot(FPR, Recall, color='red',\n         label='ROC curve (area = %0.2f)' % area)\nplt.plot([0, 1], [0, 1], color='black', linestyle='--')\nplt.xlim([-0.05, 1.05])\nplt.ylim([-0.05, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('Recall')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxindex = (Recall - FPR).tolist().index(max(Recall - FPR))\naa=thresholds[maxindex]\nprint(aa)\n\nclf = LogisticRegression(class_weight={1:11}).fit(X_train, y_train.values.ravel())\nprob=clf.predict_proba(X_test)\nprob=pd.DataFrame(prob)\nprob.loc[prob.iloc[:,1] >= aa,\"y_pred\"]=1\nprob.loc[prob.iloc[:,1] < aa,\"y_pred\"]=0\nresult=prob.loc[:,\"y_pred\"].values\nmatrix = confusion_matrix(y_test, result,labels=[1,0])\nprint(\"混淆矩阵:\\n\", matrix)\nprint(\"精度:\", precision_score(y_test, result))\nprint(\"召回率:\", recall_score(y_test, result))\nprint(\"f1分数:\", f1_score(y_test,result))\nprint(\"准确率\",accuracy_score(y_test, result))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\ndef plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    绘制混淆矩阵\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score as AC\nfrom sklearn.metrics import confusion_matrix,recall_score\nfrom sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score\nclf = LogisticRegression(class_weight={1:11}).fit(X_train, y_train.values.ravel())\nprob=clf.predict_proba(X_test)\nprob=pd.DataFrame(prob)\n#print(prob.head())\nthresholds = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nj=1\nplt.figure(figsize=(10,10))\nfor i in thresholds:\n    prob.loc[prob.iloc[:,1] >= i,\"y_pred\"]=1\n    prob.loc[prob.iloc[:,1] < i,\"y_pred\"]=0\n    result=prob.loc[:,\"y_pred\"].values\n    matrix = confusion_matrix(y_test, result,labels=[1,0])\n    print(i)\n    print(\"混淆矩阵:\\n\", matrix)\n    print(\"精度:\", precision_score(y_test, result))\n    print(\"召回率:\", recall_score(y_test, result))\n    print(\"f1分数:\", f1_score(y_test,result))\n    print(\"准确率\",accuracy_score(y_test, result))\n    print(\"-----------\")\n    class_names = [1,0]\n    plt.subplot(3,3,j)\n    j=j+1\n    \n    plot_confusion_matrix(matrix\n                          , classes=class_names\n                          , title='Threshold >= %s'%i) \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}