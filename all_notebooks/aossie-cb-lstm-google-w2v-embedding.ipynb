{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport string\nfrom tqdm import tqdm\nimport math,nltk\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy.sparse import  hstack\n# from handFeaturesV6 import hand_features, clean, get_tokenized_lemmas, remove_stopwords\nimport matplotlib.pyplot as plt\nfrom nltk.stem import SnowballStemmer\nfrom nltk.corpus import stopwords\nfrom gensim.models import Word2Vec\nfrom gensim.models import KeyedVectors\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, concatenate,Flatten,LSTM, Embedding, Input,Dropout\nfrom keras.models import Model\n# from WF_gw2v_embedding import gw2v_sentence_embeddings\nfrom keras.callbacks import ModelCheckpoint\nimport os\nimport re\nimport nltk\nimport string\nimport numpy as np\nfrom sklearn import feature_extraction\nfrom tqdm import tqdm\n\n\n_wnl = nltk.WordNetLemmatizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize_word(w):\n    return _wnl.lemmatize(w).lower()\n\n\ndef get_tokenized_lemmas(s):\n    return [normalize_word(t) for t in nltk.word_tokenize(s)]\n\n\ndef clean(text):\n    # Cleans a string: Lowercasing, trimming, removing non-alphanumeric\n    text = text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation),''))\n    return \" \".join(re.findall(r'\\w+', text, flags=re.UNICODE)).lower()\n\n\ndef remove_stopwords(l):\n    # Removes stopwords from a list of tokens\n    return [w for w in l if w not in feature_extraction.text.ENGLISH_STOP_WORDS]\ndef join_tok(text):\n    return \" \".join(text).lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process(texts):\n    lst=[]\n    for text in tqdm(texts):\n        clean_text= clean(text)\n        tok_text= get_tokenized_lemmas(clean_text)\n        remov_stp= remove_stopwords(tok_text)\n        lst.append(join_tok(remov_stp))\n    return lst","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data= pd.read_csv('../input/aossie-click-bait-dataset/clickBait_Data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titles=  process(data['titles'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tok= Tokenizer()\ntok.fit_on_texts(titles)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size= len(tok.word_index)+1\nembed_len= 300\nembedd_matrix= np.zeros((vocab_size,embed_len))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titles=tok.texts_to_sequences(titles)\ntitles= pad_sequences(titles,maxlen=40,padding='post')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fileName= '../input/googles-trained-word2vec-model-in-python/GoogleNews-vectors-negative300.bin.gz'\nG_w2v = KeyedVectors.load_word2vec_format(fileName, binary=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for word, idx in tok.word_index.items():\n    if word in G_w2v:\n            embedd_matrix[idx]=G_w2v[word][0:embed_len]\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels= data['clickbait'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len=40","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split( titles, labels, test_size=0.3, random_state=42, shuffle= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training Data size: \", X_train.shape[0])\nprint(\"Testing data size: \", X_test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.layers import Dense, Dropout,Embedding,LSTM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model= Sequential()\nmodel.add(Embedding(vocab_size,embed_len,weights= [embedd_matrix],input_length=max_len))\nmodel.add(LSTM(100,return_sequences=True))\nmodel.add(Dense(50,activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(460,activation='relu'))\nmodel.add(Dense(180,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(50,activation='relu'))\nmodel.add(Dense(20,activation='relu'))\nmodel.add(Dense(1,activation='sigmoid'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath=r\"ClickBait-2_lstm_gw2v_weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\ncallbacks_list = [checkpoint]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,y_train,epochs=30,batch_size=3,verbose=1,validation_split=0.02,callbacks=callbacks_list, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction= model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"YClass= np.zeros((len(prediction)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(prediction)):\n    if prediction[i][0]>=0.5:\n        YClass[i]=1\n    else:\n        YClass[i]=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n    \"\"\"\n    given a sklearn confusion matrix (cm), make a nice plot\n\n    Arguments\n    ---------\n    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n\n    target_names: given classification classes such as [0, 1, 2]\n                  the class names, for example: ['high', 'medium', 'low']\n\n    title:        the text to display at the top of the matrix\n\n    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n                  see http://matplotlib.org/examples/color/colormaps_reference.html\n                  plt.get_cmap('jet') or plt.cm.Blues\n\n    normalize:    If False, plot the raw numbers\n                  If True, plot the proportions\n\n    Usage\n    -----\n    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n                                                              # sklearn.metrics.confusion_matrix\n                          normalize    = True,                # show proportions\n                          target_names = y_labels_vals,       # list of names of the classes\n                          title        = best_estimator_name) # title of graph\n\n    Citiation\n    ---------\n    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import itertools\n\n    accuracy = np.trace(cm) / float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()\n    \n#matrix1 = confusion_matrix(test_labels, prediction)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix1 = confusion_matrix(y_test, YClass)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(cm=matrix1,target_names=['Non_ClickBait', 'ClickBait'])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}