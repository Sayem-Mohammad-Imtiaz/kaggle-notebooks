{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport matplotlib.pyplot as plt\nimport statistics \nimport statsmodels.tsa.seasonal as smt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\nimport datetime as dt\nfrom sklearn import linear_model \nfrom sklearn.metrics import mean_absolute_error\nimport plotly\nfrom sklearn import preprocessing\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport sklearn.metrics as metrics\nimport gc\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def transformer(df, ticker):\n    label = ticker\n    \n    #shift label\n    df['TARGET'] = df[label].shift(-1)\n    \n    #drop na\n    df = df[df['TARGET'].notna()].copy()\n    \n    #drop rows before stock start IPO by looking at mode\n    try:\n        mode = statistics.mode(df['TARGET'])\n        index_names = df[ df['TARGET'] == mode ].index \n        df.drop(index_names, inplace = True) \n        \n    except:\n        pass\n    \n    return df\n\ndef kfold_lightgbm(df, num_folds, stratified = False, debug= False):\n    \n    # Divide in training/validation and test data\n    #train_df, test_df = train_test_split(df, test_size=0.33)\n    row_split = df.shape[0] - 120\n    train_df, test_df = df.iloc[:row_split,:] , df.iloc[row_split+1:,:]\n\n    # Cross validation model\n    if stratified:\n        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)\n    else:\n        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n        \n    # Create arrays and dataframes to store results\n    oof_preds = np.zeros(train_df.shape[0])\n    sub_preds = np.zeros(test_df.shape[0])\n    feature_importance_df = pd.DataFrame()\n    feats = [f for f in train_df.columns if f not in ['TARGET','index', 'Date']]\n    \n    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n        dtrain = lgb.Dataset(data=train_df[feats].iloc[train_idx], \n                             label=train_df['TARGET'].iloc[train_idx], \n                             free_raw_data=False, silent=True)\n        dvalid = lgb.Dataset(data=train_df[feats].iloc[valid_idx], \n                             label=train_df['TARGET'].iloc[valid_idx], \n                             free_raw_data=False, silent=True)\n\n        # LightGBM parameters found by Bayesian optimization\n        params = {\n            'objective': 'regression',\n            'boosting_type': 'rf',\n            'nthread': 4,\n            'learning_rate': 0.03,  # 02,\n            'num_leaves': 4,\n            'colsample_bytree': 0.9497036,\n            'subsample': 0.8715623,\n            'subsample_freq': 1,\n            'max_depth': 8,\n            'reg_alpha': 0.041545473,\n            'reg_lambda': 0.0735294,\n            'min_split_gain': 0.0222415,\n            'min_child_weight': 60, # 39.3259775,\n            'seed': 0,\n            'verbose': -1,\n            'metric': 'mse',\n        }\n        \n        clf = lgb.train(\n            params=params,\n            train_set=dtrain,\n            num_boost_round=10000,\n            valid_sets=[dtrain, dvalid],\n            early_stopping_rounds=200,\n            verbose_eval=False\n        )\n\n        oof_preds[valid_idx] = clf.predict(dvalid.data)\n        sub_preds += clf.predict(test_df[feats]) / folds.n_splits\n\n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"feature\"] = feats\n        fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n        fold_importance_df[\"fold\"] = n_fold + 1\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n        print('Fold %2d R2 : %.6f' % (n_fold + 1,  metrics.r2_score(dvalid.label, oof_preds[valid_idx])))\n        del clf, dtrain, dvalid\n        gc.collect()\n        \n    metric = metrics.r2_score(test_df['TARGET'], sub_preds)\n    print('Test  R2 score %.6f' % metric)\n    return feature_importance_df, metric","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# original.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\ndata = pd.read_csv('/kaggle/input/5years-dailystock-quotes/original.csv', delimiter=',')\ndata.dataframeName = 'original.csv'\nnRow, nCol = data.shape\nprint(f'There are {nRow} rows and {nCol} columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#format date and labels\nnew_format = \"%Y-%m-%dT%H:%M:%SZ\"\ndata['datetime'] = pd.to_datetime(data['datetime'], format=new_format)\ndata.rename(columns={'datetime':'Date'}, inplace=True)\ndata.rename(columns={'open_price':'Open'}, inplace=True)\ndata.rename(columns={'close_price':'Close'}, inplace=True)\ndata.rename(columns={'high_price':'High'}, inplace=True)\ndata.rename(columns={'low_price':'Low'}, inplace=True)\ndata.rename(columns={'volume':'Volume'}, inplace=True)\ndata.rename(columns={'symbol':'Label'}, inplace=True)\n\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pivot tickers to columns\npivot = data.pivot(index='Date', columns='Label', values='Close')\npivot.reset_index(drop=True, inplace=True)\npivot['Date'] = data['Date']\npivot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"overall = pd.DataFrame()\nfeat_imp = pd.DataFrame()\n\n#tickers = data['Label'].unique()\ntickers = ['FBNC','TEX','ETO','OMER','SEEL']\n\nfor ticker in tickers:\n    try:\n        print(ticker)\n        df = transformer(pivot, ticker)\n        feature_importance_df, r2 = kfold_lightgbm(df, 2)\n\n        temp = pd.DataFrame()\n        temp['ticker'] = [ticker]\n        temp['R2'] = [r2]\n        overall = overall.append(temp)\n        \n        #remove temp before next step\n        del temp\n        \n        temp = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)\n        temp = temp[temp.importance != 0]\n        temp['ticker'] = ticker\n        feat_imp = feat_imp.append(temp)\n        \n    except:\n        pass\n    \noverall.sort_values(by=['R2'], inplace=True, ascending=False)\nfeat_imp.sort_values(by=['ticker','importance'], inplace=True, ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"overall.to_csv('/kaggle/working/overall.csv',index=False) # save to notebook output\noverall","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_imp = feat_imp.reset_index()\nfeat_imp.to_csv('/kaggle/working/feature_importance.csv',index=False) # save to notebook output\nfeat_imp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_imp = feat_imp.reset_index()\nfeat_imp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_imp[feat_imp['ticker']=='FBNC']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}