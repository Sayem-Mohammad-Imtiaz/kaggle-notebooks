{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom PIL import Image as m\nfrom tqdm import tqdm\nimport random\nimport cv2\nimport numpy as np\n\n\n# mass train dataset paths\nmass_images_path = \"../input/d/balraj98/massachusetts-buildings-dataset/png/train\"\nmass_labels_path = \"../input/d/balraj98/massachusetts-buildings-dataset/png/train_labels\"\nmass_image_size = 250\n\n# a train dataset paths\ninria_images_path_train = \"../input/inria180/training/training/images\"\ninria_labels_path_train = \"../input/inria180/training/training/gt\"\ninria_image_size = 500\n#由一张图像随机生成截取80张500 *500 大小的图像\ndef createSetsA(image_dir, label_dir, image_size, output_path):\n    index = 1\n    label_paths = os.listdir(label_dir)\n    for path_item in tqdm(label_paths):\n       \n        #image = m.open(image_dir + \"/\" + path_item).convert('RGB')\n        image = cv2.imread(image_dir + \"/\" + path_item, cv2.IMREAD_UNCHANGED)\n        #label = m.open(label_dir + \"/\" + path_item.split(\".\")[0] + \".tif\").convert(\"L\")\n        label = cv2.imread(label_dir + \"/\" + path_item, cv2.IMREAD_UNCHANGED)\n        X_height, X_width, _ = image.shape\n        for key in range(80):\n            random_width = random.randint(0, X_width - image_size - 1)\n            random_height = random.randint(0, X_height - image_size - 1)\n            src_roi = image[random_height: random_height + image_size, random_width: random_width + image_size, :]\n            label_roi = label[random_height: random_height + image_size, random_width: random_width + image_size, :]\n\n            cv2.imwrite((output_path + \"/images/image%d.tif\" % index), src_roi)\n            cv2.imwrite((output_path + \"/labels/label%d.tif\" % index), label_roi)\n            index += 1\n\n\ndef createSetsB(image_dir, label_dir, image_size, output_path):\n    index = 1\n    image_paths = os.listdir(image_dir)\n    for path_item in tqdm(image_paths):\n        # image = m.open(image_dir + \"/\" + path_item).convert('RGB')\n        image = cv2.imread(image_dir + \"/\" + path_item, cv2.IMREAD_UNCHANGED)\n        # label = m.open(label_dir + \"/\" + path_item.split(\".\")[0] + \".tif\").convert(\"L\")\n        label = cv2.imread(label_dir + \"/\" + path_item, cv2.IMREAD_UNCHANGED)\n        \n        src_roi = cv2.resize(image, (image_size,image_size))\n        label_roi = cv2.resize(label, (image_size,image_size))\n        \n        cv2.imwrite((output_path + \"/images/image%d.tif\" % index), src_roi)\n        cv2.imwrite((output_path + \"/labels/label%d.tif\" % index), label_roi)\n        index += 1\n\n\n\ndef change_label(label_dir):\n    image_paths = os.listdir(label_dir)\n    for path_item in tqdm(image_paths):\n        label = m.open(label_dir + \"/\" + path_item).convert(\"L\")\n\n        # change 255 to 1\n        im_point = label.point(lambda x: x // 255)\n\n        im_point.save(label_dir + \"/\" + path_item, 'png')\n\ndef mkdirs(paths):\n    \"\"\"create empty directories if they don't exist\n\n    Parameters:\n        paths (str list) -- a list of directory paths\n    \"\"\"\n    if isinstance(paths, list) and not isinstance(paths, str):\n        for path in paths:\n            mkdir(path)\n    else:\n        mkdir(paths)\n\n\ndef mkdir(path):\n    \"\"\"create a single empty directory if it didn't exist\n\n    Parameters:\n        path (str) -- a single directory path\n    \"\"\"\n    if not os.path.exists(path):\n        os.makedirs(path)\nif __name__ == \"__main__\":\n    # create the paths of created datasets\n    mkdirs(['./mass_inria/trainA/images', './mass_inria/trainA/labels','./mass_inria/trainB/images', './mass_inria/trainB/labels'])\n    mass_output_path = \"./mass_inria/trainA\"\n    createSetsA(mass_images_path, mass_labels_path, mass_image_size, mass_output_path)\n\n    inria_output_path_train = \"./mass_inria/trainB\"\n    createSetsB(inria_images_path_train, inria_labels_path_train, inria_image_size, inria_output_path_train)\n\n    trainA_label_dir = \"./mass_inria/trainA/labels\"\n    change_label(trainA_label_dir)\n    trainB_label_dir = \"./mass_inria/trainB/labels\"\n    change_label(trainB_label_dir)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train\n"},{"metadata":{},"cell_type":"markdown","source":"## SRS"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nclass ResASPPB(nn.Module):\n    def __init__(self, channels):\n        super(ResASPPB, self).__init__()\n        #(in_channels,out_channels,kernel_size,stride,padding,dilation)\n        self.conv1_1 = nn.Sequential(nn.Conv2d(channels, channels, 3, 1, 1, 1, bias=False), nn.LeakyReLU(0.1, inplace=True))\n        self.conv2_1 = nn.Sequential(nn.Conv2d(channels, channels, 3, 1, 4, 4, bias=False), nn.LeakyReLU(0.1, inplace=True))\n        self.conv3_1 = nn.Sequential(nn.Conv2d(channels, channels, 3, 1, 8, 8, bias=False), nn.LeakyReLU(0.1, inplace=True))\n        self.conv1_2 = nn.Sequential(nn.Conv2d(channels, channels, 3, 1, 1, 1, bias=False), nn.LeakyReLU(0.1, inplace=True))\n        self.conv2_2 = nn.Sequential(nn.Conv2d(channels, channels, 3, 1, 4, 4, bias=False), nn.LeakyReLU(0.1, inplace=True))\n        self.conv3_2 = nn.Sequential(nn.Conv2d(channels, channels, 3, 1, 8, 8, bias=False), nn.LeakyReLU(0.1, inplace=True))\n        self.conv1_3 = nn.Sequential(nn.Conv2d(channels, channels, 3, 1, 1, 1, bias=False), nn.LeakyReLU(0.1, inplace=True))\n        self.conv2_3 = nn.Sequential(nn.Conv2d(channels, channels, 3, 1, 4, 4, bias=False), nn.LeakyReLU(0.1, inplace=True))\n        self.conv3_3 = nn.Sequential(nn.Conv2d(channels, channels, 3, 1, 8, 8, bias=False), nn.LeakyReLU(0.1, inplace=True))\n        self.b_1 = nn.Conv2d(channels * 3, channels, 1, 1, 0, bias=False)\n        self.b_2 = nn.Conv2d(channels * 3, channels, 1, 1, 0, bias=False)\n        self.b_3 = nn.Conv2d(channels * 3, channels, 1, 1, 0, bias=False)\n    def __call__(self, x):\n        buffer_1 = []\n        buffer_1.append(self.conv1_1(x))\n        buffer_1.append(self.conv2_1(x))\n        buffer_1.append(self.conv3_1(x))\n        buffer_1 = self.b_1(torch.cat(buffer_1, 1))\n\n        buffer_2 = []\n        buffer_2.append(self.conv1_2(buffer_1))\n        buffer_2.append(self.conv2_2(buffer_1))\n        buffer_2.append(self.conv3_2(buffer_1))\n        buffer_2 = self.b_2(torch.cat(buffer_2, 1))\n\n        buffer_3 = []\n        buffer_3.append(self.conv1_3(buffer_2))\n        buffer_3.append(self.conv2_3(buffer_2))\n        buffer_3.append(self.conv3_3(buffer_2))\n        buffer_3 = self.b_3(torch.cat(buffer_3, 1))\n\n        return x + buffer_1 + buffer_2 + buffer_3\nclass ResB(nn.Module):\n    def __init__(self, channels):\n        super(ResB, self).__init__()\n        self.body = nn.Sequential(\n            nn.Conv2d(channels, channels, 3, 1, 1, bias=False),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Conv2d(channels, channels, 3, 1, 1, bias=False),\n        )\n    def __call__(self,x):\n        out = self.body(x)\n        return out + x\nclass SrdanetGenerator(nn.Module):\n    def __init__(self, num_cls=2):\n        super(SrdanetGenerator, self).__init__()\n        self.feature_extractor = nn.Sequential(\n            nn.Conv2d(3, 64, 3, 1, 1, bias=False),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Conv2d(64, 128, 3, 1, 1, bias=False),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.Conv2d(128, 256, 3, 1, 1, bias=False),\n            nn.LeakyReLU(0.1, inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            ResB(256),\n            ResASPPB(256),\n            ResB(256),\n            ResASPPB(256),\n            ResB(256),\n        )\n\n        # downsample == 2\n        # SRAAN\n        SRAAN_up2 = [nn.ConvTranspose2d(256, 256,\n                                         kernel_size=3, stride=2,\n                                         padding=1, output_padding=1,\n                                         bias=True),\n                            nn.ReLU(True)]\n        SRAAN_up4 = [nn.ConvTranspose2d(256, 128,\n                                         kernel_size=3, stride=2,\n                                         padding=1, output_padding=1,\n                                         bias=True),\n                            nn.ReLU(True)]\n        SRAAN_classifier = [nn.Conv2d(128, 3, kernel_size=9, padding=4)]\n\n        self.SRAAN_up2 = nn.Sequential(*SRAAN_up2)\n        self.SRAAN_up4 = nn.Sequential(*SRAAN_up4)\n        self.SRAAN_classifier = nn.Sequential(*SRAAN_classifier)\n\n        # SSAN\n        self.SSAN_mix_conv1 = nn.Conv2d(512, 128, kernel_size=3, padding=1)\n        self.SSAN_mix_conv2 = nn.Conv2d(256, 64, kernel_size=3, padding=1)\n        self.SSAN_classifier = nn.Conv2d(64, num_cls, kernel_size=9, padding=4)\n\n        # 初始化参数\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n    def forward(self, x):\n        # feature extractor\n        feature = self.feature_extractor(x) # channel=256\n\n        # SRAAN\n        SRAAN_up2 = self.SRAAN_up2(feature) # channel=256\n        SRAAN_up4 = self.SRAAN_up4(SRAAN_up2) # channel=128\n        sr_image = self.SRAAN_classifier(SRAAN_up4) # channel=128\n\n        # SSAN\n        _, _, h1, w1 = SRAAN_up2.size()\n        SSAN_feature_up2 = nn.functional.interpolate(feature, mode=\"bilinear\", size=(h1, w1), align_corners=True)\n        SSAN_feature_up2_cat = torch.cat((SSAN_feature_up2, SRAAN_up2), dim=1) # 512\n        SSAN_feature_up2_mix = self.SSAN_mix_conv1(SSAN_feature_up2_cat) # 128\n\n        _, _, h2, w2 = SRAAN_up4.size()\n        SSAN_feature_up4 = nn.functional.interpolate(SSAN_feature_up2_mix, mode=\"bilinear\", size=(h2, w2), align_corners=True)\n        SSAN_feature_up4_cat = torch.cat((SSAN_feature_up4, SRAAN_up4), dim=1)\n        SSAN_feature_up4_mix = self.SSAN_mix_conv2(SSAN_feature_up4_cat)\n        pre_seg = self.SSAN_classifier(SSAN_feature_up4_mix)\n\n        return feature, pre_seg, sr_image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## networks"},{"metadata":{},"cell_type":"markdown","source":"## step1train"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install torchsummary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchsummary import summary\nimport torch \n \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodule = SrdanetGenerator().to(device)\n \nsummary(module, (3,500 , 500))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}