{"cells":[{"metadata":{},"cell_type":"markdown","source":"# üßêEvaluating Classification ML Models\n\nNeed to choose between different Models\n\n**OR**\n\nChoose between different features.\n\n**OR even**\n\nChoose between different Tuning Parameters\n\n**Then**\n\nWe need to <font color=\"blue\">***evaluate model***</font>\n\nSo, that we could find out that the model which we wanted to build is completed or it's need more work upon it.\n\nIn, this Kerne/Notebook I have discussed few most popular tech. used to evaluate your model.\n\nSo, sit back and have a look over it and find out what you need to evaluate your's model.\n\nBefore going forward :\n<font color=\"Red\">Please Upvote ( It motivates me )</font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this current Notebook I have discussed these following evaluation :\n<font color=\"Purple\">\n1. Classification Accuracy\n2. Confusion Matrix\n3. F1 Score\n4. Precision And Recall\n5. ROC Curve\n3. Classication Report </font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Preprocesing and Ploting","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the Dataset\nclas_data = pd.read_csv('../input/health-care-data-set-on-heart-attack-possibility/heart.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's first find out details of our dataset\n\nLooking it's description, info, a head look gives us a rough idea of our data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_info(data):\n    print('\\t\\t Data Info:')\n    print(clas_data.info())\n    print('\\n\\n\\t\\t Data Head:')\n    print(clas_data.head())\n    print('\\n\\n\\t\\t Data Describe:')\n    print(clas_data.describe())\n    print('\\n\\nData Shape: ',clas_data.shape)\n    print('\\n\\n\\t\\t Null Values')\n    print(clas_data.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_info(clas_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now, let's have some visual information of our dataset\n\nFirst, let us find out about our **target** column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'target'\nsns.countplot(clas_data[var])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"followed with **gender/sex** column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'sex'\nsns.countplot(clas_data[var])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'age'\nf, ax = plt.subplots(figsize=(15,8))\nsns.distplot(clas_data[var])\nplt.xlim([0,80])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cleary most of dataset of person more than 40 year's of age. And it rises max in about 60.\n\nBelow, I ploted avout some more columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'chol'\nf, ax = plt.subplots(figsize=(15,8))\nsns.distplot(clas_data[var])\nplt.xlim([0,600])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'trestbps'\nf, ax = plt.subplots(figsize=(15,8))\nsns.distplot(clas_data[var])\nplt.xlim([0,250])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, comes the **heat map**\n\n### üî•Heat Map\nA heat map (or heatmap) is a data visualization technique that shows magnitude of a phenomenon as color in two dimensions. The variation in color may be by hue or intensity, giving obvious visual cues to the reader about how the phenomenon is clustered or varies over space.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,18))\nsns.heatmap(clas_data.corr(),annot=True,cmap='RdYlGn')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As given in data description, these 14 features are mostly used in all model. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clas_data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At here I have just divided the dataset first to X and y.\n\nFollowed by spliting for **test and train sets**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = clas_data.iloc[:,:-1]\ny = clas_data.iloc[:,-1]\nprint(\"\\n\\n\\t\\tIndependent features of Dataset: \")\nprint(X.head())\nprint(\"\\n\\n\\t\\tDependent features of Dataset: \")\nprint(y.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## üë®üèº‚Äçüíª Model Training\n\nI used most basic Logistic Regression here (because our focus is on Evaluation rather than a well-trained model)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)\ny_pred = log_reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## üßëüèº‚Äçüç≥Evaluation of model\n\nFrom here we are followed by the different ways we could evaluate our classification model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Model Accuracy\nIn multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint(\"Classification Model Accuracy is: \",metrics.accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ü§ØConfusion Matrix\nMost used in classification model\n\nA confusion matrix is a summary of prediction results on a classification problem.\n\nThe number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix.\n\nThe confusion matrix shows the ways in which your classification model\nis confused when it makes predictions.\n\nIt gives you insight not only into the errors being made by your classifier but more importantly the types of errors that are being made.\n\nLet's now define the most basic terms, which are whole numbers (not rates):\n* true positives (TP): These are cases in which we predicted yes (they have the disease), and they do have the disease.\n* true negatives (TN): We predicted no, and they don't have the disease.\n* false positives (FP): We predicted yes, but they don't actually have the disease. (Also known as a \"Type I error.\")\n* false negatives (FN): We predicted no, but they actually do have the disease. (Also known as a \"Type II error.\")","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install -q scikit-plot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scikitplot as skplt\nskplt.metrics.plot_confusion_matrix(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Precision and Recall\nPrecision attempts to answer the following question:\n\n*What proportion of positive identifications was actually correct?*\n\nAnd,Recall attempts to answer the following question:\n\n*What proportion of actual positives was identified correctly?*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import average_precision_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import plot_precision_recall_curve\naverage_precision = average_precision_score(y_test, y_pred)\nprint('Average precision-recall score: {0:0.2f}'.format(average_precision))\ndisp = plot_precision_recall_curve(log_reg, X_test, y_test)\ndisp.ax_.set_title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### üòµF1 score\nThe F1 score is the harmonic mean of the precision and recall, where an F1 score reaches its best value at 1 (perfect precision and recall). The F1 score is also known as the S√∏rensen‚ÄìDice coefficient or Dice similarity coefficient (DSC).[](http://)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nprint(\"Macro F1 Score: \",f1_score(y_test, y_pred, average='macro'))\nprint(\"Micro F1 Score: \",f1_score(y_test, y_pred, average='micro'))\nprint(\"Weighted F1 Score: \",f1_score(y_test, y_pred, average='weighted'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC Curve\nROC can be broken down into sensitivity and specificity. Choosing the best model is sort of a balance between predicting 1's accurately or 0's accurately. In other words sensitivity and specificity.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n\nplt.plot(fpr, tpr)\nplt.title('ROC curve for Heart Attack classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classification Report \nAt the I am using classification Report by **sckit-learn** which basically report all important evaluation criteria.\n\nRef : [https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html](http://)\n\nI wouls suggest do read this documentation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\ntarget_names = ['class 0', 'class 1']\nprint(classification_report(y_test, y_pred, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And there are many more \n\nDo check out [https://scikit-learn.org/stable/modules/model_evaluation.html](http://)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"So, Finally this NoteBook End here ü§µüèª\n\nBefore going a humble request if you liked the notebook the \n\n<font color=\"Red\">Please Upvote ( It motivates me )</font>\n\n<font color=\"Green\">Do check my other notebooks: </font>\nhttps://www.kaggle.com/iabhishekmaurya/used-car-price-prediction\nhttps://www.kaggle.com/iabhishekmaurya/applied-machine-learning/notebook\n\nAnd Stay Tuned... I WILL ALSO DO THE SAME FOR REGRESSION MODELS\n\nTill then Happy Coding\n# ü§ùü§ùü§ùü§ùü§ù","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}