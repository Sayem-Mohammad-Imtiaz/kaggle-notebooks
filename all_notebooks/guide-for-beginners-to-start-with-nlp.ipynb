{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set_style(\"whitegrid\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(r'../input/sms-spam-collection-dataset/spam.csv', encoding = 'latin-1')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find Missing Values\nplt.figure(figsize=(12,8))\nsns.heatmap(df.isnull(), cmap = 'viridis', yticklabels = False, cbar = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(how=\"any\", inplace=True, axis=1)\ndf.columns = ['label', 'message']\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('label').describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['label'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is an Imbalaanced Dataset, so f1_score will be the best metric for evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert label to a numerical variable\ndf['label_num'] = df.label.map({'ham':0, 'spam':1})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing Most Repeated Words using WordCloud"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\nstopwords = set(STOPWORDS)\ndef word_cloud(data, title=None):\n    cloud = WordCloud(background_color = 'black',\n                     stopwords = stopwords,\n                     max_words = 200,\n                     max_font_size = 40,\n                     scale = 3).generate(str(data))\n    fig = plt.figure(figsize=(15,15))\n    plt.axis('off')\n    if title:\n        fig.suptitle(title, fontsize = 20)\n        fig.subplots_adjust(top = 2.25)\n        plt.imshow(cloud)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_cloud(df[df['label_num']==1]['message'],'Most Repeated words in spam messages')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_cloud(df[df['label_num']==0]['message'],'Most Repeated words in Ham messages')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Number of characters in a sms"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\nsms_len=df[df['label_num']==1]['message'].str.len()\nax1.hist(sms_len,color='red')\nax1.set_title('spam messages')\nsms_len=df[df['label_num']==0]['message'].str.len()\nax2.hist(sms_len,color='green')\nax2.set_title('Ham messages')\nfig.suptitle('Characters in sms')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Through just basic EDA we've been able to discover a trend that spam messages tend to have more characters."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\nsms_words = df[df['label_num']==1]['message'].str.split().map(lambda x: len(x))\nax1.hist(sms_words, color='red')\nax1.set_title('Spam Messages')\nsms_words = df[df['label_num']==0]['message'].str.split().map(lambda x: len(x))\nax2.hist(sms_words, color='green')\nax2.set_title('Ham Messages')\nfig.suptitle('Words in a Sms')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.label=='ham'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.label=='spam'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nfrom nltk.corpus import stopwords\n\ndef text_process(mess):\n    \"\"\"\n    Takes in a string of text, then performs the following:\n    1. Remove all punctuation\n    2. Remove all stopwords\n    3. Returns a list of the cleaned text\n    \"\"\"\n    STOPWORDS = stopwords.words('english') + ['u', 'Ã¼', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure']\n    # Check characters to see if they are in punctuation\n    nopunc = [char for char in mess if char not in string.punctuation]\n\n    # Join the characters again to form the string.\n    nopunc = ''.join(nopunc)\n    \n    # Now just remove any stopwords\n    return ' '.join([word for word in nopunc.split() if word.lower() not in STOPWORDS])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['clean_msg'] = df.message.apply(text_process)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.clean_msg\ny = df.label_num\nprint(X.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=1, stratify = y)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Building Using Pipelines"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\npipeline_lr=Pipeline([('bow1', CountVectorizer(analyzer=text_process)),\n                      ('tfidf1', TfidfTransformer()),\n                     ('lr_classifier',LogisticRegression(random_state=0))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_dt=Pipeline([('bow2', CountVectorizer(analyzer=text_process)),\n                      ('tfidf2', TfidfTransformer()),\n                     ('dt_classifier',DecisionTreeClassifier())])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_rf=Pipeline([('bow3', CountVectorizer(analyzer=text_process)),\n                      ('tfidf3', TfidfTransformer()),\n                     ('rf_classifier',RandomForestClassifier())])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_nb=Pipeline([('bow4', CountVectorizer(analyzer=text_process)),\n                      ('tfidf4', TfidfTransformer()),\n                     ('naive_classifier',MultinomialNB())])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_svm=Pipeline([('bow5', CountVectorizer(analyzer=text_process)),\n                      ('tfidf5', TfidfTransformer()),\n                     ('svm_classifier',SVC())])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets make the list of pipelines\npipelines = [pipeline_lr, pipeline_dt, pipeline_rf, pipeline_nb, pipeline_svm]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_score=0.0\nbest_classifier=0\nbest_pipeline=\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe_dict = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'Random Forest', 3: 'Naive-Baies Classifier', 4: 'SVM Classifier'}\n\n# Fit the pipelines\nfor pipe in pipelines:\n    pipe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nfor i,model in enumerate(pipelines):\n    predictions = model.predict(X_test)\n    score = f1_score(y_test, predictions, average='macro')\n    print(\"{} Test F1_Score: {}\".format(pipe_dict[i], score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,model in enumerate(pipelines):\n    if model.score(X_test,y_test)>best_score:\n        best_score=model.score(X_test,y_test)\n        best_pipeline=model\n        best_classifier=i\nprint('Classifier with best f1_score:{}'.format(pipe_dict[best_classifier]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}