{"cells":[{"metadata":{},"cell_type":"markdown","source":"## E-Commerce Data Analysis\n### By: Brandon McManus","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Data Set Information:\n\nThis is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\n\n\n#### Attribute Information:\n**InvoiceNo:** Invoice number. Nominal, a 6-digit integral number uniquely assigned to each         transaction. If this code starts with letter 'c', it indicates a cancellation.  \n       \n**StockCode:** Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.         \n       \n**Description:** Product (item) name. Nominal.   \n        \n**Quantity:** The quantities of each product (item) per transaction. Numeric.    \n        \n**InvoiceDate:** Invoice Date and time. Numeric, the day and time when each transaction was generated.      \n       \n**UnitPrice:** Unit price. Numeric, Product price per unit in sterling.      \n      \n**CustomerID:** Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.      \n        \n**Country:** Country name. Nominal, the name of the country where each customer resides.      ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport datetime as dt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dat = pd.read_csv(\"../input/ecommerce-data/data.csv\", encoding= 'unicode_escape')\n\npd.set_option('display.max_columns', 500)\n\ndat.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Exploration & Data Cleaning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dat.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dat.head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Given the initial look of the data, We can see that the data is made up of various transactions with a seperate transaction for each Description. There are some changes that need to made with the data types of the CustomerID and InvoiceDate columns.\n        \n**InvoiceDate** should be *datetime64* rather than *object* Dtype        \n**CustomerID** should be *object* type rather than *float64* Dtype","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dat['InvoiceDate'] = pd.to_datetime(dat['InvoiceDate'])\ndat.CustomerID = dat.CustomerID.astype(object)\ndat.info() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now I want to see if there are any missing values in the dataset that may cause problems for our analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dat.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dat.isnull().sum() / dat.shape[0] * 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have almost 25% of the CustomerID column missing and less than 1% of the Description column missing. I will check to see if the rows with missing Description values are also missing CustomerID values to eliminate unnecessary work.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', 1000)\nnull_data = dat[dat.isnull().any(axis=1)]\nnull_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It appears that all the missing values for the Description column are also missing CustomerID values so lets take a look at the rows where both values are missing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"null_data = dat[dat['Description'].isnull()]\nnull_data.sample(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It appears that where there is a missing Description and CustomerID the unitprice = 0 and the quantity is either positive or negative. We can infer that these transactions are likely returns from customers and the company has not developed a clear strategy of handling returned items. It would be wise for the company to develop some sort of way to identify returns or faulty transactions so they can be assessed more accurately. However, since there is no explanation for the occurances of these transactions it is best to drop all transactions with missing descriptions and with a unitprice=0. It would also be in our best interest to drop missing CustomerID's as they will not be of use for us if we are looking to make accurate insights for this data analysis.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dat = dat.dropna()\ndat.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next I would like to determine how many transaction cancellations we have. A cancelled transaction is indicated by a C at the beginning of the InvoiceNo.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dat[\"IsCancelled\"]=np.where(dat.InvoiceNo.apply(lambda l: l[0]==\"C\"), True, False)\ndat.IsCancelled.value_counts() / dat.shape[0] * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dat.loc[dat.IsCancelled==True].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since we have negative quantities for all quartiles and positive unit prices, understanding the data without any further explanation or information will become too difficult for us to predict so it is best to drop the data from the dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dat = dat.loc[dat.IsCancelled==False].copy()\ndat = dat.drop(\"IsCancelled\", axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Stock Codes and Descriptions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dat.StockCode.nunique(), dat.Description.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 3665 unique StockCodes and 3877 unique Descriptions which aligns with the fact that the retailer sells many different types of products. Lets take a look at the most common stockcodes and descriptions being sold ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stockcode_frequency = dat.StockCode.value_counts().sort_values(ascending=False)\ndescription_frequency = dat.Description.value_counts().sort_values(ascending=False)\nfig, ax = plt.subplots(2,1,figsize=(20,15))\nsns.barplot(stockcode_frequency.iloc[0:19].index,\n            stockcode_frequency.iloc[0:19].values,\n            ax = ax[0], palette=\"Blues_r\")\nax[0].set_ylabel(\"Frequency\")\nax[0].set_xlabel(\"Stockcode\")\nax[0].set_title(\"Which stockcodes are most common?\");\nsns.barplot(description_frequency.iloc[0:19].index,\n            description_frequency.iloc[0:19].values,\n            ax = ax[1], palette=\"Purples_r\")\nax[1].set_ylabel(\"Frequency\")\nax[1].set_xlabel(\"Description\")\nax[1].tick_params(labelrotation=90)\n\nax[1].set_title(\"Which Descriptions are most common?\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that our top 20 most frequent stockcodes and descriptions generally match up with eachother in terms of level of frequency so we can say it is true that majority of the descriptions are consistent with the stockcodes except for some exceptions causing slight differences in the amount of stockcodes vs descriptions","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Customers and Countries ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Next I would like to see what customers and what countries had the most transactions and the correlation between our top customers and the countries ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_frequency = dat.CustomerID.value_counts().sort_values(ascending=False).iloc[0:19] \nplt.figure(figsize=(19,10))\ncustomer_frequency.index = customer_frequency.index.astype('Int64') \nsns.barplot(customer_frequency.index, customer_frequency.values, order=customer_frequency.index, palette=\"Spectral_r\")\nplt.ylabel(\"Frequency\")\nplt.xlabel(\"CustomerID\")\nplt.title(\"Which customers are most common?\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_frequency = dat.Country.value_counts().sort_values(ascending=False).iloc[0:20]\nplt.figure(figsize=(20,5))\nsns.barplot(country_frequency.index, country_frequency.values, palette=\"plasma_r\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Which countries made the most transactions?\");\nplt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is clear that the vast majority of transactions take place in the United Kingdom. Lets see if our top 20 Customers purchase their items in the United Kingdom or in other countries. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = dat.groupby(['CustomerID','Country']).size().sort_values(ascending=False).iloc[0:19]\npd.DataFrame(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_frequency = dat.CustomerID.value_counts().sort_values(ascending=False).iloc[0:19] \nuk_customers = dat.groupby(dat['CustomerID']).size().where(dat['Country'] == 'United Kingdom').sort_values(ascending=False).iloc[0:19]\nfig, ax = plt.subplots(2,1,figsize=(20,20))\nsns.barplot(customer_frequency.index,\n            customer_frequency.values,\n            ax = ax[0], palette=\"Blues_r\", order=customer_frequency.index)\nax[0].set_ylabel(\"Frequency\")\nax[0].set_xlabel(\"CustomerID\")\nax[0].set_title(\"Which Customers are most common?\");\nsns.barplot(uk_customers.index,\n            uk_customers.values,\n            ax = ax[1], palette=\"cool\", order=uk_customers.index)\nax[1].set_ylabel(\"Frequency\")\nax[1].set_xlabel(\"CustomerID\")\nax[1].set_title(\"Which Customers are most common in the United Kingdom?\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It appears we have a few outliers in our top customers group where the top country is Ireland and the Netherlands.However, the majority are from the United Kingdom which makes sense due to the large difference in transactions between the United Kingdom and the rest of the countries in our dataset.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Unit Price and Quantity ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Before I start doing any time-series analysis, I want to make sure my price and quantity features make sense and will be easy for us to analyze.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dat.UnitPrice.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before a graph the unit price, I want to make sure there are no 0 or less than 0 valued unit prices as this will become a problem when we are finding the log of the unitprice.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dat = dat.loc[dat.UnitPrice > 0].copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that there are no zero value unit prices we can graph the distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,1,figsize=(15,15))\nsns.distplot(dat.UnitPrice, ax=ax[0])\nax[0].set_ylabel('Frequency')\nsns.distplot(np.log(dat.UnitPrice), ax=ax[1], bins=20)\nax[1].set_ylabel('Frequency')\nax[1].set_xlabel(\"Log-Unit-Price\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the graphs we can see that a large portion of the prices are quite small and we have a few outliers that are very large. Due to the high frequency of small transactions I will focus on the transactions with prices in the log-unit-price graph. To find the prices i will take the exponent of -2 and the exponent of 3 as the majority of the price are between these two log units.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"np.exp(-2),np.exp(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the majority of our distribution lies between 0.1 and 20.1 so I will delete all outliers outside of this range","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dat = dat.loc[(dat.UnitPrice > 0.1) & (dat.UnitPrice < 20)].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dat.UnitPrice.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,1,figsize=(15,15))\nsns.distplot(dat.UnitPrice, ax=ax[0])\nax[0].set_ylabel('Frequency')\nsns.distplot(np.log(dat.UnitPrice), ax=ax[1], bins=20)\nax[1].set_ylabel('Frequency')\nax[1].set_xlabel(\"Log-Unit-Price\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now are std is much smaller and we have a more evenly distributed graph. Our graph is still skewed to the right which is something to make note of for which we will deal with later. Now lets take a look at the Quantity column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dat.Quantity.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,1,figsize=(15,15))\nsns.distplot(dat.Quantity, ax=ax[0], kde=False)\nax[0].set_title(\"Quantity distribution\")\nax[0].set_ylabel('Frequency')\nax[0].set_yscale(\"log\")\nsns.distplot(np.log(dat.Quantity), ax=ax[1], bins=20, kde=False)\nax[0].set_title(\"Log-Quantity distribution\")\nax[1].set_ylabel('Frequency')\nax[1].set_xlabel(\"Log-Quantity\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the graphs it looks like we have a small amount of outliers greater than 70000. lets take the exponent where Log-Quantity=4 as most of our distribution lies within this region","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"np.exp(4),np.quantile(dat.Quantity, 0.95)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like we will be able to keep more than 95% of our data with a max quantity set at 55. Lets take a look at our distribution after we drop the outliers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dat = dat.loc[dat.Quantity < 55].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,1,figsize=(15,15))\nsns.distplot(dat.Quantity, ax=ax[0], kde=False)\nax[0].set_title(\"Quantity distribution\")\nax[0].set_ylabel('Frequency')\nax[0].set_yscale(\"log\")\nsns.distplot(np.log(dat.Quantity), ax=ax[1], bins=20, kde=False)\nax[0].set_title(\"Log-Quantity distribution\")\nax[1].set_ylabel('Frequency')\nax[1].set_xlabel(\"Log-Quantity\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dat.Quantity.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have a much better distribution now and a much smaller std. Now we can move on to our Time-Series Analysis.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Which months had the highest Revenue?","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now I would like to explore what statistics and insights we can uncover with different time periods and dates in our data. I will start by creating new columns that represent different date ranges that we can use. I will also create a revenue column as that will be a good metric to look at to determine sales performance in different time ranges.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dat[\"Revenue\"] = dat.Quantity * dat.UnitPrice\n\ndat[\"Month\"] = dat.InvoiceDate.dt.month\n\ndat.groupby('Month').sum().sort_values(by='Revenue', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams.update({'font.size': 12})\nz = dat.groupby('Month').sum().sort_values(by='Revenue',ascending=False)\nx = z.index\ny = z['Revenue'].sort_values(ascending=False)\nplt.figure(figsize=(10,10))\nsns.barplot(x, y, order=x)\nplt.ylabel(\"Revenue\", Size=14)\nplt.xlabel(\"Months\", Size=14)\nplt.title(\"Which Month had the highest Revenue?\", Size=14);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that November is the highest revenue month for the company followed by October and then September. This could be because these are the months leading up to the holiday months where it is more likely people will be buying gifts and business increasing their inventory. It should be noted that the company considers many of their customers to be wholesalers indicating that customers are likely preparing for the holiday season by purchasing more products.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### What product contributed the most to revenue? Why?","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"\ndf = dat[['StockCode','Revenue']].groupby('StockCode').sum().sort_values(by='Revenue', ascending=False).iloc[0:9]\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that StockCode 22423 contributed the most to revenue by over $60000. Lets take a look at a sample of the transactions for StockCode 22423 to see if there are any clues that can explain why it's contribution to revenue is so high","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"dat[dat['StockCode'] == '22423'].sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The only clue to explain it's high contribution to revenue would be the relatively high UnitPrice compared to the rest of the products. This allows it to generate more revenue in lower quantities being sold. The other data features seem to be relatively random and so without further information we can make any more inferences.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let me know of any suggestions and critiques you have in the comments below!\nCheers!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}