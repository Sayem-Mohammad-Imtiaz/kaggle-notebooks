{"cells":[{"metadata":{},"cell_type":"markdown","source":"*** Please Upvote if this kernal help you***"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets check the GPU provided\n!nvidia-smi ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import all the required packages\nimport os\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import applications\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\nfrom sklearn import model_selection\nimport warnings\nimport json\nimport cv2\nimport plotly.express as px\nfrom collections import Counter\nwarnings.filterwarnings('ignore')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE=150\nBATCH_SIZE = 32\nEPOCHS = 15\nCLASSES = 6\nFOLDS=5","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Lets check the tensorflow version\ntf.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GPU Initialize\ndevice_name = tf.test.gpu_device_name()\nif device_name!='/device:GPU:0':\n    raise SystemError('GPU Device not found')\nprint('Found GPU at:{}'.format(device_name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets initialize the parent dir\nPARENT_DIR = '../input/hackerearth-deep-learning-challenge-holidayseason/dataset'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List folders are files\nprint(os.listdir(PARENT_DIR))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import train and sample csv\ntrain_df = pd.read_csv(os.path.join(PARENT_DIR,'train.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check the mapping of labels\ndf_c = train_df.Class.value_counts().reset_index()\ndf_c.columns = ['class','count']\nfig = px.bar(df_c, x='class', y='count')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets take a look into the images\ntrain_df_Airplane = train_df[train_df['Class']=='Airplane'].head(10).Image\ntrain_df_Candle = train_df[train_df['Class']=='Candle'].head(10).Image\ntrain_df_Christmas_Tree = train_df[train_df['Class']=='Christmas_Tree'].head(10).Image\ntrain_df_Jacket = train_df[train_df['Class']=='Jacket'].head(10).Image\ntrain_df_Miscellaneous = train_df[train_df['Class']=='Miscellaneous'].head(10).Image\ntrain_df_Snowman = train_df[train_df['Class']=='Snowman'].head(10).Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = ['Airplane','Candle','Christmas_Tree','Jacket','Miscellaneous','Snowman']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# helper function for printing different class of images\ndef show_image(img_dir):\n    i_dir = img_dir\n    train_dir= PARENT_DIR +'/'+'train'\n    i = 1\n    plt.figure(figsize=(20,10))\n    for img in i_dir:\n        img = cv2.imread(os.path.join(train_dir,img),cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE),interpolation = cv2.INTER_NEAREST)\n        plt.subplot(2,5,i)\n        plt.imshow(img)\n        i+=1\n\n\ndef display_confusion_matrix(cmat, score, precision, recall):\n    plt.figure(figsize=(15,15))\n    ax = plt.gca()\n    ax.matshow(cmat, cmap='Reds')\n    ax.set_xticks(range(len(c)))\n    ax.set_xticklabels(c, fontdict={'fontsize': 7})\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n    ax.set_yticks(range(len(c)))\n    ax.set_yticklabels(c, fontdict={'fontsize': 7})\n    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n    titlestring = \"\"\n    if score is not None:\n        titlestring += 'f1 = {:.3f} '.format(score)\n    if precision is not None:\n        titlestring += '\\nprecision = {:.3f} '.format(precision)\n    if recall is not None:\n        titlestring += '\\nrecall = {:.3f} '.format(recall)\n    if len(titlestring) > 0:\n        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n    plt.show()\n    \ndef display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sample Airplane Images\nshow_image(train_df_Airplane)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sample Candle Images\nshow_image(train_df_Candle)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sample Christmas Tree\nshow_image(train_df_Christmas_Tree)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sample Jacket Images\nshow_image(train_df_Jacket)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Miscllaneous Images\nshow_image(train_df_Miscellaneous)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sample Snowman Images\nshow_image(train_df_Snowman)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets do a cross validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define Cross Validation\nskf = model_selection.StratifiedKFold(n_splits = FOLDS, random_state = 42, shuffle = True,) \nY = train_df[['Class']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Helper Function to save model\ndef get_model_name(k):\n    return 'model_'+str(k)+'.h5'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize Image Generator\ndatagen = ImageDataGenerator(\n                    rotation_range = 40,\n                    width_shift_range = 0.2,\n                    height_shift_range = 0.2,\n                    shear_range = 0.2,\n                    zoom_range = 0.2,\n                    horizontal_flip = True,\n                    vertical_flip = True,\n                    fill_mode = 'nearest',\n                    validation_split=0.25\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model\ndef create_new_model():\n    model = tf.keras.Sequential([\n        tf.keras.applications.Xception(\n            input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n            weights='imagenet',\n            include_top=False\n        #    drop_connect_rate=0.7\n        ),\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(CLASSES, activation='softmax')\n    ])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"VALIDATION_ACCURACY = []\nVALIDAITON_LOSS = []\nn = len(train_df)\nsave_dir = './'\nfold_var = 1\n\nfor train_index, val_index in skf.split(np.zeros(n),Y):\n    training_data = train_df.iloc[train_index]\n    validation_data = train_df.iloc[val_index]\n    \n    # Creating training validation and test generator\n    train_generator=datagen.flow_from_dataframe(\n                        dataframe=train_df,\n                        directory=\"../input/hackerearth-deep-learning-challenge-holidayseason/dataset/train/\",\n                        x_col=\"Image\",\n                        y_col=\"Class\",\n                        subset=\"training\",\n                        batch_size=32,\n                        seed=42,\n                        shuffle=True,\n                        class_mode = 'categorical',\n                        color_mode='rgb',\n                        target_size=(IMAGE_SIZE,IMAGE_SIZE)\n                        )\n\n\n    valid_data_generator=datagen.flow_from_dataframe(\n                        dataframe=train_df,\n                        directory=\"../input/hackerearth-deep-learning-challenge-holidayseason/dataset/train/\",\n                        x_col=\"Image\",\n                        y_col=\"Class\",\n                        subset=\"validation\",\n                        batch_size=32,\n                        seed=42,\n                        shuffle=True,\n                        class_mode=\"categorical\",\n                        color_mode='rgb',\n                        target_size=(IMAGE_SIZE,IMAGE_SIZE)\n                        )\n    # Define CallBacks\n    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var),save_best_only=True,monitor = 'val_loss',mode='min')\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss',factor = 0.3,patience = 3, min_lr = 1e-5, mode = 'min',verbose = 1)\n    early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss',mode='min',patience=5,restore_best_weights=True,verbose=1)\n    callbacks_list = [checkpoint_cb,reduce_lr,early_stopping_cb]\n    \n    # Define Class Weight\n    counter = Counter(train_generator.classes)       \n    max_val = float(max(counter.values()))       \n    class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}     \n    \n    \n    # Perform training \n    with tf.device('/gpu:0'):\n        model = create_new_model()\n        model.compile(\n            optimizer=tf.keras.optimizers.Adam(learning_rate = 1e-3),\n            loss='categorical_crossentropy',\n            metrics=['categorical_accuracy'])\n        history = model.fit(\n                train_generator,\n                steps_per_epoch = train_generator.n/BATCH_SIZE,\n                epochs=EPOCHS,\n                batch_size = BATCH_SIZE,\n                validation_data=valid_data_generator,\n                validation_steps = valid_data_generator.n/BATCH_SIZE,\n                callbacks=[checkpoint_cb,reduce_lr,early_stopping_cb],\n                class_weight=class_weights)\n        \n    # Plotting accuracy history\n    plt.figure(figsize= (15,10))\n    plt.plot(history.history['categorical_accuracy'])\n    plt.plot(history.history['val_categorical_accuracy'])\n    plt.title('Accuracy Tracker', fontsize=15)\n    plt.xlabel('Epochs', fontsize=15)\n    plt.ylabel('Accuracy', fontsize=15)\n    plt.legend(['training', 'validation'])\n    \n    # Plotting loss history\n    plt.figure(figsize= (15,10))\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Loss Tracker', fontsize=15)\n    plt.xlabel('Epochs', fontsize=15)\n    plt.ylabel('Loss', fontsize=15)\n    plt.legend(['training', 'validation'])\n    \n    # LOAD BEST MODEL to evaluate the performance of the model\n    model.load_weights(\"./model_\"+str(fold_var)+\".h5\")\n\n    results = model.evaluate(valid_data_generator)\n    results = dict(zip(model.metrics_names,results))\n\n    VALIDATION_ACCURACY.append(results['categorical_accuracy'])\n    VALIDAITON_LOSS.append(results['loss'])\n\n    tf.keras.backend.clear_session()\n\n    fold_var += 1\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display_training_curves(\n#     history.history['loss'],\n#     history.history['val_loss'],\n#     'loss',\n#     211,\n# )\n# display_training_curves(\n#     history.history['categorical_accuracy'],\n#     history.history['val_categorical_accuracy'],\n#     'accuracy',\n#     212,\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_generator.class_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cm_correct_labels = np.array(val_generator.labels)\n# cm_predictions = np.argmax(model.predict(val_generator),-1)\n# labels = range(len(c))\n# cmat = confusion_matrix(\n#     cm_correct_labels,\n#     cm_predictions,\n#     labels=labels,\n# )\n# cmat = (cmat.T / cmat.sum(axis=1)).T # normalize","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# score = f1_score(\n#     cm_correct_labels,\n#     cm_predictions,\n#     labels=labels,\n#     average='macro',\n# )\n# precision = precision_score(\n#     cm_correct_labels,\n#     cm_predictions,\n#     labels=labels,\n#     average='macro',\n# )\n# recall = recall_score(\n#     cm_correct_labels,\n#     cm_predictions,\n#     labels=labels,\n#     average='macro',\n# )\n# display_confusion_matrix(cmat, score, precision, recall)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(score, precision, recall)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(columns=['Image','Class'])\nfor image_name in os.listdir(PARENT_DIR + '/test'):\n    image_path = os.path.join(PARENT_DIR + '/test', image_name)\n    image = tf.keras.preprocessing.image.load_img(image_path)\n    resized_image = image.resize((IMAGE_SIZE, IMAGE_SIZE))\n    numpied_image = np.expand_dims(resized_image, 0)\n    tensored_image = tf.cast(numpied_image, tf.float32)\n    submission = submission.append(pd.DataFrame({'Image': image_name,\n                                                 'Class': model.predict_classes(tensored_image)}))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"{'Airplane': 0,\n 'Candle': 1,\n 'Christmas_Tree': 2,\n 'Jacket': 3,\n 'Miscellaneous': 4,\n 'Snowman': 5}"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['Class'] = submission['Class'].map({\n0:'Airplane',\n1:'Candle',\n2:'Christmas_Tree',\n3:'Jacket',\n4:'Miscellaneous',\n5:'Snowman'\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving CSV to output folder\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}