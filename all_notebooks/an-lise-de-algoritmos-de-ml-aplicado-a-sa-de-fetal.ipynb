{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Análise dos Algoritmos SVM, MLP, KNN e Random Forest baseados na classificação do Dataset \"Fetal Health Classification\"","metadata":{}},{"cell_type":"code","source":"# Bibliotecas básicas\nimport numpy as np \nimport pandas as pd \n\n# Biblioteca para marcar os tempos de execução\nimport time as tm\n\n# Biblioteca para separar os dados em treino e teste\nfrom sklearn.model_selection import train_test_split\n\n# Biblioteca de métricas de análise de dados\nfrom sklearn.metrics import f1_score\n\n# Bibliotecas de Análises Estatísticas e Gráficos\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Biblioteca para detalhar os resultados obtidos\nfrom sklearn.metrics import classification_report\n\n# Bibliotecas de Aprendizado de Máquina\nfrom sklearn import svm\nfrom sklearn.neural_network import MLPClassifier \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Biblioteca para balanceamento de datasets\nfrom imblearn.over_sampling import RandomOverSampler","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:10:01.845727Z","iopub.execute_input":"2021-08-02T01:10:01.846157Z","iopub.status.idle":"2021-08-02T01:10:03.163019Z","shell.execute_reply.started":"2021-08-02T01:10:01.846078Z","shell.execute_reply":"2021-08-02T01:10:03.161951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"O dataset utilizado na análise foi o [fetal-health-classification](https://www.kaggle.com/andrewmvd/fetal-health-classification), que se trata de uma amostra resultante da análise de cardiotocografias realizadas em gestantes para conseguir classificar a saúde de seus fetos em \"**Normal**\", \"**Suspeito**\" e \"**Patológico**\". ","metadata":{}},{"cell_type":"code","source":"# Carregamos o dataset escolhido\ndataset = pd.read_csv(\"../input/fetal-health-classification/fetal_health.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:10:05.917239Z","iopub.execute_input":"2021-08-02T01:10:05.917603Z","iopub.status.idle":"2021-08-02T01:10:05.951754Z","shell.execute_reply.started":"2021-08-02T01:10:05.917573Z","shell.execute_reply":"2021-08-02T01:10:05.950873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"O dataset possui 22 colunas, sendo 21 atributos, e a última coluna contendo a classificação da amostra, e 2126 linhas, como podemos visualizar abaixo:","metadata":{}},{"cell_type":"code","source":"dataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:10:08.740135Z","iopub.execute_input":"2021-08-02T01:10:08.740499Z","iopub.status.idle":"2021-08-02T01:10:08.786452Z","shell.execute_reply.started":"2021-08-02T01:10:08.740469Z","shell.execute_reply":"2021-08-02T01:10:08.78545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Após o carregamento do dataset, verificamos se o mesmo possui [**missing values**](https://www.kaggle.com/alexisbcook/missing-values):","metadata":{}},{"cell_type":"code","source":"dataset.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:10:12.922863Z","iopub.execute_input":"2021-08-02T01:10:12.923193Z","iopub.status.idle":"2021-08-02T01:10:12.932043Z","shell.execute_reply.started":"2021-08-02T01:10:12.923165Z","shell.execute_reply":"2021-08-02T01:10:12.93112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"De acordo com a tabela acima, podemos notar que todos os dados estão preenchidos.\n\nA segunda análise necessária nos dados, é verificar a quantidade de amostras de cada uma das classes, para sabermos se o conjunto de dados está balanceado, evitando assim de enviezarmos o algoritmo, que irá priorizar a classe majoritária a fim de melhorar seu score.","metadata":{}},{"cell_type":"code","source":"# Método que imprime a quantidade de amostras por classe\ndef print_number_of_elements_per_class(y):\n    classes_name = ['Normal', 'Suspeito', 'Patológico']\n    \n    classes_id = list(y)\n    number_of_elements = [classes_id.count(1), classes_id.count(2), classes_id.count(3)]\n    \n    print(classes_name[0], number_of_elements[0])\n    print(classes_name[1], number_of_elements[1])\n    print(classes_name[2], number_of_elements[2])\n    \n    plt.bar(classes_name, number_of_elements)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:18:03.139217Z","iopub.execute_input":"2021-08-02T01:18:03.13958Z","iopub.status.idle":"2021-08-02T01:18:03.146213Z","shell.execute_reply.started":"2021-08-02T01:18:03.139542Z","shell.execute_reply":"2021-08-02T01:18:03.14521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dividimos os atributos (X) da classificação (y) das amostras\nX = np.array(dataset.drop(columns = ['fetal_health']))\ny = np.array(dataset['fetal_health'])\n\nprint_number_of_elements_per_class(y)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:18:04.735925Z","iopub.execute_input":"2021-08-02T01:18:04.73628Z","iopub.status.idle":"2021-08-02T01:18:04.86275Z","shell.execute_reply.started":"2021-08-02T01:18:04.736248Z","shell.execute_reply":"2021-08-02T01:18:04.861826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Observando o gráfico obtido, nota-se que os dados estão completamente desbalanceados, a classe \"Normal\" possui muito mais amostras que as demais, sendo assim, antes de executarmos nossos algoritmos de classificação, iremos aplicar a técnica de [**Oversampling**](https://en.wikipedia.org/wiki/Oversampling) no dataset para balancear os dados.","metadata":{}},{"cell_type":"code","source":"X, y = RandomOverSampler(random_state = 21).fit_resample(X,y)\n\nprint_number_of_elements_per_class(y)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:18:08.893993Z","iopub.execute_input":"2021-08-02T01:18:08.894422Z","iopub.status.idle":"2021-08-02T01:18:09.024223Z","shell.execute_reply.started":"2021-08-02T01:18:08.894383Z","shell.execute_reply":"2021-08-02T01:18:09.023294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Depois de realizado o balanceamento, temos quantidades iguais de amostras por classe, o que permite obter um melhor resultado na execução de nossos algitmos classificadores.\n\nA próxima etapa é dividir nossos dados em treino e teste, a divisão escolhida foi de 70% para treino (1159) e 30% para teste (496).","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 19, stratify = y)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:10:50.012173Z","iopub.execute_input":"2021-08-02T01:10:50.012579Z","iopub.status.idle":"2021-08-02T01:10:50.023389Z","shell.execute_reply.started":"2021-08-02T01:10:50.012536Z","shell.execute_reply":"2021-08-02T01:10:50.022433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Para visualizar como os dados estão dividos e se seguem algum padrão, podemos plotar seus atributos dois a dois:","metadata":{}},{"cell_type":"code","source":"sns.pairplot(dataset[np.array(dataset.columns)], hue='fetal_health')","metadata":{"execution":{"iopub.status.busy":"2021-08-01T22:45:43.74706Z","iopub.execute_input":"2021-08-01T22:45:43.747498Z","iopub.status.idle":"2021-08-01T22:45:50.289946Z","shell.execute_reply.started":"2021-08-01T22:45:43.747461Z","shell.execute_reply":"2021-08-01T22:45:50.287758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tendo ajustado o dataset, podemos gerar nossos classificadores e executar os algoritmos selecionados:","metadata":{}},{"cell_type":"code","source":"# Criamos arrays que irão armazenar os tempos de execução e acurácia de cada um dos algoritmos\naccuracies, times = [], []\n\n# Também armazenamos os nomes dos algoritmos para utilizar posteriormente na impressão dos resultados\nalgorithms = ['SVM', 'MLP', 'KNN', 'Random Forest']\n\n# Classificações possíveis dos dados\nclasses = ['Normal', 'Suspeito', 'Patológico']\n\n# Geramos nossos 4 classificadores com auxílio das bibliotecas importadas\nclf_svm = svm.SVC(kernel = 'poly', C = 1)\nclf_mlp = MLPClassifier(random_state = 1, learning_rate_init = 0.003 , max_iter = 10000)\nclf_knn = KNeighborsClassifier(n_neighbors = 1)\nclf_rfc = RandomForestClassifier(random_state = 30)\n\nclassifiers = [clf_svm, clf_mlp, clf_knn, clf_rfc]","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:10:57.868665Z","iopub.execute_input":"2021-08-02T01:10:57.869008Z","iopub.status.idle":"2021-08-02T01:10:57.875472Z","shell.execute_reply.started":"2021-08-02T01:10:57.868978Z","shell.execute_reply":"2021-08-02T01:10:57.874391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Após gerados os classificadores, podemos realizar o fit e imprimir o tempo de execução de cada um deles:","metadata":{}},{"cell_type":"code","source":"# Imprime os tempos de execução obtidos\ndef print_exec_times(algorithms):\n    for i in range(len(algorithms)):\n        print(algorithms[i], \" - Tempo de execução em segundos: \", times[i])\n        \n# Executam o fit dos classificadores\ndef classifiers_fit(classifiers):\n    for i in range(len(classifiers)):  \n        init = tm.time()\n        classifiers[i].fit(X_train, y_train)\n        end = tm.time()\n\n        times.insert(0, end - init)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:11:04.022123Z","iopub.execute_input":"2021-08-02T01:11:04.022461Z","iopub.status.idle":"2021-08-02T01:11:04.028267Z","shell.execute_reply.started":"2021-08-02T01:11:04.022434Z","shell.execute_reply":"2021-08-02T01:11:04.027321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifiers_fit(classifiers)\nprint_exec_times(algorithms)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:11:07.037116Z","iopub.execute_input":"2021-08-02T01:11:07.037492Z","iopub.status.idle":"2021-08-02T01:11:08.864777Z","shell.execute_reply.started":"2021-08-02T01:11:07.037458Z","shell.execute_reply":"2021-08-02T01:11:08.863895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Agora que obtemos os classificadores e realizamos o fit de cada um deles, vamos calcular as acurácias:","metadata":{}},{"cell_type":"code","source":"# Calcula a acurácia de cada um dos classificadores\ndef calculate_accuracies(classifiers):\n    i = 0\n    for classifier in classifiers:\n        accuracies.insert(i, classifier.score(X_test, y_test).round(4) * 100)\n        i += 1\n\n# Imprime a acurácia de cada um dos classificadores \ndef print_accuracies(accuracies, algorithms):\n    for i in range(len(classifiers)):\n        print(algorithms[i], \" - Acurácia: \", accuracies[i], \"%\")","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:11:14.769482Z","iopub.execute_input":"2021-08-02T01:11:14.769815Z","iopub.status.idle":"2021-08-02T01:11:14.775245Z","shell.execute_reply.started":"2021-08-02T01:11:14.769788Z","shell.execute_reply":"2021-08-02T01:11:14.774599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"calculate_accuracies(classifiers)\nprint_accuracies(accuracies, algorithms)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:11:18.169069Z","iopub.execute_input":"2021-08-02T01:11:18.1696Z","iopub.status.idle":"2021-08-02T01:11:18.391125Z","shell.execute_reply.started":"2021-08-02T01:11:18.169558Z","shell.execute_reply":"2021-08-02T01:11:18.390321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos notar que o melhor desempenho foi o do Random Forest, seguido do KNN, os dois quase alcançaram 100% de acurácia.\n\nComo era de se esperar, o MLP foi o algoritmo que obteve a menor quantidade de acertos, pois este algoritmo performa melhor em problemas não-linearmente separáveis.\n\nAgora, vamos imprimir o detalhamento dos resultados obtidos por cada um dos algoritmos:","metadata":{}},{"cell_type":"code","source":"# Imprime o report da classificação do algoritmo\ndef generate_classification_report(X, y, classifier, classes, algorithm): \n    print(algorithm, \" - Resultados: \\n\\n\", classification_report(y, classifier.predict(X), target_names=classes))","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:11:23.762597Z","iopub.execute_input":"2021-08-02T01:11:23.762941Z","iopub.status.idle":"2021-08-02T01:11:23.768655Z","shell.execute_reply.started":"2021-08-02T01:11:23.762913Z","shell.execute_reply":"2021-08-02T01:11:23.767409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(algorithms)):\n    generate_classification_report(X_test, y_test, classifiers[i], classes, algorithms[i])","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:11:25.957215Z","iopub.execute_input":"2021-08-02T01:11:25.957589Z","iopub.status.idle":"2021-08-02T01:11:26.199606Z","shell.execute_reply.started":"2021-08-02T01:11:25.957558Z","shell.execute_reply":"2021-08-02T01:11:26.198859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Posteriormente, iremos calcular o f1-score de cada um dos algoritmos:","metadata":{}},{"cell_type":"code","source":"f1_scores = []\n\ndef generate_classifiers_f1_score(X, y, classifiers, algorithms): \n    for i in range(len(algorithms)):\n        f1_score_i = f1_score(y, classifiers[i].predict(X), average='macro')\n        f1_scores.insert(i, f1_score_i)\n        print(algorithms[i], \": f1-score = \", f1_score_i)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:11:30.573161Z","iopub.execute_input":"2021-08-02T01:11:30.573528Z","iopub.status.idle":"2021-08-02T01:11:30.578959Z","shell.execute_reply.started":"2021-08-02T01:11:30.573499Z","shell.execute_reply":"2021-08-02T01:11:30.577971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_classifiers_f1_score(X, y, classifiers, algorithms)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:11:32.908251Z","iopub.execute_input":"2021-08-02T01:11:32.908759Z","iopub.status.idle":"2021-08-02T01:11:33.452381Z","shell.execute_reply.started":"2021-08-02T01:11:32.908726Z","shell.execute_reply":"2021-08-02T01:11:33.45151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ao final, geramos os gráficos de comparação de tempo de execução, acurácia e f1-score:","metadata":{}},{"cell_type":"code","source":"# Geramos o gráfico Algoritmo x Tempo de Execução\nplt.bar(algorithms, times, color=\"orange\")\nplt.ylabel('Tempo de Execução (s)')\nplt.xlabel('Algoritmo')\nplt.title(\"Algoritmo x Tempo de Execução\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:11:36.469458Z","iopub.execute_input":"2021-08-02T01:11:36.469856Z","iopub.status.idle":"2021-08-02T01:11:36.591173Z","shell.execute_reply.started":"2021-08-02T01:11:36.469826Z","shell.execute_reply":"2021-08-02T01:11:36.590271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Geramos o gráfico Algoritmo x Acurácia\nplt.bar(algorithms, accuracies, color=\"orange\")\nplt.ylabel('Acurácia (%)')\nplt.xlabel('Algoritmo')\nplt.title(\"Algoritmo x Acurácia\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:11:39.964487Z","iopub.execute_input":"2021-08-02T01:11:39.964865Z","iopub.status.idle":"2021-08-02T01:11:40.189632Z","shell.execute_reply.started":"2021-08-02T01:11:39.964837Z","shell.execute_reply":"2021-08-02T01:11:40.188662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Geramos o gráfico Algoritmo x F1-Score\nplt.bar(algorithms, f1_scores, color=\"orange\")\nplt.ylabel('F1-Score (%)')\nplt.xlabel('Algoritmo')\nplt.title(\"Algoritmo x F1-Score\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T01:11:43.069177Z","iopub.execute_input":"2021-08-02T01:11:43.069532Z","iopub.status.idle":"2021-08-02T01:11:43.187208Z","shell.execute_reply.started":"2021-08-02T01:11:43.069502Z","shell.execute_reply":"2021-08-02T01:11:43.186375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Em relação aos acertos nos testes da classe \"**Patológico**\", os algoritmos Random Forest e KNN obteveram um desempenho excelente, com média 99% de precisão na classe nos testes realizados; logo atrás temos o MLP, com uma média de 89% de precisão, e por último o SVM, com média de 87%.\n\nA análise desta classe foi levada em consideração na análise por se tratar de um ponto crítico, já que uma classificação incorreta na mesma pode causar complicações sérias, dado o problema abordado.\n\nSe tratando de f1-score, os algoritmos Random Forest e KNN obteveram um desempenho excelente, com uma medida de precisão de teste de 100%; logo atrás temos o MLP, com uma média de 97% de precisão, e por último o SVM, com 87%.","metadata":{}},{"cell_type":"markdown","source":"# Conclusão\n\nPor fim, podemos concluir que o algoritmo que melhor performou em nossa análise, ficando na primeira colocação em todos os testes, exceto o tempo de execução, foi o Random Forest, que conseguiu aliar uma rápida excução com uma excelente precisão. Pode-se inferir também, com base nos resultados, que o KNN é uma ótima solução também para a classificação do dataset. Ao final, conseguimos notar que o MLP e SVM, apesar do bom desempenho, para o problema em questão, dado os parâmetros utilizados, não são a melhor opção para problemas similares ao estudado nesta análise.","metadata":{}},{"cell_type":"markdown","source":"*Feito por Thiago Henrique Leite da Silva, aluno do 5º semestre de Ciência da Computação na Universidade Federal de São Paulo. (UNIFESP)*","metadata":{}}]}