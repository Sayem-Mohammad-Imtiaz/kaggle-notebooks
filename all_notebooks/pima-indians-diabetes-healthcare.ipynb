{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Data Pre-proccessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing important libraries\nimport pandas as pd, numpy as np\nimport seaborn as sns\n\nimport os\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Current working directory\nos.getcwd()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The current working directory name\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load the data\nhealth =  pd.read_csv(\"../input/pima-indians-diabetes/health care diabetes.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check the nature of the datasets\nprint(health.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#View the the first 10 instances\nhealth.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Column wise null values check\nhealth.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For the entire DataFrame null values check\nhealth.isnull().any().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We obesrve that the data contains no null values, however let's do the value counts to see the nomalies of each variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#The mean of the variable 'Insulin'\nprint(health['Insulin'].mean(), health['Insulin'].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Describe the data to get the various statistics excluding the 'missing values' for the entire DataFrame \nhealth.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"health.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check the value counts for each of the indexes\nfor col in health.columns:\n    print('The value counts in '+col+' are:', health[col].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there are 0 values in columns(BloodPressure, SkinThickness, Insulin, BMI) which is anomaly, as this is \nthe first thing for every patients prior the doctor's consultation.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Performing a value_count plot below for Glucose. We can see zeros about six of them.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# We further do a histogram plot (value_counts) for Glucose column to see if contain any 0 values.\n\nplt.figure(figsize=(18,8))\nhealth['Glucose'].value_counts().plot.bar(title='Frequency Distribution of Glucose')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The distribution column of the Glucose shows a positively skewed distribution. A large number of values occurs on the left\n#with the fewer number of data values on the right side.\nplt.figure(figsize=(18,8))\nhealth['Glucose'].value_counts().plot.hist(title='Frequency Distribution of Glucose', color='g')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data type conversions\nhealth['BMI'] = health['BMI'].astype('int64')\nhealth['DiabetesPedigreeFunction'] = health['DiabetesPedigreeFunction'].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show new data types\nhealth.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"health.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_with_0 = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Visually explore these columns using histogram","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exploring the variables using histogram\nhealth.hist(column=col_with_0, rwidth=0.95, figsize=(15,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We set an appropriate range to observe the 0 value counts\nhealth.hist(column=col_with_0, bins=[0,10,15], rwidth=0.95, figsize=(15,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace the all the zero values with NaN\ncols = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']\nhealth[cols] = health[cols].replace(0, np.nan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"health","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Treat the missing values with the pandas method using the mean.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"health.fillna(health.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"health = health.fillna(health.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"health.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"health['Pregnancies']=health['Pregnancies'].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"health.hist(column=cols, rwidth=0.95, figsize=(15,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the Histogram barplot to compare the frequency distribution of each indexes.\n# We also create a range to compare and analyse different distribution.\n\nbins=[40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200]\n\nplt.hist(health['Glucose'], rwidth=0.95, bins=bins, color='g')\nplt.xlabel('Glucose range')\nplt.ylabel('Total no of patients')\nplt.title('Glucose Analysis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The nomal glucose level is between 80 and 115. If its above 115 you are considered as diabetic, the outcome is '1'.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We can observe above that in 120 glucose range there are more than 100 patients considered possible diabetic. The maximum \nnumber of patients with no diabetic is almost 120. The number of patients who are normal are more the number of pre-diabetic \nor diabetic patients.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bin_BP=[10,20,30,40,50,60,70,80,100,110,120,130]\n\nplt.hist(health['BloodPressure'], bins=bin_BP, rwidth=0.9, color='orange', orientation='horizontal')\nplt.title('Blood Presure Analysis')\nplt.xlabel('No of patients')\n\nplt.ylabel('BloodPressure range')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the new data type\nhealth.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(health.dtypes.map(str))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib.pyplot import figure\nfigure(figsize=(16,8))\nsns.countplot(data=health, x='Age', hue='Outcome')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We note in the above age count plot that:\n+ The age between 21 to 30 have the more patients without diabetes compared to the patients with diabetes. However, we \nobserve that most of our data is distributed between this range of age. If you are in this age range you are more likely to\nhave no diabetes.\n+ The age between 31 to 54 have more diabetic patients compared to non diabetic, when you grow older you are more likely to\nhave diabetes. One of the factors causing this may be the less activities and excercises compared to the age between 21-30.\n+ The older patients from age 54 up to the age of 81 which are less populated, they are more likey to have diabetes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax =plt.subplots(1,2)\nfigure(figsize=(12,6))\nsns.countplot(health['Age'],  ax=ax[0])\nsns.countplot(health['DiabetesPedigreeFunction'], ax=ax[1])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"health=health.astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"health.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(health['Glucose'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2, 4, figsize=(20, 10))\nfor variable, subplot in zip(health, ax.flatten()):\n    sns.countplot(health[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"health['Outcome'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=health, x='Outcome', palette='hls')\nplt.show()\nplt.savefig('count_plot')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This is an Impalanced Data\n+ Looking at the count plot above we can see that we are dealing with an imbalanced data. Which refers to a problem with \nclassification problems where the classes are not represented equally.\n+ This is an imbalanced dataset and the ratio of class-1 to class-0 instances is 500:268 or more concisely 2:1.\n\n### Techniques we can use to combat the imbalanced training data:\n#### 1.Collect More Data\n+ The collection of more data is the another good way of fixing the imbalanced data. The large dataset might expose a\ndifferent and perhaps more balanced perspective on the classes.\n\n#### 2.Change the Performance Metric\n+ Accuracy is not the metrics to use when dealing with an imbalanced dataset, this metric is misleading.\n+ There are metrics that have been designed to tell us a more truthful story when working with an imbalanced dataset.\n+ The following performance measures can give more insight into the accuracy of the model than the traditional  \nclassification accuracy:\n    \n##### Confusion Matrix: \n+ A breakdown of predictions into a table showing correct predictions (the diagonal) and the types of incorrect \n predictions made (what classes incorrect predictions were assigned).\n##### Precision: \n+ A measure of a classifiers exactness.\n##### Recall:\n+ A measure of a classifiers completeness\n   ##### F1 Score (or F-score): \n+ A weighted average of precision and recall.\n   \n    We can also look at the following:\n##### ROC Curves: \n+ Like precision and recall, accuracy is divided into sensitivity and specificity and models can be chosen\nbased on the balance thresholds of these values.\n            \n#### 3. Try Different Algorithms  \n+ Using one favorite algorithm on every problem is not adviceable. Using different algorithms on a problem will give \ndifferent results and accuracy. Random Forest and Decision tree algorithms they often perform well.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(y=health['Age'], x=health['Outcome']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Feature-Feature Relationships\n+ We explore the relationship between the attributes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# The scatter charts between the pair of variables to understand the relationship.\nsns.pairplot(health)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the pair plot above we can see that we have the positive correlation between BMI and SkinThickness, no correlation between Glucose and SkinThickness. Age have the strong positive correlation with bloodPressure.","execution_count":null},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"from pandas.plotting import scatter_matrix\nscatter_matrix(health, alpha=0.2, figsize=(16, 10), diagonal='kde')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"+ Looking at the matrix of scatter plots of all attributes versus all attributes. We can see possible correlation between the \nBloodPressure and BMI and another possible relationship between Age and Pregnancies.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Correlation Analysis and Feature Selection","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Univariate Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Important libraries\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nX = health.iloc[:,0:8]\ny = health.iloc[:,-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Apply SeleckKBest class to extarct top 6 best features\nbestfeatures = SelectKBest(score_func=chi2, k=6)\nfit = bestfeatures.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Concat two DataFrames for better visualization\nfeatureScores = pd.concat([dfcolumns, dfscores], axis=1)\nfeatureScores.columns = ['col','Score']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The feature with highest scores will be much more correlated to the 'Outcome' feature that we have in our dataset.\nBelow if the the score is high, then the more important that feature is. We can see that the Insulin and Glucose have the\nhighest scores, that means if the Glucose and Insulin increases the Outcome of patients with diabetes also increases.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"featureScores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the 6 best features\nprint(featureScores.nlargest(6,'Score'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above we can observe the top six features that are correlated to the Outcome variable.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Correlation Matrix with Heatmap","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#The correlation of each feauture in the dataset\ncorrmat = health.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(16,8))\n#We plot the heatmap\nsns.heatmap(health[top_corr_features].corr(), annot=True, cmap='RdYlGn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"+ Here we can infer that \"Outcome\" has the strong positive correlation with \"Glucose\" whereas it almost has no correlation \n  with DiabetesPedigreeFunction.\n+ \"SkinThickness\" and \"Insulin\" has almost no correlation with \"Pregnancies\".\n+ There is a strong correlation between independent features which are \"Insulin and Glucose\", \"BMI and SkinThickness\", \"Age and\n  Pregnancies\".","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Correlation matrix with heatmap also gives a clear correlation between independent features, which is very great.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can drop this two features since they are not correlated with target variable(Outcome)\nhealth.drop(['BloodPressure','DiabetesPedigreeFunction'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"health.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Modeling","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### To medel this dataset I will use logistic Regression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Logistic Regression\n\nIn statistics, the logistic model is used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead or healthy/sick.\n\nLogistic regression is the appropriate regression analysis to conduct when the dependent variable is dichotomous (binary). ... Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#split the dataset in features and target varaible\nX = health.drop(\"Outcome\", axis=1)\ny = health[\"Outcome\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Split the datset\nTo understand the model perfomance we split the datasets into training set and test set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split X and y into training and testing set.\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The 75% of the data will be used for model training and 25% for model testing.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Model Development and predictions\n+ Import the Logistc Regressiom module and create a Logistic Regressin classifier object using LogisticRegression() unction.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the class\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#instantiate the model\nlogreg = LogisticRegression()\n\n#fit the model with train data\nlogreg.fit(X_train, y_train)\n\n#fit the model with predictor test data(X_test)\ny_pred = logreg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model Evaluation using Confusion Matrix","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Confusion Matrix\n\nA confusion matrix is a table that is often used to describe the performance of a classification model (or “classifier”) \non a set of test data for which the true values are known. It allows the visualization of the performance of an algorithm. It \nis a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the metrics\nfrom sklearn import metrics\ncf_matrix = metrics.confusion_matrix(y_test, y_pred)\ncf_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dimension of this matrix is 2*2 because this model is binary classification. We have two classes 0 and 1.\nDiagonal values represent accurate predictions, while non-diagonal elements are inaccurate predictions.\n\nThere were 118 True Positives, patients with diabetes that were correctly classified and 33 True Negatives, patients without\ndiabetes that were correctly classified. However, the algorithm misclassified 29 patients that did have a diabetes by saying \nthey did not (False Negative) and algorithm misclassified 12 patients that did not have diabetes by saying that they\ndid (False Positive)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Visual Confinsion Matrix using Heatmap\nWe visualize the results of the model in the form of the confusion matrix using matplotlib and seaborn.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\nsns.heatmap(pd.DataFrame(cf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Evaluation Matrix of Confusion Matrix\n+ Accuracy, Precision, and Recall\n\n    + Accuracy is the proportion of true results among the total number of cases examined.\n    + Precision gives the proportion of predicted Positives that are truly Positive.\n    + Recall measures the proportion of actual Positives that were correctly classified.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We got the classification rate of 78% considered as the good accuracy. This are true results among the total number of cases \nexamined.\n\nThe model got the 73% accururateness in predicting the patients with diabetes.\n\nReacall: This are the results of the patients predicted to have diabetes and Logistic regression can capture 53% of patients\n    with diabetes.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Comparing the KNN Algorithm with DecisionTree, Random Forest, and Logistic Regression classifier.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### We use the pipeline in sklearn","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the libraries (pipeline and models)\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_dt=Pipeline([('dt_classifier',DecisionTreeClassifier(random_state=0))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_rf=Pipeline([('rf_classifier',RandomForestClassifier())])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_knn=Pipeline([('kn_classifier',KNeighborsClassifier())])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_lr=Pipeline([('lr_classifier',LogisticRegression())])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Make the list of pipelines\npipelines = [pipeline_dt,pipeline_rf,pipeline_knn,pipeline_lr]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_accuracy=0.0\nbest_classifier=0\nbest_pipeline=\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dictionery of pipelines and classifier type for ease of reference\npipe_dict = {0: 'Decision Tree', 1: 'RandomForest', 2: 'KNeighbors', 3:'Logistic Regression'}\n\n#Fit the pipilines\nfor pipe in pipelines:\n    pipe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,model in enumerate(pipelines):\n    print(\"{} Test Accuracy: {}\".format(pipe_dict[i],model.score(X_test,y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,model in enumerate(pipelines):\n    if model.score(X_test,y_test)>best_accuracy:\n        best_accuracy=model.score(X_test,y_test)\n        best_pipeline=model\n        best_classifier=i\nprint('Classifier with best accuracy:{}'.format(pipe_dict[best_classifier]))         ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression is the best classifier compared with other algorithms, with the good accuracy of 78%. This is the\nproportion of true results among the total number of cases examined.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### The Confusion Matrix for each Agorithm","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Decision Tree Confusion Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_0 = pipeline_dt.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_cnf_matrix=metrics.confusion_matrix(y_test,y_pred_0)\ndt_cnf_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Random Forest Confusion Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_1 = pipeline_rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_cnf_matrix=metrics.confusion_matrix(y_test,y_pred_1)\nrf_cnf_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### KNeighborsClassifier Confusion Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_3 = pipeline_knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_cnf_matrix=metrics.confusion_matrix(y_test,y_pred_3)\nknn_cnf_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### LogisticRegression Confusion Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_4=pipeline_lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_cnf_matrix=metrics.confusion_matrix(y_test,y_pred_4)\nlr_cnf_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the results the KNN correctly classified 113 patients with diabetes and 34 patients without diabetes, better TP\ncompared to the Decision Tree and Random Forest. Decision Tree and Random Forest are the only classifiers with the better number of True Negatives\ncompared to other classifiers. However KNN did better compared to the Logistic Regression which got 118 correctly \nclassified patients with diabetes and 33 correctly classified patients without diabetes.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"If identifying patients without diabetes was more important in this data we would choose Random Forest or Decision tree Classifier. \nAlso if identifying patients with diabetes was more important in this data, we would choose Logistic regression.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### The Logistic Regression or KNeighbors Classifier are better choices over Random Forest and Decision Tree Classifier in correctly identifying true positive patients.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"However the two Confusion Matric of Logistic Regression and KNeighbors Classifier make it hard to choose which machine\nlearning method is the better fit for this data. They differ with a small margin.\n+ We need to use more sophisticated metrics, like Sensitivity, Specificity, ROC and AUC that can help us make a decision.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Sensitivity and Specificity\n+ Sensitivity tells us what percentage of patients with diabetes were correctlly identified.\n+ Specificity tells us what percentage of patients without diabetes were correctly identified.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Sensitivity and Specificity of Random Forest and Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# For KNeighbors\nsensitivity, specificity= [113/(113+28), 34/(34+17)]\nprint(\"sensitivity:\", sensitivity)\nprint(\"specificity:\", specificity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For Logistic Regression\nsensitivity, specificity= [117/(117+29), 33/(33+13)]\nprint(\"sensitivity:\", sensitivity)\nprint(\"specificity:\", specificity)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since identifying patients with diabetes and without diabetes were more important. We choose Logistic Regression as the best \nclassifier for both classifications, beacuse of its good sensitivity and specificity compared to the KNeighbors classifier.\nWe take note that they have the same parcentage of sensitivity because Logistic Regression have the high number of errors of \nTrue Negative compared to KNeighbors.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### AUC Curve and Area Under ROC Curve in Machine Learning \n+ ROC or Receiver Operating Characteristic curve is used to evaluate classification models in Machine Learing.\n+ ROC or Receiver Operating Characteristic plot is used to visualise the performance of a binary classifier. It gives us the\ntrade-off between the True Positive Rate (TPR) and the False Positive Rate (FPR) at different classification thresholds.\n+ It is nothing but a graph dispalying the performance of a classification model.\n+ It is very popular model to measure the accuracy of a classification model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Lets try and Improve the performance of Random Classifier by thresholding","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### ROC Curve of the Random Forest Classifier vs. Perfect Classifier(default threshold(0.5))","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the roc libraries and use roc_curve() to get the threshold, TPR, and FPR\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfpr, tpr, thresholds = roc_curve(y_test, pipeline_rf.predict_proba(X_test)[:,1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The fpr, tpr and threshold arrays:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thresholds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For AUC we use roc_auc_score() function for ROC\nrf_roc_auc1 = roc_auc_score(y_test, pipeline_rf.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot the ROC Curve\nplt.figure()\nplt.plot(fpr, tpr, label='Random Forest(Sensitivity = %0.3f)' % rf_roc_auc1)\nplt.plot([0,1], [0,1], 'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tuning the threshold value to build a classifier model with more desired output.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# The predicted probabilities of class 1(diabetes patients)\ny_pred_11 = pipeline_rf.predict_proba(X_test)[:,1]\ny_pred_11 = y_pred_11.reshape(1,-1)\ny_pred_11","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set the threshold at 0.35\nfrom sklearn.preprocessing import binarize\ny_pred_11 = binarize(y_pred_11,0.6)[0]\ny_pred_11","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting the array from float data type to integer data type\ny_pred_11 = y_pred_11.astype(int)\ny_pred_11","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_cnf_matrix1 = metrics.confusion_matrix(y_test, y_pred_11)\nrf_cnf_matrix1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"+ Note: Here\n    + True Positive is 117\n    + True Negative is 32\n    + False Positve is 13\n    + False Negative is 30\n    \nWe can clearly see the classifier has improved. Compare with the previous Confusion Matrix given below:    ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_cnf_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Other performance matrics\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred_11))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We compare the performance metrics (above) at threshold 0.6 to the performance metrics at default threshold (below).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred_1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see an improvement on the precision of the threshold classifier with 70% on classification patients with diabetes.\nWhereas the default classifier got 69% of patients with diabetes.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We observe how sensitity changes with threshold, we plot the ROC Curve again.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_roc_auc2 = roc_auc_score(y_test, y_pred_11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.plot(fpr, tpr, label='Threshold=.5=>Sensitivity = %0.3f,\\nThreshold=.6=>Sensitivity= %0.3f' % (rf_roc_auc1,rf_roc_auc2))\nplt.plot([0,1], [0,1], 'r--')\nplt.plot([0,1], [0,1], 'b--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"best\")\nplt.savefig('Log_ROC')         \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the sensitivity for the threshold which is slightly below the default threshold, this is because there was an \nincrease of the False Negative","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### ROC Curve for Logistic Regression Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# We use roc_curve() to get the threshold, TPR and FPR\nfpr, tpr, thresholds = roc_curve(y_test, pipeline_lr.predict_proba(X_test)[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thresholds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For AUC we use roc_auc_score() function for ROC\nlr_roc_auc3 = roc_auc_score(y_test, pipeline_lr.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot the ROC Curve\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression(Sensitivity = %0.3f)' % lr_roc_auc3)\nplt.plot([0,1], [0,1], 'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"+ We can tune the threshold values to build a classifier model with more desired output for Logistic algorithm and other \nclassifier models.\n+ ROC curve assist to choose a threshold that balances sensitivity and specificity that makes sense of perspective for certain\nconditions.\n+ Increasing the threshold may decrease the sensitivity and increase the specificity. Therefore sensitivity is inversely \nproportional to the the specificity. There is always a trade-off between sensitivity and specificity.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}