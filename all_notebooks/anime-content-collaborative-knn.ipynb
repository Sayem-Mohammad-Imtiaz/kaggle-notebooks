{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Anime Recommended System - Content Based & Collaborative Filtering\n\nThis notebook use a classic method (KNN) to recommend anime using 2 different approach: \n\n- Content Based\n- Collaborative Filtering\n\nIn Content bases, I explore 7 ways to recommend a list of anime based in 1 given anime:\n\n1. Only Metadata\n2. Using one hot encoding to embedding the genre.\n3. Using TF-IDF to embedding the genre\n4. Concatenate opction 1, 2 and 3.\n5. Apply PCA to generate reduced vector of option 4.\n6. Using TF-IDF to embedding the synopsis\n7. Apply PCA to generate reduced vector of option 6.\n\n\nI was based on the following work https://www.kaggle.com/benroshan/content-collaborative-anime-recommendation","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer, MinMaxScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.neighbors import NearestNeighbors\nfrom scipy.sparse import csr_matrix\nfrom sklearn.decomposition import PCA\n\npd.set_option(\"max_colwidth\", None)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T06:38:45.047897Z","iopub.execute_input":"2021-05-22T06:38:45.048282Z","iopub.status.idle":"2021-05-22T06:38:45.054697Z","shell.execute_reply.started":"2021-05-22T06:38:45.048252Z","shell.execute_reply":"2021-05-22T06:38:45.053454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Content Based","metadata":{}},{"cell_type":"code","source":"usecols = [\"MAL_ID\", \"Name\", \"Score\", \"Genders\", \"Type\", \"Episodes\", \"Premiered\",\n           \"Studios\", \"Source\", \"Rating\", \"Members\"]\n\nanime_data=pd.read_csv('../input/anime-recommendation-database-2020/anime.csv',usecols=usecols)\n\nprint(\"anime_data.shape:\", anime_data.shape)\n\nanime_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T06:38:45.588197Z","iopub.execute_input":"2021-05-22T06:38:45.588569Z","iopub.status.idle":"2021-05-22T06:38:45.723046Z","shell.execute_reply.started":"2021-05-22T06:38:45.588541Z","shell.execute_reply":"2021-05-22T06:38:45.72203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_multilabel(series):\n    series = series.split(\",\")\n    if \"Unknown\" in series:\n        series.remove(\"Unknown\")\n    return series\n\nanime_data[\"Genders\"] = anime_data[\"Genders\"].map(process_multilabel)\nanime_data[\"Studios\"] = anime_data[\"Studios\"].map(process_multilabel)\nanime_data[\"Score\"] = anime_data[\"Score\"].replace(\"Unknown\", 0).astype(float)\nanime_data[\"Episodes\"] = anime_data[\"Episodes\"].replace(\"Unknown\", 0).astype(int)\n\nanime_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T06:38:46.651831Z","iopub.execute_input":"2021-05-22T06:38:46.652186Z","iopub.status.idle":"2021-05-22T06:38:46.846965Z","shell.execute_reply.started":"2021-05-22T06:38:46.652157Z","shell.execute_reply":"2021-05-22T06:38:46.845938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessing_category(df, column, is_multilabel=False):\n    # Binarise labels\n    lb = LabelBinarizer()\n    if is_multilabel:\n        lb = MultiLabelBinarizer()\n        \n    expandedLabelData = lb.fit_transform(df[column])\n    labelClasses = lb.classes_\n\n    # Create a pandas.DataFrame from our output\n    category_df = pd.DataFrame(expandedLabelData, columns=labelClasses)\n    del df[column]\n    return pd.concat([df, category_df], axis=1)\n\nanime_metadata = anime_data.copy()\nanime_metadata = preprocessing_category(anime_metadata, \"Type\")\nanime_metadata = preprocessing_category(anime_metadata, \"Premiered\")\nanime_metadata = preprocessing_category(anime_metadata, \"Studios\", is_multilabel=True)\nanime_metadata = preprocessing_category(anime_metadata, \"Source\")\nanime_metadata = preprocessing_category(anime_metadata, \"Rating\")\n\nGenders = anime_metadata[\"Genders\"]\nID_NAME = anime_metadata[[\"MAL_ID\", \"Name\"]]\n\ndel anime_metadata[\"Genders\"]\ndel anime_metadata[\"MAL_ID\"]\ndel anime_metadata[\"Name\"]\ndel anime_metadata[\"Unknown\"]\n\nanime_metadata[[\"Score\", \"Episodes\", \"Members\"]] = MinMaxScaler().fit_transform(anime_metadata[[\"Score\", \"Episodes\", \"Members\"]])\nanime_metadata = anime_metadata.values","metadata":{"execution":{"iopub.status.busy":"2021-05-22T06:38:56.837539Z","iopub.execute_input":"2021-05-22T06:38:56.837966Z","iopub.status.idle":"2021-05-22T06:38:58.663514Z","shell.execute_reply.started":"2021-05-22T06:38:56.837928Z","shell.execute_reply":"2021-05-22T06:38:58.662689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfv = TfidfVectorizer(min_df=3,  max_features=None, \n            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 3),\n            stop_words = 'english')\n\n# Filling NaNs with empty string\ngenres_original = anime_data['Genders'].fillna('').astype(str)\ngenres_vector_tf_idf = tfv.fit_transform(genres_original)\n\ngenres_vector_one_hot = preprocessing_category(pd.DataFrame(Genders), \"Genders\", True).values","metadata":{"execution":{"iopub.status.busy":"2021-05-22T06:39:00.078265Z","iopub.execute_input":"2021-05-22T06:39:00.07887Z","iopub.status.idle":"2021-05-22T06:39:00.430147Z","shell.execute_reply.started":"2021-05-22T06:39:00.078835Z","shell.execute_reply":"2021-05-22T06:39:00.429169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"anime_metadata.shape:\", anime_metadata.shape)\nprint(\"genres_vector_tf_idf.shape:\", genres_vector_tf_idf.shape)\nprint(\"genres_vector_one_hot.shape:\", genres_vector_one_hot.shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T06:39:03.255167Z","iopub.execute_input":"2021-05-22T06:39:03.25574Z","iopub.status.idle":"2021-05-22T06:39:03.261923Z","shell.execute_reply.started":"2021-05-22T06:39:03.25569Z","shell.execute_reply":"2021-05-22T06:39:03.260946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Recommend with KNN","metadata":{}},{"cell_type":"code","source":"def get_recommended(vector, query_index, n_neighbors=10):\n    model_knn = NearestNeighbors(metric='cosine', n_neighbors=n_neighbors)\n    model_knn.fit(csr_matrix(vector))\n\n    distances, indices = model_knn.kneighbors(vector[query_index,:].reshape(1, -1), n_neighbors = n_neighbors)\n    result = []\n    for i in range(0, len(distances.flatten())):\n        index = indices.flatten()[i]\n        if index == query_index:\n            continue\n        result.append(anime_data.iloc[index])\n        \n    return pd.DataFrame(result)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T06:39:09.245255Z","iopub.execute_input":"2021-05-22T06:39:09.245673Z","iopub.status.idle":"2021-05-22T06:39:09.252728Z","shell.execute_reply.started":"2021-05-22T06:39:09.245609Z","shell.execute_reply":"2021-05-22T06:39:09.251438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# query_index = np.random.choice(anime_metadata.shape[0])\nquery_index = ID_NAME[ID_NAME.MAL_ID == 32281].index[0]\nanime_data.iloc[[query_index]]","metadata":{"execution":{"iopub.status.busy":"2021-05-22T06:39:09.556463Z","iopub.execute_input":"2021-05-22T06:39:09.556858Z","iopub.status.idle":"2021-05-22T06:39:09.575788Z","shell.execute_reply.started":"2021-05-22T06:39:09.556827Z","shell.execute_reply":"2021-05-22T06:39:09.574745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_recommended(anime_metadata, query_index, 10)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T06:39:12.152675Z","iopub.execute_input":"2021-05-22T06:39:12.153048Z","iopub.status.idle":"2021-05-22T06:39:12.516703Z","shell.execute_reply.started":"2021-05-22T06:39:12.153013Z","shell.execute_reply":"2021-05-22T06:39:12.515827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_recommended(genres_vector_tf_idf, query_index, 10)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T06:39:12.625183Z","iopub.execute_input":"2021-05-22T06:39:12.625735Z","iopub.status.idle":"2021-05-22T06:39:12.662144Z","shell.execute_reply.started":"2021-05-22T06:39:12.62566Z","shell.execute_reply":"2021-05-22T06:39:12.661203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_recommended(genres_vector_one_hot, query_index, 10)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T06:39:13.121171Z","iopub.execute_input":"2021-05-22T06:39:13.121574Z","iopub.status.idle":"2021-05-22T06:39:13.175033Z","shell.execute_reply.started":"2021-05-22T06:39:13.121542Z","shell.execute_reply":"2021-05-22T06:39:13.173944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data = np.concatenate((anime_metadata, genres_vector_tf_idf.todense(), genres_vector_one_hot), axis=1)\nall_data.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-22T06:39:15.065578Z","iopub.execute_input":"2021-05-22T06:39:15.066047Z","iopub.status.idle":"2021-05-22T06:39:15.616028Z","shell.execute_reply.started":"2021-05-22T06:39:15.066015Z","shell.execute_reply":"2021-05-22T06:39:15.614999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_recommended(all_data, query_index, 10)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T06:39:17.890366Z","iopub.execute_input":"2021-05-22T06:39:17.89075Z","iopub.status.idle":"2021-05-22T06:39:18.379351Z","shell.execute_reply.started":"2021-05-22T06:39:17.890716Z","shell.execute_reply":"2021-05-22T06:39:18.378216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nreduced_all_data = PCA(n_components=250).fit_transform(all_data)\nget_recommended(reduced_all_data, query_index, 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Use Synopsis and TF-IDF","metadata":{}},{"cell_type":"code","source":"usecols = [\"MAL_ID\", \"Name\", \"Genders\", \"sypnopsis\"]\nanime_data_2 = pd.read_csv('../input/anime-recommendation-database-2020/anime_with_synopsis.csv', usecols=usecols)\nanime_data_2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_index_2 = anime_data_2[anime_data_2.MAL_ID == 32281].index[0]\nanime_data_2.iloc[[query_index_2]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfv = TfidfVectorizer(min_df=3,  max_features=None, \n            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 3),\n            stop_words = 'english')\n\n# Filling NaNs with empty string\n\nsynopsis_original = anime_data_2['sypnopsis'].fillna('').astype(str)\nsynopsis_vector_tf_idf = tfv.fit_transform(synopsis_original)\nsynopsis_vector_tf_idf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_recommended_another_df(vector, query_index, n_neighbors=10):\n    model_knn = NearestNeighbors(metric='cosine', n_neighbors=n_neighbors)\n    model_knn.fit(csr_matrix(vector))\n\n    distances, indices = model_knn.kneighbors(vector[query_index,:].reshape(1, -1), n_neighbors = n_neighbors)\n    result = []\n    for i in range(0, len(distances.flatten())):\n        index = indices.flatten()[i]\n        if index == query_index:\n            continue\n        result.append(anime_data_2.iloc[index])\n        \n    return pd.DataFrame(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_recommended_another_df(synopsis_vector_tf_idf, query_index_2, 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nreduced_all_data = PCA(n_components=250).fit_transform(synopsis_vector_tf_idf.todense())\nget_recommended_another_df(reduced_all_data, query_index_2, 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Collaborative Filtering","metadata":{}},{"cell_type":"code","source":"rating_data=pd.read_csv('../input/anime-recommendation-database-2020/rating_complete.csv')\n\nprint (\"rating_data.shape:\", rating_data.shape)\nprint (rating_data.info())\nrating_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"users_count = rating_data.groupby(\"user_id\").size().reset_index()\nusers_count.columns = [\"user_id\", \"anime_count\"]\n\nprint(users_count.shape)\n\nfiltered_users = users_count[users_count.anime_count >= 300]\nusers = set(filtered_users.user_id)\n\nprint(len(users))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rating_data = rating_data[rating_data.user_id.isin(users)]\nprint (\"rating_data.shape:\", rating_data.shape)\nprint (rating_data.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_users = {int(x): i for i,x in enumerate(rating_data.user_id.unique())}\nunique_items = {int(x): i for i,x in enumerate(anime_data.MAL_ID.unique())}\n\nprint(len(unique_items), len(unique_users))\nanime_collabolative_filter = np.zeros((len(unique_items), len(unique_users)))\n\nfor user_id, anime_id, rating in rating_data.values:\n    anime_collabolative_filter[unique_items[anime_id], unique_users[user_id]] = rating","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_recommended(anime_collabolative_filter, query_index, 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}