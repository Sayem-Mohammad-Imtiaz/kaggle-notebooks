{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from numpy import concatenate\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom tensorflow.keras import models,layers ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset=pd.read_csv(\"../input/bitcoin/BTC-EUR.csv\",\n                   index_col='Date',parse_dates=['Date'])\ntraining_set=dataset[:'2018'].iloc[:,2:3].to_numpy()\ntest_set=dataset['2018':].iloc[:,2:3].to_numpy()\n\nsc=MinMaxScaler(feature_range=(0,1))\ntraining_set_scaled=sc.fit_transform(training_set)\n\nX_train=[]\ny_train=[]\nprint(training_set.shape)\nfor i in range(60, training_set.shape[0]):\n    X_train.append(training_set_scaled [i-60:i])\n    y_train.append(training_set_scaled[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sample\n# zoom=np.array([[1,2,3],\n#               [4,5,6]])\n# zoom.reshape(-1,1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_tarin=np.array(X_train),np.array(y_train)\nX_train= np.reshape(X_train ,(X_train.shape[0],X_train.shape[1],1))\n\nregressor=models.Sequential([\n    layers.Dropout (0.30),\n    #GRU\n    layers.SimpleRNN(units=50, input_shape=(\n        X_train.shape[1],1)),\n    layers.Dense(units=1)])\n\nregressor.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\nregressor.fit(X_train ,y_tarin ,epochs= 3,batch_size=32)\n\ndataset_total=pd.concat(\n    (dataset[\"High\"][:'2018'],dataset[\"High\"]['2019':]),axis=0)\ninputs=dataset_total [len(dataset_total)-len(test_set)-60:].to_numpy()\ninputs=inputs.reshape(-1,1)\ninputs=sc.transform (inputs)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test=[]\nfor i in range(60, test_set.shape[0]):\n    X_test.append(inputs[i-60:i,0])\n   \nX_test=np.array(X_test)\nX_test=np.reshape(X_test ,(X_test.shape[0],X_test.shape[1],1))\n\npredicted_stock_price=regressor.predict(X_test)\npredicted_stock_price=sc.inverse_transform(predicted_stock_price)\n\nprint(X_test.shape)\nprint(predicted_stock_price.shape)\n\nplt.plot(predicted_stock_price , color='blue',\n        label='Predicted Stock Price')\n\nplt.plot(test_set ,color ='red', label='Real Stock Price')\nplt.title('Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Stock Price')\nplt.legend()\nplt.show()\n\n# regressor=models.Sequential([\n#     layers.LSTM(units=50, input_shape=(\n#          X_train.shape[1],1)),\n#     layers.Dense(units=1)])\n\n# regressor.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\n# regressor.fit(X_train ,y_tarin ,epochs= 30,batch_size=32)\n\n# plt.plot(predicted_stock_price, color='blue',\n#          label='Predicted Stock Price')\n\n# plt.plot(test_set ,color ='red', label='Real Stock Price')\n# plt.title('Stock Price Prediction')\n# plt.xlabel('Time')\n# plt.ylabel('Stock Price')\n# plt.legend()\n# plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regressor=models.Sequential([\n    layers.LSTM(units=50, input_shape=(\n         X_train.shape[1],1)),\n    layers.Dense(units=1)])\n\nregressor.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\nregressor.fit(X_train ,y_tarin ,epochs= 30,batch_size=32)\n\nplt.plot(predicted_stock_price, color='blue',\n         label='Predicted Stock Price')\n\nplt.plot(test_set ,color ='red', label='Real Stock Price')\nplt.title('Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Stock Price')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.plot(predicted_stock_price, color='blue',\n         label='Predicted Stock Price')\n\nplt.plot(test_set ,color ='red', label='Real Stock Price')\nplt.title('Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Stock Price')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}