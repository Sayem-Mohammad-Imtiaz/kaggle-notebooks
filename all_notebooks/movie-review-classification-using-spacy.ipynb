{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport re\nimport string\n%matplotlib inline\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-13T16:09:30.585222Z","iopub.execute_input":"2021-06-13T16:09:30.58559Z","iopub.status.idle":"2021-06-13T16:09:31.494915Z","shell.execute_reply.started":"2021-06-13T16:09:30.585555Z","shell.execute_reply":"2021-06-13T16:09:31.494071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Exploration and Processing","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:08:50.763172Z","iopub.execute_input":"2021-06-13T16:08:50.763549Z","iopub.status.idle":"2021-06-13T16:08:52.458241Z","shell.execute_reply.started":"2021-06-13T16:08:50.763507Z","shell.execute_reply":"2021-06-13T16:08:52.457457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:08:58.129913Z","iopub.execute_input":"2021-06-13T16:08:58.130306Z","iopub.status.idle":"2021-06-13T16:08:58.136285Z","shell.execute_reply.started":"2021-06-13T16:08:58.130271Z","shell.execute_reply":"2021-06-13T16:08:58.13545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,6))\nplt.title(\"Data Distribution\")\nsns.countplot(x = \"sentiment\", data = data)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:09:40.576791Z","iopub.execute_input":"2021-06-13T16:09:40.57715Z","iopub.status.idle":"2021-06-13T16:09:40.781567Z","shell.execute_reply.started":"2021-06-13T16:09:40.577119Z","shell.execute_reply":"2021-06-13T16:09:40.780756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['lenght'] = data['review'].apply(lambda x : len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:10:11.803022Z","iopub.execute_input":"2021-06-13T16:10:11.803615Z","iopub.status.idle":"2021-06-13T16:10:12.52677Z","shell.execute_reply.started":"2021-06-13T16:10:11.803554Z","shell.execute_reply":"2021-06-13T16:10:12.525831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,6))\nplt.title(\"Text lenght\")\n\nsns.histplot(x=\"lenght\", data = data)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:10:27.447837Z","iopub.execute_input":"2021-06-13T16:10:27.448337Z","iopub.status.idle":"2021-06-13T16:10:28.176233Z","shell.execute_reply.started":"2021-06-13T16:10:27.448304Z","shell.execute_reply":"2021-06-13T16:10:28.175165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (14,8))\nax1 = fig.add_subplot(121)\nplt.title(\"Positive text lenght\")\nsns.histplot(x=\"lenght\", data = data[data['sentiment'] == 'positive'], ax=ax1)\n\nax2 = fig.add_subplot(122)\nplt.title(\"Negative text lenght\")\nsns.histplot(x=\"lenght\", data = data[data['sentiment'] == 'negative'], ax=ax2)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:10:49.353846Z","iopub.execute_input":"2021-06-13T16:10:49.354185Z","iopub.status.idle":"2021-06-13T16:10:50.393934Z","shell.execute_reply.started":"2021-06-13T16:10:49.354157Z","shell.execute_reply":"2021-06-13T16:10:50.393163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example\ndata.iloc[1,0]","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:15:28.920481Z","iopub.execute_input":"2021-06-13T16:15:28.920922Z","iopub.status.idle":"2021-06-13T16:15:28.928473Z","shell.execute_reply.started":"2021-06-13T16:15:28.920888Z","shell.execute_reply":"2021-06-13T16:15:28.927164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_review(text):\n    clean_text = re.sub('<br\\s?\\/>|<br>', '', text) \n    clean_text = re.sub('[^a-zA-Z\\']', ' ', clean_text)\n    clean_text = clean_text.lower()\n    return clean_text","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:15:45.980204Z","iopub.execute_input":"2021-06-13T16:15:45.98059Z","iopub.status.idle":"2021-06-13T16:15:45.985576Z","shell.execute_reply.started":"2021-06-13T16:15:45.980551Z","shell.execute_reply":"2021-06-13T16:15:45.984863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['review'] = data['review'].apply(lambda x : clean_review(x))\ndata.iloc[1,0]","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:16:11.959633Z","iopub.execute_input":"2021-06-13T16:16:11.960244Z","iopub.status.idle":"2021-06-13T16:16:17.704792Z","shell.execute_reply.started":"2021-06-13T16:16:11.960192Z","shell.execute_reply":"2021-06-13T16:16:17.703715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelling\n### Bag Of Words","metadata":{}},{"cell_type":"code","source":"# Splitting the data into train set and validation set\ntrain_data = data[:30000]\nval_data = data[30000:]","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:17:59.200908Z","iopub.execute_input":"2021-06-13T16:17:59.201235Z","iopub.status.idle":"2021-06-13T16:17:59.206248Z","shell.execute_reply.started":"2021-06-13T16:17:59.201207Z","shell.execute_reply":"2021-06-13T16:17:59.20515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For efficient processing we will disable some pipline component like parser and named entity recognition","metadata":{}},{"cell_type":"code","source":"import spacy\n\n# Create an empty model\nnlp = spacy.blank(\"en\")\n\n# Create custom TextCategorizer with exclusive classes and bag of words architecture\ntextcat = nlp.create_pipe(\"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"bow\"})\n\n# Add the TextCategorizer to the empty model\nnlp.add_pipe(textcat)\nprint(nlp.pipe_names)\ntextcat.add_label(\"positive\")\ntextcat.add_label(\"negative\")","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:18:46.199909Z","iopub.execute_input":"2021-06-13T16:18:46.200273Z","iopub.status.idle":"2021-06-13T16:18:47.436179Z","shell.execute_reply.started":"2021-06-13T16:18:46.200235Z","shell.execute_reply":"2021-06-13T16:18:47.435174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Preparation\ntrain_texts = train_data['review'].values\ntrain_labels = [{'cats': {'positive': label == 'positive','negative': label == 'negative'}} \n                for label in train_data['sentiment']]","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:19:06.588699Z","iopub.execute_input":"2021-06-13T16:19:06.589065Z","iopub.status.idle":"2021-06-13T16:19:06.621043Z","shell.execute_reply.started":"2021-06-13T16:19:06.589035Z","shell.execute_reply":"2021-06-13T16:19:06.619902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from spacy.util import minibatch\nimport random\n\ndef model_train(model, train, optimizer):\n    losses = {}\n    random.seed(1)\n    random.shuffle(train)\n    \n    batches = minibatch(train, size=8)\n    for batch in batches:\n        texts, labels = zip(*batch)\n        model.update(texts, labels, sgd=optimizer, losses=losses)\n        \n    return losses","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:19:23.010034Z","iopub.execute_input":"2021-06-13T16:19:23.010404Z","iopub.status.idle":"2021-06-13T16:19:23.016595Z","shell.execute_reply.started":"2021-06-13T16:19:23.010371Z","shell.execute_reply":"2021-06-13T16:19:23.015632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1st Iteration\nspacy.util.fix_random_seed(1)\nrandom.seed(1)\noptimizer = nlp.begin_training()\ntrain = list(zip(train_texts, train_labels))\nlosses = model_train(nlp, train, optimizer)\nprint(losses['textcat'])","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:19:40.339943Z","iopub.execute_input":"2021-06-13T16:19:40.340267Z","iopub.status.idle":"2021-06-13T16:22:22.056746Z","shell.execute_reply.started":"2021-06-13T16:19:40.340239Z","shell.execute_reply":"2021-06-13T16:22:22.055516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prediction:","metadata":{}},{"cell_type":"code","source":"data.iloc[30001,:2]","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:22:22.058867Z","iopub.execute_input":"2021-06-13T16:22:22.059263Z","iopub.status.idle":"2021-06-13T16:22:22.067625Z","shell.execute_reply.started":"2021-06-13T16:22:22.05922Z","shell.execute_reply":"2021-06-13T16:22:22.066674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"doc = nlp(data.iloc[30001,0])\nprint(doc.cats)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:22:22.069182Z","iopub.execute_input":"2021-06-13T16:22:22.069601Z","iopub.status.idle":"2021-06-13T16:22:22.081972Z","shell.execute_reply.started":"2021-06-13T16:22:22.069559Z","shell.execute_reply":"2021-06-13T16:22:22.081059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict list of reviews\ndef predict(nlp, texts): \n\n    docs = [nlp.tokenizer(text) for text in texts]    \n    # Use textcat to get the scores for each doc\n    textcat = nlp.get_pipe('textcat')\n    predicted_class = textcat.predict(docs)[0].argmin(axis=1)\n    \n    return predicted_class","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:23:28.570056Z","iopub.execute_input":"2021-06-13T16:23:28.570421Z","iopub.status.idle":"2021-06-13T16:23:28.576128Z","shell.execute_reply.started":"2021-06-13T16:23:28.570389Z","shell.execute_reply":"2021-06-13T16:23:28.575242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.iloc[30001:30004,:2]","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:23:57.27897Z","iopub.execute_input":"2021-06-13T16:23:57.279504Z","iopub.status.idle":"2021-06-13T16:23:57.294978Z","shell.execute_reply.started":"2021-06-13T16:23:57.27947Z","shell.execute_reply":"2021-06-13T16:23:57.293406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Negative review -> 0; positive review -> 1\npredict(nlp, list(data.iloc[30001:30004,0].values))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:24:12.5517Z","iopub.execute_input":"2021-06-13T16:24:12.552053Z","iopub.status.idle":"2021-06-13T16:24:12.564078Z","shell.execute_reply.started":"2021-06-13T16:24:12.552016Z","shell.execute_reply":"2021-06-13T16:24:12.56301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\nmapper = {'positive':1, 'negative':0}\nval_data['sentiment'] = val_data['sentiment'].apply(lambda x : mapper[x])\nval_data.sentiment.values","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:24:58.038565Z","iopub.execute_input":"2021-06-13T16:24:58.039092Z","iopub.status.idle":"2021-06-13T16:24:58.254037Z","shell.execute_reply.started":"2021-06-13T16:24:58.039047Z","shell.execute_reply":"2021-06-13T16:24:58.253277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, texts, labels): \n    predicted_class = predict(model, texts)\n    accuracy = accuracy_score(predicted_class, labels)\n    fscore = f1_score(predicted_class, labels)\n    return accuracy, fscore","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:25:18.73635Z","iopub.execute_input":"2021-06-13T16:25:18.736855Z","iopub.status.idle":"2021-06-13T16:25:18.741342Z","shell.execute_reply.started":"2021-06-13T16:25:18.73682Z","shell.execute_reply":"2021-06-13T16:25:18.740647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy, f1score = evaluate(nlp, list(val_data.review.values), val_data.sentiment.values)\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"F1_score: {f1score:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:25:34.761959Z","iopub.execute_input":"2021-06-13T16:25:34.762453Z","iopub.status.idle":"2021-06-13T16:25:59.303755Z","shell.execute_reply.started":"2021-06-13T16:25:34.762421Z","shell.execute_reply":"2021-06-13T16:25:59.302694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Training \nn_iters = 6\nfor i in range(n_iters):\n    losses = model_train(nlp, train, optimizer)\n    accuracy, f1score = evaluate(nlp, list(val_data.review.values), val_data.sentiment.values)\n    print(f\"Loss: {losses['textcat']:.3f} \\t Accuracy: {accuracy:.3f} \\t F1_Score: {f1score:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:25:59.880219Z","iopub.execute_input":"2021-06-13T16:25:59.880573Z","iopub.status.idle":"2021-06-13T16:45:49.446265Z","shell.execute_reply.started":"2021-06-13T16:25:59.880541Z","shell.execute_reply":"2021-06-13T16:45:49.445397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\nfrom nltk.corpus import stopwords\nstp = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:45:49.448154Z","iopub.execute_input":"2021-06-13T16:45:49.448427Z","iopub.status.idle":"2021-06-13T16:45:50.05826Z","shell.execute_reply.started":"2021-06-13T16:45:49.448401Z","shell.execute_reply":"2021-06-13T16:45:50.057392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"WordCloud of positive reviews, It is better to add some words to our stopwords set such as: movie, film, story ... because such words may appear in both positive and negative reviews.","metadata":{}},{"cell_type":"code","source":"poswords = ' '.join([text for text in train_data[train_data['sentiment'] == 'positive']['review']])\n\nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110, stopwords=stp,\n                      background_color='white').generate(poswords)\n\nplt.figure(figsize=(8, 5))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:45:50.062021Z","iopub.execute_input":"2021-06-13T16:45:50.062334Z","iopub.status.idle":"2021-06-13T16:46:05.394996Z","shell.execute_reply.started":"2021-06-13T16:45:50.062305Z","shell.execute_reply":"2021-06-13T16:46:05.393985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CNN","metadata":{}},{"cell_type":"code","source":"del nlp, textcat, optimizer","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:46:05.396305Z","iopub.execute_input":"2021-06-13T16:46:05.396741Z","iopub.status.idle":"2021-06-13T16:46:05.406485Z","shell.execute_reply.started":"2021-06-13T16:46:05.396696Z","shell.execute_reply":"2021-06-13T16:46:05.405665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.blank(\"en\")\n\n# Create custom TextCategorizer with exclusive classes and cnn architecture\ntextcat = nlp.create_pipe(\"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"simple_cnn\"})\nnlp.add_pipe(textcat)\nprint(nlp.pipe_names)\ntextcat.add_label(\"positive\")\ntextcat.add_label(\"negative\")","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:46:05.409065Z","iopub.execute_input":"2021-06-13T16:46:05.409414Z","iopub.status.idle":"2021-06-13T16:46:05.795764Z","shell.execute_reply.started":"2021-06-13T16:46:05.409382Z","shell.execute_reply":"2021-06-13T16:46:05.794864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train a CNN architecture needs many resources (RAM), I will use a small subset of data.","metadata":{}},{"cell_type":"code","source":"def load_data(data):\n    # Splitting the data into train set and validation set\n    train_data = data[:10000]\n    val_data = data[10000:13000]\n    mapper = {'positive':1, 'negative':0}\n    val_data['sentiment'] = val_data['sentiment'].apply(lambda x : mapper[x])\n    train_texts = train_data['review'].values\n    train_labels = [{'cats': {'positive': label == 'positive','negative': label == 'negative'}} \n                for label in train_data['sentiment']]\n    return list(zip(train_texts, train_labels)), list(val_data.review.values), val_data.sentiment.values","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:46:05.797509Z","iopub.execute_input":"2021-06-13T16:46:05.797837Z","iopub.status.idle":"2021-06-13T16:46:05.804387Z","shell.execute_reply.started":"2021-06-13T16:46:05.797807Z","shell.execute_reply":"2021-06-13T16:46:05.803336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_iters = 1\nspacy.util.fix_random_seed(1)\nrandom.seed(1)\noptimizer = nlp.begin_training()\ntrain, valrev, valsnt = load_data(data)\nfor i in range(n_iters):\n    losses = model_train(nlp, train, optimizer)\n    accuracy, f1score = evaluate(nlp, valrev, valsnt)\n    print(f\"Loss: {losses['textcat']:.3f} \\t Accuracy: {accuracy:.3f} \\t F1_Score: {f1score:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:46:05.805696Z","iopub.execute_input":"2021-06-13T16:46:05.806076Z","iopub.status.idle":"2021-06-13T16:50:13.725414Z","shell.execute_reply.started":"2021-06-13T16:46:05.806038Z","shell.execute_reply":"2021-06-13T16:50:13.724332Z"},"trusted":true},"execution_count":null,"outputs":[]}]}