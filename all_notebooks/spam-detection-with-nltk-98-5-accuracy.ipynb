{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/sms-spam-collection-dataset/spam.csv\")\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True)\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['v1'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=data.rename(columns = {\"v1\" : \"target\", \"v2\" : \"sms\"})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['lenght']=data['sms'].str.len()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=pd.get_dummies(data['target'], drop_first = True)\ndata=pd.concat([data,y],axis=1)\ndata.drop(\"target\",axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def meassage_lenght(msg):\n    msg_words=msg.split(\" \")\n    len_msg=len(msg_words)\n    \n    return len_msg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(meassage_lenght(data.iloc[1][0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['word_count']=data['sms'].apply(meassage_lenght)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.hist(data['word_count'],bins=50,alpha=0.5)\nplt.hist(data['lenght'],bins=50,alpha=0.5)\nplt.xlabel(\"word lenght\")\nplt.ylabel(\"Group lenght\")\nplt.title(\"word Lenght histgoramm\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data1=data[(data['word_count']>80) & (data['lenght']>100)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import string\nstring.punctuation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_punctuation(text):\n    new_text=\"\".join([char for char in text if char not in string.punctuation])\n    return new_text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['new_sms']=data['sms'].apply(lambda row:remove_punctuation(row))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ndef tockenize(text):\n    tokens=re.split('\\W+',text)\n    return tokens","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['tokenized_row']=data['new_sms'].apply(lambda row:tockenize(row.lower()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nstopwords=nltk.corpus.stopwords.words('english')\nstopwords[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def revomestopword(text):\n    clean_text=[char for char in text if char not in stopwords]\n    return clean_text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['clean_text']=data['tokenized_row'].apply(lambda x: revomestopword(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.stem.porter import *\nps=PorterStemmer()\nfrom nltk import PorterStemmer\ndef stemming(tokenized_row):\n    stemmed_text=[ps.stem(char) for char in tokenized_row]\n    return stemmed_text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['stemmed_text']=data['clean_text'].apply(lambda char :stemming(char))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[['sms','stemmed_text']].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def final_text(stemmed_text):\n    final_text=\" \".join(char for char in stemmed_text)\n    return final_text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['final_text']=data['stemmed_text'].apply(lambda x:final_text(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=data.drop(['new_sms','tokenized_row','clean_text','stemmed_text','word_count'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=df.drop(['spam'],axis=1)\ny=df['spam']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Count Vectorization\nIt involves counting the number of occurrences of each word/token in a given text.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\ncv=CountVectorizer(max_features=500)\ntemp_train=cv.fit_transform(x_train['final_text']).toarray()\ntemp_test=cv.transform(x_test['final_text']).toarray()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf=TfidfTransformer()\ntemp_train=tf.fit_transform(temp_train)\ntemp_test=tf.transform(temp_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_train=pd.DataFrame(temp_train.toarray(),index=x_train.index)\ntemp_test=pd.DataFrame(temp_test.toarray(),index=x_test.index)\nx_train=pd.concat([x_train,temp_train],axis=1,sort=False)\nx_test=pd.concat([x_test,temp_test],axis=1,sort=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.drop(['sms','final_text'],axis=1,inplace=True)\nx_test.drop(['sms','final_text'],axis=1,inplace=True)\nx_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Train","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Multinomial Naive Bayes","metadata":{}},{"cell_type":"code","source":"model=MultinomialNB()\nmodel.fit(x_train,y_train)\ny_pred=model.predict(x_test)\nprint(\"Accuracy_score:\",accuracy_score(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nmodel=DecisionTreeClassifier()\nmodel.fit(x_train,y_train)\ny_pred=model.predict(x_test)\nprint(\"Accuracy_Score:\",accuracy_score(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier()\nmodel.fit(x_train,y_train)\ny_pred=model.predict(x_test)\nprint(\"Accuracy_score:\",accuracy_score(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}