{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_values = pd.read_csv('/kaggle/input/predicting-poverty/train_values_wJZrCmI.csv')\ntrain_labels = pd.read_csv('/kaggle/input/predicting-poverty/train_labels.csv')\ntest = pd.read_csv('/kaggle/input/predicting-poverty/test_values.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_values.shape)\nprint(train_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_values.head().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_values.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_values.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train_values.merge(train_labels, on='row_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('bank_interest_rate', axis = 1, inplace = True)\ndf.drop('mm_interest_rate', axis = 1, inplace = True)\ndf.drop('mfi_interest_rate', axis = 1, inplace = True)\ndf.drop('other_fsp_interest_rate', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['education_level'].fillna(4, inplace=True)\ndf['share_hh_income_provided'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def replace_boolean(data):\n#     for col in data:\n#         data[col].replace(True, 1, inplace=True)\n#         data[col].replace(False, 0, inplace=True)\n        \n# replace_boolean(df)\n# df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(df.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_age_group(data):\n    age_conditions = [\n    (data['age'] < 30 ),\n    (data['age'] >= 30) & (data['age'] < 45),\n    (data['age'] >= 45) & (data['age'] < 60),\n    (data['age'] >= 60)\n    ]\n    age_choices = ['Under 30', '30 to 44', '45 to 59', '60 or Over']\n    data['age_group'] = np.select(age_conditions, age_choices)\n    #return data['age_group']\n\ncreate_age_group(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_unique(df, cols):\n    for col in cols:\n        print('\\n' + 'For column ' + col)\n        print(df[col].value_counts())\n\ncat_cols = ['age_group','country','is_urban','female','married','religion','relationship_to_hh_head',\n 'education_level','literacy','can_add','can_divide','can_calc_percents','can_calc_compounding',\n 'employed_last_year','employment_category_last_year','employment_type_last_year',\n 'income_ag_livestock_last_year','income_friends_family_last_year','income_government_last_year',\n 'income_own_business_last_year','income_private_sector_last_year','income_public_sector_last_year',\n 'borrowing_recency','formal_savings','informal_savings','cash_property_savings',\n 'has_insurance','has_investment','borrowed_for_emergency_last_year','borrowed_for_daily_expenses_last_year',\n 'borrowed_for_home_or_biz_last_year','phone_technology','can_call','can_text','can_use_internet',\n 'can_make_transaction','phone_ownership','advanced_phone_use','reg_bank_acct',\n 'reg_mm_acct','reg_formal_nbfi_account','financially_included','active_bank_user',\n 'active_mm_user','active_formal_nbfi_user','active_informal_nbfi_user','nonreg_active_mm_user', 'share_hh_income_provided', \n'num_times_borrowed_last_year','num_shocks_last_year','num_formal_institutions_last_year',\n            'num_informal_institutions_last_year']\n\ncount_unique(df, cat_cols)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_violin(df, cols, col_y, title):\n    for col in cols:\n        sns.set(style=\"whitegrid\")\n        sns.set_palette(\"Set1\", n_colors=7, desat=.7)\n        sns.violinplot(col, col_y, data=df)\n        plt.xlabel(col) # Set text for the x axis\n        plt.ylabel(col_y)# Set text for y axis\n        plt.title(title + ' by ' + col)\n        plt.show()\n        \nplot_violin(df, cat_cols, 'poverty_probability', 'PPI')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = ['age', 'avg_shock_strength_last_year', \n            'num_financial_activities_last_year', \n            'poverty_probability'] \n\ndef plot_density_hist(df, cols, bins = 10, hist = False):\n    for col in cols:\n        sns.set(style=\"whitegrid\", palette='Blues_r')\n        sns.distplot(df[col], bins = bins, rug=True, hist = hist)\n        plt.title('Histogram of ' + col) # Give the plot a main title\n        plt.xlabel(col) # Set text for the x axis\n        plt.ylabel('Frequency')# Set text for y axis\n        plt.show()\n        \nplot_density_hist(df, num_cols, bins = 20, hist = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = ['age', 'avg_shock_strength_last_year', \n            'num_financial_activities_last_year', 'poverty_probability'] \n\nsns.set(style=\"whitegrid\", palette='Blues_r')\nsns.pairplot(df[num_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_corrs = df[num_cols].corr()\nf,ax = plt.subplots(figsize=(5, 5))\nsns.heatmap(num_corrs, annot=True, square=True, linewidths=.1, fmt= '.2f',ax=ax, \n           cmap=\"RdBu\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature engineering\n#Aggregate categorical features\n\n#The aggregation of categorical features was performed to reduce the number of categories. \n#For discrete variables, rare values are combined to form a range of values. \n#For categorical variables, rare values are combined with common values that share a more similar distribution in PPI.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"religion_categories = {'N':'N_Q', 'O':'O_P',\n                       'P':'O_P', 'Q':'N_Q','X':'X'}\ndf['religion'] = [religion_categories[x] for x in df['religion']]\nprint(df['religion'].value_counts())\n\n#num_shocks_last_year 4_5\nnum_shocks_last_year_categories = {0:'0', 1:'1', 2:'2',\n                       3:'3', 4:'4_5', 5:'4_5'}\ndf['num_shocks_last_year'] = [num_shocks_last_year_categories[x] for x in df['num_shocks_last_year']]\nprint(df['num_shocks_last_year'].value_counts())\n\n#num_formal_institutions_last_year 3_or_over\nnum_formal_institutions_last_year_categories = {0:'0', 1:'1', 2:'2',\n                       3:'3_4_5_6', 4:'3_4_5_6', 5:'3_4_5_6', 6:'3_4_5_6'}\ndf['num_formal_institutions_last_year'] = [num_formal_institutions_last_year_categories[x] for x in df['num_formal_institutions_last_year']]\nprint(df['num_formal_institutions_last_year'].value_counts())\n\n#num_informal_institutions_last_year 2_or_over\nnum_informal_institutions_last_year_categories = {0:'0', 1:'1', 2:'2_3_4',\n                       3:'2_3_4', 4:'2_3_4'}\ndf['num_informal_institutions_last_year'] = [num_informal_institutions_last_year_categories[x] for x in df['num_informal_institutions_last_year']]\nprint(df['num_informal_institutions_last_year'].value_counts())\n\nrelationship_to_hh_head_categories = {'Other':'Other', 'Spouse':'Spouse',\n                                      'Head':'Head',\n                                      'Son/Daughter':'Son/Daughter',\n                                      'Sister/Brother':'Sister/Brother',\n                                      'Father/Mother': 'Father/Mother',\n                                      'Unknown':'Other'}\ndf['relationship_to_hh_head'] = [relationship_to_hh_head_categories[x] for x in df['relationship_to_hh_head']]\nprint(df['relationship_to_hh_head'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Labels = np.array(df['poverty_probability'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_string(cat_features):\n    ## Now, apply one hot encoding\n    ohe = preprocessing.OneHotEncoder(categories='auto')\n    encoded = ohe.fit_transform(cat_features.values.reshape(-1,1)).toarray()\n    pdfn = ohe.get_feature_names()\n    print(pdfn)\n    return encoded\n\nfeatures_cat_cols = ['country','is_urban','female','married','religion','relationship_to_hh_head',\n 'education_level','literacy','can_add','can_divide','can_calc_percents','can_calc_compounding',\n 'employed_last_year','employment_category_last_year','employment_type_last_year',\n 'income_ag_livestock_last_year','income_friends_family_last_year','income_government_last_year',\n 'income_own_business_last_year','income_private_sector_last_year','income_public_sector_last_year',\n 'borrowing_recency','formal_savings','informal_savings','cash_property_savings',\n 'has_insurance','has_investment','borrowed_for_emergency_last_year','borrowed_for_daily_expenses_last_year',\n 'borrowed_for_home_or_biz_last_year','phone_technology','can_call','can_text','can_use_internet',\n 'can_make_transaction','phone_ownership','advanced_phone_use','reg_bank_acct',\n 'reg_mm_acct','reg_formal_nbfi_account','financially_included','active_bank_user',\n 'active_mm_user','active_formal_nbfi_user','active_informal_nbfi_user','nonreg_active_mm_user', 'share_hh_income_provided', \n'num_times_borrowed_last_year','num_shocks_last_year','num_formal_institutions_last_year',\n            'num_informal_institutions_last_year']\n\nFeatures = encode_string(df['age_group'])\nfor col in features_cat_cols:\n    temp = encode_string(df[col])\n    Features = np.concatenate([Features, temp], axis = 1)\n    \nprint(Features.shape)\nprint(Features[:2, :])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_num_cols = ['avg_shock_strength_last_year',\n                     'num_financial_activities_last_year']\nFeatures = np.concatenate([Features, np.array(df[features_num_cols])], axis = 1)\nprint(Features.shape)\nprint(Features[:2, :])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import feature_selection as fs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Features selection\nprint(Features.shape)\n\n## Define the variance threhold and fit the threshold to the feature array.\nsel = fs.VarianceThreshold(threshold=(.95 * (1 - .95)))\nFeatures_reduced = sel.fit_transform(Features)\nprint(sel.get_support())\n\n## Print the support and shape for the transformed features\nprint(Features_reduced.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/johnnyyiu/poverty-prediction-from-visualization-to-stacking","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Labels = Labels.reshape(Labels.shape[0],)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy.random as nr\nimport sklearn.model_selection as ms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nr.seed(562)\nfeature_folds = ms.KFold(n_splits=10, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import linear_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_mod_l2 = linear_model.Ridge()\nnr.seed(265)\nselector = fs.RFECV(estimator = lin_mod_l2, cv = feature_folds,scoring = 'r2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selector = selector.fit(Features_reduced, Labels)\nprint(selector.support_)\nprint(selector.ranking_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Features_reduced = selector.transform(Features_reduced)\nprint(Features_reduced.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nr.seed(265)\nindx = range(Features.shape[0])\nindx = ms.train_test_split(indx, test_size = 0.2)\nx_train = Features_reduced[indx[0],:]\ny_train = np.ravel(Labels[indx[0]])\nx_test = Features_reduced[indx[1],:]\ny_test = np.ravel(Labels[indx[1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = preprocessing.StandardScaler().fit(x_train[:,104:])\nx_train[:,104:] = scaler.transform(x_train[:,104:])\nx_test[:,104:] = scaler.transform(x_test[:,104:])\nprint(x_train[:2,])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GBoost = GradientBoostingRegressor()\nmodel_xgb = xgb.XGBRegressor()\nmodel_lgb = lgb.LGBMRegressor(objective='regression', num_leaves = 32,learning_rate=0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nr.seed(265)\ninside = ms.KFold(n_splits=5, shuffle = True)\nnr.seed(562)\noutside = ms.KFold(n_splits=5, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nr.seed(2652)\nparam_grid = {'n_estimators': [2000, 3000]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gsearch = ms.GridSearchCV(estimator = model_lgb, param_grid = param_grid, \n                      cv = inside, # Use the inside folds\n                      scoring = 'r2',\n                      return_train_score = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gsearch.fit(Features_reduced, Labels)\ngsearch.best_params_, gsearch.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GBoost = GradientBoostingRegressor(n_estimators= 2000, learning_rate=0.01,\n                                   max_depth=5, max_features='sqrt',\n                                   min_samples_leaf=7, min_samples_split=15, \n                                   loss='ls', random_state = 1)\n\nmodel_xgb = xgb.XGBRegressor(max_depth = 5, min_child_weight = 0, gamma = 0, \n                           subsample = 0.8, colsample_bytree = 0.8, \n                           scale_pos_weight = 1, reg_lambda = 1,\n                           learning_rate =0.01, n_estimators=2000, \n                           objective = 'reg:squarederror', seed = 14)\n\nmodel_lgb = lgb.LGBMRegressor(objective='regression', num_leaves = 32,\n                              learning_rate=0.01, n_estimators=2100, \n                              bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.4,\n                              min_data_in_leaf = 5,  \n                              feature_fraction_seed=3, bagging_seed=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_folds = 5\n\ndef r2_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(x_train)\n    r2 = cross_val_score(model, x_train, y_train, scoring=\"r2\", cv = kf)\n    return(r2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = r2_cv(GBoost)\nprint(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = r2_cv(model_xgb)\nprint(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = r2_cv(model_lgb)\nprint(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}