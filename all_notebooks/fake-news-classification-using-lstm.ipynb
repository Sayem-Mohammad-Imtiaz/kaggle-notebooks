{"cells":[{"metadata":{},"cell_type":"markdown","source":"# FAKE NEWS CLASSIFIER USING LSTM\n\nIN THIS NOTEBOOK WE WILL CLASSIFY WHETHER THE NEWS IS FAKE OR NOT USING LSTM MODEL.\n\n1--> REAL\n\n0--> FAKE\n\nWE WILL PERFORM SOME TEXT PREPROCESSING( STEMMING, REMOVAL OF STOP WORDS, CONVERTING TEXT INTO VECTORS)\n\nTHEN WE WILL BUILD OUR LSTM MODEL TO CLASSIFY THE NEWS"},{"metadata":{"trusted":true},"cell_type":"code","source":"# IMPORTING LIBRARY\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# OUR DATA FRAME\ndf= pd.read_csv('../input/fake-news-dataset/fakenews_train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DROPPING NaN VALUES\ndf=df.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## GETTING INDEPENDENT FEATURES\nx= df.drop('label',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPENDENT FEATURE OR TARGET FEATURE\ny=df['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LOOKING AT THE SHAPE OF OUR IINDEPENDENT FEATURES DATASET\nx.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LOOKING AT THE SHAPE OF OUR DEPENDENT FEATURE\ny.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# IMPORTING MORE NECESSARY LIBRARIES\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# vocabularry size\nvoc_size=5000","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NATURAL LANGUAGE PROCESSING"},{"metadata":{"trusted":true},"cell_type":"code","source":"# COPYING OUR INDEPENDENT FEATURE DATASET 'x' INTO NEW VARIABLE 'messages'\nmessages= x.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RESETTING THE INDEX VALUES\nmessages.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# IMPORTING LIBRARIES FOR NATURAL LANGUAGE PROCESSING\nimport nltk\nimport re\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DOWNLOADING THE STOPWORDS\nnltk.download('stopwords')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TEXT PREPROCESSING--> STEMMING, REMOVAL OF STOP WORDS, CONVERTING INTO LOWER CASE\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(messages)):\n    review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LOOKING AT OUR FINAL CORPUS\ncorpus","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ONE HOT REPRESENTATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import one_hot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"onehot_repr= [one_hot(words,voc_size)for words in corpus]\nprint(onehot_repr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EMBEDDING REPRESENTATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"# SETTING OUR SENTENCE LENGTH = 20\nsent_length=20\nembedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\nprint(embedded_docs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(embedded_docs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CREATING OUR LSTM MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"## CREATING OUR LSTM MODEL\nembedding_vector_features= 40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length)) # making embedding layer\nmodel.add(LSTM(100))  # one LSTM Layer with 100 neurons\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CONVERTING X AND Y INTO ARRAYS\nimport numpy as np\nx_final= np.array(embedded_docs)\ny_final= np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SPLITTING THE DATA INTO TRAINING AND TEST SETS\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x_final,y_final,test_size=0.33,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL TRAINING"},{"metadata":{"trusted":true},"cell_type":"code","source":"# FITTING NTO THE MODEL\nmodel.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=10,batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# OUR PREDICTION VARIABLE\ny_pred= model.predict_classes(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# IMPORTING LIBRARIES TO SEE THE ACCURACY\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\n# PRINTING CONFUSION MATRIX\ncm= confusion_matrix(y_test,y_pred)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ACCURACY SCORE\nac= accuracy_score(y_test,y_pred)\nprint(ac)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### ACCURACY SCORE= 91.43 %"},{"metadata":{},"cell_type":"markdown","source":"# ADDING DROPOUT LAYER"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Dropout\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## CREATING MODEL WITH DROPOUT LAYER\nembedding_vector_features= 40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length)) # making embedding layer\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(100))  # one LSTM Layer with 100 neurons\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CONVERTING X AND Y VARIABLES INTO ARRAYS\nimport numpy as np\nx_final= np.array(embedded_docs)\ny_final= np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x_final,y_final,test_size=0.33,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FITTING INTO THE MODEL\nmodel.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=10,batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PREDICTION MODEL\ny_pred= model.predict_classes(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\n\n# PRINTING CONFUSION MATRIX\ncmm= confusion_matrix(y_test,y_pred)\nprint(cmm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ACCURACY SCORE\nac= accuracy_score(y_test,y_pred)\nprint(ac)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ##### ACCURACY SCORE AFTER ADDING DROPOUT LAYER= 91.05%\n\n\n ##### OUR ACCURACY DECREASED A LITTLE IN THIS CASE AFTER ADDING DROPOUT LAYER"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}