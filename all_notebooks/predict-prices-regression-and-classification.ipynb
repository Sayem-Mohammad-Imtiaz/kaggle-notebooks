{"cells":[{"metadata":{"_uuid":"7910220a3b21eee6cac74eee27f5373ec83afc24"},"cell_type":"markdown","source":"# Abstract"},{"metadata":{"_uuid":"9b06228bfcfc489edd8d9c2a2b19ef689b21263a"},"cell_type":"markdown","source":"**The purpose of my regression and exploratory data analysis is to get an insight of the housing prices with respect to its other attributes. Here I am studying the dataset “ Housing Prices” by Kaggle. The main focus is on  analyzing the factors which are affecting the prices of houses from the given 500000 houses with their prices and other columns which will be taken into consideration as factors which might affect the prices.**"},{"metadata":{"trusted":false,"_uuid":"3b6161ba834c5739074ae1b85740e621eef2631d"},"cell_type":"code","source":"# importing libraries\n%matplotlib inline \nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats as st\nimport seaborn as sns\nimport re\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nimport missingno as msno\nfrom math import* \nfrom reportlab.lib.styles import ParagraphStyle\nimport statsmodels.api as sm\nfrom statsmodels.sandbox.regression.predstd import wls_prediction_std\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2eba8d2e68c167d1100136395c95098f93477370"},"cell_type":"markdown","source":"**Importing the libraries and reading the dataset from CSV file**"},{"metadata":{"trusted":false,"_uuid":"1817ab72be5b09d6c1de98e5414f980a24f519e4"},"cell_type":"code","source":"# importing the dataset\ndf=pd.read_csv(\"HousePrices_HalfMil.csv\", decimal = ',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3bb1fcfc2c7474276f6888c3ef9449b432661c24"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac132ac96bd996bc25b5df244c619129239810b7"},"cell_type":"markdown","source":"**Taking the general idea about the dataset using head()**"},{"metadata":{"trusted":false,"_uuid":"40eadc24bd0866fa6f2bfb348aa0ffdce853ef08"},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a746d6dc69fdc24f23bcdc89f807b6d229554ee3"},"cell_type":"markdown","source":"**Just taking basic summary statistics of the data, which gives counts, min, max, quantiles, std deviation, mean of the data**"},{"metadata":{"trusted":false,"_uuid":"469ba941cf90dbfb83f25fa2732d65bd77abacd7"},"cell_type":"code","source":"top_housing_prices = df.sort_values('Prices',ascending=False)\n# Look at top 20\ntop_housing_prices[['Prices','Area']].head(20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85c58e02fa80c28109fffbcf789bffc388bdab12"},"cell_type":"markdown","source":"**Checking the top 20 Houses with their areas and prices**"},{"metadata":{"trusted":false,"_uuid":"850ce1b0f770f56978f93049a02fc8ab3e7fe27b"},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(16,6))\nsns.barplot(x='Area', y='Prices', data=top_housing_prices.head(33), palette='Set1')\nax.set_xlabel(ax.get_xlabel(), labelpad=15)\nax.set_ylabel(ax.get_ylabel(), labelpad=30)\nax.xaxis.label.set_fontsize(16)\nax.yaxis.label.set_fontsize(16)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c6db76d633f75ed99f494fb2d133ccaa412519b"},"cell_type":"markdown","source":"**Making a barplot of top 20 Prices of houses and last 20 houses's prices according to its Area**"},{"metadata":{"trusted":false,"_uuid":"2ef680348d10740a1fd917628a894cc09cec5373"},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(16,6))\nsns.barplot(x='Area', y='Prices', data=top_housing_prices.tail(33), palette='Set1')\nax.set_xlabel(ax.get_xlabel(), labelpad=15)\nax.set_ylabel(ax.get_ylabel(), labelpad=30)\nax.xaxis.label.set_fontsize(16)\nax.yaxis.label.set_fontsize(16)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f394dec95f09cc61c9b23dfc2b3306c355cacc9c"},"cell_type":"code","source":"total = df.isnull().sum()[df.isnull().sum() != 0].sort_values(ascending = False)\npercent = pd.Series(round(total/len(df)*100,2))\npd.concat([total, percent], axis=1, keys=['total_missing', 'percent'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f1220efcd746cbdc782dba6cfc36c7d8aac41b5"},"cell_type":"markdown","source":"**Checking the columns and the number of missing entries in them\nExamining this is important as because of this the dataset can lose expressiveness, which can lead to weak and biased analyses**"},{"metadata":{"trusted":false,"_uuid":"8218808b215cdb515f068c9e147eac31c39b7175"},"cell_type":"code","source":"print(np.isnan(df['Prices']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"65eb80c19fd3ad9cede5822a7e4c6814baff34e7"},"cell_type":"markdown","source":"**Through above code we can see that no element here is null, thus we dont have to drop any row**"},{"metadata":{"trusted":false,"_uuid":"25e2f6a8731fb3d86da41679b89bbdf653712d45"},"cell_type":"code","source":"msno.matrix(df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b24dca29ccc65afe55caf16dc03d5d595f6aa41d"},"cell_type":"markdown","source":"**The above graph shows that there are no missing values**"},{"metadata":{"trusted":false,"_uuid":"eb3168d3a5f96b5b9ec31813a52ca6cdfe2df853"},"cell_type":"code","source":"df.skew()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39651f7e48dbed5b92f62fb12b97b1f9a2f0f9cb"},"cell_type":"markdown","source":"**Skewness tells how assymmetric data is spread around the mean.. If the right tail of histogram then positive skew and negative tail is negative skew**"},{"metadata":{"trusted":false,"_uuid":"11f109023b6450d668c27508af73332c2b2906a7"},"cell_type":"code","source":"y = df['Prices']\nplt.figure(2); plt.title('Normal')\nsns.distplot(y, kde=False, fit=st.norm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"74bde49d5a01fa14edb4a1d7b862179827fb51dd"},"cell_type":"code","source":"df.kurt()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4955d2eddccc123a22c8907b682ea5a740ad79b"},"cell_type":"markdown","source":"**The higher the kurtosis the longer is the tail of the histogram which can be seen in the above graph of skewness, but here the kurtosis ins't higher for any column**"},{"metadata":{"trusted":false,"_uuid":"a564cf2a9e8cc587ed9d8a34715e9eae526874da"},"cell_type":"code","source":"sns.distplot(df['Prices'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ce33d679b2796dc1ed4e6bd4fae065e63cd9cd4"},"cell_type":"markdown","source":"**Dist plot shows hw symettrically the data is spread as we are doing regression we need to check for this, we can see the data is symmetrical**"},{"metadata":{"trusted":false,"_uuid":"a95b8a57efac9a323bed0a0c8132b1307a9f148f"},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4fac4580437ec2a3b050dcef8e28bb4a51fe62e9"},"cell_type":"markdown","source":"**The above chart shows the corelation of each coloumn with the other column**"},{"metadata":{"trusted":false,"_uuid":"e28465926fa2d2d30a6156b499a3cfdfe4738eba"},"cell_type":"code","source":"plt.figure(figsize=(16,12))\nsns.heatmap(data=df.iloc[:,:].corr(),annot=True,fmt='.2f',cmap='coolwarm')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f9f6182c89392d909411a82edbba8e84e3efe81"},"cell_type":"markdown","source":"**Heat map represents the corealtion in a better way**\nHere we can see that White Marble,Indian Marble, Fiber and Floors are max corelated\nIndian Marble and White Marble are corelated with each other as well"},{"metadata":{"_uuid":"1666dabf0786d4920b5c2ca1c643ff4b06c4939f"},"cell_type":"markdown","source":"# Linear Regression"},{"metadata":{"trusted":false,"_uuid":"1a91fd7bc618a68238fe54296670bb5d2a1089ff"},"cell_type":"code","source":"xs = df[['Area','Garage','FirePlace','Baths','White Marble','Black Marble','Indian Marble','Floors','City','Solar','Electric','Fiber','Glass Doors','Swiming Pool','Garden']]\nys = df['Prices']\nlen(xs), len(ys)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ec1abc78bd6e0e52e08a18ab7f8d06388a95867"},"cell_type":"markdown","source":"**Assigning values and xs = independent value and ys = dependent or target value**"},{"metadata":{"trusted":false,"_uuid":"8e5b59d9f0264e3e91dc9556dcfae6cf016d977a"},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(xs,ys,test_size = 0.2, random_state = 4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff60aed71352d513e9f1987c4f52540546078bfc"},"cell_type":"markdown","source":"**Using tarin_test_split to train and test the data, training with 80% of data and testing with remaining 20 %**"},{"metadata":{"trusted":false,"_uuid":"d14c018f8a9c2a7894c803dd3d4251d05eab9857"},"cell_type":"code","source":"x_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2e80ed6b38d072d7044ac01fa8884ea5bac9fe1"},"cell_type":"markdown","source":"**Checking the first 5 rows of training set before further analysis**"},{"metadata":{"trusted":false,"_uuid":"e9f2a9599608fe15b8f72d112f411c297a7e337e"},"cell_type":"code","source":"regr = LinearRegression()\nregr.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ad59019ea393f8c8f943c5476b91c8962a11380"},"cell_type":"markdown","source":"**Applying Linear Regression and fitting that in our training dataset**"},{"metadata":{"trusted":false,"_uuid":"1716eb5370ec55349418ffd5437fd23a602807ab"},"cell_type":"code","source":"regr.intercept_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"361c5d816fd14dc6659e12a1dd7a2e7bc882c224"},"cell_type":"markdown","source":"**Checking the intercept after applying Linear regression to ur model**"},{"metadata":{"trusted":false,"_uuid":"017aa3663c30ca7a1b6ac31bea21ed7cc6bb4b07"},"cell_type":"code","source":"print('Coefficients: ', regr.coef_)\nprint(\"Mean Squared Error: %.2f\"\n     % np.mean((regr.predict(x_test) - y_test) **2))\nprint ('Variance Score: %.2f'% regr.score(x_test,y_test))\nprint('Score'%regr.score(x_train,y_train))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f04d879e1558141d368006155b85472a090bf05c"},"cell_type":"markdown","source":"**Finding the coeffecient, Mean squared error and the varience score**"},{"metadata":{"trusted":false,"_uuid":"e62ca78fa1d4c20264ecb5d9c345d0612da6d758"},"cell_type":"code","source":"names = [i for i in list(xs)]\nprint(names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"773e8094a8beac0a56e91d71670671582cc1b259"},"cell_type":"code","source":"#style.use(\"bmh\")\nplt.scatter(regr.predict(x_test),y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c5ec11e71913d0258f2bdf168bac62e25ca9cee6"},"cell_type":"code","source":"print(xs.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"97b81551f8967728e8f9860e489afe127f0d8da1"},"cell_type":"code","source":"import statsmodels.formula.api as sm\nxs = np.append(arr = np.ones((500000,1)).astype(int), values = xs,axis =1)\ndef backwardElimination(x, sl):\n    numVars = len(x[0])\n    for i in range(0, numVars):\n        reg_OLS = sm.OLS(ys, x).fit()\n        maxVar = max(reg_OLS.pvalues)\n        if maxVar > sl:\n            for j in range(0, numVars - i):\n                if (reg_OLS.pvalues[j].astype(float) == maxVar):\n                    x = np.delete(x, j, 1)\n    reg_OLS.summary()\n    return x\n\nSL = 0.05\nX_opt = xs[:, [0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,13,14]]\nX_Mod = backwardElimination(X_opt, SL)\ne_df = pd.DataFrame(X_Mod)\ne_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a24bf7482b2e29f64c7c227ee3dd24e66447aefe"},"cell_type":"code","source":"model1=sm.OLS(y_train,x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"edb0a8b12424ff333b1940024b200963c7b17e29"},"cell_type":"code","source":"result = model1.fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2bf944733668ffcfc008bf12e6b888e974074b9b"},"cell_type":"code","source":"print(result.summary())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67601f06f1be9d5ba0318a7f100b9a7994b44974"},"cell_type":"markdown","source":"**The p values in any model should be less than 0.05, we have perfect p values, we can remove garden(p value = 0.02) or Swiming Pool with negative t values, We can remove Swiming Pool**"},{"metadata":{"_uuid":"6001b75ffb858929dbb6818ff68496197c56f9e7"},"cell_type":"markdown","source":"### Cross Validation"},{"metadata":{"trusted":false,"_uuid":"b6622d403035cfa5f8520ba2654887047a699348"},"cell_type":"code","source":"a= cross_val_score(regr,x_train,y_train,cv=10)\nb = (np.sqrt(a).mean())\nprint(b)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf74acf2d68faa106b53f8162c248c93fae14cea"},"cell_type":"markdown","source":" - 1) Yes, The Relationship is significant as the p values is less than 0.05 and the regression line differs significantly from 0.\n - 2.a)linearity and additivity**- Not Violated\n - 2.b)multi collinearity** - it is there it will be solved later in the code \n - 2.c)homoscedasticity**- not violated\n - 2.d)Normality**-not violated(already shown in above graph)\n - 3)Yes the model makes sense-Area, baths and Prices -it is continuos value, 'Garbage' and 'City' - multi class categorical variable, rest other columns are binary categorical variable.**\n - 4)yes cross validated it did well\n - 5)The AIC, BIC should decrease in a better model which we can check later, R square is perfect\n\n\n"},{"metadata":{"_uuid":"683f914f98e50a846d99167ca619bd3df3933224"},"cell_type":"markdown","source":"### Model 2 for Linear Regression"},{"metadata":{"trusted":false,"_uuid":"2a686a849248261a7e3f5bd1cb2a3e804027a7b6"},"cell_type":"code","source":"xs = df[['Area','Garage','FirePlace','Baths','Black Marble','Indian Marble','Floors','City']]\nys = df['Prices']\nlen(xs), len(ys)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7adafdddd294102b5acbc3b0bfb4dea2eb5142eb"},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(xs,ys,test_size = 0.2, random_state = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"27d0f4493dfc2d4181687d3e04306f8cb9d469b5"},"cell_type":"code","source":"regr = LinearRegression()\nregr.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"083623aa12cd220ada9d3089a9541765df2d6d02"},"cell_type":"code","source":"regr.intercept_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e93ce29d8a172caa1ef36d4d772c4d1cd36c3331"},"cell_type":"code","source":"print('Coefficients: ', regr.coef_)\nprint(\"Mean Squared Error: %.2f\"\n     % np.mean((regr.predict(x_test) - y_test) **2))\nprint ('Variance Score: %.2f'% regr.score(x_test,y_test))\nprint(regr.score(x_train,y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9ce2adc17f556488875a29a09425e267b6f42f0a"},"cell_type":"code","source":"#style.use(\"bmh\")\nplt.scatter(regr.predict(x_test),y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bab7b05e14643ffdc21e5febf0c3ba0da2829e16"},"cell_type":"code","source":"import statsmodels.formula.api as sm\nxs = np.append(arr = np.ones((500000,1)).astype(int), values = xs,axis =1)\ndef backwardElimination(x, sl):\n    numVars = len(x[0])\n    for i in range(0, numVars):\n        reg_OLS = sm.OLS(ys, x).fit()\n        maxVar = max(reg_OLS.pvalues)\n        if maxVar > sl:\n            for j in range(0, numVars - i):\n                if (reg_OLS.pvalues[j].astype(float) == maxVar):\n                    x = np.delete(x, j, 1)\n    reg_OLS.summary()\n    return x\n\nSL = 0.05\nX_opt = xs[:, [0, 1, 2, 3, 4, 5,6,7]]\nX_Mod = backwardElimination(X_opt, SL)\ne_df = pd.DataFrame(X_Mod)\ne_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"343648c5e20417daab4b50e1910a93181982f832"},"cell_type":"code","source":"model1=sm.OLS(y_train,x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"150dd95da908f92bf152cb7e83113d52458460ab"},"cell_type":"code","source":"result = model1.fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9b439d97968cad4314cb54bbb0ccb7e892b94e54"},"cell_type":"code","source":"print(result.summary())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"762456cb23e0214150ba73f4ea7e659d464a893c"},"cell_type":"markdown","source":"**The p value of Garden is greater than 0.05, removing the column garden to make our model more accurate** "},{"metadata":{"_uuid":"2d5f6e0f305541c7b3b0edec1b43e24a769ee2d7"},"cell_type":"markdown","source":"## Cross Validation"},{"metadata":{"trusted":false,"_uuid":"af97c59a481e1a58c4efe8605137920756cd8735"},"cell_type":"code","source":"print(np.sqrt(cross_val_score(regr,x_train,y_train,cv=10)).mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d2986f13f9a055379f5bd295dc41ba087f5174b3"},"cell_type":"markdown","source":" - 1) Yes, The Relationship is significant as the p values is less than 0.05 and the regression line differs significantly from 0.\n - 2.a)linearity and additivity**- Not Violated\n - 2.b)multi collinearity** - it is there it will be solved later in the code \n - 2.c)homoscedasticity**- not violated\n - 2.d)Normality**-not violated(already shown in above graph)\n - 3)Yes the model makes sense-Area, baths  -it is continuos value, 'Garbage' and 'City' - multi class categorical variable, rest other columns are binary categorical variable.**\n - 4)yes cross validated it did well\n - 5)The AIC, BIC should decrease but it increased here as compared to previous model a, R square increased(Thus model 1 was better"},{"metadata":{"_uuid":"a4763b7b6dcc22529310e5c5020e08f041e355fa"},"cell_type":"markdown","source":"### Model 3 of Linear Regression"},{"metadata":{"trusted":false,"_uuid":"25284ab0f1a387ddb42ae3d001741eeaac964a73"},"cell_type":"code","source":"xs = df[['Area','Garage','FirePlace','Baths','Floors','City','Electric','Fiber','Glass Doors']]\nys = df['Prices']\nlen(xs), len(ys)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"24c946c9fcf40240587c9929bbb7e881a91a6845"},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(xs,ys,test_size = 0.2, random_state = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"8236b4b5153ab1d45005a292df1e22f42ed021a1"},"cell_type":"code","source":"regr = LinearRegression()\nregr.fit(x_train, y_train)\ny_pred = regr.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b68bd0a4dd5d77c79d607d830fdb6b8775918df9"},"cell_type":"code","source":"regr.intercept_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"631c26c3247263343d49c59278c62444c98f1568"},"cell_type":"code","source":"print('Coefficients: ', regr.coef_)\nprint(\"Mean Squared Error: %.2f\"\n     % np.mean((regr.predict(x_test) - y_test) **2))\nprint ('Variance Score: %.2f'% regr.score(x_test,y_test))\nprint(regr.score(x_train,y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"addbf935c9aa4c3f21d7783b8a06ac95fa107cdc"},"cell_type":"code","source":"#style.use(\"bmh\")\nplt.scatter(regr.predict(x_test),y_test)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3b7319725a7d53ad16273e273bd40b8b2141bb4b"},"cell_type":"code","source":"import statsmodels.formula.api as sm\nxs = np.append(arr = np.ones((500000,1)).astype(int), values = xs,axis =1)\ndef backwardElimination(x, sl):\n    numVars = len(x[0])\n    for i in range(0, numVars):\n        reg_OLS = sm.OLS(ys, x).fit()\n        maxVar = max(reg_OLS.pvalues)\n        if maxVar > sl:\n            for j in range(0, numVars - i):\n                if (reg_OLS.pvalues[j].astype(float) == maxVar):\n                    x = np.delete(x, j, 1)\n    reg_OLS.summary()\n    return x\n\nSL = 0.05\nX_opt = xs[:, [0, 1, 2, 3, 4, 5,6,7,8]]\nX_Mod = backwardElimination(X_opt, SL)\ne_df = pd.DataFrame(X_Mod)\ne_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d31b163553ad2d28517957955eb07ede0eaf6151"},"cell_type":"code","source":"model1=sm.OLS(y_train,x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f843a6cc31c1b76caaf86027ae94260ae83f3d74"},"cell_type":"code","source":"result = model1.fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"acd7d1175d2fac79b4e183a2a4a0067c7b581525"},"cell_type":"code","source":"print(result.summary())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad56992a2fa280074912cf875b7a494c9f79e738"},"cell_type":"markdown","source":"**Thus the 1st model is our best model**"},{"metadata":{"_uuid":"d38872eb78c1d812a2fc462433275d0f0c86e420"},"cell_type":"markdown","source":"## Cross Validation"},{"metadata":{"trusted":false,"_uuid":"088a12868e138ca18c14dcb5bc0a96094ead6a78"},"cell_type":"code","source":"print(np.sqrt(cross_val_score(regr,x_train,y_train,cv=10)).mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c638c671117725dd618d2347d1a58f02ed22a74c"},"cell_type":"markdown","source":" - 1) Yes, The Relationship is significant as the p values is less than 0.05 and the regression line differs significantly from 0.\n - 2.a)linearity and additivity**- Not Violated\n - 2.b)multi collinearity** - it is there it will be solved later in the code \n - 2.c)homoscedasticity**- not violated\n - 2.d)Normality**-not violated(already shown in above graph)\n - 3)Yes the model makes sense-Area, baths and Prices -it is continuos value, 'Garbage' and 'City' - multi class categorical variable, rest other columns are binary categorical variable.**\n - 4)yes cross validated it did well\n - 5)The AIC, BIC decreased from 2nd model but increased from 1st. Thus 1st is the best model, R square increased from 2nd but still decreased from 1st \n - The best model is Model 1"},{"metadata":{"_uuid":"c607d93d9d2b6698270bc6004fedefbfbae5522c"},"cell_type":"markdown","source":"### Multicolinearity"},{"metadata":{"_uuid":"fbf7a192cd9131b95aaebfabc8e8869c4f41e2b1"},"cell_type":"markdown","source":"**White and Indian Marble are corelated with each other and are inter corelated as well**"},{"metadata":{"trusted":false,"_uuid":"e0bc937a2ee2248f420161d0278a0984d6debf61"},"cell_type":"code","source":"xs = df[['Area','Garage','FirePlace','Baths','White Marble','Black Marble','Indian Marble','Floors','City','Solar','Electric','Fiber','Glass Doors','Swiming Pool','Garden']]\nys = df['Prices']\nlen(xs), len(ys)\nx_train, x_test, y_train, y_test = train_test_split(xs,ys,test_size = 0.2, random_state = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"62f28dcf5999c025395fd4ba24a32f24a591c82a"},"cell_type":"code","source":"from statsmodels.stats import outliers_influence\ndef variance_IF(x):\n    vif=vif = pd.DataFrame()\n    vif[\"VIF Factor\"] = [outliers_influence.variance_inflation_factor(x.values, i) for i in range(x.shape[1])]\n    vif[\"features\"] = x.columns\n    return vif\n\nprint(variance_IF(xs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"baeaf0c5246afb02ffb298c0759fe04908eec959"},"cell_type":"code","source":"xs = df[['Area','Garage','FirePlace','Baths','Floors','City','Solar','Electric','Fiber','Glass Doors','Swiming Pool','Garden']]\nys = df['Prices']\nlen(xs), len(ys)\nx_train, x_test, y_train, y_test = train_test_split(xs,ys,test_size = 0.2, random_state = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"73a76eb59c980580e81ec95236b6ea7b89aecdb8"},"cell_type":"code","source":"regr = LinearRegression()\nregr.fit(x_train, y_train)\ny_pred = regr.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"43a7b049fb8ca70a8bad6a5bdf2e188d3d784198"},"cell_type":"code","source":"regr.intercept_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6ea06e42669bcd8f3ca88f4bfc3979210a960dac"},"cell_type":"code","source":"print('Coefficients: ', regr.coef_)\nprint(\"Mean Squared Error: %.2f\"\n     % np.mean((regr.predict(x_test) - y_test) **2))\nprint ('Variance Score: %.2f'% regr.score(x_test,y_test))\nprint(regr.score(x_train,y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6a16a63beb64823b974e2b2e3d1b754adbd3295f"},"cell_type":"code","source":"corr_df = x_train.corr(method = 'pearson')\nprint(\"------------Create a Corelation plot----------------\")\nmask = np.zeros_like(corr_df)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(corr_df, cmap='RdYlGn_r', vmax = 1.0, vmin=-1.0, mask = mask, linewidths = 2.5)\nplt.yticks(rotation = 0)\nplt.xticks(rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"43e8e0fa9aeb43d8196e550ea1e3941fc654f5ea"},"cell_type":"code","source":"print(np.sqrt(cross_val_score(regr,x_train,y_train,cv=10)).mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"991ca03615d2dd7b0e6d320e15f4277e46303306"},"cell_type":"markdown","source":" - 1) Yes, there was multi-colinearity  in the model, which has been removed now.**\n - 2)yes, the predictor variables are independent of all other predictor variables.**\n - 3)The most significant predictor variables are Floors, Fiber, White Marbles and City, The insignificant ones are already excluded**\n - 4)Performed Cross validation**"},{"metadata":{"_uuid":"ba711c96239d3b5e8fc81776231a77a1f9429f87"},"cell_type":"markdown","source":"### Interaction Effect"},{"metadata":{"trusted":false,"_uuid":"f9b4a8090751f53fce97b7ecaebce3dd52108198"},"cell_type":"code","source":"df['interaction1'] = df['Indian Marble']*df['Black Marble']*df['White Marble']\nxs = df[['Area','Garage','FirePlace','Baths','interaction1','Floors','City','Solar','Electric','Fiber','Glass Doors','Swiming Pool','Garden']]\nys = df['Prices']\nlen(xs), len(ys)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e5d2a22baf88a6f2909700080c5154b122a59515"},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(xs,ys,test_size = 0.2, random_state = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5d96abe296ddf2a26739181ae7162b6a3392c970"},"cell_type":"code","source":"regr = LinearRegression()\nregr.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"fb730f9be2786056cedeb7812cde75f593c1dd3f"},"cell_type":"code","source":"regr.intercept_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"821c3f6b3ce443da174abf246d108419668bd615"},"cell_type":"code","source":"print('Coefficients: ', regr.coef_)\nprint(\"Mean Squared Error: %.2f\"\n     % np.mean((regr.predict(x_test) - y_test) **2))\nprint ('Variance Score: %.2f'% regr.score(x_test,y_test))\nprint(regr.score(x_train,y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"61a02a157e35203b481cb3295947e67f76a078d7"},"cell_type":"code","source":"model1=sm.OLS(y_train,x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7ed2a777cc5a31a99e1718a90d7df88555c834e2"},"cell_type":"code","source":"result_interaction = model1.fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a9e48be431178e6f29f1f490baa4cc60afcf3210"},"cell_type":"code","source":"print(result_interaction.summary())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7b740f9b363285de715ace4ec93b56b4378fe21"},"cell_type":"markdown","source":"**After appling interaction the performance is better than model 2 and 3 but not model 1**"},{"metadata":{"_uuid":"83378e39f677d8d9901df62a60e101224c2179c7"},"cell_type":"markdown","source":"## Regularization for Linear Regression (Ridge)"},{"metadata":{"trusted":false,"_uuid":"e1941a36e3ded898a617b7f81d54c49f16d975a4"},"cell_type":"code","source":"scaler = MinMaxScaler()\nscaler.fit(x_train)\nx_train_scaled = scaler.fit_transform(x_train)\nx_test_scaled = scaler.transform(x_test)\nlinridge = Ridge(alpha= this_alpha).fit(x_train_scaled,y_train)\nprint('ridge regression linear model intercept : {}'.format(linridge.intercept_))\nprint('ridge regression linear model coeff : {}'.format(linridge.coef_))\nprint('R-squared score (training) : {:.3f}'.format(linridge.score(x_train_scaled,y_train)))\nprint('R- squared score (test) : {:.3f}'.format(linridge.score(x_test_scaled,y_test)))\nprint('Number of non zero features:{}'.format(np.sum(linridge.coef_!=0)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2a8a91435bcc8d6c8108f5773819b4ce6766f8fa"},"cell_type":"code","source":"scaler = MinMaxScaler()\nscaler.fit(x_train)\nprint('Effect of Alpha regularisation parameter')\nfor this_alpha in [0,0.2,0.4,0.6,0.8,1.0] :\n    linridge = Ridge(alpha= this_alpha).fit(x_train_scaled,y_train)\n    r2_train = linridge.score(x_train_scaled,y_train)\n    r2_test =  linridge.score(x_test_scaled,y_test)\n    num_coeff_bigger = np.sum(abs(linridge.coef_)>1.0)\n    print('Alpha = {:2f}\\n\\num abs(coeff)>1.0:{},r-squared training: {:.2f}, r-squared test: {:.2f}\\n'.format(this_alpha, num_coeff_bigger, r2_train, r2_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db054e79541e48d19d92003e7f21452500ba6164"},"cell_type":"markdown","source":"**After Performing regularisation the performance didnt improve**"},{"metadata":{"_uuid":"dd8471d31fd2547f6df5de2f1544f0dc324e7caf"},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":false,"_uuid":"ec9acc3d73243660237f58cc00b1232d7224dc1c"},"cell_type":"code","source":"#Logistic Regression\nmedium = (df['Prices'].max()-df['Prices'].min())/2\ndf['Price_Logistic'] = np.where(df['Prices']>=medium, 1, 0)\nprint(medium)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1eb9691ac27746609e0e3961c6a04316747a245d"},"cell_type":"markdown","source":"**Adding another column in our dataset as Price Logistic which the target column- 1 = High Price, 0 = Low Price**"},{"metadata":{"trusted":false,"_uuid":"8fc907d650454d9ef219eab82492583a639eb65b"},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"dfb58cdc51db4ebe508e9cca3a45aed74eebdd74"},"cell_type":"code","source":"sns.countplot(x=\"Price_Logistic\", data = df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aea4076bc944df6c07a228eaa3fd6c332e489cac"},"cell_type":"markdown","source":"**Subplots which shows the distribution of high and low price**"},{"metadata":{"trusted":false,"_uuid":"86760c665686a6382f9a3c5d32fc5251177df401"},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e12cacbdc79c74a9017f7ef74063e72ff1c6d646"},"cell_type":"code","source":"xs_logi = df[['Area','Garage','FirePlace','Baths','White Marble','Black Marble','Indian Marble','Floors','City','Solar','Electric','Fiber','Glass Doors','Swiming Pool','Garden','Prices']]\n\nys_logi = df['Price_Logistic']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e0ae22fecdb52fdf6f192816d8d7522ff747d430"},"cell_type":"code","source":"x_train1, x_test1, y_train1, y_test1 = train_test_split(xs_logi,ys_logi,test_size=0.33, random_state= 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"63aea9c189396bb0ec40c9fb1ff524ba0d30b575"},"cell_type":"code","source":"sc = StandardScaler()\nx_train1 = sc.fit_transform(x_train1)\nx_test1 = sc.transform(x_test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c80162884cf7e1aec1cf8de33880e0ea79f2052a"},"cell_type":"code","source":"logmodel = LogisticRegression()\nlogmodel.fit(x_train1,y_train1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1db50bad4ac2d9b007cf30ddc54c90b6c87f8534"},"cell_type":"code","source":"prediction1 = logmodel.predict(x_test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"070b31c75190077f45b75cb473ff991c4547acf0"},"cell_type":"code","source":"#how my mdel is performing\nclassification_report(y_test1,prediction1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ad4fde5fa236568d30a0c21a4197d9db319ff350"},"cell_type":"code","source":"confusion_matrix(y_test1,prediction1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"189e7aff09bd769e2b12cc93fc141f12781aca04"},"cell_type":"code","source":"accuracy_score(y_test1,prediction1)\n#quiet good","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c1db3273b24bf7a0e829b2c1d94c44f5a79a1d9f"},"cell_type":"code","source":"print(classification_report(y_test1,prediction1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f3384c4d5176ea2fda7c024dae3de05534dd051"},"cell_type":"markdown","source":" - 1)yes it is significant as most of the predictor value matches the test variables, also the accuracy is good.**\n - 2)No assumption is being violated except multicolinearity**\n - 3)Yes the model makes sense, -Area, baths and Prices -it is continuos value, 'Garbage' and 'City' - multi class categorical variable, rest other columns are binary categorical variable.**\n - 4)Yes cross validated the model**\n - 5)the probability is 99.99**"},{"metadata":{"_uuid":"744804e4099658278df990ed4e4419b9b6f16082"},"cell_type":"markdown","source":"### Cross Validation"},{"metadata":{"trusted":false,"_uuid":"e3900c401155dcabfc3930b7f38249c7439cb131"},"cell_type":"code","source":"print(np.sqrt(cross_val_score(logmodel,xs_logi,ys_logi,cv=10)).mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aacdfdb73623285f01bcce43e72cd6c2fb13cc68"},"cell_type":"markdown","source":"### Model 2 of Logistic Regression"},{"metadata":{"trusted":false,"_uuid":"8e597694b763323f0529759fa273baf8d0116e59"},"cell_type":"code","source":"xs_logi2 = df[['Area','Garage','FirePlace','Baths','Floors','City','Solar','Electric','Fiber','Glass Doors','Swiming Pool','Garden']]\n\nys_logi2 = df['Price_Logistic']\nx_train2, x_test2, y_train2, y_test2 = train_test_split(xs_logi2,ys_logi2,test_size=0.33, random_state= 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"236efffebb67475515ff1bba133375e4d385bb82"},"cell_type":"code","source":"sc = StandardScaler()\nx_train2 = sc.fit_transform(x_train2)\nx_test2 = sc.transform(x_test2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4dfce0dd547d5b7f9689431cf4e4044509efdf70"},"cell_type":"markdown","source":"**We do standard Scalar when the dataset is large enough(say more that 10k) to improve the accuracy**"},{"metadata":{"trusted":false,"_uuid":"42439978a8cdf264b0c97c3e5a8407e70500cf10"},"cell_type":"code","source":"logmodel2 = LogisticRegression(random_state = 0)\nlogmodel2.fit(x_train2,y_train2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f99dcccefe25b24d79383b96818f51d0388e4c69"},"cell_type":"code","source":"y_pred2 = logmodel2.predict(x_test2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"eb98c592b133b9e75880888de9ab9b3d8318a606"},"cell_type":"code","source":"accuracy_score(y_test2,y_pred2)*100","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93cd1c6cd8bc3147f3ce7a23af8134ac94d1e2cd"},"cell_type":"markdown","source":"**Clearly the accuracy has decreased**"},{"metadata":{"trusted":false,"_uuid":"a2dc606520bebe559585880fa1ee7eb7fa998227"},"cell_type":"code","source":"logit_model2 = sm.Logit(y_train2, x_train2)\nresult2 = logit_model2.fit()\nprint(result2.summary())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6be92775c966e7f66a90e867946709f373b764ed"},"cell_type":"markdown","source":"### Cross Validation"},{"metadata":{"trusted":false,"_uuid":"dba0de93db19c91fc1829d2002f8488a981d6fe2"},"cell_type":"code","source":"print(np.sqrt(cross_val_score(logmodel2,xs_logi2,ys_logi2,cv=10)).mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b45ee41768e263adf2d12f58ffcf30d94bd03ec"},"cell_type":"markdown","source":" - 1)yes it is significant as most of the predictor value matches the test variables, also the accuracy is good.**\n - 2)No assumption is being violated except multicolinearity**\n - 3)Yes the model makes sense, -Area, baths -it is continuos value, 'Garbage' and 'City' - multi class categorical variable, rest other columns are binary categorical variable.**\n - 4)Yes cross validated the model**\n - 5)the probability is 86.34(Model 1 was better)** "},{"metadata":{"_uuid":"83b19714edd854fce95f36f2427ddb7ffe147630"},"cell_type":"markdown","source":"### Model 3 of Logistic Regression"},{"metadata":{"trusted":false,"_uuid":"efe9823009d8b32d0c13c4cb01a2aa791c2ae65a"},"cell_type":"code","source":"xs_logi3 = df[['Area','Garage','FirePlace','Baths','White Marble','Floors','City','Solar','Glass Doors','Swiming Pool','Garden']]\n\nys_logi3 = df['Price_Logistic']\nx_train3, x_test3, y_train3, y_test3 = train_test_split(xs_logi3,ys_logi3,test_size=0.33, random_state= 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"fc0dfd518005ce61ca526d5de410928fe27dfd5d"},"cell_type":"code","source":"sc = StandardScaler()\nx_train3 = sc.fit_transform(x_train3)\nx_test3 = sc.transform(x_test3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e71a11bebc6400088b0a1246d4b9cdee2793af4d"},"cell_type":"code","source":"logmodel3 = LogisticRegression(random_state = 0)\nlogmodel3.fit(x_train3,y_train3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7f947d425ce0401170123572ef76cffa7d2b6c38"},"cell_type":"code","source":"y_pred3 = logmodel3.predict(x_test3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"07e46c6ecf0e71667d5f4e026c02eb8278872701"},"cell_type":"code","source":"accuracy_score(y_test3,y_pred3)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b782fd3c98fe3219914ce31b5b5d2199dc7fdcc9"},"cell_type":"code","source":"logit_model3 = sm.Logit(y_train3, x_train3)\nresult3 = logit_model3.fit()\nprint(result3.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"8332aaf638c5b488b1481cda5962389e21936e57"},"cell_type":"code","source":"##Cross validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"678634b85102791dac7d77266daaaecba4fd07fb"},"cell_type":"code","source":"print(np.sqrt(cross_val_score(logmodel3,xs_logi3,ys_logi3,cv=10)).mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"21ac95c59ba8658e9d2ad927db1c7b7a1753f3d1"},"cell_type":"markdown","source":" - 1)yes it is significant as most of the predictor value matches the test variables, also the accuracy is good.**\n - 2)No assumption is being violated except multicolinearity**\n - 3)Yes the model makes sense, -Area, baths-it is continuos value, 'Garbage' and 'City' - multi class categorical variable, rest other columns are binary categorical variable.**\n - 4)Yes cross validated the model**\n - 5)the probability is 83.68**"},{"metadata":{"_uuid":"c34d838552142636e6f087e5768e78f7d04028f3"},"cell_type":"markdown","source":"### Interaction Effect"},{"metadata":{"trusted":false,"_uuid":"ba17232f06c8e599532100cc7821ece0d37d8294"},"cell_type":"code","source":"df['interaction_logi'] = df['White Marble'] * df['Black Marble'] *df['Indian Marble']\nxs_logi4 = df[['Area','Garage','FirePlace','Baths','interaction_logi','Floors','City','Solar','Electric','Fiber','Glass Doors','Swiming Pool','Garden','Prices']]\nys_logi4 = df['Price_Logistic']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4c40bae857728104201929c50e565d538ca785b5"},"cell_type":"code","source":"x_train4, x_test4, y_train4, y_test4 = train_test_split(xs_logi4,ys_logi4,test_size=0.33, random_state= 1)\nsc = StandardScaler()\nx_train4 = sc.fit_transform(x_train4)\nx_test4 = sc.transform(x_test4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"275946c3a41a65adcb811c6c20a3fed1bf9c0334"},"cell_type":"code","source":"logmodel4 = LogisticRegression(random_state = 0)\nlogmodel4.fit(x_train4,y_train4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6689fce020fd98916d6c084c9c9e0fb1c161efdf"},"cell_type":"code","source":"y_pred4 = logmodel4.predict(x_test4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c98efcc16dd73e024110a64746d81d9ed4b52861"},"cell_type":"code","source":"accuracy_score(y_test4,y_pred4)*100","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc9ec66747ffb6ca0547af3fec6b86880273110c"},"cell_type":"markdown","source":"**Yes there was synergy in the tested terms**"},{"metadata":{"_uuid":"fecd96647132234780b9e9d641e91dc68f2f2a38"},"cell_type":"markdown","source":"# Conclusion\n**The best linear regression model was model 1, and the best logistic regression model was model 1 as well.**"},{"metadata":{"_uuid":"d1565442ba44fccaf4d555b10e624c8d01247f02"},"cell_type":"markdown","source":"# Contribution\n**My contribution is 60% while 40% is the materials i have taken from internet**"},{"metadata":{"_uuid":"404fe190971650f7b5d0e97172921e1f037707dd"},"cell_type":"markdown","source":"# Citation\n - https://github.com/ResidentMario/missingno\n - https://towardsdatascience.com/visualizing-data-with-pair-plots-in-python-f228cf529166 \n - https://stackoverflow.com/\n - https://www.kaggle.com/ekami66/detailed-exploratory-data-analysis-with-python \n - https://www.datacamp.com/\n - https://www.datascience.com/blog/introduction-to-correlation-learn-data-science-tutorials\n - https://www.edureka.com\n - https://www.dummies.com/programming/big-data/data-science/data-science-how-to-create-interactions-between-variables-with-python/"},{"metadata":{"_uuid":"698e941c1ce57dfda051cf5a50b8b1e1bb6a0d78"},"cell_type":"markdown","source":"# License\n**Copyright\nJyoti Goyal**\n**THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.**"},{"metadata":{"trusted":false,"_uuid":"20e35f049269db483fb2e6125ad0928b61a09e5d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}