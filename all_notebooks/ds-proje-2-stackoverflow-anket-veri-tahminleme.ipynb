{"cells":[{"metadata":{"id":"lQzFPAAfqIKF"},"cell_type":"markdown","source":"# Proje 2 - Scikit-learn ile Makine Öğrenmesi (Tahminleme)","execution_count":null},{"metadata":{"id":"cohPfaHPqIKK"},"cell_type":"markdown","source":"**Açıklamalar:**\n* Proje-1'de verilen Stackoverflow'un 2019 yılı için geliştiricilerle yaptığı anket sonuçlarını içeren \"survey_results_public.csv\" adlı dosya kullanılacaktır.\n* Sorularda verilen her tahmin problemi için aşağıdaki işlemler adım adım gerçekleştirilecektir:\n  1. Her tahmin modeli için kullanılması gereken öznitelikleri (çıktı değişkeni üzerinde etkisi olduğunu düşündüğünüz öznitelikleri) belirleyiniz.\n  2. Kategorik olan sütunları one-hot encoding yöntemi ile dönüştürünüz.\n  3. Kategorik olmayan sütunlarda boş veri varsa uygun doldurma yöntemi (imputation) ile doldurunuz ya da ilgili satırları ihmal ediniz.\n  4. Problem bir **regresyon problemi** ise k-fold cross-validation ile probleme uygun metrikler kullanarak tahmin modelinizin performansını değerlendiriniz ve hangi özniteliklerin çıktı değişkenini daha fazla etkilediğini yorumlayınız. Problem bir **sınıflandırma problemi** ise modelde kullanılacak hyper-parametre aramasını k-fold cross-validation ile yaparak (GridSearchCV modülünü kullanabilirsiniz), test verisi üzerinde probleme uygun metrikler kullanarak tahmin modelinizin performansını değerlendiriniz.\n  5. Veri setinde olmayan yeni bir veri için geliştirdiğiniz model üzerinden bir tahminleme yapınız.\n* İşlemleri gerçekleştirirken gerekli gördüğünüz yerleri (tercih ettiğiniz birşeyin nedeni v.b. gibi) açıklayınız.","execution_count":null},{"metadata":{"id":"VImcgtozqIKL","outputId":"1664a18a-5d05-42b9-fefd-18ac7b347377","trusted":true},"cell_type":"code","source":"# Veri temizleme için gerekli kütüphaneler import edildi.\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Kullanılacak scikit-learn kütüphaneleri import edildi.\n# Kullanıldıkları yerlerde de import edildi.\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, mean_absolute_error, mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"id":"INTaZWm-qIKS","outputId":"7806d75f-e1ac-4fb5-9647-f6f97bcf0077","trusted":true},"cell_type":"code","source":"# Gerekli veri seti alındı.\ndf = pd.read_csv(\"../input/stack-overflow-developer-survey-results-2019/survey_results_public.csv\");\npd.options.display.max_columns = None\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"SQTzdE_yqIKZ","outputId":"df982105-bc84-4328-dc44-ef63ddbd7ba6","trusted":true},"cell_type":"code","source":"# df.info() tam olarak istenilen tabloyu vermediği için yeni bir tablo oluşturuldu.\ncol_info = pd.concat([df.count().rename(\"count\"), df.nunique().rename(\"unique count\"), df.isna().sum().rename(\"null count\"), df.dtypes.rename(\"types\")], axis=1)\npd.options.display.max_rows = None\ncol_info","execution_count":null,"outputs":[]},{"metadata":{"id":"cH-qRP7tqIKg","outputId":"92cbdfa6-b034-40dd-c2be-42baf5017828","trusted":true},"cell_type":"code","source":"# Respondent tahminleme için anlamsız bir sütun olduğu için silindi.\n# Diğerleri çok fazla unique ve/veya null değeri olduğu için silindi.\ndf = df.drop([\"Respondent\", \"EduOther\", \"DevType\", \"LastInt\",\n              \"JobFactors\", \"ResumeUpdate\", \"CurrencySymbol\", \"CurrencyDesc\",\n              \"CompTotal\", \"CompFreq\", \"WorkChallenge\", \"LanguageWorkedWith\",\n              \"LanguageDesireNextYear\", \"DatabaseWorkedWith\",\n              \"DatabaseDesireNextYear\", \"PlatformWorkedWith\",\n              \"PlatformDesireNextYear\", \"WebFrameWorkedWith\",\n              \"WebFrameDesireNextYear\", \"MiscTechWorkedWith\",\n              \"MiscTechDesireNextYear\", \"DevEnviron\", \"Containers\",\n              \"SocialMedia\", \"SOVisitTo\", \"SONewContent\", \"Ethnicity\"], axis=1)\n\n# YearsCode, Age1stCode, YearsCodePro, SOVisit1st genellikle sayısal değerlerden oluşuyor.\n# Sayısal değer olmayanlar, mantıklı sayılar değerlere çevrilerek sütun, tamamen sayısal değerlere çevrildi.\ndf[\"YearsCode\"] = df[\"YearsCode\"].apply(lambda x: 0 if x == \"Less than 1 year\" else x)\ndf[\"YearsCode\"] = df[\"YearsCode\"].apply(lambda x: 51 if x == \"More than 50 years\" else x)\ndf[\"YearsCode\"] = pd.to_numeric(df[\"YearsCode\"])\n\ndf[\"Age1stCode\"] = df[\"Age1stCode\"].apply(lambda x: 4 if x == \"Younger than 5 years\" else x)\ndf[\"Age1stCode\"] = df[\"Age1stCode\"].apply(lambda x: 86 if x == \"Older than 85\" else x)\ndf[\"Age1stCode\"] = pd.to_numeric(df[\"Age1stCode\"])\n\ndf[\"YearsCodePro\"] = df[\"YearsCodePro\"].apply(lambda x: 0 if x == \"Less than 1 year\" else x)\ndf[\"YearsCodePro\"] = df[\"YearsCodePro\"].apply(lambda x: 51 if x == \"More than 50 years\" else x)\ndf[\"YearsCodePro\"] = pd.to_numeric(df[\"YearsCodePro\"])\n\ndf[\"SOVisit1st\"] = df[\"SOVisit1st\"].apply(lambda x: -1 if x == \"I don't remember\" else x)\ndf[\"SOVisit1st\"] = pd.to_numeric(df[\"SOVisit1st\"])\n\n# CareerSat sorularda kullanılabilecek şekilde değiştirildi.\ndf[\"CareerSat\"] = df[\"CareerSat\"].apply(lambda x: 5 if x in [\"Very satisfied\"] else x)\ndf[\"CareerSat\"] = df[\"CareerSat\"].apply(lambda x: 4 if x in [\"Slightly satisfied\"] else x)\ndf[\"CareerSat\"] = df[\"CareerSat\"].apply(lambda x: 3 if x in [\"Neither satisfied nor dissatisfied\"] else x)\ndf[\"CareerSat\"] = df[\"CareerSat\"].apply(lambda x: 2 if x in [\"Slightly dissatisfied\"] else x)\ndf[\"CareerSat\"] = df[\"CareerSat\"].apply(lambda x: 1 if x in [\"Very dissatisfied\"] else x)\ndf[\"CareerSat\"] = pd.to_numeric(df[\"CareerSat\"])\n\n# ConvertedComp, WorkWeekHrs, CodeRevHrs, Age zaten sayısal sütunlar olduğu için işlem yapılmadı.\n\n# OpenSourcer sorularda kullanıldığı için sonra işlem yapılacak.\n# Country sütunu da tahminleme için anlamsız ancak sorularda kullanıldığı için sonra işlem yapılacak.\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"ylfXjl0ZqIKm","outputId":"287b6dac-1c82-49b9-da7c-b4d6fa6636f6","trusted":true},"cell_type":"code","source":"# NA değerler sayısal sütunlarda, sütunların ortalaması ile,\n# kategorik (metinsel) sütunlarda, sütunlarda en çok tekrar eden değer ile dolduruldu.\ncateogrical_columns = df.select_dtypes(include=[\"object\"]).columns.tolist()\nnumeric_columns = df.select_dtypes(include=[\"float64\"]).columns.tolist()\n\nfor column in df:\n    if df[column].isnull().any():\n        if column in cateogrical_columns:\n            df[column] = df[column].fillna(df[column].mode()[0])\n        else:\n            df[column] = df[column].fillna(df[column].mean())\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"BUErCmeZqIKs","outputId":"b56069fe-6f33-4f76-ec5a-feae71202872","trusted":true},"cell_type":"code","source":"# Sonuç olarak NA değerler olmayan net bir veri seti elde edildi.\nplt.figure(figsize=(20,8))\nsns.heatmap(df.isnull())","execution_count":null,"outputs":[]},{"metadata":{"id":"9Su-RZ1-qIKy","outputId":"0675d154-354c-4079-ff99-342af5936cef","trusted":true},"cell_type":"code","source":"# Kategorik değerler sayısal olarak ifade edildi.\ndf = pd.get_dummies(df, columns=[\"MainBranch\", \"Hobbyist\", \"OpenSource\", \"Employment\",\n                                 \"Student\", \"EdLevel\", \"UndergradMajor\", \"OrgSize\",\n                                 \"JobSat\", \"MgrIdiot\", \"MgrMoney\", \"MgrWant\",\n                                 \"JobSeek\", \"LastHireDate\", \"FizzBuzz\", \"WorkPlan\",\n                                 \"WorkRemote\", \"WorkLoc\", \"ImpSyn\", \"CodeRev\", \"UnitTests\",\n                                 \"PurchaseHow\", \"PurchaseWhat\", \"OpSys\", \"BlockchainOrg\",\n                                 \"BlockchainIs\", \"BetterLife\", \"ITperson\", \"OffOn\", \"Extraversion\",\n                                 \"ScreenName\", \"SOVisitFreq\", \"SOFindAnswer\", \"SOTimeSaved\", \n                                 \"SOHowMuchTime\", \"SOAccount\", \"SOPartFreq\", \"SOJobs\", \"EntTeams\",\n                                 \"SOComm\", \"WelcomeChange\", \"Gender\", \"Trans\", \"Sexuality\",\n                                 \"Dependents\", \"SurveyLength\", \"SurveyEase\"], drop_first=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"rBnLRVfKqIK8","outputId":"fd53a6f5-5973-4849-f399-2ed1d0dcfd91","trusted":true},"cell_type":"code","source":"# Temiz veri setinin boyutları\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"3jWPmIUfqILB"},"cell_type":"markdown","source":"### Soru 1: Bir geliştiricinin açık kaynak yazılımlara katkıda bulunup bulunmadığının (```OpenSourcer```) tahminlenmesi\n* \"```Never```\" ve \"```Less than once per year```\" yanıtları \"```Katkıda bulunuyor```\", \"```Less than once a month but more than once per year```\" ve \"```Once a month or more often```\" yanıtları  \"```Katkıda bulunmuyor```\" şeklinde ele alınmalıdır.","execution_count":null},{"metadata":{"id":"K9JhDmeBqILC","trusted":true},"cell_type":"code","source":"# Country sütunu bu soru için gereksiz olduğu için silindi.\nsoru1 = df.drop([\"Country\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"grlYvhbJqILH","outputId":"9b8d06f7-5dd3-4dde-865a-47259b78f8fe","trusted":true},"cell_type":"code","source":"# OpenSourcer sütunu sorudaki istediği gibi değiştirildi.\nsoru1[\"OpenSourcer\"] = soru1[\"OpenSourcer\"].apply(lambda x: \"Katkıda bulunmuyor\" if x in [\"Never\", \"Less than once per year\"] else x)\nsoru1[\"OpenSourcer\"] = soru1[\"OpenSourcer\"].apply(lambda x: \"Katkıda bulunuyor\" if x in [\"Less than once a month but more than once per year\", \"Once a month or more often\"] else x)\nsoru1.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"-klmwTr5qILN","outputId":"0351a4fb-44ea-4205-95b4-48ad63600ce8","trusted":true},"cell_type":"code","source":"# Tahminlemeye uygun hale gelmesi için OpenSourcer sütunu sayısal değerlere çevrildi.\nsoru1[\"OpenSourcerPred\"] = soru1[\"OpenSourcer\"].apply(lambda x: 0 if x == \"Katkıda bulunmuyor\" else 1)\nsoru1.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"7y9s2MecqILU","trusted":true},"cell_type":"code","source":"# Veri seti, X (tahminleme için kullanılacak özellikler) ve y (tahminlenecek özellik) veri setleri olmak üzere 2 veri setine ayrıldı.\nX = soru1.drop([\"OpenSourcer\", \"OpenSourcerPred\"], axis=1)\ny = soru1[\"OpenSourcerPred\"]","execution_count":null,"outputs":[]},{"metadata":{"id":"ei-TjMrEqILZ","trusted":true},"cell_type":"code","source":"# Veri seti, train ve test veri setleri olmak üzere 2 veri setine ayrıldı.\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)","execution_count":null,"outputs":[]},{"metadata":{"id":"krupbrOiqILe","trusted":true},"cell_type":"code","source":"# Tahminleme için gerekli kütüphaneler import edildi.\n# Tahminlemenin önceki denemelerdeki başarısızlığından dolayı ilk önce scale işlemine tabii tutalan veri seti,\n# Ardından model kullanılarak eğitildi.\n# Bu işlemi otomatikleştirmek içine pipeline kullanıldı.\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVC\nsvc = Pipeline([\n    (\"scale\", StandardScaler()),\n    (\"model\", LinearSVC(max_iter=100000, verbose=True))\n])","execution_count":null,"outputs":[]},{"metadata":{"id":"BZcWE8awqILk","outputId":"29c9312a-9d3d-45d0-9ff4-7ca432a69ff4","trusted":true},"cell_type":"code","source":"# Train veri setileri ile eğitildi.\nsvc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"eTYj2Mc9qILp","trusted":true},"cell_type":"code","source":"# Eğitilen veri seti tahminlemesi yapıldı.\npredictions = svc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"MHhyuiptqILu","trusted":true},"cell_type":"code","source":"# Tahminlemenin doğruluğu gözlemlendi.\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, mean_absolute_error, mean_squared_error\nprint(confusion_matrix(y_test, predictions))\nprint(classification_report(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"id":"gcECS8quvqft","trusted":true},"cell_type":"code","source":"print(\"Accuracy: \", accuracy_score(y_test, predictions))\nprint(\"Mean Absolute Error: \", mean_absolute_error(y_test, predictions))\nprint(\"Mean Squared Error: \", mean_squared_error(y_test, predictions))\nprint(\"Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_test, predictions)))","execution_count":null,"outputs":[]},{"metadata":{"id":"jUbP3S4XqIL4"},"cell_type":"markdown","source":"### Soru 2: Bir geliştiricinin genel olarak, şu ana kadarki kariyerinden memnuniyet derecesinin (```CareerSat```) tahminlenmesi","execution_count":null},{"metadata":{"id":"MFX335-dqIL5","trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# OpenSourcer, 1. soruda kullanılması için bırakılmıştı, ancak bu soruda sayısal değerlere çevrilerek silindi.\nsoru2 = pd.get_dummies(df, columns=[\"OpenSourcer\"], drop_first=True)\n# Country sütunu bu soru için gereksiz olduğu için silindi.\nsoru2 = soru2.drop([\"Country\"], axis=1)\n# CareerSat sütunu tahminlenecek, yukarıda bu sütundaki NA içeren hücreler sütunun ortalaması ile doldurulmuştu.\n# Şu an ortalamalar daha iyi sınıflandırmak için 3'e çevriliyor.\nsoru2[\"CareerSat\"] = soru2[\"CareerSat\"].apply(lambda x: 3 if x > 3 and x < 4 else x)\nsoru2.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"9XsCYZMhqIME","trusted":true},"cell_type":"code","source":"# Veri seti, X (tahminleme için kullanılacak özellikler) ve y (tahminlenecek özellik) veri setleri olmak üzere 2 veri setine ayrıldı.\nX = soru2.drop([\"CareerSat\"], axis=1)\ny = soru2[\"CareerSat\"]","execution_count":null,"outputs":[]},{"metadata":{"id":"kP_5bwAvqIML","trusted":true},"cell_type":"code","source":"# Veri seti, train ve test veri setleri olmak üzere 2 veri setine ayrıldı.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)","execution_count":null,"outputs":[]},{"metadata":{"id":"Frvim4wdqIMQ","trusted":true},"cell_type":"code","source":"# Tahminleme için gerekli kütüphaneler import edildi.\n# Tahminlemenin önceki denemelerdeki başarısızlığından dolayı ilk önce scale işlemine tabii tutalan veri seti,\n# Ardından model kullanılarak eğitildi.\n# Bu işlemi otomatikleştirmek içine pipeline kullanıldı.\nfrom sklearn.linear_model import LogisticRegression\nlogr = Pipeline([\n    (\"scale\", StandardScaler()),\n    (\"model\", LogisticRegression(max_iter=99999999)),\n])","execution_count":null,"outputs":[]},{"metadata":{"id":"PmMwDz9gqIMW","trusted":true},"cell_type":"code","source":"# Train veri setileri ile eğitildi.\nlogr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"Iow5RBs4qIMc","trusted":true},"cell_type":"code","source":"# Eğitilen veri seti tahminlemesi yapıldı.\npredictions = logr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tahminlemenin doğruluğu gözlemlendi.\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, mean_absolute_error, mean_squared_error\nprint(confusion_matrix(y_test, predictions))\nprint(classification_report(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"id":"5fccy2c-qIMm","trusted":true},"cell_type":"code","source":"# Tahminlemenin doğruluğu gözlemlendi.\nprint(\"Accuracy: \", accuracy_score(y_test, predictions))\nprint(\"Mean Absolute Error: \", mean_absolute_error(y_test, predictions))\nprint(\"Mean Squared Error: \", mean_squared_error(y_test, predictions))\nprint(\"Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_test, predictions)))","execution_count":null,"outputs":[]},{"metadata":{"id":"RsU1tOJHqIMr"},"cell_type":"markdown","source":"### Soru 3: Bir geliştiricinin USD cinsinden mevcut yıllık toplam gelirinin (```ConvertedComp```) tahminlenmesi","execution_count":null},{"metadata":{"id":"zh6quqRpqIMs","trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# OpenSourcer, 1. soruda kullanılması için bırakılmıştı, ancak bu soruda sayısal değerlere çevrilerek silindi.\nsoru3 = pd.get_dummies(df, columns=[\"OpenSourcer\"], drop_first=True)\n# Country sütunu bu soru için gereksiz olduğu için silindi.\nsoru3 = soru3.drop([\"Country\"], axis=1)\nsoru3.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"ihdIzb6rqIM2","trusted":true},"cell_type":"code","source":"# Veri seti, X (tahminleme için kullanılacak özellikler) ve y (tahminlenecek özellik) veri setleri olmak üzere 2 veri setine ayrıldı.\nX = soru3.drop([\"ConvertedComp\"], axis=1)\ny = soru3[\"ConvertedComp\"]","execution_count":null,"outputs":[]},{"metadata":{"id":"_zmACKmsqIM7","trusted":true},"cell_type":"code","source":"# Veri seti, train ve test veri setleri olmak üzere 2 veri setine ayrıldı.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)","execution_count":null,"outputs":[]},{"metadata":{"id":"ZOe5t9yeqINA","trusted":true},"cell_type":"code","source":"# Tahminleme için gerekli kütüphaneler import edildi.\n# Tahminlemenin önceki denemelerdeki başarısızlığından dolayı ilk önce scale işlemine tabii tutalan veri seti,\n# Ardından model kullanılarak eğitildi.\n# Bu işlemi otomatikleştirmek içine pipeline kullanıldı.\nfrom sklearn.linear_model import LinearRegression\nlinr = Pipeline([\n    (\"scale\", StandardScaler()),\n    (\"model\", LinearRegression())\n])","execution_count":null,"outputs":[]},{"metadata":{"id":"4xmSsUcaqINE","trusted":true},"cell_type":"code","source":"# Train veri setileri ile eğitildi.\nlinr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"1U8vDuMTqINI","trusted":true},"cell_type":"code","source":"# Eğitilen veri seti tahminlemesi yapıldı.\npredictions = linr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"qenU3KNNqINM","trusted":true},"cell_type":"code","source":"# Tahminlemenin doğruluğu gözlemlendi.\nprint(\"Mean Absolute Error: \", mean_absolute_error(y_test, predictions))\nprint(\"Mean Squared Error: \", mean_squared_error(y_test, predictions))\nprint(\"Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_test, predictions)))","execution_count":null,"outputs":[]},{"metadata":{"id":"62ZMc26jqINQ","trusted":true},"cell_type":"code","source":"# Tahminlemenin doğruluğu görsel olarak gözlemlendi.\nsns.scatterplot(y_test, predictions)","execution_count":null,"outputs":[]},{"metadata":{"id":"hxBG1sUxqINW"},"cell_type":"markdown","source":"### Soru 4: Türkiye'deki bir geliştiricinin mevcut yıllık toplam gelirinin (```ConvertedComp```)  18000 USD değerinden yüksek mi düşük mü olduğunun tahminlenmesi\n* 18000 ve üstü \"```Yüksek```\", 18000 altı \"```Düşük```\" şeklinde ele alınmalıdır.","execution_count":null},{"metadata":{"id":"MbDq5hO0qINX","trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# OpenSourcer, 1. soruda kullanılması için bırakılmıştı, ancak bu soruda sayısal değerlere çevrilerek silindi.\nsoru4 = pd.get_dummies(df, columns=[\"OpenSourcer\"], drop_first=True)\nsoru4.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Country sütunu bu soruda kullanılacak olan sütun, o sütun sayesinde sadece Türkiye'deki insanlar seçildi.\nsoru4 = soru4[soru4[\"Country\"] == \"Turkey\"]\nsoru4.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Daha sonra sütun sayısal değerli bir sütun olmadığı için silindi.\nsoru4 = soru4.drop([\"Country\"], axis=1)\nsoru4.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ConvertedComp sütunu sorudaki istediği gibi değiştirildi.\nsoru4[\"ConvertedComp\"] = soru4[\"ConvertedComp\"].apply(lambda x: \"Yüksek\" if x >= 18000 else \"Düşük\")\nsoru4.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tahminlemeye uygun hale gelmesi için ConvertedComp sütunu sayısal değerlere çevrildi.\nsoru4[\"ConvertedCompPred\"] = soru4[\"ConvertedComp\"].apply(lambda x: 0 if x == \"Düşük\" else 1)\nsoru4.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Yüksek sayısı, Düşük sayısının nerdeyse 3 katı olduğu için tahminleme Yüksek olmaya her zaman daha yatkın olacaktır.\nsoru4[\"ConvertedComp\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Veri seti, X (tahminleme için kullanılacak özellikler) ve y (tahminlenecek özellik) veri setleri olmak üzere 2 veri setine ayrıldı.\nX = soru4.drop([\"ConvertedComp\", \"ConvertedCompPred\"], axis=1)\ny = soru4[\"ConvertedCompPred\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Veri seti, train ve test veri setleri olmak üzere 2 veri setine ayrıldı.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tahminleme için gerekli kütüphaneler import edildi.\n# Tahminlemenin önceki denemelerdeki başarısızlığından dolayı ilk önce scale işlemine tabii tutalan veri seti,\n# Ardından model kullanılarak eğitildi.\n# Bu işlemi otomatikleştirmek içine pipeline kullanıldı.\nsvc = Pipeline([\n    (\"scale\", StandardScaler()),\n    (\"model\", LinearSVC(max_iter=100000, verbose=True))\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train veri setileri ile eğitildi.\nsvc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Eğitilen veri seti tahminlemesi yapıldı.\npredictions = svc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tahminlemenin doğruluğu gözlemlendi.\nprint(confusion_matrix(y_test, predictions))\nprint(classification_report(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy: \", accuracy_score(y_test, predictions))\nprint(\"Mean Absolute Error: \", mean_absolute_error(y_test, predictions))\nprint(\"Mean Squared Error: \", mean_squared_error(y_test, predictions))\nprint(\"Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_test, predictions)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GridsearchCV ile SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nparam_grid = {\"C\":[0.1,1,10,100,1000], \"gamma\":[1,0.1,0.01,0.001,0.0001]}\ngrid = GridSearchCV(SVC(), param_grid, verbose=3)\ngrid.cv = 3\ngrid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_pred = grid.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test, grid_pred))\nprint(classification_report(y_test, grid_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy: \", accuracy_score(y_test, grid_pred))\nprint(\"Mean Absolute Error: \", mean_absolute_error(y_test, grid_pred))\nprint(\"Mean Squared Error: \", mean_squared_error(y_test, grid_pred))\nprint(\"Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_test, grid_pred)))","execution_count":null,"outputs":[]},{"metadata":{"id":"eawc2S8zqINb"},"cell_type":"markdown","source":"### Soru 5: Bir geliştiricinin yıl olarak yaşının (```Age```) tahminlenmesi","execution_count":null},{"metadata":{"id":"EYvGQtuFqINc","trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# OpenSourcer, 1. soruda kullanılması için bırakılmıştı, ancak bu soruda sayısal değerlere çevrilerek silindi.\nsoru5 = pd.get_dummies(df, columns=[\"OpenSourcer\"], drop_first=True)\n# Country sütunu bu soru için gereksiz olduğu için silindi.\nsoru5 = soru5.drop([\"Country\"], axis=1)\nsoru5.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Age sütunu kullanılarak BirthDate sütunu oluşturuldu.\nsoru5[\"BirthDate\"] = soru5[\"Age\"].apply(lambda x: 2020 - x)\n# Daha sonra Age sütunu silindi.\nsoru5 = soru5.drop([\"Age\"], axis=1)\nsoru5.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Veri seti, X (tahminleme için kullanılacak özellikler) ve y (tahminlenecek özellik) veri setleri olmak üzere 2 veri setine ayrıldı.\nX = soru5.drop([\"BirthDate\"], axis=1)\ny = soru5[\"BirthDate\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Veri seti, train ve test veri setleri olmak üzere 2 veri setine ayrıldı.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tahminleme için gerekli kütüphaneler import edildi.\n# Tahminlemenin önceki denemelerdeki başarısızlığından dolayı ilk önce scale işlemine tabii tutalan veri seti,\n# Ardından model kullanılarak eğitildi.\n# Bu işlemi otomatikleştirmek içine pipeline kullanıldı.\nlinr = Pipeline([\n    (\"scale\", StandardScaler()),\n    (\"model\", LinearRegression())\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train veri setileri ile eğitildi.\nlinr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Eğitilen veri seti tahminlemesi yapıldı.\npredictions = linr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tahminlemenin doğruluğu gözlemlendi.\nprint(\"Mean Absolute Error: \", mean_absolute_error(y_test, predictions))\nprint(\"Mean Squared Error: \", mean_squared_error(y_test, predictions))\nprint(\"Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_test, predictions)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tahminlemenin doğruluğu görsel olarak gözlemlendi.\n# Güzel bir dağılım denebilir.\nsns.scatterplot(y_test, predictions)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}