{"cells":[{"metadata":{"_uuid":"3b48b027832eb58cc0c22f40d3564fd0978ca94c"},"cell_type":"markdown","source":"**PMR3508 - Tarefa 2 -\nClassificador de Spam ou Ham**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importando principais bibliotecas a serem utilizadas.\n\nimport sklearn # algoritmos para tratar os dados\nimport matplotlib.pyplot as plt #gráficos\nimport numpy as np # álgebra linear\nimport pandas as pd # processamento de dados\nimport scikitplot as skplt\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b1e26c06a99dec7560b503084a7f1ebaf55350f"},"cell_type":"markdown","source":"Primeiro, nomeando a base de treino e entendendo os dados da spambase."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"treino = pd.read_csv(\"../input/spambase/train_data.csv\" , engine='python')\nteste = pd.read_csv(\"../input/spambase/test_features.csv\" , engine='python')\ntreino.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"578f52d7b17a6b5e27d681a5466d58df0035a46a"},"cell_type":"code","source":"treino.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97be4fe54462b82636ae2724db011c21398624c3"},"cell_type":"markdown","source":"Percebo na tabela acima, de estatística destritiva, que algumas palavras tem mais variação quanto a média, outras menos, e algumas outras informações podem ser obtidas.  Verificar as frequências de algumas palavras chave, dentre e-mails spam ou ham, pode ser muito eficiente para diferenciá-los. Então, como partida, observar a correlação entre frequência de algumas palavras e o fato do e-mail ser ham. "},{"metadata":{"trusted":true,"_uuid":"d61883cde427cde5327f92c29eb7e802a1cae889"},"cell_type":"code","source":"treino.corr(method='pearson').ham.sort_values(ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"322dcca7bc6a36ec436336a29671c3e6b2c9fa63"},"cell_type":"code","source":"tab = pd.crosstab(treino['ham'], treino['char_freq_$'], margins = True,\nnormalize = 'columns')\ntab","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6246e4a81b28439e69126d2b2cac222975793be1"},"cell_type":"markdown","source":"Na tabela acima, informações bem relevantes estão nas primeira e última colunas, que são 0.0 e All. Podemos perceber que a ausência do caractere $ diz muito sobre o e-mail ser spam ou ham. Esse caractere, em algumas frequências, como 0.030 e 0.032 tem mais de 70 porcento de ocorrência de spam, enquanto 0.035 tem ocorrência total de spam, e 0.033 tem total ocorrência de ham. É preciso tomar alguns cuidados com as faixas de porcentagem para o reconhecimento de padrões, pois algumas tem poucos exemplos de e-mails com essa característica. Sem normalizar:"},{"metadata":{"trusted":true,"_uuid":"cac4756881736ea30e6d57f66ba2a4842a99dcc2"},"cell_type":"code","source":"tab2 = pd.crosstab(treino['ham'], treino['char_freq_$'], margins = True)\ntab2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bdbb1d19a638e1141b635d11518fccf06b7fd73f"},"cell_type":"code","source":"tab3 = pd.crosstab(treino['ham'], treino['word_freq_hp'], margins = True, normalize = \"columns\")\ntab3","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7ecefbbb40dd68098b9d2dcbbed06771e920cac"},"cell_type":"markdown","source":"Entendendo o problema : verificando quantos ham e quantos spam. O objetivo é separá-los e classificar de acordo com as características que mais os diferenciam. Para começar, dividir os conjuntos de dados entre spam e não spam."},{"metadata":{"trusted":true,"_uuid":"5ff9ec5bca423f8e18fc8b93005c26c05a78a605"},"cell_type":"code","source":"treino[\"ham\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8cde9dacc777c2f2157da91af30d15234364077"},"cell_type":"code","source":"_ham = treino.query(\"ham\").drop(columns=[\"Id\"])\n_ham[\"ham\"].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9645e1f018fc584defe1ccc673e3a9eb67e8ff46"},"cell_type":"code","source":"_spam = treino.query(\"ham == False\").drop(columns=[\"Id\"])\n_spam[\"ham\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9d665df3f8e05addc82de729c993b81377fba2d"},"cell_type":"code","source":"_spam.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83265fed43c0dc592a37853bec6c01f7621e0940"},"cell_type":"code","source":"_ham.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2ae1fe60ec4897cae2eec664b8b10d26b24aa8f"},"cell_type":"code","source":"data1 = _spam[\"word_freq_your\"]\ndata2 = _spam[\"word_freq_000\"]\ndata3 = _spam[\"char_freq_$\"]\nx = np.array(range(len(data1)))\n\nplt.plot( x, data1,  color='grey', label='your')\nplt.plot( x, data2,  color='blue', label = '000')\nplt.plot( x, data3,  color='yellow', label = '$') \n\nplt.rcParams['figure.figsize'] = (10,7)\n\n\nplt.title(\"Relação de frequências com ser spam\")\nplt.legend()\n\nplt.grid(True)\nplt.xlabel(\"e-mails spam\")\nplt.ylabel(\"frequência de your, 000, $ \")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3abb2b67490bf6375b12bc02a2e7efc2ee6136b"},"cell_type":"code","source":"data1 = _ham[\"word_freq_your\"]\ndata2 = _ham[\"word_freq_000\"]\ndata3 = _ham[\"char_freq_$\"]\nx = np.array(range(len(data1)))\n\nplt.plot( x,data1,  color='grey', label='your') \nplt.plot( x, data2,  color='blue', label = '000')  \nplt.plot( x, data3,  color='yellow', label = '$')  \n\nplt.rcParams['figure.figsize'] = (10,7)\n\nplt.legend()\nplt.title(\"Relação de frequências com ser ham\")\n\nplt.grid(True)\nplt.xlabel(\"e-mails ham\")\nplt.ylabel(\"frequência de your, 000, $ \")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fda6cf9437dd2e33d038e2d06efc11b3d08db057"},"cell_type":"code","source":"data1 = _ham[\"word_freq_000\"]\ndata2 = _spam[\"word_freq_000\"]\ndata3 = _ham[\"char_freq_$\"]\ndata4 = _spam[\"char_freq_$\"]\nx = np.array(range(len(data1)))\nw = np.array(range(len(data2)))\n\nplt.plot( w, data2  , color='purple', label = '000 spam') \nplt.plot( w, data4 ,color='pink', label = '$ spam') \nplt.plot( x, data3 ,color='grey', label = '$ ham')  \nplt.plot( x, data1, color='cyan', label='000 ham') \n\nplt.rcParams['figure.figsize'] = (10,7)\n\nplt.legend()\nplt.title(\"Relação de frequências com ser ham ou spam\")\n\nplt.grid(True)\nplt.xlabel(\"e-mails\")\nplt.ylabel(\"frequência de 000, $ \")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"adb390090fa7f53d9b139eed0c9881a913cc758d"},"cell_type":"markdown","source":"Nas tabelas acima, foi possível demonstrar que certos termos, como 000 e $ se apresentam de forma bem distinta nos e-mails spam ou ham.\n\nA partir disso, vou agora separar os labels, rótulos, dos features, atributos, para começar o método de Naive Bayes utilizando distribuição gaussiana, bernoulli e multinomial, com média e desvio estimados utilizando máxima verossimilhança. (implementado pela biblioteca sklearn.naive_bayes)\n\nUma métrica muito interessante para se ter é a matriz de confusão para cada classificador."},{"metadata":{"trusted":true,"_uuid":"6d9e14116459177368cbad1f772d83eadf6ca3ce","scrolled":true},"cell_type":"code","source":"#gaussiana sem Id\nfrom sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\nrtr = treino[\"ham\"]                                  #rotulos treino\natr_si = treino.drop(columns=[\"ham\",\"Id\"])           #atributos treino\ny_pred_gnb = gnb.fit(atr_si, rtr).predict(atr_si)\nprint(\"Número de pontos falsamente rotulados (mislabeled points) de um total de %d pontos : %d\" % (atr_si.shape[0],(rtr != y_pred_gnb).sum()))\nprint(\"Erro empírico: {:.2%}\" .format((rtr != y_pred_gnb).sum()/atr_si.shape[0]))\nscores = cross_val_score(gnb, atr_si, rtr, cv=10, n_jobs=-1, scoring='roc_auc')\nprint(\"Score por cross validation em 10 folds : {:.2%} \".format(np.mean(scores)))\nskplt.metrics.plot_confusion_matrix(rtr, y_pred_gnb,cmap=\"cool\",figsize=(6,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe79c0a43c223651cf53bca724306afc618e6f17"},"cell_type":"code","source":"#gaussiana com Id\nrtr = treino[\"ham\"]                               #rotulos treino\natr = treino.drop(columns=[\"ham\"])                #atributos treino\ny_pred_gnb2 = gnb.fit(atr, rtr).predict(atr)\nprint(\"Número de pontos falsamente rotulados (mislabeled points) de um total de %d pontos : %d\" % (atr.shape[0],(rtr != y_pred_gnb2).sum()))\nprint(\"Erro empírico: {:.2%}\" .format((rtr != y_pred_gnb2).sum()/atr.shape[0]))\nscores = cross_val_score(gnb, atr, rtr, cv=10, n_jobs=-1, scoring='roc_auc')\nprint(\"Score por cross validation em 10 folds : {:.2%} \".format(np.mean(scores)))\nskplt.metrics.plot_confusion_matrix(treino[\"ham\"], y_pred_gnb2,cmap=\"cool\",figsize=(6,6))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00a9565c4ef4409a8e1133ea7e7470be4c1a7583"},"cell_type":"markdown","source":"Acima, pude perceber que a presenca da coluna Id atrapalhou o desempenho do classificador gaussiano. Ainda assim, o erro esta muito alto, entao tentarei outra estrategia: em vez de gaussiana, utilizar o naive bayes para distribuicoes de bernoulli. Abaixo, vemos que de fato o erro empirico diminuiu bastante, porem o Id nao faz diferenca, pois sua \"binarizacao\" seria a mesma para todos os e-mails e igual a 1."},{"metadata":{"trusted":true,"_uuid":"35714160eebac1d5dc58f28b8321d2807ddda5a1"},"cell_type":"code","source":"from sklearn.naive_bayes import BernoulliNB\nbnb = BernoulliNB()\ny_pred = bnb.fit(atr, rtr).predict(atr)\nprint(\"Número de pontos falsamente rotulados (mislabeled points) de um total de %d pontos : %d\" % (atr.shape[0],(rtr != y_pred).sum()))\nprint(\"Erro empírico: {:.2%}\" .format((rtr != y_pred).sum()/atr.shape[0]))\nscores = cross_val_score(bnb, atr, rtr, cv=10, n_jobs=-1, scoring='roc_auc')\nprint(\"Score por cross validation em 10 folds : {:.2%} \".format(np.mean(scores)))\nskplt.metrics.plot_confusion_matrix(treino[\"ham\"], y_pred,cmap=\"cool\",figsize=(6,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81e6922c0803ab804e1726dd9ad88a5c8c0fe6ea"},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nmnb = MultinomialNB()\ny_pred_mnb = mnb.fit(atr_si, rtr).predict(atr_si)\nprint(\"Número de pontos falsamente rotulados (mislabeled points) de um total de %d pontos : %d\" % (atr_si.shape[0],(rtr != y_pred_mnb).sum()))\nprint(\"Erro empírico: {:.2%}\" .format((rtr != y_pred_mnb).sum()/atr_si.shape[0]))\nscores = cross_val_score(mnb, atr_si, rtr, cv=10, n_jobs=-1, scoring='roc_auc')\nprint(\"Score por cross validation em 10 folds : {:.2%} \".format(np.mean(scores)))\nskplt.metrics.plot_confusion_matrix(treino[\"ham\"], y_pred_mnb,cmap=\"cool\",figsize=(6,6))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45399af247fa3f5bfbedf69ddf5e938e50bdb092"},"cell_type":"markdown","source":"Concluo que o melhor classificador, dentre os Naive Bayes testados, é o Bernoulli Naive Bayes. Além de score mais alto e mais acertos empíricos, também obteve o melhor desempenho na matriz de confusão, ou seja, cometeu bem menos do \"pior tipo de erro\", em que o classificador moveria um e-mail importante para a caixa de spam."},{"metadata":{"_uuid":"f0b3be8307576e21a2ca47eb75b0f27757917b31"},"cell_type":"markdown","source":"Finalmente, rumo a outra forma de classificação, a **kNN**. Testei diversos parâmetros para a função K vizinhos mais próximos, até obter um inacreditável erro próximo de zero. Dentre possíveis métricas, algumas testadas foram canberra, sokalmichener, jaccard e dice. Primeiro, a função com seus parâmetros alterados, e depois, com parâmetros Default para comparação:"},{"metadata":{"trusted":true,"_uuid":"823f6c7097aa6223573b32d7ff475c7a23470252"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(algorithm='brute', leaf_size=30, metric=\"canberra\",\n           metric_params=None, n_jobs=8, n_neighbors=16,\n           weights='distance')\n\n\ny_pred_knn = knn.fit(atr_si,rtr).predict(atr_si)\nprint(\"Número de pontos falsamente rotulados (mislabeled points) de um total de %d pontos : %d\" % (atr_si.shape[0],(rtr != y_pred_knn).sum()))\nprint(\"Erro empírico: {:.2%}\" .format((rtr != y_pred_knn).sum()/atr_si.shape[0]))\nscores = cross_val_score(knn, atr_si, rtr, cv=10, n_jobs=8, scoring='roc_auc')\nprint(\"Score por cross validation em 10 folds : {:.3%} \".format(np.mean(scores)))\nskplt.metrics.plot_confusion_matrix(rtr, y_pred_knn,cmap=\"YlOrRd\",figsize=(6,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e566446a6b44b66686261be3de2441eab388753"},"cell_type":"code","source":"knn2 = KNeighborsClassifier(n_neighbors=5, weights=\"uniform\", \n                           algorithm=\"auto\", leaf_size=30, p=2, \n                           metric=\"minkowski\", metric_params=None, n_jobs=None)\n\ny_pred_knn2 = knn2.fit(atr, rtr).predict(atr)\nprint(\"Número de pontos falsamente rotulados (mislabeled points) de um total de %d pontos : %d\" % (atr.shape[0],(rtr != y_pred_knn2).sum()))\nprint(\"Erro empírico: {:.2%}\" .format((rtr != y_pred_knn2).sum()/atr.shape[0]))\nscores = cross_val_score(knn2, atr, rtr, cv=5, n_jobs=-1, scoring='roc_auc')\nprint(\"Score por cross validation em 10 folds : {:.2%} \".format(np.mean(scores)))\nskplt.metrics.plot_confusion_matrix(rtr, y_pred_knn2,cmap=\"YlOrRd\",figsize=(6,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8168c1f0a784a5802769532ab178d85b3e45c21f"},"cell_type":"code","source":"y_teste1 = knn.fit(atr_si,rtr).predict(teste.drop(columns=\"Id\"))\ny_probas1 = bnb.fit(atr_si,rtr).predict_proba(teste.drop(columns=\"Id\"))\nskplt.metrics.plot_roc(y_teste1,y_probas1,classes_to_plot =None,cmap=\"spring\",)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01782ff13f214eb9d7b2465d98b7e3ac6d5dd301"},"cell_type":"code","source":"y_teste2= bnb.fit(atr,rtr).predict(teste)\ny_probas2 = knn.fit(atr,rtr).predict_proba(teste)\nskplt.metrics.plot_roc(y_teste2,y_probas2,classes_to_plot =None,cmap=\"spring\",)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53778ceed9bd3557f8f4ba9595a986d30a84b1f0"},"cell_type":"markdown","source":"Este Notebook utilizou as seguintes referências:\n*     Python Sotfware Foundation\n*     Naive Bayes Scikit Learn\n*     Pandas Documentation\n* MatPlotLib.org\n* Scikit Learn Documentation \n"},{"metadata":{"trusted":true,"_uuid":"7338fa12adceca4606b0ac6ab82764d84ebea4f1"},"cell_type":"code","source":"submit = pd.DataFrame({'Id':teste[\"Id\"],'ham':y_teste1[:]})\nsubmit.to_csv(\"y_teste4.csv\", index = False)\nsubmit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03ae86bbc72aeb4d48cddae735dfceefb01e50cc"},"cell_type":"code","source":"def facilitador(metrica,vizinhos,pe,nome):\n    knn3 = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric=metrica,\n               metric_params=None, n_jobs=8, n_neighbors=vizinhos, p = pe,\n               weights='distance')\n\n    y_pred_knn3 = knn3.fit(atr_si,rtr).predict(atr_si)\n\n    print(\"Número de pontos falsamente rotulados (mislabeled points) de um total de %d pontos : %d\" % (atr_si.shape[0],(rtr != y_pred_knn3).sum()))\n    print(\"Erro empírico: {:.2%}\" .format((rtr != y_pred_knn3).sum()/atr_si.shape[0]))\n    \n    scores = cross_val_score(knn3, atr_si, rtr, cv=10, n_jobs=8, scoring='roc_auc')\n    print(\"Score por cross validation em 10 folds : {:.3%} \".format(np.mean(scores)))\n    \n\n    predtest = knn3.fit(atr_si,rtr).predict(teste.drop(columns=\"Id\"))\n\n    submit = pd.DataFrame({'Id':teste[\"Id\"],'ham':predtest[:]})\n    submit.to_csv(nome, index = False)\n    \nfacilitador(\"rogerstanimoto\",15,2, \"predicoes.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93a77773398baf59683183c48fdd33768b7b3e4b"},"cell_type":"code","source":"facilitador(\"sokalsneath\",16,1,\"predsokal.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cceaeb5c815e1c4280aec1cf324d432ec225c25f"},"cell_type":"code","source":"facilitador(\"rogerstanimoto\",18,1,\"predroger.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8835496480016c918d42ab0b467cb5a60881618"},"cell_type":"code","source":"facilitador(\"minkowski\",10,1,\"predmink.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b27114a00a83573a37bcc529ac91af678f32e8af"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}