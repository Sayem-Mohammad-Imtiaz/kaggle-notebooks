{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load dataset\ndata = pd.read_csv('/kaggle/input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_binary_variable = ['anaemia','diabetes','high_blood_pressure','sex','smoking']\ninput_continous_variable = ['age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time']\noutput_variable = 'DEATH_EVENT'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Normalization","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\n\nx = data.values #returns a numpy array\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\nnorm_data = pd.DataFrame(x_scaled, columns=data.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features distributions","metadata":{}},{"cell_type":"code","source":"ax = sns.violinplot(x=\"variable\", y=\"value\", hue=\"DEATH_EVENT\",\n                   data=pd.melt(norm_data,id_vars='DEATH_EVENT'), split=True, linewidth=1,inner=\"quart\",\n                    palette={1: \"b\", 0: \".85\"})\nax.set_ylim([-0.5,1.5])\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"... discuss the follow up time ...","metadata":{}},{"cell_type":"code","source":"features_no_time = input_binary_variable+input_continous_variable\nfeatures_no_time.remove('time')\nfeatures_no_time","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_with_time = input_binary_variable+input_continous_variable\nfeatures_with_time","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utilities","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\ntfkl = tf.keras.layers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#FUNCTION TO PLOT THE TRAINING\ndef plot_training(fit, evaluation):\n    best_epoch = fit.epoch[fit.history['val_loss'].index(min(fit.history['val_loss']))]\n    fig, ax = plt.subplots(2,1,figsize=(3,5))\n    \n    ax[0].plot(fit.epoch,fit.history['val_loss'],'.-',color='red', label='validation')\n    ax[0].plot(fit.epoch,fit.history['loss'],'.-',color='orange', label='train')\n    ax[0].set(ylabel='Loss',ylim=[0,1])\n    ax[0].axvspan(best_epoch-0.5,best_epoch+0.5, alpha=0.5, color='red')\n    #ax[0].autoscale(False)\n    ax[0].scatter(best_epoch, evaluation[0],s=2, zorder=1,color='green')\n    ax[0].legend()\n    \n    ax[1].plot(fit.epoch,fit.history['val_accuracy'],'.-',color='red', label='validation')\n    ax[1].plot(fit.epoch,fit.history['accuracy'],'.-',color='orange', label='train')\n    ax[1].set(ylabel='Accuracy',ylim=[0,1])\n    ax[1].axvspan(best_epoch-0.5,best_epoch+0.5, alpha=0.5, color='red')\n    #ax[1].autoscale(False)\n    ax[1].scatter(best_epoch, evaluation[1],s=2, zorder=1,color='green')\n    ax[1].legend()\n    plt.show()\n    print(\"[Best epoch]:\", best_epoch)\n    print(\"[Loss]:\", min(fit.history['val_loss']), \" test:\", evaluation[0])\n    print(\"[Accuracy]:\", max(fit.history['val_accuracy']), \" test:\", evaluation[1])\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Without follow-up time","metadata":{}},{"cell_type":"code","source":"input_array = norm_data[features_no_time].to_numpy()[:,:,np.newaxis]\noutput_array = norm_data[output_variable].to_numpy()[:,np.newaxis]\nprint(input_array.shape)\nprint(output_array.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 1\nDATASET_SIZE = input_array.shape[0]\nbase_depth = 128\nconv_filters = 512\ndropout_prob = 0.4\nactivation_func = tf.nn.leaky_relu","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_size = int(0.6 * DATASET_SIZE)//BATCH_SIZE\nval_size = int(0.2 * DATASET_SIZE)//BATCH_SIZE\ntest_size = int(0.2 * DATASET_SIZE)//BATCH_SIZE\n\ndataset = tf.data.Dataset.from_tensor_slices( (input_array,output_array) ).shuffle(1000).batch(BATCH_SIZE)\ntrain_data = dataset.take(train_size)\ntest_data = dataset.skip(train_size)\nvalid_data = test_data.skip(test_size)\ntest_data = test_data.take(test_size)\n\nprint(\"\\n[Train size]:\",len(list(train_data)),\"\\n[Valid size]:\", len(list(valid_data)),\"\\n[Test size]:\", len(list(test_data)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HFmodel_no_time = tf.keras.Sequential([\n    tf.keras.Input(shape=(len(features_no_time),1,)),\n    tfkl.Conv1D(filters=conv_filters,kernel_size=11, strides=2),\n    tfkl.Dropout(dropout_prob),\n    tfkl.Dense(base_depth,activation=activation_func),\n    tfkl.Dense(base_depth,activation=activation_func),\n    tfkl.Dense(base_depth,activation=activation_func),\n    tfkl.Dropout(dropout_prob),\n    tfkl.Dense(1,activation=tf.nn.sigmoid)\n], name=\"heart_failure_model_notime\")\n\nHFmodel_no_time.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit = HFmodel_no_time.fit(train_data, epochs=400, validation_data=valid_data,\n                    batch_size=BATCH_SIZE, verbose=False,\n                    callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.000001),\n                               tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.0, patience=100, verbose=1, mode='auto', restore_best_weights=True)])\n\nevaluation = HFmodel_no_time.evaluate(test_data)\nplot_training(fit, evaluation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Randomization ","metadata":{}},{"cell_type":"code","source":"evaluations_no_time = []\nfor i in range(30):\n    \n    dataset = tf.data.Dataset.from_tensor_slices( (input_array,output_array) ).shuffle(300).batch(BATCH_SIZE)\n    train_data = dataset.take(train_size)\n    test_data = dataset.skip(train_size)\n    valid_data = test_data.skip(test_size)\n    test_data = test_data.take(test_size)\n    \n    tf.keras.backend.clear_session()\n    \n    HFmodel_no_time = tf.keras.Sequential([\n        tf.keras.Input(shape=(len(features_no_time),1,)),\n        tfkl.Conv1D(filters=conv_filters,kernel_size=11, strides=2),\n        tfkl.Dropout(dropout_prob),\n        tfkl.Dense(base_depth,activation=activation_func),\n        tfkl.Dense(base_depth,activation=activation_func),\n        tfkl.Dense(base_depth,activation=activation_func),\n        tfkl.Dropout(dropout_prob),\n        tfkl.Dense(1,activation=tf.nn.sigmoid)\n    ], name=\"heart_failure_model_notime\")\n    \n    HFmodel_no_time.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy',metrics=['accuracy'])\n    \n    fit = HFmodel_no_time.fit(train_data, epochs=400, validation_data=valid_data,\n                        batch_size=BATCH_SIZE, verbose=False,\n                        callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.000001),\n                                   tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.0, patience=100, verbose=1, mode='auto', restore_best_weights=True)])\n\n    accuracy = HFmodel_no_time.evaluate(test_data)[1]\n    evaluations_no_time.append(accuracy)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.histplot(evaluations_no_time)\nax.set(xlim=(0,1))\nax.set(xlabel='Accuracy')\nnp.mean(evaluations_no_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# With follow-up time","metadata":{}},{"cell_type":"code","source":"input_array = norm_data[features_with_time].to_numpy()[:,:,np.newaxis]\noutput_array = norm_data[output_variable].to_numpy()[:,np.newaxis]\nprint(input_array.shape)\nprint(output_array.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_size = int(0.6 * DATASET_SIZE)//BATCH_SIZE\nval_size = int(0.2 * DATASET_SIZE)//BATCH_SIZE\ntest_size = int(0.2 * DATASET_SIZE)//BATCH_SIZE\n\ndataset = tf.data.Dataset.from_tensor_slices( (input_array,output_array) ).shuffle(1000).batch(BATCH_SIZE)\ntrain_data = dataset.take(train_size)\ntest_data = dataset.skip(train_size)\nvalid_data = test_data.skip(test_size)\ntest_data = test_data.take(test_size)\n\nprint(\"\\n[Train size]:\",len(list(train_data)),\"\\n[Valid size]:\", len(list(valid_data)),\"\\n[Test size]:\", len(list(test_data)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HFmodel_with_time = tf.keras.Sequential([\n    tf.keras.Input(shape=(len(features_with_time),1,)),\n    tfkl.Conv1D(filters=conv_filters,kernel_size=12, strides=2),\n    tfkl.Dropout(dropout_prob),\n    tfkl.Dense(base_depth,activation=activation_func),\n    tfkl.Dense(base_depth,activation=activation_func),\n    tfkl.Dense(base_depth,activation=activation_func),\n    tfkl.Dropout(dropout_prob),\n    tfkl.Dense(1,activation=tf.nn.sigmoid)\n], name=\"heart_failure_model_time\")\n\nHFmodel_with_time.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit = HFmodel_with_time.fit(train_data, epochs=400, validation_data=valid_data,\n                    batch_size=BATCH_SIZE, verbose=False,\n                    callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.000001),\n                               tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.0, patience=100, verbose=1, mode='auto', restore_best_weights=True)])\n\nevaluation = HFmodel_with_time.evaluate(test_data)\nplot_training(fit, evaluation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Randomization ","metadata":{}},{"cell_type":"code","source":"evaluations_with_time = []\nfor i in range(30):\n    \n    dataset = tf.data.Dataset.from_tensor_slices( (input_array,output_array) ).shuffle(300).batch(BATCH_SIZE)\n    train_data = dataset.take(train_size)\n    test_data = dataset.skip(train_size)\n    valid_data = test_data.skip(test_size)\n    test_data = test_data.take(test_size)\n    \n    tf.keras.backend.clear_session()\n    \n    HFmodel_with_time = tf.keras.Sequential([\n        tf.keras.Input(shape=(len(features_with_time),1,)),\n        tfkl.Conv1D(filters=conv_filters,kernel_size=12, strides=2),\n        tfkl.Dropout(dropout_prob),\n        tfkl.Dense(base_depth,activation=activation_func),\n        tfkl.Dense(base_depth,activation=activation_func),\n        tfkl.Dense(base_depth,activation=activation_func),\n        tfkl.Dropout(dropout_prob),\n        tfkl.Dense(1,activation=tf.nn.sigmoid)\n    ], name=\"heart_failure_model_time\")\n    \n    HFmodel_with_time.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy',metrics=['accuracy'])\n    \n    fit = HFmodel_with_time.fit(train_data, epochs=400, validation_data=valid_data,\n                        batch_size=BATCH_SIZE, verbose=False,\n                        callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.000001),\n                                   tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.0, patience=100, verbose=1, mode='auto', restore_best_weights=True)])\n\n    accuracy = HFmodel_with_time.evaluate(test_data)[1]\n    evaluations_with_time.append(accuracy)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.histplot(evaluations_with_time)\nax.set(xlim=(0,1))\nax.set(xlabel='Accuracy')\nnp.mean(evaluations_with_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame({'no follow-up time':evaluations_with_time,'with follow-up time':evaluations_with_time})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.boxplot(x='variable',y='value', data=df.melt())\nsns.stripplot(x='variable',y='value', data=df.melt(), ax=ax,color='black')\n#0.83 with time\n#0.74 without time\nax.set(ylim=(0,1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The models outperfom the results in the original paper.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}