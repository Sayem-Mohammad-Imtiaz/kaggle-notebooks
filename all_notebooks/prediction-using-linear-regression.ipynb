{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Prediction Using Supervised ML**\n\n\nIn this task, we will predict the scores that a student is expected to get based upon the number of hours they have studied. This task is based on simple linear regression model as it involves just two variables.","metadata":{}},{"cell_type":"code","source":"# Importing all libraries required in this notebook\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics ","metadata":{"execution":{"iopub.status.busy":"2021-07-19T12:19:30.878803Z","iopub.execute_input":"2021-07-19T12:19:30.879167Z","iopub.status.idle":"2021-07-19T12:19:30.883938Z","shell.execute_reply.started":"2021-07-19T12:19:30.879137Z","shell.execute_reply":"2021-07-19T12:19:30.883013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 1: Reading data from online source**","metadata":{}},{"cell_type":"code","source":"# Reading data from remote link\nurl =  '../input/student-study-hour-v2/Student Study Hour V2.csv'\nstudent_data = pd.read_csv(url)\nStudy_Hours=np.asarray(student_data['Hours'])\nStudent_Scores=np.asarray(student_data['Scores'])\nprint(student_data)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-19T12:19:35.817247Z","iopub.execute_input":"2021-07-19T12:19:35.817612Z","iopub.status.idle":"2021-07-19T12:19:35.830113Z","shell.execute_reply.started":"2021-07-19T12:19:35.81758Z","shell.execute_reply":"2021-07-19T12:19:35.829131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 2: Preparing the data**\n\nThe next step is to divide the data into \"attributes\" (inputs) and \"labels\"(outputs).","metadata":{}},{"cell_type":"code","source":"x = student_data.iloc[:, :-1].values  \ny = student_data.iloc[:, 1].values ","metadata":{"execution":{"iopub.status.busy":"2021-07-19T12:19:49.12912Z","iopub.execute_input":"2021-07-19T12:19:49.1295Z","iopub.status.idle":"2021-07-19T12:19:49.134521Z","shell.execute_reply.started":"2021-07-19T12:19:49.129467Z","shell.execute_reply":"2021-07-19T12:19:49.133578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 3: Data Visualization**\n\nPlotting data points on 2-D graph to observe our dataset and see if we can manually find any relationship between the data. We can create the plot with the following script:","metadata":{}},{"cell_type":"code","source":"# plotting the distribution of Scores\nplt.plot(x,y,'r*')\nplt.xlabel('Study Hours')\nplt.ylabel('Student Scores')\nplt.title('Scores vs Hours')\nplt.legend('Scores')\nplt.grid(alpha=0.3)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T12:19:52.70802Z","iopub.execute_input":"2021-07-19T12:19:52.708371Z","iopub.status.idle":"2021-07-19T12:19:52.911737Z","shell.execute_reply.started":"2021-07-19T12:19:52.708319Z","shell.execute_reply":"2021-07-19T12:19:52.910798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the graph above, we can clearly see that there is a positive linear relation between the number Study hours and Student Scores.","metadata":{}},{"cell_type":"markdown","source":"**Step 4: Algorithm Training**\n\nSplitting the data into training data-set and test data-set. Then, starting of training the algorithm.","metadata":{}},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=5)\nlg=linear_model.LinearRegression()\nlg.fit(x_train,y_train)\nprint('Training Done')","metadata":{"execution":{"iopub.status.busy":"2021-07-19T12:20:30.008104Z","iopub.execute_input":"2021-07-19T12:20:30.008433Z","iopub.status.idle":"2021-07-19T12:20:30.222196Z","shell.execute_reply.started":"2021-07-19T12:20:30.008403Z","shell.execute_reply":"2021-07-19T12:20:30.221049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plotting the Line of Regression**","metadata":{}},{"cell_type":"code","source":"# Plotting the regression line\nd=x*lg.coef_+lg.intercept_\n# Plotting for the test data\nplt.plot(x,y,'r*')\nplt.xlabel('Study Hours')\nplt.ylabel('Student Scores')\nplt.title('Scores vs Hours')\nplt.grid(alpha=0.3)\nplt.plot(x,d)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T12:23:29.228396Z","iopub.execute_input":"2021-07-19T12:23:29.228768Z","iopub.status.idle":"2021-07-19T12:23:29.384883Z","shell.execute_reply.started":"2021-07-19T12:23:29.228739Z","shell.execute_reply":"2021-07-19T12:23:29.383882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 5: Making Predictions**\n\nNow that we have trained our algorithm, it's time to make some predictions.","metadata":{}},{"cell_type":"code","source":"print(x_test)  # Testing data - In Hours\ny_pred = lg.predict(x_test) # Predicting the scores","metadata":{"execution":{"iopub.status.busy":"2021-07-19T12:25:14.765879Z","iopub.execute_input":"2021-07-19T12:25:14.766237Z","iopub.status.idle":"2021-07-19T12:25:14.772419Z","shell.execute_reply.started":"2021-07-19T12:25:14.766201Z","shell.execute_reply":"2021-07-19T12:25:14.771396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Comparing Actual vs Predicted Scores\ndifference = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})  \nprint(difference)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T12:25:19.446987Z","iopub.execute_input":"2021-07-19T12:25:19.447367Z","iopub.status.idle":"2021-07-19T12:25:19.457067Z","shell.execute_reply.started":"2021-07-19T12:25:19.447308Z","shell.execute_reply":"2021-07-19T12:25:19.456165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing our own data\nHrs=9.25\nPredicted_Score = lg.predict([[Hrs]])\nprint(\"No of Hours = {}\".format(Hrs))\nprint(\"Predicted Score = {}\".format(Predicted_Score[0]))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T12:25:30.027073Z","iopub.execute_input":"2021-07-19T12:25:30.027437Z","iopub.status.idle":"2021-07-19T12:25:30.033557Z","shell.execute_reply.started":"2021-07-19T12:25:30.027403Z","shell.execute_reply":"2021-07-19T12:25:30.032707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Step 6: Evaluating the model**\n\nThe final step is to evaluate the performance of algorithm. This step is particularly important to compare how well different algorithms perform on a particular dataset. Here, we have chosen the mean absolute error, mean squared error, root mean squared error. There are many such metrics.","metadata":{}},{"cell_type":"code","source":"print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root mean squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T12:25:34.067077Z","iopub.execute_input":"2021-07-19T12:25:34.067686Z","iopub.status.idle":"2021-07-19T12:25:34.075174Z","shell.execute_reply.started":"2021-07-19T12:25:34.06765Z","shell.execute_reply":"2021-07-19T12:25:34.074129Z"},"trusted":true},"execution_count":null,"outputs":[]}]}