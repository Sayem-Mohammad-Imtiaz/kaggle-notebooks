{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport random\nimport string\nimport sys\nimport unidecode\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-22T01:30:44.513816Z","iopub.execute_input":"2021-06-22T01:30:44.514201Z","iopub.status.idle":"2021-06-22T01:30:46.03996Z","shell.execute_reply.started":"2021-06-22T01:30:44.514123Z","shell.execute_reply":"2021-06-22T01:30:46.039047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nall_characters = string.printable\nn_characters = len(all_characters)\n\nprint(n_characters, all_characters)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T01:30:46.04325Z","iopub.execute_input":"2021-06-22T01:30:46.043511Z","iopub.status.idle":"2021-06-22T01:30:46.121634Z","shell.execute_reply.started":"2021-06-22T01:30:46.043482Z","shell.execute_reply":"2021-06-22T01:30:46.120633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas\n\nfile1 = pandas.read_csv('../input/indian-male-baby-names/Indian-Male-Names.csv')\n\nfile1.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-22T01:30:46.123682Z","iopub.execute_input":"2021-06-22T01:30:46.124335Z","iopub.status.idle":"2021-06-22T01:30:46.174347Z","shell.execute_reply.started":"2021-06-22T01:30:46.124291Z","shell.execute_reply":"2021-06-22T01:30:46.17361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_names = [str(x).split(\" \")[0] for x in file1[\"name\"].values]\n# we only need first names\nall_names[:5]","metadata":{"execution":{"iopub.status.busy":"2021-06-22T01:30:46.176675Z","iopub.execute_input":"2021-06-22T01:30:46.177163Z","iopub.status.idle":"2021-06-22T01:30:46.190426Z","shell.execute_reply.started":"2021-06-22T01:30:46.177126Z","shell.execute_reply":"2021-06-22T01:30:46.189626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file2 = open(\"names_parsed.txt\", 'w+')\nfile2.write(\"\\n\".join(all_names))\n\nimport unidecode\nfile = unidecode.unidecode(open(\"names_parsed.txt\", \"r+\").read())\n\nfile[:5]","metadata":{"execution":{"iopub.status.busy":"2021-06-22T01:30:46.19144Z","iopub.execute_input":"2021-06-22T01:30:46.193435Z","iopub.status.idle":"2021-06-22T01:30:46.251698Z","shell.execute_reply.started":"2021-06-22T01:30:46.193403Z","shell.execute_reply":"2021-06-22T01:30:46.250932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class myRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size):\n        super(myRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        self.embed = nn.Embedding(input_size, hidden_size)\n        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x, hidden, cell, test=False):\n        out = self.embed(x)\n        if (test):\n            print(\"output: \", out)\n            print(\"output unsqueeze 1: \", out.unsqueeze(1))\n            print(\"hidden : \", hidden)\n            print(\"cell : \", cell)\n        out, ( hidden, cell) = self.lstm(out.unsqueeze(1), (hidden, cell))\n        out = self.fc(out.reshape(out.shape[0], -1))\n        \n        return out, (hidden, cell)\n    \n    def init_hidden(self, batch_size):\n        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device=device)\n        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device=device)\n        return hidden, cell","metadata":{"execution":{"iopub.status.busy":"2021-06-22T01:30:46.253275Z","iopub.execute_input":"2021-06-22T01:30:46.253529Z","iopub.status.idle":"2021-06-22T01:30:46.265669Z","shell.execute_reply.started":"2021-06-22T01:30:46.253503Z","shell.execute_reply":"2021-06-22T01:30:46.264889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing","metadata":{}},{"cell_type":"code","source":"# input_size = 10\n# output_size = 2\n# hidden_size = 2\n# num_layers = 2\n# batch_size = 2","metadata":{"execution":{"iopub.status.busy":"2021-06-22T01:30:46.267476Z","iopub.execute_input":"2021-06-22T01:30:46.267814Z","iopub.status.idle":"2021-06-22T01:30:46.274108Z","shell.execute_reply.started":"2021-06-22T01:30:46.267781Z","shell.execute_reply":"2021-06-22T01:30:46.273126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rnn = myRNN(input_size, output_size, hidden_size, num_layers)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T01:30:46.276652Z","iopub.execute_input":"2021-06-22T01:30:46.276969Z","iopub.status.idle":"2021-06-22T01:30:46.292212Z","shell.execute_reply.started":"2021-06-22T01:30:46.276936Z","shell.execute_reply":"2021-06-22T01:30:46.29067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hidden,cell = rnn.init_hidden(batch_size)\n# hidden.shape, cell.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-22T01:30:46.298095Z","iopub.execute_input":"2021-06-22T01:30:46.299424Z","iopub.status.idle":"2021-06-22T01:30:46.305401Z","shell.execute_reply.started":"2021-06-22T01:30:46.29937Z","shell.execute_reply":"2021-06-22T01:30:46.30348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-06-22T01:30:46.306883Z","iopub.execute_input":"2021-06-22T01:30:46.307235Z","iopub.status.idle":"2021-06-22T01:30:46.315846Z","shell.execute_reply.started":"2021-06-22T01:30:46.307199Z","shell.execute_reply":"2021-06-22T01:30:46.31422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x = torch.tensor([1,2]).to(device=device)\n\n# x is ultimately a tensor of index","metadata":{"execution":{"iopub.status.busy":"2021-06-22T01:30:46.3174Z","iopub.execute_input":"2021-06-22T01:30:46.317772Z","iopub.status.idle":"2021-06-22T01:30:46.328339Z","shell.execute_reply.started":"2021-06-22T01:30:46.317709Z","shell.execute_reply":"2021-06-22T01:30:46.324767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rnn.forward(x, hidden, cell)\n\n# it is working but dont know how","metadata":{"execution":{"iopub.status.busy":"2021-06-22T01:30:46.329637Z","iopub.execute_input":"2021-06-22T01:30:46.33012Z","iopub.status.idle":"2021-06-22T01:30:46.33701Z","shell.execute_reply.started":"2021-06-22T01:30:46.33008Z","shell.execute_reply":"2021-06-22T01:30:46.335893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"https://www.youtube.com/watch?v=WujVlF_6h5A&list=PLhhyoLH6IjfxeoooqP9rhU3HJIAVAJ3Vz&index=33\n\n### testing over","metadata":{}},{"cell_type":"code","source":"len(all_characters)","metadata":{"execution":{"iopub.status.busy":"2021-06-22T01:30:46.338319Z","iopub.execute_input":"2021-06-22T01:30:46.338862Z","iopub.status.idle":"2021-06-22T01:30:46.349611Z","shell.execute_reply.started":"2021-06-22T01:30:46.338824Z","shell.execute_reply":"2021-06-22T01:30:46.348503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class myGenerator:\n    def __init__(self):\n        self.chunk_len = 250\n        self.hidden_size = 256\n        self.num_layers = 2\n        self.lr = 0.003\n        self.num_epochs = 200\n        self.print_every = 40\n        self.batch_size = 1\n    \n    def char_tensor(self, str_input):\n        #converts string input to tensor \n        c_tensor = torch.zeros(len(str_input)).long()\n        \n        for c in range(len(str_input)):\n            try:\n                c_tensor[c] = all_characters.index(str_input[c])\n            except Exception as e:\n                print(e)\n                print(f\" error by {str_input}\")\n        \n        return c_tensor\n\n    def get_random_batch(self):\n        start_idx = random.randint(0, len(file) - self.chunk_len)\n        end_idx = start_idx + self.chunk_len + 1\n        \n        text_str = file[start_idx:end_idx]\n        text_input = torch.zeros(self.batch_size, self.chunk_len)\n        text_target = torch.zeros(self.batch_size, self.chunk_len)\n        \n        for i in range(self.batch_size):\n            text_input[i, :] = self.char_tensor(text_str[:-1])\n            text_target[i, :] = self.char_tensor(text_str[1:])\n        \n        return text_input.long(), text_target.long()\n    \n    def generate(self, initial_str = \"A\", predict_len = 100, temprature=0.85):\n        hidden, cell = self.rnn.init_hidden(batch_size=self.batch_size)\n        initial_input = self.char_tensor(initial_str)\n        \n        predicted = initial_str\n        \n        for p in range(len(initial_str) - 1):\n            _, (hidden,cell) = self.rnn(initial_input[p].view(1).to(device=device), hidden, cell)\n        \n        last_char = initial_input[-1]\n        \n        for p in range(predict_len):\n            output, (hidden, cell) = self.rnn(last_char.view(1).to(device=device), hidden, cell)\n            output_dist = output.data.view(-1).div(temprature).exp()\n            top_char = torch.multinomial(output_dist, 1)[0]\n            predicted_char = all_characters[top_char]\n            predicted += predicted_char\n            last_char = self.char_tensor(predicted_char)\n            \n        return predicted\n            \n    def train(self):\n        #input_size, output_size, hidden_size, num_layers\n        self.rnn = myRNN(n_characters, self.hidden_size, self.num_layers, n_characters).to(device=device)\n        optimizer = torch.optim.Adam(self.rnn.parameters(),lr = self.lr)\n        \n        loss_criterion = nn.CrossEntropyLoss()\n        writer = SummaryWriter(f'runs/names0')\n        \n        print(\"start training\")\n        \n        for epoch in range(1,self.num_epochs+1):\n            inp, target = self.get_random_batch()\n            \n            inp = inp.to(device=device)\n            target = target.to(device=device)\n            \n            optimizer.zero_grad()\n            \n            hidden, cell = self.rnn.init_hidden(batch_size= self.batch_size)\n            loss = 0\n            \n            for c in range(self.chunk_len):\n                output, (hidden, cell) = self.rnn(inp[:,c], hidden, cell)\n                loss += loss_criterion(output, target[:,c])\n#             out , (hidden1, cell1) = self.rnn(inp)\n#             loss = loss_criterion(out, target)\n            \n            loss.backward()\n            \n            optimizer.step()\n            loss = loss.item() / self.chunk_len\n            \n            if epoch % self.print_every == 0:\n                print(f\"loss for epoch {epoch+1} : {loss}\")\n                print(self.generate())\n            \n            writer.add_scalar('Training loss', loss, global_step=epoch)\n            \n            \n        \n        \ngenames = myGenerator()\ngenames.train()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-22T01:30:46.351085Z","iopub.execute_input":"2021-06-22T01:30:46.351742Z"},"trusted":true},"execution_count":null,"outputs":[]}]}