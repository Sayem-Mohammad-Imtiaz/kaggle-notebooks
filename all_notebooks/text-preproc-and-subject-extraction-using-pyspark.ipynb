{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n#  <font color='blue'> Text Preprocessing and Subject Extraction Using Pyspark </font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# I hope you find this kernel useful\n# Your <font color='red'> UPVOTES </font> would be highly appreciated","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install pyspark","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport json\nimport pyspark\nfrom pyspark import SparkContext\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import *\nimport pandas as pd\nimport os\nimport nltk\nimport re\nimport spacy\nfrom spacy.lang.fr.stop_words import STOP_WORDS\nimport string\nfrom pyspark.sql.functions import lit\nfrom pyspark.sql.functions import monotonically_increasing_id \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <font color='red'> Create Spark Session </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sparkSession = SparkSession.builder.appName(\"SentimentAnalysis\").getOrCreate()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color='black'> Load CSV to pandas Dataframe </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/insurance-reviews-france/Comments.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<font color='black'> Drop  Unnamed: 0 column </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['Unnamed: 0'], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<font color='black'> Convert pandas DataFrame To Pyspark DataFrame </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"schema = StructType([\n    StructField(\"Name\", StringType(), True),\n    StructField(\"Comment\", StringType(), True),\n    StructField(\"Month\", IntegerType(), True), \n    StructField(\"year\", StringType(), True),\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sp = sparkSession.createDataFrame(df,schema =schema )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sp.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <font color='red'> Data Preprocessing </font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font color='black'> Drop Nan Values </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sp = df_sp.filter(df_sp.Comment != 'NaN')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" \n <font color='black'> Add index column </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rdd_df = df_sp.rdd.zipWithIndex()\ndf_sp = rdd_df.toDF()\ndf_sp = df_sp.withColumn('Name', df_sp['_1'].getItem(\"Name\")).withColumn('Comment', df_sp['_1'].getItem(\"Comment\")).withColumn('Month', df_sp['_1'].getItem(\"Month\")).withColumn('Year', df_sp['_1'].getItem(\"Year\")).withColumn('Index', df_sp['_2'])\ndf_sp = df_sp.select('Index', 'Name','Comment','Month','Year')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sp.show(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color='black'> Select the Comments feature </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"comments_rdd = df_sp.select(\"Comment\").rdd.flatMap(lambda x: x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color='black'> Convert the data into lowercase. </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"comments_rdd_lower = comments_rdd.map(lambda x : x.lower())\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"comments_rdd_lower.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<font color='black'> Sentence tokenization </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def sentence_tokenization(x):\n    return nltk.sent_tokenize(x)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comments_rdd_tok = comments_rdd_lower.map(sentence_tokenization)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"comments_rdd_tok.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<font color='black'> Word tokenization </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def word_TokenizeFunctSentence(x):\n    sentence_splitted = []\n    for line in x:\n        splitted = []\n        for word in re.sub(\"\\W\",\" \", line).split():\n            splitted.append(word)\n        sentence_splitted.append(splitted)\n    return sentence_splitted\ncomments_rdd_word_tok_sentence = comments_rdd_tok.map(word_TokenizeFunctSentence)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"comments_rdd_word_tok_sentence.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<font color='black'> set of Spacy's default stop words and delete negation words </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words=set(STOP_WORDS)\n\ndeselect_stop_words = ['n\\'', 'ne','pas','plus','personne','aucun','ni','aucune','rien']\nfor w in deselect_stop_words:\n    if w in stop_words:\n        stop_words.remove(w)\n    else:\n        continue","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"stop_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def removeStopWordsSentencesFunct(x):\n    sentence_stop=[]\n    for j in x:\n        fil=[]\n        for w in j:\n            if not ((w in stop_words) or (len(w) == 1)):\n                fil.append(w)\n        sentence_stop.append(' '.join(fil))\n    return sentence_stop\n\nstopwordRDDSen = comments_rdd_word_tok_sentence.map(removeStopWordsSentencesFunct)\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"stopwordRDDSen.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<font color='black'> Join Tokens </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def joinTokensFunct(x):\n    joinedTokens_list = []\n    x = \" \".join(x)\n    joinedTokens_list.append(re.sub(\"\\W\",\" \", x))\n    return joinedTokens_list\njoinedTokens = stopwordRDDSen.map(joinTokensFunct)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"joinedTokens.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <font color='red'> Subject Extraction </font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"my_words = [\"sécurité\",\"prix\", \"sociale\" , \"remboursement\" , \"dentaire\", \"aide\" , \"pack\" , \"optique\" , \"soins\" ,\n\"enfant\",\"hospitalisation\" , \"handicap\" , \"document\" , \"retraite\" , \"carte\" , \"médicament\" , \"lunettes\" ,\n\"appareil\" , \"changement\" , \"accident\" , \"intervention\",\"garantie\",\"augmentation\",\"implant\", \"pharmacie\" ,\"attente\", \"formule\" ,\n\"maternité\" , \"cotisation\", \"cpam\" , \"diabète\", \"auditif\",\n\"commercial\", \"opticien\" , \"euros\" , \"retard\" , \"contrat\", \"prestation\", \"dossier\" , \"chirurgie\" , \"résiliation\" ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def TopicsSentences(x):\n    topics =[]        \n    topic =[]\n\n    for i in x:\n        for ext in my_words:\n            if (ext in i):\n                topic.append(ext)\n    return topic\ntopics = stopwordRDDSen.map(TopicsSentences)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"topics.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Add the comments after preprocessing and the topics to our Dataframe.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"comments_after_preproc = sparkSession.createDataFrame([w for w in joinedTokens.collect()], ['comments_after_preproc'])   \nrdd_df2 = comments_after_preproc.rdd.zipWithIndex()\ncomments_after_preproc = rdd_df2.toDF()\ncomments_after_preproc = comments_after_preproc.withColumn('comments_after_preproc', comments_after_preproc['_1'])\ncomments_after_preproc = comments_after_preproc.withColumn('Index', comments_after_preproc['_2'])\ncomments_after_preproc = comments_after_preproc.select('Index', 'comments_after_preproc')\n\n\nTopics = sparkSession.createDataFrame(topics,schema = \"array<string>\")    \ntopics_df = Topics.rdd.zipWithIndex()\nTopics = topics_df.toDF()\nTopics = Topics.withColumn('Topics', Topics['_1'])\nTopics = Topics.withColumn('Index', Topics['_2'])\nTopics = Topics.select('Index', 'Topics')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_spark4 = df_sp.join(comments_after_preproc, on=['Index']).join(Topics, on=['Index'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_spark4.show(5)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}