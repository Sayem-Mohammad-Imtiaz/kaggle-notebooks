{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import Callback\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-17T13:41:01.963026Z","iopub.execute_input":"2021-08-17T13:41:01.963421Z","iopub.status.idle":"2021-08-17T13:41:01.975968Z","shell.execute_reply.started":"2021-08-17T13:41:01.963369Z","shell.execute_reply":"2021-08-17T13:41:01.974734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Thanks to jamartinh on GH for demystifying how to implement on keras.\nclass Callback(tf.keras.callbacks.Callback):\n    def __init__(self, x_train, y_train, x_val, y_val):\n        self.x = x_train\n        self.y = y_train\n        self.x_val = x_val\n        self.y_val = y_val\n\n    def on_epoch_end(self, epoch, logs={}):\n        y_pred = self.model.predict(self.x)\n        roc_train = roc_auc_score(self.y, y_pred)\n        y_pred_val= self.model.predict(self.x_val)\n        roc_val = roc_auc_score(self.y_val, y_pred_val)\n        print('\\rroc-auc_train: %s - roc-auc_val: %s' % (str(round(roc_train, 4)), str(round(roc_val, 4))),\n              end=100 * ' ' + '\\n')\n        return\n    \nencoder = LabelEncoder()\nscaler = MinMaxScaler()\n\nx = pd.read_csv(\"../input/loan-prediction-based-on-customer-behavior/Training Data.csv\")\nx = pd.concat([x.loc[x[\"Risk_Flag\"]==0][:30996], x.loc[x[\"Risk_Flag\"]==1]])\ny = x.pop(\"Risk_Flag\")\nstr_x = x.select_dtypes(include=[object])\n\nfor i in range(0, len(str_x.columns)):\n    x.pop(str_x.columns[i])\n\nx = scaler.fit_transform(x)\nx = pd.DataFrame(x)\nstr_x = str_x.apply(encoder.fit_transform)\nstr_x = pd.DataFrame(str_x)\nstr_x.index = x.index\nx = pd.concat([x, str_x], axis=1)\n\nx_train, x_val, y_train, y_val = train_test_split(x, y, train_size=0.8, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-17T13:41:01.977794Z","iopub.execute_input":"2021-08-17T13:41:01.978306Z","iopub.status.idle":"2021-08-17T13:41:02.643049Z","shell.execute_reply.started":"2021-08-17T13:41:01.97826Z","shell.execute_reply":"2021-08-17T13:41:02.64189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dense_1 = tf.keras.layers.Dense(192, activation='relu', input_dim=12)\ndense_2 = tf.keras.layers.Dense(128, activation='relu')\ndense_3 = tf.keras.layers.Dense(64, activation='relu')\ndense_4 = tf.keras.layers.Dense(32, activation='relu')\noutput = tf.keras.layers.Dense(1, activation='sigmoid')\nmodel = tf.keras.models.Sequential([\n    dense_1,\n    tf.keras.layers.Dropout(.4),\n    dense_2,\n    tf.keras.layers.Dropout(.2),\n    dense_3,\n    dense_4,\n    output\n])\n\ncallback = Callback(x_train=x_train, y_train=y_train, x_val=x_val, y_val=y_val)\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=75, batch_size=512, callbacks=[callback])","metadata":{"execution":{"iopub.status.busy":"2021-08-17T13:41:02.644855Z","iopub.execute_input":"2021-08-17T13:41:02.645175Z","iopub.status.idle":"2021-08-17T13:43:55.279077Z","shell.execute_reply.started":"2021-08-17T13:41:02.645147Z","shell.execute_reply":"2021-08-17T13:43:55.278031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.xlabel(\"Epochs\")\nplt.ylabel(\"Validation\")\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.legend([\"acc\", \"validation acc\"])\nplt.show()\n\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.plot(history.history[\"loss\"])\nplt.plot(history.history[\"val_loss\"])\nplt.legend([\"loss\", \"validation loss\"], loc=\"upper left\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-17T13:43:55.280638Z","iopub.execute_input":"2021-08-17T13:43:55.280965Z","iopub.status.idle":"2021-08-17T13:43:55.671208Z","shell.execute_reply.started":"2021-08-17T13:43:55.280934Z","shell.execute_reply":"2021-08-17T13:43:55.669845Z"},"trusted":true},"execution_count":null,"outputs":[]}]}