{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Baseball Data\n## Description\nMajor League Baseball Data from the 1986 and 1987 seasons.\n\n## Usage\nHitters\n\n## Format\nA data frame with 322 observations of major league players on the following 20 variables.\n\n- AtBat: Number of times at bat in 1986\n\n- Hits: Number of hits in 1986\n\n- HmRun: Number of home runs in 1986\n\n- Runs: Number of runs in 1986\n\n- RBI: Number of runs batted in in 1986\n\n- Walks: Number of walks in 1986\n\n- Years: Number of years in the major leagues\n\n- CAtBat: Number of times at bat during his career\n\n- CHits: Number of hits during his career\n\n- CHmRun: Number of home runs during his career\n\n- CRuns: Number of runs during his career\n\n- CRBI: Number of runs batted in during his career\n\n- CWalks: Number of walks during his career\n\n- League: A factor with levels A and N indicating player's league at the end of 1986\n\n- Division: A factor with levels E and W indicating player's division at the end of 1986\n\n- PutOuts: Number of put outs in 1986\n\n- Assists: Number of assists in 1986\n\n- Errors: Number of errors in 1986\n\n- Salary: 1987 annual salary on opening day in thousands of dollars\n\n- NewLeague: A factor with levels A and N indicating player's league at the beginning of 1987\n\n## Source\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. This is part of the data that was used in the 1988 ASA Graphics Section Poster Session. The salary data were originally from Sports Illustrated, April 20, 1987. The 1986 and career statistics were obtained from The 1987 Baseball Encyclopedia Update published by Collier Books, Macmillan Publishing Company, New York.\n\n## References\nGames, G., Witten, D., Hastie, T., and Tibshirani, R. (2013) An Introduction to Statistical Learning with applications in R, www.StatLearning.com, Springer-Verlag, New York\n\n## Examples\nsummary(Hitters)\nlm(Salary~AtBat+Hits,data=Hitters)\n--\nDataset imported from https://www.r-project.org."},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore')\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, Ridge, RidgeCV, ElasticNet, Lasso, LassoCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import RobustScaler\n\nHitters=pd.read_csv(\"../input/hitters-baseball-data/Hitters.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA UNDERSTANDING"},{"metadata":{},"cell_type":"markdown","source":"Lets take a copy and information about data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"df=Hitters.copy()\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Statistical view for all features:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observe NaN values and take a head:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.isnull().any(axis=1)].head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Total NaN values numbers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"See just 'Salary' feature has NaN values. Now, correlation that is what's going between features. How are they strict relation between them. We gave correlation values more than 0.5 between features"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlation_matrix = df.corr().round(2)\nthreshold=0.75\nfiltre=np.abs(correlation_matrix['Salary']) > 0.50\ncorr_features=correlation_matrix.columns[filtre].tolist()\nsns.clustermap(df[corr_features].corr(),annot=True,fmt=\".2f\")\nplt.title('Correlation btw features')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Missing values visualization:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import missingno as msno\nmsno.bar(df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA PREPROCESSING\n\nWe will consider some options for Missing Values."},{"metadata":{},"cell_type":"markdown","source":"###  First Option\nThis method is drop all NaN values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df.copy()\ndf1=df1.dropna()\ndf1.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then, convert categorical variable into dummy/indicator variables with 'drop_first = True'. This is for Dummy trap."},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=pd.get_dummies(df1,columns = ['League', 'Division', 'NewLeague'], drop_first = True)\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Outlier Detection\n\nUsing LOF(Local Outliers Factor) method."},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=LocalOutlierFactor(n_neighbors=20, contamination=0.1)\nclf.fit_predict(df1)\ndf1_scores=clf.negative_outlier_factor_\ndf1_scores= np.sort(df1_scores)\ndf1_scores[0:20]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And show all outliers with boxplot."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df1_scores);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Give threshold for LOF."},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold=np.sort(df1_scores)[10]\nprint(threshold)\ndf1=df1.loc[df1_scores > threshold]\ndf1=df1.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Standardization\n\nThis is first option with using drop method."},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_X=df1.drop([\"Salary\",\"League_N\",\"Division_W\",\"NewLeague_N\"], axis=1)\ndf1_X.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaled_cols=StandardScaler().fit_transform(df1_X)\n\n\n\nscaled_cols=pd.DataFrame(scaled_cols, columns=df1_X.columns)\nscaled_cols.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df1=df1.loc[:, \"League_N\":\"NewLeague_N\"]\ncat_df1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Salary=pd.DataFrame(df1[\"Salary\"])\nSalary.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concatination for all prepared data frames:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2=pd.concat([Salary,scaled_cols, cat_df1], axis=1)\ndf2.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Second Option\nThis is second option and method is fill NA values with mean."},{"metadata":{"trusted":true},"cell_type":"code","source":"df5=df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets take group between 'League','Division', 'Year_lab' features and use 'mean' aggrigation fonksiyon for 'Salary' column."},{"metadata":{"trusted":true},"cell_type":"code","source":"df5['Year_lab'] = pd.cut(x=df['Years'], bins=[0, 3, 6, 10, 15, 19, 24])\ndf5.groupby(['League','Division', 'Year_lab']).agg({'Salary':'mean'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's make assignments to NaN values according to the above grouping."},{"metadata":{"trusted":true},"cell_type":"code","source":"df5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'E') & (df5['Years'] <= 3), \"Salary\"] = 112\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'E') & (df5['Years'] > 3) & (df5['Years'] <= 6), \"Salary\"] = 656\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'E') & (df5['Years'] > 6) & (df5['Years'] <= 10), \"Salary\"] = 853\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'E') & (df5['Years'] > 10) & (df5['Years'] <= 15), \"Salary\"] = 816\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'E') & (df5['Years'] > 15) & (df5['Years'] <= 19), \"Salary\"] = 665\n\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'W') & (df5['Years'] <= 3), \"Salary\"] = 154\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'W') & (df5['Years'] > 3) & (df5['Years'] <= 6), \"Salary\"] = 401\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'W') & (df5['Years'] > 6) & (df5['Years'] <= 10), \"Salary\"] = 634\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'W') & (df5['Years'] > 10) & (df5['Years'] <= 15), \"Salary\"] = 835\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'W') & (df5['Years'] > 15) & (df5['Years'] <= 19), \"Salary\"] = 479\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"A\") & (df5['Division'] == 'W') & (df5['Years'] > 19), \"Salary\"] = 487\n\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'E') & (df5['Years'] <= 3), \"Salary\"] = 248\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'E') & (df5['Years'] > 3) & (df5['Years'] <= 6), \"Salary\"] = 501\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'E') & (df5['Years'] > 6) & (df5['Years'] <= 10), \"Salary\"] = 824\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'E') & (df5['Years'] > 10) & (df5['Years'] <= 15), \"Salary\"] = 894\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'E') & (df5['Years'] > 15) & (df5['Years'] <= 19), \"Salary\"] = 662\n\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'W') & (df5['Years'] <= 3), \"Salary\"] = 192\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'W') & (df5['Years'] > 3) & (df5['Years'] <= 6), \"Salary\"] = 458\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'W') & (df5['Years'] > 6) & (df5['Years'] <= 10), \"Salary\"] = 563\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'W') & (df5['Years'] > 10) & (df5['Years'] <= 15), \"Salary\"] = 722\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'W') & (df5['Years'] > 15) & (df5['Years'] <= 19), \"Salary\"] = 761\ndf5.loc[(df[\"Salary\"].isnull()) & (df5[\"League\"] == \"N\") & (df5['Division'] == 'W') & (df5['Years'] > 19), \"Salary\"] = 475","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now using Label Encoder object then apply 'League', 'Division' and 'NewLeague'."},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\ndf5['League'] = le.fit_transform(df5['League'])\ndf5['Division'] = le.fit_transform(df5['Division'])\ndf5['NewLeague'] = le.fit_transform(df5['NewLeague'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"and for 'Year_lab' column also."},{"metadata":{"trusted":true},"cell_type":"code","source":"df5['Year_lab'] = le.fit_transform(df5['Year_lab'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Normalization\n\nAfter standartization lets normalize last features."},{"metadata":{"trusted":true},"cell_type":"code","source":"df5_X= df5.drop([\"Salary\",\"League\",\"Division\",\"NewLeague\"], axis=1)\n\nscaled_cols5=preprocessing.normalize(df5_X)\n\n\nscaled_cols5=pd.DataFrame(scaled_cols5, columns=df5_X.columns)\nscaled_cols5.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Categorical dataframe:"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df5=pd.concat([df5.loc[:,\"League\":\"Division\"],df5.loc[:,\"NewLeague\":\"Year_lab\"]], axis=1)\ncat_df5.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concatination for all prepared data frames:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df6= pd.concat([scaled_cols5,cat_df5,df5[\"Salary\"]], axis=1)\ndf6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df6.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Third Option\n\nThis is third option for NaN values considiration. Drop NaN values and outliers like first option and log transformation of the features which have multicorrelation above 0.8 between each other."},{"metadata":{"trusted":true},"cell_type":"code","source":"df3= df1.copy()\nprint(df3.shape)\ndf3.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# log transform the variables\ndf3['CRuns'] = np.log(df3['CRuns'])\ndf3['CHits'] = np.log(df3['CHits'])\ndf3['CAtBat'] = np.log(df3['CAtBat'])\ndf3['Years'] = np.log(df3['Years'])\ndf3['CRBI'] = np.log(df3['CRBI'])\ndf3['CWalks'] = np.log(df3['CWalks'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3_X=df3.drop([\"Salary\",\"League_N\",\"Division_W\",\"NewLeague_N\"], axis=1)\ndf3_X.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3_X.shape","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"Rscaler = RobustScaler().fit(df3_X)\nscaled_cols3=Rscaler.transform(df3_X)\nscaled_cols3=pd.DataFrame(scaled_cols3, columns=df3_X.columns)\nscaled_cols3.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concatination for all prepared data frames:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df4=pd.concat([df3_X,df3.loc[:, \"League_N\": \"NewLeague_N\"], df3[\"Salary\"]], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df4.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_cols3.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df3=df3.loc[:, \"League_N\":\"NewLeague_N\"]\ncat_df3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df4.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fourth Option\nThis is fourth option for NaN values and method with mean."},{"metadata":{"trusted":true},"cell_type":"code","source":"df7=df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filled NaN values with mean\n\ndf7.loc[(df7[\"Salary\"].isnull()) & (df7[\"League\"] == \"A\") & (df7['Division'] == 'E'),\"Salary\"] = 670.849559\ndf7.loc[(df7[\"Salary\"].isnull()) & (df7[\"League\"] == \"A\") & (df7['Division'] == 'W'),\"Salary\"] = 418.593901\ndf7.loc[(df7[\"Salary\"].isnull()) & (df7[\"League\"] == \"N\") & (df7['Division'] == 'E'),\"Salary\"] = 572.348131\ndf7.loc[(df7[\"Salary\"].isnull()) & (df7[\"League\"] == \"N\") & (df7['Division'] == 'W'),\"Salary\"] = 487.259270","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Transformation"},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\ndf7['League'] = le.fit_transform(df7['League'])\ndf7['Division'] = le.fit_transform(df7['Division'])\ndf7['NewLeague'] = le.fit_transform(df7['NewLeague'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"df7_X= df7.drop([\"Salary\",\"League\",\"Division\",\"NewLeague\"], axis=1)\n\nscaled_cols7=preprocessing.normalize(df7_X)\n\n\nscaled_cols7=pd.DataFrame(scaled_cols7, columns=df7_X.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Concatenate"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df7=pd.concat([df7.loc[:,\"League\":\"Division\"],df7[\"NewLeague\"]], axis=1)\ncat_df7.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df8= pd.concat([scaled_cols7,cat_df7,df7[\"Salary\"]], axis=1)\ndf8.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df8.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODELING\n\nLet's see different models error accuracy scores according to the DataFrames we created above."},{"metadata":{},"cell_type":"markdown","source":"## Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df2[\"Salary\"]\nX=df2.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nlinreg = LinearRegression()\nmodel = linreg.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf2_linreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf2_linreg_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df6[\"Salary\"]\nX=df6.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nlinreg = LinearRegression()\nmodel = linreg.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf6_linreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf6_linreg_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df4[\"Salary\"]\nX=df4.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nlinreg = LinearRegression()\nmodel = linreg.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf4_linreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf4_linreg_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df8[\"Salary\"]\nX=df8.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nlinreg = LinearRegression()\nmodel = linreg.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf8_linreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf8_linreg_rmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ridge Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df2[\"Salary\"]\nX=df2.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nridreg = Ridge()\nmodel = ridreg.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ndf2_ridreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf2_ridreg_rmse ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df6[\"Salary\"]\nX=df6.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nridreg = Ridge()\nmodel = ridreg.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ndf6_ridreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf6_ridreg_rmse ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df4[\"Salary\"]\nX=df4.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nridreg = Ridge()\nmodel = ridreg.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ndf4_ridreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf4_ridreg_rmse ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df8[\"Salary\"]\nX=df8.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nridreg = Ridge()\nmodel = ridreg.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ndf8_ridreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf8_ridreg_rmse ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lasso Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df2[\"Salary\"]\nX=df2.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nlasreg = Lasso()\nmodel = lasreg.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf2_lasreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf2_lasreg_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df6[\"Salary\"]\nX=df6.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nlasreg = Lasso()\nmodel = lasreg.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf6_lasreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf6_lasreg_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df4[\"Salary\"]\nX=df4.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nlasreg = Lasso()\nmodel = lasreg.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf4_lasreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf4_lasreg_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df8[\"Salary\"]\nX=df8.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nlasreg = Lasso()\nmodel = lasreg.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf8_lasreg_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf8_lasreg_rmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Elastic Net Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df2[\"Salary\"]\nX=df2.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nenet = ElasticNet()\nmodel = enet.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf2_enet_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf2_enet_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df6[\"Salary\"]\nX=df6.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nenet = ElasticNet()\nmodel = enet.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf6_enet_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf6_enet_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df4[\"Salary\"]\nX=df4.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nenet = ElasticNet()\nmodel = enet.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf4_enet_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf4_enet_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df8[\"Salary\"]\nX=df8.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nenet = ElasticNet()\nmodel = enet.fit(X_train,y_train)\ny_pred = model.predict(X_test)\ndf8_enet_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf8_enet_rmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL TUNING\n\nNow, consider with model tunning and get accuracy scores."},{"metadata":{},"cell_type":"markdown","source":"## Ridge Regression with Model Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df2[\"Salary\"]\nX=df2.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nalpha = [0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]\nridreg_cv = RidgeCV(alphas = alpha, scoring = \"neg_mean_squared_error\", cv = 10, normalize = True)\nridreg_cv.fit(X_train, y_train)\nridreg_cv.alpha_\n\n#Final Model \nridreg_tuned = Ridge(alpha = ridreg_cv.alpha_).fit(X_train,y_train)\ny_pred = ridreg_tuned.predict(X_test)\ndf2_ridge_tuned_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf2_ridge_tuned_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df6[\"Salary\"]\nX=df6.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nalpha = [0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]\nridreg_cv = RidgeCV(alphas = alpha, scoring = \"neg_mean_squared_error\", cv = 10, normalize = True)\nridreg_cv.fit(X_train, y_train)\nridreg_cv.alpha_\n\n#Final Model \nridreg_tuned = Ridge(alpha = ridreg_cv.alpha_).fit(X_train,y_train)\ny_pred = ridreg_tuned.predict(X_test)\ndf6_ridge_tuned_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf6_ridge_tuned_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df4[\"Salary\"]\nX=df4.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nalpha = [0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]\nridreg_cv = RidgeCV(alphas = alpha, scoring = \"neg_mean_squared_error\", cv = 10, normalize = True)\nridreg_cv.fit(X_train, y_train)\nridreg_cv.alpha_\n\n#Final Model \nridreg_tuned = Ridge(alpha = ridreg_cv.alpha_).fit(X_train,y_train)\ny_pred = ridreg_tuned.predict(X_test)\ndf4_ridge_tuned_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf4_ridge_tuned_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df8[\"Salary\"]\nX=df8.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\n\nalpha = [0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]\nridreg_cv = RidgeCV(alphas = alpha, scoring = \"neg_mean_squared_error\", cv = 10, normalize = True)\nridreg_cv.fit(X_train, y_train)\nridreg_cv.alpha_\n\n#Final Model \nridreg_tuned = Ridge(alpha = ridreg_cv.alpha_).fit(X_train,y_train)\ny_pred = ridreg_tuned.predict(X_test)\ndf8_ridge_tuned_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf8_ridge_tuned_rmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lasso Regression with Model Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df2[\"Salary\"]\nX=df2.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nalpha = [0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]\nlasso_cv = LassoCV(alphas = alpha, cv = 10, normalize = True)\nlasso_cv.fit(X_train, y_train)\nlasso_cv.alpha_\n\n#Final Model \nlasso_tuned = Lasso(alpha = lasso_cv.alpha_).fit(X_train,y_train)\ny_pred = lasso_tuned.predict(X_test)\ndf2_lasso_tuned_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\ndf2_lasso_tuned_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df6[\"Salary\"]\nX=df6.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nalpha = [0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]\nlasso_cv = LassoCV(alphas = alpha, cv = 10, normalize = True)\nlasso_cv.fit(X_train, y_train)\nlasso_cv.alpha_\n\n#Final Model \nlasso_tuned = Lasso(alpha = lasso_cv.alpha_).fit(X_train,y_train)\ny_pred = lasso_tuned.predict(X_test)\ndf6_lasso_tuned_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\ndf6_lasso_tuned_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df4[\"Salary\"]\nX=df4.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nalpha = [0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]\nlasso_cv = LassoCV(alphas = alpha, cv = 10, normalize = True)\nlasso_cv.fit(X_train, y_train)\nlasso_cv.alpha_\n\n#Final Model \nlasso_tuned = Lasso(alpha = lasso_cv.alpha_).fit(X_train,y_train)\ny_pred = lasso_tuned.predict(X_test)\ndf4_lasso_tuned_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\ndf4_lasso_tuned_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df8[\"Salary\"]\nX=df8.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nalpha = [0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]\nlasso_cv = LassoCV(alphas = alpha, cv = 10, normalize = True)\nlasso_cv.fit(X_train, y_train)\nlasso_cv.alpha_\n\n#Final Model \nlasso_tuned = Lasso(alpha = lasso_cv.alpha_).fit(X_train,y_train)\ny_pred = lasso_tuned.predict(X_test)\ndf8_lasso_tuned_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\ndf8_lasso_tuned_rmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Elastic Net Regression with Model Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df2[\"Salary\"]\nX=df2.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nenet_params = {\"l1_ratio\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n              \"alpha\":[0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]}\n\nenet_model = ElasticNet().fit(X_train,y_train)\nenet_cv = GridSearchCV(enet_model, enet_params, cv = 10).fit(X, y)\nenet_cv.best_params_\n\n#Final Model \nenet_tuned = ElasticNet(**enet_cv.best_params_).fit(X_train,y_train)\ny_pred = enet_tuned.predict(X_test)\ndf2_enet_tuned_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf2_enet_tuned_rmse ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df6[\"Salary\"]\nX=df6.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nenet_params = {\"l1_ratio\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n              \"alpha\":[0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]}\n\nenet_model = ElasticNet().fit(X_train,y_train)\nenet_cv = GridSearchCV(enet_model, enet_params, cv = 10).fit(X, y)\nenet_cv.best_params_\n\n#Final Model \nenet_tuned = ElasticNet(**enet_cv.best_params_).fit(X_train,y_train)\ny_pred = enet_tuned.predict(X_test)\ndf6_enet_tuned_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf6_enet_tuned_rmse ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df4[\"Salary\"]\nX=df4.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nenet_params = {\"l1_ratio\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n              \"alpha\":[0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]}\n\nenet_model = ElasticNet().fit(X_train,y_train)\nenet_cv = GridSearchCV(enet_model, enet_params, cv = 10).fit(X, y)\nenet_cv.best_params_\n\n#Final Model \nenet_tuned = ElasticNet(**enet_cv.best_params_).fit(X_train,y_train)\ny_pred = enet_tuned.predict(X_test)\ndf4_enet_tuned_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf4_enet_tuned_rmse ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df8[\"Salary\"]\nX=df8.drop(\"Salary\", axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, \n                                                    random_state=46)\n\nenet_params = {\"l1_ratio\": [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n              \"alpha\":[0.1,0.01,0.001,0.2,0.3,0.5,0.8,0.9,1]}\n\nenet_model = ElasticNet().fit(X_train,y_train)\nenet_cv = GridSearchCV(enet_model, enet_params, cv = 10).fit(X, y)\nenet_cv.best_params_\n\n#Final Model \nenet_tuned = ElasticNet(**enet_cv.best_params_).fit(X_train,y_train)\ny_pred = enet_tuned.predict(X_test)\ndf8_enet_tuned_rmse = np.sqrt(mean_squared_error(y_test,y_pred))\ndf8_enet_tuned_rmse ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's put all created models into dataframe shape and watch them."},{"metadata":{"trusted":true},"cell_type":"code","source":"basicsonuc_df = pd.DataFrame({\"CONDITIONS\":[\"df2: drop NA and Outliers, normalized\",\"df6: filled with mean, normalized\",\"df4: drop NA and Outliers, log transformed\",\"df8: filled with mean,normalized\"],\n                              \"LINEAR\":[df2_linreg_rmse,df6_linreg_rmse,df4_linreg_rmse,df8_linreg_rmse],\n                               \"RIDGE\":[df2_ridreg_rmse,df6_ridreg_rmse,df4_ridreg_rmse,df8_ridreg_rmse],\n                              \"RIDGE TUNED\":[df2_ridge_tuned_rmse,df6_ridge_tuned_rmse,df4_ridge_tuned_rmse,df8_ridge_tuned_rmse],\n                              \"LASSO\":[df2_lasreg_rmse,df6_lasreg_rmse,df4_lasreg_rmse,df8_lasreg_rmse],\n                              \"LASSO TUNED\":[df2_lasso_tuned_rmse,df6_lasso_tuned_rmse,df4_lasso_tuned_rmse,df8_lasso_tuned_rmse],                              \n                              \"ELASTIC NET\":[df2_enet_rmse,df6_enet_rmse,df4_enet_rmse,df8_enet_rmse],\n                              \"ELASTIC NET TUNED\":[df2_enet_tuned_rmse,df6_enet_tuned_rmse,df4_enet_tuned_rmse,df8_enet_tuned_rmse]\n                              })\n\nbasicsonuc_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# REPORTING\n\nThe aim of this study is to set up linear regression models for the Hitters data set and minimize error scores in 4 data sets that have undergone different preprocessing. \n\nThe studies conducted are as follows:\n\n#### ** 1) ** Hitters Data Set was read.\n#### ** 2) ** With Exploratory Data Analysis:\n* Structural information of the dataset was checked.\n* Types of variables in data set were examined.\n* The size information of the data set has been accessed.\n* The number of missing observations from which variable in the data set was accessed. It was observed that there were 59 missing observations only in \"Salary\" which was dependent variable.\n* Descriptive statistics of the data set were examined.\n\n#### ** 3) ** In Data PreProcessing:\n* ** For df2: ** NaN values are dropped, Outliers are detected by LOF and dropped. Dummy variables were created. The X variables were normalized.\n* ** For df6: ** NaN values were filled by looking at \"Salary\" averages in age, league and division variables, Dummy variables were created. The X variables were normalized.\n* ** For df4: ** NaN values and outlier detected by LOF were dropped, log transformation was applied to variables with more than 80% correlation. Dummy variables were created. All x variables were brought to the same range as Robust scaler.\n* ** For df8: ** NaN values were filled by looking at \"Salary\" averages in league and division variables, Dummy variables were created. The X variables were normalized.\n\n#### ** 4) ** During the Model Building phase:\n\nUsing the Linear, Ridge, Lasso, ElasticNet machine learning models, ** RMSE ** values representing the difference between actual values and predicted values were calculated. Later, hyperparameter optimizations were applied for Ridge, Lasso and ElasticNet to further reduce the error value.\n"},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n\nWhen the model created as a result of Elastic Net Hyperparameter optimization was applied to the df6 Data Frame, the lowest RMSE was obtained. (283)\n\n#### Note: \n- After this notebook, my aim is to prepare 'kernel' which is 'not clear' data set.\n\n- If you have any suggestions, please could you write for me? I wil be happy for comment and critics!\n\n Thank you for your suggestion and votes ;) "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}