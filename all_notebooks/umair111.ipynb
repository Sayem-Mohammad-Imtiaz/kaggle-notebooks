{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---------------------------------------------------------------------------------------\n## Import libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization,DepthwiseConv2D\nfrom keras.losses import categorical_crossentropy\nfrom sklearn.metrics import accuracy_score\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nprint(os.listdir(\"../input\"))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-28T08:50:34.376539Z","iopub.execute_input":"2021-06-28T08:50:34.376858Z","iopub.status.idle":"2021-06-28T08:50:34.386542Z","shell.execute_reply.started":"2021-06-28T08:50:34.376804Z","shell.execute_reply":"2021-06-28T08:50:34.385746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Overview","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/fer2013.csv')\n#check data shape\ndata.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:24:32.161768Z","iopub.execute_input":"2021-06-28T08:24:32.165113Z","iopub.status.idle":"2021-06-28T08:24:37.93752Z","shell.execute_reply.started":"2021-06-28T08:24:32.165061Z","shell.execute_reply":"2021-06-28T08:24:37.936658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preview first 5 row of data\ndata.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:24:37.938898Z","iopub.execute_input":"2021-06-28T08:24:37.939186Z","iopub.status.idle":"2021-06-28T08:24:37.968543Z","shell.execute_reply.started":"2021-06-28T08:24:37.939138Z","shell.execute_reply":"2021-06-28T08:24:37.967407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check usage values\n#80% training, 10% validation and 10% test\ndata.Usage.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:24:37.970359Z","iopub.execute_input":"2021-06-28T08:24:37.970903Z","iopub.status.idle":"2021-06-28T08:24:37.988687Z","shell.execute_reply.started":"2021-06-28T08:24:37.970631Z","shell.execute_reply":"2021-06-28T08:24:37.987655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check target labels\nemotion_map = {0: 'Angry', 1: 'Digust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\nemotion_counts = data['emotion'].value_counts(sort=False).reset_index()\nemotion_counts.columns = ['emotion', 'number']\nemotion_counts['emotion'] = emotion_counts['emotion'].map(emotion_map)\nemotion_counts","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:24:37.992042Z","iopub.execute_input":"2021-06-28T08:24:37.992467Z","iopub.status.idle":"2021-06-28T08:24:38.01244Z","shell.execute_reply.started":"2021-06-28T08:24:37.992395Z","shell.execute_reply":"2021-06-28T08:24:38.01154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting a bar graph of the class distributions\nplt.figure(figsize=(6,4))\nsns.barplot(emotion_counts.emotion, emotion_counts.number)\nplt.title('Class distribution')\nplt.ylabel('Number', fontsize=12)\nplt.xlabel('Emotions', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:24:38.014059Z","iopub.execute_input":"2021-06-28T08:24:38.014575Z","iopub.status.idle":"2021-06-28T08:24:38.224535Z","shell.execute_reply.started":"2021-06-28T08:24:38.014328Z","shell.execute_reply":"2021-06-28T08:24:38.223676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def row2image(row):\n    pixels, emotion = row['pixels'], emotion_map[row['emotion']]\n    img = np.array(pixels.split())\n    img = img.reshape(48,48)\n    image = np.zeros((48,48,3))\n    image[:,:,0] = img\n    image[:,:,1] = img\n    image[:,:,2] = img\n    return np.array([image.astype(np.uint8), emotion])\n\nplt.figure(0, figsize=(16,10))\nfor i in range(1,8):\n    face = data[data['emotion'] == i-1].iloc[0]\n    img = row2image(face)\n    plt.subplot(2,4,i)\n    plt.imshow(img[0])\n    plt.title(img[1])\n\nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:24:38.229087Z","iopub.execute_input":"2021-06-28T08:24:38.231363Z","iopub.status.idle":"2021-06-28T08:24:39.147544Z","shell.execute_reply.started":"2021-06-28T08:24:38.231244Z","shell.execute_reply":"2021-06-28T08:24:39.146712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----------------------------------------------------------------------------------\n## Pre-processing data\n#### Summary:\n1. Splitting dataset into 3 parts: train, validation, test\n1. Convert strings to lists of integers\n1. Reshape to 48x48 and normalise grayscale image with 255.0\n1. Perform one-hot encoding label, e.g. class 3 to [0,0,0,1,0,0,0]","metadata":{}},{"cell_type":"code","source":"#split data into training, validation and test set\ndata_train = data[data['Usage']=='Training'].copy()\ndata_val   = data[data['Usage']=='PublicTest'].copy()\ndata_test  = data[data['Usage']=='PrivateTest'].copy()\nprint(\"train shape: {}, \\nvalidation shape: {}, \\ntest shape: {}\".format(data_train.shape, data_val.shape, data_test.shape))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:24:39.149463Z","iopub.execute_input":"2021-06-28T08:24:39.151449Z","iopub.status.idle":"2021-06-28T08:24:39.202936Z","shell.execute_reply.started":"2021-06-28T08:24:39.151388Z","shell.execute_reply":"2021-06-28T08:24:39.202199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# barplot class distribution of train, val and test\nemotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n\ndef setup_axe(axe,df,title):\n    df['emotion'].value_counts(sort=False).plot(ax=axe, kind='bar', rot=0)\n    axe.set_xticklabels(emotion_labels)\n    axe.set_xlabel(\"Emotions\")\n    axe.set_ylabel(\"Number\")\n    axe.set_title(title)\n    \n    # set individual bar lables using above list\n    for i in axe.patches:\n        # get_x pulls left or right; get_height pushes up or down\n        axe.text(i.get_x()-.05, i.get_height()+120, \\\n                str(round((i.get_height()), 2)), fontsize=14, color='dimgrey',\n                    rotation=0)\n\n   \nfig, axes = plt.subplots(1,3, figsize=(20,8), sharey=True)\nsetup_axe(axes[0],data_train,'train')\nsetup_axe(axes[1],data_val,'validation')\nsetup_axe(axes[2],data_test,'test')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:24:39.20702Z","iopub.execute_input":"2021-06-28T08:24:39.20924Z","iopub.status.idle":"2021-06-28T08:24:39.921338Z","shell.execute_reply.started":"2021-06-28T08:24:39.209184Z","shell.execute_reply":"2021-06-28T08:24:39.920524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notice that the later two subplots share the same y-axis with the first subplot. \n\nThe size of **train**, **validation**, **test** are **80%**, **10%** and **10%**, respectively. \n\nThe exact number of each class of these datasets are written on top of their x-axis bar. ","metadata":{}},{"cell_type":"code","source":"#initilize parameters\nnum_classes = 7 \nwidth, height = 48, 48\nnum_epochs = 50\nbatch_size = 64\nnum_features = 64","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:24:39.925633Z","iopub.execute_input":"2021-06-28T08:24:39.92789Z","iopub.status.idle":"2021-06-28T08:24:39.935035Z","shell.execute_reply.started":"2021-06-28T08:24:39.927825Z","shell.execute_reply":"2021-06-28T08:24:39.934011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CRNO stands for Convert, Reshape, Normalize, One-hot encoding\n# (i) convert strings to lists of integers\n# (ii) reshape and normalise grayscale image with 255.0\n# (iii) one-hot encoding label, e.g. class 3 to [0,0,0,1,0,0,0]\n\ndef CRNO(df, dataName):\n    df['pixels'] = df['pixels'].apply(lambda pixel_sequence: [int(pixel) for pixel in pixel_sequence.split()])\n    data_X = np.array(df['pixels'].tolist(), dtype='float32').reshape(-1,width, height,1)/255.0   \n    data_Y = to_categorical(df['emotion'], num_classes)  \n    print(dataName, \"_X shape: {}, \", dataName, \"_Y shape: {}\".format(data_X.shape, data_Y.shape))\n    return data_X, data_Y\n\n    \ntrain_X, train_Y = CRNO(data_train, \"train\") #training data\nval_X, val_Y     = CRNO(data_val, \"val\") #validation data\ntest_X, test_Y   = CRNO(data_test, \"test\") #test data","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:24:39.940332Z","iopub.execute_input":"2021-06-28T08:24:39.943335Z","iopub.status.idle":"2021-06-28T08:25:13.702086Z","shell.execute_reply.started":"2021-06-28T08:24:39.943155Z","shell.execute_reply":"2021-06-28T08:25:13.700306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----------------------------------------------------------------------------------\n## Building CNN Model\n","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\n#module 1\nmodel.add(Conv2D(2*2*num_features, kernel_size=(3, 3), input_shape=(width, height, 1), data_format='channels_last'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(2*2*num_features, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n#module 2\nmodel.add(Conv2D(2*num_features, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(2*num_features, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n#module 3\nmodel.add(Conv2D(num_features, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(num_features, kernel_size=(3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n#flatten\nmodel.add(Flatten())\n\n#dense 1\nmodel.add(Dense(2*2*2*num_features))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\n#dense 2\nmodel.add(Dense(2*2*num_features))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\n#dense 3\nmodel.add(Dense(2*num_features))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\n#output layer\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', \n              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7), \n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:25:13.704029Z","iopub.execute_input":"2021-06-28T08:25:13.70451Z","iopub.status.idle":"2021-06-28T08:25:17.338933Z","shell.execute_reply.started":"2021-06-28T08:25:13.704414Z","shell.execute_reply":"2021-06-28T08:25:17.338077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data generator\ndata_generator = ImageDataGenerator(\n                        featurewise_center=False,\n                        featurewise_std_normalization=False,\n                        rotation_range=10,\n                        width_shift_range=0.1,\n                        height_shift_range=0.1,\n                        zoom_range=.1,\n                        horizontal_flip=True)\n\n\nes = EarlyStopping(monitor='val_loss', patience = 10, mode = 'min', restore_best_weights=True)\n\nhistory = model.fit_generator(data_generator.flow(train_X, train_Y, batch_size),\n                                steps_per_epoch=len(train_X) / batch_size,\n                                epochs=num_epochs,\n                                verbose=2, \n                                callbacks = [es],\n                                validation_data=(val_X, val_Y))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:25:17.342017Z","iopub.execute_input":"2021-06-28T08:25:17.342247Z","iopub.status.idle":"2021-06-28T08:37:49.020814Z","shell.execute_reply.started":"2021-06-28T08:25:17.342203Z","shell.execute_reply":"2021-06-28T08:37:49.019676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights(\"./modelumair111.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:41:56.910249Z","iopub.execute_input":"2021-06-28T08:41:56.91058Z","iopub.status.idle":"2021-06-28T08:41:56.976779Z","shell.execute_reply.started":"2021-06-28T08:41:56.910529Z","shell.execute_reply":"2021-06-28T08:41:56.975876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize Training Performance","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(18, 6))\n# Plot training & validation accuracy values\naxes[0].plot(history.history['acc'])\naxes[0].plot(history.history['val_acc'])\naxes[0].set_title('Model accuracy')\naxes[0].set_ylabel('Accuracy')\naxes[0].set_xlabel('Epoch')\naxes[0].legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\naxes[1].plot(history.history['loss'])\naxes[1].plot(history.history['val_loss'])\naxes[1].set_title('Model loss')\naxes[1].set_ylabel('Loss')\naxes[1].set_xlabel('Epoch')\naxes[1].legend(['Train', 'Validation'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:42:48.659646Z","iopub.execute_input":"2021-06-28T08:42:48.659941Z","iopub.status.idle":"2021-06-28T08:42:49.064674Z","shell.execute_reply.started":"2021-06-28T08:42:48.659889Z","shell.execute_reply":"2021-06-28T08:42:49.063706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_true = np.argmax(test_Y, axis=1)\ntest_pred = np.argmax(model.predict(test_X), axis=1)\nprint(\"Model Accuracy on test set: {:.4f}\".format(accuracy_score(test_true, test_pred)))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:44:24.827684Z","iopub.execute_input":"2021-06-28T08:44:24.82807Z","iopub.status.idle":"2021-06-28T08:44:26.497789Z","shell.execute_reply.started":"2021-06-28T08:44:24.828023Z","shell.execute_reply":"2021-06-28T08:44:26.496554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## More Analysis using Confusion Matrix\n\nConfusion Matrix is applied and plotted to find out which emotion usually get confused with each other.","metadata":{}},{"cell_type":"code","source":"def plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    classes = classes\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        #print(\"Normalized confusion matrix\")\n    #else:\n        #print('Confusion matrix, without normalization')\n\n    #print(cm)\n\n    fig, ax = plt.subplots(figsize=(12,6))\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:43:44.225164Z","iopub.execute_input":"2021-06-28T08:43:44.225504Z","iopub.status.idle":"2021-06-28T08:43:44.238159Z","shell.execute_reply.started":"2021-06-28T08:43:44.22545Z","shell.execute_reply":"2021-06-28T08:43:44.237099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot normalized confusion matrix\nplot_confusion_matrix(test_true, test_pred, classes=emotion_labels, normalize=True, title='Normalized confusion matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:44:34.470485Z","iopub.execute_input":"2021-06-28T08:44:34.47078Z","iopub.status.idle":"2021-06-28T08:44:35.031137Z","shell.execute_reply.started":"2021-06-28T08:44:34.470722Z","shell.execute_reply":"2021-06-28T08:44:35.030178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = Sequential()\n\n#module 1\nmodel2.add(Conv2D(2*2*num_features, kernel_size=(3, 3), input_shape=(width, height, 1), data_format='channels_last'))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(Conv2D(2*2*num_features, kernel_size=(3, 3), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n#module 2\nmodel2.add(Conv2D(2*num_features, kernel_size=(3, 3), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(DepthwiseConv2D(kernel_size=(3, 3), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(Conv2D(2*num_features, kernel_size=(2, 2), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n#module 3\nmodel2.add(Conv2D(num_features, kernel_size=(3, 3), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(DepthwiseConv2D(kernel_size=(3, 3), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(Conv2D(num_features, kernel_size=(2, 2), padding='same'))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n#flatten\nmodel2.add(Flatten())\n\n#dense 1\nmodel2.add(Dense(2*2*2*num_features))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\n\n#dense 2\nmodel2.add(Dense(2*2*num_features))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\n\n#dense 3\nmodel2.add(Dense(2*num_features))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation('relu'))\n\n#output layer\nmodel2.add(Dense(num_classes, activation='softmax'))\n\nmodel2.compile(loss='categorical_crossentropy', \n              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7), \n              metrics=['accuracy'])\n\nmodel2.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:55:54.591666Z","iopub.execute_input":"2021-06-28T08:55:54.591986Z","iopub.status.idle":"2021-06-28T08:55:55.580943Z","shell.execute_reply.started":"2021-06-28T08:55:54.591932Z","shell.execute_reply":"2021-06-28T08:55:55.57949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history2 = model2.fit_generator(data_generator.flow(train_X, train_Y, batch_size),\n                                steps_per_epoch=len(train_X) / batch_size,\n                                epochs=num_epochs,\n                                verbose=2, \n                                callbacks = [es],\n                                validation_data=(val_X, val_Y))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:56:02.217003Z","iopub.execute_input":"2021-06-28T08:56:02.217333Z","iopub.status.idle":"2021-06-28T09:16:15.081926Z","shell.execute_reply.started":"2021-06-28T08:56:02.217254Z","shell.execute_reply":"2021-06-28T09:16:15.081175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.save_weights(\"./modelumair222.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-06-28T09:25:06.664278Z","iopub.execute_input":"2021-06-28T09:25:06.664973Z","iopub.status.idle":"2021-06-28T09:25:06.785465Z","shell.execute_reply.started":"2021-06-28T09:25:06.664916Z","shell.execute_reply":"2021-06-28T09:25:06.784388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_true = np.argmax(test_Y, axis=1)\ntest_pred = np.argmax(model2.predict(test_X), axis=1)\nprint(\"Model Accuracy on test set: {:.4f}\".format(accuracy_score(test_true, test_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(18, 6))\n# Plot training & validation accuracy values\naxes[0].plot(history2.history['acc'])\naxes[0].plot(history2.history['val_acc'])\naxes[0].set_title('Model accuracy')\naxes[0].set_ylabel('Accuracy')\naxes[0].set_xlabel('Epoch')\naxes[0].legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\naxes[1].plot(history2.history['loss'])\naxes[1].plot(history2.history['val_loss'])\naxes[1].set_title('Model loss')\naxes[1].set_ylabel('Loss')\naxes[1].set_xlabel('Epoch')\naxes[1].legend(['Train', 'Validation'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T09:25:31.283221Z","iopub.execute_input":"2021-06-28T09:25:31.28358Z","iopub.status.idle":"2021-06-28T09:25:32.306416Z","shell.execute_reply.started":"2021-06-28T09:25:31.283526Z","shell.execute_reply":"2021-06-28T09:25:32.305467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model3 = Sequential()\n\n#module 1\nmodel3.add(Conv2D(2*2*num_features,kernel_size=(3, 3), input_shape=(width, height, 1), data_format='channels_last'))\nmodel3.add(BatchNormalization())\nmodel3.add(Activation('relu'))\nmodel3.add(Conv2D(2*2*num_features, kernel_size=(3, 3), padding='same'))\nmodel3.add(BatchNormalization())\nmodel3.add(Activation('relu'))\nmodel3.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n#module 2\nmodel3.add(DepthwiseConv2D(kernel_size=(3, 3), padding='same'))\nmodel3.add(BatchNormalization())\nmodel3.add(Activation('relu'))\nmodel3.add(Conv2D(6*num_features, kernel_size=(2, 2), padding='same'))\nmodel3.add(BatchNormalization())\nmodel3.add(Activation('relu'))\nmodel3.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n#module 3\nmodel3.add(DepthwiseConv2D(kernel_size=(3, 3), padding='same'))\nmodel3.add(BatchNormalization())\nmodel3.add(Activation('relu'))\nmodel3.add(Conv2D(3*num_features, kernel_size=(2, 2), padding='same'))\nmodel3.add(BatchNormalization())\nmodel3.add(Activation('relu'))\nmodel3.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n#flatten\nmodel3.add(Flatten())\n\n#dense 1\nmodel3.add(Dense(2*2*2*num_features))\nmodel3.add(BatchNormalization())\nmodel3.add(Activation('relu'))\n\n#dense 2\nmodel3.add(Dense(2*2*num_features))\nmodel3.add(BatchNormalization())\nmodel3.add(Activation('relu'))\n\n#dense 3\nmodel3.add(Dense(2*num_features))\nmodel3.add(BatchNormalization())\nmodel3.add(Activation('relu'))\n\n#output layer\nmodel3.add(Dense(num_classes, activation='softmax'))\n\nmodel3.compile(loss='categorical_crossentropy', \n              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7), \n              metrics=['accuracy'])\n\nmodel3.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T09:53:04.361395Z","iopub.execute_input":"2021-06-28T09:53:04.361694Z","iopub.status.idle":"2021-06-28T09:53:05.231687Z","shell.execute_reply.started":"2021-06-28T09:53:04.361645Z","shell.execute_reply":"2021-06-28T09:53:05.228426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history3 = model3.fit_generator(data_generator.flow(train_X, train_Y, batch_size),\n                                steps_per_epoch=len(train_X) / batch_size,\n                                epochs=num_epochs,\n                                verbose=2, \n                                callbacks = [es],\n                                validation_data=(val_X, val_Y))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T09:53:12.659656Z","iopub.execute_input":"2021-06-28T09:53:12.659962Z","iopub.status.idle":"2021-06-28T10:10:13.857798Z","shell.execute_reply.started":"2021-06-28T09:53:12.659907Z","shell.execute_reply":"2021-06-28T10:10:13.856893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model3.save_weights(\"./modelumair333new.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:12:26.306797Z","iopub.execute_input":"2021-06-28T10:12:26.307262Z","iopub.status.idle":"2021-06-28T10:12:26.449916Z","shell.execute_reply.started":"2021-06-28T10:12:26.307219Z","shell.execute_reply":"2021-06-28T10:12:26.448198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(18, 6))\n# Plot training & validation accuracy values\naxes[0].plot(history3.history['acc'])\naxes[0].plot(history3.history['val_acc'])\naxes[0].set_title('Model accuracy')\naxes[0].set_ylabel('Accuracy')\naxes[0].set_xlabel('Epoch')\naxes[0].legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\naxes[1].plot(history3.history['loss'])\naxes[1].plot(history3.history['val_loss'])\naxes[1].set_title('Model loss')\naxes[1].set_ylabel('Loss')\naxes[1].set_xlabel('Epoch')\naxes[1].legend(['Train', 'Validation'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:10:17.700783Z","iopub.execute_input":"2021-06-28T10:10:17.701329Z","iopub.status.idle":"2021-06-28T10:10:18.360653Z","shell.execute_reply.started":"2021-06-28T10:10:17.701252Z","shell.execute_reply":"2021-06-28T10:10:18.359859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_true = np.argmax(test_Y, axis=1)\ntest_pred = np.argmax(model3.predict(test_X), axis=1)\nprint(\"Model Accuracy on test set: {:.4f}\".format(accuracy_score(test_true, test_pred)))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T10:10:18.365062Z","iopub.execute_input":"2021-06-28T10:10:18.367404Z","iopub.status.idle":"2021-06-28T10:10:20.779173Z","shell.execute_reply.started":"2021-06-28T10:10:18.367345Z","shell.execute_reply":"2021-06-28T10:10:20.778237Z"},"trusted":true},"execution_count":null,"outputs":[]}]}