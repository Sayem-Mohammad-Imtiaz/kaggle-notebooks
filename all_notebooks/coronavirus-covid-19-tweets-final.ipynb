{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1>Coronavirus COVID-19 Tweets</h1>\n\n\n<img src=\"https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F769452%2F35db2dd68238bfd958efdabebc9fef8f%2Fcovid-19-4961257_1280-e1586986896105.jpg?generation=1595760042647275&alt=media\" width=\"600\"></img>\n\n\n# Introduction\n\n\nThe Dataset we are using here is collected using Twitter API, **tweepy** and Python package.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Data preparation\n\n## Load packages","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install numpy\n!pip install scipy\n!pip install matplotlib\n!pip install pandas\n!pip install wordcloud\n!pip install seaborn\n!pip install sklearn\n!pip install plotly","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib\nimport seaborn as sns\nimport plotly\nimport matplotlib.pyplot as plt\n%matplotlib inline \nfrom wordcloud import WordCloud, STOPWORDS\npd.options.mode.chained_assignment = None ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load data","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"tweets_df = pd.read_csv(\"../input/covid19-tweets/covid19_tweets.csv\")\ncovid_confirmed_cases = pd.read_csv(\"../input/covid-cases/time_series_covid19_confirmed_global.csv\")\ncovid_deaths = pd.read_csv(\"../input/covid-cases/time_series_covid19_deaths_global.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data exploration\n\n\n## Glimpse the data","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(f\"data shape: {tweets_df.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tweets_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tweets_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tweets_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Missing data","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"missing_data(tweets_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Unique values","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def unique_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    uniques = []\n    for col in data.columns:\n        unique = data[col].nunique()\n        uniques.append(unique)\n    tt['Uniques'] = uniques\n    return(np.transpose(tt))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"unique_values(tweets_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Most frequent values","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def most_frequent_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    items = []\n    vals = []\n    for col in data.columns:\n        itm = data[col].value_counts().index[0]\n        val = data[col].value_counts().values[0]\n        items.append(itm)\n        vals.append(val)\n    tt['Most frequent item'] = items\n    tt['Frequence'] = vals\n    tt['Percent from total'] = np.round(vals / total * 100, 3)\n    return(np.transpose(tt))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"most_frequent_values(tweets_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize the data distribution","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def plot_count(feature, title, df, size=1):\n    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n    total = float(len(df))\n    g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set3')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    if(size > 2):\n        plt.xticks(rotation=90, size=8)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(100*height/total),\n                ha=\"center\") \n    plt.show()    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### User name","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_count(\"user_name\", \"User name\", tweets_df,4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### User location","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_count(\"user_location\", \"User location\", tweets_df,4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tweet source","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_count(\"source\", \"Source\", tweets_df,4)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"stopwords = set(STOPWORDS)\n\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='white',\n        stopwords=stopwords,\n        max_words=50,\n        max_font_size=40, \n        scale=5,\n        random_state=1\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize=(10,10))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Text wordcloauds","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"show_wordcloud(tweets_df['text'], title = 'Prevalent words in tweets')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"india_df = tweets_df.loc[tweets_df.user_location==\"India\"]\nshow_wordcloud(india_df['text'], title = 'Prevalent words in tweets from India')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"us_df = tweets_df.loc[tweets_df.user_location==\"United States\"]\nshow_wordcloud(us_df['text'], title = 'Prevalent words in tweets from US')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_df = tweets_df.loc[tweets_df.user_location==\"United Kingdom\"]\nshow_wordcloud(us_df['text'], title = 'Prevalent words in tweets from UK')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_df = tweets_df.loc[tweets_df.user_location==\"Canada\"]\nshow_wordcloud(us_df['text'], title = 'Prevalent words in tweets from Canada')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"india_df = tweets_df.loc[tweets_df.user_location==\"South Africa\"]\nshow_wordcloud(india_df['text'], title = 'Prevalent words in tweets from South Africa')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"india_df = tweets_df.loc[tweets_df.user_location==\"Switzerland\"]\nshow_wordcloud(india_df['text'], title = 'Prevalent words in tweets from Switzerland')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_df = tweets_df.loc[tweets_df.user_location==\"London\"]\nshow_wordcloud(us_df['text'], title = 'Prevalent words in tweets from London')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hashtags analysis","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def plot_features_distribution(features, title, df, isLog=False):\n    plt.figure(figsize=(12,6))\n    plt.title(title)\n    for feature in features:\n        if(isLog):\n            sns.distplot(np.log1p(df[feature]),kde=True,hist=False, bins=120, label=feature)\n        else:\n            sns.distplot(df[feature],kde=True,hist=False, bins=120, label=feature)\n    plt.xlabel('')\n    plt.legend()\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"tweets_df['hashtags'] = tweets_df['hashtags'].replace(np.nan, \"['None']\", regex=True)\ntweets_df['hashtags'] = tweets_df['hashtags'].apply(lambda x: x.replace('\\\\N',''))\ntweets_df['hashtags_count'] = tweets_df['hashtags'].apply(lambda x: len(x.split(',')))\nplot_features_distribution(['hashtags_count'], 'Hashtags per tweet (all data)', tweets_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df['hashtags_individual'] = tweets_df['hashtags'].apply(lambda x: x.split(','))\nfrom itertools import chain\nall_hashtags = set(chain.from_iterable(list(tweets_df['hashtags_individual'])))\nprint(f\"There are totally: {len(all_hashtags)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_df = pd.read_csv(\"../input/country-code/datasets_403474_773844_wikipedia-iso-country-codes.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_df.columns = [\"country\", \"alpha2\", \"alpha3\", \"numeric\", \"iso\"]\ncountry_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df['country'] = tweets_df['user_location']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df = tweets_df.merge(country_df, on=\"country\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tw_add_df = tweets_df.groupby([\"country\", \"iso\", \"alpha3\"])['text'].count().reset_index()\ntw_add_df.columns = [\"country\", \"iso\", \"alpha3\", \"tweets\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\ndef plot_map(dd_df, title):\n    hover_text = []\n    for index, row in dd_df.iterrows():\n        hover_text.append((f\"country: {row['country']}<br>tweets: {row['tweets']}\\\n                          <br>country code: {row['iso']}<br>country alpha3: {row['alpha3']}\"))\n    dd_df['hover_text'] = hover_text\n\n    fig = px.choropleth(dd_df, \n                        locations=\"alpha3\",\n                        hover_name='hover_text',\n                        color=\"tweets\",\n                        projection=\"natural earth\",\n                        color_continuous_scale=px.colors.sequential.Plasma,\n                        width=900, height=700)\n    fig.update_geos(   \n        showcoastlines=True, coastlinecolor=\"DarkBlue\",\n        showland=True, landcolor=\"LightGrey\",\n        showocean=True, oceancolor=\"LightBlue\",\n        showlakes=True, lakecolor=\"Blue\",\n        showrivers=True, rivercolor=\"Blue\",\n        showcountries=True, countrycolor=\"DarkBlue\"\n    )\n    fig.update_layout(title = title, geo_scope=\"world\")\n    fig.show()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_map(tw_add_df, \"Tweets per country (where country is specified)\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df['datedt'] = pd.to_datetime(tweets_df['date'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_df['year'] = tweets_df['datedt'].dt.year\ntweets_df['month'] = tweets_df['datedt'].dt.month\ntweets_df['day'] = tweets_df['datedt'].dt.day\ntweets_df['dayofweek'] = tweets_df['datedt'].dt.dayofweek\ntweets_df['hour'] = tweets_df['datedt'].dt.hour\ntweets_df['minute'] = tweets_df['datedt'].dt.minute\ntweets_df['dayofyear'] = tweets_df['datedt'].dt.dayofyear\ntweets_df['date_only'] = tweets_df['datedt'].dt.date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_agg_df = tweets_df.groupby([\"date_only\"])[\"text\"].count().reset_index()\ntweets_agg_df.columns = [\"date_only\", \"count\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_time_variation(df, x='date_only', y='count', hue=None, size=1, title=\"\", is_log=False):\n    f, ax = plt.subplots(1,1, figsize=(4*size,3*size))\n    g = sns.lineplot(x=x, y=y, hue=hue, data=df)\n    plt.xticks(rotation=90)\n    if hue:\n        plt.title(f'{y} grouped by {hue} | {title}')\n    else:\n        plt.title(f'{y} | {title}')\n    if(is_log):\n        ax.set(yscale=\"log\")\n    ax.grid(color='black', linestyle='dotted', linewidth=0.75)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_time_variation(tweets_agg_df, title=\"Number of tweets / day of year\",size=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sanitization/Re-formatting of Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rename state columns\ncovid_deaths = covid_deaths.rename(columns={\"Province/State\":\"state\",\"Country/Region\": \"country\"})\ncovid_confirmed_cases = covid_confirmed_cases.rename(columns={\"Province/State\":\"state\",\"Country/Region\": \"country\"})\n\n#Changing the conuntry names as required by pycountry_convert Lib\ncovid_deaths.loc[covid_deaths['country'] == \"US\", \"country\"] = 'USA'\ncovid_confirmed_cases.loc[covid_confirmed_cases['country'] == \"US\", \"country\"] = \"USA\"\n                          \ncovid_deaths.loc[covid_deaths['country'] == 'Korea, South', \"country\"] = 'South Korea'\ncovid_confirmed_cases.loc[covid_confirmed_cases['country'] == \"Korea, South\", \"country\"] = \"South Korea\"\n\ncovid_deaths.loc[covid_deaths['country'] == 'Taiwan', \"country\"] = 'Taiwan'\ncovid_confirmed_cases.loc[covid_confirmed_cases['country'] == \"Taiwan*\", \"country\"] = \"Taiwan\"\n  \ncovid_deaths.loc[covid_deaths['country'] == 'Congo (Kinshasa)', \"country\"] = 'Democratic Republic of the Congo'\ncovid_confirmed_cases.loc[covid_confirmed_cases['country'] == \"Congo (Kinshasa)\", \"country\"] = \"Democratic Republic of the Congo\"\n    \ncovid_deaths.loc[covid_deaths['country'] == \"Cote d'Ivoire\", \"country\"] = 'Côte d Ivoire'\ncovid_confirmed_cases.loc[covid_confirmed_cases['country'] == \"Cote d'Ivoire\", \"country\"] = \"Côte d'Ivoire\"\n\ncovid_deaths.loc[covid_deaths['country'] == \"Reunion\", \"country\"] = 'Réunion'\ncovid_confirmed_cases.loc[covid_confirmed_cases['country'] == \"Reunion\", \"country\"] = \"Réunion\"\n  \ncovid_deaths.loc[covid_deaths['country'] == 'Congo (Brazzaville)', \"country\"] = 'Republic of the Congo'\ncovid_confirmed_cases.loc[covid_confirmed_cases['country'] == \"Congo (Brazzaville)\", \"country\"] = \"Republic of the Congo\"\n  \ncovid_deaths.loc[covid_deaths['country'] == 'Bahamas, The', \"country\"] = 'Bahamas'\ncovid_confirmed_cases.loc[covid_confirmed_cases['country'] == \"Bahamas, The\", \"country\"] = \"Bahamas\"\n\ncovid_deaths.loc[covid_deaths['country'] == 'Gambia, The', \"country\"] = 'Gambia'\ncovid_confirmed_cases.loc[covid_confirmed_cases['country'] == \"Gambia, The\", \"country\"] = \"Gambia\"\n\n#Copy the death statistics (USA ONLY) to a new variable andstrip out the continent and latlng\ncovid_death_cases = covid_deaths.copy().drop([\"Lat\",\"Long\",\"state\"], axis=1)\ncovid_confirmed_cases = covid_confirmed_cases.copy().drop([\"Lat\",\"Long\",\"state\"], axis=1)\n\n#Set the index of the pandas dataframe\ncovid_death_cases = covid_death_cases.set_index([\"country\"])\ncovid_confirmed_cases = covid_confirmed_cases.set_index([\"country\"])\n\n#Convert column headers to date time\ncovid_death_cases.columns = pd.to_datetime(covid_death_cases.columns)\ncovid_confirmed_cases.columns = pd.to_datetime(covid_confirmed_cases.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trimmed_tweets = tweets_df.copy().drop([\n        \"user_name\",\n        \"user_description\",\n        \"user_created\",\n        \"user_followers\",\n        \"user_friends\",\n        \"user_favourites\",\n        \"user_verified\",\n        \"text\",\n        \"hashtags\",\n        \"source\",\n        \"is_retweet\",\n        \"hashtags_count\",\n        \"hashtags_individual\",\n    ], axis=1)\n\ndef user_in_usa(location):\n    import re\n    usa_list = [\"USA\",\"AL\", \"AK\", \"AZ\", \"AR\",\n                \"CA\", \"CO\", \"CT\", \"DE\", \"FL\",\n                \"GA\", \"HI\", \"ID\", \"IL\", \"IN\", \n                \"IA\", \"KS\", \"KY\", \"LA\", \"ME\",\n                \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \n                \"MO\", \"MT\", \"NE\", \"NV\", \"NH\",\n                \"NJ\", \"NM\", \"NY\", \"NC\", \"ND\", \n                \"OH\", \"OK\", \"OR\", \"PA\", \"RI\",\n                \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \n                \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n    location = str(location)\n    locations = location.replace('-', ' ').split(' ')\n\n    for location in locations:\n        if location in usa_list:\n            return True\n    return False\n\n#Filter USA only tweets\nusa_tweets = trimmed_tweets[trimmed_tweets.apply(lambda x: x['alpha2'] == \"US\", axis=1)]\n\n#Trim time away from date and convert to date format\nusa_tweets['date'] = usa_tweets.apply(lambda x: x['date'].split(\" \")[0], axis=1)\nusa_tweets['date'] = pd.to_datetime(usa_tweets['date'])\n\n#Daily tweet count\nusa_daily_counts = usa_tweets.groupby(usa_tweets['date'].dt.date).size()\n\n#convert the series to a dataframe\nusa_daily_counts = usa_daily_counts.to_frame()\nusa_daily_counts.index = pd.to_datetime(usa_daily_counts.index)\nusa_daily_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid_death_cases.head()\ncovid_confirmed_cases.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transpose the dataframe so that rows are columns and the columns are rows, order the dataframe by column name\nt_covid_death = covid_death_cases.T\nt_covid_death.sort_index(axis=1, inplace=True)\n\nt_covid_confirm = covid_confirmed_cases.T\nt_covid_confirm.sort_index(axis=1, inplace=True)\n\n# Resample the dataset and concatenate it so that data is aggregated weekly\nt_covid_death_weekly = t_covid_death.resample('D').sum()\nt_covid_confirmed_weekly = t_covid_confirm.resample('D').sum()\nusa_daily_counts = usa_daily_counts.resample('D').sum()\n\n#Isolate USA data\nw_usa_deaths = t_covid_death_weekly['USA']\nw_usa_confirmed = t_covid_confirmed_weekly['USA']\n\n#Join the deaths and confirmed cases into one df\nusa_data = pd.concat([w_usa_confirmed, w_usa_deaths, usa_daily_counts], axis=1, ignore_index=True)\n\n#Rename the columns for readability\nusa_data.columns = ['confirmed', 'deaths', 'tweets']\n\n#Fill NAN with 0\nusa_data = usa_data.fillna(0)\nusa_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_covid_death.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_data.plot.line(logy=True)\n\n#Last point in dataset is anomoly because dataset incomplete for that week\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_data_after_july = usa_data.loc[(usa_data.index > '2020-7-20')]\nusa_data_after_july","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"usa_data_after_july.plot.line(logy=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}