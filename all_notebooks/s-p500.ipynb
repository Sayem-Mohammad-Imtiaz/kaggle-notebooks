{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predicting the closing price stock price of S&P500:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndata = pd.read_csv(\"../input/sp500-20162021/SP500.csv\")\ndata = data[::-1] #invert data\ndata = data.reset_index()\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-07T08:37:19.804507Z","iopub.execute_input":"2021-09-07T08:37:19.804845Z","iopub.status.idle":"2021-09-07T08:37:20.588324Z","shell.execute_reply.started":"2021-09-07T08:37:19.804798Z","shell.execute_reply":"2021-09-07T08:37:20.5871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-07T08:37:20.590252Z","iopub.execute_input":"2021-09-07T08:37:20.590562Z","iopub.status.idle":"2021-09-07T08:37:20.602517Z","shell.execute_reply.started":"2021-09-07T08:37:20.59048Z","shell.execute_reply":"2021-09-07T08:37:20.601697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(16,6))\nplt.title('Close Price History')\nplt.plot(data['Close'])\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price TWD ($)', fontsize=18)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-07T08:37:20.604917Z","iopub.execute_input":"2021-09-07T08:37:20.60558Z","iopub.status.idle":"2021-09-07T08:37:20.934818Z","shell.execute_reply.started":"2021-09-07T08:37:20.60533Z","shell.execute_reply":"2021-09-07T08:37:20.933431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre_days = 60 # length of predicting days \n# Create a new dataframe with only the 'Close column \ndata = data.filter(['Close'])\n# Convert the dataframe to a numpy array\ndataset = data.values\n# Get the number of rows to train the model on\ntraining_data_len = int(len(dataset)*.7)\nvalidation_data_len = int(len(dataset)*0.2)\ntesting_data_len = len(dataset) - training_data_len - validation_data_len\n\nprint(\"The number of trainning dataset: \", training_data_len)\nprint(\"The number of validation dataset: \", validation_data_len)\nprint(\"The number of testing dataset: \", testing_data_len)","metadata":{"execution":{"iopub.status.busy":"2021-09-07T08:37:20.936808Z","iopub.execute_input":"2021-09-07T08:37:20.937398Z","iopub.status.idle":"2021-09-07T08:37:20.952175Z","shell.execute_reply.started":"2021-09-07T08:37:20.937148Z","shell.execute_reply":"2021-09-07T08:37:20.951116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n# Create the training data set \n# Create the scaled training data set\ntrain_data = dataset[0:training_data_len, :]\n# Split the data into x_train and y_train data sets\nx_train = []\ny_train = []\n\nfor i in range(pre_days, len(train_data)):\n    x_train.append(train_data[i-pre_days:i, 0])\n    y_train.append(train_data[i, 0])\n#    if i<= 61:\n#        print(x_train)\n#        print(y_train)\n#        print()\n        \n# Convert the x_train and y_train to numpy arrays \nx_train, y_train = np.array(x_train), np.array(y_train)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-07T08:37:20.954866Z","iopub.execute_input":"2021-09-07T08:37:20.95524Z","iopub.status.idle":"2021-09-07T08:37:20.963829Z","shell.execute_reply.started":"2021-09-07T08:37:20.955201Z","shell.execute_reply":"2021-09-07T08:37:20.963083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scale the data\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler_x = MinMaxScaler(feature_range=(0,1))\ninput_sc = scaler_x.fit(x_train)\nx_train_norm = input_sc.transform(x_train)\n\ny_train = np.reshape(y_train,(y_train.shape[0], 1))\nscaler_y = MinMaxScaler(feature_range=(0,1))\noutput_sc = scaler_y.fit(y_train)\ny_train_norm = output_sc.transform(y_train)\n\n# Reshape the data\nx_train_norm = np.reshape(x_train_norm, (x_train_norm.shape[0], x_train_norm.shape[1], 1))\nprint(\"The shape of input data: \", x_train_norm.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-07T08:37:20.965138Z","iopub.execute_input":"2021-09-07T08:37:20.965542Z","iopub.status.idle":"2021-09-07T08:37:23.320678Z","shell.execute_reply.started":"2021-09-07T08:37:20.965473Z","shell.execute_reply":"2021-09-07T08:37:23.31981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the validation data set \n# Create the scaled validation data set\nval_data = dataset[training_data_len - pre_days: training_data_len + validation_data_len, :]\n# Split the data into x_val and y_val data sets\nx_val = []\ny_val = []\n\nfor i in range(pre_days, len(val_data)):\n    x_val.append(val_data[i-pre_days:i, 0])\n    y_val.append(val_data[i, 0])\n#    if i<= 61:\n#        print(x_train)\n#        print(y_train)\n#        print()\n        \n# Convert the x_train and y_train to numpy arrays \nx_val, y_val = np.array(x_val), np.array(y_val)","metadata":{"execution":{"iopub.status.busy":"2021-09-07T08:37:23.323535Z","iopub.execute_input":"2021-09-07T08:37:23.323961Z","iopub.status.idle":"2021-09-07T08:37:23.332465Z","shell.execute_reply.started":"2021-09-07T08:37:23.323896Z","shell.execute_reply":"2021-09-07T08:37:23.331143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_val_norm = input_sc.transform(x_val)\ny_val = np.reshape(y_val, (y_val.shape[0], 1))\ny_val_norm = output_sc.transform(y_val)\n\n# Reshape the data\nx_val_norm = np.reshape(x_val_norm, (x_val_norm.shape[0], x_val_norm.shape[1], 1))\nprint(\"The shape of validation data: \", x_val_norm.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-07T08:37:23.334085Z","iopub.execute_input":"2021-09-07T08:37:23.334351Z","iopub.status.idle":"2021-09-07T08:37:23.348022Z","shell.execute_reply.started":"2021-09-07T08:37:23.334306Z","shell.execute_reply":"2021-09-07T08:37:23.346853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test 資料集處理， label處理\n# Create the testing data set \n# Create the scaled testing data set\ntest_data = dataset[training_data_len + validation_data_len - pre_days:, :]\n# Split the data into x_test and y_test data sets\nx_test = []\ny_test = []\n\nfor i in range(pre_days, len(test_data)):\n    x_test.append(test_data[i-pre_days:i, 0])\n    y_test.append(test_data[i, 0])\n#    if i<= 61:\n#        print(x_train)\n#        print(y_train)\n#        print()\n        \n# Convert the x_train and y_train to numpy arrays \nx_test, y_test = np.array(x_test), np.array(y_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-07T08:37:23.349487Z","iopub.execute_input":"2021-09-07T08:37:23.349882Z","iopub.status.idle":"2021-09-07T08:37:23.36378Z","shell.execute_reply.started":"2021-09-07T08:37:23.349782Z","shell.execute_reply":"2021-09-07T08:37:23.362783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test_norm = input_sc.transform(x_test)\ny_test = np.reshape(y_test, (y_test.shape[0],1))\ny_test_norm = output_sc.transform(y_test)\n\n\n# Reshape the data\nx_test_norm = np.reshape(x_test_norm, (x_test_norm.shape[0], x_test_norm.shape[1], 1))\nprint(\"The shape of testing data: \", x_test_norm.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-07T08:37:23.365409Z","iopub.execute_input":"2021-09-07T08:37:23.3658Z","iopub.status.idle":"2021-09-07T08:37:23.379737Z","shell.execute_reply.started":"2021-09-07T08:37:23.365736Z","shell.execute_reply":"2021-09-07T08:37:23.37834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM\n\n# Build the LSTM model\nmodel = Sequential()\nmodel.add(LSTM(128, return_sequences=True, input_shape= (x_train.shape[1], 1)))\nmodel.add(LSTM(64, return_sequences=False))\nmodel.add(Dense(25))\nmodel.add(Dense(1))\n\nmodel.summary()\nprint(\"\\n\")\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Train the model\nmodel.fit(x_train_norm, y_train_norm, batch_size = 16, epochs = 20, validation_data = (x_val_norm, y_val_norm))","metadata":{"execution":{"iopub.status.busy":"2021-09-07T08:37:23.381437Z","iopub.execute_input":"2021-09-07T08:37:23.381772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the models predicted price values \npredictions_train = model.predict(x_train_norm)\npredictions_train = output_sc.inverse_transform(predictions_train)\n\n# Get the root mean squared error (RMSE)\nrmse = np.sqrt(np.mean(((predictions_train - y_train) ** 2)))\nprint(\"root mean squred error of trainning data: \", rmse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the models predicted price values \npredictions_val = model.predict(x_val_norm)\npredictions_val = output_sc.inverse_transform(predictions_val)\n\n# Get the root mean squared error (RMSE)\nrmse = np.sqrt(np.mean(((predictions_val - y_val) ** 2)))\nprint(\"root mean squred error of validation data: \", rmse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the models predicted price values \npredictions_test = model.predict(x_test_norm)\npredictions_test = output_sc.inverse_transform(predictions_test)\n\n# Get the root mean squared error (RMSE)\nrmse = np.sqrt(np.mean(((predictions_test - y_test) ** 2)))\nprint(\"root mean squred error of testing data: \", rmse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the data\ntrain = data[:training_data_len]\nvalid = data[training_data_len: training_data_len+validation_data_len]\ntest = data[training_data_len+validation_data_len:]\nvalid['Predictions'] = predictions_val\ntest['Predictions'] = predictions_test\n\n# Visualize the data\nplt.figure(figsize=(16,6))\nplt.title('Close Price ML Predicton of S&P500')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price USD ($)', fontsize=18)\nplt.plot(train['Close'])\nplt.plot(valid[['Close', 'Predictions']])\nplt.plot(test[['Close', 'Predictions']])\nplt.legend(['Train', 'Val', 'val_predication', 'test_prediction'], loc='lower right')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}