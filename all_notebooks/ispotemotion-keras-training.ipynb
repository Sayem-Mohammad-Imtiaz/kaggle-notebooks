{"cells":[{"metadata":{"collapsed":true,"pycharm":{"is_executing":false,"name":"#%% md\n"}},"cell_type":"markdown","source":"# Machine learning using keras \n- Recognize expressions from people's face\n- Input pixels: 48*48, black and white pictures\n- Output: Angry, Fear, Happy, Sad, Surprise, Neutral\n"},{"metadata":{"pycharm":{"name":"#%% \n","is_executing":false},"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport keras\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom keras import models\nfrom tensorflow.keras import layers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Declare variables"},{"metadata":{"pycharm":{"name":"#%%\n","is_executing":false},"trusted":true},"cell_type":"code","source":"num_expressions = 6\nimg_size = 48\nepochs = 50\nbatch_size = 64\nnum_features = 64\ndata = pd.read_csv('../input/facial-expression/fer2013.csv')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Presenting data\nView data structure"},{"metadata":{"pycharm":{"name":"#%%\n","is_executing":false},"trusted":true},"cell_type":"code","source":"print(data.head(10))\nprint(data.shape)\nprint(data.Usage.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# get rid of disgust"},{"metadata":{"pycharm":{"name":"#%%\n","is_executing":false},"trusted":true},"cell_type":"code","source":"def add_one(x):\n    if x>1:\n        x=x-1\n    return x\n\ndata = data[data['emotion']!=1]\ndata['emotion'] = data['emotion'].apply(add_one)\n\nprint(data.head(10))","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"Check emotions data"},{"metadata":{"pycharm":{"name":"#%% \n","is_executing":false},"trusted":true},"cell_type":"code","source":"emotion_map = {0: 'Angry', 1: 'Fear', 2: 'Happy', 3: 'Sad', 4: 'Surprise', 5: 'Neutral'}\nemotion_counts = data['emotion'].value_counts(sort=False).reset_index()\nemotion_counts.columns = ['emotion', 'number']\nemotion_counts['emotion'] = emotion_counts['emotion'].map(emotion_map)\nprint(emotion_counts)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"View sample picture"},{"metadata":{"pycharm":{"name":"#%%\n","is_executing":false},"trusted":true},"cell_type":"code","source":"def row2image(row):\n    pixels, emotion = row['pixels'], emotion_map[row['emotion']]\n    img = np.array(pixels.split())\n    img = img.reshape(img_size, img_size)\n    image = np.zeros((img_size, img_size, 3))\n    image[:, :, 0] = img\n    image[:, :, 1] = img\n    image[:, :, 2] = img\n    return np.array([image.astype(np.uint8), emotion])\n\n\n# show sample emotion expressions from dataset\ndef showFace(index):\n    plt.figure(0, figsize=(16, 10))\n    for i in range(1, 7):\n        face = data[data['emotion'] == i - 1].iloc[index]\n        img = row2image(face)\n        plt.subplot(2, 3, i)\n        plt.imshow(img[0])\n        plt.title(img[1])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n","is_executing":false},"trusted":true},"cell_type":"code","source":"showFace(19)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pre-processing data\nSplit data to training, validation and testing set"},{"metadata":{"pycharm":{"name":"#%%\n","is_executing":false},"trusted":true},"cell_type":"code","source":"data_train = data[data['Usage'] == 'Training'].copy()\ndata_val = data[data['Usage'] == 'PublicTest'].copy()\ndata_test = data[data['Usage'] == 'PrivateTest'].copy()\n\n# use all the data to train the final model\ndata_train = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"Normalize data"},{"metadata":{"pycharm":{"name":"#%%\n","is_executing":false},"trusted":true},"cell_type":"code","source":"def CRNO(df, name):\n    # convert pixels strings to integer lists\n    df['pixels'] = df['pixels'].apply(lambda pixel_sequence: [int(pixel) for pixel in pixel_sequence.split()])\n    # to image, reshape and normalize grayscale\n    x = np.array(df['pixels'].tolist()).reshape(-1, img_size, img_size, 1) / 255.0\n    y = keras.utils.to_categorical(df['emotion'], num_expressions)\n    print(name, \"_X shape: {}, \", name, \"_Y shape: {}\".format(x.shape, y.shape))\n    return x, y","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n","is_executing":false},"trusted":true},"cell_type":"code","source":"train_X, train_Y = CRNO(data_train, \"train\")  # training data\nval_X, val_Y = CRNO(data_val, \"val\")  # validation data\ntest_X, test_Y = CRNO(data_test, \"test\")  # test data","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"# Make a model"},{"metadata":{"pycharm":{"name":"#%%\n","is_executing":false},"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(img_size, img_size, 1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Dense(num_expressions))\n\n# model.summary()\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"# Training"},{"metadata":{"pycharm":{"name":"#%%\n","is_executing":false},"trusted":true},"cell_type":"code","source":"# data generator\ndata_generator = keras.preprocessing.image.ImageDataGenerator(\n                        featurewise_center=False,\n                        featurewise_std_normalization=False,\n                        rotation_range=10,\n                        width_shift_range=0.1,\n                        height_shift_range=0.1,\n                        zoom_range=.1,\n                        horizontal_flip=True)\n\nes = keras.callbacks.ModelCheckpoint('/kaggle/working/my_model', monitor='val_loss', savebest_only=True)\n\nhistory = model.fit(data_generator.flow(train_X, train_Y, 128), batch_size=128, epochs=200, shuffle=True, callbacks = [es], validation_data=(val_X, val_Y)) \n# history = model.fit(train_X, train_Y, epochs=50, batch_size=128, validation_data=(val_X, val_Y), callbacks = [es], shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"# Testing"},{"metadata":{"pycharm":{"name":"#%% \n","is_executing":false},"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.4, 0.7])\nplt.legend(loc='lower right')\n\ntest_loss, test_acc = model.evaluate(test_X,  test_Y, verbose=2)\nprint(test_acc)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save model"},{"metadata":{"pycharm":{"name":"#%% \n","is_executing":false},"trusted":true},"cell_type":"code","source":"model.save('saved_model/my_model')  ","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n","is_executing":false},"trusted":true},"cell_type":"code","source":"new_model = tf.keras.models.load_model('saved_model/my_model')\nnew_model.summary()\n\ntest_loss, test_acc = new_model.evaluate(test_X,  test_Y, verbose=2)\nprint(test_acc)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}