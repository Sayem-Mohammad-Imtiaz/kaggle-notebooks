{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install pyspark","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark.sql import SparkSession\n\nspark = SparkSession\\\n        .builder\\\n        .appName(\"Python Spark regression example\")\\\n        .config(\"spark.some.config.option\", \"random\")\\\n        .getOrCreate()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = spark.read.format(\"csv\").\\\n    options(inferSchema = True, header = True).load(\"/kaggle/input/health-insurance-cross-sell-prediction/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.show(5, False)\n\ndf.printSchema()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Basic EDA using PySpark"},{"metadata":{},"cell_type":"markdown","source":"## Selecting few columns by their names"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.select(['Gender', 'Age', 'Policy_Sales_Channel']).show(5, False) # Method 1\n\ndf.select(df[\"Age\"], df[\"Gender\"], df[\"Policy_Sales_Channel\"]).show(10, False) # Method 2\n\nfrom pyspark.sql.functions import col # Method 3 - By import SQL function col\ndf.select(col(\"Age\"), col(\"Gender\"), col(\"Policy_Sales_Channel\")).show(5, False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating a subset of dataframe using Filter"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.filter(df[\"Age\"] > 30 ).filter(df[\"Age\"] < 45).show(5) # Selecting subset using chain of Filter of option\n\ndf.filter((df[\"Age\"] > 30) & (df[\"Age\"] < 45 )).show(5, False) # Selcting subset by using AND between the criteria","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Converting a spark DataFrame to Pandas DataFrame"},{"metadata":{"trusted":true},"cell_type":"code","source":"pandasDF = df.toPandas()\n\npandasDF.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Aggregation using Group By"},{"metadata":{"trusted":true},"cell_type":"code","source":"ageCount = df.groupBy([\"Age\", \"Response\"]).count().toPandas()\navgPremiumByAge = df.groupBy([\"Age\", \"Response\"]).avg(\"Annual_Premium\").withColumnRenamed(\"avg(Annual_Premium)\",\"Avg_Annual_Premium\").toPandas()\nmaxPremiumByAge = df.groupBy([\"Age\", \"Response\"]).max(\"Annual_Premium\").withColumnRenamed(\"max(Annual_Premium)\",\"Max_Annual_Premium\").toPandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfig, (ax1, ax2, ax3) = plt.subplots(nrows = 3, ncols = 1, sharex = False, figsize = (20, 24))\nsns.barplot(ageCount[\"Age\"], ageCount[\"count\"], hue = ageCount[\"Response\"], ax = ax1)\nax1.set_title(\"Count of People Surveyed by their Age and Response\", fontsize = 20)\nax1.set_xlabel(\"Age\",fontsize = 16); ax1.set_ylabel(\"Count\",fontsize = 16)\nsns.barplot(avgPremiumByAge[\"Age\"], avgPremiumByAge[\"Avg_Annual_Premium\"], hue = avgPremiumByAge[\"Response\"],ax = ax2)\nax2.set_xlabel(\"Age\",fontsize = 16); ax2.set_ylabel(\"Average Annual Premium\",fontsize = 16)\nax2.set_title(\"Average insurance premium by Age and Response\", fontsize = 20)\nsns.barplot(maxPremiumByAge[\"Age\"], maxPremiumByAge[\"Max_Annual_Premium\"],hue = maxPremiumByAge[\"Response\"],ax = ax3)\nax3.set_xlabel(\"Age\",fontsize = 16); ax3.set_ylabel(\"Maximum Annual Premium\",fontsize = 16)\nax3.set_title(\"Maximum insurance premium by Age and Response\", fontsize = 20)\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vehicleStats = df.groupBy([\"Vehicle_Age\", \"Response\"]).count().toPandas()\npremiumStats = df.groupBy([\"Vehicle_Damage\", \"Vehicle_Age\",\"Response\"]).avg(\"Annual_Premium\").withColumnRenamed(\"avg(Annual_Premium)\",\"Avg_Annual_Premium\").toPandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, sharex = False, figsize = (24, 8))\nsns.barplot(vehicleStats[\"Vehicle_Age\"], vehicleStats[\"count\"], hue = vehicleStats[\"Response\"], ax = ax1, ci = None)\nax1.set_title(\"Count of Respondents by Response and the Age of Vehicle owned\", fontsize = 20)\nax1.set_xlabel(\"Vehicle Age\",fontsize = 16); ax1.set_ylabel(\"Count\",fontsize = 16)\nsns.barplot(premiumStats[\"Vehicle_Age\"], premiumStats[\"Avg_Annual_Premium\"], hue = premiumStats[\"Vehicle_Damage\"],ax = ax2, ci = None)\nax2.set_xlabel(\"Vehicle Age\",fontsize = 16); ax2.set_ylabel(\"Average Annual Premium\",fontsize = 16)\nax2.set_title(\"Average insurance premiumby Age and Vehicle Condition\", fontsize = 20)\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using Bucketizer to bin the Age of Respondents"},{"metadata":{"trusted":true},"cell_type":"code","source":"splits= [0,10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n\nfrom pyspark.ml.feature import Bucketizer\n\nbucketizer = Bucketizer(splits=splits, inputCol=\"features\", outputCol=\"bucketedFeatures\")\n\nbucketizer = Bucketizer(splits = splits, inputCol = \"Age\", outputCol = \"ageBuckets\")\nbucketedData = bucketizer.transform(df)\n\nbucketedData.show(10, False)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ageBucketSummary = bucketedData.groupBy([\"ageBuckets\", \"Response\"]).count().toPandas()\nchannelSummary = df.groupBy([\"Policy_Sales_Channel\", \"Response\"]).count().toPandas()\nchannelSummary = channelSummary[channelSummary[\"count\"] >= 1000 ].sort_values(\"count\", ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing the count of Respondents against the Sales Channel and The Avergae Premium Quoted"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, sharex = False, figsize = (24, 8))\nsns.barplot(ageBucketSummary[\"ageBuckets\"], ageBucketSummary[\"count\"], hue = ageBucketSummary[\"Response\"], ax = ax1, ci = None)\nax1.set_title(\"Count of People Surveyed by Response and the Age of Vehicle owned\", fontsize = 20)\nax1.set_xlabel(\"Age of Respondents\",fontsize = 16); ax1.set_ylabel(\"Count\",fontsize = 16)\nsns.barplot(channelSummary[\"Policy_Sales_Channel\"], channelSummary[\"count\"], hue = channelSummary[\"Response\"],ax = ax2, ci = None)\nax2.set_xlabel(\"Policy Sales Channel\",fontsize = 16); ax2.set_ylabel(\"Average Annual Premium\",fontsize = 16)\nax2.set_title(\"Average insurance premium paid by Age and Response\", fontsize = 20)\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}