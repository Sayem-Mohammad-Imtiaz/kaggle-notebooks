{"cells":[{"metadata":{"_uuid":"ca25a2f95f0fc9498b9b2e3a9d96607fbb682015"},"cell_type":"markdown","source":"# broken-machine challange - quite challangeable"},{"metadata":{"_uuid":"2776978fa169449d5bf3c8f036668afe10a47502"},"cell_type":"markdown","source":"# Broken Machine dataset is used with following main steps:\n* Fill missing values with mode\n* Find correlation between features\n* Undersample data set as we've got 900,000 rows of data with almost 70%-30% distribution of labels\n* Use scaling (StandardScaler)\n* Do ramdomizedSearchCV to select initialized parameters\n* Plot learning curves over multiple iterations\n* Plot validation curves over multiple iterations\n"},{"metadata":{"_uuid":"cc4088625ae2209899d05c70dfd7bcb108cb4c3a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nimport time\nimport warnings\nwarnings.simplefilter(action = 'ignore', category = FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be294207f4e12ccf54d922814789b27998577dca","trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, precision_score, recall_score, roc_curve, f1_score, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42960cc0257a40fee0876294c6956e0aeba23023","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nfrom joblib import dump, load\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##EDA part"},{"metadata":{"_uuid":"c7b1f6a694e8c78d4edff34f27514ceb06f0eb8d","trusted":true},"cell_type":"code","source":"file_path = '../input/the-broken-machine/'\nmodel_path = '../input/the-broken-machine/'\n# file_path = './the-broken-machine/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain = pd.read_csv(file_path + 'xtrain.csv')\nytrain = pd.read_csv(file_path + 'ytrain.csv')\nprint(xtrain.shape)\nprint(ytrain.shape)\nxtrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ytrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ytrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"1 ratio isï¼š\",ytrain[ytrain==1].count()/len(ytrain)*100)\n#Then the accuracy is less than 70% is meaningless","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.value_counts(ytrain.values.flatten())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y train percentage 1 %\npd.value_counts(ytrain.values.flatten())[1]/(pd.value_counts(ytrain.values.flatten())[0]+pd.value_counts(ytrain.values.flatten())[1])*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check data\npd.set_option('display.max_columns', None)\nxtrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Check missing data\nall_data_na = (xtrain.isnull().sum() / len(xtrain)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nf, ax = plt.subplots(figsize=(8, 6))\nplt.xticks(rotation='90')\nsns.barplot(x=all_data_na.index, y=all_data_na)\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of missing values', fontsize=15)\nplt.title('Percent missing data by feature', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#EDA NA processing,lgb doesn't need na processing\nfor col in xtrain.columns:\n    xtrain[col] = xtrain[col].fillna(xtrain[col].mode()[0])#mode\nxtrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# EDA skew\nxtrain.skew(axis=0).sort_values(ascending=False)\n#Found 37 numerical anomalies","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain['37'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain['37']=xtrain['37'].apply(lambda x:200 if x>100 else x) #Handling No. 37","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#EDA No. 37\nfrom scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\ndef check_skewness(col):\n    sns.distplot(xtrain[col] , fit=norm);\n    fig = plt.figure()\n#     res = stats.probplot(xtrain[col], plot=plt) #Probplot cannot be displayed, if it is an integer index, it can be displayed\n    # Get the fitted parameters used by the function\n    (mu, sigma) = norm.fit(xtrain[col])\n    print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n    \ncheck_skewness(['37']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check unique value\nfor i in xtrain.columns:\n    print(i,\": \",len(xtrain[i].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature distribution\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nh = .2  # step size in the mesh\n\nx_min, x_max = xtrain.iloc[0:1000, 33].min() - .5, xtrain.iloc[0:1000, 33].max() + .5\ny_min, y_max = xtrain.iloc[0:1000, 36].min() - .5, xtrain.iloc[0:1000, 36].max() + .5\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n# just plot the dataset first\ncm = plt.cm.RdBu\ncm_bright = ListedColormap(['#FF0000', '#0000FF'])\nax = plt.subplot()\nax.scatter(xtrain.iloc[0:1000, 33], xtrain.iloc[0:1000, 36], c=list(ytrain.iloc[0:1000,0]),cmap=cm_bright,\n           edgecolors='k')\nax.set_xlim(xx.min(), xx.max())\nax.set_ylim(yy.min(), yy.max())\nax.set_xticks(())\nax.set_yticks(())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain['1'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#corelation\ncorrmat = xtrain.corr()\ncorrmat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat[corrmat>0.01].count()\n#No clear corelation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.figure(figsize=(10,10))\n# g = sns.heatmap(train_data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n\n# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.check_cv.html#sklearn.model_selection.check_cv\n# from sklearn.model_selection import check_cv\n# cv = check_cv(3, xtrain, ytrain, classifier=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" No clear patten for the scattering"},{"metadata":{"trusted":true},"cell_type":"code","source":"xy = xtrain.join(ytrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sample = xy.sample(n=17000, random_state=42)\npd.value_counts(train_sample['x'].values.flatten())\nX = train_sample.iloc[:, :-1]\ny = train_sample.iloc[:,-1]\nfrom imblearn.under_sampling import NearMiss\nns=NearMiss()\nX_train_ns,y_train_ns=ns.fit_sample(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://towardsdatascience.com/feature-selection-with-pandas-e3690ad8504b\n#Using Pearson Correlation\nplt.figure(figsize=(50,50))\ncor = xy.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation with output variable\ncor_target = abs(cor[\"x\"])\n#Selecting highly correlated features\nrelevant_features = cor_target[cor_target>0.5]\nrelevant_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_ns.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.value_counts(y_train_ns.values.flatten())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training part"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score, train_test_split\nX_train, X_test, y_train, y_test=train_test_split(X_train_ns[0:-1000],y_train_ns[0:-1000], test_size=0.2, random_state=3)\n# gc.collect()  \nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nX_train_scaled = pd.DataFrame(ss.fit_transform(X_train), columns=X_train.columns)\nX_test_scaled = pd.DataFrame(ss.transform(X_test), columns=X_test.columns)\n# we have now fit and transform the data into a scaler for accurate reading and results.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_scaled","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Algos code start here"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import validation_curve\nfrom scipy.stats import randint\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix\n# !pip install pydotplus\n# import pydotplus\nfrom IPython.display import Image\nfrom sklearn.model_selection import learning_curve \nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"doing random search first step source: https://gist.github.com/otaviomguerra/51df7a4cff28f92de7105f12a0724115"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n\nparam_dist = {\"max_depth\": randint(1, 30),\n              \"max_features\": randint(1, 58),\n              \"min_samples_leaf\": randint(1, 58),\n              \"criterion\": [\"gini\"]}\ntree = DecisionTreeClassifier(random_state=0)\ntree_cv = RandomizedSearchCV(tree, param_dist, cv=3, n_jobs=-1)\ntree_cv.fit(X_train_scaled,y_train)\nprint(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\nprint(\"Best score is {}\".format(tree_cv.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nprediction = tree_cv.predict(X_test_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nprint(confusion_matrix(y_test, prediction))\nprint(classification_report(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Source:https://www.geeksforgeeks.org/using-learning-curves-ml/\n# Learning curve: iteration 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sizes=np.linspace(0.01, 1.0, 100)\ndef plot_learning_curve(estimator):\n    sizes, training_scores, testing_scores , fit_times, _= learning_curve(estimator, X_train_scaled, y_train, cv=10, scoring='accuracy', n_jobs=-1,return_times=True, train_sizes=train_sizes ) \n    # Mean and Standard Deviation of training scores \n    mean_training = np.mean(training_scores, axis=1) \n    Standard_Deviation_training = np.std(training_scores, axis=1) \n\n    # Mean and Standard Deviation of testing scores \n    mean_testing = np.mean(testing_scores, axis=1) \n    Standard_Deviation_testing = np.std(testing_scores, axis=1) \n    \n    fit_times_mean = np.mean(fit_times, axis=1)\n    fit_times_std = np.std(fit_times, axis=1)\n    \n    _, axes = plt.subplots(1, 2, figsize=(20, 5))\n\n    # dotted blue line is for training scores and green line is for cross-validation score \n    axes[0].plot(sizes, mean_training, '--', color=\"b\",  label=\"Training score\") \n    axes[0].plot(sizes, mean_testing, color=\"g\", label=\"Cross-validation score\") \n\n    # Drawing plot \n#     plt.title(\"LEARNING CURVE FOR MLP Classifier\") \n    axes[0].set_title(\"LEARNING CURVE FOR DT Classifier\")\n    axes[0].set_xlabel(\"Training Set Size\"), axes[0].set_ylabel(\"accuracy\"), axes[0].legend(loc=\"best\") \n    \n    axes[1].grid()\n#     axes[1].plot(fit_times_mean, mean_testing, 'o-')\n#     axes[1].set_xlabel(\"fit_times\")\n#     axes[1].set_ylabel(\"Score\")\n\n    axes[1].plot(sizes, fit_times_mean, 'o-')\n    axes[1].set_xlabel(\"Training Set Size\")\n    axes[1].set_ylabel(\"fit_times\")\n    axes[1].set_title(\"Performance of the model\")\n    \n    \n    return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nplot_learning_curve(tree_cv.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Trying validation curve for depth parameter source: https://datascience.stackexchange.com/questions/26918/validation-curve-unlike-sklearn-sample"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_validation_curve(param, param_range,estimator):\n#     param_range = np.arange(1, 41, 2)\n    train_scores, test_scores = validation_curve(estimator, X_train_scaled, y_train, param_name=param, cv=10, param_range=param_range,n_jobs=-1, scoring=\"accuracy\")\n\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.title(\"Validation Curve with DecisionTree\")\n    plt.xlabel(param)\n    plt.ylabel(\"Score\")\n    plt.ylim(0.0, 1.1)\n    plt.plot(param_range, train_scores_mean, label=\"Training score\",\n                 color=\"r\")\n    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n                 color=\"g\")\n\n    plt.legend(loc=\"best\")\n    param_range = np.arange(1, param_range.max(), 2)\n#     plt.xticks(param_range)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparam_range = np.arange(1, 50, 5)\nparam_name=\"max_depth\"\nplot_validation_curve(param_name,param_range,tree_cv.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Findings: 12 seems to be the best value of max_depth"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_cv.best_params_['max_depth'] = 12\ndt_iter1=DecisionTreeClassifier(random_state=0)\ndt_iter1.set_params(**tree_cv.best_params_)\nmodel = dt_iter1.fit(X_train_scaled, y_train)\nprediction = dt_iter1.predict(X_test_scaled)\nprint(confusion_matrix(y_test, prediction))\nprint(classification_report(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Iter 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nplot_learning_curve(dt_iter1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparam_range = np.arange(1, 58, 1)\nparam_name=\"max_features\"\nplot_validation_curve(param_name,param_range,dt_iter1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparams=dt_iter1.get_params()\nparams['max_features']=58\ndt_iter2=DecisionTreeClassifier(random_state=0)\ndt_iter2.set_params(**params)\nmodel = dt_iter2.fit(X_train_scaled, y_train)\nprediction = dt_iter2.predict(X_test_scaled)\nprint(confusion_matrix(y_test, prediction))\nprint(classification_report(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Iter 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nplot_learning_curve(dt_iter2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparam_range = np.arange(1, 40, 1)\nparam_name=\"min_samples_leaf\"\nplot_validation_curve(param_name,param_range,dt_iter2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparams=dt_iter2.get_params()\nparams['min_samples_leaf']=15\ndt_iter3=DecisionTreeClassifier(random_state=0)\ndt_iter3.set_params(**params)\nmodel = dt_iter3.fit(X_train_scaled, y_train)\nprediction = dt_iter3.predict(X_test_scaled)\nprint(confusion_matrix(y_test, prediction))\nprint(classification_report(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nplot_learning_curve(dt_iter3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Iteration 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparam_range = np.arange(0, 600, 50)\n\n# print(type(out1))\nparam_name=\"max_leaf_nodes\"\nplot_validation_curve(param_name,param_range,dt_iter3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparams=dt_iter3.get_params()\nparams['max_leaf_nodes']=10\ndt_iter4=DecisionTreeClassifier(random_state=0)\ndt_iter4.set_params(**params)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodel = dt_iter4.fit(X_train_scaled, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nprediction = dt_iter4.predict(X_test_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(confusion_matrix(y_test, prediction))\nprint(classification_report(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nplot_learning_curve(dt_iter4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Iter 5 Decision tree pruning\n\nsource: https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# dt2 = DecisionTreeClassifier(random_state=0)\npath = dt_iter4.cost_complexity_pruning_path(X_train_scaled, y_train)\nmodel = dt_iter4.fit(X_train_scaled, y_train)\nccp_alphas, impurities = path.ccp_alphas, path.impurities","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfig, ax = plt.subplots()\nax.plot(ccp_alphas[:-1], impurities[:-1], marker='o', drawstyle=\"steps-post\")\nax.set_xlabel(\"effective alpha\")\nax.set_ylabel(\"total impurity of leaves\")\nax.set_title(\"Total Impurity vs effective alpha for training set\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nclfs = []\nfor ccp_alpha in ccp_alphas:\n    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n    clf.fit(X_train_scaled, y_train)\n    clfs.append(clf)\nprint(\"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n      clfs[-1].tree_.node_count, ccp_alphas[-1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nclfs = clfs[:-1]\nccp_alphas = ccp_alphas[:-1]\n\nnode_counts = [clf.tree_.node_count for clf in clfs]\ndepth = [clf.tree_.max_depth for clf in clfs]\nfig, ax = plt.subplots(2, 1)\nax[0].plot(ccp_alphas, node_counts, marker='o', drawstyle=\"steps-post\")\nax[0].set_xlabel(\"alpha\")\nax[0].set_ylabel(\"number of nodes\")\nax[0].set_title(\"Number of nodes vs alpha\")\nax[1].plot(ccp_alphas, depth, marker='o', drawstyle=\"steps-post\")\nax[1].set_xlabel(\"alpha\")\nax[1].set_ylabel(\"depth of tree\")\nax[1].set_title(\"Depth vs alpha\")\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_scores = [clf.score(X_train_scaled, y_train) for clf in clfs]\ntest_scores = [clf.score(X_test_scaled, y_test) for clf in clfs]\n\nfig, ax = plt.subplots()\nax.set_xlabel(\"alpha\")\nax.set_ylabel(\"accuracy\")\nax.set_title(\"Accuracy vs alpha for training and testing sets\")\nax.plot(ccp_alphas, train_scores, marker='o', label=\"train\",\n        drawstyle=\"steps-post\")\nax.plot(ccp_alphas, test_scores, marker='o', label=\"test\",\n        drawstyle=\"steps-post\")\nax.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparams=dt_iter4.get_params()\nparams['ccp_alpha']=0.002\ndt_iter5=DecisionTreeClassifier(random_state=0)\ndt_iter5.set_params(**params)\nmodel = dt_iter5.fit(X_train_scaled, y_train)\nprediction = dt_iter5.predict(X_test_scaled)\nprint(confusion_matrix(y_test, prediction))\nprint(classification_report(y_test, prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_iter5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nplot_learning_curve(dt_iter5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}