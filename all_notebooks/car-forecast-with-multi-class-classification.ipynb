{"cells":[{"metadata":{"_uuid":"b3cd4d757d4a5a6c723e0b7f07f5b72b7e5d22b9"},"cell_type":"markdown","source":"# Car Forecast with Multi Class Classification\n## Araba-Oner \n\n**Problem:** I have 20 brand-name classes. we are trying to cluster them according to the answers that people give to 12 questions and return them to the most suitable car models.\n\n**Project:** 12 Soruda To recommend the closest car models to the user.\n\n**Goal:** To remove 5 clusters from the segment. In total you will have to predict over the average 400-600 models and suggest 10 Models that are best for you.\n\n### **This project was done by the DataRaccoons Team.**\n#### **DataRaccoons:** [Web](https://www.dataraccoons.com/) / [Kaggle](https://www.kaggle.com/dataraccoons)\n\n**August 2018 - DataRaccoons**\n\n**Real Time Web Site : [www.arabaoner.com](https://www.arabaoner.com/)**\n\n\n- **Dictionary For Columns:** \n    - araba-tur : Used/New\n    - airbag : Airbag İmportance Score(1-5)\n    - araba-yas : Car Age\n    - araba-performans : High Condition- High Fuel Consumption / Standart Condition - Standart Fuel Consumption\n    - araba-kullanım-tur : Long Time Use / Buy For Sell\n    - araba-km : mileage range of  car\n    - araba-yakıt : Fuel Type (Gasoline, Gas, Diesel)\n    - araba-segment : Car Segment, (A,B,C,D,E...)\n    - araba-parca : Robust and expensive parts / Low cost, poor quality parts \n    - arac-hitap : Car Use Type (Family, Yourself, Job, Whatever)\n    - butce : Car Budget\n    - konfor-skorlama : Car Comfort Score(1-5)\n    - araba-model : Car Models\n    - marka : Car Brands\n    - kume : Clusted Data"},{"metadata":{"_uuid":"9ba2ba3512ecd927e58d9585fa00316f06e5ea60"},"cell_type":"markdown","source":"# Introduction\n1. [Data Pre-Processing](#ch0)\n - [Cleaning](#ch1)\n - [Mapping](#ch2)\n - [Creating the DataSet for target value](#ch3)\n - [Min Max Scale](#ch4)\n - [PCA(Feature Selection)](#ch5)\n       - [Build PCA](#ch6)\n       - [PCA Model Scores](#ch7)\n2. [Data Visualization](#ch8)\n - [Feature, Brand Correlations](#ch9)\n - [Feature, Brand Graphs](#ch10)\n3. [Building Machine Learning Model](#ch11)\n4. [Network Analysis](#ch12)\n - [Features Network Analysis](#ch13)\n - [Brands Network Analysis](#ch14)\n5. [Clustering with hierarchical clustering](#ch15)\n - [Clustering Data](#ch16)\n - [Clustered Data Correlations](#ch17)"},{"metadata":{"_uuid":"fc94d2f97a0429ac12ced8e6585bae73db4113a9"},"cell_type":"markdown","source":"## 1- Data Pre-Processing\n<a id=\"ch0\"></a>\n\n**Pre-Processing is an important part of a model, if you can not make the right moves in this part, your model can not be built or stabilized**"},{"metadata":{"_uuid":"f53e851ea14309345b61cbce0a38b7a58f4fa839"},"cell_type":"markdown","source":"### Cleaning\n<a id=\"ch1\"></a>"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f94402e07357362112e3f049c43681150876f251"},"cell_type":"code","source":"#Import Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom scipy.cluster.hierarchy import dendrogram, linkage","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"af07283fe18d88e4708487c5d13d72dd9b6b3d5b"},"cell_type":"code","source":"#import Dataset\ndata = pd.read_csv('../input/dataset.csv')\ndata3 = data.loc[:,['kume']].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc6083596cc5de084f5b017a0e162047857590b7","collapsed":true},"cell_type":"code","source":"#rename columns and drop not importance axis\nnames = [\"araba-tur\",\"airbag\",\"araba-yas\",\"araba-performans\",\"araba-kullanım-tur\",\"araba-km\",\n         \"araba-yakıt\",\"araba-segment\",\"araba-parca\",\"arac-hitap\",\n         \"butce\",\"konfor-skorlama\",\"araba-model\",\"marka\",\"sahibinden-link\",\"arabam-link\",\"kume\"]\n\nnames2 = [\"araba-tur\",\"airbag\",\"araba-yas\",\"araba-performans\",\"araba-kullanım-tur\",\"araba-km\",\n         \"araba-yakıt\",\"araba-segment\",\"araba-parca\",\"arac-hitap\",\n         \"butce\",\"konfor-skorlama\",\"marka\",\"kume\"]\n\ndata = data.rename(columns=dict(zip(data.columns, names)))\n\ndata = data.drop(['sahibinden-link'], axis=1)\ndata = data.drop(['arabam-link'], axis=1)\ndata = data.drop(['araba-model'], axis=1)\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da67c8d7da45e2491574fa68e08f4e3b43189833"},"cell_type":"markdown","source":"### Mapping\n<a id=\"ch2\"></a>"},{"metadata":{"trusted":true,"_uuid":"55365580b88fde24eb66d253a6fe03689a0d8161","collapsed":true},"cell_type":"code","source":"#Creating Mapping Dictionaries\nmapping_tur = {\"2. El\":0, \"Sıfır\":1}\nmapping_yas = {\"0-1\":1, \"1-3\":2, \"3-5\":3, \"5-8\":4, \"8-10\":5, \"10-12\":6, \"12+\":7}\nmapping_performans = {\"Vasat Performans, Az Yakması\":0, \"Yüksek Performans, Çok Yakması\":1, \"Standart Performans, Az Yakması\":0}\nmapping_kullanım = {\"Uzun Süre Binme Odaklı\":0, \"Satıp Para Kazanma Odaklı\":1}\nmapping_km = {\"0-25.000\":1, \"0-25.002\":1, \"25.000-50.000\":2, \"50.000-100.000\":3, \"100.000-200.000\":4, \"200.000+\":5}\nmapping_yakıt = {\"LPG\":0, \"Dizel\":1, \"Benzinli\":2, \"Farketmez\":3}\nmapping_segment = {\"A Segmenti (Ekonomik Az Yakanlar, i10)\":0, \"B Segmenti (Hyundai Getz, Polo)\":1, \"C Segmenti (Honda Civic, Renault Fluence)\":2,\n                  \"D Segmenti (Mercedes C Serisi, VW Passat, Ford Mondeo)\":3, \"E Segmenti (BMW 5 serisi, Volvo s80)\":4, \"F Segmenti (Audi A8, BMW 7 serisi)\":5,\n                  \"G Segmenti (Porshce 911)\":6, \"J Segmenti (4x4 Jipler vs.)\":7, \"D Segmenti (Mercedes C Serisi, VW Passat)\":3}\nmapping_parca = {\"Sürekli Sorun Çıkarsın Ucuz Parçaları Olsun\":0, \"Parçalar Sağlam ve Pahalı Olsun, Az Sorun Çıkarsın.\":1, \"Arada Bir Sorun Çıkarsın, Ucuz Parçaları Olsun\":0}\nmapping_hitap = {\"Aile Aracı\":0, \"Ticari\":1, \"Şahıs Aracı\":2, \"Off Road\":3}\nmapping_butce = {\"0-15.000\":0, \"15.000-25.000\":1, \"25.000-35.000\":2, \"35.000-45.000\":3, \"45.000-55.000\":4, \"55.000-65.000\":5,\n                \"65.000-75.000\":6, \"75.000-85.000\":7, \"85.000-100.000\":8, \"100.000-200.000\":9, \"200.000+\":10}\nmapping_marka = {\"Alfa Romeo\":0, \"Audi\":1, \"Bmw\":2, \"Chevrolet\":3, \"Citroen\":4, \"Dacia\":5, \"Fiat\":6, \"Ford\":7, \"Honda\":8,\n                \"Hyundai\":9, \"Kia\":10, \"Mercedes\":11, \"Mitsubishi\":12, \"Nissan\":13, \"Opel\":14, \"Peugeot\":15, \"Porsche\":16,\n                \"Renault\":17, \"Toyota\":18, \"Volkswagen\":19, \"Volvo\":20, \"Skoda\":21, \"Mazda\":22, \"Mini\":23, \"Land Rover\":24,\n                \"Seat\":25}\n\n#Mapping on Data\ndata['araba-tur'] = data['araba-tur'].map(mapping_tur)\ndata['araba-yas'] = data['araba-yas'].map(mapping_yas)\ndata['araba-performans'] = data['araba-performans'].map(mapping_performans)\ndata['araba-kullanım-tur'] = data['araba-kullanım-tur'].map(mapping_kullanım)\ndata['araba-km'] = data['araba-km'].map(mapping_km)\ndata['butce'] = data['butce'].map(mapping_butce)\ndata['araba-yakıt'] = data['araba-yakıt'].map(mapping_yakıt)\ndata['araba-segment'] = data['araba-segment'].map(mapping_segment)\ndata['araba-parca'] = data['araba-parca'].map(mapping_parca)\ndata['arac-hitap'] = data['arac-hitap'].map(mapping_hitap)\ndata['marka'] = data['marka'].map(mapping_marka)\n\ndata8=data\ndata9=data\ndata11 = data['marka']\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8405430799513f0dbceb66808c8e86e8be31977"},"cell_type":"markdown","source":"### Creating Dataset for Target Value\n<a id=\"ch3\"></a>"},{"metadata":{"trusted":true,"_uuid":"7f62907fa2ac4671a6f412d5d157a40b07ea8306","collapsed":true},"cell_type":"code","source":"#I going to define some funcs for Clustering DataSet base on brand\n\ndef plotData(data, marka = None):\n    if marka != None: \n        data = data[(data.marka == mapping_marka[marka])]\n        print(\"Opinion of \", marka)\n    fig = plt.figure(figsize=(25,10))\n    \n    names = [\"araba-tur\",\"airbag\",\"araba-yas\",\"araba-performans\",\"araba-kullanım-tur\",\"araba-km\",\n         \"araba-yakıt\",\"araba-segment\",\"araba-parca\",\"arac-hitap\",\n         \"butce\",\"konfor-skorlama\",\"marka\",\"kume\"]\n    \n    for i in range(0,13):\n        p1 = fig.add_subplot(2,5,i-3)\n        data[names[i]].value_counts().plot(kind = 'pie', autopct='%.1f%%'); \n        plt.ylabel(\" \", fontsize = 15)\n        plt.title(Q[i-4])\n    plt.grid()\n    plt.savefig(marka)\n    plt.savefig(marka + \".pdf\")\n    \ndef getOpinion(data, marka = None):\n    if marka != None: \n        data = data[(data.marka == mapping_marka[marka])]\n    return [data[col].mean() for col in names2[0:]]\n\nopinions = dict()\nfor k in mapping_marka.keys():\n    opinions[k] = getOpinion(data, marka = k)\n\ndf = pd.DataFrame.from_dict(opinions)\ndf.rename(index = dict(zip(range(len(names2[0:])),names2[0:])),inplace=True)\ndf = df.reindex(columns=['Alfa Romeo', 'Audi', 'Bmw', 'Chevrolet', 'Citroen', 'Dacia', 'Fiat', 'Ford', 'Honda', 'Hyundai',\n                        'Kia', 'Mercedes', 'Mitsubishi', 'Nissan', 'Opel', 'Peugeot', 'Renault', 'Toyota',\n                        'Volkswagen', 'Volvo'])\ndf.T","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1cead7f0616d62f5ee6b277750a3bdd8cadf89e"},"cell_type":"markdown","source":"### MİN - MAX SCALE\n** I will now do the scale mechanism to better understand the properties of the cars in correlations between cars**\n<a id=\"ch4\"></a>"},{"metadata":{"trusted":true,"_uuid":"dd94383d82202e5a06f699f5a50c5585afb8b685","collapsed":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\ndata9 = data9.drop(['kume'], axis=1)\ndata9 = data9.drop(['marka'], axis=1)\n\nscaler = MinMaxScaler(feature_range = (0,1))\nscaler.fit(data9)\ndata9 = scaler.transform(data9)\ndata9 = pd.DataFrame(data9)\n\ndata9 = pd.concat([data9, data11], axis = 1)\n\nnames = [\"araba-tur\",\"airbag\",\"araba-yas\",\"araba-performans\",\"araba-kullanım-tur\",\"araba-km\",\n         \"araba-yakıt\",\"araba-segment\",\"araba-parca\",\"arac-hitap\",\n         \"butce\",\"konfor-skorlama\",\"marka\"]\n\ndata9 = data9.rename(columns=dict(zip(data9.columns, names)))\ndata9.head(8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f0e47e3f08ebbf50905a6686f9768e678bbacdb5"},"cell_type":"code","source":"names5 = [\"araba-tur\",\"airbag\",\"araba-yas\",\"araba-performans\",\"araba-kullanım-tur\",\"araba-km\",\n         \"araba-yakıt\",\"araba-segment\",\"araba-parca\",\"arac-hitap\",\n         \"butce\",\"konfor-skorlama\",\"marka\"]\n\nnames4 = [\"araba-tur\",\"airbag\",\"araba-yas\",\"araba-performans\",\"araba-kullanım-tur\",\"araba-km\",\n         \"araba-yakıt\",\"araba-segment\",\"araba-parca\",\"arac-hitap\",\n         \"butce\",\"konfor-skorlama\",\"marka\"]\n\ndef getOpinion2(data9, marka = None):\n    if marka != None: \n        data9 = data9[(data9.marka == mapping_marka[marka])]\n    return [data9[col].mean() for col in names5[0:]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a7780c5e60a032c16547ee0f7a9d4c0c6b5dc70","collapsed":true},"cell_type":"code","source":"opinions = dict()\nfor k in mapping_marka.keys():\n    opinions[k] = getOpinion2(data9, marka = k)\n\ndf2 = pd.DataFrame.from_dict(opinions)\ndf2.rename(index = dict(zip(range(len(names4[0:])),names4[0:])),inplace=True)\ndf2 = df2.reindex(columns=['Alfa Romeo', 'Audi', 'Bmw', 'Chevrolet', 'Citroen', 'Dacia', 'Fiat', 'Ford', 'Honda', 'Hyundai',\n                        'Kia', 'Mercedes', 'Mitsubishi', 'Nissan', 'Opel', 'Peugeot', 'Renault', 'Toyota',\n                        'Volkswagen', 'Volvo'])\nprint(\"\")\ndf2.T","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61e3c3193bd4d3a7cde67878e67598c9bf0dd79d"},"cell_type":"markdown","source":"## PCA (Feature Selection)\n<a id=\"ch5\"></a>\n**What is The PCA?**\n\n- Pca is a useful statistical technique used in recognition, classification, image compression fields. pca is a very effective method to reveal the necessary information on the front. to reduce the number of dimensions, and to compress the data by finding the general properties of the oversized data. The basic logic behind the PCA is to show a multidimensional data with fewer variables by catching the basic features of the verb. the point at which some properties will be lost due to size reduction; but it is intended that these lost characteristics contain little information about the population. usually face detection is used in image compression areas\n\n\n* #### **As you know, the way to get high accuracy goes through the right feature selection. So we will do feature selection with PCA at once and what will be the results?**"},{"metadata":{"_uuid":"10328d3b036d26207ef60466b25cb5faf261c614"},"cell_type":"markdown","source":"### Build PCA\n<a id=\"ch6\"></a>"},{"metadata":{"trusted":true,"_uuid":"defa7a63fc4feacd132fa59475fe35253abc0b93","collapsed":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nnames2 = [\"araba-tur\",\"airbag\",\"araba-yas\",\"araba-performans\",\"araba-kullanım-tur\",\"araba-km\",\n         \"araba-yakıt\",\"araba-segment\",\"araba-parca\",\"arac-hitap\",\n         \"butce\",\"konfor-skorlama\",\"marka\",\"kume\"]\n\ndf2 = data8\nx = df2.loc[:, names2].values\ny = df2.loc[:,['kume']].values\nx = StandardScaler().fit_transform(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"74918a69257b8bbee01af2e26507ab53aafc991a"},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=2)\nprincipalComponents = pca.fit_transform(x)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component 1', 'principal component 2'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3ded2dc935786903b984c2b0045fbb29b229021","collapsed":true},"cell_type":"code","source":"finalDf = pd.concat([principalDf, df2[['kume']]], axis = 1)\nfinalDf.head(8)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0edf0652e40d8d35ec8d323f0dd91282d301cc2b"},"cell_type":"markdown","source":"### PCA Model Scores\n<a id=\"ch7\"></a>"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a0a3082cce235e7cae52512738333b313e81336a"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom sklearn.ensemble import RandomForestClassifier\n\npredictors = finalDf.drop([\"kume\"], axis=1)\ntarget = finalDf[\"kume\"]\nX_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size = 0.25, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d7aebd4be03d32157723514ed8ba8ab4576d81f","collapsed":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nmodels = []\nmodels.append(('Logistic Regression', LogisticRegression()))\nmodels.append(('Naive Bayes', GaussianNB()))\nmodels.append(('Decision Tree (CART)',DecisionTreeClassifier())) \nmodels.append(('K-NN', KNeighborsClassifier()))\nmodels.append(('AdaBoostClassifier', AdaBoostClassifier()))\nmodels.append(('BaggingClassifier', BaggingClassifier()))\nmodels.append(('RandomForestClassifier', RandomForestClassifier()))\n\nfor name, model in models:\n    model = model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    from sklearn import metrics\n    print(\"%s -> ACC: %%%.2f\" % (name,metrics.accuracy_score(y_test, y_pred)*100))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13577240b2479ef362ffa5422763cb9c0b1800bc"},"cell_type":"markdown","source":"## 2- Data Visualition\n<a id=\"ch8\"></a>"},{"metadata":{"_uuid":"dad95928ed99cf06e8242836de9e02d49a50d08d"},"cell_type":"markdown","source":"### Correlations\n<a id=\"ch9\"></a>"},{"metadata":{"trusted":true,"_uuid":"8d1069f11e70fbc4faa30cdedddd619d8fd2fcb5","collapsed":true},"cell_type":"code","source":"#Lets Have a Look At Correlations\nfig, ax = plt.subplots()\nfig.set_size_inches(15,15)\nsns.heatmap(data.corr(),cbar=True, annot=True, square=True, annot_kws={'size': 12})\nplt.tight_layout()\nplt.savefig('2-elaraba-corr.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"087f6d6be073b731021d72cb11384ba566f58fa3","collapsed":true},"cell_type":"code","source":"corr = df.corr()\nfig, ax = plt.subplots()\nfig.set_size_inches(20,20)\nmask = np.zeros_like(corr) #eğer corr bozuksa markaları göstermiyorsa bunu \nmask[np.triu_indices_from(mask)] = True #ve bunu silip shift+enter yapın ondan sonra geri yapıştırın ve shift+enter\nsns.heatmap(corr, mask=mask, cbar=True, annot=True, square=True, annot_kws={'size': 10})\nplt.savefig('car-corr.png')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3cb905c7379c5d7d96e27c8e86e58a6b29d8db3"},"cell_type":"markdown","source":"### Graphs\n<a id=\"ch10\"></a>"},{"metadata":{"trusted":true,"_uuid":"7d27308365a2087d86d6acd688bfb85269aee7f8","collapsed":true},"cell_type":"code","source":"qs = [q for q in questions.features if q not in [\"Sex\",\"Age\",\"Region\",\"Education\"]]\nqf = df.loc[qs]\n\nfig, ax = plt.subplots(figsize=(20,6))\nax.xaxis.set(ticks=range(0,11), # Manually set x-ticks\nticklabels=qs)\nqf[['Alfa Romeo','Audi','Bmw', 'Chevrolet', 'Citroen', 'Dacia', 'Fiat', 'Ford', 'Honda', 'Hyundai',\n                        'Kia', 'Mercedes', 'Mitsubishi', 'Nissan', 'Opel', 'Peugeot', 'Renault', 'Toyota',\n                        'Volkswagen', 'Volvo']].plot(ax=ax,alpha=0.75, rot=80)\nplt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\nplt.grid()\nplt.savefig('compare.pdf')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31dadaa3a769639e5cbfa124c98c504c3c1d7a4e","collapsed":true},"cell_type":"code","source":"df = df.T\ndf = df.drop(['marka'], axis=1)\ndf = df.drop(['kume'], axis=1)\ndf = df.T\n\n#plot data\nfig, ax = plt.subplots(figsize=(30,10))\nax.xaxis.set(ticks=range(0,14), # Manually set x-ticks\nticklabels=[\"araba-tur\",\"airbag\",\"araba-yas\",\"araba-performans\",\"araba-kullanım-tur\",\"araba-km\",\n         \"araba-yakıt\",\"araba-segment\",\"araba-parca\",\"arac-hitap\",\n         \"butce\",\"konfor-skorlama\",\"kume\"])\ndf.plot(ax=ax)\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b267ea4ffb7ef4cbc4ec5eb19ca925ad2882b73e"},"cell_type":"markdown","source":"## 3- Buildling Machine Learning Models\n<a id=\"ch11\"></a>"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"33c1948e73859cf6ed8fcc68e89c4ce86616db99"},"cell_type":"code","source":"#Split Data By Train and Test\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom sklearn.ensemble import RandomForestClassifier\n\ndata = data.drop(['marka'], axis=1)\npredictors = data.drop([\"kume\"], axis=1)\ntarget = data[\"kume\"]\nX_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size = 0.25, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22c8938e56e1d89cabb53260e18644d2d47f1a1d","collapsed":true},"cell_type":"code","source":"#Le\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nmodels = []\nmodels.append(('Logistic Regression', LogisticRegression()))\nmodels.append(('Naive Bayes', GaussianNB()))\nmodels.append(('Decision Tree (CART)',DecisionTreeClassifier())) \nmodels.append(('K-NN', KNeighborsClassifier()))\nmodels.append(('AdaBoostClassifier', AdaBoostClassifier()))\nmodels.append(('BaggingClassifier', BaggingClassifier()))\nmodels.append(('RandomForestClassifier', RandomForestClassifier()))\n\nfor name, model in models:\n    model = model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    from sklearn import metrics\n    print(\"%s -> ACC: %%%.2f\" % (name,metrics.accuracy_score(y_test, y_pred)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d04f892129e8c9654e8831e24438fa6d4005138e","collapsed":true},"cell_type":"code","source":"#Lets Look at Feature Importance\nrf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=2)\nrf.fit(X_train, y_train)\nfrom sklearn.ensemble import RandomForestClassifier\nquestions = pd.DataFrame({'features': data.columns[:-1],'importance': rf.feature_importances_})\nquestions = questions.sort_values(by='importance', ascending=False)\nquestions","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb116bdea13306e490f69a39a9332b03a449f50b"},"cell_type":"markdown","source":"## 4- Network Analysis\n<a id=\"ch12\"></a>"},{"metadata":{"_uuid":"d49fb92ef5652c735a53753cc9866c711a79823f"},"cell_type":"markdown","source":"### Brand Network Anaylsis\n<a id=\"ch13\"></a>"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ddbdbb181715f341cd6b49ee31732564a6a9bf64"},"cell_type":"code","source":"import networkx as nx\n\n#Changes from dataframe to matrix, so it is easier to create a graph with networkx\ncor_matrix = np.asmatrix(corr)\n\n#Crates graph using the data of the correlation matrix\nG = nx.from_numpy_matrix(cor_matrix)\n\n#relabels the nodes to match the  stocks names\nG = nx.relabel_nodes(G,lambda x: df.columns[x])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53a98cc2b9c042a10fc2b628d92c8a7d199b9c65","collapsed":true},"cell_type":"code","source":"def drawGraph(G, size = 20):\n    fig, ax = plt.subplots()\n    fig.set_size_inches(size,size)\n    \n    pos_fr = nx.fruchterman_reingold_layout(G)\n    edges = G.edges()\n\n    weights = [G[u][v]['weight'] for u,v in edges]\n    labels = {e: round(G[e[0]][e[1]]['weight'],2) for e in edges}\n    weights2 = [w**2 for w in weights]\n\n    nx.draw(G, pos=pos_fr, node_size=1000, node_color='lightblue', with_labels=True)\n\n    # Plot edge labels\n    nx.draw_networkx_edge_labels(G, pos=pos_fr, edge_labels=labels)\n    plt.savefig('graph.pdf')\n    \ndrawGraph(G)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b478301d4e61a13c7e5d75aa24ea23a42f7c743","collapsed":true},"cell_type":"code","source":"# remove edges with correlation < 0.5\nG.remove_edges_from([(u,v) for u,v,e in G.edges(data = True) if e['weight'] < 0.5])\ndrawGraph(G, size =30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2929aa93c9239739f84a03e7a8c173f803100c49","collapsed":true},"cell_type":"code","source":"# remove edges with correlation < 0.8\nG.remove_edges_from([(u,v) for u,v,e in G.edges(data = True) if e['weight'] < 0.8])\ndrawGraph(G, size=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32245c80948d824e9608f6a6bcac973e2b48dabe","collapsed":true},"cell_type":"code","source":"# remove edges with correlation < 0.9\nG.remove_edges_from([(u,v) for u,v,e in G.edges(data = True) if e['weight'] < 0.9])\ndrawGraph(G, size=30)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fd16deefcf141628228fa6b8945050418d520c2e"},"cell_type":"markdown","source":"### Feature Network Anaylsis\n<a id=\"ch14\"></a>"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"29006bb420e17b1933cfe85937d82652e9a4b784"},"cell_type":"code","source":"#Changes from dataframe to matrix, so it is easier to create a graph with networkx\ncor_matrix = np.asmatrix(df.T.corr())\n\n#Crates graph using the data of the correlation matrix\nG = nx.from_numpy_matrix(cor_matrix)\n\n#relabels the nodes to match the  stocks names\nG = nx.relabel_nodes(G,lambda x: df.T.columns[x])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd8855165771c92dc2a9afb24818890c03d0e22b","collapsed":true},"cell_type":"code","source":"drawGraph(G, size = 25)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41e61dbac9e506870b9eeee4b10f01b6eda76389"},"cell_type":"markdown","source":"## 5- Clustering with hierarchical clustering\n* ** I did a clustering by looking at the correlations without writing the code. I did this with the help of the clustering method you will see now.**\n<a id=\"ch15\"></a>"},{"metadata":{"_uuid":"77d328a569ba5aeea400aa26bc3315da622c197e"},"cell_type":"markdown","source":"### Clustering to Data\n<a id=\"ch16\"></a>"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a99e4eaf046e439089e5a240247541a56136b71c"},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.spatial.distance import pdist, squareform\nfrom scipy.cluster.hierarchy import linkage, dendrogram\n\n\n#data_array = ((np.float, len(data['marka'].dtype.names)))\ndata_array = df.transpose()\ndata_array = np.array(data_array)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"74788953977f2558f189a3780d7f986f4765f13c"},"cell_type":"code","source":"data_dist = pdist(data_array) # computing the distance\ndata_link = linkage(data_dist)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ebb4361bff3a0ffdb4f460430b494c6736dff83","collapsed":true},"cell_type":"code","source":"dendrogram(data_link,labels=data_array.dtype.names)\nplt.xlabel('Araba Modelleri')\nplt.ylabel('Uzaklık')\nplt.suptitle('Samples clustering', fontweight='bold', fontsize=14);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"968c662ed4112a473732d23ceb48bc75e5c729ab"},"cell_type":"markdown","source":"### Clustered Data Correlations\n<a id=\"ch17\"></a>"},{"metadata":{"trusted":true,"_uuid":"172a063a95271cf462414416c2361a76295625da","collapsed":true},"cell_type":"code","source":"# Compute and plot first dendrogram.\nfig = plt.figure(figsize=(12,12))\n# x ywidth height\nax1 = fig.add_axes([0.05,0.1,0.2,0.6])\nY = linkage(data_dist, method='single')\nZ1 = dendrogram(Y, orientation='right',labels=data_array.dtype.names) # adding/removing the axes\nax1.set_xticks([])\n\n\n# Compute and plot second dendrogram.\nax2 = fig.add_axes([0.3,0.71,0.6,0.2])\nZ2 = dendrogram(Y)\nax2.set_xticks([])\nax2.set_yticks([])\n\n#Compute and plot the heatmap\naxmatrix = fig.add_axes([0.3,0.1,0.6,0.6])\nidx1 = Z1['leaves']\nidx2 = Z2['leaves']\nD = squareform(data_dist)\nD = D[idx1,:]\nD = D[:,idx2]\nim = axmatrix.matshow(D, aspect='auto', origin='lower',cmap=plt.cm.YlGnBu)\naxmatrix.set_xticks([])\naxmatrix.set_yticks([])\n\n# Plot colorbar.\naxcolor = fig.add_axes([0.91,0.1,0.02,0.6])\nplt.colorbar(im, cax=axcolor)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"95d866d6f965afefc9b07e91831bb5e89ddc4f33"},"cell_type":"markdown","source":"## Source \n* [SciPy Hierarchical Clustering and Dendrogram Tutorial](https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/)\n* [PCA using Python (scikit-learn)](https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60)\n* [Uzay Cetin's Network Analysis](http://github.com/uzay00)\n"},{"metadata":{"_uuid":"1ddfd604f3385385d0206db3f84ee7c012e769ee"},"cell_type":"markdown","source":"**Thanks for reading, Dont Forget Your comments are worth gold for me**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}