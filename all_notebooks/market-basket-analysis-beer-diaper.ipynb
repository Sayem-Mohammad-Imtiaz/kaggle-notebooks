{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the Dataset\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load transactions from pandas.\ndf = pd.read_csv(\"/kaggle/input/beer-and-diaper/beer and diaper.csv\", header=None)\n\n# Print the header\nprint(df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split transaction strings into lists.\ntransactions = df.iloc[:,1].apply(lambda t: t.split(','))\n\n# Convert DataFrame into list of strings.\ntransactions = list(transactions)\n\n# Print the second transaction\nprint(transactions[1])\n\n# Count the number of transactions that contain bread and milk\ntransactions.count(['bread', 'milk'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df['Transactions']= df.values.tolist()\n#df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df['Transactions'] = df['Transactions'].apply(lambda x: [i for i in x if str(i) != \"nan\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transactions = df['Transactions']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert DataFrame column into list of strings\n#transactions = list(transactions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transactions.count(['burgers', 'meatballs', 'eggs'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import permutations\n\n# Extract unique items.\nflattened = [item for transaction in transactions for item in transaction]\nitems = list(set(flattened))\n\n# Compute and print rules.\nrules = list(permutations(items, 2))\nprint(rules)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the number of rules\nprint(len(rules))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Simplest Metric"},{"metadata":{"trusted":true},"cell_type":"code","source":"from mlxtend.preprocessing import TransactionEncoder\n\n# Instantiate transaction encoder\nencoder = TransactionEncoder().fit(transactions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-hot encode itemsets by applying fit and transform\nonehot = encoder.transform(transactions)\n\n# Convert one-hot encoded data to DataFrame\nonehot = pd.DataFrame(onehot, columns = encoder.columns_)\nprint(onehot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Computing Support for Single Items\nprint(onehot.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Computing Support for Multiple Items\nimport numpy as np\n\n# Define itemset that contains almonds and zucchini\nonehot['beer+bread'] = np.logical_and(onehot['beer'], onehot['bread'])\n\nprint(onehot.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"onehot=onehot.drop('beer+bread', axis=1)\nonehot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Condifence & Lift"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print first five items\nprint(onehot.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Computing support.\nsupportBD = np.logical_and(onehot['beer'],onehot['diaper']).mean()\nsupportB = onehot['beer'].mean()\nsupportD = onehot['diaper'].mean()\n\n# Compute and print confidence and lift.\nconfidence = supportBD / supportB\nlift = supportBD / (supportB * supportD)\n\n# Print results.\nprint(supportD, confidence, lift)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Computing Leverage"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute support for \"asparagus\" and \"almonds\"\nsupportBD = np.logical_and(onehot['beer'], onehot['diaper']).mean()\n\n# Compute support for \"asparagus\"\nsupportB = onehot['beer'].mean()\n\n# Compute support for \"almonds\"\nsupportD = onehot['diaper'].mean()\n\n# Compute and print leverage\nleverage = supportBD - supportB * supportD\nprint(leverage)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Computing Conviction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute support for \"asparagus\" and \"almonds\"\nsupportBD = np.logical_and(onehot['beer'], onehot['diaper']).mean()\n\n# Compute support for \"asparagus\"\nsupportB = onehot['beer'].mean()\n\n# Compute support for NOT \"almonds\"\nsupportnD = 1.0 - onehot['diaper'].mean()\n\n# Compute support for \"asparagus\" and NOT \"almonds\"\nsupportBnD = supportB - supportBD\n\n# Compute conviction\nconviction = supportB*supportnD / supportBnD\nprint(conviction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculating Metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's define the functions to calculate the metrics from the original data.\nfrom itertools import permutations\n\ndef supportA(itemA, df):\n    return float(df[itemA].mean())    \n\ndef supportB(itemB, df):\n    return float(df[itemB].mean())\n\ndef confidence(itemA,itemB,df):\n    return float(np.logical_and(df[itemA],df[itemB]).mean() /(df[itemA].mean()))\n\ndef lift(itemA,itemB,df):\n    return float(np.logical_and(df[itemA],df[itemB]).mean() /(df[itemA].mean() * df[itemB].mean()))\n\ndef leverage(itemA,itemB,df):\n    return np.logical_and(df[itemA],df[itemB]).mean() - (df[itemA].mean()*df[itemB].mean())\n\ndef conviction(itemA, itemB, df):\n    # Compute support for A and B\n    supportAB = np.logical_and(df[itemA], df[itemB]).mean()\n    # Compute support for A\n    supportA = df[itemA].mean()\n    # Compute support for not B\n    supportnB = 1.0 - df[itemB].mean()\n    # Compute support for A not B\n    supportAnB = supportA - supportAB\n    # Compute conviction\n    return float(supportA*supportnB / supportAnB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_pairs = list()\nfor itemA,itemB in permutations(onehot,2):\n    item_pairs.append(list((itemA,itemB, #names\n                            onehot[itemA].sum(),onehot[itemB].sum(), #individual count\n                            np.logical_and(onehot[itemA],onehot[itemB]).sum(), #pair count\n                            supportA(itemA, onehot),\n                            supportB(itemB, onehot),\n                            confidence(itemA,itemB,onehot), #confidence\n                            lift(itemA,itemB,onehot), #lift\n                            leverage(itemA,itemB,onehot), # leverage\n                            conviction(itemA, itemB, onehot)\n                            ))) # ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_pairs = pd.DataFrame(item_pairs,columns = ['itemA','itemB',\n                                                'countItemA','countItemB',\n                                                'countItemA&B',\n                                                'Antecedent Support',\n                                                'Consequent Support',\n                                                'Confidence',\n                                                'Lift',\n                                                'Leverage',\n                                                'Conviction'])\n\nitem_pairs.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Performing Multi-Metric Filtering"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select subset of rules with low consequent support.\nrules = item_pairs[item_pairs['Consequent Support'] < 0.05]\nprint(len(rules))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rules","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select subset of rules with lift > 1.5.\nrules_2 = rules[rules['Lift'] > 1.5]\nprint(len(rules_2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rules_2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Apriori Algorithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import Apriori algorithm\nfrom mlxtend.frequent_patterns import apriori","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute frequent itemsets\nfrequent_itemsets = apriori(onehot, min_support = 0.0005,max_len = 4, use_colnames = True)\n\n# Print number of itemsets\nprint(len(frequent_itemsets))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Print frequent itemsets\nprint(frequent_itemsets.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Apriori and Computing Association Rule "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import Apriori algorithm\nfrom mlxtend.frequent_patterns import apriori, association_rules\n\n# Compute association rules\nArules = association_rules(frequent_itemsets,\n                           metric = \"support\",\n                           min_threshold = 0.005)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Arules","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the rules.\nprint(Arules)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Raise the threshold\n# Compute association rules\nArules_2 = association_rules(frequent_itemsets,\n                           metric = \"support\",\n                           min_threshold = 0.010)\n\n# Print the rules.\nprint(Arules_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Raise the threshold\n# Compute association rules\nArules_3 = association_rules(frequent_itemsets,\n                           metric = \"support\",\n                           min_threshold = 0.050)\n\n# Print the rules.\nprint(Arules_3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(10,5))\nsns.boxplot(x='antecedent support', data=Arules, linewidth=0.9, color=\"royalblue\", ax=ax[0])\nsns.boxplot(x='support', data=Arules, linewidth=0.9, color=\"royalblue\", ax=ax[1])\nsns.boxplot(x='confidence', data=Arules, linewidth=0.9, color=\"royalblue\", ax=ax[2])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_rules = Arules[(Arules['antecedent support'] > 0.5) &\n                        (Arules['support'] > 0.3) &\n                        (Arules['confidence'] > 0.5) &\n                        (Arules['lift'] > 1.00)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_rules","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### \"Beer and Diaper\" is the most highly associated items."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}