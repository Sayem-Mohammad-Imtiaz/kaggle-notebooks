{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Facial Expression VGG vs Inception vs ResNet","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Goal\n\nTry facial expresion with VGG, Inception and Resnet to see which one is more efficient.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Activation, add\nfrom tensorflow.keras.utils import plot_model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"label_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\nnames=['emotion','pixels','usage']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/facial-expression/fer2013/fer2013.csv',names=names, na_filter=False)\ndf = df.iloc[1:]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_data(df):\n    x = []\n\n    train = df['pixels'].to_numpy()\n\n    for i in range(len(train)):\n        x.append(train[i].split(' '))\n\n    x = np.array(x)\n    x = x.astype('float32').reshape(len(train), 48, 48, 1)\n\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = get_train_data(df)\nlabels = df['emotion'].to_numpy().astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(train[0].reshape(48, 48))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train, labels, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = to_categorical(y_train)\ny_test = to_categorical(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\n\nclass TimeHistory(tf.keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.times = []\n\n    def on_epoch_begin(self, epoch, logs={}):\n        self.epoch_time_start = time.time()\n\n    def on_epoch_end(self, epoch, logs={}):\n        self.times.append(time.time() - self.epoch_time_start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time_callback_vgg = TimeHistory()\ntime_callback_incep = TimeHistory()\ntime_callback_resid = TimeHistory()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VGG","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def vgg_block(layer_in, n_filters, n_conv):\n    # add convolutional layers\n    for _ in range(n_conv):\n        layer_in = Conv2D(n_filters, (3,3), padding='same', activation='relu')(layer_in)\n    # add max pooling layer\n    layer_in = MaxPooling2D((2,2), strides=(2,2))(layer_in)\n    return layer_in","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define model input\nvisible = Input(shape=(48, 48, 1))\n# add vgg module\nlayer = vgg_block(visible, 64, 2)\n# add vgg module\nlayer = vgg_block(layer, 128, 2)\n# add vgg module\nlayer = vgg_block(layer, 256, 4)\n\nlayer = Flatten()(layer)\nlayer = Dense(7, activation='softmax')(layer)\n\nmodel_vgg = Model(inputs=visible, outputs=layer)\nmodel_vgg.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_vgg.summary()\nplot_model(model_vgg, show_shapes=True, to_file='vgg_block.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_vgg = model_vgg.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), callbacks=[time_callback_vgg])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inception","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def inception_module(layer_in, f1, f2_in, f2_out, f3_in, f3_out, f4_out):\n    # 1x1 conv\n    conv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\n    # 3x3 conv\n    conv3 = Conv2D(f2_in, (1,1), padding='same', activation='relu')(layer_in)\n    conv3 = Conv2D(f2_out, (3,3), padding='same', activation='relu')(conv3)\n    # 5x5 conv\n    conv5 = Conv2D(f3_in, (1,1), padding='same', activation='relu')(layer_in)\n    conv5 = Conv2D(f3_out, (5,5), padding='same', activation='relu')(conv5)\n    # 3x3 max pooling\n    pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\n    pool = Conv2D(f4_out, (1,1), padding='same', activation='relu')(pool)\n    # concatenate filters, assumes filters/channels last\n    layer_out = tf.keras.layers.concatenate([conv1, conv3, conv5, pool], axis=-1)\n    return layer_out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define model input\nvisible = Input(shape=(48, 48, 1))\n# add inception block 1\nlayer = inception_module(visible, 64, 96, 128, 16, 32, 32)\n# add inception block 1\nlayer = inception_module(layer, 128, 128, 192, 32, 96, 64)\n\nlayer = Flatten()(layer)\nlayer = Dense(7, activation='softmax')(layer)\n\nmodel_inception = Model(inputs=visible, outputs=layer)\nmodel_inception.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_inception.summary()\nplot_model(model_inception, show_shapes=True, to_file='inception_block.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_inception = model_inception.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), callbacks=[time_callback_incep])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Residual Network","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def residual_module(layer_in, n_filters):\n    merge_input = layer_in\n    # check if the number of filters needs to be increase, assumes channels last format\n    if layer_in.shape[-1] != n_filters:\n        merge_input = Conv2D(n_filters, (1,1), padding='same', activation='relu', kernel_initializer='he_normal')(layer_in)\n    # conv1\n    conv1 = Conv2D(n_filters, (3,3), padding='same', activation='relu', kernel_initializer='he_normal')(layer_in)\n    # conv2\n    conv2 = Conv2D(n_filters, (3,3), padding='same', activation='linear', kernel_initializer='he_normal')(conv1)\n    # add filters, assumes filters/channels last\n    layer_out = add([conv2, merge_input])\n    # activation function\n    layer_out = Activation('relu')(layer_out)\n    return layer_out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define model input\nvisible = Input(shape=(48, 48, 1))\n# add vgg module\nlayer = residual_module(visible, 64)\n# create model\n\nlayer = Flatten()(layer)\nlayer = Dense(7, activation='softmax')(layer)\n\nmodel_residual = Model(inputs=visible, outputs=layer)\nmodel_residual.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_residual.summary()\nplot_model(model_residual, show_shapes=True, to_file='residual_block.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_residual = model_residual.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), callbacks=[time_callback_resid])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Graphs","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(\"Accuracy\")\nplt.plot(history_residual.history['accuracy'], 'b')\nplt.plot(history_inception.history['accuracy'], 'g')\nplt.plot(history_vgg.history['accuracy'], 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(\"Loss\")\nplt.plot(history_residual.history['loss'], 'b')\nplt.plot(history_inception.history['loss'], 'g')\nplt.plot(history_vgg.history['loss'], 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(\"Value Loss\")\nplt.plot(history_residual.history['val_loss'], 'b')\nplt.plot(history_inception.history['val_loss'], 'g')\nplt.plot(history_vgg.history['val_loss'], 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(\"Value Accuracy\")\nplt.plot(history_residual.history['val_accuracy'], 'b')\nplt.plot(history_inception.history['val_accuracy'], 'g')\nplt.plot(history_vgg.history['val_accuracy'], 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(\"Time to train per epoch (seconds)\")\nplt.plot(time_callback_resid.times, 'b')\nplt.plot(time_callback_incep.times, 'g')\nplt.plot(time_callback_vgg.times, 'r')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}