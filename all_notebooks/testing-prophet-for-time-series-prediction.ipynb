{"cells":[{"metadata":{"_uuid":"eb1c467aeb806f6096975b309b1806cfe05df37f"},"cell_type":"markdown","source":"# Time Series Prediction with Prophet \n\n## By: Jeff Hale"},{"metadata":{"_uuid":"9cd0437b42038ddcbfa871d60b31372ca1f8522b"},"cell_type":"markdown","source":"## Plan\n\n### Explore the Prophet time series prediction library with several data sets to see how it performs with different parameters."},{"metadata":{"_uuid":"d90f8cf49af5d6b54c4c4f35a1c5696e0e8ffe90"},"cell_type":"markdown","source":"## Background\nSARIMA and exponential smoothing (Holt Winters) are proven to work well for a range of time series prediction problems, but they require a good bit of parameter tuning. \n\nProphet is a relatively new library -  it was released in 2017. It's designed for \"Business Time Series\".  Prophet is open source and was developed by Facebook. Facebook claims to use it a good deal internally. It is useful for univariate prediction. Prophet has APIs for Python and R. It is designed to be robust to use and to handle seasonal trends and holidays well. \n\nProphet uses a generalized additive model, a type of regression model, to make predictions. It can accomodate non-linear smoothers applied ot the regressors. The model is decomposable into trend, seasonality, and holiday components. Prophet is curve-fitting instead of a model class like ARIMA that explicitly accounts for the temporal component of the model through autoregression. \n\nProphet can accomodate expert information, so it's Bayesian-friendly.\n\nProphet is fast and the [Prohpet docs](https://facebook.github.io/prophet/docs/quick_start.html) are quite nice. Here's an [introductory paper](https://peerj.com/preprints/3190/) on the library. \n\nI've only found two evaluations of Prophet. One, discussed [here],(http://kourentzes.com/forecasting/2017/07/29/benchmarking-facebooks-prophet/) found it didn't perform fabulously with a relatively small amout of data, which isn't shocking. A [second analysis](https://pythondata.com/stock-market-forecasting-with-prophet/) of stock data also didn't find it to perform super well.\n\nWe're going to test it on smaller and larger data sets for business-case type problems."},{"metadata":{"_uuid":"bb3c7ca6154532483342a3667254d04832e5fb1b"},"cell_type":"markdown","source":"## Set-up\nLoad the necessary libraries.\nConfigure the Jupyter Notebook settings.\nLoad the data into a pandas DataFrame"},{"metadata":{"trusted":true,"_uuid":"5c3b109705a64a18b7c7aa03b07c15f1a1c235ba"},"cell_type":"code","source":"# essentials\nimport numpy as np \nimport pandas as pd \n\n# visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# time series algorithm\nfrom fbprophet import Prophet\nfrom fbprophet.diagnostics import performance_metrics\n\n# reproducibility\nnp.random.seed(34)\n\n# Jupyter magic\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51e15048a7c3b9374d95d0aea49c4dac06f5f96a"},"cell_type":"code","source":"!ls              # list the file in the working directory","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57229051e0ded4255a11134fb32affae3197c9ef"},"cell_type":"markdown","source":"# Shampoo Sales\n\nThe first dataset is for shampoo sales. Available at [DataMarket](https://datamarket.com/data/set/22r0/sales-of-shampoo-over-a-three-year-period#!ds=22r0&display=line), original dataset Makridakis, Wheelwright, and Hyndman (1998). Hyndman, R.J. “Time Series Data Library”, https://datamarket.com/data/list/?q=provider:tsdl. Accessed on 12/12/18.\n\nThis dataset contains monthly data over 3 years for shampoo sales. So 36 observations total.\n\nI found these datasets through Jason Brownlee's [Machine Learning Mastery](https://machinelearningmastery.com)."},{"metadata":{"trusted":true,"_uuid":"80aff8178f06e1ac6fc847b72d31001a628dda82"},"cell_type":"code","source":"!pip list      # list the package version numbers for reproducibiity","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b6995683988b16b117508fc5520b73bb42632a8"},"cell_type":"markdown","source":"We need to skip the header row and exclude the text at the bottom of the .csv file. \n\nProphet requires the date column to be labeled *ds* and the target column to be labeled *y*. \n\nThe date column isn't a standard format Pandas will be able to convert, so we'll need to make a date custom parser. We'll do that in a bit."},{"metadata":{"trusted":true,"_uuid":"54658044429ad7ec3c86fc2127bb10a049c1d316"},"cell_type":"code","source":"df_shampoo_orig = pd.read_csv('../input/sales-of-shampoo-over-a-three-year-period/sales-of-shampoo-over-a-three-ye.csv', \n                              nrows=36,\n                              skiprows = 1, \n                              names = ['ds', 'y'], \n                              parse_dates = True )\ndf = df_shampoo_orig\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50c8249ac4ddd20aafe1e0e0ab6771dd2d949d41"},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb801b0911b368f6b81cabfeb1f975d52590ff6d"},"cell_type":"markdown","source":"Let's get the *ds* column into datatime format."},{"metadata":{"trusted":true,"_uuid":"bccda1d412e4570e7df9ddba4604682dff14e98a"},"cell_type":"code","source":"df['ds'] = df.ds.apply(lambda x: \"198\"+x)\ndf.ds.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c20813a2a6917ac90e70b88d5a68e874179468f6"},"cell_type":"markdown","source":"### tseries.offset.MonthEnd(0)\nThis next cell uses the awesome tseries.offset.MonthEnd(0) method to make the day of the month the final day. This is necessary for Prophet to make the predictions we need at the correctly spaced monthly intervals."},{"metadata":{"trusted":true,"_uuid":"de1a57abc20d5bcdd869b0daa010b32a7157695e"},"cell_type":"code","source":"df['ds']=pd.to_datetime(df['ds'])+pd.tseries.offsets.MonthEnd(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b2724fb024a71701a7664a9ed76bd708e84d8fe"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6fb2ce6b3d309f0bfe7efb6c30d9f8879ada092"},"cell_type":"markdown","source":"That looks better."},{"metadata":{"_uuid":"a3d3bf5df88f18c9f21b5e0daa6e6a205718be97"},"cell_type":"markdown","source":"## Prophet forecast\n\nWe need to make a dataframe of future dates with the *.make_future_dataframe* method. Let's make 12 months worth of predictions."},{"metadata":{"trusted":true,"_uuid":"13b8bb49f39a9fb09941f9524e4978e6abfdbe56"},"cell_type":"code","source":"train = df[:24]\ntrain.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"082a535f2e4be0fbbaf7e0c8c448675e7b54d363"},"cell_type":"markdown","source":"Let's instantiate a Prophet object and fit it to the training data.\n\nProphet tries to model daily and weekly seasonality by default. We'll define our own yearly seasonal pattern. \n\n\"Seasonalities are estimated using a partial Fourier sum... a partial Fourier sum can approximate an aribtrary periodic signal. The number of terms in the partial sum (the order) is a parameter that determines how quickly the seasonality can change.\" - from the [docs](https://facebook.github.io/prophet/docs/seasonality,_holiday_effects,_and_regressors.html).\n\nWe'll try a Fourier sum of 5 to start and then adjust to see the effects.\n\nWe need to pass a n_changepoints parameter because the datset has < 25 observations, as discussedi n [this GitHub issue](https://github.com/facebook/prophet/issues/248#issuecomment-314624770)."},{"metadata":{"trusted":true,"_uuid":"7c9707a475a27a82d2d78cf4cfb7ad0270abba9f"},"cell_type":"code","source":"m = Prophet(weekly_seasonality=False, daily_seasonality=False, n_changepoints=2)\nm.add_seasonality(name='yearly', period=12, fourier_order=5)\nm.fit(train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"48b51a090416749da6a17d54a7d79d3e2d4fb4f9"},"cell_type":"markdown","source":"Let's make the future data frame and make the predictions. We need to pass *freq='m'* because we want monthly predictions."},{"metadata":{"trusted":true,"_uuid":"1b3b719357e1c0e69573d9c1514d820e34dfe57c"},"cell_type":"code","source":"future = m.make_future_dataframe(periods=12, freq='M')\nforecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06c90d90b802119da4fcab03380e83c8d90d87ff"},"cell_type":"markdown","source":"Note that Prophet's make_future_dataframe method makes a DataFrame that includes the historical data, as well as the predictions. "},{"metadata":{"_uuid":"062eb74bde0a8d3e17843fddbd9d48ed31f818ef"},"cell_type":"markdown","source":"The predictions look reasonable at first glance. Let's make at a plot."},{"metadata":{"trusted":true,"_uuid":"4ec17ed822da10ed00f1b3f71f7748fe6369be53"},"cell_type":"code","source":"figure = m.plot(forecast)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5856e5137f0c6ed3ff5a4aa05a0813e169a11a4f"},"cell_type":"markdown","source":"The dots are the actual data points. The line through the dots is the predicted values. The shared area represents the uncertainty intervals. \n\nLet's decompose this graph into the trend and seasonality."},{"metadata":{"trusted":true,"_uuid":"91d281ed2e62d65e5b7303540af12c91b9b363af"},"cell_type":"code","source":"fig_decompose = m.plot_components(forecast)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5dc9dc4ae8731e3932e78157fec9023bd8ec6af7"},"cell_type":"markdown","source":"The trend line looks correct. But the seasonality looks like it might be over-fitting."},{"metadata":{"_uuid":"942a6735049bb4a008fac8426215bba658ee880f"},"cell_type":"markdown","source":"### Reduce fourier_order\nLet's see what happens if we reduce the *fourier_order* to 1."},{"metadata":{"trusted":true,"_uuid":"19a748ba9361f4cc5e87899303fe7a2b48bb73d2"},"cell_type":"code","source":"m2 = Prophet(weekly_seasonality=False, daily_seasonality=False, n_changepoints=2)\nm2.add_seasonality(name='yearly', period=12, fourier_order=1)\n\nm2.fit(train)\nfuture2 = m2.make_future_dataframe(periods=12, freq='m')\nforecast2 = m2.predict(future2)\nforecast2[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6ff48d9e14ef25de01b216c13e64d68f74c778f"},"cell_type":"code","source":"fig2 = m2.plot(forecast2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb1313289d3899be5b7ea21d4e32390f91cf7707"},"cell_type":"code","source":"fig2_decompose = m2.plot_components(forecast2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85c90507814852b8b1d501fe9d5b0f7e15d2639c"},"cell_type":"markdown","source":"Looks fairly similar, with a bit less over-fitting to the seasonality."},{"metadata":{"_uuid":"94bd21212fcc9823b93710eb2bc1cc377d0f2224"},"cell_type":"markdown","source":"## Performance metrics\n\nLet's compare the predictions to the actual values from the first forecast, when the fourier_term was higher and nothing was log transformed. \n\nWe first need to create a cutoff column so Prophet knows when to compare predicted values to actual values."},{"metadata":{"trusted":true,"_uuid":"400e03ef23908da6b5cdb984852560bbfad4fc76"},"cell_type":"code","source":"forecast['cutoff'] = pd.to_datetime('1980-12-31')\nforecast['y'] = df['y']\nforecast.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ba709a4d3d7ef52331a679722680a2cfb0c7236"},"cell_type":"code","source":"df_p = performance_metrics(forecast)\ndf_p.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a2b7f3b8eec0ac205eab1801043feed4039a3b31"},"cell_type":"markdown","source":"Ok. Prophet is giving us a row of error terms for a variety of time windows into the future.  Let's see how these error values compare to the predictions with the lower Fourier term."},{"metadata":{"trusted":true,"_uuid":"e2e6bb63d0f774978373d9859a5d48ccd92ceaa7"},"cell_type":"code","source":"forecast2['cutoff'] = pd.to_datetime('1980-12-31')\nforecast2['y'] = df['y']\nforecast2.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f425a59f154c940ed57f19040211cda6888f94f1"},"cell_type":"code","source":"df_p2 = performance_metrics(forecast2)\ndf_p2.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c3b8b356cc0e6d8d30dd1cfd8f4716d8d6a2dab"},"cell_type":"markdown","source":"Let's make a DataFrame that subtracts the error terms from the first predictions from the second predictions so that we can see which version predicted better. We'll make the horizons into indexes for legibility."},{"metadata":{"trusted":true,"_uuid":"dff35c012d6d76e02d3dca459750b63a012f511d"},"cell_type":"code","source":"df_p.index = df_p['horizon']\ndf_p2.index = df_p2['horizon']\n\ndf_error_compare = df_p - df_p2\ndf_error_compare = df_error_compare.drop(columns=['horizon', 'coverage'])\ndf_error_compare.loc[:'365 days']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35ab42650dff4134a9e4f6bce56e5baa99ff580c"},"cell_type":"markdown","source":"Mostly we see negative numbers, which means that the second model with the Fourier term equal to 1 had larger error terms. So, in this case, the larger Fourier term model performed better."},{"metadata":{"_uuid":"0381e66c7f6465a5456344d637adcb2cd2ea6d51"},"cell_type":"markdown","source":"Let's see how our second Prophet model forecast compared to a persistence forecast. A persistence forecast means a prediction that the final sales term in the training data would continue each month going forward. We'll make a DataFrame with a persistence forecast prediction."},{"metadata":{"trusted":true,"_uuid":"685be46d3b24a832a3415b2b59bd13168b9180e5"},"cell_type":"code","source":"forecast_persist = forecast2.copy()\nforecast_persist['cutoff'] = pd.to_datetime('1980-12-31')\nforecast_persist['y'] = df['y']\nforecast_persist['yhat'] = df.at[23,'y']\nforecast_persist.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b8e40e110e5b00ae8377b909d200fc4e475ff5f"},"cell_type":"markdown","source":"Now let's compare the persistence forecast to the actual results."},{"metadata":{"trusted":true,"_uuid":"5364c289c31e573a9d257ff095bd5839fd44ce7b"},"cell_type":"code","source":"df_persist = performance_metrics(forecast_persist)\ndf_persist.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b60259daf41d1216e9788e91e330fc539d5b7b4"},"cell_type":"markdown","source":"Now let's compute the difference between the persistence forecast error terms and the second Prophet model."},{"metadata":{"trusted":true,"_uuid":"0d4cfb61ee4b03d4236e2d37c67d304e8941fa27"},"cell_type":"code","source":"df_persist.index = df_persist['horizon']\n\ndf_error_compare_persist = df_persist - df_p2\ndf_error_compare_persist = df_error_compare_persist.drop(columns=['horizon', 'coverage'])\ndf_error_compare_persist.loc[:'365 days']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"871dc738dc224ea2fe490e09b1099ddebe6fca3f"},"cell_type":"markdown","source":"Those numbers are all positive, meaning that the error terms were larger for the persistence model than for the Prophet model! Granted, this is a very small sample with a clear trend, but Prophet beat the baseline. That's good. Let's try another prediction problem."},{"metadata":{"_uuid":"c753663b9d945d6f84964a404ccf41dfac60a18e"},"cell_type":"markdown","source":"# Airline Passenger Counts\n\nThe second dataset is for International airline passengers: monthly totals in thousands. Jan 49 – Dec 60 Available at [DataMarket](http://datamarket.com/data/list/?q=provider:tsdl), original dataset Source: Box & Jenkins (1976). Accessed on 12/16/18."},{"metadata":{"trusted":true,"_uuid":"230978b77f78aca03e9ee5811817a8919433894d"},"cell_type":"code","source":"df_air_orig = pd.read_csv('../input/internationalairlinepassengers/international-airline-passengers.csv', \n                              nrows=144,\n                              skiprows = 1, \n                              names = ['ds', 'y'], \n                              parse_dates = True )\ndf_air = df_air_orig\ndf_air.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"680972e4cc2c8982e477509a48f000c1ccf1346c"},"cell_type":"code","source":"df_air.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4facd0a7a972419b8532933b3b0b2cbdb5eb0aee"},"cell_type":"code","source":"df_air.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"854154ad808804348835f4e4800c7a12ae99d9e1"},"cell_type":"markdown","source":"No nulls. That's good. Looks like we need to parse the dates again."},{"metadata":{"trusted":true,"_uuid":"dfb5df19563a299462128b6c6c93320a51e6a2d7"},"cell_type":"code","source":"df_air['ds']=pd.to_datetime(df_air['ds'])+pd.tseries.offsets.MonthEnd(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"278e7d41dab66b80239e0936c2031b4baf3e9006"},"cell_type":"code","source":"df_air.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9fe5d9be8bbb78cf26c7d38064f0181d2b0b6b91"},"cell_type":"code","source":"df_air.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61cb5775d73b7ebc3a7bbabb071814369a865787"},"cell_type":"markdown","source":"That all looks correct."},{"metadata":{"trusted":true,"_uuid":"8e0ef8889a01b4ab1de82ebfe7270c87b451f9a4"},"cell_type":"code","source":"df_air.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"658081a397223964e0e42464cad3f12d1e0691a6"},"cell_type":"markdown","source":"Ok. Now we're flying. Ha! Groan. We need to decide what time period we want to forecast. Let's forecast the last two years. \n\nLet's fit a Prophet model with the training data."},{"metadata":{"trusted":true,"_uuid":"1cc6df10effca08c73098f8ed6f793f6a8b4bb90"},"cell_type":"code","source":"train = df_air[:120]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4ddf1b008325652d4d7853a070485e80e3f2004"},"cell_type":"markdown","source":"Let's instantiate a Prophet object and fit it to the training data. Unlike the shampoo sales data, this time we're going to use the default Prophet parameters."},{"metadata":{"trusted":true,"_uuid":"156097cf00281a43417fec7eccc9aab3114f1742"},"cell_type":"code","source":"m = Prophet()\nm.fit(train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9581afd0d81c043d51a99fc5cdb84568b64f421c"},"cell_type":"markdown","source":"Let's make the future data frame and make the predictions. We need to pass *freq='m'* because we want monthly predictions."},{"metadata":{"trusted":true,"_uuid":"e207aa801ec2538be30b06399168989e9d2c5b1f"},"cell_type":"code","source":"future = m.make_future_dataframe(periods=24, freq='m')\nforecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cc22bd233b9cada2521df87951f027de2012b10"},"cell_type":"code","source":"forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a09db9dd51468e695dba065a74ec8908e6ed777"},"cell_type":"markdown","source":"That data looks reasonable at first glance. Let's make at a plot."},{"metadata":{"trusted":true,"_uuid":"56cda66865313eec9b36c8f68f581f062b14a9a9"},"cell_type":"code","source":"fig = m.plot(forecast)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3730195b49be808f82a00b20c905db564d8f2e5b"},"cell_type":"markdown","source":"Again, the dots are the actual data points. The line through the dots is the predicted values. The shared area represents the uncertainty intervals. "},{"metadata":{"_uuid":"1fdb3117b4c23fee0d676409d86fe37a2e74c2df"},"cell_type":"markdown","source":"Let's decompose this graph into the trend and seasonality. Before making any adjustments to the model."},{"metadata":{"trusted":true,"_uuid":"77a4c2c05a6db46f85c45b375e9a1f996dcb345a"},"cell_type":"code","source":"fig_decompose = m.plot_components(forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"924064ed36ff55ffe9d89551232210f98d21c681"},"cell_type":"code","source":"## Multiplicative seasonality","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"217d7b8934f111f6c9cb14c31e1895f8f43456bf"},"cell_type":"markdown","source":"It looks like the latter seasonal high and low data points in the training data weren't picked up super well. Perhpas we should try making that seasonality effect multiplicative. \n\nSo this is funny, I went to the docs to see how to add multiplicative seasonality and found a chart much like the one above. Turns out the Prophet team used this dataset as an example for multiplicative seasonality! Guess my instinct was right :) "},{"metadata":{"trusted":true,"_uuid":"8554265b97b06481906e6d0181e7410436c5a387"},"cell_type":"code","source":"m2 = Prophet(seasonality_mode='multiplicative')\nm2.fit(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68dd04090c2e12275306d9fd42953033d44e1ffd"},"cell_type":"code","source":"future2 = m2.make_future_dataframe(periods=24, freq='m')\nforecast = m2.predict(future2)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"571530e91bb37663a2563c6457b51309e1fabe13"},"cell_type":"code","source":"fig = m.plot(forecast)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e1358433c06f471d2d6e4be7145d4d4caa375c1c"},"cell_type":"markdown","source":"That looks much better!"},{"metadata":{"trusted":true,"_uuid":"63bd82f14cfbc043455411fa5b3454eb2dc40859"},"cell_type":"code","source":"fig = m.plot_components(forecast)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c9e28035d9f053f330c281bf0cc2742ac024881"},"cell_type":"markdown","source":"Looks like people travel in the summer."},{"metadata":{"_uuid":"845127a69d9f88eff7d1b48e6ed5c422a1687149"},"cell_type":"markdown","source":"## Model evaluation\n\nLet's look at how the model with the multiplicative seasonality effect performs compared to a persistence model.\n\nFirst we'll make a persistence model DataFrame."},{"metadata":{"trusted":true,"_uuid":"9c74ad95a9f8b8708cb4d07acccb169c66a9b9df"},"cell_type":"code","source":"forecast_persist = forecast.copy()\nforecast_persist['cutoff'] = pd.to_datetime('1959-01')\nforecast_persist['y'] = df_air['y']\nforecast_persist['yhat'] = df_air.at[119,'y']\nforecast_persist.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f833a402c8a7481980e4be0ce1f34cb05fe04a65"},"cell_type":"markdown","source":"Here's what the persistence forecast looks like graphically."},{"metadata":{"trusted":true,"_uuid":"4fb903ff2811564cb05826b923484c39acb0ec5f"},"cell_type":"code","source":"fig = m.plot(forecast_persist)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"683270553da5b107f84049ffeea6a5397b62db60"},"cell_type":"markdown","source":"The straight line is the persistence forecast based on the value at the last training month, December 1958. The predicted range of values for the Prophet model is in the shaded region."},{"metadata":{"_uuid":"43ce715b34311c6fdbbd59cc58839d7ea3acacdf"},"cell_type":"markdown","source":"Ok. Now we need to add the *cutoff* and *y* values to the forecast."},{"metadata":{"trusted":true,"_uuid":"03158d69ce91c70f04986cd7dddc0c518bd6fe6f"},"cell_type":"code","source":"forecast['cutoff'] = pd.to_datetime('1958-12-31')\nforecast['y'] = df_air['y']\nforecast.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a58aa4b865a91163abc8de1963f2e558545c4f5d"},"cell_type":"markdown","source":"Looks good. Now we need to compute the error terms for both models."},{"metadata":{"trusted":true,"_uuid":"760ba60b2bd658aff5f936001880dd3e3a40d0db"},"cell_type":"code","source":"df_air_p = performance_metrics(forecast[120:])\ndf_air_p.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fffe8a993082a689723d92118dc9cf3cee6918c0"},"cell_type":"code","source":"df_persist_p = performance_metrics(forecast_persist[120:])\ndf_persist_p.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57e1f22c0fffe6556225c8ea053e1bcc0b07ee1f"},"cell_type":"markdown","source":"Let's plot the RMSE lines for the two models. I chose RMSE because its a common metric that outputs an error term in the same units as the predicted variable. So in this case, passengers."},{"metadata":{"trusted":true,"_uuid":"dc6a509325e97570ab0b7124c20d4b0cfe2b7948"},"cell_type":"code","source":"df_air_plot = pd.DataFrame([df_air_p['rmse'], df_persist_p['rmse']])\ndf_air_plot = df_air_plot.T\ndf_air_plot.columns = ['prophet_rmse', 'persist_rmse']\ndf_air_plot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0a7123a54e07fbd8ad377c202722c688de65fde"},"cell_type":"code","source":"df_plot = df_air_plot[:12]\ndf_plot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9aeba888f6f6623c2c9d7a761895e57f4894a3b1"},"cell_type":"code","source":"ax = sns.lineplot(\n    data=df_plot,\n    x=list(range(12)), \n    y='prophet_rmse',\n    )\nplt.title('RMSE Comparison of Prophet Model for Flight Passenger')\nplt.xlabel('Month')\nplt.ylabel('RMSE')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cfcafd365271f17e21683b40469fb11634213059"},"cell_type":"markdown","source":"Let's add the persistence line and clean things up a bit."},{"metadata":{"trusted":true,"_uuid":"3d3ace8ea02de65e47052a6a99791910027009ab"},"cell_type":"code","source":"ax = sns.lineplot(\n    data=df_plot,\n    x=list(range(1, 13)), \n    y='prophet_rmse',\n    )\n\nax = sns.lineplot(\n    data=df_plot,\n    x=list(range(1, 13)), \n    y='persist_rmse',\n    )\n\nplt.title('RMSE Comparison of Prophet Model for Flight Passenger')\nplt.xlabel('Month')\nplt.ylabel('RMSE')\n\nplt.rcParams['figure.figsize']=(12, 6)\nplt.legend(['Prophet RMSE','Persistence RMSE'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"27a463f3e524ae31136af5ff0947fcd5f016946c"},"cell_type":"markdown","source":"The Persistence model has a higher RMSE for every time period. So Prophet beats the Persistence model! That's a low bar, but we'll take it - predicting the future isn't easy."},{"metadata":{"_uuid":"0af109a3d9b6bb7c08787789ecfd346b2fdc69c4"},"cell_type":"markdown","source":"Now we will subtract one DataFrame from the other to see the exact differences in errors."},{"metadata":{"trusted":true,"_uuid":"faffc3ae15248b88a35dcea29c9f789285e1d7f5"},"cell_type":"code","source":"df_air_compare = df_persist_p - df_air_p\n\ndf_air_compare = df_air_compare.drop(columns=['horizon', 'coverage'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8868855b90c1c1caeb05f731fb3bdcfa8139002"},"cell_type":"code","source":"df_air_compare[:12]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"242824f3947de5688e8889d2fbcb5226c69f8557"},"cell_type":"markdown","source":"Confirming what we saw in our graph, we see that the persistence model had a larger error than the Prophet model for nearly all time periods and nearly all error terms."},{"metadata":{"_uuid":"2476856518db362b4142e4b1eb8412367dfe38d5"},"cell_type":"markdown","source":"## Future directions\n\nIt would be interesting to look at Propher performance on more and larger data sets. It would also be cool to compare Prophet with SARIMA and exponential smoothing (Holt-Winters) models. Deep learning models haven't proven especially effective at time series forecasting, but they could be compared also.\n\nOverall, Prophet is fun to work with and Facebook claims to find it quite effective, so it merits further study. \n\n## If you found this helpful, please upvote this Kaggle Kernel so others can find it too."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}