{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Enap - Machine Learning em Projetos\n\n### Projeto Final\n\n# Análise de microdados do Enem: diferenças de rendimento entre alunos de escolas públicas e privadas","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Autor:** Stefano Mozart Pontes Canedo de Souza.\n\n**Objetivo:**\n\nO objetivo deste projeto é utilizar as técnicas apresentadas no curso para analisar possíveis diferenças de rendimento entre escolas públicas e privadas presentes nos microdados do Enem. A intuição, baseada em todo o histórico da educação pública no Brasil, é que o rendimento dos egressos do ensino público seja, na média, inferior àquele observado entre alunos de escolas privadas. \n\n**Método:**\n\nO método de análise empregado contará com a construção de dois grupos de modelos de classificação: o primeiro, tentando classificar o aluno como egresso de escola pública ou privada, a partir de suas notas. O segundo grupo, parte de informações socieconômicas, incluindo a classificação da escola, para prever a nota esperada para um dado aluno.\n\nO que se deseja demonstrar com esses modelos é que, caso os dados de fato apresentem uma diferença significativa nos resultados obtidos por alunos de escolas públicas e privadas, essas diferenças se refletirão no poder de classificação dos modelos treinados a partir desses dados.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Análise exploratória\n\nOs dados utilizados neste experimento são disponibilizados pelo Inep em http://inep.gov.br/web/guest/microdados. Para os modelos de classificação de alunos, foram utilizados os dados mais recentes, do Enem 2019. Para os modelos de classificação de escolas, foram utilizados os dados dos três últimos anos disponíveis: 2019, 2018 e 2017.\n\nPara o primeiro grupo de modelos, usamos as seguintes propriedades do registro:\n\n\n|Propriedade      | Descrição                             |\n|:--------------- |:--------------------------------------|\n| TP_ESCOLA\t      | Tipo de escola do Ensino Médio <sup>1</sup>|\n| NU_NOTA_CN      |Nota da prova de Ciências da Natureza  |\n| NU_NOTA_CH\t  |Nota da prova de Ciências Humanas      |\n| NU_NOTA_LC\t  |Nota da prova de Linguagens e Códigos  |\n| NU_NOTA_MT\t  |Nota da prova de Matemática            |\n| NU_NOTA_REDACAO |Nota da prova de redação               |\n\nPara o segundo grupo, foram utilizadas as seguintes propriedades:\n\n|Propriedade     | Descrição                              |\n|:---------------|:-------------------------------------- |\n| TP_ESCOLA\t     | Tipo de escola do Ensino Médio         |\n| TP_ENSINO\t     | Tipo de instituição que concluiu ou concluirá o Ensino Médio|\n| SG_UF_ESC\t     | Sigla da Unidade da Federação da escola|\n| TP_SEXO\t     | Sexo                                   |\n| TP_COR_RACA\t | Cor/raça                               |\n| Q001\t         | Formação acadêmica do pai              |\n| Q002           | Formação acadêmica da mãe              |\n| Q005           | Número de pessoas na residência        |\n| Q006           | Faixa de renda familiar mensal         |\n| Q007           | Família contrata empregada doméstica   |\n| NOTA_MEDIA     | Média das notas objetivas <sup>2</sup> |\n| NU_NOTA_REDACAO| Nota da redação                        |\n\n**Observações:**\n\n1. Os valores possíveis para esse campo são: 1. Não informou; 2. Pública; 3. Privada; 4. Exterior. Utilizamos nesta análise apenas os registros que apresetnem valor 1 ou 2 nesta propriedade.\n2. A *feature* NOTA_MEDIA é calculada da seguinte forma: NOTA_MEDIA = (NU_NOTA_CN + NU_NOTA_CH + NU_NOTA_LC + NU_NOTA_MT) / 4\n","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install pingouin","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Carregamos as bibliotecas que serão utilizadas para manipulação e visualização dos dados\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pingouin as pg\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Criamos um pipeline de pré-processamento. A ideia é utilizar essa função para microdados de\n# diferentes anos \ndef pipeline_notas_Enem(arquivo):\n    # Colunas a serem lidas no arquivo\n    features = [\n        'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT','NU_NOTA_REDACAO','TP_ESCOLA'\n    ]\n    \n    # Lemos o arquivo, retirando os registros em que um dos valores não estivesse presente.\n    df = pd.read_csv(\n        arquivo,\n        #nrows = 5000, # 5k linhas para desenvolvimento inicial\n        encoding = 'latin1',\n        usecols = features,\n        sep = ';'\n    ).dropna()\n    \n    df['NOTA_MEDIA'] = (df['NU_NOTA_CN'] + df['NU_NOTA_CH'] + df['NU_NOTA_LC'] + df['NU_NOTA_MT']) / 4\n    \n    # Filtramos os registros de com alunos de escolas públicas e privadas (valores 2 e 3 no \n    # campo TP_ESCOLA)\n    df = df.loc[df['TP_ESCOLA'].isin([2, 3])]\n    df.loc[df['TP_ESCOLA']==2, 'TP_ESCOLA'] = 'Pública'\n    df.loc[df['TP_ESCOLA']==3, 'TP_ESCOLA'] = 'Privada'\n    \n    return df\n\n# Carregamos o dataset a partir da cópia do Kaggle\nnotas = pipeline_notas_Enem('/kaggle/input/enem-2019/DADOS/MICRODADOS_ENEM_2019.csv')\n\nnotas.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribuição entre as classes\n\nAo analisarmos a distribuição de alunos entre os dois grupos, tanto no dataset original quanto nos subconjuntos de teste e treinamento, percebemos que o dataset é bastante desbalanceado. Cerca de 83% dos elementos da amostra pertencem à classe majoritária: alunos de escolas públicas. Esse desbalanceamento será levado em conta na análise dos modelos a seguir.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Para garantir a capacidade de comparação entre modelos, separamos o dataset em treinamento em teste, numa proporção de 80%/20%.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"notas.TP_ESCOLA.value_counts().plot(kind='bar')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Diferenças entre as classes\n\nAo analizarmos, por exemplo, a nota da redação, podemos concluir que existe uma diferença estatisticamente significante entre os dois grupos","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"notas[['TP_ESCOLA', 'NU_NOTA_REDACAO']].groupby('TP_ESCOLA').describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pub = notas.loc[notas.TP_ESCOLA=='Pública', 'NU_NOTA_REDACAO']\npriv = notas.loc[notas.TP_ESCOLA=='Privada', 'NU_NOTA_REDACAO']\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npg.ttest(priv, pub)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O teste nos mostra que a diferença entre as médias é estatisticamente significativa. O poder do teste é 1. Abaixo, vemos os histogramas das duas classes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 3))\n\np1=sns.distplot(\n    pub,\n    ax=axes[0],\n    axlabel=f'Média: {pub.mean():.2f}\\nDesvio padrao: {pub.std():.2f}'\n).set_title(\"Notas de alunos de escola pública\")\np2=sns.distplot(\n    priv,\n    axlabel=f'Média: {priv.mean():.2f}\\nDesvio padrao: {priv.std():.2f}'\n).set_title(\"Notas de alunos de escola privada\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O mesmo se aplica à nota média nas provas objetivas:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"notas[['TP_ESCOLA', 'NOTA_MEDIA']].groupby('TP_ESCOLA').describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pub = notas.loc[notas.TP_ESCOLA=='Pública', 'NOTA_MEDIA']\npriv = notas.loc[notas.TP_ESCOLA=='Privada', 'NOTA_MEDIA']\npg.ttest(x=priv, y=pub, correction=False).round(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 3))\n\np1=sns.distplot(\n    pub,\n    ax=axes[0],\n    axlabel=f'Média: {pub.mean():.2f}\\nDesvio padrao: {pub.std():.2f}'\n).set_title(\"Nota de alunos de escola pública\")\np2=sns.distplot(\n    priv,\n    axlabel=f'Média: {priv.mean():.2f}\\nDesvio padrao: {priv.std():.2f}'\n).set_title(\"Nota de alunos de escola privada\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pré processamento\n\nAgora, realizamos a normalização dos dados, a fim de acelerarmos o treinamento e teste dos modelos preditivos","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"std_features = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO', 'NOTA_MEDIA']\nfrom sklearn.preprocessing import StandardScaler\nstd = StandardScaler()\nnotas[std_features] = std.fit_transform(notas[std_features])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"E, para fins de comparação dos modelos, separamos o dataset em treinamento em teste, numa proporção de 80%/20%\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    notas.drop(['TP_ESCOLA', 'NOTA_MEDIA'], axis = 1), notas.TP_ESCOLA, test_size=0.2, random_state=42\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classificando alunos a partir de suas notas\n\nPara o primeiro grupo de classificadores, utilizaremos as notas dos alunos, bem como sua classe de renda no questionário sócio-econômico, para classificar se o aluno é egresso de escola pública ou privada. \n\nO primeiro classificador utilizado é o KNN, que agrupa ocorrências da amostra a partir de um critério de similaridade. O hiper-parâmetro mais importante desse modelo é justamente o número de núcleos a partir dos quais o modelo realizará o agrupamento. Nesse caso, utilizamos dois núcleos, seguindo a intuição de que há dois grupos distintos no *dataset*: alunos egressos de escolas públicas e privadas.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instanciamos o modelo KNN com dois núcleos\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=2)\n\n# Definimos uma função para treinamento e exbição dos resultados de um modelo\ndef pipeline_treino_teste(model):\n    # Ajustamos o modelo\n    model.fit(X_train, y_train)\n    # Submetemos os dados de teste ao classificador \n    y_pred = model.predict(X_test)\n    \n    # E observamos algumas métricas de desempenho desse modelo: acurácia, F1-score e matriz de confusão\n    from sklearn import metrics\n    print(f'Acurácia: {metrics.accuracy_score(y_test, y_pred)}')\n    print(f'F1-score médio: {metrics.f1_score(y_test, y_pred, average=\"weighted\")}')\n    print(f\"F1-score da classe minoritária: {metrics.f1_score(y_test, y_pred, pos_label='Privada')}\")\n    metrics.plot_confusion_matrix(model, X_test, y_test, cmap=plt.cm.Blues, normalize='true')\n    \n# Agora executamos o pipeline\npipeline_treino_teste(knn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O resultado acima, com acurácia de cerca de 83%, que é a proporção de elementos da classe majoritária (escola pública), com score F1 da classe minoritária (privada) abaixo de 30%, indicam que, muito provavelmente, o classificador KNN é simples demais para modelar o problema proposto. O poder de classificação modelado ainda não apresenta evidencia forte o suficiente da diferença de rendimento entre alunos de escolas públicas e privadas. A matriz de confusão acima, por sua vez, indica que o modelo erra bastante dado ao viés da classe majoritária. Prosseguimos, então, nosso experimento com mais 3 classificadores.\n\nO próximo modelo utilizado é o de descida de gradiente estocástica (SGD), selecionamos a função de custo (loss) do tipo 'modified_huber', que resulta num modelo de regressão linear que é mais robusto contra outliers. A função de custo (loss) do tipo \"elasticnet\" favorece a seleção de variáveis (feature selection) durante o próprio treinamento. Tendo em vista o desbalanceamento entre as classes, utilizaremos o parâmetro class_weight=\"balanced\", que pondera a função de erro por um fator inversamente proporcional à participação da classe na amostra.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instanciamos um modelo SGD (descida do gradiente estocástica)\nfrom sklearn.linear_model import SGDClassifier\nsgd = SGDClassifier(class_weight=\"balanced\", loss='modified_huber', penalty=\"elasticnet\", random_state=42)\n\n# Executamos o pipeline de treino e teste\npipeline_treino_teste(sgd)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Embora apresente um score f1 melhor para a classe minoritária, e tenha acurácia melhor para essa classe (a matriz de confusão nos mostra 75% de acerto na classe minoritária), a acurácia ponderada para todo a amostra é baixa, tendo em vista o percentual de 26% erros na classe majoritária.\n\nO próximo modelo utilizado será o de regressão logística.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instanciamos o modelo de regressão logística\nfrom sklearn.linear_model import LogisticRegression\nrlog = LogisticRegression(class_weight=\"balanced\")\n\n# E submetemos ao pipeline de treino e teste\npipeline_treino_teste(rlog)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O desempenho do modelo de regressão logística é ligeiramente superior ao do modelo anterior. A matriz de confusão acima, no entanto não apresenta uma redução significativa no viés de classificação. Cerca de 26% das ocorrências da classe minoritária foram classificadas incorretamente.\n\nA seguir, testaremos um modelo de árvore de decisão.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instanciamos uma árvore de decisão, com altura máxima de 3 nós\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\ntree = DecisionTreeClassifier(class_weight=\"balanced\", max_depth=7, random_state=42)\n\n# Executamos o pipeline de treino e teste\npipeline_treino_teste(tree)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O modelo de árvore de decisão teve desempenho muito similar ao do modelo de regressão logística, em ambas as classes. Mais uma vez, é importante notar que a acurácia de quase 75% se deve ao fato de que o modelo erra na classificação de cerca um quarto dos registros da classe majoritária.\n\nO próximo modelo utilizado é o RandomForest, que cria, internamente, uma série de árvores de decisão e apresenta, como resultado de classificação, uma combinação das respostas apresentadas pelas diversas árvores treinadas com os dados.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instanciamos o classificador Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(class_weight=\"balanced\", n_estimators=300, random_state=42)\n\n# Executamos o pipeline de treino e teste\npipeline_treino_teste(rf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O resultado desse classificador é, na verdade, uma composição de resultados dos 300 estimadores criados internamente. É interessante notar que, embora haja uma diferença significativa na acurácia, a melhora se dá apenas na classe majoritária: agora, com apenas 3% de erros. O modelo erra, no entanto, em cerca de 72% das ocorrências da classe minoritária.\n\nA seguir, testamos um modelo de máquinas de vetores-suporte. Trata-se de um modelo que busca maximizar as fronteiras de separação entre classes. Neste experimento, utilizamos a versão linear do classificador, pois o custo de computação da versão não linear (SVC) é quadrático em relação ao número de registros na amostra, o que o torna inviável para um dataset com mais de 1 milhão de registros.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instanciamos o classificador SVM\nfrom sklearn.svm import LinearSVC\nlsvm = LinearSVC(class_weight=\"balanced\", max_iter=3000, random_state=42, tol=5e-4)\n\n# Submetemos o classificador ao treino e teste\npipeline_treino_teste(lsvm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Esse classificador tem desempenho ligeriamente superior ao dos modelos de regressão logística e árvore de decisão. Sua acurácia, assim como nos classificadores anteriores, é afetada pela porcentagem de erros na classe majoritária.\n\nO próximo classificador utilizado é o XGBoost (eXtreme Gradient Boosting), que utiliza diversos modelos de árvore de decisão como estimadores subjacentes, mas faz uma otimização da busca por hiperparâmetros ótimos, de acordo com a tarefa selecionada. Nesse experimento, utilizamos o parâmetro objective='multi:softmax' para que modelo otimize os parâmetros para classificação.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nxgb = XGBClassifier(\n    objective = 'multi:softmax',\n    booster = 'gbtree',\n    num_class = 2,\n    eval_metric = 'logloss',\n    eta = .1,\n    max_depth = 14,\n    colsample_bytree = .4,\n    n_jobs=-1\n)\n\npipeline_treino_teste(xgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Esse modelo tem acurácia maior, mas, assim como o modelo de Random Forest, esse ganho se dá como resultado de um viés de classificação para a classe majoritária. Quando observamos a matriz de confusão, percebemos que o modelo erra em quase 70% dos registros da classe minoritária.\n\nPor fim, usaremos um classificador que utiliza os modelos já treinados anteriormente como estimadores subjacentes para gerar uma classificação própria. Neste caso, atribuímos pesos iguais para todos modelos e o resultado da classificação será dado pela maioria simples de votos. É possível testar diferentes combinações de pesos e alcançar um desempenho superior.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instanciamos o classficador por votos, passando os classificadores já treinados\nfrom mlxtend.classifier import EnsembleVoteClassifier\n\nvote = EnsembleVoteClassifier(\n    clfs=[knn, sgd, rlog, tree, rf, lsvm, xgb],\n    weights=[1, 1, 1, 1, 1, 1, 1],\n    refit=False\n)\n\n# Submetemos esse classificador ao teste\npipeline_treino_teste(vote)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"O classificador final tem acurácia semelhante a dos modelos de Random Forest e XGBoost, mas com desempenho superior quando consideramos sua atuação na classe minoritária.\n\nEsse resultado nos mostra que os modelos de fato captam uma diferença nas notas de alunos de escolas públicas e privadas. Todos os modelos foram instanciados com a maior parte dos hiperparâmetros em seu valor padrão. É possível que a aplicação de técnicas de otimização de hiperparâmetros produza modelos ainda melhores.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Utilizando um modelo mais complexo\n\nOs modelos utilizados até aqui são considerados modelos \"clássicos\" de Machine Learning. A maior parte desses modelos prioriza a simplicidade e explicabilidade dos resultados. Mas é possível que modelos de Deep Learning, mais compexos e mais difíceis de analizar, apresentem resultados superiores em termos de acurácia.\n\nA seguir, utilizamos a biblioteca fast.ai, que utiliza embbedings e outras técnicas avançadas para seleção, ajuste e treinamento de modelos.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.tabular import *\n\ndep_var = 'TP_ESCOLA'\ncont_names = ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO', 'NOTA_MEDIA']\n\nstart = int(len(notas)*.7)\nend = int(len(notas)*.1) + start\n\n              \ntest = TabularList.from_df(notas.iloc[start:end], cont_names=cont_names)\n\ndata = (\n    TabularList\n        .from_df(notas, cont_names=cont_names)\n        .split_by_idx(list(range(start,end)))\n        .label_from_df(cols=dep_var)\n        .add_test(test)\n        .databunch()\n)\n\ndata.show_batch(rows=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = tabular_learner(data, layers=[200,100], metrics=accuracy)\nlearn.fit_one_cycle(1, 5e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ClassificationInterpretation.from_learner(learn).plot_confusion_matrix(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  Simplificando o problema\n\nA seguir, testamos alguns dos modelos utilizados anteriormente num problemas mais simples: reduzimos as dimensões do dataset, utilizando apenas a nota média das provas objetivas e a nota da redação. Isso nos permite visualizar a dispersão dos registros num plano.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nX = notas[['NOTA_MEDIA', 'NU_NOTA_REDACAO']]\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nny = le.fit_transform(notas.TP_ESCOLA)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from mlxtend.plotting import plot_decision_regions\nimport matplotlib.gridspec as gridspec\nimport itertools\n\ngs = gridspec.GridSpec(2, 2)\nfig = plt.figure(figsize=(10,8))\n\nlabels = ['K-nearest Neighbour', 'Stochastic Gradient Descent', 'Logistic Regression', 'Decision Tree']\n\nfor clf, lab, grd in zip([knn, sgd, rlog, tree],\n                         labels,\n                         itertools.product([0, 1], repeat=2)):\n    clf.fit(nX, ny)\n    ax = plt.subplot(gs[grd[0], grd[1]])\n    fig = plot_decision_regions(X=nX.to_numpy(), y=ny, clf=clf)\n    plt.title(lab)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prevendo a nota dos alunos a partir de seus dados socioeconômicos","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criamos um pipeline de pré-processamento. A ideia é utilizar essa função para microdados de\n# diferentes anos \ndef pipeline_SocioEconomico_Enem(arquivo):\n    # Colunas a serem lidas no arquivo\n    features = [\n        'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO',  'TP_ESCOLA', \n        'TP_ENSINO', 'SG_UF_ESC', 'TP_COR_RACA', 'TP_SEXO', 'Q001', 'Q002', 'Q005', 'Q006', 'Q007',\n        'NU_IDADE'\n    ]\n\n    # Carregamos o dataset a partir do arquivo\n    df = pd.read_csv(\n        arquivo,\n        nrows = 5000, # 5k linhas para desenvolvimento inicial\n        encoding = 'latin1',\n        usecols = features,\n        sep = ';'\n    )#.dropna()\n    \n    # Filtramos os registros de com alunos de escolas públicas e privadas (valores 2 e 3 no campo TP_ESCOLA)\n    df = df.loc[df['TP_ESCOLA'].isin([2, 3])]\n    df.loc[df['TP_ESCOLA']==2, 'TP_ESCOLA'] = 'Pública'\n    df.loc[df['TP_ESCOLA']==3, 'TP_ESCOLA'] = 'Privada'\n\n    # Vamos atribuir o tipo de ensino com base na idade do aluno\n    df = df.loc[df['NU_IDADE'].notna()]\n    df.loc[df['TP_ENSINO'].isna() & df['NU_IDADE']>21, 'TP_ENSINO'] = 3\n    df.loc[df['TP_ENSINO'].isna(), 'TP_ENSINO'] = 1\n    \n    # Filtramos os demais valores ausentes\n    df.dropna(inplace=True)\n    \n    # Realizamos uma normalização dos valores das notas\n    std_features = ['NOTA_MEDIA', 'NU_NOTA_REDACAO']\n    df['NOTA_MEDIA'] = (df['NU_NOTA_CN'] + df['NU_NOTA_CH'] + df['NU_NOTA_LC'] + df['NU_NOTA_MT']) / 4\n    \n    \n    from sklearn.preprocessing import StandardScaler\n    std = StandardScaler()\n    df[std_features] = std.fit_transform(df[std_features])\n    \n    # Usamos um encoder ordinal para transformar os valores presentes na coluna 'Q006' (faixa de renda) em valores \n    # numéricos, crescentes.\n    ord_enc_features = ['Q001', 'Q002', 'Q001']\n    from sklearn.preprocessing import OrdinalEncoder\n    ord_enc = OrdinalEncoder()\n    df[ord_enc_features] = ord_enc.fit_transform(df[ord_enc_features])\n\n    ## - Colunas que passarão por um processo de codificação\n    #onehot_enc_features = ['TP_COR_RACA', 'TP_SEXO', 'TP_ENSINO', 'SG_UF_ESC']\n    #from sklearn.preprocessing import OneHotEncoder\n    #onehot_enc = OneHotEncoder()\n    #df.enc = onehot_enc.fit_transform(df[onehot_enc_features])\n\n    # Retira as colunas usadas para cálculos intermediários\n    return df.drop(['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT'], axis = 1)\n\n# Carregamos o dataset a partir da cópia do Kaggle, retirando os registros em que um dos valores não estivesse presente.\nse = pipeline_SocioEconomico_Enem('./dados/MICRODADOS_ENEM_2019.csv')\n\nse.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Utilizamos um encoder ordinal, para as variáveis em que há uma gradação de valores categóricos\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ord_enc_features = ['Q005', 'Q006', 'Q007']\nfrom sklearn.preprocessing import OrdinalEncoder\nenc = OrdinalEncoder()\nse[ord_enc_features] = enc.fit_transform(se[ord_enc_features])\nse.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Criamos variáveis dummies para as demais colunas categórcas","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"onehot_enc_features = ['TP_ESCOLA', 'TP_COR_RACA', 'TP_SEXO', 'TP_ENSINO', 'SG_UF_ESC']\nse = pd.get_dummies(se, prefix=onehot_enc_features, columns=onehot_enc_features, drop_first=True)\nse.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prevendo a média das provas objetivas","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    se.drop(['NOTA_MEDIA'], axis = 1), se.NOTA_MEDIA, test_size=0.2, random_state=42\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nossa variável alvo, nesse experimento será a nota médias nas provas objetivas. Com o dataset subdividido em treino e teste, ajustamos um modelo de regressão linear.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train, y_train)\n\nfrom sklearn.metrics import mean_squared_error\nmean_squared_error(y_test, lr.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prevendo a nota da redação\n\nAlteramos a variável-alvo e repetimos o processo de particionamento do dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    se.drop(['NU_NOTA_REDACAO'], axis = 1), se.NU_NOTA_REDACAO, test_size=0.2, random_state=42\n)\n\nlr2 = LinearRegression()\nlr2.fit(X_train, y_train)\n\nmean_squared_error(y_test, lr.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Alteramos a variável-alvo e ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}