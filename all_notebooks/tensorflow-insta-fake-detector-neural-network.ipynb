{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Tensorflow instagram fake accounts detector\n\nFor this classification problem, I decided to use Tensorflow and built a neural network with 3 dense layers (1 input, 1 hidden, 1 output). The result is a model with an accuracy of ~80%","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data\n\nThe dataset contains accounts features such as: # of followers, # of following, presence of profile picture etc.\nThe label 'fake' is a value 0 (real profile) or 1 (fake profile).\n\nThe data is available for download here: `kaggle datasets download -d free4ever1/instagram-fake-spammer-genuine-accounts`.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data pre processing and overview","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import rcParams\n%matplotlib inline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\n\nfrom numpy.random import seed\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftrain = pd.read_csv('../input/instagram-fake-spammer-genuine-accounts/train.csv')\ndftest = pd.read_csv('../input/instagram-fake-spammer-genuine-accounts/test.csv')\n\ndf = pd.concat([dftrain, dftest], axis=0, sort=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='profile pic', data=df, palette='hls', hue='fake')\nplt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='private', data=df, palette='hls', hue='fake')\nplt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 11 features in total and 1 categorical label. \nSome of them are categorical and some of them continuous, so we can scale the continous feature to prevent them from messing up with the prediction.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scale Continuous Features\ncontinuous_features = ['nums/length username', 'description length', '#posts', '#followers', '#follows']\n\nscaler = StandardScaler()\nfor feature in continuous_features:\n    df[feature] = df[feature].astype('float64')\n    df[feature] = scaler.fit_transform(df[feature].values.reshape(-1, 1))\n\ndftrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's create our train test split\nX_train = df[pd.notnull(df['fake'])].drop(['fake'], axis=1)\ny_train = df[pd.notnull(df['fake'])]['fake']\nX_test = df[pd.isnull(df['fake'])].drop(['fake'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Neural Network Model\n\nThe model consists of 3 layers. The input layer contains 11 perceptrons, one for each feature of the dataset.\nThe hidden layer is densely connected and has 22 neurons.\nFinally the output layer only contains 1 output neuron for the final prediction.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(11, input_dim=X_train.shape[1], activation='linear', name='input_layer'))\nmodel.add(Dense(22, activation='linear', name='hidden_layer'))\nmodel.add(Dropout(0.0))\nmodel.add(Dense(1, activation='sigmoid', name='output_layer'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Results","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The model has been tested at several epochs number, and it seems to peek its performance at ~10 epochs with an accuracy oscillating around 80%.\nSome factors that can increase the overall accuracy are random seeding, which also helps with reproducibility. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"training = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\nval_acc = np.mean(training.history['accuracy'])\nprint(\"\\n%s: %.2f%%\" % ('accuracy', val_acc*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(training.history['accuracy'])\nplt.plot(training.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}