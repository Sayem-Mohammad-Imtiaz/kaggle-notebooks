{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom keras.datasets import imdb\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#num_words=10000 means that in training dataset it will save only 10000 words.\n(train_data,train_labels),(test_data,test_labels) = imdb.load_data(num_words=10000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\ndef vectorize_sequences(sequences, dimension=10000):\n    results = np.zeros((len(sequences),dimension))\n    for i, sequence in enumerate(sequences):\n        results[i,sequence]=1\n    return results\n\nx_train = vectorize_sequences(train_data)\nx_test = vectorize_sequences(test_data)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = np.asarray(train_labels).astype('float32')\ny_test = np.asarray(test_labels).astype('float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import models\nfrom keras import layers\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(16, activation='relu',input_shape=(10000,)))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import optimizers\n\nmodel.compile(optimizer='rmsprop',\n             loss='binary_crossentropy',\n             metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import losses \nfrom keras import metrics\n\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.001),\n             loss=losses.binary_crossentropy,\n             metrics=[metrics.binary_accuracy])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_val = x_train[:10000]\npartial_x_train = x_train[10000:]\n\ny_val = y_train[:10000]\npartial_y_train = y_train[10000:]\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='rmsprop',\n             loss='binary_crossentropy',\n             metrics=['acc'])\nhistory = model.fit(partial_x_train,\n                    partial_y_train,\n                   epochs=20,\n                   batch_size = 512,\n                   validation_data=(x_val,y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_dict = history.history\ndistory_dict.keys()\n[u'acc',u'loss',u'val_acc',u'val_loss']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \n\nacc = history.history['acc']\nval_acc = history.history['val_loss']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1,len(acc)+1)\n\nplt.plot(epochs,loss,'bo',label='Strata trenowania')\nplt.plot(epochs,val_loss,'b',label='Strata Walidacji')\nplt.title('Strata trenowania i walidacji')\nplt.xlabel('Epoki')\nplt.ylabel('Strata')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.clf()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_values = history_dict['acc']\nval_acc_values =  history_dict['val_acc']\n\nplt.plot(epochs,acc,'bo',label='Dokladnosc trenowania')\nplt.plot(epochs,val_acc,'b',label='Dokladnosc Walidacji')\nplt.title('Dokladnosc trenowania i walidacji')\nplt.xlabel('Epoki')\nplt.ylabel('Strata')\nplt.legend()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Dense(16, activation='tanh',input_shape=(10000,)))\nmodel.add(layers.Dense(16, activation='tanh'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop',\n             loss='binary_crossentropy',\n             metrics=['accuracy'])\n\nmodel.fit(x_train,y_train,epochs=4,batch_size=512)\nresults= model.evaluate(x_test,y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.datasets import reuters\n\n(train_data, train_labels),(test_data,test_labels) = reuters.load_data(num_words=10000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_index = reuters.get_word_index()\nreverse_word_index = dict([(value,key)for (key,value) in word_index.items()])\ndecoded_newswire=''.join([reverse_word_index.get(i - 3, '?')\n                         for i in train_data[0]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \n\ndef vectorize_sequences(sequences, dimension=10000):\n    results = np.zeros((len(sequences),dimension))\n    for i, sequence in enumerate(sequences):\n        results[i,sequence] = 1\n    return results \n\nx_train = vectorize_sequences(train_data)\nx_test= vectorize_sequences(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\n\none_hot_train_labels = to_categorical(train_labels)\none_hot_test_labels = to_categorical(test_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import models \nfrom keras import layers \n\nmodel = models.Sequential()\nmodel.add(layers.Dense(64, activation='relu',input_shape=(10000,)))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(46, activation='softmax'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='rmsprop',\n             loss = 'categorical_crossentropy',\n             metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_val = x_train[:1000]\npartial_x_train = x_train[1000:]\n\ny_val = one_hot_train_labels[:1000]\npartial_y_train = one_hot_train_labels[1000:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(partial_x_train,\n                   partial_y_train,\n                   epochs=20,\n                   batch_size=512,\n                   validation_data=(x_val,y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(loss)+1)\n\nplt.plot(epochs, loss, 'bo', label='Strata trenowania')\nplt.plot(epochs, val_loss, 'b', label='Strata walidacji')\nplt.title('Strata trenowania i walidacji')\nplt.xlabel('Epoki')\nplt.ylabel('Strata')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.clf()\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\n\nplt.plot(epochs, acc, 'bo', label='Dokladnosc trenowania')\nplt.plot(epochs, val_acc, 'b', label='Dokladnosc walidacji')\nplt.title('Dokladnosc trenowania i walidacji')\nplt.xlabel('Epoki')\nplt.ylabel('Strata')\nplt.legend()\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Dense(64, activation='relu',input_shape=(10000,)))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(46, activation='softmax'))\n\nmodel.compile(optimizer='rmsprop',\n             loss = 'categorical_crossentropy',\n             metrics=['accuracy'])\n\nmodel.fit(partial_x_train,\n          partial_y_train,\n          epochs=20,\n          batch_size=512,\n          validation_data=(x_val,y_val))\n\nresults = model.evaluate(x_test, one_hot_test_labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import copy \ntest_labels_copy = copy.copy(test_labels)\nnp.random.shuffle(test_labels_copy)\nhits_array = np.array(test_labels) == np.array(test_labels_copy)\nfloat(np.sum(hits_array)) / len(test_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Dense(64, activation='relu',input_shape=(10000,)))\nmodel.add(layers.Dense(4, activation='relu'))\nmodel.add(layers.Dense(46, activation='softmax'))\n\nmodel.compile(optimizer='rmsprop',\n             loss = 'categorical_crossentropy',\n             metrics=['accuracy'])\n\nmodel.fit(partial_x_train,\n          partial_y_train,\n          epochs=20,\n          batch_size=128,\n          validation_data=(x_val,y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#boston housing page n.199\nfrom keras.datasets import boston_housing\n\n(train_data,train_targets),(test_data,test_targets) = boston_housing.load_data()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_targets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preparing data\nmean = train_data.mean(axis=0)\ntrain_data -= mean\nstd = train_data.std(axis = 0)\ntrain_data /= std\n\ntest_data -= mean\ntest_data /= std\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import models\nfrom keras import layers\n\ndef build_model():\n    model = models.Sequential()\n    model.add(layers.Dense(64,activation='relu',\n                           input_shape=(train_data.shape[1],)))\n    model.add(layers.Dense(64,activation='relu'))\n    model.add(layers.Dense(1))\n    model.compile(optimizer='rmsprop',loss='mse',metrics=['mae'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nk = 4\nnum_val_samples = len(train_data) // k\nnum_epochs = 150\nall_scores = []\nfor i in range(k):\n    print('processing fold #',i)\n    val_data = train_data[i *num_val_samples: (i +1)*num_val_samples]\n    val_targets = train_targets[i * num_val_samples: (i+1)*num_val_samples]\n    \n    partial_train_data = np.concatenate(\n        [train_data[:i* num_val_samples],\n         train_data[(i+1)*num_val_samples:]],\n        axis=0)\n    \n    partial_train_targets = np.concatenate(\n        [train_targets[:i* num_val_samples],\n         train_targets[(i+1)*num_val_samples:]],\n        axis=0)\n    \n    model = build_model()\n    model.fit(partial_train_data, partial_train_targets, epochs = num_epochs , batch_size = 1 , verbose =  0)\n    \n    val_mse, val_mae = model.evaluate(val_data , val_targets , verbose =0)\n    all_scores.append(val_mae)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(all_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 500\nall_mae_histories = []\n\nfor i in range(k):\n    print('processing fold #',i)\n    val_data = train_data[i *num_val_samples: (i +1)*num_val_samples]\n    val_targets = train_targets[i * num_val_samples: (i+1)*num_val_samples]\n    \n    partial_train_data = np.concatenate(\n        [train_data[:i* num_val_samples],\n         train_data[(i+1)*num_val_samples:]],\n        axis=0)\n    \n    partial_train_targets = np.concatenate(\n        [train_targets[:i* num_val_samples],\n         train_targets[(i+1)*num_val_samples:]],\n        axis=0)\n        \n    model = build_model()\n    model.fit(partial_train_data, partial_train_targets, epochs = num_epochs , batch_size = 1 , verbose =  0)\n    \n    mae_history = history.history['val_mae']\n    all_mae_histories.append(mae_history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\naverage_mae_history = [\n    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n\n\nplt.plot(range(1, len(average_mae_history)+1),average_mae_history)\nplt.xlabel('Liczba epok')\nplt.ylabel('Sredni blad bezwzgledny')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()\nmodel.fit(train_data, train_targets, epochs=80, batch_size = 16, vebose = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}