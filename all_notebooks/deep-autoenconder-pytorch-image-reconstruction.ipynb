{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Deep Autoencoder in PyTorch to Reconstruct Images"},{"metadata":{},"cell_type":"markdown","source":"In this implementation, we will demonstrate the implementation of a Deep Autoencoder in PyTorch for reconstructing images. This deep learning model will be trained on the MNIST handwritten digits and it will reconstruct the digit images after learning the representation of the input images. "},{"metadata":{},"cell_type":"markdown","source":"First of all, we will import all the reqired libraries"},{"metadata":{"id":"fXC3jg8LRgDe","executionInfo":{"status":"ok","timestamp":1594015393907,"user_tz":-330,"elapsed":5298,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"}},"trusted":true},"cell_type":"code","source":"import os\nimport torch \nimport torchvision\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision import datasets\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import save_image\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we will initialize the hyperparameters."},{"metadata":{"id":"_6cYRcheUJ8U","executionInfo":{"status":"ok","timestamp":1594015399860,"user_tz":-330,"elapsed":2986,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"}},"trusted":true},"cell_type":"code","source":"NUM_EPOCHS = 100\nLEARNING_RATE = 1e-3\nBATCH_SIZE = 128","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we are going to use PyTorch model, so the below function will convert the input image data into tensor that is the basic unit of a PyTorch model."},{"metadata":{"id":"zLYHCTISrlWB","executionInfo":{"status":"ok","timestamp":1594015402035,"user_tz":-330,"elapsed":1520,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"}},"trusted":true},"cell_type":"code","source":"# image transformations\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we will download the MNIST handwritten digits dataset."},{"metadata":{"id":"Pcyk4GI6UMY8","executionInfo":{"status":"ok","timestamp":1594015410805,"user_tz":-330,"elapsed":7830,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"}},"outputId":"f500da80-0f5a-40d3-906f-26ea8fd8265c","trusted":true},"cell_type":"code","source":"trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\ntestset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n\ntrainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\ntestloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"lJofH8GUUq5E","executionInfo":{"status":"ok","timestamp":1594015418549,"user_tz":-330,"elapsed":1175,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"}},"outputId":"d9becee3-11f3-417e-ae42-3c5a5679d78d","trusted":true},"cell_type":"code","source":"print(trainset)","execution_count":null,"outputs":[]},{"metadata":{"id":"S6SzaPEqUepa","executionInfo":{"status":"ok","timestamp":1594015420299,"user_tz":-330,"elapsed":1066,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"}},"outputId":"77549b4f-b682-422f-fd40-b90c39751895","trusted":true},"cell_type":"code","source":"print(trainset.classes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The below functions will:-\n1. Use the CUDA environment, if available, to accelarate the training process.\n2. Make a directory for MNIST images.\n3. Save the decoded images."},{"metadata":{"id":"mdS9SgBCUhja","executionInfo":{"status":"ok","timestamp":1594015430917,"user_tz":-330,"elapsed":1022,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"}},"trusted":true},"cell_type":"code","source":"# utility functions\ndef get_device():\n    if torch.cuda.is_available():\n        device = 'cuda:0'\n    else:\n        device = 'cpu'\n    return device\n\ndef make_dir():\n    image_dir = 'MNIST_Images'\n    if not os.path.exists(image_dir):\n        os.makedirs(image_dir)\n\ndef save_decoded_image(img, epoch):\n    img = img.view(img.size(0), 1, 28, 28)\n    save_image(img, './MNIST_Images/linear_ae_image{}.png'.format(epoch))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Defining the Autoencoder"},{"metadata":{},"cell_type":"markdown","source":"Here, we will define the Autoencoder with all its components as a class and finally, we will instatitate this class to create an autoencoder object (net)."},{"metadata":{"id":"oc62alcmUtHL","executionInfo":{"status":"ok","timestamp":1594015664012,"user_tz":-330,"elapsed":1012,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"}},"trusted":true},"cell_type":"code","source":"class Autoencoder(nn.Module):\n    def __init__(self):\n        super(Autoencoder, self).__init__()\n\n        # encoder\n        self.enc1 = nn.Linear(in_features=784, out_features=256) # Input image (28*28 = 784)\n        self.enc2 = nn.Linear(in_features=256, out_features=128)\n        self.enc3 = nn.Linear(in_features=128, out_features=64)\n        self.enc4 = nn.Linear(in_features=64, out_features=32)\n        self.enc5 = nn.Linear(in_features=32, out_features=16)\n\n        # decoder \n        self.dec1 = nn.Linear(in_features=16, out_features=32)\n        self.dec2 = nn.Linear(in_features=32, out_features=64)\n        self.dec3 = nn.Linear(in_features=64, out_features=128)\n        self.dec4 = nn.Linear(in_features=128, out_features=256)\n        self.dec5 = nn.Linear(in_features=256, out_features=784) # Output image (28*28 = 784)\n\n    def forward(self, x):\n        x = F.relu(self.enc1(x))\n        x = F.relu(self.enc2(x))\n        x = F.relu(self.enc3(x))\n        x = F.relu(self.enc4(x))\n        x = F.relu(self.enc5(x))\n\n        x = F.relu(self.dec1(x))\n        x = F.relu(self.dec2(x))\n        x = F.relu(self.dec3(x))\n        x = F.relu(self.dec4(x))\n        x = F.relu(self.dec5(x))\n        return x","execution_count":null,"outputs":[]},{"metadata":{"id":"4EHdA8baUyQ6","executionInfo":{"status":"ok","timestamp":1594015665830,"user_tz":-330,"elapsed":1044,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"}},"outputId":"204c5904-907c-4cf6-95b1-8fb0913ba249","trusted":true},"cell_type":"code","source":"net = Autoencoder()\nprint(net)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Definning the training parameters."},{"metadata":{"id":"VJ_RDRQXUzub","executionInfo":{"status":"ok","timestamp":1594015673750,"user_tz":-330,"elapsed":1060,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"}},"trusted":true},"cell_type":"code","source":"criterion = nn.MSELoss()\noptimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Defining training and image construction process"},{"metadata":{"id":"FeCEAWftU3I6","executionInfo":{"status":"ok","timestamp":1594015677610,"user_tz":-330,"elapsed":1602,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"}},"trusted":true},"cell_type":"code","source":"def train(net, trainloader, NUM_EPOCHS):\n    train_loss = []\n    for epoch in range(NUM_EPOCHS):\n        running_loss = 0.0\n        for data in trainloader:\n            img, _ = data\n            img = img.to(device)\n            img = img.view(img.size(0), -1)\n            optimizer.zero_grad()\n            outputs = net(img)\n            loss = criterion(outputs, img)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        loss = running_loss / len(trainloader)\n        train_loss.append(loss)\n        print('Epoch {} of {}, Train Loss: {:.3f}'.format(\n            epoch+1, NUM_EPOCHS, loss))\n\n        if epoch % 5 == 0:\n            save_decoded_image(outputs.cpu().data, epoch)\n\n    return train_loss\n\ndef test_image_reconstruction(net, testloader):\n     for batch in testloader:\n        img, _ = batch\n        img = img.to(device)\n        img = img.view(img.size(0), -1)\n        outputs = net(img)\n        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n        save_image(outputs, 'MNIST_reconstruction.png')\n        break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the autoenocder to generate reconstructed images"},{"metadata":{"id":"j10DH2kfU6gS","executionInfo":{"status":"ok","timestamp":1594016619432,"user_tz":-330,"elapsed":940488,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"}},"outputId":"6b9adc2f-b2d4-45e4-b5d8-dd6d8a1788f7","trusted":true},"cell_type":"code","source":"# get the computation device\ndevice = get_device()\nprint(device)\n# load the neural network onto the device\nnet.to(device)\n\nmake_dir()\n\n# train the network\ntrain_loss = train(net, trainloader, NUM_EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing the training performance"},{"metadata":{"id":"g9qbaKERVPeN","executionInfo":{"status":"ok","timestamp":1594016698572,"user_tz":-330,"elapsed":1815,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"}},"outputId":"a4064c6a-e1c4-4375-989a-24d2a81a2bff","trusted":true},"cell_type":"code","source":"plt.figure()\nplt.plot(train_loss)\nplt.title('Train Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.savefig('deep_ae_mnist_loss.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing the trained autoencoder to generate reconstructed images"},{"metadata":{"id":"uECWi3HvVRJy","executionInfo":{"status":"ok","timestamp":1594016716443,"user_tz":-330,"elapsed":1027,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"}},"trusted":true},"cell_type":"code","source":"# test the network\ntest_image_reconstruction(net, testloader)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing reconstructed images at different instance"},{"metadata":{"id":"YM9WnrVMdwFz","executionInfo":{"status":"ok","timestamp":1594016861748,"user_tz":-330,"elapsed":1444,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"}},"outputId":"97cb5d30-4d88-44a7-a938-ea3a3a558b1c","trusted":true},"cell_type":"code","source":"Image.open('./MNIST_Images/linear_ae_image0.png')","execution_count":null,"outputs":[]},{"metadata":{"id":"oeraOXaDeoeS","executionInfo":{"status":"ok","timestamp":1594016864688,"user_tz":-330,"elapsed":1169,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"}},"outputId":"5b5eaede-cd31-4219-d0d7-420303f0f9d3","trusted":true},"cell_type":"code","source":"Image.open('./MNIST_Images/linear_ae_image50.png')","execution_count":null,"outputs":[]},{"metadata":{"id":"haqs0lebeqE5","executionInfo":{"status":"ok","timestamp":1594016868236,"user_tz":-330,"elapsed":1205,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"}},"outputId":"90f46261-d181-4faa-b065-09efb4ae1803","trusted":true},"cell_type":"code","source":"Image.open('./MNIST_Images/linear_ae_image95.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualizing the finally reconstructed images"},{"metadata":{"id":"sYtUrLbDe4GR","executionInfo":{"status":"ok","timestamp":1594016827964,"user_tz":-330,"elapsed":1278,"user":{"displayName":"Dr. Vaibhav Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggv0ODnZNPUUE1bFaIOUaFH9CpYqhZjPkcwn9lJqA=s64","userId":"18385588513169057983"}},"outputId":"fe4fa292-4afc-4d14-f17b-bb842af2d45d","trusted":true},"cell_type":"code","source":"Image.open('./MNIST_reconstruction.png')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}