{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"### Importing the Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importing the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv')\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking the shape (rows, columns)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking the info of the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking how many columns have how many null values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting the NULL values into desirable values where required and applicable and retaining the data type of the columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['LoanAmount'] = dataset['LoanAmount'].fillna(dataset['LoanAmount'].mean())\ndataset['LoanAmount'] = dataset['LoanAmount'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Loan_Amount_Term'] = dataset['Loan_Amount_Term'].fillna(dataset['Loan_Amount_Term'].median())\ndataset['Loan_Amount_Term'] = dataset['Loan_Amount_Term'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Credit_History'] = dataset['Credit_History'].fillna(dataset['Credit_History'].median())\ndataset['Credit_History'] = dataset['Credit_History'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Drop the rest of the data where NULL cannot be filled","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare the X","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataset.drop(columns=['Loan_ID','Loan_Status'])\n\ndep = {'0':'0','1':'1','2':'2','3+':'3'}\nX['Dependents'] = X['Dependents'].map(dep)\n\nX.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare the y and Encode Categorical Values to 0 and 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y = dataset['Loan_Status']\ny.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nlb_make = LabelEncoder()\ny = lb_make.fit_transform(y)\n\ny","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encode all Categorical Values for X","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"##Encode Categorical Values\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\ncategorical_features = ['Gender', 'Married','Dependents','Education','Self_Employed','Property_Area']\n#categorical_features = ['Dependents', 'Education','Self_Employed','Loan_Amount_Term', 'Credit_History', 'Property_Area']\none_hot = OneHotEncoder()\ntransformer = ColumnTransformer([(\"one_hot\",one_hot,categorical_features)], remainder = 'passthrough')\nX = transformer.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Splitting data into test set and training set\n\nfrom sklearn.model_selection import train_test_split\nX_train , X_test , y_train , y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Feature Scaling\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_test.shape, y_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import keras","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential \nfrom keras.layers import Dense,Dropout","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Initialise the Artificial Neural Network","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = Sequential()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Adding the input layer and the first hidden layer\n#### The no. of units is something that one can achieve by doing regular experimentation or using parameter tunig.But \n#### As a tip can be used as the average of the no. of input variables + no. of output variables\n#### Input_dim will be equaly to the no. of input variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.add(Dense(units = 12 , kernel_initializer = 'uniform' , activation = 'relu' , input_dim = 20))\nclassifier.add(Dropout(0.5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Adding the 2nd hidden layer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.add(Dense(units = 12 , kernel_initializer = 'uniform' , activation = 'relu'))\nclassifier.add(Dropout(0.5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Here we have only created 2 hidden layers. based on the scenario or experements one can create more hidden layers or leave it to 1","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Adding the output layer\n##### Units will be 1 as this is the output layer and we are just giving 1 output either Y or N\n##### Use activation = softmax if the model has more than 2 classifications","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.add(Dense(units = 1 , kernel_initializer = 'uniform' , activation = 'sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compiling the ANN\n##### Using 'binary_crossentropy' as there are only 2 outcomes, Y or N\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fitting the training set to the ANN\n##### Say we have 230 items in the training set. batch size of 10 means that we will send 10 items per iterations.\n##### The no. of iterations would be 230/10 = 23\n##### All these 23 iterations will be part of 1 epoch","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(X_train , y_train , batch_size = 10 , epochs = 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting the results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(X_test)  ### will give the probability as the output\n\ny_pred = (y_pred > 0.5) ### to see the true and false results\ny_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Making the confusion matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluating the ANN ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\n\ndef build_classifier ():\n    classifier = Sequential()\n    classifier.add(Dense(units = 12 , kernel_initializer = 'uniform' , activation = 'relu' , input_dim = 20))\n    classifier.add(Dropout(0.3))\n    classifier.add(Dense(units = 12 , kernel_initializer = 'uniform' , activation = 'relu'))\n    classifier.add(Dropout(0.3))\n    classifier.add(Dense(units = 1 , kernel_initializer = 'uniform' , activation = 'sigmoid'))\n    classifier.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n    return classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10 , epochs = 100)\naccuracies = cross_val_score(estimator=classifier, X = X_train, y = y_train , cv = 10, n_jobs=1,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = accuracies.mean()\nvariance = accuracies.std()\nprint(mean , variance)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Improving the ANN\n##### Use dropout if required and in case of overfitting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\ndef build_classifier (optimizer):\n    classifier = Sequential()\n    classifier.add(Dense(units = 11 , kernel_initializer = 'uniform' , activation = 'relu' , input_dim = 20))\n    classifier.add(Dropout(0.4))\n    classifier.add(Dense(units = 11 , kernel_initializer = 'uniform' , activation = 'relu'))\n    classifier.add(Dropout(0.4))\n    classifier.add(Dense(units = 11 , kernel_initializer = 'uniform' , activation = 'relu'))\n    classifier.add(Dropout(0.4))\n    classifier.add(Dense(units = 1 , kernel_initializer = 'uniform' , activation = 'sigmoid'))\n    classifier.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n    return classifier\n\nclassifier = KerasClassifier(build_fn = build_classifier)\nparameter = {'batch_size' : [32,35,38],\n             'epochs' : [50,100,500],\n            'optimizer' : ['adam','rmsprop']}\ngrid_search = GridSearchCV(estimator = classifier, param_grid = parameter,scoring = 'accuracy',cv=10)\ngrid_search = grid_search.fit(X_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking the best params for the ANN model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"best_parameters = grid_search.best_params_\nbest_accuracy = grid_search.best_score_\nprint(best_parameters,\n     best_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}