{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, mean_absolute_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegressionCV\n\nfrom imblearn.under_sampling import RandomUnderSampler\nimport numpy as np\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading Input","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Exploration","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Check for linerity","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First we will check if features correlate with each other. \nEasy can use function pairplot to visualize it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n       'pH', 'sulphates', 'alcohol']])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see some features have linear dependency. In this case we need to check there correlation,\nin case if it is high, than we will drop on of it or using two of them create new feature.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Check linear relationship between the features and the target.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df, x_vars=['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n       'pH', 'sulphates', 'alcohol'], y_vars='quality')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,8))\n\ncorrelation = df.corr()\nsns.heatmap(correlation, cmap='coolwarm', annot=True, fmt=\".2f\")\n\nplt.xticks","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check dataset classes balance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['quality'], data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, labels are not balanced. So we need first to transform it to binary labels and unsample it","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['bad', 'good']\nbins = [2,6.5,8]\ndf['quality'] = pd.cut(df['quality'], bins=bins, labels=labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_enc = LabelEncoder()\ndf['quality'] = label_enc.fit_transform(df['quality'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Upsample dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('quality', axis=1)\ny = df['quality']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resampler = RandomUnderSampler(random_state=0, replacement=True)\nresampler.fit(X,y)\nX_resampled, y_resampled = resampler.fit_resample(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y_resampled)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have balanced dataset","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data PreProcessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_resampled.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split dataset on train and test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normalize data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model training","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = LogisticRegressionCV(cv=5,random_state=0)\nmodel2.fit(X_train,y_train)\npred2 = model2.predict(X_test)\nprint(mean_absolute_error(y_test,pred2))\nprint(accuracy_score(y_test,pred2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,pred2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = RandomForestClassifier(n_estimators=50, max_depth=10, max_features='log2')\n\nparam_grid = {\n    'n_estimators' : [50,1000],\n    'max_depth': [1,100],\n    'max_features': ['auto', 'sqrt', 'log2']\n}\n\n\nCV_rfc = GridSearchCV(estimator=model1, param_grid=param_grid, cv= 5)\nCV_rfc.fit(X, y)\nprint (CV_rfc.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = RandomForestClassifier(n_estimators=50, max_depth=100, max_features='log2')\n\nmodel1.fit(X_train,y_train)\npred1 = model1.predict(X_test)\nprint(mean_absolute_error(y_test,pred1))\nprint(accuracy_score(y_test,pred1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,pred1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gradient Boosting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = GradientBoostingClassifier(n_estimators=40,  learning_rate=0.2, max_depth=1)\n\nclf.fit(X_train,y_train)\npred3 = clf.predict(X_test)\nprint(mean_absolute_error(y_test,pred3))\nprint(accuracy_score(y_test,pred3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,pred3))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}