{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sports Data Analysis using Deep Learning concepts","metadata":{}},{"cell_type":"markdown","source":"### USECASE 1 : Predicting Final Score of the match","metadata":{}},{"cell_type":"markdown","source":"### Importing needed libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/ipl-cricket-dataset/deliveries.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Factorizing all Categoical Variables","metadata":{}},{"cell_type":"code","source":"batting_team_factorized, batting_team_categories = pd.factorize(df['batting_team'])\ndf['batting_team'] = batting_team_factorized\n\nbowling_team_factorized, bowling_team_categories = pd.factorize(df['bowling_team'])\ndf['bowling_team'] = bowling_team_factorized\n\nbatsman_factorized, batsman_categories = pd.factorize(df['batsman'])\ndf['batsman'] = batsman_factorized\n\nbowler_factorized, bowler_categories = pd.factorize(df['bowler'])\ndf['bowler'] = bowler_factorized\n\nnon_striker_factorized, non_striker_categories = pd.factorize(df['non_striker'])\ndf['non_striker'] = non_striker_factorized\n\nplayer_dismissed_factorized, player_dismissed_categories = pd.factorize(df['player_dismissed'])\ndf['player_dismissed'] = player_dismissed_factorized","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Grouping the data by match id and innings to find out total runs scored in each innings and merging it with original dataframe","metadata":{}},{"cell_type":"code","source":"df_Sum = df.groupby(['match_id', 'inning']).sum()\n\ndf_TotalRuns = df_Sum[['total_runs']]\n\ndf2 = pd.merge(df,df_TotalRuns, on=['match_id','inning'])\n\ndf2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Defining 4 new arrays with np.zeros. Now adding the logic for the innings which is being played and computing the wickets bowl bowled and total runs scored in that innnings","metadata":{}},{"cell_type":"code","source":"current_score = np.zeros(np.shape(batting_team_factorized)[0])\nballs_bowled = np.zeros(np.shape(batting_team_factorized)[0])\nwickets = np.zeros(np.shape(batting_team_factorized)[0])\nfinal_score = np.zeros(np.shape(batting_team_factorized)[0])\ncurrent_inning = -1\nfor i,rVal in enumerate(df2['match_id']): \n    \n    if df2['inning'][i] != current_inning:\n        current_inning = df2['inning'][i]\n        current_score[i] = df2['total_runs_x'][i]\n        if df2['player_dismissed'][i]==-1:\n            wickets[i] = 0\n        else:\n            wickets[i] = 1\n            \n    else:\n        current_score[i] = df2['total_runs_x'][i] + current_score[i-1]\n        if df2['player_dismissed'][i]!=-1:\n            wickets[i] = wickets[i-1] + 1        \n        else:\n            wickets[i] = wickets[i-1]\n    \n    balls_bowled[i] = (df2['over'][i] * 6) + df2['ball'][i]\n    final_score[i] = df2['total_runs_y'][i]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ### Here we are making an array X which conist of current score, balls bowled, wickets taken this would be our training data and final score would be our target variable. Here training data has been reshaped to 3d for RNN model","metadata":{}},{"cell_type":"code","source":"X = np.zeros((np.shape(batting_team_factorized)[0],3))\nX[:,0] = current_score\nX[:,1] = balls_bowled\nX[:,2] = wickets\nprint(X.shape)\nprint(final_score.shape)\nprint(type(X))\nprint(type(final_score))\nprint(X.shape)\nprint(X)\nprint(final_score)\nX = np.reshape(X, (X.shape[0], 1, X.shape[1]))\nprint(X.shape)\n#print(final_score.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### For the sequential model we have added a simple RNN layer and 2 dense layers where the last one acts as the output layer. Here for compilation we have used loss fuction as mean squared error and optimizer as adam. Further as it is a regression model we have used metrics as mse. (Without Regularization)","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Input,LSTM,SimpleRNN\nfrom tensorflow.keras.optimizers import SGD\nimport tensorflow as tf\ntf.random.set_seed(0)\nimport matplotlib.pyplot as plt\nmodel = Sequential()\nmodel.add(SimpleRNN(128,activation=\"relu\",input_shape = (1,3),return_sequences=True))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(1, activation='relu'))\nmodel.compile(loss='mse', optimizer='adam',metrics=['mse'])\nmodel.summary()\n# Fit and test the model by randomly splitting it \n# 67% of the data for training and 33% of the data for validation\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We have fitted the model below with batch size as 128 , epoch as 50 and validation split as 0.33 which will split the train test data as 67% and 33% respectively.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nplot_model(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X, final_score, batch_size=128, epochs=50,validation_split=0.33)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here we have added a scatter plot of the original values and the predicted values","metadata":{}},{"cell_type":"code","source":"history_dict = model.history.history\nloss_value = history_dict['loss']\nval_loss_value = history_dict['val_loss']\nepochs = range(1, len(loss_value) + 1)\nplt.plot(epochs, loss_value, 'b', label='Training Loss')\nplt.plot(epochs, val_loss_value, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred = model.predict(X)\n\nimport matplotlib.pyplot as plt\nplt.scatter(final_score,Y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here we have shown the predictions with the help of dummy data created by us.\n### Here [210,19*6+6,0] stands for 210 = current score, 19 = overs bowled, 0= wickets fallen.\n### So as we can se based on this values our final score predicted at the end of 20 overs would be 227 .\n### Similary we have predicted for 2 other scenarios.","metadata":{}},{"cell_type":"code","source":"dummyData = [[210,19*6+6,0],[150,15*6+6,5],[130,12*6+6,9]]\n#np.shape(dummyData)\n#np.shape(X)\ndummyData=np.array(dummyData)\ndummyData = np.reshape(dummyData, (dummyData.shape[0], 1, dummyData.shape[1]))\npred = model.predict(dummyData)\n\nprint(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Simple RNN with Regularization","metadata":{}},{"cell_type":"code","source":"tf.random.set_seed(0)\nimport matplotlib.pyplot as plt\nmodel1 = Sequential()\nmodel1.add(SimpleRNN(128,activation=\"relu\",input_shape = (1,3),return_sequences=True))\nmodel1.add(Dropout(0.2))\nmodel1.add(Dense(256, activation='relu'))\nmodel1.add(Dense(1, activation='relu'))\nmodel1.compile(loss='mse', optimizer='adam',metrics=['mse'])\nmodel1.summary()\n# Fit and test the model by randomly splitting it \n# 67% of the data for training and 33% of the data for validation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplot_model(model1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model1.fit(X, final_score, batch_size=128, epochs=50,validation_split=0.33)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_dict = model1.history.history\nloss_value = history_dict['loss']\nval_loss_value = history_dict['val_loss']\nepochs = range(1, len(loss_value) + 1)\nplt.plot(epochs, loss_value, 'b', label='Training Loss')\nplt.plot(epochs, val_loss_value, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred = model1.predict(X)\n\nimport matplotlib.pyplot as plt\nplt.scatter(final_score,Y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here [210,19*6+6,0] stands for 210 = current score, 19 = overs bowled, 0= wickets fallen.\n### Here we can see that with regularized input the final prediction is lower than unregularized","metadata":{}},{"cell_type":"code","source":"dummyData = [[210,19*6+6,0],[150,15*6+6,5],[130,12*6+6,9]]\n#np.shape(dummyData)\n#np.shape(X)\ndummyData=np.array(dummyData)\ndummyData = np.reshape(dummyData, (dummyData.shape[0], 1, dummyData.shape[1]))\npred = model1.predict(dummyData)\n\nprint(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### USECASE 2 : Predicting Result of the Match","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/cricket-world-cup-2019-player-analysis/ODI_Match_Results.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Removing Unwanted columns","metadata":{}},{"cell_type":"code","source":"df=df.drop(['Unnamed: 0','BR','Start Date'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Removing the records with no match results","metadata":{}},{"cell_type":"code","source":"df=df[~(df['Result'] == 'n/r')]\ndf=df[~(df['Result'] == 'aban')]\ndf=df[~(df['Result'] == 'tied')]\ndf=df[~(df['Result'] == 'canc')]\ndf=df[~(df['Result'] == '-')]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.reset_index(inplace=True)\ndf=df.drop(['index'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cleaning the data ","metadata":{}},{"cell_type":"code","source":"df['Match_ID'] = df['Match_ID'].str.replace('ODI #', '')\ndf['Opposition'] = df['Opposition'].str.replace('v ', '')\ndf['Bat'] = df['Bat'].str.replace('st', '')\ndf['Bat'] = df['Bat'].str.replace('nd', '')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Factorizing the home team and opossition in such a way that same label is encoded to the same team (India should be 0 in both opposition and home team)","metadata":{}},{"cell_type":"code","source":"f = pd.factorize(df[['Opposition','Country']].stack().drop_duplicates().sort_index(level=1))\ns1 = pd.Series(f[0], index=f[1])\ndf=df.assign(**df.apply(lambda x: x.map(s1)).add_suffix('_ID'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df.drop(['Result_ID','Margin_ID','Toss_ID','Bat_ID','Ground_ID','Match_ID_ID','Country_ID_ID'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Factorizing other attributes of the data","metadata":{}},{"cell_type":"code","source":"ground_factorized,ground_categories = pd.factorize(df['Ground'])\ntoss_factorized,toss_categories = pd.factorize(df['Toss'])\nresult_factorized,result_categories = pd.factorize(df['Result'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Ground'] = ground_factorized\ndf['Toss'] = toss_factorized\ndf['Result'] = result_factorized\narr = df['Country_ID'].to_numpy()\narr1=df['Opposition_ID'].to_numpy()\nprint(result_categories)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df.drop(['Margin','Country','Opposition'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here we are taking toss , ground on which the match is played Home team and opposition. We have taking result as our output variable so we could classify if the team has won or lost the match","metadata":{}},{"cell_type":"code","source":"X = np.zeros((np.shape(arr)[0],4))\nX[:,0] = toss_factorized\nX[:,1] = ground_factorized\nX[:,2] = arr\nX[:,3] = arr1\nprint(X.shape)\nprint(result_factorized.shape)\nprint(type(X))\nprint(type(result_factorized))\nprint(X.shape)\nprint(X)\nprint(result_factorized)\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX=sc.fit_transform(X)\nX = np.reshape(X, (X.shape[0], 1, X.shape[1]))\nprint(X.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here for the Sequential model we have 2 LSTM model and 2 dense layer were added further with last dense layer having signoid functiod as activator working as output layer (LSTM)","metadata":{}},{"cell_type":"code","source":"tf.random.set_seed(42)\nmodel1 = Sequential()\nmodel1.add(LSTM(128,activation=\"relu\",input_shape = (1,4),return_sequences=True))\nmodel1.add(LSTM(128, activation='relu'))\nmodel1.add(Dense(128, activation='relu'))\nmodel1.add(Dense(1, activation='sigmoid'))\nmodel1.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\nmodel1.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model1.fit(X,result_factorized,epochs=50,validation_split=0.33)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Here for the Sequential model we have 2 LSTM model with drop out set to 0.5 for regularization and reduce overfitting and 2 dense layer were added further with last dense layer having signoid functiod as activator working as output layer (Regularized LSTM)","metadata":{}},{"cell_type":"code","source":"history_dict = model1.history.history\nloss_value = history_dict['loss']\nval_loss_value = history_dict['val_loss']\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\nepochs = range(1, len(loss_value) + 1)\nplt.plot(epochs, loss_value, 'b', label='Training Loss')\nplt.plot(epochs, val_loss_value, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.figure()\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Input,LSTM,SimpleRNN,GRU\nfrom tensorflow.keras.optimizers import SGD\nimport tensorflow as tf\ntf.random.set_seed(42)\nimport matplotlib.pyplot as plt\nmodel = Sequential()\nmodel.add(LSTM(128,activation=\"relu\",input_shape = (1,4),return_sequences=True))\nmodel.add(Dropout(0.5))\nmodel.add(LSTM(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We have fitted the model below without batch size as the data was small , epoch as 50 and validation split as 0.33 which will split the train test data as 67% and 33% respectively","metadata":{}},{"cell_type":"code","source":"plot_model(model, to_file=\"model.png\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X,result_factorized,epochs=50,validation_split=0.33)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Below we have shown training and validation Loss as well as Acurracy graph","metadata":{}},{"cell_type":"code","source":"history_dict = model.history.history\nloss_value = history_dict['loss']\nval_loss_value = history_dict['val_loss']\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\nepochs = range(1, len(loss_value) + 1)\nplt.plot(epochs, loss_value, 'b', label='Training Loss')\nplt.plot(epochs, val_loss_value, 'r', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.figure()\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We can see the result classified as won and loss below","metadata":{}},{"cell_type":"code","source":"Y_pred = model.predict_classes(X)\nY_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Taking user input for The two teams home and opposition as well as the team which won the toss and on what ground the match is played and further predicting that the home team would win or lose","metadata":{}},{"cell_type":"code","source":"# toss\nwhile True:\n  try:\n    t= int(input(\"Input toss result 0 or 1: \"))\n    if t==1 or t==0:\n      print(\"toss value entered successfully...\")\n      break;\n    else:\n      print(\"toss value should be either 0 or 1\")      \n  except ValueError:\n    print(\"Provide an appropriate integer value...\")\n    continue\n\n#ground   \nwhile True:\n  try:\n    g= int(input(\"Input ground code (0-96): \"))\n    if g>=0 and g<=96:\n      print(\"ground code entered successfully...\")\n      break;\n    else:\n      print(\"ground code should be between 0-96\")      \n  except ValueError:\n    print(\"Provide an appropriate integer value...\")\n    continue\n\n#country\nwhile True:\n  try:\n    c= int(input(\"Input home country code(0-16): \"))\n    if c>=0 or c<=16:\n      print(\"home country code entered successfully...\")\n      break;\n    else:\n      print(\"country code value should be between 0 and 16\")      \n  except ValueError:\n    print(\"Provide an appropriate integer value...\")\n    continue\n    \n    \n#opposition\n\nwhile True:\n  try:\n    o= int(input(\"Input opposition country code(0-16): \"))\n    if o>=0 or c<=16:\n      print(\"opposition country code entered successfully...\")\n      break;\n    else:\n      print(\"opposition code value should be between 0 and 16\")      \n  except ValueError:\n    print(\"Provide an appropriate integer value...\")\n    continue","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Here we have taken toss would be won as it has set to be 1 ground to be Kolkata Country to be India Opposition to be Pakistan .The match has been predicted to be won by India.****","metadata":{}},{"cell_type":"code","source":"dummyData = [[t,g,c,o]]\n#np.shape(dummyData)\n#np.shape(X)\ndummyData=np.array(dummyData)\ndummyData = np.reshape(dummyData, (dummyData.shape[0], 1, dummyData.shape[1]))\npred = model.predict_classes(dummyData)\n\nprint(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}