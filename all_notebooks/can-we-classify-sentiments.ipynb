{"cells":[{"metadata":{},"cell_type":"markdown","source":"Analyzing sentiments related to various products such as Tablet, Mobile and various other gizmos can be fun and difficult especially when collected across various demographics around the world. Analyzing these sentiments will not only help us serve the customers better but can also reveal lot of customer traits present/hidden in the reviews.\n\nSo the task of this dataset is to correctly classify product description sentiment: our goal,insted, is to investigate which supervised machine learning methods are best suited to solve it.\n\n\n# Table of contents\n\n* [Loading data...](#obj)\n* [What we find in train set?](#eda)\n* [Text Cleaning](#textcleaning)\n* [Text Analysis](#textanalysis)\n* [Text Classification](#textclassification)\n* [What we find in test set?](#eda2****)\n* [Submission](#submission)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Data Manipulation & Visualization\nimport os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns # used for plot interactive graph. \nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\n\n# Text Manipulation\nimport re\nfrom wordcloud import STOPWORDS\nfrom nltk import FreqDist, word_tokenize\nfrom nltk import bigrams, trigrams\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nstopwords = set(STOPWORDS)\n\n# Machine Learning\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix,mean_squared_error,mean_absolute_error,log_loss,accuracy_score,classification_report\nfrom sklearn.metrics import precision_score\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='obj'></a>\n# Loading data..."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/product-sentiment-classification/Participants_Data/Train.csv\")\ntest = pd.read_csv(\"../input/product-sentiment-classification/Participants_Data/Test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# we take only what we need\ntrain = train[['Product_Description','Product_Type','Sentiment']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='eda'></a>\n# What we find in the train set?"},{"metadata":{},"cell_type":"markdown","source":"**Positive sentiment is focused only on 9th Product and overall the most present sentiment is Positive(2) and Neutral(3)**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(ncols=2,nrows=1,dpi=100,figsize=(17,5))\nsns.countplot(data=train,x=\"Product_Type\",hue=\"Sentiment\",edgecolor=\"black\",ax=ax[0],linewidth=2)\nax[0].legend(loc=\"upper left\",labels=[\"Cannot say\",\"Negative\",\"Positive\",\"No sentiment\"])\nax[0].set_title('Sentiment by product in train set',size=17)\nax[0].set_xlabel(\"Product type\")\n\nsns.countplot(data=train,x=\"Sentiment\",edgecolor=\"black\",ax=ax[1],linewidth=2)\nax[1].legend(loc=\"upper left\")\nax[1].set_title('Sentiment distribution in train set',size=17)\nax[1].set_xticklabels([\"Cannot say\",\"Negative\",\"Positive\",\"No sentiment\"])\nax[1].set_xlabel(\"\")\n\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='textcleaning'></a>\n# Text Cleaning"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"test_str = train.loc[0, 'Product_Description']\n\ndef clean_text(text):\n    text = re.sub(r'\\n',' ', text) # Remove line breaks\n    text=  re.sub('@mention',' ', text )\n    text=  re.sub('{link}',' ', text )\n    text=  re.sub('Ûª',' ', text )\n    text=  re.sub('  ',' ', text )\n    text=  re.sub('RT',' ', text )\n    text=  re.sub('//',' ', text )\n    text=  re.sub('&quot',' ', text )\n    text=  re.sub('&amp',' ', text )\n    text=  re.sub(r'[^\\w\\s]',' ', text )\n    text=  re.sub(' +',' ', text )\n    return text\n\ndef process_text(df):\n    df['description'] = df['Product_Description'].apply(lambda x: clean_text(x))\n    return df\n\nprint(\"Original text: \" + test_str)\nprint(\"Cleaned text: \" + clean_text(test_str))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train = process_text(train)\ntest = process_text(test)\ntrain.drop('Product_Description',1,inplace=True)\ntest.drop('Product_Description',1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='textanalysis'></a>\n# Text Analysis"},{"metadata":{},"cell_type":"markdown","source":"## Top 5 Words"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nword_freq = FreqDist(w for w in word_tokenize(' '.join(train['description']).lower()) if \n                     (w not in stopwords) & (w.isalpha()))\ndf_word_freq = pd.DataFrame.from_dict(word_freq, orient='index', columns=['count'])\ntop20w = df_word_freq.sort_values('count',ascending=False).head(5)\nlast20w=df_word_freq.sort_values('count',ascending=False).tail(5)\n\nsns.barplot(top20w['count'],top20w.index,color='purple',edgecolor=\"black\",linewidth=2)\nplt.title(\"Top 5 words in train\",size=17)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Top 10 Bigrams and Trigrams"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig,axes=plt.subplots(ncols=2,figsize=(17,5),dpi=100)\n###bigrams\nbigram = list(bigrams([w for w in word_tokenize(' '.join(train['description']).lower()) if \n              (w not in stopwords) & (w.isalpha())]))\nfq = FreqDist(bg for bg in bigram)\nbgdf = pd.DataFrame.from_dict(fq, orient='index', columns=['count'])\nbgdf.index = bgdf.index.map(lambda x: ' '.join(x))\nbgdf = bgdf.sort_values('count',ascending=False)\n\n#trigrams\ntrigram = list(trigrams([w for w in word_tokenize(' '.join(train['description']).lower()) if \n              (w not in stopwords) & (w.isalpha())]))\ntr_fq = FreqDist(bg for bg in trigram)\ntrdf = pd.DataFrame.from_dict(tr_fq, orient='index', columns=['count'])\ntrdf.index = trdf.index.map(lambda x: ' '.join(x))\ntrdf = trdf.sort_values('count',ascending=False)\n\nsns.barplot(bgdf.head(10)['count'], bgdf.index[:10], ax=axes[1],color='green',edgecolor='black',linewidth=2)\nsns.barplot(trdf.head(10)['count'], trdf.index[:10],ax=axes[0], color='red',edgecolor='black',linewidth=2)\n\naxes[0].set_title('Top 10 Trigrams',size=18)\naxes[1].set_title('Top 10 Bigrams',size=18)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## WordCloud"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"d = '../input/masks-for-wordcloud/'\ncomments_mask = np.array(Image.open(d + 'oval.jpg'))\n\nlong_string = ','.join(list(train['description'].values))\nwordcloud = WordCloud(background_color='black',max_words=500, contour_width=5, contour_color='black',\n                      width=1000,height=200,stopwords=stopwords,mask=comments_mask)\nwordcloud.generate(str(long_string))\nwordcloud.to_image()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='textclassification'></a>\n# Text Classification"},{"metadata":{},"cell_type":"markdown","source":"We are now ready to experiment with different machine learning models, evaluate their accuracy and find the source of any potential issues.\nWe will benchmark the following five models:\n* (Multinomial) Naive Bayes\n* Logistic Regression\n* Linear Support Vector Machine\n* Random Forest\n* XGB Classifier\n\n**For evaluating our models performance we must take into account the strong label imbalance; for this purpose its better to choose an alternative metrics than standard accuracy:**\n* Precision (tp / (tp + fp) ) measures the ability of a classifier to identify only the correct instances for each class.\n\n**Since we need to \"weight\" the score, we averaging precision weighted by label**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = train['description']\ny = train['Sentiment']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Multinomial NB"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"nb = Pipeline([('vect', TfidfVectorizer()),\n               ('tfidf', TfidfTransformer()),\n               ('clf', MultinomialNB())\n              ])\n\nnb.fit(X_train, y_train)\n\ny_pred = nb.predict(X_test)\n\nprint(\"_\"*25+\"Classification Report\"+\"_\"*25)\nprint(classification_report(y_pred,y_test,target_names=['Cannot say','Negative','Positive','No sentiment'],zero_division=0))\nprint(\"_\"*25+\"Evaluation Metrics\"+\"_\"*25)\nprint(\"\\n\")\nprint(\"Accuracy: %f\" % accuracy_score(y_pred,y_test))\nprint(\"Weighted Precision :%f\" % precision_score(y_pred,y_test,average=\"weighted\"))\n\ncm=confusion_matrix(y_pred,y_test)\ng=sns.heatmap(cm,annot=True,fmt='d',linewidths=1,linecolor='black',\n                  annot_kws={\"size\":14},cmap='viridis',cbar=False)\ng.set_xticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 15,rotation=45)\ng.set_yticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 8,rotation=45)\n\nplt.xlabel('Actual',size=16)\nplt.ylabel('Predicted',size=16)\nplt.title('Confusion Matrix \\n Naive Bayes',size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"lr = Pipeline([('vect', TfidfVectorizer()),\n               ('tfidf', TfidfTransformer()),\n               ('clf', LogisticRegression())\n              ])\n\nlr.fit(X_train, y_train)\n\ny_pred = lr.predict(X_test)\n\nprint(\"_\"*25+\"Classification Report\"+\"_\"*25)\nprint(classification_report(y_pred,y_test,target_names=['Cannot say','Negative','Positive','No sentiment'],zero_division=0))\nprint(\"_\"*25+\"Evaluation Metrics\"+\"_\"*25)\nprint(\"\\n\")\nprint(\"Accuracy: %f\" % accuracy_score(y_pred,y_test))\nprint(\"Weighted Precision :%f\" % precision_score(y_pred,y_test,average=\"weighted\"))\n\ncm=confusion_matrix(y_pred,y_test)\ng=sns.heatmap(cm,annot=True,fmt='d',linewidths=1,linecolor='black',\n                  annot_kws={\"size\":14},cmap='Spectral',cbar=False)\ng.set_xticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 15,rotation=45)\ng.set_yticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 8,rotation=45)\n\nplt.xlabel('Actual',size=16)\nplt.ylabel('Predicted',size=16)\nplt.title('Confusion Matrix \\n Logistic Regression',size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Linear SVC"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"lsvc = Pipeline([('vect', TfidfVectorizer()),\n               ('tfidf', TfidfTransformer()),\n               ('clf', LinearSVC())\n              ])\n\nlsvc.fit(X_train, y_train)\n\ny_pred = lsvc.predict(X_test)\n\nprint(\"_\"*25+\"Classification Report\"+\"_\"*25)\nprint(classification_report(y_pred,y_test,target_names=['Cannot say','Negative','Positive','No sentiment'],zero_division=0))\nprint(\"_\"*25+\"Evaluation Metrics\"+\"_\"*25)\nprint(\"\\n\")\nprint(\"Accuracy: %f\" % accuracy_score(y_pred,y_test))\nprint(\"Weighted Precision :%f\" % precision_score(y_pred,y_test,average=\"weighted\"))\n\n\ncm=confusion_matrix(y_pred,y_test)\ng=sns.heatmap(cm,annot=True,fmt='d',linewidths=1,linecolor='black',\n                  annot_kws={\"size\":14},cmap='Blues',cbar=False)\ng.set_xticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 15,rotation=45)\ng.set_yticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 8,rotation=45)\n\nplt.xlabel('Actual',size=16)\nplt.ylabel('Predicted',size=16)\nplt.title('Confusion Matrix \\n Linear SVC',size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"rf = Pipeline([('vect', TfidfVectorizer()),\n               ('tfidf', TfidfTransformer()),\n               ('clf', RandomForestClassifier(n_estimators=300))\n              ])\n\nrf.fit(X_train, y_train)\n\ny_pred = rf.predict(X_test)\n\nprint(\"_\"*25+\"Classification Report\"+\"_\"*25)\nprint(classification_report(y_pred,y_test,target_names=['Cannot say','Negative','Positive','No sentiment'],zero_division=0))\nprint(\"_\"*25+\"Evaluation Metrics\"+\"_\"*25)\nprint(\"\\n\")\nprint(\"Accuracy: %f\" % accuracy_score(y_pred,y_test))\nprint(\"Weighted Precision :%f\" % precision_score(y_pred,y_test,average=\"weighted\"))\n\n\ncm=confusion_matrix(y_pred,y_test)\ng=sns.heatmap(cm,annot=True,fmt='d',linewidths=1,linecolor='black',\n                  annot_kws={\"size\":14},cmap='BuGn',cbar=False)\ng.set_xticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 15,rotation=45)\ng.set_yticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 8,rotation=45)\n\nplt.xlabel('Actual',size=16)\nplt.ylabel('Predicted',size=16)\nplt.title('Confusion Matrix \\n Random Forest',size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGB Classifier"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"xgb = Pipeline([('vect', TfidfVectorizer()),\n               ('tfidf', TfidfTransformer()),\n               ('clf', XGBClassifier(objective=\"multi:softmax\",n_estimators=200,learning_rate=0.01))\n              ])\n\nxgb.fit(X_train, y_train)\n\ny_pred = xgb.predict(X_test)\n\nprint(\"_\"*25+\"Classification Report\"+\"_\"*25)\nprint(classification_report(y_pred,y_test,target_names=['Cannot say','Negative','Positive','No sentiment'],zero_division=0))\nprint(\"_\"*25+\"Evaluation Metrics\"+\"_\"*25)\nprint(\"\\n\")\nprint(\"Accuracy: %f\" % accuracy_score(y_pred,y_test))\nprint(\"Weighted Precision :%f\" % precision_score(y_pred,y_test,average=\"weighted\"))\n\n\ncm=confusion_matrix(y_pred,y_test)\ng=sns.heatmap(cm,annot=True,fmt='d',linewidths=1,linecolor='black',\n                  annot_kws={\"size\":14},cmap='Set1',cbar=False)\ng.set_xticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 15,rotation=45)\ng.set_yticklabels(['Cannot say','Negative','Positive','No sentiment'],fontsize = 8,rotation=45)\n\nplt.xlabel('Actual',size=16)\nplt.ylabel('Predicted',size=16)\nplt.title('Confusion Matrix \\n XGB Classifier',size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Metrics:\n\n* #### Multinomial NB - Accuracy:0.66 - Weighted Precision: 0.88\n* #### Logistic Regression - Accuracy:0.67 - Weighted Precision: 0.79\n* #### Linear SVC - Accuracy:0.67 - Weighted Precision: 0.71\n* #### Random Forest - Accuracy:0.67 - Weighted Precision: 0.77\n* #### Multinomial NB - Accuracy:0.65 - Weighted Precision: 0.86\n\n### Naive Bayes win!"},{"metadata":{},"cell_type":"markdown","source":"<a id='eda2'></a>\n# What we find in test set?"},{"metadata":{},"cell_type":"markdown","source":"### Let'see the predicted sentiment distribution in test set ( Will it be real? According to Multinomial Naive Bayes ): "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"test['Sentiment']= nb.predict(test.description)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig,ax = plt.subplots(ncols=2,nrows=1,dpi=100,figsize=(17,5))\nsns.countplot(data=test,x=\"Product_Type\",hue=\"Sentiment\",edgecolor=\"black\",ax=ax[0],linewidth=2)\nax[0].legend(loc=\"upper left\",labels=[\"Negative\",\"Positive\",\"No sentiment\"])\nax[0].set_title('Sentiment by Product in test set',size=17)\nax[0].set_xlabel(\"Product type\")\n\nsns.countplot(data=test,x=\"Sentiment\",edgecolor=\"black\",ax=ax[1],linewidth=2)\nax[1].legend(loc=\"upper left\")\nax[1].set_title('Sentiment test set',size=17)\nax[1].set_xticklabels([\"Negative\",\"Positive\",\"No sentiment\"])\nax[1].set_xlabel(\"\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='submission'></a>\n\n# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(nb.predict_proba(test.description))\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('sample_submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### This is just a little example on how NLP multi-class classification can be made, there are a lot of way to improve on this.\n### If you liked please upvote!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}