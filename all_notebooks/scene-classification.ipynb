{"cells":[{"metadata":{"_uuid":"b8c61a07-89ff-4de2-a9de-651d34d289e2","_cell_guid":"3e578cce-5c95-4c16-a77c-74344d7ac57d","trusted":true},"cell_type":"markdown","source":"# Project Description\n\n## Scene Classification\n\n> ### The Goal\n\n\n  The goal is to classify each scene and predict what it is\n\n> ### Dataset info's\n\nThis dataset contains about ~25k images from a wide range of natural    scenes from all around the world. The task is to identify which kind of scene can the image be categorized into.\n\n\n### *There are 6 possible labels*\n\n* Buildings\n* Forests\n* Mountains\n* Glacier\n* Street\n* Sea\n\n\n\n> Dataset Source\n\nScene Classification | Kaggle - https://www.kaggle.com/nitishabharathi/scene-classification\n"},{"metadata":{},"cell_type":"markdown","source":"# Importing tools"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport matplotlib.pyplot as plt\nimport os\nimport sklearn\nfrom sklearn.model_selection import  train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arr = pd.read_csv('../input/scene-classification/train-scene classification/train.csv')\narr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create filepaths\nfilepaths = ['../input/scene-classification/train-scene classification/train/' + name for name in arr['image_name']]\nfilepaths[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instances per each label\narr['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn labels in an array\nlabels = arr['label'].to_numpy()\n\n# Extract just the unique labels\nunique_labels = np.unique(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turning each label into a boolean array\nboolean_labels = [label == unique_labels for label in labels]\nboolean_labels[17033]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmax([False, False,  True, False, False, False])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Images experimentation number\nNUM_IMAGES = 1000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spliting the images and labels apart\nX = filepaths\ny = boolean_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spliting the experimentation data in to a training and validation split\nX_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES],\n                                                  y[:NUM_IMAGES],\n                                                  test_size=0.2,\n                                                  random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[:10], y_train[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing Images (Turning them into Tensors)\n\nThe steps that we have to follow to preprocess images\n\n\n\n1.   Take an image filepath\n2.   Use TensorFlow to read the file and save it toa variable\n3.   Turn the images into Tensors\n4.   Normalize the image\n5.   Resize the image\n6.   Return modified image\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Image Size\nIMG_SIZE = 224\n\n# processing images\ndef process_images(image_path, img_size=IMG_SIZE):\n  \"\"\"\n  Takes a file path as an input and turns image into Tensors\n  \"\"\"\n  # Read an image file\n  image = tf.io.read_file(image_path)\n  # Turns image to 3 color channels (RGB)\n  image = tf.image.decode_jpeg(image, channels=3)\n  # Convert color values from 0-255 to 0-1 values\n  image = tf.image.convert_image_dtype(image, tf.float32)\n  # Resize image to (224, 224)\n  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n\n  return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simple function that returns a tuple of (image, label)\ndef get_image_label(image_path, label):\n  \"\"\"\n  Processes image file path and returns a tuple of (image, label)\n  \"\"\"\n  image = process_images(image_path)\n  return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Demo\n(process_images(X[10]), tf.constant(y[10]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Turning the data into Batches\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Batch size\nBATCH_SIZE = 32\n\n# Turn data into batches\ndef create_data_batches(X, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n\n  \"\"\"\n  Create batches of data out of image (X) and labels (y) pairs.\n  Shuffles the data if its training data but doesn't shuffle if it's validation data.\n  Also accepts test data as an input (no labels).\n  \"\"\"\n\n  # If the data is a test data, no labels\n  if test_data: \n\n    print('Creating test data batches.........')\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(X))) # only filepaths (no labels)\n    data_batch = data.map(process_images).batch(BATCH_SIZE)\n    return data_batch\n  \n  # If the data is a validation dat, no need to shuffle it\n  elif valid_data:\n\n    print('Creating validation data batches......')\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), # filepaths\n                                               tf.constant(y))) # labels\n    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n    return data_batch\n  \n  # if it's a training data\n  else:\n\n    print('Creating training data batches.......')\n    # Turn filepaths and labels into Tensors\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), # filepaths\n                                              tf.constant(y))) # labels\n    # shuffling pathnames before mapping them\n    data = data.shuffle(buffer_size=len(X))\n    # turn each image into tensors and return 32 tuple of (image, label) in each interation \n    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n\n  return data_batch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a training and validation batches\ntrain_data = create_data_batches(X_train, y_train)\nval_data = create_data_batches(X_val, y_val, valid_data=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.element_spec, val_data.element_spec","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input Shape\nINPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] # batch, height, width, color channels\n\n# Output shape\nOUTPUT_SHAPE = len(unique_labels)\n\n# Model URL\nMODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/classification/4\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# A function which builds a Keras model\ndef create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):\n\n  print('Building model with:', MODEL_URL)\n\n  #  Setup the model layers\n  model = tf.keras.Sequential([\n                               hub.KerasLayer(MODEL_URL), # Layer 1 (input layer)\n                               tf.keras.layers.Dense(units=OUTPUT_SHAPE,\n                                                     activation='softmax') # Layer 2 (output layer)\n  ])\n\n  # Compile the model\n  model.compile(\n      loss=tf.keras.losses.CategoricalCrossentropy(),\n      optimizer=tf.keras.optimizers.Adam(),\n      metrics=['accuracy']\n  )\n\n  # Build the model\n  model.build(INPUT_SHAPE)\n\n  # Returns the built model\n  return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Callbacks\n\nCallbacks are helpers functions that help a model during training, save its progress, checks the progess or stop training early if a its stops improving.\n\nwe will create one for tensorboard to visualize the progress of the model after it finishes training and the other for early stopping which helps prevent our model from training too long.\n"},{"metadata":{},"cell_type":"markdown","source":"## Early Stopping Callback"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Early stopping callback\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n                                                  patience=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_EPOCHS = 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Model\n\nLet's create a function which:\n\n\n\n*   Create a model using \n*   Setup a TensorBoard callback using\n*   Fit the training set, validation set, number epochsto trian and calllbacks\n*   Return the model\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model():\n  \"\"\"\n  Trains a given model and returns the trained version.\n  \"\"\"\n  # Create a model\n  model = create_model()\n\n  # Fit the model to the data passing it the callbacks we created \n  model.fit(\n      x=train_data,\n      epochs=NUM_EPOCHS,\n      validation_data=val_data,\n      validation_freq=1,\n      callbacks=[early_stopping]\n  )\n\n  # Return the fitted model\n  return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Traning the 1000 images model\nmodel = train_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making prediction on the validation data\npredictions = model.predict(val_data, verbose=1)\npredictions ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Unbatichying the validation data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The labels were not in the right order, so I had to reorder them\nclasses = ['Buildings', 'Forests','Glacier','Mountains','Sea','Street']  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unbatching a batch dataset\ndef unbatchify(data):\n  \"\"\"\n  Takes a btached dataset of (image, label) Tensors and returns\n  separate arrays of images and labels.\n  \"\"\"\n\n  images = []\n  labels = []\n  # Loop through unbatched data\n  for image, label in data.unbatch().as_numpy_iterator():\n    images.append(image)\n    labels.append(classes[np.argmax(label)])\n  return images, labels\n\n# Unbatchify the validation data\nval_images, val_labels = unbatchify(val_data)\nval_images[2], val_labels[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes[np.argmax(predictions[2])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A function that gets the predicted label\ndef get_pred_label(prediction_probabilities):\n  \"\"\"\n  Turns an array of prediction probabilitties into a label\n  \"\"\"\n  return classes[np.argmax(prediction_probabilities)]\n\n# Get a predicted label based on an array of prediction probabilites\npred_label = get_pred_label(predictions[20])\npred_label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing the predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_pred(prediction_probabilities, labels, images, n=1):\n  \"\"\"\n  View the prediction, ground truth and image for simple n\n  \"\"\"\n  pred_prob, true_label, image = prediction_probabilities[n], labels[n],images[n]\n\n  # Get the pred label\n  pred_label = get_pred_label(pred_prob)\n\n  # Plot image &remove ticks \n  plt.imshow(image)\n  plt.xticks([])\n  plt.yticks([])\n\n  # Change the color of the title to green if it's a correct prediction otherwise red\n  if pred_label == true_label:\n    color = \"green\"\n  else:\n    color = \"red\" \n\n  plt.title(\"It think it's a {} {:2.0f}% true value: {}\".format(pred_label,\n                                    np.max(pred_prob)*100,\n                                    true_label),\n                                    color=color)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pred(prediction_probabilities=predictions,\n          labels=val_labels,\n          images=val_images,\n          n=36)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions[36]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train the full model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spliting the data in to a training and validation split\nX_train, X_val, y_train, y_val = train_test_split(X,\n                                                  y,\n                                                  test_size=0.2,\n                                                  random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating batches of data\ntrain_data = create_data_batches(X=X_train, y=y_train)\nval_data = create_data_batches(X=X_val, y=y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training on the full model\nmodel = train_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set = pd.read_csv('../input/scene-classification/test_WyRytb0.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create filepaths\ntest_filepaths = ['../input/scene-classification/train-scene classification/train/' + name for name in test_set['image_name']]\ntest_filepaths[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set = create_data_batches(X=test_filepaths, test_data=True)\ntest_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions = model.predict(test_set,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}