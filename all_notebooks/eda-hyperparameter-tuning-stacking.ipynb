{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-25T14:05:08.435102Z","iopub.execute_input":"2021-07-25T14:05:08.43574Z","iopub.status.idle":"2021-07-25T14:05:14.414353Z","shell.execute_reply.started":"2021-07-25T14:05:08.435634Z","shell.execute_reply":"2021-07-25T14:05:14.413353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\ndata","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:20.615084Z","iopub.execute_input":"2021-07-25T14:05:20.615459Z","iopub.status.idle":"2021-07-25T14:05:20.680465Z","shell.execute_reply.started":"2021-07-25T14:05:20.615427Z","shell.execute_reply":"2021-07-25T14:05:20.679604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:23.785197Z","iopub.execute_input":"2021-07-25T14:05:23.78556Z","iopub.status.idle":"2021-07-25T14:05:23.807021Z","shell.execute_reply.started":"2021-07-25T14:05:23.785529Z","shell.execute_reply":"2021-07-25T14:05:23.806185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:24.625145Z","iopub.execute_input":"2021-07-25T14:05:24.625629Z","iopub.status.idle":"2021-07-25T14:05:24.635568Z","shell.execute_reply.started":"2021-07-25T14:05:24.625597Z","shell.execute_reply":"2021-07-25T14:05:24.634827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.bmi.replace(to_replace=np.nan, value=data.bmi.mean(), inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:28.22934Z","iopub.execute_input":"2021-07-25T14:05:28.229949Z","iopub.status.idle":"2021-07-25T14:05:28.235276Z","shell.execute_reply.started":"2021-07-25T14:05:28.229907Z","shell.execute_reply":"2021-07-25T14:05:28.234638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:28.676908Z","iopub.execute_input":"2021-07-25T14:05:28.677408Z","iopub.status.idle":"2021-07-25T14:05:28.713488Z","shell.execute_reply.started":"2021-07-25T14:05:28.677359Z","shell.execute_reply":"2021-07-25T14:05:28.712613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization","metadata":{}},{"cell_type":"code","source":"labels =data['stroke'].value_counts(sort = True).index\nsizes = data['stroke'].value_counts(sort = True)\n\ncolors = [\"lightblue\",\"red\"]\nexplode = (0.05,0) \n \nplt.figure(figsize=(7,7))\nplt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90,)\n\nplt.title('Customer Churn Breakdown')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:35.069507Z","iopub.execute_input":"2021-07-25T14:05:35.069906Z","iopub.status.idle":"2021-07-25T14:05:35.235274Z","shell.execute_reply.started":"2021-07-25T14:05:35.069876Z","shell.execute_reply":"2021-07-25T14:05:35.234532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.countplot(data=data,x='gender');","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:35.40543Z","iopub.execute_input":"2021-07-25T14:05:35.405816Z","iopub.status.idle":"2021-07-25T14:05:35.550074Z","shell.execute_reply.started":"2021-07-25T14:05:35.405781Z","shell.execute_reply":"2021-07-25T14:05:35.548955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\ndata.plot(kind='scatter', x='age', y='avg_glucose_level', alpha=0.5, color='green', ax=axes[0], title=\"Age vs. avg_glucose_level\")\ndata.plot(kind='scatter', x='bmi', y='avg_glucose_level', alpha=0.5, color='red', ax=axes[1], title=\"bmi vs. avg_glucose_level\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:35.85728Z","iopub.execute_input":"2021-07-25T14:05:35.857619Z","iopub.status.idle":"2021-07-25T14:05:36.355951Z","shell.execute_reply.started":"2021-07-25T14:05:35.857587Z","shell.execute_reply":"2021-07-25T14:05:36.355217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(style=\"ticks\");\npal = [\"#FA5858\", \"#58D3F7\"]\n\nsns.pairplot(data, hue=\"stroke\", palette=pal);\nplt.title(\"stroke\");","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:36.357013Z","iopub.execute_input":"2021-07-25T14:05:36.357375Z","iopub.status.idle":"2021-07-25T14:05:56.634449Z","shell.execute_reply.started":"2021-07-25T14:05:36.357349Z","shell.execute_reply":"2021-07-25T14:05:56.633503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,7))\nsns.heatmap(data.corr(),annot=True);\n","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:56.63615Z","iopub.execute_input":"2021-07-25T14:05:56.63641Z","iopub.status.idle":"2021-07-25T14:05:57.208466Z","shell.execute_reply.started":"2021-07-25T14:05:56.636385Z","shell.execute_reply":"2021-07-25T14:05:57.207692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nstrok=data.loc[data['stroke']==1]\nsns.countplot(data=strok,x='ever_married',palette='inferno');\n","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:57.209903Z","iopub.execute_input":"2021-07-25T14:05:57.210171Z","iopub.status.idle":"2021-07-25T14:05:57.358925Z","shell.execute_reply.started":"2021-07-25T14:05:57.210146Z","shell.execute_reply":"2021-07-25T14:05:57.357455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.countplot(data=strok,x='work_type',palette='cool');\n","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:57.362641Z","iopub.execute_input":"2021-07-25T14:05:57.363029Z","iopub.status.idle":"2021-07-25T14:05:57.519944Z","shell.execute_reply.started":"2021-07-25T14:05:57.362996Z","shell.execute_reply":"2021-07-25T14:05:57.519052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.countplot(data=strok,x='smoking_status',palette='autumn');\n","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:57.521432Z","iopub.execute_input":"2021-07-25T14:05:57.521753Z","iopub.status.idle":"2021-07-25T14:05:57.667266Z","shell.execute_reply.started":"2021-07-25T14:05:57.5217Z","shell.execute_reply":"2021-07-25T14:05:57.666591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.countplot(data=strok,x='Residence_type',palette='Greens');","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:57.669151Z","iopub.execute_input":"2021-07-25T14:05:57.669399Z","iopub.status.idle":"2021-07-25T14:05:57.803308Z","shell.execute_reply.started":"2021-07-25T14:05:57.669375Z","shell.execute_reply":"2021-07-25T14:05:57.802645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.countplot(data=strok,x='heart_disease',palette='Reds');","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:57.804635Z","iopub.execute_input":"2021-07-25T14:05:57.804902Z","iopub.status.idle":"2021-07-25T14:05:57.947729Z","shell.execute_reply.started":"2021-07-25T14:05:57.804877Z","shell.execute_reply":"2021-07-25T14:05:57.946834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.countplot(data=strok,x='hypertension',palette='Pastel2');","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:57.948981Z","iopub.execute_input":"2021-07-25T14:05:57.94927Z","iopub.status.idle":"2021-07-25T14:05:58.083865Z","shell.execute_reply.started":"2021-07-25T14:05:57.949242Z","shell.execute_reply":"2021-07-25T14:05:58.082929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"cat_features = ['work_type', 'gender', 'Residence_type', 'smoking_status', 'ever_married'] # categorical features\nnum_features = ['age', 'avg_glucose_level', 'bmi']                                         # numerical features","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:58.086983Z","iopub.execute_input":"2021-07-25T14:05:58.087298Z","iopub.status.idle":"2021-07-25T14:05:58.091386Z","shell.execute_reply.started":"2021-07-25T14:05:58.087269Z","shell.execute_reply":"2021-07-25T14:05:58.0905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assigning categorical variables to a numerical value\ncat_maps = {'work_type': {'Private':0, 'Self-employed': 1, 'Govt_job':2, 'children':3, 'Never_worked':4},\n            'gender': {'Male':0, 'Female':1},\n            'Residence_type': {'Urban':0, 'Rural':1},\n            'smoking_status': {'formerly smoked':0, 'never smoked':1, 'smokes':2, 'Unknown':3},\n            'ever_married': {'Yes':0, 'No':1}\n}","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:58.092635Z","iopub.execute_input":"2021-07-25T14:05:58.093034Z","iopub.status.idle":"2021-07-25T14:05:58.102327Z","shell.execute_reply.started":"2021-07-25T14:05:58.092997Z","shell.execute_reply":"2021-07-25T14:05:58.101473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['work_type'] = data['work_type'].map(cat_maps['work_type'])\ndata['gender'] = data['gender'].map(cat_maps['gender'])\ndata['Residence_type'] = data['Residence_type'].map(cat_maps['Residence_type'])\ndata['smoking_status'] = data['smoking_status'].map(cat_maps['smoking_status'])\ndata['ever_married'] = data['ever_married'].map(cat_maps['ever_married'])","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:58.103654Z","iopub.execute_input":"2021-07-25T14:05:58.103954Z","iopub.status.idle":"2021-07-25T14:05:58.122495Z","shell.execute_reply.started":"2021-07-25T14:05:58.103928Z","shell.execute_reply":"2021-07-25T14:05:58.121675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:58.125321Z","iopub.execute_input":"2021-07-25T14:05:58.125587Z","iopub.status.idle":"2021-07-25T14:05:58.153573Z","shell.execute_reply.started":"2021-07-25T14:05:58.125561Z","shell.execute_reply":"2021-07-25T14:05:58.15281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into input data and target variable\n\nfeatures = ['age',\n 'hypertension',\n 'heart_disease',\n 'ever_married',\n 'Residence_type',\n 'avg_glucose_level',\n 'bmi',\n 'gender',\n 'work_type',\n 'smoking_status']\n\nlabel = ['stroke']\n\nX = data[features]\ny = data[label]","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:58.154609Z","iopub.execute_input":"2021-07-25T14:05:58.154861Z","iopub.status.idle":"2021-07-25T14:05:58.163577Z","shell.execute_reply.started":"2021-07-25T14:05:58.154838Z","shell.execute_reply":"2021-07-25T14:05:58.162585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.gender=(X.gender.fillna(1))\nX.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:58.164671Z","iopub.execute_input":"2021-07-25T14:05:58.165064Z","iopub.status.idle":"2021-07-25T14:05:58.175488Z","shell.execute_reply.started":"2021-07-25T14:05:58.164954Z","shell.execute_reply":"2021-07-25T14:05:58.174687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into training and validation sets. Stratified split of 80-20 ratio\n\nfrom sklearn.model_selection import train_test_split\nX_train,X_test, y_train,y_test=train_test_split(X, y,test_size=0.2,random_state=42, stratify = y)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:05:58.176407Z","iopub.execute_input":"2021-07-25T14:05:58.176636Z","iopub.status.idle":"2021-07-25T14:05:58.37393Z","shell.execute_reply.started":"2021-07-25T14:05:58.176615Z","shell.execute_reply":"2021-07-25T14:05:58.373198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nSynthetic Minority Oversampling Technique (SMOTE) for handling class imbalance.\nOnly numerical features should be inputted with categorical features untouched\n\n\"\"\"\n\nfrom imblearn.over_sampling import SMOTENC\n\nsmote = SMOTENC([1,2,3,4,7,8,9]) # we pass the index of the input numerical features\nX_train , y_train = smote.fit_resample(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:06:05.530689Z","iopub.execute_input":"2021-07-25T14:06:05.531042Z","iopub.status.idle":"2021-07-25T14:06:06.615187Z","shell.execute_reply.started":"2021-07-25T14:06:05.531014Z","shell.execute_reply":"2021-07-25T14:06:06.614203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = pd.DataFrame(data = X_train, columns = features)\nX_test = pd.DataFrame(data = X_test, columns = features)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:06:10.22059Z","iopub.execute_input":"2021-07-25T14:06:10.220976Z","iopub.status.idle":"2021-07-25T14:06:10.226197Z","shell.execute_reply.started":"2021-07-25T14:06:10.22094Z","shell.execute_reply":"2021-07-25T14:06:10.225208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install category_encoders","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:06:13.452541Z","iopub.execute_input":"2021-07-25T14:06:13.452913Z","iopub.status.idle":"2021-07-25T14:06:21.532408Z","shell.execute_reply.started":"2021-07-25T14:06:13.452884Z","shell.execute_reply":"2021-07-25T14:06:21.531327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Base Models + Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, classification_report, roc_curve, plot_roc_curve, auc, precision_recall_curve, plot_precision_recall_curve, average_precision_score\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold, RandomizedSearchCV\nfrom matplotlib import pyplot\nimport category_encoders as ce","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:06:21.53505Z","iopub.execute_input":"2021-07-25T14:06:21.535341Z","iopub.status.idle":"2021-07-25T14:06:21.829793Z","shell.execute_reply.started":"2021-07-25T14:06:21.535311Z","shell.execute_reply":"2021-07-25T14:06:21.828793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds = 5\n\nskf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001) # Stratified K-Fold Cross Validation","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:06:21.831413Z","iopub.execute_input":"2021-07-25T14:06:21.831717Z","iopub.status.idle":"2021-07-25T14:06:21.835482Z","shell.execute_reply.started":"2021-07-25T14:06:21.831671Z","shell.execute_reply":"2021-07-25T14:06:21.834666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nNumerical features are scaled using Standard Scaling. \nCategorical features are encoded in different ways for different models:\n    > For tree-based models, catboost encoding is used\n    > For linear models, one hot encoding is used\n    > For KNN, categorical features are dropped\n\"\"\"\n\n\ntree_mapper = ColumnTransformer(transformers=[('num', StandardScaler(), num_features),\n                                         ('ce', ce.CatBoostEncoder(), cat_features)\n                                         ], remainder= 'passthrough')\n\nlinear_mapper = ColumnTransformer(transformers=[('num', StandardScaler(), num_features),\n                                         ('ce', ce.OneHotEncoder(), cat_features)\n                                         ], remainder= 'passthrough')\n\nnum_mapper = ColumnTransformer(transformers=[('num', StandardScaler(), num_features)\n                                         ], remainder= 'drop')","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:06:23.291291Z","iopub.execute_input":"2021-07-25T14:06:23.291649Z","iopub.status.idle":"2021-07-25T14:06:23.298619Z","shell.execute_reply.started":"2021-07-25T14:06:23.291614Z","shell.execute_reply":"2021-07-25T14:06:23.297405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = [\n          Pipeline([('mapper', linear_mapper), ('classifier', LogisticRegression())]),\n          Pipeline([('mapper', num_mapper), ('classifier', KNeighborsClassifier())]),\n          Pipeline([('classifier', GaussianNB())]),\n          Pipeline([('classifier', BernoulliNB())]),\n          Pipeline([('mapper', tree_mapper), ('classifier', DecisionTreeClassifier())]),\n          Pipeline([('mapper', tree_mapper), ('classifier', RandomForestClassifier())]),\n          Pipeline([('mapper', tree_mapper), ('classifier', XGBClassifier())]),\n          Pipeline([('mapper', tree_mapper), ('classifier', GradientBoostingClassifier())]),\n          Pipeline([('mapper', linear_mapper), ('classifier', SVC(probability= True))]),\n          Pipeline([('mapper', tree_mapper), ('classifier', AdaBoostClassifier(\n              base_estimator=DecisionTreeClassifier(criterion='entropy',\n                                                      max_depth = None,\n                                                      max_features = None,\n                                                      min_samples_leaf = 1,\n                                                      min_samples_split = 2,\n                                                      random_state = 0)))])\n]\n\nmodel_grids = [\n               [{'classifier__C':[1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 5e-1, 1, 5, 1e1, 5e1, 1e2, 5e2, 1e3],\n                 'classifier__random_state':[0]}],                                 #logistic regression\n               \n               [{'classifier__n_neighbors':[5,7,9,11, 13, 15, 17, 19], \n                 'classifier__metric': ['euclidean', 'manhattan', 'minkowski']}],  #KNN\n               \n               [{'classifier__var_smoothing': [1e-10, 1e-09, 1e-8, 1e-7]}],        #GaussianNB\n\n               [{'classifier__alpha': [1e-2, 1e-1, 1, 1e1, 1e2]}],                 #BernoulliNB\n\n               [{'classifier__criterion':['gini','entropy'],\n                 'classifier__random_state':[0], \n                 'classifier__max_depth' : [3, 5, 8, 10, 15, None], \n                 'classifier__min_samples_split' : [1,2,5,10,15,30],\n                 'classifier__min_samples_leaf': [1,2,5,10], \n                 'classifier__max_features': ['log2', 'sqrt', None]}],             #Decision Tree\n               \n               [{'classifier__criterion':['gini','entropy'],\n                 'classifier__n_estimators': [1000],\n                 'classifier__random_state':[0], \n                 'classifier__max_depth' : [3, 5, 8, 10, 15, None], \n                 'classifier__min_samples_split' : [1,2,5,10,15,30],\n                 'classifier__min_samples_leaf': [1,2,5,10], \n                 'classifier__max_features': ['log2', 'sqrt', None]}],             #Random Forest\n\n               [{'classifier__n_estimators':[1000],\n                 'classifier__criterion':['gini','entropy'],\n                 'classifier__random_state':[0],\n                 'classifier__max_depth': [3, 5, 8, 10, 15, 30],\n                 'classifier__min_child_weight': [2,4,6,8,10],\n                 'classifier__gamma': [0, 0.1, 0.2, 0.3],\n                 'classifier__reg_alpha':[0, 0.001, 0.005, 0.01, 0.05],\n                 'classifier__colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n                 'classifier__eta': [0.1, 0.2, 0.3, 0.4, 0.5]}],                   #XGBoost\n               \n               [{'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2], \n                 'classifier__n_estimators': [1000],\n                 'classifier__random_state':[0],\n                 'classifier__max_depth' : [5, 8, 15, None], \n                 'classifier__min_samples_split' : [1,2,5,10],\n                 'classifier__min_samples_leaf': [1,2,5,10], \n                 'classifier__max_features': ['log2', 'sqrt', 'auto', 'None']}],   #Gradient Bossting Decision Tree\n                        \n\n               [{'classifier__C':[1e-1, 1, 1e1] ,\n                 'classifier__random_state':[0],\n                 'classifier__kernel': ['rbf', 'poly']\n                }],                                                                #SVM\n               \n               [{'classifier__n_estimators' : [800, 1000, 1200], \n                 'classifier__learning_rate' : [1e-3, 1e-2, 5e-2, 1e-1, 5e-1, 1, 1e1],\n                 'classifier__random_state':[0]}]                                  #AdaBoost\n]            \n          ","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:06:31.265308Z","iopub.execute_input":"2021-07-25T14:06:31.265659Z","iopub.status.idle":"2021-07-25T14:06:31.286904Z","shell.execute_reply.started":"2021-07-25T14:06:31.265625Z","shell.execute_reply":"2021-07-25T14:06:31.285758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter Tuning. Random Search of 100 iterations is used. Uncomment cell to run\n\"\"\"\nfor i,j in zip(models, model_grids):\n    grid = RandomizedSearchCV(estimator=i, param_distributions=j, n_iter = 100, scoring='f1_weighted', cv = skf)\n    grid.fit(X_train, y_train)\n    best_f1 = grid.best_score_\n    best_param = grid.best_params_\n    print('{}:\\nBest F1 : {:.4f}'.format(i.steps[-1],best_f1))\n    print('Best Parameters : ',best_param)\n    print('')\n    print('----------------')\n    print('')\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:07:10.67338Z","iopub.execute_input":"2021-07-25T14:07:10.67374Z","iopub.status.idle":"2021-07-25T14:07:10.679025Z","shell.execute_reply.started":"2021-07-25T14:07:10.673692Z","shell.execute_reply":"2021-07-25T14:07:10.678367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing tuned models","metadata":{}},{"cell_type":"code","source":"models_tuned = []\nmodels_tuned.append(Pipeline([('mapper', linear_mapper),  ('classifier', LogisticRegression(random_state = 0))]))\nmodels_tuned.append(Pipeline([('mapper', num_mapper),  ('classifier', KNeighborsClassifier(n_neighbors=5, \n                                                                                           metric = 'manhattan'))]))\nmodels_tuned.append(Pipeline([('classifier', GaussianNB(var_smoothing= 1e-7))]))\nmodels_tuned.append(Pipeline([('classifier', BernoulliNB(alpha= 100))]))\nmodels_tuned.append(Pipeline([('mapper', linear_mapper),  ('classifier', SVC(C=1, random_state = 0, probability= True))]))\n\nmodels_tuned.append(Pipeline([('mapper', tree_mapper),  \n                              ('classifier', \n                               DecisionTreeClassifier(criterion='entropy',\n                                                      max_depth = None,\n                                                      max_features = None,\n                                                      min_samples_leaf = 1,\n                                                      min_samples_split = 2,\n                                                      random_state = 0)\n                               )]))\nmodels_tuned.append(Pipeline([('mapper', tree_mapper),  \n                              ('classifier', \n                               RandomForestClassifier(n_estimators = 1000,\n                                                      criterion='entropy',\n                                                      max_depth = None,\n                                                      max_features = 'sqrt',\n                                                      min_samples_leaf = 1,\n                                                      min_samples_split = 10,\n                                                      random_state = 0)\n                               )]))\n\nmodels_tuned.append(Pipeline([('mapper', tree_mapper),  \n                              ('classifier', \n                               AdaBoostClassifier(base_estimator= DecisionTreeClassifier(criterion='gini',\n                                                      max_depth = 30,\n                                                      max_features = 'log2',\n                                                      min_samples_leaf = 5,\n                                                      min_samples_split = 15,\n                                                      random_state = 0),\n                                                  learning_rate = 0.1,\n                                                  n_estimators = 500)\n                               )]))\n\nmodels_tuned.append(Pipeline([('mapper', tree_mapper),  \n                              ('classifier', XGBClassifier(criterion = 'gini',\n                                                           eta = 0.1,\n                                                           max_depth = 8,\n                                                           n_estimators = 500,\n                                                           random_state = 0\n                                                           ))]))\n\nmodels_tuned.append(Pipeline([('mapper', tree_mapper),  \n                              ('classifier', GradientBoostingClassifier(n_estimators = 1000,\n                                                                        learning_rate= 0.2,\n                                                                        max_depth = 8,\n                                                                        min_samples_split = 10,\n                                                                        min_samples_leaf = 1,\n                                                                        max_features = 'auto',\n                                                                        random_state = 0)\n                              )]))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:07:30.805599Z","iopub.execute_input":"2021-07-25T14:07:30.806009Z","iopub.status.idle":"2021-07-25T14:07:30.820611Z","shell.execute_reply.started":"2021-07-25T14:07:30.805977Z","shell.execute_reply":"2021-07-25T14:07:30.81967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst_1_tuned= []\n\nfor m in range(len(models_tuned)):\n    lst_2_tuned= []\n    model = models_tuned[m]\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    accuracies = cross_val_score(estimator = model, X = X_train, y = y_train, cv = skf)   #K-Fold Validation\n    \n    test_acc = accuracy_score(y_test, y_pred)\n\n    cr = classification_report(y_test, y_pred)\n      \n    cm = confusion_matrix(y_test, y_pred)\n\n    precision = precision_score(y_test, y_pred, average= 'weighted')\n    recall = recall_score(y_test, y_pred, average= 'weighted')\n    f1 = f1_score(y_test, y_pred, average= 'weighted')\n    roc = roc_auc_score(y_test, y_pred)\n\n    predicted_probab = model.predict_proba(X_test)\n    predicted_probab = predicted_probab[:, 1]\n\n    fpr, tpr, _ = roc_curve(y_test, predicted_probab)\n    pyplot.plot(fpr, tpr, marker='.', label = type(models_tuned[m][-1]).__name__)\n    pyplot.xlabel('False Positive Rate')\n    pyplot.ylabel('True Positive Rate')\n    pyplot.legend()\n    pyplot.show()\n   \n    print(type(models_tuned[m][-1]).__name__ , ':')\n    \n    print('Accuracy Score: {:.4f}'.format(test_acc))\n    print('')\n    \n    print(\"K-Fold Validation Mean Accuracy: {:.4f} %\".format(accuracies.mean()*100))\n    print('')\n\n    print(\"Classification report: \")\n    print(cr)\n    print('')\n\n    print(\"Confusion matrix: \")\n    print(cm)\n    print('')\n\n    print('Precision Score: {:.4f}'.format(precision))\n    print('')\n\n    print('Recall Score: {:.4f}'.format(recall))\n    print('')\n\n    print('F1 score: {:.4f}'.format(f1))\n    \n    print('-----------------------------------')\n    print('')\n    lst_2_tuned.append(type(models_tuned[m][-1]).__name__)\n    lst_2_tuned.append(accuracies.mean())\n    lst_2_tuned.append(test_acc)\n    lst_2_tuned.append(precision)\n    lst_2_tuned.append(recall)\n    lst_2_tuned.append(f1)\n    lst_1_tuned.append(lst_2_tuned)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:07:39.376509Z","iopub.execute_input":"2021-07-25T14:07:39.37686Z","iopub.status.idle":"2021-07-25T14:12:33.649031Z","shell.execute_reply.started":"2021-07-25T14:07:39.37683Z","shell.execute_reply":"2021-07-25T14:12:33.64805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tuned = pd.DataFrame(lst_1_tuned, columns= ['Model','Cross-val acc','Test Accuracy','Precision','Recall', 'F1'])\ndf_tuned.sort_values(by= ['F1'], inplace= True, ascending= False)\ndf_tuned","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:12:33.650944Z","iopub.execute_input":"2021-07-25T14:12:33.651329Z","iopub.status.idle":"2021-07-25T14:12:33.669741Z","shell.execute_reply.started":"2021-07-25T14:12:33.651286Z","shell.execute_reply":"2021-07-25T14:12:33.668791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensembling","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier, VotingClassifier, BaggingClassifier\n\ndef get_stacking_model():\n    # define the base models\n    level0 = []\n    level0.append(['Logistic Regression', Pipeline([('mapper', linear_mapper),  \n                                                    ('classifier', LogisticRegression(random_state = 0))])])\n    \n    level0.append(['KNN', Pipeline([('mapper', num_mapper),  \n                                    ('classifier', KNeighborsClassifier(n_neighbors=5, metric = 'manhattan'))])])\n    \n    # level0.append(['Gaussian NB', Pipeline([('mapper', linear_mapper), \n    #                                         ('classifier', GaussianNB(var_smoothing= 1e-7))])])\n    \n    # level0.append(['Bernoulli NB', Pipeline([('mapper', linear_mapper), \n    #                                          ('classifier', BernoulliNB(alpha=100))])])\n    \n    level0.append(['SVM', Pipeline([('mapper', linear_mapper),  \n                                    ('classifier', SVC(C=1, random_state = 0, probability= True))])])\n    \n    # level0.append(['DT', Pipeline([('mapper', tree_mapper),  \n    #                                ('classifier', \n    #                                 DecisionTreeClassifier(criterion='entropy',\n    #                                                   max_depth = None,\n    #                                                   max_features = None,\n    #                                                   min_samples_leaf = 1,\n    #                                                   min_samples_split = 2,\n    #                                                   random_state = 0)\n    #                            )])])\n    level0.append(['Random Forest', Pipeline([('mapper', tree_mapper),  \n                              ('classifier', RandomForestClassifier(n_estimators = 1000,\n                                                      criterion='entropy',\n                                                      max_depth = None,\n                                                      max_features = 'sqrt',\n                                                      min_samples_leaf = 1,\n                                                      min_samples_split = 10,\n                                                      random_state = 0)\n                               )])\n    ])\n    level0.append(['AdaBoost', Pipeline([('mapper', tree_mapper),  \n                              ('classifier', \n                               AdaBoostClassifier(base_estimator= DecisionTreeClassifier(criterion='gini',\n                                                      max_depth = 30,\n                                                      max_features = 'log2',\n                                                      min_samples_leaf = 5,\n                                                      min_samples_split = 15,\n                                                      random_state = 0),\n                                                  learning_rate = 0.1,\n                                                  n_estimators = 500)\n                               )])\n    ])\n    level0.append(['XGBoost', Pipeline([('mapper', tree_mapper),  \n                              ('classifier', XGBClassifier(criterion = 'gini',\n                                                           eta = 0.1,\n                                                           max_depth = 8,\n                                                           n_estimators = 500,\n                                                           random_state = 0\n                                                           )\n                              )])])\n    level0.append(['GBT', Pipeline([('mapper', tree_mapper),  \n                              ('classifier', GradientBoostingClassifier(n_estimators = 1000,\n                                                                        learning_rate= 0.2,\n                                                                        max_depth = 8,\n                                                                        min_samples_split = 10,\n                                                                        min_samples_leaf = 1,\n                                                                        max_features = 'auto',\n                                                                        random_state = 0)\n                              )])\n    ])\n    \n\n    # define meta learner model\n    # level1 = KNeighborsClassifier(n_neighbors= 7)\n    level1 = RandomForestClassifier(criterion='entropy', n_estimators= 1000, random_state= 0)\n    # define the stacking ensemble\n    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=skf)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:12:33.671319Z","iopub.execute_input":"2021-07-25T14:12:33.671586Z","iopub.status.idle":"2021-07-25T14:12:33.687642Z","shell.execute_reply.started":"2021-07-25T14:12:33.671561Z","shell.execute_reply":"2021-07-25T14:12:33.686623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_stacking_model()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\n# accuracies = cross_val_score(estimator = model, X = X_train, y = y_train, cv = skf)   #K-Fold Validation\n\ntest_acc = accuracy_score(y_test, y_pred)\n\ncr = classification_report(y_test, y_pred)\n  \ncm = confusion_matrix(y_test, y_pred)\n\nprecision = precision_score(y_test, y_pred, average= 'weighted')\nrecall = recall_score(y_test, y_pred, average= 'weighted')\nf1 = f1_score(y_test, y_pred, average= 'weighted')\n\nprint('Stacking Ensemble:')\n\nprint('Accuracy Score: {:.4f}'.format(test_acc))\nprint('')\n\nprint(\"Classification report: \")\nprint(cr)\nprint('')\n\nprint(\"Confusion matrix: \")\nprint(cm)\nprint('')\n\nprint('Precision Score: {:.4f}'.format(precision))\nprint('')\n\nprint('Recall Score: {:.4f}'.format(recall))\nprint('')\n\nprint('F1 score: {:.4f}'.format(f1))\n\nprint('-----------------------------------')\nprint('')","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:12:33.689326Z","iopub.execute_input":"2021-07-25T14:12:33.689843Z","iopub.status.idle":"2021-07-25T14:17:36.247478Z","shell.execute_reply.started":"2021-07-25T14:12:33.689739Z","shell.execute_reply":"2021-07-25T14:17:36.246579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_stack=[]\nlist_stack.append(\"Stacking ensemble\")\nlist_stack.append(np.nan) # Only testing ensemble on test set\nlist_stack.append(test_acc)\nlist_stack.append(precision)\nlist_stack.append(recall)\nlist_stack.append(f1)\nfinal_list = lst_1_tuned\nfinal_list.append(list_stack)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:19:36.451908Z","iopub.execute_input":"2021-07-25T14:19:36.452306Z","iopub.status.idle":"2021-07-25T14:19:36.45779Z","shell.execute_reply.started":"2021-07-25T14:19:36.452257Z","shell.execute_reply":"2021-07-25T14:19:36.456797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tuned = pd.DataFrame(lst_1_tuned, columns= ['Model','Cross-val acc','Test Accuracy','Precision','Recall', 'F1'])\ndf_tuned.sort_values(by= ['F1'], inplace= True, ascending= False)\ndf_tuned","metadata":{"execution":{"iopub.status.busy":"2021-07-25T14:19:42.67761Z","iopub.execute_input":"2021-07-25T14:19:42.678211Z","iopub.status.idle":"2021-07-25T14:19:42.697426Z","shell.execute_reply.started":"2021-07-25T14:19:42.678167Z","shell.execute_reply":"2021-07-25T14:19:42.696368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}