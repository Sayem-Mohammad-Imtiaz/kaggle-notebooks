{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install BeautifulSoup4","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from bs4 import BeautifulSoup\nimport requests \nimport pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns=['Movie_ID','Title','Year','Genre']\ndf = pd.DataFrame(columns=columns)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"URL = {2000:'https://en.wikipedia.org/wiki/List_of_Bollywood_films_of_2000',\n       2001:'https://en.wikipedia.org/wiki/List_of_Bollywood_films_of_2001',\n       2002:'https://en.wikipedia.org/wiki/List_of_Bollywood_films_of_2002',    \n       2003:'https://en.wikipedia.org/wiki/List_of_Bollywood_films_of_2003',\n       2004:'https://en.wikipedia.org/wiki/List_of_Bollywood_films_of_2004',\n       2005:'https://en.wikipedia.org/wiki/List_of_Bollywood_films_of_2005',\n       2006:'https://en.wikipedia.org/wiki/List_of_Bollywood_films_of_2006',\n       2007:'https://en.wikipedia.org/wiki/List_of_Bollywood_films_of_2007'\n      }\nid = 34759 \nfor key, url in URL.items():\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    table = soup.findAll('table', {'class':'wikitable'})[1].tbody\n    rows = table.find_all('tr')\n    for i in range(1, len(rows)):\n        tds = rows[i].find_all('td')\n        values = [id,tds[0].text, key, tds[3].text]\n        id+=1\n        df = df.append(pd.Series(values, index=columns), ignore_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"URL = {2008:'https://en.wikipedia.org/wiki/List_of_Bollywood_films_of_2008',\n       2009:'https://en.wikipedia.org/wiki/List_of_Bollywood_films_of_2009',\n       2010:'https://en.wikipedia.org/wiki/List_of_Bollywood_films_of_2010'\n      }\n\nfor key, url in URL.items():\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    tbl = soup.findAll('table', {'class':'wikitable'})\n    for t in tbl:\n        table=t.tbody\n        rows = table.find_all('tr')\n        for i in range(1, len(rows)):\n            tds = rows[i].find_all('td')\n            if len(tds)==5:\n                values = [id, tds[1].text, key, tds[4].text.replace('\\n','')]\n\n            elif len(tds)==4:\n                values = [id, tds[0].text, key, tds[3].text.replace('\\n','')]\n\n            elif len(tds)==6:\n                values = [id, tds[2].text, key, tds[5].text.replace('\\n','')]\n\n            id+=1\n            df = df.append(pd.Series(values, index=columns), ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"URL = {\n       2011:'https://en.wikipedia.org/wiki/List_of_Bollywood_films_of_2011'\n      }\n\nfor key, url in URL.items():\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    tbl = soup.findAll('table', {'class':'wikitable'})\n    for t in tbl:\n        table=t.tbody\n        rows = table.find_all('tr')\n        for i in range(1, len(rows)):\n            tds = rows[i].find_all('td')\n            if len(tds)==7:\n                values = [id, tds[2].text, key, tds[3].text.replace('\\n','')]\n\n            elif len(tds)==5:\n                values = [id, tds[0].text, key, tds[1].text.replace('\\n','')]\n\n            elif len(tds)==6:\n                values = [id, tds[1].text, key, tds[2].text.replace('\\n','')]\n\n            id+=1\n            df = df.append(pd.Series(values, index=columns), ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"URL = {\n       2012:'https://en.wikipedia.org/wiki/List_of_Bollywood_films_of_2012'\n      }\n\nfor key, url in URL.items():\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    tbl = soup.findAll('table', {'class':'wikitable'})\n    for t in tbl:\n        table=t.tbody\n        rows = table.find_all('tr')\n        for i in range(1, len(rows)):\n            tds = rows[i].find_all('td')\n\n            if len(tds)==5:\n                values = [id, tds[1].text, key, tds[2].text.replace('\\n','')]\n\n            elif len(tds)==6:\n                values = [id, tds[2].text, key, tds[3].text.replace('\\n','')]\n            \n            elif len(tds)==4:\n                values = [id, tds[0].text, key, tds[1].text.replace('\\n','')]\n\n            id+=1\n            df = df.append(pd.Series(values, index=columns), ignore_index=True)\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"URL = {\n       2012:'https://en.wikipedia.org/wiki/List_of_Bollywood_films_of_2012'\n      }\n\nfor key, url in URL.items():\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    tbl = soup.findAll('table', {'class':'wikitable'})\n    for t in tbl:\n        table=t.tbody\n        rows = table.find_all('tr')\n        for i in range(1, len(rows)):\n            tds = rows[i].find_all('td')\n\n            if len(tds)==5:\n                values = [id, tds[1].text, key, tds[2].text.replace('\\n','')]\n\n            elif len(tds)==6:\n                values = [id, tds[2].text, key, tds[3].text.replace('\\n','')]\n            \n            elif len(tds)==4:\n                values = [id, tds[0].text, key, tds[1].text.replace('\\n','')]\n\n            id+=1\n            df = df.append(pd.Series(values, index=columns), ignore_index=True)\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"URL = {\n       2016:'https://en.wikipedia.org/wiki/List_of_Bollywood_films_of_2016'\n      }\n\nfor key, url in URL.items():\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    table = soup.findAll('table', {'class':'wikitable'})[1].tbody\n    rows = table.find_all('tr')\n    for i in range(1, len(rows)):\n        tds = rows[i].find_all('td')\n        if len(tds)==8:\n                values = [id, tds[2].text, key, tds[3].text.replace('\\n','')]\n\n        elif len(tds)==7:\n            values = [id, tds[1].text, key, tds[2].text.replace('\\n','')]\n\n        elif len(tds)==6:\n            values = [id, tds[0].text, key, tds[1].text.replace('\\n','')]\n        id+=1\n        df = df.append(pd.Series(values, index=columns), ignore_index=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"URL = {\n       2016:'https://en.wikipedia.org/wiki/List_of_Bollywood_films_of_2016'\n      }\n\nfor key, url in URL.items():\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    tbl = soup.findAll('table', {'class':'wikitable'})[1:]\n    for t in tbl:\n        table=t.tbody\n        rows = table.find_all('tr')\n        for i in range(1, len(rows)):\n            tds = rows[i].find_all('td')\n            if len(tds)==8:\n                    values = [id, tds[2].text, key, tds[5].text.replace('\\n','')]\n\n            elif len(tds)==7:\n                values = [id, tds[1].text, key, tds[4].text.replace('\\n','')]\n\n            elif len(tds)==6:\n                values = [id, tds[0].text, key, tds[3].text.replace('\\n','')]\n            id+=1\n            df = df.append(pd.Series(values, index=columns), ignore_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"URL = {\n       2017:'https://en.wikipedia.org/wiki/List_of_Bollywood_films_of_2017'\n      }\n\nfor key, url in URL.items():\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    tbl = soup.findAll('table', {'class':'wikitable'})[1:]\n    for t in tbl:\n        table=t.tbody\n        rows = table.find_all('tr')\n        for i in range(1, len(rows)):\n            tds = rows[i].find_all('td')\n            if len(tds)==8:\n                    values = [id, tds[2].text, key, tds[5].text.replace('\\n','')]\n\n            elif len(tds)==7:\n                values = [id, tds[1].text, key, tds[4].text.replace('\\n','')]\n\n            elif len(tds)==6:\n                values = [id, tds[0].text, key, tds[3].text.replace('\\n','')]\n            id+=1\n            df = df.append(pd.Series(values, index=columns), ignore_index=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport openpyxl\nwb = openpyxl.load_workbook('kaggleList.xlsx')\nsheet = wb.active\nsheet = wb['Sheet1']\nfor i in range(9481, 9684):\n    values = [id, str(sheet['B'+str(i)].value), sheet['A'+str(i)].value, sheet['E'+str(i)].value]\n    id+=1\n    df = df.append(pd.Series(values, index=columns), ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.apply(lambda x : x.lower().strip() if isinstance(x, str) else x)\ndf.drop_duplicates(inplace=True, subset='Title')\ndf.to_csv('Movie_List.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}