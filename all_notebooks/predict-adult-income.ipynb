{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Build a classifier to predict whether income of a person exceeds $50K/yr based on census data. Also known as \"Census Income\" dataset.**\n\nUse neural networks, SVM, Random Forest and Logistic Regression and compare their performance","metadata":{}},{"cell_type":"markdown","source":"**import the required packages and libraries**\n\n\n1.   Pandas is a Python library. Pandas is used to analyze data.\n2.   sklearn is a machine learning library for Python. It has classes and functions with respect to various algorithms like support vector machine, logistic regression, random forests, etc.\n\n  a. Label Encoder is for converting the values in the given column into numeric form \n\n  b.  StandardScaler will transform your data such that its distribution will have a mean value 0 and standard deviation of 1.\n\n  c. sklearn.metrics module implements functions assessing prediction error for specific purposes.\n\n  d.  train_test_split is a function in Sklearn model selection for splitting data arrays into two subsets: for training data and for testing data\n  \n5.   Keras is a Python library for neural networks\n\n6. joblib provides utilities for saving and loading Python objects that make use of NumPy data structures, efficiently. \n\n\n\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nimport sklearn.metrics\nimport keras\nimport joblib\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Dataset Preparation**\n1. read the dataset file\n2. do a little preprocessing to convert alphanumerical values in certain columns to numerical/ordinal values\n3. split the dataset into test and training datasets\n4. perform feature scaling","metadata":{}},{"cell_type":"code","source":"def readData():\n  features = pd.read_csv('/kaggle/input/adult-dataset/adult.csv',header=None) #fetching the dataset directly from the url\n  features = features.rename(columns={14 : 'class'}) #renaming the result column\n  print(\"The dataset-\")\n  print(features)\n  n=features.shape[1]  #number of columns in the dataframe\n  colnames_numerics_only = features.select_dtypes(include=np.number).columns.tolist() #forming a list of columns containing numerical values\n  # Label Encoding refers to converting the labels into numeric form so as to convert it into the machine-readable form. \n  # Machine learning algorithms can then decide in a better way on how those labels must be operated\n  label_encoder = LabelEncoder() \n  #this loop uses label_encoder to convert all non-numerical columns to numerical \n  for col in features.columns:\n    if col not in colnames_numerics_only:\n      features[col] = label_encoder.fit_transform(features[col]) \n  labels = features.pop('class')\n  features.fillna(features.mean(),inplace=True)\n  X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.20,random_state=5)\n  scaler = StandardScaler()\n  scaler.fit(X_train)\n  X_train = scaler.transform(X_train)\n  X_test = scaler.transform(X_test)\n  return X_train,y_train, X_test, y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,y_train, X_test, y_test=readData()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building a neural network classifier","metadata":{}},{"cell_type":"markdown","source":"Machine learning algorithms that use neural networks generally do not need to be programmed with specific rules that define what to expect from the input. The neural net learning algorithm instead learns from processing many labeled examples that are supplied during training and using this answer key to learn what characteristics of the input are needed to construct the correct output. Once a sufficient number of examples have been processed, the neural network can begin to process new, unseen inputs and successfully return accurate results.   \n\nHere we build a neural network classifier with 2 layers having 24 neurons each.\n1. Use tanh activation function for hidden layers\n2. Use sigmoid activation function for output layer","metadata":{}},{"cell_type":"code","source":"# Train and evaluate\ndef train_and_evaluate(X_train, Y_train, X_test, Y_test):\n    global accuracyNN\n    m=X_train.shape[0]  #number of training examples \n    n=X_train.shape[1]  #number of features\n    inputs = keras.layers.Input(shape=(n,), dtype='float32', name='input_layer') # Input (2 dimensions)\n    outputs = keras.layers.Dense(24, activation='tanh', name='hidden_layer1')(inputs) # Hidden layer\n    outputs = keras.layers.Dense(24, activation='tanh', name='hidden_layer2')(outputs) # Hidden layer\n    outputs = keras.layers.Dense(1, activation='sigmoid', name='output_layer')(outputs) # Output layer \n    # Create a model from input layer and output layers\n    model = keras.models.Model(inputs=inputs, outputs=outputs, name='neural_network')\n    # Compile the model (binary_crossentropy if 2 classes)\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    # Train the model on the train set (output debug information)\n    model.fit(X_train, Y_train, epochs=100, verbose=1)#batch_size=1\n    # Save the model (Make sure that the folder exists)\n    model.save(\"my_nn_model.h5\")\n    # Evaluate on training data\n    print('\\n-- Training data --')\n    predictions = model.predict(X_train)\n    #now make the predicted output of those training instances as 1 which have value higher than 0.5(the chosen threshold)\n    predictions[predictions>=0.5]=1\n    predictions[predictions<0.5]=0\n    accuracy = sklearn.metrics.accuracy_score(Y_train, predictions)\n    print('Accuracy: {0:.2f}'.format(accuracy * 100.0))\n    print('Classification Report:')\n    print(sklearn.metrics.classification_report(Y_train, predictions))\n    print('Confusion Matrix:')\n    print(sklearn.metrics.confusion_matrix(Y_train, predictions))\n    print('')\n    # Evaluate on test data\n    print('\\n---- Test data ----')\n    predictions = model.predict(X_test)\n    predictions[predictions>=0.5]=1\n    predictions[predictions<0.5]=0\n    predictions=np.asarray(predictions).astype('int32')\n    Y_test=np.asarray(Y_test).astype('int32')\n    accuracyNN = sklearn.metrics.accuracy_score(Y_test, predictions)\n    print('Accuracy: {0:.2f}'.format(accuracy * 100.0))\n    print('Classification Report:')\n    print(sklearn.metrics.classification_report(Y_test,predictions))\n    print('Confusion Matrix:')\n    print(sklearn.metrics.confusion_matrix(Y_test, predictions))\n\n# The main entry point for this module\ndef main():\n    X_train,Y_train,X_test,Y_test=readData()\n    train_and_evaluate(X_train, Y_train, X_test, Y_test)\n# Tell python to run main method\nif __name__ == \"__main__\": \n  main()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building an SVM classifier","metadata":{}},{"cell_type":"markdown","source":"Support-vector machines (SVMs, also support-vector networks) are supervised learning models with associated learning algorithms that analyze data for classification and regression analysis.  An SVM maps training examples to points in space so as to maximise the width of the gap between the two categories. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.","metadata":{}},{"cell_type":"code","source":"def train_and_evaluate_SVM(X_train, y_train, X_test, y_test):\n  global accuracySVM\n  svclassifier = SVC(kernel='rbf')  #using SVM with radial basis function kernel\n  svclassifier.fit(X_train, y_train)  #training\n  filename = 'svm_model.sav'\n  joblib.dump(svclassifier, filename)  #saving the svm model in a file\n  y_pred = svclassifier.predict(X_test)  #predicting the output on the test set\n  accuracySVM = sklearn.metrics.accuracy_score(y_test, y_pred)\n  print(\"Accuracy on test data: \",accuracySVM)\n  print(sklearn.metrics.confusion_matrix(y_test,y_pred))\n  print(sklearn.metrics.classification_report(y_test,y_pred))\n\ndef main():\n    X_train,Y_train,X_test,Y_test=readData()\n    train_and_evaluate_SVM(X_train, Y_train, X_test, Y_test)\n# Tell python to run main method\nif __name__ == \"__main__\": \n  main()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building a Logistic Regression classifier","metadata":{}},{"cell_type":"markdown","source":"Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. Generally, logistic regression means binary logistic regression having binary target variables.","metadata":{}},{"cell_type":"code","source":"def train_and_evaluate_Log(X_train, y_train, X_test, y_test):\n  global accuracyLog\n  logisticRegr = LogisticRegression()\n  logisticRegr.fit(X_train, y_train)  #training\n  filename = 'log_model.sav'\n  joblib.dump(logisticRegr, filename) #saving the logistic regression model in a file\n  y_pred = logisticRegr.predict(X_test) #predicting the output on the test set\n  accuracyLog = sklearn.metrics.accuracy_score(y_test, y_pred)\n  print(\"Accuracy on test data: \",accuracyLog)\n  print(sklearn.metrics.confusion_matrix(y_test,y_pred))\n  print(sklearn.metrics.classification_report(y_test,y_pred))\ndef main():\n    X_train,Y_train,X_test,Y_test=readData()\n    train_and_evaluate_Log(X_train, Y_train, X_test, Y_test)\n\n# Tell python to run main method\nif __name__ == \"__main__\": \n  main()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building a Random Forest classifier","metadata":{}},{"cell_type":"markdown","source":"The random forest is a classification algorithm consisting of many decisions trees. It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree.","metadata":{}},{"cell_type":"code","source":"def train_and_evaluate_RF(X_train, y_train, X_test, y_test):\n  global accuracyRF\n  RFclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42) # 10 decision trees used in this classifier\n  RFclassifier.fit(X_train, y_train)  #training  \n  filename = 'rf_model.sav'\n  joblib.dump(RFclassifier, filename)  #save the model\n  y_pred = RFclassifier.predict(X_test) #predict on test set\n  accuracyRF = sklearn.metrics.accuracy_score(y_test, y_pred)\n  print(sklearn.metrics.confusion_matrix(y_test,y_pred))\n  print(sklearn.metrics.classification_report(y_test,y_pred))\n\ndef main():\n    X_train,Y_train,X_test,Y_test=readData()\n    train_and_evaluate_RF(X_train, Y_train, X_test, Y_test)\n# Tell python to run main method\nif __name__ == \"__main__\": \n  main()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Comparing all the classifier models**","metadata":{}},{"cell_type":"code","source":"y = np.array([(accuracyNN),(accuracySVM),(accuracyLog),(accuracyRF)]) \nx = ['Neural Network','SVM','Log Regression', 'Random Forest']\nplt.bar(x,y)\nplt.title('Performance comparison')\nplt.xlabel('Classifier')\nplt.ylabel('accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}