{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hey Everyone !\n### In this notebook we'll learn about AutoML using H2O.ai\n### We'll start with basic EDA and visualization, followed by Feature Engineering and finally model building !!\n\n\n## Lets get started !!","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-26T09:41:44.346621Z","iopub.execute_input":"2021-08-26T09:41:44.347217Z","iopub.status.idle":"2021-08-26T09:41:44.360644Z","shell.execute_reply.started":"2021-08-26T09:41:44.347127Z","shell.execute_reply":"2021-08-26T09:41:44.359907Z"}}},{"cell_type":"code","source":"# importing some basic libraries|\nimport pandas as pd\nimport numpy as np\nimport os\nimport math","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:00.016505Z","iopub.execute_input":"2021-08-28T13:04:00.016925Z","iopub.status.idle":"2021-08-28T13:04:00.026922Z","shell.execute_reply.started":"2021-08-28T13:04:00.016823Z","shell.execute_reply":"2021-08-28T13:04:00.026077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## load train and test data\ntrain_data= pd.read_csv('../input/30-days-of-ml/train.csv')\ntest_data=pd.read_csv('../input/30-days-of-ml/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:00.037977Z","iopub.execute_input":"2021-08-28T13:04:00.03824Z","iopub.status.idle":"2021-08-28T13:04:03.443615Z","shell.execute_reply.started":"2021-08-28T13:04:00.038202Z","shell.execute_reply":"2021-08-28T13:04:03.442809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"### For this problem we don't have much to explore, but lets see what we dealing with","metadata":{}},{"cell_type":"code","source":"train_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:03.445113Z","iopub.execute_input":"2021-08-28T13:04:03.445477Z","iopub.status.idle":"2021-08-28T13:04:03.683553Z","shell.execute_reply.started":"2021-08-28T13:04:03.445442Z","shell.execute_reply":"2021-08-28T13:04:03.682764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:03.685236Z","iopub.execute_input":"2021-08-28T13:04:03.685511Z","iopub.status.idle":"2021-08-28T13:04:03.983808Z","shell.execute_reply.started":"2021-08-28T13:04:03.685486Z","shell.execute_reply":"2021-08-28T13:04:03.982941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:03.985408Z","iopub.execute_input":"2021-08-28T13:04:03.985749Z","iopub.status.idle":"2021-08-28T13:04:04.247776Z","shell.execute_reply.started":"2021-08-28T13:04:03.985711Z","shell.execute_reply":"2021-08-28T13:04:04.246836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:04.249186Z","iopub.execute_input":"2021-08-28T13:04:04.249598Z","iopub.status.idle":"2021-08-28T13:04:04.429461Z","shell.execute_reply.started":"2021-08-28T13:04:04.249556Z","shell.execute_reply":"2021-08-28T13:04:04.428505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### It's nice that we don't need to deal with null values !","metadata":{}},{"cell_type":"code","source":"pd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:04.430844Z","iopub.execute_input":"2021-08-28T13:04:04.431214Z","iopub.status.idle":"2021-08-28T13:04:05.010748Z","shell.execute_reply.started":"2021-08-28T13:04:04.431177Z","shell.execute_reply":"2021-08-28T13:04:05.009931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting continuous features","metadata":{}},{"cell_type":"code","source":"figure, axis = plt.subplots(5, 3)\nfigure.set_figheight(25)\nfigure.set_figwidth(20)\n\naxis[0, 0].scatter(x=train_data['cont0'],y=train_data['target'],s=.5)\naxis[1, 0].scatter(x=train_data['cont1'],y=train_data['target'],s=.5)\naxis[2, 0].scatter(x=train_data['cont2'],y=train_data['target'],s=.5)\naxis[0, 2].scatter(x=train_data['cont3'],y=train_data['target'],s=.5)\naxis[0, 1].scatter(x=train_data['cont4'],y=train_data['target'],s=.5)\naxis[1, 1].scatter(x=train_data['cont5'],y=train_data['target'],s=.5)\naxis[2, 1].scatter(x=train_data['cont6'],y=train_data['target'],s=.5)\naxis[1, 2].scatter(x=train_data['cont7'],y=train_data['target'],s=.5)\naxis[2, 2].scatter(x=train_data['cont8'],y=train_data['target'],s=.5)\naxis[3, 0].scatter(x=train_data['cont9'],y=train_data['target'],s=.5)\naxis[3, 1].scatter(x=train_data['cont10'],y=train_data['target'],s=.5)\naxis[3, 2].scatter(x=train_data['cont11'],y=train_data['target'],s=.5)\naxis[4, 0].scatter(x=train_data['cont12'],y=train_data['target'],s=.5)\naxis[4, 1].scatter(x=train_data['cont13'],y=train_data['target'],s=.5)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:05.012044Z","iopub.execute_input":"2021-08-28T13:04:05.012412Z","iopub.status.idle":"2021-08-28T13:04:10.575078Z","shell.execute_reply.started":"2021-08-28T13:04:05.012377Z","shell.execute_reply":"2021-08-28T13:04:10.574319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lets see how target is distributed","metadata":{}},{"cell_type":"code","source":"sns.histplot(data=train_data,x='target')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:10.577112Z","iopub.execute_input":"2021-08-28T13:04:10.577604Z","iopub.status.idle":"2021-08-28T13:04:11.410127Z","shell.execute_reply.started":"2021-08-28T13:04:10.577563Z","shell.execute_reply":"2021-08-28T13:04:11.409334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting categorical features","metadata":{}},{"cell_type":"code","source":"figure, axis = plt.subplots(3, 4)\nfigure.set_figheight(9)\nfigure.set_figwidth(12)\naxis[0, 0].scatter(x=train_data['cat0'],y=train_data['target'],s=5)\naxis[0, 1].scatter(x=train_data['cat1'],y=train_data['target'],s=5)\naxis[0, 2].scatter(x=train_data['cat2'],y=train_data['target'],s=5)\naxis[0, 3].scatter(x=train_data['cat3'],y=train_data['target'],s=5)\naxis[1, 0].scatter(x=train_data['cat4'],y=train_data['target'],s=5)\naxis[1, 1].scatter(x=train_data['cat5'],y=train_data['target'],s=5)\naxis[1, 2].scatter(x=train_data['cat6'],y=train_data['target'],s=5)\naxis[1, 3].scatter(x=train_data['cat7'],y=train_data['target'],s=5)\naxis[2, 0].scatter(x=train_data['cat8'],y=train_data['target'],s=5)\naxis[2, 1].scatter(x=train_data['cat9'],y=train_data['target'],s=5)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:11.411568Z","iopub.execute_input":"2021-08-28T13:04:11.411934Z","iopub.status.idle":"2021-08-28T13:04:18.184149Z","shell.execute_reply.started":"2021-08-28T13:04:11.411896Z","shell.execute_reply":"2021-08-28T13:04:18.183315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering\n\n### Because we don't have labels for the columns, we cant really do much other than shoot in the dark. We can create new features by combining the available featues, but right now, lets just convert categorical variables to numerical and move forward ! ","metadata":{}},{"cell_type":"code","source":"traindf=train_data.copy()\ntestdf=test_data.copy()\n\nfor i in range(10):\n    map_=list(train_data['cat'+str(i)].unique())\n    map_.sort()\n    traindf['cat'+str(i)]=traindf['cat'+str(i)].apply(lambda x : map_.index(x))\n    testdf['cat'+str(i)]=testdf['cat'+str(i)].apply(lambda x : map_.index(x))","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:18.185486Z","iopub.execute_input":"2021-08-28T13:04:18.185833Z","iopub.status.idle":"2021-08-28T13:04:21.517215Z","shell.execute_reply.started":"2021-08-28T13:04:18.185794Z","shell.execute_reply":"2021-08-28T13:04:21.516368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets plot the correlation heatmap\nsns.heatmap(traindf.corr(),annot=True,cmap='magma',linewidths=0.2,annot_kws={'size':5})\nfig=plt.gcf()\nfig.set_size_inches(14,10)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:21.518398Z","iopub.execute_input":"2021-08-28T13:04:21.518779Z","iopub.status.idle":"2021-08-28T13:04:24.488563Z","shell.execute_reply.started":"2021-08-28T13:04:21.518738Z","shell.execute_reply":"2021-08-28T13:04:24.487772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training \n\n### Alright, lets get into AutoML","metadata":{}},{"cell_type":"markdown","source":"## What is AutoML ? \n## AutoML helps solving the tedious manual task of exploring different models for our train data.\n## AutoML can search over a huge model space to find the model that best fits our task","metadata":{}},{"cell_type":"code","source":"# importing automl and converting pandas df to h2o df\nimport h2o\nfrom h2o.automl import H2OAutoML\nh2o.init()\nhf = h2o.H2OFrame(traindf.drop(columns=['id']))\ny_col = \"target\"\nx_col =[ col for col in hf.columns if col!=\"target\" ]","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:30.550664Z","iopub.execute_input":"2021-08-28T13:04:30.551022Z","iopub.status.idle":"2021-08-28T13:04:55.507584Z","shell.execute_reply.started":"2021-08-28T13:04:30.550989Z","shell.execute_reply":"2021-08-28T13:04:55.506688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Commenting out this part as it takes a while to run","metadata":{}},{"cell_type":"code","source":"# Starting the search for best model \n# We run the search for max 30 min, and limit search space to 50 models and we want to sort the models by rmse\n\n# aml = H2OAutoML(seed=1,sort_metric='rmse')\n# aml.train(x=x_col, y=y_col, training_frame=hf)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:55.511941Z","iopub.execute_input":"2021-08-28T13:04:55.513948Z","iopub.status.idle":"2021-08-28T13:04:55.519527Z","shell.execute_reply.started":"2021-08-28T13:04:55.513908Z","shell.execute_reply":"2021-08-28T13:04:55.518492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# aml.leaderboard","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:55.524996Z","iopub.execute_input":"2021-08-28T13:04:55.52758Z","iopub.status.idle":"2021-08-28T13:04:55.533366Z","shell.execute_reply.started":"2021-08-28T13:04:55.527539Z","shell.execute_reply":"2021-08-28T13:04:55.53218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# leaderboard=aml.leaderboard.as_data_frame(use_pandas=True)\n# leaderboard.to_csv('h2o_leaderboard.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:55.538714Z","iopub.execute_input":"2021-08-28T13:04:55.540974Z","iopub.status.idle":"2021-08-28T13:04:55.546256Z","shell.execute_reply.started":"2021-08-28T13:04:55.540937Z","shell.execute_reply":"2021-08-28T13:04:55.545048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"leaderboard=pd.read_csv('../input/aml-leaderboard/h2o_leaderboard (3).csv')\nleaderboard\n# model_list=leaderboard['model_id'].values\n# blend=traindf.copy()\n# blend_test=testdf.copy()\n# thf = h2o.H2OFrame(testdf.drop(columns=['id']))\n# for i in range(10):\n#     model=h2o.get_model(model_list[i])\n#     preds=model.predict(hf)\n#     preds=preds.as_data_frame(use_pandas=True)\n#     preds_test=model.predict(thf)\n#     preds_test=preds_test.as_data_frame(use_pandas=True)\n#     blend[\"pred\"+str(i)]=preds['predict']\n#     blend_test[\"pred\"+str(i)]=preds_test['predict']","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:55.550672Z","iopub.execute_input":"2021-08-28T13:04:55.552242Z","iopub.status.idle":"2021-08-28T13:04:55.598838Z","shell.execute_reply.started":"2021-08-28T13:04:55.552201Z","shell.execute_reply":"2021-08-28T13:04:55.598063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# blend.to_csv('blend.csv')\n# blend_test.to_csv('blend_test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:55.602383Z","iopub.execute_input":"2021-08-28T13:04:55.604374Z","iopub.status.idle":"2021-08-28T13:04:55.609639Z","shell.execute_reply.started":"2021-08-28T13:04:55.604336Z","shell.execute_reply":"2021-08-28T13:04:55.608528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reading the saved blend data","metadata":{}},{"cell_type":"code","source":"blend=pd.read_csv('../input/30-days-of-ml-blend/blend.csv')\nblend_test=pd.read_csv('../input/30-days-of-ml-blend/blend_test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:04:55.615005Z","iopub.execute_input":"2021-08-28T13:04:55.617182Z","iopub.status.idle":"2021-08-28T13:05:00.086502Z","shell.execute_reply.started":"2021-08-28T13:04:55.617142Z","shell.execute_reply":"2021-08-28T13:05:00.085651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_cols=[col for col in blend.columns if(\"pred\" in col or col=='target')]","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:05:00.088713Z","iopub.execute_input":"2021-08-28T13:05:00.089097Z","iopub.status.idle":"2021-08-28T13:05:00.094386Z","shell.execute_reply.started":"2021-08-28T13:05:00.08906Z","shell.execute_reply":"2021-08-28T13:05:00.093024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We could use Linear Regression,Xgboost or some other regressor. But just for fun I again used the H2O AutoML to find best model !","metadata":{}},{"cell_type":"code","source":"# from sklearn.linear_model import LinearRegression\n# from xgboost import XGBRegressor\n# lr=XGBRegressor()\n\n# lr.fit(blend[pred_cols],blend['target'])\n# preds=lr.predict(blend_test[pred_cols])\n# submission = pd.DataFrame({'id':blend_test['id'],'target':preds})\n# submission.to_csv('submission_auto.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:05:00.096165Z","iopub.execute_input":"2021-08-28T13:05:00.096756Z","iopub.status.idle":"2021-08-28T13:05:00.103106Z","shell.execute_reply.started":"2021-08-28T13:05:00.096706Z","shell.execute_reply":"2021-08-28T13:05:00.101949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hf = h2o.H2OFrame(blend[pred_cols])\n# y_col = \"target\"\n# x_col =[ col for col in hf.columns if col!=\"target\" ]","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:05:00.104423Z","iopub.execute_input":"2021-08-28T13:05:00.104793Z","iopub.status.idle":"2021-08-28T13:05:00.111101Z","shell.execute_reply.started":"2021-08-28T13:05:00.104756Z","shell.execute_reply":"2021-08-28T13:05:00.110235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# aml = H2OAutoML(seed=1,sort_metric='rmse')\n# aml.train(x=x_col, y=y_col, training_frame=hf)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:05:00.112331Z","iopub.execute_input":"2021-08-28T13:05:00.112685Z","iopub.status.idle":"2021-08-28T13:05:00.119304Z","shell.execute_reply.started":"2021-08-28T13:05:00.112648Z","shell.execute_reply":"2021-08-28T13:05:00.118479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds=aml.leader.predict(h2o.H2OFrame(blend_test[x_col]))\n# preds=preds.as_data_frame(use_pandas=True)\n# submission = pd.DataFrame({'id':blend_test['id'],'target':preds['predict']})\n# submission.to_csv('submission_auto.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T13:05:00.120672Z","iopub.execute_input":"2021-08-28T13:05:00.121056Z","iopub.status.idle":"2021-08-28T13:05:00.127062Z","shell.execute_reply.started":"2021-08-28T13:05:00.121019Z","shell.execute_reply":"2021-08-28T13:05:00.126267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n\n### Aim of this notebook to expose newbies like me to AutoML. I got better score by using tuned XGBoost, LGBM models. Comment down if you guys have any doubt or question!! \n### I Hope you guys had fun reading this one !","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}