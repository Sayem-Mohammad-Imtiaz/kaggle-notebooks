{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**VERSION NOTE**:\n\n* version 14: hyper fold 1\n* version 7: finetune fold 1\n* version 9: Hyper fold3\n* version 11: Finetune fold3\n* version 12: Hyper fold4\n* version 13: Finetune fold4\n\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#IMPORT LIBARIES\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nimport os\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn import datasets\nimport cv2\nimport PIL.Image as Image\nprint('Setup Completed')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Conf for WBF\niou_thr = 0.5\nskip_box_thr = 0.0001\nsigma = 0.1\n# ===============================\n#Fold value\ndim = 640 #512, 256, 'original'\nfold_num = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Preprocessing\n# input path là đường dẫn\n\ndef Preprocessing(input_path, output_path):\n    #Example image\n    \n    #Read image\n    img = cv2.imread(input_path)\n    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    \n    #Histogram Equlization\n    # create a CLAHE object\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n    cl1 = clahe.apply(gray_image)\n    img_f = cv2.cvtColor(cl1, cv2.COLOR_GRAY2BGR)\n    \n    #Normalization\n    norm_img = np.zeros((800,800))\n    n_img = cv2.normalize(img_f,  norm_img, 0, 255, cv2.NORM_MINMAX)\n    \n    final_image = Image.fromarray(n_img)\n    final_image.save(output_path)\ndef create_annotation(image_id,output_path,data):\n    save_txt_path = os.path.join(output_path, image_id+\".txt\") \n    file = open(save_txt_path, \"w+\")\n    image_data = data.loc[data.image_id == image_id]\n    for i in image_data.index:\n        object_label = image_data[\"class_id\"][i]\n        x_centre = image_data[\"x_mid\"][i]\n        y_centre = image_data[\"y_mid\"][i]\n        w = image_data[\"w\"][i] # w,h : ngôn ngữ trong YOLOv5 , xác định phần ảnh mình khoanh vùng\n        h = image_data[\"h\"][i]\n        file.write(f'{object_label} {x_centre} {y_centre} {w} {h}\\n')\n    file.close()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Define folder path (Custom)\nTRAIN_DIR = '/kaggle/input/image640/train_vin.csv'\nTEST_DIR = '/kaggle/input/test640'\n#Define folder path (Origin)\nOrigin_TRAIN_DIR = '/kaggle/input/image640/train.csv'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cài đặt môi trường để cbi merge annotation\n!pip install ensemble-boxes\nfrom ensemble_boxes import *\n\nprint('Setup WBF completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(Origin_TRAIN_DIR)\ndf.fillna(0, inplace=True)\ndf.loc[df[\"class_id\"] == 14, ['x_max', 'y_max']] = 1.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mặc đinh từ đầu file train chính của mình là abnormal image nên dataframe sẽ lấy luôn file train chính, k phải lọc về cuối nữa\n\ntrain_640_path = '/kaggle/input/train-640/train_image.csv'\ntrain_640_df = pd.read_csv(train_640_path)\ndisplay(train_640_df.head())\nprint(train_640_df.shape)\n\nresults = []\nimage_ids = train_640_df[\"image_id\"].unique() # id ảnh để dùng là 3515 ảnh trong 15000 ảnh\nprint(len(image_ids))\n\n\nfor image_id in tqdm(image_ids, total=len(image_ids)):\n\n    # All annotations for the current image.: do đã merge image_id của file mình muốn train640 cùng file train gốc của vin \n    data = df[df[\"image_id\"] == image_id]\n    data = data.reset_index(drop=True)\n\n    annotations = {}\n    weights = []\n\n    # WBF expects the coordinates in 0-1 range.\n    max_value = data.iloc[:, 4:].values.max()\n    data.loc[:, [\"x_min\", \"y_min\", \"x_max\", \"y_max\"]] = data.iloc[:, 4:] / max_value\n\n    # Loop through all of the annotations\n    for idx, row in data.iterrows():\n\n        rad_id = row[\"rad_id\"]\n\n        if rad_id not in annotations:\n            annotations[rad_id] = {\n                \"boxes_list\": [],\n                \"scores_list\": [],\n                \"labels_list\": [],\n            }\n\n            # We consider all of the radiologists as equal.\n            weights.append(1.0)\n\n        annotations[rad_id][\"boxes_list\"].append([row[\"x_min\"], row[\"y_min\"], row[\"x_max\"], row[\"y_max\"]])\n        annotations[rad_id][\"scores_list\"].append(1.0)\n        annotations[rad_id][\"labels_list\"].append(row[\"class_id\"])\n\n    boxes_list = []\n    scores_list = []\n    labels_list = []\n\n    for annotator in annotations.keys():\n        boxes_list.append(annotations[annotator][\"boxes_list\"])\n        scores_list.append(annotations[annotator][\"scores_list\"])\n        labels_list.append(annotations[annotator][\"labels_list\"])\n\n    # Calculate WBF\n    boxes, scores, labels = weighted_boxes_fusion(\n        boxes_list,\n        scores_list,\n        labels_list,\n        weights=weights,\n        iou_thr=iou_thr,\n        skip_box_thr=skip_box_thr\n    )\n\n    for idx, box in enumerate(boxes):\n        results.append({\n            \"image_id\": image_id,\n            \"class_id\": int(labels[idx]),\n            \"rad_id\": \"wbf\",\n            \"x_min\": box[0] * max_value,\n            \"y_min\": box[1] * max_value,\n            \"x_max\": box[2] * max_value,\n            \"y_max\": box[3] * max_value,\n        })\n\nFinal_df = pd.DataFrame(results)\ndisplay(train_640_df.head())\ndisplay(Final_df.head())\nprint(f'Size of origin Dataframe: {train_640_df.shape}')\nprint(f'Size of WBF Dataframe: {Final_df.shape}')\nprint(f'Number of images: {len(image_ids)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train_df là dùng cho 15k ảnh , 3512 ảnh mình cũng có sẵn trog 15k ảnh mà mình merge theo id rồi nên k cần quan tâm\ntrain_df = pd.read_csv(TRAIN_DIR)\n#test_df = pd.read_csv(TEST_DIR)\ndisplay(train_df.head())\nprint(train_df.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cập nhật width và height theo image id trong file train df\nwidth = {}\nheight = {}\nfor indx in tqdm(image_ids, total=len(image_ids)):\n    width.update({indx:train_df[train_df.image_id == indx].width.unique()[0]})\n    height.update({indx:train_df[train_df.image_id == indx].height.unique()[0]})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ADD width and height of image from train_df to Final_df\nFinal_df['width'] = Final_df.apply(lambda row: width[row.image_id], axis =1)\nFinal_df['height'] = Final_df.apply(lambda row: height[row.image_id], axis =1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(Final_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Final_df['x_mid'] = Final_df.apply(lambda row: ((row.x_max)/row.width+(row.x_min)/row.width)/2, axis =1)\nFinal_df['y_mid'] = Final_df.apply(lambda row: ((row.y_max)/row.height+(row.y_min)/row.height)/2, axis =1)\nFinal_df['w'] = Final_df.apply(lambda row: ((row.x_max)/row.width-(row.x_min)/row.width), axis =1)\nFinal_df['h'] = Final_df.apply(lambda row: ((row.y_max)/row.height-(row.y_min)/row.height), axis =1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(Final_df.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Liệt kê ra 14 phân loại bệnh\nclass_ids, class_names = list(zip(*set(zip(df.class_id, df.class_name))))\nclasses = list(np.array(class_names)[np.argsort(class_ids)])\nclasses = list(map(lambda x: str(x), classes))\nclasses.pop()\nclasses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# chia file train thành 5 fold, sau đó sử dụng phép so sánh chéo (cross valdiation),lưu thành 2 files riêng là train và val\ngkf  = GroupKFold(n_splits = 5)\nFinal_df['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(gkf.split(Final_df, groups = Final_df.image_id.tolist())):\n    Final_df.loc[val_idx, 'fold'] = fold\ndisplay(Final_df.head())\ntrain_files = []\nval_files   = []\nval_files += list(Final_df[Final_df.fold==fold_num].image_id.unique())\ntrain_files += list(Final_df[Final_df.fold!=fold_num].image_id.unique())\nprint(len(train_files))\nprint(len(val_files))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set up file ảnh có sẵn để train là train 640\n# tạo lập 2 file train và valdiation\n# labels bao gồm class id, x mid,ymid,w,H \nDir_origin_image = '/kaggle/input/train-640'\n# ===============================    \ntrain_image_path = '/kaggle/working/custom_data/images/train'\ntrain_labels_path = '/kaggle/working/custom_data/labels/train'\nval_image_path = '/kaggle/working/custom_data/images/val'\nval_labels_path = '/kaggle/working/custom_data/labels/val'\n# ===============================    \nos.makedirs(train_image_path, exist_ok = True)\nos.makedirs(val_image_path, exist_ok = True)\nos.makedirs(train_labels_path, exist_ok = True)\nos.makedirs(val_labels_path, exist_ok = True)\n# ===============================    \n#Copy, processing image from input to Working and create annotation file\nfor image_index in tqdm(train_files, total=len(train_files)):\n    path_origin_images = os.path.join(Dir_origin_image, image_index +\".jpg\")\n    # ===============================\n    path_images = os.path.join(train_image_path, image_index +\".jpg\")\n    path_label = os.path.join(train_labels_path, image_index +\".txt\")\n    # ===============================\n    Preprocessing(path_origin_images, path_images)\n    create_annotation(image_index,train_labels_path,Final_df)\n# ===============================    \nfor image_index in tqdm(val_files, total=len(val_files)):\n    path_origin_images = os.path.join(Dir_origin_image, image_index +\".jpg\")\n    # ===============================\n    path_images = os.path.join(val_image_path, image_index +\".jpg\")\n    path_label = os.path.join(val_labels_path, image_index +\".txt\")\n    # ===============================\n    Preprocessing(path_origin_images, path_images)\n    create_annotation(image_index,val_labels_path,Final_df)\n# ===============================       \n#Create train.txt and test.txt(txt là dạng vb)\nDir_custom = '/kaggle/working/custom_data'\ntrain = 'train'\ntest = 'test'\n# ===============================    \ntrain_txt_path = os.path.join(Dir_custom,'train.txt')\ntest_txt_path = os.path.join(Dir_custom,'test.txt') \n# ===============================    \nfile_train = open(train_txt_path, \"w+\")\nfor image_id in tqdm(train_files,total=len(train_files)):\n    file_path = os.path.join(train_image_path, image_id +\".jpg\")\n    file_train.write(f'{file_path}\\n')\nfile_train.close()\n# ===============================    \nfile_test = open(test_txt_path, \"w+\")\nfor image_id in tqdm(val_files,total=len(val_files)):\n    file_path = os.path.join(val_image_path, image_id +\".jpg\")\n    file_test.write(f'{file_path}\\n')\nfile_test.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create custom.yaml files, files yaml này sẽ lưu ở dạng text vs các số liệu có sẵn trong 2 file bên trên \n#train : lưu đường truyền của Image/Train\n#Val   : lưu đường truyền của Image/Val\nfrom os.path import isfile, join\nimport yaml\ndata = dict(\n    train =  train_txt_path ,\n    val   =  test_txt_path,\n    nc    = 14,\n    names = classes\n)\nwith open(join( Dir_custom , f'custom.yaml'), 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False)\n\nf = open(join( Dir_custom , f'custom.yaml'), 'r')\nprint('\\nyaml:')\nprint(f.read())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cloning yolov5 model\n!git clone https://github.com/ultralytics/yolov5\n\n#cloning NVIDIA/apex to speed up the process\n!git clone https://github.com/NVIDIA/apex.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom IPython.display import Image, clear_output  # to display images\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv yolov5/* ./","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source /kaggle/working/data/images/zidane.jpg\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image(filename='/kaggle/working/runs/detect/exp/zidane.jpg', width=600)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!WANDB_MODE=\"dryrun\"  python train.py --img 640 --batch 16 --epochs 100 --data /kaggle/working/custom_data/custom.yaml --weights yolov5s.pt --hyp /kaggle/working/data/hyp.scratch.yaml\n\n#!WANDB_MODE=\"dryrun\"  python train.py --batch 16 --epochs 100 --data /kaggle/working/custom_data/custom.yaml --weights /kaggle/input/weight/best_fold4.pt --hyp /kaggle/working/data/hyp.finetune.yaml","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'runs/train/exp/weights/best.pt')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('runs/train/exp/results.png'));","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}