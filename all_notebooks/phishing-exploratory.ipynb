{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Improvements\n\n2021_1 - TÓPICOS EM CIÊNCIA DA COMPUTAÇÃO - CYBERSECURITY DATA SCIENCE\n\n**Task \\#2**\n\n<span style=\"color:blue\">Code improvements are highlight in blue</span>\n\nThe improvements in this notebook were made by exploring the following modifications:\n\n* Multi Layer Perceptron (MLP) with Grid Search\n* Outlier/Anomaly detection to remove instances from training\n* Feature extraction using PCA and PolynomialFeatures models\n* Using of different classifiers\n\n## Results\n\nThe MLP could not achieve good results compared to others classifiers.\nThis occours probably due to the type of data, which is not continous, but discrite.\n\nThe Anomaly detection was performed using a model named IsolationForest, and a few number of instances were removed from the training process. This could slightly increase the accuracy.\n\nThe Feature Extraction techniques have also created interesting results.\nPCA could reduce the number of features, however leads to poor results.\nThe PolynomialFeatures model could create a significantly number of features (about 5000) using the degree parameter equal to 3. This lead to equivalent result compared to the initial.\n\nThe RandomForestClassifier model have presented the better result.\n\n### Default\n\nThe accuracy of your Logistic Regression on testing data is: 84.51684152401988\n\nThe accuracy of your Decision Tree on testing data is: 90.62396466040862\n\n\n### Improved\n\n\nThe accuracy of RandomForestClassifier(max_depth=50, n_estimators=1000, random_state=0)\n\nNormal: 93.06460519050248\n\nNormal (without outliers): 93.13086692435118\n\nPCA (without outliers): 87.49861954721149\n\nPolynomial (without outliers): 91.67310877967974\n\n\n## Future improvements\n\nIt is hard to evaluate the methods without cross validation. It is possible that the improvements leads to an overfiting in the testing data. Other possibility is to create three datasets: training, testing, and validation\n\n\nThe MLP presented poor results. However, it is possible that with more computational power and deeper layers it could lead to better results.\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-26T05:47:09.344751Z","iopub.execute_input":"2021-07-26T05:47:09.345155Z","iopub.status.idle":"2021-07-26T05:47:09.366473Z","shell.execute_reply.started":"2021-07-26T05:47:09.345121Z","shell.execute_reply":"2021-07-26T05:47:09.365285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn import *\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:47:09.36848Z","iopub.execute_input":"2021-07-26T05:47:09.369065Z","iopub.status.idle":"2021-07-26T05:47:09.374335Z","shell.execute_reply.started":"2021-07-26T05:47:09.369016Z","shell.execute_reply":"2021-07-26T05:47:09.373362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the data from 'https://archive.ics.uci.edu/ml/datasets/phishing+websites'\ntraining_data = np.genfromtxt('../input/phishing/phishing.csv', delimiter=',', dtype=np.int32)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:47:09.376479Z","iopub.execute_input":"2021-07-26T05:47:09.377096Z","iopub.status.idle":"2021-07-26T05:47:09.821055Z","shell.execute_reply.started":"2021-07-26T05:47:09.377052Z","shell.execute_reply":"2021-07-26T05:47:09.820136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:47:09.822658Z","iopub.execute_input":"2021-07-26T05:47:09.823264Z","iopub.status.idle":"2021-07-26T05:47:09.830371Z","shell.execute_reply.started":"2021-07-26T05:47:09.823218Z","shell.execute_reply":"2021-07-26T05:47:09.829211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identify the inputs (all of the attributes, except for the last one) and the outputs (the last attribute):\ninputs = training_data[:,:-1]\noutputs = training_data[:,-1]","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:47:09.831811Z","iopub.execute_input":"2021-07-26T05:47:09.832249Z","iopub.status.idle":"2021-07-26T05:47:09.84324Z","shell.execute_reply.started":"2021-07-26T05:47:09.832207Z","shell.execute_reply":"2021-07-26T05:47:09.842275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dividing the dataset into training and testing:\ntraining_inputs = inputs[:2000]\ntraining_outputs = outputs[:2000]\ntesting_inputs = inputs[2000:]\ntesting_outputs = outputs[2000:]\n\ntraining_inputs.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:47:09.844581Z","iopub.execute_input":"2021-07-26T05:47:09.845043Z","iopub.status.idle":"2021-07-26T05:47:09.860629Z","shell.execute_reply.started":"2021-07-26T05:47:09.844996Z","shell.execute_reply":"2021-07-26T05:47:09.859558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_inputs","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:47:09.862158Z","iopub.execute_input":"2021-07-26T05:47:09.862516Z","iopub.status.idle":"2021-07-26T05:47:09.874836Z","shell.execute_reply.started":"2021-07-26T05:47:09.862486Z","shell.execute_reply":"2021-07-26T05:47:09.873986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_outputs","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:47:09.8763Z","iopub.execute_input":"2021-07-26T05:47:09.876708Z","iopub.status.idle":"2021-07-26T05:47:09.889921Z","shell.execute_reply.started":"2021-07-26T05:47:09.876663Z","shell.execute_reply":"2021-07-26T05:47:09.888979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the scikit-learn logistic regression classifier with standard parameters\nclassifier1 = LogisticRegression()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:47:09.892432Z","iopub.execute_input":"2021-07-26T05:47:09.892762Z","iopub.status.idle":"2021-07-26T05:47:09.90331Z","shell.execute_reply.started":"2021-07-26T05:47:09.89273Z","shell.execute_reply":"2021-07-26T05:47:09.902417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the scikit-learn Decision Tree classifier with standard parameters.\nclassifier2 = DecisionTreeClassifier()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:47:09.904713Z","iopub.execute_input":"2021-07-26T05:47:09.905005Z","iopub.status.idle":"2021-07-26T05:47:09.915841Z","shell.execute_reply.started":"2021-07-26T05:47:09.904978Z","shell.execute_reply":"2021-07-26T05:47:09.915039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the classifiers:\nclassifier1.fit(training_inputs, training_outputs)\nclassifier2.fit(training_inputs, training_outputs)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:47:09.917082Z","iopub.execute_input":"2021-07-26T05:47:09.917669Z","iopub.status.idle":"2021-07-26T05:47:09.996306Z","shell.execute_reply.started":"2021-07-26T05:47:09.917626Z","shell.execute_reply":"2021-07-26T05:47:09.995112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(set(list(training_outputs)))\nprint(set(list(testing_outputs)))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:47:10.001967Z","iopub.execute_input":"2021-07-26T05:47:10.002486Z","iopub.status.idle":"2021-07-26T05:47:10.021295Z","shell.execute_reply.started":"2021-07-26T05:47:10.002438Z","shell.execute_reply":"2021-07-26T05:47:10.020005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions:\npredictions1 = classifier1.predict(testing_inputs)\npredictions2 = classifier2.predict(testing_inputs)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:47:10.02678Z","iopub.execute_input":"2021-07-26T05:47:10.027275Z","iopub.status.idle":"2021-07-26T05:47:10.039408Z","shell.execute_reply.started":"2021-07-26T05:47:10.027228Z","shell.execute_reply":"2021-07-26T05:47:10.038174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print out the accuracy of our phishing detector models:\naccuracy1 = 100.0 * accuracy_score(testing_outputs, predictions1)\naccuracy2 = 100.0 * accuracy_score(testing_outputs, predictions2)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:47:10.044935Z","iopub.execute_input":"2021-07-26T05:47:10.04548Z","iopub.status.idle":"2021-07-26T05:47:10.058454Z","shell.execute_reply.started":"2021-07-26T05:47:10.045429Z","shell.execute_reply":"2021-07-26T05:47:10.057496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"The accuracy of your Logistic Regression on testing data is: \" +str(accuracy1))\nprint (\"The accuracy of your Decision Tree on testing data is: \" +str(accuracy2))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:47:10.064011Z","iopub.execute_input":"2021-07-26T05:47:10.064524Z","iopub.status.idle":"2021-07-26T05:47:10.077989Z","shell.execute_reply.started":"2021-07-26T05:47:10.064477Z","shell.execute_reply":"2021-07-26T05:47:10.076662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:blue\">Improvement</span>","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_classification\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import PolynomialFeatures\n\nfrom sklearn.ensemble import IsolationForest\n\nfrom sklearn.neural_network import MLPRegressor, MLPClassifier\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import ExtraTreesClassifier\n\n# Filter by removing outliers\nclf = IsolationForest(max_samples=3, random_state=4, contamination=.1)\n\ny_pred_train = clf.fit_predict(training_inputs)\n# woo = without outliers\ntraining_inputs_woo = training_inputs[np.where(y_pred_train == 1, True, False)]\ntraining_outputs_woo = training_outputs[np.where(y_pred_train == 1)]\n\n\nscaler = MinMaxScaler()\n# scaler = StandardScaler()\nscaler.fit(training_inputs_woo)\ntraining_inputs_woo = scaler.transform(training_inputs_woo)\ntesting_inputs_woo = scaler.transform(testing_inputs)\n\npca = PCA(n_components=15)\npca.fit(training_inputs_woo)\n\npoly = PolynomialFeatures(3)\npoly.fit(training_inputs_woo)\n\n\n\ntraining_inputs_pca = pca.transform(training_inputs_woo)\ntesting_inputs_pca = pca.transform(testing_inputs_woo)\ntraining_outputs_pca = training_outputs_woo\n\ntraining_inputs_poly = poly.transform(training_inputs_woo)\ntesting_inputs_poly = poly.transform(testing_inputs_woo)\ntraining_outputs_poly = training_outputs_woo\n\n# FeatSelect = ExtraTreesClassifier().fit(training_inputs_poly, training_outputs_poly)\n# Model = SelectFromModel(FeatSelect, prefit=True, max_features=200, threshold=-np.inf)\n# training_inputs_poly = Model.transform(training_inputs_poly)\n# testing_inputs_poly = Model.transform(testing_inputs_poly)\n\n\nprint(y_pred_train, training_inputs_pca.shape, training_outputs_pca.shape)\nclassifiers = [\n#     KNeighborsClassifier(10),\n#     SVC(kernel=\"linear\", C=0.025),\n#     SVC(gamma=2, C=1),\n#     GaussianProcessClassifier(1.0 * RBF(1.0)),\n#     DecisionTreeClassifier(max_depth=5),\n#     RandomForestClassifier(max_depth=20, n_estimators=100, max_features=1),\n    RandomForestClassifier(max_depth=50, n_estimators=1000, random_state=0),\n#     LogisticRegression(),\n#     DecisionTreeClassifier(),\n#     MLPClassifier(alpha=1, max_iter=1000),\n#     AdaBoostClassifier(n_estimators=100),\n#     GaussianNB(),\n#     QuadraticDiscriminantAnalysis()\n]\n\nfor clf in classifiers:\n    print (\"\\nThe accuracy of {}\".format(str(clf)))\n    \n    clf.fit(training_inputs, training_outputs)\n    predictions_tmp = clf.predict(testing_inputs)\n    accuracy3 = 100.0 * accuracy_score(testing_outputs, np.around(predictions_tmp).astype(np.int32))\n    print (\"Normal: {}\".format(str(accuracy3)))\n    \n    clf.fit(training_inputs_woo, training_outputs_woo)\n    predictions_tmp = clf.predict(testing_inputs_woo)\n    accuracy3 = 100.0 * accuracy_score(testing_outputs, np.around(predictions_tmp).astype(np.int32))\n    print (\"Normal (wo. outliers): {}\".format(str(accuracy3)))\n    \n    clf.fit(training_inputs_pca, training_outputs_pca)\n    predictions_tmp = clf.predict(testing_inputs_pca)\n    accuracy3 = 100.0 * accuracy_score(testing_outputs, np.around(predictions_tmp).astype(np.int32))\n    print (\"PCA (wo. outliers): {}\".format(str(accuracy3)))\n    \n    clf.fit(training_inputs_poly, training_outputs_poly)\n    predictions_tmp = clf.predict(testing_inputs_poly)\n    accuracy3 = 100.0 * accuracy_score(testing_outputs, np.around(predictions_tmp).astype(np.int32))\n    print (\"Polynomial (wo. outliers): {}\\n\".format(str(accuracy3)))\n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:47:10.08251Z","iopub.execute_input":"2021-07-26T05:47:10.087102Z","iopub.status.idle":"2021-07-26T05:47:30.612727Z","shell.execute_reply.started":"2021-07-26T05:47:10.08703Z","shell.execute_reply":"2021-07-26T05:47:30.611088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <span style=\"color:blue\">MLP</span>","metadata":{}},{"cell_type":"code","source":"# from sklearn.preprocessing import MinMaxScaler\n# from sklearn.model_selection import GridSearchCV\n# from sklearn.neural_network import MLPRegressor, MLPClassifier\n\n# dataset = training_inputs\n\n# scaler = MinMaxScaler()\n# scaler = scaler.fit(dataset)\n# scaled_dataset = scaler.transform(dataset)\n\n\n# # mlpr = MLPRegressor(max_iter=10000, activation='relu', hidden_layer_sizes=[50,50], learning_rate_init=0.0001)\n# # mlpr = MLPClassifier()\n\n\n# # parameters = {\n# #     'solver': ['lbfgs', 'relu', 'logistic', 'tanh'],\n# #     'alpha': 10.0 ** -np.arange(1, 10),\n# #     'hidden_layer_sizes':[50, 100, (50,50), (100,100)],\n# #     'random_state':[0,1]\n# # }\n\n# parameters = {'alpha': [0.01], 'hidden_layer_sizes': [(50, 50)], 'random_state': [0], 'solver': ['adam']}\n# gridCV = GridSearchCV(MLPClassifier(max_iter=10000, learning_rate_init=0.001), parameters, n_jobs=-1, verbose=1)\n# gridCV.fit(dataset, training_outputs)\n# print(gridCV.best_params_)\n\n\n# classifier3 = gridCV\n# # classifier3 = mlpr\n# # predictions3 = classifier3.predict(scaler.transform(testing_inputs))\n# # accuracy3 = 100.0 * accuracy_score(testing_outputs, np.around(predictions3).astype(np.int32))\n# predictions3 = classifier3.predict(testing_inputs)\n# accuracy3 = 100.0 * accuracy_score(testing_outputs, np.around(predictions3).astype(np.int32))\n# print (\"The accuracy of your MLP Regression with Grid Search on testing data is: \" +str(accuracy3))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:47:30.614127Z","iopub.execute_input":"2021-07-26T05:47:30.614474Z","iopub.status.idle":"2021-07-26T05:47:30.619182Z","shell.execute_reply.started":"2021-07-26T05:47:30.614444Z","shell.execute_reply":"2021-07-26T05:47:30.618147Z"},"trusted":true},"execution_count":null,"outputs":[]}]}