{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/wineuci/Wine.csv\", names = ['class','Alcohol','MalicAcid','Ash','AshAlcalinity','Magnesium','Phenol',\n                                      'Flavanoid','NonFlavanoid','Proanthocyanins','ColorIntensity',\n                                      'Hue','DilutedWines','Proline'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to check the if the class is balance\nprint(df.groupby('class').size())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see that the class is imbalance with class 3 as highest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\n# Resample the minority class. You can change the strategy to 'auto' if you are not sure.\nsm = SMOTE(random_state=7)\n\n# Fit the model to generate the data.\noversampled_trainX, oversampled_trainY = sm.fit_sample(df.drop('class', axis=1), df['class'])\noversampled_train = pd.concat([pd.DataFrame(oversampled_trainY), pd.DataFrame(oversampled_trainX)], axis=1)\noversampled_train.columns = df.columns\noversampled_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to chech the class\nprint(oversampled_train.groupby('class').size())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def importdata():\n    df = oversampled_train\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def splitdataset(df):\n    \n    # Seperating the target variable\n    X = df.values[:,1:]  \n    y = df.values[:,0] \n\n    #Split data into training and test datasets (training will be based on 70% of data)\n    from sklearn.model_selection import train_test_split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify =y)\n    \n    # transform data so its distribution will have a mean value 0 and standard deviation of 1\n    from sklearn.preprocessing import StandardScaler\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    \n    X_train = scaler.transform(X_train)\n    X_test = scaler.transform(X_test)\n    \n    #test_size: if integer, number of examples into test dataset; if between 0.0 and 1.0, means proportion\n    print('There are {} samples in the training set and {} samples in the test set'.format(X_train.shape[0], X_test.shape[0]))\n    \n    return X, y, X_train, X_test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier,export_graphviz\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report\nfrom IPython.display import SVG\nfrom graphviz import Source\nfrom IPython.display import display\nfrom sklearn import tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to perform training with giniIndex. \ndef train_using_gini(X_train, X_test, y_train): \n  \n    # Creating the classifier object \n    #clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n    #        random_state = 100,max_depth=8, min_samples_leaf=3)\n    clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100)\n  \n    # Performing training \n    clf_gini.fit(X_train, y_train) \n    return clf_gini","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to perform training with entropy. \ndef tarin_using_entropy(X_train, X_test, y_train): \n  \n    # Decision tree with entropy \n    clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100) \n  \n    # Performing training \n    clf_entropy.fit(X_train, y_train) \n    return clf_entropy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to make predictions \ndef prediction(X_test, clf_object): \n  \n    # Predicton on test with giniIndex \n    y_pred = clf_object.predict(X_test) \n    return y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to show prediction values\ndef pred_result (df,y_test,y_pred_clf):\n\n    df_new = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_clf})\n    df_new['result'] = np.where(df_new['Actual'] == df_new['Predicted'], 'correct', 'wrong')\n    print(df_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to calculate accuracy \ndef cal_accuracy(y_test, y_pred): \n      \n    print(\"Confusion Matrix: \\n\", \n    confusion_matrix(y_test, y_pred)) \n      \n    print (\"Accuracy : \\n\", \n    accuracy_score(y_test,y_pred)*100) \n      \n    print(\"Report : \\n\", \n    classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to draw decision tree\ndef draw_dt (df,clf_object):\n    \n    graph = Source(tree.export_graphviz(clf_object, out_file=None\n                                        , feature_names= df.iloc[:, 1:].columns, class_names=['1', '2', '3'] \n                                        , filled = True))\n    display(SVG(graph.pipe(format='svg')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Driver code \ndef main(): \n      \n    # Building Phase \n    data = importdata() \n    X, y, X_train, X_test, y_train, y_test = splitdataset(data) \n    clf_gini = train_using_gini(X_train, X_test, y_train) \n    clf_entropy = tarin_using_entropy(X_train, X_test, y_train) \n      \n    # Operational Phase \n    print(\"\\n\\033[1m\"+\"Results Using Gini Index:\"+\"\\033[0;0m\") \n      \n    # Prediction using gini \n    y_pred_gini = prediction(X_test, clf_gini) \n    cal_accuracy(y_test, y_pred_gini)\n    \n    #Prediction result\n    pred_result(data,y_test,y_pred_gini)\n    \n     # Draw tree\n    draw_dt (data,clf_gini)\n    \n    print(\"\\n\\n\\033[1m\" + \"Results Using Entropy:\"+\"\\033[0;0m\") \n    # Prediction using entropy \n    y_pred_entropy = prediction(X_test, clf_entropy) \n    cal_accuracy(y_test, y_pred_entropy)\n    \n    #Prediction result\n    pred_result(data,y_test,y_pred_entropy)\n\n    # Draw tree\n    draw_dt (data,clf_entropy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nnp.set_printoptions(threshold=sys.maxsize)\n# Calling main function \nif __name__==\"__main__\": \n    main()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}