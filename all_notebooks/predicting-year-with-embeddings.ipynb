{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicting year of the news with word embeddings\nIn this kernel, I've tried to predict the news year, given the text of the article. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np \nimport pandas as pd\nimport tensorflow as tf\nimport os\nimport plotly.express as px\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom nltk.corpus import stopwords\n\ndevice='cuda:0'\nprint('Tensorflow Version:', tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/news-about-major-cryptocurrencies-20132018-40k/crypto_news_parsed_2013-2018_40k.csv')\nprint(data.info())\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in data.columns:\n    print(f'The unique values in {col}:', data[col].nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, year has 6 unique values. Let's see the distribution of the same in our dataset. "},{"metadata":{"trusted":true},"cell_type":"code","source":"year_dist = data['year'].value_counts()\npx.bar(x=year_dist.index, y = year_dist, title = 'Distribution of years in the dataset', \n       labels = {'x' : 'year', 'y' : 'rows in dataset'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating the model\nWe'll take the text from the data to create a classification model.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data['text'].astype('str')\ny = data['year']\nX.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords = set(stopwords.words('english'))\nX = X.apply(lambda x: ' '.join([x for x in x.split() if x not in stopwords]))\n\n# Replace the years with new encoded numbers\nyear_dict = {2013 : 0, 2014: 1, 2015: 2, 2016 : 3, 2017 : 4, 2018 : 5}\ny = y.replace(year_dict)\ny.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the train and the test set\ntraining_sentences, testing_sentences, training_labels, testing_labels = train_test_split(X, y, test_size=0.2, stratify = y) # Stratify with y to have enough of each class in the training set\ntraining_sentences = training_sentences.tolist()\ntesting_sentences = testing_sentences.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = 300000\nembedding_dim = 32\nmax_length = 500\ntrunc_type='post'\noov_tok = \"<OOV>\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_sentences[0], testing_sentences[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a tokenizer and prepare the train and test set\ntokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\ntokenizer.fit_on_texts(training_sentences)\nword_index = tokenizer.word_index\nsequences = tokenizer.texts_to_sequences(training_sentences)\npadded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n\ntesting_sequences = tokenizer.texts_to_sequences(testing_sentences)\ntesting_padded = pad_sequences(testing_sequences,maxlen=max_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, 32),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(6, activation='softmax')\n])\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 10\nhistory = model.fit(padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\ndef plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_graphs(history, 'accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_graphs(history, 'loss')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}