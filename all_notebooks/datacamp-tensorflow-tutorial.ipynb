{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Code Source:"},{"metadata":{},"cell_type":"markdown","source":"* https://www.datacamp.com/community/tutorials/tensorflow-tutorial\n* https://github.com/LoweCoryr/datacamp-community-tutorials/blob/master/TensorFlow%20Tutorial%20For%20Beginners/TensorFlow%20Tutorial%20For%20Beginners.ipynb"},{"metadata":{},"cell_type":"markdown","source":"# Data Source:"},{"metadata":{},"cell_type":"markdown","source":"* https://btsd.ethz.ch/shareddata/"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom skimage import transform\nfrom skimage import data\nimport matplotlib.pyplot as plt\nimport os\nimport numpy as np\nfrom skimage.color import rgb2gray\nimport random","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TensorFlow Basics"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import `tensorflow`\nimport tensorflow as tf\n\n# Initialize two constants\nx1 = tf.constant([1,2,3,4])\nx2 = tf.constant([5,6,7,8])\n\n# Multiply\nresult = tf.multiply(x1, x2)\n\n# Print the result\nprint(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import `tensorflow` \nimport tensorflow as tf\n\n# Initialize two constants\nx1 = tf.constant([1,2,3,4])\nx2 = tf.constant([5,6,7,8])\n\n# Multiply\nresult = tf.multiply(x1, x2)\n\n# Intialize the Session\nsess = tf.Session()\n\n# Print the result\nprint(sess.run(result))\n\n# Close the session\nsess.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import `tensorflow`\nimport tensorflow as tf\n\n# Initialize two constants\nx1 = tf.constant([1,2,3,4])\nx2 = tf.constant([5,6,7,8])\n\n# Multiply\nresult = tf.multiply(x1, x2)\n\n# Initialize Session and run `result`\nwith tf.Session() as sess:\n    output = sess.run(result)\n    print(output)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading And Exploring The Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(data_dir):\n    # Get all subdirectories of data_dir. Each represents a label.\n    directories = [d for d in os.listdir(data_dir) \n                   if os.path.isdir(os.path.join(data_dir, d))]\n    # Loop through the label directories and collect the data in\n    # two lists, labels and images.\n    labels = []\n    images = []\n    for d in directories:\n        label_dir = os.path.join(data_dir, d)\n        file_names = [os.path.join(label_dir, f) \n                      for f in os.listdir(label_dir) \n                      if f.endswith(\".ppm\")]\n        for f in file_names:\n            images.append(data.imread(f))\n            labels.append(int(d))\n    return images, labels\n\nROOT_PATH = \"../input/\"\ntrain_data_dir = os.path.join(ROOT_PATH, \"BelgiumTSC_Training/Training\")\ntest_data_dir = os.path.join(ROOT_PATH, \"BelgiumTSC_Testing/Testing\")\n\nimages, labels = load_data(train_data_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(data_dir):\n    # Get all subdirectories of data_dir. Each represents a label.\n    directories = [d for d in os.listdir(data_dir) \n                   if os.path.isdir(os.path.join(data_dir, d))]\n    # Loop through the label directories and collect the data in\n    # two lists, labels and images.\n    labels = []\n    images = []\n    for d in directories:\n        label_dir = os.path.join(data_dir, d)\n        file_names = [os.path.join(label_dir, f) \n                      for f in os.listdir(label_dir) \n                      if f.endswith(\".ppm\")]\n        for f in file_names:\n            images.append(data.imread(f))\n            labels.append(int(d))\n    return images, labels\n\nROOT_PATH = \"../input/\"\ntrain_data_dir = os.path.join(ROOT_PATH, \"BelgiumTSC_Training/Training\")\ntest_data_dir = os.path.join(ROOT_PATH, \"BelgiumTSC_Testing/Testing\")\n\nimages, labels = load_data(train_data_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_array = np.array(images)\nlabels_array = np.array(labels)\n\n# Print the `images` dimensions\nprint(images_array.ndim)\n\n# Print the number of `images`'s elements\nprint(images_array.size)\n\n# Print the first instance of `images`\nimages_array[0]\n\n# Print the `labels` dimensions\nprint(labels_array.ndim)\n\n# Print the number of `labels`'s elements\nprint(labels_array.size)\n\n# Count the number of labels\nprint(len(set(labels_array)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the `pyplot` module\nimport matplotlib.pyplot as plt \n\n# Make a histogram with 62 bins of the `labels` data\nplt.hist(labels, 62)\n\n# Show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the `pyplot` module of `matplotlib`\nimport matplotlib.pyplot as plt\n\n# Determine the (random) indexes of the images that you want to see \ntraffic_signs = [300, 2250, 3650, 4000]\n\n# Fill out the subplots with the random images that you defined \nfor i in range(len(traffic_signs)):\n    plt.subplot(1, 4, i+1)\n    plt.axis('off')\n    plt.imshow(images[traffic_signs[i]])\n    plt.subplots_adjust(wspace=0.5)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import `matplotlib`\nimport matplotlib.pyplot as plt\n\n# Determine the (random) indexes of the images\ntraffic_signs = [300, 2250, 3650, 4000]\n\n# Fill out the subplots with the random images and add shape, min and max values\nfor i in range(len(traffic_signs)):\n    plt.subplot(1, 4, i+1)\n    plt.axis('off')\n    plt.imshow(images[traffic_signs[i]])\n    plt.subplots_adjust(wspace=0.5)\n    plt.show()\n    print(\"shape: {0}, min: {1}, max: {2}\".format(images[traffic_signs[i]].shape, \n                                                  images[traffic_signs[i]].min(), \n                                                  images[traffic_signs[i]].max()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the `pyplot` module as `plt`\nimport matplotlib.pyplot as plt \n\n# Get the unique labels \nunique_labels = set(labels)\n\n# Initialize the figure\nplt.figure(figsize=(15, 15))\n\n# Set a counter\ni = 1\n\n# For each unique label,\nfor label in unique_labels:\n    # You pick the first image for each label\n    image = images[labels.index(label)]\n    # Define 64 subplots \n    plt.subplot(8, 8, i)\n    # Don't include axes\n    plt.axis('off')\n    # Add a title to each subplot \n    plt.title(\"Label {0} ({1})\".format(label, labels.count(label)))\n    # Add 1 to the counter\n    i += 1\n    # And you plot this first image \n    plt.imshow(image)\n    \n# Show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Extraction"},{"metadata":{},"cell_type":"markdown","source":"# Rescaling Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resize images\nimages32 = [transform.resize(image, (28, 28)) for image in images]\nimages32 = np.array(images32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import `matplotlib`\nimport matplotlib.pyplot as plt\n\n# Determine the (random) indexes of the images\ntraffic_signs = [300, 2250, 3650, 4000]\n\n# Fill out the subplots with the random images and add shape, min and max values\nfor i in range(len(traffic_signs)):\n    plt.subplot(1, 4, i+1)\n    plt.axis('off')\n    plt.imshow(images32[traffic_signs[i]])\n    plt.subplots_adjust(wspace=0.5)\n    plt.show()\n    print(\"shape: {0}, min: {1}, max: {2}\".format(images32[traffic_signs[i]].shape, \n                                                  images32[traffic_signs[i]].min(), \n                                                  images32[traffic_signs[i]].max()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image Conversion to Grayscale"},{"metadata":{"trusted":true},"cell_type":"code","source":"images32 = rgb2gray(np.array(images32))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(traffic_signs)):\n    plt.subplot(1, 4, i+1)\n    plt.axis('off')\n    plt.imshow(images32[traffic_signs[i]], cmap=\"gray\")\n    plt.subplots_adjust(wspace=0.5)\n    \nplt.show()\n\nprint(images32.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Deep Learning with Tensorflow"},{"metadata":{},"cell_type":"markdown","source":"# Modeling The Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = tf.placeholder(dtype = tf.float32, shape = [None, 28, 28])\ny = tf.placeholder(dtype = tf.int32, shape = [None])\nimages_flat = tf.contrib.layers.flatten(x)\nlogits = tf.contrib.layers.fully_connected(images_flat, 62, tf.nn.relu)\nloss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = logits))\ntrain_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\ncorrect_pred = tf.argmax(logits, 1)\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\nprint(\"images_flat: \", images_flat)\nprint(\"logits: \", logits)\nprint(\"loss: \", loss)\nprint(\"predicted_labels: \", correct_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Running The Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"sess = tf.Session()\n\nsess.run(tf.global_variables_initializer())\n\nfor i in range(201):\n        print('EPOCH', i)\n        _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x: images32, y: labels})\n        if i % 10 == 0:\n            print(\"Loss: \", loss)\n        print('DONE WITH EPOCH')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Alternatively, you can also run the following lines of code instead of the code chunk above:\n#with tf.Session() as sess:\n#    sess.run(tf.global_variables_initializer())\n#    for i in range(201):\n#        print('EPOCH', i)\n#        _, accuracy_val = sess.run([train_op, accuracy], feed_dict={x: images32, y: labels})\n#        if i % 10 == 0:\n#            print(\"Loss: \", loss)\n#        print('DONE WITH EPOCH')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating The Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pick 10 random images\nsample_indexes = random.sample(range(len(images32)), 10)\nsample_images = [images32[i] for i in sample_indexes]\nsample_labels = [labels[i] for i in sample_indexes]\n\n# Run the \"predicted_labels\" op.\npredicted = sess.run([correct_pred], feed_dict={x: sample_images})[0]\n                        \n# Print the real and predicted labels\nprint(sample_labels)\nprint(predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display the predictions and the ground truth visually.\nfig = plt.figure(figsize=(10, 10))\nfor i in range(len(sample_images)):\n    truth = sample_labels[i]\n    prediction = predicted[i]\n    plt.subplot(5, 2,1+i)\n    plt.axis('off')\n    color='green' if truth == prediction else 'red'\n    plt.text(40, 10, \"Truth:        {0}\\nPrediction: {1}\".format(truth, prediction), \n             fontsize=12, color=color)\n    plt.imshow(sample_images[i])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the test data\ntest_images, test_labels = load_data(test_data_dir)\n\n# Transform the images to 28 by 28 pixels\ntest_images28 = [transform.resize(image, (28, 28)) for image in test_images]\n\n# Convert to grayscale\nfrom skimage.color import rgb2gray\ntest_images28 = rgb2gray(np.array(test_images28))\n\n# Run predictions against the full test set.\npredicted = sess.run([correct_pred], feed_dict={x: test_images28})[0]\n\n# Calculate correct matches \nmatch_count = sum([int(y == y_) for y, y_ in zip(test_labels, predicted)])\n\n# Calculate the accuracy\naccuracy = match_count / len(test_labels)\n\n# Print the accuracy\nprint(\"Accuracy: {:.3f}\".format(accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sess.close()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}