{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nimport pandas_profiling as pp\n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\ndata.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#RP = ProfileReport(data)\n#RP.to_file(output_file='output.html')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\ndata.hist(bins=50, figsize=(20,15))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_matrix=data.corr()\n\ncorr_matrix['quality'].sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nf, ax = plt.subplots(figsize=(10, 8))\nsns.heatmap(corr_matrix, mask=np.zeros_like(corr_matrix, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            square=True, ax=ax)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**fixed acidity have linear relation ship with density, pH and citric acid**","metadata":{}},{"cell_type":"code","source":"plt.scatter(data['fixed acidity'], data['density'])\nplt.xlabel(\"fixed acidity\")\nplt.ylabel(\"density\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(data['fixed acidity'], data['citric acid'])\nplt.xlabel(\"fixed acidity\")\nplt.ylabel(\"citric acid\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(data['fixed acidity'], data['pH'])\nplt.xlabel(\"fixed acidity\")\nplt.ylabel(\"pH\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X= data.iloc[ : , :-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\ndef calc_vif(X):\n\n    # Calculating VIF\n    vif = pd.DataFrame()\n    vif[\"variables\"] = X.columns\n    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n\n    return(vif)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"calc_vif(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**pH is correlated with acidity, lower ph value mean more acidic property, we can look at vif of varible it also confirm pH can be explained by other variable present so i am going to drop ph**","metadata":{}},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=data[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n        'sulphates', 'alcohol']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# converting the response variables(3-7) as binary response variables that is either good or bad\nbins = (2,6.5,8)\nlabels = ['bad','good']\ndata['quality'] = pd.cut(data['quality'],bins=bins,labels=labels)\n\n#encoding categorical\nle = LabelEncoder()\ndata['quality'] = le.fit_transform(data['quality'])\n\n#set dependent variable\ny=data[['quality']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['quality'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n\n# determining the shapes of training and testing sets\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform (X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression","metadata":{}},{"cell_type":"code","source":"# creating the model\nmodel = LogisticRegression()\n\n# feeding the training set into the model\nmodel.fit(X_train, y_train)\n\n# predicting the results for the test set\ny_pred = model.predict(X_test)\n\n# calculating the training and testing accuracies\nprint(\"Training accuracy :\", model.score(X_train, y_train))\nprint(\"Testing accuracy :\", model.score(X_test, y_test))\n\n# classification report\nprint(classification_report(y_test, y_pred))\n\n# confusion matrix\nprint(confusion_matrix(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#roc_auc  score for logistic model\n\nfpr1, tpr1, thresholds1 = roc_curve(y_test, y_pred)\nauc_score1 = roc_auc_score(y_test, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## k-nearest neighbour","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nmodel = KNeighborsClassifier(n_neighbors=3)\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\n\n# calculating the training and testing accuracies\nprint(\"Training accuracy :\", model.score(X_train, y_train))\nprint(\"Testing accuracy :\", model.score(X_test, y_test))\n\n# classification report\nprint(classification_report(y_test, y_pred))\n\n# confusion matrix\nprint(confusion_matrix(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#roc_auc  score for KNN model\n\nfpr2, tpr2, thresholds2 = roc_curve(y_test, y_pred)\nauc_score2 = roc_auc_score(y_test, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#comparing roc_auc_socre for bothe the model\nprint(auc_score1, auc_score2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Result","metadata":{}},{"cell_type":"markdown","source":"**KNN work better thn logistic regression**\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}