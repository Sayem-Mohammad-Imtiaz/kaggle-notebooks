{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text extraction from Image\n\nText detection is the process of determining the location of text in an image.Text detection can be thought of as a subset of object detection.\nI am using Pytesseract library to extract the text.\nif you really like it then upvote.\n\n\n\n\n\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Import All Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud,STOPWORDS\nimport re,string,unicodedata\nimport gensim.parsing.preprocessing as gsp\nfrom gensim import utils\nfrom textblob import TextBlob, Word\nfrom nltk.corpus import stopwords\nfrom nltk import word_tokenize\nSTOPWORDS = set(stopwords.words('english'))\nimport pytesseract\nimport gc\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#read the sentiment dataset\nimage_data = '../input/detecting-sentiments-dataset/Sample Data Files/'\ndata_test = '../input/detecting-sentiments-dataset/Dataset/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text Extraction "},{"metadata":{"trusted":true},"cell_type":"code","source":"txt = []\n\n#extracting the text \ndef TxtExtract(directory):\n    \n    for subdir, dirs, files in os.walk(directory):\n        for file in files:\n            filepath = subdir + os.sep + file\n            text = pytesseract.image_to_string(Image.open(filepath), timeout=5)\n            if not text:\n                txt.extend([[file, \"blank\"]])\n            else:   \n                txt.extend([[file, text]])\n                \n    fol_nm = os.path.split(os.path.dirname(subdir))[-1]\n    \n    print(f\"Text Extracted from the images '{fol_nm}' folder & saved to list..\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text Extracted from Image"},{"metadata":{"trusted":true},"cell_type":"code","source":"TxtExtract(image_data)\nTxtExtract(data_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Created a DataFrame with text data after extraction"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(txt,columns=['Image_Name','text_data'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['text_data'].apply(str)\n# df['text_data']=df['text_data'].fillna(\"na\").values\n#Text preprocessing\n# import re\n# #train_data = text_data.reset_index(drop=True)\n# REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n# BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n# STOPWORDS = set(stopwords.words('english'))\n\n# def clean_text(text):\n#     \"\"\"\n#         text: a string\n        \n#         return: modified initial string\n#     \"\"\"\n#     text = text.lower() # lowercase text\n#     text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n#     text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n#     text = text.replace('text', ' ')\n#     text =\" \".join([i for i in text if i.isdigit()])\n#     text = re.sub(r'\\W+', '', text)\n#     text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n#     return text\n# df['text_data'] = df['text_data'].apply(clean_text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Sentiment using Textblob"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating sentiment using Textblob\n\ndef data_senti(text):\n    TB_sentiment_polarity = TextBlob(text).sentiment.polarity\n    \n    # decide sentiment as positive, negative and neutral \n    if TB_sentiment_polarity >= 0.00 : \n        return \"Positive\" \n  \n    elif TB_sentiment_polarity <= 0.00 : \n        return \"Negative\" \n  \n    else : \n        return \"Neutral\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['label'] = df['text_data'].apply(lambda x: data_senti(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Word_Cloud implementation"},{"metadata":{"trusted":true},"cell_type":"code","source":"positive1 = df[ df['label'] == 'Positive']\npositive1 = df['text_data']\nnegative1 = df[ df['label'] == 'Negative']\nnegative1 = df['text_data']\n\ndef wordcloudimp(data, color = 'black'):\n    words = ' '.join(data)\n    cleaned_word = \" \".join([word for word in words.split()\n                            if 'http' not in word\n                                and not word.startswith('@')\n                                and not word.startswith('#')\n                                and word != 'RT'\n                            ])\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                      background_color=color,\n                      width=2500,\n                      height=2000\n                     ).generate(cleaned_word)\n    plt.figure(1,figsize=(13, 13))\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n    \nprint(\"Extracted Positive words\")\nwordcloudimp(positive1,'white')\nprint(\"Extracted Negative words\")\nwordcloudimp(negative1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}