{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hi Folks!\n\nIn this project, two types of analyzes for predicting avocado prices are displayed;\n\n**Time Series Analysis** and **Machine Learning Analysis**.\n\nI used Prophet for Time Series analysis (it's open source software released by Facebook's Core Data Science team).\n\nAnd then I applied Regression and Machine Learning Algorithms to the data; \n* Linear Regression, \n* Ridge Regression, \n* Lasso Regression, \n* KNN, \n* SVR, \n* Decision Tree, and \n* Random Forest.\n\nGuess which one gives the best accuracy! It depends, we will see :)\n\nUntil then, ENJOY MACHINE LEARNING!\n\n<img src=\"https://cognigen-cellular.com/images/avocado-clipart-4.png\" width=\"250px\"/>\n","attachments":{}},{"metadata":{"trusted":true},"cell_type":"code","source":"# Update necessary packages first\n!pip3 uninstall --yes fbprophet\n!pip3 install fbprophet --no-cache-dir --no-binary :all:\n!pip3 install pydotplus --no-cache-dir --no-binary :all:\n\n        \n","execution_count":null,"outputs":[]},{"metadata":{"id":"Jx31rRciPhFz","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# importing libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport warnings\nwarnings.filterwarnings(\"ignore\") # Don't want to see the warnings in the notebook\nfrom sklearn import svm\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"fcAFIJBUSJnB","colab_type":"code","colab":{},"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"# downloading and describing the dataset\n\ndf = pd.read_csv('../input/avocado.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"id":"ZrEOeK9NmI4r","colab_type":"code","outputId":"44dedfca-f2ab-4d32-d475-81e86a9eab77","colab":{"base_uri":"https://localhost:8080/","height":204},"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"WHinvkRIxnDJ","colab_type":"code","outputId":"6809d642-dce8-4244-ce90-08e3b2f0aa0d","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"xlXpCY5Ymf-0","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Some relevant columns in the dataset:\n\n# Date - The date of the observation\n\n# AveragePrice - the average price of a single avocado\n\n# type - conventional or organic\n\n# year - the year\n\n# Region - the city or region of the observation\n\n# Total Volume - Total number of avocados sold\n\n# 4046 - Total number of avocados with PLU 4046 sold  (Small Hass)\n# 4225 - Total number of avocados with PLU 4225 sold  (Large Hass)\n# 4770 - Total number of avocados with PLU 4770 sold  (XLarge Hass)","execution_count":null,"outputs":[]},{"metadata":{"id":"X262vg_Ew9i-","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Weekly 2018 retail scan data for National retail volume (units) and price.\n\n# Retail scan data comes directly from retailers’ cash registers based on actual retail sales of Hass avocados. \n\n# The Average Price (of avocados) in the table reflects a per unit (per avocado) cost, even when multiple units (avocados) are sold in bags. \n\n# The Product Lookup codes (PLU’s) in the table are only for Hass avocados.\n\n# Other varieties of avocados (e.g. greenskins) are not included in this table.","execution_count":null,"outputs":[]},{"metadata":{"id":"M1_0AdrQxWwb","colab_type":"code","outputId":"06968616-b53c-4891-90f2-e546c5bb591e","colab":{"base_uri":"https://localhost:8080/","height":272},"trusted":true},"cell_type":"code","source":"df.isnull().sum()     # is there any NULL variable in the dataset?\n","execution_count":null,"outputs":[]},{"metadata":{"id":"6gS2vtVtmMVW","colab_type":"code","outputId":"4c41a929-c21f-42a6-d534-0ef5456783cb","colab":{"base_uri":"https://localhost:8080/","height":297},"trusted":true},"cell_type":"code","source":"df.describe().round(2)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"7nXUG33fmILX","colab_type":"code","outputId":"cb6e7ebb-2d26-4151-8a2d-fa4343baea4e","colab":{"base_uri":"https://localhost:8080/","height":340},"trusted":true},"cell_type":"code","source":"df.info() \n","execution_count":null,"outputs":[]},{"metadata":{"id":"u4IP2T8pmv_h","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# To summarise the dataset we see;\n\n# 14 columns (variables) and 18249 rows (observations)\n\n# There isn't any NULL variable\n\n# data types: float64(9), int64(2), object(3)\n\n# there are some unnamed/undefined columns\n\n# 'region','type' and 'date' columns are in object format","execution_count":null,"outputs":[]},{"metadata":{"id":"-D9ePUgVa4_4","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Target of this project is to predict the future price of avocados depending on those variables we have; \n\n# * Type     *Bags(4 units) vs Bundle(one unit)     *Region      *Volume      *Size     *Years\n","execution_count":null,"outputs":[]},{"metadata":{"id":"Smv3EO1DSQnt","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# PREPROCESSING\n\n# drop unnamed column and rename undefined columns;\n\ndf = df.drop(['Unnamed: 0'], axis = 1)\n\ndf = df.rename(index=str, columns={\"4046\" : \"Small Hass\", \"4225\" : \"Large Hass\",\"4770\" : \"XLarge Hass\" })","execution_count":null,"outputs":[]},{"metadata":{"id":"xAVJujVmSVJv","colab_type":"code","outputId":"c0424680-e4da-4736-c913-b57e30c395d2","colab":{"base_uri":"https://localhost:8080/","height":204},"trusted":true},"cell_type":"code","source":"# convert Date column's format;\n\ndf['Date'] =pd.to_datetime(df.Date)\n\ndf.sort_values(by=['Date'], inplace=True, ascending=True)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"uVUHVisOlmXX","colab_type":"code","outputId":"30e8cc27-7299-4a31-914a-631e6541ba5f","colab":{"base_uri":"https://localhost:8080/","height":497},"trusted":true},"cell_type":"code","source":"# Average price of Conventional Avocados over time\n\nmask = df['type']== 'conventional'\nplt.rc('figure', titlesize=50)\nfig = plt.figure(figsize = (26, 7))\nfig.suptitle('Average Price of Conventional Avocados Over Time', fontsize=25)\nax = fig.add_subplot(111)\nfig.subplots_adjust(top=0.93)\n\ndates = df[mask]['Date'].tolist()\navgPrices = df[mask]['AveragePrice'].tolist()\n\nplt.scatter(dates, avgPrices, c=avgPrices, cmap='plasma')\nax.set_xlabel('Date',fontsize = 15)\nax.set_ylabel('Average Price (USD)', fontsize = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"RZ4z1dc40DJl","colab_type":"code","outputId":"f3af2ad2-2f02-43c8-cb85-d178124a714b","colab":{"base_uri":"https://localhost:8080/","height":497},"trusted":true},"cell_type":"code","source":"# Average price of Organic Avocados over time\nmask = df['type']== 'organic'\nplt.rc('figure', titlesize=50)\nfig = plt.figure(figsize = (26, 7))\nfig.suptitle('Average Price of Organic Avocados Over Time', fontsize=25)\nax = fig.add_subplot(111)\nfig.subplots_adjust(top=0.93)\n\ndates = df[mask]['Date'].tolist()\navgPrices = df[mask]['AveragePrice'].tolist()\n\nplt.scatter(dates, avgPrices, c=avgPrices, cmap='plasma')\nax.set_xlabel('Date',fontsize = 15)\nax.set_ylabel('Average Price (USD)', fontsize = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"jFwEO2hbfTDQ","colab_type":"code","outputId":"fd994232-bec7-4243-fa82-b77347418b71","colab":{"base_uri":"https://localhost:8080/","height":204},"trusted":true},"cell_type":"code","source":"# TIME SERIES ANALYSIS\n\n# Since the data itself is a time series data, I first want to see time series analysis predictions, and then apply ML models.\n\n# Creating a two-column dataset to use in time series analysis;\n\ndf2 = df[['Date', 'AveragePrice']]\ndf2 = df2.set_index('Date')\n\nweekly_df = df2.resample('W').mean()\nw_df = weekly_df.reset_index().dropna()\n\nw_df.sort_values(by=['Date'])\nw_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"eyQGpijG6hyt","colab_type":"code","outputId":"48da2236-e0ac-46ae-eb43-01ab5ee21269","colab":{"base_uri":"https://localhost:8080/","height":463},"trusted":true},"cell_type":"code","source":"# Plotting the weekly average prices by month;\n\nimport matplotlib.dates as mdates\n\n\nfig = plt.figure(figsize = (27, 7))\nax = plt.axes()\n#set ticks every month\nax.xaxis.set_major_locator(mdates.MonthLocator())\n#set major ticks format\nax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\nplt.plot(w_df['Date'],w_df['AveragePrice'],color='b', linewidth=1)\nplt.xlabel(\"2015-2018\")\nplt.ylabel(\"Avocado Price USD\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"br5FFOWeAzri","colab_type":"code","outputId":"956fd4aa-8fd2-4361-8392-a5292f2b7d47","colab":{"base_uri":"https://localhost:8080/","height":221},"trusted":true},"cell_type":"code","source":"# Time Series Forecasts using Facebook's Prophet()\n\nw_df.columns = ['ds', 'y']\n\nfrom fbprophet import Prophet\n\nP=Prophet(interval_width=0.95, yearly_seasonality=True, weekly_seasonality=False, changepoint_range=1) \n#interval_width sets the uncertainty interval to produce a confidence interval around the forecast\n\nP.add_seasonality(name='monthly', period=30.5, fourier_order=5, prior_scale=0.02)\n\n\nP.fit(w_df)\n\nfuture = P.make_future_dataframe(freq='W', periods=4)  # Let's predict the next month's average prices\n\nfuture.tail()","execution_count":null,"outputs":[]},{"metadata":{"id":"nieM_WzcBL8m","colab_type":"code","outputId":"c84e4ed5-6073-46f2-92e2-2c598ea54549","colab":{"base_uri":"https://localhost:8080/","height":437},"trusted":true},"cell_type":"code","source":"from fbprophet.plot import add_changepoints_to_plot\n\nforecast = P.predict(future)\nfig = P.plot(forecast)\na = add_changepoints_to_plot(fig.gca(), P, forecast)","execution_count":null,"outputs":[]},{"metadata":{"id":"_FA7xE9m6fzC","colab_type":"code","outputId":"fd3c7043-c0a7-4681-e585-aba40bf988dd","colab":{"base_uri":"https://localhost:8080/","height":204},"trusted":true},"cell_type":"code","source":"forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","execution_count":null,"outputs":[]},{"metadata":{"id":"OfHBD3leDgM-","colab_type":"code","outputId":"2b914073-14fa-48f4-c3af-34dd85aeba8f","colab":{"base_uri":"https://localhost:8080/","height":653},"trusted":true},"cell_type":"code","source":"fig2 = P.plot_components(forecast)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"BPHOfMRIFvMg","colab_type":"code","outputId":"fa76fdb6-f9ef-48c0-af17-fe6afafe6d2f","colab":{"base_uri":"https://localhost:8080/","height":221},"trusted":true},"cell_type":"code","source":"from fbprophet.diagnostics import cross_validation, performance_metrics\ndf_cv = cross_validation(P, initial = '365 days', period = '30 days', horizon = '30 days')\n\ndf_cv.tail()","execution_count":null,"outputs":[]},{"metadata":{"id":"g9RdxKR6F6LM","colab_type":"code","outputId":"716a12d3-6e2c-4c39-e542-fe89c85cd8ba","colab":{"base_uri":"https://localhost:8080/","height":204},"trusted":true},"cell_type":"code","source":"from fbprophet.diagnostics import performance_metrics\ndf_p = performance_metrics(df_cv)\ndf_p.tail()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"069WbBDS-d9T","colab_type":"code","outputId":"8d527614-59aa-4d18-916c-7b71beda3738","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"np.mean(df_p['mape'])","execution_count":null,"outputs":[]},{"metadata":{"id":"tmJ4UtyFswtC","colab_type":"code","outputId":"8113ceca-f8dc-4f18-f3da-86ba6ac59ac2","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"np.mean(df_p['rmse'])","execution_count":null,"outputs":[]},{"metadata":{"id":"vkaShEN2F-Qx","colab_type":"code","outputId":"28dd0f1b-d913-4244-a597-d57573d9849f","colab":{"base_uri":"https://localhost:8080/","height":388},"trusted":true},"cell_type":"code","source":"from fbprophet.plot import plot_cross_validation_metric\nfig = plot_cross_validation_metric(df_cv, metric='mape')\n# mean absolute percentage error MAPE  \n","execution_count":null,"outputs":[]},{"metadata":{"id":"U8u9jFyjRfKp","colab_type":"code","outputId":"3d2cf08e-5099-44e2-e72c-6506b08c255d","colab":{"base_uri":"https://localhost:8080/","height":204},"trusted":true},"cell_type":"code","source":"forecastnew = forecast['ds']\nforecastnew2 = forecast['yhat']\n\nforecastnew = pd.concat([forecastnew,forecastnew2], axis=1)\n\nmask = (forecastnew['ds'] > \"2018-03-24\") & (forecastnew['ds'] <= \"2020-09-10\")\nforecastedvalues = forecastnew.loc[mask]\n\nmask = (forecastnew['ds'] > \"2015-01-04\") & (forecastnew['ds'] <= \"2018-03-25\")\nforecastnew = forecastnew.loc[mask]\n\nforecastedvalues\n\n# Predictions for the next month are as follows;","execution_count":null,"outputs":[]},{"metadata":{"id":"bMHQgzgE7uxI","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# We already know that y=1.347 for 2018-03-25, and the model prediction is 1.388, which is actually over 3% of the real value.","execution_count":null,"outputs":[]},{"metadata":{"id":"pOu4etw7RpfI","colab_type":"code","outputId":"ff261991-20dd-44ae-fb6d-6ba39047d6ea","colab":{"base_uri":"https://localhost:8080/","height":351},"trusted":true},"cell_type":"code","source":"fig, ax1 = plt.subplots(figsize=(21, 5))\nax1.plot(forecastnew.set_index('ds'), color='b')\nax1.plot(forecastedvalues.set_index('ds'), color='r')\nax1.set_ylabel('Average Prices')\nax1.set_xlabel('Date')\nprint(\"Red = Predicted Values, Blue = Base Values\")","execution_count":null,"outputs":[]},{"metadata":{"id":"B3OCAcit-Ggu","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# With Facebook Prophet() we obtain forecasts which are off by 8% due to MAPE values. (Accuracy= 92%)\n\n# The Prophet predicts future prices in a downward trend.","execution_count":null,"outputs":[]},{"metadata":{"id":"cmtM185iBPBE","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Now, Let's see what we get from Machine Learning Algorithms!","execution_count":null,"outputs":[]},{"metadata":{"id":"Q5NVLyB2SYlN","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Dropping the Date column (date format is not suitable for next level analysis (i.e. OHE))\ndf = df.drop(['Date'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"G51OgbKLSavh","colab_type":"code","outputId":"6cc79425-4bee-495c-87c4-89072d062b5e","colab":{"base_uri":"https://localhost:8080/","height":969},"trusted":true},"cell_type":"code","source":"# Checking if the sample is balanced;\ndf.groupby('region').size() # Approximately, there are 338 observations from each region, sample seems balanced.\n","execution_count":null,"outputs":[]},{"metadata":{"id":"BHmaBodpsQMk","colab_type":"code","outputId":"a7751722-93c7-4f05-b9c7-0fc1f52645b8","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"len(df.region.unique())\n","execution_count":null,"outputs":[]},{"metadata":{"id":"-6ncoq7MsXsw","colab_type":"code","outputId":"847c8cc3-6c66-467e-8dc5-7d2dfb9d4980","colab":{"base_uri":"https://localhost:8080/","height":238},"trusted":true},"cell_type":"code","source":"df.region.unique() # There are 54 regions but some are subsets of the other regions, i.e: San Francisco-California\n","execution_count":null,"outputs":[]},{"metadata":{"id":"CV1CS4sasSsO","colab_type":"code","outputId":"f8b20be3-5176-45c7-a443-743749efac4a","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"# basically we can remove states and work on cities rather than analysing both (to prevent multicollinerarity)\n\nregionsToRemove = ['California', 'GreatLakes', 'Midsouth', 'NewYork', 'Northeast', 'SouthCarolina', 'Plains', 'SouthCentral', 'Southeast', 'TotalUS', 'West']\ndf = df[~df.region.isin(regionsToRemove)]\nlen(df.region.unique())","execution_count":null,"outputs":[]},{"metadata":{"id":"ZiRwiyemjg07","colab_type":"code","outputId":"694b75d5-6e2b-43fd-c192-6fd73809e6eb","colab":{"base_uri":"https://localhost:8080/","height":675},"trusted":true},"cell_type":"code","source":"# The average prices by regions\n\nplt.figure(figsize=(10,11))\nplt.title(\"Avg.Price of Avocado by Region\")\nAv= sns.barplot(x=\"AveragePrice\",y=\"region\",data= df)","execution_count":null,"outputs":[]},{"metadata":{"id":"044DFSNgSnKT","colab_type":"code","outputId":"fbd2a8ed-27ab-49e7-d67a-3f00dff06c8f","colab":{"base_uri":"https://localhost:8080/","height":85},"trusted":true},"cell_type":"code","source":"type_counts = df.groupby('type').size()\nprint(type_counts) \n\n# Types of avocados are also balanced since the ratio is almost 0.5","execution_count":null,"outputs":[]},{"metadata":{"id":"4LjUrwoYjuab","colab_type":"code","outputId":"8a228d4f-52f3-49d6-d6c2-a59ec080f2f9","colab":{"base_uri":"https://localhost:8080/","height":457},"trusted":true},"cell_type":"code","source":"# The average prices of avocados by types; organic or not\n\nplt.figure(figsize=(5,7))\nplt.title(\"Avg.Price of Avocados by Type\")\nAv= sns.barplot(x=\"type\",y=\"AveragePrice\",data= df)","execution_count":null,"outputs":[]},{"metadata":{"id":"y8G6756bSoSC","colab_type":"code","outputId":"c52714b1-a040-454a-b0a7-31a02dd3743f","colab":{"base_uri":"https://localhost:8080/","height":297},"trusted":true},"cell_type":"code","source":"# Total Bags = Small Bags + Large Bags + XLarge Bags\n\n# To avoid multicollinearity I'll keep S-L-XL bags and drop Total Bags\n\n# But before droping we'd better to see the correlation between those columns:\n\ndf[['Small Hass', \"Large Hass\", \"XLarge Hass\",'Small Bags','Large Bags','XLarge Bags','Total Volume','Total Bags']].corr()","execution_count":null,"outputs":[]},{"metadata":{"id":"Xb10prmqUayx","colab_type":"code","outputId":"945ad510-ab0a-4dbf-8c36-c7caa6cd7031","colab":{"base_uri":"https://localhost:8080/","height":391},"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.heatmap(df.corr(),cmap='coolwarm',annot=True)\n\n# darker = stronger","execution_count":null,"outputs":[]},{"metadata":{"id":"_8i6hcb3SrxJ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# There is a high correlation between those pairs: \n# small hass & total volume  (0.89)      \n# total bags & total volume  (0.87)      \n# small bags & total bags    (0.96)      \n\n# Small Hass avocados are the most preferred/sold type in the US and customers tend to buy those avocados as bulk, not bag.\n# Retailers want to increase the sales of bagged avocados instead of bulks. They think this is more advantageous for them.\n# Total Bags variable has a very high correlation with Total Volume (Total Sales) and Small Bags, so we can say that most of the bagged sales comes from the small bags.","execution_count":null,"outputs":[]},{"metadata":{"id":"KUVNu9CiGXgN","colab_type":"code","outputId":"50a1f543-d926-4a42-a5e9-4e6fa49173ab","colab":{"base_uri":"https://localhost:8080/","height":204},"trusted":true},"cell_type":"code","source":"df_V = df.drop(['AveragePrice', 'Total Volume', 'Total Bags'], axis = 1).groupby('year').agg('sum')\ndf_V\n","execution_count":null,"outputs":[]},{"metadata":{"id":"ZQ_D-mAWIdEQ","colab_type":"code","outputId":"19ced112-b91f-4023-d155-a7c9d5179e6e","colab":{"base_uri":"https://localhost:8080/","height":2106},"trusted":true},"cell_type":"code","source":"indexes = ['Small Hass', 'Large Hass', 'XLarge Hass', 'Small Bags', 'Large Bags', 'XLarge Bags']\nseries = pd.DataFrame({'2015': df_V.loc[[2015],:].values.tolist()[0],\n                      '2016': df_V.loc[[2016],:].values.tolist()[0],\n                      '2017': df_V.loc[[2017],:].values.tolist()[0],\n                      '2018': df_V.loc[[2018],:].values.tolist()[0]}, index=indexes)\nseries.plot.pie(y='2015',figsize=(9, 9), autopct='%1.1f%%', colors=['silver', 'pink', 'orange', 'palegreen', 'aqua', 'blue'], fontsize=18, legend=False, title='2015 Volume Distribution').set_ylabel('')\nseries.plot.pie(y='2016',figsize=(9, 9), autopct='%1.1f%%', colors=['silver', 'pink', 'orange', 'palegreen', 'aqua', 'blue'], fontsize=18, legend=False, title='2016 Volume Distribution').set_ylabel('')\nseries.plot.pie(y='2017',figsize=(9, 9), autopct='%1.1f%%', colors=['silver', 'pink', 'orange', 'palegreen', 'aqua', 'blue'], fontsize=18, legend=False, title='2017 Volume Distribution').set_ylabel('')\nseries.plot.pie(y='2018',figsize=(9, 9), autopct='%1.1f%%', colors=['silver', 'pink', 'orange', 'palegreen', 'aqua', 'blue'], fontsize=18, legend=False, title='2018 Volume Distribution').set_ylabel('')","execution_count":null,"outputs":[]},{"metadata":{"id":"T0euMPoWXnui","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Total Bags = Small Bags + Large Bags + XLarge Bags\n\ndf = df.drop(['Total Bags'], axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"v3GBp2ngX9K4","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Total Volume = Small Hass +Large Hass +XLarge Hass + Total Bags , to avoid multicollinearity I also drop Total Volume column.\n\n\ndf = df.drop(['Total Volume'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"K7t-61OlYHOW","colab_type":"code","outputId":"bd07b291-16a8-4680-fdca-7bd5b48f1bf4","colab":{"base_uri":"https://localhost:8080/","height":272},"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"wfsO1vuXSv2k","colab_type":"code","outputId":"97997311-a95d-4e4a-c684-5acf7ed38dd1","colab":{"base_uri":"https://localhost:8080/","height":340},"trusted":true},"cell_type":"code","source":"pd.set_option('display.width', 100)\npd.set_option('precision', 3)\ncorrelations = df.corr(method='pearson')\nprint(correlations)","execution_count":null,"outputs":[]},{"metadata":{"id":"5Asi3zURSy1-","colab_type":"code","outputId":"5cad669b-5e74-4e10-a51d-50d865dc9795","colab":{"base_uri":"https://localhost:8080/","height":204},"trusted":true},"cell_type":"code","source":"# Standardizing (scaling) the variables\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndf.loc[:,'Small Hass':'XLarge Bags']= scaler.fit_transform(df.loc[:,'Small Hass':'XLarge Bags']) \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"egssxPOGS1vw","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Specifying dependent and independent variables\n\nX = df.drop(['AveragePrice'], axis = 1)\ny = df['AveragePrice']\ny=np.log1p(y)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"qI09LTuOEce6","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Labeling the categorical variables\n\nXcat=pd.get_dummies(X[[\"type\",\"region\"]], drop_first = True)","execution_count":null,"outputs":[]},{"metadata":{"id":"8cW_AzJPE5gI","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"Xnum=X[[\"Small Hass\",\"Large Hass\",\"XLarge Hass\",\"Small Bags\",\"Large Bags\",\"XLarge Bags\"]]","execution_count":null,"outputs":[]},{"metadata":{"id":"hLQxZtecFaiA","colab_type":"code","outputId":"5083950f-f81e-4a45-de75-dbaae83bbc4e","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"X= pd.concat([Xcat, Xnum], axis = 1) # Concatenate dummy categorcal variables and numeric variables\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"didfQrcBcWtr","colab_type":"code","outputId":"5cbfe62d-0dd4-42a3-f3e5-f1656e4458e5","colab":{"base_uri":"https://localhost:8080/","height":177},"trusted":true},"cell_type":"code","source":"F_DF = pd.concat([y,X],axis=1)\nF_DF.head(2)","execution_count":null,"outputs":[]},{"metadata":{"id":"FPhNRvNvc1iv","colab_type":"code","outputId":"dd5efc99-0706-47a6-a85f-898d898312fd","colab":{"base_uri":"https://localhost:8080/","height":1277},"trusted":true},"cell_type":"code","source":"# Just before the regression analysis, I want to visualise the highly correlated Variables with the Average Prices;\n\nimport seaborn as sns\nsns.set(color_codes=True)\nsns.jointplot(x=\"Small Hass\", y=\"AveragePrice\", data=F_DF, kind=\"reg\");\nsns.jointplot(x=\"Small Bags\", y=\"AveragePrice\", data=F_DF, kind=\"reg\");\nsns.jointplot(x=\"Large Bags\", y=\"AveragePrice\", data=F_DF, kind=\"reg\");","execution_count":null,"outputs":[]},{"metadata":{"id":"OGQ6aZo4eFBt","colab_type":"code","outputId":"399868b4-0ccf-4ff9-b272-15622cb1f120","colab":{"base_uri":"https://localhost:8080/","height":365},"trusted":true},"cell_type":"code","source":"sns.lmplot(x=\"Small Hass\", y=\"AveragePrice\", col=\"type_organic\", data=F_DF, col_wrap=2);\n\n# Graphs depict that organic avocados have less elasticity to the price, compared to conventional ones.","execution_count":null,"outputs":[]},{"metadata":{"id":"I5esozcOS8Bo","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# TRAIN and TEST SPLIT\n\n# Since the data is a time series data (gives weekly avocado prices between Jan 2015 and Apr 2018)\n# I sort it by Date and then split it due to date manually (not randomly), to preserve the 'times series effect' on it.\n# I determined the split ratio as 0.30, so train and test data are just as follows;\n\n\nX_train=X[0:10172]\ny_train=y[0:10172]\nX_test=X[10172:]\ny_test=y[10172:]\n","execution_count":null,"outputs":[]},{"metadata":{"id":"6cEq_fsPyke3","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Implementing machine learning models","execution_count":null,"outputs":[]},{"metadata":{"id":"mM05HclYymA4","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Multiple Linear Regression ","execution_count":null,"outputs":[]},{"metadata":{"id":"ArH1b8RtTAs9","colab_type":"code","outputId":"37b01997-c80b-4b21-a3a0-b29d757dbf91","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nLinReg = LinearRegression()\nLinReg.fit(X_train,y_train)\n\nprint (\"R2 of Linear Regresson:\", LinReg.score(X_train,y_train) )","execution_count":null,"outputs":[]},{"metadata":{"id":"VBjQ_UQLTEgR","colab_type":"code","outputId":"f31b1cf2-28fe-48fc-c2ec-2d645d0a2832","colab":{"base_uri":"https://localhost:8080/","height":68},"trusted":true},"cell_type":"code","source":"print('MAE: ',metrics.mean_absolute_error(y_test, LinReg.predict(X_test)))\nprint('MSE: ',metrics.mean_squared_error(y_test, LinReg.predict(X_test)))\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_test, LinReg.predict(X_test))))","execution_count":null,"outputs":[]},{"metadata":{"id":"GuN-Ou9qyCvg","colab_type":"code","outputId":"bef694d3-50fd-491e-db87-37e3ddf2f7ca","colab":{"base_uri":"https://localhost:8080/","height":294},"trusted":true},"cell_type":"code","source":"# Creating a Histogram of Residuals\nplt.figure(figsize=(6,4))\nsns.distplot(y_test - LinReg.predict(X_test))\nplt.title('Distribution of residuals');","execution_count":null,"outputs":[]},{"metadata":{"id":"sxTBjNF1VSUR","colab_type":"code","outputId":"bb84ed74-b998-4671-a278-873093f3ddfc","colab":{"base_uri":"https://localhost:8080/","height":364},"trusted":true},"cell_type":"code","source":"plt.scatter(y_test,LinReg.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{"id":"Cywhu8KXTGEn","colab_type":"code","outputId":"122d8592-f8d3-41bd-e169-86f85d27c0bd","colab":{"base_uri":"https://localhost:8080/","height":1258},"trusted":true},"cell_type":"code","source":"# we can confirm the R2 value (moreover, get the R2 Adj.value) of the model by statsmodels library of python\nimport statsmodels.api as sm\nX_train = sm.add_constant(X_train) # adding a constant\nmodel = sm.OLS(y_train, X_train).fit()\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"id":"Mc1_dO-vTLz_","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"X_train=X[0:10172]\ny_train=y[0:10172]\nX_test=X[10172:]\ny_test=y[10172:]","execution_count":null,"outputs":[]},{"metadata":{"id":"WQx_AZdihW3Y","colab_type":"code","outputId":"1c157903-e9db-45c6-8c39-de92ad2b0638","colab":{"base_uri":"https://localhost:8080/","height":51},"trusted":true},"cell_type":"code","source":"# LASSO and RIDGE Regressions\n\nfrom sklearn import linear_model\nfrom sklearn.model_selection import GridSearchCV\n\nalphas = np.logspace(-5,3,20)\n\nclf = GridSearchCV(estimator=linear_model.Ridge(), param_grid=dict(alpha=alphas), cv=10)\nclf.fit(X_train, y_train)\noptlamGSCV_R = clf.best_estimator_.alpha\nprint('Optimum regularization parameter (Ridge):', optlamGSCV_R)\n\nclf = GridSearchCV(estimator=linear_model.Lasso(), param_grid=dict(alpha=alphas), cv=10)\nclf.fit(X_train, y_train)\noptlamGSCV_L= clf.best_estimator_.alpha\nprint('Optimum regularization parameter (Lasso):', optlamGSCV_L)","execution_count":null,"outputs":[]},{"metadata":{"id":"kAfw0gNkTYW5","colab_type":"code","outputId":"ed1ffb8c-8cb8-48d2-cd72-04dad222d32d","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"ridge = linear_model.Ridge(alpha = optlamGSCV_R) \nridge.fit(X_train, y_train)\nprint('RMSE value of the Ridge Model is: ',np.sqrt(metrics.mean_squared_error(y_test, ridge.predict(X_test))))","execution_count":null,"outputs":[]},{"metadata":{"id":"nu3tcodh35dI","colab_type":"code","outputId":"f0def12c-846e-4049-b755-39dee127de55","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"ridge.score(X_train, y_train) #Returns the coefficient of determination (R2) of the prediction.","execution_count":null,"outputs":[]},{"metadata":{"id":"FPU4fZ9px7ng","colab_type":"code","outputId":"eb140b09-a900-4960-ba09-7bf3a6acfc16","colab":{"base_uri":"https://localhost:8080/","height":294},"trusted":true},"cell_type":"code","source":"# Creating a Histogram of Residuals\nplt.figure(figsize=(6,4))\nsns.distplot(y_test - ridge.predict(X_test))\nplt.title('Distribution of residuals');","execution_count":null,"outputs":[]},{"metadata":{"id":"kIrM_XzOTfdI","colab_type":"code","outputId":"7fc08dde-d4b8-4970-d564-9e1fa37924cd","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"lasso = linear_model.Lasso(alpha = optlamGSCV_L)\nlasso.fit(X_train, y_train)\nprint('RMSE value of the Lasso Model is: ',np.sqrt(metrics.mean_squared_error(y_test, lasso.predict(X_test))))","execution_count":null,"outputs":[]},{"metadata":{"id":"W0jLkO8_4GdP","colab_type":"code","outputId":"b4d5e2f2-4416-4217-9488-a9affe45d021","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"lasso.score(X_train, y_train) #Returns the coefficient of determination R^2 of the prediction.\n","execution_count":null,"outputs":[]},{"metadata":{"id":"xHQ8Shp8xnEN","colab_type":"code","outputId":"70f3f850-13d3-4708-b3d5-1e50108527dd","colab":{"base_uri":"https://localhost:8080/","height":294},"trusted":true},"cell_type":"code","source":"# Creating a Histogram of Residuals\nplt.figure(figsize=(6,4))\nsns.distplot(y_test - lasso.predict(X_test))\nplt.title('Distribution of residuals');","execution_count":null,"outputs":[]},{"metadata":{"id":"hkawHM26zTC-","colab_type":"code","outputId":"08bfeded-4349-479e-9e30-72c72e2a05ea","colab":{"base_uri":"https://localhost:8080/","height":1728},"trusted":true},"cell_type":"code","source":"coef = pd.Series(lasso.coef_, index = X_train.columns)\nprint(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  \n      str(sum(coef == 0)) + \" variables\")\nimp_coef = pd.concat([coef.sort_values()]) #plot all\nmatplotlib.rcParams['figure.figsize'] = (7.0, 30.0)\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Coefficients in the Lasso Model\")","execution_count":null,"outputs":[]},{"metadata":{"id":"jvWzW6FcuU4F","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# According to the RMSE results, Ridge works best compared to linear regression and lasso.\n\n# Let's see the other ML Models' RMSE values;","execution_count":null,"outputs":[]},{"metadata":{"id":"FyfLCyHCybVB","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# KNN Regressor","execution_count":null,"outputs":[]},{"metadata":{"id":"9lgXuaTRUTZt","colab_type":"code","outputId":"db39aa08-0ef7-460f-ad62-f88902a2ee45","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"from sklearn import neighbors\nfrom math import sqrt\n\nKnn = neighbors.KNeighborsRegressor()\nKnn.fit(X_train, y_train)  \nerror = sqrt(metrics.mean_squared_error( y_test, Knn.predict(X_test))) \nprint('RMSE value of the KNN Model is:', error)","execution_count":null,"outputs":[]},{"metadata":{"id":"ooeCUaNJ4tWD","colab_type":"code","outputId":"1ddeff57-1c59-48b0-9dcf-af59c113b09c","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"Knn.score(X_train, y_train)  # R2 of the KNN model","execution_count":null,"outputs":[]},{"metadata":{"id":"F6qW_pBszLJY","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":" # SVR Regressor","execution_count":null,"outputs":[]},{"metadata":{"id":"nSTVhiweX0sZ","colab_type":"code","outputId":"45e85b7e-a1ce-4a36-9f86-6960b4796043","colab":{"base_uri":"https://localhost:8080/","height":85},"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR\n\n# First, let's choose which kernel is the best for our data\n\nfor k in ['linear','poly','rbf','sigmoid']:\n    clf = svm.SVR(kernel=k)\n    clf.fit(X_train, y_train)\n    confidence = clf.score(X_train, y_train)\n    print(k,confidence)","execution_count":null,"outputs":[]},{"metadata":{"id":"GT1m6L4eUX7H","colab_type":"code","outputId":"aabfdb4f-ebe5-4d4f-96ff-36f3c6f4a780","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"Svr=SVR(kernel='rbf', C=1, gamma= 0.5)   # Parameter Tuning to get the best accuracy\n\n# Intuitively, the gamma defines how far the influence of a single training example reaches, with low values meaning ‘far’ and high values meaning ‘close’.\n# The C parameter trades off correct classification of training examples against maximization of the decision function’s margin. \n# For larger values of C, a smaller margin will be accepted if the decision function is better at classifying all training points correctly. \n# A lower C will encourage a larger margin, therefore a simpler decision function, at the cost of training accuracy. \n# In other words C behaves as a regularization parameter in the SVM.\n\nSvr.fit(X_train,y_train)\nprint(Svr.score(X_train,y_train))","execution_count":null,"outputs":[]},{"metadata":{"id":"Eo4n-80DUeB5","colab_type":"code","outputId":"3f5c27f6-5b03-455c-cf1d-ec29af98aad3","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"error = sqrt(metrics.mean_squared_error(y_test,Svr.predict(X_test))) #calculate rmse\nprint('RMSE value of the SVR Model is:', error)","execution_count":null,"outputs":[]},{"metadata":{"id":"aNNsZQkI38yx","colab_type":"code","outputId":"eb48ee5a-5edd-4de6-8fcf-f6f6f05e658f","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"Svr.predict(X_test)[0:5]  # print the first 5 predictions of our test set\n","execution_count":null,"outputs":[]},{"metadata":{"id":"1so-PlgMZlEX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"5029bf65-4a1a-4ff6-ab36-5b7f7b4d4dde","trusted":true},"cell_type":"code","source":"y_test[0:5]","execution_count":null,"outputs":[]},{"metadata":{"id":"xQ319tjKz0Jr","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Decision Tree Regressor","execution_count":null,"outputs":[]},{"metadata":{"id":"dxjJvIPW2OGK","colab_type":"code","outputId":"b60bc902-f25f-4678-a8e1-8786684db4a6","colab":{"base_uri":"https://localhost:8080/","height":323},"trusted":true},"cell_type":"code","source":"# Determining the best depth\nfrom sklearn.tree import DecisionTreeRegressor\n\nminDepth = 100\nminRMSE = 100000\n\n\nfor depth in range(2,10):\n  tree_reg = DecisionTreeRegressor(max_depth=depth)\n  tree_reg.fit(X_train, y_train)\n  y_pred = tree_reg.predict(X_test)\n  mse = mean_squared_error(y_test, y_pred)\n  rmse = np.sqrt(mse)\n  print(\"Depth:\",depth,\", MSE:\", mse)\n  print(\"Depth:\",depth, \",RMSE:\", rmse)\n  \n  if rmse < minRMSE:\n    minRMSE = rmse\n    minDepth = depth\n    \n      \nprint(\"MinDepth:\", minDepth)\nprint(\"MinRMSE:\", minRMSE)","execution_count":null,"outputs":[]},{"metadata":{"id":"__Mjr7TAV3GT","colab_type":"code","outputId":"596d2e22-5624-4e56-d755-ffc972731194","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"DTree=DecisionTreeRegressor(max_depth=minDepth)\nDTree.fit(X_train,y_train)\nprint(DTree.score(X_train,y_train))  \n","execution_count":null,"outputs":[]},{"metadata":{"id":"4mjjD4rw0Jau","colab_type":"code","outputId":"e0f52c1d-1d36-4549-ecb5-b0efc414ef55","colab":{"base_uri":"https://localhost:8080/","height":68},"trusted":true},"cell_type":"code","source":"print('MAE:', metrics.mean_absolute_error(y_test, DTree.predict(X_test)))\nprint('MSE:', metrics.mean_squared_error(y_test, DTree.predict(X_test)))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, DTree.predict(X_test))))","execution_count":null,"outputs":[]},{"metadata":{"id":"iYnJ0sHe4wEC","colab_type":"code","outputId":"a8d3a0e4-dadb-49e3-dea9-eb179488f831","colab":{"base_uri":"https://localhost:8080/","height":376},"trusted":true},"cell_type":"code","source":"#!pip3 install pydotplus --no-cache-dir --no-binary :all:\n        \nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\ndot_data = StringIO()\nexport_graphviz(DTree, out_file=dot_data, feature_names = X.columns, \n                filled=True, rounded=True,\n                special_characters=True)\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \nImage(graph.create_png())  \n\n# We obtain a 2 depth figure :)","execution_count":null,"outputs":[]},{"metadata":{"id":"pM6IhYOlYs4P","colab_type":"code","outputId":"ce3180ed-6953-47cb-8e24-61da62dbf1fa","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nRForest = RandomForestRegressor()\nRForest.fit(X_train,y_train)\nprint(RForest.score(X_train,y_train))  ","execution_count":null,"outputs":[]},{"metadata":{"id":"VpG9e9bsY43U","colab_type":"code","outputId":"db559a59-feca-4ef3-b93c-10c68f4c5af7","colab":{"base_uri":"https://localhost:8080/","height":68},"trusted":true},"cell_type":"code","source":"print('MAE:', metrics.mean_absolute_error(y_test, RForest.predict(X_test)))\nprint('MSE:', metrics.mean_squared_error(y_test, RForest.predict(X_test)))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, RForest.predict(X_test))))","execution_count":null,"outputs":[]},{"metadata":{"id":"2bYjGelSl8or","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# CONCLUSION \n\n# Comparing The RMSE Values Of The Models","execution_count":null,"outputs":[]},{"metadata":{"id":"gp8kr5k3JhnQ","colab_type":"code","outputId":"970ea6d2-aa0d-4a7f-bcec-34aafd9723ae","colab":{"base_uri":"https://localhost:8080/","height":153},"trusted":true},"cell_type":"code","source":"# Linear Regression RMSE : \nprint('RMSE value of the Linear Regr : ',round(np.sqrt(metrics.mean_squared_error(y_test, LinReg.predict(X_test))),4))\n\n# Ridge RMSE             : \nprint('RMSE value of the Ridge Model : ',round(np.sqrt(metrics.mean_squared_error(y_test, ridge.predict(X_test))),4))\n\n# Lasso RMSE             : \nprint('RMSE value of the Lasso Model : ',round(np.sqrt(metrics.mean_squared_error(y_test, lasso.predict(X_test))),4))\n\n# KNN RMSE               : \nprint('RMSE value of the KNN Model   : ',round(np.sqrt(metrics.mean_squared_error(y_test, Knn.predict(X_test))),4))\n\n# SVR RMSE               : \nprint('RMSE value of the SVR Model   : ',round(np.sqrt(metrics.mean_squared_error(y_test, Svr.predict(X_test))),4))\n\n# Decision Tree RMSE     : \nprint('RMSE value of the Decis Tree  : ',round(np.sqrt(metrics.mean_squared_error(y_test, DTree.predict(X_test))),4))\n\n# Random Forest RMSE     : \nprint('RMSE value of the Rnd Forest  : ',round(np.sqrt(metrics.mean_squared_error(y_test, RForest.predict(X_test))),4))\n\n# Times Series RMSE      : \nprint('RMSE value of the TS Analysis : ',round(np.mean(df_p['rmse']),4))\n","execution_count":null,"outputs":[]},{"metadata":{"id":"PpiDox3sOvdZ","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Now, it's time to decide wheather you're interested in short term predictions or long term!\n\n# When we analyse the results, due to the RMSE values, we see that:\n\n# If we need to get short period estimates, we'd better to use Time Series Analysis for this dataset. (MAPE= 8% and Accuracy= 92%)\n\n# But, if we need longer periods prices, SVR model gives the best predicts. (coefficient of determination of 82%)\n\n# That's all for now. Hope you like my work :) Thanks for your interest, take care!","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"DBDA408_FutureAvocadoPrices.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":1}