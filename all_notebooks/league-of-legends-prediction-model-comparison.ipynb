{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport warnings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/league-of-legends-diamond-ranked-games-10-min/high_diamond_ranked_10min.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking if some duplicates exists\nduplicated = df.duplicated(subset=['gameId'])\nprint(duplicated.any() ==1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar plot of the outcomes to see how they are distributed\nlabels = ['Red Team Wins', 'Blue Team Wins']\nred_wins = len(df.blueWins[df['blueWins']==0])\nblue_wins = len(df.blueWins[df['blueWins']==1])\nwins = (red_wins,blue_wins)\nfig = plt.figure()\nbarPlot = plt.bar(labels,wins)\nplt.ylabel('Number of Wins')\nplt.title('Outcome Distribution')\nbarPlot[0].set_color('red')\nbarPlot[1].set_color('blue')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The outcome column is distributed equally."},{"metadata":{},"cell_type":"markdown","source":"### Feature Selection"},{"metadata":{},"cell_type":"markdown","source":"1. Highly correlated features should be dropped."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation matrix with absolute vals\ncorrelation_mat = df.corr().abs()\n\n# Getting upper triangle of correlation matrix\nupper = correlation_mat.where(np.triu(np.ones(correlation_mat.shape), \n                                  k=1).astype(np.bool))\n\n\n# Getting features with correlation greater than 0.75\nto_drop = [column for column in upper.columns if any(\n        upper[column] > 0.75)]\n\n# Dropping those features \nX = df.drop(to_drop, axis=1)\n\n# Two columns are removed manually since they are some subsets of others\nX = X.drop([\"blueHeralds\"], axis = 1)\nX = X.drop([\"redHeralds\"], axis = 1)\n\n# Dropping the ID column\nX = X.drop([\"gameId\"],axis=1)\n\n# Plotting the new correlation matrix\ncorrelation_mat_X = X.corr().abs()\nplt.figure(figsize=(15,10))\nsns.heatmap(correlation_mat_X, annot = True, linewidths=.3, cmap =\"YlOrRd\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Features with low correlation with the outcome column can be dropped."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping the features with low correlation with the outcome column\nX = X.drop([\"blueWardsPlaced\", \"blueWardsDestroyed\",\n           \"blueTowersDestroyed\", \"blueTotalJungleMinionsKilled\",\n           \"redWardsPlaced\", \"redWardsDestroyed\",\n           \"redTowersDestroyed\", \"redTotalJungleMinionsKilled\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the final correlation matrix\ncorrelation_mat_X = X.corr().abs()\nplt.figure(figsize=(10,8))\nsns.heatmap(correlation_mat_X, annot = True, linewidths=.3, cmap =\"YlOrRd\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Independent and dependent variables\nX = X.drop(['blueWins'], axis = 1)\nY = df[\"blueWins\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the histograms of selected features\nX.hist(figsize=(12,12), color = 'darkblue')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the data \nfrom sklearn.model_selection import train_test_split\ntestSize = 0.2\nx_train, x_test, y_train, y_test = train_test_split(\n        X, Y, test_size=testSize, random_state = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression Model\nfrom sklearn.linear_model import LogisticRegression\nlogistic = LogisticRegression()\nlogistic.fit(x_train,y_train)\nlogistic_prob = logistic.predict_proba(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Naive Bayes Model\nfrom sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train, y_train)\nnb_predict = nb.predict(x_test)\nnb_prob = nb.predict_proba(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SVC Model\nfrom sklearn.svm import SVC\nsvc = SVC(kernel = 'rbf', probability=True,\n          gamma='auto')\nsvc.fit(x_train,y_train)\nsvc_predict = svc.predict(x_test)\nsvc_prob = svc.predict_proba(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# KNN Model\nfrom sklearn.neighbors import KNeighborsClassifier\nneighbors = int(np.sqrt(len(X)))\nknn = KNeighborsClassifier(n_neighbors= neighbors)\nknn.fit(x_train,y_train)\nknn_predict = knn.predict(x_test)\nknn_prob = knn.predict_proba(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Guess\nrandom = [1 for game in range(len(y_test))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logistic_prob = logistic_prob[:,-1]\nnb_prob = nb_prob[:,-1]\nsvc_prob = svc_prob[:,-1]\nknn_prob = knn_prob[:,-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ROC Curve\nlogistic_fpr, logistic_tpr, logistic_thresholds = roc_curve(y_test, logistic_prob)\nnb_fpr, nb_tpr, nb_thresholds                   = roc_curve(y_test, nb_prob)\nsvc_fpr, svc_tpr, svc_thresholds                = roc_curve(y_test, svc_prob)\nknn_fpr, knn_tpr, knn_thresholds                = roc_curve(y_test, knn_prob)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AUC Scores\nlogistic_auc = roc_auc_score(y_test, logistic_prob)\nnb_auc = roc_auc_score(y_test, nb_prob)\nsvc_auc = roc_auc_score(y_test, svc_prob)\nknn_auc = roc_auc_score(y_test, knn_prob)\nrandom_auc = roc_auc_score(y_test, random)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tabulate import tabulate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_table = [\n['Logistic Regression   ', logistic_auc],\n['Naive Bayes', nb_auc ],\n['KNN', svc_auc ],\n['SVC',knn_auc],\n['Random Guess', random_auc]\n] \nprint (tabulate(auc_table, headers=[\"Model\", \"AUC Score\"]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression and Naive Bayes models are expected to perform better because of the higher AUC Score."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best threshold for Logistic Regression Model\nequation_logistic = np.sqrt(logistic_tpr * (1-logistic_fpr))\nindex_logistic = np.argmax(equation_logistic)\nprint('Best Threshold for Logistic Regression Model: %f' % (logistic_thresholds[index_logistic]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best threshold for Naive Bayes Model\nequation_nb = np.sqrt(nb_tpr * (1-nb_fpr))\nindex_nb = np.argmax(equation_nb)\nprint('Best Threshold for Naive Bayes Model: %f' % (nb_thresholds[index_nb]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the ROC Curve for models\nplt.figure(figsize=(8,6))\nplt.plot(logistic_fpr,logistic_tpr, linestyle = '-', label = 'Logistic Regression')\nplt.plot(nb_fpr,nb_tpr,  label = 'Naive Bayes')\nplt.plot(knn_fpr,knn_tpr, label = 'KNN')\nplt.plot(svc_fpr,svc_tpr,  label = 'SVC')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.plot([0,1], [0,1], linestyle='--', label='Random Guess')\nplt.scatter(logistic_fpr[index_logistic], logistic_tpr[index_logistic], marker='D', color='k',\n            label='Best Score for Logistic Regression')\nplt.scatter(nb_fpr[index_nb], nb_tpr[index_nb], marker='o', color='k', label='Best Score for Naive Bayes')\nplt.legend(loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression Model predictions\nlogistic_prediction = []\nfor i in logistic_prob:\n    if i>= logistic_thresholds[index_logistic]:\n        i = 1\n        logistic_prediction.append(i)\n    else:\n        i=0\n        logistic_prediction.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Naive Bayes Model predictions\nnb_predict = []\nfor i in logistic_prob:\n    if i>= nb_thresholds[index_nb]:\n        i = 1\n        nb_predict.append(i)\n    else:\n        i=0\n        nb_predict.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accuracy, Precision, and Recall Scores of Logistic Regression Model \nlogistic_acc    = accuracy_score(logistic_prediction, y_test)\nlogistic_prec   = precision_score(logistic_prediction, y_test)\nlogistic_recall = recall_score(logistic_prediction, y_test)\n\n# Accuracy, Precision, and Recall Scores of Naive Bayes Model \nnb_acc    = accuracy_score(nb_predict, y_test)\nnb_prec   = precision_score(nb_predict, y_test)\nnb_recall = recall_score(nb_predict, y_test)\n\n# Accuracy, Precision, and Recall Scores of KNN Model\nknn_acc    = accuracy_score(knn_predict, y_test)\nknn_prec   = precision_score(knn_predict, y_test)\nknn_recall = recall_score(knn_predict, y_test)\n\n# Accuracy, Precision, and Recall Scores of SVC Model\nsvc_acc    = accuracy_score(svc_predict, y_test)\nsvc_prec   = precision_score(svc_predict, y_test)\nsvc_recall = recall_score(svc_predict, y_test)\n\n# Accuracy, Precision, and Recall Scores of Random Guess\nrandom_acc    = accuracy_score(random, y_test)\nrandom_prec   = precision_score(random, y_test)\nrandom_recall = recall_score(random, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix for Logistic Regression Model\nlogistic_tn, logistic_fp, logistic_fn, logistic_tp = confusion_matrix(\n        y_test, logistic_prediction).ravel()\n\n# Confusion Matrix for Naive Bayes Model\nnb_tn, nb_fp, nb_fn, nb_tp = confusion_matrix(\n        y_test, nb_predict).ravel()\n\n# Confusion Matrix for KNN Model\nknn_tn, knn_fp, knn_fn, knn_tp = confusion_matrix(\n        y_test, knn_predict).ravel()\n\n\n# Confusion Matrix for SVC Model\nsvc_tn, svc_fp, svc_fn, svc_tp = confusion_matrix(\n        y_test, svc_predict).ravel()\n\n# Confusion Matrix for Random Guess\nrandom_tn, random_fp, random_fn, random_tp = confusion_matrix(\n        y_test, random).ravel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"table = [\n['Logistic Regression   ', logistic_acc, logistic_prec, logistic_recall, logistic_tp, logistic_fp, logistic_tn, logistic_fn],\n['Naive Bayes'           , nb_acc      , nb_prec      , nb_recall      , nb_tp      , nb_fp      , nb_tn      , nb_fn      ],\n['KNN'                   , knn_acc     , knn_prec     , knn_recall     , knn_tp     , knn_fp     , knn_tn     , knn_fn     ],\n['SVC'                   , svc_acc     , svc_prec     , svc_recall     , svc_tp     , svc_fp     , svc_tn     , svc_fn     ],\n['Random Guess'          , random_acc  , random_prec  , random_recall  , random_tp  , random_fp  , random_tn  , random_fn  ]\n        ] \nprint (tabulate(table, headers=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\",\n                               \"TP\", \"FP\", \"TN\", \"FN\"]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}