{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Affiliation: Whiting School of Engineering, Johns Hopkins University (685.621) Programming Assignment 2 - Problem 1"},{"metadata":{},"cell_type":"markdown","source":"## Authors: Jack Shu, Sriharshareddy Katpally, Sarah Henry"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import standard libraries\nimport pandas as pd\nimport numpy as np\nimport os\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport seaborn as sns\nfrom sklearn import svm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom statistics import mean","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# read in data (provided via course website)\ndata_dir = '/kaggle/input/coronavirusdataset'\ncase = pd.read_csv(os.path.join(data_dir, 'Case.csv'), na_values='-')\npatient_route = pd.read_csv(os.path.join(data_dir, 'PatientRoute.csv'))\nregion = pd.read_csv(os.path.join(data_dir, 'Region.csv'))\n\n# Subsampling patient route to improve map visualization performance\npatient_route = patient_route.sample(750, random_state=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Problem 1 - 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# count based on province only\ncase_province = pd.DataFrame(case['confirmed'].groupby(case['province']).sum())\n\n# get average geocode info\n# gc = case[['latitude', 'longitude']].groupby(case['province']).mean()\n\n# get average geocode info from Region dataset (which is more complete)\ngc = region[['latitude', 'longitude']].groupby(region['province']).mean()\n\n# combine into single dataset\ndf_case = case_province.join(gc)\n\n# center of lon & lat average\ncenter = df_case.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## cases"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# generate map object for cases\nfig = px.scatter_mapbox(df_case,\n                        lat='latitude', lon='longitude', \n                        size='confirmed', size_max=50,\n                        hover_name=df_case.index)\n\n# update layout\nfig.update_layout(mapbox_style= \"carto-positron\", \n                  mapbox_zoom=6, \n                  mapbox_center_lat = center['latitude'],\n                  mapbox_center_lon = center['longitude'],\n                  \n                  margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## routes (note: rendering takes a few minutes, please be patient)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.line_mapbox(patient_route, \n                     lat='latitude', lon='longitude', \n                     color='patient_id')\n\nfig.update_layout(mapbox_style= \"carto-positron\", \n                  mapbox_zoom=6, \n                  mapbox_center_lat = center['latitude'],\n                  mapbox_center_lon = center['longitude'],\n                  margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n\nfig.update_layout(showlegend=False)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## region"},{"metadata":{"trusted":true},"cell_type":"code","source":"region_counts = region[['nursing_home_count','kindergarten_count', 'elementary_school_count','university_count']]\nregion_counts = region_counts.groupby(region['province']).sum()\nregion_counts = region_counts.join(gc)\nregion_counts['province'] = region_counts.index\nregion_melt = pd.melt(region_counts, id_vars=['province', 'latitude', 'longitude'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = px.scatter_mapbox(region_melt, \n                        lat='latitude', lon='longitude',\n                        color='variable', opacity=0.3,\n                        size='value', size_max=50)\n\nfig.update_layout(mapbox_style= \"carto-positron\", \n                  mapbox_zoom=6, \n                  mapbox_center_lat = center['latitude'],\n                  mapbox_center_lon = center['longitude'],\n                  margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Problem 1 - 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"# read in data\ntime = pd.read_csv(os.path.join(data_dir, 'Time.csv'))\n\ntime_age = pd.read_csv(os.path.join(data_dir, 'TimeAge.csv'))\ntime_gender = pd.read_csv(os.path.join(data_dir, 'TimeGender.csv'))\ntime_province = pd.read_csv(os.path.join(data_dir, 'TimeProvince.csv'))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"time_cumulative = time[['test', 'confirmed']].cumsum()\ntime_cumulative['date'] = time['date']\ntime_cumulative_melt = pd.melt(time_cumulative, id_vars=['date'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# fig = px.line(time_cumulative_melt, x = 'date', y = 'value', color = 'variable')\n# fig.show()\n\n# time_cumulative['confirmed_ratio'] = time_cumulative['confirmed'] / time_cumulative['test']\n# fig = px.line(time_cumulative, x = 'date', y = 'confirmed_ratio')\n# fig.show()\n\nfig = px.bar(time, x = 'date', y = 'confirmed')\nfig.show()\n\n# fig = px.line(time_cumulative, x = 'date', y = 'confirmed')\n# fig.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"time_age_cumulative = time_age[['confirmed', 'deceased']].groupby(time_age['age']).cumsum()\ntime_age_cumulative = time_age[['date', 'age']].join(time_age_cumulative)\ntime_age_cumulative_melt = pd.melt(time_age_cumulative, id_vars=['date', 'age'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = px.line(time_age_cumulative_melt, x = 'date', y = 'value', color = 'variable', facet_col='age', facet_col_wrap=5)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time_gender_cumulative = time_gender[['confirmed', 'deceased']].groupby(time_gender['sex']).cumsum()\ntime_gender_cumulative = time_gender[['date', 'sex']].join(time_gender_cumulative)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"time_gender_cumulative_melt = pd.melt(time_gender_cumulative, id_vars=['date', 'sex'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = px.line(time_gender_cumulative_melt, \n              x = 'date', y = 'value', \n              color = 'sex', facet_row='variable')\nfig.update_yaxes(matches=None)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Problem 1 - 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"SearchTrend = pd.read_csv(os.path.join(data_dir, 'SearchTrend.csv'))\nsearch = SearchTrend.drop('date', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"search.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"search.skew()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"search.kurt()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"search_melt = pd.melt(search)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"search_melt.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = px.box(search_melt, y = 'value', color = 'variable', log_y=True)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = px.scatter_matrix(search)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the statistics, and boxplots, each of the terms looks to have a pretty wide distribution. From the scatter plot matrix, the data seems to be pretty random, there does not seem to be an obvious relationship (e.g. linear)"},{"metadata":{},"cell_type":"markdown","source":"# Problem 1 - 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"weather = pd.read_csv(os.path.join(data_dir, 'Weather.csv'))\n\n#print(weather)\n\nweather.index = weather['date']\nweather = weather.drop('date', axis=1)\ntemp = weather[['avg_temp', 'min_temp', 'max_temp']]\nprecip = weather[['precipitation', 'avg_relative_humidity']]\nwind = weather[['max_wind_speed', 'most_wind_direction']]\n\nsearch.index = SearchTrend['date']\n#print(search.index)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"temp_trend = search.join(temp)\nprint(temp_trend)\ntemp_trend_melt = pd.melt(temp_trend, id_vars=['cold', 'flu', 'pneumonia', 'coronavirus'],\n                          var_name = 'weather_var', value_name='weather_val')\n\ntemp_trend_melt2 = pd.melt(temp_trend_melt, id_vars = ['weather_var', 'weather_val'], \n                           var_name = 'search_var', value_name='search_val')\n\nfig = px.scatter(temp_trend_melt2, x = 'weather_val', y = 'search_val', \n                 facet_col = 'weather_var', facet_row = 'search_var')\nfig.update_yaxes(matches=None)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precip_trend = search.join(precip)\n\nprecip_trend_melt = pd.melt(precip_trend, id_vars = ['cold', 'flu', 'pneumonia', 'coronavirus'],\n                           var_name = 'precip_var', value_name = 'precip_val')\n\nprecip_trend_melt2 = pd.melt(precip_trend_melt, id_vars = ['precip_var', 'precip_val'],\n                            var_name = 'search_var', value_name = 'search_val')\n\nfig = px.scatter(precip_trend_melt2, x = 'precip_val', y = 'search_val',\n                facet_col = 'precip_var', facet_row = 'search_var')\n\nfig.update_yaxes(matches=None)\nfig.update_xaxes(matches=None)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"wind_search = search.join(wind)\n\nwind_search_melt = pd.melt(wind_search, id_vars = ['cold', 'flu', 'pneumonia', 'coronavirus'],\n                          var_name = 'wind_var', value_name = 'wind_val')\n\nwind_search_melt2 = pd.melt(wind_search_melt, id_vars = ['wind_var', 'wind_val'],\n                           var_name = 'search_var', value_name = 'search_val')\n\nfig = px.scatter(wind_search_melt2, x = 'wind_val', y = 'search_val', \n                 facet_col = 'wind_var', facet_row = 'search_var')\n\nfig.update_yaxes(matches=None)\nfig.update_xaxes(matches=None)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wind_search_melt2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Problem 1 - 5"},{"metadata":{},"cell_type":"markdown","source":" Identify trends by date and location tying in all 11 files"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading additional tables\npatient_info = pd.read_csv(os.path.join(data_dir, 'PatientInfo.csv'))\n\n# Total confirmed cases in Korea\nnumConfirmedCases = case['confirmed'].sum();\ndisplay('Total confirmed cases: ', numConfirmedCases)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model 1: Perform SVM on data\n\npatient_info['province_cat_codes'] = patient_info.province.astype('category').cat.codes\npatient_info['city_cat_codes'] = patient_info.city.astype('category').cat.codes\npatient_info['sex_cat_codes'] = patient_info.sex.astype('category').cat.codes\npatient_info['age_cat_codes'] = patient_info.age.astype('category').cat.codes\npatient_info['state_cat_codes'] = patient_info.state.astype('category').cat.codes\npatient_info['disease_cat_codes'] = patient_info.disease.astype('category').cat.codes\n\n# Combine isolated and recovered patients into a single category to represent all living patients\npatient_info.loc[\n   (patient_info['state_cat_codes'] == 2)\n   , 'state_cat_codes'] = 1\n\n# The accuracy went up when I removed those patients whose birth year we didn't know\n#patient_info = patient_info[patient_info['birth_year'].notnull()]\n\n# There are way more trues than falses. So filter down\ntemp = patient_info.loc[patient_info['state_cat_codes'] == 1]\n\ntemp3 = patient_info.loc[patient_info['state_cat_codes'] == 0]\n\ntemp2 = temp.sample(n=len(temp3), random_state=1)\n\nframes = [temp2, temp3]\nbalanced_patient_info = pd.concat(frames)\ncor = balanced_patient_info.corr()\ncor_target = abs(cor[\"state_cat_codes\"])\nrelevant_features = cor_target[cor_target>0.5]\n\nX = balanced_patient_info[['province_cat_codes','age_cat_codes', 'disease_cat_codes']]\ny = balanced_patient_info['state_cat_codes']\naccuracies = list()\nprecisions = list()\nrecalls = list()\n# Perform 2000 MC reps. There is no change after this to in the first two decimal places\nfor i in range(2000):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n    y_train = y_train.astype(np.int8)\n\n    clf = svm.SVC()\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n\n    y_test = y_test.to_numpy()\n    temp = np.vstack((y_test,y_pred)).transpose()\n\n    accuracies.append(metrics.accuracy_score(y_test, y_pred))\n    precisions.append(metrics.precision_score(y_test, y_pred))\n    recalls.append(metrics.recall_score(y_test, y_pred))\n\nprint(\"Accuracy: \",mean(accuracies))\nprint(\"Precision: \",mean(precisions))\nprint(\"Recall: \",mean(recalls))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n"},{"metadata":{},"cell_type":"markdown","source":"Model 1 Analysis:\nWe can get a reasonable model by only using province, age, and disease. \n\nSystem flow: generate categorical codes -> SVM -> metrics\n\nRuntime: The runtime is O($n$) due to the for-loop for the Monte Carlo reps. Depending on the number of Monte Carlo reps chosen, the runtime can vary drastically. This was definitely noticeable when increasing the number to 10000 reps or above"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Model 2: Determine if there is a correlation between the number of places and individual has gone and how many people they infect\n\n# Question: Which individuals affected the most other people?\ninfectors = patient_info.groupby('infected_by').count().reset_index()\ninfectors['num_patients_infected'] = infectors['patient_id']\npatientCausesOfInfection = infectors[['infected_by','num_patients_infected']].sort_values(by=['num_patients_infected'],ascending=False)\n\n# Top 3 culprits\nprint('Top 3 Infectors in Korea')\ndisplay(patientCausesOfInfection[0:3])\n\nprint('Bottom 3 Infectors in Korea (must have infected at least one person)')\ndisplay(patientCausesOfInfection[-1:-4:-1])\n\n# Top culprit\ntopInfected_by = patientCausesOfInfection.head(1)\ntopInfected_by = topInfected_by['infected_by'].to_numpy()[0]\n\n# Information about the top culprit\nprint('Top infector in Korea')\ndisplay(patient_info[patient_info['patient_id'] == topInfected_by])\nprint('')\n\n# All patients affected by top culprit\nprint('All patients affected by top infector')\ndisplay(patient_info[patient_info['infected_by'] == topInfected_by])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The top infector infected people from the same province and city. They were of all different ages."},{"metadata":{"trusted":true},"cell_type":"code","source":"patient_route = pd.read_csv(os.path.join(data_dir, 'PatientRoute.csv'))\n\n# Percentage of patients we know the routes for\nprint('Percentage of patients we have routes for: ', len(patient_route['patient_id'].value_counts()) / patient_info.shape[0] * 100)\n\n# This was another possible route: to track the top and bottom infectors and compare differences between them. \n# We moved on from this idea because the route data was too sparse and proved to be too much of a challenge\n\n# Unable to track first and third because they have no routes\n# top3 = patientCausesOfInfection.head(3)\n# firstInfected_by = top3['infected_by'].to_numpy()[0]\n# secondInfected_by = top3['infected_by'].to_numpy()[1]\n# thirdInfected_by = top3['infected_by'].to_numpy()[2]\n# lastInfected_by = patientCausesOfInfection['infected_by'].to_numpy()[-3]\n\n# Who infected the second top?\n# temp = patient_info[patient_info['patient_id'] == secondInfected_by]\n# Nobody knows! It's NaN\n\n# Join patient route to info\npatient_info_route = patient_info.merge(patient_route, on='patient_id', how='left')\n\n# Count up the number of routes. Counting the number of times a patient ID appears works because every row is a route\nnum_places = patient_info_route['patient_id'].value_counts()\ninfectors = patient_info['infected_by'].value_counts()\n\n# Merge number of places into the table\ntemp1 = num_places.keys().to_frame(name='patient_id').to_numpy()\ntemp2 = num_places.to_frame(name='num_places').to_numpy()\ntemp2 = pd.DataFrame(np.concatenate((temp1,temp2), axis=1))\ntemp3 = temp2.rename(columns={0: \"patient_id\", 1: \"num_places\"})\n\nfiltered_patient_info_route = patient_info_route.merge(temp3, on='patient_id', how='left')\n\n# Merge number of infected by individuals into the table\ntemp1 = infectors.keys().to_frame(name='patient_id').to_numpy()\ntemp2 = infectors.to_frame(name='infected').to_numpy()\ntemp2 = pd.DataFrame(np.concatenate((temp1,temp2), axis=1))\ntemp3 = temp2.rename(columns={0: \"patient_id\", 1: \"infected\"})\n\nfiltered_patient_info_route = filtered_patient_info_route.merge(temp3, on='patient_id', how='left')\n\n# Remove all those that don't have route\nfiltered_patient_info_route = filtered_patient_info_route[filtered_patient_info_route['type'].notnull()]\n\n# Remove all those that don't have infected\nfiltered_patient_info_route = filtered_patient_info_route[filtered_patient_info_route['infected'].notnull()]\n\nfig = plt.figure()\nax = plt.subplot(111)\nfiltered_patient_info_route.plot(x='num_places',y='infected',ax=ax, kind='scatter')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model 2 Analysis\n\nSystem flow: infector calculations -> input gathering -> dataframe -> filter\n\nRuntime: This function has a runtime of O($n$) due to the merging. Here is an article that references runtimes:\nhttps://wiki.python.org/moin/TimeComplexity\n\nIt does not appear that going to lots of places necessarily indicates a large number of infections.\n\nHowever, given a number of infections greater than or equal to 5, it certainly seems that as the number of places increased, so did the number of people an individual infected\n\nWe only have routes for about 1/3 of patients we have info for, which is about 1/3 of the total cases in South Korea. So we are not able to include all data points\n\nNotice that that top infector (50+ people infected) is not include here because route information was not present\n\nAdditionally, it is unclear whether a null value for infected means the individual infected 0 people or the value is simply unknown. For this reason"},{"metadata":{},"cell_type":"markdown","source":"# Other observations"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Question: Which cases had the biggest outbreak?\n\ncase_infection_case = case.groupby('infection_case').sum().reset_index()\nconfirmed_by_infection_case = case_infection_case[['infection_case','confirmed']].sort_values(by=['confirmed'],ascending=False)\n\n# Top 5 culprits:\nconfirmed_by_infection_case['percentage_of_total'] = (confirmed_by_infection_case['confirmed'] / case['confirmed'].sum()) * 100\ndisplay(confirmed_by_infection_case[0:5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The outbreak associated with Shincheonji Church is a huge issue. It accounts for over 50% of all cases in Korea! Not everyone from the church started in the same location, although most came from Daegu. This certainly explains why there are so many cases in Daegu. The media has blamed the church for the outbreak, as referenced below\nhttps://www.bbc.com/news/av/world-asia-51851250/shincheonji-and-coronavirus-the-mysterious-cult-church-blamed-for-s-korea-s-outbreak"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Question: How many patients do we have data on and what is the largest infection case associated with this?\n\n# What percentage of patients do we have info for?\ndisplay('Percentage of patients we have info for: ', patient_info.shape[0] / numConfirmedCases * 100)\n\n# Highest infection case type\npatient_info_infection_case = patient_info.groupby('infection_case').count().reset_index()\npatient_info_infection_case['num_patients'] = patient_info_infection_case['patient_id']\npatientCausesOfInfection = patient_info_infection_case[['infection_case','num_patients']].sort_values(by=['num_patients'],ascending=False)\ndisplay(patientCausesOfInfection)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interestingly enough, there is only data on 107 Shincheonji Church members. That is much less than the total number of cases associated. This suggests either lack of testing or potentially challenges getting the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Question: Who was the first infector in Korea?\n\ndisplay(patient_info.sort_values('confirmed_date').head(1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first infector appears to have come from Incheon in the Wuhan province of China and was an overseas transfer. This same individual was discussed on the media https://www.who.int/csr/don/21-january-2020-novel-coronavirus-republic-of-korea-ex-china/en/"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.1"}},"nbformat":4,"nbformat_minor":4}