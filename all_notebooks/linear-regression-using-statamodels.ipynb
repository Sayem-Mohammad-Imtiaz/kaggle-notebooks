{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nwave = pd.read_csv(\"/kaggle/input/waves-measuring-buoys-data-mooloolaba/Coastal Data System - Waves (Mooloolaba) 01-2017 to 06 - 2019.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wave.describe()\n# we can notice that there is an abnormal value of -99.9 presents in every variables.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wave.info()\n# we can change \"Date/Time\" from object format to datetime format ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wave[\"Date/Time\"] = pd.to_datetime(wave[\"Date/Time\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I will remove rows with value -99.9 before I do any EDA on the data itself\nHs_index = wave[wave[\"Hs\"] == -99.9].index\nwave.drop(Hs_index, inplace=True)\n\nPeak_index = wave[wave[\"Peak Direction\"] == -99.9].index\nwave.drop(Peak_index, inplace=True)\n\nSST_index = wave[wave[\"SST\"] == -99.9].index\nwave.drop(SST_index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wave.describe()\n# just to make sure value of -99.9 removed from the data.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################## Exploratory Data Analysis #####################################\n\nplt.figure(figsize=(16,8))\nsns.lineplot(x=\"Date/Time\", y=\"Hs\", data=wave)\nplt.show()\n# Hs shows highest readings at around Oct-2018 and Mar-2019","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.lineplot(x=\"Date/Time\", y=\"Tp\", data=wave)\nplt.show()\n# Increase in peak energy wave period does not neccessary increase wave height\n# It does not really explain why there were two sudden peaks of wave height at around Oct-2018 and Mar-2019.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.lineplot(x=\"Date/Time\", y=\"Peak Direction\", data=wave)\nplt.show()\n# There is a considerably high peak direction value at around Mar-2019 which could explain why there is a sudden peak of wave height.\n# However it still doesn't explain sudden peak of wave height at around Oct-2018.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.lineplot(x=\"Date/Time\", y=\"SST\", data=wave)\nplt.show()\n# Sudden increase of SST at around Oct-2018 may be the reason of sudden peak of wave height at around that time.\n# However it does not really explain sudden peak of wave height at around Mar-2019.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perhaps there is other factor that can explain the sudden peak of wave height around Oct-2018 and Mar-2019.\n# Or it could be simply due to measurement error.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.scatterplot(x=\"Hmax\", y=\"Hs\", data=wave)\nplt.show()\n# Hmax and Hs has very strong correlation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.scatterplot(x=\"SST\", y=\"Hs\", data=wave)\nplt.show()\n# Hs and SST has weak correlation\n# Perhaps change of sea surface temperature will not affect wave height","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = wave.corr()\nsns.heatmap(corrmat, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = corrmat[\"Hs\"]\nfeatures.abs().sort_values(ascending=False)\n# it seems like Hmax has very strong correlation with Hs\n# Tp and Peak Direction has very weak correlation with Hs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################################ Feature Engineer #########################################\n\n# check for missing values\n\nwave.isnull().sum()\n# no missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for outliers\n\nsns.boxplot(wave[\"Hs\"])\n# got outliers at upper end","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(wave[\"Hmax\"])\n# got outliers at upper end","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(wave[\"Tz\"])\n# got outliers at both ends","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(wave[\"Peak Direction\"])\n# got outliers at both ends\n# got one extreme outlier at upper end","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(wave[\"SST\"])\n# no outliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove the extreme outlier\npeak_index = wave[wave[\"Peak Direction\"] > 300].index\nwave.drop(peak_index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# unsure of whether to retain or remove those outliers\n# I decided to create another set of data with removed outliers\n\nwave_removed = wave.copy()\n\nhs_ind = wave_removed[wave_removed[\"Hs\"] > 2.6015].index\nwave_removed.drop(hs_ind, inplace=True)\n\nhmax_ind = wave_removed[wave_removed[\"Hmax\"] > 4.275].index\nwave_removed.drop(hmax_ind, inplace=True)\n\ntz_lower_ind = wave_removed[wave_removed[\"Tz\"] < 3.2375].index\nwave_removed.drop(tz_lower_ind, inplace=True)\ntz_upper_ind = wave_removed[wave_removed[\"Tz\"] > 7.8415].index\nwave_removed.drop(tz_upper_ind, inplace=True)\n\npeak_lower_ind = wave_removed[wave_removed[\"Peak Direction\"] < 38.5].index\nwave_removed.drop(peak_lower_ind, inplace=True)\npeak_upper_ind = wave_removed[wave_removed[\"Peak Direction\"] > 162.5].index\nwave_removed.drop(peak_upper_ind, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model building on wave data sets\n# split the data into train and test sets\n\nX = wave.drop([\"Date/Time\", \"Hs\"], axis=1)\nY = wave[\"Hs\"]\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.regression.linear_model import OLS\n\nmodel = OLS(Y_train, X_train).fit()\nmodel.summary()\n# adjusted r-squared is 0.992 which is very good\n# all variables have p-value less than 0.05 which show that all of them are significant to our model.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate the model\npred = model.predict(X_test)\n\nfrom sklearn.metrics import mean_squared_error\nmean_squared_error(Y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model building on wave_removed data sets\n# split the data into train and test sets\n\nX_removed = wave_removed.drop([\"Date/Time\", \"Hs\"], axis=1)\nY_removed = wave_removed[\"Hs\"]\n\nX_train_removed, X_test_removed, Y_train_removed, Y_test_removed = train_test_split(X_removed, Y_removed, test_size=0.3, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_removed = OLS(Y_train_removed, X_train_removed).fit()\nmodel_removed.summary()\n# adjusted r-squared is 0.993 which is slightly higher than model with outliers retained.\n# all variables have p-value less than 0.05","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate the model\npred_removed = model.predict(X_test_removed)\nmean_squared_error(Y_test_removed, pred_removed)\n# it shows that mean_squarer_error of model with outliers removed is lower.\n# removal of outliers will slightly increase performance of the model.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As a conclusion, we can choose to remove those outliers in order to improve performance of the model.\n# Those variables of data are sufficient to predict Hs.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}