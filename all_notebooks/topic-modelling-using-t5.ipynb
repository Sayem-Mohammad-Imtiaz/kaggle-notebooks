{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"news = pd.read_json(\"/kaggle/input/news-category-dataset/News_Category_Dataset_v2.json\",lines=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_rows\npd.set_option('display.max_colwidth', -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news.headline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news.short_description","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news[\"category\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"short = news.sample(frac = 0.1,random_state = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"short.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"short[\"category\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"short.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install transformers\n!pip install pytorch_lightning","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import argparse\nimport glob\nimport os\nimport json\nimport time\nimport logging\nimport random\nimport re\nfrom itertools import chain\nfrom string import punctuation\n\nimport nltk\nnltk.download('punkt')\nfrom nltk.tokenize import sent_tokenize\n\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport pytorch_lightning as pl\n\n\nfrom transformers import (\n    AdamW,\n    T5ForConditionalGeneration,\n    T5Tokenizer,\n    get_linear_schedule_with_warmup\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_seed(seed):\n  random.seed(seed)\n  np.random.seed(seed)\n  torch.manual_seed(seed)\n  if torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed)\n\nset_seed(42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class T5FineTuner(pl.LightningModule):\n  def __init__(self, hparams):\n    super(T5FineTuner, self).__init__()\n    self.hparams = hparams\n    \n    self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n    self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n  \n  def is_logger(self):\n    return self.trainer.proc_rank <= 0\n  \n  def forward(\n      self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None\n  ):\n    return self.model(\n        input_ids,\n        attention_mask=attention_mask,\n        decoder_input_ids=decoder_input_ids,\n        decoder_attention_mask=decoder_attention_mask,\n        lm_labels=lm_labels,\n    )\n\n  def _step(self, batch):\n    lm_labels = batch[\"target_ids\"]\n    lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n\n    outputs = self(\n        input_ids=batch[\"source_ids\"],\n        attention_mask=batch[\"source_mask\"],\n        lm_labels=lm_labels,\n        decoder_attention_mask=batch['target_mask']\n    )\n\n    loss = outputs[0]\n\n    return loss\n\n  def training_step(self, batch, batch_idx):\n    loss = self._step(batch)\n\n    tensorboard_logs = {\"train_loss\": loss}\n    return {\"loss\": loss, \"log\": tensorboard_logs}\n  \n  def training_epoch_end(self, outputs):\n    avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n    tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n    return {\"avg_train_loss\": avg_train_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n\n  def validation_step(self, batch, batch_idx):\n    loss = self._step(batch)\n    return {\"val_loss\": loss}\n  \n  def validation_epoch_end(self, outputs):\n    avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n    tensorboard_logs = {\"val_loss\": avg_loss}\n    return {\"avg_val_loss\": avg_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n\n  def configure_optimizers(self):\n    \"Prepare optimizer and schedule (linear warmup and decay)\"\n\n    model = self.model\n    no_decay = [\"bias\", \"LayerNorm.weight\"]\n    optimizer_grouped_parameters = [\n        {\n            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n            \"weight_decay\": self.hparams.weight_decay,\n        },\n        {\n            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n            \"weight_decay\": 0.0,\n        },\n    ]\n    optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n    self.opt = optimizer\n    return [optimizer]\n  \n  def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None):\n    if self.trainer.use_tpu:\n      xm.optimizer_step(optimizer)\n    else:\n      optimizer.step()\n    optimizer.zero_grad()\n    self.lr_scheduler.step()\n  \n  def get_tqdm_dict(self):\n    tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n\n    return tqdm_dict\n\n  def train_dataloader(self):\n    train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"train\", args=self.hparams)\n    dataloader = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True, num_workers=4)\n    t_total = (\n        (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n        // self.hparams.gradient_accumulation_steps\n        * float(self.hparams.num_train_epochs)\n    )\n    scheduler = get_linear_schedule_with_warmup(\n        self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n    )\n    self.lr_scheduler = scheduler\n    return dataloader\n\n  def val_dataloader(self):\n    val_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"val\", args=self.hparams)\n    return DataLoader(val_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logger = logging.getLogger(__name__)\n\nclass LoggingCallback(pl.Callback):\n  def on_validation_end(self, trainer, pl_module):\n    logger.info(\"***** Validation results *****\")\n    if pl_module.is_logger():\n      metrics = trainer.callback_metrics\n      # Log results\n      for key in sorted(metrics):\n        if key not in [\"log\", \"progress_bar\"]:\n          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n\n  def on_test_end(self, trainer, pl_module):\n    logger.info(\"***** Test results *****\")\n\n    if pl_module.is_logger():\n      metrics = trainer.callback_metrics\n\n      # Log and save results to file\n      output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n      with open(output_test_results_file, \"w\") as writer:\n        for key in sorted(metrics):\n          if key not in [\"log\", \"progress_bar\"]:\n            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"args_dict = dict(\n    data_dir=\"\", # path for data files\n    output_dir=\"\", # path to save the checkpoints\n    model_name_or_path='t5-base',\n    tokenizer_name_or_path='t5-base',\n    max_seq_length=512,\n    learning_rate=3e-4,\n    weight_decay=0.0,\n    adam_epsilon=1e-8,\n    warmup_steps=0,\n    train_batch_size=8,\n    eval_batch_size=8,\n    num_train_epochs=2,\n    gradient_accumulation_steps=16,\n    n_gpu=1,\n    early_stop_callback=False,\n    fp_16=False, # if you want to enable 16-bit training then install apex and set this to true\n    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n    max_grad_norm=1.0, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n    seed=42,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Topic Modelling with T5","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = news.sample(frac = 0.1,random_state = 1)\nval = news.sample(frac = 0.01,random_state = 41)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_list = ['authors', 'link', 'date']\ntrain.drop(drop_list,axis = 1,inplace = True)\nval.drop(drop_list,axis = 1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pwd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir data\ntrain.to_csv(\"/kaggle/working/data/train.csv\",index = False)\nval.to_csv(\"/kaggle/working/data/val.csv\",index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained('t5-base')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Topicmodel(Dataset):\n    def __init__(self, tokenizer, data_dir, type_path, max_len=256):\n        self.path = os.path.join(data_dir, type_path + '.csv')\n\n        self.source_column_1 = 'headline'\n        self.source_column_2 = 'short_description'\n        self.target_column = 'category'\n        self.data = pd.read_csv(self.path)\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n        self.inputs = []\n        self.targets = []\n\n        self._build()\n\n    def __len__(self):\n        return len(self.inputs)\n\n    def __getitem__(self, index):\n        source_ids = self.inputs[index][\"input_ids\"].squeeze()\n        target_ids = self.targets[index][\"input_ids\"].squeeze()\n\n        src_mask = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n        target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n\n        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n\n    def _build(self):\n        for idx in range(len(self.data)):\n            input_1,input_2,target = self.data.loc[idx, self.source_column_1],self.data.loc[idx, self.source_column_2],self.data.loc[idx, self.target_column]\n\n            input_ = \"Text : \"+ str(input_1) + \".\"+ str(input_2)  +\"</s>\"\n            target = \"Topic : \" +str(target) + \" </s>\"\n\n            # tokenize inputs\n            tokenized_inputs = self.tokenizer.batch_encode_plus(\n                [input_], max_length=self.max_len, pad_to_max_length=True, return_tensors=\"pt\"\n            )\n            # tokenize targets\n            tokenized_targets = self.tokenizer.batch_encode_plus(\n                [target], max_length=self.max_len, pad_to_max_length=True, return_tensors=\"pt\"\n            )\n\n            self.inputs.append(tokenized_inputs)\n            self.targets.append(tokenized_targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pwd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = Topicmodel(tokenizer, '/kaggle/working/data/', 'val', 312)\nprint(\"Val dataset: \",len(dataset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = dataset[61]\nprint(tokenizer.decode(data['source_ids']))\nprint(tokenizer.decode(data['target_ids']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if not os.path.exists('t5_data'):\n    os.makedirs('t5_data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls t5_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"args_dict.update({'data_dir': '/kaggle/working/data/', 'output_dir': 't5_data', 'num_train_epochs':1,'max_seq_length':312})\nargs = argparse.Namespace(**args_dict)\nprint(args_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint_callback = pl.callbacks.ModelCheckpoint(\n    filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n)\n\ntrain_params = dict(\n    accumulate_grad_batches=args.gradient_accumulation_steps,\n    gpus=args.n_gpu,\n    max_epochs=args.num_train_epochs,\n    early_stop_callback=False,\n    precision= 16 if args.fp_16 else 32,\n    amp_level=args.opt_level,\n    gradient_clip_val=args.max_grad_norm,\n    checkpoint_callback=checkpoint_callback,\n    callbacks=[LoggingCallback()],\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_dataset(tokenizer, type_path, args):\n  return Topicmodel(tokenizer=tokenizer, data_dir=args.data_dir, type_path=type_path,  max_len=args.max_seq_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Initialize model\")\nmodel = T5FineTuner(args)\n\ntrainer = pl.Trainer(**train_params)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\" Training model\")\ntrainer.fit(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"training finished\")\n\nprint (\"Saving model\")\nmodel.model.save_pretrained('t5_data')\n\nprint (\"Saved model\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import textwrap\nfrom tqdm.auto import tqdm\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pwd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset =  Topicmodel(tokenizer, data_dir='/kaggle/working/data/', type_path='val')\nloader = DataLoader(dataset, batch_size=32, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outputs = []\ntargets = []\nfor batch in tqdm(loader):\n  outs = model.model.generate(input_ids=batch['source_ids'].cuda(), \n                              attention_mask=batch['source_mask'].cuda(), \n                              max_length=20)\n\n  dec = [tokenizer.decode(ids) for ids in outs]\n  target = [tokenizer.decode(ids) for ids in batch[\"target_ids\"]]\n  \n  outputs.extend(dec)\n  targets.extend(target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.accuracy_score(targets, outputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def topic(string):\n    text = \"Text : \" + string + \"</s>\"\n    encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n#     input_ids, attention_masks = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n    outs = model.model.generate(input_ids=encoding[\"input_ids\"].cuda(), \n                              attention_mask=encoding[\"attention_mask\"].cuda(), \n                              max_length=20)\n    print (\"\\nOriginal Text ::\")\n    print (string)\n    print (\"Topic :: \")\n    string_final = [tokenizer.decode(ids) for ids in outs]    \n    return(\" \".join(string_final))\n\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"str1 = \"sachin tendulkar\"\ntopic(str1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"str1 = \"Donald Trump\"\ntopic(str1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"str1 = \"pharma\"\ntopic(str1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge both Title and description\n# !wget http://blob.thijs.ai/wiki-summary-dataset/raw.tar.gz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !unzip raw.tar.gz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !tar --gunzip --extract --verbose --file=raw.tar.gz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df = pd.read_csv('raw.txt', sep=\"|\", header=None, names=['Topic','Nan','Nan2','Text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop_list = [\"Nan\",\"Nan2\"]\n# df.drop(drop_list,inplace = True,axis = 1 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# new_df = df.sample(frac=0.01, replace=True, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# new_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# new_df.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df = pd.read_csv(\"/kaggle/input/medium-stories/Medium_Clean.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop_list = ['Image', 'Author', 'Publication','Year', 'Month', 'Day', 'Reading_Time']\n# df.drop(drop_list,axis = 1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop_list = ['Unnamed: 0','Claps', 'url', 'Author_url']\n\n\n\n\n# df.drop(drop_list,axis = 1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.dropna(axis=0, how='any', thresh=None, subset=None, inplace=True)\n# df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# listl = ['Tag_ai', 'Tag_android', 'Tag_apple','Tag_architecture', 'Tag_art', 'Tag_artificial-intelligence','Tag_big-data', 'Tag_bitcoin', 'Tag_blacklivesmatter', 'Tag_blockchain',\n#        'Tag_blog', 'Tag_blogging', 'Tag_books', 'Tag_branding', 'Tag_business',\n#        'Tag_college', 'Tag_computer-science', 'Tag_creativity',\n#        'Tag_cryptocurrency', 'Tag_culture', 'Tag_data', 'Tag_data-science',\n#        'Tag_data-visualization', 'Tag_deep-learning', 'Tag_design', 'Tag_dogs',\n#        'Tag_donald-trump', 'Tag_economics', 'Tag_education', 'Tag_energy',\n#        'Tag_entrepreneurship', 'Tag_environment', 'Tag_ethereum',\n#        'Tag_feminism', 'Tag_fiction', 'Tag_food', 'Tag_football', 'Tag_google',\n#        'Tag_government', 'Tag_happiness', 'Tag_health', 'Tag_history',\n#        'Tag_humor', 'Tag_inspiration', 'Tag_investing', 'Tag_ios',\n#        'Tag_javascript', 'Tag_jobs', 'Tag_journalism', 'Tag_leadership',\n#        'Tag_life', 'Tag_life-lessons', 'Tag_love', 'Tag_machine-learning',\n#        'Tag_marketing', 'Tag_medium', 'Tag_mobile', 'Tag_motivation',\n#        'Tag_movies', 'Tag_music', 'Tag_nba', 'Tag_news', 'Tag_nutrition',\n#        'Tag_parenting', 'Tag_personal-development', 'Tag_photography',\n#        'Tag_poem', 'Tag_poetry', 'Tag_politics', 'Tag_product-design',\n#        'Tag_productivity', 'Tag_programming', 'Tag_psychology', 'Tag_python',\n#        'Tag_racism', 'Tag_react', 'Tag_relationships', 'Tag_science',\n#        'Tag_self-improvement', 'Tag_social-media', 'Tag_software-engineering',\n#        'Tag_sports', 'Tag_startup', 'Tag_tech', 'Tag_technology', 'Tag_travel',\n#        'Tag_trump', 'Tag_ux', 'Tag_venture-capital', 'Tag_web-design',\n#        'Tag_web-development', 'Tag_women', 'Tag_wordpress', 'Tag_work',\n#        'Tag_writing']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# listl[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# len(df)\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df[\"Tags\"] = \" \"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.reset_index(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def tag(df):\n#     for i in range(10000):\n#         for j in listl:\n#             if df[j][i] == int(1):\n#                 df[\"Tags\"][i] = str(df[\"Tags\"][i]) + \" \" +str(j)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%timeit\n# tag(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df[\"Tags\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}