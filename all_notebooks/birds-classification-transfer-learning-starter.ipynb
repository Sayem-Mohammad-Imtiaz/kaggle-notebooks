{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Introduction\n\nIn this project, I will classify images of birds by using transfer learning from a pre-trained network. I will use MobileNet V2 model developed at Google. I am beginner for computer vision and i am trying to learn more about it. I will follow transfer learning and fine-tuning which is tensorflow tutorial for the project as a guideline.\n\nMy aim is to complete an end to end computer vision problem with basic parts, such as bulding an input pipeline, compose the model, data augmentation etc.\n\nLet's get started !!","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-05-30T16:52:00.726824Z","iopub.execute_input":"2021-05-30T16:52:00.727177Z","iopub.status.idle":"2021-05-30T16:52:00.73206Z","shell.execute_reply.started":"2021-05-30T16:52:00.727143Z","shell.execute_reply":"2021-05-30T16:52:00.730915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Processing","metadata":{}},{"cell_type":"code","source":"PATH=\"../input/100-bird-species\"\ntrain_dir = os.path.join(PATH, 'train')\nvalidation_dir = os.path.join(PATH, 'valid')\ntest_dir = os.path.join(PATH, 'test')","metadata":{"execution":{"iopub.status.busy":"2021-05-30T16:52:01.704077Z","iopub.execute_input":"2021-05-30T16:52:01.704396Z","iopub.status.idle":"2021-05-30T16:52:01.709086Z","shell.execute_reply.started":"2021-05-30T16:52:01.704361Z","shell.execute_reply":"2021-05-30T16:52:01.707884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create tf.data.Dataset for training, validation and test using Keras image_dataset_from_directory\n\nBATCH_SIZE = 32\nIMG_SIZE = (224,224)\n\ntrain_dataset = image_dataset_from_directory(train_dir,\n                                             shuffle=True,\n                                             batch_size=BATCH_SIZE,\n                                             image_size=IMG_SIZE)\n\nvalidation_dataset = image_dataset_from_directory(validation_dir,\n                                                  shuffle=True,\n                                                  batch_size=BATCH_SIZE,\n                                                  image_size=IMG_SIZE)\n\ntest_dataset = image_dataset_from_directory(test_dir,\n                                            shuffle=True,\n                                            batch_size=BATCH_SIZE,\n                                            image_size=IMG_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T16:52:02.06282Z","iopub.execute_input":"2021-05-30T16:52:02.063129Z","iopub.status.idle":"2021-05-30T16:52:04.789771Z","shell.execute_reply.started":"2021-05-30T16:52:02.063097Z","shell.execute_reply":"2021-05-30T16:52:04.789007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Control bathches sizes\n\nprint('Number of train batches: %d' % tf.data.experimental.cardinality(train_dataset))\nprint('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\nprint('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2021-05-30T16:52:04.791396Z","iopub.execute_input":"2021-05-30T16:52:04.791721Z","iopub.status.idle":"2021-05-30T16:52:04.79801Z","shell.execute_reply.started":"2021-05-30T16:52:04.791683Z","shell.execute_reply":"2021-05-30T16:52:04.797195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The first nine images and labels from training set\n\nclass_names = train_dataset.class_names\n\nplt.figure(figsize=(12,12))\nfor images, labels in train_dataset.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-05-30T16:52:04.800226Z","iopub.execute_input":"2021-05-30T16:52:04.800886Z","iopub.status.idle":"2021-05-30T16:52:06.453738Z","shell.execute_reply.started":"2021-05-30T16:52:04.800842Z","shell.execute_reply":"2021-05-30T16:52:06.45273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for better data performance using buffered prefetching \n\nAUTOTUNE = tf.data.AUTOTUNE\n\ntrain_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\nvalidation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\ntest_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T16:52:06.455541Z","iopub.execute_input":"2021-05-30T16:52:06.455872Z","iopub.status.idle":"2021-05-30T16:52:06.473068Z","shell.execute_reply.started":"2021-05-30T16:52:06.455838Z","shell.execute_reply":"2021-05-30T16:52:06.467693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Simple Data Augmentation","metadata":{}},{"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n])","metadata":{"execution":{"iopub.status.busy":"2021-05-30T16:52:06.473974Z","iopub.execute_input":"2021-05-30T16:52:06.474287Z","iopub.status.idle":"2021-05-30T16:52:06.500487Z","shell.execute_reply.started":"2021-05-30T16:52:06.474253Z","shell.execute_reply":"2021-05-30T16:52:06.499522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Result for an image after apply the augmentation\n\nfor image, _ in train_dataset.take(1):\n    plt.figure(figsize=(10, 10))\n    first_image = image[0]\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n        plt.imshow(augmented_image[0] / 255)\n        plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-05-30T16:52:06.501859Z","iopub.execute_input":"2021-05-30T16:52:06.502223Z","iopub.status.idle":"2021-05-30T16:52:07.792551Z","shell.execute_reply.started":"2021-05-30T16:52:06.502188Z","shell.execute_reply":"2021-05-30T16:52:07.791811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create a base pre-trained model","metadata":{}},{"cell_type":"code","source":"# Download mobilenet_v2 model architecture.\n\npreprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input","metadata":{"execution":{"iopub.status.busy":"2021-05-30T16:52:07.793634Z","iopub.execute_input":"2021-05-30T16:52:07.79413Z","iopub.status.idle":"2021-05-30T16:52:07.797751Z","shell.execute_reply.started":"2021-05-30T16:52:07.794087Z","shell.execute_reply":"2021-05-30T16:52:07.797008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the base model from the pre-trained model MobileNet V2\n\nIMG_SHAPE = IMG_SIZE + (3,)\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')","metadata":{"execution":{"iopub.status.busy":"2021-05-30T16:52:07.799704Z","iopub.execute_input":"2021-05-30T16:52:07.800246Z","iopub.status.idle":"2021-05-30T16:52:08.738432Z","shell.execute_reply.started":"2021-05-30T16:52:07.800185Z","shell.execute_reply":"2021-05-30T16:52:08.73754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This feature extractor converts each 224x224x3 image into a 7x7x1280 block of features\n\nimage_batch, label_batch = next(iter(train_dataset))\nfeature_batch = base_model(image_batch)\nprint(feature_batch.shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T16:55:36.360646Z","iopub.execute_input":"2021-05-30T16:55:36.360996Z","iopub.status.idle":"2021-05-30T16:55:36.818538Z","shell.execute_reply.started":"2021-05-30T16:55:36.360964Z","shell.execute_reply":"2021-05-30T16:55:36.8165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze the model weights before compile and train the model.\n\nbase_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-05-30T16:54:25.732842Z","iopub.execute_input":"2021-05-30T16:54:25.733189Z","iopub.status.idle":"2021-05-30T16:54:25.741035Z","shell.execute_reply.started":"2021-05-30T16:54:25.733157Z","shell.execute_reply":"2021-05-30T16:54:25.740173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the features to a single 1280 element vector per image\n\nglobal_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nfeature_batch_average = global_average_layer(feature_batch)\nprint(feature_batch_average.shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T16:54:27.174824Z","iopub.execute_input":"2021-05-30T16:54:27.175159Z","iopub.status.idle":"2021-05-30T16:54:27.181239Z","shell.execute_reply.started":"2021-05-30T16:54:27.175129Z","shell.execute_reply":"2021-05-30T16:54:27.18014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply a tf.keras.layers.Dense layer to convert these features into 270 predictions per image\n\nprediction_layer = tf.keras.layers.Dense(270, activation = 'softmax')\nprediction_batch = prediction_layer(feature_batch_average)\nprint(prediction_batch.shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T16:52:08.764369Z","iopub.execute_input":"2021-05-30T16:52:08.764717Z","iopub.status.idle":"2021-05-30T16:52:08.777467Z","shell.execute_reply.started":"2021-05-30T16:52:08.764683Z","shell.execute_reply":"2021-05-30T16:52:08.776449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build a model by chaining together the data augmentation, rescaling, base_model and feature extractor layers using the Keras\n\ninputs = tf.keras.Input(shape=(224, 224, 3))\nx = data_augmentation(inputs)\nx = preprocess_input(x)\nx = base_model(x, training=False)\nx = global_average_layer(x)\nx = tf.keras.layers.Dropout(0.2)(x)\noutputs = prediction_layer(x)\nmodel = tf.keras.Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T16:52:08.778961Z","iopub.execute_input":"2021-05-30T16:52:08.779451Z","iopub.status.idle":"2021-05-30T16:52:09.200584Z","shell.execute_reply.started":"2021-05-30T16:52:08.779415Z","shell.execute_reply":"2021-05-30T16:52:09.199786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model before training it. Since there are multi classes, I will use a Sparse Categorical Crossentropy loss \n\nbase_learning_rate = 0.0001\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['acc'])","metadata":{"execution":{"iopub.status.busy":"2021-05-30T16:52:11.218466Z","iopub.execute_input":"2021-05-30T16:52:11.21879Z","iopub.status.idle":"2021-05-30T16:52:11.233763Z","shell.execute_reply.started":"2021-05-30T16:52:11.218762Z","shell.execute_reply":"2021-05-30T16:52:11.232705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T16:52:11.572585Z","iopub.execute_input":"2021-05-30T16:52:11.572869Z","iopub.status.idle":"2021-05-30T16:52:11.591021Z","shell.execute_reply.started":"2021-05-30T16:52:11.572842Z","shell.execute_reply":"2021-05-30T16:52:11.59009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train The Model","metadata":{}},{"cell_type":"code","source":"initial_epochs = 10\nhistory = model.fit(train_dataset,\n                    epochs=initial_epochs,\n                    validation_data=validation_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T15:33:05.001518Z","iopub.execute_input":"2021-05-30T15:33:05.003395Z","iopub.status.idle":"2021-05-30T15:45:15.557625Z","shell.execute_reply.started":"2021-05-30T15:33:05.003356Z","shell.execute_reply":"2021-05-30T15:45:15.55682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Learning Curves","metadata":{}},{"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,max(plt.ylim())])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-30T15:45:15.560716Z","iopub.execute_input":"2021-05-30T15:45:15.560974Z","iopub.status.idle":"2021-05-30T15:45:15.825456Z","shell.execute_reply.started":"2021-05-30T15:45:15.560949Z","shell.execute_reply":"2021-05-30T15:45:15.824693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation and prediction","metadata":{}},{"cell_type":"code","source":"# Finaly we can verify the performance of the model on test set.\n\nloss, accuracy = model.evaluate(test_dataset)\nprint('Test accuracy :', accuracy)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T15:45:15.826572Z","iopub.execute_input":"2021-05-30T15:45:15.826892Z","iopub.status.idle":"2021-05-30T15:45:24.119826Z","shell.execute_reply.started":"2021-05-30T15:45:15.826858Z","shell.execute_reply":"2021-05-30T15:45:24.119102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot prediction results\n\nimage_batch, label_batch = test_dataset.as_numpy_iterator().next()\npredicted_batch = model.predict(image_batch)\npredicted_id = np.argmax(predicted_batch, axis=-1)\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(image_batch[i].astype(\"uint8\"))\n    plt.title(class_names[predicted_id[i]])\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-05-30T16:26:40.483951Z","iopub.execute_input":"2021-05-30T16:26:40.48431Z","iopub.status.idle":"2021-05-30T16:26:41.513833Z","shell.execute_reply.started":"2021-05-30T16:26:40.484279Z","shell.execute_reply":"2021-05-30T16:26:41.512931Z"},"trusted":true},"execution_count":null,"outputs":[]}]}