{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\ntrain = pd.read_csv(\"../input/hackerearth-ml-challenge-pet-adoption/train.csv\")\ntest=pd.read_csv(\"../input/hackerearth-ml-challenge-pet-adoption/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['breed_category'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=train['breed_category'][(np.isnan(train['condition']))]\na.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_id=test['pet_id']\nntrain=train.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y1=train['breed_category']\ny2=train['pet_category']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = pd.concat((train, test)).reset_index(drop=True)\nall_data.drop(['breed_category','pet_category'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['condition'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['condition'].fillna(-1,inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['condition'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['issue_date']=pd.to_datetime(all_data['issue_date'])\nall_data['listing_date']=pd.to_datetime(all_data['listing_date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=[]\nfor d in all_data['issue_date']:\n    y=d.month\n    x.append(y)\nall_data['issue_month']=x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=[]\nfor d in all_data['listing_date']:\n    y=d.month\n    x.append(y)\nall_data['listing_month']=x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=[]\nfor d in all_data['listing_date']:\n    y=d.year+(d.month/12.0)+(d.day/365.0)\n    x.append(y)\nall_data['modified_listing_date']=x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=[]\nfor d in all_data['issue_date']:\n    y=d.year+(d.month/12.0)+(d.day/365.0)\n    x.append(y)\nall_data['modified_issue_date']=x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['took_time']=abs(all_data['modified_listing_date']-all_data['modified_issue_date'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['1stnum'] = all_data['pet_id'].str[:6]\nall_data['1st2num'] = all_data['pet_id'].str[:7]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = all_data[:ntrain]\ntest = all_data[ntrain:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=train.drop(['pet_id','issue_date','listing_date','modified_issue_date'],axis=1)\ntest=test.drop(['pet_id','issue_date','listing_date','modified_issue_date'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.select_dtypes(exclude='number').columns.to_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=pd.get_dummies(x)\ntest=pd.get_dummies(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=set(x.columns)-set(test.columns)\na=list(a)\na","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=x.drop(a,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = pd.concat((x, test)).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\nnames = all_data.columns\n\nscaler = preprocessing.StandardScaler()\n\nscaled_df = scaler.fit_transform(all_data)\nall_data = pd.DataFrame(scaled_df, columns=names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = all_data[:ntrain]\ntest = all_data[ntrain:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx1_train,x1_test,y1_train,y1_test=train_test_split(x,y2,test_size=0.2,random_state=44,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = XGBClassifier()\nmodel1.fit(x1_train, y1_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_feat=model1.predict(x)\n#output1 is new first output i.e the predicted pet_category of model 1 for test data\noutput1=model1.predict(test)\n#vld1 is validation 1 i.e we'll check score with the predicted result of validation data of model 1\nvld1=model1.predict(x1_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x2 = pd.DataFrame(x, columns=names)\ntest2 = pd.DataFrame(test, columns=names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x2['output1']=new_feat\n#the predicted pet_category of model 1 for test data is used as a input variable or feature of the test data of model 2\ntest2['output1']=output1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x2_train,x2_test,y2_train,y2_test=train_test_split(x2,y1,test_size=0.2,random_state=44)\nxgb2 = XGBClassifier()\nxgb2=xgb2.fit(x2_train,y2_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output2=xgb2.predict(test)\n#vld2 is validation 2 i.e we'll check score with the predicted result of validation data of model 2\nvld2=xgb2.predict(x2_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics  import f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s1=f1_score(y1_test,vld1,average='weighted')\ns2=f1_score(y2_test,vld2,average='weighted')\naccuracy=100*((s1+s2)/2)\naccuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_new=pd.DataFrame({\n    \"pet_id\":test_id,\n    \"breed_category\":output2,\n    \"pet_category\":output1\n})\nsub_new.to_csv(\"sub_pet.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}