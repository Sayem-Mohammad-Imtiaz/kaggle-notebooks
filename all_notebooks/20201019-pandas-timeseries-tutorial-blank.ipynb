{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Getting started with Pandas TimeSeries\n\nThis notebook is intended to introduce you to the basic Pandas DateTime    \nThe following five points will be covered:\n\n1. [Parsing DateTime](#task1)\n2. [Aggregating columns](#task2)\n3. [Extracting DateTime properties](#task3)\n4. [Fitering and Selecting specific durations](#task4)\n5. [Changing the granularity of the Timeseries](#task5)\n","metadata":{}},{"cell_type":"markdown","source":"### Prepare environment and read data ","metadata":{}},{"cell_type":"code","source":"# Constants \nINPUT_PATH = '/kaggle/input/netflix-shows/netflix_titles.csv'\n\n# Libraries \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\n# Set default properties for plotting \nplt.rcParams['figure.figsize'] = [11, 4]\nplt.rcParams['figure.dpi'] = 100 ","metadata":{"execution":{"iopub.status.busy":"2021-07-02T09:05:01.764572Z","iopub.execute_input":"2021-07-02T09:05:01.765003Z","iopub.status.idle":"2021-07-02T09:05:01.773004Z","shell.execute_reply.started":"2021-07-02T09:05:01.764968Z","shell.execute_reply":"2021-07-02T09:05:01.772041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read data and display 5 random entries \nraw_df = pd.read_csv(INPUT_PATH)\n\nraw_df.head()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-07-02T09:05:02.909898Z","iopub.execute_input":"2021-07-02T09:05:02.910435Z","iopub.status.idle":"2021-07-02T09:05:03.064863Z","shell.execute_reply.started":"2021-07-02T09:05:02.910385Z","shell.execute_reply":"2021-07-02T09:05:03.063188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_____\n\n## Task 1: Countthe number of shows added per day     \n\nIn the following section, we will parse the raw date format into      \npandas datetime and summarize the daily shows added to the total number \n\n### Parse timestamp into datetime column <a id='task1'></a>\n\nChange the raw format to a pandas datetime format.    \nOnce we have changed the format as such, we will be able to    \napply more functionalities illustrated below \n","metadata":{}},{"cell_type":"code","source":"df = raw_df.copy()\n\ndf.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-07-02T09:05:04.908971Z","iopub.execute_input":"2021-07-02T09:05:04.909395Z","iopub.status.idle":"2021-07-02T09:05:04.921144Z","shell.execute_reply.started":"2021-07-02T09:05:04.909359Z","shell.execute_reply":"2021-07-02T09:05:04.919544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Parse dae_added to be datetime**","metadata":{}},{"cell_type":"code","source":"pd.to_datetime(df['date_added'])\n\n# result below, 1st column is called index","metadata":{"execution":{"iopub.status.busy":"2021-07-02T09:05:07.196811Z","iopub.execute_input":"2021-07-02T09:05:07.197243Z","iopub.status.idle":"2021-07-02T09:05:07.401339Z","shell.execute_reply.started":"2021-07-02T09:05:07.197205Z","shell.execute_reply":"2021-07-02T09:05:07.400011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**add date_added column to DF after parsing it.**","metadata":{}},{"cell_type":"code","source":"df['date_added'] = pd.to_datetime(df['date_added'])\ndf.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-07-02T09:05:09.587773Z","iopub.execute_input":"2021-07-02T09:05:09.588303Z","iopub.status.idle":"2021-07-02T09:05:09.78381Z","shell.execute_reply.started":"2021-07-02T09:05:09.588267Z","shell.execute_reply":"2021-07-02T09:05:09.782898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf","metadata":{"execution":{"iopub.status.busy":"2021-07-02T09:05:10.684422Z","iopub.execute_input":"2021-07-02T09:05:10.684808Z","iopub.status.idle":"2021-07-02T09:05:10.717319Z","shell.execute_reply.started":"2021-07-02T09:05:10.684775Z","shell.execute_reply":"2021-07-02T09:05:10.716405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Count shows added  per date <a id='task2'></a>\nAll the shows have been listed in the original dataframe.     \nNow let's count the total number of shows added per day","metadata":{}},{"cell_type":"code","source":"show_count = df.groupby('date_added')[['show_id']].count()\n\nshow_count\n#show_count.index\n#show_count.min\n#show_count.max","metadata":{"execution":{"iopub.status.busy":"2021-07-02T09:05:12.732871Z","iopub.execute_input":"2021-07-02T09:05:12.733318Z","iopub.status.idle":"2021-07-02T09:05:12.753889Z","shell.execute_reply.started":"2021-07-02T09:05:12.733279Z","shell.execute_reply":"2021-07-02T09:05:12.752722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"______\n\n## Task 2: Extract the day name and sum-up the shows added \n<a id='task3'></a>\n\nIn the last step, we have used the `date_added` column to count the number of shows.    \nSince we've used the `groupby` functionality to count the number of shows,     \nthe column is set as our index. \n\nWe could now use our new index directly to extract the Attributes of the timestamp.    \nOne example of those Attributes is the `day_name`.    \nCheck out the [full list of the attributes here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DatetimeIndex.html).","metadata":{}},{"cell_type":"code","source":"# DatetimeIndex\nshow_count.index","metadata":{"execution":{"iopub.status.busy":"2021-07-02T09:05:30.952345Z","iopub.execute_input":"2021-07-02T09:05:30.953062Z","iopub.status.idle":"2021-07-02T09:05:30.960537Z","shell.execute_reply.started":"2021-07-02T09:05:30.953016Z","shell.execute_reply":"2021-07-02T09:05:30.959662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Extract day from DatetimeIndex**","metadata":{}},{"cell_type":"code","source":"show_count.index.day_name()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T09:11:01.974844Z","iopub.execute_input":"2021-07-02T09:11:01.975273Z","iopub.status.idle":"2021-07-02T09:11:01.985047Z","shell.execute_reply.started":"2021-07-02T09:11:01.975237Z","shell.execute_reply":"2021-07-02T09:11:01.983416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Extract the day name and sum-up the shows added**","metadata":{}},{"cell_type":"code","source":"show_count['day_of_week'] = show_count.index.day_name()\n#Show_per_day_name = df.groupby(show_count.index.day_name())[['show_id']].count()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T09:12:36.191899Z","iopub.execute_input":"2021-07-02T09:12:36.192297Z","iopub.status.idle":"2021-07-02T09:12:36.206756Z","shell.execute_reply.started":"2021-07-02T09:12:36.192267Z","shell.execute_reply":"2021-07-02T09:12:36.205475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_count","metadata":{"execution":{"iopub.status.busy":"2021-07-02T09:12:48.263124Z","iopub.execute_input":"2021-07-02T09:12:48.263569Z","iopub.status.idle":"2021-07-02T09:12:48.281614Z","shell.execute_reply.started":"2021-07-02T09:12:48.263535Z","shell.execute_reply":"2021-07-02T09:12:48.279819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Show_per_day_name = show_count.groupby('day_of_week')[['show_id']].sum()\nShow_per_day_name","metadata":{"execution":{"iopub.status.busy":"2021-07-02T09:21:10.37862Z","iopub.execute_input":"2021-07-02T09:21:10.378991Z","iopub.status.idle":"2021-07-02T09:21:10.393355Z","shell.execute_reply.started":"2021-07-02T09:21:10.378957Z","shell.execute_reply":"2021-07-02T09:21:10.392301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"______\n\n## Task 3: Select data from 2016 onwards \n<a id='task4'></a>\n\nYou can also use the regular masking way to select and filter entries.      \nThe syntax is even simpler than one could expect. You don't even need to parse    \nyour filtering criteria to `datetime`. A simple string with `%YYYY-%MM-%DD` format     \nwill do the job  \n","metadata":{}},{"cell_type":"markdown","source":"**Plotting from 2008 to 2020, it is noticed that data is more consistant starting from 2016.**","metadata":{}},{"cell_type":"code","source":"#show_count\nshow_count['show_id'].plot()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T09:26:23.765984Z","iopub.execute_input":"2021-07-02T09:26:23.766407Z","iopub.status.idle":"2021-07-02T09:26:24.026893Z","shell.execute_reply.started":"2021-07-02T09:26:23.766373Z","shell.execute_reply":"2021-07-02T09:26:24.025418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#show_count.index >= '2016-01-01'\nshow_count[show_count.index >= '2016-01-01']\n\n# To make sure\n# show_count[show_count.index >= '2016-01-01'].index\n# show_count[show_count.index >= '2016-01-01'].index.min()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T09:36:20.53923Z","iopub.execute_input":"2021-07-02T09:36:20.539637Z","iopub.status.idle":"2021-07-02T09:36:20.557148Z","shell.execute_reply.started":"2021-07-02T09:36:20.539603Z","shell.execute_reply":"2021-07-02T09:36:20.556309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Take copy of 2016 onwards**","metadata":{}},{"cell_type":"code","source":"show_count = show_count[show_count.index >= '2016-01-01'].copy()\nshow_count","metadata":{"execution":{"iopub.status.busy":"2021-07-02T09:38:02.142807Z","iopub.execute_input":"2021-07-02T09:38:02.143384Z","iopub.status.idle":"2021-07-02T09:38:02.160868Z","shell.execute_reply.started":"2021-07-02T09:38:02.143346Z","shell.execute_reply":"2021-07-02T09:38:02.159194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"______\n\n## Task 4: Sum up weekly data \n<a id='task5'></a>\n\nIt is possible to change the granularity of your timeseries directly using Pandas datetie module.        \n       \n       \nTo do that, you need to specify two things: \n- Your new granularity passed as an argument to the `resample` function. [Read more details](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects)\n- The function that will be used to generate the new granularity","metadata":{}},{"cell_type":"code","source":"show_count['show_id'].resample('1W').sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T09:46:26.516577Z","iopub.execute_input":"2021-07-02T09:46:26.517007Z","iopub.status.idle":"2021-07-02T09:46:26.536581Z","shell.execute_reply.started":"2021-07-02T09:46:26.516973Z","shell.execute_reply":"2021-07-02T09:46:26.535485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}