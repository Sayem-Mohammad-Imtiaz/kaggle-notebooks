{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"text-align: center;\">EDA of Udemy Courses and ML to Predict Subscribers</h1>","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# common imports\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# pandas imports\nfrom pandas.plotting import scatter_matrix\n\n# machine learning imports\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn import metrics\n\n# display setup\npd.set_option(\"display.max_columns\", None) # the None parameter displays unlimited columns\nsns.set(style=\"whitegrid\") # for plots","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Getting the Data","metadata":{}},{"cell_type":"code","source":"# read the csv file\ndf = pd.read_csv(\"../input/udemy-courses/udemy_courses.csv\")","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display the first 5 rows for a quick look\ndf.head()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DataFrame shape (rows, columns)\n# understand the amount of data we are working with\ndf.shape","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# description of data\ndf.info()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check if there are null values\ndf.isna().sum()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summary of the numerical attributes\ndf.describe()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> As shown above, there are no missing values which is excellent!\n>\n> ##### *It is vital to understand the features we are working with.*\n> ### Features in the DataFrame:\n>> 1. course_id: Course identification number\n>> 2. course_title: Title of course\n>> 3. url: Course URL\n>> 4. is_paid: True if the course costs money, false if the course is free\n>> 5. price: Price of course\n>> 6. num_subscribers: Number of subscribers for the course\n>> 7. num_lectures: Number of lectures in the course\n>> 8. level: Difficulty level of the course\n>> 9. content_duration: Duration of all course materials\n>> 10. published_timestamp: Course publication date\n>> 11. subject: Subject of course","metadata":{}},{"cell_type":"code","source":"# a histogram plot for each numerical attribute\ndf.drop(\"is_paid\", axis=1).hist(bins=30, figsize=(20,15))\nplt.tight_layout()\nplt.show()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Initial observations from the histograms:\n>> 1. Most course durations are between 0-5 hours.\n>> 2. There are usually around 1-50 lectures per course.\n>> 3. Courses tend to have few reviews. There are probably a handful of courses\n>> with a large amount of reviews since the X axis goes up to 25000 while over 3000\n>> instances are represented in the first bin.\n>> 4. The majority of courses are in the same range of subscribers. The instances farther up\n>> the scale were probably more successful or perhaps courses on a trending topic.\n>> 5. Assuming the prices are in USD, the range is between 0-250 dollars.\n>> The plot shows the most common price roughly $25.","metadata":{}},{"cell_type":"markdown","source":"> # Objective\n> ## Predicting the number of subscribers for a course.\n>> ### Chosen Feature:\n>> #### *num_subscribers* column\n>>> The column represents how many people have subscribed to each course.\n>>> ### Motive:\n>>> Predicting the number of people subscribed to a course, course popularity.","metadata":{}},{"cell_type":"markdown","source":"> ### Splitting the Data:\n>> Before further analysis let's split the data into a training set and a testing set.\n>> This will ensure avoidance of bias that could occur from learning the data as a whole.","metadata":{}},{"cell_type":"code","source":"# use sklearn train_test_split function to split the data\n# the random state parameter ensures that data will be shuffled and split the same way in each run\ntrain_set, test_set = train_test_split(df, test_size=0.20, random_state=42)","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of instances in training set: \", len(train_set))\nprint(\"Number of instances in testing set: \", len(test_set))","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Understanding and Visualizing the Data\n> ##### *The motivation for this section is to gain more insights*","metadata":{}},{"cell_type":"code","source":"# deep copy of the training set\ndf2 = train_set.copy()","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.head(2)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ## Exploring Attribute Combinations","metadata":{}},{"cell_type":"code","source":"# method creates a correlations matrix\ncorr_matrix = df2.corr()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# looking at attributes correlation with num_subscribers feature\ncorr_matrix[\"num_subscribers\"].sort_values(ascending=False)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a histogram plot for attributes with a high correlation\n\nattributes = [\"num_subscribers\", \"num_reviews\", \"num_lectures\", \"content_duration\", \"course_id\"]\n\nscatter_matrix(df2[attributes], figsize=(12,8))\nplt.tight_layout()\nplt.show()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scatter plot of the strongest correlation in the corr matrix\n# the alpha is set to show the distribution more clearly\ndf2.plot(kind=\"scatter\", x=\"num_reviews\", y=\"num_subscribers\", alpha=0.1,\n         color='b', figsize=(10,5))\nplt.title(\"Reviews and Subscribers Correlation\", size=20)\nplt.xlabel(\"num_reviews\", size=15)\nplt.ylabel(\"num_subscribers\", size=15)\nplt.tight_layout()\nplt.show()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### Correlations with num_subscribers Attribute- Overview:\n>> The strongest positive correlations (0.1 or more) are:\n>> * num_reviews\n>> * num_lectures\n>> * content_duration\n>>\n>> The strongest negative correlations (-0.1 or less) are:\n>> * course_id\n>> * is_paid","metadata":{}},{"cell_type":"markdown","source":"> ### Examining Course ID Feature","metadata":{}},{"cell_type":"code","source":"print(\"Number of unique course IDs:\", df2[\"course_id\"].nunique())\nprint(\"Length of DataFrame:\", len(df2))","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check if number of unique urls\n# should be individual for each instance\ndf2[\"url\"].nunique()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Since there is a unique value for almost every course ID, the correlation was probably\n> coincidental.","metadata":{}},{"cell_type":"code","source":"# show duplicated listings\ndf2[df2.duplicated(\"course_id\")]","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove duplicated listings\ndf2.drop_duplicates(inplace=True)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# examine changes\ndf2.shape","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### Overview:\n>> * The course ID is unique for each course.\n>> * This column should be removed when training a model in order to generalize better.","metadata":{}},{"cell_type":"markdown","source":"> ### Assessing Price Features","metadata":{}},{"cell_type":"code","source":"# evaluate current values in column\ndf2[\"is_paid\"].head(10)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use encoder to convert \"is_paid\" column to binary outcome\nordinal_encoder = OrdinalEncoder(dtype=int)\ndf2[\"is_paid\"] = ordinal_encoder.fit_transform(df2[[\"is_paid\"]])","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate changes\ndf2[\"is_paid\"].head(10)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 0 is False, 1 is True\nordinal_encoder.categories_","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# count number of instances for each outcome\ndf2[\"is_paid\"].value_counts()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use groupby for price attribute\nprice_values = df2.groupby(\"price\")","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check if number of free courses matches when the price is 0\nprice_values_0 = price_values.get_group(0)\nprice_values_0.shape","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot of free and paid courses\nplt.figure(figsize=(10,5))\nsns.countplot(x=df2[\"is_paid\"])\nplt.title(\"Free and Paid Courses\", size=20)\nplt.xlabel(\"is_paid\", size = 15)\nplt.ylabel(\"count\", size=15)\nplt.tight_layout()\nplt.show()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# course price values sorted by prices\ndf2[\"price\"].value_counts().sort_index()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# top ten course price values sorted by value counts\nprices_top10 = df2[\"price\"].value_counts().sort_values(ascending=False).head(10)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate percentage of instances per price in data\nprices_percent_in_data = []\nnum_subscribed = []\n\nfor i in range(len(prices_top10.index)):\n    prices_percent_in_data.append(round((prices_top10.values[i]/len(df2))*100,2))\n    num_subscribed.append(price_values.get_group(prices_top10.index[i])[\"num_subscribers\"].sum())","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a DataFrame with the results\nprices_top10_dict = {\"price\": prices_top10.index, \"number_of_instances\": prices_top10.values,\n                     \"% of data\": prices_percent_in_data, \"num_subscribers\": num_subscribed}\nprices_top10_df = pd.DataFrame(prices_top10_dict, index=range(1,11))\nprices_top10_df","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot of top 10 common prices by amount of subscribers\nplt.figure(figsize=(10,5))\nsns.barplot(x=prices_top10_df[\"price\"], y=prices_top10_df[\"num_subscribers\"])\nplt.xlabel(\"price\", size=15)\nplt.ylabel(\"num_subscribers\\n(millions)\", size=15)\nplt.title(\"Top 10 Common Prices by Subscribers\", size=20)\nplt.tight_layout()\nplt.show()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot of content duration by free or paid course\nplt.figure(figsize=(10,5))\nsns.scatterplot(x=df2[\"content_duration\"], y=df2[\"is_paid\"], alpha=0.1)\nplt.title(\"Content Duration by Type of Course Payment\", size=20)\nplt.xlabel(\"content_duration\", size=15)\nplt.ylabel(\"is_paid\", size=15)\nplt.tight_layout()\nplt.show()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### Observations:\n>> * As speculated earlier in the initial observations, $20 is the most common price for a course.\n>> * The number of listings with the price $0 matches the number of instances that were\n>> labeled \"False\" in the is_paid column.\n>> * The prices listed tend to increase by 5 dollars until they reach the maximum price\n>> which is $200.\n>> * Amongst the 10 most common prices in the data, most are subscribed to the free courses.\n>> * Content duration is longer for paid courses.","metadata":{}},{"cell_type":"markdown","source":"> ### Researching Level and Subject Features","metadata":{}},{"cell_type":"code","source":"# count number of instances\nlevel_values = df2[\"level\"].value_counts()\nlevel_values","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# count number of instances\nsubject_values = df2[\"subject\"].value_counts()\nsubject_values","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pie plot of course levels and subjects in data\nfig, ax = plt.subplots(1,2, figsize=(10,5))\nax[0].pie(level_values, startangle=180, labels=level_values.index, autopct=\"%1.1f%%\")\nax[0].set_title(\"Course Levels\", size=20)\nax[1].pie(subject_values, startangle=180, labels=subject_values.index, autopct=\"%1.1f%%\")\nax[1].set_title(\"Course Subjects\", size=20)\nplt.tight_layout()\nplt.show()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scatter plot of price by course level\nplt.figure(figsize=(10,5))\nsns.scatterplot(y=df2[\"level\"], x=df2[\"price\"], alpha=0.1)\nplt.title(\"Price by Course Level\", size=20)\nplt.xlabel(\"price\", size=15)\nplt.ylabel(\"level\", size=15)\nplt.tight_layout()\nplt.show()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot subject by number of subscribers and level\n# the black bars represent the error\nplt.figure(figsize=(10,5))\nsns.barplot(x=df2[\"subject\"], y=df2[\"num_subscribers\"], hue=df2[\"level\"])\nplt.title(\"Subject by Number of Subscribers and Level\", size=20)\nplt.xlabel(\"subject\", size=15)\nplt.ylabel(\"num_subscribers\", size=15)\nplt.tight_layout()\nplt.show()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### Observations:\n>> * All Levels is the most common level, representing over 50%.\n>> * Web Development is the most common subject, and Business Finance is second with\n>> approximately a 1% differential.\n>> * Price variations according to the level of the course also show that Expert is\n>> the least common level in the data. It is also the only level that does not\n>> provide free courses. The other levels are dispersed more frequently\n>> throughout the line.\n>> * Web Development courses are significantly higher in subscribers than the other subjects.\n>> Since Business Finance falls shortly behind in content, it is likely that people are more\n>> interested in studying Web Development courses.","metadata":{}},{"cell_type":"markdown","source":"> ### Analyzing Additional Columns","metadata":{}},{"cell_type":"code","source":"# examine current shape\ndf2.shape","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# every course has a unique URL\ndf2[\"url\"].nunique()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# some courses have an identical title\ndf2[\"course_title\"].nunique()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find duplicated instances\n# false marks all duplicates as true\ntitle_df = df2[df2.duplicated(\"course_title\", keep=False)].copy()\n# show duplicated titles\ntitle_df[\"course_title\"].unique()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# examine number of unique subscribers values\ntitle_df[\"num_subscribers\"].nunique()","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# groupy course title\ntitle = title_df.groupby(\"course_title\")","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# examining one of the duplicated courses\n# the courses have the same name and different values for some features\ntitle.get_group(\"Acoustic Blues Guitar Lessons\")","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### Observations:\n>> * The duplicated courses have different parameters such as is_paid or published_timestamp.\n>> Maybe the course provides the first lessons free of charge, or they added new content.\n>> * These instances can be kept as they are likely to have various values (i.e. each\n>> value in the num_subscribers column is unique).","metadata":{}},{"cell_type":"markdown","source":"# 3. Data Cleaning","metadata":{}},{"cell_type":"code","source":"# clean copy of training set\ndf3 = train_set.copy()","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3.shape","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove duplicated instances\ndf3.drop_duplicates(\"course_id\", inplace=True)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate changes\ndf3.shape","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# separate predictors from target values\n\n# drop creates a copy without changing the training set\nX_train = df3.drop(\"num_subscribers\", axis=1)\n\n# create a deep copy of the target values\ny_train = df3[\"num_subscribers\"].copy()","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### Removing the Following Columns:\n> The reason for removing these columns is for the model to generalize better.\n> Furthermore, these columns have a unique value for each instance (i.e. URL, course ID) which\n> does not provide information the model can learn from to predict on new data.\n>> * course_id\n>> * course_title\n>> * url\n>> * published_timestamp","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# list of numerical features\nnum_features = [\"price\", \"num_reviews\", \"num_lectures\", \"content_duration\"]\n\n# list of level feature categories\nlevels = [\"All Levels\", \"Beginner Level\", \"Intermediate Level\", \"Expert Level\"]\n\n# column transformer:\n# features generated by each transformer will be concatenated to form a single feature space\n# columns of the original feature matrix that are not specified are dropped\nfull_pipeline = ColumnTransformer([\n\n# MinMaxScaler normalizes data (rescales between 0-1)\n    (\"num\", MinMaxScaler(), num_features),\n\n# OrdinalEncoder converts categories to integers according to order specified in list\n    (\"level\", OrdinalEncoder(categories=[levels]), [\"level\"]),\n\n# OrdinalEncoder converts True and False values to integers\n# True=1, False=0\n    (\"is_paid\", OrdinalEncoder(dtype=int), [\"is_paid\"]),\n\n# OneHotEncoder converts categories to a binary dummy array\n    (\"subject\", OneHotEncoder(handle_unknown=\"ignore\"), [\"subject\"])\n])","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = num_features+[\"level\", \"is_paid\", \"subject\"]\n\n# transform training data using pipeline\nX_train_prepared = full_pipeline.fit_transform(X_train)\nX_tr_testing = full_pipeline.transform(X_train)","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Training and Evaluating Models","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"markdown","source":"> Chosen evaluation metric:\n>\n> The root-mean-square error (RMSE) is the standard deviation of the prediction error.\n> It is the differences between the predicted and actual values, and shows how much they are\n> spread out.","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# function prints scores, mean and std\ndef display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())\n\n# function prints evaluation metrics\ndef display_evaluation(actual, pred):\n    mse = metrics.mean_squared_error(actual, pred)\n    print(\"Mean Squared Error:\", mse)\n    print(\"Root Mean Squared Error:\", np.sqrt(mse))","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> The Linear Regression model computes a weighted sum of the input features, and a constant which\n> is the bias/intercept term. As the name implies, this is in fact a linear function.","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"markdown","source":"#### Model 1: Linear Regression","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# instantiate model\nlr = LinearRegression()","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the training data\nlr.fit(X_train_prepared, y_train)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict using training data\nlr_pred = lr.predict(X_tr_testing)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test on a few instances from training data\nsome_data = X_train.iloc[:10]\nsome_labels = y_train.iloc[:10]\nsome_data_prepared = full_pipeline.transform(some_data)\nprint(\"Predictions:\", lr.predict(some_data_prepared))\nprint(\"Labels:\", list(some_labels))","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use function to show results\ndisplay_evaluation(y_train, lr_pred)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Cross Validation for Linear Regression Model","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# 10 fold cross validation\nlr_scores = cross_val_score(lr, X_train_prepared, y_train, cv=10, scoring=\"neg_mean_squared_error\", )\n\n# scoring function returns a negative value for MSE (need to add the minus)\nlr_rmse_scores = np.sqrt(-lr_scores)\ndisplay_scores(lr_rmse_scores)","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# estimate prediction using cross validation\nlr_pred = cross_val_predict(lr, X_tr_testing, y_train, cv=10)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test on a few instances from training data\nsome_data = X_train.iloc[:10]\nsome_labels = y_train.iloc[:10]\nsome_data_prepared = full_pipeline.transform(some_data)\nprint(\"Predictions:\", lr.predict(some_data_prepared))\nprint(\"Labels:\", list(some_labels))","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use function to show results\ndisplay_evaluation(y_train, lr_pred)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> The Random Forest Regressor model is based on many decision trees.\n> A decision tree is a non-linear model built by constructing many linear boundaries.\n> The random forest model samples random points and subsets of features when training.\n> Then, the predictions are made by averaging the predictions made by each decision tree.","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"markdown","source":"#### Model 2: Random Forest Regressor","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# instantiate model\nrfr = RandomForestRegressor(random_state=42)","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the training data\nrfr.fit(X_train_prepared, y_train)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict using training data\nrfr_pred = rfr.predict(X_tr_testing)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use function to show results\ndisplay_evaluation(y_train, rfr_pred)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> The Random Forest Regressor model performed better than the linear regression model,\n> even after cross validation. The next step is to find the hyperparameters\n> that provide the best results.\n>\n> For this task we can use grid search cv. The grid search works by trying all parameter\n> combinations from the ones instantiated, then shows the best combination according to\n> the highest score.","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"markdown","source":"#### Grid Search Cross Validation 1","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# max features default is sqrt (number of features selected per split)\n# bootstrap default is true (resampling data true)\n# n estimators default is 100 (number of decision trees)\n# parameters for grid search\nparam_grid = {\"n_estimators\": [10,50,100,500], \"max_features\":[2,4,8], \"bootstrap\": [True, False]}","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# instantiate grid search\ngrid_search = GridSearchCV(rfr, param_grid, cv=5, scoring=\"neg_mean_squared_error\", return_train_score=True)","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit to the training data\ngrid_search.fit(X_train_prepared, y_train)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show the best score\nnp.sqrt(-grid_search.best_score_)","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show the best parameters\ngrid_search.best_estimator_","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show results for each iteration\ncvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model 3: Random Forest Regressor","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# instantiate model\nrfr = grid_search.best_estimator_\nrfr","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test on a few instances from training data\nsome_data = X_train.iloc[:10]\nsome_labels = y_train.iloc[:10]\nsome_data_prepared = full_pipeline.transform(some_data)\nprint(\"Predictions:\", rfr.predict(some_data_prepared))\nprint(\"Labels:\", list(some_labels))","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict using training data\nrfr_pred_2 = rfr.predict(X_tr_testing)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use function to show results\ndisplay_evaluation(y_train, rfr_pred_2)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Feature Importance","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"level_encoder = full_pipeline.named_transformers_[\"level\"]\nlevel_encoder_attribs = list(level_encoder.categories_[0])\n\nsubject_encoder = full_pipeline.named_transformers_[\"subject\"]\nsubject_encoder_attribs = list(subject_encoder.categories_[0])\n\nfeatures_sub = num_features+level_encoder_attribs+[\"is_paid\"]+subject_encoder_attribs","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pair the feature names with the results from grid search\nfeature_importance = grid_search.best_estimator_.feature_importances_\nsorted(zip(feature_importance,features_sub), reverse=True)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Next, lets train a model without the parameters that have less than 0.05 feature importance\n> and compare the model performances.\n>\n> In this case, all categorical features will be removed.","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# column transformer with numerical attributes only\nfull_pipeline_2 = ColumnTransformer([\n    (\"num\", MinMaxScaler(), num_features),\n])","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_prepared_2 = full_pipeline_2.fit_transform(X_train)\nX_tr_testing_2 = full_pipeline_2.transform(X_train)","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model 4: Random Forest Regressor","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# instantiate model\nrfr = RandomForestRegressor(random_state=42)","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the training data\nrfr.fit(X_train_prepared_2, y_train)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test on a few instances from training data\nsome_data = X_train.iloc[:10]\nsome_labels = y_train.iloc[:10]\nsome_data_prepared = full_pipeline_2.transform(some_data)\nprint(\"Predictions:\", rfr.predict(some_data_prepared))\nprint(\"Labels:\", list(some_labels))","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict using training data\nrfr_pred_3 = rfr.predict(X_tr_testing_2)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use function to show results\ndisplay_evaluation(y_train, rfr_pred_3)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Grid Search Cross Validation 2","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# parameters for grid search\nparam_grid_2 = {\"n_estimators\": [10,50,100,500], \"max_features\":[2,3,4], \"bootstrap\": [True, False]}","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# instantiate grid search\ngrid_search_2 = GridSearchCV(rfr, param_grid_2, cv=5, scoring=\"neg_mean_squared_error\", return_train_score=True)","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the training data\ngrid_search_2.fit(X_train_prepared_2, y_train)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show the best score\nnp.sqrt(-grid_search.best_score_)","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show the best parameters\ngrid_search_2.best_estimator_","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show results for each iteration\ncvres = grid_search_2.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model 5: Random Forest Regressor","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# instantiate model\nrfr_2 = grid_search_2.best_estimator_\nrfr_2","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test on a few instances from training data\nsome_data = X_train.iloc[:10]\nsome_labels = y_train.iloc[:10]\nsome_data_prepared = full_pipeline_2.transform(some_data)\nprint(\"Predictions:\", rfr_2.predict(some_data_prepared))\nprint(\"Labels:\", list(some_labels))","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict using training data\nrfr_pred_4 = rfr_2.predict(X_tr_testing_2)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use function to show results\ndisplay_evaluation(y_train, rfr_pred_4)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Dummy Regressor\n> The dummy regressor serves as an indication and comparison for model performance.","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# instantiate dummy regressor\n# predicts the mean for each instance\ndummy = DummyRegressor(strategy=\"mean\")","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the training set\ndummy.fit(X_train_prepared_2, y_train)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict using dummy regressor\ndummy_pred = dummy.predict(X_train_prepared_2)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# use function to show results\ndisplay_evaluation(y_train, dummy_pred)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### Overview:\n>> ####  Removing the categorical features even slightly improved the score.\n>> * The RMSE with all features was approximately 2551.\n>> * The RMSE with only the numerical features was approximately 2520.\n>> * The model is substantially better than the dummy regressor.","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"markdown","source":"# 5. Evaluating the Test Set","metadata":{}},{"cell_type":"code","source":"# separate test set predictors and labels\nX_test = test_set.drop(\"num_subscribers\", axis=1)\ny_test = test_set[\"num_subscribers\"].copy()","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_model = grid_search_2.best_estimator_\nfinal_model","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform test set\nX_test_prep = full_pipeline_2.transform(X_test)","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict test set\nfinal_predictions = final_model.predict(X_test_prep)","metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate predictions\ndisplay_evaluation(y_test, final_predictions)","metadata":{"pycharm":{"name":"#%%\n"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> #### Resources:\n> 1. Udemy Courses Dataset <a href=\"https://www.kaggle.com/andrewmvd/udemy-courses\"\n> title=\"Kaggle\">link</a>\n> 2. Regression Evaluation Metrics Article <a href=\"https://medium.com/analytics-vidhya/mae-mse-rmse\n> -coefficient-of-determination-adjusted-r-squared-which-metric-is-better-cd0326a5697e\" title=\"medium\">link</a>\n> 3. Random Forest Article <a href=\"https://towardsdatascience.com/an-implementation-and-\n> explanation-of-the-random-forest-in-python-77bf308a9b76\" title=\"towardsdatascience\">link</a>","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"markdown","source":"### Any feedback, suggestions, questions? Leave a comment below!\n### Upvote if you liked this notebook, learned something new or found it useful!","metadata":{"pycharm":{"name":"#%% md\n"}}}]}