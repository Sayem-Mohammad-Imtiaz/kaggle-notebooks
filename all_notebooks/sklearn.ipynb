{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Sklearn end to end workflow,\n #1. Getting the data ready\n #2. Choose the right estimator/algorithm for our problems\n #3. Fit the model/algorithm and use it to take predictions on data\n #4. Evaluating a model\n #5. Improve a model\n #6. Save and load a trained model"},{"metadata":{},"cell_type":"markdown","source":"# 1. Getting our data ready to be used with machine learning \n    Three main things we have to doL\n        1. Split the data into features and labels (usually 'x' & 'y')\n        2. Filling (called imputing) or disregarding missing values\n        3. Converting non-numerical values to numerical values (also called feature encoding)"},{"metadata":{},"cell_type":"markdown","source":"### 1.1 Make sure it is all numerical"},{"metadata":{"trusted":true},"cell_type":"code","source":"car_sales = pd.read_csv('../input/scikitconf/car-sales-extended.csv')\ncar_sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car_sales_missinging = pd.read_csv('../input/scikitconf/car-sales-extended-missing-data.csv')\ncar_sales_missing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split data into x,y\nX = car_sales.drop('Price',axis=1)\ny = car_sales['Price']\n\n#Split into training and test\n\nX_train, X_test, y_train, y_train = train_test_split(X,y,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build machine learning model\nfrom sklearn.ensemble import RandomForestRegressor\n\nmodel = RandomForestRegressor()\nmodel.fit(X_train,y_train)\nmodel.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One Hot Encoding helps transform the categorital features to numbers\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\ncategorical_features = ['Make','Colour','Doors']\none_hot = OneHotEncoder()\ntransformer = ColumnTransformer([(\"one_hot\",one_hot,categorical_features)],remainder=\"passthrough\")\n\ntransformed_X = transformer.fit_transform(X)\ntransformed_X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(transformed_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummies = pd.get_dummies(car_sales[['Make','Colour','Doors']])\ndummies","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model\n\nnp.random.seed(42)\nX_train, X_test, y_train, y_test = train_test_split(transformed_X,y, test_size=0.2)\nmodel.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#What if there were missing values?\n   # 1. Fill them with some values(know as imputation).\n   # 2. Remove the samples with mssing data altogether.\n    \ncar_sales_missing.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create X and Y\nX = car_sales_missing.drop('Price',axis=1)\ny = car_sales_missing['Price']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Option 1: Fill missing data with Pandas\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fill the 'Make' Column\n\ncar_sales_missing['Make'].fillna('missing',inplace=True)\n\n# Fill the 'Colour' column\n\ncar_sales_missing['Colour'].fillna('missing',inplace=True)\n\n#Fill the 'Odometer' column\ncar_sales_missing['Odometer (KM)'].fillna(car_sales_missing['Odometer (KM)'].mean(),inplace=True)\n\n#Fill the door column\n\ncar_sales_missing['Doors'].fillna(4,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check out dataframe after imputation\ncar_sales_missing.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop rows missing pricing values\ncar_sales_missing.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(car_sales_missing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = car_sales_missing.drop('Price',axis=1)\ny = car_sales_missing['Price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\ncategorical_features = ['Make','Colour','Doors']\none_hot = OneHotEncoder()\ntransformer = ColumnTransformer([(\"one_hot\",one_hot,categorical_features)],remainder=\"passthrough\")\n\ntransformed_X = transformer.fit_transform(car_sales_missing)\ntransformed_X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Option 2: Fill missing values with Scikit learn\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"car_sales_missing = pd.read_csv('../input/scikitconf/car-sales-extended-missing-data.csv')\ncar_sales_missing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car_sales_missing.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop the rows with no labels\ncar_sales_missing.dropna(subset=['Price'],inplace=True)\ncar_sales_missing.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split into X & Y\nX = car_sales_missing.drop('Price',axis=1)\ny = car_sales_missing['Price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\n\n#Fill categorical values with missing & Numerical values with mean\n\ncat_imputer = SimpleImputer(strategy = 'constant',fill_value = ',missing')\ndoor_imputer = SimpleImputer(strategy='constant',fill_value=4)\nnum_imputer = SimpleImputer(strategy='mean')\n\n#Define columns\ncat_features = ['Make','Colour']\ndoor_features = ['Doors']\nnum_features = ['Odometer (KM)']\n\n#Create an imputer (something that fills missing data)\n\nimputer = ColumnTransformer([\n    ('cat_imputer',cat_imputer,cat_features),\n    ('door_imputer',door_imputer,door_features),\n    ('num_imputer', num_imputer,num_features)\n])\n\n# Transform the data\n\nfilled_X = imputer.fit_transform(X)\nfilled_X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car_sales_filled = pd.DataFrame(filled_X,columns=['Make','Colour','Doors','Odometer (KM)'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"car_sales_filled.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\ncategorical_features = ['Make','Colour','Doors']\none_hot = OneHotEncoder()\ntransformer = ColumnTransformer([(\"one_hot\",one_hot,categorical_features)],remainder=\"passthrough\")\n\ntransformed_X = transformer.fit_transform(car_sales_filled)\ntransformed_X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Use filled data fit the model\n\nnp.random.seed(42)\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(transformed_X,y, test_size = 0.2)\n\nmodel = RandomForestRegressor(n_estimators=100)\nmodel.fit(X_train,y_train)\nmodel.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Choosing the right estimator/algorithm for problem\n\n    Scikit-learn uses estimartor as another term for machine  learning model or algorithm\n    * Classification - prediction whether a sample is one or another\n    * Regression - predicting a number\n    \n    Step 1 - check the Scikit-Learn machine learning map..."},{"metadata":{},"cell_type":"markdown","source":"### 2.1 Picking a machine learning model for a regression model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import load_boston\nboston = load_boston()\nboston;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boston_df = pd.DataFrame(boston['data'],columns = boston['feature_names'])\nboston_df['target'] = pd.Series(boston['target'])\nboston_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's try the Ridge regression model\n\nfrom sklearn.linear_model import Ridge\n\n#Setup random seed\nnp.random.seed(42)\n\n#Create Data\nX = boston_df.drop('target',axis=1)\ny= boston_df['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n\n#Instantiate Ridge Model\n\nmodel = Ridge()\nmodel.fit(X_train,y_train)\n\n#Check the score of the Ridge model on test data\nmodel.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How to imporve the score\n# What if Ridge was not working?"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nnp.random.seed(42)\n\nX= boston_df.drop('target',axis=1)\ny = boston_df['target']\n\nX_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nrf = RandomForestRegressor(n_estimators=100)\nrf.fit(X_train,y_train)\n\nrf.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check the Ridge model again\n\nmodel.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2 Choosing and estimator for a classification problem"},{"metadata":{"trusted":true},"cell_type":"code","source":"heart_disease = pd.read_csv('../input/scikitconf/heart-disease.csv')\nheart_disease.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Consulting the map and it shows to try LinearSVC"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the LinearSVC estimator class\nfrom sklearn.svm import LinearSVC\n\n#Setup random seed\nnp.random.seed(42)\n\n#Make the data\nX = heart_disease.drop('target',axis=1)\ny = heart_disease['target']\n\n#Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n#Instantiate LinearSVC\n\nclf = LinearSVC(max_iter=100000)\nclf.fit(X_train,y_train)\n\n#Evaluate the LienarSVC\n\nclf.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the RandomForestClassifier estimator class\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Setup random seed\nnp.random.seed(42)\n\n#Make the data\nX = heart_disease.drop('target',axis=1)\ny = heart_disease['target']\n\n#Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n#Instantiate Random Forest Classifier\n\nrfc = RandomForestClassifier(n_estimators=100)\n\n#Fit the model to the data\nrfc.fit(X_train,y_train)\n\n#Evaluate the RandomForestClassifier\n\nrfc.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Fit the model/algorithm on our data and use it to make predictions"},{"metadata":{},"cell_type":"markdown","source":"###      3.1 Fitting the model to the data\n\nDifferent name for:\n\n* 'X' = features, features variables, data\n\n* 'y' = labels, targets, target variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the RandomForestClassifier estimator class\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Setup random seed\nnp.random.seed(42)\n\n#Make the data\nX = heart_disease.drop('target',axis=1)\ny = heart_disease['target']\n\n#Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n#Instantiate Random Forest Classifier\n\nrfc = RandomForestClassifier(n_estimators=100)\n\n#Fit the model to the data\nrfc.fit(X_train,y_train)\n\n#Evaluate the Random Forest Classifier (use the patterns the model has learned)\n\nrfc.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2 Make predictions using a machine learning model\n\n    2 ways to make predictions:\n        1. predict()\n        2. predict_proba()\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use a trained model to predictions\n# Compare predictions to true labels to evaluate the model (3 ways to evaluate the result)\n\ny_preds = clf.predict(X_test)\n\nnp.mean(y_preds==y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Make predictions with predict_proba()\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict_proba() returns probabilities of a classificaiton label\n\nrfc.predict_proba(X_test[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc.predict(X_test[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heart_disease['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### 'predict()' can be also be used for regression model."},{"metadata":{"trusted":true},"cell_type":"code","source":"len(boston_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nnp.random.seed(42)\n\n#Create the data\n\nX = boston_df.drop('target', axis=1)\n\ny = boston_df['target']\n\n#Split the data\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n\n#Instantiate and fit model\nrfr = RandomForestRegressor()\nrfr.fit(X_train, y_train)\n\n#Make predictions\ny_preds = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_preds[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(y_test[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Compare the predictions to the truth\n\nfrom sklearn.metrics import mean_absolute_error\nmean_absolute_error(y_test,y_preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Evaluating a machine learning model\n\nThree ways to evaluate Scikit-Learn models/estimators:\n1. Estimator 'score method\n2. The 'scoring' parameter\n3. Problem-specific metric functions.\n\n\n### 4.1 Evaluate a model with the score method\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nnp.random.seed(42)\n\nX = heart_disease.drop('target',axis=1)\ny = heart_disease['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n\nrfc = RandomForestClassifier()\nrfc.fit(X_train,y_train)\n\n#Random Classifier use mean accuracy to measure\nrfc.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### let's do the same but for the regression\nfrom sklearn.ensemble import RandomForestRegressor\n\nnp.random.seed(42)\n\n#Create the data\n\nX = boston_df.drop('target', axis=1)\n\ny = boston_df['target']\n\n#Split the data\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n\n#Instantiate and fit model\nrfr = RandomForestRegressor()\nrfr.fit(X_train, y_train)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Score funtion is different in every model. Regressor use coeffication determanation\n\nrfr.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### 4.2 Evaluating a model using the scoring parameter\n\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nnp.random.seed(42)\n\nX = heart_disease.drop('target', axis=1)\ny = heart_disease['target']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nclf = RandomForestClassifier(n_estimators=100)\n\nclf.fit(X_train, y_train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(clf,X,y,cv=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)\n\n#Single training and test split score\nclf_single_score = clf.score(X_test,y_test)\n\n#Take the mean of 5-fold cv score\nclf_cross_val_score = np.mean(cross_val_score(clf,X,y,cv=5))\n\n#compare the two\n\nclf_single_score,  clf_cross_val_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Default scoring parameter of classifier = mean accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scoring parameter set to None by default\ncross_val_score(clf,X,y,cv=5,scoring=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2.1 Classification model evaluation metrics\n\n1. Accuracy\n2. Area under ROC curve\n3. Confusion matrix\n4. Classification report\n\n\nAccuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\n\nnp.random.seed(42)\n\nX = heart_disease.drop(\"target\",axis=1)\ny = heart_disease['target']\n\nclf = RandomForestClassifier()\ncross_val_score = cross_val_score(clf,X,y,cv=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(cross_val_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Heart Disease Classifier Cross-Validaiton Accuracy: {np.mean(cross_val_score)*100:.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Area under the receiver operating characteristic curve(AUC/ROC)\n\n*Area under curve (AUC)\n\n\n*ROC curve\n\n\nROC curvers are comparision of a model's true postive rate(tpr) veruss a models false positive rate (fpr).\n\n*True positive = model predicts 1 when truth is 1\n\n*False positive = model predicts 1 when truth is 0\n\n*True negative = model predicts 0 when truth is 0\n\n*False negative = model predicts 0 when truth is 1\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create X_test... etc\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\n\n#Fit the classifier\nclf.fit(X_train,y_train)\n\n#Mame predictions with probabilities\ny_probs = clf.predict_proba(X_test)\n\ny_probs[:10], len(y_probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_probs_positive = y_probs[:,1]\n\ny_probs_positive[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate fpr, tpr and thresholds\n\nfpr, tpr, thresholds = roc_curve(y_test,y_probs_positive)\n\n#check the false positive rates\n\nfpr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create a function for plotting ROC curves\n\nimport matplotlib.pyplot as plt\n\ndef plot_roc_curve(fpr,tpr):\n    \"\"\"\n    Plots a ROC curve given the false positive rate (fpr)\n    and true positive rate (tpr) of a model.\n    \"\"\"\n    # Plot roc curve\n    plt.plot(fpr,tpr,color='orange',label = 'ROC')\n    #Plot line with no predictive power baseline\n    \n    plt.plot([0,1],[0,1],color = 'darkblue',linestyle = '--',label = 'Guessing')\n    \n    plt.xlabel('False Positive rate (fpr)')\n    plt.ylabel('True Positive rate (tpr)')\n    plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n    plt.legend()\n    plt.show()\n\nplot_roc_curve(fpr,tpr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\nroc_auc_score(y_test, y_probs_positive)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot perfect ROC curve and AUC score \nfpr, tpr, thresholds = roc_curve(y_test,y_test)\nplot_roc_curve(fpr,tpr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perfect AUC score\n\nroc_auc_score(y_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Confusion Matrix\n\nA confusion matrix is a quick way to compare the labels a model predicts and the actual label it was supposed to predict.\n\nIn essence,giving you an idea of where the model is getting confused.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ny_preds = clf.predict(X_test)\n\nconfusion_matrix(y_test,y_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize confusion matrix with pd.crosstab()\n\npd.crosstab(y_test,\n           y_preds,\n           rownames = ['Actural Labels'],\n           colnames=['Predicted Labels'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Make our confusion matrix more visual with Seaborn heatmao()\nimport seaborn as sns\n\n#Set the font scale\nsns.set(font_scale = 1.5)\n\n#Create a confusion matrix\n\nconf_mat = confusion_matrix(y_test,y_preds)\n\n#plot it using seaborn\n\nsns.heatmap(conf_mat)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_conf_mat(conf_mat):\n    \"\"\"\n    Plt a confusion matrix using seaborn's heatmap()\n    \n    \"\"\"\n    fig, ax = plt.subplots(figsize=(3,3))\n    ax = sns.heatmap(conf_mat,\n                    annot=True,#Annotrate the boxes\n                    cbar = False)\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label');\n    \nplot_conf_mat(conf_mat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\n\nplot_confusion_matrix(clf,X,y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test,y_preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Where precision and recall become valuable\n\ndisease_true = np.zeros(10000)\ndisease_true[0] = 1#Only one positive\n\ndisease_preds = np.zeros(10000) #model predicts every case as 0\n\npd.DataFrame(classification_report(disease_true,disease_preds,output_dict=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"To summarize classification metrics:\n* Accuracy is a good measure to start with if all classes are balanced(e.g. same amount of samples which are labelled with 0 or 1)\n\n* Precision and Recall become more import when classes are imbalanced.\n* If false positive predictions are worse than false negatives, aim for higher precision.\n* F1-score is a combination of precision and recall."},{"metadata":{},"cell_type":"markdown","source":"###4.2.2 Regression model evluation metrics\n\n* Model evaluation https://scikit-learn.org/stable/modules/model_evaluation.html\n\n1. R^2 or called Coefficient of determination.\n2. Mean absolute error (MAE)\n3. Mean squared error (MSE)\n\n**R^2**\n\nWhat R-squared does: Compares your models prediction to the mean of the targets. Values can range from negative infinity (a very poor model) to 1. For example, if all your model does is predict the mean of the targets, it's R^2 value would be 0. And if your model perfectly predicts a range of numbers it's R^2 value would be 1. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nnp.random.seed(42)\n\nx = boston_df.drop(\"target\",axis=1)\ny = boston_df['target']\n\nX_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n\nmodel = RandomForestRegressor(n_estimators=100)\nmodel.fit(X_train,y_train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\n\n#Fill an array with y_test mean\n\ny_test_mean = np.full(len(y_test),y_test.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2_score(y_test,y_test_mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2_score(y_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Mean absolute error (MEA)**\n\nMAE is the average of the absolute differences between predictions and actural values. It gives you an idea of how wrong your models predictions are."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mean absolute error\n\nfrom sklearn.metrics import mean_absolute_error\n\ny_preds = model.predict(X_test)\nmae = mean_absolute_error(y_test,y_preds)\nmae","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(data = {\"actural values\":y_test,\n                          \"predicted values\":y_preds})\n\ndf[\"differences\"] = df['predicted values'] - df['actural values']\nmean_absolute_error = df[\"differences\"].abs().mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Mean squared error**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\ny_preds = model.predict(X_test)\nmse = mean_squared_error(y_test,y_preds)\nmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculate MSE by hand\n\nSquared = df['differences']**2\nMean_Squared_Error = Squared.mean()\nMean_Squared_Error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.23 Finally using the scoring parameter\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\n\nnp.random.seed(42)\n\nx = heart_disease.drop('target',axis=1)\ny = heart_disease['target']\n\nclf = RandomForestClassifier(n_estimators=100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)\ncv_acc = cross_val_score(clf, X, y, cv=5,scoring=None)\ncv_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cross_validated accuracy\n\nprint(f'The cross-validate accuracy is: {np.mean(cv_acc)*100:.2f}%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)\ncv_acc = cross_val_score(clf, X, y, cv=5,scoring='accuracy')\nprint(f'The cross-validate accuracy is: {np.mean(cv_acc)*100:.2f}%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Precision\n\ncv_precision = cross_val_score(clf,X,y,cv=5,scoring='precision')\nnp.mean(cv_precision)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recall\n\ncv_recall = cross_val_score(clf,X,y,cv=5, scoring = 'recall')\nnp.mean(cv_recall)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_f1 = cross_val_score(clf,X,y,cv=5,scoring='f1')\nnp.mean(cv_f1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How about our regression model?"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\n\nnp.random.seed(42)\n\nX = boston_df.drop(\"target\", axis=1)\ny = boston_df['target']\n\nmodel = RandomForestRegressor(n_estimators=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)\ncv_r2 = cross_val_score(model,X,y, cv=5,scoring=None)\ncv_r2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)\ncv_r2 = cross_val_score(model,X,y, cv=5,scoring='r2')\ncv_r2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mean absolute error\ncv_mae = cross_val_score(model, X, y, cv = 5, scoring = 'neg_mean_absolute_error')\ncv_mae","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mean squared error\ncv_mse = cross_val_score(model, X,y, cv=5,scoring = 'neg_mean_squared_error')\nnp.mean(cv_mse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}