{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"cd /kaggle/input/pokemon-images-and-types/images/","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dir = \"images/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom PIL import Image\nimport imageio","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_pokemon():\n    data = []\n    for i in os.listdir(dir):\n        \n        img = imageio.imread(dir + i)\n        img = Image.fromarray(img)\n        img.load()\n        \n        if(len(img.split()) == 4):\n        \n        # replace alpha channel with white color\n            im = Image.new('RGB', img.size, (255, 255, 255))\n            im.paste(img, mask=img.split()[3])\n           \n        \n        else:\n            im = img\n        pixels = tf.keras.preprocessing.image.img_to_array(im)\n        pixels = pixels.astype(\"float32\")\n        pixels /= 255.\n        data.append(pixels)\n    return np.stack(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = load_pokemon()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,15))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.axis(\"off\")\n    plt.imshow(dataset[i])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def discriminator2(inp_shape = (120,120,3)):\n    tf.keras.backend.clear_session()\n    base_model = tf.keras.applications.MobileNetV2(input_shape = inp_shape, include_top = False, weights=\"imagenet\")\n    base_model.trainable = True\n    glob_avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n    pred_layer = tf.keras.layers.Dense(1, \"sigmoid\")\n    model = tf.keras.models.Sequential([base_model,\n            glob_avg_pool,\n            pred_layer])\n    model.compile(optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.5), loss = \"binary_crossentropy\", metrics = ['acc'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def discriminator(inp_shape = (120,120,3)):\n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Conv2D(128, (3,3), strides = (2,2), padding=\"same\", input_shape = inp_shape),\n        tf.keras.layers.LeakyReLU(0.2),\n        \n        tf.keras.layers.Conv2D(128, (3,3), padding=\"same\",  strides = (2,2)),\n        tf.keras.layers.LeakyReLU(0.2),\n        \n        tf.keras.layers.Conv2D(64, (3,3), padding=\"same\",  strides = (2,2)),\n        tf.keras.layers.LeakyReLU(0.2),\n        \n        tf.keras.layers.Conv2D(64, (3,3), padding = \"same\", strides = (2,2)),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Flatten(),\n        \n        tf.keras.layers.Dense(1, activation = \"sigmoid\")\n    ])\n    model.compile(optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.5), loss = \"binary_crossentropy\", metrics = ['acc'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_model = discriminator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd /kaggle/working","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.utils.plot_model(d_model, show_shapes = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_fake_samples(n_samples):\n    rand_samp = np.random.randn(120 * 120 * 3 * n_samples)\n    rand_samp = -1 + rand_samp * 2\n    X = rand_samp.reshape(n_samples, 120, 120, 3)\n    y = np.zeros(shape = (n_samples,1))\n    return X,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_discriminator(model, dataset, num_iterations = 20, n_batch = 128):\n    half_batch = int(n_batch/2)\n    for i in range(num_iterations):\n        X_real, y_real = generate_real_samples(dataset, half_batch)\n       \n        _, real_acc = model.train_on_batch(X_real, y_real)\n        \n        X_fake, y_fake = generate_fake_samples(half_batch)\n      \n        _, fake_acc = model.train_on_batch(X_fake, y_fake)\n        print(\"Batch {}: Real acc: {} and Fake acc: {}\".format(i+1, real_acc*100, fake_acc* 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_discriminator(d_model, dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_real, y_real = generate_real_samples(dataset,800)\nX_fake, y_fake = generate_fake_samples(800)\nX,y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = d_model.fit(X,y, epochs = 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generator(latent_dim = 100):\n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Dense(128 * 15 * 15, input_dim = latent_dim),\n        tf.keras.layers.LeakyReLU(0.2),\n        tf.keras.layers.Reshape((15,15,128)),\n        \n        # 30 * 30\n        tf.keras.layers.Conv2DTranspose(128, (3,3), strides = (2,2), padding = \"same\"),\n        tf.keras.layers.LeakyReLU(0.2),\n        \n        #60 * 60\n        tf.keras.layers.Conv2DTranspose(128, (3,3), strides = (2,2), padding = \"same\"),\n        tf.keras.layers.LeakyReLU(0.2),\n        \n        # 120 * 120\n        tf.keras.layers.Conv2DTranspose(64, (3,3), strides = (2,2), padding = \"same\"),\n        tf.keras.layers.LeakyReLU(0.2),\n        \n        tf.keras.layers.Conv2D(3, (3,3), padding = \"same\", activation = \"sigmoid\")\n        \n    ])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g_model = generator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_real_samples(dataset, n_size = 128):\n    ind = np.random.randint(0, dataset.shape[0], n_size)\n    data = dataset[ind]\n    y = np.ones((n_size, 1))\n    return data, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.imshow(generate_fake_examples(g_model)[0][3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_latent_space(n_size = 128, latent_dim = 100):\n    points = np.random.randn(n_size * latent_dim)\n    points = points.reshape((n_size, latent_dim))\n    return points","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_fake_examples(g_model, n_size = 128, latent_dim = 100):\n    latent_space = generate_latent_space(n_size, latent_dim)\n    preds = g_model.predict(latent_space)\n    y = np.zeros((n_size , 1))\n    return preds, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gan(g_model, d_model):\n    d_model.trainable = False\n    model = tf.keras.models.Sequential([\n        g_model,\n        d_model\n    ])\n    model.compile(optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.5), loss = \"binary_crossentropy\")\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gan_model = gan(g_model, d_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gan_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_samples(data):\n    plt.figure(figsize = (15,15))\n    for i in range(7*7):\n        plt.subplot(7,7,i+1)\n        plt.axis(\"off\")\n        plt.imshow(data[i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def summarize_performance(g_model, dataset, n_size = 128):\n    X_real, y_real = generate_real_samples(dataset)\n    _,accr = d_model.evaluate(X_real, y_real)\n    \n    X_fake, y_fake = generate_fake_examples(g_model)\n    _, accf = d_model.evaluate(X_fake, y_fake)\n    \n    print(\"Real samples Acc: {}\".format(accr*100))\n    print(\"Fake samples Acc: {}\".format(accf*100))\n    \n    plot_samples(X_fake)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd /kaggle/working","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_history(d1_hist, d2_hist, g_hist, a1_hist, a2_hist):\n\t# plot loss\n\tplt.subplot(2, 1, 1)\n\tplt.plot(d1_hist, label='d-real')\n\tplt.plot(d2_hist, label='d-fake')\n\tplt.plot(g_hist, label='gen')\n\tplt.legend()\n\t# plot discriminator accuracy\n\tplt.subplot(2, 1, 2)\n\tplt.plot(a1_hist, label='acc-real')\n\tplt.plot(a2_hist, label='acc-fake')\n\tplt.legend()\n\t# save plot to file\n\tplt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(g_model, d_model, gan_model, dataset,epochs = 1500, latent_dim = 100, batch_size = 128):\n    half_batch = int(batch_size/2)\n    batch_per_epoch = int(len(dataset)/batch_size)\n    d1_hist, d2_hist, g_hist, a1_hist, a2_hist = list(), list(), list(), list(), list()\n    for i in range(epochs):\n        for j in range(batch_per_epoch):\n            X_real, y_real = generate_real_samples(dataset, half_batch)\n            d_loss1, d_acc1 = d_model.train_on_batch(X_real, y_real)\n            \n            X_fake, y_fake = generate_fake_examples(g_model, half_batch)\n            d_loss2, d_acc2 = d_model.train_on_batch(X_fake, y_fake)\n            \n            X_gan = generate_latent_space()\n            y_gan = np.ones((batch_size, 1))\n            \n            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n            \n            d1_hist.append(d_loss1)\n            d2_hist.append(d_loss2)\n            g_hist.append(g_loss)\n            a1_hist.append(d_acc1)\n            a2_hist.append(d_acc2)\n            \n            if((j+1) % 5 == 0):\n                print('>%d, d1=%.3f, d2=%.3f g=%.3f, a1=%d, a2=%d' %\n                    (i+1, d_loss1, d_loss2, g_loss, int(100*d_acc1), int(100*d_acc2)))\n        \n        if((i+1) % 50 == 0):\n            summarize_performance(g_model, dataset)\n    plot_history(d1_hist, d2_hist, g_hist, a1_hist, a2_hist)\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trained for 1500 epochs\ntrain(g_model, d_model, gan_model, dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g_model.save(\"pokemon.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Vizualizaing Generated Pokemons ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_input = generate_latent_space(n_size = 49)\npreds = g_model.predict(X_input)\nplot_samples(preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}