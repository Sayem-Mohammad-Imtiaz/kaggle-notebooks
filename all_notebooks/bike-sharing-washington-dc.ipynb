{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data Importing & Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n#importing necessary libraries\nimport pandas as pd\nimport numpy as np\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# to show the figures in the jupyter notebook itself\n%matplotlib inline     ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/bike-sharing-system-washington-dc/train_bikes.csv', parse_dates=['datetime']) # loading the training data\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.tail() # looking at the training data from end","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.plot.scatter(x = 'season', y = 'count') # plotting the counts based on the season","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.plot.scatter(x = 'holiday', y = 'count') # plotting the counts based on the holidays","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.plot.scatter(x = 'workingday', y = 'count') # plotting the counts based on working day","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.plot.scatter(x = 'weather', y = 'count') # plotting the counts based on the weather","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.plot.scatter(x = 'temp', y = 'count') # plotting the counts based on the temparature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.plot.scatter(x = 'atemp', y = 'count') # plotting the counts based on atemp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.plot.scatter(x = 'humidity', y = 'count')# plotting the counts based on humidity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.plot.scatter(x = 'windspeed', y = 'count') # plotting the counts based on windspeed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.plot.scatter(x = 'casual', y = 'count')# plotting the counts based casual user","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info() # observing the data types of the columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Generate descriptive statistics that summarize the central tendency,dispersion and shape of a dataset's distribution**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/bike-sharing-system-washington-dc/test_bikes.csv') # loading the test data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()  #looking at the 1st 5 rows of the test data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.tail() # last 5 rows of the test data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info() # observing the data types of the columns for test data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Generate descriptive statistics that summarize the central tendency,dispersion and shape of a dataset's distribution for test data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**installing the pandas profiling library. It is used for a deeper understanding than the normal Dataframe.describe() method**"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pandas-profiling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_profiling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.profile_report()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"count samples & features: \", train.shape) # printing the number of rows and columns\nprint(\"Are there missing values: \", train.isnull().values.any()) # printing if dataset has any NaN value","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Method for creating the count plot based on hour for a given year"},{"metadata":{"trusted":true},"cell_type":"code","source":" def plot_by_hour(data, year=None, agg='sum'):\n    dd = data\n    if year: dd = dd[ dd.datetime.dt.year == year ]\n    dd.loc[:, ('hour')] = dd.datetime.dt.hour # extracting the hour data if the year in the data is equal to the year passed as argument\n    \n    by_hour = dd.groupby(['hour', 'workingday'])['count'].agg(agg).unstack() # groupby hour and working day\n    return by_hour.plot(kind='bar', ylim=(0, 80000), figsize=(15,5), width=0.9, title=\"Year = {0}\".format(year)) # returning the figure grouped by hour\n\n\nplot_by_hour(train, year=2011) # plotting the count plot based on hour for 2011 \nplot_by_hour(train, year=2012) # plotting the count plot based on hour for 2012","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Method for creating the count plot based on year"},{"metadata":{"trusted":true},"cell_type":"code","source":" def plot_by_year(agg_attr, title):\n    # extracting the required fields\n    dd = train.copy()\n    dd['year'] = train.datetime.dt.year # extratcing the year\n    dd['month'] = train.datetime.dt.month # extratcing the month\n    dd['hour'] = train.datetime.dt.hour # extratcing the hour\n    \n    by_year = dd.groupby([agg_attr, 'year'])['count'].agg('sum').unstack() # groupby year\n    return by_year.plot(kind='bar', figsize=(15,5), width=0.9, title=title) # returning the figure grouped by year\n\n\nplot_by_year('month', \"Rent bikes per month in 2011 and 2012\") # plotting monthly bike rentals based on year\nplot_by_year('hour', \"Rent bikes per hour in 2011 and 2012\") # plotting hourls bike rentals based  on year","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Method to plot a graph for count per hour"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_hours(data, message = ''):\n    dd = data.copy()\n    dd['hour'] = data.datetime.dt.hour # extratcing the hour\n    \n    hours = {}\n    for hour in range(24):\n        hours[hour] = dd[ dd.hour == hour ]['count'].values\n\n    plt.figure(figsize=(20,10))\n    plt.ylabel(\"Count rent\")\n    plt.xlabel(\"Hours\")\n    plt.title(\"count vs hours\\n\" + message)\n    plt.boxplot( [hours[hour] for hour in range(24)] )\n    \n    axis = plt.gca()\n    axis.set_ylim([1, 1100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hours( train[train.datetime.dt.year == 2011], 'year 2011') # box plot for hourly count for the mentioned year\nplot_hours( train[train.datetime.dt.year == 2012], 'year 2012') # box plot for hourly count for the mentioned year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = pd.to_datetime(train[\"datetime\"]) # converting the column to datetime for train dataset\ntrain[\"hour\"] = dt.map(lambda x: x.hour) # adding the hour column for train dataset\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_test = pd.to_datetime(test[\"datetime\"]) # converting the column to datetime for test dataset\ntest[\"hour\"] = dt_test.map(lambda x: x.hour) # adding the hour column for test dataset\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hours( train[train.workingday == 1], 'working day') # plotting hourly count of rented bikes for working days for a given year\nplot_hours( train[train.workingday == 0], 'non working day') # plotting hourly count of rented bikes for non-working days for a given year","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def categorical_to_numeric(x):\n    if 0 <=  x < 6:\n        return 0\n    elif 6 <= x < 13:\n        return 1\n    elif 13 <= x < 19:\n        return 2\n    elif 19 <= x < 24:\n        return 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['hour'] = train['hour'].apply(categorical_to_numeric)# applying the above conversion logic to training data\ntrain.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['hour'] = test['hour'].apply(categorical_to_numeric) # applying the above conversion logic to test data\ntest.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop unnecessary columns\n\ntrain = train.drop(['datetime'], axis=1)\ntest = test.drop(['datetime'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### An Hour bs Count Graph depicting average bike demand based on the hour"},{"metadata":{"trusted":true},"cell_type":"code","source":" figure,axes = plt.subplots(figsize = (10, 5))\nhours = train.groupby([\"hour\"]).agg(\"mean\")[\"count\"]  \nhours.plot(kind=\"line\", ax=axes) \nplt.title('Hours VS Counts')\naxes.set_xlabel('Time in Hours')\naxes.set_ylabel('Average of the Bike Demand')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# count of different temp values\na = train.groupby('temp')[['count']].mean()\na","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# count of different atemp values\na = train.groupby('atemp')[['count']].mean()\na","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Count based on holiday"},{"metadata":{"trusted":true},"cell_type":"code","source":"a = train.groupby('holiday')[['count']].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# method to  select the features. If a feature is not in the blaklist, it gets selected\ndef select_features(data):\n    black_list = ['casual', 'registered', 'count', 'is_test', 'datetime', 'count_log']\n    return [feat for feat in data.columns if feat not in black_list]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model fitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"# a method to show results of various model and their predictions\ndef _simple_modeling(X_train, X_test, y_train, y_test):\n    # sepcifying the model names\n    models = [\n        ('dummy-mean', DummyRegressor(strategy='mean')),\n        ('dummy-median', DummyRegressor(strategy='median')),\n        ('random-forest', RandomForestRegressor(random_state=0)),\n    ]\n    \n    results = []\n\n    for name, model in models:\n        model.fit(X_train, y_train)# fitting the training data to model\n        y_pred = model.predict(X_test) # doing predictions using the model\n        \n        results.append((name, y_test, y_pred)) # creating the list of predictions from various models\n        \n    return results\n\n# a method to return the performance metric of the model used in the above method\ndef simple_modeling(X_train, X_test, y_train, y_test):\n    results = _simple_modeling(X_train, X_test, y_train, y_test) # using the function defined above to caluclate the predictions\n    \n    return [ (r[0], rmsle(r[1], r[2]) ) for r in results] # returning the performance metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\nforest_reg = RandomForestRegressor(n_estimators=100) # instantiating the random Forest Regressor\n\nscore = cross_val_score(forest_reg, train, train, cv=4) # calcuating the cross validation score\nprint (score)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}