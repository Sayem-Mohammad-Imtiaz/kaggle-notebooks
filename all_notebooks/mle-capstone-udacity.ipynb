{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing\nimport seaborn as sns # visualization\nimport matplotlib.pyplot as plt # visualization\nfrom sklearn import preprocessing #normalizing values\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_validate, GridSearchCV #dividing into train and test for cross_validation\nfrom sklearn.multiclass import OneVsRestClassifier #strategy for star multiclass classification\nfrom sklearn.metrics import roc_curve, roc_auc_score, make_scorer, confusion_matrix, accuracy_score, r2_score #scorers\nfrom sklearn.svm import LinearSVC, SVC #ML model\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nimport time","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/booking_com-travel_sample.csv') #import data\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['hotel_facilities'].iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#features considered unecessary\nto_drop = ['address', 'city','country', 'crawl_date', 'hotel_brand', 'hotel_description',  'locality', 'pageurl',\n           'property_id', 'property_name', 'property_type', 'province', 'qts', 'room_type', 'similar_hotel', 'sitename',\n           'site_review_count', 'site_stay_review_rating', 'special_tag', 'uniq_id', 'zone']\n#remove rows without name (unreliable) or explicit facilities (lack information)\ndf_reliable = df.dropna(subset = ['property_name', 'hotel_facilities'], thresh = 2, inplace = True)\n#drop unecessary features and duplicates \ndf_reduced = df.drop(to_drop, axis = 1)\ndf_reduced.drop_duplicates(inplace = True)\n#fill NaN\ndf_reduced['image_count'].fillna(0, inplace = True)\n\n#create dummies for states\ndf_dummies = pd.concat([df_reduced, pd.get_dummies(df_reduced['state'])], axis=1)\ndf_dummies.drop('state', axis = 1, inplace = True) #drop states (attribute was dummied)\ndf_dummies.reset_index(drop = True, inplace = True)\ndf_dummies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#find hotel_facilities keys\ncolumns_facilities = []\nfor row in df_dummies.hotel_facilities:\n    splitten = row.split(sep = '•')\n    columns_facilities.extend([a.split(':', 1)[0]for a in splitten])\ncolumns_facilities = sorted(list(set(columns_facilities)))\n\n#create datafame with such keys\nhotel_facilities_preparation = pd.DataFrame(columns = columns_facilities)\n\n#iterates over all df rows and input number of items in each facilities to facilities_dataframe \nfor row in df_dummies.hotel_facilities:\n    first = row.split(sep = '•')\n    features_columns = [row.split(':', 1)[0] for row in first]\n    second = [row.split(':', 1)[-1] for row in first]\n    third = [row.split(sep = '|') for row in second]\n    lenghts = [len(row) for row in third]\n    \n    to_special_cases = dict(zip(features_columns,third))\n    to_df = dict(zip(features_columns,lenghts))\n    \n    if to_special_cases['Pets'] == ['Pets are not allowed.']:\n        to_df['Pets'] = 0\n\n    if to_special_cases['Internet'] == ['No internet access available.']:\n        to_df['Internet'] = 0\n\n    try:\n        if to_special_cases['Parking'] == ['No parking available.']:\n            to_df['Parking'] = 0\n    except:\n        None\n    \n    hotel_facilities_preparation = hotel_facilities_preparation.append(to_df, ignore_index=True)\n    \n    \nhotel_facilities_preparation.fillna(0, inplace = True)\n\n#concat facilities dataframe to df_dummies\ndf_final = pd.concat([df_dummies, hotel_facilities_preparation], axis = 1)\ndf_final.drop('hotel_facilities', axis = 1, inplace = True) #drop hotel_facilities\ndf_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_facilities_preparation.columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create df hotel_star_rating and remove rows with NaN\ndf_star_rating = df_final.drop('site_review_rating', axis = 1)\ndf_star_rating.dropna(subset = ['hotel_star_rating'], inplace = True)\ndf_star_rating.reset_index(drop = True, inplace = True)\n\n#create df site_review_rating and remove rows with NaN\ndf_review_rating = df_final.drop('hotel_star_rating', axis = 1)\ndf_review_rating.dropna(subset = ['site_review_rating'], inplace = True)\ndf_review_rating.reset_index(drop = True, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_review_rating.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# organizing hotel_star_rating values\ndf_star_rating['hotel_star_rating'] = df_star_rating['hotel_star_rating'].map({'1-star hotel': 1,\n                                                                               '2-star hotel': 2,\n                                                                               '3-star hotel': 3,\n                                                                               '4-star hotel': 4,\n                                                                               '5-star hotel': 5,\n                                                                               '1 stars': 1,\n                                                                               '2 stars': 2,\n                                                                               '3 stars': 3,\n                                                                               '4 stars': 4,\n                                                                               '5 stars': 5})\n# scale all columns to go between 0 and 1\ndf_star_rating.iloc[:,1:] = preprocessing.MinMaxScaler().fit_transform(df_star_rating.iloc[:,1:])\ndf_review_rating.iloc[:,:] = preprocessing.MinMaxScaler().fit_transform(df_review_rating)\n\n#reorder columns of df_review_rating so site_review_rating comes first\ncolumn_names_list = df_review_rating.columns.tolist()\ncolumn_names_list.remove('site_review_rating')\ncolumn_names_list.insert(0, 'site_review_rating')\ndf_review_rating = df_review_rating[column_names_list]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label=np.arange(0,10,1)\nvalues=df_review_rating.groupby(pd.cut(df_review_rating['site_review_rating']*10, np.arange(0,11,1))).count().iloc[:,0].values\nplt.bar(label,values)\nplt.xticks(np.arange(0, 10, step=1), rotation=90)\nplt.title('Number of hotels for each customer score')\nplt.ylim([0, 590])\nfor i, v in enumerate(values):\n    plt.text(i-0.4, v+10, str(round(v,3)), color='black', rotation = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_star_rating.groupby('hotel_star_rating').count().iloc[:,1].values\n\nlabel=['1 star', '2 stars', '3 stars', '4 stars', '5 stars']\nvalues=df_star_rating.groupby('hotel_star_rating').count().iloc[:,1].values\nplt.bar(label,values)\nplt.xticks(rotation=90)\nplt.title('Number of hotels for each star rating')\nfor i, v in enumerate(values):\n    plt.text(i-0.2, v-50, str(round(v,3)), color='white', rotation = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_star_rating heatmap with states\n\ndf_star_rating_heatmap = df_star_rating.copy()\n\nfig, ax = plt.subplots(figsize=(20,20)) #figsize in inches\nplt.rcParams.update({'font.size': 12}) #font size\nplt.yticks(va=\"center\")\nsns.heatmap(df_star_rating_heatmap.iloc[:,:33].corr().iloc[0:1,:], square = True, ax=ax, annot = True, fmt = '.2f',\n            vmin = -1, vmax = 1,\n            cmap = sns.diverging_palette(220, 20, n = 10), cbar_kws = dict(use_gridspec=False,location=\"top\", shrink = 0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_star_rating heatmap with hotel_facilities\n\nfig, ax = plt.subplots(figsize=(20,20)) #figsize in inches\nplt.rcParams.update({'font.size': 12}) #font size\nplt.yticks(va=\"center\")\nsns.heatmap(df_star_rating_heatmap.drop(df_star_rating_heatmap.columns[5:33], axis = 1).corr().iloc[0:1,:],\n            square = True, ax=ax, annot = True, fmt = '.2f', vmin = -1, vmax = 1,\n            cmap = sns.diverging_palette(220, 20, n = 10), cbar_kws = dict(use_gridspec=False,location=\"top\", shrink = 0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_review_rating heatmap with states\n\nfig, ax = plt.subplots(figsize=(20,20)) #figsize in inches\nplt.rcParams.update({'font.size': 12}) #font size\nplt.yticks(va=\"center\")\nsns.heatmap(df_review_rating.iloc[:,:33].corr().iloc[0:1,:], square = True, ax=ax, annot = True, fmt = '.2f', vmin = -1, vmax = 1,\n            cmap = sns.diverging_palette(220, 20, n = 10), cbar_kws = dict(use_gridspec=False,location=\"top\", shrink = 0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_review_rating heatmap with hotel_facilities\n\nfig, ax = plt.subplots(figsize=(20,20)) #figsize in inches\nplt.rcParams.update({'font.size': 12}) #font size\nplt.yticks(va=\"center\")\nsns.heatmap(df_review_rating.drop(df_review_rating.columns[5:33], axis = 1).corr().iloc[0:1,:], square = True, ax=ax,\n            annot = True, fmt = '.2f', vmin = -1, vmax = 1,\n            cmap = sns.diverging_palette(220, 20, n = 10), cbar_kws = dict(use_gridspec=False,location=\"top\", shrink = 0.5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Star_rating modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating training and testing sets\n\nX_star = df_star_rating.iloc[:,1:]\ny_star = df_star_rating['hotel_star_rating']\n\n#dividing into train and test - sss to star rating\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=0)\nsss.get_n_splits(X_star, y_star)\n\nfor train_index, test_index in sss.split(X_star, y_star):\n    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_star_train, X_star_test = X_star.iloc[train_index], X_star.iloc[test_index]\n    y_star_train, y_star_test = y_star[train_index], y_star[test_index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Baseline / Benchmark model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#selecting random values for each hotel using weights \nfrom numpy.random import choice\n\nacc = 0\niterations = 100\nweight = np.array(df_star_rating.groupby(['hotel_star_rating'])['hotel_star_rating'].count()/df_star_rating['hotel_star_rating'].count())\n\nfor i in range(iterations):\n \n    #create random weighted answers\n    random_results = []\n    for i in range(len(y_star_test)):\n        random_results.append(choice(sorted(df_star_rating['hotel_star_rating'].unique()), 1, p = weight)[0])\n    \n    #check correct values\n    acc += sum(list(random_results == y_star_test))/len(y_star_test)\n    \nacc/iterations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = 0\niterations = 100\n\nfor i in range(iterations):\n    \n    model = DecisionTreeClassifier(max_depth = 1, max_features = 1)\n    model.fit(X_star_train, y_star_train)\n    predictions = model.predict(X_star_test)\n    acc += accuracy_score(y_star_test, predictions)\n\nacc/iterations","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#gridsearch Decision Trees - could do better -> ensamble methods may improve\n\nestimator = DecisionTreeClassifier()\nparameters = {'max_depth': [30, 50, 70, 100], 'min_samples_split': [2, 3, 4, 5]}\nscorer = make_scorer(accuracy_score) #this metric will be used for GridSearch to find best models/parameters. Promissing results will be testes with other metrics\n\nclf = GridSearchCV(estimator = estimator, scoring = scorer, param_grid  = parameters, cv = 10, return_train_score=True)\nclf.fit(X = X_star_train,y = y_star_train)\nclf.cv_results_ ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gridsearch Random Forest - best\n\nestimator = RandomForestClassifier()\nparameters = {'max_depth': [10, 30, 50, 70], 'n_estimators': [20, 50, 100]}\nscorer = make_scorer(accuracy_score) #this metric will be used for GridSearch to find best models/parameters. Promissing results will be testes with other metrics\n\nclf = GridSearchCV(estimator = estimator, scoring = scorer, param_grid  = parameters, cv = 10, return_train_score=True)\nclf.fit(X = X_star_train,y = y_star_train)\nclf.cv_results_ ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gridsearch AdaBoost - slower with same results as RandomForest\n\nestimator = AdaBoostClassifier()\nparameters = {'base_estimator': [DecisionTreeClassifier(max_depth=10)], 'learning_rate': [0.3, 0.5, 0.7, 1], 'n_estimators': [20, 50, 100]}\nscorer = make_scorer(accuracy_score) #this metric will be used for GridSearch to find best models/parameters. Promissing results will be testes with other metrics\n\nclf = GridSearchCV(estimator = estimator, scoring = scorer, param_grid  = parameters, cv = 10, return_train_score=True)\nclf.fit(X = X_star_train,y = y_star_train)\nclf.cv_results_ ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.best_params_ ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Otimization of Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"#consfusion matrix\niterations = 10\ncm_train = [0] #creates confusion matrix instance for train\ncm_test = [0] #creates confusion matrix instance for test\n\ntrain_acc = 0\ntest_acc = 0\n\nX_star = df_star_rating.iloc[:,1:]\ny_star = df_star_rating['hotel_star_rating']\n\nstart = time.time() \nfor n in range(iterations):\n\n    #dividing into train and test - sss to star rating\n    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=n)\n    sss.get_n_splits(X_star, y_star)\n\n    for train_index, test_index in sss.split(X_star, y_star):\n        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n        X_star_train, X_star_test = X_star.iloc[train_index], X_star.iloc[test_index]\n        y_star_train, y_star_test = y_star[train_index], y_star[test_index]\n    \n    model = RandomForestClassifier(max_depth = 30, n_estimators = 100)\n    model.fit(X = X_star_train, y = y_star_train)\n    \n    predict_train = model.predict(X_star_train)    \n    cm_train += confusion_matrix(y_star_train, predict_train)\n\n    predict_test = model.predict(X_star_test)\n    cm_test += confusion_matrix(y_star_test, predict_test)\n    \n    train_acc += accuracy_score(y_star_train, predict_train)\n    test_acc += accuracy_score(y_star_test, predict_test)\n\ncm_train = cm_train/iterations #takes the mean\ntotal_train = [i.sum() for i in cm_train]\nacc_train = [cm_train[i][i]/total_train[i] for i in range(5)]\nscore_train = pd.DataFrame(0, columns = np.append(np.sort(y_star.unique()),['Acc']), index = np.sort(y_star.unique()))\nscore_train.iloc[:,:5] = cm_train\nscore_train.iloc[:,5:] = acc_train\n\ncm_test = cm_test/iterations # takes the mean\ntotal_test = [i.sum() for i in cm_test]\nacc_test = [cm_test[i][i]/total_test[i] for i in range(5)]\nscore_test = pd.DataFrame(0, columns = np.append(np.sort(y_star.unique()),['Acc']), index = np.sort(y_star.unique()))\nscore_test.iloc[:,:5] = cm_test\nscore_test.iloc[:,5:] = acc_test\n\ntrain_acc = train_acc/iterations\ntest_acc = test_acc/iterations\n(time.time() - start)/iterations","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"score_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.diag(score_test).sum()/score_test.iloc[:,:-1].sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_estimators = 100\nacc_train = []\nacc_test = []\n\n#dividing into train and test - sss to star rating\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=0)\nsss.get_n_splits(X_star, y_star)\n\nfor train_index, test_index in sss.split(X_star, y_star):\n    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_star_train, X_star_test = X_star.iloc[train_index], X_star.iloc[test_index]\n    y_star_train, y_star_test = y_star[train_index], y_star[test_index]\n    \nfor n in range(1,n_estimators+1):\n    model = RandomForestClassifier(n_estimators = n)\n    model.fit(X = X_star_train, y = y_star_train)\n    \n    predict_train = model.predict(X_star_train)    \n    predict_test = model.predict(X_star_test)\n    \n    acc_train.append(accuracy_score(y_star_train, predict_train))\n    acc_test.append(accuracy_score(y_star_test, predict_test))\n\nplt.plot(list(range(1,n_estimators+1)),acc_train, label = 'Train score')\nplt.plot(list(range(1,n_estimators+1)),acc_test, label = 'Test score')\nplt.grid(True)\nplt.xlabel('Number of estimators')\nplt.ylabel('Accuracy score')\nplt.xlim([0, n_estimators])\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_estimators = 40\nmax_depth = [10, 30, 50, 100]\n\n#dividing into train and test - sss to star rating\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=0)\nsss.get_n_splits(X_star, y_star)\n\nfor train_index, test_index in sss.split(X_star, y_star):\n    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_star_train, X_star_test = X_star.iloc[train_index], X_star.iloc[test_index]\n    y_star_train, y_star_test = y_star[train_index], y_star[test_index]\n\nfor md in max_depth:\n    acc_train = []\n    acc_test = []\n    for n in range(1,n_estimators+1):\n\n        model = RandomForestClassifier(n_estimators = n, max_depth = md)\n        model.fit(X = X_star_train, y = y_star_train)\n\n        predict_train = model.predict(X_star_train)    \n        predict_test = model.predict(X_star_test)\n\n        acc_train.append(accuracy_score(y_star_train, predict_train))\n        acc_test.append(accuracy_score(y_star_test, predict_test))\n\n    plt.plot(list(range(1,n_estimators+1)),acc_test, label = 'Test score (md = '+str(md)+')')\n\nplt.plot(list(range(1,n_estimators+1)),acc_train, label = 'Train score')\nplt.grid(True)\nplt.xlabel('Number of estimators')\nplt.ylabel('Accuracy score')\nplt.xlim([0, n_estimators])\nplt.legend(loc='lower right')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Optimized model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#consfusion matrix\niterations = 100\ncm_train = [0] #creates confusion matrix instance for train\ncm_test = [0] #creates confusion matrix instance for test\nFI = [0]*63\n\nX_star = df_star_rating.iloc[:,1:]\ny_star = df_star_rating['hotel_star_rating']\n\nstart = time.time()\nfor n in range(iterations):\n\n    #dividing into train and test - sss to star rating\n    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=n)\n    sss.get_n_splits(X_star, y_star)\n\n    for train_index, test_index in sss.split(X_star, y_star):\n        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n        X_star_train, X_star_test = X_star.iloc[train_index], X_star.iloc[test_index]\n        y_star_train, y_star_test = y_star[train_index], y_star[test_index]\n    \n    model = RandomForestClassifier(max_depth = 30, n_estimators = 30)\n    model.fit(X = X_star_train, y = y_star_train)\n    \n    predict_train = model.predict(X_star_train)    \n    cm_train += confusion_matrix(y_star_train, predict_train)\n\n    predict_test = model.predict(X_star_test)\n    cm_test += confusion_matrix(y_star_test, predict_test)\n    FI += model.feature_importances_\n    \ncm_train = cm_train/iterations #takes the mean\ntotal_train = [i.sum() for i in cm_train]\nacc_train = [cm_train[i][i]/total_train[i] for i in range(5)]\nscore_train = pd.DataFrame(0, columns = np.append(np.sort(y_star.unique()),['Acc']), index = np.sort(y_star.unique()))\nscore_train.iloc[:,:5] = cm_train\nscore_train.iloc[:,5:] = acc_train\n\ncm_test = cm_test/iterations # takes the mean\ntotal_test = [i.sum() for i in cm_test]\nacc_test = [cm_test[i][i]/total_test[i] for i in range(5)]\nscore_test = pd.DataFrame(0, columns = np.append(np.sort(y_star.unique()),['Acc']), index = np.sort(y_star.unique()))\nscore_test.iloc[:,:5] = cm_test\nscore_test.iloc[:,5:] = acc_test\n\nFI1 = FI/iterations\n\n(time.time() - start)/iterations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(sorted(zip(FI1, X_star_test.columns),reverse=True)[:15])[:,0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# features_importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,5))\n\n#using 15 most important features\nlabel1=np.array(sorted(zip(FI1, X_star_test.columns),reverse=True)[:15])[:,1]\nvalues1=np.array(sorted(zip(FI1, X_star_test.columns),reverse=True)[:15])[:,0]\nvalues1 = [round(float(v),3) for v in values1]\nplt.bar(label1,values1)\nplt.xticks(rotation=90)\nplt.ylim([0,0.12])\n\nfor i, v in enumerate(values1):\n    plt.text(i-0.15, v+0.012, str(round(v,3)), color='black', rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ROC curve (and why it did not work)\n5 curves were ploted in a OneVsRest approach. The ROC curve based on binary classification and is not able to represent multiclass. For each execution (each class vs other classes), the model asserts if an item is or is not part of the class, but oversees if the item would be a better fit for other classes."},{"metadata":{"trusted":true},"cell_type":"code","source":"roc = {label: [0] for label in y_star.unique()}\nauc = {label: [0] for label in y_star.unique()}\nestimator = DecisionTreeClassifier()\nfor label in y_star.unique():\n    single_class_train = []\n    single_class_test = []\n    for item in y_star_train:\n        if item == label:\n            single_class_train.append(1)\n        else:\n            single_class_train.append(0)\n    for item in y_star_test:\n        if item == label:\n            single_class_test.append(1)\n        else:\n            single_class_test.append(0)\n    estimator.fit(X = X_star_train, y = single_class_train)\n    predictions_proba = estimator.predict_proba(X_star_test)\n    roc[label] += roc_curve(single_class_test, predictions_proba[:,1])\n    auc[label] += roc_auc_score(single_class_test, predictions_proba[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\ncolor = ['red', 'darkorange', 'yellow', 'green', 'purple']\ni=0\nfor lbl in np.sort(y_star.unique()):\n    plt.plot(roc[lbl][1], roc[lbl][2], color=color[i], lw=1, label='ROC curve (area = %0.2f)' % auc[label])\n    i+=1\n\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic ')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# site_review modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating training and testing sets\n\nX_rev = df_review_rating.iloc[:,1:]\ny_rev = df_review_rating['site_review_rating']\n\n#dividing into train and test - train test split\nX_rev_train, X_rev_test, y_rev_train, y_rev_test = train_test_split(X_rev, y_rev, test_size=0.25, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_rev_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# baseline - average/ 1-degree DT / free DT"},{"metadata":{"trusted":true},"cell_type":"code","source":"aver_predict = [np.mean(y_rev_train)]*len(y_rev_test)\nr2_score(y_rev_test, aver_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = DecisionTreeRegressor(max_depth = 1, max_features = 1)\nmodel.fit(X_rev_train, y_rev_train)\npredict_train = model.predict(X_rev_train)\nscore_train = r2_score(y_rev_train, predict_train)\npredict_test = model.predict(X_rev_test)\nscore_test = r2_score(y_rev_test, predict_test)\nscore_train, score_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso, ElasticNet, Ridge\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor, BaggingRegressor, ExtraTreesRegressor\n\nmodel = RandomForestRegressor(n_estimators = 100)\nmodel.fit(X_rev_train, y_rev_train)\npredict_train = model.predict(X_rev_train)\nscore_train = r2_score(y_rev_train, predict_train)\npredict_test = model.predict(X_rev_test)\nscore_test = r2_score(y_rev_test, predict_test)\nscore_train, score_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_estimators = 100\nr2_train = []\nr2_test = []\n\n#dividing into train and test\nX_rev_train, X_rev_test, y_rev_train, y_rev_test = train_test_split(X_rev, y_rev, test_size=0.25, random_state=0)\n    \nfor n in range(1,n_estimators+1):\n    model = BaggingRegressor(n_estimators = n)\n    model.fit(X = X_rev_train, y = y_rev_train)\n    \n    predict_train = model.predict(X_rev_train)    \n    predict_test = model.predict(X_rev_test)\n    \n    r2_train.append(r2_score(y_rev_train, predict_train))\n    r2_test.append(r2_score(y_rev_test, predict_test))\n\nplt.plot(list(range(1,n_estimators+1)),r2_train, label = 'Train score')\nplt.plot(list(range(1,n_estimators+1)),r2_test, label = 'Test score')\nplt.grid(True)\nplt.xlabel('Number of estimators')\nplt.ylabel('R2 score')\nplt.xlim([0, n_estimators])\nplt.legend(loc = 'lower right')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2_test[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_estimators = 40\nmax_depth = [10, 30, 50, 100]\n\n#dividing into train and test\nX_rev_train, X_rev_test, y_rev_train, y_rev_test = train_test_split(X_rev, y_rev, test_size=0.25, random_state=0)\n\nfor md in max_depth:\n    r2_train = []\n    r2_test = []\n    for n in range(1,n_estimators+1):\n\n        model = ExtraTreesRegressor(n_estimators = n, max_depth = md)\n        model.fit(X = X_rev_train, y = y_rev_train)\n\n        predict_train = model.predict(X_rev_train)    \n        predict_test = model.predict(X_rev_test)\n\n        r2_train.append(r2_score(y_rev_train, predict_train))\n        r2_test.append(r2_score(y_rev_test, predict_test))\n\n    plt.plot(list(range(1,n_estimators+1)),r2_test, label = 'Test score (md = '+str(md)+')')\n\nplt.plot(list(range(1,n_estimators+1)),r2_train, label = 'Train score')\nplt.grid(True)\nplt.xlabel('Number of estimators')\nplt.ylabel('R2 score')\nplt.xlim([0, n_estimators])\nplt.legend(loc='lower right')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# optimized model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#consfusion matrix\niterations = 100\nr2_train = 0 #creates instance for train\nr2_test = 0 #creates instance for test\nFI = [0]*63 \n\nX_rev = df_review_rating.iloc[:,1:]\ny_rev = df_review_rating['site_review_rating']\n\nstart = time.time()\nfor n in range(iterations):\n\n    #dividing into train and test - sss to star rating\n    X_rev_train, X_rev_test, y_rev_train, y_rev_test = train_test_split(X_rev, y_rev, test_size=0.25, random_state=n)\n    \n    model = ExtraTreesRegressor(n_estimators = 30, max_depth = 30)\n    model.fit(X = X_rev_train, y = y_rev_train)\n\n    predict_train = model.predict(X_rev_train)    \n    predict_test = model.predict(X_rev_test)\n\n    r2_train += r2_score(y_rev_train, predict_train)\n    r2_test += r2_score(y_rev_test, predict_test)\n    FI += model.feature_importances_\n\nr2_train = r2_train/iterations #takes the mean\nr2_test = r2_test/iterations #takes the mean\n\nFI2 = FI/iterations\n\n(time.time() - start)/iterations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,5))\n\nlabel2=np.array(sorted(zip(FI2, X_rev_test.columns),reverse=True)[:15])[:,1]\nvalues2=np.array(sorted(zip(FI2, X_rev_test.columns),reverse=True)[:15])[:,0]\nvalues2 = [round(float(v),3) for v in values2]\nplt.bar(label2,values2)\nplt.xticks(rotation=90)\nplt.ylim([0,0.08])\n\nfor i, v in enumerate(values2):\n    plt.text(i-0.15, v+0.008, str(round(v,3)), color='black', rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#comparing feature importances for both analysis\n\nfig, ax = plt.subplots(figsize=(15,8))\nplt.subplots_adjust(hspace = 1.2)\nplt.figure(1)\n\nplt.subplot(211)\nlabel1=np.array(sorted(zip(FI1, X_star_test.columns),reverse=True)[:15])[:,1]\nvalues1=np.array(sorted(zip(FI1, X_star_test.columns),reverse=True)[:15])[:,0]\nvalues1 = [round(float(v),3) for v in values1]\nplt.bar(label1,values1)\nplt.xticks(rotation=90)\nplt.ylim([0,0.11])\nplt.title('Star rating feature importances')\n\nfor i, v in enumerate(values1):\n    plt.text(i-0.15, v-0.01, str(round(v,3)), color='white', rotation = 90)\n\n\nplt.subplot(212)\nlabel2=np.array(sorted(zip(FI2, X_rev_test.columns),reverse=True)[:15])[:,1]\nvalues2=np.array(sorted(zip(FI2, X_rev_test.columns),reverse=True)[:15])[:,0]\nvalues2 = [round(float(v),3) for v in values2]\nplt.bar(label2,values2)\nplt.xticks(rotation=90)\nplt.ylim([0,0.07])\nplt.title('Customer review feature importances')\n\nfor i, v in enumerate(values2):\n    plt.text(i-0.15, v-0.008, str(round(v,3)), color='white', rotation = 90)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}