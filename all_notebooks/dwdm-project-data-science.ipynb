{"cells":[{"metadata":{"_uuid":"c797752a0ba18aece737c110f81cd5adcf5b72f2"},"cell_type":"markdown","source":"**Data Warehouse and Data Mining**\n* Group Members\n* Kevoy Walters - 1403487\n* Jevaun Harris - 1403164\n* Sheneal McCourtie - 1501076\n* Shanygne Downey - 1503760\n"},{"metadata":{"_uuid":"5dc8530f60259d2010469994ff57274e4ea2553d"},"cell_type":"markdown","source":"**Description of Dataset**"},{"metadata":{"_uuid":"3215427b0f64d519daba8e81a498414aa4ed750d"},"cell_type":"markdown","source":"This dataset includes information which will help predict customer behaviour in order to ensure satisfaction and minimize churn. Each row represents a customer, each column contains customer’s attributes described on the column Metadata. The raw data contains 7043 rows (customers) and 21 columns (features). The ‘Churn’ column is our target. Excluding the ‘customerID’ column, there are 3 numerical and 17 categorical columns. The data set includes information about:\n* Customers who left within the last month – the column is called Churn\n** Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n* Customer account information – how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n* Demographic info about customers – gender, age range, and if they have partners and dependents\n\n"},{"metadata":{"_uuid":"52ccc81818ec2031ed52dc3eece8fdfb40bc4b70"},"cell_type":"markdown","source":"**Background**"},{"metadata":{"_uuid":"a55d0d6e855a5f474ddb1dd2afe93c624089a8fb"},"cell_type":"markdown","source":"Flashpoint Communications is a telecommunications company which provides several services such as telephone and internet service, tv and movie streaming, tech support, device protection, online backup and online security. The company is concerned about the number of customers leaving their landline business for cable competitors. They need to understand who is leaving and why. This attrition or turnover of customers of a business or users of a service is called churn. Having a high churn rate is bad for the company as is reduces growth and profit and that is the opposite of what Flashpoint Communications want.   \n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nimport plotly.offline as py\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa30b9608dc3cd677243abce4ff9a69ee2736cde"},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf9b68c05e88b7220e3e747b051f85127f357623"},"cell_type":"code","source":"# output = (rows, columns)\ndata.shape ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"626f6e4ca32bf60078581138d6b6cf1c2239dd89"},"cell_type":"markdown","source":"**Target Variable - Churn**"},{"metadata":{"_uuid":"a01bca0c26cb49663178d0fd16c5dd95c4df335e"},"cell_type":"markdown","source":"Which features are numerical?\nSeniorCitizen, Tenure, MonthlyCharges, TotalCharges\n\nContinous - Tenure, MonthlyCharges, TotalCharges\n\nDiscrete - SeniorCitizen\n\nWhich features are categorical?\nPhoneService, MultipleLines, InternetService, OnlineSecurity, OnlineBackup DeviceProtection, TechSupport, StreamingTV, StreamingMovies, Contract, PaperlessBilling, PaymentMethod, gender, Partner, Dependents"},{"metadata":{"_uuid":"6f51865b732744051ec39a7de2ff84e563a54c8c"},"cell_type":"markdown","source":"This dataset is a categorical dataset since most of its columns including the target varibles are categorical data"},{"metadata":{"trusted":true,"_uuid":"d61946081828d1b92082040951855f15bf78a32b"},"cell_type":"code","source":"# making a copy of the data and saving it in a variable \ndata_temp = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac1978c76b37cf38aba13a18981190ae730cdf1d"},"cell_type":"markdown","source":"**Visualization on the Dataset**"},{"metadata":{"trusted":true,"_uuid":"69354eec269642680c18c2a8bf45bef984f1c63f"},"cell_type":"code","source":"data_temp['Churn'].value_counts().plot.pie(autopct='%1.1f%%')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f1e52c0990855a7345cb39aeae06bc67215dc34"},"cell_type":"markdown","source":"Pie chart showing the percentage of who churn which is 26.5% and those who stayed with the company which is 73.5%"},{"metadata":{"trusted":true,"_uuid":"00da9ecd4336674e8a81f7322c71f8d9baad0665"},"cell_type":"code","source":"sns.factorplot(x=\"Contract\", y=\"MonthlyCharges\", hue=\"PaymentMethod\", kind=\"point\", data=data_temp)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8490004042c243ded6f4e3f6d48ac4b58070a832"},"cell_type":"markdown","source":"Point chart showing the relationship between the type of contarct and the month charges also using the type of payment method as the key"},{"metadata":{"trusted":true,"_uuid":"b07f3f5b09a723c081ceb1988c7212f4b45872c9"},"cell_type":"code","source":"sns.pairplot(data_temp[['tenure','MonthlyCharges','TotalCharges','Churn','Contract','SeniorCitizen']], hue='Churn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fb5c36ebcfd135ab4025cc62e54d9a6449cf215"},"cell_type":"code","source":"# shorter the contract period, higher probability of churn? lets check crosstab\n\ncr  = pd.crosstab(data_temp.Contract, data_temp.Churn)\ncr.plot(kind='bar')\nplt.title('Churn by Contract')\nplt.ylabel(\"Number of chrun\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58e0a92e1571fe16c3823a9a933ca3c0061d6443"},"cell_type":"markdown","source":"bar garph showing the number of customers churn against the type of contract"},{"metadata":{"trusted":true,"_uuid":"a326000094a7f0021f9704dd7d2ec625426dfbbd"},"cell_type":"code","source":"data_temp.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47d35f7966dc9b0885ca7fe115df33557f9962cd"},"cell_type":"markdown","source":"**Preprocessing**"},{"metadata":{"_uuid":"05143654aea888f7b876e90b6ddc6de6ed1b1a9f"},"cell_type":"markdown","source":"Here we can see that Total Charges is an object variable. Let's Change it to float"},{"metadata":{"trusted":true,"_uuid":"d810704fc7c61a2781c1488c802e655681e8297f"},"cell_type":"code","source":"tot_charges = data_temp[\"TotalCharges\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57ce4d6be43106c6345108769cea33f7c4e4460e"},"cell_type":"code","source":"def convert_to_float(strin):\n        try:\n            return float(strin)\n        except:\n            return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d5cc803062464607c6a8e7b2bea5da1a6b715dc"},"cell_type":"code","source":"data_temp['TotalCharges']=data_temp['TotalCharges'].apply(convert_to_float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef66fb20d0dab60c51d277f1506da4555f223f71"},"cell_type":"code","source":"data_temp['TotalCharges']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d680b2304df43bd2201203ba0d164710fdfdc59"},"cell_type":"code","source":"#describe the data\ndata_temp.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1400096e0ef93d51bf144ae0a2c2453d98af7677"},"cell_type":"code","source":"# Checking For NULL \ndata_temp.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebb821e431fa387828da9b380476ce523bd570bb"},"cell_type":"code","source":"#Identifying the rows containing 0 value in Total Charges\nzero_value_row = list(data_temp[data_temp['TotalCharges'] == 0].index)\nprint('0 Value Rows=',zero_value_row, \"\\ntotal =\", len(zero_value_row))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a3dcbbb26e5ddddfb560411447a57fd7de91c50"},"cell_type":"code","source":"for zero_row in zero_value_row :\n    print( data_temp['MonthlyCharges'][zero_row],data_temp['tenure'][zero_row],data_temp['TotalCharges'][zero_row])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94ff06b73a0f700687b0350cf04360bdabe5a2d8"},"cell_type":"markdown","source":"So Tenure is 0 for the cstomers with TotalCharges as 0, that initially had a space.  might mean that they have not yet been with the company for a whole month, and therefore have not yet been charged any money. This explains why TotalCharges is missing, and also why none of them have churned yet.\n\n "},{"metadata":{"trusted":true,"_uuid":"434a7b4a40d33d81e7ec5b89ded1c8b00ea8a353","scrolled":false},"cell_type":"code","source":"# Look at the shape before and after to be sure they were removed\nprint(data_temp.shape)\ndata_temp = data_temp.drop(data_temp.index[[488, 753, 936, 1082, 1340, 3331, 3826, 4380, 5218, 6670, 6754]])\nprint(data_temp.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6e0c450d83ad7c1462b100f2a753e08e475fd297"},"cell_type":"markdown","source":"**Let's Convert Our Target Variable 'Churn' for Yes or No to 1 or 0.**\n* Using the logistic regression model, categories must be transformed into numbers first before we can apply the learning algorithm.\n"},{"metadata":{"trusted":true,"_uuid":"4587580a1d7ad79f7417ed560c0ee48f1449f0f6"},"cell_type":"code","source":"#coverting Churn from Yes or No to 1 or 0 and saving it in a new column name class\ndata_temp['class'] = data_temp['Churn'].apply(lambda x : 1 if x == \"Yes\" else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d8de02bbdd972e25029292a7c63d5191ee92a0e"},"cell_type":"code","source":"count_no_churn = len(data_temp[data_temp['class']==0])\ncount_churn = len(data_temp[data_temp['class']==1])\npct_of_no_churn = count_no_churn/(count_no_churn+count_churn)\nprint(\"percentage of no churn is\", pct_of_no_churn*100)\npct_of_churn = count_churn/(count_no_churn+count_churn)\nprint(\"percentage of churn\", pct_of_churn*100)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bba34a09f0f5d40c0906c3bbc098fd64e15c00cf"},"cell_type":"markdown","source":"**when churn is \"Yes\"**"},{"metadata":{"trusted":true,"_uuid":"a85a8559e03afcd93c7cbe260e69216bd8db6ffe","scrolled":true},"cell_type":"code","source":"data_temp.loc[(data_temp.Churn == 'Yes'),'MonthlyCharges'].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce99119072159c5d24cd745ecdc02ad0afd59865"},"cell_type":"code","source":"data_temp.loc[(data_temp.Churn == 'Yes'),'TotalCharges'].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fd5b0475bb26909119d8b65aec474a8b224d054"},"cell_type":"code","source":"data_temp.loc[(data_temp.Churn == 'Yes'),'tenure'].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a251bd36c33235e559064a558a910a9355e8595"},"cell_type":"code","source":"data_temp.loc[(data_temp.Churn == 'Yes'), 'Contract'].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e54da4c821f81e787f138601e2b9e26702f60e7"},"cell_type":"code","source":"data_temp.loc[(data_temp.Churn == 'Yes'),'PaymentMethod'].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77b0c60331db72f35a32484ad9bd143045ba64a3"},"cell_type":"markdown","source":"**Most of the People that Left are the Ones who had Payment Method as Electronic Check so Let's Make a Seperate Variable for it so that The Model can Easily Predict our Target Variable.**"},{"metadata":{"trusted":true,"_uuid":"69b24a143bfd2f9fc8d6efab462460fe35eb5494"},"cell_type":"code","source":"data_temp['Is_Electronic_check'] = np.where(data_temp['PaymentMethod'] == 'Electronic check',1,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37211971b75bceea4131445a6d14e837579ee269"},"cell_type":"code","source":"data_temp.loc[(data_temp.Churn == 'Yes'),'PaperlessBilling'].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e746bb29126de32860b502216269333a3402948e"},"cell_type":"code","source":"data_temp.loc[(data_temp.Churn == 'Yes'), 'Contract'].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e23da303be8b1cdceb4047e3f16bcd218e93826"},"cell_type":"code","source":"data_temp['Is_Contract_Month'] = np.where(data_temp['PaymentMethod'] == 'Month-to-month',1,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"673bb8d0071bff98f04251e45101adb652944104"},"cell_type":"code","source":"data_temp.loc[(data_temp.Churn == 'Yes'),'DeviceProtection'].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09fc7aa7c987f7623390d39b1a6570519a359d41"},"cell_type":"code","source":"data_temp.loc[(data_temp.Churn == 'Yes'),'OnlineBackup'].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9efd13ce472311214cb59245663b60c3cbe7b70"},"cell_type":"code","source":"data_temp.loc[(data_temp.Churn == 'Yes'),'TechSupport'].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c075d6e5c2c83ccf15104acf6202c670f804f20"},"cell_type":"code","source":"data_temp.loc[(data_temp.Churn == 'Yes'),'OnlineSecurity'].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b2d4fdf6d18b6c3a038b8fe5af3248003b6d67c3"},"cell_type":"markdown","source":"**We can See that People That Left the Company did'nt use Services Like Online Security , Device Protection , Tech Support and Online Backup quite often. Hence for Our Prediction these variables will not be of much Importance. We will Drop them in the End.**"},{"metadata":{"trusted":true,"_uuid":"585b8ee88c1559cc82e1fadea6a8f28177799432"},"cell_type":"code","source":"data_temp= pd.get_dummies(data_temp,columns=['Partner','Dependents',\n       'PhoneService', 'MultipleLines','StreamingTV',\n       'StreamingMovies','Contract','PaperlessBilling','InternetService'],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0a2c7895f3d64ed4066223993d7c00a7fa4f022"},"cell_type":"markdown","source":"We have Encoded the Categorical Variables with Numeric using get dummies Property which will make it easy for the Machine to Make Correct Prediction."},{"metadata":{"trusted":true,"_uuid":"9e3e02bb17398101f88601465a5fa2366165a9aa"},"cell_type":"code","source":"data_temp.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58ae702dcdf212d8ac4845dbba6864272a312ef7"},"cell_type":"markdown","source":"**Transformation**\n* Transforming the data to get the best outcome  from the algorithms"},{"metadata":{"_uuid":"2b2874ccf31cc8a0557433149d88592e6d77487a"},"cell_type":"markdown","source":"Now Let's Drop the variables that are not Important For us according to our Analysis."},{"metadata":{"trusted":true,"_uuid":"e9d946f4aa39893e9e05f0e13a057ed8c6bd43de"},"cell_type":"code","source":"data_temp.drop(['StreamingTV_No internet service','StreamingMovies_No internet service'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f868d6c4e8e29fb28459296bf321f06eb387a78"},"cell_type":"code","source":"data_temp.drop('gender',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cee319e6181e3aa86ed8c758bcdb85deacf85c0"},"cell_type":"code","source":"data_temp.drop('class',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e24b2aa74fc56082ca871e31e4cd44e25a67188"},"cell_type":"code","source":"data_temp.drop('customerID',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd013beb91347af2588484f1697614abe322db12"},"cell_type":"code","source":"#data_temp.drop(['tenure','MonthlyCharges'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"353cd95f8e4a12571fd40c427889364f340aa911"},"cell_type":"code","source":"data_temp.drop(['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','PaymentMethod'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51cb8d1796f64fb87d6a58c4f978df031d6da37f"},"cell_type":"code","source":"data_temp = pd.get_dummies(data_temp,columns=['Churn'],drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c9d01446c0bd3dc9fe0ec586227fd3c56bf15c9","scrolled":true},"cell_type":"code","source":"data_temp.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9bbd59e00c4c11745b6c7da589a8a302839d7488"},"cell_type":"markdown","source":"**Data Mining Algorithm**"},{"metadata":{"_uuid":"b5445150911e7027aeb59c96d8dd5c91d91a7eb8"},"cell_type":"markdown","source":"Description of algorithms\nA total of three algorithms were used to analyze and produce evaluations for the telecommunication dataset. Each algorithm has its own description, application and advantages. There algorithms used were Decision trees, Logistic regression and K-Modes. \n"},{"metadata":{"_uuid":"70c2e1e07f3f6a628334fcf5047fd26920a9da44"},"cell_type":"markdown","source":"**Let's start with Logistic Regression Model because we know Our Target Variable has a Binary Outcome.**\n* Binary logistic regression requires the dependent variable to be binary.\n* For a binary regression, the factor level 1 of the dependent variable should represent the desired outcome.\n* Only the meaningful variables should be included."},{"metadata":{"_uuid":"1c31e77b922669083b675df2a2b6d78ce6b80044"},"cell_type":"markdown","source":" Logistic regression gives you a discrete outcome but linear regression gives a continuous outcome."},{"metadata":{"_uuid":"3ea2ad862a32aa6b836ef1d379489d9d234e0530"},"cell_type":"markdown","source":"**Logistic Regression**\n* Regression is a technique for determining the statistical relationship between two or more variables where a change in a dependent variable is associated with, and depends on, a change in one or more independent variables. There are multiple types of regressions available in data mining however logistic regression was fit for our dataset and its columns. There are several benefits of using regression analysis, two of which are:\n1. It indicates the significant relationships between dependent variable and independent variable.\n2. It indicates the strength of impact of multiple independent variables on a dependent variable."},{"metadata":{"_uuid":"5495ae9584dd3a58826512b8b1c5cb1b2f2f0b6a"},"cell_type":"markdown","source":"Logistic regression is used to find the probability of event=Success and event=Failure. Logistic regression is used when the dependent variable is binary (0/ 1, True/ False, Yes/ No) in nature. \n"},{"metadata":{"_uuid":"1fcd2841310ba5dccd1a46a9ae0e9af0bd43e93c"},"cell_type":"markdown","source":"This type of regression is widely used for classification problems. In general, according to analyticsvidhya.com (2018), there are few important points to note when using logistic regression as a data mining technique. They are:\n* Logistic regression doesn’t require linear relationship between dependent and independent variables.  It can handle various types of relationships because it applies a non-linear log transformation to the predicted odds ratio\n* To avoid overfitting and underfitting, we should include all significant variables. A good approach to ensure this practice is to use a step wise method to estimate the logistic regression\n* It requires large sample sizes because maximum likelihood estimates are less powerful at low sample sizes than ordinary least square\n* The independent variables should not be correlated with each other i.e. no multicollinearity.  However, we have the options to include interaction effects of categorical variables in the analysis and in the model.\n* If the values of dependent variable is ordinal, then it is called as Ordinal logistic regression\n* If dependent variable is multi class then it is known as Multinomial Logistic regression.\n"},{"metadata":{"trusted":true,"_uuid":"faf781b189f50f49551cd695ad4aacb0b77ce6a4"},"cell_type":"code","source":"X = data_temp.drop('Churn_Yes',axis=1).values.astype('float')\ny = data_temp['Churn_Yes']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24257b997df22c123665d9789c152ce281b3dd29"},"cell_type":"code","source":"# train test 70/30\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\nprint (X_train.shape, y_train.shape)\nprint (X_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1301fce13e4d0fec908306cdfed9aa3b1160a61"},"cell_type":"code","source":"# create model\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4099c579e3bcd0a206f0bdbef9ab51b11fc6fb4"},"cell_type":"code","source":"# train model\nmodel.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d1d940218aff3b2fba5d74b241395e4e26a0436"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score,classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91a7032e3871db35732049a76a3f5b6119980366"},"cell_type":"code","source":"print('Model Score:',model.score(X_train,y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d59adb05f01048a4f958e1c18cf9f05dad62a08f"},"cell_type":"code","source":"y_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e55dd125758eb76b618fbaa80db886fc6d42187"},"cell_type":"code","source":"from sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\nprint ('confusion matrix for logistic regression \\n ', cnf_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05f5e1edf621273166271697966669953f2d5eb2"},"cell_type":"code","source":"class_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74495ff7cf385f42dc301e8070faaed6e556c5b3"},"cell_type":"markdown","source":"**The results from the confusion matrix are telling us that 1404 and 265 are the number of correct predictions. 151 and 290 are the number of incorrect predictions.**"},{"metadata":{"_uuid":"07dd646ea48410fe8fe47264119e8692ae2dba2d"},"cell_type":"markdown","source":"Precision is the fraction of correctly identified examples of a class (ratio of true possitive to all positives)\nRecall is the fraction of observation classified in that class that was correctly classified"},{"metadata":{"trusted":true,"_uuid":"c413fcb9c028ee4130f6c579da460ade235d217d","scrolled":true},"cell_type":"code","source":"print ('accuracy for logistic regression  : {0:.2f}'.format(accuracy_score(y_test, model.predict(X_test))))\nprint ('precision for logistic regression : {0:.2f}'.format(precision_score(y_test, model.predict(X_test))))\nprint ('recall for logistic regression    : {0:.2f}'.format(recall_score(y_test, model.predict(X_test))))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8aa1bfd050577ea06668ecc007ae05ca0849830"},"cell_type":"markdown","source":"**We have a classification rate of 80%, considered as good accuracy.**"},{"metadata":{"trusted":true,"_uuid":"98c0f5e08e9f8838eabcbce392d0a276985cf057"},"cell_type":"code","source":"print(classification_report(y_test,model.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb6905dc8c6ceb86101084c9f10f0d47ca2448df"},"cell_type":"markdown","source":"**Plotting Output of the Logistic Resggresion**"},{"metadata":{"_uuid":"345e506d71a099ca0c247a3cc922351f090f0305"},"cell_type":"markdown","source":"**ROC Curve**\nReceiver Operating Characteristic(ROC) curve is a plot of the true positive rate against the false positive rate. It shows the tradeoff between sensitivity and specificity."},{"metadata":{"trusted":true,"_uuid":"1d6ac82a903ae5172e22259fbac3aa3f2a0364f7"},"cell_type":"code","source":"y_pred_prob = model.predict(X_test)\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_prob)\nauc = metrics.roc_auc_score(y_test, y_pred_prob)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.xlabel('False Positive Rate (1 - specificity)', fontsize=14)\nplt.ylabel('True Positive Rate (recall)', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f87d5a255d51f9781172369ad5c37a44acaeb3d"},"cell_type":"markdown","source":"**AUC score for the case is 0.69 AUC score 1 represents perfect classifier, and 0.5 represents a worthless classifier.**"},{"metadata":{"_uuid":"ecc52d9e96f8130f76d78d3dd6c7fbb38b80eb83"},"cell_type":"markdown","source":"**Clustering Algorithm**\n* Clustering (K Modes) "},{"metadata":{"_uuid":"7d5f992962eca731f00a114fcd33f2271e03e060"},"cell_type":"markdown","source":"K-Modes (Clustering)\nUtilizing clustering techniques in machine learning forms a crucial part in data mining or analysis because diving the entire dataset in similar subgroups helps in gaining a lot of insight from the data. This unsupervised algorithm uses modes instead of the usual means (K-Means) to form clusters of categorical data. Firstly, mode can be defined as the value that occurs most frequently in a given set of data. K-Modes helps to provide insights on specific subgroups in a dataset, allowing data scientists to evaluate data or client structures and provide recommendations and counter measures in organizations.  "},{"metadata":{"trusted":true,"_uuid":"39f04d4ec282fc8ee8a5acf5a8ce19b5a434e79e"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split  \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e61cca138633fbfb91616603cda63357f5e9db2e"},"cell_type":"code","source":"from kmodes.kmodes import KModes ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"994d60c068a4e3e57180522b2fc953ffa2f280ae"},"cell_type":"code","source":"data_temp2 = data_temp.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ceb44e817a8bab7161d750a1e3a583b24e3e288"},"cell_type":"code","source":"data_temp=data_temp.drop(['TotalCharges', 'tenure', 'MonthlyCharges'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2907455497b97f9291662cd12d7b9bfef983f52e"},"cell_type":"code","source":"\n# random categorical data\n\nkm = KModes(n_clusters=4, init='Huang', n_init=5, verbose=1)\n\nclusters = km.fit_predict(data_temp)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a7f6617a72bde48368eb51f5ae88037ac72f65d"},"cell_type":"code","source":"km.cluster_centroids_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ea7706b1c9e3835ba862c1ad86f4fdf9393680f"},"cell_type":"code","source":"clusters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef85c52956c81f4b0094e040dbfd1c5c76e34430"},"cell_type":"code","source":"data_temp['Cluster_Group']= clusters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a83e0077e761fff7c2d8d9565f08e08fb84d256"},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c70b06ec08e82bde90a27a3ba2d83b277dac531"},"cell_type":"code","source":"data_temp.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bdbb582b14b7ad50c3baff2b0395922f8be00ac7"},"cell_type":"code","source":"data_temp['Cluster_Group'].value_counts().plot(kind='bar',title='Distribution of Customers across groups')\nplt.xlabel(\"Clusters\")\nplt.ylabel(\"Number of Clusters\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36d3bd40d0e641217d6f8fa8117b10c938fc6f7b"},"cell_type":"code","source":"ct  = pd.crosstab(data_temp['Cluster_Group'],data_temp.Churn_Yes)\nct.plot(kind='bar')\nplt.title('Churn rate of each Cluster Group')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ebc0aac03b5a7b7ec74a1a47de7328a9424b0bc"},"cell_type":"code","source":"data_temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3d115953a4dee5f98e76544619d2f95a1dfa1cd"},"cell_type":"code","source":"pd.DataFrame({\n    'clusters':clusters,\n    'SeniorCitizen': data_temp['SeniorCitizen'],\n    'Churn_Yes': data_temp['Churn_Yes']\n}).plot(kind='scatter', x='SeniorCitizen', y='Churn_Yes',c=\"clusters\")\nplt.xlabel('SeniorCitizen')\nplt.figure(figsize=(13,13))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c33368d9ba79d9d7facfb506b87ca6b095ba364"},"cell_type":"code","source":"cgroup = data_temp.groupby('Cluster_Group')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e34abe8a55a37e494e00e6aaabef5ebbe6620580","scrolled":true},"cell_type":"code","source":"cgroup.apply(lambda x : x.mode())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49c5cf17dc33a872ea14dcf3bcddd1da40ae1ac7"},"cell_type":"code","source":"sns.pairplot(data_temp[['Is_Contract_Month','Contract_One year','Contract_Two year','Cluster_Group']], hue='Cluster_Group')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d51aebdddbf003554ce84c3be9db56c6320ea7ef"},"cell_type":"markdown","source":"Pair Plot showing the cluster groups with the type of contact "},{"metadata":{"trusted":true,"_uuid":"d613a9e506ed5a271008bb4896b8d57f4fdf5abd"},"cell_type":"code","source":"sns.pairplot(data_temp[['Is_Electronic_check','PaperlessBilling_Yes','Cluster_Group']], hue='Cluster_Group')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5db2424aa33497e4e4d568a069c7a565cda7206b"},"cell_type":"markdown","source":"Pair Plot showing the cluster groups with the type of payment method"},{"metadata":{"trusted":true,"_uuid":"d64b27fda3850cc51e7c9a7185928bffcfc42b0b"},"cell_type":"code","source":"subgroup = data_temp[['Is_Contract_Month','Contract_One year','Contract_Two year','Is_Electronic_check','PaperlessBilling_Yes','Cluster_Group']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80dd683abb9488f88cb5a74091b4c4fbebc9f3cd"},"cell_type":"code","source":"cluster_data = subgroup.groupby('Cluster_Group')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5f77c65cc4fa61c10c3133303960be09a0669b1"},"cell_type":"code","source":"cluster_data.plot(subplots=True,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67f09c834670e19c23798df9430f26ccb25fa939"},"cell_type":"code","source":"# Print the cluster centroids\nprint(km.cluster_centroids_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db138a8ea487bb47ebb3368ddf49e20de772078d"},"cell_type":"markdown","source":"**Decision Tree**"},{"metadata":{"trusted":true,"_uuid":"0c1c3f60c89d947d3a4bb801dcc58b0969af2b23"},"cell_type":"markdown","source":"According to chapter three of a research paper done at The Princeton university, Decision tree learning is a supervised learning strategy for approximating discrete-valued target functions in which this machine learning is represented by a graphical decision tree. Learned trees can and is typically represented as a set of if-then-else rules to improve human readability and experience. The goal of a decision tree is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. Unfortunately, the deeper the tree, the more complex the rules and fitter the model. If a decision tree displays overfitting then, it should be noted that it becomes difficult to predict a target value. \n"},{"metadata":{"trusted":true,"_uuid":"98ee745f9f50b1480510c90f5273afb665e1e62a"},"cell_type":"code","source":"X_data = data_temp2[['SeniorCitizen','tenure','MonthlyCharges','TotalCharges','Is_Electronic_check','Is_Contract_Month','StreamingTV_Yes']]\ny_data = data_temp2['Churn_Yes']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c42dfdf605229ef96a2f2ae7b0811f122fafe0c4"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c600c1e50ace895a3af3e4517ff0c846e9c7590d"},"cell_type":"code","source":"clf = DecisionTreeClassifier(max_depth=2, criterion='entropy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35ac836a109df628e84a697f9e76d2953bba62ce"},"cell_type":"code","source":"clf.fit(X_data, y_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5037d0859ade69556d65cfac4c8b1bba63b554db"},"cell_type":"code","source":"DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=2,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_split=1e-07, min_samples_leaf=1,\n            min_samples_split=2, min_weight_fraction_leaf=0.0,\n            presort=False, random_state=None, splitter='best')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d8a0a2095b2cbc44f57b5babdff539134e69cbb"},"cell_type":"code","source":"y_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52ac852cca60b695f374ff9aaab987c6b2b9bce1"},"cell_type":"code","source":"pd.DataFrame([ \"%.2f%%\" % perc for perc in (clf.feature_importances_ * 100) ], index = X_data.columns, columns = ['Feature Significance in Decision Tree'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59bd9ec7bc109f82346864be80841a9f568af34d"},"cell_type":"code","source":"import graphviz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86a8229900ac0c5b77a5dc4b4ba702cb8013a1d9"},"cell_type":"code","source":"dot_data = tree.export_graphviz(clf,out_file=None, \n                                feature_names=X_data.columns,\n                                class_names = ['No', 'Yes'],\n                         filled=True, rounded=True,  proportion=True,\n                                node_ids=True, #impurity=False,\n                         special_characters=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53b4eeb535c020f3c155174f6805c631c6ff393e"},"cell_type":"markdown","source":"**Ploting the Decision**"},{"metadata":{"trusted":true,"_uuid":"e985c9e9af17329b56ef8a6b5495f7398a60b052"},"cell_type":"code","source":"graph = graphviz.Source(dot_data) \ngraph","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee1ec793085a383fbb96346a58d0bfca2ad48fae"},"cell_type":"markdown","source":"**Justification for use of algorithms with data set**"},{"metadata":{"_uuid":"389d906df22f1f72c7998738e991ba3a6b7e7e51"},"cell_type":"markdown","source":"Decision Tree\n* The decision tree algorithm was a good fit for this data set as it is a supervised learning algorithm that outlines an outcome based on a series of related conditions based on the features of the data set. In this case ‘Churn’ was the target output and the goal was to find out what was making customers churn or leave the company. The decision tree gives a graphical view to show the features that are affecting churn and how they affect it. This gives a clear idea of what is making customers churn and what can be done to prevent churning.\n"},{"metadata":{"_uuid":"fe4c1772aada2950aeb1167b59b89da8b20aa298"},"cell_type":"markdown","source":"K-Modes\n* The K-Modes algorithm was used to see what groups of clusters of customers was churning the most and to see what were the common values for the different features among them. This is very valuable as an effort can be made to analyze what is increasing the likeliness of the a customer churning and rectify the problem. Also we can see what cluster has the lowest churn rate and try to increase those conditions in order to increase customer satisfaction as that cluster would be the most satisfied.\n"},{"metadata":{"_uuid":"a2b6da75f719629f6262182e7144644c8f066603"},"cell_type":"markdown","source":"Logistic Regression\n* Logistic Regression was used because it is used to predict a target variable and it is used for classification data. It also works well with large sample sizes and binary input. We can use it to predict what would cause customers to churn based on the values of the various features and how much they impact the churn rate. \n"},{"metadata":{"_uuid":"db49b61d6c7d6bc8c376e4bb8da373691e888d8f"},"cell_type":"markdown","source":"**Description of how algorithms operated on data**"},{"metadata":{"_uuid":"c6fcca0e694aefb0e6523fc263f1f7b7fce50dfd"},"cell_type":"markdown","source":"**Logistic Regression**\n* For us to have performed the logistic regression, we had to divide our columns in two distinctions ; dependent variable (or target variable) and independent variable(or feature variables). As mentioned previously, our target variable is ‘Churn’. The data is split in a train set, which trains the model, and a test set. The train_test_set() function was used to achieve this, and a 70/30 ratio used. This means 70% of our data was used to train the model, while the remaining 30% was used as the test set. In order to develop our model, we first import the Logistic Regression module and create a logistic regression classifier object, using the LogisticRegression() function. Our object was called ‘model’. We then fit our model on the train set using the fit() function and predict the test test using the predict() function. The output which is then produced is a confusion matrix, using a heat map. The visualizes the number of correct and incorrect predicts made by our model. Based on our matrix, our model made a correct prediction of 1669 and 441 incorrect predictions. Our model correctly predicted 80% of the data.\n"},{"metadata":{"_uuid":"261e1276e23ca4e58407949ca4b09c8c6f921dd4"},"cell_type":"markdown","source":"**K-Modes**\n* The Kmodes algorithm forms clusters based on the number of matching categories between data points. The Kmodes() function is passed four parameters; the amount of clusters we would like to form, initialisation type, number of iterations which will be run with different centroid seeds and the verbose. We then store the results in a variable ‘km’.The k-modes approach  uses a dissimilarity measure, using modes to represent cluster centers and updating modes with the most frequent categorical values in each iteration of the clustering process. At the end of the iterations, the best run is selected. The fit_predict function accepts our dataset and forms the clusters, which we store in a variable called ‘clusters’. We use a bar graph to illustrate the output of the different cluster groups.\n"},{"metadata":{"_uuid":"f5800a539609ba29dd141177b8c669e6543398c7"},"cell_type":"markdown","source":"**Decision Tree**\n* A decision tree was used to create a model which predicts the target variable by learning simple decision rules based on the dependent variables. The X_data consists of SeniorCitizen, Tenure,MonthlyCharges, TotalCharges, Is_Electronic_check, Is_Contract_Month, StreamingTV_Yes and the Y_data is ‘Churn_Yes’.  We import the tree and DecisionTreeClassifier() modules to help us build the tree. The DecisionTreeClassifier() takes a number of parameters. A few of these parameters include criterion which defines the quality of a split, max_features, which defines the number of features to consider when looking for the best split, max_depth, which states the maximum depth of the tree, max_leaf_nodes which defines the maximum number of possible leaf nodes. We use the fit() function to accept the X_data and Y_data,in order  to train the tree. The tree.export_graphviz() function accepts parameters which defines the placement of the data on the tree, specifications and headings. That information is then stored in our dot_data variable, which is then passed to the graphviz.Source() and stored in a variable ‘graph’, which is used to produce the tree visualization.\n\n"},{"metadata":{"_uuid":"444a2b862448a49574ed08b9f2195e7ca686d935"},"cell_type":"markdown","source":"**Outline of methods/activities done at each step of the KDD process**\n\n* The term Knowledge Discovery in Databases, or KDD for short, refers to the broad process of finding knowledge in data, and emphasizes the \"high-level\" application of particular data mining methods. The unifying goal of the KDD process is to extract knowledge from data in the context of large databases. (Piatetsky-Shapiro, 1999). Additionally, KDD is an iterative process where evaluation measures can be enhanced, mining can be refined, new data can be integrated and transformed in order to get different and more appropriate results. \n* Selection Process\nData selection in the KDD model can defined as the process where data relevant to the analysis is decided and retrieved from the data collection (complete dataset). During this process, based on the type of algorithm that was implemented, specific columns were included or removed from the main dataset. Specific algorithms required only categorical data while other times, only numerical data was needed to perform the analysis. \nDecision trees required only numerical data that had a significance on the target variable therefore, only specific columns were included. \nRegression required only discrete-valued data.\nK-modes required only categorical data.  \n* Preprocessing\nPreprocessing is a data mining technique which essentially, prepares data before it is fed into an algorithm. When data is sourced, it may have several bad or inconsistent entries which will adversely impact the outcome of the algorithm. Data must first be cleaned up to ensure we achieve the best results. For our preprocessing, we ensured that there are no null values or bad data before conducting our algorithms. Also, we transformed the ‘Total_Charges’ column to float, as it was being recognized as an object, which would hinder us from doing any form of operations to it. \n* Transformation\nData Transformation is defined as the process of transforming data into appropriate form required by mining procedure. Data may need to be changed into different forms in order to work properly with certain algorithms. There are two main types of variable, categorical and numerical. Categorical data has sub-types: dichotomous, discrete, nominal and may be ranked. Numerical data is continuous. Firstly, all Yes/No variables were transformed to 1/0 as it better suited the algorithms selected. \n The dataset had mostly categorical data and the data was transformed to ensure that the dataset had uniform discrete data. We then dropped the the variables that according to our analysis were unimportant these were, : 'StreamingTV_No internet service', 'StreamingMovies_No internet service', ‘gender’, ‘class’, ‘customerID’, 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport' and 'PaymentMethod'.\nFor the K-Modes algorithm the columns 'TotalCharges', 'tenure' and 'MonthlyCharges' were dropped because these were continuous numerical data and K-Modes clustering deals with only categorical data. \nNo transformation was required for the decision tree as the data was already in a suitable form.\n* Data Mining\nThrough reading and understanding, data mining is the process of using clever techniques for analyzing and extracting useful  hidden patterns of data according to different perspectives for categorization into useful information. Our dataset consisted of both categorical and numerical data. Additionally, it also consisted of a target variable (Churn rate) therefore we had the opportunity to utilize both supervised and unsupervised machine learning algorithms to analyze and extract patterns and also make predictions using dependent and independent variables. Supervised learning is typically done in the context of classification, when we want to map input to output labels, or regression, when we want to map input to a continuous output. We utilized two (2) supervised algorithm, namely logistic regression and Decision tree. On the other hand, the most common tasks within unsupervised learning are clustering and we used just one algorithm:K-Modes to display this. \n* Supervised Learning\nThe decision tree algorithm used in our project firstly required the several of the dataset columns to be transformed into  numerical data. This was achieved using the python function called lambda. This newly transformed data now was able to be placed in a decision tree which allowed us to analyze the if-then-else structure to determine the sequence/reasons that might affect a customer’s decision to churn. \nThe logistic regression used in our project was implemented because we as a group of aspiring data scientists decided it was important to know if we could possibly use the existing data by identifying patterns and extracting knowledge in order to make future predictions. Again, the data was transformed and the newly transformed dataset was used to train and test and produced a confusion matrix and regression graph which allowed us to make interpretations and evaluations. \n* Unsupervised Learning\nDuring this stage of the KDD process, clustering categorical data is an important research technique in data mining in order to provide insights, understand and provide evaluations and interpretations. This algorithm was used to see what groups of clusters of customers was churning the most and to see what were the common values for the different features among them. \nInterpretation/Evaluation\nBased on the logistic regression algorithm, we were able to create a confusion matrix and the results from the confusion matrix told us that 1404 and 265 are the number of correct predictions. 151 and 290 are the number of incorrect predictions.Consequently, we had a classification rate of 80%, and we considered that  as a good accuracy because we could predict future trends based on the patterns we identified in this dataset. \nAdditionally, the decision tree provided insights on the reasons why a customer may decide to churn. We saw that using the if-then-else structure, if a customer’s tenure is less than or is equal to 17.5 AND their monthly charges are greater than approximately 69 dollars then they will definitely churn. In summary, the algorithms with their specific functions helped to answer the aim of the project which was to determine the reasons why a customer may churn. \n"},{"metadata":{"trusted":true,"_uuid":"edf09a3ad9dcfa69edbf68f406618ec16c185647"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}