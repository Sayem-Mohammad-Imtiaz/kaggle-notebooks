{"cells":[{"metadata":{},"cell_type":"markdown","source":"### In this notebook I'm using train dataset only. In this case the dataset is being splitted into train and test in order to evalue model prediction output. The key idea is to compare the known results of classification test dataset with machine learning (ML) model prediction as a way to guarantee generalization of model  "},{"metadata":{},"cell_type":"markdown","source":"### Step 1: Data set import"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/titanic-machine-learning-from-disaster/train.csv\")\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"############################## DESCRIPTION OF DATASET (TRAIN) ##############################\")\nprint(df_train.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 3: Checking age distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (11,7))\nsns.distplot(x = df_train[\"Age\"], axlabel = \"Age_train\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Mean of age on training training: \", df_train[\"Age\"].mean())\nprint(\"Median of age on training dataset: \", df_train[\"Age\"].median())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 4: Fill missing values of age for the median"},{"metadata":{"trusted":true},"cell_type":"code","source":"median_train    = df_train[\"Age\"].median()\ndf_train[\"Age\"] = df_train[\"Age\"].fillna(median_train)     ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 5: Checking Target proportion"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 7))\nsns.countplot(data = df_train, x = \"Survived\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An interesting point in this variable is the proportion of survived and not survived is considerable. For ML model this might be a problem "},{"metadata":{},"cell_type":"markdown","source":"### Step 5: Proportion of classifications in each classificatory variable "},{"metadata":{"trusted":true},"cell_type":"code","source":"class_var = [\"Pclass\", \"Sex\", \"Embarked\", \"SibSp\", \"Parch\"]\n\nn = 1\nm = 5\n\nfig, ax = plt.subplots(n, m, figsize = (18, 7))\n\nfor i, ax in enumerate(fig.axes):\n    sns.countplot(data = df_train, x = class_var[i], ax = ax)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 6: Evaluation of possible correlations between independent variables and Target"},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 1\nm = 5\n\nfig, ax = plt.subplots(n, m, figsize = (18, 7))\nhue = [\"Sex\", \"Pclass\", \"Embarked\", \"SibSp\", \"Parch\"]\n\nfor i, ax in enumerate(fig.axes):\n    sns.countplot(x = \"Survived\", hue = hue[i], data = df_train, ax = ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These graphics are a good form to see possibles correlations between the independet variables and the target. The first one shows that sex is an important variable to distinguish who is going to survived or not. The difference in amount of male not survived and survived is remarkable. In the same way for female. "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize = (15, 7))\ncolumns = [\"Age\", \"Fare\"]\n\nfor i, ax in enumerate(fig.axes):\n    sns.boxplot(x = \"Survived\", y = columns[i], data = df_train, ax = ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another import conclusion that was possibled to concluded is the average of age is almost the same for survived or not survived. "},{"metadata":{},"cell_type":"markdown","source":"### Step 7: Evaluation of possible correlations among independent variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15, 7))\nsns.boxplot(x = \"Pclass\", y = \"Fare\", data = df_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 8: Machine learning model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV\n\n#-------------------------------- Categorical into numerical variable -------------------------------#\ndf_train[\"new_Sex\"] = df_train[\"Sex\"].map({\"female\": 0, \"male\": 1})\n\nnames = [\"Pclass\", \"new_Sex\", \"Fare\"]\n\n#---------------------- Erasing missing values for Embarked ---------------------#\nnew_df = df_train[names]\ntarget = df_train[\"Survived\"]\n\n\n#--------------------Split dataset into train and test--------------------------#\nx_train, x_test, y_train, y_test = train_test_split(new_df, target,\n                                                   test_size= 0.3, random_state= 111)\n\n#------------------------------ Model adjust ------------------------------------#\nRFC = RandomForestClassifier(n_estimators = 100, max_depth = 5, criterion = \"entropy\",\n                            random_state = 10)\n\n\nmodel = RFC.fit(x_train, y_train)\n\n\n#-------------------- Prediction with train dataset -----------------------------#\nprev_train = model.predict(x_train)\n\n#-------------------- Prediction with test dataset -----------------------------#\nprev_test = model.predict(x_test)\n\n#---------------------- Train dataset accuracy ----------------------------#\naccur_train = accuracy_score(y_train, prev_train)\n\n#---------------------- Test dataset accuracy ----------------------------#\naccur_test = accuracy_score(y_test, prev_test)\n\n#---------------------- Train dataset confusion matrix ----------------------------#\nmatrix_train = confusion_matrix(y_train, prev_train)\n\n#---------------------- Test dataset confusion matrix ----------------------------#\nmatrix_test = confusion_matrix(y_test, prev_test)\n\n\nprint(\"Accuracy in train dataset: \", accur_train)\nprint(\"###################### Confusion Matrix (train) #########################\")\nprint(matrix_train)\n\nprint(\"\")\nprint(\"Accuracy in test dataset: \", accur_test)\nprint(\"###################### Confusion Matrix (test) #########################\")\nprint(matrix_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The metrics of train and test dataset are almost similar. This is a good indicative that model is generalizating. But it still can be better. "},{"metadata":{},"cell_type":"markdown","source":"### Step 9: Balancing Target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTEN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oversample = SMOTEN()\nx, y = oversample.fit_resample(new_df, target)\n\nplt.figure(figsize = (12, 7))\nsns.countplot(x = y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 8: Machine learning model with balacend data train"},{"metadata":{"trusted":true},"cell_type":"code","source":"#---------------------- Erasing missing values for Embarked ---------------------#\nnew_df = x\ntarget = y\n\n\n#--------------------Separando dados de treino e teste--------------------------#\nx_train, x_test, y_train, y_test = train_test_split(new_df, target,\n                                                   test_size= 0.3, random_state= 111)\n\n#------------------------------ Model adjust ------------------------------------#\nRFC = RandomForestClassifier(criterion = \"entropy\", \n                             random_state = 0)\n\nmodel = RFC.fit(x_train, y_train)\n\n\n#-------------------- Prediction with train dataset -----------------------------#\nprev_train = model.predict(x_train)\n\n#-------------------- Prediction with test dataset -----------------------------#\nprev_test = model.predict(x_test)\n\n#---------------------- Train dataset accuracy ----------------------------#\naccur_train = accuracy_score(y_train, prev_train)\n\n#---------------------- Test dataset accuracy ----------------------------#\naccur_test = accuracy_score(y_test, prev_test)\n\n#---------------------- Train dataset confusion matrix ----------------------------#\nmatrix_train = confusion_matrix(y_train, prev_train)\n\n#---------------------- Test dataset confusion matrix ----------------------------#\nmatrix_test = confusion_matrix(y_test, prev_test)\n\n\nprint(\"Accuracy in train dataset: \", accur_train)\nprint(\"###################### Confusion Matrix (train) #########################\")\nprint(matrix_train)\n\nprint(\"\")\nprint(\"Accuracy in test dataset: \", accur_test)\nprint(\"###################### Confusion Matrix (test) #########################\")\nprint(matrix_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}