{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom xgboost import XGBRegressor\nfrom sklearn.impute import SimpleImputer\nfrom pandas.api.types import CategoricalDtype\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\nfrom category_encoders import MEstimateEncoder\nfrom sklearn.cluster import KMeans","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data():\n    df_train = pd.read_csv('../input/house-prices-dataset/train.csv', index_col='Id')\n    df_test = pd.read_csv(\"../input/house-prices-dataset/test.csv\", index_col=\"Id\")\n    # Merge the splits so we can process them together\n    df = pd.concat([df_train, df_test])\n    # Preprocessing\n    df = clean(df)\n    df = encode(df)\n    df = impute(df)\n    df = label_encode(df)\n    # Reform splits\n    df_train = df.loc[df_train.index, :]\n    df_test = df.loc[df_test.index, :]\n    return df_train, df_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def score_dataset(X,y,model=XGBRegressor()):\n    log_y = np.log(y)\n    score = cross_val_score(model, X, log_y, cv=5, scoring='neg_mean_squared_error')\n    score = -1 * score.mean()\n    score = np.sqrt(score)\n    return score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean(df):\n    # Names beginning with numbers are awkward to work with\n    df.rename(columns={\n        \"1stFlrSF\": \"FirstFlrSF\",\n        \"2ndFlrSF\": \"SecondFlrSF\",\n        \"3SsnPorch\": \"Threeseasonporch\",\n    },inplace=True,\n    )\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Сделаем encoding всех categorical feature, то есть точно определим тип feature,\nпоскольку, например, \"MSSubClass\" Pandas читает как int, хотя на самом деле это категории","metadata":{}},{"cell_type":"code","source":"# The nominative (unordered) categorical features\nfeatures_nom = [\"MSSubClass\", \"MSZoning\", \"Street\", \"Alley\", \"LandContour\", \"LotConfig\",\n                \"Condition1\", \"Condition2\", \"BldgType\", \"HouseStyle\", \n                \"RoofStyle\", \"RoofMatl\", \"MasVnrType\", \n                \"Foundation\", \"Heating\", \"CentralAir\", \"GarageType\", \"MiscFeature\", \n                \"SaleType\", \"SaleCondition\", 'Neighborhood', 'Exterior1st', 'Exterior2nd']\n\n# The ordinal (ordered) categorical features \n\n# Pandas calls the categories \"levels\"\nfive_levels = [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\nten_levels = list(range(10))\n\nordered_levels = {\n    \"OverallQual\": ten_levels,\n    \"OverallCond\": ten_levels,\n    \"ExterQual\": five_levels,\n    \"ExterCond\": five_levels,\n    \"BsmtQual\": five_levels,\n    \"BsmtCond\": five_levels,\n    \"HeatingQC\": five_levels,\n    \"KitchenQual\": five_levels,\n    \"FireplaceQu\": five_levels,\n    \"GarageQual\": five_levels,\n    \"GarageCond\": five_levels,\n    \"PoolQC\": five_levels,\n    \"LotShape\": [\"Reg\", \"IR1\", \"IR2\", \"IR3\"],\n    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n    \"BsmtExposure\": [\"No\", \"Mn\", \"Av\", \"Gd\"],\n    \"BsmtFinType1\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"BsmtFinType2\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n    \"Functional\": [\"Sal\", \"Sev\", \"Maj1\", \"Maj2\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n    \"GarageFinish\": [\"Unf\", \"RFn\", \"Fin\"],\n    \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n    \"Utilities\": [\"NoSeWa\", \"NoSewr\", \"AllPub\"],\n    \"CentralAir\": [\"N\", \"Y\"],\n    \"Electrical\": [\"Mix\", \"FuseP\", \"FuseF\", \"FuseA\", \"SBrkr\"],\n    \"Fence\": [\"MnWw\", \"GdWo\", \"MnPrv\", \"GdPrv\"],\n}\n\n# Add a None level for missing values\nordered_levels = {key: [\"None\"] + value for key, value in\n                  ordered_levels.items()}\n\n\ndef encode(df):\n    # Nominal categories\n    for name in features_nom:\n        df[name] = df[name].astype(\"category\")\n        # Add a None category for missing values\n        if \"None\" not in df[name].cat.categories:\n            df[name].cat.add_categories(\"None\", inplace=True)\n    # Ordinal categories\n    for name, levels in ordered_levels.items():\n        df[name] = df[name].astype(CategoricalDtype(levels,\n                                                    ordered=True))\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def impute(df):\n    for name in df.select_dtypes(\"number\"):\n        df[name] = df[name].fillna(0)\n    for name in df.select_dtypes(\"category\"):\n        df[name] = df[name].fillna(\"None\")\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Заполним значения NaN  с помощью SimpleImputer()","metadata":{}},{"cell_type":"code","source":"def simple_imputer(df):\n    my_imputer = SimpleImputer()\n    imputed_df = pd.DataFrame(my_imputer.fit_transform(df))\n    imputed_df.columns = df.columns\n    return imputed_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A label encoding is okay for any kind of categorical feature when you're using a tree-ensemble like XGBoost, even for unordered categories.","metadata":{}},{"cell_type":"code","source":"def label_encode(df):\n    X = df.copy()\n    for colname in X.select_dtypes([\"category\"]):\n        X[colname] = X[colname].cat.codes\n    return X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train, df_test = load_data()\nX_train = df_train.copy()\ny_train = X_train.pop('SalePrice')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_score = score_dataset(X_train, y_train)\nprint(f'Score: {base_score: .5f} RMSLE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Нужно сделать feature engeneering.\n- Удалить features которые не несут важной информации (mutual information)\n- Добавить нужные features\n- K-means, PCA","metadata":{}},{"cell_type":"markdown","source":"Посчитаем mutual information ","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_regression\n\n\ndef make_mi_scores(X,y):\n    discrete_features = X.dtypes == int\n    mi_scores = mutual_info_regression(X,y,discrete_features=discrete_features)\n    mi_scores = pd.Series(mi_scores, name='MI Scores', index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=True)\n    return mi_scores\n\ndef plot_mi_scores(scores):\n    scores = scores.sort_values(ascending=True)\n    width = np.arange(len(scores))\n    ticks = list(scores.index)\n    plt.barh(width, scores)\n    plt.yticks(width, ticks)\n    plt.title(\"Mutual Information Scores\")\n\nmi_scores = make_mi_scores(X_train, y_train)\nplot_mi_scores(mi_scores[-10:])\nmi_scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Drop uninformative features","metadata":{}},{"cell_type":"code","source":"def drop_uninformative(X, mi_scores):\n    X_drop = X.loc[:, mi_scores > 0.0]\n    X_drop[\"Threeseasonporch\"] = X[\"Threeseasonporch\"]\n    return X_drop\n\ndrop_X_train = drop_uninformative(X_train, mi_scores)\nscore = score_dataset(drop_X_train,y_train)\nprint(f'Score: {score: .5f} RMSLE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create new features","metadata":{}},{"cell_type":"code","source":"def mathematical_transform(df):\n    X = pd.DataFrame()\n    # отношение надземной жилой площади к общей\n    X['LivLotRatio'] = df.GrLivArea / df.LotArea\n    # отношение площади на первом и втором этажах к кол-ву комнат (не включая ванные комнаты)\n    X['Spaciousness'] = (df.FirstFlrSF + df.SecondFlrSF) / df.TotRmsAbvGrd\n    # общая внешняя площадь\n#     X[\"TotalOutsideSF\"] = df.WoodDeckSF + df.OpenPorchSF + df.EnclosedPorch + df.Threeseasonporch + df.ScreenPorch\n    X['QualCond'] = df.OverallQual * df.OverallCond\n    return X\n\ndef interactions(df):\n    X = pd.get_dummies(df.BldgType, prefix='Bldg')\n    X = X.mul(df.GrLivArea, axis=0)\n    return X\n\ndef interactions_1(df):\n    X = pd.get_dummies(df.BsmtQual, prefix='Bsmt')\n    X = X.mul(df.TotalBsmtSF, axis=0)\n    return X\n\ndef counts(df):\n    X = pd.DataFrame()\n    X['PorchTypes'] = df[[\n        \"WoodDeckSF\",\n        \"OpenPorchSF\",\n        \"EnclosedPorch\",\n        \"Threeseasonporch\",\n        \"ScreenPorch\",\n    ]].gt(0.0).sum(axis=1)\n    return X\n\ndef group_transforms(df):\n    X = pd.DataFrame()\n    X['MedNhbdArea'] = df.groupby('Neighborhood')['GrLivArea'].transform('median')\n    return X\n\ndef sqrt_area(X):\n    X_new = X.copy()\n    features = ['LotArea', 'BsmtUnfSF', 'TotalBsmtSF', 'FirstFlrSF', 'SecondFlrSF',\n                'LowQualFinSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', \n                'EnclosedPorch', 'Threeseasonporch', 'ScreenPorch', 'PoolArea']\n    for feature in features:\n        X_new[feature] = X_new[feature].apply(np.sqrt)\n    return X_new\n\ndef log(X):\n    X_new = X.copy()\n    for feature in X.columns:\n        if X[feature].dtype=='float64' or X[feature].dtype=='int64':\n            X_new[feature] = X_new[feature].apply(np.log)\n    return X_new","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_math_transform(X):\n#     X = sqrt_area(X)\n#     X = log(X)\n    X = X.join(mathematical_transform(X))\n    X = X.join(interactions(X))\n#     X = X.join(interactions_1(X))\n    X = X.join(counts(X))\n    X = X.join(group_transforms(X))\n    \n    return X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_CF = create_math_transform(drop_X_train)\nscore = score_dataset(X_train_CF,y_train)\nprint(f'Score: {score: .5f} RMSLE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# K-means Clustering","metadata":{}},{"cell_type":"code","source":"cluster_features = [\n    \"LotArea\",\n    \"TotalBsmtSF\",\n    \"FirstFlrSF\",\n    \"SecondFlrSF\",\n    \"GrLivArea\",\n]\n\ndef cluster_labels(df, features, n_clusters=20):\n    X = df.copy()\n    X_scaled = X.loc[:, features]\n    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0)\n    X_new = pd.DataFrame()\n    X_new['Cluster'] = kmeans.fit_predict(X_scaled)\n    return X_new\n\ndef cluster_distance(df, features, n_clusters=20):\n    X = df.copy()\n    X_scaled = X.loc[:, features]\n    X_scaled = (X_scaled-X_scaled.mean(axis=0))/X_scaled.std(axis=0)\n    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0)\n    X_cd = kmeans.fit_transform(X_scaled)\n    X_cd = pd.DataFrame(X_cd, columns=[f\"Centroid_{i}\" for i in range(X_cd.shape[1])])\n    return X_cd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PCA (Principal Component analysis)","metadata":{}},{"cell_type":"code","source":"def apply_pca(X, standardize=True):\n    if standardize:\n        X = (X-X.mean(axis=0)) / X.std(axis=0)\n        pca = PCA()\n        X_pca = pca.fit_transform(X)\n        component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n        X_pca = pd.DataFrame(X_pca, columns=component_names)\n        loadings = pd.DataFrame(pca.components_.T, columns=component_names, index=\n                               X.columns)\n        return pca, X_pca, loadings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pca_inspired(df):\n    X = pd.DataFrame()\n    X['Feature1'] = df.GrLivArea + df.TotalBsmtSF\n    X['Feature2'] = df.YearRemodAdd * df.TotalBsmtSF\n    return X\n\ndef pca_components(df, features):\n    X = df.loc[:, features]\n    _, X_pca, _ = apply_pca(X)\n    return X_pca\n\npca_features = [\n    \"GarageArea\",\n    \"YearRemodAdd\",\n    \"TotalBsmtSF\",\n    \"GrLivArea\",\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def corrplot(df, method=\"pearson\", annot=True, **kwargs):\n    sns.clustermap(\n        df.corr(method),\n        vmin=-1.0,\n        vmax=1.0,\n        cmap=\"icefire\",\n        method=\"complete\",\n        annot=annot,\n        **kwargs,\n    )\n\n\ncorrplot(X_train, annot=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def indicate_outliers(df):\n    X_new = pd.DataFrame()\n    X_new['Outlier'] = (df.Neighborhood == 'Edwards') & (df.SaleCondition == 'Partial')\n    return X_new","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create final features","metadata":{}},{"cell_type":"code","source":"def create_features(df, df_test=None):\n    X = df.copy()\n    y = X.pop(\"SalePrice\")\n    mi_scores = make_mi_scores(X, y)\n\n    if df_test is not None:\n        X_test = df_test.copy()\n        X_test.pop(\"SalePrice\")\n        X = pd.concat([X, X_test])\n\n\n    X = drop_uninformative(X, mi_scores)\n    X = create_math_transform(X)\n\n    X = X.join(cluster_labels(X, cluster_features, n_clusters=20))\n#     X = X.join(cluster_distance(X, cluster_features, n_clusters=20))\n\n    X = X.join(pca_inspired(X))\n#     X = X.join(pca_components(X, pca_features))\n    X = X.join(indicate_outliers(X))\n\n\n    # Reform splits\n    if df_test is not None:\n        X_test = X.loc[df_test.index, :]\n        X.drop(df_test.index, inplace=True)\n\n    if df_test is not None:\n        return X, X_test\n    else:\n        return X\n\n\ndf_train, df_test = load_data()\nX_train = create_features(df_train)\ny_train = df_train.loc[:, \"SalePrice\"]\n\nscore_dataset(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tune hyperparameters","metadata":{}},{"cell_type":"code","source":"X_train = create_features(df_train)\ny_train = df_train.loc[:, \"SalePrice\"]\n\nxgb_params = dict(\n    max_depth=6,           # maximum depth of each tree - try 2 to 10\n    learning_rate=0.01,    # effect of each tree - try 0.0001 to 0.1\n    n_estimators=1000,     # number of trees (that is, boosting rounds) - try 1000 to 8000\n    min_child_weight=1,    # minimum number of houses in a leaf - try 1 to 10\n    colsample_bytree=0.7,  # fraction of features (columns) per tree - try 0.2 to 1.0\n    subsample=0.7,         # fraction of instances (rows) per tree - try 0.2 to 1.0\n    reg_alpha=0.5,         # L1 regularization (like LASSO) - try 0.0 to 10.0\n    reg_lambda=1.0,        # L2 regularization (like Ridge) - try 0.0 to 10.0\n    num_parallel_tree=1,   # set > 1 for boosted random forests\n)\n\nxgb = XGBRegressor(**xgb_params)\nscore_dataset(X_train, y_train, xgb)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create submissions","metadata":{}},{"cell_type":"code","source":"X_train, X_test = create_features(df_train, df_test)\ny_train = df_train.loc[:, \"SalePrice\"]\n\nxgb = XGBRegressor(**xgb_params)\nxgb.fit(X_train, np.log(y_train))\npredictions = np.exp(xgb.predict(X_test))\n\noutput = pd.DataFrame({'Id': X_test.index, 'SalePrice': predictions})\noutput.to_csv('my_submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}