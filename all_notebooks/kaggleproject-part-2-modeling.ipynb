{"cells":[{"metadata":{},"cell_type":"markdown","source":"----------\n**Kaggle Mini-Project II: Modeling**\n=====================================\nMaggie Maurer\n\nCoderGirl, DataScience Cohort\n\nJuly 2019\n\n----------"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"- <a href=''>Statistics Review</a>  \n- <a href='#1'>1. Libraries and Data</a>  \n    - <a href='#1.1'>1.1. Loding Libraries</a> \n    - <a href='#1.2'>1.2. Reading and Cleaning Data</a>\n- <a href='#2'>2. Paired T-Test</a>  \n- <a href='#3'>3. Machiene Learning Preprocessing</a>  \n    - <a href='#3.1'>3.1. One Hot Encoding/ Splitting Dependent and Independent Variables</a> \n    - <a href='#3.2'>3.2. Scale the Data</a> \n    - <a href='#3.3'>3.3. Train/Test Split</a>    \n- <a href='#4'>4. Supervised Learning</a>  \n    - <a href='#4.1'>4.1. Logistic Regression</a> \n    - <a href='#4.2'>4.2. K-Nearest Neighbors</a> \n    - <a href='#4.3'>4.3. Decision Tree</a>\n    - <a href='#4.4'>4.4. AdaBoost with Decision Tree Base</a> \n    - <a href='#4.5'>4.5. Random Forest</a>     \n    - <a href='#4.6'>4.6. XGBoost</a> \n- <a href=‘#5’>5. Comparing the Models</a>  \n    - <a href=‘#5.1’>5.1. Assesing the Model of Best Fit</a> \n- <a id=‘#6’>6. Note About One Hot Encoding</a> "},{"metadata":{},"cell_type":"markdown","source":"# <a id=''>Statistics Review</a> "},{"metadata":{"_kg_hide-input":true,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#Data Analysis Libraries\nimport numpy as np\nimport pandas as pd\nfrom pandas import Series,DataFrame\nfrom scipy import stats\nimport statistics as st\nimport math\nimport os\nfrom datetime import datetime\n\n#Visualization Libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(color_codes=True)\nfrom IPython.display import HTML\nfrom IPython.display import display\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\ninit_notebook_mode(connected = True)\n%matplotlib inline\nfrom IPython.core.display import HTML\ndef multi_table(table_list):\n    ''' Acceps a list of IpyTable objects and returns a table which contains each IpyTable in a cell\n    '''\n    return HTML(\n        '<table><tr style=\"background-color:white;\">' + \n        ''.join(['<td>' + table._repr_html_() + '</td>' for table in table_list]) +\n        '</tr></table>'\n    )\n\n#sklearn\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, roc_auc_score, auc, accuracy_score,confusion_matrix, classification_report, confusion_matrix, jaccard_similarity_score, f1_score, fbeta_score\n\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler, Imputer,MinMaxScaler\n\nfrom sklearn import model_selection\nfrom sklearn.model_selection import GridSearchCV,train_test_split,cross_val_score, validation_curve, RandomizedSearchCV, cross_val_predict\n\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\n\nfrom sklearn import naive_bayes\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn import neighbors\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn import ensemble\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostRegressor\n\nfrom sklearn.svm import SVC\n\nfrom sklearn.ensemble import AdaBoostClassifier\n\nfrom sklearn import datasets\n\n#misc\nfrom functools import singledispatch\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nimport shap\nfrom mpl_toolkits.mplot3d import Axes3D\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nprint(os.listdir(\"../input\"))\nimport itertools\nfrom xgboost import XGBClassifier\n\nheart = pd.read_csv(\"../input/heart.csv\")\nheart2= heart.drop(heart.index[164])\n\nheart2.columns=['age', 'sex', 'cpain','resting_BP', 'chol', 'fasting_BS', 'resting_EKG', \n                'max_HR', 'exercise_ANG', 'ST_depression', 'm_exercise_ST', 'no_maj_vessels', 'thal', 'target']\n\nheart2['chol']=heart2['chol'].replace([417, 564], 240)\nheart2['chol']=heart2['chol'].replace([407, 409], 249)\n\nheart2['ST_depressionAB']=heart2['ST_depression'].apply(lambda row: 1 if row > 0 else 0)\nheart2A=heart2.iloc[:,0:11]\nheart2B=heart2.iloc[:,11:14]\nheart2C=heart2.loc[:,'ST_depressionAB']\nheart2C=pd.DataFrame(heart2C)\nheart2C.head()\nheart2 = pd.concat([heart2A, heart2C, heart2B], axis=1, join_axes=[heart2A.index])\n\nheart2.loc[48, 'thal']=2.0\nheart2.loc[281, 'thal']=3.0\n\n#seperate independent (feature) and dependent (target) variables\n#KNN cannot process text/ categorical data unless they are be converted to numbers\n#For this reason I did not input the heart3 DataFrame created above\nX=heart2.drop('target',1)\ny=heart2.loc[:,'target']\n\n#Scale the data\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n#Split the data into training and testing sets\nX_train,X_test,y_train,y_test = train_test_split(X_scaled, y,test_size=.2,random_state=40)\n\n#Call classifier and, using GridSearchCV, find the best parameters\nknn = KNeighborsClassifier()\nparams = {'n_neighbors':[i for i in range(1,33,2)]}\nmodelKNN = GridSearchCV(knn,params,cv=10)\nmodelKNN.fit(X_train,y_train)\nmodelKNN.best_params_   \n\n#Use the above model (modelKNN) to predict the y values corresponding to the X testing set\npredictKNN = modelKNN.predict(X_test)\n\n#Compare the results of the model's predictions (predictKNN) to the actual y values\naccscoreKNN=accuracy_score(y_test,predictKNN)\n\nimport warnings\n\ndef fxn():\n    warnings.warn(\"deprecated\", DeprecationWarning)\n\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    fxn()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id=''>Confusion Matricies</a> "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"conf_matrixKNN = confusion_matrix(y_test,predictKNN)\n\nprint('Confusion Matrix:\\n{}\\n'.format(conf_matrixKNN))\nprint('True Positive:\\t{}'.format(conf_matrixKNN[1,1]))\nprint('True Negative:\\t{}'.format(conf_matrixKNN[0,0]))\nprint('False Positive:\\t{}'.format(conf_matrixKNN[0,1]))\nprint('False Negative:\\t{}'.format(conf_matrixKNN[1,0]))\n\nclass_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(conf_matrixKNN), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for K-Nearest Neighbors Model', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A confusion matrix shows how many correctly predicted values there were, as well as how many incorrectly predicted.  The incorrectly predicted values are split into False Positives and False Negatives.\n\n* False Positives are where the model predicted a target value of 1 (prescence of Heart Disease), but the patient was not diagnosed with Heart Disease in real life\n* False Positives are where the model predicted a target value of 0 (absence of Heart Disease), but the patient was diagnosed with Heart Disease in real life\n\nThis model is pretty accurate.  \nIt gives 3 False Positives and 1 False Negative.\n\nLet's look at the Sensitivity and Specificity\n\n\\begin{align}\nSensitivity = \\frac{True\\:Positives}{True\\:Positives + False\\:Negatives}\n\\end{align}\n\n\\begin{align}\nSpecificity = \\frac{True\\:Negatives}{True\\:Negatives + False\\:Positives}\n\\end{align}\n\n\n\nThe closer the Sensitivity and Specificity are to 1, the better fit the model is."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"total=sum(sum(conf_matrixKNN))\n\nsensitivityKNN = conf_matrixKNN[1,1]/(conf_matrixKNN[1,1]+conf_matrixKNN[1,0])\nprint('Sensitivity : ', sensitivityKNN)\n\nspecificityKNN = conf_matrixKNN[0,0]/(conf_matrixKNN[0,0]+conf_matrixKNN[0,1])\nprint('Specificity : ', specificityKNN)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id=‘#’>F1 Score</a>"},{"metadata":{},"cell_type":"markdown","source":"The F1 score is a measure of how accurate a model is. It is determined by examining both the precision and recall of the model.  \n\n* Precision is the number of correct positive results divided by the number of all positive results\n\n\\begin{align}\nPrecision = \\frac{True\\:Positives}{True\\:Positives + False\\:Positives}\n\\end{align}\n\n\n* Recall is the number of correct positive results divided by the number of positive results that should have been returned, had the model been 100% accurate\n\n\\begin{align}\nRecall = \\frac{True\\:Negatives}{True\\:Positives + False\\:Negatives}\n\\end{align}\n\n* The F1 score:\n\n\\begin{align}\nF1 = 2* \\frac{Precision * Recall}{Precision + Recall}\n\\end{align}\n\nThe F1 score of my KNN model is as follows:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"KNNF1=metrics.f1_score(y_test,predictKNN)\nprint(classification_report(y_test,predictKNN))\nprint(\"F1 Score:\" ,round((100*KNNF1),2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"F1 score is quite high for this model, incidating that this model is highly accurate."},{"metadata":{},"cell_type":"markdown","source":"## <a id=‘#’>Reciever Operator Curve and the Area Under the Curve</a>"},{"metadata":{},"cell_type":"markdown","source":"The area under the ROC curve ( AUC ) is a measure of how well a model can distinguish between two diagnostic groups (diseased/normal).\n\nAUC can be generally classed as follows:\n\n* 0.90 - 1.00 = excellent\n* 0.80 - 0.90 = good\n* 0.70 - 0.80 = fair\n* 0.60 - 0.70 = poor\n* 0.50 - 0.60 = fail\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"predictKNN_quant = modelKNN.predict_proba(X_test)[:, 1]\n\nfprKNN, tprKNN, thresholds = roc_curve(y_test, predictKNN_quant)\n\nfig, ax = plt.subplots()\nax.plot(fprKNN, tprKNN)\nax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC Curve for Heart Disease Classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)\n\naucKNN=auc(fprKNN, tprKNN)\nprint(\"Area under the curve:\", aucKNN)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nSo, the area under the curve indicates that this model can distinguish between those not diagnosis with Heart Disease and those diagnosed very well!"},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>Cross Validation and R2 Scores</a>"},{"metadata":{},"cell_type":"markdown","source":"The Train/Test Split function I will be using (and did use for this dummy model) does have it's danger.  For example, if the split is not random.  For example, if the split included all of most of the patients showing left ventricular hypertrophy it could cause out data to be overfit.\n\nOne way to fight overfitting it to use cross-validation and R2 scores.  In both of those measures, it reduces the potential bias and overfitting created from utilizing only one random seed.\n\nScikit learn's cross_val_score function returns mutliple cross validated accuracy scores.  I then took the mean of these scores to predict how accurate my model truley was. \n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"KNNscores = cross_val_score(modelKNN, X_scaled, y, cv=5)\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (KNNscores.mean(), KNNscores.std() * 2))\nprint ('Cross_validated scores:', KNNscores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I also examined the R2 score.  The R2 score is defined as the proportion of variance in the dependent variable that is predictable from the independent variables.  So, the closer to 1 the R2 value is, the better the model explains/predicts the variation in the data."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"KNNR2 = metrics.r2_score(y_test,predictKNN)\nprint ('R2:', KNNR2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Neither the cross validation, nor the R2 score are amazing.  The cross validation score show that some of the accuracy in the model is due to likely due to overfitting/ bias created from the train/test split action.\n\nKeep these statistical test in mind as I run through the Machiene Learning algorithms below!"},{"metadata":{},"cell_type":"markdown","source":"# <a id='1'>1. Librairies and data</a> "},{"metadata":{},"cell_type":"markdown","source":"## <a id='1.1'>1.1. Loading libraries</a> "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Analysis Libraries\nimport numpy as np\nimport pandas as pd\nfrom pandas import Series,DataFrame\nfrom scipy import stats\nimport statistics as st\nimport math\nimport os\nfrom datetime import datetime\n\n#Visualization Libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(color_codes=True)\nfrom IPython.display import HTML\nfrom IPython.display import display\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\ninit_notebook_mode(connected = True)\n%matplotlib inline\nfrom IPython.core.display import HTML\ndef multi_table(table_list):\n    ''' Acceps a list of IpyTable objects and returns a table which contains each IpyTable in a cell\n    '''\n    return HTML(\n        '<table><tr style=\"background-color:white;\">' + \n        ''.join(['<td>' + table._repr_html_() + '</td>' for table in table_list]) +\n        '</tr></table>'\n    )\n\n#sklearn\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, roc_auc_score, auc, accuracy_score,confusion_matrix, classification_report, confusion_matrix, jaccard_similarity_score, f1_score, fbeta_score\n\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler, Imputer,MinMaxScaler\n\nfrom sklearn import model_selection\nfrom sklearn.model_selection import GridSearchCV,train_test_split,cross_val_score, validation_curve, RandomizedSearchCV, cross_val_predict\n\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\n\nfrom sklearn import naive_bayes\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn import neighbors\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn import ensemble\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostRegressor\n\nfrom sklearn.svm import SVC\n\nfrom sklearn.ensemble import AdaBoostClassifier\n\nfrom sklearn import datasets\n\n#misc\nfrom functools import singledispatch\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nimport shap\nfrom mpl_toolkits.mplot3d import Axes3D\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nprint(os.listdir(\"../input\"))\nimport itertools\nfrom xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='1.2'>1.2. Reading and Cleaning Data</a> "},{"metadata":{"trusted":true},"cell_type":"code","source":"heart = pd.read_csv(\"../input/heart.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Change DataFrame to match preprocessing changes made in [Part 1](https://www.kaggle.com/maurerm/kaggleproject-part-1-exploratory-data-analysis) of this Kaggle Assignment."},{"metadata":{"trusted":true},"cell_type":"code","source":"heart2= heart.drop(heart.index[164])\n\nheart2.columns=['age', 'sex', 'cpain','resting_BP', 'chol', 'fasting_BS', 'resting_EKG', \n                'max_HR', 'exercise_ANG', 'ST_depression', 'm_exercise_ST', 'no_maj_vessels', 'thal', 'target']\n\nheart2['chol']=heart2['chol'].replace([417, 564], 240)\nheart2['chol']=heart2['chol'].replace([407, 409], 249)\n\nheart2['ST_depressionAB']=heart2['ST_depression'].apply(lambda row: 1 if row > 0 else 0)\nheart2A=heart2.iloc[:,0:11]\nheart2B=heart2.iloc[:,11:14]\nheart2C=heart2.loc[:,'ST_depressionAB']\nheart2C=pd.DataFrame(heart2C)\nheart2C.head()\nheart2 = pd.concat([heart2A, heart2C, heart2B], axis=1, join_axes=[heart2A.index])\n\nheart2.loc[48, 'thal']=2.0\nheart2.loc[281, 'thal']=3.0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='#2'>2. Paired T-Test</a> "},{"metadata":{},"cell_type":"markdown","source":"I am only going to run the paired T-Test on the quantitative features.  As the discrete feautes have, at maximum, 5 discrete values, comparing their means would not provide meaningful information.  "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"PHD=heart2.loc[heart2.loc[:,\"target\"]==1]\nAHD=heart2.loc[heart2.loc[:,\"target\"]==0]\n\nfrom scipy.stats import ttest_ind\ndef rowz(ttest): \n    name=ttest_ind(PHD[ttest], AHD[ttest])\n    name=list(name)\n    name = pd.DataFrame(np.array(name))\n    name=name.T\n    col=[\"t-statistic\", \"p_value\"]\n    name.columns=col\n    return name\n\nAGE=rowz('age')\nAGE.loc[:,\"Names\"]=\"Age\"\nRESTING_BP=rowz('resting_BP')\nRESTING_BP.loc[:,\"Names\"]=\"Resting_BP\"\nCHOLESTEROL=rowz('chol')\nCHOLESTEROL.loc[:,\"Names\"]=\"Cholesterol\"\nMAX_HR=rowz('max_HR')\nMAX_HR.loc[:,\"Names\"]=\"Max_HR\"\nST_DEP=rowz('ST_depression')\nST_DEP.loc[:,\"Names\"]=\"ST_Depression\"\n\nPVALS = pd.concat([AGE, RESTING_BP,CHOLESTEROL,MAX_HR, ST_DEP], axis=0)\nPVALS=PVALS.set_index(PVALS[\"Names\"])\nP_VALS= PVALS.drop('Names',axis=1)\n\nP_VALS","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, almost all of the p-values are significant (<0.05).\n* ST_Depression: 0.000000000000005815\n* Maximum Heart Rate: 0.00000000000002476\n* Age: 0.001039\n* Resting Blood Pressure: 0.010927\n\nThe only non-significant p-value is cholesterol (0.07985).\n\n\nThis means that for ST depression, maximum heart rate, age, and resting blood pressure there is less than a 5% chance that the differences between the target sample^ means could have occured by chance  alone.\n   \n   ^ Target Sample: Absence or presence of heart disease"},{"metadata":{},"cell_type":"markdown","source":"# <a id=‘#3’>3. Machiene Learning Preprocessing</a> "},{"metadata":{},"cell_type":"markdown","source":"## <a id='#3.1'>3.1. One Hot Encoding/ Splitting Dependent and Independent Variables</a>"},{"metadata":{},"cell_type":"markdown","source":"DataFrames must be preprocessed before they can be analyzed by Machiene Learning algorithms.  \n\nThis is because Machiene Learning algorithms cannot process text/ categorical data unless they have be converted to numbers.  For this reason I did not input the heart3 DataFrame created in Part 1 of the Kaggle Assignment.\n\nFurthermore, Machiene Learning Algorithms need the data to be split into the independent and dependant variable, as follows:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=heart2.drop('target',1)\ny=heart2.loc[:,'target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First 5 lines of the dataframe, X:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First 5 lines of y values (the target, prescence or absence of heart disease)"},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='#3.2'>3.2. Scale the Data</a> "},{"metadata":{},"cell_type":"markdown","source":"I scaled the data before splitting it because I don't want minute differences between the training and test set to be further amplified via scaling.\n\nScaling makes it so the fetures with large numbers/ a wide range of numbers do not adversely affect, or weigh, the model.  Without scaling, features like heart rate, which have values starting in the 70s, could be seen as more important than features with a smaller range, such as ST depression."},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='#3.3'>3.3. Train/Test Split</a> "},{"metadata":{},"cell_type":"markdown","source":"Sklearn's train_test_split randomly splits the dataset into training and testing subsets. The model then learns on the training set based on known output.  The test data is then used to evaluate the accuracy and precision of the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X_scaled,y,test_size=.3,random_state=40)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print ('Train set:  ', X_train.shape,  y_train.shape)\nprint ('Test set:   ', X_test.shape,  y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id=‘#4’>4. Supervised Learning</a> \n"},{"metadata":{},"cell_type":"markdown","source":"## <a id='#4.1'>4.1. Logistic Regression</a>"},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression (LR) is a classification-based machiene learning algorithm.  It attempts to learn the relationship between a set of feature variables and a target variable.   Specifically, LR tries to predict a discrete target field, such as 0 or 1, instead of a numeric one.  \n\nIn the dataset, the target attribute predicted is the presence (1) or absence (0) of heart disease."},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"#seperate independent (feature) and dependent (target) variables\n#KNN cannot process text/ categorical data unless they are be converted to numbers\n#For this reason I did not input the heart3 DataFrame created above\nX=heart2.drop('target',1)\ny=heart2.loc[:,'target']\n\n#Scale the data\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n#Split the data into training and testing sets\nX_train,X_test,y_train,y_test = train_test_split(X_scaled,y,test_size=.2,random_state=40)\n\n#Use the above model (modelKNN) to predict the y values corresponding to the X testing set\nLR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\ny_predictLR = LR.predict(X_test)\n\n#Compare the results of the model's predictions (predictKNN) to the actual y values\naccscoreLR=accuracy_score(y_test,y_predictLR)\nprint('Using Logistic Regression we get an accuracy score of: ',\n      round(accuracy_score(y_test,y_predictLR),5)*100,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>Logistic Regression: Confusion Matrix</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"conf_matrixLR = confusion_matrix(y_test, y_predictLR)\n\nprint('Confusion Matrix:\\n{}\\n'.format(conf_matrixLR))\nprint('True Positive:\\t{}'.format(conf_matrixLR[1,1]))\nprint('True Negative:\\t{}'.format(conf_matrixLR[0,0]))\nprint('False Positive:\\t{}'.format(conf_matrixLR[0,1]))\nprint('False Negative:\\t{}'.format(conf_matrixLR[1,0]))\n\nclass_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(conf_matrixLR), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for Logistic Regression Model Model', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>Logistic Regression: Sensitivity and Specificity</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"total=sum(sum(conf_matrixLR))\n\nspecificityLR = conf_matrixLR[0,0]/(conf_matrixLR[0,0]+conf_matrixLR[1,0])\nprint('Specificity : ', specificityLR)\n\nsensitivityLR = conf_matrixLR[1,1]/(conf_matrixLR[1,1]+conf_matrixLR[0,1])\nprint('Sensitivity : ', sensitivityLR )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>Logistic Regression: Reciever Operator Curve (ROC) and Area Under the Curve (AUC)</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"y_pred_quantLR = LR.predict_proba(X_test)[:, 1]\n\nfprLR, tprLR, thresholdsLR = roc_curve(y_test, y_pred_quantLR)\n\nfig, ax = plt.subplots()\nax.plot(fprLR, tprLR)\nax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC Curve for Heart Disease Classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"aucLR=auc(fprLR, tprLR)\nprint(\"Area under the curve:\", aucLR)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>Logistic Regression: Precsion, Recall, and F1</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"LRF1=metrics.f1_score(y_test,y_predictLR)\nprint(classification_report(y_test,y_predictLR))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>Logistic Regression: Cross Validation and R2 Scores</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"LRscores = cross_val_score(LR, X_scaled, y, cv=5)\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (LRscores.mean(), LRscores.std() * 2))\n\nLRR2 = metrics.r2_score(y_test,y_predictLR)\nprint ('R2:', LRR2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='#4.2'>4.2. K-Nearest Neighbors</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#seperate independent (feature) and dependent (target) variables\n#KNN cannot process text/ categorical data unless they are be converted to numbers\n#For this reason I did not input the heart3 DataFrame created above\nX=heart2.drop('target',1)\ny=heart2.loc[:,'target']\n\n#Scale the data\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n#Split the data into training and testing sets\nX_train,X_test,y_train,y_test = train_test_split(X_scaled, y,test_size=.2,random_state=40)\n\n#Call classifier and, using GridSearchCV, find the best parameters\nknn = KNeighborsClassifier()\nparams = {'n_neighbors':[i for i in range(1,33,2)]}\nmodelKNN = GridSearchCV(knn,params,cv=10)\nmodelKNN.fit(X_train,y_train)\nmodelKNN.best_params_   \n\n#Use the above model (modelKNN) to predict the y values corresponding to the X testing set\npredictKNN = modelKNN.predict(X_test)\n\n#Compare the results of the model's predictions (predictKNN) to the actual y values\naccscoreKNN=accuracy_score(y_test,predictKNN)\nprint('Accuracy Score: ',accuracy_score(y_test,predictKNN))\nprint('Using k-NN we get an accuracy score of: ',\n      round(accuracy_score(y_test,predictKNN),5)*100,'%')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>KNN: Confusion Matrix</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"conf_matrixKNN = confusion_matrix(y_test,predictKNN)\n\nprint('Confusion Matrix:\\n{}\\n'.format(conf_matrixKNN))\nprint('True Positive:\\t{}'.format(conf_matrixKNN[1,1]))\nprint('True Negative:\\t{}'.format(conf_matrixKNN[0,0]))\nprint('False Positive:\\t{}'.format(conf_matrixKNN[0,1]))\nprint('False Negative:\\t{}'.format(conf_matrixKNN[1,0]))\n\nclass_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(conf_matrixKNN), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for K-Nearest Neighbors Model', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>KNN: Sensitivity and Specificity</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"total=sum(sum(conf_matrixKNN))\n\nspecificityKNN = conf_matrixKNN[0,0]/(conf_matrixKNN[0,0]+conf_matrixKNN[1,0])\nprint('Specificity : ', specificityKNN)\n\nsensitivityKNN = conf_matrixKNN[1,1]/(conf_matrixKNN[1,1]+conf_matrixKNN[0,1])\nprint('Sensitivity : ', sensitivityKNN )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>KNN: ROC and AUC</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"predictKNN_quant = modelKNN.predict_proba(X_test)[:, 1]\n\nfprKNN, tprKNN, thresholds = roc_curve(y_test, predictKNN_quant)\n\nfig, ax = plt.subplots()\nax.plot(fprKNN, tprKNN)\nax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC Curve for Heart Disease Classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"aucKNN=auc(fprKNN, tprKNN)\nprint(\"Area under the curve:\", aucKNN)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>KNN: Precsion, Recall, and F1</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"KNNF1=metrics.f1_score(y_test,predictKNN)\nprint(classification_report(y_test,predictKNN))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>KNN: Cross Validation and R2 Scores</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"KNNscores = cross_val_score(modelKNN, X_scaled, y, cv=5)\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (KNNscores.mean(), KNNscores.std() * 2))\n\nKNNR2 = metrics.r2_score(y_test,predictKNN)\nprint ('R2:', KNNR2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='#4.3'>4.3. Decision Tree</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=heart2.drop('target',1)\ny=heart2.loc[:,'target']\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nX_train,X_test,y_train,y_test = train_test_split(X_scaled, y,test_size=.3,random_state=40)\n\ndtree= DecisionTreeClassifier()\nparams = {'max_features': ['auto', 'sqrt', 'log2'],\n          'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n          'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10,11]}#\n\ntree_model = GridSearchCV(dtree, param_grid=params, n_jobs=-1)\ntree_model.fit(X_train,y_train)\n\n#Printing best parameters selected through GridSearchCV\n\ntree_model.best_params_\npredictTREE = tree_model.predict(X_test)\n\naccsocreTREE=accuracy_score(y_test,predictTREE)\nprint('Accuracy Score: ',accuracy_score(y_test,predictTREE))\nprint('Using Decision Tree we get an accuracy score of: ',\n      round(accuracy_score(y_test,predictTREE),5)*100,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>Decision Tree: Confusion Matrix</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"conf_matrixTREE = confusion_matrix(y_test, predictTREE)\n\nprint('Confusion Matrix:\\n{}\\n'.format(conf_matrixTREE))\nprint('True Positive:\\t{}'.format(conf_matrixTREE[1,1]))\nprint('True Negative:\\t{}'.format(conf_matrixTREE[0,0]))\nprint('False Positive:\\t{}'.format(conf_matrixTREE[0,1]))\nprint('False Negative:\\t{}'.format(conf_matrixTREE[1,0]))\nclass_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(conf_matrixTREE), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for Decision Tree Model', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’> Decision Tree: Sensitivity and Specificity</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"total=sum(sum(conf_matrixTREE))\n\nspecificityTREE = conf_matrixTREE[0,0]/(conf_matrixTREE[0,0]+conf_matrixTREE[1,0])\nprint('Specificity : ', specificityTREE)\n\nsensitivityTREE = conf_matrixTREE[1,1]/(conf_matrixTREE[1,1]+conf_matrixTREE[0,1])\nprint('Sensitivity : ', sensitivityTREE )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>Decision Tree: ROC and AUC</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"predictTREE_quant = tree_model.predict_proba(X_test)[:, 1]\n\nfprTREE, tprTREE, thresholds = roc_curve(y_test, predictTREE_quant)\n\nfig, ax = plt.subplots()\nax.plot(fprTREE, tprTREE)\nax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC Curve for Heart Disease Classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"aucTREE=auc(fprTREE, tprTREE)\nprint(\"Area under the curve:\", aucTREE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>Decision Tree: Precision, Recall, and F1</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"TREEF1=metrics.f1_score(y_test,predictTREE)\nprint(classification_report(y_test,predictTREE))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>Decision Tree: Cross Validation and R2 Scores</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"TREEscores = cross_val_score(tree_model, X_scaled, y, cv=5)\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (TREEscores.mean(), TREEscores.std() * 2))\n\nTREER2 = metrics.r2_score(y_test,predictTREE)\nprint ('R2:', TREER2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yikes.  The Decision Tree model selected by GridSearchCV is *bad*.\n\nR2 is defined as the proportion of the variance in the dependent variable that is predictable from the independent variable(s).  So, the closer to 1 the R2 value is, the better the model fits the data.\nFurthermore, R2 compares the fit of the chosen model with that of a horizontal straight line (the null hypothesis). If the chosen model fits worse than a horizontal line, then R^2 is negative. \n\nLet's build a AdaBoost on top of the Decision Tree framework and see what happens."},{"metadata":{},"cell_type":"markdown","source":"## <a id='#4.4'>4.4. AdaBoost with Decision Tree Base</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X= heart2.drop('target',1)\ny= heart2['target']\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nX_train,X_test,y_train,y_test = train_test_split(X_scaled,y, test_size=.3,random_state=40)\n\nmodelABC = AdaBoostClassifier(base_estimator=dtree)\nparam_dist = {\n 'n_estimators': [i for i in range(1,100)],\n 'learning_rate' : [0.01,0.05,0.1,0.3,1]\n }\n\nABC = RandomizedSearchCV(AdaBoostClassifier(),\n param_distributions = param_dist,\n cv=3,\n n_iter = 10,\n n_jobs=-1)\n\nABC.fit(X_train, y_train)\nABC.best_params_ \ny_predictABC = ABC.predict(X_test)\n\n\naccscoreAB=accuracy_score(y_test,y_predictABC)\nprint('Using AdaBoost we get an accuracy score of: ',\n      round(accuracy_score(y_test,y_predictABC),5)*100,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>AdaBoost: Confusion Matrix</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"conf_matrixAB = confusion_matrix(y_test, y_predictABC)\n\nprint('Confusion Matrix:\\n{}\\n'.format(conf_matrixAB))\nprint('True Positive:\\t{}'.format(conf_matrixAB[1,1]))\nprint('True Negative:\\t{}'.format(conf_matrixAB[0,0]))\nprint('False Positive:\\t{}'.format(conf_matrixAB[0,1]))\nprint('False Negative:\\t{}'.format(conf_matrixAB[1,0]))\n\nclass_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(conf_matrixAB), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for AdaBoost Model', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>AdaBoost: Sensitivity and Specificity</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"total=sum(sum(conf_matrixAB))\n\nspecificityAB = conf_matrixAB[0,0]/(conf_matrixAB[0,0]+conf_matrixAB[1,0])\nprint('Specificity : ', specificityAB)\n\nsensitivityAB = conf_matrixAB[1,1]/(conf_matrixAB[1,1]+conf_matrixAB[0,1])\nprint('Sensitivity : ', sensitivityAB )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>AdaBoost: ROC and AUC</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"y_predABC_quant = ABC.predict_proba(X_test)[:, 1]\n\nfprABC, tprABC, thresholds = roc_curve(y_test, y_predABC_quant)\n\nfig, ax = plt.subplots()\nax.plot(fprABC, tprABC)\nax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC Curve for Heart Disease Classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"aucAB=auc(fprABC, tprABC)\nprint(\"Area under the curve:\", aucAB)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>AdaBoost: Precsion, Recall, and F1</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ABF1=metrics.f1_score(y_test,y_predictABC)\nprint(classification_report(y_test,y_predictABC))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>AdaBoost: Cross Validation and R2 Scores</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ABscores = cross_val_score(ABC, X_scaled, y, cv=5)\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (ABscores.mean(), ABscores.std() * 2))\n\nABR2 = metrics.r2_score(y_test,y_predictABC)\nprint ('R2:', ABR2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='#4.5'>4.5. Random Forest</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X= heart2.drop('target',1)\ny= heart2['target']\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nX_train,X_test,y_train,y_test = train_test_split(X_scaled,y, test_size=.3,random_state=40)\n\nclf=RandomForestClassifier()\nparams = {'n_estimators':[i for i in range(1,100)]}\nmodelRF = GridSearchCV(clf,params,cv=10)\nmodelRF.fit(X_train,y_train)\nmodelRF.best_params_   \n\ny_predCLF=modelRF.predict(X_test)\n\naccscoreRF=accuracy_score(y_test,y_predCLF)\nprint('Using Random Forest we get an accuracy score of: ',\n      round(accuracy_score(y_test,y_predCLF),5)*100,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>Random Forest: Confusion Matrix</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#y_predCLFH=modelRFH.predict(H_test)\nconf_matrixRF = confusion_matrix(y_test, y_predCLF)\n\nprint('Confusion Matrix:\\n{}\\n'.format(conf_matrixRF))\nprint('True Positive:\\t{}'.format(conf_matrixRF[1,1]))\nprint('True Negative:\\t{}'.format(conf_matrixRF[0,0]))\nprint('False Positive:\\t{}'.format(conf_matrixRF[0,1]))\nprint('False Negative:\\t{}'.format(conf_matrixRF[1,0]))\n\nclass_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(conf_matrixRF), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for Random Forest Model', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>Random Forest: Sensitivity and Specificity</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"total=sum(sum(conf_matrixRF))\n\nspecificityRF = conf_matrixRF[0,0]/(conf_matrixRF[0,0]+conf_matrixRF[1,0])\nprint('Specificity : ', specificityRF)\n\nsensitivityRF = conf_matrixRF[1,1]/(conf_matrixRF[1,1]+conf_matrixRF[0,1])\nprint('Sensitivity : ', sensitivityRF)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>Random Forest: ROC and AUC</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"y_predCLF_quant = modelRF.predict_proba(X_test)[:, 1]\n\nfprRF, tprRF, thresholds = roc_curve(y_test, y_predCLF_quant)\n\nfig, ax = plt.subplots()\nax.plot(fprRF, tprRF)\nax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC Curve for Heart Disease Classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"aucRF=auc(fprRF, tprRF)\nprint(\"Area under the curve:\", aucRF)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>Random Forest: Precsion, Recall, and F1</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"RFF1=metrics.f1_score(y_test,y_predCLF)\nprint(classification_report(y_test,y_predCLF))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>Random Forest: Cross Validation and R2 Scores</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"RFscores = cross_val_score(modelRF, X_scaled, y, cv=5)\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (RFscores.mean(), RFscores.std() * 2))\n\nRFR2 = metrics.r2_score(y_test,y_predCLF)\nprint ('Cross-Predicted Accuracy:', RFR2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='#4.6'>4.6. XGBoost</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X= heart2.drop('target',1)\ny= heart2['target']\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nX_train,X_test,y_train,y_test = train_test_split(X_scaled,y, test_size=.3,random_state=40)\n\nparam_dist = {\n 'n_estimators': [i for i in range(1,100)],\n 'learning_rate' : [0.01,0.05,0.1,0.3,1]\n }\n\nXGB = RandomizedSearchCV(XGBClassifier(),\n param_distributions = param_dist,\n cv=3,\n n_iter = 10,\n n_jobs=-1)\n\nXGB.fit(X_train, y_train)\nXGB.best_params_ \ny_predictXGB = XGB.predict(X_test)\n\n\naccscoreXGB=accuracy_score(y_test,y_predictXGB)\nprint('Using XGBoost we get an accuracy score of: ',\n      round(accuracy_score(y_test,y_predictXGB),5)*100,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>XGBoost: Confusion Matrix</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"conf_matrixXGB = confusion_matrix(y_test, y_predictXGB)\n\nprint('Confusion Matrix:\\n{}\\n'.format(conf_matrixXGB))\nprint('True Positive:\\t{}'.format(conf_matrixXGB[1,1]))\nprint('True Negative:\\t{}'.format(conf_matrixXGB[0,0]))\nprint('False Positive:\\t{}'.format(conf_matrixXGB[0,1]))\nprint('False Negative:\\t{}'.format(conf_matrixXGB[1,0]))\n\nclass_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(conf_matrixXGB), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for XGBoost Model', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>XGBoost: Sensitivity and Specificity</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"total=sum(sum(conf_matrixXGB))\n\nspecificityXGB = conf_matrixXGB[0,0]/(conf_matrixXGB[0,0]+conf_matrixXGB[1,0])\nprint('Specificity : ', specificityXGB)\n\nsensitivityXGB = conf_matrixXGB[1,1]/(conf_matrixXGB[1,1]+conf_matrixXGB[0,1])\nprint('Sensitivity : ', sensitivityXGB)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>XGBoost: ROC and AUC</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"y_predXGB_quant = XGB.predict_proba(X_test)[:, 1]\n\nfprXGB, tprXGB, thresholds = roc_curve(y_test, y_predXGB_quant)\n\nfig, ax = plt.subplots()\nax.plot(fprXGB, tprXGB)\nax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC Curve for Heart Disease Classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"aucXGB=auc(fprXGB, tprXGB)\nprint(\"Area under the curve:\", aucXGB)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>XGBoost: Precsion, Recall, and F1</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"XGF1=metrics.f1_score(y_test,y_predictXGB)\nprint(classification_report(y_test,y_predictXGB))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>XGBoost: Cross Validation Scores/ R2 Scores</a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"XGscores = cross_val_score(XGB, X_scaled, y, cv=5)\nprint(\"Accuracy: %0.2f (+/- %0.2f)\" % (XGscores.mean(), XGscores.std() * 2))\n\nXGR2 = metrics.r2_score(y_test,y_predictXGB)\nprint ('Cross-Predicted Accuracy:', XGR2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id=‘#5’>5. Comparing the Models</a>"},{"metadata":{},"cell_type":"markdown","source":"We just went thorugh 6 models very fast.  Let's compare them to see which predicted the best results for our data."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.subplot(3,2,1)\nsns.heatmap(pd.DataFrame(conf_matrixLR), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for Logisitc Regression', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()\n\nplt.subplot(3,2,2)\nsns.heatmap(pd.DataFrame(conf_matrixKNN), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for KNN', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()\n\nplt.subplot(3,2,3)\nsns.heatmap(pd.DataFrame(conf_matrixTREE), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for Decision Tree', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()\n\nplt.subplot(3,2,4)\nsns.heatmap(pd.DataFrame(conf_matrixRF), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for Random Forest', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()\n\nplt.subplot(3,2,5)\nsns.heatmap(pd.DataFrame(conf_matrixAB), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for AdaBoost', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()\n\nplt.subplot(3,2,6)\nsns.heatmap(pd.DataFrame(conf_matrixXGB), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for XGBoost', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This visualization is helpful, but it still does not reall tell us which model would be the best to base our findings off of. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"comparisons=pd.DataFrame()\ncomparisons.loc[\"Logistic Regression\",\"Accuracy\"]=accscoreLR\ncomparisons.loc[\"Logistic Regression\",\"Sensitivity\"]=sensitivityLR\ncomparisons.loc[\"Logistic Regression\",\"Specificity\"]=specificityLR\ncomparisons.loc[\"Logistic Regression\",\"F1\"]=LRF1\ncomparisons.loc[\"Logistic Regression\",\"Area Under the Curve\"]=aucLR\ncomparisons.loc[\"Logistic Regression\",\"Cross Validation Accuracy\"]=LRscores.mean()\ncomparisons.loc[\"Logistic Regression\",\"R2\"]=LRR2\n\ncomparisons.loc[\"KNN\",\"Accuracy\"]=accscoreKNN\ncomparisons.loc[\"KNN\",\"Sensitivity\"]=sensitivityKNN\ncomparisons.loc[\"KNN\",\"Specificity\"]=specificityKNN\ncomparisons.loc[\"KNN\",\"F1\"]=KNNF1\ncomparisons.loc[\"KNN\",\"Area Under the Curve\"]=aucKNN\ncomparisons.loc[\"KNN\",\"Cross Validation Accuracy\"]=KNNscores.mean()\ncomparisons.loc[\"KNN\",\"R2\"]=KNNR2\n\ncomparisons.loc[\"Decision Tree\",\"Accuracy\"]=accsocreTREE\ncomparisons.loc[\"Decision Tree\",\"Sensitivity\"]=sensitivityTREE\ncomparisons.loc[\"Decision Tree\",\"Specificity\"]=specificityTREE\ncomparisons.loc[\"Decision Tree\",\"F1\"]=TREEF1\ncomparisons.loc[\"Decision Tree\",\"Area Under the Curve\"]=aucTREE\ncomparisons.loc[\"Decision Tree\",\"Cross Validation Accuracy\"]=TREEscores.mean()\ncomparisons.loc[\"Decision Tree\",\"R2\"]=TREER2\n\ncomparisons.loc[\"AdaBoost\",\"Accuracy\"]=accscoreAB\ncomparisons.loc[\"AdaBoost\",\"Sensitivity\"]=sensitivityAB\ncomparisons.loc[\"AdaBoost\",\"Specificity\"]=specificityAB\ncomparisons.loc[\"AdaBoost\",\"F1\"]=ABF1\ncomparisons.loc[\"AdaBoost\",\"Area Under the Curve\"]=aucAB\ncomparisons.loc[\"AdaBoost\",\"Cross Validation Accuracy\"]=ABscores.mean()\ncomparisons.loc[\"AdaBoost\",\"R2\"]=ABR2\n\ncomparisons.loc[\"Random Forest\",\"Accuracy\"]=accscoreRF\ncomparisons.loc[\"Random Forest\",\"Sensitivity\"]=sensitivityRF\ncomparisons.loc[\"Random Forest\",\"Specificity\"]=specificityRF\ncomparisons.loc[\"Random Forest\",\"F1\"]=RFF1\ncomparisons.loc[\"Random Forest\",\"Area Under the Curve\"]=aucRF\ncomparisons.loc[\"Random Forest\",\"Cross Validation Accuracy\"]=RFscores.mean()\ncomparisons.loc[\"Random Forest\",\"R2\"]=RFR2\n\ncomparisons.loc[\"XGBoost\",\"Accuracy\"]=accscoreXGB\ncomparisons.loc[\"XGBoost\",\"Sensitivity\"]=sensitivityXGB\ncomparisons.loc[\"XGBoost\",\"Specificity\"]=specificityXGB\ncomparisons.loc[\"XGBoost\",\"F1\"]=XGF1\ncomparisons.loc[\"XGBoost\",\"Area Under the Curve\"]=aucXGB\ncomparisons.loc[\"XGBoost\",\"Cross Validation Accuracy\"]=XGscores.mean()\ncomparisons.loc[\"XGBoost\",\"R2\"]=XGR2\n\n\ndef highlight_max(s):\n    '''\n    highlight the maximum in a Series yellow.\n    '''\n    is_max = s == s.max()\n    return ['background-color: yellow' if v else '' for v in is_max]\n\ncompare=comparisons.style.apply(highlight_max)\ncompare","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow.  K-Nearest Neighbors has the highest Accuracy, Sensivity, Specificity, F1, and R2.  It is also a close second for Area Under the Curve and within .02 of the most cross-validated model.  In the next section of this study I will further examine the results k-nearest neighbors gave and what it indicates for predicting heart disease.\n\nThe cross validation and R2 scores exemplifiy that one score with a set random seed will not always represent how good a fit the model is for the data."},{"metadata":{},"cell_type":"markdown","source":"Let's Take a deeper look at the KNN Model"},{"metadata":{},"cell_type":"markdown","source":"## <a id=‘#5.1’>5.1. Assesing the Model of Best Fit</a>"},{"metadata":{},"cell_type":"markdown","source":"### <a id=‘#’>Elbow Method</a>"},{"metadata":{},"cell_type":"markdown","source":"Using Elbow Method to find the most efficient K value.  We alreadly used GridSearchCV to select the 'best parameters', but it is always good to examine the chosen parameters."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"error_rate = []\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))\n    \nplt.figure(figsize=(10,6))\nplt.plot(range(1,40),error_rate,marker='o', linestyle='dashed',color='b',markerfacecolor='r', markersize=10)\nplt.title('K-Value vs Error Mean')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"modelKNN.best_params_   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That seems reasonable.  Go to the next section for a more indepth analysis of the results of the KNN model."},{"metadata":{},"cell_type":"markdown","source":"# <a id=‘#6’>6. Note About One Hot Encoding</a>"},{"metadata":{},"cell_type":"markdown","source":"In theory, one hot encoding helps Machiene Learning algorithms better process data by maping all categorical data to binary vectors.  \n\nFor example, if your hypothetical column, \"bean type\", had 3 values (1, 2, 3) it would convert the one column into three new columns as follows:\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"Default=pd.DataFrame()\nDefault.loc[\"1\",\"Type\"]=1\nDefault.loc[\"2\",\"Type\"]=2\nDefault.loc[\"3\",\"Type\"]=3\n\nAfter_OneHot=pd.DataFrame()\nAfter_OneHot.loc[:,\"Type1\"]=Default.loc[:,\"Type\"].apply(lambda x: 1 if x==1 else 0)\nAfter_OneHot.loc[:,\"Type2\"]=Default.loc[:,\"Type\"].apply(lambda x: 1 if x==2 else 0)\nAfter_OneHot.loc[:,\"Type3\"]=Default.loc[:,\"Type\"].apply(lambda x: 1 if x==3 else 0)\n\nprint(\"Before --> After One Hot Encoding\")\nmulti_table([Default, After_OneHot])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I ran all six models with and without One Hot Encoding. The code and results follow:"},{"metadata":{},"cell_type":"markdown","source":"In order to determine if One Hot Encoding improves the accuracy of my predictive model, I am going to save made a new DataFrame, H.  For refrence:\n\n*Dependent Variables*\n   * H: One Hot encoded X values\n   * X: Non- One Hot encoded X values\n     \n*Independent Variable*\n* y: Target values "},{"metadata":{"trusted":true},"cell_type":"code","source":"heart4=pd.DataFrame.copy(heart2)\nheart4.loc[:,\"sex_female\"]=heart4.loc[:,\"sex\"].apply(lambda x: 0 if x==1 else 1)\nheart4.loc[:,\"CP_Asymptomatic\"]=heart4.loc[:,\"cpain\"].apply(lambda x: 1 if x==0 else 0)\nheart4.loc[:,\"CP_TypicalAng\"]=heart4.loc[:,\"cpain\"].apply(lambda x: 1 if x==1 else 0)\nheart4.loc[:,\"CP_AtypicalAng\"]=heart4.loc[:,\"cpain\"].apply(lambda x: 1 if x==2 else 0)\nheart4.loc[:,\"CP_NonAnginal\"]=heart4.loc[:,\"cpain\"].apply(lambda x: 1 if x==3 else 0)\nheart4.loc[:,\"BSLT120\"]=heart4.loc[:,\"fasting_BS\"].apply(lambda x: 1 if x==0 else 0)\nheart4.loc[:,\"EKG_Normal\"]=heart4.loc[:,\"resting_EKG\"].apply(lambda x: 1 if x==0 else 0)\nheart4.loc[:,\"EKG_LVH\"]=heart4.loc[:,\"resting_EKG\"].apply(lambda x: 1 if x==1 else 0)\nheart4.loc[:,\"EKG_STT\"]=heart4.loc[:,\"resting_EKG\"].apply(lambda x: 1 if x==2 else 0)\nheart4.loc[:,\"ExerciseANG_No\"]=heart4.loc[:,\"exercise_ANG\"].apply(lambda x: 1 if x==0 else 0)\nheart4.loc[:,\"STUpsloping\"]=heart4.loc[:,\"m_exercise_ST\"].apply(lambda x: 1 if x==0 else 0)\nheart4.loc[:,\"STFlat\"]=heart4.loc[:,\"m_exercise_ST\"].apply(lambda x: 1 if x==1 else 0)\nheart4.loc[:,\"STDownsloping\"]=heart4.loc[:,\"m_exercise_ST\"].apply(lambda x: 1 if x==2 else 0)\nheart4.loc[:,\"STABNNormal\"]=heart4.loc[:,\"ST_depressionAB\"].apply(lambda x: 1 if x==0 else 0)\n\nheart4= heart4.drop('cpain',axis=1)\nheart4= heart4.drop('m_exercise_ST',axis=1)\nheart4= heart4.drop('resting_EKG',axis=1)\nheart4=heart4[['age', 'sex','sex_female', 'CP_Asymptomatic', 'CP_TypicalAng', 'CP_AtypicalAng',\n              'CP_NonAnginal', 'resting_BP', 'chol', 'fasting_BS', 'BSLT120', 'EKG_Normal',\n              'EKG_LVH', 'EKG_STT', 'max_HR', 'ExerciseANG_No','exercise_ANG', 'ST_depression',\n              'STUpsloping', 'STFlat', 'STDownsloping','ST_depressionAB', 'STABNNormal', \n               'no_maj_vessels', 'thal']]\nheart4.columns=['Age', 'Sex_Male','Sex_Female', 'CP_Asymptomatic', 'CP_TypicalAng', 'CP_AtypicalAng',\n              'CP_NonAnginal', 'Resting_BP', 'Chol', 'BSMT120', 'BSLT120', 'EKG_Normal',\n              'EKG_LVH', 'EKG_STT', 'max_HR', 'ExerciseANG_No','ExerciseANG_Yes', 'ST_Depression',\n              'STUpsloping', 'STFlat', 'STDownsloping','ST_depressionAB', 'STABNNormal',\n             '#Major_Vessels', 'Thalium_ST']\n\nH=heart4\nX=heart2.drop('target',1)\ny=heart2.loc[:,'target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First 5 lines of One Hot encoded dataframe:"},{"metadata":{"trusted":true},"cell_type":"code","source":"H.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the below code I ran and analyzed the accuracy of all 6 examined models."},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"H=heart4\ny=heart2.loc[:,'target']\nscaler = StandardScaler()\nH_scaled = scaler.fit_transform(H)\nH_train,H_test,y_train,y_test = train_test_split(H_scaled,y,test_size=.2,random_state=40)\n\n#Logisitc Regression\nLRH = LogisticRegression(C=0.01, solver='liblinear').fit(H_train,y_train)\ny_predictLRH = LRH.predict(H_test)\naccscoreLRH=accuracy_score(y_test,y_predictLRH)\nLRHscores = cross_val_score(LRH, H_scaled, y, cv=5)\nLRHR2 = metrics.r2_score(y_test,y_predictLRH)\n\n\n#KNN\nknn =KNeighborsClassifier()\nparams = {'n_neighbors':[i for i in range(1,33,2)]}\nmodelKNNH = GridSearchCV(knn,params,cv=10)\nmodelKNNH.fit(H_train,y_train)\nmodelKNNH.best_params_   \npredictKNNH = modelKNNH.predict(H_test)\naccscoreKNNH=accuracy_score(y_test,predictKNNH)\nKNNHscores = cross_val_score(modelKNNH, H_scaled, y, cv=5)\nKNNHR2 = metrics.r2_score(y_test,predictKNNH)\n\n#Decision Tree\ndtreeH= DecisionTreeClassifier()\nparamsH = {'max_features': ['auto', 'sqrt', 'log2'],\n          'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n          'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10,11]}#\ntree_modelH = GridSearchCV(dtreeH, param_grid=paramsH, n_jobs=-1)\ntree_modelH.fit(H_train,y_train)\ntree_modelH.best_params_\npredictTREEH = tree_modelH.predict(H_test)\naccscoreTREEH=accuracy_score(y_test,predictTREEH)\nTREEHscores = cross_val_score(tree_modelH, H_scaled, y, cv=5)\nTREEHR2 = metrics.r2_score(y_test, predictTREEH)\n\n#AdaBoost with Decision Tree Base\nmodelABCH = AdaBoostClassifier(base_estimator=dtree)\nparam_distH = {\n 'n_estimators': [i for i in range(1,100)],\n 'learning_rate' : [0.01,0.05,0.1,0.3,1]\n }\nABCH = RandomizedSearchCV(AdaBoostClassifier(), param_distributions = param_distH, cv=3, n_iter = 10,n_jobs=-1)\nABCH.fit(H_train, y_train)\nABCH.best_params_ \ny_predictABCH = ABCH.predict(H_test)\naccscoreABH=accuracy_score(y_test,y_predictABCH)\nABHscores = cross_val_score(ABCH, H_scaled, y, cv=5)\nABHR2 = metrics.r2_score(y_test, y_predictABCH)\n\n#Random Forest\nclfH=RandomForestClassifier()\nparamsH = {'n_estimators':[i for i in range(1,100)]}\nmodelRFH = GridSearchCV(clfH,paramsH,cv=10)\nmodelRFH.fit(H_train,y_train)\nmodelRFH.best_params_   \ny_predCLFH=modelRFH.predict(H_test)\naccscoreRFH=accuracy_score(y_test,y_predCLFH)\nRFHscores = cross_val_score(modelRFH, H_scaled, y, cv=5)\nRFHR2 = metrics.r2_score(y_test, y_predCLFH)\n\n#XGBoost\nparam_distH = {\n 'n_estimators': [i for i in range(1,100)],\n 'learning_rate' : [0.01,0.05,0.1,0.3,1]\n }\nXGBH = RandomizedSearchCV(XGBClassifier(),param_distributions = param_distH, cv=3, n_iter = 10,n_jobs=-1)\nXGBH.fit(H_train, y_train)\nXGBH.best_params_ \ny_predictXGBH = XGBH.predict(H_test)\naccscoreXGBH=accuracy_score(y_test,y_predictXGBH)\nXGHscores = cross_val_score(XGBH, H_scaled, y, cv=5)\nXGHR2 = metrics.r2_score(y_test, y_predictXGBH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Accuracy=pd.DataFrame()\nAccuracy.loc[\"Logistic Regression Accuracy\",\"One Hot Encoded\"]=accscoreLRH\nAccuracy.loc[\"Logistic Regression Accuracy\",\"Unaltered\"]=accscoreLR\nAccuracy.loc[\"KNN Accuracy\",\"One Hot Encoded\"]=accscoreKNNH\nAccuracy.loc[\"KNN Accuracy\",\"Unaltered\"]=accscoreKNN\nAccuracy.loc[\"Decision Tree Accuracy\",\"One Hot Encoded\"]=accscoreTREEH\nAccuracy.loc[\"Decision Tree Accuracy\",\"Unaltered\"]=accsocreTREE\nAccuracy.loc[\"AdaBoost Accuracy\",\"One Hot Encoded\"]=accscoreABH\nAccuracy.loc[\"AdaBoost Accuracy\",\"Unaltered\"]=accscoreAB\nAccuracy.loc[\"Random Forest Accuracy\",\"One Hot Encoded\"]=accscoreRFH\nAccuracy.loc[\"Random Forest Accuracy\",\"Unaltered\"]=accscoreRF\nAccuracy.loc[\"XGBoost Accuracy\",\"One Hot Encoded\"]=accscoreXGBH\nAccuracy.loc[\"XGBoost Accuracy\",\"Unaltered\"]=accscoreXGB\n\nAccuracy=Accuracy.T\nAccuracy.style.apply(highlight_max)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"CVA=pd.DataFrame()\nCVA.loc[\"Logistic Regression CVA\",\"One Hot Encoded\"]=LRHscores.mean()\nCVA.loc[\"Logistic Regression CVA\",\"Unaltered\"]=LRscores.mean()\nCVA.loc[\"KNN CVA\",\"One Hot Encoded\"]=KNNHscores.mean()\nCVA.loc[\"KNN CVA\",\"Unaltered\"]=KNNscores.mean()\nCVA.loc[\"Decision Tree CVA\",\"One Hot Encoded\"]=TREEHscores.mean()\nCVA.loc[\"Decision Tree CVA\",\"Unaltered\"]=TREEscores.mean()\nCVA.loc[\"AdaBoost CVA\",\"One Hot Encoded\"]=ABHscores.mean()\nCVA.loc[\"AdaBoost CVA\",\"Unaltered\"]=ABscores.mean()\nCVA.loc[\"Random Forest CVA\",\"One Hot Encoded\"]=RFHscores.mean()\nCVA.loc[\"Random Forest CVA\",\"Unaltered\"]=RFscores.mean()\nCVA.loc[\"XGBoost Accuracy CVA\",\"One Hot Encoded\"]=XGHscores.mean()\nCVA.loc[\"XGBoost Accuracy CVA\",\"Unaltered\"]=XGscores.mean()\n\nCVA=CVA.T\nCVA.style.apply(highlight_max)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"R2=pd.DataFrame()\nR2.loc[\"Logistic Regression R2\",\"One Hot Encoded\"]=LRHR2\nR2.loc[\"Logistic Regression R2\",\"Unaltered\"]=LRR2\nR2.loc[\"KNN R2\",\"One Hot Encoded\"]=KNNHR2\nR2.loc[\"KNN R2\",\"Unaltered\"]=KNNR2\nR2.loc[\"Decision Tree R2\",\"One Hot Encoded\"]=TREEHR2\nR2.loc[\"Decision Tree R2\",\"Unaltered\"]=TREER2\nR2.loc[\"AdaBoost R2\",\"One Hot Encoded\"]=ABHR2\nR2.loc[\"AdaBoost R2\",\"Unaltered\"]=ABR2\nR2.loc[\"Random Forest R2\",\"One Hot Encoded\"]=RFHR2\nR2.loc[\"Random Forest R2\",\"Unaltered\"]=RFR2\nR2.loc[\"XGBoost Accuracy R2\",\"One Hot Encoded\"]=XGHR2\nR2.loc[\"XGBoost Accuracy R2\",\"Unaltered\"]=XGR2\n\nR2=R2.T\nR2.style.apply(highlight_max)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, the difference between the accuracies, cross-validated accuracies, and R2's of the one hot encoded samples and unaltered samples is very small.  For this reason, as well as the fact that these tests were run solely to pick the best model for my data, I did not include further analysis of the one hot encoded dataframe (confusion matricies, etc.)."},{"metadata":{},"cell_type":"markdown","source":"# <a id=‘#’>FIN</a>"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}