{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# importing libraries\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nimport math\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting data\ndataset = pd.read_csv('../input/Pokemon.csv')\n\n# drop rows with missing 'Legendary' values\ndataset.dropna(axis=0, subset=['Legendary'], inplace=True)\n\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# separate target from predictors\ny = dataset.Legendary\nX = dataset.drop('Legendary', axis=1)\nX = X.drop('#', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get list of categorical variables\ns = (X.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop unconsidered variables\nX.drop('Name', axis=1, inplace=True)\n\nobject_cols.remove('Name')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dealing with missing data\n\n# get names of columns with missing values\ncols_with_missing = [col for col in X.columns\n                    if X[col].isnull().any()]\n\nprint(cols_with_missing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# decided what to do with missing values\n# mark them as 0\nX.fillna(' ', inplace=True)\n\n# change all 'object' dtypes to strings\nstr_all = np.vectorize(str)\nstr_all(X[object_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# one-hot encoding categorical variables\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols = pd.DataFrame(OH_encoder.fit_transform(X[object_cols]))\n\n# # one-hot encoding removed index, put it back\n# OH_cols.index = X.index\n# print(OH_cols.index)\n\n# remove categorical columns, replaced with one-hot encoding\nX.drop(object_cols, axis=1, inplace=True)\nX = pd.concat([X, OH_cols], axis=1)\n\nprint(\"one-hot encoding done\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scaling the data\nsc = MinMaxScaler(feature_range=(0, 1))\nX_scaled = sc.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X, test_X, train_y, test_y = train_test_split(X_scaled, y, train_size=0.8, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features = train_X.shape[1]\nnum_outputs = 2\n\nmodel = keras.Sequential([\n    keras.layers.Dense(num_features, activation=tf.nn.relu),\n    keras.layers.Dense(num_outputs, activation=tf.nn.softmax)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y = train_y.values\ntest_y = test_y.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_X, train_y, epochs=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss, test_acc = model.evaluate(test_X, test_y)\n\nprint('Test accuracy:', test_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_X[0])\ntest_X[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pre_process_data(X):\n    s = (X.dtypes == 'object')\n    object_cols = list(s[s].index)\n    \n    # drop unconsidered variables\n    X.drop('Name', axis=1, inplace=True)\n    object_cols.remove('Name')\n\n    # decided what to do with missing values\n    # mark them as 0\n    X.fillna(' ', inplace=True)\n\n    # change all 'object' dtypes to strings\n    str_all = np.vectorize(str)\n    str_all(X[object_cols])\n\n    # one-hot encoding categorical variables\n    OH_cols = pd.DataFrame(OH_encoder.transform(X[object_cols]))\n\n    # one-hot encoding removed index, put it back\n    OH_cols.index = X.index\n\n    # remove categorical columns, replaced with one-hot encoding\n    X.drop(object_cols, axis=1, inplace=True)\n    X = pd.concat([X, OH_cols], axis=1)\n\n    X_scaled = sc.transform(X)\n    \n    return X_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make a single prediction on new pokemon(s)\nnew_df = pd.DataFrame({\"Name\":[\"tylerino\"], \"Type 1\":[\"Grass\"], \"Type 2\":[None], \"Total\":[365], \"HP\":[50], \"Attack\":[63], \n                               \"Defense\":[60], \"Sp. Atk\":[62], \"Sp. Def\":[60], \"Speed\":[50], \"Generation\":[2]})\nnew_names = new_df.Name\n\nnew_processed_df = pre_process_data(new_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(new_processed_df[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_processed_data = (np.expand_dims(new_processed_df[0],0))\n\nprint(new_processed_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_predictions = model.predict(new_processed_data)\nprint(new_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_result = np.argmax(new_predictions[0])\n\nif prediction_result == 0:\n    print(new_names.values[0], \"is not a Legendary Pokemon, what a noob!\")\nelse:\n    print(new_names.values[0], \"is a Legendary Pokemon, amazing!\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}