{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\ntrain_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check null\ntrain_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert numeric data to range data\ndef divide_convert(age, num = 10) :\n    return int(age/num)\n\ntrain_data[\"Age\"] = train_data[\"Age\"].apply(lambda x : divide_convert(x))\ntrain_data[\"SkinThickness\"] = train_data[\"SkinThickness\"].apply(lambda x : divide_convert(x))\n\ntrain_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n#use last 20 datas for validate\nx = train_data.iloc[:-20, :-1].to_numpy()\nx = torch.FloatTensor(x).to(device)\ny = train_data.iloc[:-20, -1].to_numpy()\ny = torch.FloatTensor(y).to(device).reshape(-1, 1)\n\nvalid_x = train_data.iloc[-20:, :-1].to_numpy()\nvalid_x = torch.FloatTensor(valid_x).to(device)\nvalid_y = train_data.iloc[-20:, -1].to_numpy()\nvalid_y = torch.FloatTensor(valid_y).to(device).reshape(-1, 1)\n\nprint(x.shape, y.shape)\nprint(valid_x.shape, valid_y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass BinaryDnnModel(nn.Module) :\n    def __init__(self, features) :\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(features, features*2),\n            nn.LeakyReLU(),\n            nn.Linear(features*2, features),\n            nn.LeakyReLU(),\n            nn.Linear(features, 1),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, x) :\n        return self.model(x)\n\nmodel = BinaryDnnModel(x.shape[1]).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epoch = 500\nmodel.train()\n\nfor epoch in range(n_epoch) :\n    predict = model(x)\n    \n    loss = F.binary_cross_entropy(predict, y)\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    predict = predict >= torch.FloatTensor([0.5]).to(device)\n    predict = predict.float()\n    \n    acc = (predict == y)\n    acc = acc.sum()\n    acc = acc / x.shape[0]\n    \n    print('Epoch : {}/{},   loss : {:.5f},    acc : {:.5f}'.format(epoch+1, n_epoch, loss.item(), acc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\n\nvalid_acc = 0\nvalid_loss = 0\nfor i in range(20) :\n    predict = model(valid_x[i])\n    \n    loss = F.binary_cross_entropy(predict, valid_y[i])\n    valid_loss += loss.item() / 20\n    \n    predict = predict >= torch.FloatTensor([0.5]).to(device)\n    predict = predict.float()\n    \n    if predict.item() == valid_y[i].item() : valid_acc += 1\n    \nprint('acc : {0}, loss : {1:.5f}'.format(valid_acc/20, valid_loss))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}