{"cells":[{"cell_type":"markdown","metadata":{},"source":"What is puzzling me ?\n---\nIn your text you describe the location goes from 0 - 180\ni could only find 97 locations in reference ?\n"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"1705b40e-f641-4d64-8f37-365f65728949","_uuid":"c4010f1e9137e3ce1ef00388c0ab9ac84f9a13e7"},"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.offline as py\npy.init_notebook_mode(connected = True)\nimport plotly.graph_objs as go\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.decomposition import PCA"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{"_cell_guid":"039bb644-fb4d-44d3-a927-19f858d6ca9f","_uuid":"ca877e7796069471d1dfe7a9183ffefa3debeaa4"},"source":"df = pd.read_csv('../input/slice_localization_data.csv')[:100000]\n\ndf.describe().T\n\n"},{"execution_count":null,"cell_type":"code","outputs":[],"metadata":{},"source":"\nfrom sklearn.linear_model import OrthogonalMatchingPursuitCV,RANSACRegressor,LogisticRegression,MultiTaskElasticNet,HuberRegressor, Ridge, Lasso,LassoCV,LarsCV,BayesianRidge,SGDClassifier,LogisticRegressionCV,RidgeClassifier\nfrom sklearn.preprocessing import MinMaxScaler\nimport seaborn as sns\n\nfrom sklearn.linear_model import OrthogonalMatchingPursuit,RANSACRegressor,LogisticRegression,ElasticNet,HuberRegressor, Ridge, Lasso,LassoCV,Lars,BayesianRidge,SGDClassifier,LogisticRegressionCV,RidgeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import MinMaxScaler,PolynomialFeatures\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nparam_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']}\n\nX = df.drop('reference',axis=1) # we only take the first two features.\n#le = preprocessing.LabelEncoder()\ndef rmsle(y_predicted, y_real):\n    return np.sqrt(np.mean(np.power(np.log1p(y_predicted)-np.log1p(y_real), 2)))\ndef procenterror(y_predicted, y_real):\n     return np.round( np.mean(np.abs(y_predicted-y_real) )/ np.mean(y_real) *100 ,1)\n\n    \n#le.fit(train['Outcome'])\n#print(list(le.classes_))\n\nY=np.round(df['reference'])\n#scaler = MinMaxScaler()\n#scaler.fit(X)\n#X=scaler.transform(X)\n#poly = PolynomialFeatures(2)\n#X=poly.fit_transform(X)\n\n\nnames = [\n         'DecisionTree',\n         'RandomForestClassifier',    \n         #'ElasticNet',\n         #'KNN',\n         #'GridSearchCV',\n         #'HuberRegressor',\n         #'Ridge',\n         #'Lasso',\n         #'LassoCV',\n         #'Lars',\n         #'BayesianRidge',\n         #'SGDClassifier',\n         #'RidgeClassifier',\n         #'LogisticRegression',\n         #'OrthogonalMatchingPursuit',\n         #'RANSACRegressor',\n         #'SVC',\n         #'kSVC',\n         ]\n\nclassifiers = [\n    DecisionTreeClassifier(),\n    RandomForestClassifier(n_estimators = 200,n_jobs=-1),    \n    #ElasticNet(alpha=0.1),\n    #KNeighborsClassifier(n_neighbors = 5,n_jobs=-1),\n    #GridSearchCV(SVC(),param_grid, refit = True, verbose = 1),\n    #HuberRegressor(fit_intercept=True, alpha=0.0, max_iter=100,epsilon=2.95),\n    #Ridge(fit_intercept=True, alpha=0.0, random_state=0, normalize=True),\n    #Lasso(alpha=0.5),\n    #LassoCV(),\n    #LarsCV(n_jobs=-1),\n    #BayesianRidge(),\n    #SGDClassifier(n_jobs=-1),\n    #RidgeClassifier(),\n    #LogisticRegression(n_jobs=-1),\n    #OrthogonalMatchingPursuitCV(n_jobs=-1),\n    #SVC(),\n    #SVC(kernel = 'rbf', random_state = 0),    \n    #RANSACRegressor(),\n]\ncorrection= [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n\nmodel=zip(names,classifiers,correction)\nprint(model)\n\nfor name, clf,correct in model:\n    regr=clf.fit(X,Y)\n    #print( name,'% errors', abs(regr.predict(X)+correct-Y).sum()/(Y.sum())*100)\n    print(name,'%error',procenterror(regr.predict(X),Y),'rmsle',rmsle(regr.predict(X),Y))\n    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,f1_score, precision_score, recall_score\n\n    # Confusion Matrix\n    print(name,'Confusion Matrix')\n    conf=confusion_matrix(Y, np.round(regr.predict(X) ) )     \n    #label = Y.sort_values().unique()\n    #sns.heatmap(conf, annot=True, xticklabels=label, yticklabels=label, cmap=\"YlGnBu\")\n    #plt.show()\n\n    print(confusion_matrix(Y, np.round(regr.predict(X) ) ) )\n    print('--'*40)\n\n    # Classification Report\n    print(name,'Classification Report')\n    print(classification_report(Y,np.round( regr.predict(X) ) ))\n\n    # Accuracy\n    print('--'*40)\n    logreg_accuracy = round(accuracy_score(Y, np.round( regr.predict(X) ) ) * 100,2)\n    print('Accuracy', logreg_accuracy,'%')\n\n"}],"nbformat_minor":1,"nbformat":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"mimetype":"text/x-python","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.1","file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python"}}}