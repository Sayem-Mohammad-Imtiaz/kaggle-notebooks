{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Doğrusal Regresyon Egzersizleri","metadata":{}},{"cell_type":"markdown","source":"50 adet Startup'ın araştırma ve geliştirmeye yönelik harcaması, yönetime yönelik harcaması, pazarlama harcaması, kazandıkları kar miktarı ve kuruldukları lokasyon bilgisi bulunmaktadır. Amaç kar miktarını tahmin etmektir. Bu bir sayısal tahmin problemidir ve bağımlı değişkenimiz \"Profit\".","metadata":{}},{"cell_type":"markdown","source":"Numpy, matplotlib.pyplot, pandas ve seaborn kütüphanelerini çekirdeğe dahil edelim.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dizinde bulunan veri çerçevemizi startups değişkenine atayalım. startups değişkenini df değişkenine kopyalayarak kullanmaya başlayalım.","metadata":{}},{"cell_type":"code","source":"startups  = pd.read_csv(\"../input/50-startups/50_Startups.csv\")\ndf = startups.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"İlk 5 gözlemini yazdıralım.","metadata":{}},{"cell_type":"code","source":"df.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Veri çerçevesinin bilgilerini görüntüleyelim.","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Kaç gözlem ve öznitelikten oluştuğunu görüntüleyelim.","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"veri setimiz 50 gözlem ve 5 öznitelikten oluşmaktadır.","metadata":{}},{"cell_type":"markdown","source":"Eksik verileri kontrol edelim.","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Veri setimizde eksik gözlem bulunmamaktadır.","metadata":{}},{"cell_type":"markdown","source":"Korelasyon matrisi çizdirelim.","metadata":{}},{"cell_type":"code","source":"df.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Korelasyon katsayısı yorumu: İki değer arasındaki ilişki **Korelasyon** \"1\" değerine yaklaştıkça artar ve güçlenir. \n* Bu bilgiler ile veri setimizin \"1\" e yakın olup pozitif değere sahip olan değerlerimiz 0.972900 korelasyon katsayısı ile \"R&D Spend\" ve \"Profit\" değeridir.","metadata":{}},{"cell_type":"markdown","source":"Seaborn ile korelasyon matrisinin ısı haritasını çizdirelim.","metadata":{}},{"cell_type":"code","source":"sns.heatmap(df.corr());","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Isı haritasını kullanmamızın sebebi renklendirme ile daha rahat korelasyon yorumu yapabildiğimizdir. \n* Koyu renkler: Korelasyon düşük yani sıfıra yakın değerler. Mesela: \"Administration\" ve \"Marketing Spend\"\n* Açık renkler: Korelasyon yüksek yani bire yakın değerler. Mesela: \"R&D Spend\" ve \"Profit\"","metadata":{}},{"cell_type":"markdown","source":"R&D Spend ve Profit arasındaki korelasyonu daha iyi görebilmek için scatterplot çizdirelim.","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(x = \"R&D Spend\", y = \"Profit\", data = df);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Grafiğe bakıldığında sonlara doğru doğrusal bir artış olduğu söz konusudur.","metadata":{}},{"cell_type":"markdown","source":"Sayısal değişkenlerin dağılımını görmek için df üzerinden histogram çizdirelim.","metadata":{}},{"cell_type":"code","source":"df.hist(figsize =(13,10))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Histogram grafikleri genelde dağılıma bakmak için kullanılır.\n* figsize:Grafiğin boyutunu belirler. Parantez içinde yazılan ilk değer grafiğin enini, ikincisi boyutunu belirtir.","metadata":{}},{"cell_type":"markdown","source":"Veri çerçevesinin temel istatistik değerlerini görüntüleyelim.","metadata":{}},{"cell_type":"code","source":"df.describe().T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Eğer bir veri ortalamaya yakın ise Standart Sapma'da düşük olacaktır. Eğer ortalamaya uzakta bir yaygın dağılım söz konusuysa standart sapma değeri de büyük olacaktır. Standart sapma varyansın kare kökü olduğundan dolayı ortalamaları ve standart sapma değerleri ile **Varyans** yorumu yapabiliriz.\n* Standart sapması en yüksek olan değer \"Marketing Spend\" dir. Bu yüzden **en yüksek varyansa** sahiptir.\n* Standart sapması en düşük değer ise \"Administration\" dir. Bu yüzden **en küçük varyans** değerine sahiptir.","metadata":{}},{"cell_type":"markdown","source":"State'a ait benzersiz değerleri görüntüleyelim.","metadata":{}},{"cell_type":"code","source":"df[\"State\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"get_dummies yardımıyla State'a dair kategorik öznitelik çıkarımlarında bulunalım. Çünkü State'ların birbirine üstünlüğü yok, nominaller. Ordinal değil.","metadata":{}},{"cell_type":"code","source":"df_State = pd.get_dummies(df[\"State\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"pd.get_dummies () , veri işleme için kullanılır. Kategorik verileri kukla veya gösterge değişkenlere dönüştürür.","metadata":{}},{"cell_type":"code","source":"df_State.head(5)\n# ilk 5 gözlemi listeleyerek kontrol edelim.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_State.columns = ['California','Florida','New York']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_State.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"State özniteliğini silip dummy olarak yaratılan State'lardan da birisini hariç tutarak veri çerçevemizi güncelleyelim.","metadata":{}},{"cell_type":"code","source":"df.drop([\"State\"], axis=1 , inplace =True)\ndf=pd.concat([df,df_State],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop([\"California\"], axis=1, inplace = True)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Veri çerçevemizi bağımlı ve bağımsız değişkenler olmak üzere bölütleyelim.","metadata":{}},{"cell_type":"code","source":"X = df.drop(\"Profit\", axis = 1) #bağımsız değişkenler \ny = df[\"Profit\"] #bağımlı değişkenler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bağımlı ve bağımsız değişkenleri kontrol edelim.","metadata":{}},{"cell_type":"code","source":"X #bağımsız değişkenimiz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y #bağımlı değişkenimiz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bu bağımlı ve bağımsız değişkenlerden train ve test olmak üzere 4 parça oluşturalım. Bunu yapmak için train_test_split kullanalım.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Train - Test modellerini oluştumak için sklearn.model_selection kütüphanesini import ediyoruz.\n* Train ve Test için veri setimizi böldük.","metadata":{}},{"cell_type":"markdown","source":"4 parça değişkeni kontrol edelim.","metadata":{}},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LinearRegression'u çekirdeğe dahil edip modeli inşa edelim.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlm = LinearRegression()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lineer(Doğrusal) regresyonu kullanmak için sklearn.linear_model kütüphanesini import ediyoruz.","metadata":{}},{"cell_type":"markdown","source":"Modeli eğitmek için bağımlı bağımsız değişkenlerden oluşturulan eğitim verilerini verelim.","metadata":{}},{"cell_type":"code","source":"lm.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modele daha önce görmediği bağımlı test değişkenini tahmin ettirelim. Bu tahmin değerlerimizi y_pred değişkenine atayalım.","metadata":{}},{"cell_type":"code","source":"y_pred=lm.predict(X_test) #predic = tahmin işlemini gerçekleştirir\ny_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tahminleri ve gerçek değerleri bir veri çerçevesinde toplayıp üzerinde göz gezdirelim.","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame({\"Gerçek veriler\" : y_test, \"Tahmin edilen veriler\" : y_pred,\"Hata payı sonucu\" : abs(y_test - y_pred)})\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Gerçek verilerimiz ile tahmin verilerimizin arsındaki farkların mutlak değerlerini alıyoruz.","metadata":{}},{"cell_type":"markdown","source":"sklearn bünyesinde barınan metrics'i çekirdeğe dahil edelim ve MAE, MSE, RMSE değerlerini görüntüleyelim.","metadata":{}},{"cell_type":"code","source":"import sklearn.metrics as metrics\nimport math\n\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = math.sqrt(mse)\n\nprint(\"Hata Mutlak Ortalama Degeri(MAE):\",mae) \nprint(\"Hata Kareler Ortalaması Degeri(MSE):\", mse) \nprint(\"Hata Kareler Ortalamasının Karekök Degeri(RMSE):\", rmse) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modelin R Squared değerini eğitim verileri üzerinden yazdıralım.","metadata":{}},{"cell_type":"code","source":"print(\"R Squared=\", lm.score(X_train, y_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* R^2 ifademiz 1 e yaklaştıkca modelimizin doğruluğu artmaktadır.  0.9537019995248526 R^2 ifademizin doğruluk oranı yüksektir diyebiliriz.","metadata":{}},{"cell_type":"markdown","source":"Dileyenler statsmodel kullanarak hangi özniteliklerin model için %95 güvenilirlikle ne kadar anlamlı olup olmadığına da bakabilir. Modelde bazı feature selection işlemleri yaparak tekrardan eğitip yeni sonuçlar mukayese edilebilir.","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\nsttmodel = sm.OLS(y, X).fit()\nsttmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"R^2 ifadesi: bağımsız değişkenlerin bağımlı değişkendeki değişikliği açıklama yüzdesidir. 0.988 oldukça yüksek bir rakam.  R^2 ne kadar değişken eklenirse o kadar şişmektedir. Şişmenin önüne geçmek için düzeltilmiş R^2 değeri ortaya çıkar. Daha sağlıklı bir açıklanabilirlik oranı vermektedir. F-statistic: modelin anlamlılığını test etmek için kullanılan istatistiktir. Prob(F- statistic: 0.05 den oldukça küçük bir değere sahip. Bu yüzden modelin anlamlı olduğu bilgisini bize veriyor. (modelin anlamlılığıyla ilgili bize bilgi veriyor.)","metadata":{}},{"cell_type":"markdown","source":"coef: bağımsız değişkenlerin katsayılarını ifade ediyor. (b1, b2, b3 katsayılarını ifade ediyor.) std err: bağımsız değişkenlerin standart hata değeridir. t istatistiği anlamlılığı ifade eder. P>t modellemek için kullandığımız bütün değişkenler anlamlıdır. 0.05 ten küçük değerler elde ettiğimiz sürece anlamlı değişkenler olur. coef katsayısı yorumu: örn: R&D Spend e 1 birimlik yatırım yapıldığı zaman 0.7182 bir artış söz konusu olacaktır.","metadata":{}}]}