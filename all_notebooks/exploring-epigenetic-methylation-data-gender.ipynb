{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id=\"1.1\"></a>\n<h3 style=\"background-color:orange;font-family:newtimeroman;font-size:250%;text-align:center;border-radius: 15px 50px;\">Introduction</h3>\n","metadata":{}},{"cell_type":"markdown","source":"![](https://www.nutracera.com/wp-content/uploads/2018/04/Why-is-Methylation-Important-1200x500.png)","metadata":{}},{"cell_type":"markdown","source":"**WHAT IS METHYLATION IMPORTANT?**\n\nDNA methylation is a biological process by which methyl groups are added to the DNA molecule. Methylation can change the activity of a DNA segment without changing the sequence. When located in a gene promoter, DNA methylation typically acts to repress gene transcription. In mammals, DNA methylation is essential for normal development and is associated with a number of key processes including genomic imprinting, X-chromosome inactivation, repression of transposable elements, aging, and carcinogenesis.\n\n**WHY IS METHYLATION IMPORTANT?**\n\nThe body is a very complex machine, with various gears and switches that need to be all functioning properly to operate optimally. Think of methylation, and the opposite action, demethylation, as the mechanism that allows the gears to turn, and turns biological switches on and off for a host of systems in the body.\n\n**HOW DOES METHYLATION HAPPEN?**\n\nCH3 is provided to the body through a universal methyl donor known as SAMe (S-adenosylmethionine). SAMe readily gives away its methyl group to other substances in the body, which enables the cardiovascular, neurological, reproductive, and detoxification systems to perform their functions.\n\nUnfortunately, the system that produces SAMe is reliant on one switch being turned on by a critical B vitamin, 5-MTHF (also known as active folate or methylfolate).\n\nSources(Wikipedia.com,thorne.com)\n\n","metadata":{}},{"cell_type":"markdown","source":"![](https://www.researchgate.net/profile/Marian-Hajduch/publication/323190556/figure/fig1/AS:610867326513153@1522653528846/Interplay-between-DNA-methylation-gene-transcription-and-chromatin-structure-The.png)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1.1\"></a>\n<h3 style=\"background-color:orange;font-family:newtimeroman;font-size:250%;text-align:center;border-radius: 15px 50px;\">Libraries And Utilities</h3>\n","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nimport pymc3 as pm\nimport theano.tensor as tt\nimport string\nimport nltk\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport plotly.express as ex\nimport plotly.graph_objs as go\nimport plotly.offline as pyo\nfrom plotly.subplots import make_subplots\npyo.init_notebook_mode()\nfrom sklearn.decomposition import TruncatedSVD,PCA\nfrom sklearn.cluster import KMeans\nimport matplotlib.gridspec as gridspec\nimport random\nfrom tqdm.notebook import tqdm\nimport gc\nfrom scipy.stats.mstats import mquantiles\n%pip install joypy\nfrom joypy import joyplot\nplt.rc('figure',figsize=(17,10))\nsns.set_context('paper',font_scale=2)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-27T09:21:37.635728Z","iopub.execute_input":"2021-06-27T09:21:37.6363Z","iopub.status.idle":"2021-06-27T09:21:53.24455Z","shell.execute_reply.started":"2021-06-27T09:21:37.636207Z","shell.execute_reply":"2021-06-27T09:21:53.243195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"1.1\"></a>\n<h3 style=\"background-color:orange;font-family:newtimeroman;font-size:250%;text-align:center;border-radius: 15px 50px;\">Data Loading</h3>","metadata":{}},{"cell_type":"code","source":"s_data = pd.read_csv('/kaggle/input/cpg-values-of-smoking-and-non-smoking-patients/Smoker_Epigenetic_df.csv')\ns_data.Gender = s_data.Gender.str.lower()\ns_data.drop(columns=['GSM'],inplace=True)\ns_data.head(3)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-27T09:21:53.246383Z","iopub.execute_input":"2021-06-27T09:21:53.246718Z","iopub.status.idle":"2021-06-27T09:21:53.319403Z","shell.execute_reply.started":"2021-06-27T09:21:53.246685Z","shell.execute_reply":"2021-06-27T09:21:53.318197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"1.1\"></a>\n<h3 style=\"background-color:orange;font-family:newtimeroman;font-size:250%;text-align:center;border-radius: 15px 50px;\">Exploratory Data Analysis</h3>\n","metadata":{}},{"cell_type":"code","source":"plt.title('Number of Missing Values at Each Feature')\nsns.heatmap(s_data.isna().sum().to_frame(),cmap='coolwarm',linewidth=2,annot=True)\ns_data.dropna(inplace=True)\nplt.show()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T09:21:53.321377Z","iopub.execute_input":"2021-06-27T09:21:53.3217Z","iopub.status.idle":"2021-06-27T09:21:54.133689Z","shell.execute_reply.started":"2021-06-27T09:21:53.321668Z","shell.execute_reply":"2021-06-27T09:21:54.132904Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Apparently, there are 62 samples in our dataset the are missing all their genetic features; as we are interested in exploring genetic attributes, we will drop the missing samples in this stage, but it may be interesting to try and treat those samples as a test set for a predictive model and try to replace the missing value with the predictive model.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure()\n\nax1 = plt.subplot(221)\nax1.set_title('Distribution of Genders')\nsns.countplot(x=s_data['Gender'],ax=ax1,palette=['tab:pink','tab:blue'])\nax2 = plt.subplot(222)\nax2.set_title('Distribution of Smoking Labels')\nsns.countplot(x=s_data['Smoking Status'],ax=ax2)\nax3 = plt.subplot(212)\nax3.set_title('Distribution of Sample Ages')\nsns.histplot(data=s_data['Age'],ax=ax3,kde=True)\n\n\nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T09:21:54.135Z","iopub.execute_input":"2021-06-27T09:21:54.135445Z","iopub.status.idle":"2021-06-27T09:21:54.763153Z","shell.execute_reply.started":"2021-06-27T09:21:54.135413Z","shell.execute_reply":"2021-06-27T09:21:54.762342Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation**: depending on our questions of interest, we will have to take in mind that our dataset is imbalanced both gender-wise and smoking status wise as well as our dataset age distribution appearing to be negatively skewed; such skewness reduces the confidence of our inference and models among younger patients as the average age is centered around 55.","metadata":{}},{"cell_type":"code","source":"joyplot(\n    data=s_data[list(s_data.columns[4:])], \n    figsize=(15, 12),\n    alpha=0.85\n    ,title='Difference in Probe Methylation Distribution Across Given Cites'\n\n)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T09:21:54.764278Z","iopub.execute_input":"2021-06-27T09:21:54.764727Z","iopub.status.idle":"2021-06-27T09:21:56.442941Z","shell.execute_reply.started":"2021-06-27T09:21:54.764696Z","shell.execute_reply":"2021-06-27T09:21:56.441816Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation**: looking at the distribution of each individual probe we can see that many of our probes follow a bimodal distribution this can point out to 2 distinct underlying groups in our data.\nWe have 2 known to us groups: smokers and non-smokers and females/males, but it is not exclusive to those groups. We may uncover an underlying group originating on the ages of our patients, for example.","metadata":{}},{"cell_type":"code","source":"joyplot(\n    data=s_data[list(s_data.columns[4:])+['Smoking Status']], \n    figsize=(13, 8),\n    by='Smoking Status',\n    alpha=0.85\n    ,title='Difference in Probe Methylation Between Smoking Status'\n\n)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T09:21:56.4442Z","iopub.execute_input":"2021-06-27T09:21:56.444525Z","iopub.status.idle":"2021-06-27T09:21:57.414553Z","shell.execute_reply.started":"2021-06-27T09:21:56.444491Z","shell.execute_reply":"2021-06-27T09:21:57.413829Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation**: when looking at the difference in the distribution of methylation level in our probes, we see no significant visible difference between smokers and non-smokers.","metadata":{}},{"cell_type":"code","source":"joyplot(\n    data=s_data[list(s_data.columns[4:])+['Gender']], \n    figsize=(13, 8),\n    by='Gender',\n    alpha=0.85,title='Difference in Probe Methylation Between Genders'\n)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T09:21:57.415562Z","iopub.execute_input":"2021-06-27T09:21:57.415974Z","iopub.status.idle":"2021-06-27T09:21:58.378441Z","shell.execute_reply.started":"2021-06-27T09:21:57.415943Z","shell.execute_reply":"2021-06-27T09:21:58.377706Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation**: We can see that when looking at the difference in distribution based on gender, there is an amazingly significant difference between the two genders, the genetic explanations behind this difference are unclear to me as we do not have the associated genes to our probes in our dataset.","metadata":{}},{"cell_type":"code","source":"#Encoding Categorical Features\ns_data.Gender = s_data.Gender.astype('category').cat.codes\ns_data['Smoking Status'] = s_data['Smoking Status'].astype('category').cat.codes","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T09:21:58.380441Z","iopub.execute_input":"2021-06-27T09:21:58.380858Z","iopub.status.idle":"2021-06-27T09:21:58.388451Z","shell.execute_reply.started":"2021-06-27T09:21:58.380828Z","shell.execute_reply":"2021-06-27T09:21:58.387528Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cx = sns.clustermap(np.round(s_data.corr(),2),linewidth=0.8,cmap='vlag',figsize=(15,15),annot=True,annot_kws=dict(fontsize=11))\ncx.ax_row_dendrogram.set_visible(False)\ncx.ax_col_dendrogram.set_visible(False)\ncx.fig.suptitle('Pearson Correlation Between Features') \ncx.fig.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T09:21:58.390065Z","iopub.execute_input":"2021-06-27T09:21:58.390561Z","iopub.status.idle":"2021-06-27T09:22:02.346058Z","shell.execute_reply.started":"2021-06-27T09:21:58.390527Z","shell.execute_reply":"2021-06-27T09:22:02.344962Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation**: looking at the clustered Pearson correlations, we see many features correlated to each other, especially our probes.\nSuch an observation leads us to believe that we have multicollinearity in our data and that we most likely cannot assume independence between all the probes we are working with. Next, we will try and reduce the dimensionality of our data and try to confirm our hypothesis.\nIf the same data in a reduced dimension will have a high EVR, we will continue our analysis with the more appropriate reduced dimension.","metadata":{}},{"cell_type":"code","source":"pca = PCA(2)\ntransformed = pca.fit_transform(s_data.iloc[:,4:])\nt_df = pd.DataFrame(transformed,columns=['pc1','pc2'])\nt_df['Gender'] = s_data.Gender\nt_df['Age'] = s_data.Age\nt_df['Smoking Status'] = s_data['Smoking Status']\n\nsns.barplot(x=['PC_1','PC_2'],y=pca.explained_variance_ratio_)\nsns.pointplot(x=['PC_1','PC_2'],y=np.cumsum(pca.explained_variance_ratio_),lw=5,legend=True,label='Cumulative',color='tab:red')\nplt.ylabel('Explained Variance')\nplt.title('Explained Variance Ratio After Projecting $R^{20} \\longrightarrow R^{2}$')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T09:22:02.347355Z","iopub.execute_input":"2021-06-27T09:22:02.347636Z","iopub.status.idle":"2021-06-27T09:22:02.778323Z","shell.execute_reply.started":"2021-06-27T09:22:02.347609Z","shell.execute_reply":"2021-06-27T09:22:02.776992Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation**: Looking at the amount of variance we are able to preserve even after projecting our data to a 2-dimensional space confirms our prior hypothesis, being able to preserve more than 80% of the variance with just 2 Principal Components is amazing.","metadata":{}},{"cell_type":"code","source":"ax1 = plt.subplot(221)\nax1.set_title('$R^{2}$ Reduced Dimension of Our Genomic Representation of Each Sample',fontsize=15)\nsns.scatterplot(x=t_df['pc1'],y=t_df['pc2'],hue=t_df['Gender'],ax=ax1)\nax1.set_title('$R^{2}$ Reduced Dimension of Our Genomic Representation of Each Sample',fontsize=15)\nax2 = plt.subplot(223)\nsns.scatterplot(x=t_df['pc1'],y=t_df['pc2'],hue=t_df['Smoking Status'],ax=ax2)\nax3 = plt.subplot(122)\nsns.scatterplot(x=t_df['pc1'],y=t_df['pc2'],size=t_df['Age'],hue=t_df['Age'],ax=ax3)\nax2.set_title('$R^{2}$ Reduced Dimension of Our Genomic Representation of Each Sample',fontsize=15)\nax3.set_title('$R^{2}$ Reduced Dimension of Our Genomic Representation of Each Sample',fontsize=15)\n\nplt.tight_layout()\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T09:22:02.77971Z","iopub.execute_input":"2021-06-27T09:22:02.780056Z","iopub.status.idle":"2021-06-27T09:22:04.040869Z","shell.execute_reply.started":"2021-06-27T09:22:02.780021Z","shell.execute_reply":"2021-06-27T09:22:04.039817Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation**: now that we represent all our 20 probes with linear combinations consisting of 2 coefficients, we revisit the analysis we performed based on ridge plots in an earlier section, and here the massive difference between the genders is clear as day light!","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1.1\"></a>\n<h3 style=\"background-color:orange;font-family:newtimeroman;font-size:250%;text-align:center;border-radius: 15px 50px;\">Probabilistic Inference</h3>\n","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nplt.title('Gender vs PC 1 Value')\nsns.scatterplot(x=t_df['pc1'],y=t_df['Gender'])\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T09:22:04.042065Z","iopub.execute_input":"2021-06-27T09:22:04.042362Z","iopub.status.idle":"2021-06-27T09:22:04.311456Z","shell.execute_reply.started":"2021-06-27T09:22:04.042334Z","shell.execute_reply":"2021-06-27T09:22:04.310462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks clear that *the probability* of being male increases as the first Principal Component increases. We are interested in modeling the probability here. The best we can do is ask, \"At PC1 Value $X$, what is the probability of a being male?\". The goal of the following experiment is that question.\n\nWe need a function of PC1, call it $p(X)$, that is bounded between 0 and 1 and changes from 1 to 0 as we increase PC1. Such a function is well defined and known to us all, the *logistic function.*\n\n$$p(X) = \\frac{1}{ 1 + e^{ \\;\\beta X } } $$\n\nIn this model, $\\beta$ is the variable we are uncertain about. Below are some examples for different value of beta plotted for $\\beta = -2, 52, 7$.","metadata":{}},{"cell_type":"code","source":"plt.title('Different Values of Beta Example')\nx = np.linspace(-4, 4, 100)\nplt.plot(x, 1.0 / (1.0 + np.exp(-2 * x)), label=r\"$\\beta = -2$\",lw=3)\nplt.plot(x, 1.0 / (1.0 + np.exp(52 * x)), label=r\"$\\beta = 52$\",lw=3)\nplt.plot(x, 1.0 / (1.0 + np.exp(7 * x) ), label=r\"$\\beta = 7$\",lw=3)\nplt.legend();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T09:22:04.312637Z","iopub.execute_input":"2021-06-27T09:22:04.312915Z","iopub.status.idle":"2021-06-27T09:22:04.630823Z","shell.execute_reply.started":"2021-06-27T09:22:04.312888Z","shell.execute_reply":"2021-06-27T09:22:04.629739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can *shift* our logsitic function along the x axis by adding some constant $\\alpha$ to our exponent, i.e.\n\n$$p(X) = \\frac{1}{ 1 + e^{ \\;\\beta X + \\alpha } } $$\n","metadata":{}},{"cell_type":"code","source":"plt.title('Different Values of Beta and Alpha Example')\nx = np.linspace(-4, 4, 100)\nplt.plot(x, 1.0 / (1.0 + np.exp(-2 * x)), label=r\"$\\beta = -2$\",ls=\"--\", lw=3)\nplt.plot(x, 1.0 / (1.0 + np.exp(52 * x)), label=r\"$\\beta = 52$\",ls=\"--\", lw=3)\nplt.plot(x, 1.0 / (1.0 + np.exp(7 * x) ), label=r\"$\\beta = 7$\", ls=\"--\", lw=3)\n\nplt.plot(x, 1.0 / (1.0 + np.exp(-2 * x+3)), label=r\"$\\beta = -2 \\alpha = 3$\",\n         color=\"#348ABD\")\nplt.plot(x, 1.0 / (1.0 + np.exp(52 * x-1)), label=r\"$\\beta = 52 \\alpha = -1$\",\n         color=\"#A60628\")\nplt.plot(x, 1.0 / (1.0 + np.exp(7 * x+2) ), label=r\"$\\beta = 7 \\alpha = 2$\",\n         color=\"#7A68A6\")\n\nplt.legend(loc=\"lower left\");","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T09:22:04.632656Z","iopub.execute_input":"2021-06-27T09:22:04.63312Z","iopub.status.idle":"2021-06-27T09:22:05.006443Z","shell.execute_reply.started":"2021-06-27T09:22:04.633074Z","shell.execute_reply":"2021-06-27T09:22:05.005087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"$$ \\text{Sample is Male, $M_i$} \\sim \\text{Ber}( \\;p(PC1_i)\\; ), \\;\\; i=1..N$$\n\nwhere $p(PC1)$ is our logistic function and $PC1_i$ are the PC1 values.","metadata":{}},{"cell_type":"code","source":"with pm.Model() as model:\n    beta = pm.Normal(\"beta\", mu=0, tau=0.001, testval=0)\n    alpha = pm.Normal(\"alpha\", mu=0, tau=1/t_df.pc1.std(), testval=0)\n    p = pm.Deterministic(\"p_parm\", 1.0/(1. + tt.exp(beta*t_df.pc1 + alpha)))","metadata":{"execution":{"iopub.status.busy":"2021-06-27T09:22:05.008402Z","iopub.execute_input":"2021-06-27T09:22:05.00889Z","iopub.status.idle":"2021-06-27T09:22:21.725973Z","shell.execute_reply.started":"2021-06-27T09:22:05.008837Z","shell.execute_reply":"2021-06-27T09:22:21.724691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Notice in the above code we had to set the values of `beta` and `alpha` to 0. The reason for this is that if `beta` and `alpha` are very large, they make `p` equal to 1 or 0. Unfortunately, `pm.Bernoulli` does not like probabilities of exactly 0 or 1, though they are mathematically well-defined probabilities. So by setting the coefficient values to `0`, we set the variable `p` to be a reasonable starting value.","metadata":{}},{"cell_type":"code","source":"with model:\n    observed = pm.Bernoulli(\"obs\", p, observed=t_df.Gender)\n    start = pm.find_MAP()\n    step = pm.Metropolis()\n    trace = pm.sample(120000, step=step, start=start)\n    burned_trace = trace[100000::2]","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-06-27T09:22:21.727705Z","iopub.execute_input":"2021-06-27T09:22:21.728142Z","iopub.status.idle":"2021-06-27T09:25:17.782938Z","shell.execute_reply.started":"2021-06-27T09:22:21.728095Z","shell.execute_reply":"2021-06-27T09:25:17.781667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alpha_samples = burned_trace[\"alpha\"][:, None]\nbeta_samples = burned_trace[\"beta\"][:, None]\nplt.subplot(211)\nplt.title(r\"Posterior distributions of the variables $\\alpha, \\beta$\")\nsns.histplot(beta_samples, bins=35, alpha=0.85,label=r\"posterior of $\\beta$\", palette=[\"#7A68A6\"],stat='probability')\nplt.legend()\n\nplt.subplot(212)\nsns.histplot(alpha_samples, bins=35, alpha=0.85,label=r\"posterior of $\\alpha$\", palette=[\"#A60628\"],stat='probability')\nplt.legend();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T09:25:17.784667Z","iopub.execute_input":"2021-06-27T09:25:17.785012Z","iopub.status.idle":"2021-06-27T09:25:18.871631Z","shell.execute_reply.started":"2021-06-27T09:25:17.784973Z","shell.execute_reply":"2021-06-27T09:25:18.870708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All samples of $\\beta$ are smaller than 0. If instead the posterior was centered around 0, we may suspect that $\\beta = 0$, implying that PC1 has no effect on the probability of being Male based on PC1. \n\nIn contrast, all $\\alpha$ posterior values are centered around 0, implying that it is correct to believe that $\\alpha$ is close to 0. \n  \n\nNext, let's look at the *expected probability* for a specific value of PC1. That is, we average over all samples from the posterior to get a likely value for $p(PC1_i)$.","metadata":{}},{"cell_type":"code","source":"t = np.linspace(t_df.pc1.min() - 2, t_df.pc1.max()+2, 50)[:, None]\ndef logistic(x, beta, alpha=0):\n    return 1.0 / (1.0 + np.exp(np.dot(beta, x) + alpha))\np_t = logistic(t.T, beta_samples, alpha_samples)\n\nmean_prob_t = p_t.mean(axis=0)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T09:25:18.872842Z","iopub.execute_input":"2021-06-27T09:25:18.873161Z","iopub.status.idle":"2021-06-27T09:25:18.934659Z","shell.execute_reply.started":"2021-06-27T09:25:18.873131Z","shell.execute_reply":"2021-06-27T09:25:18.933254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(t, mean_prob_t, lw=3, label=\"average posterior \\nprobability \\ of defect\")\nplt.plot(t, p_t[0, :], ls=\"--\", label=\"realization from posterior\")\nplt.plot(t, p_t[-2, :], ls=\"--\", label=\"realization from posterior\")\nplt.scatter(t_df.pc1, t_df.Gender, color=\"tab:red\", s=50, alpha=0.5)\nplt.title(\"Posterior expected value of probability of being Male; \\\nplus realizations\")\nplt.legend()\nplt.ylim(-0.1, 1.1)\nplt.xlim(t.min(), t.max())\nplt.ylabel(\"probability\")\nplt.xlabel(\"temperature\");","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T09:25:18.936586Z","iopub.execute_input":"2021-06-27T09:25:18.937073Z","iopub.status.idle":"2021-06-27T09:25:19.29584Z","shell.execute_reply.started":"2021-06-27T09:25:18.937028Z","shell.execute_reply":"2021-06-27T09:25:19.294714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above we also plotted two possible realizations of what the actual underlying system might be. Both are equally likely as any other draw. The blue line is what occurs when we average all the 242000 possible dotted lines together.\n\nAn interesting question to ask is for what PC1 value are we most uncertain about the male gender probability? Below we plot the expected value line **and** the associated 95% intervals for each temperature. ","metadata":{}},{"cell_type":"code","source":"qs = mquantiles(p_t, [0.025, 0.975], axis=0)\nplt.fill_between(t[:, 0], *qs, alpha=0.7,color=\"#7A68A6\")\nplt.plot(t[:, 0], qs[0], label=\"95% CI\", color=\"#7A68A6\", alpha=0.7)\nplt.plot(t, mean_prob_t, lw=1, ls=\"--\", color=\"k\",\n         label=\"average posterior \\nprobability of defect\")\nplt.xlim(t.min(), t.max())\nplt.ylim(-0.02, 1.02)\nplt.legend()\nsns.scatterplot(x=t_df.pc1,y= t_df.Gender, color=\"tab:red\", s=50, alpha=0.5)\nplt.xlabel(\"$PC_1$, $X$\")\nplt.ylabel(\"probability estimate\")\nplt.title(\"Posterior probability estimates given $PC_1$ Value. $X$\");","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T09:25:19.297603Z","iopub.execute_input":"2021-06-27T09:25:19.298066Z","iopub.status.idle":"2021-06-27T09:25:19.715319Z","shell.execute_reply.started":"2021-06-27T09:25:19.298018Z","shell.execute_reply":"2021-06-27T09:25:19.713811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The *95% credible interval*, or 95% CI, painted in purple, represents the interval, for each $PC_1$ value, that contains 95% of the distribution. For example, at 0.01 , we can be 95% sure that the probability of being male between 0.98 and 0.99.","metadata":{}}]}