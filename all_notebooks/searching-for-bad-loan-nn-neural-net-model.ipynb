{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Import libraries\n\n# data anlysis\nimport numpy as np\nimport pandas as pd\n\n# data visualization\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# data preparation for modelling\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\n\nimport time\nimport tensorflow as tf\nimport pandas as pd\nimport os\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\nfrom keras import Sequential\nfrom keras import layers\nfrom keras import backend as K\nfrom keras.layers.core import Dense\nfrom keras import regularizers\nfrom keras.layers import Dropout , BatchNormalization\nfrom keras.constraints import max_norm\n\n# ensure comparability of different runs\nnp.random.seed(2020)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df = pd.read_pickle(\"../input/handling-imbalanced-data-eda-small-fe/df_for_use.pkl\")\n# df_fe = pd.read_pickle(\"../input/handling-imbalanced-data-eda-small-fe/df_fe.pkl\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_pickle('../input/searching-for-bad-loan-data-preprocessing/df_pp.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X = df.drop('Loan_status', axis=1)\n# # x_dd = X.copy()\n# # from sklearn.preprocessing import StandardScaler\n# # from sklearn.preprocessing import MinMaxScaler\n# # minMaxScaler = MinMaxScaler()\n# # minMaxScaler.fit(X)\n# # X_scaled = minMaxScaler.transform(X)\n\n# # X= pd.DataFrame(X_scaled, columns=x_dd.columns)\n# # X = reduce_mem_usage(X)\n# y = df['Loan_status']\n\n# from sklearn import preprocessing as pp\n# featuresToScale = X.columns\n# sX = pp.MinMaxScaler(copy=True)\n# X.loc[:,featuresToScale] = sX.fit_transform(X[featuresToScale])\n\n\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 , random_state = 2020, stratify = y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# numerical_transformer = Pipeline(steps=[\n#     ('imputer', SimpleImputer(strategy='mean')),\n#     ('scaler', StandardScaler())\n# ])\n\n# categorical_transformer = Pipeline(steps=[\n#     ('imputer', SimpleImputer(strategy='most_frequent',)),\n#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n# ])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Categorical Features in the dataset:, home_ownership, term, application_type, purpose, region.\n\nOrdinal Features in the dataset :emp_length_int, grade, interest_payments, income_category\n\nContinous Features in the dataset: loan_amount, annual_inc, interest_rate, dti, total_pymnt, recoveries, installment","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = [ 'home_ownership_cat', 'term_cat', 'application_type_cat', 'purpose_cat', 'region','emp_length_int', 'grade_cat', 'interest_payment_cat', 'income_cat' ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = ['loan_amount', 'annual_inc', 'interest_rate', 'dti', 'total_pymnt', 'recoveries', 'installment']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop('Loan_status', axis=1)\n# x_dd = X.copy()\n# from sklearn.preprocessing import StandardScaler\n# from sklearn.preprocessing import MinMaxScaler\n# minMaxScaler = MinMaxScaler()\n# minMaxScaler.fit(X)\n# X_scaled = minMaxScaler.transform(X)\n\n# X= pd.DataFrame(X_scaled, columns=x_dd.columns)\n# X = reduce_mem_usage(X)\ny = data['Loan_status']\n\nfrom sklearn import preprocessing as pp\nfeaturesToScale = X.columns\nsX = pp.MinMaxScaler(copy=True)\nX.loc[:,featuresToScale] = sX.fit_transform(X[featuresToScale])\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 , random_state = 2020, stratify = y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_dim = X_train.shape[1]\ninput_dim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add RUC metric to monitor NN\ndef auc(y_true, y_pred):\n    auc = tf.metrics.auc(y_true, y_pred)[1]\n    K.get_session().run(tf.local_variables_initializer())\n    return auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(64, input_dim = 31 , kernel_initializer = 'uniform', kernel_regularizer=regularizers.l2(0.005),activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32,  kernel_initializer = 'uniform',kernel_regularizer=regularizers.l2(0.005),activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(16,  kernel_initializer = 'uniform',kernel_regularizer=regularizers.l2(0.005),activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_logloss', optimizer='adam', metrics=['accuracy' ,auc])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.AUC()])\nearlystopper = EarlyStopping(monitor='val_loss', patience = 20, verbose=1)\nstart = time.time() \nmodel.fit(X_train, y_train, epochs=1000,validation_split=0.2,  batch_size = 512, callbacks=[earlystopper] )\nnn_runtime = time.time() - start","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( ' Neural Net Runtime : {0:.4f}'.format(nn_runtime ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve ,auc , log_loss ,  classification_report ,average_precision_score\n\npred = model.predict(X_test)\npred = pd.DataFrame(data = pred , dtype=np.float32)\ny_test =  pd.DataFrame(data = y_test)\ny_test.reset_index(inplace = True)\ny_test.drop('index',axis=1,inplace=True)\npreds = pd.concat([y_test,pred], axis=1)\npreds.columns = ['trueLabel','prediction']\n# predictionsBasedOnKFoldsXGBoostGradientBoosting = preds.copy()\n\nprecision, recall, thresholds = \\\n    precision_recall_curve(preds['trueLabel'],preds['prediction'])\naverage_precision = \\\n    average_precision_score(preds['trueLabel'],preds['prediction'])\n\nplt.step(recall, precision, color='k', alpha=0.7, where='post')\nplt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.ylim([0.0, 1.05])\nplt.xlim([0.0, 1.0])\n\nplt.title('Precision-Recall curve: Average Precision = {0:0.2f}'.format(\n          average_precision))\n\nfpr, tpr, thresholds = roc_curve(preds['trueLabel'],preds['prediction'])\nareaUnderROC = auc(fpr, tpr)\n\nplt.figure()\nplt.plot(fpr, tpr, color='r', lw=2, label='ROC curve')\nplt.plot([0, 1], [0, 1], color='k', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic: \\\n        Area under the curve = {0:0.2f}'.format(areaUnderROC))\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NN_roc_auc_score = roc_auc_score(y_test, model.predict(X_test))\n\nprint( 'NeuralNet_ROC_AUC : {0:.4f} '.format(NN_roc_auc_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}