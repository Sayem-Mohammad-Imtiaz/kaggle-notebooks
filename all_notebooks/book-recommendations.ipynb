{"cells":[{"metadata":{"id":"YHVJakOuZwAk"},"cell_type":"markdown","source":"Book Recommender System using [Book Crossing Dataset](http://www2.informatik.uni-freiburg.de/~cziegler/BX/)"},{"metadata":{"id":"2uBqws4TZwAz"},"cell_type":"markdown","source":"### Importing Usual Libraries"},{"metadata":{"id":"V3qjBzw5ZwAz","trusted":true},"cell_type":"code","source":"import numpy as np          # linear algebra\nimport pandas as pd         # data processing\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nimport warnings; warnings.simplefilter('ignore')","execution_count":null,"outputs":[]},{"metadata":{"id":"7J0HLbUjZwA1"},"cell_type":"markdown","source":"### Importing Dataset"},{"metadata":{"id":"KvNsG9t7ZwA1","outputId":"c84882d1-5e2a-43fc-e121-6da339fbd67e","trusted":true},"cell_type":"code","source":"book_data = pd.read_csv('../input/bookcrossing-dataset/Book reviews/BX_Books.csv', sep=';', error_bad_lines=False, encoding=\"latin-1\")\nbook_data.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"fXrfW-w2ZwA3"},"cell_type":"markdown","source":"* Let's see how one previously problematic line looks now after correction! "},{"metadata":{"id":"621bwcHpZwA3","outputId":"343f1155-1a9c-4b0a-9e0b-69e4f0ccec6a","trusted":true},"cell_type":"code","source":"book_data[book_data['ISBN']== \"078946697X\"]","execution_count":null,"outputs":[]},{"metadata":{"id":"y-VRmI67ZwA3"},"cell_type":"markdown","source":"Everything looks nice and clean."},{"metadata":{"id":"u1fZVKemZwA4","outputId":"820eeec9-0bc3-4854-dbf3-50131d37fb22","trusted":true},"cell_type":"code","source":"book_data.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"aJAUoM5uZwA4","outputId":"5d4ab656-8d65-4498-880e-a471be02a55c","trusted":true},"cell_type":"code","source":"user_data= pd.read_csv('../input/bookcrossing-dataset/Book reviews/BX-Users.csv', sep= ';', encoding= 'latin-1')\nuser_data.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"tsFviTR4ZwA4","outputId":"b6f2e4eb-f706-47f0-c105-76f62aa74660","trusted":true},"cell_type":"code","source":"rating_data= pd.read_csv('../input/bookcrossing-dataset/Book reviews/BX-Book-Ratings.csv', sep= ';', encoding= 'latin-1')\nrating_data.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"Z_zf9-ltZwA5"},"cell_type":"markdown","source":"### Data Preprocessing"},{"metadata":{"id":"B112GJ9vZwA5"},"cell_type":"markdown","source":"At first, I'll investigate the tables to see if any improvement is needed. Then I will do necessary operations to make the data clean so that I can work better with them."},{"metadata":{"id":"VPnK11jYZwA5","trusted":true},"cell_type":"code","source":"book_data.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], axis= 1, inplace= True)\nbook_data.columns= book_data.columns.str.strip().str.lower().str.replace('-', '_')\nuser_data.columns= user_data.columns.str.strip().str.lower().str.replace('-', '_')\nrating_data.columns= rating_data.columns.str.strip().str.lower().str.replace('-', '_')","execution_count":null,"outputs":[]},{"metadata":{"id":"SPCBk6oVZwA6","trusted":true},"cell_type":"code","source":"pd.set_option('display.max_colwidth', -1)","execution_count":null,"outputs":[]},{"metadata":{"id":"tCqASfWFZwA6","outputId":"66a7eb92-df34-4d50-8dc3-06fdc9d16170","trusted":true},"cell_type":"code","source":"print(book_data.dtypes)\nprint('-'*40)\nprint(book_data.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"id":"VcbmuIrDZwA6"},"cell_type":"markdown","source":"Let's take care of the missing value in 'book_author' column."},{"metadata":{"id":"mxsShqViZwA7","outputId":"301208b9-9a39-4592-fe86-a7519fd9de8c","trusted":true},"cell_type":"code","source":"book_data.loc[(book_data['book_author'].isnull()),: ]","execution_count":null,"outputs":[]},{"metadata":{"id":"8DtaB4t1ZwA7","trusted":true},"cell_type":"code","source":"book_data.loc[(book_data['isbn'] == '9627982032'),'book_author'] = 'other'","execution_count":null,"outputs":[]},{"metadata":{"id":"40ahMg93ZwA7"},"cell_type":"markdown","source":"* Let's look at the unique years to realize the time period as this dataset was created in 2004. "},{"metadata":{"id":"YM7R0eTQZwA7","outputId":"d3af2ec2-413f-47c0-ea5d-479acdded948","trusted":true},"cell_type":"code","source":"book_data['year_of_publication'].unique()","execution_count":null,"outputs":[]},{"metadata":{"id":"X6nNAny2ZwA8","scrolled":false,"trusted":true},"cell_type":"code","source":"# def replace_df_value(df, idx, col_name, val):\n#     df.loc[idx, col_name] = val\n\n\n# replace_df_value(book_data, 209538, 'book_title', 'DK Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)')\n# replace_df_value(book_data, 209538, 'book_author', 'Michael Teitelbaum')\n# replace_df_value(book_data, 209538, 'year_of_publication', 2000)\n# replace_df_value(book_data, 209538, 'publisher', 'DK Publishing Inc')\n\n# replace_df_value(book_data, 221678, 'book_title', 'DK Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers)')\n# replace_df_value(book_data, 221678, 'book_author', 'James Buckley')\n# replace_df_value(book_data, 221678, 'year_of_publication', 2000)\n# replace_df_value(book_data, 221678, 'publisher', 'DK Publishing Inc')\n\n# replace_df_value(book_data, 220731,'book_title', \"Peuple du ciel, suivi de 'Les Bergers\")\n# replace_df_value(book_data, 220731, 'book_author', 'Jean-Marie Gustave Le ClÃ?Â©zio')\n# replace_df_value(book_data, 220731, 'year_of_publication', 2003)\n# replace_df_value(book_data, 220731, 'publisher', 'Gallimard')","execution_count":null,"outputs":[]},{"metadata":{"id":"PLAVeeCNZwA8"},"cell_type":"markdown","source":"* So the corrections are made. We've seen there are two missing values in the 'publisher' column. Let's take care of that."},{"metadata":{"id":"GGWnCnu9ZwA9","trusted":true},"cell_type":"code","source":"book_data.loc[(book_data['publisher'].isnull()),'publisher'] = 'no mention'","execution_count":null,"outputs":[]},{"metadata":{"id":"LdS08R_1ZwA9","outputId":"13d814b1-b01f-44e9-943a-66756d95953d","trusted":true},"cell_type":"code","source":"print(book_data['publisher'].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"id":"A7ie_7SdZwA9"},"cell_type":"markdown","source":"**Let's investigate the user_rating dataset"},{"metadata":{"id":"Dy1zuldAZwA9","outputId":"6b73fb35-5edc-4658-9afc-8a838b93f00e","trusted":true},"cell_type":"code","source":"print(user_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"gb-TgWBaZwA-","outputId":"77465daa-49fc-4a4e-d7e5-4cdea6b91607","trusted":true},"cell_type":"code","source":"user_data['user_id'].unique()","execution_count":null,"outputs":[]},{"metadata":{"id":"oGanhlbTZwA_"},"cell_type":"markdown","source":"* So user_id's alright. Let's check out the age of the users."},{"metadata":{"id":"FwTFfLWAZwBB","outputId":"ccb66692-ec44-4787-b5c8-56e64116a32b","trusted":true},"cell_type":"code","source":"user_data['age'].unique()","execution_count":null,"outputs":[]},{"metadata":{"id":"3ZBc7CbuZwBC","outputId":"f9bdf95f-c267-4d4e-f2da-7c20a3447039","trusted":true},"cell_type":"code","source":"user_data.loc[(user_data['age'] > 90) | (user_data['age'] < 5)] = np.nan\nuser_data['age'].fillna((user_data['age'].mean()), inplace=True)\nuser_data['age']= user_data['age'].astype('int64')\nuser_data['age'].unique()","execution_count":null,"outputs":[]},{"metadata":{"id":"AJlc1w-PZwBC"},"cell_type":"markdown","source":"* We need to investigate out rating dataset too. "},{"metadata":{"id":"30p7-M5uZwBC","outputId":"98eae3fb-18ae-4440-fe6a-84e64ebf329b","trusted":true},"cell_type":"code","source":"rating_data.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"ePYEQIIrZwBD"},"cell_type":"markdown","source":"* I'll only take the ISBNs that also belongs to the main book_data set."},{"metadata":{"id":"Q0r5mKX0ZwBD","trusted":true},"cell_type":"code","source":"unique_ratings = rating_data[rating_data.isbn.isin(book_data.isbn)]","execution_count":null,"outputs":[]},{"metadata":{"id":"Gx7iVKqbZwBD"},"cell_type":"markdown","source":"* Ratings dataset should have ratings from users which exist in users dataset, unless new users are added to users dataset"},{"metadata":{"id":"Xt1tQ3LUZwBD","trusted":true},"cell_type":"code","source":"rating_data = rating_data[rating_data.user_id.isin(user_data.user_id)]","execution_count":null,"outputs":[]},{"metadata":{"id":"o46xxM-6ZwBE","outputId":"eaaa9b24-9db9-41e7-a088-fd53f7004da5","trusted":true},"cell_type":"code","source":"print(rating_data.shape)\nprint(unique_ratings.shape)\nprint(book_data.shape)\nprint(user_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"eD0-gTLaZwBE","outputId":"ef6a93f7-f507-43d9-8ee1-1f8fa7274ad6","trusted":true},"cell_type":"code","source":"unique_ratings['book_rating'].unique()","execution_count":null,"outputs":[]},{"metadata":{"id":"9md9RqRsZwBE"},"cell_type":"markdown","source":"## Visualization"},{"metadata":{"id":"zyI8NH5ZZwBF"},"cell_type":"markdown","source":"Lat's now make some pretty plots to visualize the data. "},{"metadata":{"id":"GD3-XJQWZwBF"},"cell_type":"markdown","source":"The age distribution of the readers: "},{"metadata":{"id":"L_O0tx8IZwBG","outputId":"21c4a0a9-7356-4ffe-dabd-e1c7586df7c5","trusted":true},"cell_type":"code","source":"user_data.age.hist(bins=[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\nplt.title('Age Distribution\\n')\nplt.xlabel('age')\nplt.ylabel('count')\nplt.savefig('age_dist.png', bbox_inches='tight')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"4BZMD41JZwBG"},"cell_type":"markdown","source":"Let's see which rating people tend to give more : "},{"metadata":{"id":"R9HegIvmZwBG","outputId":"f4221326-5e32-49c6-eaff-89b661314f91","trusted":true},"cell_type":"code","source":"sns.set_style('darkgrid')\nsns.countplot(data= unique_ratings , x='book_rating')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"9Yv7XRWEZwBH"},"cell_type":"markdown","source":"This countplot shows users have rated 0 the most, which can mean they haven't rated bokks at all. We have to separate the explicit ratings represented by 1–10 and implicit ratings represented by 0."},{"metadata":{"id":"HJ3VQETBZwBH","trusted":true},"cell_type":"code","source":"ratings_explicit= unique_ratings[unique_ratings['book_rating'] != 0]\nratings_implicit= unique_ratings[unique_ratings['book_rating'] == 0]","execution_count":null,"outputs":[]},{"metadata":{"id":"qGTBuqzjZwBH","outputId":"42910cb9-116e-4b0a-90f4-477e33a260fa","trusted":true},"cell_type":"code","source":"sns.set_style('darkgrid')\nsns.countplot(data= ratings_explicit , x='book_rating')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"AXWWEmKhZwBI"},"cell_type":"markdown","source":"Now this countplot of book_rating indicates that higher ratings are more common amongst users and rating 8 has been rated highest number of times."},{"metadata":{"id":"59WC990MZwBI","trusted":true},"cell_type":"code","source":"# book_data.year_of_publication = pd.to_numeric(book_data.year_of_publication, errors='coerce')\n\n# # Check for 0's or NaNs in Year of Publication\n# zero_year = book_data[book_data.year_of_publication == 0].year_of_publication.count()\n# nan_year = book_data.year_of_publication.isnull().sum()\n\n# print(f'There are {zero_year} entries as \\'0\\', and {nan_year} NaN entries in the Year of Publication field')\n\n# # Replace all years of zero with NaN\n# book_data.year_of_publication.replace(0, np.nan, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"Py6-CZU2ZwBJ"},"cell_type":"markdown","source":"* As the problem of string 'year_of _publication' values was solved in the preprocessing steps, so now there's no need to convert the data types anymore and the code is commented out. Below the plot says there are 4619 'year_of_publication' values ranging from 0-99 which were not visible in the previous notebook. So, I plotted this interactive plot to see more accurately the 'year_of _publication' distribution. "},{"metadata":{"id":"25Z2i2UJZwBK","outputId":"37e1e523-064f-4f37-a22a-f7a98f780881","trusted":true},"cell_type":"code","source":"import plotly.express as px\n\nfig = px.histogram(book_data, x = \"year_of_publication\", nbins = 30, width = 800, height = 500)\nfig.update_xaxes(tick0 = 0 , dtick = 1000)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"h-zm2ZhaZwBO"},"cell_type":"markdown","source":"### Popularity Based Recommendation"},{"metadata":{"id":"tt7oFL3NZwBO"},"cell_type":"markdown","source":"Now let's try to build our first recommendation system based on popularity. This recommendations are usually given to every user irrespective of personal charecterization. "},{"metadata":{"id":"BjAyhtKKZwBQ","outputId":"745cb65b-de89-44cb-d78e-aab8727c6262","trusted":true},"cell_type":"code","source":"ratings_explicit.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"uVY--nsZZwBS","outputId":"b73e0e9e-86ea-45af-f762-7c4845a8a95b","trusted":true},"cell_type":"code","source":"print(unique_ratings.shape)\nprint(ratings_explicit.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"v7FEqcz2ZwBT"},"cell_type":"markdown","source":"I'll only consider ISBNs that were explicitely rated for this recommendation system."},{"metadata":{"id":"Z-QbFdmqZwBX","scrolled":false,"outputId":"5a695c86-4e80-4196-ff72-f180838210b9","trusted":true},"cell_type":"code","source":"new_book_df= pd.merge(book_data, ratings_explicit, on='isbn')\nnew_book_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"0jWF4AGyZwBY","outputId":"02191679-183d-438e-9fb8-3aec6cf84eb6","trusted":true},"cell_type":"code","source":"print(new_book_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"tA2EqxehZwBY","outputId":"10561f58-425a-42a0-b5a3-b3503aa6fab3","trusted":true},"cell_type":"code","source":"new_book_df['book_title'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"id":"1zr6QPoWZwBY","outputId":"46f4007c-c742-4211-8167-55ef8d1b34e0","trusted":true},"cell_type":"code","source":"top_ten_books= pd.DataFrame(new_book_df.groupby('book_title')['book_rating'].count()\n                         .sort_values(ascending=False).head(10))\n\nprint('The top ten books recommendation : ')\ntop_ten_books","execution_count":null,"outputs":[]},{"metadata":{"id":"QmBcM95DZwBY"},"cell_type":"markdown","source":"So our 'All Time Favourite\" book recommendations are ready."},{"metadata":{"id":"QDuXAI-zZwBZ"},"cell_type":"markdown","source":"### Memory-Based Collaborative Filtering"},{"metadata":{"id":"3jGUax47ZwBZ"},"cell_type":"markdown","source":"Memory-Based Collaborative Filtering are of two kinds: \n1. user-item filtering \n2. item-item filtering\n\nA user-item filtering will take a particular user and find users that are similar to that user based on similarity of ratings. Then it will recommend items that are similar to the ones the users liked.\n\nUnlike user-item filtering, item-item filtering will take an item, find users who liked that item, and find other items that those users or similar users also liked. It takes items and recommends other items.\n\n* Item-Item Collaborative Filtering: “Users who liked this item also liked …”\n* User-Item Collaborative Filtering: “Users who are similar to you also liked …”"},{"metadata":{"id":"b4b5qDvWaxQj","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"S_XybHlGZwBZ"},"cell_type":"markdown","source":"### Train - Test Split"},{"metadata":{"id":"aiUftBx4ZwBZ","trusted":true},"cell_type":"code","source":"from sklearn import model_selection\ntrain_data, test_data = model_selection.train_test_split(new_book_df, test_size=0.20)","execution_count":null,"outputs":[]},{"metadata":{"id":"Lc81rT8qZwBZ","outputId":"2f26b70a-cdf1-41ee-c5a5-f7c68a9e78ad","trusted":true},"cell_type":"code","source":"print(f'Training set lengths: {len(train_data)}')\nprint(f'Testing set lengths: {len(test_data)}')\nprint(f'Test set is {(len(test_data)/(len(train_data)+len(test_data))*100):.0f}% of the full dataset.')","execution_count":null,"outputs":[]},{"metadata":{"id":"oZQMi7sAZwBa","trusted":true},"cell_type":"code","source":"# Get int mapping for user_id in train dataset\n\nu_unique_train = train_data.user_id.unique()  \ntrain_data_user2idx = {o:i for i, o in enumerate(u_unique_train)}\n\n# Get int mapping for isbn in train dataset\n\ni_unique_train = train_data.isbn.unique()  \ntrain_data_book2idx = {o:i for i, o in enumerate(i_unique_train)}\n\n# Get int mapping for user_id in test dataset\n\nu_unique_test = test_data.user_id.unique()  \ntest_data_user2idx = {o:i for i, o in enumerate(u_unique_test)}\n\n# Get int mapping for isbn in train dataset\n\ni_unique_test = test_data.isbn.unique() \ntest_data_book2idx = {o:i for i, o in enumerate(i_unique_test)}\n","execution_count":null,"outputs":[]},{"metadata":{"id":"qx5BQRwUZwBa","trusted":true},"cell_type":"code","source":"# TRAINING SET\ntrain_data['u_unique'] = train_data['user_id'].map(train_data_user2idx)\ntrain_data['i_unique'] = train_data['isbn'].map(train_data_book2idx)\n\n# TESTING SET\ntest_data['u_unique'] = test_data['user_id'].map(test_data_user2idx)\ntest_data['i_unique'] = test_data['isbn'].map(test_data_book2idx)\n\n# Convert back to 3-column df\ntrain_data = train_data[['u_unique', 'i_unique', 'book_rating']]\ntest_data = test_data[['u_unique', 'i_unique', 'book_rating']]","execution_count":null,"outputs":[]},{"metadata":{"id":"J5KJS4m5ZwBa","outputId":"cb48940e-6d78-474a-e66c-4b2d2eaca0a9","trusted":true},"cell_type":"code","source":"train_data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"id":"uyFgraOQZwBa"},"cell_type":"markdown","source":"### User-Item Matrix for Train Data"},{"metadata":{"id":"GjerDPO3ZwBa"},"cell_type":"markdown","source":"At first I'll create an empty matrix of users * books and the will add the appropriate values to the matrix by extracting them from the dataset."},{"metadata":{"id":"j7B3W1CyZwBb","trusted":true},"cell_type":"code","source":"n_users = train_data['u_unique'].nunique()\nn_books = train_data['i_unique'].nunique()\n\ntrain_matrix = np.zeros((n_users, n_books))\n\nfor entry in train_data.itertuples():                  # entry[1] is the user-id, entry[2] is the book-isbn\n    train_matrix[entry[1]-1, entry[2]-1] = entry[3]    # -1 is to counter 0-based indexing","execution_count":null,"outputs":[]},{"metadata":{"id":"vxT-UnsdZwBb","trusted":true},"cell_type":"code","source":"train_matrix.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"XAgit1d2ZwBb"},"cell_type":"markdown","source":"### User-Item Matrix for Test Data"},{"metadata":{"id":"2cNX7qhYZwBb","trusted":true},"cell_type":"code","source":"n_users = test_data['u_unique'].nunique()\nn_books = test_data['i_unique'].nunique()\n\ntest_matrix = np.zeros((n_users, n_books))\n\nfor entry in test_data.itertuples():\n    test_matrix[entry[1]-1, entry[2]-1] = entry[3] ","execution_count":null,"outputs":[]},{"metadata":{"id":"Oyj0PlXDZwBb","trusted":true},"cell_type":"code","source":"test_matrix.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"ztZFqCTOZwBc"},"cell_type":"markdown","source":"### Cosine Similarity Based Recommendation System"},{"metadata":{"id":"K7hN0-rcZwBc"},"cell_type":"markdown","source":"As I am doing this calculations on my PC, so it is not a good idea to perform this huge calculation. So I'll perform on a subset initially. It will take a bit of time to calculate."},{"metadata":{"id":"cOEW_VfLZwBc"},"cell_type":"markdown","source":"A distance metric commonly used in recommender systems is *cosine similarity*, where the ratings are seen as vectors in ``n``-dimensional space and the similarity is calculated based on the angle between these vectors. "},{"metadata":{"id":"U2R2TyEAZwBd"},"cell_type":"markdown","source":"To make item-item similarity we need to take the transpose of the matrix."},{"metadata":{"id":"HRrAwDshZwBd","trusted":true},"cell_type":"code","source":"train_matrix_small = train_matrix[:5000, :5000]\ntest_matrix_small = test_matrix[:5000, :5000]\n\nfrom sklearn.metrics.pairwise import pairwise_distances\nuser_similarity = pairwise_distances(train_matrix_small, metric='cosine')\nitem_similarity = pairwise_distances(train_matrix_small.T, metric='cosine') ","execution_count":null,"outputs":[]},{"metadata":{"id":"gnKB-MYrZwBd"},"cell_type":"markdown","source":"Now I'll define a function to predict the similarity :"},{"metadata":{"id":"ZXrTidHYZwBe","trusted":true},"cell_type":"code","source":"def predict_books(ratings, similarity, type='user'): # default type is 'user'\n    if type == 'user':\n        mean_user_rating = ratings.mean(axis=1)\n        \n        # Use np.newaxis so that mean_user_rating has the same format as ratings\n        \n        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n    elif type == 'item':\n        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n    return pred","execution_count":null,"outputs":[]},{"metadata":{"id":"fwGvf5p3ZwBe","trusted":true},"cell_type":"code","source":"item_prediction = predict_books(train_matrix_small, item_similarity, type='item')\nuser_prediction = predict_books(train_matrix_small, user_similarity, type='user')","execution_count":null,"outputs":[]},{"metadata":{"id":"yfZJqRh_ZwBe"},"cell_type":"markdown","source":"### Evaluation"},{"metadata":{"id":"tnMTpjV0ZwBe","trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\ndef rmse(prediction, test_matrix):\n    prediction = prediction[test_matrix.nonzero()].flatten()\n    test_matrix = test_matrix[test_matrix.nonzero()].flatten()\n    return sqrt(mean_squared_error(prediction, test_matrix))\n\nprint(f'Item-based CF RMSE: {rmse(item_prediction, test_matrix_small)}')\nprint(f'User-based CF RMSE: {rmse(user_prediction, test_matrix_small)}')\n","execution_count":null,"outputs":[]},{"metadata":{"id":"LQapCN8rZwBe"},"cell_type":"markdown","source":"* We see our recommendation system gives 7.94 RMSE score. I want to check if we can make any improvement in this score by using another method. For this I will use Single valu decomposition method from the Surprise library."},{"metadata":{"id":"KxZvlLUoZwBe"},"cell_type":"markdown","source":"### SVD Based recommendation System"},{"metadata":{"id":"eBfblRx1ZwBf","trusted":true},"cell_type":"code","source":"from surprise import Reader, Dataset\n\n# Creating a 'Reader' object to set the limit of the ratings \n\nreader = Reader(rating_scale=(1, 10))\n\ndata = Dataset.load_from_df(ratings_explicit, reader)","execution_count":null,"outputs":[]},{"metadata":{"id":"zdVtQborZwBf","trusted":true},"cell_type":"code","source":"from surprise import SVD, model_selection, accuracy\n\nmodel = SVD()\n\n# Train on books dataset\n\n%time model_selection.cross_validate(model, data, measures=['RMSE'], cv=5, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"I1yeNZ44ZwBf"},"cell_type":"markdown","source":"### Train - Test Split"},{"metadata":{"id":"sTdvsIeYZwBf","trusted":true},"cell_type":"code","source":"trainset, testset = model_selection.train_test_split(data, test_size=0.2)\n\nmodel = SVD()\n\nmodel.fit(trainset)\npredictions = model.test(testset)\n\naccuracy.rmse(predictions)","execution_count":null,"outputs":[]},{"metadata":{"id":"GojlY6o5ZwBg"},"cell_type":"markdown","source":"We see the RMSE score has improved a lot. It is now on average 1.64 which is pretty good. "},{"metadata":{"id":"JT31uqVcZwBh"},"cell_type":"markdown","source":"### Testing Results !"},{"metadata":{"id":"_YutEEuWZwBh"},"cell_type":"markdown","source":"Let's take an arbitrary user-id and item-id to test our model. "},{"metadata":{"id":"MtIB67MFZwBi","trusted":true},"cell_type":"code","source":"uid = 276744  \niid = '038550120X' \npred = model.predict(uid, iid, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"hXLGhSndZwBj","trusted":true},"cell_type":"code","source":"print(f'The estimated rating for the book with ISBN code {pred.iid} from user #{pred.uid} is {pred.est:.2f}.\\n')\nactual_rtg= ratings_explicit[(ratings_explicit.user_id==pred.uid) & \n                             (ratings_explicit.isbn==pred.iid)].book_rating.values[0]\nprint(f'The real rating given for this was {actual_rtg:.2f}.')","execution_count":null,"outputs":[]},{"metadata":{"id":"JC3Q87esZwBj","trusted":true},"cell_type":"code","source":"# The following function was adapted from the surprise docs\n# and can be used to get the top book recommendations for each user.\nfrom collections import defaultdict\n\ndef get_top_n(predictions, n=10):\n    '''Return the top-N recommendation for each user from a set of predictions.\n\n    Args:\n        predictions(list of Prediction objects): The list of predictions, as\n            returned by the test method of an algorithm.\n        n(int): The number of recommendation to output for each user. Default\n            is 10.\n\n    Returns:\n    A dict where keys are user (raw) ids and values are lists of tuples:\n        [(raw item id, rating estimation), ...] of size n.\n    '''\n\n    # First map the predictions to each user.\n    \n    top_n = defaultdict(list)\n    for uid, iid, true_r, est, _ in predictions:\n        top_n[uid].append((iid, est))\n\n    # Then sort the predictions for each user and retrieve the k highest ones.\n    \n    for uid, user_ratings in top_n.items():\n        user_ratings.sort(key=lambda x: x[1], reverse=True)\n        top_n[uid] = user_ratings[:n]\n        \n    return top_n","execution_count":null,"outputs":[]},{"metadata":{"id":"xiA222PPZwBj","trusted":true},"cell_type":"code","source":"pred = model.test(testset)\ntop_n = get_top_n(pred)","execution_count":null,"outputs":[]},{"metadata":{"id":"yUQHK8L7ZwBk","trusted":true},"cell_type":"code","source":"def get_reading_list(userid):\n    \"\"\"\n    Retrieve full book titles from full 'books_users_ratings' dataframe\n    \"\"\"\n    reading_list = defaultdict(list)\n    top_n = get_top_n(pred, n=10)\n    print(top_n[userid])\n\n    for n in top_n[userid]:\n        book, rating = n\n        title = new_book_df.loc[new_book_df.isbn==book].book_title.unique()[0]\n        reading_list[title] = rating\n    print(reading_list)\n    return reading_list","execution_count":null,"outputs":[]},{"metadata":{"id":"OLwGkUeDZwBk","trusted":true},"cell_type":"code","source":"# Just take a random look at user_id=116866\nexample_reading_list = get_reading_list(userid = 116866)\nfor book, rating in example_reading_list.items():\n    print(f'{book}: {rating}')","execution_count":null,"outputs":[]},{"metadata":{"id":"rcqfDq-cZwBk"},"cell_type":"markdown","source":"Avobe recommended books seems pretty much related. So my first recommender engine is finished. "},{"metadata":{"id":"c5Liuc2r1mT5","trusted":true},"cell_type":"code","source":"example_reading_list","execution_count":null,"outputs":[]},{"metadata":{"id":"xOkUKyf62g3j","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}