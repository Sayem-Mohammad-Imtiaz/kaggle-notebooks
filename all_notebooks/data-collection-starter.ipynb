{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Reddit Scrapper Overview \nA walkthrough of the different features of the reddit scrapper package\n\nYou can read more about the process [here](https://towardsdatascience.com/predicting-reddit-flairs-using-machine-learning-and-deploying-the-model-on-heroku-part-1-574b69098d9a).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Install the praw library \n!pip install praw","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Import the library\nimport reddit_scraper as rs\nimport praw\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Authenticating client","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Credentials generated from the reddit developers applications page\n# Hidden to protect my details. Add your own info.  \nmy_client_id = ''\nmy_client_secret = ''\nuser = ''","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Authenticate the Reddit instance\nreddit = rs.reddit_auth(my_client_id, my_client_secret, user)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# NOTE:- This is currently not autheticating properly. \n# In case you get the output as none then authenticate conventionally\nprint(reddit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Conventional authentication\n#reddit = praw.Reddit(client_id=my_client_id, client_secret=my_client_secret, user_agent=user)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Add your own details. I have hidden my data. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Scraping Data without the specified flairs","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# These are the predefined features and will be set by default \nfeatures = [\n    'ID', \n    'is_Original', \n    'Flair',\n    'num_comments', \n    'Title',\n    'Subreddit', \n    'Body', \n    'URL', \n    'Upvotes',\n    'created_on', \n    'Comments'\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set the desired subreddit \nsubreddit = \"depression\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The parameters are:- \n1. The reddit instance \n2. sub_name: name of the subreddit\n3. num_posts: num of posts you want to collect \n4. comments: Set to True to get all the comments. False to only get the top comment. Default- True (Preferable True)","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Collect data in a dataframe\ndata = rs.scrape_without_flairs(reddit, sub_name=subreddit, \n                                          features=features, \n                                          num_posts=100, comments=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Save Data \ndata.to_csv('depression_reddit_data.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scraping data using reddit flairs","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### List the reddit flairs","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Get a list of the unique flairs associated with a subreddit.\nflair_list = rs.get_unique_flairs(reddit, sub_name='India', num_posts=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(flair_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get data based on flairs","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# Scrape data with a list of flairs\ndata = rs.scrape_with_flairs(reddit, sub_name='India', flairs=flair_list, num_per_flair=5, features=features, comments=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}