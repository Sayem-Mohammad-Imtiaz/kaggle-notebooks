{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Дипломная работа Александра Соколова\n\n#### Градиентный бустинг\nКернел 3 из 5 в разделе ML (отредактирован 21.04.2021)\n---\n\n# 1. Импорт библиотек, инициализация глобальных констант\n## 1.1. Импорт библиотек","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tqdm\nimport pickle\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.inspection import permutation_importance\n\nimport lightgbm as lgb\nimport catboost as cb\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport shap\n\nnp.warnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2. Глобальные константы","metadata":{}},{"cell_type":"code","source":"# CURRENT_DIR = './'  # имя текущей директории для локальной машины \nCURRENT_DIR = '../'  # имя текущей директории для каггл\n\nPATH_TO_WORKDIR = CURRENT_DIR + 'working/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip freeze > requirements.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Импорт предобработанных данных\n---\nпредобработка осуществлялась в [первом кернеле](https://www.kaggle.com/sokolovaleks/sf-dst-10-diplom-1-ml-sokolov)","metadata":{}},{"cell_type":"code","source":"merged_train_data = pd.read_csv('../input/alfabattle2-sandbox/preproc_data_for_boosting/preproc_data_for_boosting/merged_data.csv')\nmerged_test_data = pd.read_csv('../input/alfabattle2-sandbox/preproc_data_for_boosting/preproc_data_for_boosting/merged_test_data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Разбиваем тренировочную выборку\n---\nВажно выделять валидационную выборку, чтобы контролировать обучение и не переобучаться. ","metadata":{}},{"cell_type":"code","source":"targets = merged_train_data.flag.values\n\ncv = KFold(n_splits=5, random_state=100, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. LightGBM + CV (1)\n---\n## 4.1. Первая модель (model1)","metadata":{}},{"cell_type":"code","source":"num_model = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir model1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = [x for x in merged_train_data.columns if x not in ['app_id', 'flag']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\noof = np.zeros(len(merged_train_data))\ntrain_preds = np.zeros(len(merged_train_data))\n\nmodels = []\n\ntree_params = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'learning_rate': 0.05,\n    'max_depth': 3,\n    'reg_lambda': 1,\n    'num_leaves': 64,\n    'n_jobs': 5,\n    'n_estimators': 1000\n}\n\nfor fold_, (train_idx, val_idx) in enumerate(cv.split(merged_train_data, targets), 1):\n    print(f'Началось обучение на фолде номер:= {fold_}.')\n    lgb_model = lgb.LGBMClassifier(**tree_params)\n    train, val = merged_train_data.iloc[train_idx], merged_train_data.iloc[val_idx]\n    \n    lgb_model.fit(train[features], train.flag.values, eval_set=[(val[features], val.flag.values)],\n              early_stopping_rounds=50, verbose=50)\n\n    oof[val_idx] = lgb_model.predict_proba(val[features])[:, 1]\n    train_preds[train_idx] += lgb_model.predict_proba(train[features])[:, 1] / (cv.n_splits-1)\n    models.append(lgb_model)\n    \n    file_name_model = f'model{num_model}/model{num_model}_{fold_}.txt'\n    lgb_model.booster_.save_model(PATH_TO_WORKDIR+file_name_model)\n    print(f'Обучение на фолде номер:= {fold_} завершилось.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_name_pickle = PATH_TO_WORKDIR + f'model{num_model}/feats_model{num_model}.pickle'\nwith open(file_name_pickle, 'wb') as f:\n    pickle.dump(features, f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f'Train roc-auc model{num_model}', roc_auc_score(targets, train_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f'CV roc-auc model{num_model}', roc_auc_score(targets, oof)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2. Submission (model1) ","metadata":{}},{"cell_type":"code","source":"score = np.zeros(len(merged_test_data))\n\nfor model in tqdm.tqdm_notebook(models):\n    score += model.predict_proba(merged_test_data[features])[:, 1] / len(models)\n    \nsubmission = pd.DataFrame({\n    'app_id' : merged_test_data.app_id.values,\n    'score': score\n}) \n\nsubmission.to_csv(f'sub_model{num_model}.csv', index=None)  # ~ 0.737 roc-auc на public test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Feature Importance\n---\nОценка важности признаков - важный шаг в построении моделей. LightGBM имеет внутренние способы оценки важности признаков - на основе того, как часто делается сплит в вершине по признаку (split) и на основе того, какой суммарный прирост в информации дает разбиение по признаку (gain). Используем первый способ оценки важности признаков. Затем отберем топ признаков по важности и построим на них новые модели.","metadata":{}},{"cell_type":"code","source":"importances = np.zeros(len(features))\nfor model in models:\n    importances += model.feature_importances_ / len(models)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_feature_importance(feature_names, feature_scores, top_feats=20, title='Importance', x_label='Importance', \n                            y_label='Features'):\n    tuples = [(name, round(score, 3)) for name, score in zip(feature_names, feature_scores)]\n    tuples = sorted(tuples, key=lambda x: x[1])[-top_feats:]\n    \n    labels, values = zip(*tuples)\n    _, ax = plt.subplots(1, 1, figsize=(10, 8))\n    ylocs = np.arange(len(values))\n    \n    ax.barh(ylocs, values, align='center', height=0.4)\n    for x, y in zip(values, ylocs):\n        ax.text(x + 1, y, x, va='center')\n        \n    ax.set_yticks(ylocs)\n    ax.set_yticklabels(labels)\n    xlim = (0, max(values) * 1.1)\n    ax.set_xlim(xlim)\n    ylim = (-1, len(values))\n    ax.set_ylim(ylim)\n    \n    ax.set_title(title)\n    ax.set_xlabel(x_label)\n    ax.set_ylabel(y_label)\n    ax.grid(True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_feature_importance(features, importances, top_feats=20, title='LightGBM feature importance', \n                        x_label='Importance')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuples = [(name, round(score, 3)) for name, score in zip(features, importances)]\ntuples = sorted(tuples, key=lambda x: x[1])\n\ntop_selected_feats = [x[0] for x in tuples if x[1] >= np.median(importances)]\nprint(f'Кол-во отобранных признаков на этапе Feature importance (median):= {len(top_selected_feats)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. LightGBM + CV (2)\n---\n## 6.1. Вторая модель (model2)\n(на признаках расчетная важность которых не меньше медианы)","metadata":{}},{"cell_type":"code","source":"num_model = 2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir model2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\noof = np.zeros(len(merged_train_data))\ntrain_preds = np.zeros(len(merged_train_data))\n\nnew_models = []\n\ntree_params = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'learning_rate': 0.05,\n    'max_depth': 3,\n    'reg_lambda': 1,\n    'num_leaves': 64,\n    'n_jobs': 5,\n    'n_estimators': 1000\n}\n\n\nfor fold_, (train_idx, val_idx) in enumerate(cv.split(merged_train_data, targets), 1):\n    print(f'Началось обучение на фолде номер:= {fold_}.')\n    lgb_model = lgb.LGBMClassifier(**tree_params)\n    train, val = merged_train_data.iloc[train_idx], merged_train_data.iloc[val_idx]\n    \n    lgb_model.fit(train[top_selected_feats], train.flag.values, eval_set=[(val[top_selected_feats], val.flag.values)],\n              early_stopping_rounds=50, verbose=50)\n\n    oof[val_idx] = lgb_model.predict_proba(val[top_selected_feats])[:, 1]\n    train_preds[train_idx] += lgb_model.predict_proba(train[top_selected_feats])[:, 1] / (cv.n_splits-1)\n    new_models.append(lgb_model)\n    \n    file_name_model = f'model{num_model}/model{num_model}_{fold_}.txt'\n    lgb_model.booster_.save_model(PATH_TO_WORKDIR+file_name_model)\n    print(f'Обучение на фолде номер:= {fold_} завершилось.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_name_pickle = PATH_TO_WORKDIR + f'model{num_model}/feats_model{num_model}.pickle'\nwith open(file_name_pickle, 'wb') as f:\n    pickle.dump(top_selected_feats, f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f'Train roc-auc model{num_model}', roc_auc_score(targets, train_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f'CV roc-auc model{num_model}', roc_auc_score(targets, oof)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = np.zeros(len(merged_test_data))\n\nfor model in tqdm.tqdm_notebook(new_models):\n    score += model.predict_proba(merged_test_data[top_selected_feats])[:, 1] / len(models)\n    \nsubmission = pd.DataFrame({\n    'app_id' : merged_test_data.app_id.values,\n    'score': score\n}) \n\nsubmission.to_csv(f'sub_model{num_model}.csv', index=None)  # ~ 0.7346 на public test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Permutation importance\n---\nЭто способ оценки важности признаков, который можно применить к любой обученной модели на табличных данных. Данный тип важности определеяется для каждого признака, как изменение в скоре (в нашем случае - roc_auc) при случайном перемешиваниии столбца с значениями этого признака несколько раз.","metadata":{}},{"cell_type":"code","source":"%%time\npermut_importance = np.zeros(len(features))\n\nfor fold_, (_, val_idx) in enumerate(cv.split(merged_train_data, targets), 1):\n    print(f'Началась обработка фолда:= {fold_}')\n    val = merged_train_data.iloc[val_idx]\n    importances_report = permutation_importance(models[fold_-1], val[features], val.flag.values, n_repeats=3, \n                                     n_jobs=3, scoring='roc_auc')\n    permut_importance += importances_report.importances_mean / cv.n_splits\n    print(f'Обработка фолда:= {fold_} закончена.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_feature_importance(features, permut_importance*10000, top_feats=20, title='Permutation importance', \n                        x_label='Importance')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Используя техники оценки важности признаков можно интерпретировать модель, пытаться генерировать новые признаки или упрощать модель, удаляя самые неинформативные. Попробуем оставить топ информативных признаков (с точки зрения) `permutation importance`. Удаление из модели признаков, как правило, уменьшает ее склонность к переобучению. А самое главное - может существенно ускорить процесс обучения и последующий процесс использования ее в продуктовых целях, что для меня достаточно важно потому что есть цель развернуть деплой модели на heroku, а его мощности скромные. ","metadata":{}},{"cell_type":"code","source":"tuples = [(name, round(score, 3)) for name, score in zip(features, permut_importance)]\ntuples = sorted(tuples, key=lambda x: x[1])\n\ntop_selected_feats = [x[0] for x in tuples if x[1] > 0]\nprint(f'Кол-во отобранных признаков после метода Permutation importance:= {len(top_selected_feats)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. LightGBM + CV (3)\n---\n## 8.1. Третья модель (model3)\n(на признаках после отбора с помощью методов Features importance(median) и Permutation importance)","metadata":{}},{"cell_type":"code","source":"num_model = 3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir model3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\noof = np.zeros(len(merged_train_data))\ntrain_preds = np.zeros(len(merged_train_data))\n\nnew_models = []\n\ntree_params = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'learning_rate': 0.05,\n    'max_depth': 3,\n    'reg_lambda': 1,\n    'num_leaves': 64,\n    'n_jobs': 5,\n    'n_estimators': 1000\n}\n\n\nfor fold_, (train_idx, val_idx) in enumerate(cv.split(merged_train_data, targets), 1):\n    print(f'Training with fold {fold_} started.')\n    lgb_model = lgb.LGBMClassifier(**tree_params)\n    train, val = merged_train_data.iloc[train_idx], merged_train_data.iloc[val_idx]\n    \n    lgb_model.fit(train[top_selected_feats], train.flag.values, eval_set=[(val[top_selected_feats], val.flag.values)],\n              early_stopping_rounds=50, verbose=50)\n\n    \n    oof[val_idx] = lgb_model.predict_proba(val[top_selected_feats])[:, 1]\n    train_preds[train_idx] += lgb_model.predict_proba(train[top_selected_feats])[:, 1] / (cv.n_splits-1)\n    new_models.append(lgb_model)\n    \n    file_name_model = f'model{num_model}/model{num_model}_{fold_}.txt'\n    lgb_model.booster_.save_model(PATH_TO_WORKDIR+file_name_model)\n    print(f'Training with fold {fold_} completed.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_name_pickle = PATH_TO_WORKDIR + f'model{num_model}/feats_model{num_model}.pickle'\nwith open(file_name_pickle, 'wb') as f:\n    pickle.dump(top_selected_feats, f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f'Train roc-auc model{num_model}', roc_auc_score(targets, train_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f'CV roc-auc model{num_model}', roc_auc_score(targets, oof)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = np.zeros(len(merged_test_data))\n\nfor model in tqdm.tqdm_notebook(new_models):\n    score += model.predict_proba(merged_test_data[top_selected_feats])[:, 1] / len(models)\n    \nsubmission = pd.DataFrame({\n    'app_id' : merged_test_data.app_id.values,\n    'score': score\n}) \n\nsubmission.to_csv(f'sub_model{num_model}.csv', index=None)  # ~ 0.736 roc-auc на public test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9. Интерпретация предсказаний модели (shap)\n---\nВ задаче кредитного скорринга важна интепретируемость модели, для этого можно использовать  библиотеку shap. Мы используем так называемый summary plot, позволяющий получить общую картину о влиянии того или иного признака на предсказание модели визуализуруя всю выборку сразу. Я не смог разобраться как использовать методы shap для модели обученной на 5-ти фолдах. Ниже я заново обучаю модель после сплита 90:10 без деления на фолды, чтобы выделить основные закономерности влияния фич на таргет и попытаться визуализировать их разделяющую способность.","metadata":{}},{"cell_type":"code","source":"%%time\ntrain, val = train_test_split(merged_train_data, random_state=100, test_size=0.1)\n\ntree_params = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'learning_rate': 0.05,\n    'max_depth': 3,\n    'reg_lambda': 1,\n    'num_leaves': 64,\n    'seed': 100,\n    'n_jobs': 5,\n    'n_estimators': 1000\n}\n\nlgb_model = lgb.LGBMClassifier(**tree_params)\nlgb_model.fit(train[features], train.flag.values, eval_set=[(val[features], val.flag.values)],\n              early_stopping_rounds=50, verbose=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"explainer = shap.TreeExplainer(lgb_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap_values = explainer.shap_values(val[features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.summary_plot(shap_values[1], val[features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"График выше показывает влияние и разделяющую способность признаков:\n- каждая точка графика это клиент\n- цвет - значение прогноза дефолта, чем краснее - тем прогноз дефолта выше, и наоборот\n- горизонтальное положение точки показывает, приводит ли значение конкретной фичи этого клиента к росту предсказания дефолта, или наоборот.\n\n***Например можно увидеть следующие тренды:***\n\n1. уменьшение признака 'hour_diff_median' приводит к росту значения целевой переменной (то есть можно предположить, что клиенту приходится делать транзакции слишком часто - а это свидетельство того, что клиент вероятнее выйдет в дефолт, чем клиент который чувствует себя более уверенно в финансовом плане и может позволить делать крупные оплаты сразу не разбивая их на части)\n2. увеличение признака 'hour_diff_max' приводит к росту значения целевой переменной (то есть можно предположить, что клиент долго не пользовался картой это могло произойти в следствии овердрафта и необходимости перекредитования в другом банке)\n3. уменьшение признака 'count_mcc_category_9' приводит к росту значения целевой переменной (к сожалению категории торговых точек как данные о клиентах были обезличены, остается только предположить, что вероятно это категория 'Кафе,бары и рестораны' и клиенты испытывающие сложности в финансах перестают их посещать или делают это существенно реже.)\n4. увеличение признака 'count_operation_type_5' приводит к росту значения целевой переменной (из-за обезличивания типа операций и дополнительного анализа видно что у большинства клиентов таких операций нет, вероятно речь об операции внесение минимального платежа, вместо гашения очередного платежа. И собственно если это так что увеличение кол-ва таких операций приводит к дефолту потому что нагрузка в этом случае только возрастает)\n5. среднее и максимальное значение признака 'product' приводит к росту значения целевой переменной (предположу что 0 - кредит безналичными на карту, 1 - это кредит наличными, 2 - кредит на крупные покупки, 3 - кредит на покупку авто, 4 - ипотека. Сделать такое предположение можно и-за того что 80% всех кредитов по кол-ву приходится на продукты 0,1. А самый редкий это продукт 4. Среднее значение дефолтов 2-2,5% процента по продуктам 0,1,3. По продукту 2 - 7%. А по продукту 4 - 3%. Вероятно кредиты на крупные покупки проверяются менее чем ипотека и они не имеют обеспечения как авто для погашения кредита.)\n6. уменьшение признака 'days_before_max' приводит к росту значения целевой переменной (низкое значение максимума кол-ва дней перед взятием кредита означает короткая история транзакций в банке. Можно предположить, что клиент открыл карту и через короткое время получил кредит. Это либо мошеническая схема, но этот вариант мы не рассматривает ибо он скорее всего не массовый. А вероятно это случай перекредитования в другом банке, когда банк по соновной карте перестал предоставлять или увеличивать кредитную линию. Что является свидетельством неплатежеспособности клиента.)","metadata":{}},{"cell_type":"markdown","source":"# 10. Target Permutation\n---\nОтбор признаков методом target permutation основан на сравнении важности признака, которая быал получена при обучении на обычной выборке, с распределением важности этого признака для моделей, которые обучены на выборках с перемешанной целевой переменной.","metadata":{}},{"cell_type":"code","source":"def get_feature_importances(frame, shuffle=False, seed=100, importance_type='gain'):\n    # запишем целевую target в переменную\n    y = frame.flag.values.copy()\n    if shuffle:\n        # перемешаем целевую переменную\n        y = frame.flag.copy().sample(frac=1.0).values\n    \n    # обучим случайный лес из LightGBM ( реализация гораздо быстрее, чем в sklearn )\n    # сделаем это для того, чтобы не выделять отдельную выборку под валидацию для градиентного бустинга\n    tree_params = {\n    'objective': 'binary',\n    'boosting_type': 'rf',\n    'metric': 'auc',\n    'subsample_freq': np.random.choice([5, 10, 15, 20]),\n    'subsample': np.random.choice([0.6, 0.8, 0.9]),\n    'max_depth': np.random.choice([7, 8, 10]),\n    'num_leaves': 64,\n    'seed': seed,\n    'n_jobs': 5,\n    'n_estimators': 100,\n    'importance_type': importance_type\n    }\n    \n    lgb_model = lgb.LGBMClassifier(**tree_params)\n    lgb_model.fit(frame[features], y)\n    \n    importance = pd.DataFrame({\n        'feature': features,\n        f'importance_{importance_type}': lgb_model.feature_importances_,\n        'score': roc_auc_score(y, lgb_model.predict_proba(frame[features])[:, 1])\n    })\n    \n    return importance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посчитаем важность признаков (на основе количества сплитов по признаку в алгоритме random forest) при обучении на исходной выборке","metadata":{}},{"cell_type":"code","source":"real_importance = get_feature_importances(train, shuffle=False, seed=100, importance_type='split')\nreal_importance.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посчитаем важность признаков для выборок, у которых целевая переменная перемешана. То есть фактически, обучаем алгоритм на шуме.","metadata":{}},{"cell_type":"code","source":"def calculate_null_importance(frame, num_runs=80, importance_type='gain'):\n    null_importance = pd.DataFrame()\n    for i in tqdm.tqdm_notebook(range(num_runs)):\n        # посчитаем текущую важность признаков при перемешивании целевой переменной\n        importance = get_feature_importances(frame, shuffle=True, seed=None, importance_type=importance_type)\n        importance['run'] = i + 1 \n        null_importance = pd.concat([null_importance, importance], axis=0)\n    return null_importance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nnull_importance = calculate_null_importance(train, num_runs=30, importance_type='split')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Теперь имеем возможность для каждого признака построить гистограмму важности этого признака при обучении на выборке с перемешанным таргетом и на выборке с реальной целевой переменной. В идеале, гистограмма должна быть как можно дальше от реального значения важности признака","metadata":{}},{"cell_type":"code","source":"def plot_distribution(real_importance, null_importance, feature_name, importance_name='gain'):\n    fig, ax = plt.subplots(figsize=(8, 6))\n    a = ax.hist(null_importance.loc[null_importance['feature'] == feature_name, f'importance_{importance_name}'].values, \n                label='Null importances')\n    \n    ax.vlines(x=real_importance.loc[real_importance['feature'] == feature_name, f'importance_{importance_name}'].mean(), \n               ymin=0, ymax=np.max(a[0]), color='r',linewidth=10, label='Real Target')\n    ax.legend()\n    ax.set_title(f'Split Importance of {feature_name}', fontweight='bold')\n    plt.xlabel(f'Null Importance ({importance_name}) Distribution for {feature_name}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_distribution(real_importance, null_importance, feature_name='product', importance_name='split')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_distribution(real_importance, null_importance, feature_name='hour_diff_median', importance_name='split')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_distribution(real_importance, null_importance, feature_name='amnt_sum', importance_name='split')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Попробуем поставить каждому признаку новый скор, важность, с учетом той информации, которую имеем. Один из вариантов - поделить реальноа значение важности признака на среднее значение для перемешанных важностей этого признака. ","metadata":{}},{"cell_type":"code","source":"scores = []\nimportance_name = 'split'\n\nfor feature in features:\n    hist_null_importance = null_importance.loc[null_importance['feature'] == feature, f'importance_{importance_name}'].values\n    actual_importance = real_importance.loc[real_importance['feature'] == feature, f'importance_{importance_name}'].mean()\n    score = (1e-10 + actual_importance) / (1 + np.mean(hist_null_importance))        \n    scores.append(round(score, 3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_feature_importance(features, scores, top_feats=20, title='target permutation importance', \n                        x_label='Importance')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuples = [(name, round(score, 3)) for name, score in zip(features, scores)]\ntuples = sorted(tuples, key=lambda x: x[1])\n\ntop_selected_feats = [x[0] for x in tuples if x[1] > 0]\nprint(f'Кол-во отобранных признаков после всех методов отбора:= {len(top_selected_feats)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 11. LightGBM + CV (4)\n---\n## 11.1. Четвертая модель (model4)\n(на признаках после отбора с помощью всех методов Features importance(median), Permutation importance и Target importance)","metadata":{}},{"cell_type":"code","source":"num_model = 4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir model4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\noof = np.zeros(len(merged_train_data))\ntrain_preds = np.zeros(len(merged_train_data))\n\nnew_models = []\n\ntree_params = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'learning_rate': 0.05,\n    'max_depth': 3,\n    'reg_lambda': 1,\n    'num_leaves': 64,\n    'n_jobs': 5,\n    'n_estimators': 1000\n}\n\n\nfor fold_, (train_idx, val_idx) in enumerate(cv.split(merged_train_data, targets), 1):\n    print(f'Training with fold {fold_} started.')\n    lgb_model = lgb.LGBMClassifier(**tree_params)\n    train, val = merged_train_data.iloc[train_idx], merged_train_data.iloc[val_idx]\n    \n    lgb_model.fit(train[top_selected_feats], train.flag.values, eval_set=[(val[top_selected_feats], val.flag.values)],\n              early_stopping_rounds=50, verbose=50)\n\n    \n    oof[val_idx] = lgb_model.predict_proba(val[top_selected_feats])[:, 1]\n    train_preds[train_idx] += lgb_model.predict_proba(train[top_selected_feats])[:, 1] / (cv.n_splits-1)\n    new_models.append(lgb_model)\n    \n    file_name_model = f'model{num_model}/model{num_model}_{fold_}.txt'\n    lgb_model.booster_.save_model(PATH_TO_WORKDIR+file_name_model)\n    print(f'Training with fold {fold_} completed.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_name_pickle = PATH_TO_WORKDIR + f'model{num_model}/feats_model{num_model}.pickle'\nwith open(file_name_pickle, 'wb') as f:\n    pickle.dump(top_selected_feats, f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f'Train roc-auc model{num_model}', roc_auc_score(targets, train_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f'CV roc-auc model{num_model}', roc_auc_score(targets, oof)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = np.zeros(len(merged_test_data))\n\nfor model in tqdm.tqdm_notebook(new_models):\n    score += model.predict_proba(merged_test_data[top_selected_feats])[:, 1] / len(models)\n    \nsubmission = pd.DataFrame({\n    'app_id' : merged_test_data.app_id.values,\n    'score': score\n})\nsubmission.to_csv(f'sub_model{num_model}.csv', index=None)  # ~ 0.733 на public test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Расчет модели Catboost реализован в следующем кернеле, чтобы не использовать квоту так как запускается на GPU\n\n**Результаты всех экспериментов моделей (метрика AUC ROC):**  \n                    Model                            | число призн. |    Train     |     CV      |   Public Test      \n---  \n                     lgb+cv(5)                     |        127           |    0.801    |    0.77     |    0.737       \n       lgb+cv(5)+split_importance      |          64            |    0.795    |    0.767    |    0.735  \nlgb+cv(5)+permutation_importance |         57            |    0.796    |    0.768    |    0.736   \n    lgb+cv(5)+target_permutation     |          60            |    0.796    |    0.766    |    0.733 \n","metadata":{}}]}