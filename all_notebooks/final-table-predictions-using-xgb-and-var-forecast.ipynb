{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Created on Tue Jun  2 11:06:39 2020<br>\nauthor: jaketuricchi\nGenerated in Spyder 4.0 using J2P for conversion from .py to .ipynb","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Predicting the final EPL table: <br>\nUsing a combination of machine learning model generated on game-level data and VAR forecasting to forecast features based on prior features to predict the final league table.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Aim 1: We want to predict match reuslt given match statistics (removing obvious stats such as goals); Supervised classification","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Aim 2: Forecast match features for the final 6 games of the season using VAR","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Aim 3: Predict the last 6 results for each team using the previously generated model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Aim 4: Predict final league table (ML/forecasting?)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"All meanings of variables can be found at: https://www.kaggle.com/idoyo92/epl-stats-20192020 along with the complete data set.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"\nImport packages","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport warnings \nimport seaborn as sns\nimport sklearn\nfrom datetime import datetime\nimport calendar\n%matplotlib inline\nimport shelve\nimport warnings\nwarnings.simplefilter('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Set wd and read in data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games = pd.read_csv('../input/epl-stats-20192020/epl2020.csv')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sort games df ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(games.columns)\nprint(games.isna().sum()) #no missing data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"games = games.drop('Unnamed: 0', axis=1) # drop useless column\ngames = games.drop(['scored', 'missed', 'wins', 'draws', 'loses', 'pts',\n                    'tot_points', 'tot_goal', 'tot_con'], axis=1) # drop columns which give away result","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Code target","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games['target']=np.where(games['result']=='l', 0,\n                         np.where(games['result']=='d', 1,2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop result string variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games = games.drop('result', axis=1) # drop useless column","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set categorical variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games[['target', 'h_a', 'teamId', 'Referee.x', 'matchDay']] = games[['target', 'h_a', 'teamId', 'Referee.x', 'matchDay']].astype('category')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Here we explore 'expected' variables (goals, concedes) given by the bookmakers, in relation to the target. We could do a more extensive visualisation with more time.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"EDA_pairplot1=games.filter(items=['xG', 'xGA', 'npxG', 'npxGA', 'npxGD', 'h_a', 'target'])\nsns.pairplot(EDA_pairplot1, hue='target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we explore HOME team match stats, in relation to the target","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"EDA_pairplot2=games.filter(items=['ppda_cal', 'allowed_ppda', 'HS.x', 'HST.x', 'HF.x', 'HC.x', 'target'])\nsns.pairplot(EDA_pairplot2, hue='target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we explore AWAY team match stats, in relation to the target","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"EDA_pairplot3=games.filter(items=['ppda_cal', 'allowed_ppda', 'AS.x', 'AST.x', 'AF.x', 'AC.x', 'target'])\nsns.pairplot(EDA_pairplot3, hue='target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Game outcomes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"EDA_plot4=games.groupby('teamId')['target'].agg(counts='value_counts').reset_index()\nEDA_plot4['target']=np.where(EDA_plot4['target']==0, 'loss',\n                         np.where(EDA_plot4['target']==1, 'draw','win'))\nEDA_plot4=EDA_plot4.reset_index() \nsns.catplot(y=\"teamId\",x='counts', hue='target',data=EDA_plot4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling - Preprocessing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Scale numeric data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nums= games.select_dtypes(include=['float', 'int64'])\nother= games.select_dtypes(exclude=['float', 'int64']).drop(['date', 'target'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nnums_scaled = scaler.fit_transform(nums)\ngames_scaled=pd.DataFrame(nums_scaled, columns=nums.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One hot encode categorical data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dummies=pd.get_dummies(other)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generate an analysis dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gameday_pred = pd.concat([games_scaled,dummies, games['target']], axis=1)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split the data into features and labels","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X=gameday_pred.drop('target', axis=1)\ny=gameday_pred['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y.dtypes)\nprint(X.dtypes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split the data intro train and test sets for model training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Algorithm testing and initial selection","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Load packages","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis,  QuadraticDiscriminantAnalysis\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, log_loss, precision_score, recall_score, f1_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Select classification algorithms we'll test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers = [\n    KNeighborsClassifier(3),\n    SVC(kernel=\"rbf\", C=0.025, probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    GaussianNB(),\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logging for Visual Comparison","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\nlog = pd.DataFrame(columns=log_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Run algo loop","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for clf in classifiers:\n    clf.fit(X_train, y_train)\n    name = clf.__class__.__name__\n    \n    print(\"=\"*30)\n    print(name)\n    \n    print('****Results****')\n    train_predictions = clf.predict(X_test)\n    acc = accuracy_score(y_test, train_predictions)\n    \n    # calculate score\n    precision = precision_score(y_test, train_predictions, average = 'macro') \n    recall = recall_score(y_test, train_predictions, average = 'macro') \n    f_score = f1_score(y_test, train_predictions, average = 'macro')\n    \n    \n    print(\"Precision: {:.4%}\".format(precision))\n    print(\"Recall: {:.4%}\".format(recall))\n    print(\"F-score: {:.4%}\".format(recall))\n    print(\"Accuracy: {:.4%}\".format(acc))\n    \n    train_predictions = clf.predict_proba(X_test)\n    ll = log_loss(y_test, train_predictions)\n    print(\"Log Loss: {}\".format(ll))\n    \n    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n    log = log.append(log_entry)\n    \nprint(\"=\"*30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"collinearity should be expected given the type of data\n\n# Plot results of algo testing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_color_codes(\"muted\")\nsns.barplot(x='Log Loss', y='Classifier', data=log, color=\"g\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What are the most important features?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=500)\nrf.fit(X_train, y_train);\nfeat_importances = pd.Series(rf.feature_importances_, index=X_train.columns)\nfeat_importances.nlargest(10).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These results suggest that the 'expected' (i.e. betting agent prediction) variables provide more predictive value than the actual game statistics which is surprising.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Model selection and tuning<br>\nThe initial results suggest that XGb and RF are the two best performing classifiers for this problem. Lets begin by tuning the best algorithm (XGb)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom xgboost import XGBClassifier\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(objective='multi:softprob',silent=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generate a basic Xgb model and predict the test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.fit(X_train,y_train)\ny_pred_xgb_basic=xgb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculate score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"precision = precision_score(y_test, y_pred_xgb_basic, average = 'macro') * 100\nrecall = recall_score(y_test, y_pred_xgb_basic, average = 'macro') * 100\nf_score = f1_score(y_test, y_pred_xgb_basic, average = 'macro') * 100\na_score = accuracy_score(y_test, y_pred_xgb_basic) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Precision: %.3f' % precision)\nprint('Recall: %.3f' % recall)\nprint('F-Measure: %.3f' % f_score)\nprint('Accuracy: %.3f' % a_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tuning the XGb using Grid search","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters_xgb = {\n        'learning_rate': [0.05, 0.1, 0.2, 0.3, 0.5], \n        'n_estimators': [200, 300, 400, 500, 600], \n        'max_depth': [1, 5, 10, 15, 20], \n        'gamma' :[0.1, 0.5, 1, 2, 5], \n        'subsample': [0.5, 0.75, 1], \n        'colsample_bytree': [0.01, 0.1, 0.5, 1], \n        }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Instantiate the grid search model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_xgb = GridSearchCV(estimator = xgb, param_grid = parameters_xgb, \n                          cv = 3,n_jobs=-1, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fit the grid search to the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_xgb.fit(X_train,y_train)\nprint(grid_search_xgb.best_params_)\n    # {'colsample_bytree': 0.1, 'gamma': 0.5, 'learning_rate': 0.3, 'max_depth': 15, 'n_estimators': 300, 'subsample': 1}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Run best params","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"best_grid_xgb = grid_search_xgb.best_estimator_\nbest_grid_xgb.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predict test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_xgb = best_grid_xgb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculate score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"precision = precision_score(y_test, y_pred_xgb, average = 'macro') * 100\nrecall = recall_score(y_test, y_pred_xgb, average = 'macro') * 100\nf_score = f1_score(y_test, y_pred_xgb, average = 'macro') * 100\na_score = accuracy_score(y_test, y_pred_xgb) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Precision: %.3f' % precision)\nprint('Recall: %.3f' % recall)\nprint('F-Measure: %.3f' % f_score)\nprint('Accuracy: %.3f' % a_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hyperparameter tuning gives us a very small additional boost in XGB performance. We could improve the grid search but are limited by time and computation power currently.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Tune random forest","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Generate a basic model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(random_state = 1)\nrf_model_basic = rf.fit(X_train, y_train)\ny_pred_rf_basic = rf_model_basic.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculate score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"precision = precision_score(y_test, y_pred_rf_basic, average = 'macro') * 100\nrecall = recall_score(y_test, y_pred_rf_basic, average = 'macro') * 100\nf_score = f1_score(y_test, y_pred_rf_basic, average = 'macro') * 100\na_score = accuracy_score(y_test, y_pred_rf_basic) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Precision: %.3f' % precision)\nprint('Recall: %.3f' % recall)\nprint('F-Measure: %.3f' % f_score)\nprint('Accuracy: %.3f' % a_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tuning the RF using Grid search","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters_rf = {\n    'bootstrap': [True],\n    'n_estimators' : [100, 300, 500, 800, 1200],\n    'max_depth' : [5, 8, 15, 25, 30],\n    'min_samples_split' : [2, 5, 10, 15, 100],\n    'min_samples_leaf' : [1, 2, 5, 10],\n    'max_features': [2, 4]\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Instantiate the grid search model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_rf = GridSearchCV(estimator = rf, param_grid = parameters_rf, \n                          cv = 3,n_jobs=-1, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fit the grid search to the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_rf.fit(X_train,y_train)\nprint(grid_search_rf.best_params_)\n    # {'bootstrap': True, 'max_depth': 15, 'max_features': 4, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 800}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Run best params","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"best_grid_rf = grid_search_rf.best_estimator_\nbest_grid_rf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predict test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_rf = best_grid_rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculate score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"precision = precision_score(y_test, y_pred_rf, average = 'macro') * 100\nrecall = recall_score(y_test, y_pred_rf, average = 'macro') * 100\nf_score = f1_score(y_test, y_pred_rf, average = 'macro') * 100\na_score = accuracy_score(y_test, y_pred_rf) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Precision: %.3f' % precision)\nprint('Recall: %.3f' % recall)\nprint('F-Measure: %.3f' % f_score)\nprint('Accuracy: %.3f' % a_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Small increases in performance observed from tuning the RF, but a tuned XGb is still the best performing algorithm","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# PART 2: how will the league finish?","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Initial stage: calculate the current table. We need to reload the table to get points back.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"games2 = pd.read_csv('../input/epl-stats-20192020/epl2020.csv')\ntable=games2.groupby('teamId')['pts'].agg(table_points='sum').reset_index().sort_values('table_points', ascending=False)\ntable['position']=range(0,len(table), 1)\ntable['position']=table['position']+1\nprint(table)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we'll use multivariate time series forecasting to forecast the match statistics used as features. Then, we'll use the XGb model we generated to predict the results of these matches<br>\nLast, we'll add the results to generate a final league table","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fc_games=games\nfc_games['date'] = pd.to_datetime(fc_games.date , format = '%Y-%m-%d %H:%M:%S')\nfc_games.index = fc_games['date']\nfc_games = fc_games.drop(['date'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To forecast using VAR, categorical variables must be label encoded","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seperate categories and numerics for preprocessing, and then rejoin.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categories= fc_games.select_dtypes(include=['category']).drop(['teamId','target'], axis=1).apply(LabelEncoder().fit_transform)\nfc_games=fc_games.drop(categories.columns.values, axis=1)\nfc_games=pd.concat([fc_games, categories], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll need to check stationarity for each participant. Perform ADFuller to test for Stationarity of given series and print report","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Function adapted from: https://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.adfuller.html","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def adfuller_test(series, signif=0.05, name='', verbose=False):\n    r = adfuller(series, autolag='AIC')\n    output = {'test_statistic':round(r[0], 4), 'pvalue':round(r[1], 4), 'n_lags':round(r[2], 4), 'n_obs':r[3]}\n    p_value = output['pvalue'] \n    def adjust(val, length= 6): return str(val).ljust(length)\n\n    # Print Summary\n    print(f'    Augmented Dickey-Fuller Test on \"{name}\"', \"\\n   \", '-'*47)\n    print(f' Null Hypothesis: Data has unit root. Non-Stationary.')\n    print(f' Significance Level    = {signif}')\n    print(f' Test Statistic        = {output[\"test_statistic\"]}')\n    print(f' No. Lags Chosen       = {output[\"n_lags\"]}')\n    for key,val in r[4].items():\n        print(f' Critical value {adjust(key)} = {round(val, 3)}')\n    if p_value <= signif:\n        print(f\" => P-Value = {p_value}. Rejecting Null Hypothesis.\")\n        print(f\" => Series is Stationary.\")\n    else:\n        print(f\" => P-Value = {p_value}. Weak evidence to reject the Null Hypothesis.\")\n        print(f\" => Series is Non-Stationary.\")   \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=fc_games[fc_games['teamId']=='Liverpool'] #lets take an example and see if we can test/produce stationarity\nx=x.drop(['teamId','target'], axis=1) #dont want to forecast either of these.\nfc_train = x[:int(0.8*(len(x)))] #split data\nfc_valid = x[int(0.8*(len(x))):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, column in fc_train.iteritems(): #run the ADF test of stationarity\n    adfuller_test(column, name=column.name)\n    print('\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most columns are non-stationary, lets difference and retry","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fc_train_diff = fc_train.diff().dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NOTE: having tried differencing multiple times - this will not significantly change the stationarity of the series - this gives us less forecasting power but also impossible to avoid, probably due to<br>\nthe small number of obs.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Validation of forecasting","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"It is clear that forecasting all columns is given the number of observations we have is not possible. As such I decided to select the 1-5 and 6-10 most important variables<br>\nand forecast these.   ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.tsa.api import VAR\n \nfeat_importances_1=feat_importances.nlargest(5).index.values\nfeat_importances_2=feat_importances.nlargest(10).index.values[5:]\nfeat_importances_3=feat_importances.nlargest(15).index.values[10:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def validation_by_team(x):\n    x1=x.filter(items=feat_importances_1)\n    x2=x.filter(items=feat_importances_2)\n    \n    fc_train1 = x1[:int(0.8*(len(x1)))] #split data\n    fc_valid1 = x1[int(0.8*(len(x1))):]\n    \n    fc_train2 = x2[:int(0.8*(len(x2)))] #split data\n    fc_valid2 = x2[int(0.8*(len(x2))):]\n    \n    model1 = VAR(endog=fc_train1) #fit VAR model\n    model_fit1 = model1.fit()\n    \n    model2 = VAR(endog=fc_train2) #fit VAR model\n    model_fit2 = model2.fit()\n    \n    prediction1 = model_fit1.forecast(model_fit1.y, steps=len(fc_valid1)) #predict\n    prediction1 = pd.DataFrame(data=prediction1, columns=x1.columns)\n    \n    prediction2 = model_fit2.forecast(model_fit2.y, steps=len(fc_valid2)) #predict\n    prediction2 = pd.DataFrame(data=prediction2, columns=x2.columns)\n       \n    # Check the performance of the by serial correlation of errors using the Durbin Watson statistic.\n    \n    # The value of this statistic can vary between 0 and 4. The closer it is to the value 2, \n    # then there is no significant serial correlation. The closer to 0, there is a positive \n    # serial correlation, and the closer it is to 4 implies negative serial correlation.\n    \n    out1 = durbin_watson(model_fit1.resid)\n    print(out1)\n    out2 = durbin_watson(model_fit2.resid)\n    print(out2)\n    \n    prediction_performance = pd.DataFrame([out1, out2]).T\n    return(prediction_performance)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_validations=fc_games.groupby('teamId').apply(validation_by_team)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These values seem suitable. They are generally around 2. The distance between days doesnt matter so we can ignore the errors here.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Forecasting of match statistics","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Since we cannot forecast every one of the features due to limited obs, we'll forecast the top 10, and use mean imputation for the rest.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"There are 6 more games in the EPL season, so we'll predict 6 lags ahead.  It is important to note that with the amount of variables and previous observations we have, the predictions will be similar to an approximate mean imputation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def forecast_by_team(x):\n    target=x['target'].reset_index(drop=True)\n    x=x.drop(['teamId','target'], axis=1) #dont want to forecast either of these.\n    \n    x1=x.filter(items=feat_importances_1)\n    x2=x.filter(items=feat_importances_2)\n    x3=x.filter(items=feat_importances_3)\n    \n    model1 = VAR(endog=x1) #fit VAR model1\n    model_fit1 = model1.fit()\n    \n    model2 = VAR(endog=x2) #fit VAR model2\n    model_fit2 = model2.fit()\n    \n    model3 = VAR(endog=x3) #fit VAR model3\n    model_fit3 = model3.fit()\n    \n    prediction1 = model_fit1.forecast(model_fit1.y, steps=6) #predict\n    prediction1 = pd.DataFrame(data=prediction1, columns=x1.columns)\n    \n    prediction2 = model_fit2.forecast(model_fit2.y, steps=6) #predict\n    prediction2 = pd.DataFrame(data=prediction2, columns=x2.columns)\n    \n    prediction3 = model_fit3.forecast(model_fit3.y, steps=6) #predict\n    prediction3 = pd.DataFrame(data=prediction3, columns=x3.columns)\n    \n    predictions=pd.concat([prediction1, prediction2, prediction3], axis=1)\n    \n    x_forecasted=pd.concat([x, predictions], axis=0).reset_index()\n    \n    # Lets randomly impute home/away games as 0 or 1\n    # I start by generating random 0s and 1s and selecting the index where data is missing\n    # Then we fill.\n    na_loc =x_forecasted.index[x_forecasted['h_a'].isnull()]\n    num_nas = len(na_loc)\n    fill_values = pd.DataFrame({'h_a': [random.randint(0,1) for i in range(num_nas)]}, index = na_loc)\n    \n    x=pd.concat([x, fill_values], axis=0).reset_index(drop=True)\n    predictions.index=fill_values.index\n    x_forecasted2=x.combine_first(predictions)\n    \n    # Now lets mean (numeric) or mode (categorical) impute the other missing variables\n    # Since these are of less modelling importance, a mean impute shouldn't make much difference/\n    # Also, it is logical to assume consistency in Season performance, without any new data\n    # to think otherwise.\n    \n    nums= x_forecasted2.select_dtypes(include=['float', 'int64']).apply(lambda x: x.fillna(x.mean()),axis=0).round()\n    x_forecasted3=x_forecasted2.combine_first(nums) #join this imputation back in to fill missingness\n    x_forecasted4=pd.concat([x_forecasted3, target], axis=1)\n    \n    return(x_forecasted4)\n    \nforecasted_data=fc_games.groupby('teamId').apply(forecast_by_team).reset_index().drop('level_1', axis=1) # run seperately for all teams\nprint(forecasted_data.isna().sum()) #no missing data but the target","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction of future games<br>\nFirst we must ensure that the new forecasted df is in the same format as the previous matchday prediction df<br>\nThat includes changing categories back to categories and one-hot encoding as well as scaling.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"forecasted_data[[\n    'target', 'h_a', 'teamId', 'Referee.x', 'matchDay']] = forecasted_data[[\n        'target', 'h_a', 'teamId', 'Referee.x', 'matchDay']].astype('category')\n        \n# Scale numeric data\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nums= forecasted_data.select_dtypes(include=['float', 'int64'])\nother= forecasted_data.select_dtypes(exclude=['float', 'int64']).drop('target', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nnums_scaled = scaler.fit_transform(nums)\nfc_scaled=pd.DataFrame(nums_scaled, columns=nums.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One hot encode categorical data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dummies=pd.get_dummies(other)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generate an analysis dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fc_pred = pd.concat([fc_scaled,dummies, forecasted_data['target']], axis=1)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prediction data - since there is slight differences in the feature names, we'll retrain the best (tuned XGB) model on the new data<br>\nThis shouldn't make much difference to results but just improve compatability.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = fc_pred[fc_pred['target'].notnull()]\nX_train=train_data.drop('target', axis=1)\ny_train=train_data['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test=fc_pred[fc_pred['target'].isnull()].drop('target', axis=1).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fit to training data and predict. For the XGb parameters we'll insert the tuned hyperparameters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(objective='multi:softprob',\n                    colsample_bytree = 0.5, gamma = 2, learning_rate= 0.2, max_depth= 10, \n                    n_estimators= 500, subsample = 1)\nxgb.fit(X_train,y_train)\nfinal_predictions=pd.DataFrame({'target':xgb.predict(X_test)})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Put the final df together","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"final_test=pd.concat([X_test, final_predictions], axis=1)\ncomplete_season=pd.concat([train_data, final_test], axis=0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Backwards transform OneHotEncoded (dummy) variables (specifically, we need team)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"team_cols=complete_season[complete_season.columns[complete_season.columns.to_series().str.contains('teamId')]]#[col==1].stack().reset_index().drop(0,1)\nteam_cols_long=team_cols[team_cols==1].stack().reset_index().drop(0,1).drop('level_0', axis=1)\nteam_cols_long['team']=team_cols_long['level_1'].str.rpartition('_')[2]\nteam_cols_long=team_cols_long.drop('level_1', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"complete_season=pd.concat([complete_season, team_cols_long], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Rebuilding the final table","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_points=complete_season.filter(items=['team', 'target'])\nnew_points['pts_new']=np.where(new_points['target']==0, 0,\n                           np.where(new_points['target']==1,1, 3))\ntable_final=new_points.groupby('team')['pts_new'].agg(table_points_new='sum').reset_index().sort_values('table_points_new', ascending=False)\ntable_final['position']=range(0,len(table_final), 1)\ntable_final['position']=table_final['position']+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(table_final)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Table changes - did anyone overtake anyone in the last 6 games?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"table_final.sort_values('team', inplace=True)\ntable.sort_values('teamId', inplace=True)\ntable_final['positition_change'] = table['position'] -  table_final['position']\ntable_final.sort_values('position', inplace=True, ascending=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final table","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(table_final)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Complete","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"After some preprocessing and EDA, I used a range of classification algorithms to test which would best<br>\npredict match result. I found that XGb and RF performed best. I tuned these both and found that<br>\n RF improved in performance slightly, as did XGB though increased were small, this is probably due to the fact that<br>\nlimited computation power did not allow for a full grid search so I limited the ability to tune<br>\nparameters to save time.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Note: we could have developed individual team-level predictive models (or combined both) - but did not have time currently.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I then forecasting the final 6 games to the end of the season using VAR. I had planned to forecast all<br>\npredictive variables but soon realised we did not have anywhere near enough observations for this.<br>\nI chose to forecast the 15 most importance variables (according to RF importance) in smaller batches of 5.<br>\nThis is not ideal, and for this reason the forecasts are not too informative (though with more data may will<br>\nbe).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Lastly, I applied the XGb model generated earlier to predict the target (match result) in the final 6 games. <br>\nI then put the league table back together based on the results of the newly predicted games and calculated<br>\na change in the table.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The biggest climbers in the final 6 games will be Burnley!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir(r\"C:/Users/jaket\")\n!jupyter nbconvert --to html EPL_2020_predictions.ipynb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}