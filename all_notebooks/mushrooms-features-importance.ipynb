{"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"version":"3.6.4","name":"python","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","pygments_lexer":"ipython3"}},"nbformat":4,"cells":[{"metadata":{"_cell_guid":"1daba71b-9e76-4ee6-97b1-3b62afdfd62c","collapsed":true,"_uuid":"882cd7b2dfa109f90dded9cc0f737fbb977f655c"},"source":"#Import libraries\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport sklearn\n\nimport sklearn.linear_model\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.linear_model import LogisticRegression\n\n\n\n#Load data\nmushrooms_df = pd.read_csv('../input/mushrooms.csv')\n\nmushrooms_df.rename(columns={'class':'classes'}, inplace=True)\n\n#del mushrooms_df['veil-type']\n\n\n\n#Prepare data using LabelEncoder library\nlabelencoder=LabelEncoder()\n\nfor col in mushrooms_df.columns:\n    mushrooms_df[col]=labelencoder.fit_transform(mushrooms_df[col])\n\n\n''' \nAlternatively I used also a code of this type for all features of mushrooms's file\n#Prepare data\ntotal_rowsn = len(mushrooms_df.index)\n\n#class: edible=e, poisonous=p\nfor i in range(0, total_rowsn):\n    if mushrooms_df.iloc[i, 0] == 'e':\n        mushrooms_df.iloc[i, 0] = 1  # edible\n    else:mushrooms_df.iloc[i, 0] = 0  # poisonous\n\nand so on ....\n\n'''\n\n\n#correlation matrix\ncorr = mushrooms_df.corr()\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n\n\nplt.show(block=True)\n\n'''\nPlotting the correlation \nmatrix we discover thatthe vail-type is a feature \nnot relevat for our classification. Indeed its values \nare all \"p\" and this doesn't contribute to our predictive model.\n\nThe correaltion matrix helps to discover this type of \nfeature without a previous knowledge of the source data file.\n\n'''\n\n#split train and test data\ntrain_df = mushrooms_df.sample(frac=0.7,random_state=200)\n\ntest_df = mushrooms_df.drop(train_df.index)\n\ntest_rowsn = len(test_df.index)\n\ntrain_rowsn = len(train_df.index)\n\n\nX_train = train_df.drop(\"classes\", axis=1)\n\nY_train = train_df.iloc[:, 0]\n\nX_test = test_df.drop(\"classes\", axis=1)\n\nY_test = test_df.iloc[:, 0]\n\n\n#Logistic Regression:\n\nlogreg = LogisticRegression()\n\nlogreg.fit(X_train, Y_train)\n\nY_pred = logreg.predict(X_test)\n\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n\n# accuracy of the Logisti Regression algorithm\nprint (\"accuracy:\")\n\nprint(acc_log)\n\n\n'''\nwe use the logistic regression to analyze the features and what are more important in classificaction\n\nthese are the most important features and we should use only them to check our algorithm\n\nveil-color  6.099109\ngill-size   6.812580\n\nalso they are in red color in the correlation matrix\n\n'''\ncoeff_df = pd.DataFrame(train_df.columns.delete(0))\n\ncoeff_df.columns = ['Feature']\n\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\nresult = coeff_df.sort_values(by=['Correlation'], ascending=[True])\n\n\n\nprint(\"Features importance:\")\n\nprint(result)\n\n#Original data\ndf_origin = pd.DataFrame(Y_test)\n\n#Prediction result\ndf_pred = pd.DataFrame(Y_pred)\n\n\nprint(\"End\")","cell_type":"code","execution_count":null,"outputs":[]}],"nbformat_minor":1}