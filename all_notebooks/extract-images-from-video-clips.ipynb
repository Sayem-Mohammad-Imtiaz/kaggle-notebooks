{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport torch\nimport torch.utils.data","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:53:20.107353Z","iopub.execute_input":"2021-07-26T14:53:20.107758Z","iopub.status.idle":"2021-07-26T14:53:20.113362Z","shell.execute_reply.started":"2021-07-26T14:53:20.107726Z","shell.execute_reply":"2021-07-26T14:53:20.112129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VideoClipLoader(torch.utils.data.Dataset):\n    def __init__(self, video_dir, metadata, pattern_vid = \".mp4\", every = 25 ):\n        \n        \n        self.every = every\n\n        \n        self.metadata = metadata\n        #  make a list of all the videos available from the given metadata dataset\n        self.video_list = video_dir + \"/\" + metadata[\"Folder name\"].astype(str) + \"/\" + metadata[\"Clip Name\"].astype(str)  + pattern_vid\n                   \n\n    # load the full video and separate into images\n    def load_video_as_images(self, video_path):\n        \n        vc = cv2.VideoCapture(video_path)\n                \n        image_list = []\n        \n        index = 0\n        while(vc.isOpened()):\n            # Read a frame from video\n            ret, frame = vc.read()\n\n            if frame is None:\n                break\n                \n            if index % self.every == 0: # check if the frame is the every other one\n                frame = frame[:,:,0] # get only first dimension, they are the same\n                image_list.append(frame)    \n            \n            index+=1\n                \n        \n        vc.release()\n                \n        image_array = np.array(image_list)\n        return image_array, video_path\n    \n    # get the metadata for the video clip\n    def get_video_metadata(self, video_path):\n        \n        #  get the video path and slipt it\n        video_path_split = video_path.split(\"/\")\n        \n        #  extract the folder name and clip name \n        video_folder = video_path_split[-2]\n        video_file = video_path_split[-1].split(\".\")[0]\n        \n        #  select the specified metadata row\n        curr_metadata = self.metadata[(self.metadata.iloc[:,0]== int(video_folder))&(self.metadata.iloc[:,1]== video_file)].dropna()\n        \n        \n        \n        return curr_metadata\n        \n\n    #  get the new n images a video clip\n    def __getitem__(self, idx):\n        \n        #  get images and path\n        img, path = self.load_video_as_images(self.video_list.iloc[idx])\n        \n        \n        #  get metadata\n        metadata_curr = self.get_video_metadata(self.video_list.iloc[idx])\n        \n        # transform the images\n        img = img / 255.0\n        img = torch.from_numpy(img)\n        img = img.float()\n        img = torch.unsqueeze(img, 0)\n        \n        img = img.permute(1, 0, 2, 3)\n        \n        # transform the metadata to a string \n        output_metadata_list = metadata_curr.squeeze().values.tolist()\n        output_metadata_list[2] = output_metadata_list[2].strftime(\"%Y-%m-%d %H:%M:%S\")\n        \n        output_metadata_str = ','.join(map(str, output_metadata_list)) \n        \n        return img, path ,output_metadata_str\n\n    def __len__(self):\n        return len(self.video_list)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:53:23.386177Z","iopub.execute_input":"2021-07-26T14:53:23.386796Z","iopub.status.idle":"2021-07-26T14:53:23.401492Z","shell.execute_reply.started":"2021-07-26T14:53:23.38674Z","shell.execute_reply":"2021-07-26T14:53:23.400637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n'''\nMETADATA structure:\n\n    Folder name - name of the day folder in the format of YYYYMMDD\n    Clip Name - name of the clip folderin the format clip_{number}_{HHMM}\n    DateTime - the date time when the 2 min has started\n    Temperature - in C\n    Humidity - in %\n    Precipitation - in kg/m2\n    Dew Point - in C\n    Wind Direction - in degrees\n    Wind Speed - in m/s2\n    Sun Radiation Intensity - W/m2\n    Min of sunshine latest 10 min - in minutes\n\n'''\n\n'''\nConfig file structure:\n\n    video_path - top path that contains all day video folders and the metadata csv\n    metadata - the selected metadata dataframe that will be used to select the clips\n    main_save_path - the top path for saving the created images and metadata\n    every - sampling rate at which the images will be created from the video, default one is every 25th\n    pattern_video - what pattern to be searched for in the folders, default one is .mp4\n\n'''\n\n\n# Script to get the queried metadata and create image set for it\ndef make_imagesets(cfg, save = False):\n\n    # get the dataset from the selected metadata and the specified \"every\" next one\n    dataset = VideoClipLoader(video_dir=cfg['video_path'], metadata = cfg['metadata'], every = cfg['every'])\n\n\n    # create the folder\n    if not os.path.exists(cfg['main_save_path']):\n\n        os.makedirs(cfg['main_save_path'])\n\n    #  go through all the clips in the dataset, cut them in images and save them\n    metadata_list = []\n    for i, sample in enumerate(dataset):\n        img, path, curr_metadata = sample\n        curr_metadata = curr_metadata.split(',')\n        #  save dir for all the images from each clip\n        save_dir = os.path.join(cfg['main_save_path'],curr_metadata[0],curr_metadata[1])\n\n        #  create the save dir\n        if save:\n            if not os.path.exists(save_dir):\n\n                os.makedirs(save_dir)\n\n        #  go through all the images from the clip, transform them and save them to disk\n        count = 0\n        for sub_img in img:\n            sub_img = sub_img.unsqueeze(0)\n            input_img = sub_img.squeeze(1).mul(255).byte().numpy()\n\n            count_str =\"image_\" + str(count).zfill(4)\n            \n            if save:\n                cv2.imwrite(os.path.join(save_dir, count_str + '.jpg'), np.squeeze(input_img))\n            #  create a metadata entry for the image, containing the image number\n            img_metadata = [curr_metadata[0], curr_metadata[1], count_str, curr_metadata[2], curr_metadata[3], curr_metadata[4], curr_metadata[5], curr_metadata[6],curr_metadata[7], curr_metadata[8],curr_metadata[9],curr_metadata[10]]\n            metadata_list.append(img_metadata)\n\n\n            count+=1\n\n        print(f\"Finished {save_dir}\")\n\n    # save all the new metadata entries per image to a new csv in the same folder\n    metadata_df = pd.DataFrame.from_records(metadata_list, columns=['Folder name', 'Clip Name', 'Image Number', 'DateTime', 'Temperature', 'Humidity', 'Precipitation', 'Dew Point', 'Wind Direction', 'Wind Speed', 'Sun Radiation Intensity', 'Min of sunshine latest 10 min'])\n    \n    if save:\n        metadata_df.to_csv(os.path.join(cfg['main_save_path'], \"metadata_images.csv\"), index=False)\n\n\n\nif __name__ == '__main__':\n\n    every = 25\n\n    pattern_vid = \".mp4\"\n\n    video_path = r\"/kaggle/input/longterm-thermal-drift-dataset/LTD Dataset/Video Clips\"\n\n    metadata_name = r\"/kaggle/input/longterm-thermal-drift-dataset/LTD Dataset/metadata.csv\"\n    metadata_path = os.path.join(video_path, metadata_name)\n\n    metadata = pd.read_csv(metadata_path)\n    metadata[\"DateTime\"] = pd.to_datetime(metadata['DateTime'], dayfirst = True)\n\n\n    main_save_dir = r\"Image Dataset\"\n    \n    \n\n    # Training\n    #  creating the cfg file containing all the necessary information for creating the training set\n    cfg = {\n        'video_path': video_path,\n        'metadata': metadata,\n        'main_save_path': main_save_dir,\n        'every': every,\n        'pattern_video': pattern_vid,\n\n    }\n    #  call the function\n    make_imagesets(cfg, save = False)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:53:52.078403Z","iopub.execute_input":"2021-07-26T14:53:52.078965Z","iopub.status.idle":"2021-07-26T14:54:05.569954Z","shell.execute_reply.started":"2021-07-26T14:53:52.078908Z","shell.execute_reply":"2021-07-26T14:54:05.568519Z"},"trusted":true},"execution_count":null,"outputs":[]}]}