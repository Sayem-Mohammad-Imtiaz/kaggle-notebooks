{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nimport tensorflow as tf\nfrom tensorflow import keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(df.Outcome,label=\"Count\") \ndf.Outcome.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(df.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.melt(df,id_vars=\"Outcome\",var_name=\"features\",value_name=\"value\")\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,10))\nplt.xticks(rotation=90)\nsns.violinplot(x=\"features\", y=\"value\", hue=\"Outcome\", data=data,split=True, inner=\"quart\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df[\"Outcome\"]\nx=df.drop([\"Outcome\"],axis=1)\nmean = x.mean(axis=0)\nstd = x.std(axis=0)\npd.concat([mean,std],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_norm=(x - mean)/std\ndf_norm = pd.concat([y,x_norm],axis=1)\ndf_norm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_norm = pd.melt(df_norm,id_vars=\"Outcome\",var_name=\"features\",value_name=\"value\")\ndata_norm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,10))\nplt.xticks(rotation=90)\nsns.violinplot(x=\"features\", y=\"value\", hue=\"Outcome\", data=data_norm, split=True, inner=\"quart\")\n# sns.swarmplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data_norm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,10))\nplt.xticks(rotation=90)\nsns.boxplot(x=\"features\", y=\"value\", hue=\"Outcome\", data=data_norm)\n# sns.stripplot(x=\"features\", y=\"value\",data=data_norm, jitter = True, color = \"black\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Then create models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0,test_size=0.2)\ny_one_hot = pd.get_dummies(y)\nx_train,x_test,y_one_hot_train,y_one_hot_test=train_test_split(x,y_one_hot,random_state=0,test_size=0.2)\nx_norm_train,x_norm_test,y_norm_train,y_norm_test=train_test_split(x_norm,y,random_state=0,test_size=0.2) #y_train==y_norm_train\nx_norm_train,x_norm_test,y_norm_one_hot_train,y_norm_one_hot_test=train_test_split(x_norm,y_one_hot,random_state=0,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nlist_1=[]\nfor i in range(1,21):\n    knn=KNeighborsClassifier(n_neighbors=i)\n    knn.fit(x_norm_train,y_norm_train)\n    pred_s=knn.predict(x_test)\n    scores=accuracy_score(y_test,pred_s)\n    list_1.append(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x=list(range(1,21)),y=list_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(max(list_1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression(max_iter=10000)\nlr.fit(x_train,y_train)\npred_1=lr.predict(x_test)\nscore_1=accuracy_score(y_test,pred_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmx = confusion_matrix(y_test,pred_1)\nsns.heatmap(cmx,annot=True,fmt=\"d\")\nprint(\"score_1 = \",score_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier()\nrfc.fit(x_train,y_train)\npred_2=rfc.predict(x_test)\nscore_2=accuracy_score(y_test,pred_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmx = confusion_matrix(y_test,pred_2)\nsns.heatmap(cmx,annot=True,fmt=\"d\")\nprint(\"score_2 = \",score_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngbc=GradientBoostingClassifier()\ngbc.fit(x_train,y_train)\npred_3=gbc.predict(x_test)\nscore_3=accuracy_score(y_test,pred_3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmx = confusion_matrix(y_test,pred_3)\nsns.heatmap(cmx,annot=True,fmt=\"d\")\nprint(\"score_3 = \",score_3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n  model = keras.Sequential([\n    keras.layers.Dense(64, activation=tf.nn.relu,\n                       input_shape=(x.shape[1],)),\n    keras.layers.Dense(64, activation=tf.nn.sigmoid),\n    keras.layers.Dense(2)\n  ])\n \n  optimizer = tf.optimizers.RMSprop(0.001)\n \n  model.compile(loss='binary_crossentropy',\n                optimizer=optimizer,\n                metrics=['accuracy'])\n  return model\n\nmodel = build_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display training progress by printing a single dot for each completed epoch.\nclass PrintDot(keras.callbacks.Callback):\n  def on_epoch_end(self,epoch,logs):\n    if epoch % 100 == 0: print('')\n    print('.', end='')\n    \ndef plot_history(history):\n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Mean Abs Error [1000$]')\n  plt.plot(history.epoch, np.array(history.history['accuracy']),\n           label='accuracy')\n  plt.plot(history.epoch, np.array(history.history['loss']),\n           label='loss')\n  plt.plot(history.epoch, np.array(history.history['val_accuracy']),\n           label = 'Val accuracy')\n  plt.plot(history.epoch, np.array(history.history['val_loss']),\n           label='Val loss')\n\n  plt.legend()\n  plt.ylim([0,1])\n \nEPOCHS = 20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Store training stats\nhistory = model.fit(x_norm_train, y_norm_one_hot_train, epochs=EPOCHS,\n                    validation_split=0.2, verbose=0,\n                    callbacks=[PrintDot()])\nplot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_4 =model.predict(x_norm_test) \ncmx = confusion_matrix(np.argmax(y_norm_one_hot_test.values,axis=1),np.argmax(pred_4,axis=1))\nsns.heatmap(cmx,annot=True,fmt=\"d\")\nscore_4=accuracy_score(np.argmax(y_norm_one_hot_test.values,axis=1),np.argmax(pred_4,axis=1))\nscore_4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model_2():\n  model = keras.Sequential([\n    keras.layers.Dense(64, activation=tf.nn.relu,\n                       input_shape=(x.shape[1],)),\n    keras.layers.Dense(64, activation=tf.nn.sigmoid),\n    keras.layers.Dense(1,activation='sigmoid')\n  ])\n \n  optimizer = tf.optimizers.RMSprop(0.001)\n \n  model.compile(loss='binary_crossentropy',\n                optimizer=optimizer,\n                metrics=['accuracy'])\n  return model\n\nmodel_2 = build_model_2()\nmodel_2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Store training stats\nhistory_2 = model_2.fit(x_norm_train, y_norm_train, epochs=EPOCHS,\n                    validation_split=0.2, verbose=0,\n                    callbacks=[PrintDot()])\nplot_history(history_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_5 =model_2.predict(x_norm_test) \ncmx = confusion_matrix(y_norm_test,pred_5>0.5)\nsns.heatmap(cmx,annot=True,fmt=\"d\")\nscore_5=accuracy_score(y_norm_test,pred_5>0.5)\nscore_5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# neural net is not as good as other models\n# then clean the data and try again\n\n(df==0).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Glucose,BloodPressure, SkinThickness, Insulin, BMI, should not to be 0, and seems to be miising data. Okay, let's replace them with mean.\nprint(\"Glucose\",df[\"Glucose\"].mean(),df[df[\"Glucose\"]!=0].Glucose.mean())\nprint(\"BloodPressure\",df[\"BloodPressure\"].mean(),df[df[\"BloodPressure\"]!=0].BloodPressure.mean())\nprint(\"SkinThickness\",df[\"SkinThickness\"].mean(),df[df[\"SkinThickness\"]!=0].SkinThickness.mean())\nprint(\"Insulin\",df[\"Insulin\"].mean(),df[df[\"Insulin\"]!=0].Insulin.mean())\nprint(\"BMI\",df[\"BMI\"].mean(),df[df[\"BMI\"]!=0].BMI.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fill = df\ndf_fill[\"Glucose\"] = df_fill[\"Glucose\"].replace(0,df[df[\"Glucose\"]!=0].Glucose.mean())\ndf_fill[\"BloodPressure\"] = df_fill[\"BloodPressure\"].replace(0,df[df[\"BloodPressure\"]!=0].BloodPressure.mean())\ndf_fill[\"SkinThickness\"] = df_fill[\"SkinThickness\"].replace(0,df[df[\"SkinThickness\"]!=0].SkinThickness.mean())\ndf_fill[\"Insulin\"] = df_fill[\"Insulin\"].replace(0,df[df[\"Insulin\"]!=0].Insulin.mean())\ndf_fill[\"BMI\"] = df_fill[\"BMI\"].replace(0,df[df[\"BMI\"]!=0].BMI.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fill","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_fill=df_fill.drop([\"Outcome\"],axis=1)\nmean_fill = x_fill.mean(axis=0)\nstd_fill = x_fill.std(axis=0)\npd.concat([mean_fill,std_fill],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_fill_norm=(x_fill - mean_fill)/std_fill\ndf_fill_norm = pd.concat([y,x_fill_norm],axis=1)\ndf_fill_norm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_fill_norm = pd.melt(df_fill_norm,id_vars=\"Outcome\",var_name=\"features\",value_name=\"value\")\ndata_fill_norm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,10))\nplt.xticks(rotation=90)\nsns.violinplot(x=\"features\", y=\"value\", hue=\"Outcome\", data=data_fill_norm, split=True, inner=\"quart\")\n# sns.swarmplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=data_norm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_fill_norm_train,x_fill_norm_test,y_train,y_test=train_test_split(x_fill_norm,y,random_state=0,test_size=0.2)\nmodel_3 = build_model_2()\nmodel_3.summary()\n# Store training stats\nhistory_3 = model_3.fit(x_fill_norm_train, y_train, epochs=EPOCHS,\n                    validation_split=0.2, verbose=0,\n                    callbacks=[PrintDot()])\nplot_history(history_3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_6 =model_3.predict(x_fill_norm_test) \ncmx = confusion_matrix(y_test,pred_6>0.5)\nsns.heatmap(cmx,annot=True,fmt=\"d\") \nscore_6=accuracy_score(y_test,pred_6>0.5)\nscore_6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}