{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Update\n\nI am trying to add the **Mosaic** augmentation. However, it's not completed yet. To create a class label in `CutMix` or `MixUp` type augmentation, we can use `beta` such as `np.random.beta` or `scipy.stats.beta` and do as follows for two labels:\n\n\n```\nlabel = label_one*beta + (1-beta)*label_two\n```\n\nBut what if we've **more than two** images? In [YoLo4](https://arxiv.org/abs/2004.10934), they've tried an interesting augmentation called **Mosaic Augmentation** for object detection problems. Unlike `CutMix` or `MixUp`, this augmentation creates augmented samples with **4** images. In object detection cases, we can compute the shift of each instance co-ords and thus possible to get the proper ground truth, [here][2]. But for only image classification cases, how can we do that efficiently? Here is an asked a question over [SO](https://stackoverflow.com/questions/65181294/how-to-create-class-label-for-mosaic-augmentation-in-image-classification), if you able to get some workaroud, please suggest. -)","metadata":{}},{"cell_type":"markdown","source":"# Advanced Augmentation\n\nHi, This is a simple EDA and data augmentation pipeline for multi-class image classification with custom sequence data generator in `tf.keras`. Here image samples will be used. Mainly I will try to show how you can use some of the advanced augmentation in a custom `tf.keras.utils.Sequence` generator in `tf.keras`. The advanced augmentaiton are as follows:\n\n```\n- CutMix\n- MixUp\n- FMix\n```\n\nThe implementations of `CutMix` and `MixUp` augmentation are taken from [Chris Deotte](https://www.kaggle.com/cdeotte/cutmix-and-mixup-on-gpu-tpu) and integrated into a custom [tf.keras.utils.Sequence](https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence) generator with few modification. The `FMix` is simply taken from the original source code, from [here](https://github.com/ecs-vlc/FMix). ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom glob import glob\nimport albumentations as A \nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport os, gc, cv2, random, warnings, math, sys, json, pprint\n\n# sklearn\nfrom sklearn.utils import class_weight\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score\n\n# tf \nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \nwarnings.simplefilter('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-03T10:00:06.803267Z","iopub.execute_input":"2021-07-03T10:00:06.80362Z","iopub.status.idle":"2021-07-03T10:00:13.016579Z","shell.execute_reply.started":"2021-07-03T10:00:06.803587Z","shell.execute_reply":"2021-07-03T10:00:13.015851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# helper function to plot sample \ndef plot_imgs(dataset_show, row, col):\n    rcParams['figure.figsize'] = 20,10\n    for i in range(row):\n        f, ax = plt.subplots(1,col)\n        for p in range(col):\n            idx = np.random.randint(0, len(dataset_show))\n            img, label = dataset_show[idx]\n            ax[p].grid(False)\n            ax[p].imshow(img[0])\n            try:\n                ax[p].set_title(label[0].numpy())\n            except:\n                ax[p].set_title(label[0])\n    plt.show()\n    \n\ndef visulize(path, n_images, is_random=True, figsize=(16, 16)):\n    plt.figure(figsize=figsize)\n    \n    w = int(n_images ** .5)\n    h = math.ceil(n_images / w)\n    \n    image_names = os.listdir(path)\n    for i in range(n_images):\n        image_name = image_names[i]\n        if is_random:\n            image_name = random.choice(image_names)\n            \n        img = cv2.imread(os.path.join(path, image_name))\n        plt.subplot(h, w, i + 1)\n        plt.imshow(img)\n        plt.xticks([])\n        plt.yticks([])\n    plt.show()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-03T10:06:58.10521Z","iopub.execute_input":"2021-07-03T10:06:58.105553Z","iopub.status.idle":"2021-07-03T10:06:58.116292Z","shell.execute_reply.started":"2021-07-03T10:06:58.105516Z","shell.execute_reply":"2021-07-03T10:06:58.11536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comp_cassava = False\ncomp_covid19 = True\n\ndef hot_to_sparse(row):\n    return(row.index[row.apply(lambda x: x==1)][0])\n\nclass BaseConfig(object):\n    SEED  = 101\n    if comp_cassava:\n        TRAIN_DF = '../input/cassava-leaf-disease-classification/train.csv'\n        TRAIN_IMG_PATH = '../input/cassava-leaf-disease-classification/train_images/'\n        TEST_IMG_PATH  = '../input/cassava-leaf-disease-classification/test_images/'\n        CLASS_MAP  = '../input/cassava-leaf-disease-classification/label_num_to_disease_map.json'\n        NUM_CLASSES = 5\n    elif comp_covid19:\n        TRAIN_IMG_PATH = '../input/covid19-detection-890pxpng-study/train/'\n        NUM_CLASSES = 4\n        study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv'); print(study_df.shape)\n        study_df['StudyInstanceUID'] = study_df['id'].apply(lambda x: x.replace('_study', ''))\n        del study_df['id']\n\n        study_df['diagnosis'] = study_df.apply(lambda row:hot_to_sparse(row), axis=1)\n        cls = {\n            'Typical Appearance':1,                    \n            'Negative for Pneumonia':2,                \n            'Indeterminate Appearance':3,                     \n            'Atypical Appearance':4,    \n        }\n        study_df['sparse_gt'] = study_df.diagnosis.map(cls) \n\n        image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv'); print(image_df.shape)\n        df = image_df.merge(study_df, on='StudyInstanceUID')\n        df['id'] = df['id'].apply(lambda x: x.replace('_image', ''))\n        display(df.head()); print(df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T10:00:13.027847Z","iopub.execute_input":"2021-07-03T10:00:13.028187Z","iopub.status.idle":"2021-07-03T10:00:14.096855Z","shell.execute_reply.started":"2021-07-03T10:00:13.028162Z","shell.execute_reply":"2021-07-03T10:00:14.096239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Overview**","metadata":{}},{"cell_type":"code","source":"if comp_cassava:\n    df = pd.read_csv(BaseConfig.TRAIN_DF)\n    assert df.shape[0] == len(df.image_id.unique()) , \"NOT ALL ID UNIQUE\"\n    print(df.info())\n    df.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-03T10:00:14.097718Z","iopub.execute_input":"2021-07-03T10:00:14.09806Z","iopub.status.idle":"2021-07-03T10:00:14.101921Z","shell.execute_reply.started":"2021-07-03T10:00:14.098035Z","shell.execute_reply":"2021-07-03T10:00:14.101334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Significant Class Imbalance**","metadata":{}},{"cell_type":"code","source":"if comp_cassava:\n    with open(os.path.join(BaseConfig.CLASS_MAP)) as file:\n        pprint.pprint(json.loads(file.read()))","metadata":{"execution":{"iopub.status.busy":"2021-07-03T10:00:14.103791Z","iopub.execute_input":"2021-07-03T10:00:14.104036Z","iopub.status.idle":"2021-07-03T10:00:14.11319Z","shell.execute_reply.started":"2021-07-03T10:00:14.104012Z","shell.execute_reply":"2021-07-03T10:00:14.112322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if comp_cassava:\n    temp_df = df.copy()\n    temp_df[['CBB', 'CBSD', 'CGM', 'CMD', 'Healthy']] = pd.get_dummies(temp_df[\"label\"])\n\n    fig = go.Figure(data=[go.Pie(labels=temp_df.columns[2:],values=temp_df.iloc[:, 2:].sum().values)])\n    fig.show()\n\n    del temp_df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-03T10:00:14.114337Z","iopub.execute_input":"2021-07-03T10:00:14.114637Z","iopub.status.idle":"2021-07-03T10:00:14.122112Z","shell.execute_reply.started":"2021-07-03T10:00:14.114613Z","shell.execute_reply":"2021-07-03T10:00:14.121504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Displaying Samples**","metadata":{}},{"cell_type":"code","source":"visulize(BaseConfig.TRAIN_IMG_PATH, 9, is_random=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T10:00:14.123182Z","iopub.execute_input":"2021-07-03T10:00:14.123487Z","iopub.status.idle":"2021-07-03T10:00:15.535318Z","shell.execute_reply.started":"2021-07-03T10:00:14.123464Z","shell.execute_reply":"2021-07-03T10:00:15.53471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation\n\nThe `albumentation` is primarily used for resizing and normalization. ","metadata":{}},{"cell_type":"code","source":"# For Training \ndef albu_transforms_train(data_resize): \n    return A.Compose([\n            A.ToFloat(),\n            A.Resize(data_resize, data_resize),\n        ], p=1.)\n\n# For Validation \ndef albu_transforms_valid(data_resize): \n    return A.Compose([\n            A.ToFloat(),\n            A.Resize(data_resize, data_resize),\n        ], p=1.)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T10:00:15.53628Z","iopub.execute_input":"2021-07-03T10:00:15.536679Z","iopub.status.idle":"2021-07-03T10:00:15.541547Z","shell.execute_reply.started":"2021-07-03T10:00:15.536651Z","shell.execute_reply":"2021-07-03T10:00:15.540903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CutMix** Augmentation","metadata":{}},{"cell_type":"code","source":"def CutMix(image, label, DIM, PROBABILITY = 1.0):\n    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n    # output - a batch of images with cutmix applied\n    CLASSES = BaseConfig.NUM_CLASSES\n    \n    imgs = []; labs = []\n    for j in range(len(image)):\n        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.int32)\n        \n        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n        k = tf.cast( tf.random.uniform([],0,len(image)),tf.int32)\n        \n        # CHOOSE RANDOM LOCATION\n        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        \n        b = tf.random.uniform([],0,1) # this is beta dist with alpha=1.0\n        \n        WIDTH = tf.cast( DIM * tf.math.sqrt(1-b),tf.int32) * P\n        ya = tf.math.maximum(0,y-WIDTH//2)\n        yb = tf.math.minimum(DIM,y+WIDTH//2)\n        xa = tf.math.maximum(0,x-WIDTH//2)\n        xb = tf.math.minimum(DIM,x+WIDTH//2)\n        \n        # MAKE CUTMIX IMAGE\n        one = image[j,ya:yb,0:xa,:]\n        two = image[k,ya:yb,xa:xb,:]\n        three = image[j,ya:yb,xb:DIM,:]\n        middle = tf.concat([one,two,three],axis=1)\n        img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM,:,:]],axis=0)\n        imgs.append(img)\n        \n        # MAKE CUTMIX LABEL\n        a = tf.cast(WIDTH*WIDTH/DIM/DIM,tf.float32)\n        labs.append((1-a)*label[j] + a*label[k])\n            \n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n    image2 = tf.reshape(tf.stack(imgs),(len(image),DIM,DIM,3))\n    label2 = tf.reshape(tf.stack(labs),(len(image),CLASSES))\n    \n    return image2,label2","metadata":{"execution":{"iopub.status.busy":"2021-07-03T10:00:15.542519Z","iopub.execute_input":"2021-07-03T10:00:15.542781Z","iopub.status.idle":"2021-07-03T10:00:15.556142Z","shell.execute_reply.started":"2021-07-03T10:00:15.542756Z","shell.execute_reply":"2021-07-03T10:00:15.555499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**MixUp** Augmentation","metadata":{}},{"cell_type":"code","source":"def MixUp(image, label, DIM, PROBABILITY = 1.0):\n    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n    # output - a batch of images with mixup applied\n    CLASSES = BaseConfig.NUM_CLASSES\n    \n    imgs = []; labs = []\n    for j in range(len(image)):\n        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\n        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n                   \n        # CHOOSE RANDOM\n        k = tf.cast( tf.random.uniform([],0,len(image)),tf.int32)\n        a = tf.random.uniform([],0,1)*P # this is beta dist with alpha=1.0\n                    \n        # MAKE MIXUP IMAGE\n        img1 = image[j,]\n        img2 = image[k,]\n        imgs.append((1-a)*img1 + a*img2)\n                    \n        # MAKE CUTMIX LABEL\n        labs.append((1-a)*label[j] + a*label[k])\n            \n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n    image2 = tf.reshape(tf.stack(imgs),(len(image),DIM,DIM,3))\n    label2 = tf.reshape(tf.stack(labs),(len(image),CLASSES))\n    return image2,label2","metadata":{"execution":{"iopub.status.busy":"2021-07-03T10:00:15.557287Z","iopub.execute_input":"2021-07-03T10:00:15.557609Z","iopub.status.idle":"2021-07-03T10:00:15.569106Z","shell.execute_reply.started":"2021-07-03T10:00:15.557583Z","shell.execute_reply":"2021-07-03T10:00:15.568264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FMix** Augmentation","metadata":{}},{"cell_type":"code","source":"sys.path.insert(0, \"/kaggle/input/pyutils\")\nfrom fmix_utils import sample_mask\n\ndef FMix(image, label, DIM,  alpha=1, decay_power=3, max_soft=0.0, reformulate=False):\n    lam, mask = sample_mask(alpha, decay_power,(DIM, DIM), max_soft, reformulate)\n    index = tf.constant(np.random.permutation(int(image.shape[0])))\n    mask  = np.expand_dims(mask, -1)\n    \n    # samples \n    image1 = image * mask\n    image2 = tf.gather(image, index) * (1 - mask)\n    image3 = image1 + image2\n\n    # labels\n    label1 = label * lam \n    label2 = tf.gather(label, index) * (1 - lam)\n    label3 = label1 + label2 \n    return image3, label3","metadata":{"execution":{"iopub.status.busy":"2021-07-03T10:00:15.570149Z","iopub.execute_input":"2021-07-03T10:00:15.57048Z","iopub.status.idle":"2021-07-03T10:00:15.591532Z","shell.execute_reply.started":"2021-07-03T10:00:15.57045Z","shell.execute_reply":"2021-07-03T10:00:15.590705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Mosaic** Augmentation","metadata":{}},{"cell_type":"code","source":"def MosaicMix(image, label, DIM, minfrac=0.25, maxfrac=0.75):\n    xc, yc  = np.random.randint(DIM * minfrac, DIM * maxfrac, (2,))\n    indices = np.random.permutation(int(image.shape[0]))\n    mosaic_image = np.zeros((DIM, DIM, 3), dtype=np.float32)\n    final_imgs   = []\n    \n    # Iterate over the full indices \n    for j in range(len(indices)): \n        # Take 4 sample for to create a mosaic sample randomly \n        rand4indices = [j] + random.sample(list(indices), 3) \n        \n        # Make mosaic with 4 samples \n        for i in range(len(rand4indices)):\n            if i == 0:    # top left\n                x1a, y1a, x2a, y2a =  0,  0, xc, yc\n                x1b, y1b, x2b, y2b = DIM - xc, DIM - yc, DIM, DIM # from bottom right        \n            elif i == 1:  # top right\n                x1a, y1a, x2a, y2a = xc, 0, DIM , yc\n                x1b, y1b, x2b, y2b = 0, DIM - yc, DIM - xc, DIM # from bottom left\n            elif i == 2:  # bottom left\n                x1a, y1a, x2a, y2a = 0, yc, xc, DIM\n                x1b, y1b, x2b, y2b = DIM - xc, 0, DIM, DIM-yc   # from top right\n            elif i == 3:  # bottom right\n                x1a, y1a, x2a, y2a = xc, yc,  DIM, DIM\n                x1b, y1b, x2b, y2b = 0, 0, DIM-xc, DIM-yc    # from top left\n                \n            # Copy-Paste\n            mosaic_image[y1a:y2a, x1a:x2a] = image[i,][y1b:y2b, x1b:x2b]\n                   \n        # Append the Mosiac samples\n        final_imgs.append(mosaic_image)\n \n    return final_imgs, label","metadata":{"execution":{"iopub.status.busy":"2021-07-03T10:00:15.592618Z","iopub.execute_input":"2021-07-03T10:00:15.592848Z","iopub.status.idle":"2021-07-03T10:00:15.603278Z","shell.execute_reply.started":"2021-07-03T10:00:15.592824Z","shell.execute_reply":"2021-07-03T10:00:15.602547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom Sequence Data Generator","metadata":{}},{"cell_type":"code","source":"class SequenceGenerator(tf.keras.utils.Sequence):\n    def __init__(self, img_path, data, batch_size, \n                 dim, shuffle=True, transform=None, \n                 use_mixup=False, use_cutmix=False,\n                 use_fmix=False, use_mosaicmix=False):\n        self.dim  = dim\n        self.data = data\n        self.shuffle  = shuffle\n        self.img_path = img_path\n        self.augment  = transform\n        self.use_cutmix = use_cutmix\n        self.use_mixup  = use_mixup\n        self.use_fmix   = use_fmix \n        self.use_mosaicmix = use_mosaicmix\n        self.batch_size = batch_size\n        self.list_idx   = self.data.index.values\n        if comp_cassava:\n            self.label = pd.get_dummies(self.data['label'], columns = ['label'])\n        elif comp_covid19:\n            self.label = pd.get_dummies(self.data['sparse_gt'], columns = ['label'])\n        self.on_epoch_end()\n        \n    def __len__(self):\n        return int(np.ceil(float(len(self.data)) / float(self.batch_size)))\n    \n    def __getitem__(self, index):\n        batch_idx = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n        idx = [self.list_idx[k] for k in batch_idx]\n        \n        Data   = np.empty((self.batch_size, *self.dim))\n        Target = np.empty((self.batch_size, BaseConfig.NUM_CLASSES), dtype = np.float32)\n\n        for i, k in enumerate(idx):\n            # load the image file using cv2\n            if comp_cassava:\n                image = cv2.imread(self.img_path + self.data['image_id'][k])\n            elif comp_covid19:\n                image = cv2.imread(self.img_path + self.data['id'][k] + '.png')\n            image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n            \n            res = self.augment(image=image)\n            image = res['image']\n            \n            # assign \n            Data[i,] =  image\n            Target[i,] = self.label.iloc[k,].values\n                \n        # cutmix \n        if self.use_cutmix:\n            Data, Target = CutMix(Data, Target, self.dim[0])\n            \n        # mixup \n        if self.use_mixup:\n            Data, Target = MixUp(Data, Target, self.dim[0]) \n            \n        # fmix \n        if self.use_fmix:\n            Data, Target = FMix(Data, Target, self.dim[0])\n            \n        if self.use_mosaicmix:\n            Data, Target = MosaicMix(Data, Target, self.dim[0]) \n\n        return Data, Target \n    \n    def on_epoch_end(self):\n        self.indices = np.arange(len(self.list_idx))\n        if self.shuffle:\n            np.random.shuffle(self.indices)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T10:00:15.604233Z","iopub.execute_input":"2021-07-03T10:00:15.604469Z","iopub.status.idle":"2021-07-03T10:00:15.619326Z","shell.execute_reply.started":"2021-07-03T10:00:15.604446Z","shell.execute_reply":"2021-07-03T10:00:15.618615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font color = \"seagreen\">CutMix Visualizaiton</font>\n\n[paper-work](https://arxiv.org/abs/1905.04899)","metadata":{}},{"cell_type":"code","source":"check_gens = SequenceGenerator(BaseConfig.TRAIN_IMG_PATH, BaseConfig.df, 20, \n                              (320, 320, 3),shuffle = True, \n                              use_mixup = False, use_cutmix = True, \n                              use_fmix = False, transform = albu_transforms_train(320))\n\nplot_imgs(check_gens, row=5, col=3)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-03T10:07:02.840964Z","iopub.execute_input":"2021-07-03T10:07:02.841273Z","iopub.status.idle":"2021-07-03T10:07:12.057409Z","shell.execute_reply.started":"2021-07-03T10:07:02.841244Z","shell.execute_reply":"2021-07-03T10:07:12.056571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font color = \"seagreen\">MixUp Visualizaiton</font>\n\n[paper-work](https://arxiv.org/abs/1710.09412)","metadata":{}},{"cell_type":"code","source":"check_gens = SequenceGenerator(BaseConfig.TRAIN_IMG_PATH, BaseConfig.df, 20, \n                              (320, 320, 3),shuffle = True, \n                              use_mixup = True, use_cutmix = False, \n                              use_fmix = False, transform = albu_transforms_train(320))\n\nplot_imgs(check_gens, row=5, col=3)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-03T10:07:20.745802Z","iopub.execute_input":"2021-07-03T10:07:20.746259Z","iopub.status.idle":"2021-07-03T10:07:29.890075Z","shell.execute_reply.started":"2021-07-03T10:07:20.746228Z","shell.execute_reply":"2021-07-03T10:07:29.889332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font color = \"seagreen\">FMix Visualizaiton</font>\n\n[paper-work](https://arxiv.org/abs/2002.12047)","metadata":{}},{"cell_type":"code","source":"check_gens = SequenceGenerator(BaseConfig.TRAIN_IMG_PATH, BaseConfig.df, 20, \n                              (420, 420, 3),shuffle = True, \n                              use_mixup = False, use_cutmix = False, \n                              use_fmix = True, transform = albu_transforms_train(420))\n\nplot_imgs(check_gens, row=5, col=3)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-03T10:07:33.552851Z","iopub.execute_input":"2021-07-03T10:07:33.553164Z","iopub.status.idle":"2021-07-03T10:07:46.913591Z","shell.execute_reply.started":"2021-07-03T10:07:33.553133Z","shell.execute_reply":"2021-07-03T10:07:46.912857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font color = \"seagreen\">Mosaic Visualization [WIP]</font>\n\n[paper-work](https://arxiv.org/abs/2004.10934)","metadata":{}},{"cell_type":"code","source":"check_gens = SequenceGenerator(BaseConfig.TRAIN_IMG_PATH, BaseConfig.df, 20, \n                              (512, 512, 3),shuffle = True, \n                              use_mixup = False, use_cutmix = False, \n                              use_fmix = False, use_mosaicmix=True, transform = albu_transforms_train(512))\n\nplot_imgs(check_gens, row=7, col=3)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T10:07:58.971823Z","iopub.execute_input":"2021-07-03T10:07:58.972305Z","iopub.status.idle":"2021-07-03T10:08:12.141493Z","shell.execute_reply.started":"2021-07-03T10:07:58.972262Z","shell.execute_reply":"2021-07-03T10:08:12.140552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plese note**, if you want to use this augmentation in your custom data generator, you probabely need to eunsure randomness of chosing each augmentaiton. This notebook is just for **demonstration purpose**. Also please note that, for best input data pipelines, `tf.data` API is highly recommended. ","metadata":{}}]}