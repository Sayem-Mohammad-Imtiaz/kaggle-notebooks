{"cells":[{"metadata":{"_cell_guid":"135804c3-d0e3-446a-8fce-466cfaa5ca18","_uuid":"fa54b4344444736402c122a50e1a30665cb37806"},"cell_type":"markdown","source":"This notebook provides a quick introduction to binary classification, using two common techniques:\n* Decision Trees\n* Logistic Regression\n\nBoth techniques have their strengths. Decision Trees are an excellent classifier, as they do not require linearity and perform implicit feature selection. More importantly, they are easy to interpret by a person, for example a mushroom hunter in the field.  However, out of the box a decision tree only predicts a label (edible or poisonous). \n\nThe logistic regression is less interpretable, but outputs a continous number representing the probability of a class. This arms the user with information about *how certain* the classifier is about a given prediction. \n\nIn addition, we'll use a technique called bootstrapping to develop a confidence interval around the prediction. This will arm the user with confidence interval illustrating a range of likely probabilities, in addition to the expected probability that a given mushroom is poisonous. "},{"metadata":{"_kg_hide-output":false,"_cell_guid":"1c86184a-0d9c-474c-9a61-f30fd57b4556","_uuid":"1123c83e60ec6b15a0564f018de2d24eb3522d4c","_kg_hide-input":false,"collapsed":true},"cell_type":"code","execution_count":null,"source":"from subprocess import check_output\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport itertools\nimport graphviz\nimport random\nimport math\nimport matplotlib.pyplot as plt # plotting\nfrom scipy import stats \nfrom scipy.stats import chi2_contingency\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import tree\nfrom sklearn.utils import resample\n\n%matplotlib inline\n\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nraw_data = pd.read_csv('../input/mushrooms.csv')\nprint(raw_data.describe())","outputs":[]},{"metadata":{"_cell_guid":"ffecf9b0-6f3e-4f1e-9d00-18c4c7780d9a","_uuid":"ad4525d5759c15e6e17f26357cf7e96cd53cd464","collapsed":true},"cell_type":"code","execution_count":null,"source":"raw_data.head()","outputs":[]},{"metadata":{"_cell_guid":"c4f48e28-ccb5-46f7-82c5-d26338c43594","_uuid":"5ab6d8288f7b6f3953e34aef2bd978bb73265d47","_kg_hide-input":true,"collapsed":true},"cell_type":"code","execution_count":null,"source":"# Helper functions\n\ndef replace_binary(field_value, possible_values):\n    \"\"\" Replace an arbitray two label field with a binary value\n    possible_values: list of values to check against\n    \"\"\"\n    if field_value == possible_values[0]:\n        return 0\n    elif field_value == possible_values[1]:\n        return 1\n    else:\n        raise KeyError\n\ndef plot_ConfusionMatrix(y_test,y_pred, classes,\n                          normalize=False, size=(8,6),\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    # Compute confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    np.set_printoptions(precision=2)\n\n    # Plot non-normalized confusion matrix\n    plt.figure(figsize=size)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","outputs":[]},{"metadata":{"_cell_guid":"f7f82e45-87b8-473b-8325-22cc4a1269e4","_uuid":"1dbc6f015c10a4c6a65bbfb49a15bf6cc2415203"},"cell_type":"markdown","source":"First, lets pre-process the data into usable form. There are many two-label and multi-label features, we'll convert these into binary values using the one-hot method. "},{"metadata":{"_cell_guid":"62f16fb6-7ad5-4b4b-a157-cf3b8f1c18a3","_uuid":"1c0564a8d67c9f50ca1ec1e4bfb03556f008c959","collapsed":true},"cell_type":"code","execution_count":null,"source":"two_label_columns = { 'class': ['e','p'], # Note: This will make edible=0, poisonous=\n                      'bruises': ['f','t'],\n                      'gill-attachment': ['f','a'],\n                      'gill-spacing': ['c','w'],\n                      'gill-size': ['b','n'],\n                      'stalk-shape': ['t','e'],\n                      'veil-type': ['p','n'] }\nmulti_label_columns = ['cap-shape','cap-surface', 'cap-color', 'odor', 'gill-color',\n                       'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring',\n                       'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-color',\n                       'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat' ]\n\n# Expand each multi-label column into n columns, where the column has n possible values.\ndata = pd.get_dummies(raw_data, columns=multi_label_columns)\n\n# Would could also use get_dummies for the two-label columns, but this is a good introduction to\n# using a callable to transform or create new features.\nfor column, values in two_label_columns.items():\n    data[column] = raw_data[column].apply(replace_binary, possible_values=values)\n\n# Show the data now\ndata.head()","outputs":[]},{"metadata":{"_cell_guid":"daeb0394-dad6-45dc-89e5-627b8ad00939","_uuid":"1b4629f798b7c59a5fc46f792a7d6403f78565b5"},"cell_type":"markdown","source":"The best way to explore categorical variable's importance in a  classification is the Chi Squared Test. Essentially, this test compares the expected frequency of a categorical label with the observed frequency. More specifically, the Chi Squared Test of Independence tries to reject the null hypothesis that the two variables are unrelated. \n\nThe test is performed by calculating a test statistic, defined by the equation,  Χ2 = Σ [ (Or,c - Er,c)2 / Er,c ]. Additionally, a p-value is calculated from a distribution table. When a significance level is met, commonly 0.05 or 0.025, the null hypothesis can be rejected. "},{"metadata":{"_cell_guid":"307a157d-6b8d-4945-8508-d066a00a0c01","scrolled":false,"_uuid":"69b4f92dd35f366c174cf09657e8577ebce66ca4","collapsed":true},"cell_type":"code","execution_count":null,"source":"# Create a DataFrame that will house \nchisquare_tests = pd.DataFrame(columns=['Feature','Test Statistic','P-Value'])\n\n# A key assumption of the Chi Square test is that the expected frequency of each\n# category will be great than 5. We perform a test to highlight which categories\n# violate this.\nprint('Variable Frequency Check:')\nfor col in data.columns.drop('class'):\n    ct = pd.crosstab(data[col],data['class'],margins=True)\n    if (ct['All']/2<5).any():\n        print(col,' is too small')\n    else:\n        chi2, p, dof, expted = chi2_contingency(ct)\n        chisquare_tests = chisquare_tests.append(\n            {'Feature':col,\n             'Test Statistic':chi2,\n             'P-Value':p,\n             'DOF':dof }, \n            ignore_index=True )\n\n# Refactor the dataframe\nchisquare_tests = chisquare_tests.set_index('Feature')\nchisquare_tests = chisquare_tests.sort_values(by='P-Value')\n\n# Plot the results in a bar plot\n# \"Confidence Level\" is just 1-pvalue. This is probably made up, but it's easier \n# for non-statistical types to understand\nmax_stat = chisquare_tests['Test Statistic'].max()\nfig = plt.figure(figsize=(8,24))\nax = chisquare_tests['Test Statistic'].plot(kind='barh',color='C1')\nax.set_title('Chi Square Test Results')\nax.set_xlabel('Test Statistic')\nax.set_xlim((0,max_stat+3))\nax.set_ylim((-1,chisquare_tests.shape[0]+0.25))\nplt.text(max_stat+0.5, chisquare_tests.shape[0]-0.5,'Confidence Level')\nfor i in np.arange(chisquare_tests.shape[0]):\n    confidence = (1-chisquare_tests.iloc[i]['P-Value'])\n    plt.text(max_stat+2, i,'{0:0.1%}'.format(confidence))","outputs":[]},{"metadata":{"_cell_guid":"9c3eb081-cedc-4b48-b658-77518dd29627","_uuid":"3c9986e392edd8aa6d9108692394b89b5e5debb0"},"cell_type":"markdown","source":"So we know that a large number of variables have excellent correlation to the mushroom class.  So let's try to fit a model.\n\nBefore we fit a model, we need to set up a way to evaluate the model. This is most simply done with by splitting the data into test and train sets. I use a test set that contains 33% of the original samples.  With over 8000 samples, we can afford to use a larger test group.  If we had less data, or the data wasn't so clear, we could use other methods like Cross Validation.\n\nNext, we'll fit a model. To start with, I'll fit a Random Forest classifier. This is an ensemble method that fits many decision trees, each on a subset of the data, and averages the resulting model. This method is useful because it avoids overfitting by limiting the data the classifiers learn, and often has improved accuracy."},{"metadata":{"_cell_guid":"81352108-27ee-474c-ba36-ef0538ca46c6","_uuid":"1c41ea740db879c542461e7fbb7375190ae39b6a","collapsed":true},"cell_type":"code","execution_count":null,"source":"X_train, X_test, y_train, y_test = train_test_split(data.drop('class',axis=1), \n                                                    data['class'], \n                                                    test_size=0.33, random_state=25)\n\nRFclf = RandomForestClassifier(n_estimators=100,\n                             max_depth=4, \n                             random_state=25)\n\nRFclf.fit(X_train, y_train)\n\nprint('Random Forest Classifier Score on Train Set: {:0.3f}'.format(RFclf.score(X_train, y_train)))\nprint('Random Forest Classifier Score on Test Set: {:0.3f}'.format(RFclf.score(X_test, y_test)))","outputs":[]},{"metadata":{"_cell_guid":"618b2f98-16f0-4795-ba14-b01a901946bf","_uuid":"05d598449d1fa74afec6c9a78179d4e655fb9fdf"},"cell_type":"markdown","source":"The Random Forest classifier is great, but its isn't terribly easy to understand for a layman. Using just one decision tree, as opposed to a forest of trees, the user can take a visual tool into the field to make predictions without a computer. This type of classifier was commonly used to taxonomy before computers were commonplace. "},{"metadata":{"_cell_guid":"05cfbfbc-a99b-475c-975a-851273fef165","_uuid":"0b92fd5628db61241da1d99089c811f830cdbdef","collapsed":true},"cell_type":"code","execution_count":null,"source":"DTclf = DecisionTreeClassifier(max_depth=3,random_state=43)\nDTclf.fit(X_train, y_train)\n\nprint('Decision Tree Classifier Score on Train Set: {:0.3f}'.format(DTclf.score(X_train, y_train)))\nprint('Decision Tree Classifier Score on Test Set: {:0.3f}'.format(DTclf.score(X_test, y_test)))\n\nfeature_names = data.columns.drop('class')\nclass_names = ['Edible','Poisonous']\n\ndot_data = tree.export_graphviz(DTclf, out_file=None, \n                                    feature_names=feature_names,\n                                    class_names=class_names, \n                                    impurity=False,proportion=True)\ngraph = graphviz.Source(dot_data)\n\nDT_y_pred = DTclf.predict(X_test)","outputs":[]},{"metadata":{"_cell_guid":"869adfa3-1f0e-4125-89c0-d613cc215457","_uuid":"48dcf7b8a45804a9b74b6644e06141d2d4952611","collapsed":true},"cell_type":"code","execution_count":null,"source":"graph","outputs":[]},{"metadata":{"_cell_guid":"5ea347c4-d4fc-4dea-b761-ab1f5b9c2320","_uuid":"e47967ecc766a7b1b1f5ccdef6f3e4977e5265b4"},"cell_type":"markdown","source":"Before applying a classifier, or any predictive tool in a production environment, you should understand the consequences of its use. Specifically, you should understand the consequences of incorrect predictions, and their liklihoods. \n\nStatisticians talk about Type I and Type II errors. In layman's terms, these are false positive and false negative predictions. Much like in medicial diagnostics, falsely idenfitying a sample as either positive or negative can have varying consequences. In our case, falsely identyfing a mushroom and poisonous is relatively innocous. The user simply misses out on a tasty snack.  However, incorrectly identifying a mushroom as edible could be fatal. It is imperitive that you understand the liklihood of this before releasing a tool in a production environment.\n\nThe confusion matrix is a common tool for communicating false negative and false positive predictions in a classification problem. Below, we can see that the decision tree classifier has a low false negative rate (falsely identifying as edible), at 3%, but not zero.  Is this acceptable?  The answer likely depends on how many mushrooms are actually poisonous, and their lethality."},{"metadata":{"_cell_guid":"3614ec16-94c7-4edf-840f-410929e9f345","_uuid":"0cbc7bfb6580daf10f10d1b01be67e9bf8635c00","collapsed":true},"cell_type":"code","execution_count":null,"source":"plot_ConfusionMatrix(y_test, DT_y_pred, \n                     class_names,\n                     normalize=True, \n                     title='Mushroom Identification Confusion matrix')","outputs":[]},{"metadata":{"_cell_guid":"81040319-31cf-4f83-8c2c-dd43c5fb5a0d","_uuid":"19a1662a5ba37e289e9351a5a2769c55bb59bc71"},"cell_type":"markdown","source":"While the Decision Tree, and by extension Random Forest, both perform very well, there are some limitations.  Primarily, they only predict a label. There is no indication as to how strongly the sample fits a particular label.  Enter the logistic regression. \n\nThe logistic regression, while technically a regression algorithm, is used as a classifier. In its most simple form, the logistic regression returns a continuous variable calculated using a sigmoid, or logistic function, that represents the probability that the sample belongs to the specified class, or label. This provides the user not only with a prediction, but a probability, or a strength of prediction.  This can be useful, because often times the classifier *feels* strongly about some predictions, but not others. Knowing this, the user can make decisions based on the risk inherent with a specific prediction."},{"metadata":{"_cell_guid":"5f2e6f4e-0530-4f96-bfaa-84c7dc309245","_uuid":"7de4fc365732c49aa3d16dfc32db6918df5f05c2","collapsed":true},"cell_type":"code","execution_count":null,"source":"LRclf = LogisticRegression(C=0.1)\nLRclf.fit(X_train, y_train)\n\nprint('Logistic Regression Score on Train Set: {:0.3f}'.format(LRclf.score(X_train, y_train)))\nprint('Logistic Regression Score on Test Set: {:0.3f}'.format(LRclf.score(X_test, y_test)))","outputs":[]},{"metadata":{"_cell_guid":"d81da9d2-f572-4ba0-8a96-d718604ec7ef","_uuid":"b9efd5b8899bc6de4b7cc5a77302d07a8868f6c5"},"cell_type":"markdown","source":"Clearly, the Logistic Regression can also be very accurate. However, it would be nice to know how accurate a given prediction is. Because this classifier is trained on only a portion of the data available, which is in turn only a portion of the actual population data, its accuracy is actually less than reported. One way to quantify the probabalistic nature of this process is to perform resampling, or bootstrapping. \n\nBootstrapping is a way to show the range in performance of a classifier. By training many models, each on their own set of data, we get an idea of the how much of the classifier's accuracy due to chance. More concretely, we can develop a probability distribution for both the classifier's score, and an individual prediction. This gives this the user a confidence interval around the prediction, so they can, for example, know that a given mushroom has between 70% and 80% chance of being poisonous."},{"metadata":{"_cell_guid":"913503b1-7469-455c-b94e-ad2fcc41c974","_uuid":"91f70852da63b7af27db0e6518a9e2bf1191d8e6","collapsed":true},"cell_type":"code","execution_count":null,"source":"def bootstrap_predict(classifiers, X):\n    \"\"\"\n    Perform a prediction across a population of classifiers\n    Arguments:\n    classifiers - list of classifiers\n    X - DataFrame of samples to predict\n    Returns:\n    List of predictions\n    \"\"\"\n    preds = np.zeros(len(classifiers))\n    for clf,i in zip(classifiers, np.arange(len(classifiers))):\n        # Predict_proba returns probabilities for both classes (sum is 1)\n        # Return the first value, referring to probability of the mushroom being edible\n        pred = clf.predict_proba(X).ravel()[0]\n        preds[i]= pred\n\n    # confidence intervals\n    alpha = 0.95\n    p = ((1.0-alpha)/2.0) * 100\n    lower = max(0.0, np.percentile(preds, p))\n    p = (alpha+((1.0-alpha)/2.0)) * 100\n    upper = min(1.0, np.percentile(preds, p))\n    return preds.mean(), (lower,upper)\n\n\nn_iterations = 1000\nclassifiers = []\nscores = np.zeros(n_iterations)\nfor i in range(n_iterations):\n    # Each iteration selects a new sample set from the data\n    X, y = resample(data.drop('class',axis=1), data['class'], random_state=i)\n    # For model scoring purposes, we still need training and testing sets\n    bsX_train, bsX_test, bsy_train, bsy_test = train_test_split(X, y, test_size=0.33, random_state=i)\n    # Train and test the classifier\n    clf = LogisticRegression(C=0.1)\n    clf.fit(bsX_train, bsy_train)\n    classifiers.append(clf)\n    scores[i] = clf.score(bsX_train, bsy_train)\n    \nprint('Classifiers Average Score: {:0.3f} '.format(scores.mean()))\nprint('Classifiers Score Std Dev: {:0.3f} '.format(np.std(scores)))\n\n# Here's an example of how to predict a value, and provide \npred, CI = bootstrap_predict(classifiers, X.iloc[1].values.reshape(1, -1))\n\nprint('Prediction Expected Value: {:0.3f} '.format(pred))\nprint('Prediction 95% Confidence Interval: ({0:0.3f},{1:0.3f})'.format(CI[0],CI[1]))","outputs":[]},{"metadata":{"_cell_guid":"8334f822-eefd-4c34-bc99-913bf920dd59","_uuid":"e4339f7d9ee12483500c85852f83ecca8a88568f"},"cell_type":"markdown","source":"That was a quick introduction to basic statistical analysis and classification of a categorical dataset. Fortunately, the data lended itself well to classification, and all methods performed extremely well. In many circumstances, this wouldn't be the case and we would have to try other methods. \n\nThanks for reading this far, and please feel free to leave feed back or ask questions.\n\nR"}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","version":"3.6.4","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":1}