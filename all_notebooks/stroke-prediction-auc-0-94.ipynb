{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings  \nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CONTEXT**\n\nAccording to the World Health Organization (WHO) stroke is the 2nd leading cause of death globally, responsible for approximately 11% of total deaths.\nThis dataset is used to predict whether a patient is likely to get stroke based on the input parameters like gender, age, various diseases, and smoking status. Each row in the data provides relavant information about the patient.*","metadata":{}},{"cell_type":"markdown","source":"*A stroke occurs when the blood supply to part of your brain is interrupted or reduced, preventing brain tissue from getting oxygen and nutrients. Brain cells begin to die in minutes*\n*There can be various factors related to occurence to stroke. So using the data given we try to list out the potential factors by using various visualization techniques. *","metadata":{}},{"cell_type":"markdown","source":"**READ DATA**","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CHECK FOR NULL VALUES**","metadata":{}},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*AS WE CAN SEE BMI CONTAINS NULL VALUES AND WE NEED TO FIX THIS*","metadata":{}},{"cell_type":"markdown","source":"***FILLING THE NULL VALUES WITH AVERAGE OF THE BMI'S***","metadata":{}},{"cell_type":"code","source":"avg = data['bmi'].mean()\navg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.bmi=(data.bmi.fillna(28.74))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"FOR ADULTS THE NORMAL BMI RANGE IS BETWEEN 18.5 TO 24.9 FOR ADULTS AND AS WE OBSERVE THAT AVERAGE BMI CALCULTION COMES OUT TO BE MORE THAN NORMAL THAT LARGE PROPROTION OF THE POPULATION IN THE GIVEN DATASET IS OVERWEIGHT","metadata":{}},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SO NOW NO NULL VALUES PRESENT","metadata":{}},{"cell_type":"code","source":"data.info() # THIS FUNCTION LETS US KNOW WHAT DATA TYPE VARIABLE ARE PROVIDED IN THE DATASET","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So from above statistical description of the dataset we can see that mean age of people is around 43 years and mean bmi is more than normal","metadata":{}},{"cell_type":"markdown","source":"WHILE PLOTTING WE NEED TO KEEP IN MIND THAT AGAINST WHICH TYPE OF VARIABLES WE ARE PLOTTING THEN ONLY WE CAN DRAW INSIGHT FROM IT","metadata":{}},{"cell_type":"markdown","source":"**COUNTPLOT TO SEE THE DISTRIBUTION OF WORK_TYPE**","metadata":{}},{"cell_type":"code","source":"sns.countplot(data['work_type'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"THERE ARE LARGE NUMBER OF PEOPLE WHO WORK ON PRIVATE SECTOR ","metadata":{}},{"cell_type":"code","source":"sns.countplot(data['Residence_type'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"THERE ARE ALMOST SAME NUMBER OF PEOPLE LIVING IN BOTH URBAN AND RURAL AREAS","metadata":{}},{"cell_type":"code","source":"sns.countplot(data['smoking_status'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"GOOD TO SEE THAT MOST NUMBER OF PEOPLE NEVER SMOKED AS \"SMOKING KILLS\"","metadata":{}},{"cell_type":"code","source":"sns.countplot(data['stroke'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"THE ABOVE PLOT SHOWS THAT THERE IS **HIGH IMBALANCE** IN THE BOTH THE TARGET CLASSES AN WE NEED TO RESOLVE THIS ISSUE BEFORE APPLYING ANY ALGORITHM","metadata":{}},{"cell_type":"code","source":"sns.countplot(data['ever_married'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min_avg_glucose_level = min(data.avg_glucose_level)\nmax_avg_glucose_level = max(data.avg_glucose_level)\nprint(min_avg_glucose_level)\nprint(max_avg_glucose_level)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"THE ABOVE MINIMUM AND MAXIMUM VALUES OF AVERAGE GLUCOSE LEVEL SHOWS THAT THE COLUMN NEEDS TO BE STANDARDIZED AS THERE IS VERY HIGH DIFFERENCE BETWEEN THEM","metadata":{}},{"cell_type":"code","source":"sns.distplot(data['age'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(data['avg_glucose_level'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**MAPPING OF CATEGORICAL VARIABLES**","metadata":{}},{"cell_type":"code","source":"data['work_type'] = data['work_type'].map({'Private':0, 'Self-employed': 1, 'Govt_job':2, 'children':3, 'Never_worked':4})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['gender'] = data['gender'].map({'Male':0, 'Female':1})\ndata['Residence_type'] = data['Residence_type'].map({'Urban':0, 'Rural':1})\ndata['smoking_status'] = data['smoking_status'].map({'formerly smoked':0, 'never smoked':1, 'smokes':2, 'Unknown':3})\ndata['ever_married'] = data['ever_married'].map({'Yes':0, 'No':1})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"DATASET AFTER MAPPING OF CATEGORICAL VARIABLES","metadata":{}},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CORRELATION HEATMAP** TO CHECK FOR ANY CORRELATION BETWEEN VARIABLES","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16,10))\nsns.heatmap(data.corr(method='pearson'), annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"FROM THE ABOVE FIGURE WE CAN SEE THAT-\nWORK_TYPE AND BMI - NEGATIVE CORRELATION\nSTROKE AND AGE HAS A POSITIVE CORRELATION\nSIMILARLY MANY OTHER VARIABLES HAVE SUCH CORRELATION VALUES WE CANNOT REMOVE ANY VARIABLES. WE HAVE TO CONSIDER ALL THE VARIABLES FOR OUR MODEL","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(x=data['age'], y=data['avg_glucose_level'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"FROM THE ABOVE SCATTER PLOT IT IS QUITE VISIBLE THAT AS THE AGE INCREASE IT LEADS TO INCREASE IN GLUCOSE LEVEL","metadata":{}},{"cell_type":"code","source":"sns.catplot(x='heart_disease',y='age', hue=\"work_type\", kind=\"bar\", data=data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"PEOPLE WHO ARE SELF EMPLOYED ARE THE ONES WHO HAVE HEART DISEASE AND OBVIOUSLY LEAST NUMBERS ARE OF CHILDREN","metadata":{}},{"cell_type":"code","source":"sns.catplot(x='hypertension',y='age', hue=\"work_type\", kind=\"bar\", data=data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x=\"smoking_status\", y=\"stroke\", hue=\"work_type\", kind=\"bar\", data=data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"AGAIN SELF-EMPLOYED PEOPLE HAVE HIGHER RISK OF STROKE. THIS SHOWS THAT THESE PEOPLE ARE MORE VULNERABLE TO DIFFERENT DISEASES AS THEY CARRY LOT OF TENSION OF EARNINGS AND FAMILY INCOME","metadata":{}},{"cell_type":"code","source":"sns.catplot(x=\"hypertension\", y=\"stroke\", hue=\"work_type\", kind=\"bar\", data=data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x=\"Residence_type\", y=\"stroke\", hue=\"work_type\", kind=\"bar\", data=data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"TYPE OF RESIDENCE HARDLY MAKES ANY DIFFERENCE TO DISEASE","metadata":{}},{"cell_type":"code","source":"sns.catplot(x='stroke', y=\"avg_glucose_level\", kind=\"box\", data=data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"PEOPLE HAVING HIGHER GLUCOSE LEVEL ARE AT HIGH RISK OF STROKE","metadata":{}},{"cell_type":"code","source":"sns.catplot(x='stroke', y=\"age\", hue = 'gender', kind=\"box\", data=data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"HIGH AGE FEMALES ARE AT THE RISK TO STROKE","metadata":{}},{"cell_type":"code","source":"sns.catplot(x='stroke', y=\"age\", hue = 'work_type', kind=\"box\", data=data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**APPLY MACHINE LEARNING ALGORITHM FOR PREDICTION**","metadata":{}},{"cell_type":"markdown","source":"DIVIDING THE DATASET INTO FEATURES AND LABELE","metadata":{}},{"cell_type":"code","source":"features = ['id','age',\n 'hypertension',\n 'heart_disease',\n 'ever_married',\n 'Residence_type',\n 'avg_glucose_level',\n 'bmi',\n 'gender',\n 'work_type',\n 'smoking_status']\n\nlabel = ['stroke']\n\nX = data[features]\ny = data[label]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ONCE AGAIN CHECK FOR NULL VALUES IN THE DATASET","metadata":{}},{"cell_type":"code","source":"X.isnull().sum() #WE STILL HAVE 1 NULL VALUE IN THE GENDER COLUMN","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.gender=(X.gender.fillna(1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SINCE THE TARGET CLASS IS HIGHLY IMBALANCED, WE NEED TO TREAT IT AS IT'S PRESENCE WILL LEAD TO POOR PERFORMANCE OF THE MODEL. HERE I HAVE USED SMOTE (Synthetic Minority Oversampling Technique) TECHNIQUE. SMOTE WORKS BY RANDOMNLY PICKING A POINT FROM MINORITY CLASS AND COMPUTING A K-NEAREST NEIGHBOURS FOR THIS POINT.","metadata":{}},{"cell_type":"markdown","source":"**TREATING IMBALANCE CLASS USING SMOTE**","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE()\nx_smote, y_smote = smote.fit_resample(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SPLITTING OF DATASET INTO TRAIN AND TEST","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test, y_train,y_test=train_test_split(x_smote,y_smote,test_size=0.33,random_state=42)\nX_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing = X_test['id'] #taking ID column for the purpose of submission\ntesting","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"AS ID COLUMN DOES NOT AFFETCT THE MODEL'S PERFORMANCE, WE DROP IT","metadata":{}},{"cell_type":"code","source":"X_train = X_train.drop(columns=['id'])\nX_test = X_test.drop(columns=['id'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"STANDARDIZATION OF THE DATA IS REQUIRED AS DATA ARE IN DIFFERENT SCALES","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\n\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"DATA POINTS AFTER STANDARDIZATION:","metadata":{}},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LET'S APPLY **LOGISTIC REGRESSION**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train,y_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_log_reg = log_reg.predict(X_test)\ny_pred_log_reg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CLASSIFICATION REPORT OF LOGISTIC REGRESSION","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import f1_score, roc_auc_score,accuracy_score,confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score, classification_report \nclassification_report = classification_report(y_test, y_pred_log_reg)\nprint(classification_report)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"VALUES OF F1 SCORE SHOWS THAT THE MODEL IS PERFORMING QUITE WELL","metadata":{}},{"cell_type":"code","source":"auc = roc_auc_score(y_test, y_pred_log_reg)\nauc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"AUC SCORE OF AROUND 80% IS QUITE GOOD. MODEL IS ABLE TO CLASSIFY THE CLASSES VERY WELL","metadata":{}},{"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred_log_reg)\ncm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_probab_log = log_reg.predict_proba(X_test)\npredicted_probab_log = predicted_probab_log[:, 1]\nfpr, tpr, _ = roc_curve(y_test, predicted_probab_log)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ROC CURVE**","metadata":{}},{"cell_type":"code","source":"from matplotlib import pyplot\npyplot.plot(fpr, tpr, marker='.', label='Logistic Regression')\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.legend()\npyplot.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LOGISTIC REGRESSION IS PERFORMING WELL, BUT CAN WE IMPROVE PERFORMANCE USING ANOTHER MODEL? LET'S APPLY ANOTHER ALGORITHM","metadata":{}},{"cell_type":"markdown","source":"**RANDOM FOREST**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc_predict = rfc.predict(X_test)\nroc_auc_score(y_test, rfc_predict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"AUC SCORE HAS INCREASED TO **94%**. AMAZING!!","metadata":{}},{"cell_type":"code","source":"cm = confusion_matrix(y_test, rfc_predict)\ncm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CALCULATION OF F1 SCORE","metadata":{}},{"cell_type":"code","source":"tn = cm[0,0]\nfp = cm[0,1]\ntp = cm[1,1]\nfn = cm[1,0]\naccuracy  = (tp + tn) / (tp + fp + tn + fn)\nprecision = tp / (tp + fp)\nrecall    = tp / (tp + fn)\nf1score  = 2 * precision * recall / (precision + recall)\nprint(f1score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_probab = rfc.predict_proba(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_probab = predicted_probab[:, 1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr, tpr, _ = roc_curve(y_test, predicted_probab)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ROC CURVE**","metadata":{}},{"cell_type":"code","source":"from matplotlib import pyplot\npyplot.plot(fpr, tpr, marker='.', color='red', label='Random Forest')\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.legend()\npyplot.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LET'S SEE IF WE CAN IMPROVE IT FURTHER USING ANOTHER MODEL","metadata":{}},{"cell_type":"markdown","source":"**XGBOOST CLASSIFIER**","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = xgb.XGBClassifier()\nmodel.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred1 = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_auc_score(y_test, y_pred1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"WOW!! AUC SCORE INCREASED","metadata":{}},{"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred1)\ncm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tn = cm[0,0]\nfp = cm[0,1]\ntp = cm[1,1]\nfn = cm[1,0]\naccuracy  = (tp + tn) / (tp + fp + tn + fn)\nprecision = tp / (tp + fp)\nrecall    = tp / (tp + fn)\nf1score  = 2 * precision * recall / (precision + recall)\nprint(f1score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"AMAZING F1 SCORE","metadata":{}},{"cell_type":"code","source":"predicted_probab = model.predict_proba(X_test)\npredicted_probab = predicted_probab[:, 1]\nfpr, tpr, _ = roc_curve(y_test, predicted_probab)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ROC CURVE**","metadata":{}},{"cell_type":"code","source":"from matplotlib import pyplot\npyplot.plot(fpr, tpr, marker='.', color='green',label='XGB Classifier')\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.legend()\npyplot.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmy_submission = pd.DataFrame({'Id': testing, 'Stroke': y_pred1})\nmy_submission.to_csv('submission.csv', index=False)\nmy_submission = pd.read_csv('submission.csv')\nmy_submission\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LET'S FIND OUT THE BEST PARAMETERS**","metadata":{}},{"cell_type":"code","source":"params = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5]\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb = xgb.XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n                    silent=True, nthread=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**APPLYING GRID SEARCH**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfolds = 5\nparam_comb = 5\n\nskf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n\nrandom_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4,  verbose=3, random_state=1001 )\nrandom_search.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('\\n All results:')\nprint(random_search.cv_results_)\nprint('\\n Best estimator:')\nprint(random_search.best_estimator_)\nprint('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\nprint(random_search.best_score_ * 2 - 1)\nprint('\\n Best hyperparameters:')\nprint(random_search.best_params_)\nresults = pd.DataFrame(random_search.cv_results_)\nresults.to_csv('xgb-random-grid-search-results-01.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CONCLUSION**","metadata":{}},{"cell_type":"markdown","source":"IN THE GIVEN DATASET WE FIRT APPLIED GENERAL PREPROCESSING TO REMOVE/IMPUTE MISSING VALUES. STANDARDIZATION WAS IMPORTANT AS INDEPENDENT FEATURES WERE IN DIFFERENT SCALES.\nWE MUST MAKE SURE THAT RARGET CLASS IS NOT IMBALANCED AND IF IT IS SO THEN WE MUST HANDLE IT USING APPROPRIATE TECHNIQUE.\nAMONG THREE MODELS APPLIED, XGBOOST WAS FOUND TO BE THE MOST SUCCESSFUL WITH F1 SCORE OF AROUND 95%. IN SUCH TYPE OF DATASET LIKE THIS WHERE THERE IS HIGH CLASS IMBALANCE ACCURACY METRIC SHOULD NOT BE RELIED ON. WE MUST SEE CONFUSION MATRIX FOR CLEAR INSIGHT OF HOW THE MODEL IS PERFORMING.\n","metadata":{}},{"cell_type":"markdown","source":"IF YOU FIND THIS NOTEBOOK USEFUL THEN PLEASE UPVOTE!!\n\n\n\nTHANK YOU..","metadata":{}}]}