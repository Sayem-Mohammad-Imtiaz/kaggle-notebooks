{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![CF](https://dataconomy.com/wp-content/uploads/2015/03/Beginners-Guide-Recommender-Systems-Collaborative-Filtering-620x340.jpg)\n\n## **Collaborative Filtering**\n+ **predicting** what **users** will **like** based on their **similarity to other users.**\n+ **Advantages:** capable of accurately recommending complex items such as movies without requiring an “understanding” of the item itself. \n+ many  have been used in measuring (**user similarity** or **item similarity**) in **recommender systems.** \n+ **Task 1**: finding similar animes\n+ **Task 2**: finding similar users\n+ **Task 3**: Recommending Animes for a random user","metadata":{}},{"cell_type":"code","source":"INPUT_DIR = '/kaggle/input/anime-recommendation-database-2020'\n!ls {INPUT_DIR}","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-06-09T14:33:16.024951Z","iopub.execute_input":"2021-06-09T14:33:16.025455Z","iopub.status.idle":"2021-06-09T14:33:16.787008Z","shell.execute_reply.started":"2021-06-09T14:33:16.025346Z","shell.execute_reply":"2021-06-09T14:33:16.785677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nrating_df = pd.read_csv(INPUT_DIR + '/animelist.csv', \n                        low_memory=False, \n                        usecols=[\"user_id\", \"anime_id\", \"rating\"]\n                        #, nrows=90000000\n                        )\nrating_df.head(4)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:33:17.925684Z","iopub.execute_input":"2021-06-09T14:33:17.926061Z","iopub.status.idle":"2021-06-09T14:34:30.280593Z","shell.execute_reply.started":"2021-06-09T14:33:17.926012Z","shell.execute_reply":"2021-06-09T14:34:30.279373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# User should rate atleast 400 animies\nn_ratings = rating_df['user_id'].value_counts()\nrating_df = rating_df[rating_df['user_id'].isin(n_ratings[n_ratings >= 400].index)].copy()\nlen(rating_df)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:37:33.013972Z","iopub.execute_input":"2021-06-09T14:37:33.014404Z","iopub.status.idle":"2021-06-09T14:37:38.327015Z","shell.execute_reply.started":"2021-06-09T14:37:33.014359Z","shell.execute_reply":"2021-06-09T14:37:38.32561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scaling BTW (0 , 1.0)\nmin_rating = min(rating_df['rating'])\nmax_rating = max(rating_df['rating'])\nrating_df['rating'] = rating_df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values.astype(np.float64)\n\nAvgRating = np.mean(rating_df['rating'])\nprint('Avg', AvgRating)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:37:38.328479Z","iopub.execute_input":"2021-06-09T14:37:38.328786Z","iopub.status.idle":"2021-06-09T14:38:37.105388Z","shell.execute_reply.started":"2021-06-09T14:37:38.328758Z","shell.execute_reply":"2021-06-09T14:38:37.104282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing Duplicated Rows\nduplicates = rating_df.duplicated()\n\nif duplicates.sum() > 0:\n    print('> {} duplicates'.format(duplicates.sum()))\n    rating_df = rating_df[~duplicates]\n\nprint('> {} duplicates'.format(rating_df.duplicated().sum()))","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:38:37.107243Z","iopub.execute_input":"2021-06-09T14:38:37.107555Z","iopub.status.idle":"2021-06-09T14:39:31.745007Z","shell.execute_reply.started":"2021-06-09T14:38:37.107526Z","shell.execute_reply":"2021-06-09T14:39:31.743908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://content.codecademy.com/programs/code-foundations-path/ds-survey/utilitymatrix.gif)","metadata":{}},{"cell_type":"code","source":"g = rating_df.groupby('user_id')['rating'].count()\ntop_users = g.dropna().sort_values(ascending=False)[:20]\ntop_r = rating_df.join(top_users, rsuffix='_r', how='inner', on='user_id')\n\ng = rating_df.groupby('anime_id')['rating'].count()\ntop_animes = g.dropna().sort_values(ascending=False)[:20]\ntop_r = top_r.join(top_animes, rsuffix='_r', how='inner', on='anime_id')\n\npd.crosstab(top_r.user_id, top_r.anime_id, top_r.rating, aggfunc=np.sum)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-06-09T14:39:31.746518Z","iopub.execute_input":"2021-06-09T14:39:31.746816Z","iopub.status.idle":"2021-06-09T14:39:38.551304Z","shell.execute_reply.started":"2021-06-09T14:39:31.746788Z","shell.execute_reply":"2021-06-09T14:39:38.550151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"# Encoding categorical data\nuser_ids = rating_df[\"user_id\"].unique().tolist()\nuser2user_encoded = {x: i for i, x in enumerate(user_ids)}\nuser_encoded2user = {i: x for i, x in enumerate(user_ids)}\nrating_df[\"user\"] = rating_df[\"user_id\"].map(user2user_encoded)\nn_users = len(user2user_encoded)\n\nanime_ids = rating_df[\"anime_id\"].unique().tolist()\nanime2anime_encoded = {x: i for i, x in enumerate(anime_ids)}\nanime_encoded2anime = {i: x for i, x in enumerate(anime_ids)}\nrating_df[\"anime\"] = rating_df[\"anime_id\"].map(anime2anime_encoded)\nn_animes = len(anime2anime_encoded)\n\nprint(\"Num of users: {}, Num of animes: {}\".format(n_users, n_animes))\nprint(\"Min rating: {}, Max rating: {}\".format(min(rating_df['rating']), max(rating_df['rating'])))","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:39:38.552959Z","iopub.execute_input":"2021-06-09T14:39:38.553403Z","iopub.status.idle":"2021-06-09T14:40:00.365331Z","shell.execute_reply.started":"2021-06-09T14:39:38.553358Z","shell.execute_reply":"2021-06-09T14:40:00.364627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shuffle\nrating_df = rating_df.sample(frac=1, random_state=73)\n\nX = rating_df[['user', 'anime']].values\ny = rating_df[\"rating\"]","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:40:00.366239Z","iopub.execute_input":"2021-06-09T14:40:00.36649Z","iopub.status.idle":"2021-06-09T14:40:20.044753Z","shell.execute_reply.started":"2021-06-09T14:40:00.366466Z","shell.execute_reply":"2021-06-09T14:40:20.04378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split\ntest_set_size = 10000 #10k for test set\ntrain_indices = rating_df.shape[0] - test_set_size \n\nX_train, X_test, y_train, y_test = (\n    X[:train_indices],\n    X[train_indices:],\n    y[:train_indices],\n    y[train_indices:],\n)\n\nprint('> Train set ratings: {}'.format(len(y_train)))\nprint('> Test set ratings: {}'.format(len(y_test)))","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:40:20.045934Z","iopub.execute_input":"2021-06-09T14:40:20.046372Z","iopub.status.idle":"2021-06-09T14:40:20.054189Z","shell.execute_reply.started":"2021-06-09T14:40:20.04634Z","shell.execute_reply":"2021-06-09T14:40:20.053129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_array = [X_train[:, 0], X_train[:, 1]]\nX_test_array = [X_test[:, 0], X_test[:, 1]]","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:40:20.056934Z","iopub.execute_input":"2021-06-09T14:40:20.057302Z","iopub.status.idle":"2021-06-09T14:40:20.067644Z","shell.execute_reply.started":"2021-06-09T14:40:20.057265Z","shell.execute_reply":"2021-06-09T14:40:20.066507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accelerator check\nimport tensorflow as tf\n\nTPU_INIT = True\n\nif TPU_INIT:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    !nvidia-smi\n    \nprint(tf.__version__)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-06-09T14:40:20.069809Z","iopub.execute_input":"2021-06-09T14:40:20.070216Z","iopub.status.idle":"2021-06-09T14:40:32.035482Z","shell.execute_reply.started":"2021-06-09T14:40:20.070181Z","shell.execute_reply":"2021-06-09T14:40:32.034392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Model Building**","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras import layers \nimport tensorflow as tf\nfrom keras.models import Model\nfrom keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:40:32.037002Z","iopub.execute_input":"2021-06-09T14:40:32.037461Z","iopub.status.idle":"2021-06-09T14:40:32.106799Z","shell.execute_reply.started":"2021-06-09T14:40:32.037425Z","shell.execute_reply":"2021-06-09T14:40:32.105813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Embedding layers\nfrom keras.layers import Add, Activation, Lambda, BatchNormalization, Concatenate, Dropout, Input, Embedding, Dot, Reshape, Dense, Flatten\n\ndef RecommenderNet():\n    embedding_size = 128\n    \n    user = Input(name = 'user', shape = [1])\n    user_embedding = Embedding(name = 'user_embedding',\n                       input_dim = n_users, \n                       output_dim = embedding_size)(user)\n    \n    anime = Input(name = 'anime', shape = [1])\n    anime_embedding = Embedding(name = 'anime_embedding',\n                       input_dim = n_animes, \n                       output_dim = embedding_size)(anime)\n    \n    #x = Concatenate()([user_embedding, anime_embedding])\n    x = Dot(name = 'dot_product', normalize = True, axes = 2)([user_embedding, anime_embedding])\n    x = Flatten()(x)\n        \n    x = Dense(1, kernel_initializer='he_normal')(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"sigmoid\")(x)\n    \n    model = Model(inputs=[user, anime], outputs=x)\n    model.compile(loss='binary_crossentropy', metrics=[\"mae\", \"mse\"], optimizer='Adam')\n    \n    return model\n\nif TPU_INIT:    \n    with tpu_strategy.scope():\n        model = RecommenderNet()\nelse:\n    model = RecommenderNet()\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:40:32.108487Z","iopub.execute_input":"2021-06-09T14:40:32.108921Z","iopub.status.idle":"2021-06-09T14:40:32.745548Z","shell.execute_reply.started":"2021-06-09T14:40:32.108876Z","shell.execute_reply":"2021-06-09T14:40:32.744008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Callbacks\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, ReduceLROnPlateau\n\nstart_lr = 0.00001\nmin_lr = 0.00001\nmax_lr = 0.00005\nbatch_size = 10000\n\nif TPU_INIT:\n    max_lr = max_lr * tpu_strategy.num_replicas_in_sync\n    batch_size = batch_size * tpu_strategy.num_replicas_in_sync\n\nrampup_epochs = 5\nsustain_epochs = 0\nexp_decay = .8\n\ndef lrfn(epoch):\n    if epoch < rampup_epochs:\n        return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n    elif epoch < rampup_epochs + sustain_epochs:\n        return max_lr\n    else:\n        return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n\n\nlr_callback = LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=0)\n\ncheckpoint_filepath = './weights.h5'\n\nmodel_checkpoints = ModelCheckpoint(filepath=checkpoint_filepath,\n                                        save_weights_only=True,\n                                        monitor='val_loss',\n                                        mode='min',\n                                        save_best_only=True)\n\nearly_stopping = EarlyStopping(patience = 3, monitor='val_loss', \n                               mode='min', restore_best_weights=True)\n\nmy_callbacks = [\n    model_checkpoints,\n    lr_callback,\n    early_stopping,   \n]","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:40:32.747009Z","iopub.execute_input":"2021-06-09T14:40:32.747341Z","iopub.status.idle":"2021-06-09T14:40:32.75646Z","shell.execute_reply.started":"2021-06-09T14:40:32.74731Z","shell.execute_reply":"2021-06-09T14:40:32.755606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model training\nhistory = model.fit(\n    x=X_train_array,\n    y=y_train,\n    batch_size=batch_size,\n    epochs=20,\n    verbose=1,\n    validation_data=(X_test_array, y_test),\n    callbacks=my_callbacks\n)\n\nmodel.load_weights(checkpoint_filepath)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:40:32.757573Z","iopub.execute_input":"2021-06-09T14:40:32.757983Z","iopub.status.idle":"2021-06-09T14:45:09.914501Z","shell.execute_reply.started":"2021-06-09T14:40:32.757953Z","shell.execute_reply":"2021-06-09T14:45:09.912667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training results\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.plot(history.history[\"loss\"][0:-2])\nplt.plot(history.history[\"val_loss\"][0:-2])\nplt.title(\"model loss\")\nplt.ylabel(\"loss\")\nplt.xlabel(\"epoch\")\nplt.legend([\"train\", \"test\"], loc=\"upper left\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:09.91748Z","iopub.execute_input":"2021-06-09T14:45:09.918023Z","iopub.status.idle":"2021-06-09T14:45:10.165314Z","shell.execute_reply.started":"2021-06-09T14:45:09.917971Z","shell.execute_reply":"2021-06-09T14:45:10.163989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Extracting weights from model**","metadata":{}},{"cell_type":"code","source":"def extract_weights(name, model):\n    weight_layer = model.get_layer(name)\n    weights = weight_layer.get_weights()[0]\n    weights = weights / np.linalg.norm(weights, axis = 1).reshape((-1, 1))\n    return weights\n\nanime_weights = extract_weights('anime_embedding', model)\nuser_weights = extract_weights('user_embedding', model)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:10.166954Z","iopub.execute_input":"2021-06-09T14:45:10.167454Z","iopub.status.idle":"2021-06-09T14:45:10.390657Z","shell.execute_reply.started":"2021-06-09T14:45:10.167395Z","shell.execute_reply":"2021-06-09T14:45:10.389505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **anime meta data**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(INPUT_DIR + '/anime.csv', low_memory=True)\ndf = df.replace(\"Unknown\", np.nan)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:10.392006Z","iopub.execute_input":"2021-06-09T14:45:10.392316Z","iopub.status.idle":"2021-06-09T14:45:10.752531Z","shell.execute_reply.started":"2021-06-09T14:45:10.392288Z","shell.execute_reply":"2021-06-09T14:45:10.751347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fixing Names\ndef getAnimeName(anime_id):\n    try:\n        name = df[df.anime_id == anime_id].eng_version.values[0]\n        if name is np.nan:\n            name = df[df.anime_id == anime_id].Name.values[0]\n    except:\n        print('error')\n    \n    return name\n\ndf['anime_id'] = df['MAL_ID']\ndf[\"eng_version\"] = df['English name']\ndf['eng_version'] = df.anime_id.apply(lambda x: getAnimeName(x))\n\ndf.sort_values(by=['Score'], \n               inplace=True,\n               ascending=False, \n               kind='quicksort',\n               na_position='last')\n\ndf = df[[\"anime_id\", \"eng_version\", \n         \"Score\", \"Genders\", \"Episodes\", \n         \"Type\", \"Premiered\", \"Members\"]]","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:10.753845Z","iopub.execute_input":"2021-06-09T14:45:10.754187Z","iopub.status.idle":"2021-06-09T14:45:34.743405Z","shell.execute_reply.started":"2021-06-09T14:45:10.754154Z","shell.execute_reply":"2021-06-09T14:45:34.742472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getAnimeFrame(anime):\n    if isinstance(anime, int):\n        return df[df.anime_id == anime]\n    if isinstance(anime, str):\n        return df[df.eng_version == anime]","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:34.74459Z","iopub.execute_input":"2021-06-09T14:45:34.745027Z","iopub.status.idle":"2021-06-09T14:45:34.749121Z","shell.execute_reply.started":"2021-06-09T14:45:34.744979Z","shell.execute_reply":"2021-06-09T14:45:34.748315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **sypnopsis data**","metadata":{}},{"cell_type":"code","source":"cols = [\"MAL_ID\", \"Name\", \"Genders\", \"sypnopsis\"]\nsypnopsis_df = pd.read_csv(INPUT_DIR + '/anime_with_synopsis.csv', usecols=cols)\n\ndef getSypnopsis(anime):\n    if isinstance(anime, int):\n        return sypnopsis_df[sypnopsis_df.MAL_ID == anime].sypnopsis.values[0]\n    if isinstance(anime, str):\n        return sypnopsis_df[sypnopsis_df.Name == anime].sypnopsis.values[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:34.750193Z","iopub.execute_input":"2021-06-09T14:45:34.750599Z","iopub.status.idle":"2021-06-09T14:45:34.99203Z","shell.execute_reply.started":"2021-06-09T14:45:34.75056Z","shell.execute_reply":"2021-06-09T14:45:34.991003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Task 1**: Finding Similar Animes (Item Based Recommendation)","metadata":{}},{"cell_type":"code","source":"#pd.reset_option('all')\npd.set_option(\"max_colwidth\", None)\n\ndef find_similar_animes(name, n=10, return_dist=False, neg=False):\n    try:\n        index = getAnimeFrame(name).anime_id.values[0]\n        encoded_index = anime2anime_encoded.get(index)\n        weights = anime_weights\n        \n        dists = np.dot(weights, weights[encoded_index])\n        sorted_dists = np.argsort(dists)\n        \n        n = n + 1            \n        \n        if neg:\n            closest = sorted_dists[:n]\n        else:\n            closest = sorted_dists[-n:]\n\n        print('animes closest to {}'.format(name))\n\n        if return_dist:\n            return dists, closest\n        \n        rindex = df\n\n        SimilarityArr = []\n\n        for close in closest:\n            decoded_id = anime_encoded2anime.get(close)\n            sypnopsis = getSypnopsis(decoded_id)\n            anime_frame = getAnimeFrame(decoded_id)\n            \n            anime_name = anime_frame.eng_version.values[0]\n            genre = anime_frame.Genders.values[0]\n            similarity = dists[close]\n            SimilarityArr.append({\"anime_id\": decoded_id, \"name\": anime_name,\n                                  \"similarity\": similarity,\"genre\": genre,\n                                  'sypnopsis': sypnopsis})\n\n        Frame = pd.DataFrame(SimilarityArr).sort_values(by=\"similarity\", ascending=False)\n        return Frame[Frame.anime_id != index].drop(['anime_id'], axis=1)\n\n    except:\n        print('{}!, Not Found in Anime list'.format(name))","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:34.993283Z","iopub.execute_input":"2021-06-09T14:45:34.993568Z","iopub.status.idle":"2021-06-09T14:45:35.004488Z","shell.execute_reply.started":"2021-06-09T14:45:34.99354Z","shell.execute_reply":"2021-06-09T14:45:35.0037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **these animes are my fav**","metadata":{}},{"cell_type":"markdown","source":"![](https://i.pinimg.com/originals/1f/cb/2a/1fcb2af4376fe78b6d82197bd1fdbff6.gif)","metadata":{}},{"cell_type":"code","source":"find_similar_animes('Dragon Ball Z', n=5, neg=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:35.005606Z","iopub.execute_input":"2021-06-09T14:45:35.006067Z","iopub.status.idle":"2021-06-09T14:45:35.080137Z","shell.execute_reply.started":"2021-06-09T14:45:35.006004Z","shell.execute_reply":"2021-06-09T14:45:35.077091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://64.media.tumblr.com/1b942774dc6d4240cfbb3da22d99a681/tumblr_phsucvmeDT1sivxmj_500.gifv)","metadata":{}},{"cell_type":"code","source":"find_similar_animes('Your Name.', n=5, neg=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:35.082147Z","iopub.execute_input":"2021-06-09T14:45:35.082609Z","iopub.status.idle":"2021-06-09T14:45:35.143541Z","shell.execute_reply.started":"2021-06-09T14:45:35.082565Z","shell.execute_reply":"2021-06-09T14:45:35.142269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://i.pinimg.com/originals/26/fd/49/26fd49fa54b204fbaf6301efefd53ae2.gif)","metadata":{}},{"cell_type":"code","source":"find_similar_animes('Sword Art Online', n=5, neg=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:35.148852Z","iopub.execute_input":"2021-06-09T14:45:35.150077Z","iopub.status.idle":"2021-06-09T14:45:35.206671Z","shell.execute_reply.started":"2021-06-09T14:45:35.149998Z","shell.execute_reply":"2021-06-09T14:45:35.205523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://steamuserimages-a.akamaihd.net/ugc/993512070845192516/C18040A95DB14DD58438DDDEBF721BA8ABAD0E84/)","metadata":{}},{"cell_type":"code","source":"find_similar_animes('Black Clover', n=5, neg=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T14:45:35.209165Z","iopub.execute_input":"2021-06-09T14:45:35.209978Z","iopub.status.idle":"2021-06-09T14:45:35.266695Z","shell.execute_reply.started":"2021-06-09T14:45:35.209922Z","shell.execute_reply":"2021-06-09T14:45:35.265555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Task 2**: Finding Similar Users (User Based Recommendation)","metadata":{}},{"cell_type":"code","source":"print('> picking up random user')\n\nratings_per_user = rating_df.groupby('user_id').size()\nrandom_user = ratings_per_user[ratings_per_user < 500].sample(1, random_state=None).index[0]\nprint('> user_id:', random_user)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:49:18.916993Z","iopub.execute_input":"2021-06-09T15:49:18.917356Z","iopub.status.idle":"2021-06-09T15:49:23.646178Z","shell.execute_reply.started":"2021-06-09T15:49:18.917327Z","shell.execute_reply":"2021-06-09T15:49:23.645217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pd.reset_option('all')\npd.set_option(\"max_colwidth\", None)\n\ndef find_similar_users(item_input, n=10,return_dist=False, neg=False):\n    try:\n        index = item_input\n        encoded_index = user2user_encoded.get(index)\n        weights = user_weights\n    \n        dists = np.dot(weights, weights[encoded_index])\n        sorted_dists = np.argsort(dists)\n        \n        n = n + 1\n        \n        if neg:\n            closest = sorted_dists[:n]\n        else:\n            closest = sorted_dists[-n:]\n\n        print('> users similar to #{}'.format(item_input))\n\n        if return_dist:\n            return dists, closest\n        \n        rindex = df\n        SimilarityArr = []\n        \n        for close in closest:\n            similarity = dists[close]\n\n            if isinstance(item_input, int):\n                decoded_id = user_encoded2user.get(close)\n                SimilarityArr.append({\"similar_users\": decoded_id, \n                                      \"similarity\": similarity})\n\n        Frame = pd.DataFrame(SimilarityArr).sort_values(by=\"similarity\", \n                                                        ascending=False)\n        \n        return Frame\n    \n    except:\n        print('{}!, Not Found in User list'.format(name))","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:49:23.647374Z","iopub.execute_input":"2021-06-09T15:49:23.647648Z","iopub.status.idle":"2021-06-09T15:49:23.657965Z","shell.execute_reply.started":"2021-06-09T15:49:23.647622Z","shell.execute_reply":"2021-06-09T15:49:23.656792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similar_users = find_similar_users(int(random_user), \n                                   n=5, \n                                   neg=False)\n\nsimilar_users = similar_users[similar_users.similarity > 0.4]\nsimilar_users = similar_users[similar_users.similar_users != random_user]\nsimilar_users.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:50:36.353618Z","iopub.execute_input":"2021-06-09T15:50:36.354199Z","iopub.status.idle":"2021-06-09T15:50:36.394436Z","shell.execute_reply.started":"2021-06-09T15:50:36.354154Z","shell.execute_reply":"2021-06-09T15:50:36.393191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **User preferences**","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\n\ndef showWordCloud(all_genres):\n    genres_cloud = WordCloud(width=700, height=400, \n                             background_color='white', \n                             colormap='gnuplot').generate_from_frequencies(all_genres)\n    \n    plt.figure(figsize=(10,8)) \n    plt.imshow(genres_cloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.show()\n\ndef getFavGenre(frame, plot=False):\n        frame.dropna(inplace=False)\n        all_genres = defaultdict(int)\n        \n        genres_list = []\n        for genres in frame['Genders']:\n            if isinstance(genres, str):\n                for genre in genres.split(','):\n                    genres_list.append(genre)\n                    all_genres[genre.strip()] += 1    \n        if plot:\n            showWordCloud(all_genres)\n        \n        return genres_list\n\n    \ndef get_user_preferences(user_id, plot=False, verbose=0):\n    animes_watched_by_user = rating_df[rating_df.user_id==user_id]\n    user_rating_percentile = np.percentile(animes_watched_by_user.rating, 75)\n    animes_watched_by_user = animes_watched_by_user[animes_watched_by_user.rating >= user_rating_percentile]\n    top_animes_user = (\n        animes_watched_by_user.sort_values(by=\"rating\", ascending=False)#.head(10)\n        .anime_id.values\n    )\n    \n    anime_df_rows = df[df[\"anime_id\"].isin(top_animes_user)]\n    anime_df_rows = anime_df_rows[[\"eng_version\", \"Genders\"]]\n    \n    if verbose != 0:\n        print(\"> User #{} has rated {} movies (avg. rating = {:.1f})\".format(\n          user_id, len(animes_watched_by_user),\n          animes_watched_by_user['rating'].mean(),\n        ))\n    \n        print('> preferred genres')\n    \n    if plot:\n        getFavGenre(anime_df_rows, plot)\n        \n    return anime_df_rows#.eng_version.values","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:50:36.871718Z","iopub.execute_input":"2021-06-09T15:50:36.872137Z","iopub.status.idle":"2021-06-09T15:50:36.885082Z","shell.execute_reply.started":"2021-06-09T15:50:36.8721Z","shell.execute_reply":"2021-06-09T15:50:36.883742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_pref = get_user_preferences(random_user, plot=True, verbose=1)\nprint('> animes highly rated by this user')\n\npd.DataFrame(user_pref).head(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:50:37.18079Z","iopub.execute_input":"2021-06-09T15:50:37.181191Z","iopub.status.idle":"2021-06-09T15:50:37.708662Z","shell.execute_reply.started":"2021-06-09T15:50:37.181156Z","shell.execute_reply":"2021-06-09T15:50:37.707884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Task 3**: **Recommending** animes for a user","metadata":{}},{"cell_type":"code","source":"def get_recommended_animes(similar_users, n=10):\n    recommended_animes = []\n    anime_list = []\n    \n    for user_id in similar_users.similar_users.values:\n        pref_list = get_user_preferences(int(user_id), verbose=0)\n        pref_list = pref_list[~ pref_list.eng_version.isin(user_pref.eng_version.values)]\n        anime_list.append(pref_list.eng_version.values)\n        \n    anime_list = pd.DataFrame(anime_list)\n    sorted_list = pd.DataFrame(pd.Series(anime_list.values.ravel()).value_counts()).head(n)\n    \n    for i, anime_name in enumerate(sorted_list.index):        \n        n_user_pref = sorted_list[sorted_list.index == anime_name].values[0][0]\n        if isinstance(anime_name, str):\n            try:\n                frame = getAnimeFrame(anime_name)\n                anime_id = frame.anime_id.values[0]\n                genre = frame.Genders.values[0]\n                sypnopsis = getSypnopsis(int(anime_id))\n                recommended_animes.append({#\"anime_id\": anime_id ,\n                                            \"n\": n_user_pref,\n                                            \"anime_name\": anime_name, \n                                            \"Genders\": genre, \n                                            \"sypnopsis\": sypnopsis})\n            except:\n                pass\n    \n    return pd.DataFrame(recommended_animes)","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:50:38.213889Z","iopub.execute_input":"2021-06-09T15:50:38.214384Z","iopub.status.idle":"2021-06-09T15:50:38.223357Z","shell.execute_reply.started":"2021-06-09T15:50:38.214352Z","shell.execute_reply":"2021-06-09T15:50:38.222307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recommended_animes = get_recommended_animes(similar_users, n=10)\ngetFavGenre(recommended_animes, plot=True)\n\nprint('\\n> Top recommendations for user: {}'.format(random_user))\nrecommended_animes","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:50:38.505931Z","iopub.execute_input":"2021-06-09T15:50:38.506335Z","iopub.status.idle":"2021-06-09T15:50:39.407943Z","shell.execute_reply.started":"2021-06-09T15:50:38.506306Z","shell.execute_reply":"2021-06-09T15:50:39.406883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Ranking based Recommendation**","metadata":{}},{"cell_type":"code","source":"print(\"Showing recommendations for user: {}\".format(random_user))\nprint(\"===\" * 25)\n\nanimes_watched_by_user = rating_df[rating_df.user_id==random_user]\nanime_not_watched_df = df[\n    ~df[\"anime_id\"].isin(animes_watched_by_user.anime_id.values)\n]\n\nanime_not_watched = list(\n    set(anime_not_watched_df['anime_id']).intersection(set(anime2anime_encoded.keys()))\n)\n\nanime_not_watched = [[anime2anime_encoded.get(x)] for x in anime_not_watched]\n\nuser_encoder = user2user_encoded.get(random_user)\n\nuser_anime_array = np.hstack(\n    ([[user_encoder]] * len(anime_not_watched), anime_not_watched)\n)\n\nuser_anime_array = [user_anime_array[:, 0], user_anime_array[:, 1]]\nratings = model.predict(user_anime_array).flatten()\n\ntop_ratings_indices = (-ratings).argsort()[:10]\n\nrecommended_anime_ids = [\n    anime_encoded2anime.get(anime_not_watched[x][0]) for x in top_ratings_indices\n]\n\nResults = []\ntop_rated_ids = []\n\nfor index, anime_id in enumerate(anime_not_watched):\n    rating = ratings[index]\n    id_ = anime_encoded2anime.get(anime_id[0])\n    \n    if id_ in recommended_anime_ids:\n        top_rated_ids.append(id_)\n        try:\n            condition = (df.anime_id == id_)\n            name = df[condition]['eng_version'].values[0]\n            genre = df[condition].Genders.values[0]\n            score = df[condition].Score.values[0]\n            sypnopsis = getSypnopsis(int(id_))\n        except:\n            continue\n            \n        Results.append({#\"anime_id\": id_, \n                        \"name\": name, \n                        \"pred_rating\": rating,\n                        \"genre\": genre, \n                        'sypnopsis': sypnopsis})\n\nprint(\"---\" * 25)\nprint(\"> Top 10 anime recommendations\")\nprint(\"---\" * 25)\n\n\nResults = pd.DataFrame(Results).sort_values(by='pred_rating', ascending=False)\nResults","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:50:39.409531Z","iopub.execute_input":"2021-06-09T15:50:39.409825Z","iopub.status.idle":"2021-06-09T15:50:42.396905Z","shell.execute_reply.started":"2021-06-09T15:50:39.409798Z","shell.execute_reply":"2021-06-09T15:50:42.395628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('anime_model.h5')\n\nfrom IPython.display import FileLink\nFileLink(r'./anime_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-06-09T15:50:42.398491Z","iopub.execute_input":"2021-06-09T15:50:42.398771Z","iopub.status.idle":"2021-06-09T15:50:43.317804Z","shell.execute_reply.started":"2021-06-09T15:50:42.398745Z","shell.execute_reply":"2021-06-09T15:50:43.316618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}