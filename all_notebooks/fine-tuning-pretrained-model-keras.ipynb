{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Problem Statement","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Build an image tagging Deep Learning model that can help the company classify these images into eight categories of Indian classical dance.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing Required Libraries[](http://)","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nimport os\nimport random\nfrom shutil import copyfile","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading the train and test directory containing images and csv files containing images names and labels","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '/kaggle/input/train/'\ntest_dir = '/kaggle/input/test/'\ntrain_csv = pd.read_csv(r'/kaggle/input/train.csv')\ntest_csv = pd.read_csv(r'/kaggle/input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing Data for training","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Making the required directories for flow_from_directory command\n\nMaking source directory with 8 sub categories named as the 8 dance forms given in the train.csv file to keep all the images present in the train directory provided for the competition\n\nSimilarly, Making training directory with 8 sub categories named as the 8 dance forms given in the train.csv file to keep the images used for training after the splitting of train and validation images\n\nSimilarly, Making testing directory with 8 sub categories named as the 8 dance forms given in the train.csv file to keep the images used for validation after the splitting of train and validation images\n\nMaking tests directory with sub directory unknown to contain test directory images for predict_generator","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir(r'/kaggle/working/identify-dance-form')\nos.mkdir(r'/kaggle/working/identify-dance-form/training')\nos.mkdir(r'/kaggle/working/identify-dance-form/testing')\nos.mkdir(r'/kaggle/working/identify-dance-form/source')\nos.mkdir(r'/kaggle/working/identify-dance-form/training/manipuri')\nos.mkdir(r'/kaggle/working/identify-dance-form/testing/manipuri')\nos.mkdir(r'/kaggle/working/identify-dance-form/source/manipuri')\nos.mkdir(r'/kaggle/working/identify-dance-form/training/bharatanatyam')\nos.mkdir(r'/kaggle/working/identify-dance-form/testing/bharatanatyam')\nos.mkdir(r'/kaggle/working/identify-dance-form/source/bharatanatyam')\nos.mkdir(r'/kaggle/working/identify-dance-form/training/odissi')\nos.mkdir(r'/kaggle/working/identify-dance-form/testing/odissi')\nos.mkdir(r'/kaggle/working/identify-dance-form/source/odissi')\nos.mkdir(r'/kaggle/working/identify-dance-form/training/kathakali')\nos.mkdir(r'/kaggle/working/identify-dance-form/testing/kathakali')\nos.mkdir(r'/kaggle/working/identify-dance-form/source/kathakali')\nos.mkdir(r'/kaggle/working/identify-dance-form/training/kathak')\nos.mkdir(r'/kaggle/working/identify-dance-form/testing/kathak')\nos.mkdir(r'/kaggle/working/identify-dance-form/source/kathak')\nos.mkdir(r'/kaggle/working/identify-dance-form/training/sattriya')\nos.mkdir(r'/kaggle/working/identify-dance-form/testing/sattriya')\nos.mkdir(r'/kaggle/working/identify-dance-form/source/sattriya')\nos.mkdir(r'/kaggle/working/identify-dance-form/training/kuchipudi')\nos.mkdir(r'/kaggle/working/identify-dance-form/testing/kuchipudi')\nos.mkdir(r'/kaggle/working/identify-dance-form/source/kuchipudi')\nos.mkdir(r'/kaggle/working/identify-dance-form/training/mohiniyattam')\nos.mkdir(r'/kaggle/working/identify-dance-form/testing/mohiniyattam')\nos.mkdir(r'/kaggle/working/identify-dance-form/source/mohiniyattam')\nos.mkdir('/kaggle/working/identify-dance-form/tests')\nos.mkdir('/kaggle/working/identify-dance-form/tests/unknown')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading the jpg files from the train directory and saving their names in the list named files","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"files = []\nfor  r, d, f in os.walk(train_dir):\n    for file in f:\n        if '.jpg' in file:\n            files.append(file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One of the images from train directory","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.image as mpimg\nplt.imshow(mpimg.imread(os.path.join(train_dir,files[0])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Copying images from the train directory to the Source directory's sub folders based on the labels of the images provided in train.csv file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in files:\n    if (train_csv[train_csv['Image'] == x]['target'] == 'odissi').bool():\n        train_temp = os.path.join(train_dir,x)\n        final_train = os.path.join('/kaggle/working/identify-dance-form/source/odissi/',x)\n        copyfile(train_temp, final_train)\n    elif (train_csv[train_csv['Image'] == x]['target'] == 'manipuri').bool():\n        train_temp = os.path.join(train_dir,x)\n        final_train = os.path.join('/kaggle/working/identify-dance-form/source/manipuri/',x)\n        copyfile(train_temp, final_train)\n    elif (train_csv[train_csv['Image'] == x]['target'] == 'bharatanatyam').bool():\n        train_temp = os.path.join(train_dir,x)\n        final_train = os.path.join('/kaggle/working/identify-dance-form/source/bharatanatyam/',x)\n        copyfile(train_temp, final_train)\n    elif (train_csv[train_csv['Image'] == x]['target'] == 'kathakali').bool():\n        train_temp = os.path.join(train_dir,x)\n        final_train = os.path.join('/kaggle/working/identify-dance-form/source/kathakali/',x)\n        copyfile(train_temp, final_train)\n    elif (train_csv[train_csv['Image'] == x]['target'] == 'kathak').bool():\n        train_temp = os.path.join(train_dir,x)\n        final_train = os.path.join('/kaggle/working/identify-dance-form/source/kathak/',x)\n        copyfile(train_temp, final_train)\n    elif (train_csv[train_csv['Image'] == x]['target'] == 'sattriya').bool():\n        train_temp = os.path.join(train_dir,x)\n        final_train = os.path.join('/kaggle/working/identify-dance-form/source/sattriya/',x)\n        copyfile(train_temp, final_train)\n    elif (train_csv[train_csv['Image'] == x]['target'] == 'kuchipudi').bool():\n        train_temp = os.path.join(train_dir,x)\n        final_train = os.path.join('/kaggle/working/identify-dance-form/source/kuchipudi/',x)\n        copyfile(train_temp, final_train)\n    elif (train_csv[train_csv['Image'] == x]['target'] == 'mohiniyattam').bool():\n        train_temp = os.path.join(train_dir,x)\n        final_train = os.path.join('/kaggle/working/identify-dance-form/source/mohiniyattam/',x)\n        copyfile(train_temp, final_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining the function for splitting the Source Diretory images into training and testing(validation) directories ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n    shuffle=random.sample(os.listdir(SOURCE),len(os.listdir(SOURCE)))\n    train_data_length=int(len(os.listdir(SOURCE))*SPLIT_SIZE)\n    test_data_length=int(len(os.listdir(SOURCE))-train_data_length)\n    train_data=shuffle[0:train_data_length]\n    test_data=shuffle[-test_data_length:]\n    for x in train_data:\n        train_temp=os.path.join(SOURCE,x)\n        final_train=os.path.join(TRAINING,x)\n        copyfile(train_temp,final_train)\n    for x in test_data:\n        test_temp=os.path.join(SOURCE,x)\n        final_test=os.path.join(TESTING,x)\n        copyfile(test_temp,final_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bhatanatyam_source_dir = '/kaggle/working/identify-dance-form/source/bharatanatyam/'\nbhatanatyam_training_dir = '/kaggle/working/identify-dance-form/training/bharatanatyam/'\nbhatanatyam_testing_dir = '/kaggle/working/identify-dance-form/testing/bharatanatyam/'\n\nkathak_source_dir = '/kaggle/working/identify-dance-form/source/kathak/'\nkathak_training_dir = '/kaggle/working/identify-dance-form/training/kathak/'\nkathak_testing_dir = '/kaggle/working/identify-dance-form/testing/kathak/'\n\nkathakali_source_dir = '/kaggle/working/identify-dance-form/source/kathakali/'\nkathakali_training_dir = '/kaggle/working/identify-dance-form/training/kathakali/'\nkathakali_testing_dir = '/kaggle/working/identify-dance-form/testing/kathakali/'\n\nkuchipudi_source_dir = '/kaggle/working/identify-dance-form/source/kuchipudi/'\nkuchipudi_training_dir = '/kaggle/working/identify-dance-form/training/kuchipudi/'\nkuchipudi_testing_dir = '/kaggle/working/identify-dance-form/testing/kuchipudi/'\n\nmanipuri_source_dir = '/kaggle/working/identify-dance-form/source/manipuri/'\nmanipuri_training_dir = '/kaggle/working/identify-dance-form/training/manipuri/'\nmanipuri_testing_dir = '/kaggle/working/identify-dance-form/testing/manipuri/'\n\nmohiniyattam_source_dir = '/kaggle/working/identify-dance-form/source/mohiniyattam/'\nmohiniyattam_training_dir = '/kaggle/working/identify-dance-form/training/mohiniyattam/'\nmohiniyattam_testing_dir = '/kaggle/working/identify-dance-form/testing/mohiniyattam/'\n\nodissi_source_dir = '/kaggle/working/identify-dance-form/source/odissi/'\nodissi_training_dir = '/kaggle/working/identify-dance-form/training/odissi/'\nodissi_testing_dir = '/kaggle/working/identify-dance-form/testing/odissi/'\n\nsattriya_source_dir = '/kaggle/working/identify-dance-form/source/sattriya/'\nsattriya_training_dir = '/kaggle/working/identify-dance-form/training/sattriya/'\nsattriya_testing_dir = '/kaggle/working/identify-dance-form/testing/sattriya/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting the Source Diretory images into training and testing(validation) sub directories ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"split_size = 0.85\nsplit_data(bhatanatyam_source_dir, bhatanatyam_training_dir, bhatanatyam_testing_dir, split_size)\nsplit_data(sattriya_source_dir, sattriya_training_dir, sattriya_testing_dir, split_size)\nsplit_data(odissi_source_dir, odissi_training_dir, odissi_testing_dir, split_size)\nsplit_data(mohiniyattam_source_dir, mohiniyattam_training_dir, mohiniyattam_testing_dir, split_size)\nsplit_data(manipuri_source_dir, manipuri_training_dir, manipuri_testing_dir, split_size)\nsplit_data(kuchipudi_source_dir, kuchipudi_training_dir, kuchipudi_testing_dir, split_size)\nsplit_data(kathakali_source_dir, kathakali_training_dir, kathakali_testing_dir, split_size)\nsplit_data(kathak_source_dir, kathak_training_dir, kathak_testing_dir, split_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing VGG16 Model for Pre-training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.vgg16 import VGG16","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Initializing VGG16 Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_trained_model = VGG16(include_top = False,\n                            input_shape = (156,156,3),\n                            weights = 'imagenet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_trained_model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Setting the layers of pre trained model to be trainable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_trained_model.trainable = True\n\nprint(len(pre_trained_model.layers))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fine Tuning the VGG16 Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fine_tune_at = 17","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Making some of the layers non-trainable of the VGG16 Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in pre_trained_model.layers[:fine_tune_at]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_output = pre_trained_model.output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adding some layers to implement VGG16 Model to fit well on our Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x = tf.keras.layers.Flatten()(last_output)\nx = tf.keras.layers.Dense(1024, activation = 'relu')(x)\nx = tf.keras.layers.Dropout(0.5)(x)\nx = tf.keras.layers.Dense(8, activation = 'softmax')(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Formation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Model(pre_trained_model.input, x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Initializing ImageDataGenerator and applying **Image Augmentation**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nTRAINING_DIR = \"/kaggle/working/identify-dance-form/training\"\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                  rotation_range=20,\n                                  width_shift_range=0.2,\n                                  height_shift_range=0.2,\n                                  shear_range=0.1,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,\n                                  fill_mode='nearest')\n\n\ntrain_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n                                                   target_size=(156,156),\n                                                   color_mode = 'rgb',\n                                                   batch_size=32,\n                                                   class_mode='categorical')\n\nVALIDATION_DIR = \"/kaggle/working/identify-dance-form/testing\"\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n\n\nvalidation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n                                                   target_size=(156,156),\n                                                   color_mode = 'rgb',\n                                                   batch_size=32,\n                                                   class_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Initializing the Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(tf.keras.optimizers.RMSprop(lr = 0.001), loss='categorical_crossentropy', metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Initializing the Callback","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fitting the Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(train_generator,\n                              epochs=40,\n                              verbose=1,\n                              validation_data=validation_generator,\n                             callbacks = [learning_rate_reduction])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Graphical Comparison of Training and validation - accuracy and loss","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nax1 = plt.subplot(1,2,1)\nax1.plot(history.history['loss'], color='b', label='Training Loss') \nax1.plot(history.history['val_loss'], color='r', label = 'Validation Loss',axes=ax1)\nlegend = ax1.legend(loc='best', shadow=True)\nax2 = plt.subplot(1,2,2)\nax2.plot(history.history['acc'], color='b', label='Training Accuracy') \nax2.plot(history.history['val_acc'], color='r', label = 'Validation Accuracy')\nlegend = ax2.legend(loc='best', shadow=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading the jpg files from the test directory and saving their names in the list named files","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Predicting the test images labels and preparing submission file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fil = []\nfor  r, d, f in os.walk(test_dir):\n    for file in f:\n        if '.jpg' in file:\n            fil.append(file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One of the images from train directory","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(mpimg.imread(os.path.join(test_dir,fil[0])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Copying images from the train directory to the tests directory - to prepare it for predict_generator function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in fil:\n    train_temp = os.path.join(test_dir,x)\n    final_train = os.path.join('/kaggle/working/identify-dance-form/tests/unknown',x)\n    copyfile(train_temp, final_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tests_dir = '/kaggle/working/identify-dance-form/tests'\ntest_datagen = ImageDataGenerator(rescale = 1./255)\ntest_generator = test_datagen.flow_from_directory(tests_dir,\n                                                  target_size = (156,156),\n                                                  color_mode = 'rgb',\n                                                  batch_size=32,\n                                                  class_mode=None,\n                                                  shuffle=False,\n                                                  seed=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Saving train images names in img_list","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"img_list = []\nfor x in test_generator.filenames:\n    x = x.split('/')[1]\n    img_list.append(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Making prediction on test images using predict_trainer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict_generator(test_generator)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Converting the probabalities we got from softmax layers into the integer labels","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_clases = np.argmax(predictions,axis=-1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Class Indices assigned to the sub classes by the train_generator","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator.class_indices","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating a DataFrame with the image name and the predicted image label","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {'Image': img_list, 'target': predicted_clases}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(data)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mapping back the class indices with the class label name","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['target']= df['target'].map({0: 'bharatanatyam',\n                                1: 'kathak',\n                                2: 'kathakali',\n                                3: 'kuchipudi',\n                                4: 'manipuri',\n                                5: 'mohiniyattam',\n                                6: 'odissi',\n                                7: 'sattriya'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exporting csv file for submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv(r'submission_dance.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# If You like it DO UPVOTE","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}