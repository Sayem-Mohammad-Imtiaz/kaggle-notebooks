{"cells":[{"metadata":{},"cell_type":"markdown","source":"# This notebook is derived from the notebook below by Priyanka Sachdeva. Many thanks.\nhttps://www.kaggle.com/priyankasachdeva20/autoviz-fake-news-classifier-6-ml-models"},{"metadata":{},"cell_type":"markdown","source":"# We are going to use Auto_NLP to see if we can get a better score using automated ML techniques vs. manual tuning as we saw in the above notebook.\nAuto_NLP can be found here: https://github.com/AutoViML/Auto_ViML"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk \nimport re\nfrom pandas_profiling import ProfileReport\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport sklearn.metrics\nimport sklearn\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"../input/source-based-news-classification/news_articles.csv\")\nprint(data.shape)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Since the data set above has both Text and Tabular data, we are going to use Auto_ViML which has Auto_NLP built-in so that it can find the best model and the best NLP technique for this complex data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install autoviml","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from autoviml.Auto_ViML import Auto_ViML","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Since there are duplicate columns such as title and title_without_stopwords, etc.,we will remove duplicates and combine all text columns into one column called \"NLP_column\" to make Auto_ViML processing easier."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.shape)\ndata.drop([ 'title_without_stopwords','text_without_stopwords'], axis=1,inplace=True)\ndata['NLP_column'] = data['title']+'  '+ (data['text']) + \"  \"+ data['main_img_url']\ndata.drop([ 'title','text', 'main_img_url'], axis=1,inplace=True)\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# We'll split the dataset into two the same way as above notebook so we can see whether the AutoML library can generalize well on unseen data (test) just as manual training did."},{"metadata":{"trusted":true},"cell_type":"code","source":"### There is one NaN value in label column => so let's drop that single row!!\n### Holy cow! there was ~50 rows with NaN = though AutoViML can handle NaN rows, \n###  we will delete them here to make the comparison apples to apples with previous noteboonk\nprint(data.shape)\ndata=data.dropna()\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(data, test_size=0.2, random_state = 42)\n\nprint(len(train), len(test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Now let us run Auto_ViML (including Auto_NLP on train and test). This may take about 10 mins to run"},{"metadata":{"trusted":true},"cell_type":"code","source":"target = 'label'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m, feats, trainm, testm = Auto_ViML(train, target, test,\n                            sample_submission='',\n                            scoring_parameter='', KMeans_Featurizer=False,\n                            hyper_param='RS',feature_reduction=True,\n                             Boosting_Flag='CatBoost', Binning_Flag=False,\n                            Add_Poly=0, Stacking_Flag=False,Imbalanced_Flag=False,\n                            verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow that was a 100% accuracy on validation data! Now let's see how well Auto_ViML performs on unseen test data"},{"metadata":{},"cell_type":"markdown","source":"# Evaluating Auto_ViML on unseen test data"},{"metadata":{},"cell_type":"markdown","source":"# Auto_ViML scores a 100 on Unseen Test data!"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = test[target].values\ny_pred = testm[target+'_predictions'].values\nprint(y_true.shape, y_pred.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_true, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So Auto_VIML has generalized well and performed well on Unseen (test) data as well"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}