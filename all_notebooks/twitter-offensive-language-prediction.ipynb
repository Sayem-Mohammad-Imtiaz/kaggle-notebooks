{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-17T11:53:01.688478Z","iopub.execute_input":"2021-06-17T11:53:01.689148Z","iopub.status.idle":"2021-06-17T11:53:01.70983Z","shell.execute_reply.started":"2021-06-17T11:53:01.689041Z","shell.execute_reply":"2021-06-17T11:53:01.708464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## OLID (Offensive Language Identification Dataset)\n### Predicting the Type and Target of Offensive Posts in Social Media","metadata":{}},{"cell_type":"markdown","source":"### Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport string\nimport numpy as np\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\nfrom sklearn.metrics import mean_squared_error,r2_score,classification_report,roc_auc_score,roc_curve\nfrom sklearn import metrics\nfrom sklearn import model_selection, svm\nfrom sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score\nfrom sklearn.preprocessing import scale,StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import Pipeline\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:57:59.698096Z","iopub.execute_input":"2021-06-17T11:57:59.698611Z","iopub.status.idle":"2021-06-17T11:57:59.72085Z","shell.execute_reply.started":"2021-06-17T11:57:59.698581Z","shell.execute_reply":"2021-06-17T11:57:59.719936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load the Data","metadata":{}},{"cell_type":"code","source":"train_data=pd.read_csv('../input/olid-dataset/olid-training-v1.0.tsv', delimiter='\\t', encoding='utf-8')\n\ntrain_tweets = train_data[['tweet']] #Extract tweets\ntrain_task_a_labels= train_data[['subtask_a']] #Extract subtsak_a labels\ntrain_task_b_labels= train_data[['subtask_b']] #Extract subtsak_b labels\ntrain_task_c_labels= train_data[['subtask_c']] #Extract subtsak_c labels\n\ntrain_task_a_labels.columns.values[0] = 'class_a' #Rename class attribute\ntrain_task_b_labels.columns.values[0] = 'class_b' #Rename class attribute\ntrain_task_c_labels.columns.values[0] = 'class_c' #Rename class attribute\n\nprint(train_data)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:53:34.490832Z","iopub.execute_input":"2021-06-17T11:53:34.491491Z","iopub.status.idle":"2021-06-17T11:53:34.615988Z","shell.execute_reply.started":"2021-06-17T11:53:34.49144Z","shell.execute_reply":"2021-06-17T11:53:34.614793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Preprocessing","metadata":{}},{"cell_type":"code","source":"#Function to clean tweets in a data frame's tweet column\ndef clean_tweets(df):\n    \n    punctuations = string.punctuation\n    \n    df.loc[:, 'tweet'] = df.tweet.str.replace('@USER', '') #Remove mentions (@USER)\n    df.loc[:, 'tweet'] = df.tweet.str.replace('URL', '') #Remove URLs\n    df.loc[:, 'tweet'] = df.tweet.str.replace('&amp', 'and') #Replace ampersand (&) with and\n    df.loc[:, 'tweet'] = df.tweet.str.replace('&lt','') #Remove &lt\n    df.loc[:, 'tweet'] = df.tweet.str.replace('&gt','') #Remove &gt\n    df.loc[:, 'tweet'] = df.tweet.str.replace('\\d+','') #Remove numbers\n    df.loc[:, 'tweet'] = df.tweet.str.lower() #Lowercase\n\n    #Remove punctuations\n    for punctuation in punctuations:\n        df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n\n    df.loc[:, 'tweet'] = df.astype(str).apply(\n        lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii')\n    )\n    #Remove emojis\n    df.loc[:, 'tweet'] = df.tweet.str.strip() #Trim leading and trailing whitespaces","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:53:49.749393Z","iopub.execute_input":"2021-06-17T11:53:49.749966Z","iopub.status.idle":"2021-06-17T11:53:49.758666Z","shell.execute_reply.started":"2021-06-17T11:53:49.749928Z","shell.execute_reply":"2021-06-17T11:53:49.757913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_tweets(train_tweets)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:54:00.858396Z","iopub.execute_input":"2021-06-17T11:54:00.859069Z","iopub.status.idle":"2021-06-17T11:54:01.483177Z","shell.execute_reply.started":"2021-06-17T11:54:00.859026Z","shell.execute_reply":"2021-06-17T11:54:01.481955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_task_a_data = train_tweets.join(train_task_a_labels)\n\ntrain_task_b_data = train_tweets.join(train_task_b_labels)\ntrain_task_b_data = train_task_b_data.dropna() #Drop records with missing values\n\ntrain_task_c_data = train_tweets.join(train_task_c_labels)\ntrain_task_c_data = train_task_c_data.dropna() #Drop records with missing values\n\n#Apply quotes to cleaned tweets\ntrain_task_a_data.update(train_task_a_data[['tweet']].applymap('\\'{}\\''.format))\ntrain_task_b_data.update(train_task_b_data[['tweet']].applymap('\\'{}\\''.format))\ntrain_task_c_data.update(train_task_c_data[['tweet']].applymap('\\'{}\\''.format))","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:54:05.973012Z","iopub.execute_input":"2021-06-17T11:54:05.97339Z","iopub.status.idle":"2021-06-17T11:54:06.04141Z","shell.execute_reply.started":"2021-06-17T11:54:05.973358Z","shell.execute_reply":"2021-06-17T11:54:06.040299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_task_a_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:54:11.345621Z","iopub.execute_input":"2021-06-17T11:54:11.345975Z","iopub.status.idle":"2021-06-17T11:54:11.361299Z","shell.execute_reply.started":"2021-06-17T11:54:11.345945Z","shell.execute_reply":"2021-06-17T11:54:11.360077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Read tweets from test sets\ntest_tweet_a=pd.read_csv('../input/olid-dataset/testset-levela.tsv', delimiter='\\t', encoding='utf-8')\ntest_tweet_b=pd.read_csv('../input/olid-dataset/testset-levelb.tsv', delimiter='\\t', encoding='utf-8')\ntest_tweet_c=pd.read_csv('../input/olid-dataset/testset-levelc.tsv', delimiter='\\t', encoding='utf-8')\n\n#Read tweet labels\ntest_label_a=pd.read_csv('../input/olid-dataset/labels-levela.csv', encoding='utf-8', \n                         index_col=False, names=['id', 'class_a'])\ntest_label_b=pd.read_csv('../input/olid-dataset/labels-levelb.csv', encoding='utf-8', \n                         index_col=False, names=['id', 'class_b'])\ntest_label_c=pd.read_csv('../input/olid-dataset/labels-levelc.csv', encoding='utf-8', \n                         index_col=False, names=['id', 'class_c'])\n\n#Merge tweets with labels by id\ntest_tweet_a = test_tweet_a.merge(test_label_a, on='id')\ntest_tweet_b = test_tweet_b.merge(test_label_b, on='id')\ntest_tweet_c = test_tweet_c.merge(test_label_c, on='id')\n\n#Drop id column\ntest_tweet_a = test_tweet_a.drop(columns='id')\ntest_tweet_b = test_tweet_b.drop(columns='id')\ntest_tweet_c = test_tweet_c.drop(columns='id')\n\n#Clean tweets in test sets\nclean_tweets(test_tweet_a)\nclean_tweets(test_tweet_b)\nclean_tweets(test_tweet_c)\n\n#Apply quotes to cleaned tweets\ntest_tweet_a.update(test_tweet_a[['tweet']].applymap('\\'{}\\''.format))\ntest_tweet_b.update(test_tweet_b[['tweet']].applymap('\\'{}\\''.format))\ntest_tweet_c.update(test_tweet_c[['tweet']].applymap('\\'{}\\''.format))\n\ntest_tweet_a.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:55:00.416025Z","iopub.execute_input":"2021-06-17T11:55:00.416423Z","iopub.status.idle":"2021-06-17T11:55:00.646063Z","shell.execute_reply.started":"2021-06-17T11:55:00.416389Z","shell.execute_reply":"2021-06-17T11:55:00.644914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quick look at the topic numbers on the total dataset\ndef plot_classes(df,col_name):\n    fig = plt.figure(figsize=(6,4))\n    print(df.groupby(col_name)[col_name].count())\n    df.groupby(col_name)[col_name].count().plot.bar(ylim=0)\n    plt.show()\n\nplot_classes(train_task_a_data,\"class_a\")","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:55:08.539477Z","iopub.execute_input":"2021-06-17T11:55:08.539811Z","iopub.status.idle":"2021-06-17T11:55:08.722361Z","shell.execute_reply.started":"2021-06-17T11:55:08.539784Z","shell.execute_reply":"2021-06-17T11:55:08.721039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quick look at the topic numbers on the total dataset\n\nplot_classes(test_tweet_a,\"class_a\")","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:55:14.73158Z","iopub.execute_input":"2021-06-17T11:55:14.731981Z","iopub.status.idle":"2021-06-17T11:55:14.869637Z","shell.execute_reply.started":"2021-06-17T11:55:14.731941Z","shell.execute_reply":"2021-06-17T11:55:14.867994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Task A","metadata":{}},{"cell_type":"code","source":"# Creating labelEncoder\nencoder = LabelEncoder()\n# Converting string labels into numbers.\ntrain_task_a_data[\"class_a_code\"] = encoder.fit_transform(train_task_a_data[\"class_a\"])\ntest_tweet_a[\"class_a_code\"] = encoder.fit_transform(test_tweet_a[\"class_a\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:55:29.832901Z","iopub.execute_input":"2021-06-17T11:55:29.833311Z","iopub.status.idle":"2021-06-17T11:55:29.845235Z","shell.execute_reply.started":"2021-06-17T11:55:29.833277Z","shell.execute_reply":"2021-06-17T11:55:29.844293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create tuple pair for class and class code\ntrain_task_a_data['class-tuple'] = train_task_a_data[['class_a', 'class_a_code']].apply(tuple, axis=1)\nclass_a = train_task_a_data['class-tuple'].unique()\nclass_a","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:55:35.102404Z","iopub.execute_input":"2021-06-17T11:55:35.102757Z","iopub.status.idle":"2021-06-17T11:55:35.272903Z","shell.execute_reply.started":"2021-06-17T11:55:35.102728Z","shell.execute_reply":"2021-06-17T11:55:35.271657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label the Data\n\nX_train = train_task_a_data['tweet']\ny_train = train_task_a_data['class_a_code']\n\nX_test = test_tweet_a['tweet']\ny_test = test_tweet_a['class_a_code']\n\n\nprint(\"Shape of X_train is {} and shape of y_train is {}\".format(X_train.shape, y_train.shape))\nprint(\"Shape of X_test is {} and shape of y_test is {}\".format(X_test.shape, y_test.shape))","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:55:40.40488Z","iopub.execute_input":"2021-06-17T11:55:40.40524Z","iopub.status.idle":"2021-06-17T11:55:40.414667Z","shell.execute_reply.started":"2021-06-17T11:55:40.405211Z","shell.execute_reply":"2021-06-17T11:55:40.412886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model - Support Vector Machines","metadata":{}},{"cell_type":"code","source":"# SVM Model\n\nsvm_model = SVC(kernel=\"linear\")\npipeline_svm = Pipeline([('vectorizer', TfidfVectorizer(sublinear_tf=True, min_df=5, \n                                                        norm='l2', encoding='latin-1', \n                                                        ngram_range=(1, 2), stop_words='english')),\n                         ('classifier', svm_model)])\n\n\npipeline_svm.fit(X_train, y_train)\ny_pred = pipeline_svm.predict(X_test)\naccuracy_svm = accuracy_score(y_test, y_pred)\nprint(\"model accuracy:\",accuracy_svm)\nprint(\"\\n\")\nprint(metrics.classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:58:07.022425Z","iopub.execute_input":"2021-06-17T11:58:07.022834Z","iopub.status.idle":"2021-06-17T11:58:21.424096Z","shell.execute_reply.started":"2021-06-17T11:58:07.022801Z","shell.execute_reply":"2021-06-17T11:58:21.42307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_conf_matrix(test_label,predicted_label):\n    cm = confusion_matrix(test_label,predicted_label)\n    class_names=[0,1] # name  of classes\n    fig, ax = plt.subplots()\n    tick_marks = np.arange(len(class_names))\n    plt.xticks(tick_marks, class_names)\n    plt.yticks(tick_marks, class_names)\n    # create heatmap\n    sns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"BuPu\" ,fmt='g')\n    ax.xaxis.set_label_position(\"top\")\n    plt.tight_layout()\n    plt.title('Confusion matrix', y=1.1)\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label');\n\nplot_conf_matrix(y_test,y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:58:28.841341Z","iopub.execute_input":"2021-06-17T11:58:28.841739Z","iopub.status.idle":"2021-06-17T11:58:29.069778Z","shell.execute_reply.started":"2021-06-17T11:58:28.841704Z","shell.execute_reply":"2021-06-17T11:58:29.069011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Task B","metadata":{}},{"cell_type":"code","source":"# Our predicted OFF - offensive data\ndf_pred = pd.DataFrame(data=y_pred,columns=[\"predicted\"])\npredicted_data = pd.concat([test_tweet_a, df_pred],axis=1)\noff_data = predicted_data[predicted_data.predicted ==1]\noff_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:58:45.298568Z","iopub.execute_input":"2021-06-17T11:58:45.298933Z","iopub.status.idle":"2021-06-17T11:58:45.316038Z","shell.execute_reply.started":"2021-06-17T11:58:45.298903Z","shell.execute_reply":"2021-06-17T11:58:45.314534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare test data for task B\ntest_b = off_data.merge(test_tweet_b,on=\"tweet\")\ntest_b = test_b[[\"tweet\",\"class_b\"]]\nprint(test_b.shape)\ntest_b.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:58:52.813147Z","iopub.execute_input":"2021-06-17T11:58:52.813662Z","iopub.status.idle":"2021-06-17T11:58:52.830675Z","shell.execute_reply.started":"2021-06-17T11:58:52.813613Z","shell.execute_reply":"2021-06-17T11:58:52.829963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare train data for task B\n# dataframe task_a and task_b merged\ndf_a_b = pd.concat([train_task_a_data,train_task_b_data],axis=1)\ndf_a_b = df_a_b[df_a_b.class_a ==\"OFF\"]\ndf_a_b = df_a_b[[\"tweet\",\"class_b\"]]\ndf_a_b= df_a_b.T.drop_duplicates().T\ntrain_b = df_a_b.copy()\nprint(\"Data shape without undersampling:\",train_b.shape)\ntrain_b.head()\n\ntrain_b_unt = train_b[train_b[\"class_b\"] == \"UNT\"]\ntrain_b_tin = train_b[train_b[\"class_b\"] == \"TIN\"]\ntrain_b_tin = train_b_tin.sample(1000)\ntrain_b_new = pd.concat([train_b_unt,train_b_tin])\nprint(\"Data shape with undersampling\",train_b_new.shape)\ntrain_b_new.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:58:59.256959Z","iopub.execute_input":"2021-06-17T11:58:59.257504Z","iopub.status.idle":"2021-06-17T11:59:00.357048Z","shell.execute_reply.started":"2021-06-17T11:58:59.257457Z","shell.execute_reply":"2021-06-17T11:59:00.355899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Before under-sampling the train data\nplot_classes(train_b,\"class_b\")","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:59:07.146302Z","iopub.execute_input":"2021-06-17T11:59:07.146655Z","iopub.status.idle":"2021-06-17T11:59:07.289267Z","shell.execute_reply.started":"2021-06-17T11:59:07.146627Z","shell.execute_reply":"2021-06-17T11:59:07.288324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After under-sampling the train data\nplot_classes(train_b_new,\"class_b\")","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:59:14.081729Z","iopub.execute_input":"2021-06-17T11:59:14.082134Z","iopub.status.idle":"2021-06-17T11:59:14.220406Z","shell.execute_reply.started":"2021-06-17T11:59:14.082087Z","shell.execute_reply":"2021-06-17T11:59:14.219494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot test data \nplot_classes(test_b,\"class_b\")","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:59:24.11226Z","iopub.execute_input":"2021-06-17T11:59:24.112779Z","iopub.status.idle":"2021-06-17T11:59:24.234073Z","shell.execute_reply.started":"2021-06-17T11:59:24.11274Z","shell.execute_reply":"2021-06-17T11:59:24.232661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating labelEncoder\nencoder = LabelEncoder()\n# Converting string labels into numbers.\ntrain_b[\"class_b_code\"] = encoder.fit_transform(train_b[\"class_b\"])\ntrain_b_new[\"class_b_code\"] = encoder.fit_transform(train_b_new[\"class_b\"])\ntest_b[\"class_b_code\"] = encoder.fit_transform(test_b[\"class_b\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:59:31.043448Z","iopub.execute_input":"2021-06-17T11:59:31.043787Z","iopub.status.idle":"2021-06-17T11:59:31.053912Z","shell.execute_reply.started":"2021-06-17T11:59:31.043758Z","shell.execute_reply":"2021-06-17T11:59:31.052629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create tuple pair for class and class code\ntrain_b['class-tuple'] = train_b[['class_b', 'class_b_code']].apply(tuple, axis=1)\nclass_b = train_b['class-tuple'].unique()\nclass_b","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:59:36.372395Z","iopub.execute_input":"2021-06-17T11:59:36.372739Z","iopub.status.idle":"2021-06-17T11:59:36.438629Z","shell.execute_reply.started":"2021-06-17T11:59:36.372711Z","shell.execute_reply":"2021-06-17T11:59:36.437754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the labels and train-test split\n\ntrain_tweets = train_b_new['tweet']\ntrain_labels = train_b_new['class_b_code']\n\ntest_tweets = test_b['tweet']\ntest_labels = test_b['class_b_code']\n\nX_train,X_test,y_train,y_test = train_test_split(train_tweets,train_labels,test_size=0.30,random_state=42)\n\nprint(\"Shape of X_train is {} and shape of y_train is {}\".format(X_train.shape, y_train.shape))\nprint(\"Shape of X_test is {} and shape of y_test is {}\".format(X_test.shape, y_test.shape))\n\nprint(\"Shape of test_tweets is {} and shape of test_labels is {}\".format(test_tweets.shape, test_labels.shape))","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:59:42.311552Z","iopub.execute_input":"2021-06-17T11:59:42.311934Z","iopub.status.idle":"2021-06-17T11:59:42.323339Z","shell.execute_reply.started":"2021-06-17T11:59:42.311901Z","shell.execute_reply":"2021-06-17T11:59:42.322158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SVM Model- For train set\n\nsvm_model = SVC(kernel=\"linear\")\npipeline_svm = Pipeline([('vectorizer', TfidfVectorizer(sublinear_tf=True, min_df=5, \n                                                        norm='l2', encoding='latin-1', \n                                                        ngram_range=(1, 2), stop_words='english')),\n                         ('classifier', svm_model)])\n\n\npipeline_svm.fit(X_train, y_train)\ny_pred = pipeline_svm.predict(X_test)\naccuracy_svm = accuracy_score(y_test, y_pred)\nprint(\"model accuracy:\",accuracy_svm)\nprint(\"\\n\")\nprint(metrics.classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:59:48.306976Z","iopub.execute_input":"2021-06-17T11:59:48.307417Z","iopub.status.idle":"2021-06-17T11:59:48.471738Z","shell.execute_reply.started":"2021-06-17T11:59:48.30738Z","shell.execute_reply":"2021-06-17T11:59:48.470262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SVM Model- For test set\n\nsvm_model = SVC(kernel=\"linear\")\npipeline_svm = Pipeline([('vectorizer', TfidfVectorizer(sublinear_tf=True, min_df=5, \n                                                        norm='l2', encoding='latin-1', \n                                                        ngram_range=(1, 2), stop_words='english')),\n                         ('classifier', svm_model)])\n\n\npipeline_svm.fit(train_tweets, train_labels)\ny_pred = pipeline_svm.predict(test_tweets)\naccuracy_svm = accuracy_score(test_labels, y_pred)\nprint(\"model accuracy:\",accuracy_svm)\nprint(\"\\n\")\nprint(metrics.classification_report(test_labels, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-17T11:59:59.390675Z","iopub.execute_input":"2021-06-17T11:59:59.391076Z","iopub.status.idle":"2021-06-17T11:59:59.605795Z","shell.execute_reply.started":"2021-06-17T11:59:59.391045Z","shell.execute_reply":"2021-06-17T11:59:59.604524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_conf_matrix(test_labels,y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:00:07.802008Z","iopub.execute_input":"2021-06-17T12:00:07.802385Z","iopub.status.idle":"2021-06-17T12:00:08.110397Z","shell.execute_reply.started":"2021-06-17T12:00:07.802354Z","shell.execute_reply":"2021-06-17T12:00:08.109562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Task C","metadata":{}},{"cell_type":"code","source":"# Our predicted TIN - Targeted Insult data\ndf_pred = pd.DataFrame(data=y_pred,columns=[\"predicted\"])\npredicted_data = pd.concat([test_tweet_b, df_pred],axis=1)\ntin_data = predicted_data[predicted_data.predicted ==0]\nprint(tin_data.shape)\ntin_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:00:21.779666Z","iopub.execute_input":"2021-06-17T12:00:21.780198Z","iopub.status.idle":"2021-06-17T12:00:21.798396Z","shell.execute_reply.started":"2021-06-17T12:00:21.780165Z","shell.execute_reply":"2021-06-17T12:00:21.797314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare test data for task C\ntest_c = tin_data.merge(test_tweet_c,on=\"tweet\")\ntest_c = test_c[[\"tweet\",\"class_c\"]]\nprint(test_c.shape)\ntest_c.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:00:27.661814Z","iopub.execute_input":"2021-06-17T12:00:27.662209Z","iopub.status.idle":"2021-06-17T12:00:27.679215Z","shell.execute_reply.started":"2021-06-17T12:00:27.662171Z","shell.execute_reply":"2021-06-17T12:00:27.678212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare train data for task C\n# dataframe task_b and task_c merged\ndf_b_c = pd.concat([train_task_b_data,train_task_c_data],axis=1)\ndf_b_c = df_b_c[df_b_c.class_b ==\"TIN\"]\ndf_b_c = df_b_c[[\"tweet\",\"class_c\"]]\ndf_b_c= df_b_c.T.drop_duplicates().T\ntrain_c = df_b_c.copy()\nprint(\"Data shape without over and undersampling:\",train_c.shape)\ntrain_c.head()\n\n\ntrain_c_ind = train_c[train_c[\"class_c\"] == \"IND\"]\ntrain_c_oth = train_c[train_c[\"class_c\"] == \"OTH\"]\ntrain_c_grp = train_c[train_c[\"class_c\"] == \"GRP\"]\ntrain_c_ind = train_c_ind.sample(1500)\ntrain_c_oth = train_c_oth.sample(1000, replace=True)\ntrain_c_grp = train_c_grp.sample(1000)\ntrain_c_new = pd.concat([train_c_ind,train_c_oth,train_c_grp])\nprint(\"Data shape with undersampling\",train_c_new.shape)\ntrain_c_new.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:00:34.493944Z","iopub.execute_input":"2021-06-17T12:00:34.494319Z","iopub.status.idle":"2021-06-17T12:00:35.333261Z","shell.execute_reply.started":"2021-06-17T12:00:34.494288Z","shell.execute_reply":"2021-06-17T12:00:35.33201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the train data without over and undersapmling the classes\n\nplot_classes(train_c,\"class_c\")","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:00:44.626162Z","iopub.execute_input":"2021-06-17T12:00:44.626588Z","iopub.status.idle":"2021-06-17T12:00:44.767642Z","shell.execute_reply.started":"2021-06-17T12:00:44.62655Z","shell.execute_reply":"2021-06-17T12:00:44.766159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the train data with over and undersapmling the classes\n\nplot_classes(train_c_new,\"class_c\")","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:00:51.391332Z","iopub.execute_input":"2021-06-17T12:00:51.391762Z","iopub.status.idle":"2021-06-17T12:00:51.557552Z","shell.execute_reply.started":"2021-06-17T12:00:51.391728Z","shell.execute_reply":"2021-06-17T12:00:51.556304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot test data \n\nplot_classes(test_c,\"class_c\")","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:00:57.728182Z","iopub.execute_input":"2021-06-17T12:00:57.72858Z","iopub.status.idle":"2021-06-17T12:00:57.871914Z","shell.execute_reply.started":"2021-06-17T12:00:57.728545Z","shell.execute_reply":"2021-06-17T12:00:57.870845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating labelEncoder\nencoder = LabelEncoder()\n# Converting string labels into numbers.\ntrain_c[\"class_c_code\"] = encoder.fit_transform(train_c[\"class_c\"])\ntrain_c_new[\"class_c_code\"] = encoder.fit_transform(train_c_new[\"class_c\"])\ntest_c[\"class_c_code\"] = encoder.fit_transform(test_c[\"class_c\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:01:11.722022Z","iopub.execute_input":"2021-06-17T12:01:11.722525Z","iopub.status.idle":"2021-06-17T12:01:11.738269Z","shell.execute_reply.started":"2021-06-17T12:01:11.722481Z","shell.execute_reply":"2021-06-17T12:01:11.736242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create tuple pair for class and class code\ntrain_c['class-tuple'] = train_c[['class_c', 'class_c_code']].apply(tuple, axis=1)\nclass_c = train_c['class-tuple'].unique()\nclass_c","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:01:18.060792Z","iopub.execute_input":"2021-06-17T12:01:18.061213Z","iopub.status.idle":"2021-06-17T12:01:18.128978Z","shell.execute_reply.started":"2021-06-17T12:01:18.061175Z","shell.execute_reply":"2021-06-17T12:01:18.127523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the labels and train-test split\n\ntrain_tweets = train_c_new['tweet']\ntrain_labels = train_c_new['class_c_code']\n\ntest_tweets = test_c['tweet']\ntest_labels = test_c['class_c_code']\n\nX_train,X_test,y_train,y_test = train_test_split(train_tweets,train_labels,test_size=0.30,random_state=42)\n\nprint(\"Shape of X_train is {} and shape of y_train is {}\".format(X_train.shape, y_train.shape))\nprint(\"Shape of X_test is {} and shape of y_test is {}\".format(X_test.shape, y_test.shape))\n\nprint(\"Shape of test_tweets is {} and shape of test_labels is {}\".format(test_tweets.shape, test_labels.shape))","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:01:24.035874Z","iopub.execute_input":"2021-06-17T12:01:24.036303Z","iopub.status.idle":"2021-06-17T12:01:24.04893Z","shell.execute_reply.started":"2021-06-17T12:01:24.036265Z","shell.execute_reply":"2021-06-17T12:01:24.047866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SVM Model- For train set\n\nsvm_model = SVC(kernel=\"linear\")\npipeline_svm = Pipeline([('vectorizer', TfidfVectorizer(sublinear_tf=True, min_df=5, \n                                                        norm='l2', encoding='latin-1', \n                                                        ngram_range=(1, 2), stop_words='english')),\n                         ('classifier', svm_model)])\n\n\npipeline_svm.fit(X_train, y_train)\ny_pred = pipeline_svm.predict(X_test)\naccuracy_svm = accuracy_score(y_test, y_pred)\nprint(\"model accuracy:\",accuracy_svm)\nprint(\"\\n\")\nprint(metrics.classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:01:29.4223Z","iopub.execute_input":"2021-06-17T12:01:29.42295Z","iopub.status.idle":"2021-06-17T12:01:30.354835Z","shell.execute_reply.started":"2021-06-17T12:01:29.422911Z","shell.execute_reply":"2021-06-17T12:01:30.353993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SVM Model- For test set\n\nsvm_model = SVC(kernel=\"linear\")\npipeline_svm = Pipeline([('vectorizer', TfidfVectorizer(sublinear_tf=True, min_df=5, \n                                                        norm='l2', encoding='latin-1', \n                                                        ngram_range=(1, 2), stop_words='english')),\n                         ('classifier', svm_model)])\n\n\npipeline_svm.fit(train_tweets, train_labels)\ny_pred = pipeline_svm.predict(test_tweets)\naccuracy_svm = accuracy_score(test_labels, y_pred)\nprint(\"model accuracy:\",accuracy_svm)\nprint(\"\\n\")\nprint(metrics.classification_report(test_labels, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:01:40.971969Z","iopub.execute_input":"2021-06-17T12:01:40.972406Z","iopub.status.idle":"2021-06-17T12:01:42.424797Z","shell.execute_reply.started":"2021-06-17T12:01:40.97237Z","shell.execute_reply":"2021-06-17T12:01:42.423497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_conf_matrix(test_labels,y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T12:01:50.758378Z","iopub.execute_input":"2021-06-17T12:01:50.758776Z","iopub.status.idle":"2021-06-17T12:01:50.99726Z","shell.execute_reply.started":"2021-06-17T12:01:50.758743Z","shell.execute_reply":"2021-06-17T12:01:50.995909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}