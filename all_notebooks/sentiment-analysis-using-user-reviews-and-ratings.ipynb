{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport datetime as dt\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix\nimport sklearn.metrics as mt\n\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n \ndf1 = pd.read_csv('../input/Womens Clothing E-Commerce Reviews.csv')\ndf = df1[['Review Text','Rating','Class Name','Age']]\n#df1.info()\n#df1.describe()\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cda9ceace361f152f30fa199f021528d0f9f2b7","_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"# fill NA values by space\ndf['Review Text'] = df['Review Text'].fillna('')\n\n# CountVectorizer() converts a collection \n# of text documents to a matrix of token counts\nvectorizer = CountVectorizer()\n# assign a shorter name for the analyze\n# which tokenizes the string\nanalyzer = vectorizer.build_analyzer()\n\ndef wordcounts(s):\n    c = {}\n    # tokenize the string and continue, if it is not empty\n    if analyzer(s):\n        d = {}\n        # find counts of the vocabularies and transform to array \n        w = vectorizer.fit_transform([s]).toarray()\n        # vocabulary and index (index of w)\n        vc = vectorizer.vocabulary_\n        # items() transforms the dictionary's (word, index) tuple pairs\n        for k,v in vc.items():\n            d[v]=k # d -> index:word \n        for index,i in enumerate(w[0]):\n            c[d[index]] = i # c -> word:count\n    return  c\n\n# add new column to the dataframe\ndf['Word Counts'] = df['Review Text'].apply(wordcounts)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review_length = {'100':0,'200':0,'300':0,'400':0,'500':0,'600':0,'700':0}\nfor review in df['Review Text']:\n    if len(review)<100:\n        review_length['100'] +=1\n    if 100<len(review)<200:\n        review_length['200'] +=1\n    if 200<len(review)<300:\n        review_length['300'] +=1\n    if 300<len(review)<400:\n        review_length['400'] +=1\n    if 400<len(review)<500:\n        review_length['500'] +=1\n    if 500<len(review)<600:\n        review_length['600'] +=1\n    if 600<len(review):\n        review_length['700'] +=1\n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review_length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.xlabel('length of reviews')  \nplt.ylabel('number of reviews')  \n  \n\nplt.title(\"num vs len of reviews\")\nplt.bar(*zip(*review_length.items()))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddd45a2082a6a6a70642ec16fca3f4b355da1285","_kg_hide-input":true},"cell_type":"code","source":"# selecting some words to examine detailed \nselectedwords = ['awesome','great','fantastic','extraordinary','amazing','super',\n                 'magnificent','stunning','impressive','wonderful','breathtaking',\n                 'love','content','pleased','happy','glad','satisfied','lucky',\n                 'shocking','cheerful','wow','sad','unhappy','horrible','regret',\n                 'bad','terrible','annoyed','disappointed','upset','awful','hate']\n\ndef selectedcount(dic,word):\n    if word in dic:\n        return dic[word]\n    else:\n        return 0\n    \ndfwc = df.copy()  \nfor word in selectedwords:\n    dfwc[word] = dfwc['Word Counts'].apply(selectedcount,args=(word,))\n    \nword_sum = dfwc[selectedwords].sum()\nprint('Selected Words')\nprint(word_sum.sort_values(ascending=False).iloc[:5])\n\nprint('\\nClass Names')\nprint(df['Class Name'].fillna(\"Empty\").value_counts().iloc[:5])\n\n\n\ncn = df['Class Name'].fillna(\" \").value_counts()\n\n\nrt = df['Review Text']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f4a2b818be0f6364e6bec4cebf94ba13a869432","_kg_hide-input":true},"cell_type":"code","source":"df1=df['Rating'].value_counts().to_frame()\navgdf1 = df.groupby('Class Name').agg({'Rating': np.average})\navgdf2 = df.groupby('Class Name').agg({'Age': np.average})\navgdf3 = df.groupby('Rating').agg({'Age': np.average})\n\ntrace1 = go.Bar(\n    x=avgdf1.index,\n    y=round(avgdf1['Rating'],2),\n    marker=dict(\n        color=avgdf1['Rating'],\n        colorscale = 'RdBu')\n)\n\ntrace2 = go.Bar(\n    x=df1.index,\n    y=df1.Rating,\n    marker=dict(\n        color=df1['Rating'],\n        colorscale = 'RdBu')\n)\n\ntrace3 = go.Bar(\n    x=avgdf2.index,\n    y=round(avgdf2['Age'],2),\n    marker=dict(\n        color=avgdf2['Age'],\n        colorscale = 'RdBu')\n)\n\ntrace4 = go.Bar(\n    x=avgdf3.index,\n    y=round(avgdf3['Age'],2),\n    marker=dict(\n        color=avgdf3['Age'],\n        colorscale = 'Reds')\n)\n\nfig = tools.make_subplots(rows=2, cols=2, print_grid=False)\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\nfig.append_trace(trace3, 2, 1)\nfig.append_trace(trace4, 2, 2)\n\nfig['layout']['xaxis1'].update(title='Class')\nfig['layout']['yaxis1'].update(title='Average Rating')\nfig['layout']['xaxis2'].update(title='Rating')\nfig['layout']['yaxis2'].update(title='Count')\nfig['layout']['xaxis3'].update(title='Class')\nfig['layout']['yaxis3'].update(title='Average Age of the Reviewers')\nfig['layout']['xaxis4'].update(title='Rating')\nfig['layout']['yaxis4'].update(title='Average Age of the Reviewers')\n\nfig['layout'].update(height=800, width=900,showlegend=False)\nfig.update_layout({'plot_bgcolor':'rgba(0,0,0,0)',\n                   'paper_bgcolor':'rgba(0,0,0,0)'})\n#fig['layout'].update(plot_bgcolor='rgba(0,0,0,0)')\n#fig['layout'].update(paper_bgcolor='rgba(0,0,0,0)')\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c688babf6822d1b322ae38d34264d2adce7b5e97"},"cell_type":"markdown","source":"It seems that most of the ratings are positive and the average rating between the classes looks close. On the other hand, when we look at ages, average age does not change significantly according to the rating. Also, average age changes slightly between class names except casual bottoms. We can disregard casual bottoms because the below chart shows that there are just two reviews and making an inference will not be right."},{"metadata":{"trusted":true,"_uuid":"fbf76a6f3e33e712706170704857fd44634571fb","_kg_hide-input":true},"cell_type":"code","source":"cv = df['Class Name'].value_counts()\n\ntrace = go.Scatter3d( x = avgdf1.index,\n                      y = avgdf1['Rating'],\n                      z = cv[avgdf1.index],\n                      mode = 'markers',\n                      marker = dict(size=10,color=avgdf1['Rating']),\n                      hoverinfo =\"text\",\n                      text=\"Class: \"+avgdf1.index+\" \\ Average Rating: \"+avgdf1['Rating'].map(' {:,.2f}'.format).apply(str)+\" \\ Number of Reviewers: \"+cv[avgdf1.index].apply(str)\n                      )\n\ndata = [trace]\nlayout = go.Layout(title=\"Average Rating & Class & Number of Reviewers\",\n                   scene = dict(\n                    xaxis = dict(title='Class'),\n                    yaxis = dict(title='Average Rating'),\n                    zaxis = dict(title='Number of Sales'),),\n                   margin = dict(l=30, r=30, b=30, t=30))\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)\nplt.savefig('3D_Scatter.png')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96797ed17ba3cd3c6aa41bdef38cb10deb409341"},"cell_type":"markdown","source":" # <span id=\"6\"></span> Building a Sentiment Classifier\n#### [Return Contents](#0)\n<hr/>"},{"metadata":{"_uuid":"a0ca41ad24d601e6eed1dd42dc592ac927edc7a7"},"cell_type":"markdown","source":"Since we do not have a column which shows the sentiment as positive or negative in the dataset, I defined a new sentiment column. To do this, I assumed the reviews which has **4 or higher ** rating as **positive (True in the new dataframe)** and **2 or lower** rating as **negative (False in the new dataframe)**. Also, I did not include the lines that has **neutral** ratings which are equal to **3**. Following that, I splitted the data as training and test sets."},{"metadata":{"trusted":true,"_uuid":"ef4e5b9dac84bbbb9bf3a08b5e63e75a70514dfe","_kg_hide-input":true},"cell_type":"code","source":"# Rating of 4 or higher -> positive, while the ones with \n# Rating of 2 or lower -> negative \n# Rating of 3 -> neutral\ndf = df[df['Rating'] != 3]\ndf['Sentiment'] = df['Rating'] >=4\ndf.head()\n\n# split data\ntrain_data,test_data = train_test_split(df,train_size=0.8,random_state=0)\n# select the columns and \n# prepare data for the models \nX_train = vectorizer.fit_transform(train_data['Review Text'])\ny_train = train_data['Sentiment']\nX_test = vectorizer.transform(test_data['Review Text'])\ny_test = test_data['Sentiment']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6123ca5c04391db3023f31c3363474db1c8afee5"},"cell_type":"markdown","source":"Then, I fitted the models one by one. Since, some of them take too much time, running each of them in different cells is a better choice.   "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Sentiment']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd935dbe4f4fdbd0a721695bffb72c2778b16690"},"cell_type":"markdown","source":"## <span id=\"7\"></span> Logistic Regression"},{"metadata":{"trusted":true,"_uuid":"b78e37c89e02fd1dea22b87509dc871f5ad973c6"},"cell_type":"code","source":"start=dt.datetime.now()\nlr = LogisticRegression()\nlr.fit(X_train,y_train)\nprint('Elapsed time: ',str(dt.datetime.now()-start))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad4bd4a855ddc670eedf280b3a81efa9a57d470e"},"cell_type":"markdown","source":"## <span id=\"8\"></span> Naive Bayes"},{"metadata":{"trusted":true,"_uuid":"4715c54fec338f8017b2f5597490c9a16ce4f101"},"cell_type":"code","source":"start=dt.datetime.now()\nnb = MultinomialNB()\nnb.fit(X_train,y_train)\nprint('Elapsed time: ',str(dt.datetime.now()-start))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"daaf5d10642b2ba0e89846091f7a6b4a1de4252b"},"cell_type":"markdown","source":"## <span id=\"9\"></span> Support Vector Machine (SVM)"},{"metadata":{"trusted":true,"_uuid":"ab7e1fcbe45995e034124b97ae5d2674554abd66"},"cell_type":"code","source":"start=dt.datetime.now()\nsvm = SVC()\nsvm.fit(X_train,y_train)\nprint('Elapsed time: ',str(dt.datetime.now()-start))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"048d88c13016a4f8a39d1427c3eeaf01d8a4f2b9"},"cell_type":"markdown","source":"## <span id=\"10\"></span> Neural Network"},{"metadata":{"trusted":true,"_uuid":"3dfb24752703bcadb607fe5bd43026941b41a65a"},"cell_type":"code","source":"start=dt.datetime.now()\nnn = MLPClassifier()\nnn.fit(X_train,y_train)\nprint('Elapsed time: ',str(dt.datetime.now()-start))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5e0df1e9c4fc2e9b6c00c57d5b8be355be89b7e"},"cell_type":"markdown","source":"## <span id=\"12\"></span> Adding Results to the Dataframe"},{"metadata":{"_uuid":"7550e005914243acf6e7928fe76e3e67cae3ae64"},"cell_type":"markdown","source":"At first, I added the prediction results to my training data. However, if you want to observe the prediction probabilies, you might use the commented out code."},{"metadata":{"trusted":true,"_uuid":"268d92918c01136e0222364060abf37d91422849","_kg_hide-input":true},"cell_type":"code","source":"# define a dataframe for the prediction probablities of the models\n#df1 = train_data.copy()\n#df1['Logistic Regression'] = lr.predict_proba(X_train)[:,1]\n#df1['Naive Bayes'] = nb.predict_proba(X_train)[:,1]\n#df1['SVM'] = svm.decision_function(X_train)\n#df1['Neural Network'] = nn.predict_proba(X_train)[:,1]\n#df1=df1.round(2)\n#df1.head()\n\n# define a dataframe for the predictions\ndf2 = train_data.copy()\ndf2['Logistic Regression'] = lr.predict(X_train)\ndf2['Naive Bayes'] = nb.predict(X_train)\ndf2['SVM'] = svm.predict(X_train)\ndf2['Neural Network'] = nn.predict(X_train)\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint(accuracy_score(df2['Logistic Regression'],df2['Sentiment']))\nprint(accuracy_score(df2['Naive Bayes'],df2['Sentiment']))\nprint(accuracy_score(df2['SVM'],df2['Sentiment']))\nprint(accuracy_score(df2['Neural Network'],df2['Sentiment']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndtr = DecisionTreeClassifier()\ndtr.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_dtr = dtr.predict_proba(X_test)[:,1]\nfpr_dtr,tpr_dtr,_ = roc_curve(y_test,pred_dtr)\nroc_auc_dtr = auc(fpr_dtr,tpr_dtr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(2,2,figsize=(15,10))\naxes[0,1].plot(fpr_dtr, tpr_dtr, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_dtr))\naxes[0,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[0,1].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[0,1].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Decision Tree')\naxes[0,1].legend(loc='lower right', fontsize=13)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ca48e96a1af34602deeed24ee1df8c09b5f0012"},"cell_type":"markdown","source":"## <span id=\"13\"></span> ROC Curves and AUC"},{"metadata":{"trusted":true,"_uuid":"967355c906e983f36af66b7cc3b6fb43f2447e7c","_kg_hide-input":true},"cell_type":"code","source":"pred_lr = lr.predict_proba(X_test)[:,1]\nfpr_lr,tpr_lr,_ = roc_curve(y_test,pred_lr)\nroc_auc_lr = auc(fpr_lr,tpr_lr)\n\npred_nb = nb.predict_proba(X_test)[:,1]\nfpr_nb,tpr_nb,_ = roc_curve(y_test.values,pred_nb)\nroc_auc_nb = auc(fpr_nb,tpr_nb)\n\npred_svm = svm.decision_function(X_test)\nfpr_svm,tpr_svm,_ = roc_curve(y_test.values,pred_svm)\nroc_auc_svm = auc(fpr_svm,tpr_svm)\n\npred_nn = nn.predict_proba(X_test)[:,1]\nfpr_nn,tpr_nn,_ = roc_curve(y_test.values,pred_nn)\nroc_auc_nn = auc(fpr_nn,tpr_nn)\n\nf, axes = plt.subplots(2, 2,figsize=(15,10))\naxes[0,0].plot(fpr_lr, tpr_lr, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_lr))\naxes[0,0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[0,0].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[0,0].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Logistic Regression')\naxes[0,0].legend(loc='lower right', fontsize=13)\n\naxes[0,1].plot(fpr_nb, tpr_nb, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_nb))\naxes[0,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[0,1].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[0,1].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Naive Bayes')\naxes[0,1].legend(loc='lower right', fontsize=13)\n\naxes[1,0].plot(fpr_svm, tpr_svm, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_svm))\naxes[1,0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[1,0].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[1,0].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Support Vector Machine')\naxes[1,0].legend(loc='lower right', fontsize=13)\n\naxes[1,1].plot(fpr_nn, tpr_nn, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_nn))\naxes[1,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[1,1].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[1,1].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Neural Network')\naxes[1,1].legend(loc='lower right', fontsize=13);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ea828d90388d25949f285634db0546ef329d869"},"cell_type":"markdown","source":"## <span id=\"14\"></span> Confusion Matrices"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"b8eb4577a0c1a15ac00b554eebbcbbbd2dbf3ee8"},"cell_type":"code","source":"# preparation for the confusion matrix\nlr_cm=confusion_matrix(y_test.values, lr.predict(X_test))\nnb_cm=confusion_matrix(y_test.values, nb.predict(X_test))\nsvm_cm=confusion_matrix(y_test.values, svm.predict(X_test))\nnn_cm=confusion_matrix(y_test.values, nn.predict(X_test))\n\nplt.figure(figsize=(15,12))\nplt.suptitle(\"Confusion Matrices\",fontsize=24)\n\nplt.subplot(2,2,1)\nplt.title(\"Logistic Regression\")\nsns.heatmap(lr_cm, annot = True, cmap=\"Greens\",cbar=False);\n\nplt.subplot(2,2,2)\nplt.title(\"Naive Bayes\")\nsns.heatmap(nb_cm, annot = True, cmap=\"Greens\",cbar=False);\n\nplt.subplot(2,2,3)\nplt.title(\"Support Vector Machine (SVM)\")\nsns.heatmap(svm_cm, annot = True, cmap=\"Greens\",cbar=False);\n\nplt.subplot(2,2,4)\nplt.title(\"Neural Network\")\nsns.heatmap(nn_cm, annot = True, cmap=\"Greens\",cbar=False);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span id=\"15\"></span> Precision - Recall - F1-Score"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Logistic Regression\")\nprint(mt.classification_report(y_test, lr.predict(X_test)))\nprint(\"\\n Naive Bayes\")\nprint(mt.classification_report(y_test, nb.predict(X_test)))\nprint(\"\\n Support Vector Machine (SVM)\")\nprint(mt.classification_report(y_test, svm.predict(X_test)))\nprint(\"\\n Neural Network\")\nprint(mt.classification_report(y_test, nn.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}