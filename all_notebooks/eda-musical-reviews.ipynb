{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pandas_profiling import ProfileReport\nimport plotly.express as px\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# import joypy\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nimport seaborn as sns; sns.set()\n%matplotlib inline\n\nfrom sklearn.datasets import load_breast_cancer\n\n# garbage\nimport gc; gc.enable()\n\n# warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# modeling\nfrom sklearn.naive_bayes import GaussianNB\n# from sklego.mixture import GMMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score, make_scorer\nfrom sklearn.model_selection import GridSearchCV\n# from sklego.meta import Thresholder\nfrom sklearn.pipeline import make_pipeline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"instruments = pd.read_json('/kaggle/input/amazon-music-reviews/Musical_Instruments_5.json', lines = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews = pd.read_csv('/kaggle/input/amazon-music-reviews/Musical_instruments_reviews.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert reviews.shape == instruments.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_profile = ProfileReport(reviews, title='Pandas Profiling Report', html={'style':{'full_width':True}})\n# train_profile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews.overall.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig = px.histogram(reviews, x=\"overall\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"fairly imbalanced data with approx. 87% being 4 and 5 stars","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Looks like loging the target may normalize the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews['log_overall'] = np.log1p(reviews['overall']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.histogram(reviews, x=\"log_overall\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well that didnt work","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#check amount of reviewers\nreviews.reviewerID.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"a lot of repeat reviewer IDs\n\nlets check the most prolific","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews.reviewerID.value_counts(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Also interesting to note that the lowest amount of reviews is 5","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews[reviews.reviewerID == 'ADH0O8UVJOT10']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews.groupby('reviewerID')['overall'].agg(['mean','count']).sort_values(by='mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews[reviews.reviewerID == 'A1B3CNORXB1USI']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = reviews['overall']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import wordnet\nimport string\nfrom nltk import pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import WhitespaceTokenizer\nfrom nltk.stem import WordNetLemmatizer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nltk is natral language tool.\n*TODO* adapt code to use spacy package\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_wordnet_pos(pos_tag):\n    if pos_tag.startswith('J'):\n        return wordnet.ADJ\n    elif pos_tag.startswith('V'):\n        return wordnet.VERB\n    elif pos_tag.startswith('N'):\n        return wordnet.NOUN\n    elif pos_tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n\n    # lower text\n    text = text.lower()\n    # tokenize text and remove puncutation\n    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n    # remove words that contain numbers\n    text = [word for word in text if not any(c.isdigit() for c in word)]\n\n    # remove stop words\n    stop = stopwords.words('english')\n    text = [x for x in text if x not in stop]\n    # remove empty tokens\n    text = [t for t in text if len(t) > 0]\n    # pos tag text\n    pos_tags = pos_tag(text)\n    # lemmatize text\n    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n    # remove words with only one letter\n    text = [t for t in text if len(t) > 1]\n    # join all\n    text = \" \".join(text)\n    return(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews[\"reviewText\"] = reviews[\"reviewText\"].astype(str)\nreviews['clean_review'] = reviews[\"reviewText\"].apply(lambda x: clean_text(x))\nreviews","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nsid = SentimentIntensityAnalyzer()\nreviews[\"sentiments\"] = reviews['clean_review'].apply(lambda x: sid.polarity_scores(x))\nreviews_df = pd.concat([reviews.drop(['sentiments'], axis=1), reviews['sentiments'].apply(pd.Series)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# add number of characters column\nreviews[\"nb_chars\"] = reviews[\"reviewText\"].apply(lambda x: len(x))\n\n# add number of words column\nreviews[\"nb_words\"] = reviews[\"reviewText\"].apply(lambda x: len(x.split(\" \")))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install gensim\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# create doc2vec vector columns\nfrom gensim.test.utils import common_texts\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\n\ndocuments = [TaggedDocument(doc, [i]) for i, doc in enumerate(reviews_df[\"clean_review\"].apply(lambda x: x.split(\" \")))]\n\n# train a Doc2Vec model with our text data\nmodel = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n\n# transform each document into a vector data\ndoc2vec_df = reviews_df[\"clean_review\"].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(pd.Series)\ndoc2vec_df.columns = [\"doc2vec_vector_\" + str(x) for x in doc2vec_df.columns]\nreviews_df = pd.concat([reviews_df, doc2vec_df], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# t_profile = ProfileReport(reviews_df, title='Pandas Profiling Report', html={'style':{'full_width':True}})\n# t_profile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(min_df = 10)\ntfidf_result = tfidf.fit_transform(reviews_df[\"clean_review\"]).toarray()\ntfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())\ntfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\ntfidf_df.index = reviews_df.index\nreviews_df = pd.concat([reviews_df, tfidf_df], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reviews_df.columns[:11]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ignore_cols = reviews_df.columns[:11].tolist()\nused_cols = [c for c in reviews_df.columns.tolist() if c not in ignore_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, train_test_split\nfrom xgboost import XGBRFRegressor\nfrom sklearn.linear_model import LinearRegression, MultiTaskElasticNet\nfrom sklearn.ensemble import RandomForestClassifier\nimport sklearn\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBRFRegressor()\nlr = LinearRegression()\nforest = RandomForestClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"used_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(sklearn.metrics.SCORERS.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_xgb = cross_val_score(xgb,reviews_df[used_cols], reviews_df['overall'], cv=5, scoring='neg_median_absolute_error')\nscores_forest = cross_val_score(forest,reviews_df[used_cols], reviews_df['overall'], cv=5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(scores_xgb)\nprint(scores_forest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_lr = cross_val_score(lr,reviews_df[used_cols], reviews_df['overall'], cv=5, scoring= 'neg_median_absolute_error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_lr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(reviews_df[used_cols], reviews_df['overall'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.fit(X_train,y_train)\nforest.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_preds = xgb.predict(X_test)\nforest_preds = forest.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in [xgb_preds,forest_preds]:\n    print(i.mean(),\n          i.std(),\n          i.min(),\n          i.max())\n   \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### With this imbalanced dataset both algorithms favor 5 star reviews with little variation ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_test.mean(),\n        y_test.std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(xgb_preds - y_test).sum()/len(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(forest_preds - y_test).sum()/len(y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### above i take the difference of the predicted values and the true values sum them and divide by the length of the test to get an average error ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The xgbreggressor seems to do better as it isn't constrained to discrete values \nLets try a confusion matrix to see how that looks","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import plot_confusion_matrix\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titles_options = [(\"Confusion matrix, without normalization\", None),\n                  (\"Normalized confusion matrix\", 'true')]\nclass_names = y_test.unique()\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(forest, X_test, y_test,\n                                 display_labels=class_names,\n                                 cmap=plt.cm.Blues,\n                                 normalize=normalize)\n    disp.ax_.set_title(title)\n\n    print(title)\n    print(disp.confusion_matrix)\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ya the imbalanced dataset really hurt the random forest \nnext set is to try SMOTE or another way of compensating with the imbalanced data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}