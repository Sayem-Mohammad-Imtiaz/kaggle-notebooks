{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"8eac5409-aa5c-4578-a111-2bf8ce7dcee8"},"source":"# Classifying by category with Logistic Regression (0.9473)\n\n## Summary\n\nWe have used **Naive Bayes** and **Logistic regression models** to predict the category of the news. These are fast models to train and to execute and we have obtained a very good accuracy with them. The best one has been the Logistic Regression one which provides an accuracy of **0.9473** and an average f1-score of **0.95**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c69e9a4-de65-a0eb-dbe8-081d70679e13"},"outputs":[],"source":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(123456)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b761c81a-b974-07bb-1134-abd5067cb9b7"},"outputs":[],"source":"dataset = pd.read_csv(\"../input/uci-news-aggregator.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f91c9fa5-18f7-3fb0-1cbe-960c8e9f661a"},"outputs":[],"source":"dataset.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e0e11dee-7f0d-c6f8-4409-1f36da96c76e"},"outputs":[],"source":"dataset['CATEGORY'].unique()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"429356f1-f83d-8f66-bf26-559143c83ca6"},"outputs":[],"source":"dataset['CATEGORY'].value_counts().plot(kind=\"bar\")\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c3f08e3b-8c4b-5bc2-84b9-d1c9490cd03d"},"outputs":[],"source":"import re\nimport string\n\ndef clean_text(s):\n    s = s.lower()\n    for ch in string.punctuation:                                                                                                     \n        s = s.replace(ch, \" \") \n    s = re.sub(\"[0-9]+\", \"||DIG||\",s)\n    s = re.sub(' +',' ', s)        \n    return s\n\ndataset['TEXT'] = [clean_text(s) for s in dataset['TITLE']]"},{"cell_type":"markdown","metadata":{"_cell_guid":"0083f581-5c81-8b86-e754-e6ad1f48f6f8"},"source":"## Naive bayes model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b57168e7-b80a-f986-d442-4071581d438d"},"outputs":[],"source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import cross_val_score\n\n# pull the data into vectors\nvectorizer = CountVectorizer()\nx = vectorizer.fit_transform(dataset['TEXT'])\n\n# for Tfidf (we have tried and the results aren't better)\n#tfidf = TfidfVectorizer()\n#x = tfidf.fit_transform(dataset['TEXT'].values)\n\nencoder = LabelEncoder()\ny = encoder.fit_transform(dataset['CATEGORY'])\n\n# split into train and test sets\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n\n# take a look at the shape of each of these\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"019ea10b-caef-5fba-9ba7-47a4720ec2a1"},"outputs":[],"source":"%%time \n\nnb = MultinomialNB()\nnb.fit(x_train, y_train)"},{"cell_type":"markdown","metadata":{"_cell_guid":"d81c00f9-024b-ac00-5ea1-ed37db42a76b"},"source":"Let's see cross validation:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8353cc3e-c980-300d-adb6-a5b40c58f154"},"outputs":[],"source":"%%time\n\nresults_nb_cv = cross_val_score(nb, x_train, y_train, cv=10)\nprint(results_nb_cv.mean())"},{"cell_type":"markdown","metadata":{"_cell_guid":"01bc622d-a5d9-f1e2-43df-526c889f4301"},"source":"Test data accuracy is very near to cross validation accuracy which is ok:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4d1807d3-3355-3232-5560-67bd89bd225c"},"outputs":[],"source":"nb.score(x_test, y_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c928ead3-44a7-b62b-d33b-93f67105ef7c"},"outputs":[],"source":"x_test_pred = nb.predict(x_test)\nconfusion_matrix(y_test, x_test_pred)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0812f4a2-1ddd-aeac-f906-5b8582b3c836"},"outputs":[],"source":"print(classification_report(y_test, x_test_pred, target_names=encoder.classes_))"},{"cell_type":"markdown","metadata":{"_cell_guid":"7bb19b15-b139-9046-28ff-9beab4cd090e"},"source":"Function to predict category from a direct tittle:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"63618516-a89e-88d3-ed2c-256b40cbf934"},"outputs":[],"source":"def predict_cat(title):\n    cat_names = {'b' : 'business', 't' : 'science and technology', 'e' : 'entertainment', 'm' : 'health'}\n    cod = nb.predict(vectorizer.transform([title]))\n    return cat_names[encoder.inverse_transform(cod)[0]]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fa78f38e-ba92-ffb0-0021-f5eeffb3b67b"},"outputs":[],"source":"predict_cat(\"the economy goes up\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"c3fe658c-9257-d419-9449-c785bed0ba47"},"source":"## Logistic regression model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"edc50ba9-aa37-5eea-6ea2-473901cdb4e7"},"outputs":[],"source":"%%time \n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsRestClassifier\n\n# Instantiate the classifier: clf\nclf = OneVsRestClassifier(LogisticRegression())\n\n# Fit the classifier to the training data\nclf.fit(x_train, y_train)\n\n# Print the accuracy\nprint(\"Accuracy: {}\".format(clf.score(x_test, y_test)))"},{"cell_type":"markdown","metadata":{"_cell_guid":"834f47af-6042-0793-c3c1-4ad4f1acf0bf"},"source":"Let's see cross validation accuracy. It took a lot and killed the kernel, so we omit here. The result was very close to the previous test data accuracy"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b2aa6e21-6521-f375-2400-d1c7104a93da"},"outputs":[],"source":"#%%time\n\n#results_clf_cv = cross_val_score(clf, x_train, y_train, cv=10)\n#print(results_clf_cv.mean())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"12245c1c-71ef-f725-d485-75a2373e3700"},"outputs":[],"source":"x_test_clv_pred = clf.predict(x_test)\nconfusion_matrix(y_test, x_test_clv_pred)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"85e2029e-cda6-501f-8cf6-e57a9959c92b"},"outputs":[],"source":"print(classification_report(y_test, x_test_clv_pred, target_names=encoder.classes_))"},{"cell_type":"markdown","metadata":{"_cell_guid":"481716e9-a86c-9f60-c92c-ff814eef50f2"},"source":"There is a high correlation between Logistic regression and naive bayes model."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d18e01ab-7b09-7f14-6d1a-b70b565f3435"},"outputs":[],"source":"clf_pred = clf.predict(x)\nnp_pred = nb.predict(x)\n\nmodels_correlation = np.corrcoef(clf_pred, np_pred)\nmodels_correlation[0,1]"},{"cell_type":"markdown","metadata":{"_cell_guid":"7ed9e3f4-93b8-1e3b-2073-aa4326be045e"},"source":"##Â Conclusion\n\nNaive Bayes and Logistic regression are fast and provide good accuracy.  The faster is Naive Bayes. The best accuracy is obtained with the Logistic Regression model which provides an accuracy of **0.9473** and an average f1-score of **0.95**"},{"cell_type":"markdown","metadata":{"_cell_guid":"49d3ed63-8a87-69be-6964-91b13707dbcf"},"source":"## Reference\n\n- [Classifying News Headlines with scikit-learn](https://www.kaggle.com/kinguistics/classifying-news-headlines-with-scikit-learn)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}