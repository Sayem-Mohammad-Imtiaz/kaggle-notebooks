{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop, Adam, SGD\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Input, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom shutil import copyfile, rmtree\nfrom timeit import default_timer as timer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Вспомогательная функция для доступа к файлам относительно корня директория с данными.\nINPUT_ROOT = \"../input/gtsrb-german-traffic-sign\"\ndef from_input(path):\n    return os.path.join(INPUT_ROOT, path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Загружаем таблицу с данными о данных.\ntrain_info = pd.read_csv(from_input(\"Train.csv\"))\ntrain_info.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим как выглядят наши данные.\ntrain_info.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# сколько примеров в каждом из классов\ntrain_info.groupby('ClassId')['ClassId'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_info =  pd.read_csv(from_input(\"Test.csv\"))\ntest_info.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_info.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# сколько примеров в каждом из классов\ntest_info.groupby('ClassId')['ClassId'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n# Показываем изображения в сетке 6х8.\nnrows = 8\nncols = 6\n\npic_offset = 0 # Чтобы итерировать по изображениям каждый раз когда запустим код ниже.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images(offset):\n    fig = plt.gcf()\n    fig.set_size_inches(ncols*3, nrows*3)\n\n    for i in range(43):\n        # subplot индексы начинаются с 1\n        sp = plt.subplot(nrows, ncols, i + 1)\n        sp.axis('Off')\n        subdir = os.path.join(from_input('train'), str(i))\n        files = os.listdir(subdir)\n        img_path = os.path.join(subdir, files[offset % len(files)])\n        img = mpimg.imread(img_path)\n        #print(img.shape)\n        plt.imshow(img)\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_images(pic_offset)\npic_offset += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Загрузка и подготовка данных:"},{"metadata":{"trusted":true},"cell_type":"code","source":"TARGET_SIZE = (40, 40) # изображения будут изменены до этого размера\nBATCH_SIZE=300","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paths = train_info['Path'].values\ny_train = train_info['ClassId'].values\n\nindices = np.arange(y_train.shape[0])\nrandgen = random.Random(62)\nrandgen.shuffle(indices)\n\npaths = paths[indices]\ny_train = y_train[indices]\ny_train = to_categorical(y_train, 43)\n\ndata=[]\n\nfor i, f in enumerate(paths):\n    print('\\rLoading data {0:.1f}%...'.format((i / len(paths)) * 100), end = '\\r')\n    image = Image.open(os.path.join(from_input('train'), f.replace('Train/', '')))\n    resized_image = image.resize(TARGET_SIZE)\n    data.append(np.array(resized_image))\n\nX_train = np.array(data).astype('float32') / 255.0\n\nprint('Data loaded.              ')\n\ntrain_datagen = ImageDataGenerator()\ntrain_generator = train_datagen.flow(X_train,\n                                    y_train,\n                                    batch_size=BATCH_SIZE,\n                                    shuffle=True,\n                                    seed=17)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paths = test_info['Path'].values\ny_test = test_info['ClassId'].values\ny_test = to_categorical(y_test, 43)\n\ndata=[]\n\nfor i, f in enumerate(paths):\n    print('\\rLoading data {0:.1f}%...'.format((i / len(paths)) * 100), end = '\\r')\n    image = Image.open(os.path.join(from_input('test'), f.replace('Test/', '')))\n    resized_image = image.resize(TARGET_SIZE)\n    data.append(np.array(resized_image))\n\nprint('Data loaded.              ')\n\nX_test = np.array(data).astype('float32') / 255.0 \n\ntest_datagen = ImageDataGenerator()\ntest_generator = test_datagen.flow(X_test,\n                                    y_test,\n                                    batch_size=BATCH_SIZE,\n                                    shuffle=False,\n                                    seed=17)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Некоторые вспомогательные функции:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot(history):\n    %matplotlib inline\n\n    import matplotlib.image  as mpimg\n    import matplotlib.pyplot as plt\n\n    acc=history.history['acc']\n    loss=history.history['loss']\n    epochs=range(len(acc))\n\n    plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n    plt.title('Training accuracy')\n    plt.xlabel('Epoch')\n    plt.figure()\n\n    plt.plot(epochs, loss, 'r', \"Training Loss\")\n    plt.xlabel('Epoch')\n    plt.title('Training loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_layers(model):\n    print('Name\\tOutput shape\\tActivation\\tInitializer')\n    for l in model.layers:\n        print('{0}({1})\\t{2}\\t{3}\\t{4}'\n            .format(l.name,\n              l.__class__.__name__,\n              l.output_shape,\n              l.activation.__name__ if hasattr(l, 'activation') else '<none>',\n              l.kernel_initializer.__class__.__name__ if hasattr(l, 'kernel_initializer') else '<none>'))\n\n\ndef custom_summary(model):\n    model.summary()\n    show_layers(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"VERBOSE=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, kernel_initializer, optimizer, epochs):\n    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n    start_time = timer()\n    history = model.fit_generator(train_generator,\n                        epochs=epochs,\n                        verbose=VERBOSE,\n                        steps_per_epoch= round(X_train.shape[0] / BATCH_SIZE))\n    end_time = timer()\n    \n    custom_summary(model)\n    print('==============================')\n    print('Initializer: ', kernel_initializer)\n    print('Optimizer: ', optimizer.__class__.__name__)\n    print('Learning rate: ', optimizer.get_config()['learning_rate'])\n    print('Epochs: ', epochs)\n    print('==============================')\n    print('Trained in {0:.2f} minutes'.format((end_time - start_time) / 60))\n    \n    acc=history.history['acc'][-1]\n    test_acc = model.evaluate_generator(test_generator)[1]\n    \n    print('Results at the end of training: acc={1:.02f}%, test_acc={2:.02f}%'\n          .format(i, acc*100, test_acc*100))\n\n    plot(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Тренируем сети:"},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Попробуем добавлять слои:"},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Не стоит добавлять больше одинаковых слоёв. Попробуем изменять количество фильтров."},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Попробуем обратный подход, должен дать получше результаты."},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Стало лучше. Попробуем уменьшить и увеличить количество фильтров."},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Попробуем увеличить размер ядра в первом свёрточном слое, так как тут размер карты признаков достаточно большой."},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(256, (5, 5), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(256, (7, 7), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Попробуем использовать тангенс гиперболический, но в первом слое оставим relu что бороться с исчезающим градиентом."},{"metadata":{"trusted":true},"cell_type":"code","source":"kernel_initializer='glorot_uniform'\noptimizer=Adam(learning_rate=0.0005)\nepochs=20\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(256, (7, 7), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(512, (3, 3), activation='tanh', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(1024, (3, 3), activation='tanh', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, kernel_initializer, optimizer, epochs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Результаты очевидно значительно хуже по сравнению с тренировочнoй выборкой, но тем не менее хорошие. Причин может быть много, разница между тестовыми и тренировочными данными может быть большой. Может стоит добавлять регуляризацию, Dropout, а также искусственно изменять и добавлять данные в тренировочную выборку (augmentation)."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}