{"cells":[{"metadata":{"_uuid":"867e52da-f35c-4f96-8689-078ee401d85a","_cell_guid":"614e4268-249c-4c5c-bd27-1872b8229a48","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport sys\nfrom tqdm import tqdm\nimport pathlib\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2\n\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import fbeta_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4abf1a1b-4977-4e94-8537-596ca9ecd6dd","_cell_guid":"38e64de4-9ea3-442a-ba30-bc880f5b6f0a","trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input/planets-dataset'):\n    for filename in filenames:\n        os.path.join(dirname, filename)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8bd5523-0f6b-41dd-a26b-b65bd7c13489","_cell_guid":"507562e5-7101-438e-b004-ebe7df1bdd7b","trusted":true},"cell_type":"code","source":"!ls /kaggle/input/planets-dataset","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30fa36d4-c30e-4c48-a2a2-53cce77838c6","_cell_guid":"984cc1e9-3bb3-45dc-808e-8f767187dc47","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/planets-dataset/planet/planet/train_classes.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/planets-dataset/planet/planet/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0334debe-2ad4-429f-901a-d3e11010e1b1","_cell_guid":"84f0b23c-6ae8-4aae-a40f-28e812755641","trusted":true},"cell_type":"markdown","source":"# Data Exploration"},{"metadata":{"_uuid":"147b907e-336f-45e7-a564-081bd01d3679","_cell_guid":"b4287878-baa7-4b5e-b7ac-7192aeb0055e","trusted":true},"cell_type":"code","source":"train_classes = train_df[:]['tags']\n\nno_classes = len(train_classes.unique())\nprint(f'Given {len(train_classes)} samples, there are {no_classes} unique classes.', '\\n')\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the tags column to get the unique labels\nflatten = lambda l: [item for sublist in l for item in sublist]\nlabels = list(set(flatten([l.split(' ') for l in train_df['tags'].values])))\n\n# Mapping the label value counts\nlabel_map = {l: i for i, l in enumerate(labels)}\nprint(f'labels = {labels},\\n length = {len(labels)}', '\\n')\n\nprint(f'label_map = {label_map},\\n length = {len(label_map)}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9feb0a7f-31fd-403b-a007-97de055ff20e","_cell_guid":"10698f16-ddbb-44c9-b9a2-9b1d23d0ede3","trusted":true},"cell_type":"code","source":"keys = list(label_map.keys())\nvalues = list(label_map.values())\nlabels_df = pd.DataFrame({'labels':keys, 'freq':values})\nlabels_df = labels_df.sort_values('freq')\n\nplt.rcParams['figure.figsize']=(14,5)\nplt.xticks(rotation=90)\nplt.bar('labels', 'freq', data=labels_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"defd5af3-69a4-4f5c-919f-1a3476031e5e","_cell_guid":"9e56dd1b-8b0f-44a7-bbd2-494bfd145330","trusted":true},"cell_type":"code","source":"new_style = {'grid': False}\nplt.rc('axes', **new_style)\n_, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(15, 15))\ni = 0\nfor f, tags in train_df[:9].values:\n    img = cv2.imread('/kaggle/input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(f))\n    ax[i // 3, i % 3].imshow(img)\n    ax[i // 3, i % 3].set_title('{} - {}'.format(f, tags))\n  \n    i += 1\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0741d9b-b4b6-49eb-89bd-29aad579589b","_cell_guid":"5ecacb77-db46-48b6-94f8-56b5217d9463","trusted":true},"cell_type":"raw","source":"Data Preprocessing "},{"metadata":{"_uuid":"44b71524-5de9-435d-971c-80077a7a35b2","_cell_guid":"24c92248-ca52-4397-a509-ccd7c6b92478","trusted":true},"cell_type":"markdown","source":"Since there two file formats (.jpg and .csv) for the train and test sets, after loading the csv, the jpegs will be loaded through their paths, to ensure that both file types are of the same size."},{"metadata":{"_uuid":"a699dd2c-8123-48a8-9d63-7073c41bcce1","_cell_guid":"f7d2bfc5-9790-4396-bc79-caa6d303a5c0","trusted":true},"cell_type":"code","source":"# Load the train-jpg file path\n\ntrain_img_dir = pathlib.Path('/kaggle/input/planets-dataset/planet/planet/train-jpg')\n\ntrain_img_path = sorted(list(train_img_dir.glob('*.jpg')))\n\ntrain_img_count = len(train_img_path)\nprint(train_img_count)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d812ec3-ed2f-49b1-b0b2-ff52420a79f0","_cell_guid":"288a145a-d54d-41b9-84f2-4d357a246bc7","trusted":true},"cell_type":"code","source":"# first test jpg file path\ntest_img_dir = pathlib.Path('/kaggle/input/planets-dataset/planet/planet/test-jpg')\n\ntest_img_path = sorted(list(test_img_dir.glob('*.jpg')))\n\ntest_img_count = len(test_img_path)\nprint(test_img_count)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f059eea1-7c07-441c-be3f-0d27a22f318f","_cell_guid":"24edbfcd-157b-495e-92b5-ad26a055b295","trusted":true},"cell_type":"code","source":"# second test jpg file path\n\ntest_add_img_dir = pathlib.Path('/kaggle/input/planets-dataset/test-jpg-additional')\n\ntest_add_img_path = sorted(list(test_add_img_dir.glob('*/*.jpg')))\n\ntest_add_img_count = len(test_add_img_path)\nprint(test_add_img_count)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1bb29bfb-0aa8-4b3d-b181-0c9d580e5f54","_cell_guid":"a8e71760-8774-4dc7-ab03-881aba2c6689","trusted":true},"cell_type":"code","source":"# Ensure the number of jpg images are equal to the number of samples in the csv file for each data set\n\n# train\nassert len(train_img_path) == len(train_df)\n\n# test\nassert len(test_img_path)+len(test_add_img_path) == len(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training a Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size = 64\ninput_channels = 3\n\nbatch_size = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = []\ny_train = []\n\nfor f, tags in tqdm(train_df.values, miniters=1000):\n    img = cv2.imread('/kaggle/input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(f))\n    img = cv2.resize(img, (input_size, input_size))\n    targets = np.zeros(17)\n    for t in tags.split(' '):\n        targets[label_map[t]] = 1\n    x_train.append(img)\n    y_train.append(targets)\n        \nx_train = np.array(x_train, np.float32)\ny_train = np.array(y_train, np.uint8)\n\nprint(x_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = []\n\ntest_jpg_dir = '/kaggle/input/planets-dataset/planet/planet/test-jpg'\ntest_image_names = os.listdir(test_jpg_dir)\n\nn_test = len(test_image_names)\ntest_classes = test_df.iloc[:n_test, :]\nadd_classes = test_df.iloc[n_test:, :]\n\ntest_jpg_add_dir = '/kaggle/input/planets-dataset/test-jpg-additional/test-jpg-additional'\ntest_add_image_names = os.listdir(test_jpg_add_dir)\n\nfor img_name, _ in tqdm(test_classes.values, miniters=1000):\n    img = cv2.imread(test_jpg_dir + '/{}.jpg'.format(img_name))\n    x_test.append(cv2.resize(img, (64, 64)))\n    \nfor img_name, _ in tqdm(add_classes.values, miniters=1000):\n    img = cv2.imread(test_jpg_add_dir + '/{}.jpg'.format(img_name))\n    x_test.append(cv2.resize(img, (64, 64)))\n\nx_test = np.array(x_test, np.float32)\nprint(x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b27fa03-f388-4d96-a0fb-840eb58ac0ee","_cell_guid":"570f62fc-d591-445b-9c65-d3073cb1a14f","trusted":true},"cell_type":"code","source":"# split the train data into train and validation data sets\nX_train = x_train[ :33000]\nY_train = y_train[ :33000]\n\nX_valid = x_train[33000: ]\nY_valid = y_train[33000: ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **The Model Architecture**"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = VGG16(include_top=False,\n                   weights='imagenet',\n                   input_shape=(input_size, input_size, input_channels))\n\nmodel = Sequential()\nmodel.add(BatchNormalization(input_shape=(input_size, input_size, input_channels)))\n\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(17, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import SGD\nopt  = SGD(lr=0.01)\n\nmodel.compile(loss='binary_crossentropy',optimizer=opt, metrics=['accuracy'])\n    \ncallbacks = [EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n                ModelCheckpoint(filepath='weights/best_weights',\n                                 save_best_only=True,\n                                 save_weights_only=True)]\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x=X_train, y=Y_train, validation_data=(X_valid, Y_valid),\n                  batch_size=batch_size,verbose=2, epochs=15,callbacks=callbacks,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Model Evaluation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"p_valid = model.predict(X_valid, batch_size = batch_size, verbose=1)\n\nprint(fbeta_score(Y_valid, np.array(p_valid) > 0.18, beta=2, average='samples'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Prediction on Test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = []\np_test = model.predict(x_test, batch_size=batch_size, verbose=2)\ny_pred.append(p_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = np.array(y_pred[0])\nfor i in range(1, len(y_pred)):\n    result += np.array(y_pred[i])\nresult = pd.DataFrame(result, columns=labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Translating the probability predictions to the unique labels\npreds = []\nfor i in tqdm(range(result.shape[0]), miniters=1000):\n    a = result.loc[[i]]\n    a = a.apply(lambda x: x>0.2, axis=1)\n    a = a.transpose()\n    a = a.loc[a[i] == True]\n    ' '.join(list(a.index))\n    preds.append(' '.join(list(a.index)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing the tags columns with the predicted labels\ntest_df['tags'] = preds\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting the dataframe to a csv file for submission\ntest_df.to_csv('amazon_sample_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}