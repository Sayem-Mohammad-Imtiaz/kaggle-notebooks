{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport shutil\n\n# helpful character encoding module\nimport chardet\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-16T15:29:38.416691Z","iopub.execute_input":"2021-07-16T15:29:38.417092Z","iopub.status.idle":"2021-07-16T15:29:38.428241Z","shell.execute_reply.started":"2021-07-16T15:29:38.417055Z","shell.execute_reply":"2021-07-16T15:29:38.427417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# This is my attempt at the character decoding challenge from the Data Cleaning course. \n\n## I am a learner at python so if anyone has any suggestions as to how I can reduce my code length, (constructive!) criticism regarding my approach, or advice on how better to face this problem, please let me know!","metadata":{}},{"cell_type":"markdown","source":"# 1. Read in metadata to obtain file names","metadata":{}},{"cell_type":"code","source":"titles = pd.read_csv(\"/kaggle/input/character-encoding-examples/file_guide.csv\")\ntitles","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:29:38.430456Z","iopub.execute_input":"2021-07-16T15:29:38.43084Z","iopub.status.idle":"2021-07-16T15:29:38.469856Z","shell.execute_reply.started":"2021-07-16T15:29:38.430801Z","shell.execute_reply":"2021-07-16T15:29:38.468791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# 2. Create array of encoding estimations using chardet","metadata":{}},{"cell_type":"code","source":"encoding_array = []\nfor i in titles['File']:\n    src = '/kaggle/input/character-encoding-examples/' + str(i)\n    with open(src,'rb') as rawdata:\n        result = chardet.detect(rawdata.read())\n        encoding_array.append(result)\nprint(encoding_array)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:29:38.471815Z","iopub.execute_input":"2021-07-16T15:29:38.472097Z","iopub.status.idle":"2021-07-16T15:29:39.753501Z","shell.execute_reply.started":"2021-07-16T15:29:38.47207Z","shell.execute_reply":"2021-07-16T15:29:39.752531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Create forloop to decode each document based on the estimated encoding from previous step and encode in utf8","metadata":{}},{"cell_type":"code","source":"\n# 'utf8-'+ titles['File'][0]\nfor i in range(0,len(titles['File'])):\n    src = '/kaggle/input/character-encoding-examples/' + str(titles['File'][i])\n    with open(src,'rb') as rawdata:\n        dest = 'utf8-' + str(titles['File'][i])\n        with open(dest,'wb') as file:\n            file.write(rawdata.read().decode(encoding_array[i]['encoding']).encode())\n\n# dst = \"/kaggle/working/olaf_Utf8.txt\"\n# shutil.copyfile(src,dst)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:29:39.755178Z","iopub.execute_input":"2021-07-16T15:29:39.755803Z","iopub.status.idle":"2021-07-16T15:29:39.771296Z","shell.execute_reply.started":"2021-07-16T15:29:39.755758Z","shell.execute_reply":"2021-07-16T15:29:39.770541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Check directory to confirm ","metadata":{}},{"cell_type":"code","source":"path = r\"/kaggle/working/\"\nencoded_file_names = []\nfor files in os.listdir(path):\n    if (os.path.isfile(os.path.join(path, files))) & (files.endswith('.txt')):\n        encoded_file_names.append(files)\nprint(encoded_file_names)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:29:39.772819Z","iopub.execute_input":"2021-07-16T15:29:39.773398Z","iopub.status.idle":"2021-07-16T15:29:39.780831Z","shell.execute_reply.started":"2021-07-16T15:29:39.773353Z","shell.execute_reply":"2021-07-16T15:29:39.780056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Assess whether the process has been successful","metadata":{}},{"cell_type":"code","source":"array_encoded = []\nfor i in encoded_file_names:\n    src = path + i\n    with open(src,'rb') as rawdata:\n        result = chardet.detect(rawdata.read())\n        array_encoded.append(result)\nprint(array_encoded)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T15:29:39.781921Z","iopub.execute_input":"2021-07-16T15:29:39.782353Z","iopub.status.idle":"2021-07-16T15:29:40.886956Z","shell.execute_reply.started":"2021-07-16T15:29:39.782308Z","shell.execute_reply":"2021-07-16T15:29:40.885913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encoding appears to have been successful in all cases except 'Harper's round table.'\n### Why is this?","metadata":{}}]}