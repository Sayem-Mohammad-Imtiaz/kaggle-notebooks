{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import time\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\n\nimport keras\nfrom keras.models import Model\nfrom keras.layers import *\nfrom keras import optimizers\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# mnist data\ndf_train = pd.read_csv('../input/mnist_train.csv')\ndf_test = pd.read_csv('../input/mnist_test.csv')\n\n#Normalization\nX_train = df_train.iloc[:, 1:785]\nX_train = X_train.values.astype('float32')/255.\noutput_X_train = X_train.reshape(-1,28,28,1)\n\nX_test = df_test.iloc[:, 1:785]\nX_test = X_test.values.astype('float32')/255.\noutput_X_test = X_test.reshape(-1,28,28,1)\n\nprint(X_train.shape, X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encoder\nencoder_inputs = Input(shape = (28,28,1))\n \nconv1 = Conv2D(16, (3,3), activation = 'relu', padding = \"SAME\")(encoder_inputs)\npool1 = MaxPooling2D(pool_size = (2,2), strides = 2)(conv1)\nconv2 = Conv2D(32, (3,3), activation = 'relu', padding = \"SAME\")(pool1)\npool2 = MaxPooling2D(pool_size = (2,2), strides = 2)(conv2)\nflat = Flatten()(pool2)\n \nencoder_outputs = Dense(32, activation = 'relu')(flat)\n\n#sparsity constraint\n#enocder_outputs = Dense(32, activation = 'relu', activity_regularizer=regularizers.l1(10e-5))(flat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#AE decoder\ndense_layer_d = Dense(7*7*32, activation = 'relu')(encoder_outputs)\noutput_from_d = Reshape((7,7,32))(dense_layer_d)\nconv1_1 = Conv2D(32, (3,3), activation = 'relu', padding = \"SAME\")(output_from_d)\nupsampling_1 = Conv2DTranspose(32, 3, padding='same', activation='relu', strides=(2, 2))(conv1_1)\nupsampling_2 = Conv2DTranspose(16, 3, padding='same', activation='relu', strides=(2, 2))(upsampling_1)\ndecoded_outputs = Conv2DTranspose(1, 3, padding='same', activation='relu')(upsampling_2)\n\n#AE\nautoencoder = Model(encoder_inputs, decoded_outputs)\n\nm = 256\nn_epoch = 10\nautoencoder.compile(optimizer='adam', loss='binary_crossentropy')\nautoencoder.fit(output_X_train,output_X_train, epochs=n_epoch, batch_size=m, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_imgs = autoencoder.predict(output_X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_imgs.shape)\nimport matplotlib.pyplot as plt\n\nn = 10  # how many digits we will display\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i + 1)\n    plt.imshow(output_X_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    ax = plt.subplot(2, n, i + 1 + n)\n    plt.imshow(test_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#VAE\ninput_to_z = Dense(32, activation = 'relu')(flat)\n\nlatent_dim = 2 # dimension of latent variable\nmu = Dense(latent_dim, name='mu')(input_to_z)\nsigma = Dense(latent_dim, name='log_var')(input_to_z)\n \nencoder_vae = Model(encoder_inputs, mu)\n\n# create latent distribution function and generate vectors\ndef sampling(args):\n    mu, sigma = args\n    epsilon = K.random_normal(shape=(K.shape(mu)[0], latent_dim),\n                              mean=0., stddev=1.)\n    return mu + K.exp(sigma) * epsilon\n \nz = Lambda(sampling)([mu, sigma])\n\n#create decoder network which is reverse of encoder\ndecoder_inputs = Input(K.int_shape(z)[1:])\ndense_layer_d = Dense(7*7*32, activation = 'relu')(decoder_inputs)\noutput_from_z_d = Reshape((7,7,32))(dense_layer_d)\ntrans1_d = Conv2DTranspose(32, 3, padding='same', activation='relu', strides=(2, 2))(output_from_z_d)\ntrans1_1_d = Conv2DTranspose(16, 3, padding='same', activation='relu', strides=(2, 2))(trans1_d)\ntrans2_d = Conv2DTranspose(1, 3, padding='same', activation='relu')(trans1_1_d)\n \ndecoder_vae = Model(decoder_inputs, trans2_d)\nz_decoded = decoder_vae(z)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculate reconstruction loss and KL divergence\n\nclass calc_output_with_loss(keras.layers.Layer):\n\n    def vae_loss(self, x, z_decoded):\n        x = K.flatten(x)\n        z_decoded = K.flatten(z_decoded)\n\n        xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n\n        kl_loss = -5e-4 * K.mean(1 + sigma - K.square(mu) - K.exp(sigma), axis=-1)\n        return K.mean(xent_loss + kl_loss)\n\n    def call(self, inputs):\n        x = inputs[0]\n        z_decoded = inputs[1]\n        loss = self.vae_loss(x, z_decoded)\n        self.add_loss(loss, inputs=inputs)\n        return x\n\ndecoded_outputs_vae = calc_output_with_loss()([encoder_inputs, z_decoded])\n\n# define variational autoencoder model and train it\n\nvae = Model(encoder_inputs, decoded_outputs_vae)\nm = 256\nn_epoch = 10\nvae.compile(optimizer='adam', loss=None)\nvae.fit(output_X_train, epochs=n_epoch, batch_size=m, shuffle=True, validation_data=(output_X_test, None))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 15  # figure with 15x15 digits\n \ndigit_size = 28\nfigure = np.zeros((digit_size * n, digit_size * n))\n \ngrid_x = np.linspace(-1, 1, n)\ngrid_y = np.linspace(-1, 1, n)\n \nfor i, yi in enumerate(grid_x):\n    for j, xi in enumerate(grid_y):\n        z_sample = np.array([[xi, yi]]) * 1.\n        x_decoded = decoder_vae.predict(z_sample)\n \n        digit = x_decoded[0].reshape(digit_size, digit_size)\n        figure[i * digit_size: (i + 1) * digit_size,\n               j * digit_size: (j + 1) * digit_size] = digit\n \nplt.figure(figsize=(10, 10))\nplt.imshow(figure)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}