{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# import os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d010d9e1-7d51-4f43-8788-1d25e594f585","_uuid":"ac5e719c1e9b616570c21d2409a8b7c92815b3f4","collapsed":true,"trusted":true},"cell_type":"code","source":"#!/usr/bin/env python\n\nimport re\nimport nltk\n\nimport pandas as pd\nimport numpy as np\n\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\n\n\nclass KaggleWord2VecUtility(object):\n    \"\"\"KaggleWord2VecUtility is a utility class for processing raw HTML text into segments for further learning\"\"\"\n\n    @staticmethod\n    def review_to_wordlist( review, remove_stopwords=False ):\n        # Function to convert a document to a sequence of words,\n        # optionally removing stop words.  Returns a list of words.\n        #\n        # 1. Remove HTML\n        review_text = BeautifulSoup(review).get_text()\n        #\n        # 2. Remove non-letters\n        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n        #\n        # 3. Convert words to lower case and split them\n        words = review_text.lower().split()\n        #\n        # 4. Optionally remove stop words (false by default)\n        if remove_stopwords:\n            stops = set(stopwords.words(\"english\"))\n            words = [w for w in words if not w in stops]\n        #\n        # 5. Return a list of words\n        return(words)\n\n    # Define a function to split a review into parsed sentences\n    @staticmethod\n    def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n        # Function to split a review into parsed sentences. Returns a\n        # list of sentences, where each sentence is a list of words\n        #\n        # 1. Use the NLTK tokenizer to split the paragraph into sentences\n        raw_sentences = tokenizer.tokenize(review.decode('utf8').strip())\n        #\n        # 2. Loop over each sentence\n        sentences = []\n        for raw_sentence in raw_sentences:\n            # If a sentence is empty, skip it\n            if len(raw_sentence) > 0:\n                # Otherwise, call review_to_wordlist to get a list of words\n                sentences.append( KaggleWord2VecUtility.review_to_wordlist( raw_sentence, \\\n                  remove_stopwords ))\n        #\n        # Return the list of sentences (each sentence is a list of words,\n        # so this returns a list of lists\n        return sentences\n","execution_count":5,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"dd41fba743953b47d9b5fbb6e9a39d4a5c008630"},"cell_type":"code","source":"# origin data\nimport os\nimport pandas as pd\nimport numpy as np\n\ntrain = pd.read_csv(\"../input/labeledTrainData.tsv\", header=0, \\\n                delimiter=\"\\t\", quoting=3)\ntest = pd.read_csv(\"../input/testData.tsv\", header=0, delimiter=\"\\t\", \\\n               quoting=3 )\ny = train[\"sentiment\"]\n\nprint('train','\\n',train.head(10))\nprint('test','\\n',test.head(10))\nprint('y','\\n',y.head(10))","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca55047ae2013d574de3f2704383d5365787cafe"},"cell_type":"code","source":"print(\"Cleaning and parsing movie reviews...\\n\")\ntraindata = []\nfor i in range( 0, len(train[\"review\"])):\n    traindata.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(train[\"review\"][i], False)))\ntestdata = []\nfor i in range(0,len(test[\"review\"])):\n    testdata.append(\" \".join(KaggleWord2VecUtility.review_to_wordlist(test[\"review\"][i], False)))\n\nprint('traindata','\\n',traindata[0])\nprint('testdata','\\n',testdata[0])\n","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"528a8591c8814204bcdaff0080ce9e2ec300e096"},"cell_type":"code","source":"# import KaggleWord2VecUtility\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import cross_validation","execution_count":10,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1099f0c0b44fa797f51a3a9e5bcf91e66a8cea31"},"cell_type":"code","source":"print ('vectorizing... '), \ntfv = TfidfVectorizer(min_df=3,  max_features=None, \n        strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n        ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1,\n        stop_words = 'english')\nX_all = traindata + testdata\nlentrain = len(traindata)\n\nprint(\"fitting pipeline... \"),\ntfv.fit(X_all)\nX_all = tfv.transform(X_all)\n\nX = X_all[:lentrain]\nX_test = X_all[lentrain:]\n\nprint('X shape',X.shape)\nprint('X_test shape',X_test.shape)\n\nprint('X0',X[0])\nprint('X_test 0',X_test[0])","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f7de5ae3eb989a260a57d0d7c01359b07e74377"},"cell_type":"code","source":"model = LogisticRegression(penalty='l2', dual=True, tol=0.0001, \n                         C=1, fit_intercept=True, intercept_scaling=1.0, \n                         class_weight=None, random_state=None)\nprint (\"20 Fold CV Score: \", np.mean(cross_validation.cross_val_score(model, X, y, cv=20, scoring='roc_auc')))\n\nprint (\"Retrain on all training data, predicting test labels...\\n\")\nmodel.fit(X,y)\nresult = model.predict_proba(X_test)[:,1]","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n\n# Use pandas to write the comma-separated output file\noutput.to_csv('Bag_of_Words_model.csv', index=False, quoting=3)\nprint (\"Wrote results to Bag_of_Words_model.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}