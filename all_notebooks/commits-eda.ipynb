{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport pickle\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n\nfrom datetime import datetime as dt\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn import preprocessing\n\nimport statsmodels.api as sm\nimport statsmodels.graphics as smg\nimport statsmodels.stats as sm_stats\nimport statsmodels.tsa.api as tsa\n\nfrom scipy import stats\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nfrom typing import List","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Commits Bug Classification and Analysis"},{"metadata":{},"cell_type":"markdown","source":"**This project aims to leverage \"Github Commit Nessages Dataset\" to assess the quality of the software among 32 popular open source projects hosted in Github using their commits messages to track corrections in code which is a signal for bad quality in develpoment**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/github-commit-messages-dataset/full.csv', parse_dates=True, infer_datetime_format=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pre-processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['date'] = df['date'].apply(lambda x: dt.strptime(x,\"%a %b %d %H:%M:%S %Y %z\"))\n#df['date'].apply(lambda x: dt.strptime(x,\"%z \"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['date'] = pd.to_datetime(df['date'], utc=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['dday'] = df['date'].dt.date\ndf['wday'] = df['date'].dt.weekday\ndf['day'] = df['date'].dt.day\ndf['month'] = df['date'].dt.month\ndf['year'] = df['date'].dt.year\ndf['hour'] = df['date'].dt.hour\ndf['min'] = df['date'].dt.minute\ndf['sec'] = df['date'].dt.second","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.join(df['author'].str.split('(<)',n=2,expand=True ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('author', axis=1)\ndf = df.drop(1, axis=1)\ndf = df.rename({0:'user', 2:'email' }, axis=1)\ndf['email'] = df['email'].str.strip('>')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Repos Description"},{"metadata":{},"cell_type":"markdown","source":"### Languages"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nfor repo in df['repo'].unique():\n    print(repo)\n    #print('https://api.github.com/repos/'+repo+'/languages')\n    repo_lang = pd.read_json('https://api.github.com/repos/'+repo+'/languages', orient='index')\n    repo_lang.rename({0:'language'})\n    print(repo_lang)\n    #repo_lang.plot.pie(y=0, figsize=(6,6)).set_title(repo)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X =  vectorizer.fit_transform(df['message'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X.toarray()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(df['repo'].unique()))\ndf['repo'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ustats = df.groupby('repo').nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ustats = ustats.sort_values(by=\"message\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1,ax2) = plt.subplots(2,1, figsize=(18,8))\nfig.autofmt_xdate(rotation=90)\nax1.bar(x=ustats.index, height=ustats['message'])\nax1.set_title('Count of Commits')\nax2.bar(x=ustats.index, height=ustats['user'])\nax2.set_title('Count of Users')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ustats['message'].plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ustats['message'].plot.pie(figsize=(10,10), autopct='%1.1f%%',\n        shadow=True, startangle=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ustats['user'].plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ustats.plot.scatter(x='user',y='message')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ustats.drop('torvalds/linux').plot.scatter(x='user',y='message') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ustats.drop('torvalds/linux').sort_values(by='user',ascending=False)['user'].plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ustats.drop('torvalds/linux').sort_values(by='message',ascending=False)['message'].plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Time series"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sort = df.sort_values('dday')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sort.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"message_day = df.pivot_table(index='dday', columns='repo', values='message', aggfunc='count', fill_value=0, margins=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"message_day.drop('All')[100:-5].rolling(90)['All'].mean().plot(figsize=(20,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"message_day.drop('All')[100:-5].rolling(30)['All'].mean().plot(figsize=(20,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"message_day.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"message_day.drop('All')[100:-5].rolling(30)['torvalds/linux'].mean().plot(figsize=(20,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"message_day.drop('All')[100:-5].rolling(30)['freebsd/freebsd-src'].mean().plot(figsize=(20,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"message_day.drop('All')[8500:-5].rolling(30)['pytorch/pytorch'].mean().plot(figsize=(20,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"message_day.drop('All')[8500:-5].rolling(30)['tensorflow/tensorflow'].mean().plot(figsize=(20,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"message_day.drop('All')[6500:-5].rolling(30)['scikit-learn/scikit-learn'].mean().plot(figsize=(20,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_user = df[['dday','repo','user']].drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_day = df_user.pivot_table(index='dday', columns='repo', values='user', aggfunc='count', fill_value=0, margins=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_day.drop('All')[8500:-5].rolling(30)['pytorch/pytorch'].mean().plot(figsize=(20,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_day.drop('All')[8500:-5].rolling(30)['tensorflow/tensorflow'].mean().plot(figsize=(20,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Competitors\n\nnode x deno\ntensorflow  x pytorch\nlinux x freebsd\niphython x rstudio\nmatplotlib x ggplot2\ngo x rust\nllvm x gcc ?\nhttpd x nginx"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = df.loc[1:100]\ntest","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Commit Classification "},{"metadata":{},"cell_type":"markdown","source":"Reference\n* Idan Amit, and Dror G. Feitelson. (2020). The Corrective Commit Probability Code Quality Metric.\n* https://arxiv.org/abs/2007.10912\n* https://github.com/evidencebp/commit-classification\n"},{"metadata":{},"cell_type":"markdown","source":"Language_utils"},{"metadata":{"trusted":true},"cell_type":"code","source":"regex_list : List[str]\n\nSCHEMA_NAME = 'general'\nfile_scheme = '([a-zA-Z0-9_\\*\\.])+\\.[a-zA-Z]{1,4}'\n\nREGULAR_SUFFIX = '(?:s|ed|ing)?'\nVERB_E_SUFFIX = '(?:e|es|ed|ing)'\n\nNEAR_ENOUGH = '[\\S\\s]{0,40}'\n\n#term_seperator = \"(\\s|\\.|\\?|\\!|\\[|\\]|\\(|\\)|\\:|^|$|\\,|\\'|\\\"|/|#|\\$|\\%|&|\\*|\\+|=|`|;|<|>|@|~|{|}|-|\\|)\" # Adding - should be tuned\n#term_seperator = \"(\\s|\\.|\\?|\\!|\\[|\\]|\\(|\\)|\\:|^|$|\\,|\\'|\\\"|/|#|\\$|\\%|&|\\*|\\+|=|`|;|<|>|@|~|{|}|\\|)\"\n#term_seperator = \"[^abcdefghijklmnopqrstuvwxyz]\"\nterm_seperator = \"(\\s|\\.|\\?|\\!|\\[|\\]|\\(|\\)|\\:|^|$|\\,|\\'|\\\"|/|#|\\$|\\%|&|\\*|\\+|=|`|;|<|>|@|~|{|}|_|\\|)\"\n#term_seperator = \"(\\s|\\.|\\?|\\!|\\[|\\]|\\(|\\)|\\:|^|$|\\,|/|#|\\$|\\%|&|\\*|\\+|=|`|;|<|>|@|~|{|}|_|\\|)\" # no \",'\n#term_seperator = \"(\\s|\\.|\\?|\\!|\\[|\\]|\\(|\\)|\\:|^|$|\\,|\\'|\\\"|#|\\$|\\%|&|\\*|\\+|=|`|;|<|>|@|~|{|}|_|\\|)\" # without /\n\n# Negation\nnegation_terms = [\"aren't\",\n 'arent',\n \"can't\",\n 'cannot',\n 'cant',\n 'could not',\n \"couldn't\",\n 'couldnt',\n \"didn't\",\n 'didnt',\n \"doesn't\",\n 'doesnt',\n \"don't\",\n 'dont',\n \"hasn't\",\n \"haven't\",\n \"isn't\",\n 'isnt',\n 'lack',\n \"n't\",\n 'never',\n 'no',\n 'nobody',\n 'none',\n 'not',\n 'nothing',\n \"shouldn't\",\n 'shouldnt',\n \"weren't\",\n 'werent',\n 'without',\n \"won't\",\n 'wont',\n \"wouldn't\",\n 'wouldnt']\n\n# TODO - consider adding if, maybe\nmodals = [#'if', 'maybe',\n          'can', 'could', 'ha(?:ve|s|d)', 'may', 'might', 'must', 'need', 'ought', 'shall'\n    , 'should', 'will', 'would']\n\n\n\n# TODO - check https://arxiv.org/pdf/2001.09148.pdf for more\n\nsecurity_terms = [\n 'advisory',\n 'attack',\n 'authenticat(e|ion)',\n 'brute force', # consider\n 'bug bount(y|ies)',\n 'bypass', # consider\n 'constant time',\n 'crack',\n 'credential(s)?',\n 'cross-origin',\n 'cross site',\n 'cve(-d+)?(-d+)?',\n 'clickjack',\n 'cyber',\n 'denial of service',\n '(de)?serializ', # consider\n 'directory traversal',\n 'dos', # consider\n 'exploit',\n 'expos(e|ing)',\n 'hack',\n 'hijack',\n 'harden',\n #'infinite loop', # consider\n 'injection',\n '(in)?secur(e|ity)',\n 'lockout',\n 'malicious',\n 'malware',\n 'nvd' # NVD\n 'open redirect',\n 'osvdb', # OSVDB\n 'overflow', # consider\n 'password(s)?',\n 'permission(s)?',\n 'poison',\n 'port scan',\n 'privilege',\n # 'proof of concept', # consider\n 'rce', # remote code execution\n 'redos' # ReDoS\n 'remote code execution',\n 'return oriented programming',\n 'security',\n 'session fixation',\n 'spoof',\n 'threat',\n 'timing', # consider\n 'traversal',\n 'unauthori[z|s]ed',\n 'vulnerabilit(?:y|ies)',\n 'x(?: |-)frame(?: |-)options',\n 'xss',\n 'xsrf', # XSRF\n 'xxe' # XXE\n    ]\n\n\ndocumentation_entities = [\n    'change(?:s)?(?: |-)?(list|log|set|file)',\n    'comment(s)?',\n    'copy(?: |-)?right(?:s)?',\n    'doc(?:s)?',\n    'documentation',\n    'explanation(?:s)?',\n    'man(?: |-)?page(?:s)?',\n    'manual',\n    'note(?:s)?',\n    'readme(?:.md)?',\n    r'[-a-z\\d_/\\\\]*.(md|txt)',\n    'translation(?:s)?',\n    'java(?: |-)?doc(?:s)?',\n    'java(?: |-)?documentation',\n    'example(?:s)?',\n    'diagram(?:s)?',\n    'guide(?:s)?',\n    'gitignore',\n    'icon(?:s)?',\n    'doc(?: |-)?string(?:s)?',\n    'tutorials(?:s)?',\n    'help',\n    'man',\n    'doc(?: |-)?string(?:s)?',\n    'desc(?:ription)?(?:s)?',\n    'copy(?: |-)?right(?:s)?',\n    'explanation(?:s)?',\n    'release notes',\n    'tag(?:s)?', # Git commit tags\n\n]\n\nprefective_entities = documentation_entities +[\n    'indentation(?:s)?'\n    , 'style'\n    , 'todo(s)?'\n    , 'typo(s)?'\n    , 'verbosity']\n\nsoftware_goals = ['abstraction', 'coherence', 'cohesion', 'complexity', 'correctness', 'coupling', 'dependability'\n    , 'duplication', 'efficiency', 'extensibility', 'flexibility' ,'maintainability', 'naming', 'performance', 'portability', 'quality'\n    , 'readability', 'reliability', 're(?:-| )?use' ,'re(?:-| )?usability', 'security', 'simplicity', 'testability', 'testable', 're(?:-| )?usable'\n    , 'readable', 'portable', 'maintainable', 'flexible', 'efficient', 'encapsulation'\n                  ]\n\nsoftware_goals_modification = [\n    'better','improv(?:e|es|ed|ing)', 'increas(?:e|es|ed|ing)', 'reduc(?:e|es|ed|ing)', 'worse', 'make', 'more', 'less'\n]\n\nsoftware_entities = ['algorithm(?:s)?',\n 'class(?:es)?',\n 'collection(?:s)?',\n 'constant(?:s)?',\n 'constructor(?:s)?',\n 'field(?:s)?',\n 'function(?:s)?',\n 'interface(?:s)?',\n 'member(?:s)?',\n 'method(?:s)?',\n 'module(?:s)?',\n 'parameter(?:s)?',\n 'procedure(?:s)?',\n 'routine(?:s)?`',\n 'structure(?:s)?',\n 'template(?:s)?',\n 'type(?:s)?',\n 'unit(?:s)?',\n]\n\nsoftware_terms = [ 'assertion(?:s)?', 'assignment(?:s)?',  'code',  'conditional(?:s)?',  'control', 'definition(?:s)?'\n    , 'delegate', 'delegation'\n    , 'design pattern(?:s)?', 'error(?:-| )?code(?:s)?', 'exception(?:s)?',  'flag(?:s)?',  'getter(?:s)?'\n    , 'guard clause(?:s)?', 'hierarch(?:y|ies)', 'implementation(?:s)?', 'inheritance', 'inline'\n    ,  'internal', 'macro(?:s)?'\n    , 'magic number(?:s)?', 'modifier(?:s)?', 'null object(?:s)?', 'object(?:s)?'\n    , 'patch(?:es)?',  'pointer(?:s)?', 'polymorphism', 'quer(?:y|ies)',  'reference(?:s)?'\n    , 'ref(?:s)?'\n    , 'return type', 'setter(?:s)?', 'static',  'sub(?:-| )?class(?:es)?', 'super(?:-| )?class(?:es)?'\n    , '(?:sub)?(?:-| )?system(?:s)?'\n    , 'uninline'\n    #, 'value(?:s)?'\n    , 'variable(?:s)?', 'handler', 'plugin'\n    #, '(?:in)?validation'\n    #, 'input', 'output'\n    , 'contravariant', 'covariant'\n                  # , 'link(?:s)?'\n    ,\n                  'action(?:s)?'\n                  # , 'event(?:s)?'\n    , 'queue(?:s)?', 'stack(?:s)?'\n    #, 'change(?:\\s)?log'\n    , 'driver(?:s)?'\n    #, 'hook(?:s)?'\n    #, 'target(?:s)?'\n    , 'storage', 'tool(?:s)?',  'log(?:s)?', 'setting(?:s)?'\n    #, '(?:index|indexes|indices)'\n    , 'fall(?: |-)back(?:s)?', 'memory', 'param(?:s)?', 'volatile', 'file(?:s)?'\n    , 'generic(?:s)?'\n    #, 'test(?:s)?'\n    , 'initialization(?:s)?', 'public', 'protected', 'private' ,'framework', 'singelton', 'declaration(?:s)?'\n    , 'init' , 'destructor(?:s)?', 'instances(?:s)?', 'primitive(?:s)?'\n    #, 'middle man'\n    #, 'hierarchy'\n                  ] + software_entities\n\n\n# Well, we need them...\nunnedded_terms = ['unnecessary', 'unneeded', 'unused', '(?:not|never|no longer) used'\n    #, 'old'\n    , 'no longer needed', 'redundant', 'useless', 'duplicate(?:d)?', 'deprecated', 'obsolete(?:d)?', 'commented']\n\n\nstatic_analyzers = ['lint', 'pylint', 'tslint', 'jlint', 'jslint', 'eslint', 'klint', 'xlint', 'linter']\n\ncode_review_fixes = ['(cr|pr)(s)?(-)?(d+)?\\sfix(es)?', 'fix(?:ing|es|ed)?\\s(cr|pr|code review|code-review|review)']\n\nno_message = ['no message', 'wip', 'work in progress', 'message', 'change(?:-|\\s)?set', 'commit']\n\nprogramming_languges = [i.lower() for i in ['Python', 'JavaScript', 'Java', 'C\\+\\+', 'PHP', 'TypeScript', 'C',\n       'C\\#', 'Go', 'Ruby', 'HTML', 'Shell', 'CSS', 'Kotlin', 'Scala',\n       'Swift', 'Jupyter Notebook', 'Rust', 'Perl', 'Lua', 'Haskell', 'R',\n       'Objective\\-C', 'Groovy', 'Vue', 'PowerShell', 'TSQL', 'Dart',\n       'Clojure', 'MATLAB', 'Emacs Lisp', 'OCaml', 'Erlang', 'Elixir',\n       'CoffeeScript', 'TeX', 'Fortran', 'Assembly', 'Vim script',\n       'PLpgSQL', 'Makefile', 'Julia', 'BitBake', 'F\\#', 'Common Lisp',\n       'Vala', 'Coq', 'Smalltalk', 'Scheme', 'Visual Basic .NET',\n       'Puppet', 'HCL', 'Smarty', 'Dockerfile', 'XSLT', 'GLSL', 'Haxe',\n       'Cuda', 'Ada', 'SQF', 'Pascal', 'PLSQL', 'Gherkin', 'Jsonnet',\n       'Nix', 'Roff', 'Apex', 'QML', 'CMake', 'D', 'Perl 6',\n       'Visual Basic', 'Objective\\-C\\+\\+', 'Prolog', 'Mathematica',\n       'Batchfile', 'Reason', 'Markdown', 'DM', 'Elm', 'FreeMarker',\n       'ABAP', 'M4', 'SystemVerilog', 'AutoHotkey', 'Verilog', 'IDL',\n       'Tcl', 'Rich Text Format', 'SaltStack', 'UnrealScript', 'Zig',\n       'WebAssembly', 'RAML', 'F\\*', 'Stan', 'ColdFusion', 'Factor',\n       'LLVM', 'Pike', 'VBA', 'Isabelle', 'OpenSCAD', 'ASP', 'Arc',\n       'Racket', 'LookML', 'SMT', 'q', 'Xojo', 'ZenScript', 'Ceylon',\n       'Agda', 'Limbo', 'SuperCollider', 'Pawn', 'xBase', 'JSON', 'Nim',\n       'M', 'XC', 'SourcePawn', 'GDScript', 'LilyPond', 'SQLPL',\n       'PostScript', \"Ren'Py\", 'Gnuplot', 'OpenEdge ABL',\n       'Common Workflow Language', 'Xtend', 'Mercury', 'Genshi',\n       'Open Policy Agent', 'RobotFramework']]\n\n\ndef build_sepereted_term(term_list : List, just_before =False):\n    if just_before:\n        sep = \"%s(%s)\" % (term_seperator, \"|\".join(term_list))\n    else:\n        sep = \"%s(%s)%s\" % (term_seperator, \"|\".join(term_list), term_seperator)\n    return sep\n\n\ndef build_non_positive_linguistic(positive_re\n                                  , neg=negation_terms):\n\n    non_actionable_context = ['for(?:get|gets|got|getting)'\n        , 'allow(s|ed|ing)?']\n\n\n    return '(?:%s)' % \"|\".join([\n        ('(?:%s)' + NEAR_ENOUGH + '(?:%s)') % (build_sepereted_term(modals, just_before=True)\n                                      ,  positive_re)\n        , ('(?:%s)' + NEAR_ENOUGH + '(?:%s)') % (build_sepereted_term(neg, just_before=True)\n                                        ,  positive_re)\n        , ('(?:%s)' + NEAR_ENOUGH + '(?:%s)') % (build_sepereted_term(non_actionable_context, just_before=True)\n                                        ,  positive_re)\n        # TODO - take care of documentation entities spereatly\n        #, '(?:%s)[\\s\\S]{0,10}(?:%s)' % (build_sepereted_term(documentation_entities, just_before=True)\n        #                                ,positive_re)\n    ])\n\n\ndef match(commit_text, regex):\n    text = commit_text.lower()\n\n    return len(re.findall(regex, text))\n\n\ndef regex_to_big_query(reg_exp\n                       , text_field='message'):\n    # TODO - check\n    # Take care of encoding\n    reg_exp = reg_exp.replace(\"\\\\\", \"\\\\\\\\\").replace(\"'\", \"\\\\'\")\n    #reg_exp = reg_exp.replace(\"\\\\\\\\\", \"\\\\\")\n    # No need for grouping\n    reg_exp = reg_exp.replace(\"(?:\", \"(\")\n    str = \"(\" + \"LENGTH(REGEXP_REPLACE(lower(\" + text_field + \"),\" + \"'%s', '@'))\" % reg_exp + \"-\" \\\n          + \"LENGTH(REGEXP_REPLACE(lower(\" + text_field + \"),\" + \"'%s', ''))\" % reg_exp + \")\"\n\n    return str\n\n\ndef generate_bq_function(func_name\n                         , code_generator\n                         , commit: str ='XXX'):\n    print(\"# Run in Standard sql \")\n    print(\"CREATE OR REPLACE FUNCTION \")\n    print(func_name)\n    print(\" (message string) \")\n    print(\" RETURNS int64 \")\n    print(\"AS (\")\n    print(\"# Model language based on commit: {commit} \".format(commit=commit))\n    code_generator()\n    print(\" ) \")\n    print(\" ; \")\n\n\ndef normalize(string):\n    string = re.sub(r\"\\s+\", \" \", string.strip())\n    while \"  \" in string:\n        string = string.replace(\"  \", \" \")\n    return string\n\ndef print_logic_to_bq(regex_func\n                      , concept):\n    print(\"# \" + concept)\n    print( regex_to_big_query(regex_func()))\n    print(\"# \" + concept + \" - end\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conventional Commits"},{"metadata":{"trusted":true},"cell_type":"code","source":"cc_adaptive_terms = ['feat' # Feature\n                        , 'build'\n                        , 'chore'\n                        , 'ci' # continuous integration\n                        , 'test'\n                        , 'perf' # performance\n                     ]\ncc_corrective_terms = ['fix']\ncc_perfective_terms = ['docs', 'style']\ncc_refactor_terms = ['refactor']\n\ncc_actions = cc_adaptive_terms + cc_corrective_terms + cc_perfective_terms + cc_perfective_terms\n\ncc_etc = ['breaking\\s+change(!)?:']\n\n\ndef cc_title(astions):\n\n    return '^(' + \"|\".join(astions) +\")(\\(.*\\))?(!)?:\"\n\n\n# Adaptive\ndef build_cc_adaptive_regex():\n\n    return cc_title(cc_adaptive_terms)\n\n\ndef is_cc_adaptive(commit_text):\n\n    return len(re.findall(build_cc_adaptive_regex(), commit_text)) > 0\n\n\n# Corrective\ndef build_cc_corrective_regex():\n\n    return cc_title(cc_corrective_terms)\n\n\ndef is_cc_corrective(commit_text):\n\n    return len(re.findall(build_cc_corrective_regex(), commit_text)) > 0\n\n# Refactor\ndef build_cc_refactor_regex():\n\n    return cc_title(cc_refactor_terms)\n\n\ndef is_cc_refactor(commit_text):\n\n    return len(re.findall(build_cc_refactor_regex(), commit_text)) > 0\n\n# Just Perfective\ndef build_cc_just_perfective_regex():\n\n    return cc_title(cc_perfective_terms)\n\n\ndef is_cc_just_perfective(commit_text):\n\n    return len(re.findall(build_cc_just_perfective_regex(), commit_text)) > 0\n\n# Perfective\ndef build_cc_perfective_regex():\n\n    return \"(\" + \"|\".join([build_cc_refactor_regex()\n                              , build_cc_just_perfective_regex()]) + \")\"\n\n\ndef is_cc_perfective(commit_text):\n\n    return len(re.findall(build_cc_perfective_regex(), commit_text)) > 0\n\n# CC message\ndef build_cc_message_regex():\n\n    return \"(\" + \"|\".join([cc_title(cc_actions)] + cc_etc) + \")\"\n\n\n\ndef is_cc_message(commit_text):\n\n    return len(re.findall(build_cc_message_regex(), commit_text)) > 0\n\n\n\n\ndef print_cc_functions_for_bq(commit: str = 'XXX'):\n\n    concepts = {'cc_adaptive' : build_cc_adaptive_regex\n                , 'cc_corrective' : build_cc_corrective_regex\n                , 'cc_refactor' : build_cc_refactor_regex\n                , 'cc_just_perfective' : build_cc_just_perfective_regex\n                , 'cc_perfective' : build_cc_perfective_regex\n                , 'cc_message' : build_cc_message_regex\n                }\n\n    for i in concepts.keys():\n        print()\n        print_func = lambda : print_logic_to_bq(regex_func=concepts[i]\n                                                , concept=i)\n        generate_bq_function('{schema}.bq_{concept}'.format(schema=SCHEMA_NAME\n                                                            , concept=i)\n                             , print_func\n                             , commit=commit)\n        print()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Corrective"},{"metadata":{},"cell_type":"markdown","source":"### Keywords"},{"metadata":{"trusted":true},"cell_type":"code","source":"core_bug_terms = [\n             'bug(s|z)?',\n             'bug(?:-|\\s)?fix(es)?',\n             'defect(?:s)?',\n             'error(?:s)?',\n             'failur(?:ing|e|es|ed)',\n             'fault(s)?',\n             'fix(ed|es|ing)?',\n             'fixing(?:s)?',\n             'incorrect(ly)?',\n             'mistake(s|n|d|nly)?',\n             'problem(?:s)?',\n             ]\n# Positive\nbug_terms = ['actual.*expected',\n             '((assignment|assign|=) in if|== instead of =)',\n             'expected.*actual'\n             '(choose|take|set|use)\\\\s*(the|a)?\\\\s*correct', # correct as adjective\n             \"(not|isn't|doesn't)\\\\s+work(s|ing)?\", # TODO - check with negation\n             \"doesn't recognize\", # TODO Extend\n             'double(?:-| )allocat(?:e|ion|ions)',\n             'double(?:-| )free(?:s)?',\n             \"caused a regression\", # TODO Extend\n             'bad initialization(?:s)?',\n             'buffer overflow(?:s)?',\n             'fixme(?:s)?',\n             'fixes(?:-| )?commit(?::| )?',\n             '(break|breaks|broke|broked|breaking|broken)[\\s\\S]{0,20}(code|system|function|method)',\n             '(this|that|it)\\s(break|breaks|broke|broked|breaking|broken)',\n             'break strict(?:-|\\s)aliasing rule(s)?',\n             'crash(?:ing|s|ed)?',\n             'correct(?:ing|s|ed)?\\\\s*(a|the|some|few|this)', # make sure that correct serves as a verb\n             'correct(ed|ion|ly|s)?',\n             '(dangling|hanging) pointer(?:s)?',\n             'deadlock(?:s)?',\n             '(divid(e|es|ed|ing)|division) by (zero|0)',\n             'double(?:-| )free',\n             'fail(?:ing|s|ed)?',\n             'faulty initialization(?:s)?',\n             'fix(?:-| )?in(?:s)?',\n             'fix(?:-| )?up(?:s)?',\n             'flaw(?:s|ed)?',\n             '(float|integer) (under|over)(?:-| )?flow',\n             'hot(?:-| )?fix(?:ed|es|ing)?',\n             #'hang',\n             'heap overflow(?:s)?',\n             '(?:im|im-)?proper'\n             'memory(?:-| )?leak(?:s)?',\n             'missing\\s(default value|initialization|switch case)(?:s)?',\n             'is\\smissing',\n             'add(?:ing|s|ed)?\\smiss(?:ing|es|ed)?',\n             #'must not',\n             'npe(?:s)?'\n             'null pointer(?:s)?',\n             'off(?:-| )by(?:-| )(one|1)',\n             'out of bound(?:s)?',\n             'over(?:-| )?run(?:s)?',\n             'patch(?:ed|ing)',\n             #'prevent(?:ing|s|ed)?', # should be tuned\n             'race condition(?:s)?',\n             'data race(?:s)?',\n             'repair(?:ing|s|ed)?',\n             'resource leak(?:s)?',\n             # TODO - check generalization to leaks works in the other direction to expected (reduces FP, increases FN)\n             'leak(?:s)?',\n             'revert(?:ing|s|ed)?',\n             'segmentation (fault|violation)(?:s)?',\n             'resolv(?:ing|e|es|ed)',\n             #'solv(?:ing|e|es|ed)',\n             'workaround(?:s)?',\n             'wrong(nly)?',\n             '(type(s)? mis(?:-| )?match|(not|non|none) matching type(s)?)',\n             'trouble(?:s)?',\n             '(un(?:-| )?|not )initialized variable(s)?',\n             'unintended',\n             'not intended',\n             'unintentionally',\n             'not intentionally',\n             # 'unexpected.*occurred', # very rare, 90% are bugs anyway\n             'vulnerabilit(?:y|ies)'\n             ] + core_bug_terms\n\n# Valid_fix_objects\nvalid_fix_object = prefective_entities + ['#',\n                    '(camel|snake|kebab|flat|lower|upper)\\\\s*case',\n                    \"code review('s|s)?\",\n                    'comment(?:s)?',\n                    'cosmetic(?:s)?',\n                    'cr(s)?(?:-)?',\n                    'documentation(?:s)?',\n                    #'exception(?: |-)?handling',\n                    #'format(s|ing)? fix(ed|es|ing)?',\n                    'format(?:ing)?',\n                    'help',\n                    'remark(s)?',\n                    'space(s)?',\n                    'style|styling',\n                    'typo(s)?',\n                    'typing(?: |-)?(error|mistake)(s)?',\n                    'warning(s)?',\n                    'white(?: |-)?space(s)?']\n\nvalid_terms = [\n    'break\\sout',\n    'error(?: |-)?check(ing)?',\n    'error(?: |-)?handling',\n    'error message(s)?',\n    'error report(s|ing)?',\n    'fixed(?: |-)?point',\n    'fix(?:ed) ticket(?:s)?',\n    #'format(ing)?',\n    '(?:fix(?:ed|es)?|bug)(?: )?(?: |-|=|:)(?: )?[a-z]{0,3}(?:-)?\\d+' + term_seperator,\n    '(if|would)[\\s\\S]{0,40}go wrong',\n    'line(?:s)? break(?:s)?',\n    'typo(s)?\\sfix(es)?',\n    'fix(ed|es|ing)?' + build_sepereted_term(software_entities) + 'name(s)?',\n    build_sepereted_term(static_analyzers) + 'fix(es|ed)?',\n    'fix(es|ed)?' + build_sepereted_term(static_analyzers) ,\n    '^### Bug Fix', # tends to be a title, later stating if the commit is a bug fix\n    'edit the jira link to the correct issue', # Another occurring title\n    'page(?:s)? break(?:s)?',\n\n\n] + code_review_fixes\n\n\n\nfixing_verbs = ['correct(?:ing|s|ed)'\n                    , 'fix(ed|s|es|ing)?'\n                    , 'repair(?:ing|s|ed)?'\n                    ,  'revert(?:ing|s|ed)?'\n                    , 'resolv(?:ing|e|es|ed)'\n                    , 'revok(?:ing|e|es|ed)'\n                    , 'und(?:oing|id)'\n                ]\nMERGE_PREFIX = '(merge (branch|pull request).{0,25}|merge (branch|pull request).{0,25}(from|into).{0,25})'\nEND_OF_LINE = r'(\\r\\n|\\r|\\n|$)'\ncorrective_header_entities = fixing_verbs + [\n    'miss(?:ing|es|ed)?', 'should', 'must', '(have|has) to', 'avoid', 'prevent', 'break(s|ed|ing)?', 'broken'\n    , 'remov(?:ing|e|es|ed) change(?:s)?', 'unable', 'proper(?:ly)?'\n    , MERGE_PREFIX + \"(%s)\" % \"|\".join(core_bug_terms) + '.{0,250}' + END_OF_LINE\n    #, \"(does not|doesn't) need\" , \"cannot\", \"can not\"\n ] #+ [ \"do not\" ,\"don't\", \"dont\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Regex Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_sepereted_term(term_list : List, just_before =False):\n    if just_before:\n        sep = \"%s(%s)\" % (term_seperator, \"|\".join(term_list))\n    else:\n        sep = \"%s(%s)%s\" % (term_seperator, \"|\".join(term_list), term_seperator)\n    return sep","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_valid_find_regex():\n    fix_re = \"(\" + \"|\".join(fixing_verbs + [MERGE_PREFIX]) + \")\"\n    prefix = term_seperator + fix_re + '[\\s\\S]{1,40}' + \"(\" + \"|\".join(valid_fix_object) + \")\" + term_seperator\n\n    suffix = term_seperator + \"(\" + \"|\".join \\\n        (valid_fix_object) + \")\" + term_seperator + '[\\s\\S]{0,40}' + term_seperator + fix_re + term_seperator\n\n    # TODO - check seperation\n    #sepertion = '(?:%s|%s[\\s\\S]{0,40}%s)' % (term_seperator, term_seperator, term_seperator)\n    #suffix = \"(\" + \"|\".join \\\n    #    (valid_fix_object) + \")\" + sepertion + fix_re + term_seperator\n\n    #other_valid_re = \"(%s)\" % \"|\".join(valid_terms)\n    other_valid_re = build_sepereted_term(valid_terms)\n    return \"((%s)|(%s)|(%s))\" % (prefix, suffix, other_valid_re)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_bug_fix_regex(use_conventional_commits=True):\n    header_regex =  '(?:^|^[\\s\\S]{0,25}%s)(?:%s)%s' % (term_seperator\n                                                       , \"|\".join(corrective_header_entities)\n                                                       , term_seperator)\n   # strict_header = \"^(?:%s)%s\"  % ( \"|\".join([ \"do not\" ,\"don't\"])\n   #                                                    , term_seperator)\n\n    bug_fix_re = build_sepereted_term(bug_terms)\n\n\n    if use_conventional_commits:\n        agg_re = \"((%s)|(%s)|(%s))\" % (bug_fix_re, header_regex, build_cc_corrective_regex())\n    else:\n        agg_re = \"((%s)|(%s))\" % (bug_fix_re, header_regex)\n\n    return agg_re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_negeted_bug_fix_regex():\n    bug_fix_re = build_bug_fix_regex(use_conventional_commits=False)\n    negation_re = build_sepereted_term(negation_terms)\n\n\n    return \"%s[\\s\\S]{0,20}%s\" % (negation_re, bug_fix_re)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_core_bug_regex():\n\n    return '(%s)' % build_sepereted_term(core_bug_terms)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def is_core_bug(commit_text):\n    text = commit_text.lower()\n\n    cnt = len(re.findall(build_core_bug_regex(), text))\n\n    return cnt > 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def is_fix(commit_text):\n\n    text = commit_text.lower()\n    #text = normalize(text)\n\n    fix_num = len(re.findall(build_bug_fix_regex(), text))\n    valid_num = len(re.findall(build_valid_find_regex(), text))\n    negated_num = len(re.findall(build_negeted_bug_fix_regex(), text))\n    # TODO  consider modals\n    #negated_num = len(re.findall(build_non_positive_linguistic(build_bug_fix_regex()), text))\n    return (fix_num - valid_num - negated_num) > 0\n    #return (fix_num ) > 0 # max recall with current predictor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrections = 0\nfor m in test['message']:\n    print(m)\n    print('CORRECTION: ' + str(is_fix(m)))\n    print(' ')\n    if is_fix(m) ==  True:\n        corrections += 1\n        \nprint(corrections)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrections = 0\nfor m in test['message']:\n    print(m)\n    print('CORRECTION: ' + str(is_core_bug(m)))\n    print(' ')\n    if is_core_bug(m) ==  True:\n        corrections += 1\n        \nprint(corrections)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Security"},{"metadata":{},"cell_type":"markdown","source":"### Keywords"},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_terms = [\n 'advisory',\n 'attack(?:s)?',\n 'auth',\n 'authenticat(e|ion)',\n 'brute force', # consider\n 'bug bount(y|ies)',\n 'bypass(?:es|ed|ing)?', # consider\n 'certificate(?:s)?',\n #'constant time', # too general\n 'crack',\n 'credential(s)?',\n 'cross(?: |-)origin',\n 'cross(?: |-)site',\n 'cve(-d+)?(-d+)?',\n 'clickjack',\n 'cyber',\n 'denial of service',\n '(de)?serializ', # consider\n 'directory traversal',\n 'dos', # consider\n 'exploit',\n #'expos(e|ing)',\n # 'hack', # A bit general, consider\n 'hijack',\n 'harden',\n #'infinite loop', # consider\n 'injection',\n '(in)?secur(e|ity)',\n 'lockout',\n 'malicious',\n 'malware(?:s)?', #plural of malware is malware yet not all are aware\n 'nvd' # NVD\n 'open redirect',\n 'osvdb', # OSVDB\n 'overflow', # consider\n 'password(?:s)?',\n 'permission(?:s)?',\n 'poison(?:s|es|ed|ing)?',\n 'port scan',\n 'privilege(?:s)?',\n # 'proof of concept', # consider\n 'rce', # remote code execution\n 'redos' # ReDoS\n 'remote code execution',\n 'return oriented programming',\n '(?:safe|safety|unsafe|safer)',\n 'security',\n 'session fixation',\n 'spoof(?:s|es|ed|ing)?',\n 'threat(?:s|ed|ing)?',\n 'timing', # consider\n 'token(?:s)?',\n #'traversal',\n 'unauthori[z|s]ed',\n 'vulnerabilit(?:y|ies)',\n 'x(?: |-)frame(?: |-)option(?:s)?',\n 'xss',\n 'xsrf', # XSRF\n 'xxe' # XXE\n    ]\n\nexcluded_terms = ['_____PLACEHOLDER_____'\n                  ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Regex Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_positive_regex():\n\n    return build_sepereted_term(positive_terms)\n\n\n\ndef build_excluded_regex():\n\n    return build_sepereted_term(excluded_terms)\n\ndef build_not_positive_regex():\n\n    return build_non_positive_linguistic(build_positive_regex())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classification Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def is_security(commit_text):\n\n    return (len(re.findall(build_positive_regex(), commit_text))\n            - len(re.findall(build_excluded_regex(), commit_text))\n            - len(re.findall(build_not_positive_regex(), commit_text)))  > 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrections = 0\nfor m in test['message']:\n    print(m)\n    print('CORRECTION: ' + str(is_security(m)))\n    print(' ')\n    if is_security(m) ==  True:\n        corrections += 1\n        \nprint(corrections)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Adaptive"},{"metadata":{},"cell_type":"markdown","source":"### Keywords"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncore_adaptive_terms = [\n    'add(?:s|ed|ing)?',\n    'creat(?:e|es|ing)',\n    'disabl(?:e|es|ed|ing)',\n    'implement(?:ed|s|ing)?',\n    'import(?:s|ed|ing)?',\n    'introduc(?:e|es|ed|ing)',\n    'port(?:s|ed|ing)?',\n    'provid(?:e|es|ed|ing)',\n    'updat(?:e|es|ed|ing)',\n    'upgrad(?:e|es|ed|ing)'\n\n]\n\nadaptive_context = [\n '(?:un)?hid(?:e|es|den)',\n 'allow(?:s|ed|ing)?',\n 'buil(?:t|ds|ing)',\n 'calibirat(?:e|es|ed|ing)',\n 'configure',\n 'deferr(?:ed|s|ing)?',\n 'enhanc(?:e|es|ed|ing)',\n 'extend(?:s|ed|ing)?',\n 'form(?:ed|s|ing)?',\n 'report(?:s|ed|ing)?',\n 'support(s|ed|ing)?',\n\n# , 'mov(e|es|ed|ing)'\n# , 'print(s|ed|ing)?'\n\n] + core_adaptive_terms\n\n\n\nadaptive_entities = ['ability', 'configuration', 'conversion', 'debug', 'new', 'possibility', 'support'\n    , 'test(s)?', 'tweak(s)?', 'mode', 'option']\n\n\nadaptive_header_action = \"|\".join([\n    'upgrad(?:e|es|ed|ing)',\n    'configur(?:e|es|ed|ing)',\n    'chang(?:e|es|ed|ing)',\n    '(?:keep|change)\\s+(?:the\\s+)?default',\n    'new',\n    # '(?:make(?:s)?|made|making)',\n    'merg(?:e|es|ed|ing)',\n    'clear(?:s|ed|ing)?',\n    #'comment(?:s|ed|ing)?\\sout'\n    'creat(?:e|es|ed|ing)',\n    'cast(?:s|et|ing)?' + NEAR_ENOUGH + '\\sas',\n    # 'convert(?:s|ed|ing)?',\n    # 'check(?:s|ed|ing)?',\n    'add(?:s|ed|ing)?',\n    # 'buil(?:d|t|ds|ing)',\n    'Initial revision',\n    '(?:im)?port(?:s|ed|ing)?',\n    '(?:un)?hid(?:e|es|den)',\n    'updat(?:e|es|ed|ing)',\n    'upload(?:s|ed|ing)?',\n    'disabl(?:e|es|ed|ing)',\n    'delet(?:e|es|ed|ing)',\n    'enabl(?:e|es|ed|ing)',\n    'quirk(?:s|ed|ing)?',\n    'skip(?:s|ed|ing)?',\n    'switch(?:s|ed|ing)?',\n    'allow(?:s|ed|ing)?',\n    'provid(e|es|ed|ing)',\n\n    ###\n    # , 'build'\n    # , 'mark(?:s|ed|ing)?'\n    # , 'us(?:e|es|ed|ing)'\n    # , '(?:make|made|making)'\n    # , 'creat(?:e|es|ed|ing)'\n    # , 'handl(?:e|es|ed|ing)'\n    'remov(?:e|es|ed|ing)',\n    'refresh(?:s|ed|ing)?',\n    #'re(-)?enabl(?:e|es|ed|ing)',\n\n] +no_message\n)\n\nadaptive_actions = [  # 'revert(?:s|ed|ing)?',\n    #'merg(?:e|es|ed|ing)[\\s\\S]{1,5}(pull request|pr|branch)',\n    'add(?:s|ed|ing)?[\\s\\S]{1,50}(?:version|v\\d|ver\\d)',\n    #'(cr(s)?(-)?|code\\sreview)\\sfix(?:s|ed|ing)?',\n    '(^|\\s)implement(?:ed|s|ing)?\\s',\n    '(?:make(?:s)?|made|making)[\\s\\S]{1,50}consitent',\n    'updat(?:e|es|ed|ing)[\\s\\S]{1,25}to[\\s\\S]{1,25}\\d+.\\d',\n    'updat(?:e|es|ed|ing)\\s+(to\\s+)?\\d+\\.\\d',\n    '(?:add(s|ed|ing)?|delet(?:e|es|ed|ing)|updat(?:e|es|ed|ing))\\s+' + file_scheme,\n    # '(add(s|ed|ing)?|delet(e|es|ed|ing)|updat(e|es|ed|ing))\\s+([A-Z0-9_]*)', # TODO - run without lower\n    '(^|^[\\s\\S]{0,25}%s)(%s)%s' % (term_seperator, adaptive_header_action, term_seperator),\n    # '^(?:version|v\\d+\\.\\d|ver\\d+\\.\\d)',\n    '^\\[(?:IMP|imp)\\]',  # TODO - take care of upper/lower case\n    'support(?:s|ed|ing)?\\sfor\\s',\n    'show(?:es|ed|ing)?[\\s\\S]instead',\n    'scal(?:e|es|ed|ing)?\\s(up|down)'\n\n                   ] + code_review_fixes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_adaptive_action_regex():\n\n    return \"(%s)\" % (\"|\".join(\n    adaptive_actions))\n\n\n\n\ndef build_adaptive_regex(use_conventional_commits=True):\n\n    adaptive_context_re = build_sepereted_term(adaptive_context, just_before=True)\n\n\n    base_re = \"((%s)\\s[\\s\\S]{0,50}(%s)%s)\" % (adaptive_context_re\n                            ,  \"|\".join(adaptive_entities + software_terms)\n                            , term_seperator)\n\n    if use_conventional_commits:\n        agg_re = \"((%s)|(%s))\" % (base_re\n                                  , build_cc_adaptive_regex())\n    else:\n        agg_re = base_re\n\n    return agg_re\n\n\n\ndef build_non_adaptive_context():\n\n    non_adaptive_header_action = \"|\".join([\n                                'transla(?:tion|et|eted|ets|ting)'\n                                ,  'readme(?:.md)?'\n                              ])\n\n    non_adaptive_header ='^[\\s\\S]{0,50}(%s)' % non_adaptive_header_action\n\n    entities = documentation_entities + ['bug',\n                'helper',\n                'miss(?:ing|ed)',\n                'to(?: |-)?do(?:s)?',\n                'warning(?:s)?'\n                ]\n\n    adaptive_actions = ['remov(?:e|es|ed|ing)']\n    non_adaptive_entities = documentation_entities + software_terms + unnedded_terms + [file_scheme]\n\n\n    return '(%s)' % \"|\".join(['(?:%s)\\s[\\s\\S]{0,50}(?:%s)' % (build_sepereted_term(adaptive_context, just_before=True)\n                                                            , \"|\".join(entities))\n                     , non_adaptive_header\n                     , '(?:%s)\\s[\\s\\S]{0,50}(?:%s)' % (build_sepereted_term(adaptive_actions, just_before=True)\n                                                            , \"|\".join(non_adaptive_entities))\n                     ])\n\n\ndef build_non_adaptive_linguistic():\n\n    return build_non_positive_linguistic(build_adaptive_regex(use_conventional_commits=False))\n\ndef build_core_adaptive_regex():\n\n    return '(%s)' % build_sepereted_term(core_adaptive_terms)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Classification Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def is_adaptive(text):\n\n    return (match(text, build_adaptive_regex())\n            + match(text, build_adaptive_action_regex())\n            - match(text, build_non_adaptive_context())\n            - match(text, build_non_adaptive_linguistic()))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adaptive = 0\nfor m in test['message']:\n    print(m)\n    print('CORRECTION: ' + str(is_adaptive(m)))\n    print(' ')\n    if is_adaptive(m) ==  True:\n        adaptive += 1\n        \nprint(adaptive)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Refactor"},{"metadata":{},"cell_type":"markdown","source":"### Keywords"},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://arxiv.org/pdf/2002.11049.pdf\nrefactor_entities = software_terms + ['(helper|utility|auxiliary) function(?:s)?']\n\n\n# Well, we need them...\nunnedded_terms = ['unnecessary', 'unneeded', 'unused', '(?:not|never|no longer) used'\n    #, 'old'\n    , 'no longer needed', 'redundant', 'useless', 'duplicate(?:d)?', 'deprecated', 'obsolete(?:d)?', 'commented']\n\ncore_refactor_terms = [\n    'clean(?:ing)?(?:-| )?up(?:s)?',\n    'clean(?:ing|s|ed)?',\n    'combin(?:e|es|ed|ing)',\n    'compos(?:e|es|ed|ing)',\n    'de(?:-| )?compos(?:e|es|ed|ing)',\n    'deprecat(?:e|es|ed|ing)',\n    'encapsulat(?:e|es|ed|ing)',\n    'polish(?:ed|es|ing)?',\n    're(?:-| )?factor(?:ed|s|ing|ings)?', # TODO - should be here - check why slightly decreases performance\n    're(?:-|)?organiz(?:e|es|ed|ing)',\n    're(?:-|)?structur(?:e|es|ed|ing)',\n    'rebuil(?:d|ds|ding|t)',\n    'tid(?:y|ying|ied)'\n]\n\n\nmodification_activity = [\n'(?:get|got|getting) rid',\n '(?:make|makes|made|making)',\n 'convert(?:ed|s|ing)?',\n 'dead',\n 'drop(?:ed|s|ing)?',\n 'duplicat(?:e|es|ed|ing)',\n 'extract(?:ed|s|ing)?',\n 'hide(?:e|es|ed|ing)',\n 'improv(?:e|es|ed|ing)',    # Goals modification only?\n 'increas(?:e|es|ed|ing)',\n 'mov(?:e|es|ed|ing)',\n 'parameteriz(?:e|es|ed|ing)',\n 'redundant',\n 'replac(?:e|es|ed|ing)',\n 'separat(?:e|e s|ed|ing)',\n 'short(:?en|er|ing|s)?',\n 'split(?:s|ing)?',\n 'subsitut(?:e|es|ed|ing)',\n 'substitut(?:e|es|ed|ing)',\n 'un(?:-| )?hid(?:e|es|ed|ing)'\n\n    #'chang(?:e|esed|ing)'\n    #, 'creat(?:e|es|ed|ing)'\n    #, 'delet(?:e|es|ed|ing)'\n    #, 'instead'\n    #, 'kill(?:ed|s|ing)?'\n    # , 'provid(?:e|es|ed|ing)'\n    #, 'introduc(?:e|es|ed|ing)'\n] + core_refactor_terms + unnedded_terms\n\nfeedbak_terms = [ 'py(?:-| )?lint', 'lint', 'review comments(?:s)?', 'code review', 'cr', 'pep8'\n                  ]\nfeedback_action = ['fix(?:ed|s|es|ing)?', 'fix(?:-| )?up(?:s)?', 'resolv(?:e|ed|es|ing)', 'correct(?:ed|s|es|ing)?']\n\nperfective_header_action = [\n    #'polish(?:ed|es|ing)?'\n    #, 'clean(?:ing|s|ed)?(?:-| )?up(?:s)?'\n     'clean(?:ing|s|ed)?(?:-| )?up(?:s)?'\n    , 'cleaner'\n    , 'deprecat(?:e|es|ed|ing)'\n    , 'extract(?:ed|s|ing)?',\n    're(?:-|)?organiz(?:e|es|ed|ing)', 're(?:-|)?structur(?:e|es|ed|ing)', 'tid(?:y|ying|ied) up'\n    , 'improv(?:e|ed|es|ing|ement|ements)' , 're(?:-|)?organiz(?:e|es|ed|ing)', 're(?:-|)?structur(?:e|es|ed|ing)'\n    , '(helper|utility|auxiliary) function(?:s)?'\n    , '(?:move|moved|moves|moving) to'\n    , 'separat(?:e|es|ed|ing)'\n    , 'split(?:s|ing)?', '->'\n    , build_sepereted_term(static_analyzers) + 'fix(es|ed)?'\n    , 'fix(es|ed)?' + build_sepereted_term(static_analyzers)\n\n    #, '(private|public|protected|static)'\n]\n\n# TODO - rewrited, move into/out???, deduplicate, remove legacy, redo, PR, feedback\n\n# TODO - clean , style, prettier, \"->\", refine, \"Removed commented code\", \"More startup improvements.\", recode\n# \"\"Remove another old function\", \"improved redis error message\", utility functions, never used\n# Checkstyle\n\n\n# TODO - perfective, not refactor - ident, spacing, tabs, \"tabs -> spaces\", cosmetic, \"\"*** empty log message ***\"\n# examples \"\"DOC: remove mention of TimeSeries in docs\"\n\n# TODO - add \"resolving review comments\"\n# TODO - lint, pylint\nrefactor_context = [ 'clean(ing)?(-| )?up(s)?'\n    ,'call(?:s|ed|ing)?[\\s\\S]{1,50}instead'\n    , 'collaps(?:e|es|ed|ing)', 'consolidat(e|es|ed|ing)'\n    , 'decompos(?:e|es|ed|ing)'\n    , 'drop(?:ed|s|ing)?( back)', 'encapsulat(e|es|ed|ing)'\n    , 'gereneliz(?:e|es|ed|ing)'\n                    # , 'inline'\n                    # , 'no longer needed', 'not used', 'obsolete(d)?'\n    , 'optimiz(?:e|es|ed|ing|ation|ations)'\n    , 'pull(?:ed|s|ing)? (up|down)', 're(?:-)?(?:write|wrote)', 're(?:-| )?factor(?:ed|s|ing|ings)?'\n    , 're(-)?implement(ed|s|ing)?'\n    , 'renam(?:e|es|ed|ing|ings)', 'better nam(?:e|es|ing)','re(?:-)?organiz(e|es|ed|ing)', 're(?:-)?organization'\n    , 're(?:-)?work(ed|s|ing|ings)?'\n    , 'reorg' , 'simplif(y|es|ied|ying|ication)', 'suppress(es|ed|ing)? warning(?:s)?'\n    , 'unif(?:y|ies|ied|ing)', 'uninline'\n    , 'beef(?:ed|s|ing)? up', 'refactor(?:ing)?(?:s)?', 'code improvement(?:s)?'\n    #, '(?:^|^[\\s\\S]{0,25}%s)(?:%s)%s[\\s\\S]{0,25}$' % (term_seperator, \"|\".join(perfective_header_action), term_seperator)\n    , 'revis(?:e|es|ed|ing)'\n    , 're(?:-)?construct(?:s|ed|ing)?'\n    , 're(?:-)?(?:write|write|wrote|writing)'\n    , 're(?:-)?cod(?:e|ed|es|ing)'\n    , 'factor(?:ed|s|ing)? out'\n    , 're(?:-| )?packag(?:e|es|ed|ing)'\n    #, 'code review'\n    #, 'collapse'\n    #, \"(?:(?:%s)(?:%s|%s[\\s\\S]{0,50}%s)(?:%s)%s)\" % (build_sepereted_term(feedback_action\n    #                                                                                      , just_before=True)\n    #                                                                 , term_seperator\n    #                                                                 , term_seperator\n    #                                                                 , term_seperator\n    #                                                                 , \"|\".join(feedbak_terms)\n    #                                                                 , term_seperator)\n                    # ,'us(e|es|ed|ing)[\\s\\S]{1,50}(instead)'\n                    # , '(instead)[\\s\\S]{1,50}us(e|es|ed|ing)'\n                    ]\n# https://refactoring.guru/refactoring/techniques\n\n# TODO - change [\\s\\S] with . ?\nremoval = [ 'add(?:s|ed|ing)?[\\s\\S]{1,50}helper(?:s)?'\n    ,  'us(?:e|es|ed|ing)[\\s\\S]{1,50}instead'\n    #,  'us(?:e|es|ed|ing)[\\s\\S]{1,25}\\(\\)[\\s\\S]{1,25}instead'\n    ,  'split(?:s|ing)?[\\s\\S]{1,50}into'\n    ,  'break(?:s|ing)?[\\s\\S]{1,50}into'\n    ,  'separat(?:e|e s|ed|ing)[\\s\\S]{1,50}into'\n    #,  'replac(?:e|es|ed|ing)?[\\s\\S]{1,50}with'\n    ,  'replac(?:e|es|ed|ing)?[\\s\\S]{1,50}(?:%s)' % \"|\".join(unnedded_terms)\n    , 'remov(?:e|es|ed|ing)[\\s\\S]{1,50}(?:%s)' % \"|\".join(unnedded_terms)\n    #, '(?:this|that|is)[\\s\\S]{1,50}(?:%s)' % \"|\".join(unnedded_terms)\n    ,  'kill(?:s|ed|ing)?[\\s\\S]{1,50}(?:%s)' % \"|\".join(unnedded_terms)\n    ,  'drop(?:s|ed|ing)?[\\s\\S]{1,50}(?:%s)' % \"|\".join(unnedded_terms)\n    ,  'mov(?:e|es|ed|ing)?[\\s\\S]{1,50}(?:%s)' % \"|\".join(unnedded_terms)\n            ]\nadaptive_context = [\n    '(?:un)?hid(?:e|es|den)', 'add(?:s|ed|ing)?', 'allow(?:s|ed|ing)?'\n    , 'buil(?:t|ds|ing)', 'calibirat(?:e|es|ed|ing)'\n    , 'configure'\n    , 'creat(?:e|es|ing)' #   O created\n    , 'deferr(?:ed|s|ing)?'\n    , 'disabl(?:e|es|ed|ing)'\n    , 'enhanc(?:e|es|ed|ing)', 'extend(?:s|ed|ing)?', 'form(?:ed|s|ing)?'\n    , 'implement(?:ed|s|ing)?', 'import(?:s|ed|ing)?', 'introduc(?:e|es|ed|ing)'\n    , 'port(?:s|ed|ing)?'\n    , 'provid(?:e|es|ed|ing)'\n    , 'report(?:s|ed|ing)?'\n    , 'support(s|ed|ing)?'\n    , 'updat(?:e|es|ed|ing)'\n    , 'upgrad(?:e|es|ed|ing)'\n\n    # , 'mov(e|es|ed|ing)'\n    # , 'print(s|ed|ing)?'\n\n\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Regex Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_core_refactor_regex():\n\n    return '(%s)' % build_sepereted_term(core_refactor_terms)\n\ndef build_refactor_regex(use_conventional_commits=True):\n    header_regex =  '(?:^|^[\\s\\S]{0,25}%s)(?:%s)%s' % (term_seperator\n                                                       , \"|\".join(perfective_header_action)\n                                                       , term_seperator)\n\n    activity_regerx = \"(?:(?:%s)(?:%s|%s[\\s\\S]{0,50}%s)(?:%s)%s)\" % (build_sepereted_term(modification_activity\n                                                                                          , just_before=True)\n                                                                     , term_seperator\n                                                                     , term_seperator\n                                                                     , term_seperator\n                                                                     , \"|\".join(refactor_entities)\n                                                                     , term_seperator)\n    if use_conventional_commits:\n        agg_re = \"(%s)|(%s)|(%s)|(%s)\" % (build_sepereted_term(refactor_context)\n                          , activity_regerx\n                          , header_regex\n                          , build_cc_refactor_regex())\n    else:\n        agg_re = \"(%s)|(%s)|(%s)\" % (build_sepereted_term(refactor_context)\n                          , activity_regerx\n                          , header_regex)\n    return agg_re\n\n\n\ndef build_refactor_goals_regex():\n    goals_regerx = \"(?:(?:%s)(?:%s|%s[\\s\\S]{0,50}%s)(?:%s)%s)\" % (build_sepereted_term(software_goals_modification\n                                                                                       , just_before=True)\n                                                                  , term_seperator\n                                                                  , term_seperator\n                                                                  , term_seperator\n                                                                  , \"|\".join(software_goals)\n                                                                  , term_seperator)\n    return goals_regerx\n\n\ndef build_non_code_perfective_regex():\n\n    non_perfective_entities = ['warning(?:s)?'\n                               , 'format(?:ing)?'\n                               , 'indentation(?:s)?'\n                              ]\n    # TODO - applied to perfective entities too here, which is a bug.\n    modification_action = ['clean(?:-| )?up(?:s)?']\n    non_perfective_context = [\n                            'fix(?:es|ed|ing)?'\n                            ,'(?:get|got|getting) rid'\n                            , 'support(?:s|ed|ing)?'\n                            ]\n    modifiers = modification_activity + non_perfective_context\n    activity_regerx = \"((?:%s)(?:\\s|%s[\\s\\S]{0,50}%s)(?:%s))\" % (build_sepereted_term(modifiers, just_before=True)\n                                                                                , term_seperator\n                                                                                , term_seperator\n                                                                                , \"|\".join(prefective_entities\n                                                                                           + non_perfective_entities))\n    doc_header_regex =  '(?:^|^[\\s\\S]{0,25}%s)(?:%s)[\\s\\S]{0,25}(?:%s)' % (term_seperator\n                                                       , \"|\".join(perfective_header_action)\n                                                       , build_sepereted_term(documentation_entities))\n\n\n    no_prefective_action = \"|\".join([\n        'convert(?:ed|s|ing)?(?:%s|%s[\\s\\S]{0,50}%s)support(?:s|ed|ing)?' % (\n            term_seperator,term_seperator, term_seperator)\n        , '(?:make|made|making|makes)(?:%s|%s[\\s\\S]{0,50}%s)work' % (term_seperator, term_seperator, term_seperator)\n        , '(?:make|made|making|makes)(?:%s|%s[\\s\\S]{0,50}%s)sense' % (term_seperator, term_seperator, term_seperator)\n        , 'improv(?:e|es|ed|ing) handling'\n        , 'need(?:s|ing)?\\srefactor(?:ing)?'\n        , '(?:%s)(?:%s|%s[\\s\\S]{0,50}%s)(?:%s)' %(build_sepereted_term(non_perfective_entities,just_before=True)\n                                                   ,term_seperator\n                                                   , term_seperator\n                                                   , term_seperator\n                                                   , \"|\".join(modification_action)\n                                                   )\n        , doc_header_regex\n\n    ])\n    non_perfective_context = '(?:%s|%s)' % (no_prefective_action\n                                         , activity_regerx)\n\n    return non_perfective_context\n\n\ndef build_documentation_entities_context(positive_re):\n\n    return '(?:%s)' % \"|\".join([\n        # TODO - take care of documentation entities spereatly\n         '(?:%s)[\\s\\S]{0,10}(?:%s)' % (build_sepereted_term(documentation_entities, just_before=True)\n                                        ,positive_re)\n    ])\n\ndef build_perfective_regex():\n    non_code = build_sepereted_term (prefective_entities)\n\n    perfective = \"(%s)\" %  non_code\n\n    return perfective","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Classification Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def built_is_refactor(commit_text):\n    removal_re = build_sepereted_term(removal)\n\n    return (match(commit_text, build_refactor_regex())\n            + match(commit_text, removal_re)\n            + match(commit_text, build_refactor_goals_regex())\n            - match(commit_text, build_non_code_perfective_regex())\n            - match(commit_text\n                    , build_documentation_entities_context(build_refactor_regex(use_conventional_commits=False)))\n            - match(commit_text\n                    , build_non_positive_linguistic(build_refactor_regex(use_conventional_commits=False)))\n            - match(commit_text, build_non_positive_linguistic(build_sepereted_term(removal)))\n            - match(commit_text, build_non_positive_linguistic(build_refactor_goals_regex()))\n            ) > 0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"refactors = 0\nfor m in test['message']:\n    print(m)\n    print('CORRECTION: ' + str(built_is_refactor(m)))\n    print(' ')\n    if built_is_refactor(m) ==  True:\n        refactors += 1\n        \nprint(refactors)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analysis"},{"metadata":{},"cell_type":"markdown","source":"### Timeframe  2000 to 2020"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.loc[df['date'] > '2000-01-01'].loc[df['date'] < '2021-01-01']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['date']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df['date'] > '2000-01-01'].loc[df['date'] < '2021-01-01']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#df['is_adpative'] = df[0:100]['message'].apply(lambda x: is_adaptive(str(x)))\ndf['is_core_bug'] = df['message'].apply(lambda x: is_core_bug(str(x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#df['is_fix'] = df['message'].apply(lambda x: is_fix(str(x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('data.pickle', 'wb') as f:\n    # Pickle the 'data' dictionary using the highest protocol available.\n    pickle.dump(df, f, pickle.HIGHEST_PROTOCOL)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load classified data"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('data.pickle', 'rb') as f:\n    # The protocol version used is detected automatically, so we do not\n    # have to specify it.\n    data = pickle.load(f)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"commits_sum = df.pivot_table(index='repo', columns='dday', values='message', aggfunc='count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"commits_sum = commits_sum.fillna(0).cumsum(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"commits_sum","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"commits_sum.loc['rstudio/rstudio'].dropna().plot.area()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"commits_sum.loc['tensorflow/tensorflow'].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"commits_sum.loc['apache/httpd'].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"commits_sum.where(commits_sum > 0).loc['kubernetes/kubernetes'].dropna().plot.area()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"repo_lang = pd.read_json('https://api.github.com/repos/apache/httpd/languages', orient='index')\n\nrepo_lang.plot.pie(figsize=(10,10), autopct='%1.1f%%',\n        shadow=True, startangle=90, subplots=True, fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(commits_sum.where(commits_sum > 0).loc['kubernetes/kubernetes'].dropna())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"commits_sum","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"summary = df.pivot_table(index='repo', values='message', aggfunc='count', margins=True)\nsummary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"users = df.groupby('repo')['user'].nunique()\nsummary = summary.join(users)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary['user'][-1] = summary['user'].dropna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary['message %'] = (summary['message']/summary.loc['All']['message']).apply(lambda x: \"{:.1%}\".format(x))\nsummary['user %'] = (summary['user']/summary.loc['All']['user']).apply(lambda x: \"{:.1%}\".format(x))\nsummary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['dday'][0:100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['week'] = df['dday'].apply(lambda x: x.strftime('%W'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"week = df.pivot_table(index='repo',columns=['week','year'],values='message', aggfunc='count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"week.mean(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#bugs = df.pivot_table(index='repo', values=['is_core_bug','is_fix'], aggfunc='sum')\nbugs = df.pivot_table(index='repo', values=['is_core_bug'], aggfunc='sum')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bugs = bugs.join(summary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bugs['is_not_core_bug'] = bugs['message'] - bugs['is_core_bug']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,5))\nfig.autofmt_xdate(rotation=90)\nbugs['bug %'] = bugs['is_core_bug']/bugs['message']\nbugs['other %'] = bugs['is_not_core_bug']/bugs['message']\nbugs = bugs.sort_values('bug %')\nax.bar(bugs.index, bugs['bug %'], label='bug', color='#f00000')\nax.bar(bugs.index, bugs['other %'], label='other', bottom=bugs['bug %'])\nax.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"commit_days = df.pivot_table(index='repo',columns=['dday'],values='message', aggfunc='count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"days = df.pivot_table(index='repo',columns=['dday'],values='is_core_bug', aggfunc='sum')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig.autofmt_xdate(rotation=90)\npd.plotting.boxplot(days.T, figsize=(15,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sm_stats.descriptivestats.describe(commit_days.T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"commit_days.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for repo in days.index:\n    fig, ax = plt.subplots()\n    ax.plot(days.loc[repo].dropna())\n    ax.set_title(repo)\n    #days.loc[repo].dropna().plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"days.loc['tidyverse/ggplot2'].reset_index().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = preprocessing.StandardScaler()\nday_norm = scaler.fit_transform(days.T).T\nday_norm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"days.mean().hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nfor repo in days.index:\n    fig, ax = plt.subplots()\n    ax.hist(day_norm.loc[repo])\n    #sns.lmplot(x='index',y=repo,data=days.loc[repo].reset_index().reset_index(), markers='.', palette=\"Set1\")\n    #ax.plot(days.loc[repo].dropna())\n    ax.set_title(repo)\n    #days.loc[repo].dropna().plot()\n    \n#sns.regplot(x='index', y='tidyverse/ggplot2' ,data=days.loc['tidyverse/ggplot2'].dropna().reset_index().reset_index())\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KDE"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KernelDensity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kde = KernelDensity(kernel='gaussian', bandwidth=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kde.fit(np.array(df.loc[df['repo'] == 'pandas-dev/pandas']['is_core_bug']).reshape(1,-1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bug Corrections Daily Proportions"},{"metadata":{"trusted":true},"cell_type":"code","source":"commit_months = commit_days.T.asfreq('M')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bug_months = days.T.asfreq('M')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bug_month_ratio = bug_months/commit_months","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_date = {}\nfor repo in bug_ratio.columns:\n    initial_date[repo] = bug_ratio[repo].dropna().head(1).index\ninitial_date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bug_month_ratio['matplotlib'] = bug_ratio.loc[bug_ratio.index > '2010-01-01']['matplotlib/matplotlib'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bug_month_ratio['ggplot2'] = bug_ratio.loc[bug_ratio.index > '2010-01-01']['tidyverse/ggplot2'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tests"},{"metadata":{},"cell_type":"markdown","source":"### Binomial Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"#sm_stats.proportion.binom_test(count, nobs, prop=0.5, alternative='two-sided')\nbin_test = {}\nfor repo in df['repo'].unique():\n    count = df.loc[df['repo'] == repo]['is_core_bug'].sum()\n    nobs = df.loc[df['repo'] == repo]['is_core_bug'].count()\n    bin_test[repo] = sm_stats.proportion.binom_test(count, nobs, prop=0.5, alternative='smaller')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(bin_test).sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bug_ratio.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pairs = [['tensorflow/tensorflow','pytorch/pytorch'],['tidyverse/ggplot2','matplotlib/matplotlib'],['denoland/deno','nodejs/node'],\n         ['facebook/react','angular/angular'],['apache/httpd', 'nginx/nginx'], ['rstudio/rstudio', 'jupyterlab/jupyterlab']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bin_test2 = {}\nfor repo in pairs:\n    print(repo[0])\n    print(repo[1])\n    count1 = df.loc[df['repo'] == repo[0]]['is_core_bug'].sum()\n    nobs1 = df.loc[df['repo'] == repo[0]]['is_core_bug'].count()\n    count2 = df.loc[df['repo'] == repo[1]]['is_core_bug'].sum()\n    nobs2 = df.loc[df['repo'] == repo[1]]['is_core_bug'].count()\n    #print(count1, nobs1, count2, nobs2 )\n    #print(count1/nobs1, count2/nobs2 )\n    bin_test2[repo[0]] = sm_stats.proportion.test_proportions_2indep(count1, nobs1, count2, nobs2, value=None, method=None, compare='diff', alternative='smaller', correction=True, return_results=False)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bin_test2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(bin_test2).T.rename({0:'stats',1:'p-value'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"[ bin_test2[k][1] < 0.05 for k in bin_test2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pairs_initial_date = []\nfor pair in pairs:\n    if initial_date[pair[0]] > initial_date[pair[1]]:\n        pairs_initial_date.append(0)\n    else:\n        pairs_initial_date.append(1)\npairs_initial_date        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Normality"},{"metadata":{"trusted":true},"cell_type":"code","source":"shapiro_test = stats.shapiro(bug_ratio['matplotlib/matplotlib'].dropna())\nshapiro_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats.kstest(bug_ratio['matplotlib/matplotlib'].dropna(), 'norm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bug_month_ratio['matplotlib'].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bug_month_ratio['ggplot2'].plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Two sample tests"},{"metadata":{"trusted":true},"cell_type":"code","source":"stats.ttest_ind(bug_month_ratio['matplotlib'], bug_month_ratio['ggplot2'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats.ks_2samp(bug_ratio['matplotlib/matplotlib'].dropna(), bug_ratio['tidyverse/ggplot2'].dropna())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats.wilcoxon(bug_month_ratio['matplotlib'], bug_month_ratio['ggplot2'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Time Series"},{"metadata":{"trusted":true},"cell_type":"code","source":"kpss = {}\nfor repo in days.index:\n    kpss[repo] = tsa.stattools.kpss(days.loc[repo].dropna(), nlags=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsa.stattools.kpss(days.loc['pytorch/pytorch'], nlags=120)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(kpss).T","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}