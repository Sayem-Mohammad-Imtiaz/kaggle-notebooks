{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Netflix Data Visualisation and recomendation system ##\n$\n\\\\Netflix\n$","metadata":{}},{"cell_type":"code","source":"# Importing required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing Netflix Dataset\n\ndf=df = pd.read_csv(\"/kaggle/input/netflix-shows/netflix_titles.csv\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#As we can see 'release_year' is string type, we need to convert this column into date type\ndf.date_added=pd.to_datetime(df.date_added )\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.show_id.isnull().value_counts())\nprint(df.type.isnull().value_counts())\nprint(df.title.isnull().value_counts())\nprint(df.director.isnull().value_counts())\nprint(df.cast.isnull().value_counts())\nprint(df.country.isnull().value_counts())\nprint(df.date_added.isnull().value_counts())\nprint(df.release_year.isnull().value_counts())\nprint(df.rating.isnull().value_counts())\nprint(df.duration.isnull().value_counts())\nprint(df.listed_in.isnull().value_counts())\nprint(df.description.isnull().value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"tags":[],"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" According to above description 'director':2389, 'cast':718, 'country':507, 'date_added':10, 'rating':7 has null value. We need to remove this null value or fill with corresponding values. ","metadata":{}},{"cell_type":"code","source":"#Visualize the null values through heat map\n!pip install missingno\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport missingno as ms","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"heatmap_null_values=ms.heatmap(df, figsize=(10,7), cmap='PuBuGn')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#count of unique values\nunique_val=df.nunique()\nunique_val","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Null values of corresponding rows\ndf[df.rating.isna()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fill 'ratings' NaN values with specific ratings\nuser_rating={67:'TV-MA', 2359:'R',3660:'R', 3736:'PG-13', 3737:'TV-MA', 3738:'R', 4323:'PG-13'}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.rating=df.rating.fillna(user_rating)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.rating.isnull().value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.rating.isna()] # No null values are present in rating column","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Replacing country null value with maximum number of country\ncountry=df.loc[df.country.notnull(), 'country'].astype('str').apply(lambda t: t.split(', '))\n\ncountry=list(country)\nlen(country)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install mlxtend","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mlxtend.frequent_patterns import apriori\nfrom mlxtend.preprocessing import TransactionEncoder","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Apriori is a popular algorithm for extracting frequent itemsets with applications in association rule learning. As we can see in 'country' cloumn frequent names are given, thats'y I have used apriori algorithm for finding frequency distribution","metadata":{}},{"cell_type":"code","source":"#Initiating encoder and fit and transform the encoder\nencoder_model=TransactionEncoder().fit(country)\n\nencode_country=encoder_model.transform(country)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creating new dataframe with encoded counties\ndf_encode=pd.DataFrame(encode_country, columns=encoder_model.columns_, index=df.loc[df.country.notnull(), 'show_id'])\ndf_encode.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"country_share=df_encode.mean().sort_values(ascending=False)\n\ncountry_share=country_share * 100\ncountry_share","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport matplotlib as mpl\n\nmpl.style.use('ggplot') # optional: for ggplot-like style\n\n# check for latest version of Matplotlib\nprint('Matplotlib version: ', mpl.__version__) # >= 2.0.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualiztion of country share in pie chart\n\n# take countries that share more than 1%\ncountry_share=country_share[country_share > 1 ]\nlabels=country_share.round(3).astype('str') + '%'\n#explode_list = [0.1, 0, 0, 0, 0.1, 0.1]\ncountry_share.plot(kind='pie', figsize=(10,10), labels=labels, shadow=True)\n\nplt.title('Percent of produced Movies/TV Show by Country', fontsize=20)\nplt.legend(labels=country_share.index, loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"tags":[],"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Another method\n# take countries that share more than 2%\ncountry_share_1 = country_share[country_share > 2]\nlabels = country_share_1.round(3).astype('str') + ' %'\n\nfig1, ax1 = plt.subplots(figsize=(10,10), facecolor='white')\nax1.pie(country_share_1, labels=labels, labeldistance=1.05,\n        shadow=True)\nplt.title('Percent of produced Movies/TV Show by Country', fontsize=20)\nplt.legend(labels=country_share_1.index, loc='upper right')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'Unites States' has the maximum frequency. I will fill 'NaN' value in country column with 'United States'","metadata":{}},{"cell_type":"code","source":"df['country']=df['country'].fillna('United States')\ndf.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Drop all the null values from cast column\ndf=df.dropna(subset=['cast'], how='all')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.cast.isnull().value_counts() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No missing value is present in 'cast' column","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"country_share","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Formation of dataframe from 'country_share' series. \ndf_country_share=country_share.to_frame().reset_index()\ndf_country_share.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_country_share=df_country_share.rename(columns={'index':'Country', 0:'Frequency'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_country_share.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualise data in World Map\nimport folium\nprint('Folium installed and imported')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"world_map = folium.Map()\nworld_map","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install xlrd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# download countries geojson file\n!wget --quiet https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DV0101EN-SkillsNetwork/Data%20Files/world_countries.json\n    \nprint('GeoJSON file downloaded!')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"world_json= '/kaggle/input/jsonfile/world_countries.json.1'\nworld_json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate choropleth map using Percent of produced Movies/TV Show of each country\nworld_map.choropleth(\n    geo_data=world_json,\n    data=df_country_share,\n    columns=['Country', 'Frequency'],\n    key_on='feature.properties.name',\n    fill_color='RdBu',\n    fill_opacity=0.7, \n    line_opacity=0.2,\n    legend_name='Percent of produced Movies/TV Show by Country'\n)\n\n# display map\nworld_map","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#Extraction of genre fron 'listed_in' column\ngenre=df['listed_in'].apply(lambda x:x.strip() )\ngenre=genre.str.split(', ')\n#another method:\n#genre=df['listed_in'].apply(lambda x:x.split(', ') )\ngenre\ngenre_list=list(genre)\nprint(genre_list[5])\nprint(len(genre_list))\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Initiate encoder for finding count of unique items","metadata":{"tags":[]}},{"cell_type":"code","source":"#Initiate encoder\ngenre_encoder=TransactionEncoder().fit(genre)\ntransform=genre_encoder.transform(genre)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_genre=pd.DataFrame(transform, columns=genre_encoder.columns_, index=df['show_id'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_genre.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Total number of counts of each genre type\ngenre_count=df_genre.sum().sort_values(ascending=False)\ngenre_count.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating Bar plot for genres\n\ngenre_count.plot(kind='bar', figsize=(15,7), color='b')\n\nplt.xlabel('Genre Type')\nplt.ylabel('Count of Contents')\nplt.title('Plot between Genre Type vs Count of Contents')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"movies=df[df['type']=='Movie']['release_year'].value_counts().rename('Movies').reset_index()\nTV_shows=df[df['type']=='TV Show']['release_year'].value_counts().rename('TV Shows').reset_index()\n\n#Sorting value counts by years\nmovies=movies.sort_values(by='index')\nTV_shows=TV_shows.sort_values(by='index')\n\nmovies_plot=movies.plot(kind='line', x='index', y='Movies', legend='Movies', color='r')\n\nTV_Show_plot=TV_shows.plot(kind='line', x='index', y='TV Shows', legend='TV Shows', color='g')","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Recomendation System ##","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import sigmoid_kernel\nmodel=TfidfVectorizer(max_df=2, min_df=1, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', max_features=None, stop_words='english', ngram_range=(1, 4))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['combination']= df['description'] + df['cast'] + df['director']\ndf.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['combination']=df['combination'].fillna(' ')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Utilising fit and transform method on model object\ntf_matrix=model.fit_transform(df['combination'])\n\nsigmoid=sigmoid_kernel(tf_matrix, tf_matrix)\nsigmoid[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices=pd.Series(df.index, index=df['title'].drop_duplicates())\nindices","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recommend(title,sig=sigmoid):\n    idx = indices[title]\n    sig_scores = list(enumerate(sig[idx]))\n    sig_scores = sorted(sig_scores,key = lambda x:x[1], reverse = True)\n    sig_scores = sig_scores[1:11]\n    movies_indices = [i[0] for i in sig_scores]\n    return df['title'].iloc[movies_indices]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recommend(\"Inside Man: Most Wanted\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Please drop your suggetions here for any kind of modification. Your suggestion will be appreciated toward more learning ##","metadata":{}}]}