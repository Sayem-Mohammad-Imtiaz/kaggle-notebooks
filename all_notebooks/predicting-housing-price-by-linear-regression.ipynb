{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Housing Case Study"},{"metadata":{},"cell_type":"markdown","source":"This notebook aims to analyse the dataset of a real estate company and build a model to optimize sales prices of the houses and its dependency on different parameters."},{"metadata":{},"cell_type":"markdown","source":"# Step-1 Reading and Understanding the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Supress Warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing the libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read the data by csv file\nhousing_data = pd.read_csv('../input/housing-simple-regression/Housing.csv')\nhousing_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above dataframe shows first 5 rows of dataset. This data set has both numerical and categorical data present in it. Let's check the last 5 rows of data set as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check the shape of the dataframe\nhousing_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This dataset contains 545 rows and 13 columns, out of which 6 columns contain numerical data while other 7 have categorical data."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check the information about the data\nhousing_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's check about null values\nhousing_data.isna().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clearly there are no null values present in the dataset.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#statstical summary of the data\nhousing_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This dataframe represents count, mean,standard deviation, minimum, maximum and interquartile values for each column containing numerical data."},{"metadata":{},"cell_type":"markdown","source":"# Step-2 Visualizing the data"},{"metadata":{},"cell_type":"markdown","source":"VISUALIZING NUMERICAL DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_data.hist(figsize=(20,20))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Histogram shows that only area and price have continous data while other columns such as bathrooms, bedrooms, parking and stories have discrete data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's make pairplot of numerical data\nsns.pairplot(housing_data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pairplots show there is a correlation between area and price. Now let's visualize categorical data as well."},{"metadata":{},"cell_type":"markdown","source":"**VISUALIZING CATEGORICAL DATA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Box plots\nplt.figure(figsize=(20,12))\nplt.subplot(2,3,1)\nsns.boxplot(x='mainroad', y='price', data=housing_data)\nplt.subplot(2,3,2)\nsns.boxplot(x='guestroom', y='price', data=housing_data)\nplt.subplot(2,3,3)\nsns.boxplot(x='basement', y='price', data=housing_data)\nplt.subplot(2,3,4)\nsns.boxplot(x='hotwaterheating', y='price', data=housing_data)\nplt.subplot(2,3,5)\nsns.boxplot(x='airconditioning', y='price', data=housing_data)\nplt.subplot(2,3,6)\nsns.boxplot(x='furnishingstatus', y='price', data=housing_data)\nplt.show()\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It can be clearly seen from box plots that furnishing status has three levels so dummy encoding has to be performed here. Also categorical data needs to be converted into numerical data for modelling."},{"metadata":{},"cell_type":"markdown","source":"# Step 3 Data Preparation"},{"metadata":{},"cell_type":"markdown","source":"Let's convert categorical data into numerical data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#List of variables to map\nvarlist= ['mainroad','guestroom','basement','hotwaterheating','airconditioning','prefarea']\n#Defining the map function\ndef binary_map(x):\n    return x.map({'yes':1,'no':0})\nhousing_data[varlist]=housing_data[varlist].apply(binary_map)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DUMMY VARIABLES**"},{"metadata":{},"cell_type":"markdown","source":"The attribute furnishingstatus has 3 levels. We need to convert this into numerical data as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get the dummy variable for the attribute furnishingstatus and store it in a new dataframe\ndf=pd.get_dummies(housing_data['furnishingstatus'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check how new dataset df looks like\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As it is clearly visible that there are 3 levels; furnished, semi-furnished and unfurnished but type of furnishing can be determined by only two columns so first column can be dropped."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's drop first column\ndf=pd.get_dummies(housing_data['furnishingstatus'], drop_first=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Add the above dataframe df into original housing_data dataframe\nhousing_data=pd.concat([housing_data, df], axis=1)\nhousing_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here in this concated dataframe previous attribute of furnishingstatus is still there so let's drop this."},{"metadata":{"trusted":true},"cell_type":"code","source":"housing_data.drop(['furnishingstatus'], axis=1, inplace= True)\nhousing_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 4 Scaling the data"},{"metadata":{},"cell_type":"markdown","source":"Except area all other attributes have very low integer values so MinMax Scaler will be used here. But first let's split the data into training and testing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting of data into train and test set\nfrom sklearn.model_selection import train_test_split\ntrain, test = train_test_split(housing_data,train_size=0.8,test_size=0.2,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scaling the features\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Apply scaler everywhere except categorical data\nnum = ['area','bedrooms','bathrooms','stories','parking','price']\ntrain[num] = scaler.fit_transform(train[num])\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's find outh the correlation matrix\ncorr=housing_data.corr()\ncorr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's check heatmap\nplt.figure(figsize=(16,10))\nsns.heatmap(corr,annot=True, cmap='YlGnBu')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As it is clearly seen from the correlation matrix and heatmap that there is no case of multicollinearity since maximum correlation lies between price and area which is 0.54."},{"metadata":{},"cell_type":"markdown","source":"# Step 5 Model Building"},{"metadata":{},"cell_type":"markdown","source":"Let's use automated feature selection."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nX_train= train\nY_train= train.pop('price')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**RECRUSIVE FEATURE ELIMINATION (RFE)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\nlm = LinearRegression()\nlm.fit(X_train, Y_train)\nrfe = RFE(lm, 10)             \nrfe = rfe.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Displaying the columns in order of preference that can be used for model building as suggested by RFE"},{"metadata":{"trusted":true},"cell_type":"code","source":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All those columns with ranking 1 and true are the most preferrable columns for RFE."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Display the columns suuported by RFE\ncol = X_train.columns[rfe.support_]\ncol","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Display the columns not supported by RFE\nX_train.columns[~rfe.support_]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Building model using statsmodel, for the detailed statistics"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating training dataframe with RFE selected variables\nX_train_rfe = X_train[col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_train_rfe = sm.add_constant(X_train_rfe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running the linear model\nlm = sm.OLS(Y_train,X_train_rfe).fit()   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's see the summary of our linear model\nprint(lm.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here cofficients for feature bedrooms are insignificant so it can be dropped"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drooping the bedrooms column\nX_train_new = X_train_rfe.drop([\"bedrooms\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rebuilding the model without bedrooms\n\nimport statsmodels.api as sm  \nX_train_lm = sm.add_constant(X_train_new)\nlm = sm.OLS(Y_train,X_train_lm).fit() \n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's see the summary of our linear model\nprint(lm.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop(['const'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the VIFs for the new model\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A variance inflation factor under 5 is considered to be good and here all the attributes have value of VIF<5, hence our model is doing great soo far"},{"metadata":{},"cell_type":"markdown","source":"# **Step 6 Residual Analysis on the training data**\nSo, now to check if the error terms are also normally distributed (which is infact, one of the major assumptions of linear regression), let us plot the histogram of the error terms and see what it looks like.\n\n\n\n\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicted value of price\nY_train_price = lm.predict(X_train_lm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying error terms\nfig = plt.figure()\nsns.distplot((Y_train - Y_train_price), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                   \nplt.xlabel('Errors', fontsize = 18)                         ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 7 Model evaluation on test data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Applying the scaling on the test sets\nnum = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking','price']\ntest[num] = scaler.transform(test[num])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test = test.pop('price')\nX_test = test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's use our model to make predictions.\n\n# Creating X_test_new dataframe by dropping variables from X_test\nX_test_new = X_test[X_train_new.columns]\n\n# Adding a constant variable \nX_test_new = sm.add_constant(X_test_new)\n# Making predictions\nY_pred = lm.predict(X_test_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying available and predicted price values for the test data \nfig = plt.figure()\nplt.scatter(Y_test,Y_pred)\nfig.suptitle('Y_test vs Y_pred', fontsize=20)            \nplt.xlabel('Y_test', fontsize=18)                          \nplt.ylabel('Y_pred', fontsize=16)                          ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since errors are normally distributed so our model is doing good enough. Hence final equation will be\nprice=(0.314*area+0.193*bathrooms+0.112*stories+0.040*mainroad+0.051*guestroom+0.111*hotwaterheating+0.082*airconditioning+0.07*parking+0.069*prefera)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}