{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport re\nimport nltk\n\nnltk.download('stopwords')\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv(\"/kaggle/input/sms-spam-collection-dataset/spam.csv\",encoding='latin-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataset.head())\nprint(\"Size of the dataset:\" , len(dataset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"required_dataset = dataset[['v1', 'v2']]\n\nrequired_dataset = required_dataset.dropna(how='any',axis=0)\n\nprint(\"Size of the required dataset(After removing other columns and removing Nulls):\" , len(required_dataset))\n\nprint(required_dataset.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus = []\n\nfor i in range(0, len(required_dataset)):\n  detailed_desc = re.sub('[^a-zA-Z]', ' ', str(required_dataset['v2'][i]))\n  detailed_desc = detailed_desc.lower()\n  detailed_desc = detailed_desc.split()\n  ps = PorterStemmer()\n  detailed_desc = [ps.stem(word) for word in detailed_desc if not word in set(stopwords.words('english'))]\n  detailed_desc = ' '.join(detailed_desc)\n  corpus.append(detailed_desc)\nprint(\"size of the corpus \", len(corpus))\nprint(\"corpus: \" , corpus[8])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating the bag of words model\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features= 500)\nX = cv.fit_transform(corpus).toarray()\ny = required_dataset.iloc[:,0].values\n#print(X)\nprint(X[12])\nprint(\"Dimension of Matrix :\" , X.shape)\nprint(y)\nprint(\"Size of the result list y\",len(y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#using Logistic regression with simple validation set..\nfrom sklearn.model_selection import train_test_split as tts\nx_train, x_test, y_train, y_test = tts(X, y, test_size=0.20, random_state = 0)\n\nprint(\"Creating a testing data set and training dataset using train_test_split lib\")\n\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nprint(\"Importing the logistic regression and accuracy_score\")\n\n\n# train a logistic regression model on the training set\n# instantiate model\nlrm_model = LogisticRegression(solver = 'newton-cg', multi_class = 'multinomial')\n\nprint(lrm_model)\n\n# fit model\nlrm_model.fit(x_train, y_train)\n\n# make class predictions for the testing set\nlrm_predictions = lrm_model.predict(x_test)\n\n# calculate accuracy\nmodel_accuracy = accuracy_score(y_test, lrm_predictions)\n\n# calculate accuracy on training data\nlrm_predictions_on_training_data = lrm_model.predict(x_train)\nmodel_accuracy_on_training_data = accuracy_score(y_train, lrm_predictions_on_training_data)\n\n\n#print(lrm_predictions)\n\nprint(\"-----------------------------------------------\")\nprint(\"Using Logistic Regression:\")\nprint(\"-----------------------------------------------\")\nprint(\"Size of the Feature Vector  :\", len(X[0]))\nprint()\nprint(\"Size of the Dataset         :\",len(X))\nprint()\nprint(\"Accuracy score of the model :\",model_accuracy)\nprint()\nprint(\"Accuracy score on training data:\",model_accuracy_on_training_data)\nprint()\n\n\n#accuracy using confusion matrix\nfrom sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\ncm = confusion_matrix(y_test,lrm_predictions)\n#print(cm)\ntmp = 0\ntt = 0\nfor i in range(0 , len(cm)):\n  for j in range(0, len(cm)):\n    tt += cm[i][j]\n    if i==j :\n      tmp += cm[i][j]\n      #print(cm[i][j])\n#print(tmp)\n#print(tt)\nprint(\"Accuracy score using confusion matrix: \",tmp/tt)\n\n#HeatMap\nfig, ax = plt.subplots(figsize=(15,15))\nsns.heatmap(cm, annot=True, fmt='d')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using Kfold for logistic regression Validation\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as plt\n\nlrm_model = LogisticRegression(solver = 'newton-cg', multi_class = 'multinomial')\n\nkf = KFold(n_splits=10, random_state=None, shuffle=False)\n\nX = np.array(X)\ny = np.array(y)\ncount=0\nfor train_index, test_index in kf.split(X):\n  print(count)\n  #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n  x_train, x_test = X[train_index], X[test_index]\n  y_train, y_test = y[train_index], y[test_index]\n  # fit model\n  # train a logistic regression model on the training set\n  # fit model\n  lrm_model.fit(x_train, y_train)\n\n  # make class predictions for the testing set\n  lrm_predictions = lrm_model.predict(x_test)\n\n  # calculate accuracy\n  model_accuracy = accuracy_score(y_test, lrm_predictions)\n\n  # calculate accuracy on training data\n  lrm_predictions_on_training_data = lrm_model.predict(x_train)\n  model_accuracy_on_training_data = accuracy_score(y_train, lrm_predictions_on_training_data)\n  #print(lrm_predictions)\n  print(\"-----------------------------------------------\")\n  print(\"Using Logistic Regression:\")\n  print(\"-----------------------------------------------\")\n  print(\"Size of the Feature Vector  :\", len(X[0]))\n  print()\n  print(\"Size of the Dataset         :\",len(X))\n  print()\n  print(\"Accuracy score of the model :\",model_accuracy)\n  print()\n  print(\"Accuracy score on training data:\",model_accuracy_on_training_data)\n  print()\n\n  #accuracy using confusion matrix\n  cm = confusion_matrix(y_test,lrm_predictions)\n  #print(cm)\n  tmp = 0\n  tt = 0\n  for i in range(0 , len(cm)):\n    for j in range(0, len(cm)):\n      tt += cm[i][j]\n      if i==j :\n        tmp += cm[i][j]\n        #print(cm[i][j])\n  #print(tmp)\n  #print(tt)\n  print(\"Accuracy score using confusion matrix: \",tmp/tt)\n  count+=1\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}