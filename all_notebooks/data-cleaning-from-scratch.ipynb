{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Data Cleaning from Scratch and Visualization of Cleanind Data\n\n # Data Cleaning Operation\n \n 1. Treatment Of Missing Values\n 2. Smoothing of noisy Data\n 3. Data Transformation","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"#### **Source of the database**: https://sci2s.ugr.es/keel/dataset/data/classification/pima-10-fold.zip\n\n   From National Institute of Diabetes and Digestive and Kidney Diseases. Several constraints \nwere placed on the selection of these instances from a larger database. In particular, all patients \nhere are females at least 21 years old of Pima Indian heritage. \n\n   The class label represents if the person has not diabetes (tested_negative) or the person \nhas diabetes (tested_positive). ","metadata":{}},{"cell_type":"markdown","source":"#### Attribute information: \n1. Preg = Number of times pregnant \n2. Plas = Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n3. Pres = Diastolic blood pressure (mm Hg) \n4. Skin = Triceps skin fold thickness (mm) \n5. Insu = 2-Hour serum insulin (mu U/ml) \n6. Mass = Body mass index (weight in kg/(height in m)^2) \n7. Pedi = Diabetes pedigree function \n8. Age = Age (years)\n","metadata":{}},{"cell_type":"markdown","source":"#### Missing Values: 50.65%","metadata":{}},{"cell_type":"markdown","source":"#### The program can be divided into 4 parts:\n1. Reading the CSV file\n2. Find the missing values and replaces them. (by any one of following methods).\n        a. Fill the missing value manually\n        b. Use a Global Constant\n        c. Use mean to fill the value\n        d. Use Median to fill the value\n3. Divide key values into bins and smoothing them. (by any one of the following methods)\n        a. Smooth by Bin Means\n        b. Smooth by Bin Boundaries\n4. Apply the normalization process. (by any of the following methods)\n        a. Min-max Normalization\n        b. Z-score normalization\n        c. Decimal Scaling","metadata":{}},{"cell_type":"code","source":"## Import Support libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport array\nimport math","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Reading the CSV File Downloaded from the source\ndf = pd.read_csv(\"../input/missing-values-pima-indians-diabetes-data/pima_Missing_values.csv\")\nprint(df.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data preprossessing ----\n### converting categorical column (output column) into nominal values","metadata":{}},{"cell_type":"code","source":"for i in range(0, 690):\n    if(df.Class[i] == 'tested_positive'):\n        df.Class[i] = 1\n    if(df.Class[i] == 'tested_negative'):\n        df.Class[i] = 0\ndf.Class = df.Class.astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### replacing \"< null >\" values as '-999' (to numeric)","metadata":{}},{"cell_type":"code","source":"sum = [0] * 8\nfor i in range(0,8):\n    for j in range(0, 690):\n        if(df.iloc[j, i] == '<null>'):\n            df.iloc[j, i] = -999\n            sum[i] = sum[i] + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### converting object datatype into float datatype ","metadata":{}},{"cell_type":"code","source":"for i in range(0, 8):\n    df.iloc[:, i] = df.iloc[:, i].astype(float)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Global Constants ----","metadata":{}},{"cell_type":"code","source":"GlobConst = [3, 110, 105, 18, 20.0, 26.5, 0.5, 30]\n\nprint(\"Global Constants for given database is: \")\nfor i in range(0, 8):\n\tprint(df.columns[i], \" = \", GlobConst[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## --------------------Filling the missing values-------\n\n### Using column Global Constant","metadata":{}},{"cell_type":"code","source":"def useGlobalConstant():\n\tfor i in range(0, 8):\n\t\tfor j in range(0, 690):\n\t\t\tif df.iloc[j, i] == -999:\n\t\t\t\tdf.iloc[j, i] = GlobConst[i]\n\tfor i in range(0, 8):\n\t\tfor j in range(0, 690):\n\t\t\tif df.iloc[j, i] == -999:\n\t\t\t\tprint('Error')\n\tprint(df.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using column Mean","metadata":{}},{"cell_type":"code","source":"def useMean():\n\tfor i in range(0, 8):\n\t\tcount = 0\n\t\tsumm = 0\n\t\tfor j in range(0, 690):\n\t\t\tif df.iloc[j, i] != -999:\n\t\t\t\tsumm = summ + df.iloc[j, i]\n\t\t\t\tcount = count + 1\n\t\tavg = summ / count\n\t\tavg = round(avg, 3)\n\t\tprint(\"col \", i, \" Average = \", avg, \" total missing = \", (690-count))\n\t\tfor j in range(0, 690):\n\t\t\tif df.iloc[j, i] == -999:\n\t\t\t\tdf.iloc[j, i] = avg\n\tprint(df.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using column Median","metadata":{}},{"cell_type":"code","source":"def useMedian():\n\tfor i in range(0, 8):\n\t\tcount = 0\n\t\tsr = df.iloc[:, i][df.iloc[:, i] != -999]\n\t\t# print(type(sr), \"  \", len(sr))\n\t\tmedian = sr.median()\n\t\tprint(\"col \", i, \" Median = \", median, \" total missing = \", (690 - len(sr)))\n\t\tfor j in range(0, 690):\n\t\t\tif df.iloc[j, i] == -999:\n\t\t\t\tdf.iloc[j, i] = median\n\tprint(df.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n\\nFilling the missing values choice: \")\nprint(\"\\n 1. Use a Global Constant\\n 2. Use mean to fill the value\\n 3. Use Median to fill the value\\n\")\nc = input(\"Choice = \")\nprint(c)\nif c == '1':\n\tuseGlobalConstant()\nelif c == '2':\n    useMean()\nelif c == '3':\n    useMedian()\nelse:\n    print(\"Invalid Input.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## --------------------Smooting data by binning------------","metadata":{}},{"cell_type":"code","source":"df_copy = df.iloc[:, 0:8].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Binning by frequency","metadata":{}},{"cell_type":"code","source":"def binningByFreqency(sr):\n\tnoOfBins = (int)(math.sqrt(690))\n\tsr = sr.sort_values()\n\tsort_index = np.array(sr.index)\n\trang = 690\n\tbinwidth = (int)(rang / noOfBins)\n\tbins = [[0 for i in range(binwidth)] for j in range(noOfBins)]\n\treturn(bins, sort_index, noOfBins, binwidth)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Smoothing:\n\n### Smoothing by bin means","metadata":{}},{"cell_type":"code","source":"def smoothByBinMeans():\n\tfor i in range(0, 8):\n\t\tsr = df.iloc[:, i]\n\t\tsr1 = [0 for i in range(0, 690)]\n\t\t(bins, ind, noOfBins, binwidth) = binningByFreqency(sr)\n\t\tn=0\n\t\tfor m in range(0, noOfBins):\n\t\t\tbins[m] = sr[n : (n + binwidth)]\n\t\t\tif(i == 5):\n\t\t\t\tbinMean = round(bins[m].mean(), 1)\n\t\t\telif(i == 6):\n\t\t\t\tbinMean = round(bins[m].mean(), 3)\n\t\t\telse:\n\t\t\t\tbinMean = (int)(bins[m].mean())\n\t\t\tbins[m] = [binMean for k in range(binwidth)]\n\t\t\tn = n + binwidth\n\t\tbins = np.array(bins).flatten()\n\t\t# print(bins)\n\t\tfor j in range(0, len(bins)):\n\t\t\tsr1[ind[j]] = bins[j]\n\t\tdf_copy.iloc[:, i] = sr1\n\tprint(\"CSV named \\\"BinnedDataPimaIndianDiabetes.csv\\\" is generated after binning.\")\n\tdf_copy.to_csv('BinnedDataPimaIndianDiabetes.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Smoothing by bin boundries","metadata":{}},{"cell_type":"code","source":"def smoothByBinBoundaries():\n\tfor i in range(0, 8):\n\t\tsr = df.iloc[:, i]\n\t\tsr1 = [0 for i in range(0, 690)]\n\t\t(bins, ind, noOfBins, binwidth) = binningByFreqency(sr)\n\t\tn=0\n\t\tfor m in range(0, noOfBins):\n\t\t\tbins[m] = sr[n : (n + binwidth)]\n\t\t\tfro = bins[m][0]\n\t\t\tbck = bins[m][binwidth-1]\n\t\t\tk=0\n\t\t\tfor l in bins[m]:\n\t\t\t\tx1 = l - fro\n\t\t\t\tx2 = bck - l\n\t\t\t\tif(x1 < x2):\n\t\t\t\t\tbins[m][k] = fro\n\t\t\t\telse:\n\t\t\t\t\tbins[m][k] = bck\n\t\t\t\tk = k + 1\n\t\t\tn = n + binwidth\n\t\t\t# print(bins[m])\n\t\tbins = np.array(bins).flatten()\n\t\tfor j in range(0, len(bins)):\n\t\t\tsr1[ind[j]] = bins[j]\n\t\tdf_copy.iloc[:, i] = sr1\n\tprint(\"CSV named \\\"BinnedDataPimaIndianDiabetes.csv\\\" is generated after binning.\")\n\tdf_copy.to_csv('BinnedDataPimaIndianDiabetes.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n\\nSmoothing by Binning methods: \")\nprint(\"\\n1. Smooth by Bin Means\\n2. Smooth by Bin Boundaries\")\nc = input(\"Choice = \")\nprint(c)\nif c == '1':\n\tsmoothByBinMeans()\nelif c == '2':\n\tsmoothByBinBoundaries()\nelse:\n\tprint(\"Invalid Input.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## -------------------Normalization --------------------------","metadata":{}},{"cell_type":"code","source":"df_copy2 = df.iloc[:, 0:8].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### min max normalization","metadata":{}},{"cell_type":"code","source":"def MinMaxNorm():\n\tfor i in range(0, 8):\n\t\tsr = df.iloc[:, i]\n\t\tsr1 = []\n\t\tmina = min(sr)\n\t\tmaxa = max(sr)\n\t\tprint(\"New min value for \", df.columns[i])\n\t\tnew_mina = round((float)(input()), 2)\n\t\tprint(\"New max value for \", df.columns[i])\n\t\tnew_maxa = round((float)(input()), 2)\n\t\tfor j in sr:\n\t\t\tsr1 = sr1 + [((j - mina) / (maxa - mina)) * (new_maxa - new_mina) + new_mina]\n\t\tdf_copy2.iloc[:, i] = sr1\n\tprint(\"\\nCSV named \\\"NormalizedDataPimaIndianDiabetes.csv\\\" is generated with normalized values.\")\n\tdf_copy2.to_csv('NormalizedDataPimaIndianDiabetes.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### z-score normalization","metadata":{}},{"cell_type":"code","source":"def ZScoreNorm():\n\tfor i in range(0, 8):\n\t\tsr = df.iloc[:, i]\n\t\tsr1=[]\n\t\tmean_sr = sr.mean()\n\t\tstd_sr = sr.std()\n\t\tfor j in sr:\n\t\t\tsr1 = sr1 + [(j - mean_sr) / std_sr]\n\t\tdf_copy2.iloc[:, i] = sr1\n\tprint(\"\\nCSV named \\\"NormalizedDataPimaIndianDiabetes.csv\\\" is generated with normalized values.\")\n\tdf_copy2.to_csv('NormalizedDataPimaIndianDiabetes.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### decimal scaling","metadata":{}},{"cell_type":"code","source":"def DecimalScal():\t\n\tfor i in range(0, 8):\n\t\tsr = df.iloc[:, i]\n\t\tmaxa = max(sr)\n\t\td = 1\n\t\tsr1 = []\n\t\twhile(maxa > 0):\n\t\t\tmaxa = (int)(maxa / 10)\n\t\t\td = d * 10\n\t\tfor j in sr:\n\t\t\tsr1 = sr1 + [j / d]\n\t\tdf_copy2.iloc[:, i] = sr1\n\tprint(\"\\nCSV named \\\"NormalizedDataPimaIndianDiabetes.csv\\\" is generated with normalized values.\")\n\tdf_copy2.to_csv('NormalizedDataPimaIndianDiabetes.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n\\nNormalization: \")\nprint(\"\\n1. Min-Max Normalization\\n2. Z-Score Normalization\\n3. Decimal Scaling\")\nc = input(\"Choice = \")\nprint(c)\nif c == '1':\n\tMinMaxNorm()\nelif c == '2':\n\tZScoreNorm()\nelif c == '3':\n\tDecimalScal()\nelse:\n\tprint(\"Invalid Input.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization of data:","metadata":{}},{"cell_type":"code","source":"df2 = pd.read_csv(\"./NormalizedDataPimaIndianDiabetes.csv\")\nprint(df2.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Correlation Matrix:","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 12))\nsns.set(rc={'figure.figsize':(12, 6)})\nsns.heatmap(df2.corr(), annot = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Univariate Analysis\n\n#### Target variable -> “Class” (0 = non-diabetic, 1 = diabetic)","metadata":{}},{"cell_type":"code","source":"df2['Class'] = df.iloc[:, 8]\nsns.countplot(x=\"Class\", data=df2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### All the columns are numerical, so we will plot the histograms of it. From it, we can view the distribution of the data.","metadata":{}},{"cell_type":"code","source":"df2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_columns = df.select_dtypes(exclude='object').columns.tolist()\nnum_columns.remove('Class')\nprint(num_columns)\n\nplt.figure(figsize=(16,40))\nfor i,col in enumerate(num_columns,1):\n    plt.subplot(8,4,i)\n    sns.kdeplot(df[col],shade=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### By using boxplots, we can analyse the outliers and inter-quartile range of data.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16,40))\nfor i,col in enumerate(num_columns,1):\n    plt.subplot(8,4,i)\n    df[col].plot.box()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the measures of below skewness and kurtosis value we can identify which column might have outliers.\n\nWe can see that “BloodPressure” and “DiabetesPedigree” has the kurtosis value >3,it means they have outlier values which can be normalized using some processing.","metadata":{}},{"cell_type":"code","source":"num_data = df[num_columns]\npd.DataFrame(data=[num_data.skew(),num_data.kurtosis()],index=['skewness','kurtosis'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Bivariate Analysis\n\n### With target variable","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,40))\n\nfor i,col in enumerate(num_columns,1):\n    plt.subplot(10,1,i)\n    if col in ['X','Y']:\n        sns.swarmplot(data=df,x=col,y='Class')\n    else:\n        sns.scatterplot(data=df,x=col,y='Class')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Multivariate Analysis","metadata":{}},{"cell_type":"code","source":"selected_features = df.columns\nprint(selected_features)\n\nsns.pairplot(df,hue='Class',vars=selected_features)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}