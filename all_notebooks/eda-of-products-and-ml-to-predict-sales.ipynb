{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Sales of summer clothes in E-commerce Wish\n\n## Content:\n\n## 1. EDA\nTopics covered and questions to answer from the data:\n* Comparison between price and retail price\n* Sales versus origin country\n* Sales comparison by colors\n* Sales comparison by ratings of products\n* What factor contributes most to a fast shipping badge?\n* Tags encoding\n* Which badge contribuits most to the sales of a product?\n* What kind of merchants are likely to gain product success?\n\n## 2. Experimenting with the data to gain prediction insights\nWe are going to build a model that can help predict how well a product is going to sell, i.e., the exact sales for each product.\n\nSuch a model has many implications and could be used in many different ways, the most straightforward being to adjust how much of a product should be kept in stock.\n\nBefore we select and train a model, we should experiment and combine more with data to find inspirations to prediction. For exemple, do proportions of good ratings and bad ratings, number of tags (making a product more discoverable) and price drops factor into the success of a product?\n\n\n## 3. Prepare the data for Machine Learning algorithms\nAfter we settled on all the features to be used, we need to prepare the data for Machine Learning algorithms.\n\n\n## 4. Select and train a model\nIn this project, I will be using four common classification model to see which performs best. In the end, fine-tune the best model.\n\nOBS: We need to divide the dataset into training set and test set. The training set is be preprocessed, and each model is trained and validated using cross-validation. During this process, we put the test set aside and don't even look at it to make sure the model is unbaised. Once the model type and hyperparameters have been selected, the generalized error is measured on the test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\nimport plotly\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2, venn2_circles, venn2_unweighted\nfrom matplotlib_venn import venn3, venn3_circles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data cleaning"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"wish=pd.read_csv(\"../input/summer-products-and-sales-in-ecommerce-wish/summer-products-with-rating-and-performance_2020-08.csv\")\nwish.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None)\nwish.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wish.drop(columns=['title_orig','merchant_name','merchant_info_subtitle','merchant_id',\n                   'merchant_profile_picture','product_url','product_picture','product_id','crawl_month','theme','currency_buyer'],inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"wish.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"nan_replace={'has_urgency_banner':0,'urgency_text':'N/A','origin_country':'unknown','product_color':'unknown'}\nwish.fillna(nan_replace,inplace=True)\nwish_cln=wish.dropna()\nwish_cln.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. EDA"},{"metadata":{},"cell_type":"markdown","source":"# Comparison between price and retail price"},{"metadata":{},"cell_type":"markdown","source":"Retail price is used by the seller to indicate a regular value or the price before discount. How do price, retai price and the price drop in discount define the product success?"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"price_cmp=wish_cln[['price','retail_price','units_sold']]\nprice_cmp.describe()\nprice_cmp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(20,12))\nsns.scatterplot(data=wish_cln,\n               x=\"price\",\n               y='units_sold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"trace1 = go.Violin(y=price_cmp[\"price\"],name='Price')\ntrace2 = go.Violin(y=price_cmp[\"retail_price\"],name='Retail price')\nfig=go.Figure([trace1, trace2])\nfig.update_layout(\ntitle='Comparison between price and retail price',\nyaxis_title='Price(EUR)')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"price_cmp['price_drops']=price_cmp[\"retail_price\"]-price_cmp[\"price\"]\nplt.figure(figsize=(20,12))\nsns.regplot(data=price_cmp,\n           x='price_drops',\n           y='units_sold')\nplt.title('Prices drops versus units sold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a visible downward trend in units sold as the price increases. Products with high sales are usually concentrated in the price range of 0-20.\n\nThe difference between actuall price and retail price is quite large. Prices are more concentrated while the retail prices have significantely more outliers. This could be a popular sales strategy.\n\nThe steep prices drops don't necessarily result in product success. \n"},{"metadata":{},"cell_type":"markdown","source":"# Sales versus origin country"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"country_price=wish_cln[['units_sold','origin_country']]\ncountry_mean_price=country_price.groupby('origin_country')['units_sold'].mean().reset_index()\ncountry_mean_price.rename(columns={'units_sold': 'units_sold_mean'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"to_codes={'CN':'CHN',\n         'GB':'GBR',\n         'SG':'SGP',\n         'US':'USA',\n         'VE':'VEN'}\ncountry_mean_price['code']=country_mean_price['origin_country'].map(to_codes)\ncountry_mean_price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"country_sales_map=px.choropleth(country_mean_price,\n                       color='units_sold_mean',\n                       locations='code',\n                       hover_name='code',\n                       color_continuous_scale=px.colors.sequential.Plasma,\n                       title='Sales verses origin country')\ncountry_sales_map.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Products from Singapore and China have higher average sales than the ones from other countries such as Britain, US and Vietnam."},{"metadata":{},"cell_type":"markdown","source":"# Sales comparison by colors"},{"metadata":{},"cell_type":"markdown","source":"Find out the ten most popular colors by sorting out units sold."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"color_sale=wish_cln.groupby('product_color')['units_sold'].sum()\ncolor_sale=color_sale.reset_index().sort_values(by='units_sold',ascending=False)\ncolor_sale","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"top_10_color_sale=color_sale.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig=px.bar(data_frame=top_10_color_sale,\n      x='product_color',\n      y='units_sold')\nfig.update_layout(title='Top 10 color sales')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Let's take a look at the sales of all the colors in case we miss some emerging fashion trend."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig=px.bar(data_frame=color_sale,\n      x='product_color',\n      y='units_sold')\nfig.update_layout(title='All color sales')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that some more specific colors sells well too, such as orange, navyblue and winered. "},{"metadata":{},"cell_type":"markdown","source":"# Sales comparison by ratings of products"},{"metadata":{},"cell_type":"markdown","source":"To start with, let's take a look at the distribution of ratings."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"rating_cols=['rating_count','rating_five_count','rating_four_count',\n             'rating_three_count','rating_two_count','rating_one_count']\nratings_data=wish_cln[rating_cols+['uses_ad_boosts']]\n\nratings_data.groupby('uses_ad_boosts').describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Use box plot to visualize how add boosts define the distributions of ratings."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure()\nfor col in rating_cols:\n    fig.add_trace(go.Box(x=ratings_data['uses_ad_boosts'],\n                         y=ratings_data[col],\n                         name=col,\n                         boxmean=True,\n                         boxpoints=False))\nfig.update_traces(quartilemethod=\"exclusive\")\nfig.update_layout(boxmode='group',\n                  title='Relations between ad boosts and rating',\n                  xaxis = dict(\n                  tickvals = [0,1],\n                  ticktext = ['Without add boosts','With add boosts']))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" By dividing the data into two groups of \"with\" and \"without add boosts\", we can see that surprisingly,  produsts without add boosts gain higher number of ratings on average, the same goes for number of 5, 4, 3, 2, 1-star ratings.\n \n Now let's analyse how ratings factor into sales, which is what really matters."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cmp_table=wish_cln[['units_sold','rating','rating_count']]\nplt.figure(figsize=(20,12))\nsns.jointplot(data=cmp_table,\n             x='rating',\n             y='units_sold')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Successful products sold more than 20,000 pieces usually have a mean rating above 3.5.\n\nNow let's analyze how mean rating and number of ratings define sales respectively using 3D plot."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"line=go.Scatter3d(x=cmp_table['rating'],\n                  y=cmp_table['rating_count'],\n                  z=cmp_table['units_sold'])\nfig=go.Figure(line)\nfig.update_layout(title='Impact of rating and rating count to sales',\n                  height = 1000,\n                  width = 1000,\n                  scene = dict(\n                  xaxis_title='rating',\n                  yaxis_title='rating_count',\n                  zaxis_title='units_sold'))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There's a visible upward trend of sales as numbers of ratings increase. Meanwhile, the average rating popularity will not have such a big impact on sales, however, as mentioned earlier, products with higher sales are mainly concentrated in ratings above 3.5."},{"metadata":{},"cell_type":"markdown","source":"# What factor contributes most to a fast shipping badge?"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"index,name=wish_cln['shipping_option_name'].factorize()\nwish_cln['shipping_option_index']=index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"corr_map=wish_cln[['badge_fast_shipping','shipping_option_index','shipping_option_price','shipping_is_express','countries_shipped_to']]\ncorr_map=corr_map.corr()\nplt.figure(figsize=(20,12))\nsns.heatmap(corr_map,annot=True,cmap='Blues')\nplt.xticks(rotation=45,fontsize=14)\nplt.yticks(rotation=45,fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tags encoding"},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"from wordcloud import WordCloud\n\ntags_for_count=[]\n\nfor x in wish_cln['tags']:\n    for word in str(x).split(sep=','):\n        word=word.lower()\n        tags_for_count.append(word)\ntags_for_count       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.subplots(figsize=(25,15))\nwordcloud = WordCloud(\n                          background_color='white',\n                          width=1920,\n                          height=1080\n                         ).generate(\" \".join(tags_for_count))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" From the words clouds, we can see the most frequent words the merchants put in tags are \"women\", \"fashion\", \"plus\", \"size\", \"sexy\" and \"shirt\", ect.."},{"metadata":{},"cell_type":"markdown","source":"# Which badge contributes most to the sales of a product?"},{"metadata":{},"cell_type":"markdown","source":" For better visualization of the distribution of badges, I sorted out new columns of \"badge1_badge2\", \"badge1_badge3\", \"badge2_badge3\" and \"badge1_badge2_badge3\" to indicate if the product have two of them or all of them."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"wish_cln[wish_cln['badges_count']!=0].head(10)\nbadges=wish_cln[['badges_count','badge_local_product', 'badge_product_quality', 'badge_fast_shipping']]\n\nbadges_cats=[]\n\nfor i in badges.index:\n    categories = ['badge_local_product', 'badge_product_quality', 'badge_fast_shipping']\n    codes = badges.loc[[i],['badge_local_product', 'badge_product_quality', 'badge_fast_shipping']].values.reshape(3,).tolist()\n    zipped = zip(codes,categories)\n    my_cats=[]\n    for m,n in list(zipped):\n        my_cats.append(m*n)\n    badges_cats.append(my_cats)\nbadges_cats = pd.Series((v[0]+v[1]+v[2] for v in badges_cats))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"badges.drop(columns=['badge_local_product', 'badge_product_quality', 'badge_fast_shipping'],inplace=True)\nbadges['badges_cats']=badges_cats.values\nbadges['records']=np.ones((1514,))\nbadges_data=badges.groupby(['badges_count','badges_cats']).count().reset_index()\nbadges_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Overwhelming majority products (1368/1514) don't have any badge; it's more common to have badge of product quality among those have badges; only 2 products have all the badges."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"badges_cmp=wish_cln[['title','units_sold','badges_count','badge_local_product','badge_product_quality','badge_fast_shipping']]\nplt.figure(figsize=(20,20))\nsns.pairplot(data=badges_cmp,kind='reg')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Neither the number of badges nor any kind of badge affects much the sales."},{"metadata":{},"cell_type":"markdown","source":"# What kind of merchants are likely to gain product success?"},{"metadata":{},"cell_type":"markdown","source":"Pull out all the columns concerning merchant information from dataset.\n\nAs the ratings and numbers of ratings of merchants are discrete numericals, it's better to divide them into several bins."},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"merchant_sales=wish_cln[['merchant_title','merchant_rating_count',\n                         'merchant_rating','merchant_has_profile_picture','units_sold']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merchant_sales['merchant_rating'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merchant_sales['merchant_rating'].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"bins1 = [2.9, 3.5, 4.0, np.inf]\ncats1 = pd.cut(merchant_sales['merchant_rating'],bins1)\nmerchant_sales['merchant_raing_cats']=cats1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"bins2 = [0, 250000, 900000, np.inf]\ncats2 = pd.cut(merchant_sales['merchant_rating_count'],bins2)\nmerchant_sales['raing_count_cats']=cats2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"merchant_top_50 = merchant_sales.groupby(['merchant_has_profile_picture','merchant_title','merchant_raing_cats','raing_count_cats'])['units_sold'].sum().nlargest(50).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = px.bar(data_frame = merchant_top_50,\n           x = 'merchant_title',\n           y = 'units_sold',\n           color = 'merchant_raing_cats',\n           facet_col = 'merchant_has_profile_picture',\n           facet_row = 'raing_count_cats',\n           width = 1200, height = 800)\nfig.update_layout(title = 'Top 50 merchants')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Among the top 50 merchants, the majority have number of ratings less than 250,000, mean ratings above 4.0 and have profile picture."},{"metadata":{},"cell_type":"markdown","source":"# 2. Experimenting with the data to gain prediction insights"},{"metadata":{"trusted":true},"cell_type":"code","source":"wish_cln_copy = wish_cln.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clean and simplify the product color column by keeping the values of top ten best seller colors and setting other colors as \"others\"."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"color_sale = wish_cln_copy.groupby('product_color')['units_sold'].sum()\ncolor_sale = color_sale.reset_index().sort_values(by = 'units_sold',ascending=False)\ntop_10_color_sale = color_sale.head(10)\ntop_10 = list(top_10_color_sale['product_color'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"wish_cln_copy['product_color'][~wish_cln_copy['product_color'].isin(top_10)]='other'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"wish_cln_copy['product_color'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Also, let's add a column of the numbers of tags."},{"metadata":{"trusted":true},"cell_type":"code","source":"f = lambda x: len(x)\nwish_cln_copy['tags_num'] = wish_cln_copy['tags'].apply(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wish_cln_copy['rating_count'].hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We will divide the dataset into training set and test set. The training set is preprocessed, and each model is trained and validated using cross-validation. During this process, we put the test set aside and don't even look at it to make sure the model is unbaised. Once the model type and hyperparameters have been selected, the generalized error is measured on the test set."},{"metadata":{},"cell_type":"markdown","source":" As the EDA showed before, the numbers of ratings have a major impact on sales. To ensure the test set is representative of the various categories of numbers ratings in the whole dataset, we need to create a category attribute and divide the dataset into homogeneous subgroup."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sns.scatterplot(data=wish_cln_copy,x='rating_count',y='units_sold')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"wish_cln_copy[\"rating_count_cat\"] = pd.cut(wish_cln_copy[\"rating_count\"],\n                               bins=[0, 300, 1000, np.inf],\n                               labels=[1, 2, 3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"wish_cln_copy[\"rating_count_cat\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(wish_cln_copy, wish_cln_copy[\"rating_count_cat\"]):\n    strat_train_set = wish_cln_copy.iloc[train_index]\n    strat_test_set = wish_cln_copy.iloc[test_index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, the test and train sets generated using stratified sampling has rating count category proportions almost identical to those in the full dataset."},{"metadata":{"scrolled":true,"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"strat_test_set[\"rating_count_cat\"].value_counts() / len(strat_test_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"strat_train_set[\"rating_count_cat\"].value_counts() / len(strat_train_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"for set_ in (strat_train_set, strat_test_set):\n    set_.drop(\"rating_count_cat\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Make a copy pf train set to experiment the attributes and their correlations with the target attribute."},{"metadata":{"trusted":true},"cell_type":"code","source":"wish_exp = strat_train_set.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = wish_exp.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"corr_matrix[\"units_sold\"].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the the correlation matrix, it's clearly that numbers of ratings from one to five all greatly contribute to the sales, which doesn't sound right from common sense: a product with massive sheerly bad ratings is not likely to sell well. We probably want to compare the numbers of each kind of rating with the overall numbers of ratings."},{"metadata":{"trusted":true},"cell_type":"code","source":"wish_exp['rating_three_count_prop']=wish_exp['rating_three_count']/wish_exp['rating_count']\nwish_exp['rating_four_count_prop']=wish_exp['rating_four_count']/wish_exp['rating_count']\nwish_exp['rating_five_count_prop']=wish_exp['rating_five_count']/wish_exp['rating_count']\nwish_exp['rating_two_count_prop']=wish_exp['rating_two_count']/wish_exp['rating_count']\nwish_exp['rating_one_count_prop']=wish_exp['rating_one_count']/wish_exp['rating_count']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Also, let's calculate the price drop."},{"metadata":{"trusted":true},"cell_type":"code","source":"wish_exp['drops']=wish_exp[\"retail_price\"]-wish_exp[\"price\"]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"corr_matrix = wish_exp.corr()\ncorr_matrix[\"units_sold\"].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can keep the new attributs of proportions of ratings and price drop."},{"metadata":{},"cell_type":"markdown","source":"# 3. Prepare the data for Machine Learning algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"wish = strat_train_set.drop(\"units_sold\", axis=1) # drop labels for training set\nwish_labels = strat_train_set[\"units_sold\"].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"wish.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Which numerical features are most important?\n\nFirst of all, we need to drop text features. To predict the sales of products, the inventory and countries_shipped_to is a possible source of leakage, because these information can change over time. I will also not include unimportant features such as 'badge_fast_shipping','shipping_is_express', to avoid overfitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"wish_num = wish.drop(['title','tags','product_variation_size_id','product_variation_inventory',\n                      'inventory_total','product_color','origin_country','urgency_text',\n                      'shipping_option_name','badge_fast_shipping','shipping_option_index',\n                      'merchant_title','countries_shipped_to'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"wish_num.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wish_cat = wish[['product_color','origin_country','shipping_option_name']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\ncat_encoder = OneHotEncoder(sparse=False)\nwish_cat_1hot = cat_encoder.fit_transform(wish_cat)\nwish_cat_1hot","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"cat_encoder.categories_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use FunctionTransformer to add the combined attributes we discussed earlier."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import FunctionTransformer\n\none_ix, two_ix, three_ix, four_ix, five_ix, rating_count_ix, retail_price_ix, price_ix= [\n    list(wish.columns).index(col)\n    for col in (\"rating_one_count\", \"rating_two_count\", \n                \"rating_three_count\", \"rating_four_count\",\n               'rating_five_count', 'rating_count','retail_price','price')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_extra_features(X):\n    rating_one_count_prop = X[:,one_ix]/ X[:,rating_count_ix]\n    rating_two_count_prop = X[:,two_ix]/ X[:,rating_count_ix]\n    rating_three_count_prop = X[:,three_ix]/ X[:,rating_count_ix]\n    rating_four_count_prop = X[:,four_ix]/ X[:,rating_count_ix]\n    rating_five_count_prop = X[:,five_ix]/ X[:,rating_count_ix]\n    drops = X[:,retail_price_ix] - X[:,price_ix]\n    return np.c_[X, rating_one_count_prop, rating_two_count_prop, \n                 rating_three_count_prop,rating_four_count_prop, \n                 rating_five_count_prop,drops]\n\nattr_adder = FunctionTransformer(add_extra_features, validate=False)\nwish_extra_attribs = attr_adder.transform(wish.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"attr_adder","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test if the FunctionTransformer works fine before building the pipeline."},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"wish_extra_attribs = pd.DataFrame(\n    wish_extra_attribs,\n    columns = list(wish.columns)+[\"rating_one_count_prop\", \"rating_two_count_prop\",\n                               'rating_three_count_prop','rating_four_count_prop',\n                               'rating_five_count_prop','drops'],\n    index = wish.index)\nwish_extra_attribs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nnum_pipeline = Pipeline([\n        ('imputer', SimpleImputer(strategy=\"median\")),\n        ('std_scaler', StandardScaler()),\n        ('attribs_adder', FunctionTransformer(add_extra_features, validate=False))])\n\nwish_num_tr = num_pipeline.fit_transform(wish_num)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"wish_num_tr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Building the full pipeline to preprocessing numerical and categorical features.\nfrom sklearn.compose import ColumnTransformer\nnum_attribs = list(wish_num)\ncat_attribs = list(wish_cat)\n\nfull_pipeline = ColumnTransformer([\n        (\"num\", num_pipeline, num_attribs),\n        (\"cat\", OneHotEncoder(), cat_attribs),\n    ])\n\nwish_prepared = full_pipeline.fit_transform(wish)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"wish_prepared","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Select and train a model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost.sklearn import XGBClassifier \nfrom sklearn.model_selection import KFold,cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_models = [('DT_model',DecisionTreeClassifier(random_state=42)),\n            ('RF_model',RandomForestClassifier(random_state=42,n_jobs=-1)),\n            ('LR_model',LogisticRegression(random_state=42,n_jobs=-1)),\n            (\"XGB_model\", XGBClassifier(random_state=42, n_jobs=-1))]\n# split data into 'kfolds' parts for cross validation,\n# use shuffle to ensure random distribution of data:\nkfolds = 4\nsplit = KFold(n_splits=kfolds,shuffle=True,random_state=42)\n\n# Preprocessing, fitting, making predictions and scoring for every model:\nfor name,model in base_models:\n    model_steps = Pipeline(steps=[('model',model)])\n    model_steps.fit(wish_prepared, wish_labels)\n    cv_results = cross_val_score(model_steps,wish_prepared,wish_labels,cv=split,scoring='accuracy',\n                              n_jobs=-1)\n    # output:\n    min_score = round(min(cv_results),4)\n    max_score = round(max(cv_results),4)\n    mean_score = round(np.mean(cv_results),4)\n    std_dev = round(np.std(cv_results),4)\n    print(f'{name} cross validation accuracy score:{mean_score} +- {std_dev} (std) min:{min_score},max:{max_score}')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the accuracy score of RF_model and XGB_model are close and in order to avoid overfitting, let's validate both models on the test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"XGB_clf = XGBClassifier(random_state=42,n_jobs=-1)\n\nX_test = strat_test_set.drop(\"units_sold\", axis=1)\ny_test = strat_test_set[\"units_sold\"].copy()\nX_test_prepared = full_pipeline.transform(X_test)\n\nkfolds = 4\nsplit = KFold(n_splits=kfolds,shuffle=True,random_state=42)\n\ncv_results = cross_val_score(XGB_clf,X_test_prepared,y_test,cv=split,scoring='accuracy',\n                              n_jobs=-1)\nmin_score = round(min(cv_results),4)\nmax_score = round(max(cv_results),4)\nmean_score = round(np.mean(cv_results),4)\nstd_dev = round(np.std(cv_results),4)\nprint(f'XGB_model cross validation accuracy score:{mean_score} +- {std_dev} (std) min:{min_score},max:{max_score}')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_clf = RandomForestClassifier(random_state=42,n_jobs=-1)\n\nX_test = strat_test_set.drop(\"units_sold\", axis=1)\ny_test = strat_test_set[\"units_sold\"].copy()\nX_test_prepared = full_pipeline.transform(X_test)\n\nkfolds=4\nsplit=KFold(n_splits=kfolds,shuffle=True,random_state=42)\n\ncv_results=cross_val_score(RF_clf,X_test_prepared,y_test,cv=split,scoring='accuracy',\n                              n_jobs=-1)\nmin_score=round(min(cv_results),4)\nmax_score=round(max(cv_results),4)\nmean_score=round(np.mean(cv_results),4)\nstd_dev=round(np.std(cv_results),4)\nprint(f'RF_model cross validation accuracy score:{mean_score} +- {std_dev} (std) min:{min_score},max:{max_score}')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Random Forest model performs the best for predicting the sales of procuts."},{"metadata":{},"cell_type":"markdown","source":"I also did some hyperparameter optimization. Sometimes I got a slightly better accuracy score the refined model, sometimes it's even worse."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint\nimport numpy as np\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nparam_distribs = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\nforest_clf = RandomForestClassifier(random_state=42, n_jobs=-1)\nrnd_search = RandomizedSearchCV(forest_clf, param_distributions=param_distribs,\n                                n_iter=5, cv=4,scoring=\"accuracy\", random_state=42)\nrnd_search.fit(wish_prepared, wish_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"rnd_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# final_model = grid_search.best_estimator_\nfinal_RF_clf = RandomForestClassifier(random_state=42,n_jobs=-1,n_estimators= 1366,\n min_samples_split= 5,\n min_samples_leaf= 1,\n max_features='sqrt',\n max_depth= 30,\n bootstrap= True)\n\nX_test = strat_test_set.drop(\"units_sold\", axis=1)\ny_test = strat_test_set[\"units_sold\"].copy()\nX_test_prepared = full_pipeline.transform(X_test)\n\nkfolds=4\nsplit=KFold(n_splits=kfolds,shuffle=True,random_state=42)\n\ncv_results=cross_val_score(final_RF_clf,X_test_prepared,y_test,cv=split,scoring='accuracy',\n                              n_jobs=-1)\nmin_score=round(min(cv_results),4)\nmax_score=round(max(cv_results),4)\nmean_score=round(np.mean(cv_results),4)\nstd_dev=round(np.std(cv_results),4)\nprint(f'Final_RF_model cross validation accuracy score:{mean_score} +- {std_dev} (std) min:{min_score},max:{max_score}')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Comments, questions, suggestions? Let me know!"},{"metadata":{},"cell_type":"markdown","source":"## If you like the notebook or learned something please upvote! :D"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}