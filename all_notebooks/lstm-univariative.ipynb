{"cells":[{"metadata":{"id":"sbJuwxJ5cO2c"},"cell_type":"markdown","source":"1-VERİ HAZIRLAMA AŞAMASI\n"},{"metadata":{"id":"89G5nptPcVja"},"cell_type":"markdown","source":"Gerekli kütüphaneleri çağıralım "},{"metadata":{"id":"THValPY7cMYg","trusted":true},"cell_type":"code","source":"#Genel komutlar\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom pandas import read_csv\nfrom sklearn.preprocessing import MinMaxScaler\nimport os\nimport math\n#RMSE ile tahmin hatalarımı belirlemek için sqrt çağırdım.(evaluate forecast)\nfrom math import sqrt\nfrom sklearn.metrics import mean_squared_error\n#Verisetini ayıklamak için çağırdım\nfrom numpy import split\nfrom numpy import array\n#TimeSerieslerde kullanılan kütüphaneler\nfrom datetime import timedelta\n#Tensorflow kütüphaneleri\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import Sequence\n","execution_count":null,"outputs":[]},{"metadata":{"id":"51BTJB0Icv4t"},"cell_type":"markdown","source":"Öğrenme setini çağırdım.Verisetimi google drive'a kaydedip çağırdım.\n\n"},{"metadata":{"id":"YxsPfGfdwYyC","trusted":true},"cell_type":"code","source":"path = \"../input/solar-radiation-dataset/solar_angles_dataset.csv\"\ndf = pd.read_csv(path)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"_1SR0tvUf7RW"},"cell_type":"markdown","source":"Verisetini oluşturuken oluşan boş sütunu sildim"},{"metadata":{"id":"WvcivPfqxTFt","trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"7bJc_Vr6f4K-","trusted":true},"cell_type":"code","source":"df=df.drop(['Julian day',\"Top. azimuth angle (eastward from N)\",\"Topocentric zenith angle\"], axis = 1) \ndf=df","execution_count":null,"outputs":[]},{"metadata":{"id":"opzrVa9wgCDR"},"cell_type":"markdown","source":"-Zaman sütunlarını birleştirip datetime'a çevirdim, sonra diğer sütunları sildim.\n\n-Datetime sütununu index yaptım ."},{"metadata":{"id":"vs6XzwNJfu1l","trusted":true},"cell_type":"code","source":"cols = [\"Date (M/D/YYYY)\",\"Time (H:MM:SS)\"]\ndf[\"date_time\"] = df[cols].apply(lambda row: \"\".join(row.values.astype(str)), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"1IVeOPkif2tM","trusted":true},"cell_type":"code","source":"df['date_time'] = pd.to_datetime(df['date_time'], format='%m/%d/%Y%H:%M:%S')","execution_count":null,"outputs":[]},{"metadata":{"id":"7wAhQipsggb3","trusted":true},"cell_type":"code","source":"df=df.drop([\"Date (M/D/YYYY)\",\"Time (H:MM:SS)\" ,\"Unnamed: 0\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"ocoPaycP9i8o","trusted":true},"cell_type":"code","source":"# Split into training, validation and test datasets.\n# Since it's timeseries we should do it by date.\ntest_cutoff_date = df['date_time'].max() - timedelta(days=1)\nval_cutoff_date = test_cutoff_date - timedelta(days=14)\n\ndf_test = df[df['date_time'] > test_cutoff_date]\ndf_val = df[(df['date_time'] > val_cutoff_date) & (df['date_time'] <= test_cutoff_date)]\ndf_train = df[df['date_time'] <= val_cutoff_date]\n\n#check out the datasets\nprint('Test dates: {} to {}'.format(df_test['date_time'].min(), df_test['date_time'].max()))\nprint('Validation dates: {} to {}'.format(df_val['date_time'].min(), df_val['date_time'].max()))\nprint('Train dates: {} to {}'.format(df_train['date_time'].min(), df_train['date_time'].max()))","execution_count":null,"outputs":[]},{"metadata":{"id":"wQ8s4BH2taUk","trusted":true},"cell_type":"code","source":"df_test=df_test.set_index('date_time') #Columnu index yapmak için\ndf_val=df_val.set_index('date_time') #Columnu index yapmak için\ndf_train=df_train.set_index('date_time') #Columnu index yapmak için","execution_count":null,"outputs":[]},{"metadata":{"id":"xFTGKYlotpil","trusted":true},"cell_type":"code","source":"df_train.plot(figsize=(16,8))","execution_count":null,"outputs":[]},{"metadata":{"id":"g0dDZLh1v3VR","trusted":true},"cell_type":"code","source":"len(df_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"5odQ9-sswUa6","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(df_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"63tgVZCixEDD","trusted":true},"cell_type":"code","source":"scaled_train=scaler.transform(df_train)\nscaled_test =scaler.transform(df_test)\nscaled_val=scaler.transform(df_val)","execution_count":null,"outputs":[]},{"metadata":{"id":"XxDlp_q3xt1c","trusted":true},"cell_type":"code","source":"from keras.preprocessing.sequence import TimeseriesGenerator","execution_count":null,"outputs":[]},{"metadata":{"id":"X9z4AzpK0Qh8","trusted":true},"cell_type":"code","source":"n_input =4\nn_features =1\ntrain_generator = TimeseriesGenerator(scaled_train,scaled_train,length=n_input,batch_size = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"anwJjDeQ56zt","trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM","execution_count":null,"outputs":[]},{"metadata":{"id":"tXJiYl9I1S3e","trusted":true},"cell_type":"code","source":"model =Sequential()\nmodel.add(LSTM(64,activation =\"relu\",input_shape=(n_input,n_features)))\nmodel.add(Dense(1))\nmodel.compile(optimizer =\"adam\",loss=\"mse\")\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"v4vS3uN_6tT7","trusted":true},"cell_type":"code","source":"model.fit_generator(train_generator,epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"id":"KBs0FghF7CZF","trusted":true},"cell_type":"code","source":"model.history.history.keys()  ","execution_count":null,"outputs":[]},{"metadata":{"id":"aSVG9qoe7NaG","trusted":true},"cell_type":"code","source":"myloss = model.history.history[\"loss\"]\nplt.plot(range(len(myloss)),myloss)","execution_count":null,"outputs":[]},{"metadata":{"id":"88uK-ch4ChLt"},"cell_type":"markdown","source":"Forecast Visualisation"},{"metadata":{"id":"GM_4r_ZMCf4V","trusted":true},"cell_type":"code","source":"test_predictions = []\n\nfirst_eval_batch = scaled_train[-n_input:]\ncurrent_batch = first_eval_batch.reshape((1, n_input, n_features))\n\nfor i in range(len(df_test)):\n    \n    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])\n    current_pred = model.predict(current_batch)[0]\n    \n    # store prediction\n    test_predictions.append(current_pred) \n    \n    # update batch to now include prediction and drop first value\n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"tUR0tV2NdVuf","trusted":true},"cell_type":"code","source":"true_predictions = scaler.inverse_transform(test_predictions)","execution_count":null,"outputs":[]},{"metadata":{"id":"pQxc2gnBEbZj","trusted":true},"cell_type":"code","source":"true_predictions","execution_count":null,"outputs":[]},{"metadata":{"id":"OGWCdoRREfwG","trusted":true},"cell_type":"code","source":"df_test['Predictions'] = true_predictions","execution_count":null,"outputs":[]},{"metadata":{"id":"jZXjL-8EEg-f","trusted":true},"cell_type":"code","source":"df_test.plot(figsize=(20,8))","execution_count":null,"outputs":[]},{"metadata":{"id":"2-KAkAiBEk8I","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}