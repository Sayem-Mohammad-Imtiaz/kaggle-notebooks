{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Sales EDA"},{"metadata":{},"cell_type":"markdown","source":"By Eric Wilson"},{"metadata":{},"cell_type":"markdown","source":"### Import Libraries and Data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales = pd.read_csv('../input/retail-sales-forecasting/mock_kaggle.csv')\nsales.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This data comes from a Brazil; we'll convert the columns from Portugese into English."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales = sales.rename(columns={'data' : 'Date', 'venda' : 'Sales', 'estoque' : 'Stock', 'preco' : 'Price'})\nprint(sales.shape)\nsales.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Cleaning"},{"metadata":{},"cell_type":"markdown","source":"Let's make sure that there aren't any null values, or any unusable data."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well, that makes it easy. Now, for data types."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to convert Date to datetime, versus object. We'll also split the datetime into Day, Month, and Year catagories, to make more analysis options available (sales per year, stock per month, etc...). Finally, we'll add a \"revenue\" column, which will be sales multiplied by price, to see how much money was made per day."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales['Date'] = pd.to_datetime(sales['Date'], format='%Y-%m-%d')\nsales.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales = sales.assign(Day = sales.Date.dt.day,\n               Month = sales.Date.dt.month,\n               Year = sales.Date.dt.year)\nsales['Revenue'] = sales['Sales'] * sales['Price']\nsales.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check if there's any leakage now the the data is a little more friendly. We'll see how many time each year shows up (since all variables are tied to the date sold, and there should be fewer years on file than months or days)."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.Year.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like our data is missing about a week in 2014, perfect for 2015, and incomplete for 2016. Good to know."},{"metadata":{},"cell_type":"markdown","source":"### Data Exploration"},{"metadata":{},"cell_type":"markdown","source":"First, let's see if there's any correlation between the variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the size of the data, I would say anything less than .1 is a minor correlation and likely to have some coincidence, rather than a strong meaning. Further, with the data from Dates having a correlation, I would say that's simply coincidence as well.\n\nFor Sales, there is some positive correlation between Year and Sales, and a little positive correlation between Sales and Stock. It seems that more stock leads to more sales, and sales have increased year over year.\n\nFor Stock, there is some negative correlation between Month and Stock, and a little negative correlation between Year and Stock. As the year goes on, stock seems to diminish, and each year sees less stock available than previous years. Could this hint at production issues, or a heavy stockpile to begin with?\n\nFor Price, the only correlation that really shows is between Price and Year. There is a slightly strong correlation between an increase in price as time goes by; perhaps, like a lesser amount of stock in later years, this has to do with supply and demand trying to find a new equilibrium? \n\nRevenue, which should not come as a surprise, is very highly correlated to sales - you can't make money if you don't sell product. There is a moderate correlation to price, as well, but price is far less important in determining revenue than the number of sales."},{"metadata":{},"cell_type":"markdown","source":"#### Changes in Variables by Date"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(4, figsize = [14, 14])\nfig.suptitle('Variables per Year', fontsize = 18)\naxs[0].plot(sales.Date, sales.Price, color = 'gold')\naxs[0].set_title('Price', fontsize = 14)\naxs[1].plot(sales.Date, sales.Stock, color = 'red')\naxs[1].set_title('Stock', fontsize = 14)\naxs[2].plot(sales.Date, sales.Sales, color = 'black')\naxs[2].set_title('Sales', fontsize = 14)\naxs[3].plot(sales.Date, sales.Revenue, color = 'green')\naxs[3].set_title('Revenue', fontsize = 14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each of the variables shows a pretty strong amount of volatility. \n\nPrice seems to be the most stable of all, with a minimal amount of sharp peaks and troughs, being better represented by plateaus. \n\nFor stock, nothing seems extraordinary: stock climbs steeply as large shipments or orders are received, and then dwindles as sales are made.\n\nAs for sales, it is the most volatile of all variables. It will be worth looking into specific days of the week to see what days are the most popular."},{"metadata":{},"cell_type":"markdown","source":"#### Data by Days"},{"metadata":{},"cell_type":"markdown","source":"Let's see what the averages of sales, stock, price, and revenue tend to look like based on day of the month. "},{"metadata":{"trusted":true},"cell_type":"code","source":"dsales = sales.groupby('Day').mean()\ndsales = dsales[['Sales', 'Stock', 'Price', 'Revenue']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(2, 2 , figsize = [14, 14])\nfig.suptitle('Variables Over the Month', fontsize = 18)\naxs[0, 0].plot(dsales.index, dsales.Sales, color = 'black')\naxs[0, 0].set_title('Sales', fontsize = 14)\naxs[0, 1].plot(dsales.index, dsales.Stock, color = 'red')\naxs[0, 1].set_title('Stock', fontsize = 14)\naxs[1, 0].plot(dsales.index, dsales.Price, color = 'gold')\naxs[1, 0].set_title('Price', fontsize = 14)\naxs[1, 1].plot(dsales.index, dsales.Revenue, color = 'green')\naxs[1, 1].set_title('Revenue', fontsize = 14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's put all four variables on a graph to compare movements. First, we'll do a rough scaling by amplifying the values of price and sales, in order to ensure all variables have values on a similar scale."},{"metadata":{"trusted":true},"cell_type":"code","source":"dsm = dsales\ndsm['Price'] = dsm['Price'] * 1000\ndsm['Sales'] = dsm['Sales'] * 15\ndsm['Revenue'] = dsm['Revenue'] * 10\ndsm = dsm.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nplt.title('Relationship Between Variables', fontsize = 18)\nplt.plot('Day', 'Sales', data = dsm, color='black', linewidth=2, label = \"Sales\")\nplt.plot('Day', 'Price', data = dsm, color='gold', linewidth=2, label = \"Price\")\nplt.plot('Day', 'Stock', data = dsm, color='red', linewidth=2, label=\"Stock\")\nplt.plot('Day', 'Revenue', data = dsm, color='green', linewidth=2, label=\"Revenue\")\nplt.yticks([])\nplt.legend(fontsize = 12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It can be seen that sales (and, therefore, revenue) peak at the beginnings of the months, and have a minor uptick later in the months. \n\nStock tends to get depleted towards the beginnings of the months, in two noticable waves, before slowly refilling throughout the rest of the month.\n\nPrice tends to be slightly higher at the beginnings and ends of the months with a slump towards the middle of the month."},{"metadata":{},"cell_type":"markdown","source":"#### Data by Month"},{"metadata":{},"cell_type":"markdown","source":"Similarly now, let's take a look at what business looks like, on average, over the course of a year. It is worth noting that 2016 data is missing later months, so the last few months only take 2014 and 2015 into account. "},{"metadata":{"trusted":true},"cell_type":"code","source":"msales = sales.groupby('Month').mean()\nmsales = msales[['Sales', 'Stock', 'Price', 'Revenue']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(2, 2 , figsize = [14, 14])\nfig.suptitle('Variables by the Month', fontsize = 18)\naxs[0, 0].plot(msales.index, msales.Sales, color = 'black')\naxs[0, 0].set_title('Sales', fontsize = 14)\naxs[0, 1].plot(msales.index, msales.Stock, color = 'red')\naxs[0, 1].set_title('Stock', fontsize = 14)\naxs[1, 0].plot(msales.index, msales.Price, color = 'gold')\naxs[1, 0].set_title('Price', fontsize = 14)\naxs[1, 1].plot(msales.index, msales.Revenue, color = 'green')\naxs[1, 1].set_title('Revenue', fontsize = 14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sales peak in June and hit their bottom in August, both during the winter months (for the Southern Hemisphere) - could weather have something to do with supply and demand?\n\nStock, similar to data over the course of a month, begins with a much larger reserve and dwindles as the year continues. \n\nPrice has two noticable peaks, at the start and end of the year - they may be much closer on a linear timeline than by the breakdown shown here.\n\nRevenue sees a more general climb towards its' peak than sales, without as much of a second peak late in the year, due to the lower value of price."},{"metadata":{},"cell_type":"markdown","source":"#### Top 5 Most Common Price Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Only showing the 5 most common prices\nsales.Price.value_counts().head().plot(kind='bar', color = 'gold', figsize = (14, 8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It would be safe to assume that 1.29 monetary units (specific monetary units were not mentioned in the data) is the market equilibrium, being represented nearly 2.5x more often than the next closest price. "},{"metadata":{},"cell_type":"markdown","source":"### Conclusion"},{"metadata":{},"cell_type":"markdown","source":"Based on the data, the 7th of June should be expected to bring in the most money of the year, whereas the 24th of August should be expected to earn the least amount of money of the year.\n\nStock should hit its' lowest points of the year in early November, while climbing to its' highest points in the middle through late February.\n\nPrice should trough around the 15th of August, hitting its' lowest point, while peaking around the start and end of February."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}