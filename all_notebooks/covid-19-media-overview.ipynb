{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Getting started with the Covid-19 Public Media Dataset"},{"metadata":{},"cell_type":"markdown","source":"This notebook shows how the [Covid-19 Public Media Dataset by Anacode](https://www.kaggle.com/jannalipenkova/covid19-public-media-dataset) can be used for data and text analysis. In the first section, we perform some aggregations on the metadata to get an initial overview. In the second section, we apply linguistic preprocessing and dive deeper into the text data. Specifically, we apply clustering to identify major themes in the data which can then be used for further analysis. \n\nFor those who are impatient, please check [this interactive chart](https://anacode.de/wordpress/wp-content/uploads/2020/04/covid19media_clusters5.html) for the final clustering of the data. "},{"metadata":{},"cell_type":"markdown","source":"## 1. Initial overview\n\nLet's first load the data and aggregate on some of the metadata - namely the domain, topic_area and date columns. For simplicity, we are relying on pandas built-in plotting functions."},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data file; please change the path to the data file if needed\ndf = pd.read_csv(\"/kaggle/input/covid19-public-media-dataset/covid19_articles.csv\")\nprint(len(df))\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# aggregate by domains\ndomain_stats = df.domain.value_counts(ascending=True)\npd.DataFrame(domain_stats).plot.barh(figsize=(8, 8), legend=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All data sources are in English, and the most prominent data sources such as express.co.uk, cnbc and theguardian are focussed on UK and US author- and readership. Therefore, we expect a corresponding bias towards these countries in the analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"# aggregate by topic areas\ntopic_area_stats = df.topic_area.value_counts(ascending=True)\npd.DataFrame(topic_area_stats).plot.barh(figsize=(8, 3), legend=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# aggregate dates\ndate_stats = df.date.value_counts()\ndate_stats.sort_index(inplace=True)\ndate_stats.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this aggregation, note the typical weekly slumps in this chart that normally occur on weekends."},{"metadata":{},"cell_type":"markdown","source":"## 2. Preprocessing the text data\n\nWe mainly rely on spacy for preprocessing and apply the following steps:\n\n- Tokenization\n- Lemmatization\n- POS-based filtering function words, leaving only content words\n- Stopword filtering based on a custom list\n\nBe patient - preprocessing will take a while."},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy\nNLP = spacy.load(\"en_core_web_sm\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RELEVANT_POS_TAGS = [\"PROPN\", \"VERB\", \"NOUN\", \"ADJ\"]\nCUSTOM_STOPWORDS = [\"say\", \"%\", \"will\", \"new\", \"would\", \"could\", \"other\", \n                    \"tell\", \"see\", \"make\", \"-\", \"go\", \"come\", \"can\", \"do\", \n                    \"such\", \"give\", \"should\", \"must\", \"use\"]\n\ndef preprocess(text):\n    doc = NLP(text)\n    relevant_tokens = \" \".join([token.lemma_.lower() for token in doc if token.pos_ in RELEVANT_POS_TAGS and token.lemma_.lower() not in CUSTOM_STOPWORDS])\n    return relevant_tokens","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\ntqdm.pandas()\nprocessed_content = df[\"content\"].progress_apply(preprocess)\ndf[\"processed_content\"] = processed_content","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## 3. Clustering\n\nIn this section, we apply PCA, T-SNE and K-means clustering for clustering of the preprocessed texts. We close the section with an interactive plot in bokeh and some observations about the clusters. This section is inspired by the notebook published by Maksim Eren for Covid-19 Literature Clustering (https://www.kaggle.com/maksimeren/covid-19-literature-clustering)."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn import metrics\nfrom scipy.spatial.distance import cdist\nfrom sklearn.manifold import TSNE\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def vectorize(text, maxx_features):    \n    vectorizer = TfidfVectorizer(max_features=maxx_features)\n    X = vectorizer.fit_transform(text)\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"texts = df.processed_content.tolist()\ntexts[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = vectorize(texts, 2 ** 10)\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=0.95, random_state=42)\nX_reduced= pca.fit_transform(X.toarray())\nX_reduced.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distortions = []\nK = range(8, 20)\nfor k in K:\n    k_means = KMeans(n_clusters=k, random_state=42).fit(X_reduced)\n    k_means.fit(X_reduced)\n    distortions.append(sum(np.min(cdist(X_reduced, k_means.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nX_line = [K[0], K[-1]]\nY_line = [distortions[0], distortions[-1]]\n\n# Plot the elbow\nplt.plot(K, distortions, 'b-')\nplt.plot(X_line, Y_line, 'r')\nplt.xlabel('k')\nplt.ylabel('Distortion')\nplt.title('Finding optimal k using the elbow method')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We choose 11 as number of clusters and fit the data accordingly."},{"metadata":{"trusted":true},"cell_type":"code","source":"k = 11\nkmeans = KMeans(n_clusters=k, random_state=42)\ny_pred = kmeans.fit_predict(X_reduced)\ndf['y'] = y_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To reduce the dimensionality of our data to 2-dimensional space, we apply t-SNE and plot the result."},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne = TSNE(verbose=1, perplexity=100, random_state=42)\nX_embedded = tsne.fit_transform(X.toarray())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# sns settings\nsns.set(rc={'figure.figsize':(10,10)})\n\n# colors\npalette = sns.color_palette(\"bright\", 1)\n\n# plot\nsns.scatterplot(X_embedded[:,0], X_embedded[:,1], palette=palette)\nplt.title('t-SNE without clusters')\nplt.savefig(\"tsne_covid19media_unlabelled.png\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we use the clusters generated by k-means to color clustered areas in the t-SNE reduced dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\n\n# sns settings\nsns.set(rc={'figure.figsize':(10,10)})\n\n# colors\npalette = sns.hls_palette(k, l=.4, s=.9)\n\n# plot\nsns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y_pred, legend='full', palette=palette)\nplt.title('t-SNE with {} clusters'.format(k))\nplt.savefig(\"tsne_covid19media_labelled.png\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To provide more transparency into the data, you can further use the bokeh interactive library to plot an interactive version of the chart which shows individual articles on mousehover, as described in [Maksim Eken's notebook on Covid-19 Literature Clustering](https://www.kaggle.com/maksimeren/covid-19-literature-clustering). Please check [this final plot](https://anacode.de/wordpress/wp-content/uploads/2020/04/covid19media_clusters5.html) where we also provided manual labels to the clusters."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}