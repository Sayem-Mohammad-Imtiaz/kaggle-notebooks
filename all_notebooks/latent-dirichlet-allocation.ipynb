{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Latent Dirichlet Allocation"},{"metadata":{},"cell_type":"markdown","source":"## Data\n\nWe will be using articles from NPR (National Public Radio), obtained from their website [www.npr.org](http://www.npr.org)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"npr = pd.read_csv('../input/npr-data/npr.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"npr.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice how we don't have the topic of the articles! Let's use LDA to attempt to figure out clusters of the articles."},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**`max_df`**` : float in range [0.0, 1.0] or int, default=1.0`<br>\nWhen building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.\n\n**`min_df`**` : float in range [0.0, 1.0] or int, default=1`<br>\nWhen building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None."},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtm = cv.fit_transform(npr['Article'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import LatentDirichletAllocation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LDA = LatentDirichletAllocation(n_components=7,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This can take awhile, we're dealing with a large amount of documents!\nLDA.fit(dtm)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Showing Stored Words"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(cv.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(10):\n    random_word_id = random.randint(0,54776)\n    print(cv.get_feature_names()[random_word_id])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(10):\n    random_word_id = random.randint(0,54776)\n    print(cv.get_feature_names()[random_word_id])","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"### Showing Top Words Per Topic"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(LDA.components_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LDA.components_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(LDA.components_[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"single_topic = LDA.components_[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Returns the indices that would sort this array.\nsingle_topic.argsort()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Word least representative of this topic\nsingle_topic[18302]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Word most representative of this topic\nsingle_topic[42993]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top 10 words for this topic:\nsingle_topic.argsort()[-10:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_word_indices = single_topic.argsort()[-10:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index in top_word_indices:\n    print(cv.get_feature_names()[index])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These look like business articles perhaps... Let's confirm by using .transform() on our vectorized articles to attach a label number. But first, let's view all the 10 topics found."},{"metadata":{"trusted":true},"cell_type":"code","source":"for index,topic in enumerate(LDA.components_):\n    print(f'THE TOP 15 WORDS FOR TOPIC #{index}')\n    print([cv.get_feature_names()[i] for i in topic.argsort()[-15:]])\n    print('\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Attaching Discovered Topic Labels to Original Articles"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtm.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(npr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topic_results = LDA.transform(dtm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topic_results.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topic_results[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topic_results[0].round(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topic_results[0].argmax()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This means that our model thinks that the first article belongs to topic #1."},{"metadata":{},"cell_type":"markdown","source":"### Combining with Original Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"npr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"topic_results.argmax(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"npr['Topic'] = topic_results.argmax(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"npr.head(10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}