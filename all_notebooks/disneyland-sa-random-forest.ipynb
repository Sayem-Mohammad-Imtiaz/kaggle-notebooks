{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nplt.style.use('seaborn')\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom collections import Counter, defaultdict\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom PIL import Image\nfrom nltk.tokenize import word_tokenize\nfrom nltk.util import ngrams\nimport string\nnltk.download('stopwords')\n\nstop = set(stopwords.words('english'))\n\nSEED = 13","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/disneyland-reviews/DisneylandReviews.csv', encoding='iso-8859-1', na_values='missing')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking duplicated\ndata[data['Review_ID'].isin(data['Review_ID'][data['Review_ID'].duplicated()])].sort_values('Review_ID')","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop_duplicates('Review_ID', inplace=True, keep='first')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Rating.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remap_rating(rating):\n    if rating <3:\n        return 'negative'\n    elif rating >3:\n        return 'positive'\n    else:\n        return 'neutral'\n    \ndata['Rating'] = data['Rating'].apply(lambda rating: remap_rating(rating))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Rating.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Review_Text'] = data['Review_Text'].astype(str)\nclass_data = data.groupby('Rating').count()['Review_Text'].reset_index().sort_values('Review_Text', ascending=False)\npercent_rating = class_data.Review_Text\nlabels = class_data.Rating\ncolors = ['#00ff00', '#0000ff', '#ff0000']\nchart, _, _ = plt.pie(percent_rating, colors=colors, radius=1.0, labels=labels, autopct=\"%.1f%%\")\nplt.setp(chart, width=0.5)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10,5))\n\nreview_len = data[data['Rating']=='negative']['Review_Text'].str.len()\nax1.hist(review_len, color='#ff0000')\n\nreview_len = data[data['Rating']=='neutral']['Review_Text'].str.len()\nax2.hist(review_len, color='#0000ff')\n\nreview_len = data[data['Rating']=='positive']['Review_Text'].str.len()\nax3.hist(review_len, color='#00ff00')\n\nfig.suptitle('Number of characters in reviews')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10,5))\n\nreview_len = data[data['Rating']=='negative']['Review_Text'].str.split().map(lambda review: len(review))\nax1.hist(review_len, color='#ff0000')\n\nreview_len = data[data['Rating']=='neutral']['Review_Text'].str.split().map(lambda review: len(review))\nax2.hist(review_len, color='#0000ff')\n\nreview_len = data[data['Rating']=='positive']['Review_Text'].str.split().map(lambda review: len(review))\nax3.hist(review_len, color='#00ff00')\n\nfig.suptitle('Total words in a review')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_corpus(target):\n    corpus = []\n    for x in data[data['Rating']==target]['Review_Text'].str.split():\n        for i in x:\n            corpus.append(i)\n    return corpus","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop = set(stopwords.words('english'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pos_common_words = create_corpus('positive')\npos_counter = Counter(pos_common_words)\npos_most = pos_counter.most_common()\nx = []\ny = []\nfor word, count in pos_most[:40]:\n    if word not in stop:\n        x.append(word)\n        y.append(count)\nsns.barplot(x=y, y=x)\nplt.title('Most common words in positive reviews')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neu_common_words = create_corpus('neutral')\nneu_counter = Counter(neu_common_words)\nneu_most = neu_counter.most_common()\nx = []\ny = []\nfor word, count in neu_most[:40]:\n    if word not in stop:\n        x.append(word)\n        y.append(count)\nsns.barplot(x=y, y=x)\nplt.title('Most common words in neutral reviews')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neg_common_words = create_corpus('negative')\nneg_counter = Counter(neg_common_words)\nneg_most = neg_counter.most_common()\nx = []\ny = []\nfor word, count in neg_most[:40]:\n    if word not in stop:\n        x.append(word)\n        y.append(count)\nsns.barplot(x=y, y=x)\nplt.title('Most common words in negative reviews')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport random","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_punctuations(review):\n    return re.sub(r'(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)|([^\\x00-\\x7F]+)|([0-9])|(\\w+:\\/\\/\\S+)|([^\\w\\s])|(\\s+)', ' ', review)\n\ndef rep(review):\n    return review.replace('_', ' ')\n\ndef whitespace_LT(review):\n    return review.strip()\n\ndef multispace(review):\n    return re.sub(r'\\s+', ' ', review)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Review_Text'] = data['Review_Text'].str.lower()\n\ndata['Review_Text'] = data['Review_Text'].apply(lambda review: remove_punctuations(review))\ndata['Review_Text'] = data['Review_Text'].apply(lambda review: rep(review))\ndata['Review_Text'] = data['Review_Text'].apply(lambda review: whitespace_LT(review))\ndata['Review_Text'] = data['Review_Text'].apply(lambda review: multispace(review))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Review_Text'][random.randint(0, len(data['Review_Text']))]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize\nfrom nltk.probability import FreqDist\n\ndef word_tokenize_wrapper(review):\n    return word_tokenize(review)\n\ndef freqDist_wrapper(review):\n    return FreqDist(review)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Review_Text_Token'] = data['Review_Text'].apply(lambda review: word_tokenize_wrapper(review))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Review_Text_Token_FreqDist'] = data['Review_Text_Token'].apply(lambda token: freqDist_wrapper(token))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords\nlist_stopwords = stopwords.words('english')\nlist_stopwords = set(list_stopwords)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def stopwords_removal(words):\n    return [word for word in words if word not in list_stopwords]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Review_Text_Token_WSW'] = data['Review_Text_Token'].apply(lambda word: stopwords_removal(word))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Review_Text_Token_WSW'].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install swifter","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.stem import PorterStemmer\nimport swifter\n\nstemmer = PorterStemmer()\n\ndef stemmer_wrapper(term):\n    return stemmer.stem(term)\n\nterm_dict = {}\n\nfor document in data['Review_Text_Token_WSW']:\n    for term in document:\n        if term not in term_dict:\n            term_dict[term] = ' '\n            \nprint(len(term_dict))\n\nfor term in term_dict:\n    term_dict[term] = stemmer_wrapper(term)\n    print(term, ':', term_dict[term])\n    \nprint(term_dict)\n\ndef get_stemmed_term(document):\n    return [term_dict[term] for term in document]\n\ndata['Review_Stemmed'] = data['Review_Text_Token_WSW'].swifter.apply(lambda doc: get_stemmed_term(doc))\nprint(data['Review_Stemmed'])","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = ['Rating', 'Review_Stemmed']\ndata = data[cols]\ndata.columns = ['label', 'review']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ast\ndef join(reviews):\n    return ' '.join([review for review in reviews])\n\ndata['review'] = data['review'].apply(lambda review: join(review))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.label.value_counts(normalize=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remap_label(label):\n    if label == 'positive':\n        return 1\n    elif label == 'negative':\n        return -1\n    else:\n        return 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['label'] = data['label'].apply(lambda label: remap_label(label))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf = TfidfVectorizer(analyzer='word')\nfeatures = tfidf.fit_transform(data['review'])\nfeatures_array = features.toarray()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = features.astype(np.float32)\nfeatures_array = features_array.astype(np.float32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = data['label']\nprint('%d reviews, %d feature' %(features.shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = features\ny = labels\nX = X.astype(np.float32)\ny = y.astype(np.int8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, f1_score, roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc_score = []\nf1s_score = []\nfor train_idx, val_idx in skf.split(X, y):\n    Xt, Xv = X[train_idx, :], X[val_idx, :]\n    yt, yv = y.iloc[train_idx], y.iloc[val_idx]\n\n    model = RandomForestClassifier(\n        criterion='entropy',\n        random_state=SEED,\n        n_estimators=500,\n        max_features='sqrt',\n        n_jobs=-1\n    )\n\n    model.fit(Xt, yt)\n    y_pred = model.predict(Xv)\n    y_prob = model.predict_proba(Xv)[:,1]\n    acc_score.append(accuracy_score(yv, y_pred))\n    f1s_score.append(f1_score(yv, y_pred, average='macro'))\n        \nacc_mean = np.mean(acc_score)\nf1s_mean = np.mean(f1s_score)\ndf_result = pd.DataFrame({\n    'Accuracy': [acc_mean],\n    'F1 Score': [f1s_mean],\n})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_result","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}