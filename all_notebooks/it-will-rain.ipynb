{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We can see that we have many missing values.\n* And we have 23 columns. (21 if we exclude target feature and RISK_MM)\n* We are going to drop RISK_MM because our target feature is based on this feature, like it says in dataset description.\n* Date feature needs to be converted to datetime type. Currently it's object.\n* And lastly in RainTomorrow column i'll replace No with 0 and Yes with 1. I'll do same to RainToday column too.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Date\"] = pd.to_datetime(df[\"Date\"])\ndf.drop(\"RISK_MM\",axis=1,inplace = True)\ndf[\"RainTomorrow\"] = [1 if each == \"Yes\" else 0 for each in df[\"RainTomorrow\"]]\ndf[\"RainToday\"] = [1 if each == \"Yes\" else 0 for each in df[\"RainToday\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Features and what do they mean**\n* Date: The date of observation\n* Location: The common name of the lcoation of the weather station\n* MinTemp: The minimum temperature in degrees celcius\n* MaxTemp: The maximum temperature in degrees celsius\n* Rainfall: The amount of rainfall recorded for the day in mm\n* Evaporation: The so-called Class A pan evaporation (mm) in the 24 hours to 9am\n* Sunshine: The number of hours of bright sunshine in the day.\n* WindGustDir: The direction of the strongest wind gust in the 24 hours to midnight\n* WindGustSpeed: The speed (km/h) of the strongest wind gust in the 24 hours to midnight\n* WindDir9am: Direction of the wind at 9am\n* WindDir3pm: Direction of the wind at 3pm\n* WindSpeed9am: Wind speed (km/hr) averaged over 10 minutes prior to 9am\n* WindSpeed3pm: Wind speed (km/hr) averaged over 10 minutes prior to 3pm\n* Humidity9am: Humidity (percent) at 9am\n* Humidity3pm: Humidity (percent) at 3pm\n* Pressure9am: Atmospheric pressure (hpa) reduced to mean sea level at 9am\n* Pressure3pm: Atmospheric pressure (hpa) reduced to mean sea level at 3pm\n* Cloud9am: Fraction of sky obscured by cloud at 9am. This is measured in \"oktas\", which are a unit of eigths. It records how many eigths of the sky are obscured by cloud. A 0 measure indicates completely clear sky whilst an 8 indicates that it is completely overcast.\n* Cloud3pm: Fraction of sky obscured by cloud (in \"oktas\": eighths) at 3pm. See Cload9am for a description of the values\n* Temp9am: Temperature (degrees C) at 9am\n* Temp3pm: Temperature (degrees C) at 3pm\n* RainToday: 1 if precipitation (mm) in the 24 hours to 9am exceeds 1mm, otherwise 0\n* RainTomorrow: The target variable. Did it rain tomorrow?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We have some extreme outliers in Ranfall and Evaporation column, we'll inspect these outliers later.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* First i'll define two functions to visualize categorical and numerical features to target feature. After that i'll look at relations between features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = []\nnum_cols = []\nother_cols = []\n\nfor each in df.columns:\n    if df[each].dtype == \"object\":\n        cat_cols.append(each)\n    elif df[each].dtype == \"float64\":\n        num_cols.append(each)\n    else:\n        other_cols.append(each)\nprint(\"Categorical Columns: \",cat_cols)\nprint(\"Numerical Columns: \",num_cols)\nprint(\"Other Columns: \",other_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ctgplt(variable,to):\n    \n    \"Function for visualization of categorical variables.\"\n    \n    var = df[variable]\n    values=var.value_counts()\n    \n    f, ax = plt.subplots(figsize = (8,8))\n    g = sns.barplot(x = variable, y = to, data = df)\n    g.set_xticklabels(g.get_xticklabels(),rotation = 90)\n    plt.show()\n    \n    print(\"{}:\\n{}\".format(variable,values))\n\ndef numplt(data,variable,to):\n  \n  \"Function for visualization of numerical variables.\"\n\n  c = sns.FacetGrid(data,col=to,height=6)\n  c.map(sns.distplot,variable,bins=25)\n  plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in cat_cols:\n    ctgplt(i, \"RainTomorrow\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Rain rates for some cities are very low, but most of them are around 0.2.\n* Wind is coming from Northwest if its going to rain, mostly.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for k in num_cols:\n    numplt(df, k, \"RainTomorrow\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Lets look at the graphs and comment the graps:\n* MinTemps are nicely distributed around 10 Degrees for RainTomorrow = 0. But for RainTomorrow = 1 its grouped around 15 degrees. And we have some more values around 25 - 30 degrees.\n* MaxTemps are stuck at 20 ish degrees for RainTomorrow = 1 and some in 30 - 35 degrees. But we can see that its warmer if tomorrow is a rainy day.\n* Like i said before Rainfall and Evaporation has some extreme outliers that makes impossible to commentate the graphs. I'll drop outliers and look at these graphs again.\n* Weather is mostly cloudy if its going to rain. (as expected) But no clouds if its not.\n* Wind is more distributed for RainTomorrow = 1 it's getting stronger if its going to rain.\n* 9 am wind speeds are almost same.\n* 3 pm wind speeds are a little bit strongter if its going to rain.\n* Humidity is more (as normal) if its going to rain. Especially in early hours of the day.\n* Atmospheric pressures distributions are almost same.\n* More clouds for rainy days.\n* Temperatures are not changed so much, like i said earlier most days grouped around 20 degrees for rainy days.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x = df[\"Rainfall\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We cant even see the distribution. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x= df[\"Evaporation\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* This one is not bad as the Rainfall column but still has some serious outliers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df.corr()\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nf, ax = plt.subplots(figsize=(12, 8))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, annot=True, mask=mask, cmap=cmap, ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We have some highly correlated features. This collinear features wont do any good to our models. So we need to drop one of them.\n* Columns to drop: Temp3pm, Temp9am, Pressure9am. Lets drop these columns and look our correlation matrix again.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns = [\"Temp3pm\", \"Temp9am\", \"Pressure9am\"], axis=1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df.corr()\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nf, ax = plt.subplots(figsize=(12, 8))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, annot=True, mask=mask, cmap=cmap, ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* It's looking better now.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# I removed the columns that i just deleted from dataframe.\nto_remove = (\"Temp3pm\", \"Temp9am\", \"Pressure9am\")\nnum_cols = [each for each in num_cols if each not in to_remove]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outlier Removal","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Q3 = df[\"Rainfall\"].quantile(0.75)\nQ1 = df[\"Rainfall\"].quantile(0.25)\n\nIQR = Q3 - Q1\nstep = IQR * 3\n\nmaxm = Q3 + step\nminm = Q1 - step\n\ndf = df[df[\"Rainfall\"].fillna(1) < (maxm)]\n\nQ3 = df[\"Evaporation\"].quantile(0.75)\nQ1 = df[\"Evaporation\"].quantile(0.25)\n\nIQR = Q3 - Q1\nstep = IQR * 3\n\nmaxm = Q3 + step\nminm = Q1 - step\n\ndf = df[df[\"Evaporation\"].fillna(1) < (maxm)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df[\"Evaporation\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Distribution looks better without outliers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"RainTomorrow\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = \"RainTomorrow\", data=df, palette = \"RdBu\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We have a imbalanced data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Missing Values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_values_table(data):\n        # Total missing values\n        mis_val = data.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * data.isnull().sum() / len(data)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values_table(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most of the missing value percentages is between 0 - 10.\n* Cloud columns, Evaporation and Sunshine features have 40% missing data.\n* I will fill categorical variables with mode and numerical variables with median.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in cat_cols:\n    df[i].fillna(value=df[i].mode()[0],inplace=True)\n\nfor k in num_cols:\n    df[k].fillna(value=df[k].median(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* So now that we filled our missing values we can prepare out data for modeling.\n* i will drop date column after i seperated it to 3 pieces (year,month,day).\n* Label encode the categorical features.\n* Min max scale the numerical features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Year\"] = df[\"Date\"].dt.year\n\ndf[\"Month\"] = df[\"Date\"].dt.month\n\ndf[\"Day\"] = df[\"Date\"].dt.day\n\ndf.drop(\"Date\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nmms = MinMaxScaler()\n\nfor each in cat_cols:\n    df[each] = le.fit_transform(df[each])\n\ndf[df.columns] = mms.fit_transform(df[df.columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modeling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(\"RainTomorrow\",axis=1)\ny = df[\"RainTomorrow\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* First i will fit a baseline model with logistic regression, then i will use xgboost.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\n\nlr.fit(X_train, y_train)\npreds = lr.predict(X_test)\nprint(\"train_score\",lr.score(X_train, y_train))\nprint(\"test_score\",lr.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cf_matrix = confusion_matrix(y_test, preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(cf_matrix,annot = True, fmt=\"g\",cmap=\"Greens\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(objective = \"binary:logistic\")\nxgb.fit(X_train,y_train)\npred = xgb.predict(X_test)\nprint(xgb.score(X_train,y_train))\nprint(xgb.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We get a better result with XGBoost but because we did not specify the parameters. Now lets apply Grid Search with xgb classifier.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# I will not use a huge parameter grid because it will took to long to train, so here few parameters that could be useful.\nparams = {\n  'min_child_weight':[1,2],\n  'max_depth': [3,5],\n  'n_estimators':[200,300],\n  'colsample_bytree':[0.7,0.8],\n  'scale_pos_weight':[1.1,1.2]  \n}\n\nmodel = GridSearchCV(estimator=XGBClassifier(objective=\"binary:logistic\"), param_grid=params, cv=StratifiedKFold(n_splits=5), scoring=\"f1_macro\", n_jobs=-1, verbose=3)\nmodel.fit(X_train, y_train)\n\nprint(\"Best Score: \",model.best_score_)\nprint(\"Best Estimator: \",model.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* So grid search is did not do better then default parameters. Let's look at the confusion matrix with default parameters.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mat = confusion_matrix(y_test,model.predict(X_test))\nsns.heatmap(mat,annot=True,cmap=\"Greens\", fmt=\"g\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,model.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Recall is pretty low because we missclassified most of the zeros as ones. This is caused because of the imbalance.\n* I will use over-sampling with imblearn library to overcome this problem.\n* To learn what is over-sampling you can read here: https://imbalanced-learn.readthedocs.io/en/stable/user_guide.html\n* Other then over-sampling what can we do?\n* We could do missing value imputation with KNN or MICE. These both are available in sklearn library. \n* We could do more feature engineering.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = pd.Series(data=xgb.feature_importances_,\n                        index= X_train.columns)\n\nimportances_sorted = importances.sort_values()\nplt.figure(figsize=(8,8))\nimportances_sorted.plot(kind='barh', color='lightgreen')\nplt.title('Features Importances')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We can see that humidity and clouds are the most important features. But ratios are pretty close to each other.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nmethod = SMOTE()\n\nX_resampled, y_resampled = method.fit_sample(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.fit(X_resampled, y_resampled)\npred1 = xgb.predict(X_test)\nprint(\"Train Score: \", xgb.score(X_resampled,y_resampled))\nprint(\"Test Score: \", xgb.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mat = confusion_matrix(y_test,pred1)\nsns.heatmap(mat,annot=True,cmap=\"Greens\", fmt=\"g\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,pred1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### UPDATE\n\n* After some time i checked the notebook and i realized that i resampled in the all data, so because of that accuracy is increasing. But now i fixed it and accuracy went down a little with over sampling.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### That's all. Thank you for reading, i hope you like it. ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}