{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nContent\n1. Linear Regression\n2. Multiple Linear Regression\n3. Polynomial Linear Regression\n4. Decision Tree Regression\n5. Random Forest Regression\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\n\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# > Linear Regression\n \ny=b1*x+b0 \n\nb1=constant(bias) \n\nb0=coefficient[](http://)\n\nA feature (x) is required for linear regression so I used pelvic_incidence column for this regression. And target is sacral slope column.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\ndf= pd.read_csv('/kaggle/input/biomechanical-features-of-orthopedic-patients/column_2C_weka.csv')\nplt.figure(figsize=[10,10])\nplt.scatter(df.pelvic_incidence,df.sacral_slope)\nplt.xlabel(\"pelvic incidence\")\nplt.ylabel(\"sacral slope\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlinear_reg=LinearRegression()\nx=df.pelvic_incidence.values.reshape(-1,1)\ny=df.sacral_slope.values.reshape(-1,1)\nlinear_reg.fit(x,y)\ny_head=linear_reg.predict(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%% # Plot regression line and scatter\nplt.figure(figsize=[10,10])\nplt.scatter(x,y)\nplt.xlabel(\"pelvic incidence\")\nplt.ylabel(\"sacral slope\")\nplt.plot(x,y_head,color=\"red\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%% prediction\nb0=linear_reg.predict([[0]])\nb1=linear_reg.coef_\nprint(\"b0: \",b0)\nprint(\"b1: \",b1)\n#pelvic incidence = 80 sacral slope=?\nprint(\"Predict: \",b1*80+b0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%% R^2 score\nfrom sklearn.metrics import r2_score\nprint(\"R^2 : \",r2_score(y,y_head))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# > Multiple Linear Regression\n\ny=b0+b1*x1+b2*x2+...+bn*xn\nMultiple linear regression is similar to linear regression. Multiple linear regression required more than one features.\nI used all dataset's feature.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.linear_model import LinearRegression\n\nx=df.iloc[:,[1,2,3,4,5]].values\ny=df.pelvic_incidence.values.reshape(-1,1)\n\nmultiple_reg=LinearRegression()\nmultiple_reg.fit(x,y)\nprint(\"b0: \",multiple_reg.intercept_) # or print(\"b0: \",multiple_reg.predict(0))\nprint(\"b1,b2,b3,b4,b5 : \", multiple_reg.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_head=multiple_reg.predict(x)\n#%% R^2 score\nfrom sklearn.metrics import r2_score\nprint(\"R^2 : \",r2_score(y,y_head))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"R^2 score different way to show R^2 score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#%% R^2 score\nprint(\"R^2 :\",multiple_reg.score(x,y))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# > Polynomial Linear Regression\n\ny=b0+b1*x+b2*x^2+...+bn*x^n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\npolynomial_regression = PolynomialFeatures(degree = 4)\nx_polynomial = polynomial_regression.fit_transform(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nplt.figure(figsize=[20,20])\npoly_reg=LinearRegression()\npoly_reg.fit(x_polynomial,y)\ny_head=poly_reg.predict(x_polynomial)\nplt.plot(x,y_head,color=\"orange\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%% R^2 score\nfrom sklearn.metrics import r2_score\nprint(\"R^2 : \",r2_score(y,y_head))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# > Decision Tree Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nimport numpy as np\nx=df.pelvic_incidence.values.reshape(-1,1)\ny=df.sacral_slope.values.reshape(-1,1)\ntree=DecisionTreeRegressor()\ntree.fit(x,y)\n\nx_=np.arange(min(x),max(x),0.01).reshape(-1,1)\ny_head=tree.predict(x_)\nplt.plot(x_,y_head,color=\"red\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# > Random Forest Regression\n\nUsing more than one machine language algorithm in one algorithm -->Ensemble Learning\n\nRandom forest is a mamber of ensemble learning.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x=df.pelvic_incidence.values.reshape(-1,1)\ny=df.sacral_slope.values.reshape(-1,1)\nplt.figure(figsize=[20,20])\nplt.scatter(x,y)\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nrandom_reg=RandomForestRegressor(n_estimators=100,random_state=42)\n\nrandom_reg.fit(x,y)\n\nx_=np.arange(min(x),max(x),0.01).reshape(-1,1)\ny_head=random_reg.predict(x_)\nplt.plot(x_,y_head,color=\"red\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}