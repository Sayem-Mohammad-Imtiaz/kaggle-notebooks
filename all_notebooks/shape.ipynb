{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport cv2\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.utils import to_categorical ,Sequence\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, BatchNormalization, Activation, Dropout\nfrom tensorflow.keras.optimizers import Adadelta, Nadam ,Adam\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, TensorBoard\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nfrom glob import glob\nfrom pathlib import Path\nimport shutil\nfrom tqdm import tqdm_notebook\nfrom random import sample, choice\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"dataset_path = Path(\"../input/data-shapes/DataX/\")\nlist(dataset_path.iterdir())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def tree(directory):\n#     print(f'+ {directory}')\n#     for path in sorted(directory.rglob('*')):\n#         depth = len(path.relative_to(directory).parts)\n#         spacer = '    ' * depth\n#         print(f'{spacer}+ {path.name}')       \n#tree(dataset_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2aa8e55311ce68e1f9c0ccbc84db792af8747c55"},"cell_type":"code","source":"train_imgs = list((dataset_path / \"train\").glob(\"*.png\"))\ntrain_labels = list((dataset_path / \"train_labels\").glob(\"*.png\"))\nval_imgs = list((dataset_path / \"val\").glob(\"*.png\"))\nval_labels = list((dataset_path / \"val_labels\").glob(\"*.png\"))\ntest_imgs = list((dataset_path / \"test\").glob(\"*.png\"))\ntest_labels = list((dataset_path / \"test_labels\").glob(\"*.png\"))\n\n(len(train_imgs),len(train_labels)), (len(val_imgs),len(val_labels)) , (len(test_imgs),len(test_labels))\n\nimg_size = 512","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d752e0fd817391d1a0026ec52ed99517c719fe93"},"cell_type":"code","source":"assert len(train_imgs) == len(train_labels), \"No of Train images and label mismatch\"\nassert len(val_imgs) == len(val_labels), \"No of Train images and label mismatch\"\nassert len(test_imgs) == len(test_labels), \"No of Train images and label mismatch\"\n\nsorted(train_imgs), sorted(train_labels), sorted(val_imgs), sorted(val_labels), sorted(test_imgs), sorted(test_labels);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for im in train_imgs:\n    assert dataset_path / \"train_labels\" / (im.stem +\".png\") in train_labels , \"{im} not there in label folder\"\nfor im in val_imgs:\n    assert dataset_path / \"val_labels\" / (im.stem +\".png\") in val_labels , \"{im} not there in label folder\"\nfor im in test_imgs:\n    assert dataset_path / \"test_labels\" / (im.stem +\".png\") in test_labels , \"{im} not there in label folder\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_pair(img,label,dataset):\n    pairs = []\n    for im in img:\n        pairs.append((im , dataset / label / (im.stem +\".png\")))\n    \n    return pairs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d523d89e24952204be653b191443a9bc4bd571c2"},"cell_type":"code","source":"train_pair = make_pair(train_imgs, \"train_labels\", dataset_path)\nval_pair = make_pair(val_imgs, \"val_labels\", dataset_path)\ntest_pair = make_pair(test_imgs, \"test_labels\", dataset_path)\n\n# print(train_pair)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c9870f3abb5243d5687637affb59cd80904f5b4"},"cell_type":"code","source":"temp = choice(train_pair)\nimg = img_to_array(load_img(temp[0], target_size=(img_size,img_size)))\nmask = img_to_array(load_img(temp[1], target_size = (img_size,img_size)))\nplt.figure(figsize=(10,10))\nplt.subplot(121)\nplt.imshow(img/255)\nplt.subplot(122)\nplt.imshow(mask/255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_map_df = pd.read_csv(dataset_path / \"class_dict.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0fe53acf9e898dab1a633e027e79e19031600f1"},"cell_type":"code","source":"class_map = []\nfor index,item in class_map_df.iterrows():\n    class_map.append(np.array([item['r'], item['g'], item['b']]))\n    \nlen(class_map)\n\n# print(class_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"418fec1fd56485370067ccde5255734a72b19a5b"},"cell_type":"code","source":"# def assert_map_range(mask,class_map):\n#     mask = mask.astype(\"uint8\")\n#     for j in range(img_size):\n#         for k in range(img_size):\n#             assert mask[j][k] in class_map , tuple(mask[j][k])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d055d4f6d59927f2eebf27ab03007660551ab36"},"cell_type":"code","source":"def form_2D_label(mask,class_map):\n    mask = mask.astype(\"uint8\")\n    label = np.zeros(mask.shape[:2],dtype= np.uint8)\n    \n    for i, rgb in enumerate(class_map):\n        label[(mask == rgb).all(axis=2)] = i\n    \n    return label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41d2c39a01154352517127b5d23b6a8128ffbad6"},"cell_type":"code","source":"lab = form_2D_label(mask,class_map)\nprint(lab.shape)\nprint(lab)\nnp.unique(lab,return_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5cf51be2c6c392853df33b37a9f26acc39e01f1"},"cell_type":"code","source":"class DataGenerator(Sequence):\n    'Generates data for Keras'\n    \n    def __init__(self, pair, class_map, batch_size=16, dim=(224,224,3), shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.pair = pair\n        self.class_map = class_map\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.pair) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [k for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.pair))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        batch_imgs = list()\n        batch_labels = list()\n\n        # Generate data\n        for i in list_IDs_temp:\n            # Store sample\n            img = load_img(self.pair[i][0] ,target_size=self.dim)\n            img = img_to_array(img)/255.\n            batch_imgs.append(img)\n\n            label = load_img(self.pair[i][1],target_size=self.dim)\n            label = img_to_array(label)\n            label = form_2D_label(label,self.class_map)\n            label = to_categorical(label , num_classes = 5)\n            batch_labels.append(label)\n            \n        return np.array(batch_imgs) ,np.array(batch_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcb288a4013fb383086dbfab6647629554860c26"},"cell_type":"code","source":"train_generator = DataGenerator(train_pair+test_pair,class_map,batch_size=4, dim=(img_size,img_size,3) ,shuffle=True)\ntrain_steps = train_generator.__len__()\ntrain_steps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55bfeb11d33052021d9e10c50eba36adc9d478e1"},"cell_type":"code","source":"X,y = train_generator.__getitem__(1)\ny.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6852a0059812b727ae4ebe095da0e843dd010e3b"},"cell_type":"code","source":"val_generator = DataGenerator(val_pair, class_map, batch_size=4, dim=(img_size,img_size,3) ,shuffle=True)\nval_steps = val_generator.__len__()\nval_steps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"078175a1e6f12557b267f606efc1e56a1cf1041d"},"cell_type":"code","source":"def conv_block(tensor, nfilters, size=3, padding='same', initializer=\"he_normal\"):\n    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(tensor)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    return x\n\n\ndef deconv_block(tensor, residual, nfilters, size=3, padding='same', strides=(2, 2)):\n    y = Conv2DTranspose(nfilters, kernel_size=(size, size), strides=strides, padding=padding)(tensor)\n    y = concatenate([y, residual], axis=3)\n    y = conv_block(y, nfilters)\n    return y\n\n\ndef Unet(h, w, filters):\n# down\n    input_layer = Input(shape=(h, w, 3), name='image_input')\n    conv1 = conv_block(input_layer, nfilters=filters)\n    conv1_out = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = conv_block(conv1_out, nfilters=filters*2)\n    conv2_out = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = conv_block(conv2_out, nfilters=filters*4)\n    conv3_out = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = conv_block(conv3_out, nfilters=filters*8)\n    conv4_out = MaxPooling2D(pool_size=(2, 2))(conv4)\n    conv4_out = Dropout(0.5)(conv4_out)\n    conv5 = conv_block(conv4_out, nfilters=filters*16)\n    conv5 = Dropout(0.5)(conv5)\n# up\n    deconv6 = deconv_block(conv5, residual=conv4, nfilters=filters*8)\n    deconv6 = Dropout(0.5)(deconv6)\n    deconv7 = deconv_block(deconv6, residual=conv3, nfilters=filters*4)\n    deconv7 = Dropout(0.5)(deconv7) \n    deconv8 = deconv_block(deconv7, residual=conv2, nfilters=filters*2)\n    deconv9 = deconv_block(deconv8, residual=conv1, nfilters=filters)\n    output_layer = Conv2D(filters=5, kernel_size=(1, 1), activation='softmax')(deconv9)\n\n    model = Model(inputs=input_layer, outputs=output_layer, name='Unet')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2021f96a4b8b838375beda097cefcf8b4cc3a1f6"},"cell_type":"code","source":"model = Unet(img_size , img_size , 10)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0252284e6b285e35a3d75dd0251944007986950b"},"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy' ,metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mc = ModelCheckpoint(mode='max', filepath='top-weights.h5', monitor='val_acc',save_best_only='True', save_weights_only='True', verbose=1)\nes = EarlyStopping(mode='max', monitor='val_acc', patience=10, verbose=0)\ntb = TensorBoard(log_dir=\"logs/\", histogram_freq=0, write_graph=True, write_images=False)\nrl = ReduceLROnPlateau(monitor='val_acc',factor=0.1,patience=5,verbose=1,mode=\"max\",min_lr=0.00001)\ncv = CSVLogger(\"logs/log.csv\" , append=True , separator=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dcb64c1d2569a9e883bfec7b7cba50e96296628f"},"cell_type":"code","source":"results = model.fit_generator(train_generator , steps_per_epoch=train_steps ,epochs=30,\n                              validation_data=val_generator,validation_steps=val_steps,callbacks=[mc,es,tb,rl,cv])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3bc07a14f8c3035263fad837497b4bcad6c2f52a"},"cell_type":"code","source":"img_mask = choice(test_pair)\nimg= img_to_array(load_img(img_mask[0] , target_size= (img_size,img_size)))\ngt_img = img_to_array(load_img(img_mask[1] , target_size= (img_size,img_size)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4981badedd11f0e4af0d93f93ac261cf603ed7a5"},"cell_type":"code","source":"def make_prediction(model,img_path,shape):\n    img= img_to_array(load_img(img_path , target_size= shape))/255.\n    img = np.expand_dims(img,axis=0)\n    labels = model.predict(img)\n    labels = np.argmax(labels[0],axis=2)\n    return labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"214de2662c28112119680ff4ae4b3329641e4528"},"cell_type":"code","source":"pred_label = make_prediction(model, img_mask[0], (img_size,img_size,3))\npred_label.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def form_colormap(prediction,mapping):\n    h,w = prediction.shape\n    color_label = np.zeros((h,w,3),dtype=np.uint8)    \n    color_label = mapping[prediction]\n    color_label = color_label.astype(np.uint8)\n    return color_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c51bbcc27d0555071c8441c851c31d64c0764461"},"cell_type":"code","source":"pred_colored = form_colormap(pred_label,np.array(class_map))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5052a1cba71150357cf927739b32a538f3226e5"},"cell_type":"code","source":"plt.figure(figsize=(15,15))\nplt.subplot(131);plt.title('Original Image')\nplt.imshow(img/255.)\nplt.subplot(132);plt.title('True labels')\nplt.imshow(gt_img/255.)\nplt.subplot(133)\nplt.imshow(pred_colored/255.);plt.title('predicted labels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('../working/my-model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pip install --no-deps tensorflowjs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflowjs as tfjs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfjs.converters.save_keras_model(model, \"my-model\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink, FileLinks\nFileLinks('.') #lists all downloadable files on serve","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}