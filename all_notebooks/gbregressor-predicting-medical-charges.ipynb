{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"105d572e-e0ed-4b87-860e-7994af0b3aac","_cell_guid":"a0139781-2df6-4287-8fcc-859281c3a507","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-24T07:47:20.499992Z","iopub.execute_input":"2021-06-24T07:47:20.500355Z","iopub.status.idle":"2021-06-24T07:47:20.505337Z","shell.execute_reply.started":"2021-06-24T07:47:20.500307Z","shell.execute_reply":"2021-06-24T07:47:20.504178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/insurance/insurance.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-24T07:47:20.507029Z","iopub.execute_input":"2021-06-24T07:47:20.507638Z","iopub.status.idle":"2021-06-24T07:47:20.523618Z","shell.execute_reply.started":"2021-06-24T07:47:20.507598Z","shell.execute_reply":"2021-06-24T07:47:20.522607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataset: *Machine Leearning with R* Brett Lantz, with a region set in the USA. ","metadata":{}},{"cell_type":"code","source":"## Data Info\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T07:47:20.525685Z","iopub.execute_input":"2021-06-24T07:47:20.526038Z","iopub.status.idle":"2021-06-24T07:47:20.539168Z","shell.execute_reply.started":"2021-06-24T07:47:20.526005Z","shell.execute_reply":"2021-06-24T07:47:20.538337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head().T","metadata":{"execution":{"iopub.status.busy":"2021-06-24T07:47:20.541844Z","iopub.execute_input":"2021-06-24T07:47:20.542169Z","iopub.status.idle":"2021-06-24T07:47:20.554509Z","shell.execute_reply.started":"2021-06-24T07:47:20.542137Z","shell.execute_reply":"2021-06-24T07:47:20.553559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Missing Values\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T07:47:20.555874Z","iopub.execute_input":"2021-06-24T07:47:20.556452Z","iopub.status.idle":"2021-06-24T07:47:20.567039Z","shell.execute_reply.started":"2021-06-24T07:47:20.556417Z","shell.execute_reply":"2021-06-24T07:47:20.566022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Target Variable\n### Distribution\nsns.displot(df.charges, kde = True, color = \"b\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T07:47:20.568553Z","iopub.execute_input":"2021-06-24T07:47:20.568895Z","iopub.status.idle":"2021-06-24T07:47:20.879865Z","shell.execute_reply.started":"2021-06-24T07:47:20.56886Z","shell.execute_reply":"2021-06-24T07:47:20.879219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in df.columns:\n    if df[column].dtype == 'O':\n        print(column)\n        print(df[column].value_counts(), \"\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-06-24T07:47:20.881414Z","iopub.execute_input":"2021-06-24T07:47:20.881728Z","iopub.status.idle":"2021-06-24T07:47:20.89246Z","shell.execute_reply.started":"2021-06-24T07:47:20.881695Z","shell.execute_reply":"2021-06-24T07:47:20.890333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Feature Engineering\n\nfrom sklearn.preprocessing import LabelEncoder\n\nsex_map = {'male':1, 'female':0}\ndf['sex'] = df['sex'].map(sex_map).astype('int64')\n\nsmoker_map = {'yes':1, 'no':0}\ndf['smoker'] = df['smoker'].map(smoker_map).astype('int64')\n\nLE = LabelEncoder()\ndf['region'] = LE.fit_transform(df['region'])\n# Southeast region makes highest expense so let region southeast = 2 and others are 1\n# df['region'] = df['region'].replace(('southeast', 'southwest', 'northwest', 'northeast'), (2, 1, 1, 1))\n# df['region'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T07:47:20.893857Z","iopub.execute_input":"2021-06-24T07:47:20.894188Z","iopub.status.idle":"2021-06-24T07:47:20.907119Z","shell.execute_reply.started":"2021-06-24T07:47:20.894153Z","shell.execute_reply":"2021-06-24T07:47:20.906107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.shape[0])\ndf = df.dropna()\n\nprint(df.shape[0])","metadata":{"execution":{"iopub.status.busy":"2021-06-24T07:47:20.908183Z","iopub.execute_input":"2021-06-24T07:47:20.908568Z","iopub.status.idle":"2021-06-24T07:47:20.921509Z","shell.execute_reply.started":"2021-06-24T07:47:20.908533Z","shell.execute_reply":"2021-06-24T07:47:20.920728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{"execution":{"iopub.status.busy":"2021-06-24T07:38:49.074886Z","iopub.execute_input":"2021-06-24T07:38:49.075197Z","iopub.status.idle":"2021-06-24T07:38:49.142192Z","shell.execute_reply.started":"2021-06-24T07:38:49.075169Z","shell.execute_reply":"2021-06-24T07:38:49.140159Z"}}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nsex_map = {'male':1, 'female':0}\ndf['sex'] = df['sex'].map(sex_map)\n\nsmoker_map = {'yes':1, 'no':0}\ndf['smoker'] = df['smoker'].map(smoker_map)\n\nLE = LabelEncoder()\ndf['region'] = LE.fit_transform(df['region'])\n# Southeast region makes highest expense so let region southeast = 2 and others are 1\n# df['region'] = df['region'].replace(('southeast', 'southwest', 'northwest', 'northeast'), (2, 1, 1, 1))\n# df['region'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-24T07:51:14.252439Z","iopub.execute_input":"2021-06-24T07:51:14.252766Z","iopub.status.idle":"2021-06-24T07:51:14.263754Z","shell.execute_reply.started":"2021-06-24T07:51:14.252736Z","shell.execute_reply":"2021-06-24T07:51:14.262737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score","metadata":{"execution":{"iopub.status.busy":"2021-06-24T07:49:35.962791Z","iopub.execute_input":"2021-06-24T07:49:35.96315Z","iopub.status.idle":"2021-06-24T07:49:36.016896Z","shell.execute_reply.started":"2021-06-24T07:49:35.963118Z","shell.execute_reply":"2021-06-24T07:49:36.016127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop(columns = 'charges').values\ny = df['charges'].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size  = 0.2, \n                                                    random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T07:49:45.998003Z","iopub.execute_input":"2021-06-24T07:49:45.998347Z","iopub.status.idle":"2021-06-24T07:49:46.005554Z","shell.execute_reply.started":"2021-06-24T07:49:45.998317Z","shell.execute_reply":"2021-06-24T07:49:46.00438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Size of x_train = ', X_train.shape)\nprint('Size of x_test  = ', X_test.shape)\nprint('Size of y_train = ', y_train.shape)\nprint('Size of y_test  = ', y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T07:50:08.368816Z","iopub.execute_input":"2021-06-24T07:50:08.36913Z","iopub.status.idle":"2021-06-24T07:50:08.378447Z","shell.execute_reply.started":"2021-06-24T07:50:08.369099Z","shell.execute_reply":"2021-06-24T07:50:08.377637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Feature Scaling\n\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T08:28:49.081869Z","iopub.execute_input":"2021-06-24T08:28:49.082179Z","iopub.status.idle":"2021-06-24T08:28:49.090853Z","shell.execute_reply.started":"2021-06-24T08:28:49.08215Z","shell.execute_reply":"2021-06-24T08:28:49.090013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score, mean_squared_error, mean_squared_log_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n\n## Model Selection\nmodels = []\nmodels.append(('LR', LinearRegression()))\nmodels.append(('RF', RandomForestRegressor()))\nmodels.append(('GBR', GradientBoostingRegressor()))\n\n## Model Evaluation\nresults = []\nnames = []\nfor name, model in models:\n    fit_model = model.fit(X_train, y_train)\n    y_pred = fit_model.predict(X_test)\n\n    r2 = r2_score(y_test, y_pred)\n    mse = mean_squared_error(y_test, y_pred)\n    rmse = np.sqrt(mse)\n    \n    ## Cross Validation\n    cv = cross_val_score(model, X, y, cv = 7)\n\n    results.append((r2_score, rmse))\n    names.append(name)\n    print(\"Cross Validation - Reported accuracy should not have high variance\")\n    print(cv)\n    print()\n    print('{}:R2 {}% Accuracy - RMSE: Predicted Values +/-{}'.format(name, (round(r2, 3)*100), rmse))","metadata":{"execution":{"iopub.status.busy":"2021-06-24T08:31:36.22644Z","iopub.execute_input":"2021-06-24T08:31:36.226807Z","iopub.status.idle":"2021-06-24T08:31:39.555537Z","shell.execute_reply.started":"2021-06-24T08:31:36.226775Z","shell.execute_reply":"2021-06-24T08:31:39.55456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Linear Regression, RandomForestRegressor and Gradient Boosting Regressor models give increasingly reliable results in the same order.\n\nThe GradientBoost returns the r squared as 89.6% and Root Mean Squared Error of 4063.9423, this can be interpreted as an almost 90% accuracy of this model and a +/- of 4024.6516 the predicted values from the auctual values.\n\nNow we tune the parameters of the best performing Regressor.","metadata":{}},{"cell_type":"code","source":"### Hyper Parameter Tuning\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'loss':['ls', 'lad', 'huber', 'quantile'],\n    'max_features': ['auto', 'sqrt', 'log2'],\n    'learning_rate':[0.05, 0.1, 0.2],\n    'max_depth':[1, 2, 10, 150],\n    'n_estimators':[100, 150, 500, 750, 1000]\n}\n\nGBR = GradientBoostingRegressor()\nGBR_cv = GridSearchCV(estimator = GBR, param_grid = param_grid, verbose = 1)\nGBR_cv.fit(X_train, y_train)\n\nparams = GBR_cv.best_params_\nprint(params)","metadata":{"execution":{"iopub.status.busy":"2021-06-24T08:49:52.001646Z","iopub.execute_input":"2021-06-24T08:49:52.001992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Pipeline\n# from sklearn.pipeline import make_pipeline\n\nmodel = GradientBoostingRegressor(learning_rate = params['learning_rate'], \n                                  loss=params['loss'], \n                                  max_features = params['max_features'])\nmodel.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, X_test, y_test, modelName, DataImb):\n    print('------------------------------------------------')\n    print(\"Model \", modelName, end=\"\\n\")\n    print(\"Data Balancing Type \", DataImb)\n    ### Model must be ran outside the function\n    y_pred = model.predict(X_test)\n    r2 = r2_score(y_test, y_pred)\n    mse = mean_squared_error(y_test, y_pred)\n    rmse = np.sqrt(mse)\n    print(\"R2 Score\", r2)\n    print(\"RMSE\", rmse)\n    return[modelName, DataImb, r2, rmse]\n\nevaluate_model(model, X_test, y_test, 'Gradient Boosting Regressor', \"Auctual Data\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not much imporvement from our original accuracy, however the GBRegressor returns the r squared as ~ 90% and Root Mean Squared Error of 3998.0224.\n\nBetter Tuning methods and inputs can still be explored.","metadata":{}}]}