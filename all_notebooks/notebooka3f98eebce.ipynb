{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-30T13:25:19.196975Z","iopub.execute_input":"2021-06-30T13:25:19.197315Z","iopub.status.idle":"2021-06-30T13:25:19.206648Z","shell.execute_reply.started":"2021-06-30T13:25:19.197274Z","shell.execute_reply":"2021-06-30T13:25:19.205739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install -r ../input/transactions/requirements_financial_transactions.txt\n# !pip install 'scikit_learn==0.24.2'","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:19.208346Z","iopub.execute_input":"2021-06-30T13:25:19.208657Z","iopub.status.idle":"2021-06-30T13:25:19.218233Z","shell.execute_reply.started":"2021-06-30T13:25:19.208626Z","shell.execute_reply":"2021-06-30T13:25:19.217359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn\nprint('The scikit-learn version is {}.'.format(sklearn.__version__))","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:19.220316Z","iopub.execute_input":"2021-06-30T13:25:19.221Z","iopub.status.idle":"2021-06-30T13:25:19.229871Z","shell.execute_reply.started":"2021-06-30T13:25:19.220965Z","shell.execute_reply":"2021-06-30T13:25:19.228979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"../input/transactions/transactions.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:19.231498Z","iopub.execute_input":"2021-06-30T13:25:19.232218Z","iopub.status.idle":"2021-06-30T13:25:20.495371Z","shell.execute_reply.started":"2021-06-30T13:25:19.232183Z","shell.execute_reply":"2021-06-30T13:25:20.494398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df.drop(columns = \"Class\"),\n                                                    df[\"Class\"],\n                                                    test_size = 0.2,\n                                                    stratify = df[\"Class\"])\nprint(f\"{y_train.size} train samples\\n {y_test.size} test samples\")","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:20.496818Z","iopub.execute_input":"2021-06-30T13:25:20.497173Z","iopub.status.idle":"2021-06-30T13:25:20.704619Z","shell.execute_reply.started":"2021-06-30T13:25:20.497136Z","shell.execute_reply":"2021-06-30T13:25:20.703605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.dummy import DummyClassifier\ndummy = DummyClassifier().fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:20.706018Z","iopub.execute_input":"2021-06-30T13:25:20.706383Z","iopub.status.idle":"2021-06-30T13:25:20.71694Z","shell.execute_reply.started":"2021-06-30T13:25:20.706346Z","shell.execute_reply":"2021-06-30T13:25:20.716142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\ndef save_model(model, filename='model.sav'):\n    pickle.dump(model, open(filename, 'wb'))\n    \ndef load_model(filename='model.sav'):\n    model = pickle.load(open(filename, 'rb'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:20.718132Z","iopub.execute_input":"2021-06-30T13:25:20.71861Z","iopub.status.idle":"2021-06-30T13:25:20.725699Z","shell.execute_reply.started":"2021-06-30T13:25:20.718572Z","shell.execute_reply":"2021-06-30T13:25:20.724984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nprint(\"y_train frauds\", np.count_nonzero(y_train))\nprint(\"y_test frauds\", np.count_nonzero(y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:20.726679Z","iopub.execute_input":"2021-06-30T13:25:20.726966Z","iopub.status.idle":"2021-06-30T13:25:20.7365Z","shell.execute_reply.started":"2021-06-30T13:25:20.726939Z","shell.execute_reply":"2021-06-30T13:25:20.735459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import resample\n\ndef resample_data(n_samples=0):\n    minority_idx = y_train == 1\n    majority_idx = np.logical_not(minority_idx)\n    if n_samples <= 0:\n        n_samples = y_train[majority_idx].shape[0]\n        \n    X_0, y_0 = resample(X_train[majority_idx],\n                        y_train[majority_idx],\n                        replace=True,\n                        n_samples=n_samples,\n                        random_state=123)\n    \n    X_1, y_1 = resample(X_train[minority_idx],\n                        y_train[minority_idx],\n                        replace=True,\n                        n_samples=n_samples,\n                        random_state=123)\n    \n    X = np.vstack((X_0, X_1))\n    y = np.hstack((y_0, y_1))\n \n    permut = np.random.permutation(X.shape[0])\n    X = X[permut]\n    y = y[permut]\n    \n    return X, y","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:20.739871Z","iopub.execute_input":"2021-06-30T13:25:20.740272Z","iopub.status.idle":"2021-06-30T13:25:20.748068Z","shell.execute_reply.started":"2021-06-30T13:25:20.740242Z","shell.execute_reply":"2021-06-30T13:25:20.746921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\ndef pca():\n    pca = PCA()\n    errors = []\n\n    for i in range(2, 10):\n        pca = PCA(n_components=i)\n        X_reduced = pca.fit_transform(X_train)\n        X_reconstructed = pca.inverse_transform(X_reduced)\n\n        error = np.mean((X_train - X_reconstructed) ** 2)\n        error = np.mean(error)\n        errors.append(error)\n        print('i:', i)\n        print('Error:', error)\n\n    plt.plot(range(2,10), errors)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:20.750197Z","iopub.execute_input":"2021-06-30T13:25:20.750811Z","iopub.status.idle":"2021-06-30T13:25:20.760019Z","shell.execute_reply.started":"2021-06-30T13:25:20.750766Z","shell.execute_reply":"2021-06-30T13:25:20.759212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\ndef plot_best_features(): \n    \"\"\"\n    Displays the best features using the sklearn ExtraTreesClassifier.\n    \n    \"\"\"\n        \n    data = df\n    X = data.iloc[:,0:30]  #independent columns\n    y = data.iloc[:,-1]    #target column i.e price range\n    from sklearn.ensemble import ExtraTreesClassifier\n    \n    model = ExtraTreesClassifier()\n    model.fit(X,y)\n    print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n    #plot graph of feature importances for better visualization\n    feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n    feat_importances.nlargest(10).plot(kind='barh')\n    plt.show()\n\ndef plot_corr():\n    \"\"\"\n    Displays the correlation matrix of the features.\n    \"\"\"\n    corr = df.corr()\n    plt.figure(figsize=(20, 10))\n    sns.heatmap(df.corr(), annot=True)\n    \n# plot_best_features()\n# plot_corr()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-06-30T13:25:20.761167Z","iopub.execute_input":"2021-06-30T13:25:20.761632Z","iopub.status.idle":"2021-06-30T13:25:20.769963Z","shell.execute_reply.started":"2021-06-30T13:25:20.761597Z","shell.execute_reply":"2021-06-30T13:25:20.768888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nclf = dummy\nstandardScaler = StandardScaler()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:20.77134Z","iopub.execute_input":"2021-06-30T13:25:20.771675Z","iopub.status.idle":"2021-06-30T13:25:20.781575Z","shell.execute_reply.started":"2021-06-30T13:25:20.771643Z","shell.execute_reply":"2021-06-30T13:25:20.780784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def leader_board_predict_fn(values):\n    # YOUR CODE HERE\n    values = standardScaler.transform(values)\n    return clf.predict(values)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:20.782624Z","iopub.execute_input":"2021-06-30T13:25:20.782856Z","iopub.status.idle":"2021-06-30T13:25:20.790792Z","shell.execute_reply.started":"2021-06-30T13:25:20.782834Z","shell.execute_reply":"2021-06-30T13:25:20.790003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### LEADER BOARD TEST\nfrom sklearn.metrics import roc_auc_score\n# score = roc_auc_score(y_test, leader_board_predict_fn(X_test))\n# print(f\"Leaderboard Score: {score}\")\n### LEADER BOARD TEST\n\ndef leader_board_predict_fn_sklearn(standardScaler, clf, values):\n    # YOUR CODE HERE\n    values = standardScaler.transform(values)\n    return clf.predict(values)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:20.791957Z","iopub.execute_input":"2021-06-30T13:25:20.792459Z","iopub.status.idle":"2021-06-30T13:25:20.799196Z","shell.execute_reply.started":"2021-06-30T13:25:20.792424Z","shell.execute_reply":"2021-06-30T13:25:20.798369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\nclassifiers = {\n    \"LDA\": LDA(),\n    \"SVM\": SVC(),\n    \"DTREE\": DecisionTreeClassifier(),\n    \"LOG_REG\": LogisticRegression(),\n    \"KNearest\": KNeighborsClassifier(),\n    \"NAIVE_BAYES\": GaussianNB()\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:20.800411Z","iopub.execute_input":"2021-06-30T13:25:20.800749Z","iopub.status.idle":"2021-06-30T13:25:20.809107Z","shell.execute_reply.started":"2021-06-30T13:25:20.800714Z","shell.execute_reply":"2021-06-30T13:25:20.808264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import SMOTE\n\nresampler = {\n    \"oversample\": RandomOverSampler(random_state=12),\n    \"undersample\": RandomUnderSampler(random_state=12),\n    \"smote\": SMOTE(random_state=12),\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:20.811876Z","iopub.execute_input":"2021-06-30T13:25:20.812146Z","iopub.status.idle":"2021-06-30T13:25:20.821762Z","shell.execute_reply.started":"2021-06-30T13:25:20.812115Z","shell.execute_reply":"2021-06-30T13:25:20.820927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_classifiers_resampler(classifiers, resampler):\n    \"\"\"\n    Does combinations of the given classifiers and resamplers and executes the roc_auc_score.\n    The data is scaled with StandardScaler before fitting the model.\n    Uses preimplemented sklearn models and imblearn sampling to get an overview of classifier performance\n    \"\"\"\n    for i in [5000, 7500, 10000, 20000, 50000]:\n        \n        X, y = resample_data(n_samples=i)\n        standardScaler = StandardScaler()\n        X = standardScaler.fit_transform(X, y)\n        \n        print(\"Resample to: N =\", i)\n        for key, classifier in classifiers.items():\n            if i > 5000 and (key == \"SVM\" or key == \"KNearest\"):\n                # continue because SVM and KNearest would take to long for such a problem size\n                # without real benefit\n                continue\n            \n            print(\"Classifier:\", key)\n            clf = classifier\n            clf = clf.fit(X, y)\n            score = roc_auc_score(y_test, leader_board_predict_fn_sklearn(standardScaler, clf, X_test))\n            print(f\"Leaderboard Score: {score}\")\n\n    for key_resample, resample in resampler.items():\n        X, y = resample.fit_resample(X_train, y_train)\n        print(\"Resampler:\", key_resample)\n        \n        standardScaler = StandardScaler()\n        X = standardScaler.fit_transform(X, y)\n        for key, classifier in classifiers.items():\n            if key == \"SVM\" or key == \"KNearest\":\n                # Too big problem size for SVM, KNearest. SVM, KNearest performance tested above\n                continue\n\n            print(\"Classifier:\", key)\n            clf = classifier\n            clf = clf.fit(X, y)\n            score = roc_auc_score(y_test, leader_board_predict_fn_sklearn(standardScaler, clf, X_test))\n            print(f\"Leaderboard Score: {score}\")\n            \n            \n# UNCOMMENT the line below if you want to compare different classifiers and resamplers\n# test_classifiers_resampler(classifiers, resampler)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:20.823177Z","iopub.execute_input":"2021-06-30T13:25:20.823568Z","iopub.status.idle":"2021-06-30T13:25:20.835688Z","shell.execute_reply.started":"2021-06-30T13:25:20.823479Z","shell.execute_reply":"2021-06-30T13:25:20.834945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Classifier:\n    \"\"\"\n    Basic classifier defining methods train and predict.\n    This class does no classifications. Use Sub-classes instead\n    \"\"\"\n    def train(self, X, y):\n        pass\n\n    def predict(self, X):\n        pass","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:20.836984Z","iopub.execute_input":"2021-06-30T13:25:20.837464Z","iopub.status.idle":"2021-06-30T13:25:20.843931Z","shell.execute_reply.started":"2021-06-30T13:25:20.837427Z","shell.execute_reply":"2021-06-30T13:25:20.84317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LogisticRegression(Classifier):\n\n    def __init__(self):\n        self.w = None\n\n    def sigmoid(self, z):\n        \"\"\"\n        Function that computes the sigmoid of the input values.\n\n        :param z: input values\n        :returns: sigmoid values for each input value\n        \"\"\"\n\n        return 1 / (1 + np.exp(-z))\n\n    def loss_function_gradient(self, w, x, y):\n        \"\"\"\n        Function that computes the empirical loss for a logistic regression model.\n\n        :param w: Weights vector\n        :param x: Training input data\n        :param y: Training target labels\n        :returns: gradient of the loss\n        \"\"\"\n\n        N = y.shape[0]\n\n        f_x = self.sigmoid(x @ w)\n\n        gradient = np.dot(x.T, (f_x - y)) / N \n\n        return gradient\n\n    def batch_gradient_descent(self, x, y, alpha=0.01, num_steps=5000):\n        \"\"\"\n        Implementation of the gradient descent algorithm for logistic regression\n\n        :param: x: Training input data\n        :param: y: Training target labels\n        :param: alpha: Scalar learning rate\n        :param: num_steps: Number of gradient descent steps\n        :returns: weight vector 'w'\n        \"\"\"\n\n        # Initialize the weights to zero\n        w = np.zeros((x.shape[1]))\n\n        for i in range(num_steps):\n            w = w - alpha * self.loss_function_gradient(w, x, y)\n\n        return w\n\n    def train(self, X, y):\n        self.w = self.batch_gradient_descent(X, y)\n        print(\"Finished training\")\n\n    def predict(self, x):\n        \"\"\"\n        Assign input to a class using the logistic regression model.\n\n        :param: w: Weight vector\n        :param: x: Test input data\n        :returns: Predicted class labels (0 or 1)\n        \"\"\"\n\n        if self.w is None:\n            print(\"Weights not specified. Train the model first\")\n            return\n\n        f_x = self.sigmoid(x @ self.w)\n#         predictions = np.round(f_x)\n        \n        predictions = f_x\n\n        return predictions\n","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:20.84488Z","iopub.execute_input":"2021-06-30T13:25:20.845151Z","iopub.status.idle":"2021-06-30T13:25:20.855704Z","shell.execute_reply.started":"2021-06-30T13:25:20.845123Z","shell.execute_reply":"2021-06-30T13:25:20.854751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_LogisticRegression():\n    \"\"\"\n    Trains a LogisticRegression model using RandomOverSampler and the LogisticRegression class.\n    :returns: the standardScaler and the trained model\n    \"\"\"\n    clf = LogisticRegression()\n    standardScaler = StandardScaler()\n\n    X, y = RandomUnderSampler(sampling_strategy=0.2).fit_resample(X_train, y_train)\n    X = standardScaler.fit_transform(X, y)\n\n    clf.train(X, y)\n    \n    return standardScaler, clf\n\nstandardScaler, clf = train_LogisticRegression()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:20.857272Z","iopub.execute_input":"2021-06-30T13:25:20.857934Z","iopub.status.idle":"2021-06-30T13:25:23.600831Z","shell.execute_reply.started":"2021-06-30T13:25:20.85788Z","shell.execute_reply":"2021-06-30T13:25:23.599863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## LEADER BOARD TEST\nfrom sklearn.metrics import roc_auc_score\nscore = roc_auc_score(y_test, leader_board_predict_fn(X_test))\nprint(f\"Leaderboard Score: {score}\")\n## LEADER BOARD TEST","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:23.604769Z","iopub.execute_input":"2021-06-30T13:25:23.606946Z","iopub.status.idle":"2021-06-30T13:25:23.650012Z","shell.execute_reply.started":"2021-06-30T13:25:23.606885Z","shell.execute_reply":"2021-06-30T13:25:23.649128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n# Check https://pytorch.org/docs/stable/notes/randomness.html#reproducibility\ntorch.manual_seed(123)\nprint(\"gpu available:\", torch.cuda.is_available())\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:23.654052Z","iopub.execute_input":"2021-06-30T13:25:23.656145Z","iopub.status.idle":"2021-06-30T13:25:23.668072Z","shell.execute_reply.started":"2021-06-30T13:25:23.656096Z","shell.execute_reply":"2021-06-30T13:25:23.666949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define hyperparameters\nLEARNING_RATE = 0.0002\nINPUT_SIZE = 30\nHIDDEN_SIZE = 11\nOUTPUT_SIZE = 1\n\nNUM_EPOCHS = 3\nBATCH_SIZE = 64\n\nMODEL_NAME = 'model.pt'\nSCALER_NAME = 'scaler.sav'","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:23.672329Z","iopub.execute_input":"2021-06-30T13:25:23.674443Z","iopub.status.idle":"2021-06-30T13:25:23.681425Z","shell.execute_reply.started":"2021-06-30T13:25:23.674397Z","shell.execute_reply":"2021-06-30T13:25:23.680512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(Net, self).__init__()\n        self.hidden_size = hidden_size\n        self.input_size = input_size\n        self.output_size = output_size\n        \n        self.fc1 = nn.Linear(input_size, hidden_size)\n        self.fc2 = nn.Linear(hidden_size, hidden_size)\n        self.fc3 = nn.Linear(hidden_size, hidden_size)\n        self.fc4 = nn.Linear(hidden_size, output_size)\n        \n        \n        \n    def forward(self, x):\n        # Flatten the input x keeping the batch dimension the same\n        # Use the relu activation functions \n        # Pass x through functions but do not apply any activation function\n        \n        \n        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        \n        \n        return x  # Return x (logits)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:23.686605Z","iopub.execute_input":"2021-06-30T13:25:23.687212Z","iopub.status.idle":"2021-06-30T13:25:23.700407Z","shell.execute_reply.started":"2021-06-30T13:25:23.687173Z","shell.execute_reply":"2021-06-30T13:25:23.699347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def binary_acc(y_pred, y_test):\n    \"\"\"\n    Calculates the accuracy of the predicted values y_pred in comparison to y_test.\n    :returns: the accuracy\n    \"\"\"\n    predictions = torch.round(torch.sigmoid(y_pred))\n\n    correct_results_sum = (predictions == y_test).sum().float()\n    acc = correct_results_sum / y_test.shape[0]\n    acc = torch.round(acc * 100)\n    \n    return acc","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:23.705549Z","iopub.execute_input":"2021-06-30T13:25:23.708095Z","iopub.status.idle":"2021-06-30T13:25:23.715891Z","shell.execute_reply.started":"2021-06-30T13:25:23.708052Z","shell.execute_reply":"2021-06-30T13:25:23.714973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\ndef train_neural_network_pytorch(net, train_loader, optimizer, criterion, num_epochs):\n    \"\"\"\n    Function for training the PyTorch network.\n    \n    :param net: the neural network object\n    :param inputs: numpy array of training data values\n    :param labels: numpy array of training data labels \n    :param optimizer: PyTorch optimizer instance\n    :param criterion: PyTorch loss function\n    :param iterations: number of training steps\n    \"\"\"    \n    net.train()  # Before training, set the network to training mode\n    \n    for epoch in range(num_epochs):\n        epoch_loss = 0.0\n        epoch_acc = 0.0\n        for batch_idx, (inputs, labels) in enumerate(tqdm(train_loader)):\n            inputs = inputs.to(device)\n            labels = labels = labels.unsqueeze(1).to(device)\n\n            # 1. Zero parameter gradients\n            # 2. Forward\n            # 3. Compute loss\n            # 4. Backward\n            # 5. Update step\n\n            optimizer.zero_grad()\n            outputs = net.forward(inputs)\n            loss = criterion(outputs, labels)\n            # calculate current accuracy\n            acc = binary_acc(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            epoch_loss += loss.item()\n            epoch_acc += acc.item()\n            if batch_idx % 1000 == 999:\n                print(f'Loss: {loss.item():.5f}')\n            \n        print(f'Epoch {epoch}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n        \n    print('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:23.721081Z","iopub.execute_input":"2021-06-30T13:25:23.72326Z","iopub.status.idle":"2021-06-30T13:25:23.735401Z","shell.execute_reply.started":"2021-06-30T13:25:23.723217Z","shell.execute_reply":"2021-06-30T13:25:23.73447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the network\nnet = Net(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\nnet = net.to(device)\n\n# Define the loss criterion and the training algorithm\n\ncriterion = nn.BCEWithLogitsLoss().to(device)  # binary cross entropy\n\n# Using Adam optimizer instead of SGD\n# Adam was faster converging to the (nearly) optimum\n# Adam Optimizer does not need a momentum\noptimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:23.743531Z","iopub.execute_input":"2021-06-30T13:25:23.746219Z","iopub.status.idle":"2021-06-30T13:25:23.756501Z","shell.execute_reply.started":"2021-06-30T13:25:23.746177Z","shell.execute_reply":"2021-06-30T13:25:23.75541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass trainData(Dataset):\n    \"\"\"\n    Basic class to store a dataset as torch-Dataset that can be used for torch epochs.\n    \"\"\"\n    \n    def __init__(self, X_data, y_data):\n        self.X_data = X_data\n        self.y_data = y_data\n        \n    def __getitem__(self, index):\n        return self.X_data[index], self.y_data[index]\n        \n    def __len__ (self):\n        return len(self.X_data)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:23.759022Z","iopub.execute_input":"2021-06-30T13:25:23.759346Z","iopub.status.idle":"2021-06-30T13:25:23.765379Z","shell.execute_reply.started":"2021-06-30T13:25:23.759315Z","shell.execute_reply":"2021-06-30T13:25:23.764458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ndef train_nn():\n    \"\"\"\n    Preprocesses data, transforms data to torch datasets and starts training the NN-model.\n    \"\"\"\n    X, y = SMOTE(random_state=12).fit_resample(X_train.values, y_train.values.ravel())\n        \n    scaler = StandardScaler()\n    X = scaler.fit_transform(X, y)\n\n    train_data = trainData(torch.FloatTensor(X), \n                           torch.FloatTensor(y))\n    \n    train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n    \n    # Train the PyTorch network\n    train_neural_network_pytorch(net, train_loader, optimizer, criterion, NUM_EPOCHS)\n    \n    return scaler\n    \nscaler = train_nn()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:25:23.766702Z","iopub.execute_input":"2021-06-30T13:25:23.767106Z","iopub.status.idle":"2021-06-30T13:26:17.09508Z","shell.execute_reply.started":"2021-06-30T13:25:23.767072Z","shell.execute_reply":"2021-06-30T13:26:17.094096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save standardScaler\nsave_model(scaler, filename=SCALER_NAME)\n# save nn-model\ntorch.save(net, MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:26:17.096407Z","iopub.execute_input":"2021-06-30T13:26:17.096898Z","iopub.status.idle":"2021-06-30T13:26:17.103759Z","shell.execute_reply.started":"2021-06-30T13:26:17.096857Z","shell.execute_reply":"2021-06-30T13:26:17.102994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def leader_board_predict_fn(values):\n    \"\"\"\n    Function for producing neural network predictions\n    \"\"\"\n    # standardscalar for scaling the data (preprocessing)\n    scaler = load_model(filename=SCALER_NAME)\n    X = scaler.transform(values.values.astype(np.float32))\n\n    net = torch.load(MODEL_NAME, map_location='cpu')\n    net.eval()\n    \n    # Make predictions (class 0 or 1) using the learned parameters\n    # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.\n    X = torch.tensor(X)\n    logits = net(X)\n    # class 0 if < 0.5, class 1 if >= 0.5 and <= 1\n    predictions = torch.round(torch.sigmoid(logits))\n    \n    return predictions.int()","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:26:17.105299Z","iopub.execute_input":"2021-06-30T13:26:17.10583Z","iopub.status.idle":"2021-06-30T13:26:17.113952Z","shell.execute_reply.started":"2021-06-30T13:26:17.105793Z","shell.execute_reply":"2021-06-30T13:26:17.113238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### LEADER BOARD TEST\nfrom sklearn.metrics import roc_auc_score\ny_pred = leader_board_predict_fn(X_test)\nscore_test = roc_auc_score(y_test, y_pred)\nprint(f\"test: Leaderboard Score: {score_test}\")\n### LEADER BOARD TEST\n\nscore_train = roc_auc_score(y_train, leader_board_predict_fn(X_train))\nprint(f\"train: Leaderboard Score: {score_train}\")\n\nmean_score = np.mean([score_test, score_train])\nprint(f\"mean: Leaderboard Score: {mean_score}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:26:17.115211Z","iopub.execute_input":"2021-06-30T13:26:17.115569Z","iopub.status.idle":"2021-06-30T13:26:17.22912Z","shell.execute_reply.started":"2021-06-30T13:26:17.115533Z","shell.execute_reply":"2021-06-30T13:26:17.228223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Print classification report. Usefull to see if the minority class is predicted good enough\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:26:17.230362Z","iopub.execute_input":"2021-06-30T13:26:17.230867Z","iopub.status.idle":"2021-06-30T13:26:17.28646Z","shell.execute_reply.started":"2021-06-30T13:26:17.230829Z","shell.execute_reply":"2021-06-30T13:26:17.285621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom pandas import DataFrame\n\ndef cross_validation():\n    \"\"\"\n    Performs a cross validation. Trains the NN, tests its performance and prints the result\n    Usefull to check the overall or best performance of a NN model\n    \"\"\"\n    X = df.drop(columns = \"Class\").values\n    y = df[\"Class\"].values\n    \n    kf = StratifiedKFold(n_splits=5)\n    scores = []\n    for train, test in kf.split(X, y):\n        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n\n        X_train, y_train = RandomOverSampler(random_state=12).fit_resample(X_train, y_train.ravel())\n\n        scaler = StandardScaler()\n        X_train = scaler.fit_transform(X_train, y_train)\n\n        # Initialize the network\n        net = Net(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE).to(device)\n\n        # Define the loss criterion and the training algorithm\n        criterion = nn.BCEWithLogitsLoss().to(device)  # binary cross entropy\n        optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n\n        train_data = trainData(torch.FloatTensor(X_train), \n                       torch.FloatTensor(y_train))\n        train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n\n        train_neural_network_pytorch(net, train_loader, optimizer, criterion, num_epochs=NUM_EPOCHS)\n\n        # save standardScaler\n        save_model(scaler, filename=SCALER_NAME)\n        # save nn-model\n        torch.save(net, MODEL_NAME)\n\n        ### LEADER BOARD TEST\n        y_pred = leader_board_predict_fn(DataFrame(X_test))\n        score_test = roc_auc_score(y_test, y_pred)\n        print(f\"Leaderboard Score: {score_test}\")\n        scores.append(score_test)\n        print(classification_report(y_test, y_pred))\n            \n    \n    plt.plot(scores)\n    plt.show()\n# cross_validation()    ","metadata":{"execution":{"iopub.status.busy":"2021-06-30T13:26:17.287757Z","iopub.execute_input":"2021-06-30T13:26:17.288105Z","iopub.status.idle":"2021-06-30T13:26:17.29922Z","shell.execute_reply.started":"2021-06-30T13:26:17.28807Z","shell.execute_reply":"2021-06-30T13:26:17.298165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}