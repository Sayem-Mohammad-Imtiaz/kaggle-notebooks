{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n#ignore warnings for convenience\nwarnings.filterwarnings(\"ignore\")\n\nimport os\n\nprint(os.listdir(\"../input/vectordigits\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, we get the basic info about the dataset."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","scrolled":true,"trusted":true},"cell_type":"code","source":"#extracting training data and obtaining the basic info\n\ntrain_data = pd.read_csv(\"../input/vectordigits/training.csv\")\ntrain_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we test different algorithms on the dataset. Separate the target variable and the arguments"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_data['label']\ntrain_data = train_data.drop(['label'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We clearly see that the ranges of values of each feature are too large to encode it in binary. There are no missing values, so no imputing is needed. We might want to create a normalized (scaled) dataset:  "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nscaled_data = pd.DataFrame(ss.fit_transform(train_data.values), columns=train_data.columns, index=train_data.index)\nscaled_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next step would be to find out which features contain most information."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\npca = PCA(n_components = len(train_data.columns), whiten = True)\npca.fit(train_data)\nplt.bar(range(len(train_data.columns)), pca.explained_variance_ratio_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, most features contain negligible amount of information. For now, we do not drop any of them, since their number is not too large. The correlation map looks like:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\ng = sns.heatmap(train_data.corr(), cmap = \"coolwarm\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is clear that the features are not correlated too much with each other. Now we test different algorithms on the dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn import tree\nmodel_1 = tree.DecisionTreeClassifier(random_state = 1) #decision tree\nmodel_1.fit(train_data, y)\nfrom sklearn.model_selection import cross_val_score\ncross_val_score(model_1, train_data, y, scoring = 'accuracy', cv = 5).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy achieved is already pretty high. Let us try parameter tuning using GridSearchCV:"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\npars = {\n    'criterion': ['gini', 'entropy'],\n    'max_features': ['auto', 'log2', None],\n    'min_samples_split': [2, 4, 5, 10],\n    'max_depth': [None, 5, 10, 15]\n}\n\ngs = GridSearchCV(estimator = tree.DecisionTreeClassifier(random_state = 1), param_grid = pars, \n                  scoring = 'accuracy', cv = 5)\n\ngs.fit(train_data, y)\n\ngs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"gs.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_1 = gs.best_estimator_\nmodel_1.fit(train_data, y)\ncross_val_score(model_1, train_data, y, scoring = 'accuracy', cv = 5).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is already quite a high accuracy. With the scaled data we get:"},{"metadata":{"trusted":false},"cell_type":"code","source":"model_1_s = gs.best_estimator_\nmodel_1_s.fit(scaled_data, y)\ncross_val_score(model_1_s, scaled_data, y, scoring = 'accuracy', cv = 5).mean()\n\nscores = dict({}) #holds scores of different algorithms\nscores['Decision tree'] = cross_val_score(model_1_s, scaled_data, y, scoring = 'accuracy', cv = 5).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Performing parameter tuning for scaled data:"},{"metadata":{"trusted":false},"cell_type":"code","source":"pars = {\n    'criterion': ['gini', 'entropy'],\n    'max_features': ['auto', 'log2', None],\n    'min_samples_split': [2, 4, 5, 10],\n    'max_depth': [None, 5, 10, 15]\n}\n\ngs = GridSearchCV(estimator = tree.DecisionTreeClassifier(random_state = 1), param_grid = pars, \n                  scoring = 'accuracy', cv = 5)\n\ngs.fit(scaled_data, y)\n\ngs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"gs.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see, there is no difference between accuracy for scaled and original data. From now on, however, we will use scaled data."},{"metadata":{},"cell_type":"markdown","source":"Next, we try random forest (from now on, we use scaled data only):"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel_2 = RandomForestClassifier(random_state = 1)\nmodel_2.fit(scaled_data, y)\ncross_val_score(model_2, scaled_data, y, scoring = 'accuracy', cv = 5).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can clearly see that random forest helps achieve a higher accuracy. Now let us look at how the accuracy is affected by the number of estimators (i.e. trees in the random forest):"},{"metadata":{"trusted":false},"cell_type":"code","source":"from matplotlib.pyplot import plot\naccuracy = []\nfor i in range(30):\n    a = cross_val_score(RandomForestClassifier(random_state = 1, n_estimators = i+1), \n                           scaled_data, y, scoring = 'accuracy', cv = 5).mean()\n    accuracy.append(a)\nplot(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can tune hyperparameters, like we did with the single decision tree:"},{"metadata":{"trusted":false},"cell_type":"code","source":"pars = {\n    'n_estimators': [10, 50, 100, 250],\n    'criterion': ['gini', 'entropy'],\n    'min_samples_split': [2, 4, 5, 10],\n    'max_depth': [None, 5, 10, 15]\n}\n\ngs = GridSearchCV(estimator = RandomForestClassifier(random_state = 1), param_grid = pars, \n                  scoring = 'accuracy', cv = 5)\n\ngs.fit(scaled_data, y)\n\ngs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"gs.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_2 = gs.best_estimator_\nscores['Random forest'] = cross_val_score(model_2, scaled_data, y, scoring = 'accuracy', cv = 5).mean()\nprint(scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that random forest gives a much higher accuracy than a single decision tree. Now let us look at the performance of logistic regression:  "},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel_3 = LogisticRegression(random_state = 1)\nmodel_3.fit(scaled_data, y)\ncross_val_score(model_3, scaled_data, y, scoring = 'accuracy', cv = 5).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clearly, logistic regression performs really well. After doing some parameter tuning, we get:"},{"metadata":{"trusted":false},"cell_type":"code","source":"pars = {\n    'l1_ratio': [0, 0.25, 0.5, 0.75, 1],\n    'max_iter': [50, 100, 250],\n}\n\ngs = GridSearchCV(estimator = LogisticRegression(random_state = 1, penalty = 'elasticnet', solver = 'saga'), param_grid = pars, \n                  scoring = 'accuracy', cv = 5)\n\ngs.fit(scaled_data, y)\n\ngs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"gs.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_3 = gs.best_estimator_\nscores['Logistic regression'] = cross_val_score(model_3, scaled_data, y, scoring = 'accuracy', cv = 5).mean()\nprint(scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic regression performs slightly worse than random forest, but better than a single decision tree."},{"metadata":{},"cell_type":"markdown","source":"Next, we try to implement boosted algorithms. The first one we look at is adaptive boosting:"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nmodel_4 = AdaBoostClassifier(random_state = 1)\nmodel_4.fit(scaled_data, y)\ncross_val_score(model_4, scaled_data, y, scoring = 'accuracy', cv = 5).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is not a satisfactory result - some parameter tuning is needed. "},{"metadata":{"trusted":false},"cell_type":"code","source":"pars = {\n    'n_estimators': [100, 250, 500],\n    'learning_rate': [0.25, 0.5, 0.75, 1.0, 1.5],\n}\n\ngs = GridSearchCV(estimator = AdaBoostClassifier(random_state = 1), param_grid = pars, \n                  scoring = 'accuracy', cv = 5)\n\ngs.fit(scaled_data, y)\n\ngs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"gs.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_4 = gs.best_estimator_\nscores['AdaBoost'] = cross_val_score(model_4, scaled_data, y, scoring = 'accuracy', cv = 5).mean()\nprint(scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"It might be worth looking at how accuracy changes with the number of estimators: "},{"metadata":{"trusted":false},"cell_type":"code","source":"accuracy = []\nfor i in range(50):\n    a = cross_val_score(AdaBoostClassifier(random_state = 1, n_estimators = i+1, learning_rate = 0.5), \n                           scaled_data, y, scoring = 'accuracy', cv = 5).mean()\n    accuracy.append(a)\nplot(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The convergence of the algorithm for this dataset is somewhat slower than the one of random forest. Next, we can take a look at how other boosted algorithms perform. The first one would be gradient boosting classifier:"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nmodel_5 = GradientBoostingClassifier(random_state = 1)\nmodel_5.fit(scaled_data, y)\ncross_val_score(model_5, scaled_data, y, scoring = 'accuracy', cv = 5).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The algorithm performs better than AdaBoost from the start. Tuning parameters gives:"},{"metadata":{"trusted":false},"cell_type":"code","source":"pars = {\n    'n_estimators': [15, 25, 35, 45],\n    'learning_rate': [0.05, 0.1, 0.15, 0.2],\n    'max_depth':[1,2,3]\n}\n\ngs = GridSearchCV(estimator = GradientBoostingClassifier(random_state = 1, warm_start = True), param_grid = pars, \n                  scoring = 'accuracy', cv = 5)\n\ngs.fit(scaled_data, y)\n\ngs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"gs.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_5 = gs.best_estimator_\nscores['GradientBoost'] = cross_val_score(model_5, scaled_data, y, scoring = 'accuracy', cv = 5).mean()\nprint(scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is slightly worse than AdaBoost. Convergence of accuracy can be seen in the figure below:"},{"metadata":{"trusted":false},"cell_type":"code","source":"accuracy = []\nfor i in range(50):\n    a = cross_val_score(GradientBoostingClassifier(random_state = 1, n_estimators = i+1, learning_rate = 0.15, max_depth = 1), \n                           scaled_data, y, scoring = 'accuracy', cv = 5).mean()\n    accuracy.append(a)\nplot(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The convergence is faster than for AdaBoost, and somewhat smoother as well. Note that for both algorithms, the other parameters were same as for the best estimator found by grid search. Finally, let us have a look at extreme gradient boosting:"},{"metadata":{"trusted":false},"cell_type":"code","source":"from xgboost import XGBClassifier\nmodel_6 = XGBClassifier(random_state = 1)\nmodel_6.fit(scaled_data, y)\ncross_val_score(model_6, scaled_data, y, scoring = 'accuracy', cv = 5).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Performing parameter tuning:"},{"metadata":{"trusted":false},"cell_type":"code","source":"pars = {\n    #'lambda': [0, 0.5, 1],\n    'learning_rate':[0.05, 0.1, 0.15, 0.2, 0.3],\n    'max_depth':[6, 8, 10],\n    'min_child_weight':[0.25, 0.5, 0.75, 1],\n    'n_estimators':[100, 250, 500]\n}\n\n#best results - learning_rate = 0.05, max_depth = 6, min_child_weight = 0.75, n_estimators = 250\n\n#gs = GridSearchCV(estimator = XGBClassifier(random_state = 1), param_grid = pars, \n#                  scoring = 'accuracy', cv = 5)\n\n#gs.fit(scaled_data, y)\n\n#gs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_6 = XGBClassifier(learning_rate = 0.05, max_depth = 6, min_child_weight = 0.75, n_estimators = 250)\nmodel_6.fit(scaled_data, y)\nscores['XGBoost'] = cross_val_score(model_6, scaled_data, y, scoring = 'accuracy', cv = 5).mean()\nprint(scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The result is better than for other boosting algorithms, but still worse than for logistic regression and random forest. The convergence of accuracy against number of estimators looks like:"},{"metadata":{"trusted":false},"cell_type":"code","source":"accuracy = []\nfor i in range(50):\n    a = cross_val_score(XGBClassifier(random_state = 1, n_estimators = i+1, learning_rate = 0.05, max_depth = 6, min_child_weight = 0.75), \n                           scaled_data, y, scoring = 'accuracy', cv = 5).mean()\n    accuracy.append(a)\nplot(accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although accuracy is higher than for both of the previous boosting algorithms, convergence is noticeably slower. The two algorithms we have not tried yet are SVM and Naive Bayes. First, we look at SVM:"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.svm import SVC\nmodel_7 = SVC() \nmodel_7.fit(scaled_data, y)\ncross_val_score(model_7, scaled_data, y, scoring = 'accuracy', cv = 5).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy achieved is really high even without parameter tuning. After parameter tuning we get:"},{"metadata":{"trusted":false},"cell_type":"code","source":"pars = {\n    'kernel':['linear', 'rbf', 'poly', 'sigmoid'],\n    'C':[0.1, 0.2, 0.4, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0]\n}\n\ngs = GridSearchCV(estimator = SVC(), param_grid = pars, \n                  scoring = 'accuracy', cv = 5)\n\ngs.fit(scaled_data, y)\n\ngs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"gs.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_7 = gs.best_estimator_\nmodel_7.fit(scaled_data, y)\nscores['SVC'] = cross_val_score(model_7, scaled_data, y, scoring = 'accuracy', cv = 5).mean()\nprint(scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The cross-validation score of 1.0 is achieved, meaning that the data is well-separated enough for SVM to classify every hand-written digit correctly. Moving on to Bernoulli Naive Bayes:"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.naive_bayes import BernoulliNB\nmodel_8 = BernoulliNB(binarize=0.0)\nmodel_8.fit(scaled_data, y)\ncross_val_score(model_8, scaled_data, y, scoring = 'accuracy', cv = 5).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The score is rather good as well. The most important parameter is smoothing, which we can tune:"},{"metadata":{"trusted":false},"cell_type":"code","source":"pars = {\n    'alpha':[0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2]\n}\n\ngs = GridSearchCV(estimator = BernoulliNB(), param_grid = pars, \n                  scoring = 'accuracy', cv = 5)\n\ngs.fit(scaled_data, y)\n\ngs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"gs.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_8 = gs.best_estimator_\nmodel_8.fit(scaled_data, y)\nscores['BernoulliNB'] = cross_val_score(model_8, scaled_data, y, scoring = 'accuracy', cv = 5).mean()\nprint(scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The score is very high. Trying Gaussian Naive Bayes:"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nmodel_9 = GaussianNB()\nmodel_9.fit(scaled_data, y)\nscores['GaussianNB'] = cross_val_score(model_9, scaled_data, y, scoring = 'accuracy', cv = 5).mean()\nprint(scores)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}