{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\n\ntrain_df=pd.read_csv(\"/kaggle/input/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv\")\ntest_df=pd.read_csv(\"/kaggle/input/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_full=train_df\nX_train_full.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_full=X_train_full.iloc[:,0]\nX_train_full=X_train_full.iloc[:,1:]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_full.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_full.value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training data misses label \"9\" in the sign language.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_full.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since both training and testing data misses the label \"9\",there will be no problem.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"When splitting the training data and validation data,all distinct labels should be considered.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_valid,X_train=X_train_full.iloc[:5491,:]/255,X_train_full.iloc[5491:,:]/255\ny_valid,y_train=y_train_full.iloc[:5491],y_train_full.iloc[5491:]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(y_valid.value_counts()/len(y_valid)).sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(y_train.value_counts()/len(y_train)).sort_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A descent sampling to generate training and validation set.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**All data are converted into numpy arrays for ease of visualization of the sign language picture plots.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_valid=y_valid.to_numpy()\ny_train=y_train.to_numpy()\n\nX_train=X_train.to_numpy()\nX_valid=X_valid.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.imshow(X_train[0].reshape(28,28),interpolation=\"gaussian\")\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train[0] # The above figure is a 7 in sign language.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us plot to see all the different sign languages.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def index_sign_labels(target):\n    labels_index=[None]*25   # to store index of individual labels\n    for i in range(len(target)):\n        labels_index[target[i]]=i\n    return labels_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx=index_sign_labels(y_train)\n\nn_rows=5\nn_columns=5\n\ni=0\nplt.figure(figsize=(15,12))\nfor rows in range(n_rows):\n    for columns in range(n_columns):\n        if i!=9:\n            index=n_columns*rows+columns\n            plt.subplot(n_rows,n_columns,index+1)\n            plt.imshow(X_train[idx[i]].reshape(28,28),interpolation=\"gaussian\")\n            plt.axis(\"off\")\n            plt.title(i)\n        i+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Early stopping with patience limit 10 epochs for capturing the best weights.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping_cb=keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n\nmodel=keras.models.Sequential([keras.layers.Dense(128,activation='relu',input_shape=[784]),\n                               keras.layers.Dense(100,activation='relu'),\n                               keras.layers.Dense(100,activation='relu'),\n                               keras.layers.Dense(100,activation='relu'),\n                               keras.layers.Dense(25,activation='softmax')])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(X_train,y_train,epochs=150,validation_data=(X_valid,y_valid),callbacks=[early_stopping_cb])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(history.history).plot(figsize=(12,8))\nplt.grid(True)\nplt.ylim(0,1.2)\nplt.xlabel(\"Epochs\",fontsize=14)\nplt.ylabel(\"Loss / Accuracy\",fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_full=test_df\n\nX_test=X_test_full.iloc[:,1:]/255\ny_test=X_test_full.iloc[:,0]\n\nX_test=X_test.to_numpy()\ny_test=y_test.to_numpy()\n\nmodel.evaluate(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy is not as high as expected.Let us see pick first 10 samples of test set and see the accuracy on them.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**The output of the neural network contains softmax activation function.It produces probablities of all the class.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"size=len(y_test)\nn_class=24\n\nX_new=X_test[-10:,:]\noutput_probs=model.predict(X_new)\ny_pred=[]\n\nfor i in range(10):\n    m=output_probs[i][0]\n    x=0\n    for j in range(1,n_class):\n        if output_probs[i][j]>m:\n            m=output_probs[i][j]\n            x=j\n    y_pred.append(x)\n\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test[-10:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4 out of last 10 instances in the test set are incorrectly classified.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=np.array(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc=sum(y_pred==y_test)/len(y_test)\nacc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inspite of having good validation accuracy,the model does not perform exceptionally in the test set.Let us see the figures in the test set,to check if they are different from training instances. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let us plot the test set figures.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"idx=index_sign_labels(y_test)\n\nn_rows=5\nn_columns=5\n\ni=0\nplt.figure(figsize=(15,12))\nfor rows in range(n_rows):\n    for columns in range(n_columns):\n        if i!=9:\n            index=n_columns*rows+columns\n            plt.subplot(n_rows,n_columns,index+1)\n            plt.imshow(X_train[idx[i]].reshape(28,28),interpolation=\"gaussian\")\n            plt.axis(\"off\")\n            plt.title(i)\n        i+=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****It is clearly evident that the training and testing instances do not match exactly for many target values.Hence is the failure of the model in test set inspite of having excellent validation accuracies inside the training set.****","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"****If you like my notebook,please upvote and also comment for further improvements.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}