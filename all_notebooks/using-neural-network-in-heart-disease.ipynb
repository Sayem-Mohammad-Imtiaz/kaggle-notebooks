{"cells":[{"metadata":{},"cell_type":"markdown","source":"Steps:\n\nImport Data\n\nExploratory Data Analysis\n\nData Preparation + Feature Enginnering\n\nSplit data in train and test\n\nFeature importance using decision tree\n\nTry Logistic Regresion\n\nTry Neural Network","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Import Data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport xgboost as xgb\nimport sklearn\nfrom sklearn.model_selection import cross_val_score,GridSearchCV\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder\nfrom sklearn.tree import DecisionTreeClassifier,export_graphviz\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression,Perceptron,SGDClassifier\nfrom sklearn.metrics import f1_score,accuracy_score,recall_score,classification_report,make_scorer,roc_curve, auc\nfrom sklearn.model_selection import train_test_split\nfrom category_encoders.one_hot import OneHotEncoder\nimport keras\n\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/heart-disease-uci/heart.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_features = ['age','trestbps','thalach','oldpeak','chol']\ncategorical_features = ['sex','cp','fbs','restecg','exang','slope','ca','thal']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[numeric_features].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting distribution of numeric features","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"numerics = df[numeric_features]\nfig, ax = plt.subplots(5,1,figsize=(22, 30))\nfor i, col in enumerate(numerics):\n    plt.subplot(5,1,i+1)\n    plt.xlabel(col, fontsize=10)\n    sns.distplot(numerics[col].values)\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation between numeric features","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"corr = numerics.corr()\nsns.heatmap(corr,annot=True,fmt='.3f',linewidths=2)\nplt.title('Correlation Matrix')\nplt.gcf().set_size_inches(11,7)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting the frequency of categorical features","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"categorical = df[categorical_features]\nfig, axes = plt.subplots(round(len(categorical.columns) / 4), 3, figsize=(22, 10))\n\nfor i, ax in enumerate(fig.axes):\n    if i < len(categorical.columns):\n        sns.countplot(x=categorical.columns[i], data=categorical, ax=ax)\n\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting the frequency and distribution of age by target","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"pd.crosstab(df.age,df.target).plot(kind=\"bar\",figsize=(18,5))\nplt.title('Heart Disease Frequency for Ages')\nplt.xlabel('Age')\nplt.ylabel('N')\nplt.show()\n\nplt.subplots(figsize=(18, 5))\nplt.title('Heart Disease Distribution for Ages')\nsns.distplot(df[df['target'] == 1]['age'], label=\"Target = 1 \")\nsns.distplot(df[df['target'] == 0]['age'], label=\"Target = 0 \")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style=\"ticks\")\nsns.pairplot(df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation + Feature Enginnering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.mode.chained_assignment = None  # default='warn'\n\nscaler = sklearn.preprocessing.StandardScaler().fit(df[numeric_features])\ndf[numeric_features]= scaler.transform(df[numeric_features])\n\ndf['sex'][df['sex'] == 0] = 'female'\ndf['sex'][df['sex'] == 1] = 'male'\n\ndf['cp'][df['cp'] == 1] = 'typical angina'\ndf['cp'][df['cp'] == 2] = 'atypical angina'\ndf['cp'][df['cp'] == 3] = 'non-anginal pain'\ndf['cp'][df['cp'] == 4] = 'asymptomatic'\n\ndf['fbs'][df['fbs'] == 0] = 'lower than 120mg/ml'\ndf['fbs'][df['fbs'] == 1] = 'greater than 120mg/ml'\n\ndf['restecg'][df['restecg'] == 0] = 'normal'\ndf['restecg'][df['restecg'] == 1] = 'ST-T wave abnormality'\ndf['restecg'][df['restecg'] == 2] = 'left ventricular hypertrophy'\n\ndf['exang'][df['exang'] == 0] = 'no'\ndf['exang'][df['exang'] == 1] = 'yes'\n\ndf['slope'][df['slope'] == 1] = 'upsloping'\ndf['slope'][df['slope'] == 2] = 'flat'\ndf['slope'][df['slope'] == 3] = 'downsloping'\n\ndf['thal'][df['thal'] == 1] = 'normal'\ndf['thal'][df['thal'] == 2] = 'fixed defect'\ndf['thal'][df['thal'] == 3] = 'reversable defect'\n\ndf = pd.get_dummies(df, drop_first=True)\ndf_eda = df.copy()\n\ndummies = OneHotEncoder(cols= 'ca',use_cat_names=True)\ndummies.fit(df)\ndf = dummies.transform(df)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split in train and test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split data in train and test\ny = df[['target']]\nx = df.drop(['target'],axis = 1)\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Importance using decision tree","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import os\nfrom IPython.display import SVG\nfrom graphviz import Source\nimport itertools\n\ntree = DecisionTreeClassifier(max_depth=3)\ntree.fit(x,y)\ngraph = Source(export_graphviz(tree\n                               , feature_names=x.columns\n                               , filled = True))\ndisplay(SVG(graph.pipe(format='svg')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting the frenquency of thal fixed in target","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"pd.crosstab(df['thal_fixed defect'],df.target).plot(kind=\"bar\",figsize=(18,5))\nplt.title('Thal Fixed defect x Target')\nplt.xlabel('thal_fixed defect')\nplt.ylabel('N')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting the frenquency of ca in target","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"pd.crosstab(df_eda['ca'],df_eda.target).plot(kind=\"bar\",figsize=(18,5))\nplt.title('Ca x Target')\nplt.xlabel('ca')\nplt.ylabel('N')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 1) Try logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(class_weight = 'balanced', solver = 'liblinear',penalty=\"l2\")\nlr.fit(x_train,y_train)\n\ny_prob = lr.predict_proba(x_test)[:,1] # This will give you positive class prediction probabilities  \ny_pred = np.where(y_prob > 0.5, 1, 0) # This will threshold the probabilities to give class predictions.\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nplt.figure(figsize=(10,8))\nplt.plot(false_positive_rate,true_positive_rate, color='red',label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],linestyle='--')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\n\nprint(\"acc:\",accuracy_score(y_test,y_pred))\nprint(\"recall:\",recall_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2) Try Neural Network","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transform the data in float and print the number of features\nx_train = x_train.astype(float) \nx_test = x_test.astype(float) \n\n\ny_train = to_categorical(y_train,2) \ny_test =  to_categorical(y_test,2) \n\nx_train.shape, x_test.shape, y_train.shape , y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Starting Neural network\nmodel = Sequential()\n\n\n#First hidden\nmodel.add(Dense(5 #number of neurals in the first hidden\n                ,activation = 'relu' \n                ,input_shape = (23,) #Number of features that my model will receive\n                ))\n\n\n\n#out hidden\nmodel.add(Dense(2 #number of class\n                ,activation = 'softmax' #its will show me the probrably in the each class\n                ))\n\n\n#summary the model\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Compile the first Neural Network\nmodel.compile(\n                loss='categorical_crossentropy' \n               ,optimizer='adam' \n               ,metrics=['accuracy'] \n)\n\nhistory = model.fit(x_train,y_train\n         ,epochs=100\n         ,batch_size =32\n         ,verbose = 1\n         ,validation_data=(x_test,y_test)\n         )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predict the x_test\np = model.predict(x_test)\np = (p > 0.5)\nprint('ACC: %.3f%%' % (accuracy_score(y_test, p)*100))\nprint('---------')\nprint(classification_report(y_test, p))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting Model Accurancy","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(13, 8))\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting Model Loss","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(13, 8))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}