{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://i.ytimg.com/vi/ZqjDy8QJGp8/maxresdefault.jpg)youtube.com"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nRowsRead = 1000 # specify 'None' if want to read whole file\ndf = pd.read_csv('../input/cusersmarildownloadsweeklycsv/weekly.csv', delimiter=';', encoding = \"utf8\", nrows = nRowsRead)\ndf.dataframeName = 'weekly.csv'\nnRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Codes by Sufyan Cunningham  https://www.kaggle.com/sufyancunningham/white-whine-quality-sgd-scratch"},{"metadata":{"trusted":true},"cell_type":"code","source":"from random import seed\nfrom random import randrange\nfrom csv import reader\nfrom math import sqrt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n#fill in mean for floats\nfor c in df.columns:\n    if df[c].dtype=='float16' or  df[c].dtype=='float32' or  df[c].dtype=='float64':\n        df[c].fillna(df[c].mean())\n\n#fill in -999 for categoricals\ndf = df.fillna(-999)\n# Label Encoding\nfor f in df.columns:\n    if df[f].dtype=='object': \n        lbl = LabelEncoder()\n        lbl.fit(list(df[f].values))\n        df[f] = lbl.transform(list(df[f].values))\n        \nprint('Labelling done.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.get_dummies(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_hot_encoded_training_predictors = pd.get_dummies(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load a CSV file\ndef load_csv(filename):\n\tdataset = list()\n\twith open(filename, 'r') as file:\n\t\tcsv_reader = reader(file)\n\t\theadings = next(csv_reader) \n\t\tfor row in csv_reader:\n\t\t\tif not row:\n\t\t\t\tcontinue\n\t\t\tdataset.append(row)\n\treturn dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert string column to float\ndef str_column_to_float(dataset, column):\n\tfor row in dataset:\n\t\trow[column] = float(row[column].strip())\n\n# Find the min and max values for each column\ndef dataset_minmax(dataset):\n\tminmax = list()\n\tfor i in range(len(dataset[0])):\n\t\tcol_values = [row[i] for row in dataset]\n\t\tvalue_min = min(col_values)\n\t\tvalue_max = max(col_values)\n\t\tminmax.append([value_min, value_max])\n\treturn minmax\n\n# Rescale dataset columns to the range 0-1\ndef normalize_dataset(dataset, minmax):\n\tfor row in dataset:\n\t\tfor i in range(len(row)):\n\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split a dataset into k folds\ndef cross_validation_split(dataset, n_folds):\n\tdataset_split = list()\n\tdataset_copy = list(dataset)\n\tfold_size = int(len(dataset) / n_folds)\n\tfor i in range(n_folds):\n\t\tfold = list()\n\t\twhile len(fold) < fold_size:\n\t\t\tindex = randrange(len(dataset_copy))\n\t\t\tfold.append(dataset_copy.pop(index))\n\t\tdataset_split.append(fold)\n\treturn dataset_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate root mean squared error\ndef rmse_metric(actual, predicted):\n\tsum_error = 0.0\n\tfor i in range(len(actual)):\n\t\tprediction_error = predicted[i] - actual[i]\n\t\tsum_error += (prediction_error ** 2)\n\tmean_error = sum_error / float(len(actual))\n\treturn sqrt(mean_error)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate an algorithm using a cross validation split\ndef evaluate_algorithm(dataset, algorithm, n_folds, *args):\n\tfolds = cross_validation_split(dataset, n_folds)\n\tscores = list()\n\tfor fold in folds:\n\t\ttrain_set = list(folds)\n\t\ttrain_set.remove(fold)\n\t\ttrain_set = sum(train_set, [])\n\t\ttest_set = list()\n\t\tfor row in fold:\n\t\t\trow_copy = list(row)\n\t\t\ttest_set.append(row_copy)\n\t\t\trow_copy[-1] = None\n\t\tpredicted = algorithm(train_set, test_set, *args)\n\t\tactual = [row[-1] for row in fold]\n\t\trmse = rmse_metric(actual, predicted)\n\t\tscores.append(rmse)\n\treturn scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a prediction with coefficients\ndef predict(row, coefficients):\n\tyhat = coefficients[0]\n\tfor i in range(len(row)-1):\n\t\tyhat += coefficients[i + 1] * row[i]\n\treturn yhat\n\n# Estimate linear regression coefficients using stochastic gradient descent\ndef coefficients_sgd(train, l_rate, n_epoch):\n\tcoef = [0.0 for i in range(len(train[0]))]\n\tfor epoch in range(n_epoch):\n\t\tfor row in train:\n\t\t\tyhat = predict(row, coef)\n\t\t\terror = yhat - row[-1]\n\t\t\tcoef[0] = coef[0] - l_rate * error\n\t\t\tfor i in range(len(row)-1):\n\t\t\t\tcoef[i + 1] = coef[i + 1] - l_rate * error * row[i]\n\t\t\t# print(l_rate, n_epoch, error)\n\treturn coef\n\n# Linear Regression Algorithm With Stochastic Gradient Descent\ndef linear_regression_sgd(train, test, l_rate, n_epoch):\n\tpredictions = list()\n\tcoef = coefficients_sgd(train, l_rate, n_epoch)\n\tfor row in test:\n\t\tyhat = predict(row, coef)\n\t\tpredictions.append(yhat)\n\treturn(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Snippet by Joseph Chan https://www.kaggle.com/josephchan524/housepricesregressor-using-lightgbm\n\n#Label Encoding\n#%% MultiColumnLabelEncoder\n# Code snipet found on Stack Exchange \n# https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn\nfrom sklearn.preprocessing import LabelEncoder\n\n\nclass MultiColumnLabelEncoder:\n    def __init__(self,columns = None):\n        self.columns = columns # array of column names to encode\n\n    def fit(self,X,y=None):\n        return self # not relevant here\n\n    def transform(self,X):\n        '''\n        Transforms columns of X specified in self.columns using\n        LabelEncoder(). If no columns specified, transforms all\n        columns in X.\n        '''\n        output = X.copy()\n        if self.columns is not None:\n            for col in self.columns:\n                # convert float NaN --> string NaN\n                output[col] = output[col].fillna('NaN')\n                output[col] = LabelEncoder().fit_transform(output[col])\n        else:\n            for colname,col in output.iteritems():\n                output[colname] = LabelEncoder().fit_transform(col)\n        return output\n\n    def fit_transform(self,X,y=None):\n        return self.fit(X,y).transform(X)\n\n# store the catagorical features names as a list      \ncat_features = df.select_dtypes(['object']).columns.to_list()\n\n# use MultiColumnLabelEncoder to apply LabelEncoding on cat_features \n# uses NaN as a value , no imputation will be used for missing data\ndf_encoded = MultiColumnLabelEncoder(columns = cat_features).fit_transform(df)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Linear Regression \nseed(1)\n# load and prepare data\nfilename = '../input/cusersmarildownloadsweeklycsv/weekly.csv'\ndataset = load_csv(filename)\nfor i in range(len(dataset[0])):\n\tstr_column_to_float(dataset, i)\n# normalize\nminmax = dataset_minmax(dataset)\nnormalize_dataset(dataset, minmax)\n# evaluate algorithm\nn_folds = 5\nl_rate = 0.01\nn_epoch = 50\nscores = evaluate_algorithm(dataset, linear_regression_sgd, n_folds, l_rate, n_epoch)\nprint('Scores: %s' % scores)\nprint('Mean RMSE: %.3f' % (sum(scores)/float(len(scores))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#I tried to encode. Though it didn't work."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}