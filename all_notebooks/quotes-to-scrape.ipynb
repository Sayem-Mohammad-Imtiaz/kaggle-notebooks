{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import requests                 # Simpler HTTP requests \nfrom bs4 import BeautifulSoup   # Python package for pulling data out of HTML and XML files\nimport pandas as pd             # Python package for data manipulation and analysis\nimport re                       # regular expressions\n\nQuote=[]\nAuthor=[]\n\nfor i in range(1,11):\n    url = 'https://quotes.toscrape.com/page/{}/'.format(i)  #Can be further extrapolated for mutiple pages \n    #print(url)\n    url_text = requests.get(url).text                    # Get the session text for the link\n    url_soup = BeautifulSoup(url_text, 'html.parser')   # Get data from the HTML\n\n    Quote.append(url_soup.find_all(\"span\",attrs={\"itemprop\" : \"text\"}))\n    Author.append(url_soup.find_all(\"small\",attrs={\"itemprop\" : \"author\"}))\n\ndataframe_columns = [ 'Author', 'Quote']\ndataframe = pd.DataFrame(columns=dataframe_columns)\n\nQuote = [item for sublist in Quote for item in sublist]\nAuthor= [item for sublist in Author for item in sublist]\n\nfor f, b, j in zip(Author, Quote,range(0,len(Author))):\n    dataframe.at[j,'Author'] = f.text.strip()\n    dataframe.at[j,'Quote'] = b.text.strip()\n\ndataframe.to_csv('Quotes to Scrape.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}