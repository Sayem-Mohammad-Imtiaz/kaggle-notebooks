{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install rouge","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glob('../input/pl-articles-split/pl_spacy_model-0.1.0/*')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python -m pip install ../input/pl-articles-split/pl_spacy_model-0.1.0/pl_spacy_model-0.1.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nimport random\nimport re\nimport spacy\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.nn.utils import clip_grad_norm_\n\nfrom glob import glob\nfrom spacy.symbols import LEMMA, ORTH, POS\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import notebook, tqdm_notebook\nfrom torchtext.data import Field, BucketIterator, TabularDataset\n\nfrom rouge import Rouge","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"glob('../input/*/*')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load('en', disable=['ner', 'parser'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"special_tokens = ['<num>']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"special_case = [{POS: 'NOUN', ORTH: '<num>', LEMMA: '<num>'}]\nnlp.tokenizer.add_special_case(\"<num>\", special_case)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenize_pl(text):\n    text = re.sub(r\"(\\„|\\”|\\“|\\‟|\\‶|\\‚|\\’|\\‘|\\‛|\\⁏|\\;|\\-|\\—|\\―|\\–|\\⁋|\\‰|\\\\|\\%|\\^|\\&|\\*|\\$|\\#|\\@|\\!)\", '', str(text))\n    text = re.sub(\"\\.\\.+\", ' ', str(text))\n#     text = re.sub(\"\\.\", ' .', str(text))\n    text = re.sub(r\"(\\/)\", ' ', str(text))\n    text = re.sub(\"[0-9]+\", \" <num> \", str(text)) # hide numbers\n#     text = re.sub(\"[0-9]+\", ' ', str(text))\n    return [tok.text for tok in nlp.tokenizer(re.sub(\"\\s+\", ' ', str(text)))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_dataset(batch_size, special_tokens=None):\n\n    TEXT = Field(tokenize=tokenize_pl, include_lengths=True, tokenizer_language='pl',\n                init_token='<sos>', eos_token='<eos>')\n    SUMMARY = Field(tokenize=tokenize_pl, include_lengths=True, tokenizer_language='pl',\n                    init_token='<sos>', eos_token='<eos>')\n    train, val, test = TabularDataset.splits(\n        skip_header=True, \n        path='../input/pl-articles-split/', format='csv', \n        fields=[('index', None), ('lead', SUMMARY), ('text', TEXT)],\n        train='train.csv', validation='val.csv', test='test.csv'\n    )\n    TEXT.build_vocab(train, specials=special_tokens, min_freq=10)\n#     SUMMARY.build_vocab(train, min_freq=2)\n    SUMMARY.vocab = TEXT.vocab\n    train_iter, val_iter, test_iter = BucketIterator.splits(\n        (train, val, test), batch_size=batch_size, repeat=False, sort_key=lambda x: len(x.text), sort_within_batch=False\n    )\n    return train_iter, val_iter, test_iter, TEXT, SUMMARY, (train, val, test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 16","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_iter, val_iter, test_iter, TEXT, SUMMARY, _ = load_dataset(batch_size, special_tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def indices_from_text(text, lang=TEXT):\n    indices = []\n    for word in text.strip().split(' '):\n        indices.append(lang.vocab.stoi[word])\n    return torch.LongTensor(indices).cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def text_from_indices(indices, lang=TEXT):\n    text = \"\"\n    for element in indices:\n        if type(element) is torch.Tensor:\n            text += lang.vocab.itos[element.item()] + \" \"\n        else:\n            text += lang.vocab.itos[element] + \" \"\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(TEXT.vocab.stoi)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch = next(iter(train_iter))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Random text"},{"metadata":{"trusted":true},"cell_type":"code","source":"text_from_indices(batch.text[0].transpose(0, 1)[-1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Random summary"},{"metadata":{"trusted":true},"cell_type":"code","source":"text_from_indices(batch.lead[0].transpose(0, 1)[-1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Seq2Seq model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, n_layers=1, dropout=0.1):\n        super(EncoderRNN, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.embedding_size = embedding_size\n        self.embedding = nn.Embedding(input_size, embedding_size).cuda()\n        self.gru = nn.GRU(embedding_size, hidden_size, n_layers,\n                          dropout=dropout, bidirectional=True).cuda()\n\n    def forward(self, sequence, hidden=None):\n        embedding_output = self.embedding(sequence) # max_text_len x batch_size x embedding_size\n        encoder_outputs, hidden = self.gru(embedding_output, hidden)\n        # hidden: bidirectional x batch_size x hidden_size\n        # output: max_text_len x batch_size x bidirectional * hidden_size\n        encoder_outputs = encoder_outputs[:, :, :self.hidden_size] + encoder_outputs[:, :, self.hidden_size:]\n        # output: max_text_len x batch_size x hidden_size\n        encoder_outputs = encoder_outputs\n        return encoder_outputs, hidden","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BahdanauAttention(nn.Module):\n    def __init__(self, hidden_size):\n        super(BahdanauAttention, self).__init__()\n        self.hidden_size = hidden_size\n        self.attention = nn.Linear(hidden_size * 2, hidden_size).cuda()\n        self.v = nn.Parameter(torch.rand(hidden_size)).cuda()\n        stdv = 1. / math.sqrt(self.v.size(0))\n        self.v.data.uniform_(-stdv, stdv)\n\n    def forward(self, hidden, encoder_outputs):\n        timestep = encoder_outputs.size(0)\n        h = hidden.repeat(timestep, 1, 1).transpose(0, 1)\n        encoder_outputs = encoder_outputs.transpose(0, 1) \n        attn_energies = self.score(h, encoder_outputs) # batch_size x t x hidden\n        return F.softmax(attn_energies, dim=1).unsqueeze(1) # batch_size x t\n\n    def score(self, hidden, encoder_outputs):\n        # batch_size x t x 2*hidden -> batch_size x t x hidden\n        energy = torch.tanh(self.attention(torch.cat([hidden, encoder_outputs], 2)))\n        energy = energy.transpose(1, 2) # batch_size x t x 2*hidden -> batch_size x t x hidden\n        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1) # batch_size x 1 x hidden\n        energy = torch.bmm(v, energy) # batch_size x 1 x t\n        return energy.squeeze(1) # batch_size x t","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DecoderRNN(nn.Module):\n    def __init__(self, embedding_size, hidden_size, output_size, n_layers=1, dropout=0.1):\n        super(DecoderRNN, self).__init__()\n        self.embedding_size = embedding_size\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.dropout = dropout\n\n        self.embedding = nn.Embedding(output_size, embedding_size).cuda()\n        self.dropout = nn.Dropout(dropout, inplace=True).cuda()\n        self.attention = BahdanauAttention(hidden_size).cuda()\n        self.gru = nn.GRU(hidden_size + embedding_size, hidden_size, n_layers, dropout=dropout).cuda()\n        self.output = nn.Linear(hidden_size * 2, output_size).cuda()\n\n    def forward(self, sequence, hidden, encoder_outputs):\n        # Get the embedding of the current input word (last output word)\n        embedding_output = self.embedding(sequence).unsqueeze(0)  # 1 x batch_size x n\n        embedding_output = self.dropout(embedding_output)\n        # Calculate attention weights and apply to encoder outputs\n        attention_weights = self.attention(hidden[-1], encoder_outputs)\n        context = attention_weights.bmm(encoder_outputs.transpose(0, 1)) # batch_size x 1 x n\n        context = context.transpose(0, 1)  # (1,B,N)\n        # Combine embedded input word and attended context, run through RNN\n        decoder_input = torch.cat([embedding_output, context], 2)\n        decoder_output, hidden = self.gru(decoder_input, hidden)\n        decoder_output = decoder_output.squeeze(0)  # (1,B,N) -> (B,N)\n        context = context.squeeze(0)\n        decoder_output = self.output(torch.cat([decoder_output, context], 1))\n        decoder_output = F.log_softmax(decoder_output, dim=1)\n        return decoder_output, hidden, attention_weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, text, summary, teacher_forcing_ratio=0.5):\n        batch_size = text.size(1)\n        max_len = summary.size(0)\n        vocab_size = self.decoder.output_size\n\n        encoder_output, hidden = self.encoder(text)\n        hidden = hidden[:self.decoder.n_layers]\n        output = summary.data[0, :]  # sos\n        \n        outputs = torch.cuda.FloatTensor(max_len, batch_size, vocab_size).fill_(0)\n        for t in range(1, max_len):\n            output, hidden, attention_weights = self.decoder(\n                    output, hidden, encoder_output)\n            outputs[t] = output\n            is_teacher = random.random() < teacher_forcing_ratio\n            top_first = output.data.max(1)[1]\n            output = summary.data[t] if is_teacher else top_first\n        return outputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rouge = Rouge()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(e, model, optimizer, scheduler, train_iter, vocab_size, grad_clip, lang=TEXT):\n    model.train()\n    total_loss = 0\n    pad = lang.vocab.stoi['<pad>']\n#     train_iter = train_iter.cuda()\n    for b, batch in notebook.tqdm(enumerate(train_iter), total=len(train_iter)):\n        text, len_text = batch.text\n        summary, len_summary = batch.lead\n        text, summary = text.cuda(), summary.cuda()\n        optimizer.zero_grad()\n        output = model(text, summary)\n        loss = F.nll_loss(\n            output[1:].view(-1, vocab_size),\n            summary[1:].contiguous().view(-1),\n            ignore_index=pad,\n        )\n        loss.backward()\n        clip_grad_norm_(model.parameters(), grad_clip)\n        optimizer.step()\n        scheduler.step()\n        total_loss += loss.data\n        \n        del output\n        del loss\n        \n        if b % 10 == 0 and b != 0:\n            total_loss = total_loss / 100\n            print(f'[{b} / {len(train_iter)}]  [loss: {total_loss}]')\n            total_loss = 0\n            torch.cuda.empty_cache()\n        if b % 400 == 0 and b != 0:\n            original_text = text_from_indices(text.transpose(0, 1)[0])\n            target_summary = text_from_indices(summary.transpose(0, 1)[0])\n            output_summary, attentions = summarize(text_from_indices(text.transpose(0, 1)[0]))\n            print('Original :', original_text)\n            print('-' * 80)\n            print('Target :', target_summary)\n            print('-' * 80)\n            print('Summary :', output_summary)\n            print('=' * 80)\n            scores = calculate_rouge(hypothesis=output_summary, reference=target_summary)\n            if scores:\n                for key, value in scores[0].items():\n                    print(f'{key.upper()} [precision] : {np.round(value[\"p\"] * 100, 2)} '\n                          f'| [recall] : {np.round(value[\"r\"] * 100, 2)} '\n                          f'| [f-score] : {np.round(value[\"f\"] * 100, 2)}')\n                draw_attention_matrix(attention=attentions, original=original_text, summary=output_summary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, val_iter, vocab_size, lang=TEXT):\n#     val_iter = val_iter.cuda()\n    with torch.no_grad():\n        pad = lang.vocab.stoi['<pad>']\n        total_loss = 0\n        for b, batch in enumerate(val_iter):\n            text, len_text = batch.text\n            summary, len_summary = batch.lead\n#             text = text.data\n#             summary = summary.data\n            text = text.data.cuda()\n            summary = summary.data.cuda()\n            output = model(text, summary, teacher_forcing_ratio=0.0)\n            loss = F.nll_loss(\n                output[1:].view(-1, vocab_size),\n                summary[1:].contiguous().view(-1),\n                ignore_index=pad,\n            )\n            total_loss += loss.data\n        return total_loss / len(val_iter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_rouge(hypothesis, reference):\n    hypothesis = hypothesis.split('<sos>')[1].split('<eos>')[0].strip()\n    reference = reference.split('<sos>')[1].split('<eos>')[0].strip()\n    if len(hypothesis) > 0:\n        scores = rouge.get_scores(hypothesis, reference)\n        return scores\n    return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_attention_matrix(attention, original, summary):\n    labels_original = original.split('<sos>')[1].split('<eos>')[0].strip().split()\n    labels_summary = summary.split('<sos>')[1].split('<eos>')[0].strip().split()\n    plt.figure(figsize=(20, 10))\n    plt.imshow(attention.numpy()[:len(labels_summary), 1:len(labels_original)])\n    plt.xticks([i for i in range(len(labels_original)-1)], labels_original, rotation=75)\n    plt.yticks([i for i in range(len(labels_summary))], labels_summary)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def summarize(text):\n    with torch.no_grad():\n        sequence = indices_from_text(text).unsqueeze(0)\n        sequence_length = sequence.size(1)\n        encoder_outputs, encoder_hidden = encoder(sequence.transpose(0, 1))\n        \n        decoder_input = torch.cuda.LongTensor([indices_from_text(TEXT.init_token)])\n        hidden = encoder_hidden[:decoder.n_layers]\n        summary_words = ['<sos>']\n        max_summary_length = int(sequence_length * 0.25)\n        decoder_attentions = torch.zeros(max_summary_length, sequence_length)\n        \n        for idx in range(max_summary_length):\n            output, hidden, decoder_attention = decoder(\n                decoder_input, \n                hidden, \n                encoder_outputs,\n            )\n            decoder_attentions[idx, :decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n            top_v, top_i = output.data.topk(1)\n            ni = top_i[0]\n            if ni == indices_from_text(TEXT.eos_token):\n                break\n            else:\n                summary_words.append(text_from_indices(ni))\n            \n            decoder_input = torch.cuda.LongTensor([ni])\n        summary_words.append(TEXT.eos_token)\n        summary = \" \".join(summary_words).lstrip()\n        return summary, decoder_attentions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 10\nlr = 0.01\ngrad_clip = 10.0\nscheduler_step_size = 50\nscheduler_gamma = 0.75","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hidden_size = 256\nembed_size = 128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'[!] preparing dataset...')\ntext_size, summary_size = len(TEXT.vocab), len(SUMMARY.vocab)\nprint(f'[TRAIN]: {len(train_iter)} | {len(train_iter.dataset)}\\t [TEST]: {len(test_iter)} | {len(test_iter.dataset)}')\nprint(f'[TEXT_vocab] & [SUMMARY_vocab] (same) {text_size}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"[!] Instantiating models...\")\nencoder = EncoderRNN(text_size, embed_size, hidden_size,\n                  n_layers=2, dropout=0.5)\ndecoder = DecoderRNN(embed_size, hidden_size, text_size,\n                  n_layers=1, dropout=0.5)\nseq2seq = Seq2Seq(encoder, decoder).cuda()\noptimizer = optim.Adam(seq2seq.parameters(), lr=lr)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step_size, gamma=scheduler_gamma)\nprint(seq2seq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.empty_cache()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_val_loss = None\nfor e in notebook.tqdm(range(1, epochs+1)):\n    train(e, seq2seq, optimizer, scheduler, train_iter, text_size, grad_clip, TEXT)\n    val_loss = evaluate(seq2seq, val_iter, text_size, TEXT)\n    print(f'[Epoch: {e}] val_loss: {val_loss} | val_pp: {math.exp(val_loss)}')\n\n    # Save the model if the validation loss is the best we've seen so far.\n    if not best_val_loss or val_loss < best_val_loss:\n        print(\"[!] saving model...\")\n        if not os.path.isdir(\".save\"):\n            os.makedirs(\".save\")\n        torch.save(seq2seq.state_dict(), './.save/seq2seq_%d.pt' % (e))\n        best_val_loss = val_loss\ntest_loss = evaluate(seq2seq, test_iter, text_size, TEXT)\nprint(f'[TEST] loss: {test_loss}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glob('../working/*')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir(r'../working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(seq2seq.state_dict(), 'pl_seq2seq_small.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_seq2seq = Seq2Seq(encoder, decoder).cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_seq2seq.load_state_dict(torch.load('../working/pl_seq2seq.pt'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_seq2seq.decoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def summarize2(text):\n    with torch.no_grad():\n        sequence = indices_from_text(text).unsqueeze(0)\n        sequence_length = sequence.size(1)\n        encoder_outputs, encoder_hidden = eval_seq2seq.encoder(sequence.transpose(0, 1))\n        \n        decoder_input = torch.LongTensor([indices_from_text(TEXT.init_token)]).cuda()\n        hidden = encoder_hidden[:eval_seq2seq.decoder.n_layers]\n        summary_words = ['<sos>']\n        max_summary_length = int(sequence_length * 0.25)\n        decoder_attentions = torch.zeros(max_summary_length, sequence_length)\n        \n        for idx in range(max_summary_length):\n            output, hidden, decoder_attention = eval_seq2seq.decoder(\n                decoder_input, \n                hidden, \n                encoder_outputs,\n            )\n            decoder_attentions[idx, :decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n            top_v, top_i = output.data.topk(1)\n            ni = top_i[0]\n            if ni == indices_from_text(TEXT.eos_token):\n                break\n            else:\n                summary_words.append(text_from_indices(ni))\n            \n            decoder_input = torch.LongTensor([ni]).cuda()\n        summary_words.append(TEXT.eos_token)\n        summary = \" \".join(summary_words).lstrip()\n        return summary, decoder_attentions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, param in seq2seq.named_parameters():\n    if param.requires_grad:\n        print (name, param.data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torchsummary\nfrom torchsummary import summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary(seq2seq.encoder, (500, 8), (100, 8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"next(iter(train_iter)).text[0].shape, next(iter(train_iter)).lead[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, param in seq2seq.named_parameters():\n    if param.requires_grad:\n        print (name, param.data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hidden size 128"},{"metadata":{"trusted":true},"cell_type":"code","source":"count_parameters(encoder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_parameters(decoder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_parameters(seq2seq)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hidden size 256"},{"metadata":{"trusted":true},"cell_type":"code","source":"count_parameters(encoder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_parameters(decoder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_parameters(seq2seq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}