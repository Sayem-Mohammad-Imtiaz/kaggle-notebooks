{"cells":[{"metadata":{"_uuid":"5be9c1e69f9f04927cccded8123b5af189e99d5e"},"cell_type":"markdown","source":"목차를 만들고 싶었는데 못만들었음. 열심히 스크롤하기 바라.\n\n우리가 하고싶은 일, 궁극적인 목표는 여러여러 요소들(우린 보통 Feature라 칭하고 이외에 독립변수 등등 라고 칭함.)을 가지고 Churn(Target, 종속변수)이라는 고객이탈을 알고 싶은거임.\n\n예를 들자면 한 유저가 있으면 이 사람이 한달에 통화를 얼마나 했는지, 한달에 요금은 얼마나 냈는지는 feature들이고, 고객이탈은 target임.\n\n다시한번 말하자면, 우리는 컴퓨터에게 feature들을 입력시켜서 target을 예측하고 싶은거임.\n\n그냥 이 feature들을 입력시켜 컴퓨터가 알아서 딱 계산을 해줬으면 좋겠지만, 그렇지않음.  그전에 해야할 과정이 있음.\n\n그 과정들을 우리가 첫날에 조사를 했음.\n\n멘토님이 보내주신 캐글자료의 과정은\n\n1. Data\n\n2. Data Manipulation\n\n3. Exploratory Data Analysis\n\n4. Data preprocessing\n\n5. Model Building\n\n6. Model Performances\n\n이런 흐름대로 흘러가고, 대부분의 데이터를 분석하고 예측할 때 이런 과정으로 거쳐감.\n\n1.Data부터 보자면 데이터를 들여다 보는 과정임.\n\n전체적인 데이터가 어떻게 생겨먹었고, 어떤 친구들이 feature로 존재하고, 결측치(입력이 없는 값)은 있는지 살펴보는 시간임. 정말 전체적으로 어떻게 생겨먹었구나~ 알려고 하는 과정.\n\n2.Data Manipulation이 친구는 들여다 봤던 친구들을 만져주는 과정임 데이터 분석후에 하기도 하지만, 여기서는 먼저 만져주는 방식을 택했음. \n\n때에 따라 다른데 이 사람은 정확히 이 데이터에 대해 알고 있는 사람이라 먼저 만져주고 분석을 한 것같음.\n\n왜 데이터를 만져주냐? 라는 의문이 생기는데 우리가 feature들을 컴퓨터에게 주고 target을 알아서 예측해라! 하고 싶지만 컴퓨터는 집어넣은대로만 받아들임. 예측력이 떨어지거나 아예 의미없는 결과값이 만들어지기도 함. \n\n그래서 예측력을 올리려면 찾았던 결측치를 채워주고, 데이터 형식을 바꿔주고(뒤에서 설명) 등등으로 데이터를 컴퓨터가 알아먹게 예쁘게 데이터를 다듬어줘야함.\n\n3.Exploratory Data Analysis 탐색적자료분석이라고 하던 그놈의 EDA임.\n\nChurn과 관련해서 하나의 feature마다 혹은 여러개의 feature들과의 관계를 찾아내는 과정. 좀 더 관계 높은 feature를 찾아내고 저어언혀 연관성 없는지 뭐 그런걸 보고싶어서 이런걸 함. \n\n시각적으로 만들어 줘서 좀 있어보임.이걸 하고 2.Data Manipulation로 돌아가서 데이터를 다시 만져주기도 함. feature가 target과 깊은 관계로 만들어 주기 위해서. 컴퓨터가 더 예측을 잘하기 위해서.\n\n4.Data preprocessing 이것도 데이터를 만져주는 역할임.\n\n근데 이 친구는 좀 더 전문적으로 만진다고 해야하나? 직접적으로 컴퓨터가 알아먹을 수 있도록 바꿔주는 역할임. \n\n컴퓨터는 글자로 집어넣으면 못알아먹고 숫자로 넣어줘야하고, 이 숫자도 너무 커버리면 컴퓨터가 얘네한테 관심을 모두 쏟아버림. \n\n그런걸 해결하는 과정인데, 이 외에도 다른 과정이 있지만 지금 말하는 것 보다 밑에서 설명되어 있음. 대강 이런거구나 ~ 넘어가자.\n\n5.Model Building\n\n6.Model Performances\n\n5와 6은 한꺼번에 보는게 좋을것 같아서. 5번은 모델을 만드는 과정이고 6번은 이 모델을 평가하는 과정임. \n\n여기서 말하는 모델이란, feature들을 집어 넣어서 target으로 예측하게 만드는 도구정도로 생각하면 좋음. \n\n이 도구들이 굉장히 많은데 컴퓨터는 연산을 하잖아? feature들을 연산해서 target으로 예측하는 과정이 수학적으로,또 방식적으로 달라서 모델이 많은거. 하나하나 밑에서 다시 설명할 예정임. \n\n또 Performances를 측정하는 방식도 많음. 이것도 밑에서 설명.\n\n이게 전체적인 분석, 예측의 과정이고 사람마다 조금씩 다르다.\n\n이제 코드를 보면서 하나하나 살펴볼거임. \n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"데이터 정제, 프레임만드는 친구들\n"},{"metadata":{"trusted":true,"_uuid":"2dad6829cff5eb9e2f3033564215bb19cb1dd01b"},"cell_type":"code","source":"import os\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"813389bf6ec3736cbe7f76046973a68efcf5b32b"},"cell_type":"markdown","source":"코드 짜다보면 경고문자 뜨는데 그걸 안나오게 해줌.\n"},{"metadata":{"trusted":true,"_uuid":"b7871e6f7ae36aa4a2e608946d4cfbad3b3fa603"},"cell_type":"code","source":"import io","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2ae43f6d899ca60529585c712946643b15b296d"},"cell_type":"markdown","source":"얘 뭐냐??"},{"metadata":{"trusted":true,"_uuid":"073107b3208b5e1c5e5b412961b77b32b5181cc2","scrolled":true},"cell_type":"code","source":"import plotly.offline as py\nimport plotly.tools as tls\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nimport matplotlib.pyplot as plt\nfrom PIL import  Image\n%matplotlib inline\nimport seaborn as sns\npy.init_notebook_mode(connected=True)\nimport itertools\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8bc8a3ce2a6d488c181866cb4514731e5670a558"},"cell_type":"markdown","source":"시각화를 위한 자료들.\nimport '라이브러리' as '지칭용어'를 해주면 이후 지칭용어로 불러올 수 있다.\n\npy.init_notebook_mode~를 해주면 원래는 웹에서 그림을 띄우는게 되는건데 여기 안에서도 실행하여 볼 수 있게해주는거임.\n\nimport pandas as pd면 이후 pandas를 pd로 불러올 수 있다.\n필요한 라이브러리들 필요한 함수를 쓸 수 있게 해준다.\n\n#1.Data"},{"metadata":{"trusted":true,"_uuid":"76e86de7ab3f10df0f35b920c78a0891e715894f"},"cell_type":"code","source":"tel=pd.read_csv(r\"../input/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d8592496307fa85909211b8b21dc683abf681c5"},"cell_type":"markdown","source":"pandas에 read_csv라는 함수를 쓰면 csv파일을 불러올 수 있음.\n.을 찍으면 하위속성으로 들어간다고 생각하면 좋음. 위의 pd.read_csv는 pd(pandas라는 라이브러리 안의 read_csv라는 함수를 씀\n\n##1.1. Data Overview"},{"metadata":{"trusted":true,"_uuid":"fd1e3dbb12b49c66322286fb863ab345d70cf4bc","scrolled":true},"cell_type":"code","source":"tel.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f809d73bcce90c2ef2eafb3d9e2dfe1581e3f48c"},"cell_type":"markdown","source":"head는 데이터 상단의 친구들을 띄울 수 있다. 괄호안의 숫자를 넣으면 숫자만큼 불러올 수 있음. 기본으로 5개\n"},{"metadata":{"trusted":true,"_uuid":"41e1f47efed9ebe5669d5dd62c80fedbe18edced"},"cell_type":"code","source":"tel.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc514fe5b863db33c982b5768a1b2273e6de1107"},"cell_type":"markdown","source":"얘를 보면 전체적인 데이터 숫자, 데이터 형태 등을 알 수 있다."},{"metadata":{"trusted":true,"_uuid":"a3a33fc0543192ec7bffcbaac6aa8c6796804f3e"},"cell_type":"code","source":"tel.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba4032f6c207c6376bd2da4515c1923fbfef6d3b"},"cell_type":"markdown","source":"데이터의 모양을 확인하는 건데 0은 행을 의미한다. - 행갯수 확인"},{"metadata":{"trusted":true,"_uuid":"39e64f32692996ea96221d5a3c3aa791e1704976"},"cell_type":"code","source":"tel.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e24740610d1868cda1391b388a1be1a89d24bfce"},"cell_type":"markdown","source":"1은 열. 열갯수 확인"},{"metadata":{"trusted":true,"_uuid":"abc0bbae4f3a72b789ede1870e9650f36c6f5d4c"},"cell_type":"code","source":"tel.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73f2da675bbc791fbcc99fb65c42c700a6a0a368"},"cell_type":"markdown","source":"columns 열(보통 feature, 독립변수, 속성)을 불러오는 것. tel.columns는 열을 불러온 뒤 .tolist()를 해줘서 이를 리스트 형식으로 뽑아낸것.\n한번 실행해보면 알아볼 수 있을거야. 열이 어떤것들이 있는지 생각해주면 좋음.\n독립, 종속이라고 하면 좀 어려운데 일정 '조건'(독립 혹은 우린보통 feature라 칭함) 들을 가지고 '결과'(종속)를 예측 한다고 하면 쉬우려나"},{"metadata":{"trusted":true,"_uuid":"2e4e066be1fe82967d9a305b71e0ce7a278c05f1"},"cell_type":"code","source":"tel.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5be73c23787e97410b8b6afd4f4ab46b730fc671"},"cell_type":"markdown","source":"tel이라는 객체에 isnull()이라는 함수를 적용시켰는데 이건 결측치를 알아보기 위함.\n결측치란 비어있는 항목 정도로 생각해주면 좋음.\nisnull()을 적용하면 결측치인 항목엔 TRUE, 채워져 있으면 FALSE로 보여줌.\n뒤에 .sum()은 tel.isnull()의 TRUE값을 세라는 의미."},{"metadata":{"trusted":true,"_uuid":"d7604d4f03b9a1078351ffa7277722b81318ae74"},"cell_type":"code","source":"tel.nunique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6a0da431c6151d1ff061a1f17980f8b4eeaf4b8"},"cell_type":"markdown","source":"nunique()는 독립적인 값들을 의미함. unique한 값이라고 해야하나 예를 들어 1,1,1,1 이런식으로 있으면 한개만 있다고함.  "},{"metadata":{"trusted":true,"_uuid":"e7e59486b68d2c30e97c3541cec1f0827d554602"},"cell_type":"code","source":"tel.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d25667e212a82d8b9c6d2045c046da313b706c1e"},"cell_type":"markdown","source":"describe()은 수치형변수의 대략적인 수치값(평균, 중위수 등)들을 볼 수 있게 해준다."},{"metadata":{"trusted":true,"_uuid":"a3cbe84fc1bc8c741628dc69765c06d0da2fbc68"},"cell_type":"code","source":"tel.describe(include='O')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e1a23d59d58374b85626252721c00da6db9a1697"},"cell_type":"markdown","source":"describe() 괄호안에 include=하고 조건을 넣을 수 있는데, 'O'를 넣으면 범주형 변수의 대략적인 정보를 알 수 있다.\n수치형변수(numeric)란 보통 숫자로 표현된 아이. 수학점수 같은 것? 범주형변수란 class를 구별해 줄 수있는 친구들 반이 1반 2반 3반 이런식으로 구별해줄 수 있는.\n\n#2. Data Manipulation"},{"metadata":{"trusted":true,"_uuid":"48eb781a1eea070b017d42b746ac445c2ff662cf"},"cell_type":"code","source":"tel['TotalCharges']=tel['TotalCharges'].replace(\" \",np.nan)\ntel.TotalCharges.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4c707633f3375faa4c0bd2bd4465c1034490544"},"cell_type":"markdown","source":"tel의 'TotalCarges'라는 열(혹은 feature)에 접근을 함. 위에서도 설명 했듯이 .을 찍어서(tel.TotalCharges) tel의 하위에 있는 TotalCarges에 접근을 할 수도 있음.\nreplace함수를 써서 replace(당하는 아이, 바뀔아이)로 해줄 수 있음. 해석하자면 tel의 TotalCarges의 \" \"(빈칸) 얘를 np.nan(결측값)으로 바꿔라 라는 뜻. np는 numpy를 뜻함."},{"metadata":{"trusted":true,"_uuid":"7a4f1d3c7b708d9d8b203680bbbcd91cbbb55169"},"cell_type":"code","source":"tel=tel[tel[\"TotalCharges\"].notnull()]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7662acebd00e50a38f69f0b7e8b2025ce76d242c"},"cell_type":"markdown","source":"tel을/ tel에서/ tel[\"Totalcarges\"]가 /notnull()은 결측값이 아닌 친구들로만 뽑아라. 라는 뜻임.\n대괄호나 점이 있으면 안으로 들어간다고 생각하면 편할거임."},{"metadata":{"trusted":true,"_uuid":"9e49e3c2221db1205286fedb06853ef283710599"},"cell_type":"code","source":"tel=tel.reset_index()[tel.columns]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54253398545a26afde95759580150e7670b4c55e"},"cell_type":"markdown","source":"reset_index()란 인덱스값을 다시 지정해주란거임. 실행해 보면 알겠지만 tel을 불러오면 맨 왼쪽에 옆에 숫자 친구들이 있음.\n하지만 우리는 결측치를 없앴잖음? 그래서 빈 공간이 생김. 중간에 듬성듬성하게 번호가 붙여져있음. 얘네를 다시 0부터 순서대로 지정해줌.\n맨뒤에 [tel.columns]가 왜붙나 해봤더니 그냥 reset_index()를 하면 새로운 index라는 열이 생기더라. 모든열에 대해 reset_index하나보다 싶어."},{"metadata":{"trusted":true,"_uuid":"682f400c5ae964603cb24899bd1d5ffcf7dee30b"},"cell_type":"code","source":"tel['TotalCharges']=tel['TotalCharges'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56580ba1c46090a6bcc0e5c6744b9058e2df657a"},"cell_type":"markdown","source":"astype은 열의 속성을 바꿔주는 것. ()괄호안의 속성으로 바꾼다.\n\n위에 정보를 보면 TotalCarges는 원래 object로 분류되어 있었음. 아까 빈공간 \" \"이 친구 때문에.\n\n그래서 범주형(object)를 수치형(float, int 등)으로 바꿔준거임."},{"metadata":{"trusted":true,"_uuid":"c81d0467a5dba141e4137a63cae0043123d93130"},"cell_type":"code","source":"replace_cols=['OnlineSecurity', 'OnlineBackup', 'DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\nfor i in replace_cols:\n    tel[i]=tel[i].replace({'No internet service': 'No'})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5811a763d71ec40dd46922a45b3e1a83adb2a2fa"},"cell_type":"markdown","source":"replace_cols라는 새로운 객체를 설정해줬음. 근데 얘네를 보면 tel안에 있는 열들이고, 이 열의 값들엔 Yes,No, No internet service가 있음.\n\n얘네를 for문을 써서 한꺼번에 No internet service를 No로 간단하게 바꿔주고 싶은거임.\n\nfor문 설명 한번만. for i in replace_cols/ replace_cols안에 있는 친구(i)들을 한번씩 불러오는 거임.\n\n첫번째로 tel['OnlineSecurity']=tel['OnlineSecurity'].replace({'No internet service':'No'})가 되는건데 나머진 replace설명이랑 같음\n\n{당하는애:바뀔값} 대괄호치고 이런식으로 해도 똑같음. No internet service를 No로. 주의할 점이 숫자는 그냥 적어도 되는데 문자는 따옴표(작은,큰다됨)을 적어야함.\n"},{"metadata":{"trusted":true,"_uuid":"639fafdf292a885a96fdf22b1b694a603e5aa49a"},"cell_type":"code","source":"tel['SeniorCitizen']=tel['SeniorCitizen'].replace({1:\"Yes\",0:'No'})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fcee2bb1f668534c37559c4c247de8f485f47db"},"cell_type":"markdown","source":"1을 Yes로 0을 No로"},{"metadata":{"trusted":true,"_uuid":"c4ba8600358752bea86d5a15f63cefc6a1ee1684"},"cell_type":"code","source":"def lab(tel):\n    if tel['tenure']<=12:\n        return 'Tenure_0-12'\n    elif (tel['tenure']>12)&(tel['tenure']<=24):\n        return 'Tenure_12-24'\n    elif (tel['tenure']>24)&(tel['tenure']<=48):\n        return 'Tenure_24-48'\n    elif (tel['tenure']>48)&(tel['tenure']<=60):\n        return \"Tenure_48-60\"\n    elif tel[\"tenure\"]>60:\n        return 'Tenure_gt_60'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53ec29fc371f4f59d8d5b99c2a0fa66d3404b539"},"cell_type":"markdown","source":"def는 함수를 만들기 위한 명령어?임.  lab()이란 이름으로 함수를 정의 괄호안에 있는 tel은 매개변수 라는 역할을 하는데.\n\n사실 이 tel은 위에 적힌 tel과 다른아이임. 그냥 함수 정의할 때 밑에 tel을 쓰려고 넣는 아이임. 헷갈리지 않게 쓴다고 생각하자.\n\ntenure가 지속 계약기간? 같은건데 tel['tenure']의 값이 12개월 이하를 Tenure_0-12로 변환시킨다 ~ 라는 함수임\n"},{"metadata":{"trusted":true,"_uuid":"16fb401e1290c2123bbfdb8552fbe33903094641"},"cell_type":"code","source":"tel['tenure_group']=tel.apply(lambda tel:lab(tel),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"21c627bcbd20fda4f65281ae169a51b6cc171188"},"cell_type":"markdown","source":"tel에 없는 열을 생성할 수 있음. tel['열의 이름']= 이런식으로 생성하면됨.\n\n여기서는 tel에 .apply함수를 썼음. 값을 집어넣어주는 친구인데 괄호안의 lambda는 형식적으로 써준다고 그냥 생각.\n\ntel:lab(tel) 함수lab을 tel에 적용시키는 거라고 생각하면됨. axis=1은 열. 설명이 어렵다.. 그냥 넘어가도 형식만 기억하면 될듯 써보면 앎\n\n결과적으론 tel의 tenure를 lab함수를 적용, 변환시켜서 tenure_group에 삽입한다.\n"},{"metadata":{"trusted":true,"_uuid":"2e0c4b3a80feda8a9f1758111c52ecc39f4f1936"},"cell_type":"code","source":"churn=tel[tel['Churn']=='Yes']\nnot_churn=tel[tel['Churn']=='No']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"789d512073716d56b3f6410e56930ffee0a84a8a"},"cell_type":"markdown","source":"churn이라는 객체에 tel에/ tel에있는 Churn 값이 'Yes'인 친구들만 뽑아내서 저장\nnot_churn이라는 객체에 ~~"},{"metadata":{"trusted":true,"_uuid":"52a58406f09768320e159e5affe245c576e8ae51"},"cell_type":"code","source":"Id_col=['customerID']\ntarget_col=['Churn']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"326c6cec61a7e4a36bbabbb6c92370f5bdd563f3"},"cell_type":"markdown","source":"새로운 객체 Id_col과 target_col에 각각 customerID와 Churn을 집어넣음."},{"metadata":{"trusted":true,"_uuid":"c7def86d6e4515b673f5541cf4c02bf25fccd19c"},"cell_type":"code","source":"cat_cols=tel.nunique()[tel.nunique()<6].keys().tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9a838963c1048b8372f99136041ef97ef836d88"},"cell_type":"markdown","source":"cat_cols라는 객체에 tel의 nunique()에서 tel.nunique가 6개 미만인 친구들을 뽑아내서 list로 정리.\n\nnunique()란 고유값 갯수를 세주는 친구. 위에 있다.\n\n정리하자면 cat_cols라는 객체에 고유값의 갯수가 6개 미만인 feature를 뽑아낸것.\n"},{"metadata":{"trusted":true,"_uuid":"40bf2665b73fe69dade34b68fa5a4c002c45bc41"},"cell_type":"code","source":"cat_cols=[x for x in cat_cols if x not in target_col]\nnum_cols   = [x for x in tel.columns if x not in cat_cols + target_col + Id_col]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0c1582b14b99101a0cc4e0f1b8ca822779a13cb"},"cell_type":"markdown","source":"좀 있어보이게 쓴거 같은데 cat_cols라는 객체를 덮어쓰는거임.\n\nfor문 아래에 if문이 있고 target_col이 Churn인데 Churn 빼고 모든 cat_cols의 친구들을 다 넣은거.\n\n#3. Exploratory Data Analysis\n##3.1. Customer attrition in data"},{"metadata":{"trusted":true,"_uuid":"507e16570e0c469ea1074c7dc2809cc8b2fae1e1"},"cell_type":"code","source":"lab=tel['Churn'].value_counts().keys().tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"136ed06397da7f7d835b5473a462f9da67bef638"},"cell_type":"markdown","source":"lab이란 객체에 tel['Churn']/ value_counts()는 항목별 갯수를 세어줌. yes 몇개, no 몇개 이런식.\n\nkeys는 여기에 있는 yes와 no를 뽑아줌. tolist는 이걸 리스트 형식으로 나열해주는것 ['No','Yes']이런식"},{"metadata":{"trusted":true,"_uuid":"49cf47b7ab91d8bced38d57b1259e05a1c3c766e"},"cell_type":"code","source":"val=tel['Churn'].value_counts().values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"313e6086c2e8591875f3f2d79f201a93478df4be"},"cell_type":"markdown","source":"#얘는 val이란 객체에 tel['Churn']의 항목별 갯수를 센후에, values란 숫자임 yes 몇개, no 몇개라 하면,\n#몇개를 뽑아주는 친구. 이걸 리스트 형식으로 바꿈."},{"metadata":{"trusted":true,"_uuid":"ca767410bdf3b06a76b105f5ac00239b533f673e"},"cell_type":"code","source":"trace=go.Pie(labels=lab, values=val,\n             marker=dict(colors=['royalblue','lime'],\n                         line= dict(color=\"white\",\n                                    width=1.3)\n                         ),\n             rotation=90,\n             hoverinfo=\"label+value+text\",\n             \n             hole=.5\n            )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c58aaad69cb0f513fec58a563c87fd695b84c96d"},"cell_type":"markdown","source":"얘는 파이차트를 만들어주는 친구임 trace란 객체에 go라는 라이브러리 안의 Pie를 불러옴\n\nlabels에 아까 지정해준 lab을 입력, values에 val을 넣어줌. \n\nmarker로 dict는 집어 넣는 친구인데 여기에 colors와 line을 이용해서 색과 선 속성을 지정해준거임.\n\n색은 로얄블루, 라임색. 라인은 흰색에 두께는 1.3 이런느낌\n\n실험해봤는데 rotation은 다른속성(여기선 Yes)가 몇도 정도에 위치해 있을지를 보여줌. 원 각도라고 생각.\n\nhole은 가운데 있는(빈공간)원의 크기를 보여줌.\n\nhoverinfo는 어딘가에 위치해있을텐데 아직 못찾음.."},{"metadata":{"trusted":true,"_uuid":"382061ad5d74fd4b43990a1ead3a0aaff1372771"},"cell_type":"code","source":"layout=go.Layout(dict(title=\"Customer attrition in data\",\n                     plot_bgcolor='rgb(243,243,243)',\n                      paper_bgcolor='rgb(243,243,243)',\n                    \n                     \n                     ))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6ea77c52ab7680abf306681b5952b92e7dcabd1"},"cell_type":"markdown","source":"레이아웃 설정 title, 색상들 설정해주는 친구\n\nplot_bgcolor는 어디서 변하는지 모르겠네 \npaper는 배경색깔이 변함. 바꿔보면"},{"metadata":{"trusted":true,"_uuid":"28d3620267b189c2167a4e07c9c42b89320d98de"},"cell_type":"code","source":"data=[trace]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0bd8fc0b11c22d37f675cf7999d495dc2d4ad17b"},"cell_type":"markdown","source":"데이터라는 객체에 trace를 넣어줌"},{"metadata":{"trusted":true,"_uuid":"e4d1ab9ddc634b6dd41dc3cdd0341f02b03e69c8"},"cell_type":"code","source":"fig=go.Figure(data=data,layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6c5497a369ed2c9edffe28277f51fd3c5139b37"},"cell_type":"markdown","source":"얘네를 Figure라는 함수에 집어넣어서 형상화를 해주는거임. 여태 위에서 trace와 layout은 이런형식으로 만들꺼임! 이라고 지정해 줬다면 Figure는 얘네를 종합해서 그림으로 만들어줌.\n\n이걸 우리가 눈으로 볼 수 있게 해주는 친구는 py.iplot(fig)가 해줌.\n\n##3.2. Varibles distribution in customer attrition\n"},{"metadata":{"trusted":true,"_uuid":"b8e6923f891d855ddff391ddba080fa9ade1fd2b"},"cell_type":"code","source":"def plot_pie(column) :\n    \n    trace1 = go.Pie(values  = churn[column].value_counts().values.tolist(),\n                    labels  = churn[column].value_counts().keys().tolist(),\n                    hoverinfo = \"label+percent+name\",\n                    domain  = dict(x = [0,.48]),\n                    name    = \"Churn Customers\",\n                    marker  = dict(line = dict(width = 2,\n                                               color = \"rgb(243,243,243)\")\n                                  ),\n                    hole    = .6\n                   )\n    trace2 = go.Pie(values  = not_churn[column].value_counts().values.tolist(),\n                    labels  = not_churn[column].value_counts().keys().tolist(),\n                    hoverinfo = \"label+percent+name\",\n                    marker  = dict(line = dict(width = 2,\n                                               color = \"rgb(243,243,243)\")\n                                  ),\n                    domain  = dict(x = [.52,1]),\n                    hole    = .6,\n                    name    = \"Non churn customers\" \n                   )\n\n\n    layout = go.Layout(dict(title = column + \" distribution in customer attrition \",\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            annotations = [dict(text = \"churn customers\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .15, y = .5),\n                                           dict(text = \"Non churn customers\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .88,y = .5\n                                               )\n                                          ]\n                           )\n                      )\n    data = [trace1,trace2]\n    fig  = go.Figure(data = data,layout = layout)\n    py.iplot(fig)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5143aa9082dac6db9399addde00a1d76724a1ad"},"cell_type":"markdown","source":"굉장히 길어보이고 복잡해 보이지만 위에있는 것들을 반복한 것 뿐임.\n겁먹지 말고 천천히 살펴보자.\n\n\n단지 우리가 각 속성들에 대한 churn과 No churn일때 어느정도 차지하는지 보고싶은건데,\n코드를 각 속성마다 하나하나 쓰면 귀찮으니 plot_pie란 함수를 지정해 놓고 쉽게 불러와주고 싶은거임.\n\n예를들어 인터넷 서비스를 이용하는지에 따른 churn일때 비율, no churn일때 비율, \n나이가 많을때 churn 비율, no churn일때 비율등등. \n\n\ndef바로 밑줄부터 보면 trace1부터, trace2, layout 해서 똑같은 코드가 반복되고 있음.\ntrace1엔 churn을, trace2엔 No churn을 설정해서 두개의 차트를 한번에 볼 수 있게 해준것. \n\n\n이전엔 value와 label을 따로 \n~~~\nval=tel['Churn'].value_counts().values.tolist()<-이런식으로 만들어서\n\n\ntrace=go.Pie(labels=lab, values=val, <-이렇게 넣어줬는데\n~~~\ndef 이하에선 \n~~~\ntrace1=go.Pie(values=churn[column].value_counts().values.tolist(),\n\nlabels=churn[column].value_counts().keys().tolist()\n~~~\nChurn 객체의 ['column']을 불러오게 했음. \n\n\n\n이전의 trace와 layout과 추가된 코드를 보자면 먼저 trace에서 \ndomain은 실험해 봤는데 위치를 설정해줌. name은 그냥 이름설정(딱히 변하는 건 눈에 안보임).\n~~~\n+domain=dict(x=[0,.48]) \n~~~\n에서 봤을때 dict는 삽입, (x=['수평위치','수직위치'])이고, 각 위치값은 0~1사이 값을 가진다.\n\n다음엔 layout을 보면 \n~~~\n    layout = go.Layout(dict(title = column + \" distribution in customer attrition \",\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            annotations = [dict(text = \"churn customers\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .15, y = .5)\n~~~                                            \nannotation이란 친구가 있음. dict를 해서 삽입을 해주는데, 들여다보면\n\ntext, font, showarrow, x, y같은게 들어가 있음.\n\ntext는 이 그래프가 누구에요~ 알려주는 친구임. 그래프의 보여지는 이름 설정같은거. font는 언제나 그렇듯 글자크기 등을 조절할 수 있게해줌.  \n\nshowarrow가 뭘까 궁금했는데 실험해보니까 얘가 걔에요 하면서 화살표로 표시해줌 ㅋㅋㅋ 근데 기본값은 True고 False로 설정해주면 화살표가 없음\nx,y는 이 text의 위치를 지정해준다.\n\n\n\n\n"},{"metadata":{"trusted":true,"_uuid":"a381ce83447401faf8883c9349c91cb09c4eb3b3"},"cell_type":"code","source":"def histogram(column) :\n    trace1 = go.Histogram(x  = churn[column],\n                          histnorm= \"percent\",\n                          name = \"Churn Customers\",\n                          marker = dict(line = dict(width = .5,\n                                                    color = \"black\"\n                                                    )\n                                        ),\n                         opacity = .9 \n                         ) \n    \n    trace2 = go.Histogram(x  = not_churn[column],\n                          histnorm = \"percent\",\n                          name = \"Non churn customers\",\n                          marker = dict(line = dict(width = .5,\n                                              color = \"black\"\n                                             )\n                                 ),\n                          opacity = .9\n                         )\n    \n    data = [trace1,trace2]\n    layout = go.Layout(dict(title =column + \" distribution in customer attrition \",\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                             title = column,\n                                             zerolinewidth=1,\n                                             ticklen=5,\n                                             gridwidth=2\n                                            ),\n                            yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                             title = \"percent\",\n                                             zerolinewidth=1,\n                                             ticklen=5,\n                                             gridwidth=2\n                                            ),\n                           )\n                      )\n    fig  = go.Figure(data=data,layout=layout)\n    \n    py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fce53b0d3be2bbd8f390b1e88a3111d800df75a"},"cell_type":"markdown","source":"이번엔 히스토그램을 그려주고 싶음.\n\n이전까지는 yes,no 같은걸로 분류되는 범주형 친구들이었다면,  이젠 수치형 친구들을 그래프로 나타내주고 싶음.\n\n그럴려면 히스토그램을 그려줘야함.\n\n아까랑 구성은 비슷함. def histogram으로 함수를 정의해주고 trace1, trace2, layout은 그대로 유지.\n\nx=churn[column]-> x축엔 수치형의 column이 들어간다. y축은 histnorm='percent'이라는 녀석이 들어가는데, 이게 뭔가 검색해봤더니 여러수치로 표시할 수 있음(percent외에 probability, density등). \n\n우리는 x축에 따라 전체의 몇 %를 차지하고 있는지를 표시할 거임.(밑에 그림을 보면 이해하기 쉽다.)\n\nname은 옆에 표시되는 색인? 정도로 인식하면 좋다. 그림 왼쪽에 표시.\n\nmarker는 이전과 같음.\n\nopacity는 그래프 불투명도.\n\n\nlayout을 보면 \n\n~~~\nxaxis= dict(gridcolor='rgb(255,255,255)',\n                     title=column,\n                     zerolinewidth=1,\n                     ticklen=5,\n                     gridwidth=2)\n~~~                                  \n이런 친구가 있는데 x축의 설정을 해주는것. \n\nx축 색깔과 이름, zeroline은 말그대로 맨밑에 있는 0의 라인임. 두께설정.\n\nticklen은 0,5,10 같이 단위 구분했을 때 왼쪽에 - 요런거 나와있는 친구 길이, \n\ngridwidth는 가운데 있는 구분선 두께! 라고 하고싶은데 보면 앎. 물어봐\n\ny축도 같음.\n"},{"metadata":{"_uuid":"b7ef662aef89904156c48e257a86369efb5bca1f","trusted":true},"cell_type":"code","source":"def scatter_matrix(df)  :\n    \n    df  = df.sort_values(by = \"Churn\" ,ascending = True)\n    classes = df[\"Churn\"].unique().tolist()\n    classes\n    \n    class_code  = {classes[k] : k for k in range(2)}\n    class_code\n\n    color_vals = [class_code[cl] for cl in df[\"Churn\"]]\n    color_vals\n\n    pl_colorscale = \"Portland\"\n\n    pl_colorscale\n\n    text = [df.loc[k,\"Churn\"] for k in range(len(df))]\n    text\n\n    trace = go.Splom(dimensions = [dict(label  = \"tenure\",\n                                       values = df[\"tenure\"]),\n                                  dict(label  = 'MonthlyCharges',\n                                       values = df['MonthlyCharges']),\n                                  dict(label  = 'TotalCharges',\n                                       values = df['TotalCharges'])],\n                     text = text,\n                     marker = dict(color = color_vals,\n                                   colorscale = pl_colorscale,\n                                   size = 3,\n                                   showscale = False,\n                                   line = dict(width = .1,\n                                               color='rgb(230,230,230)'\n                                              )\n                                  )\n                    )\n    axis = dict(showline  = True,\n                zeroline  = False,\n                gridcolor = \"#fff\",\n                ticklen   = 4\n               )\n    \n    layout = go.Layout(dict(title  = \n                            \"Scatter plot matrix for Numerical columns for customer attrition\",\n                            autosize = False,\n                            height = 800,\n                            width  = 800,\n                            dragmode = \"select\",\n                            hovermode = \"closest\",\n                            plot_bgcolor  = 'rgba(240,240,240, 0.95)',\n                            xaxis1 = dict(axis),\n                            yaxis1 = dict(axis),\n                            xaxis2 = dict(axis),\n                            yaxis2 = dict(axis),\n                            xaxis3 = dict(axis),\n                            yaxis3 = dict(axis),\n                           )\n                      )\n    data   = [trace]\n    fig = go.Figure(data = data,layout = layout )\n    py.iplot(fig)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0c1f766e543ae0f675a59aaa6dfafa8c99008a9"},"cell_type":"markdown","source":"이제 scatter 산점도를 그리고 싶음.\n\nscatter는 수치형과 수치형의 관계를 알고 싶은거임.\n~~~\ndf  = df.sort_values(by = \"Churn\" ,ascending = True)\n~~~\ndf라는 객체에 sort_values라는 함수를 쓰면 내림차순 오름차순으로 설정할 수 있음. ascending=으로 설정할 수 있는데 False는 내림차순 True는 오름차순.\n\n~~~\nclasses = df[\"Churn\"].unique().tolist()\n~~~\n\nclasses라는 객체에 df['Churn']의 .unique() 고유 값들을 .tolist() 리스트화 한다.\n\n\n\nclass_code라는 객체안에 classes의 값들에 for문으로 range(2) 범위 0,1안에서 한번씩 넣어주는거임. 그래서 No에는 0이, Yes엔 1이 할당됨. \n\n~~~\ncolor_vals = [class_code[cl] for cl in df[\"Churn\"]]\n~~~\ncolor_vals라는 객체안에 class_code를 df['Churn']의 Yes, No에 맞게 0과 1을 넣어줌.\n\n~~~\n  pl_colorscale = \"Portland\"\n~~~\npl_colorscale 색상 속성중에 Portland라는 테마가 있나봄. 이따가 씀.\n\n~~~\ntext = [df.loc[k,\"Churn\"] for k in range(len(df))]\n~~~\nloc라는 함수는 원하는 자료를 잘라낼 수 있는 함수. loc[행,열]을 지목해서 잘라낸다.\n\n뒤에 for문을 써줘서 k만큼 len(df)번 집어넣는건데. len은 길이를 나타내는 함수고 여기서는 df의 행길이를 의미한다.\n\n다시쓰자면, text란 객체에 df를 잘라내는데 [k행, 'Churn'열]을 k번(행길이->len(df)) 만큼 집어넣는 것. 그냥 text란 객체 안에 df['Churn']을 집어넣는 것.\n\n~~~\ntrace = go.Splom(dimensions = [dict(label  = \"tenure\",\n                                       values = df[\"tenure\"]),\n                                  dict(label  = 'MonthlyCharges',\n                                       values = df['MonthlyCharges']),\n                                  dict(label  = 'TotalCharges',\n                                       values = df['TotalCharges'])],\n                     text = text,\n                     marker = dict(color = color_vals,\n                                   colorscale = pl_colorscale,\n                                   size = 3,\n                                   showscale = False,\n                                   line = dict(width = .1,\n                                               color='rgb(230,230,230)'\n                                              )\n                                  )\n                    )\n    axis = dict(showline  = True,\n                zeroline  = False,\n                gridcolor = \"#fff\",\n                ticklen   = 4\n               )\n~~~\ntrace구성은 아까와 비슷함. Splom이란 함수는 Scatter Plot Matrix의 준말. 이후 나오게 될 그림을 보면 아 이게 그거구나 알게 될거임.\n\n다음을 보면 dimensions가 나오고, 우리가 보고싶은 수치형 변수들을 집어넣어 줄거임. 라벨에 이름을 지정해주고, value에 수치형변수를 집어넣어 준다. \n\ntext=text라고 하는데 아까 지정해줬던 text를 불러오는 것.\n\nmaker는 아까 했듯이 색상이나 여러 조건값을 지정해주는데 이거 이제 넘어가자..\nhttps://plot.ly/python/reference/ 여기 들어가서 ctrl+f 해서 찾쟈..\n\n밑의 axis는 축설정임. 이것도 전에 했던 것.\n~~~\n layout = go.Layout(dict(title  = \n                            \"Scatter plot matrix for Numerical columns for customer attrition\",\n                            autosize = False,\n                            height = 800,\n                            width  = 800,\n                            dragmode = \"select\",\n                            hovermode = \"closest\",\n                            plot_bgcolor  = 'rgba(240,240,240, 0.95)'\n~~~\nlayout설정은 이전에 했고 다른점은 dragmode나 hovermode는 그냥 보는 방식설정.\n\nrgba는 기존 색상 rgb에 a가 붙어서 알파로 투명도 조절.\n\n\n"},{"metadata":{"_uuid":"7c846dbe5e25a7761a574e7272963d4865bdced7","trusted":true},"cell_type":"code","source":"for i in cat_cols:\n    plot_pie(i)\nfor i in num_cols:\n    histogram(i)\nscatter_matrix(tel)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d42a2263b6c41c1fbde82a59222b4dda6dd63f4"},"cell_type":"markdown","source":"드디어 코드실행!! 두둥 아까 열심히 그렸던 그래프를 \n우리가 지정해둔 함수를 써서 for문을 써서 여러개를 한꺼번에, 산점도는 한방에 넣어줌.\n\n코드는 띄어쓰기랑 괄호랑 항상 주의할 것... 에러떴음 ㅂㄷ\n\n##3.3. Customer attrition in tenure groups"},{"metadata":{"_uuid":"593d05ddc4627ad02189518c2088e2a4ae3dfb59","trusted":true},"cell_type":"code","source":"tg_ch=churn['tenure_group'].value_counts().reset_index()\ntg_nch=not_churn['tenure_group'].value_counts().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38bbba61ecfe3ff4971a8d1833d476b3c6f556ae"},"cell_type":"markdown","source":"위에서 설명했으니 생략."},{"metadata":{"trusted":true,"_uuid":"596f85e1e264d1ad9f832643ecde20a774267c71"},"cell_type":"code","source":"tg_ch.columns=['tenure_group','count']\ntg_nch.columns=['tenure_group','count']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4dc13d07f497f47fd3c9a500fb4ae1835d463d0b"},"cell_type":"markdown","source":"칼럼 명 설정"},{"metadata":{"trusted":true,"_uuid":"1b3687766e4c43e748678c3d973979aab5d709a8"},"cell_type":"code","source":"trace1=go.Bar(x=tg_ch['tenure_group'], y=tg_ch['count'],\n             name='Churn Customers',\n             marker=dict(line=dict(width=.5,color='black')),\n             opacity=.9)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"062c5a09e0a79297be5778ef43dee901ec484c86"},"cell_type":"markdown","source":"막대 그래프를 만들어주기 위한 설정. x 는 x축 y는 y축."},{"metadata":{"trusted":true,"_uuid":"eda9b32377a976de130e36106c7f579b9bb53aa2"},"cell_type":"code","source":"trace2 = go.Bar(x = tg_nch[\"tenure_group\"] , y = tg_nch[\"count\"],\n                name = \"Non Churn Customers\",\n                marker = dict(line = dict(width = .5,color = \"black\")),\n                opacity = .9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ff7e5f842e1edf9eace86f4e256d52afeda63e8"},"cell_type":"code","source":"layout=go.Layout(dict(title='Customer attrition in tenure groups',\n                     plot_bgcolor='rgb(243,243,243)',\n                     paper_bgcolor='rgb(243,243,243)',\n                     xaxis=dict(gridcolor='rgb(255,255,255)',\n                               title='tenure group',\n                               zerolinewidth=1,\n                               ticklen=5,\n                               gridwidth=2),\n                     yaxis=dict(gridcolor='rgb(255,255,255)',\n                               title='count',\n                               zerolinewidth=1,ticklen=5,gridwidth=2),\n                     )\n                )\ndata=[trace1,trace2]\nfig=go.Figure(data=data,layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e0e8fb50d017369471895d31fd8833e33c30b06"},"cell_type":"markdown","source":"넘어간다~~ \n\n##3.4. Monthly Charges and Total Charges by Tenure and Churn groups"},{"metadata":{"trusted":true,"_uuid":"a709c92d8fa9428d3a26dfb4e7e979738dbb76a2"},"cell_type":"code","source":"def plot_tenure_scatter(tenure_group,color) :\n    tracer = go.Scatter(x = tel[tel[\"tenure_group\"] == tenure_group][\"MonthlyCharges\"],\n                        y = tel[tel[\"tenure_group\"] == tenure_group][\"TotalCharges\"],\n                        mode = \"markers\",marker = dict(line = dict(color = \"black\",\n                                                                   width = .2),\n                                                       size = 4 , color = color,\n                                                       symbol = \"diamond-dot\",\n                                                      ),\n                        name = tenure_group,\n                        opacity = .9\n                       )\n    return tracer\n\ndef plot_churncharges_scatter(churn,color) :\n    tracer = go.Scatter(x = tel[tel[\"Churn\"] == churn][\"MonthlyCharges\"],\n                        y = tel[tel[\"Churn\"] == churn][\"TotalCharges\"],\n                        mode = \"markers\",marker = dict(line = dict(color = \"black\",\n                                                                   width = .2),\n                                                       size = 4 , color = color,\n                                                       symbol = \"diamond-dot\",\n                                                      ),\n                        name = \"Churn - \" + churn,\n                        opacity = .9\n                       )\n    return tracer\n\ntrace1 = plot_tenure_scatter(\"Tenure_0-12\",\"#FF3300\")\ntrace2 = plot_tenure_scatter(\"Tenure_12-24\",\"#6666FF\")\ntrace3 = plot_tenure_scatter(\"Tenure_24-48\",\"#99FF00\")\ntrace4 = plot_tenure_scatter(\"Tenure_48-60\",\"#996600\")\ntrace5 = plot_tenure_scatter(\"Tenure_gt_60\",\"grey\")\ntrace6 = plot_churncharges_scatter(\"Yes\",\"red\")\ntrace7 = plot_churncharges_scatter(\"No\",\"blue\")\n\ndata1   = [trace1,trace2,trace3,trace4,trace5] \ndata2   = [trace7,trace6]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0e2e7ec466f34e937844b8a643539604e06cdcb"},"cell_type":"markdown","source":"나머진 같은데 산점도를 그릴때 \n~~~\nx = tel[tel[\"tenure_group\"] == tenure_group][\"MonthlyCharges\"]여길 보면 \n~~~\n이 코드는 x축에 tel/에 /[tel['tenure_group']/의 값이 /== tenure_group/  tenure_group값과 같을 때의  [''MonthlyCharges\"]를 불러와라. 임. tel['tenure_group']==tenure_group은 조건이고, 궁극적으로 가져오고 싶은애는  [''MonthlyCharges\"] 얘임.\n~~~\ndef plot_tenure_scatter(tenure_group,color) :\n~~~\n위엔 함수의 정의고 밑에서 \n~~~\ntrace1 = plot_tenure_scatter(\"Tenure_0-12\",\"#FF3300\")를 보면. \n~~~\n\ntrace1이라는 객체에 함수인 plot_tenure_sctter를 호출하고 거기에 ('Tenure_0-12'<- tenure_group이고 ,'#FF3300'<-color다.)"},{"metadata":{"trusted":true,"_uuid":"7880dd8cfa36a929df8ffbffa7257d27266a90f6"},"cell_type":"code","source":"def layout_title(title) :\n    layout = go.Layout(dict(title = title,\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                         title = \"Monthly charges\",\n                                         zerolinewidth=1,ticklen=5,gridwidth=2),\n                            yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                         title = \"Total Charges\",\n                                         zerolinewidth=1,ticklen=5,gridwidth=2),\n                            height = 600\n                           )\n                      )\n    return layout\n\nlayout1  = layout_title(\"Monthly Charges & Total Charges by Tenure group\")\nlayout2  = layout_title(\"Monthly Charges & Total Charges by Churn group\")\nfig1 = go.Figure(data = data1,layout = layout1)\nfig2 = go.Figure(data = data2,layout = layout2)\npy.iplot(fig1)\npy.iplot(fig2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"280d9bc36c0d3fc6048e42df401bd487477a2a7a"},"cell_type":"markdown","source":"layout과 산점도.\n\n##3.5. Average Charges by tenure groups"},{"metadata":{"trusted":true,"_uuid":"d66e02c0fa7d406fdfcdd40a9fcf32349e0f2548"},"cell_type":"code","source":"avg_tgc = tel.groupby([\"tenure_group\",\"Churn\"])[[\"MonthlyCharges\",\n                                                    \"TotalCharges\"]].mean().reset_index()\n\nno=tel.groupby([\"tenure_group\",\"Churn\"])[[\"MonthlyCharges\",\n                                                    \"TotalCharges\"]].mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5fb2338c4dd97ed38dd1c09a7756eb774aaef87"},"cell_type":"markdown","source":"groupby란 함수가 처음 나왔는데 이 친구는 얘네 기준으로 묶어주라는 거임.\n\n(['tenure_group',\"Churn'])을 기준으로 묶어놓은거에서,\n\n[['MonthlyCharges','TotalCharges']]를 뽑아내서\n\n.mean() 평균을 내고\n\n.reset_index()를 해줘라.인데 reset_index를 안해주면 조금 다른형태로 지저분하게 나옴.\n지워고 차이점을 보면 좋을듯?\n\n그래서 비교하려고 no라는 애를 만들어 줘봤음.\n"},{"metadata":{"trusted":true,"_uuid":"478974713ccad44169a42356388bfc09d27793eb"},"cell_type":"code","source":"avg_tgc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4985423b526ff248fbf064736a6b89af7a2383b8"},"cell_type":"markdown","source":"얘는 원본이고\n"},{"metadata":{"trusted":true,"_uuid":"ccbefd237a03c7b54aea1f00ab52fefffc8bf3c6"},"cell_type":"code","source":"no","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"779f94e155c4ba1155b2bb2b0ece30ddd75af637"},"cell_type":"markdown","source":"얘가 reset_index()를 뺀애임. "},{"metadata":{"trusted":true,"_uuid":"469ccdb8905c4a4f14fc237f4606c64fb9adb13d"},"cell_type":"code","source":"def mean_charges(column,aggregate) :\n    tracer = go.Bar(x = avg_tgc[avg_tgc[\"Churn\"] == aggregate][\"tenure_group\"],\n                    y = avg_tgc[avg_tgc[\"Churn\"] == aggregate][column],\n                    name = aggregate,marker = dict(line = dict(width = 1)),\n                    text = \"Churn\"\n                   )\n    return tracer","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8929e5a6b65520f81fb5351b973f22090f3d6882"},"cell_type":"markdown","source":"아까와 비슷한 함수를 정의, 써주고"},{"metadata":{"trusted":true,"_uuid":"85f1278db853c485203a1ce22eaa161e433ffc8e"},"cell_type":"code","source":"def layout_plot(title,xaxis_lab,yaxis_lab) :\n    layout = go.Layout(dict(title = title,\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            xaxis = dict(gridcolor = 'rgb(255, 255, 255)',title = xaxis_lab,\n                                         zerolinewidth=1,ticklen=5,gridwidth=2),\n                            yaxis = dict(gridcolor = 'rgb(255, 255, 255)',title = yaxis_lab,\n                                         zerolinewidth=1,ticklen=5,gridwidth=2),\n                           )\n                      )\n    return layout","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1b8dc7b268bf31dadb7a6fc957a7902667690d8"},"cell_type":"markdown","source":"layout도 이전과 비슷"},{"metadata":{"trusted":true,"_uuid":"ae4aa7da283fe97ef109cc64e25ba4a5fcbd9c02"},"cell_type":"code","source":"trace1  = mean_charges(\"MonthlyCharges\",\"Yes\")\ntrace2  = mean_charges(\"MonthlyCharges\",\"No\")\nlayout1 = layout_plot(\"Average Monthly Charges by Tenure groups\",\n                      \"Tenure group\",\"Monthly Charges\")\ndata1   = [trace1,trace2]\nfig1    = go.Figure(data=data1,layout=layout1)\n\n\ntrace3  = mean_charges(\"TotalCharges\",\"Yes\")\ntrace4  = mean_charges(\"TotalCharges\",\"No\")\nlayout2 = layout_plot(\"Average Total Charges by Tenure groups\",\n                      \"Tenure group\",\"Total Charges\")\ndata2   = [trace3,trace4]\nfig2    = go.Figure(data=data2,layout=layout2)\n\npy.iplot(fig1)\npy.iplot(fig2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42e9570a6a61a7b81afbc472307d012a9277bb59"},"cell_type":"markdown","source":"그리면 요런식으로 나온다.\n\n##3.6. Monthly charges,total charges and tenure in customer attrition"},{"metadata":{"trusted":true,"_uuid":"1183997eec82536ddbde02390966d0d8c7ad9b3e"},"cell_type":"code","source":"tel_df=tel.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4cafa40f0cda12786c60d689dc859e09b57221a6"},"cell_type":"markdown","source":"copy는 말 그대로 복사임. 원본의 데이터를 헤치지 않으려고 복사해서 씀."},{"metadata":{"trusted":true,"_uuid":"1f22c5dc1bb9761af3b245387d62b0a7679c4de8"},"cell_type":"code","source":"tel=tel.drop('tenure_group',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ebbccd60fdc178e1da3e2a6211ac2282a1e8dc61"},"cell_type":"markdown","source":"drop이 나오는데 행 혹은 열을 드랍할 수 있다. 여기선 axis=값으로 0은 행, 1은 열. \n\n'tenure_group'열을 없앤거임."},{"metadata":{"trusted":true,"_uuid":"2060dd1674f35418054f5a79f32f5ad00bfcd347"},"cell_type":"code","source":"trace1 = go.Scatter3d(x = churn[\"MonthlyCharges\"],\n                      y = churn[\"TotalCharges\"],\n                      z = churn[\"tenure\"],\n                      mode = \"markers\",\n                      name = \"Churn customers\",\n                      text = \"Id : \" + churn[\"customerID\"],\n                      marker = dict(size = 1,color = \"red\")\n                     )\ntrace2 = go.Scatter3d(x = not_churn[\"MonthlyCharges\"],\n                      y = not_churn[\"TotalCharges\"],\n                      z = not_churn[\"tenure\"],\n                      name = \"Non churn customers\",\n                      text = \"Id : \" + not_churn[\"customerID\"],\n                      mode = \"markers\",\n                      marker = dict(size = 1,color= \"green\")\n                     )\n\n\n\nlayout = go.Layout(dict(title = \"Monthly charges,total charges & tenure in customer attrition\",\n                        scene = dict(camera = dict(up=dict(x= 0 , y=0, z=0),\n                                                   center=dict(x=0, y=0, z=0),\n                                                   eye=dict(x=1.25, y=1.25, z=1.25)),\n                                     xaxis  = dict(title = \"monthly charges\",\n                                                   gridcolor='rgb(255, 255, 255)',\n                                                   zerolinecolor='rgb(255, 255, 255)',\n                                                   showbackground=True,\n                                                   backgroundcolor='rgb(230, 230,230)'),\n                                     yaxis  = dict(title = \"total charges\",\n                                                   gridcolor='rgb(255, 255, 255)',\n                                                   zerolinecolor='rgb(255, 255, 255)',\n                                                   showbackground=True,\n                                                   backgroundcolor='rgb(230, 230,230)'\n                                                  ),\n                                     zaxis  = dict(title = \"tenure\",\n                                                   gridcolor='rgb(255, 255, 255)',\n                                                   zerolinecolor='rgb(255, 255, 255)',\n                                                   showbackground=True,\n                                                   backgroundcolor='rgb(230, 230,230)'\n                                                  )\n                                    ),\n                        height = 700,\n                       )\n                  )\n                  \n\ndata = [trace1,trace2]\nfig  = go.Figure(data = data,layout = layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ded04f3ba8aa2bc2c2bfe24c95d8e84c30df7bc"},"cell_type":"markdown","source":"3d로 한번 구현해본것.  코드는 이전과 비슷 3d로 구현하는 함수인 Scatter3d인거 이외엔 없다.\n\n#4. Data preprocessing"},{"metadata":{"trusted":true,"_uuid":"9dac1f8d860f0fe471f75ad08220dee78604a1c0"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6bfff2e832567e5cba28a66f3647209c0052cbd"},"cell_type":"markdown","source":"데이터 프로세싱을 위한 도구들임. sklearn에 있는 LabelEncoder와 StandardScaler를 씀."},{"metadata":{"trusted":true,"_uuid":"36e528ac3eb1dc30cf3db85cb082ff27cbdc4793"},"cell_type":"code","source":"Id_col=['customerID']\ntarget_col=['Churn']\ncat_cols   = tel.nunique()[tel.nunique() < 6].keys().tolist()\ncat_cols   = [x for x in cat_cols if x not in target_col]\nnum_cols   = [x for x in tel.columns if x not in cat_cols + target_col + Id_col]\nbin_cols   = tel.nunique()[tel.nunique() == 2].keys().tolist()\nmulti_cols = [i for i in cat_cols if i not in bin_cols]\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f556aa4973268fadb291ef868593d9b966f3ed92"},"cell_type":"markdown","source":"비슷비슷 \ncat_cols는 범주형, num_cols는 수치형, bin_cols는 독립된 값이 0과 1 이런식으로 두개 밖에 없는 친구들을 뽑아낸 것."},{"metadata":{"trusted":true,"_uuid":"ed9f8e6331accafbef7eda591c32cb4d63b1eba5"},"cell_type":"code","source":"le = LabelEncoder()\nfor i in bin_cols :\n    tel[i] = le.fit_transform(tel[i])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c78568fbb926c204ebe4db6454627d9e62c938a7"},"cell_type":"markdown","source":"컴퓨터가 알아먹게 하기 위해서 범주형 친구들을 수치화해서 표현해야함. LabelEncoder란 친구를 써서 bin_cols 친구들을 수치화해준거임."},{"metadata":{"_uuid":"de72c6075887f98308a72061d1afbbbcbe9852d8","trusted":true},"cell_type":"code","source":"tel=pd.get_dummies(data=tel, columns=multi_cols)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69553e57c06391eefb13661b60afe59c6b01fb9b"},"cell_type":"markdown","source":"get_dummies함수가 쓰임. 얘는 또 다른 범주형을 수치화 시켜주는 친구임\n\nmulti_cols애들을 수치화 해주었는데, 왜 똑같은 LabelEncoder()를 쓰지 않았나 검색을 해봤더니, \n\nLabelEncoder를 쓰면 종설=['종국','윤식','보미','유선','혜인'] 이런식으로 있을때 [0,1,2,3,4]이런 식으로 변환을 시켜줌. \n\n하지만 get_dummies를 쓰면 '종설_ 종국' '종설_ 윤식' '종설_ 보미' '종설_ 유선' '종설_혜인' 이런식으로 열이 하나씩 만들어지고 0과 1 로만 표현이 됨. \n\n종국을 찾고 싶다면 '종설_종국'엔 1, 나머진 0이면 종국이라는걸 알 수 있도록. \n\n어떤 차이점이 있는가 했더니 LabelEncoder는 공간을 줄여주면서 구별이 가능하게 만들어 줌.\n\nget_dummies는 열을 여러개 생성하니 많아짐. \n\n하지만, 컴퓨터가 읽기에 LabelEncoder를 쓰면 0,1,2,3,4라고 있으면 좀 더 큰 값에 더 많은 가중치를 줄 것이다. 라고 해서 get_dummies를 쓴다함.\n\n그래서 bin_cols는 두개이기에 0,1로 표현 가능하니 Lable을, multi는 get_dummies를 쓴 것으로 보여짐."},{"metadata":{"_uuid":"dd017ecda227a0efb23aad663033e2a136e130a0","trusted":true,"scrolled":false},"cell_type":"code","source":"std = StandardScaler()\nscaled=std.fit_transform(tel[num_cols])\nscaled=pd.DataFrame(scaled,columns=num_cols)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b408a4ad909babb17a1c52852a028f0201682e47"},"cell_type":"markdown","source":"StandardScaler는 스케일링을 해주기 위한 도구로, 그냥 두면 숫자가 너무 커지니 이를 좀 더 작게 표현하여 매우 큰 숫자에 가중치를 줄여주고 서로 다른 데이터를 비교하기 쉽게 해줌.\n\n표준화의 식은 z=(x-u)/s로, (값-평균)/표준편차 이다."},{"metadata":{"_uuid":"d1845e8ae942a44b49c7dd009fbd2dd69370b78b","trusted":true},"cell_type":"code","source":"df_tel_og=tel.copy()\ntel=tel.drop(columns=num_cols,axis=1)\ntel=tel.merge(scaled,left_index=True,right_index=True, how='left')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11759105f55b9f8b765d07c99844cbe9f97a0cf3"},"cell_type":"markdown","source":"원래있던 놈을 복사해주고, num_cols(수치형변수)들을 제거해준뒤\nmerge함수를 써서 스케일링 된 친구들을 합쳐준다.\n\n\n\nmerge함수는 데이터프레임을 합치는 친구로 언제봐도 헷갈리는데, \n\nleft_index, right_index는 합칠때의 기준을 왼쪽에 있는 친구의 index를 기준을 삼을 것인지, right_index를 기준삼을지 해주는 것. \n\nhow는 left, right, outer, inner의 속성을 갖고 있다. default는 inner다.\n\n여기선 left가 쓰였는데 왼쪽친구가 key를 가지고 있을 때를 뜻한다.\nright은 오른쪽.\n\nouter는 키를 둘다 가지고 있을 때.  \ninner는 공통된 키가 있을 때.\n\n기억하기 싫겠지만 정분설 key를 생각해보면..ㅎㅎ..\n\n\n##3.7. Variable Summary"},{"metadata":{"_uuid":"83ce9ff31902ffae53d233b2ae9c97e4a20bf89d","trusted":true},"cell_type":"code","source":"summary = (df_tel_og[[i for i in df_tel_og.columns if i not in Id_col]].\n           describe().transpose().reset_index())\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a2fa861d298e731cc4b1f123b8f506f7d707240b"},"cell_type":"markdown","source":"갑자기 다시 데이터를 만지다가 데이터를 분석하려고 옴.\n\ndf_tel_og에서의 칼럼을 Id빼고 다 넣어서 describe해주고, transpose()가 뭔가 했더니 열과 행의 위치를 뒤바꿈.\n\nreset_index()로 보기 깔끔하게 해줌."},{"metadata":{"_uuid":"c73166910429a9e40dae625c4f88967ed75d2af3","trusted":true},"cell_type":"code","source":"summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f6c4d3d13a79ca3c507ffd37e988455c944325a"},"cell_type":"code","source":"summary=summary.rename(columns={'index':'feature'})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de1bd401bbcf1b868f3f782b9bf472a2f41f828c"},"cell_type":"markdown","source":"rename은 이름을 다시 설정하는 것. 열에서 'index'란 친구를 'feature'로 바꿔라."},{"metadata":{"trusted":true,"_uuid":"c6feb550758093459621cfaafd041b52094e4d90"},"cell_type":"code","source":"summary=np.around(summary,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"242ab494aa2fe6cdf47e2f4fbc28f16f584af104"},"cell_type":"code","source":"summary","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17eb9c3023658ebab0f5923e21375f1f9efbaac4"},"cell_type":"markdown","source":"지저분 하니까 소수점 세번째 자리까지 표현."},{"metadata":{"_uuid":"78a63a961a62bbec07d19ec21b56a85a8a7c434e","trusted":true},"cell_type":"code","source":"val_lst = [summary['feature'], summary['count'],\n           summary['mean'],summary['std'],\n           summary['min'], summary['25%'],\n           summary['50%'], summary['75%'], summary['max']]\n\ntrace  = go.Table(header = dict(values = summary.columns.tolist(),\n                                line = dict(color = ['#506784']),\n                                fill = dict(color = ['#119DFF']),\n                               ),\n                  cells  = dict(values = val_lst,\n                                line = dict(color = ['#506784']),\n                                fill = dict(color = [\"lightgrey\",'#F5F8FF'])\n                               ),\n                  columnwidth = [200,60,100,100,60,60,80,80,80])\nlayout = go.Layout(dict(title = \"Variable Summary\"))\nfigure = go.Figure(data=[trace],layout=layout)\npy.iplot(figure)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf5dee347c43d3bc2eaca2ef37002ef6304d1bba"},"cell_type":"markdown","source":"얘네를 구우우욷이 테이블 형식으로 표현을 해주시고 싶으시대.. \n\n테이블을 불러와서 함수도 딱히 어려운건 없어보이고 읽어보면 뭔지 알거임. \n\n##3.8. Correlation Matrix"},{"metadata":{"_uuid":"d5aaefb5f38d9d57fa7f1c4a12cd4297e0c626e8","trusted":true},"cell_type":"code","source":"correlation=tel.corr()\ncorrelation","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f6fd01bb7fcc5f33f0afe50434fa3b2d204d6fe"},"cell_type":"markdown","source":"상관분석을 하기위해서. 각 변수(feature)들 사이의 상관계수를 구해주는게 corr임."},{"metadata":{"_uuid":"1271272c2b7494aa2715998d9851c1cdb7033a62","trusted":true},"cell_type":"code","source":"matrix_cols = correlation.columns.tolist()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4aa17c775bcfed075da041466215899a1eb99f87"},"cell_type":"markdown","source":"열을 뽑아내서 list형식으로 저장."},{"metadata":{"trusted":true,"_uuid":"bb473c416ea0dd74dda593f4f102b23f508b9d20"},"cell_type":"code","source":"corr_array=np.array(correlation)\ncorr_array","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7e81b6c9b4c5c83020fc09bc09ed4f4b3740c6c9"},"cell_type":"markdown","source":"array형식으로 저장해줌 시각화를 위해 이런짓을 하고 있는데 array는 아까같이 깔끔한 표같은 모양에서 위의 모형처럼 생긴게 array임."},{"metadata":{"trusted":true,"_uuid":"dbce8a5a9b67baee9869253aed915d001e2b3423"},"cell_type":"code","source":"trace = go.Heatmap(z = corr_array,\n                   x = matrix_cols,\n                   y = matrix_cols,\n                   colorscale = \"Viridis\",\n                   colorbar   = dict(title = \"Pearson Correlation coefficient\",\n                                     titleside = \"right\"\n                                    ) ,\n                  )\nlayout = go.Layout(dict(title = \"Correlation Matrix for variables\",\n                        autosize = False,\n                        height  = 720,\n                        width   = 800,\n                        margin  = dict(r = 0 ,l = 210,\n                                       t = 25,b = 210,\n                                      ),\n                        yaxis   = dict(tickfont = dict(size = 9)),\n                        xaxis   = dict(tickfont = dict(size = 9))\n                       )\n                  )\ndata = [trace]\nfig = go.Figure(data=data,layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"09571eb9c4e2dae41221a9d4797abae24e49600c"},"cell_type":"markdown","source":"Heatmap이란 친구를 그려줄거임. x축, y축, z축에 각각 값이 들어갔고,\n\ncolorscale은 색 형식이고 colorbar는 색상이 의미하는 바를 보여주는 바임. ㅎㅎ\n보면 알거임. 글씨랑 바가 오른쪽에 위치해있음. \n\n나머진 그냥 layout과 그림을 나타내기 위한 과정들.\n\n##3.9. Visualising data with principal components\n"},{"metadata":{"_uuid":"e109ea9be21728ac4b514a5553c9a778f68cb0a0","trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca=PCA(n_components=2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1dd72703b004ce0dd82908b7337efc6166e13d1"},"cell_type":"markdown","source":"PCA라는 친구를 해줄거임 sklearn에서 할 수 있도록 제공해주고 있음.\n\nPCA란 N(feature 갯수)차원의 데이터가 존재하는 공간 상에서 데이터를 가장 잘 표현할 수 있는 기저(선)을 찾는 것. 이라고 함.\n\n전체 데이터를 파악하기 어려운 상황에 있거나 한계에 이를 때,\n어떤 변수가 전체 데이터에서 많은 ‘비중’을 차지하고 있는지 알고 싶거나,\n변수가 너무 많아서 선택(FEATURE SELECTION)을 통해 줄이고 싶을 때,\nPCA를 사용하면 데이터의 손실을 최대한 줄일 수 있다.\nPCA는 수치형변수 친구들을 계산해주는 친구이다.\n\nPCA자체는 FEATURE EXTRACTION이다. 여러 변수들을 조합해서 잘 설명하는 새로운 변수를 만들어 내는것. 하지만 FEATURE SELECTION에도 쓰일 수 있다. 비중이 더 높은 변수를 찾을 수도 있고 더 많은 수학적 작업을 통해 구할 수 있다고 한다. 하지만 보통은 그렇게까지 하진 않고, 어떤 관계가 어떻고 설명하는건 매우 난해하고 힘들다고 한다. \n이런 머신러닝 모델에서 보여주는건 정말 보여주기 식이 아닌가 싶다.\n\n보통 변수(FEATURE)가 매애애애우 많은 이미지 처리에 관해 설명이 많다.\n\n좀 더 예를 들어 설명한다.\n\n100개의 FEATURE가 있다고 치면, 우리가 100개를 다 대조하고, 둘씩 짝지어 산점도를 그린다면 100(100-1)/2로 4950개의 산점도를 봐야하는데, 현실적으로 그러기가 힘들다.\n그래서, PCA를 하여 차원을 줄여주면 이럴 필요가 없다고 한다. \n\n자세한 면면을 들여다 보려면 \n\n코드를 보면, pca란 객체에 n_components=2는 데이터를 가장 잘 표현할 수 있는 선을 두개를 보겠다는 것."},{"metadata":{"trusted":true,"_uuid":"01341645ee80616755c8c6f6edd74a4e5865dba6"},"cell_type":"code","source":"X = tel[[i for i in tel.columns if i not in Id_col + target_col]]\nY = tel[target_col + Id_col]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70ffcf27a17bc8e54c295f3f11bac732e5caf020"},"cell_type":"markdown","source":"계속하던 열 설정."},{"metadata":{"_uuid":"7bb7eb6075753d98ee36eb6f543e08fb0ad9b914","trusted":true},"cell_type":"code","source":"principal_components = pca.fit_transform(X)\nprincipal_components","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa5e5f717ff663bd1c3f8e5c772169d3e9d93a20"},"cell_type":"markdown","source":"X라는 변수를 pca 적용시키고 변환시키는 거임."},{"metadata":{"trusted":true,"_uuid":"cd3c91202080c9fcd0e13adfe9a842701669c8ad"},"cell_type":"code","source":"pca_data = pd.DataFrame(principal_components,columns = [\"PC1\",\"PC2\"])\npca_data = pca_data.merge(Y,left_index=True,right_index=True,how=\"left\")\npca_data[\"Churn\"] = pca_data[\"Churn\"].replace({1:\"Churn\",0:\"Not Churn\"})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42f18ae3f13597f35c74bbfbbcd0d263c5ca6f87"},"cell_type":"markdown","source":"pca_data에다가 DataFrame형식으로 위의 principa_components를 넣어주고 열을 PC1, PC2라 한다. \n\n"},{"metadata":{"trusted":true,"_uuid":"b12f3bfe7fc152c73d810df2c070c263461233f0"},"cell_type":"code","source":"def pca_scatter(target,color) :\n    tracer = go.Scatter(x = pca_data[pca_data[\"Churn\"] == target][\"PC1\"] ,\n                        y = pca_data[pca_data[\"Churn\"] == target][\"PC2\"],\n                        name = target,mode = \"markers\",\n                        marker = dict(color = color,\n                                      line = dict(width = .5),\n                                      symbol =  \"diamond-open\"),\n                        text = (\"Customer Id : \" + \n                                pca_data[pca_data[\"Churn\"] == target]['customerID'])\n                       )\n    return tracer\n\nlayout = go.Layout(dict(title = \"Visualising data with principal components\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"principal component 1\",\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"principal component 2\",\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        height = 600\n                       )\n                  )\ntrace1 = pca_scatter(\"Churn\",'red')\ntrace2 = pca_scatter(\"Not Churn\",'royalblue')\ndata = [trace2,trace1]\nfig = go.Figure(data=data,layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1eb10f28bd58e6e994131d31e27aa7181babc8ec"},"cell_type":"markdown","source":"pca를 그리는 과정과 그래프.\n\n##3.10. Binary variables distribution in customer attrition(Radar Chart)"},{"metadata":{"trusted":true,"_uuid":"e10163ae5bc7fb1536c9aafa73a04f7c7dfc642d"},"cell_type":"code","source":"bi_cs=tel.nunique()[tel.nunique()==2].keys()\ndat_rad=tel[bi_cs]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2df61ef7e08f5efa008d2a5a369a326f62457075"},"cell_type":"markdown","source":"레이더차트를 만들기 위한 과정이다. \nbinary 변수들을 뽑아다가 dat_rad 객체에 넣었다."},{"metadata":{"trusted":true,"_uuid":"4a403d8d2258d5fd560ec1805e84b29e31a5f137"},"cell_type":"code","source":"def plot_radar(df,aggregate,title) :\n    data_frame = df[df[\"Churn\"] == aggregate] \n    data_frame_x = data_frame[bi_cs].sum().reset_index()\n    data_frame_x.columns  = [\"feature\",\"yes\"]\n    data_frame_x[\"no\"]    = data_frame.shape[0]  - data_frame_x[\"yes\"]\n    data_frame_x  = data_frame_x[data_frame_x[\"feature\"] != \"Churn\"]\n    \n    #count of 1's(yes)\n    trace1 = go.Scatterpolar(r = data_frame_x[\"yes\"].values.tolist(),\n                             theta = data_frame_x[\"feature\"].tolist(),\n                             fill  = \"toself\",name = \"count of 1's\",\n                             mode = \"markers+lines\",\n                             marker = dict(size = 5)\n                            )\n    #count of 0's(No)\n    trace2 = go.Scatterpolar(r = data_frame_x[\"no\"].values.tolist(),\n                             theta = data_frame_x[\"feature\"].tolist(),\n                             fill  = \"toself\",name = \"count of 0's\",\n                             mode = \"markers+lines\",\n                             marker = dict(size = 5)\n                            ) \n    layout = go.Layout(dict(polar = dict(radialaxis = dict(visible = True,\n                                                           side = \"counterclockwise\",\n                                                           showline = True,\n                                                           linewidth = 2,\n                                                           tickwidth = 2,\n                                                           gridcolor = \"white\",\n                                                           gridwidth = 2),\n                                         angularaxis = dict(tickfont = dict(size = 10),\n                                                            layer = \"below traces\"\n                                                           ),\n                                         bgcolor  = \"rgb(243,243,243)\",\n                                        ),\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            title = title,height = 700))\n    \n    data = [trace2,trace1]\n    fig = go.Figure(data=data,layout=layout)\n    py.iplot(fig)\nplot_radar(dat_rad,1,\"Churn -  Customers\")\nplot_radar(dat_rad,0,\"Non Churn - Customers\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"528ba28d901cce33761e78d6f8677e3e830f5b15","trusted":true},"cell_type":"markdown","source":"레이더 코드 짜는 과정인데.\n함수인 plot_radar에 매개변수 df, aggregate, title을 씀.\n\n다시한번 말하지만 얘넨 나중에 plot_radar함수를 불러오면 (df, aggregate, title)순으로 집어넣어서 함수를 실행시키는 거임.\n\n코드를 좀 더 알기 쉽게 뜯어보자."},{"metadata":{"trusted":true,"_uuid":"af76acce597469ebf529edfd46c47f137d8fcb58"},"cell_type":"code","source":"data_frame=tel[tel['Churn']==1]\ndata_frame","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5035bd9a2842836b45ca57f1970919f8e940ff6"},"cell_type":"markdown","source":"여기엔 매개변수 df가 아니라 우리가 직접적으로 쓸 tel을 넣어줬다.\n그리고 Churn과 같은 값을 지닐 aggregate안에 들어갈 숫자가 1인 친구들을 나타낸 것이다."},{"metadata":{"_uuid":"1f61aae44bcfbc527e1d4d96d3bf85e807d1b3c2","trusted":true},"cell_type":"code","source":"data_frame_x=data_frame[bi_cs].sum().reset_index()\ndata_frame_x","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a5ddc1e726eb331576cc82edaa8cce9e7c6bdc4a"},"cell_type":"markdown","source":"살펴보자면, 각 열마다 0과 1로 표시되어 있는건 알 수 있는데, 이걸 sum함수를 취해줘서 각 열의 합을 구한것. 즉 1의 갯수를 구한 것과 같다."},{"metadata":{"_uuid":"8cc9ffb790e97ace26129c9274604f598c81795b","trusted":true},"cell_type":"code","source":"data_frame_x.columns=['feature','yes']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"913c32fd2ca14ae916bfcbb3c1947ae5fc9baa6f"},"cell_type":"markdown","source":"위의 열 명을 index는 feature로 0은 yes로 바꾼 것. "},{"metadata":{"_uuid":"586ac358cdd824a2b4baec9e6603470e21f8fed4","trusted":true},"cell_type":"code","source":"data_frame_x['no']=data_frame.shape[0]-data_frame_x['yes']\ndata_frame_x['no']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c8fca975b75173479a26c62f5fb97dc5f6ffdf6d"},"cell_type":"markdown","source":"shape[0]은 행을 뜻하고, yes를 제외한 나머지들을 불러와서 no로 지정해줬다고 생각하면 됨."},{"metadata":{"_uuid":"5ecccc96c2c04b92e9ea4d086dd1e0b42d19c5ba","trusted":true},"cell_type":"code","source":"data_frame_x=data_frame_x[data_frame_x['feature']!='Churn']\ndata_frame_x","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"721110922858fcc899336852b80abedc668dba63"},"cell_type":"markdown","source":"그냥 Churn을 없애주기 위한 작업인데, 왜 저렇게 적었는지 모르겠음.\nfeature들 중에 Churn이 아닌 애들만 남겨놓음.\n\n나머진 계속하던 trace와 layout, 그림으로 형상화 해주는 작업이니 pass\n\n#5. Model Building\n##5.1. Baseline Model"},{"metadata":{"_uuid":"500a0e00136d8d43a4e6c7fd4dfc3cce490bf752","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve,scorer\nfrom sklearn.metrics import f1_score\nimport statsmodels.api as sm\nfrom sklearn.metrics import precision_score,recall_score\nfrom yellowbrick.classifier import DiscriminationThreshold","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b616b75f4bbbeecb354b75a89c33ef6914dd769a"},"cell_type":"markdown","source":"이제 모델링을 할꺼임. 여기서 모델이란, 분석하고 예측을 해주는 친구를 말함. \n\n우리가 여태 했던 작업들은 고객이탈에 관련된 자료들을 봤었는데, 그 친구들(feature)들을 모아서 특정한 계산과 알고리즘을 이용하여 고객이탈(target)을 예측하는 것임.\n\n그 특정한 계산이나 알고리즘에 따라 여러 모델들이 있는데 이것들을 하나하나 비교해가면서 고객이탈을 제일 잘하는 친구를 찾는거임.\n\n위의 from import같은 것들은 모델링 작업을 위한 라이브러리를 불러온 것. "},{"metadata":{"trusted":true,"_uuid":"3cef3045a7853f35abcfd02a587e28453a2ab9af"},"cell_type":"code","source":"train,test=train_test_split(tel,test_size=.25, random_state=111)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"43f540f2a3e66d8b69ad169f8697531390fec5bd"},"cell_type":"markdown","source":"전체 데이터 자료를 train, test셋으로 나눌거임. 왜 이런짓을 하냐면 우리가 목표로 하는건 고객이탈을 예측하는 것인데, \n\n어떤 친구들이 고객이탈을 하는지 미리 알고 분류를 하면 매우 쉬울 것. 답을 알고 문제를 푸는 것이나 같은 것.\n\n그래서 우리는 train셋과 test셋으로 나눠 train친구는 고객이탈 예측을 학습을 시키는 용도(공부용)이고 test셋은 블라인드로 가지고 있다가 시험을 치는 용도.\n\n위 코드를 보면 train, test란 객체 안에 train_test_split이란 함수를 써서 \ntel<- 처음에 지정해놓은 전체 데이터를 얘기한다.\n\ntest_size=.25<- 테스트셋의 크기임. 그러면 train셋은 자동으로 나뉨. 25%를 테스트셋으로, 75%를 train셋으로 가져갔다. train_size로 나눠도 됨. \n\nrandom_state는 이 train_test_split이란 친구는 랜덤하게 전체데이터를 나누는건데 번호를 입력해줘서 하나의 상황을 지정해줬다.\n\n이걸 지정해주지 않으면 매번 train_test 셋이 바뀌어서 정확도나 여러 수치들이 매번 다르게 나온다.\n\n"},{"metadata":{"trusted":true,"_uuid":"15ef892c2810d542e3ea6a8b88e216cc03d13689"},"cell_type":"code","source":"cols=[i for i in tel.columns if i not in Id_col + target_col]\ntrain_X=train[cols]\ntrain_Y=train[target_col]\ntest_X=test[cols]\ntest_Y=test[target_col]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2bf00143b57b8cda16e0e2d6fb9b683f80dea34d"},"cell_type":"markdown","source":"train과 test를 나눠줬고, cols에 target(churn),과 id를 뺀 feature를 넣어줬다.\n\nID를 빼는 이유는 예측할 때 어떠한 의미도 가지고 있지 않기 때문.\n'2057'이란 숫자ID만 보고 이 사람이 어떤걸 할 것이다 예측은 불가능.\n\ntrain_X, test_X에 cols를, train_Y, test_Y에 target_col을 넣어준다.\n\n시험을 예로 들자면 train은 모의고사임. 모의고사를 train_X(feature들)로 시험 문제를 풀고 train_Y(target)는 답을 맞추는 것.  \n\nX는 FEATURE고, Y는 TARGET임. \n\n이제 모의고사를 봤으면 수능을 봐야함. 그건 test임. \n\ntest_X로 시험문제를 풀고 test_Y로 답을 맞추는 것."},{"metadata":{"_uuid":"0642e928cb0977ed8dbe3ed889b41a4c6f242bc6","trusted":true},"cell_type":"code","source":"cols    = [i for i in tel.columns if i not in Id_col + target_col]\ntrain_X = train[cols]\ntrain_Y = train[target_col]\ntest_X  = test[cols]\ntest_Y  = test[target_col]\n\n#Function attributes\n#dataframe     - processed dataframe\n#Algorithm     - Algorithm used \n#training_x    - predictor variables dataframe(training)\n#testing_x     - predictor variables dataframe(testing)\n#training_y    - target variable(training)\n#training_y    - target variable(testing)\n#cf - [\"coefficients\",\"features\"](cooefficients for logistic \n                                 #regression,features for tree based models)\n\n#threshold_plot - if True returns threshold plot for model\n    \ndef telecom_churn_prediction(algorithm,training_x,testing_x,\n                             training_y,testing_y,cols,cf,threshold_plot) :\n    \n    #model\n    algorithm.fit(training_x,training_y)\n    predictions   = algorithm.predict(testing_x)\n    probabilities = algorithm.predict_proba(testing_x)\n    #coeffs\n    if   cf == \"coefficients\" :\n        coefficients  = pd.DataFrame(algorithm.coef_.ravel())\n    elif cf == \"features\" :\n        coefficients  = pd.DataFrame(algorithm.feature_importances_)\n        \n    column_df     = pd.DataFrame(cols)\n    coef_sumry    = (pd.merge(coefficients,column_df,left_index= True,\n                              right_index= True, how = \"left\"))\n    coef_sumry.columns = [\"coefficients\",\"features\"]\n    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n    \n    print (algorithm)\n    print (\"\\n Classification report : \\n\",classification_report(testing_y,predictions))\n    print (\"Accuracy   Score : \",accuracy_score(testing_y,predictions))\n    #confusion matrix\n    conf_matrix = confusion_matrix(testing_y,predictions)\n    #roc_auc_score\n    model_roc_auc = roc_auc_score(testing_y,predictions) \n    print (\"Area under curve : \",model_roc_auc,\"\\n\")\n    fpr,tpr,thresholds = roc_curve(testing_y,probabilities[:,1])\n    \n    #plot confusion matrix\n    trace1 = go.Heatmap(z = conf_matrix ,\n                        x = [\"Not churn\",\"Churn\"],\n                        y = [\"Not churn\",\"Churn\"],\n                        showscale  = False,colorscale = \"Picnic\",\n                        name = \"matrix\")\n    \n    #plot roc curve\n    trace2 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2))\n    trace3 = go.Scatter(x = [0,1],y=[0,1],\n                        line = dict(color = ('rgb(205, 12, 24)'),width = 2,\n                        dash = 'dot'))\n    \n    #plot coeffs\n    trace4 = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n                    name = \"coefficients\",\n                    marker = dict(color = coef_sumry[\"coefficients\"],\n                                  colorscale = \"Picnic\",\n                                  line = dict(width = .6,color = \"black\")))\n    \n    #subplots\n    fig = tls.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n                            subplot_titles=('Confusion Matrix',\n                                            'Receiver operating characteristic',\n                                            'Feature Importances'))\n    \n    fig.append_trace(trace1,1,1)\n    fig.append_trace(trace2,1,2)\n    fig.append_trace(trace3,1,2)\n    fig.append_trace(trace4,2,1)\n    \n    fig['layout'].update(showlegend=False, title=\"Model performance\" ,\n                         autosize = False,height = 900,width = 800,\n                         plot_bgcolor = 'rgba(240,240,240, 0.95)',\n                         paper_bgcolor = 'rgba(240,240,240, 0.95)',\n                         margin = dict(b = 195))\n    fig[\"layout\"][\"xaxis2\"].update(dict(title = \"false positive rate\"))\n    fig[\"layout\"][\"yaxis2\"].update(dict(title = \"true positive rate\"))\n    fig[\"layout\"][\"xaxis3\"].update(dict(showgrid = True,tickfont = dict(size = 10),\n                                        tickangle = 90))\n    py.iplot(fig)\n    \n    if threshold_plot == True : \n        visualizer = DiscriminationThreshold(algorithm)\n        visualizer.fit(training_x,training_y)\n        visualizer.poof()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1dd20cb1fb2b29814c9e57859b3db5af9f2830ae"},"cell_type":"markdown","source":"굉장히 코드가 길다. \n\n알고리즘을 평가하기 위한 코드+ 그 평가를 시각화를 위한 코드다. 여러여러 평가지표가 있는데, 코드를 보면서 하나씩 들여다보자.\n\n~~~\ndef telecom_churn_prediction(algorithm,training_x,testing_x,\n                             training_y,testing_y,cols,cf,threshold_plot):\n~~~\n함수 정의만 봐도 굉장히 많은 매개변수들이 들어가 있다. 나올때마다 하나씩 설명.\n\n~~~\n    algorithm.fit(training_x,training_y)\n~~~\n아까 예측하기 위한 여러 모델들을 알고리즘이라고 여기서 표현했다. 이 알고리즘을 적용시키는 걸 fit이라하고 괄호 안에는 train_x, train_y가 들어간다. .fit은 training_x와 training_y로 공부를 시킨다.  정도로 생각하면 좋다.\n\n~~~\n    predictions = algorithm.predict(testing_x)\n    probabilities = algorithm.predict_proba(testing_x)\n~~~\n시험공부를 했으니 수능을 칠 차례. 적용시킨 알고리즘으로 testing_x를 예측 한다.\nprediction은 결과값, proba를 붙이면 몇%로 예측했는지 나온다.\n\n~~~\nif   cf == \"coefficients\" :\n        coefficients  = pd.DataFrame(algorithm.coef_.ravel())\n    elif cf == \"features\" :\n        coefficients  = pd.DataFrame(algorithm.feature_importances_)\n~~~\n이건 feature들이 얼마나 높은 중요도를 가지고 있는지 보고싶은 거다.\n\n중요도란 분류할 때 feature가 가지는 영향력을 끼치는지를 말한다.\n여기서는 고객이탈에 영향을 끼치는 정도.\n\nlogistic모델에선 coefficients로 중요도 표현을 하고, feature_importances_는 tree모델들이 갖는 중요도 이름이다. 모델들에 대해선 나중에 설명.\n\n나온 코드중 .ravel()은 다차원을 평평하게 만들어주는 역할을 하는데 [[1,1],[2,2]]요런식으로 되어있는 애들을 [1,1,2,2]이렇게 만들어준다고 생각하면 된다.\n\n~~~\n    column_df     = pd.DataFrame(cols)\n    coef_sumry    = (pd.merge(coefficients,column_df,left_index= True,\n                              right_index= True, how = \"left\"))\n    coef_sumry.columns = [\"coefficients\",\"features\"]\n    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n~~~\n이전에 다 설명했던 내용들이므로 패스.\n\n~~~\n    print (algorithm)\n    print (\"\\n Classification report : \\n\",classification_report(testing_y,predictions))\n    print (\"Accuracy   Score : \",accuracy_score(testing_y,predictions))\n    #confusion matrix\n    conf_matrix = confusion_matrix(testing_y,predictions)\n    #roc_auc_score\n    model_roc_auc = roc_auc_score(testing_y,predictions) \n    print (\"Area under curve : \",model_roc_auc,\"\\n\")\n    fpr,tpr,thresholds = roc_curve(testing_y,probabilities[:,1])\n~~~\nprint함수는 다 알테고 \\n같은 경우엔 줄바꿈 코드이다.\n\nclassification_report(testing_y<-실제 target값, prediction<-test_x를 통해 예측한 값)이란 precision , recall, f1-score, support 값을 보여준다. 아래의 그림처럼 나오는 친구가 classification_report.\n![2](https://i2.wp.com/kgracia44.github.io/images/project_5/mod2_classReport.png?w=696)\n![11](https://cdn-images-1.medium.com/max/1600/1*Z54JgbS4DUwWSknhDCvNTQ.png)\n\n위의 그림은 confusion matrix라는 친구로 설명을 위해 가져왔다.\n\nprecision(정확도)는 TP/(TP+FP)를 뜻하고 긍정이라고 예측한 값 중 실제로 긍정인 값.\n\nrecall는 TP/(TP+FN)을 뜻하고 실제 긍정 값들 중 긍정이라고 예측한 값이다. \n\nf1-score는 좀 더 복잡한데, F1=2*(precision * recall)/(precision+recall)을 뜻한다.\n\nsupport는 실제 값들의 숫자다. 위에선 실제로 0이 543개, 1이 342개 있다는 소리다.\n\nmicro, macro, weighted avg가 나오긴 하는데 크게 중요한가..? 싶은데 알고 싶다면 물어볼 것.\n\n~~~\nprint (\"Accuracy   Score : \",accuracy_score(testing_y,predictions))\n~~~\naccuracy_score는 간단하다. 실제값과 예측값을 단순히 비교한 값. 전체 개수중 실제로 맞춘 개수.\n위의 confusion matrix로 본다면 (tp+tn)/전체개수.\n\nconfusion_matrix는 패스\n\n~~~\nmodel_roc_auc = roc_auc_score(testing_y,predictions) \n    print (\"Area under curve : \",model_roc_auc,\"\\n\")\n~~~\nroc_auc_socre는 roc커브의 개념을 알아야 한다.\nFPR과 TPR을 각각 x,y축으로 놓은 그래프를 ROC커브라고 하는데, \n\n여기서 TPR은 많은 용어로 표시된다. 민감도, Sensitive, 재현률으로 표기된다. 그래서 맨날 헷갈렸는데, 아까 말했던 classification_report에서의 recall(재현률)이고 실제로 긍정값 중 긍정으로 예측한 값을 말한다.  \n\nFPR은 1-특이도(Specificity)를 뜻하고 여기서 특이도(Specificity)란 실제 부정값 중 부정으로 예측한 값을 뜻하고, confusion matrix에서 보면 TN/(TN+FP), FPR은 그래서 실제 부정값 중 긍정으로 예측한 값을 말한다 FP/(TN+FP).\n\nFPR이란 잘못된 긍정 예측비율, TPR은 실제 긍정 예측비율 정도로 생각하면 좋겠다. \n\n![ROC](https://t1.daumcdn.net/cfile/tistory/262E8E3F544837AD27)\n\n![ROC2](http://www.cbgstat.com/method_ROC_curve/images/ROC_curve_Snap8.gif)\n이게 ROC커브 그래프이고, FPR이 낮고 TPR이 높을 때  즉 그래프가 왼쪽위로 향할 수록, 좋은 모델이다. \n\n다시 설명하자면, reference Line을 볼 수 있는데 우리가 동전을 눈감고 던지면 50:50으로 앞뒷면이 나올 것이다. TPR과 FPR이 반반.  \n\n그 라인이 reference이고, 우리는 TPR이 FPR보다 더 좋게 나왔으면 하는거다. 예측률이 높다는 거니까. \n\n그래서 왼쪽위로 높게 올라간 그래프가 좋은 예측모델이며, reference line보다 더 아래로 간건 의미가 없다고 하는 것.\n\n다시 본론으로 들어와서, roc_auc_score는 이 roc커브에서 커브 아래, 즉 면적을 평가한 것이며 이 면적을 AUC(The Area Under an ROC CURVE)라고 한다. \n\n면적이 높을 수록 더 좋은 모델이고, ROC커브를 생각해 보면 왼쪽위로 올라갈 수록 더 넓은 면적을 나타낸다.\n\n위의 그래프들은 깔끔하게 그려져있지만 여러 모델을 쓰다보면 아래의 그래프마냥 굉장히 커브가 요상하게 그려져서 비교할때 면적을 쓴다.\n\n![ROC4](https://t1.daumcdn.net/cfile/tistory/99ABC43359E629C83C)\n\n~~~\nfpr,tpr,thresholds = roc_curve(testing_y,probabilities[:,1])\n~~~\nsckitlearn의 함수에 roc_curve라는 친구가 있다. 얘는 실제값과 예측값의 확률값을 비교하여 fpr과 tpr, thresholds를 가지고 있다. 그 값들을 각각 객체에 넣어주겠다는 것.\n\nfpr과 tpr은 위에서 설명했고 thresholds는 임계값인데, 우리가 실제값과 예측값의 확률값으로 ROC커브를 그렸잖음? 그래서 그 확률값으로 예측을 긍정으로 분류할지 부정으로 분류할지의 기준값임. \n\n이 임계값이 작아지면 긍정으로 분류하는게 많아짐. 그래서 전체 긍정이라고 분류하는건 높아질텐데, TPR 실제 긍정 예측비율이 올라갈테고, FPR 잘못된 긍정 예측비율 또한 올라갈거임.\n\n이제부터 ROC커브 밑 부분은 다 산점도를 그리기 위함이고, 값을 넣은 친구들을 보면 trace1은 confusion_matrix, trace2는 ROC커브 trace3은 ROC커브의 [0,0]과 [1,1]값을 찍어주기 위한 녀석(ROC커브보면 0,0과 1,1에 점이 찍혀있음.), trace4는 feature 중요도이다. \n\n\n~~~\nfig.append_trace(trace1,1,1)\nfig.append_trace(trace2,1,2)\nfig.append_trace(trace3,1,2)\nfig.append_trace(trace4,2,1)\n~~~\n을 보면 fig에 trace를 입력해 주고 뒤에 있는 숫자들은 (trace1<-trace(나타낼 그래프),1<-행 위치값,1<-열 위치값) 이런 형식이다.\n\n~~~\nfig['layout'].update(showlegend=False, title=\"Model performance\" ,\n                         autosize = False,height = 900,width = 800,\n                         plot_bgcolor = 'rgba(240,240,240, 0.95)',\n                         paper_bgcolor = 'rgba(240,240,240, 0.95)',\n                         margin = dict(b = 195))\n    fig[\"layout\"][\"xaxis2\"].update(dict(title = \"false positive rate\"))\n    fig[\"layout\"][\"yaxis2\"].update(dict(title = \"true positive rate\"))\n    fig[\"layout\"][\"xaxis3\"].update(dict(showgrid = True,tickfont = dict(size = 10),\n                                        tickangle = 90))\n~~~\nlayout 설정. update는 새로운 정보를 입력해 주는 것. showlegend는 범례 표시를 할 것인지.  나머진 이전 내용과 다 같다.\n\n~~~\npy.iplot(fig)\n~~~\n그림 띄우는 친구.\n\n~~~\nif threshold_plot == True : \n    visualizer = DiscriminationThreshold(algorithm)\n    visualizer.fit(training_x,training_y)\n    visualizer.poof()\n        \n~~~\n\n~~~\ndef telecom_churn_prediction(algorithm,training_x,testing_x,\n                             training_y,testing_y,cols,cf,threshold_plot):\n~~~\nthreshold_plot이란 모델마다 threshhold_plot이 존재하기도 안하기도 하는데, threshold_plot == True는 존재할 때를 의미한다.\n\n존재한다면 Discrimination Threshold라는 함수를 쓸 수 있는데 이 함수의 주의점은 binary일때만 쓰는 친구다. \n\nprecision,recall,f1 score, threshold를 보여준다.\n\npoof()는 그림을 그려주는 친구. 이미지 띄우는 애."},{"metadata":{"trusted":true,"_uuid":"4c80ed1d93830c9cd6b0f1c547f59874e9c635a8"},"cell_type":"code","source":"logit  = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n\ntelecom_churn_prediction(logit,train_X,test_X,train_Y,test_Y,\n                         cols,\"coefficients\",threshold_plot = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4d2aaf6b7965707f96627393494e8d1d7af6384"},"cell_type":"markdown","source":"LogisticRegression은 로지스틱 회귀분석이다. Churn과 No Churn을 구분하기 위한 첫 모델인데, 이를 알려면 선형회귀분석부터 알아야 한다.\n\n선형회귀분석은 모두가 봤듯이 y=ax+b의 모양을 가진다. 흔히들 아는 일차함수의 모형이고, 직선을 의미한다. \n\n로지스틱은 이걸 y값을 확률로 변환하여 생각한다.  A와 B로 분류를 한다면 0.5이상은 A, 0.5이하면 B로 분류하게 만든다. \n\n![logistic](http://www.jidum.com/upload/ckeditor/2018/01/20180123111132718.png)\n여러여러 과정을 통해 위의 그래프에 써진 E(y)처럼 y를 확률값으로 바꿔주는데, 자세히 알아도 쓸모 없다고 생각하여 대강의 흐름만 파악하고 생략한다.\n\n이제 코드를 들여다보자면, \n~~~\nlogit  = LogisticRegression(C=1.0,\n~~~\nC는 정규화의 강도정도를 얘기한다. 오버피팅(Overfitting)을 막기위해 정규화를 할 때 쓰는 값으로 DEFAULT값은 1이고, 값이 적을수록 강한 정규화를 한다고 함. \n\n처음에 말했듯이, 큰 값이 있으면 컴퓨터는 거기에 관심이 쏠리게 되어있다. 그래서 과도하게 그쪽으로 편중된 결과값이 나오고, 이건 좋지 못한 모델이라고 할 수 있다.\n\n여기서 오버피팅이란 과적합이라고도 하는데, 머신러닝 예측에 관해서 굉장히 중요한 요소이다.\n\n![overfitting](https://i.stack.imgur.com/t0zit.png)\n위의 그림을 보면 언더피팅, 적절한 모양, 오버피팅에 대해서 나와있다. \n\n우리가 train과 test셋으로 나누는 이유도 여기서 찾을 수 있다.\n\n예측모델이 과도하게 답을 찾아버리면, 새로운 문제가 들어와 버렸을 땐 해결하지 못한다. \n마치 우리가 답을 외우고 공부를 하면 어느정돈 성적이 나오지만 처음보는 유형엔 대처를 못하는 거 처럼.\n\n언더피팅은 데이터가 적거나 feature가 적을 때 나올 수 있는 현상이다. 답을 찾아가지 못한다.\n반면 오버피팅은 과도하게 답을 찾아간다.\n\n언더피팅은 feature수를 늘리고 데이터를 늘리고 하는 해결방법 오버피팅은 정규화나 feature수를 줄여주거나 등등의 방법을 택한다.\n\n~~~\n, class_weight=None\n~~~\n이건 각 클래스(여기선 Churn과 No Chrun을 클래스라 지칭한다)마다 weight(가중치)를 설정해줘서 클래스를 더 강조하는 역할을 하는데 defualt값은 None이고 이때 모든 클래스는 하나의 weight값을 가진다. \n\n뒤에도 다 수식적인 내용이고 복잡하니까 패스함. 설정해주고 수학적으로 똑똑해질순 있는데, 보통 계산을 컴퓨터에게 다 맡길 수 있음. 우리가 손으로 찾을 필요없이. 간략한 설명만 남기고 넘어가겠음.\n\n~~~\ndual=False, fit_intercept=True,intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n   penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False\n~~~\n대부분 수학적인 친구들이고 하면서 느끼는건데 이 사람은 정말 보여주는걸 좋아함. \n\ndefault값을 그냥 써준 정도 밖에 안된다. 모두 안써도 돌아가는 친구들. \n\n그나마 default가 아닌친구들을 보자면 n_jobs인데 이건 내 컴퓨터의 cpu core를 얼마나 쓸건지고, -1이면 모든 프로세서를 다 쓴다는 뜻.  \n\n~~~\ntelecom_churn_prediction(logit,train_X,test_X,train_Y,test_Y,\n                         cols,\"coefficients\",threshold_plot = True)\n~~~\n아까 설정해준 함수를 쓴 것. \n\n##5.2. Synthetic Minority Oversampling TEchnique (SMOTE)"},{"metadata":{"_uuid":"b8206815526a0e63628a8855223b6b7fb2416984","trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\ncols    = [i for i in tel.columns if i not in Id_col+target_col]\n\nsmote_X = tel[cols]\nsmote_Y = tel[target_col]\n\n#Split train and test data\nsmote_train_X,smote_test_X,smote_train_Y,smote_test_Y = train_test_split(smote_X,smote_Y,\n                                                                         test_size = .25 ,\n                                                                         random_state = 111)\n\n#oversampling minority class using smote\nos = SMOTE(random_state = 0)\nos_smote_X,os_smote_Y = os.fit_sample(smote_train_X,smote_train_Y)\nos_smote_X = pd.DataFrame(data = os_smote_X,columns=cols)\nos_smote_Y = pd.DataFrame(data = os_smote_Y,columns=target_col)\n\nlogit_smote = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n\ntelecom_churn_prediction(logit_smote,os_smote_X,test_X,os_smote_Y,test_Y,\n                         cols,\"coefficients\",threshold_plot = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3904da46c445e0db25644323392778871c568840"},"cell_type":"markdown","source":"이제 기본적인 Logistic Regression에서 벗어나 좀 더 심화된 과정을 쓴다. \n~~~\nfrom imblearn.over_sampling import SMOTE\n~~~\n먼저 라이브러리를 불러오는데 SMOTE이라고 써져있는 친구임.\n\n위에도 써져있지만 SMOTE은 Synthetic Minority Oversampling TEchnique을 뜻함.\n\n왜 오버샘플링을 하는가?는 우리가 만약에 10000명이 있는 집단이 있고 10명이 남자라 하자. \n컴퓨터에게 이들의 정보를 주고 분류해내라 하면 다 여자로 분류할 것임. 남녀를 구별할 엄청 특징적인 FEATURE를 주지 않는 이상. 모두 여자로 분류해도 무려 99.9%의 정확도를 가지고 있음 컴퓨터는. \n\n극단적인 예였지만, 한쪽으로 예측하는 것을 방지하고 예측률을 높이기 위한 하나의 방법으로 오버 샘플링을 한다. 마구잡이로 오버샘플링을 하게 되면 중복된 값이 많아지고 좋지 못한데이터가 된다. 그래서 오버샘플링의 방법 중 하나인 SMOTE를 하는 것. \n\nSMOTE을 설명하기 위해 우리는 KNN이라는 k-Nearest-Neighber를 먼저 알아보자. \n\nk-최근접 이웃이라고도 하는데 이 친구는 뒤에서도 나올거지만 정말 단순한 알고리즘이다.\n\n블로그의 내용을 조금 베껴오자면, \n\n![knn](https://img1.daumcdn.net/thumb/R960x0/?fname=http%3A%2F%2Fcfile28.uf.tistory.com%2Fimage%2F23227D4358C791081D4555)\n![knn1](https://img1.daumcdn.net/thumb/R960x0/?fname=http%3A%2F%2Fcfile7.uf.tistory.com%2Fimage%2F2539894358C791092FA552)\n\n이런 데이터가 있다고 치자. A~F까지의 데이터가 원래 있었고 그룹(class)이 O와 ▲로 나뉘어져 있었다. 거기서 새로운 데이터인 N이라는 친구가 들어온 것이다.\n\n![KKN](https://img1.daumcdn.net/thumb/R960x0/?fname=http%3A%2F%2Fcfile1.uf.tistory.com%2Fimage%2F216CEE4358C791092166EE)\n여기서 k값이 들어간다. k값이 1이면 1-Nearest-Neighber로 하나의 거리가 가장 가까운 친구를 찾고,그 친구의 그룹에 들어가게 된다. \n\n거리를 구하는 것은 아주 쉽다. 점 사이의 거리. 여기선 X와 Y가 FEATURE가 되는 것이고, 이 FEATURE들로 거리를 구하는 것이다. \n\n하지만 거리를 구하는 방법에는 여러가지가 있다. 이는 안봐도 좋은 내용이고 혼자의 공부를 위해서 밑에서 정리하던가 생략하던가 할 것.\n\n위의 그림에서, N은 C랑 가장 가까운 사이이면서, O로 분류가 되게 된다.\n\n![knn2](https://img1.daumcdn.net/thumb/R960x0/?fname=http%3A%2F%2Fcfile7.uf.tistory.com%2Fimage%2F2749594358C7910A067786)\n한번 더. 여기서 k가 3이면 3-Nearest-Neighber로 세번째까지 가까운 친구들을 찾고, 다수결에 의해 판단을 한다. \n\n위의 그림처럼 된다면 새로들어온 N은 ▲로 분류가 된다.\n\n![SMOTE](https://camo.githubusercontent.com/1e85918f840fd9c5cbe78b0fcf0a40377f08dd96/687474703a2f2f692e696d6775722e636f6d2f55515a30354e302e6a7067)\n위의 그림은 SMOTE을 그림으로 그려줬다.\n\n아까 설명했던 예로 설명을 좀 더 하자면, 첫번째로 대다수를 차지하는 여자를 지워버린다. 그리고 설정에 따라 몇개의 가까운 이웃들을 찾아주고, 이 이웃들 사이에 위치할 수 있는 값들을 가진 남자들을 늘려준다.\n\n코드를 보자. \n\n~~~\ncols    = [i for i in tel.columns if i not in Id_col+target_col]\n\nsmote_X = tel[cols]\nsmote_Y = tel[target_col]\n\n#Split train and test data\nsmote_train_X,smote_test_X,smote_train_Y,smote_test_Y = train_test_split(smote_X,smote_Y,\n                                                                         test_size = .25 ,\n                                                                         random_state = 111)\n~~~\n여기까지는 비슷한 내용이다. 단지 train_X,train_Y에서 smote_train_X,smote_train_Y 이런식으로 바꿔준 것 뿐이다.\n\n~~~\nos = SMOTE(random_state = 0)\nos_smote_X,os_smote_Y = os.fit_sample(smote_train_X,smote_train_Y)\nos_smote_X = pd.DataFrame(data = os_smote_X,columns=cols)\nos_smote_Y = pd.DataFrame(data = os_smote_Y,columns=target_col)\n~~~\nSMOTE을 적용시켜주는 과정이다. default로 이웃은 5개로 설정되어져 있고, 만드는 방법은 자동, random_state는 항상 같은 오버샘플링을 해주기 위함이다. 이외 여러 옵션들이 있지만 나머진 default값으로 했다.\n\n적용시키고 데이터프레임화 시켜주었다.\n\n~~~\nlogit_smote = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n\ntelecom_churn_prediction(logit_smote,os_smote_X,test_X,os_smote_Y,test_Y,\n                         cols,\"coefficients\",threshold_plot = True)\n~~~\n\n다시말하지만 이는 로지스틱의 심화과정이라고 생각하면 된다. 데이터 구조를 바꾸기 위해 SMOTE해주고 로지스틱 회귀분석에 넣어줬다.\n\n##5.3. Recursive Feature Elimination"},{"metadata":{"_uuid":"bbeaf5a87de65d2184cd99eb2d5d094922c1e477","trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\n\nlogit = LogisticRegression()\n\nrfe = RFE(logit,10)\nrfe = rfe.fit(os_smote_X,os_smote_Y.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6b3514f32010b69fcb84d2a2485698e2e188f9c"},"cell_type":"markdown","source":"RFE란 위에서 써져있듯이 Recursive Feature Elimination인데, 재귀적 ..? 특성.. 제거..? 영어가 짧아서 잘 모르겠다.\n\n개념적인 부분은 우리의 많던 Feature를 컴퓨터님이 알아서 줄여주신다는데에 있다.\n\nlogistic 처음에 구했던 특성 중요도(coefficient or feature importance)가 큰 순으로 뽑아내고 영향이 미비한 친구들은 지워버려서 오버피팅을 막고 정확도를 올리기 위함이다.\n\n코드로 보자면,\n\n~~~\nfrom sklearn.feature_selection import RFE\n\nlogit = LogisticRegression()\n~~~\n일단 라이브러리를 불러와준 후, 모델인 로지스틱 리그레션은 logit이란 객체에 넣어주었다.\n\n~~~\nrfe = RFE(logit,10)\n~~~\nrfe란 객체에 RFE함수를 불러와줬고, logit(Logistic Regression)으로 특성 중요도를 계산해서 feature 10개를 뽑아내라. 라는 말임. \n\n10이란 숫자를 적지 않는다면, 전체 feature를 반으로 줄여준다고 한다.\n\n~~~\nrfe = rfe.fit(os_smote_X,os_smote_Y.values.ravel())\n~~~\nfit을 시켜주는데, 아까 오버샘플링 했던 값들을 넣어준다. \n\n왜 Y의 경우 os_smote_Y.values.ravel()로 하나 궁금해서 그냥 돌려봤더니 warning이 뜨면서 차원을 평평하게 만들어주라고 한다. \n\n그래서 Y의 경우 .values를 써서 값들을 꺼내준뒤 ravle()로 차원을 평평하게 해준다.(이전에 설명했음)\n\n안해도 상관없이 돌아가긴 한다."},{"metadata":{"_uuid":"bddf7824e39b1f2d7b501470e3fe8cd680f6102a","trusted":true},"cell_type":"code","source":"idc_rfe = pd.DataFrame({\"rfe_support\" :rfe.support_,\n                       \"columns\" : [i for i in tel.columns if i not in Id_col + target_col],\n                       \"ranking\" : rfe.ranking_,\n                      })\ncols = idc_rfe[idc_rfe[\"rfe_support\"] == True][\"columns\"].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1763aecd6abc3e88c45fe000152a14d301f24b9"},"cell_type":"code","source":"rfe.support_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b2fa5c0637358534b1d81e38b8fe0de6fcdc6ef"},"cell_type":"code","source":"rfe.ranking_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a84f09bdb724274d3f3a91d69faf9fd41dc7043b"},"cell_type":"code","source":"cols = idc_rfe[idc_rfe[\"rfe_support\"] == True][\"columns\"].tolist()\ncols","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6715030a57e8f5979560b8cc9da18fd70aede25f"},"cell_type":"markdown","source":"이제 순위를 매긴 feature 친구들만 로지스틱 회귀분석에 넣고자 한다.\n\nidc_rfe엔 rfe.support_는 위에 나온 친구들처럼 10개 중 뽑혔는지 뽑히지 않았는지를 True와 False로 표현한다.\n\nrfe.ranking_은 순위를 나타내며, 뽑힌 친구들은 모두 1로 표현된다.\n\n결국 뽑은 친구들을 열로 만들어주는 코드는 아래와 같다.\n~~~\ncols = idc_rfe[idc_rfe[\"rfe_support\"] == True][\"columns\"].tolist()\n~~~\n새로만든 idc_rfe라는 데이터 프레임에 rfe_support가 True값을 가진애들을 columns에서 데려와 리스트 형식으로 바꿔준 것이다. \n\n모두 어떤 친구들인지 실행해놔서 설명과 같이 보면 알기 쉬울듯."},{"metadata":{"trusted":true,"_uuid":"b50ede64bf4f29feb8baaf93a151b4a76bd5881c","scrolled":false},"cell_type":"code","source":"#separating train and test data\ntrain_rf_X = os_smote_X[cols]\ntrain_rf_Y = os_smote_Y\ntest_rf_X  = test[cols]\ntest_rf_Y  = test[target_col]\n\nlogit_rfe = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\n#applying model\ntelecom_churn_prediction(logit_rfe,train_rf_X,test_rf_X,train_rf_Y,test_rf_Y,\n                         cols,\"coefficients\",threshold_plot = True)\n\ntab_rk = ff.create_table(idc_rfe)\npy.iplot(tab_rk)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2caa134f4710c47cd17e99ae4d365605db2bb20"},"cell_type":"markdown","source":"이제 로지스틱 회귀분석에 진짜로 넣어주는 작업을 한다. \n\n똑같다. train, test로 나눠주는 작업, Logistic Regressor에 넣어주는 작업. \n\n다만 하나 다른점이 있다면\n~~~\ntab_rk = ff.create_table(idc_rfe)\npy.iplot(tab_rk)\n~~~\n이런 친구를 시각화 해줬다는건데, 아래의 코드는 그냥 시각화를 위함이고\n객체 tab_rk라는 곳에 ff라는 라이브러리를 불러와 create_table로 테이블을 만들었다.\n\n위의 시각화 자료중에 처음보는 테이블이 있는걸 알 수 있다. \n\n##5.4 Univariate Selection"},{"metadata":{"_uuid":"1195746964539a832417d66642ceb93919e85819","trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import SelectKBest\n\n#select columns\ncols = [i for i in tel.columns if i not in Id_col + target_col ]\n\n#dataframe with non negative values\ndf_x = df_tel_og[cols]\ndf_y = df_tel_og[target_col]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02013be2958010e2778c7d89bbc1341b182dc24c"},"cell_type":"markdown","source":"필요한 라이브러리를 넣어줬고. Univariate Selection이란 친구를 해줄거임. 아래와 같은 설명이 써져있다.\n\nFeature Extraction with Univariate Statistical Tests (Chi-squared for classification)\n\nuses the chi squared (chi^2) statistical test for non-negative features to select the best features\n\n카이제곱 검정을 통해서 하는데 수학적인거 제쳐두고 p-value값이 0.05보다 작으면 유의하다 !!! 이정도만 기억하면 좋을듯.\n\n아무튼 위에 코드들은 평상시 해주던 친구들과 크게 다르지 않음. x(feature)와 y(target)로 나눔."},{"metadata":{"_uuid":"fcb2629079f35aeb13ad9ebc84fe5cd8789569e4","trusted":true},"cell_type":"code","source":"select = SelectKBest(score_func = chi2,k = 3)\nfit    = select.fit(df_x,df_y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"338879db0ec0061608dea18c3a1590f997585a7c"},"cell_type":"markdown","source":"select란 객체에 SelectKBest란 함수를 쓴다. score_func은 점수를 매길때 어떤 친구를 사용할 건지고, 여기선 chi2로 카이제곱을 썼다. k=3은 이들 중 높은 것 세개를 뽑아내겠다는 뜻.\n\nfit으로 적용시켜준다.\n"},{"metadata":{"_uuid":"ea06da7b4c2736be456785e9efe0151f8e4cdf3a","trusted":true},"cell_type":"code","source":"print (\"scores\")\nprint (fit.scores_)\nprint (\"P - Values\")\nprint (fit.pvalues_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51cacd8ecdc3ca9f08f665be53ab23c87693cb59"},"cell_type":"markdown","source":"socres를 나오게 해줬고, P-Value값을 나오게 해줬다."},{"metadata":{"_uuid":"1f28feb125a41c95d0608abee8075ecc43bff650","trusted":true},"cell_type":"code","source":"score = pd.DataFrame({\"features\":cols,\"scores\":fit.scores_,\"p_values\":fit.pvalues_ })\nscore = score.sort_values(by = \"scores\" ,ascending =False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11e7eb6a5d3ce72b321e3808395f317f5d167a70"},"cell_type":"markdown","source":"이전에 했던 데이터 프레임 만드는 과정과 내림차순 방법."},{"metadata":{"_uuid":"4a8b8bf966371c0cc30faa2aca73841c93cf0d6e","trusted":true},"cell_type":"code","source":"score[\"feature_type\"] = np.where(score[\"features\"].isin(num_cols),\"Numerical\",\"Categorical\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e8a8718906ddb984bf04301c76ba10358d06e89"},"cell_type":"markdown","source":"np.where란 친구가 있는데, (조건, 조건값을 만족했을 때 반환값, 조건을 만족 못했을 때 반환값) 을 넣어 주는 함수이다.\n말이 좀 어려운데, if 랑 비슷한 느낌이다. 엑셀 if문이랑 비슷함.\n\n위의 코드에서 조건은 score['features']에 .isin이란 함수를 썼는데 .isin은 ()안에 있는 값을 가지고 있으면 True, 아니면 False를 반환한다. \n\nnum_cols라고 이이이전에 설정해 놓은 애있음. 얘는 수치형 변수들을 모아놓은 친구임.\n\n정리하자면 score['features']에/ .isin(num_cols) 수치형 변수라면/ 'Numerical'이라고/ 아니면 'Categorical'이라고 변환해 줘라. 이런 내용임."},{"metadata":{"_uuid":"1a8d628c627654f307eef70da963c5d22d816eaa","trusted":true},"cell_type":"code","source":"trace  = go.Scatter(x = score[score[\"feature_type\"] == \"Categorical\"][\"features\"],\n                    y = score[score[\"feature_type\"] == \"Categorical\"][\"scores\"],\n                    name = \"Categorial\",mode = \"lines+markers\",\n                    marker = dict(color = \"red\",\n                                  line = dict(width =1))\n                   )\n\ntrace1 = go.Bar(x = score[score[\"feature_type\"] == \"Numerical\"][\"features\"],\n                y = score[score[\"feature_type\"] == \"Numerical\"][\"scores\"],name = \"Numerical\",\n                marker = dict(color = \"royalblue\",\n                              line = dict(width =1)),\n                xaxis = \"x2\",yaxis = \"y2\"\n               )\nlayout = go.Layout(dict(title = \"Scores for Categorical & Numerical features\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     tickfont = dict(size =10),\n                                     domain=[0, 0.7],\n                                     tickangle = 90,zerolinewidth=1,\n                                     ticklen=5,gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"scores\",\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        margin = dict(b=200),\n                        xaxis2=dict(domain=[0.8, 1],tickangle = 90,\n                                    gridcolor = 'rgb(255, 255, 255)'),\n                        yaxis2=dict(anchor='x2',gridcolor = 'rgb(255, 255, 255)')\n                        )\n                  )\n\ndata=[trace,trace1]\nfig = go.Figure(data=data,layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c937e2ea42d2293fea9275f8f97ac22a98a5f24"},"cell_type":"markdown","source":"이전과 같은 그림 그려주는 코드\n\n##5.5. Decision Tree Visualization"},{"metadata":{"_uuid":"a1b5bfb831271487caf37ba32385c10bf3d0f290","trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz\nfrom sklearn import tree\nfrom graphviz import Source\nfrom IPython.display import SVG,display\n\nfeatures_cat  = score[score[\"feature_type\"] == \"Categorical\"][\"features\"][:3].tolist()\n\n#top 3 numerical features\nfeatures_num  = score[score[\"feature_type\"] == \"Numerical\"][\"features\"][:3].tolist()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"328e1a282a7cae2f6b7b414c1a20dd7bc2f5a853"},"cell_type":"markdown","source":"드디어 Decision Tree가 나왔다. 한국어로 의사결정 나무라고 한다.\n\n이 친구는 우리가 쓸 많은 모델들의 어머니와 같은 존재랄까?\n\n![decision2](https://thebook.io/img/006723/480.jpg)\n![decision](https://mblogthumb-phinf.pstatic.net/20160128_264/2011topcit_1453956712931ERjYE_JPEG/%BB%FD%B0%A2%C6%AE%B8%AE1.jpg?type=w2)\n\n이런 느낌으로 아래로 내려가는 친구인데 나무와 같은 모양을 하고 있어서 의사결정나무라고 한다.\n\n보는대로 기준을 삼고, 그 기준에 따라 가지를 뻗어나간다. \n\n예, 아니요로도 나갈수 있지만 여러 가지들로도 뻗어나갈 수 있다. 약간 스무고개 느낌도 난다.\n\n불순도라는 친구가 여기서 나오게 되는데, 한 공간에 남자, 여자가 존재할때 50:50으로 있다면 불순하다고 표현한다.\n![GINI](https://mblogthumb-phinf.pstatic.net/20160128_125/2011topcit_1453956726357KboxY_JPEG/%BB%FD%B0%A2%C6%AE%B8%AE2.jpg?type=w2)\n우리는 기준을 잡아 남자, 여자로 깔끔하게 분류해야 하는데, 불순도를 최대한 줄이는 방향으로 계산해 나가야한다.\n\n이때 쓰는 친구들이 'entropy. 엔트로피'라는 친구와 'gini, 지니'라는 친구다.\n\n우리 크롤링 세미나로 예를 들어보자.\n\n남녀 특징적인걸로 분류하지 않는다고 생각했을 때,\n\n파주에 사는가?로 분류해내면 예->여1, 아니요->남3,여3이다. \n\n하지만 96인가? 로 분류해내면 예->여2, 아니요->남3,여2이다.\n\n불순도는 '파주'보다 '96'이라는 기준이 조금 더 잘 분류를 해냈다. \n\n기본적으로 위에서 불순도를 줄여나가는 것이 좋은 것이다. 계산식이 차이가 있어 상황에 따라 값이 살짝 다르게 분류해나갈 뿐이다.\n\n분류기준이 적고 정확하게 분류해낼수록 좋은 모델이라고 할 수 있다. 한명한명의 특징적인 것을 가져다가 분류해내면 의미가 없다. \n\n크롤링세미나 사람들로 TRAIN을 시키고, 다른 사람을 TEST로 삼아 분류해 낸다면 이전까지 가지고 있던 한명한명의 특징들은 분류기준이 될 수없다.\n\n데이터가 무수히 많아 모든 것을 예측했으면 좋겠지만, 데이터는 스무고개를 하는 마냥 한정적이고 모든 것을 정확하게 예측하고 분류할 수는 없다.\n\n그래서 분류기준이 적고 정확하게 분류해낼수록 좋은 모델이다.\n\n여기까지가 의사결정나무의 어느정도 설명이고 이제 코드를 설명하자면,\n~~~\nfeatures_cat  = score[score[\"feature_type\"] == \"Categorical\"][\"features\"][:3].tolist()\n\n#top 3 numerical features\nfeatures_num  = score[score[\"feature_type\"] == \"Numerical\"][\"features\"][:3].tolist()\n~~~\nfeatures_cat엔 score에서/ feature_type이 == Categorical인 애들중([score[\"feature_type\"] == \"Categorical\"]) /feature들 중에([\"features\"]) /[:3] 세개를 뽑아주고/ 리스트 형식으로 바꿔줬다.  (.tolist())\n\n[:3]이 처음 나왔는데, 이는 파이썬에서 리스트를 잘라주는 방식(인덱싱)이라고 생각하면 된다. \n\n[종국,보미,윤식,유선,혜인] 이런 친구가 있다고 치자. 파이썬에서 종국은 0, 보미는 1, 윤식은 2 이런식으로 할당된다.\n\n제일 처음이 0이다! 얘네를 잘라서 보고싶다. 그러면 [ : ]요런 친구를 쓰게되는데 : 앞뒤로 숫자를 넣거나 비워둔다.  \n\n아까 말했듯이 종국은 0이다. 하지만 처음부터를 보여주고 싶으면 앞을 비워두면 된다. 윤식까지를 보고 싶다면 [:2]가 아니라, [:3]을 넣어야한다. \n\n이유는 앞은 이상이고, 뒤는 미만같은 느낌이다. [:2]면 종국,보미만 선택이 되고 [:3]이면 종국,보미,윤식까지 선택된다.\n\n또, [1:] 이런식으로 뒤를 비워두면 1부터 끝까지 같은 느낌으로, 보미,윤식,유선,혜인이 해당된다.\n\n음수로도 표현할 수 있는데 0이 종국이니까 -1은 혜인이다. 거꾸로 가는 느낌. \n\nfeature_num도 똑같은 녀석이다. 2시가 넘었으니 내일할꺼\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_decision_tree(columns,maximum_depth,criterion_type,\n                       split_type,model_performance = None) :\n    \n    #separating dependent and in dependent variables\n    dtc_x = df_x[columns]\n    dtc_y = df_y[target_col]\n    \n    #model\n    dt_classifier = DecisionTreeClassifier(max_depth = maximum_depth,\n                                           splitter  = split_type,\n                                           criterion = criterion_type,\n                                          )\n    dt_classifier.fit(dtc_x,dtc_y)\n    \n    #plot decision tree\n    graph = Source(tree.export_graphviz(dt_classifier,out_file=None,\n                                        rounded=True,proportion = False,\n                                        feature_names = columns, \n                                        precision  = 2,\n                                        class_names=[\"Not churn\",\"Churn\"],\n                                        filled = True                         \n                                       )\n                  )\n    \n    #model performance\n    if model_performance == True :\n        telecom_churn_prediction(dt_classifier,\n                                 dtc_x,test_X[columns],\n                                 dtc_y,test_Y,\n                                 columns,\"features\",threshold_plot = True)\n    display(graph)\n    \nplot_decision_tree(features_num,3,\"gini\",\"best\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6aa8b3d107beeec39b2a6a3f003b1677ebfb1c97"},"cell_type":"markdown","source":"~~~\ndef plot_decision_tree(columns,maximum_depth,criterion_type,\n                       split_type,model_performance = None) :\n~~~\n기존 친구들과 똑같은 형식. 매개변수 친구들이 많은데 columns는 열을 선택하는 것,\n\nmaximum_depth는 트리의 max_depth를 의미하는데 위에서 내려오면서 기준을 몇개를 삼고 어디까지 뻗어나갈지 정하는 것. 아무것도 적지 않는다면 분류기준을 모두 넣어 끝까지 나눠준다.(대신 FEATURE가 많을 경우에 오버피팅에 주의)\n\ncriterion_type은 아까 말했던 불순도 계산방식(gini,entropy)을 선택하는 것.\n\nsplit_type은 best와 random이 있는데 모든 feature들을 계산하여 불순도를 낮춰 내려가는 방식을 택한 것이 best, random은 feature들을 random하게 선택하여 나누는 방식. \n\nmodel performance는 True값을 줬을시 performance를 확인할 수 있다.\n\n~~~\n    dtc_x = df_x[columns]\n    dtc_y = df_y[target_col]\n    \n    #model\n    dt_classifier = DecisionTreeClassifier(max_depth = maximum_depth,\n                                           splitter  = split_type,\n                                           criterion = criterion_type,\n                                          )\n~~~\n다시한번 x(features)와 y(target)로 나눠주는 작업을 했고 의사결정나무를 설정해줬다. DecisionTreeClassifier는 sklearn에서 제공하는 의사결정나무 모델이다.\n\nmax_depth,splitter,criterion은 def에서 정의된 매개변수들을 넣어줬다.\n\n~~~\n    dt_classifier.fit(dtc_x,dtc_y)\n~~~\n의사결정 나무를 x,y값을 넣어줘 적용시켰다.\n\n~~~\n    graph = Source(tree.export_graphviz(dt_classifier,out_file=None,\n                                        rounded=True,proportion = False,\n                                        feature_names = columns, \n                                        precision  = 2,\n                                        class_names=[\"Not churn\",\"Churn\"],\n                                        filled = True                         \n                                       )\n                  )\n~~~\n\ngraphviz라는 친구가 있다. 라이브러리인데 여기의 Source라는 친구를 불러와주고, tree.exprot_graphviz라는 친구를 소환해 준다. \n\n라이브러리에서 불러온 의사결정나무를 그림으로 표현해주기 위한 친구들이다.\n\nout_file은 output파일의 이름을 지정할 수 있다. default는 None인데 그냥 이름이 표출된다.\n\nrounded는 그냥 박스의 각을 동그랗게 만들어주고 싶은것..\n\nprecision은 불순도의 계산 값이 소수 몇째까지 나오는지 알려고 하는것.\n\nfilled=True일 때 더 중요한 친구에게 색을 칠해준다고 한다.\n\n~~~\n    if model_performance == True :\n        telecom_churn_prediction(dt_classifier,\n                                 dtc_x,test_X[columns],\n                                 dtc_y,test_Y,\n                                 columns,\"features\",threshold_plot = True)\n    display(graph)\n~~~\n\n이전에 보여줬던 model 평가 지표들을 눈으로 보여주게 한다.\n\n~~~\nplot_decision_tree(features_num,3,\"gini\",\"best\")\n~~~\n수치형 변수 친구들을 넣어줬을때.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_decision_tree(features_cat,3,\"entropy\",\"best\",\n                   model_performance = True )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33929d5f9feb90cb44ce0160b9bb28baa6e9a904"},"cell_type":"markdown","source":"범주형 변수들만 넣어줬을때."},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = ['tenure','Contract_Month-to-month', 'PaperlessBilling',\n           'Contract_One year', 'Contract_Two year']\n\nplot_decision_tree(columns,3,\"gini\",\"best\",model_performance= True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78e980e59178ed1cf44070f39fae902392f5568a"},"cell_type":"markdown","source":"돈을 낸, 계약 관련 feature들을 뽑아줘서 넣었을 때."},{"metadata":{"trusted":true},"cell_type":"code","source":"def telecom_churn_prediction_alg(algorithm,training_x,testing_x,\n                                 training_y,testing_y,threshold_plot = True) :\n    \n    #model\n    algorithm.fit(training_x,training_y)\n    predictions   = algorithm.predict(testing_x)\n    probabilities = algorithm.predict_proba(testing_x)\n    \n    print (algorithm)\n    print (\"\\n Classification report : \\n\",classification_report(testing_y,predictions))\n    print (\"Accuracy Score   : \",accuracy_score(testing_y,predictions))\n    #confusion matrix\n    conf_matrix = confusion_matrix(testing_y,predictions)\n    #roc_auc_score\n    model_roc_auc = roc_auc_score(testing_y,predictions) \n    print (\"Area under curve : \",model_roc_auc)\n    fpr,tpr,thresholds = roc_curve(testing_y,probabilities[:,1])\n     \n    #plot roc curve\n    trace1 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2),\n                       )\n    trace2 = go.Scatter(x = [0,1],y=[0,1],\n                        line = dict(color = ('rgb(205, 12, 24)'),width = 2,\n                        dash = 'dot'))\n    \n    #plot confusion matrix\n    trace3 = go.Heatmap(z = conf_matrix ,x = [\"Not churn\",\"Churn\"],\n                        y = [\"Not churn\",\"Churn\"],\n                        showscale  = False,colorscale = \"Blues\",name = \"matrix\",\n                        xaxis = \"x2\",yaxis = \"y2\"\n                       )\n    \n    layout = go.Layout(dict(title=\"Model performance\" ,\n                            autosize = False,height = 500,width = 800,\n                            showlegend = False,\n                            plot_bgcolor  = \"rgb(243,243,243)\",\n                            paper_bgcolor = \"rgb(243,243,243)\",\n                            xaxis = dict(title = \"false positive rate\",\n                                         gridcolor = 'rgb(255, 255, 255)',\n                                         domain=[0, 0.6],\n                                         ticklen=5,gridwidth=2),\n                            yaxis = dict(title = \"true positive rate\",\n                                         gridcolor = 'rgb(255, 255, 255)',\n                                         zerolinewidth=1,\n                                         ticklen=5,gridwidth=2),\n                            margin = dict(b=200),\n                            xaxis2=dict(domain=[0.7, 1],tickangle = 90,\n                                        gridcolor = 'rgb(255, 255, 255)'),\n                            yaxis2=dict(anchor='x2',gridcolor = 'rgb(255, 255, 255)')\n                           )\n                  )\n    data = [trace1,trace2,trace3]\n    fig = go.Figure(data=data,layout=layout)\n    \n    py.iplot(fig)\n    \n    if threshold_plot == True : \n        visualizer = DiscriminationThreshold(algorithm)\n        visualizer.fit(training_x,training_y)\n        visualizer.poof()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"081da0e5e2c7e37efcf4146db0cf3da89c1076e7"},"cell_type":"markdown","source":"예전에 정의해줬던 친구들을 다시 정의해준다. 모델 평가를 위한 그림 그리는 과정. \n\n아마 내용이 살짝 다르기 때문에 그럴텐데, 대체로 비슷한 내용이라 패스한다.\n\n##5.6 KNN Clssifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n           weights='uniform')\ntelecom_churn_prediction_alg(knn,os_smote_X,test_X,\n                             os_smote_Y,test_Y,threshold_plot = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55342b3ea46d1b69dd18acbab548233e06a46700"},"cell_type":"markdown","source":"sklearn라이브러리에서 제공하는 KNN을 데려왔다.\n\n내부를 보면 algorithm은 몇가지 방식이 있는데 auto는 알아서 적절한 방법을 적용 시켜준다고 한다.\n\nleaf_size는 속도와 메모리 관련 내용인데 여기선 그냥 default인 30을 그대로 써줬다. \n\nmetric은 거리 계산 방식을 뜻하는데 default는 minkowski방식이다. 이전에 한번 언급했고, 계산방식이 조금 다르다. 아래 이미지 참조.\n\np를 같이 설명을 해야할 것 같다. p값에 2 가들어가면 유클리드거리가 된다. 1이면 맨하탄 거리. 아래 그림의 q가 p다. 수학적인게 귀찮다면 pass.\n\n![1](https://www.saedsayad.com/images/KNN_similarity.png)\n\nmetric_params는 None값. default값이다. 뭔지는 잘 모르겠다. 아마 계산에 가중치? 주는형식이 아닐까 싶은데 정확하진 않다.\n\nweight는 근접 이웃에 대한 가중치다. 옵션인 uniform은 가중치를 모든 곳에 동등하게 주는 친구. 거리가 멀 수록 가중치를 더 하는 방법은 distance를 쓰면 된다.\n\n나머지는 이전처럼 그림그리는 친구.\n\n##5.7. Vizualising a decision tree from random forest classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f9356ebac0e566be1812875af1e19674457d7f8f"},"cell_type":"markdown","source":"이제 앙상블(Ensemble)이란 친구를 해줄꺼다.\n\n앙상블이란? 프랑스어로 여러개를 합친다가 기본적인 내용이고. 머신러닝에선 여러개의 모델을 조합하여 최종 예측모델을 만드는 기법을 의미한다.\n\n우리가 최초로 다룰 친구는 랜덤포레스트(RandomForest)라는 친구다.\n\n랜덤포레스트를 알려면 배깅(Bagging)이라는 친구를 먼저 알아야한다.\n\n배깅이란 Boostrap aggregating의 줄임말으로 데이터를 중복랜덤샘플링(Boostrap)한 뒤 모델(Decision Tree)을 만들고,\n다시 이들을 모아 모델링 한 것.(Aggregating)\n\n예측 값이 연속형일 때는 평균값을 따르고, 범주형일 때는 투표형식을 따라 분류한다.\n\n의사결정나무 하나만 있는 것 보다 여러개의 결과를 합쳐보면 좀 더 좋은 결과값을 가지게 되어있다.\n\n![random](http://www.birc.co.kr/wp-content/uploads/2017/02/randomforest-2-1024x380.png)\n\n위의 그림은 랜덤포레스트와 배깅의 모습으로 보면 되는데,배깅과 랜덤포레스트의 다른 점은 배깅은 모든 feature들을 분류에 써서 모델들이 한쪽으로 쏠릴 수 있지만 랜덤포레스트는 feature를 랜덤하게 선택하고 사용해 한쪽으로 쏠림을 방지한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_tree_randomforest(columns,nf_estimators,\n                           estimated_tree,maximum_depth,\n                           criterion_type,model_performance = None) :\n    \n    dataframe = df_tel_og[columns + target_col].copy()\n    \n    #train and test datasets\n    rf_x     = dataframe[[i for i in columns if i not in target_col]]\n    rf_y     = dataframe[target_col]\n    \n    #random forest classifier\n    rfc   = RandomForestClassifier(n_estimators = nf_estimators,\n                                   max_depth = maximum_depth,\n                                   criterion = criterion_type,\n                                  )\n    rfc.fit(rf_x,rf_y)\n    \n    estimated_tree = rfc.estimators_[estimated_tree]\n    \n    graph = Source(tree.export_graphviz(estimated_tree,out_file=None,\n                                        rounded=True,proportion = False,\n                            feature_names = columns, \n                            precision  = 2,\n                            class_names=[\"Not churn\",\"Churn\"],\n                            filled = True))\n    display(graph)\n    \n    #model performance\n    if model_performance == True :\n        telecom_churn_prediction(rfc,\n                                 rf_x,test_X[columns],\n                                 rf_y,test_Y,\n                                 columns,\"features\",threshold_plot = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6fa59c47ee5d7bd1d543fac82d4f4ae4ce2fbcdd"},"cell_type":"markdown","source":"코드는 이전과 비슷하다. sklearn에서 제공하는 RandomForestClassifier를 사용하였고, 데이터를 x와 y로 나누는 과정도 같다.\n\n이제 내부의 설정 값들을 보자면,\n\n~~~\n    rfc   = RandomForestClassifier(n_estimators = nf_estimators,\n                                   max_depth = maximum_depth,\n                                   criterion = criterion_type\n~~~\nn_estimators란 모델의 갯수를 의미한다. 의사결정나무가 몇개를 만들고 합칠 것인지 결정한다.\n\n나머진 의사결정나무와 같다.\n\n~~~\nestimated_tree = rfc.estimators_[estimated_tree]\n~~~\nestimated_tree는 보여줄 트리의 갯수. estimators_는 그 아이들을 합쳐놓은 친구.\n\n\n나머진 다른점이 없다\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols1 = [ i for i in train_X.columns if i not in target_col + Id_col] \nplot_tree_randomforest(cols1,100,99,3,\"entropy\",True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7758f8b185fba242e20296a8953c6b69dc102cc7"},"cell_type":"markdown","source":"그림을 그려준다.\n\n##5.8A random forest classifier\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"n = np.arange(0,10).tolist()\ncols1 = [ i for i in train_X.columns if i not in target_col + Id_col] \nfor i in n :\n    plot_tree_randomforest(cols1,10,i,3,\"entropy\",model_performance=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"n이라는 객체에 0부터 9까지 넣어줘서 리스트 형식으로 바꿨다.\n\ncol1에 feature들을 넣어주고,\n\n~~~\nfor i in n :\n    plot_tree_randomforest(cols1,10,i,3,\"entropy\",model_performance=False)\n~~~\nfor문으로 랜덤포레스트를 돌려줬는데 우리가 보고싶은건 0부터 9까지 총 10개의 그림을 보고싶은 것. \n\ni는 estimated_tree를 의미한다. 그래서 0부터 9까지 집어넣고 0부터 9까지의 plot을 띄우고싶은 것.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"n = np.arange(0,10).tolist()\ncols = idc_rfe[idc_rfe[\"rfe_support\"] == True][\"columns\"].tolist() \nfor i in n :\n    plot_tree_randomforest(cols,10,i,3,\"gini\",model_performance=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5.4에서 RFE로 얻은 feature들을 뽑아 randomforest를 돌려준다.\n\n##5.9. Gaussian Naive Bayes."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB(priors=None)\n\ntelecom_churn_prediction_alg(gnb,os_smote_X,test_X,os_smote_Y,test_Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"나이브 베이즈 모형 중 GaussianNB(가우시안 정규분포 나이브 베이즈)를 썼다.\n\n나이브 베이즈는 조건부 확률 모델로, 분류될 친구들은 n개의 feature를 나타내는 벡터 x1,x2등으로 표현되며, 이 벡터를 이용하여 클래스를 아래와 같이 할당한다.\n\n![naive](https://wikimedia.org/api/rest_v1/media/math/render/svg/6add9e9bd1434964d43c21b91e028802fc062873)\n\n아래의 식으로 클래스를 분류한다.\n![naive2](https://wikimedia.org/api/rest_v1/media/math/render/svg/ed400a98da3c68951dfa9befb07c5268f30c9c7b)\n\n가우시안, 다항분포, 베르누이 나이브베이즈가 있으며 각각 수식이 다르다. \n\n아무튼, 나이브베이즈 방식으로 분류한 모습이다.\n\n##5.10. Support Vector Machine"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SVM이라는 친구를 해줄거임.\n\n![svm](http://i.imgur.com/7TNlFVd.png)\n\n그림처럼 다른 클래스와 거리가 가장 가까운 친구를 서포트 벡터라고 하고 둘 사이의 거리를 마진이라고 한다.\n\n우리의 목표는 마진을 가장 크게 만드는 친구이다. 이게 선형일땐 이렇게 보이는데 아래의 그림처럼\n\n![SVM2](https://wikidocs.net/images/page/5719/noname01_1uOrfWW.png)\n이런 식으로 둘러쌓여져 있는 경우, 선형으로 구분이 힘들경우엔 커널트릭이란 방법을 써서 차원을 바꿔준다.\n\n그래서 마진을 늘리는 형식을 말한다."},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_lin  = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n               decision_function_shape='ovr', degree=3, gamma=1.0, kernel='linear',\n               max_iter=-1, probability=True, random_state=None, shrinking=True,\n               tol=0.001, verbose=False)\n\ncols = [i for i in tel.columns if i not in Id_col + target_col]\ntelecom_churn_prediction(svc_lin,os_smote_X,test_X,os_smote_Y,test_Y,\n                         cols,\"coefficients\",threshold_plot = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"C는 패널티를 의미 1 은 default값\n\ncache_size는 kernel의 cache값을 지정, 컴퓨터 용량관련 내용인거 같음.\n\nclass Weight는 C앞에 붙여줄 가중치 값을 얘기하는데, 만약 None이면 모든 클래스는 가중치가 하나 주어짐.\nbalanced를 줄 경우 자동적으로 웨이트 값이 조정된다고함. class빈도수에 따라서.\n\nkernel은 형식 여기선 linear형식을 썼는데, rbf가 default라고함. 먼저 커널매트릭스를 계산하는 방식이라고 한다.\n\nmax_iter은 몇번 수행할 것인지 정하는건데 -1이 default고 제한없이 하는 것.\n\ndicision_function_shape은 one vs rest형식 ovr또는 one vs one인 ovo로 한다고 한다. ovr\n\n알아듣기 힘들다.. 나머진 다 default값이라 그냥 안쓸래 뭐가뭔지도 솔직히 잘 모르겠음.\n\nsvm잘 안쓰기도 하고..\n\n##5.11 Tuning parameters for support vector machine"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_rbf  = SVC(C=1.0, kernel='rbf', \n               degree= 3, gamma=1.0, \n               coef0=0.0, shrinking=True,\n               probability=True,tol=0.001,\n               cache_size=200, class_weight=None,\n               verbose=False,max_iter= -1,\n               random_state=None)\n\ntelecom_churn_prediction_alg(svc_rbf,os_smote_X,test_X,os_smote_Y,test_Y,threshold_plot = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"설정을 바꿔서 돌린 버전인데 kernel을 rbf로 바꿨음.\n\n##5.12 LightGBMClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"이제 새로운 부스팅이란 친구를 할거임.\n\n부스팅이란, 의사결정나무의 앙상블 버젼 중 하나.\n\n간단히 말하면 분류를 잘 못하는 분류기를 모아 가중치를 더해준 뒤에 최종 모델을 만드는 친구. \n\n![boost](http://www.birc.co.kr/wp-content/uploads/2017/02/boosting.png)\n\n이런 친구다. \n\n부스팅엔 가중치를 주는 방식에 따라 여러 방식이 존재한다.\n\n![boost](https://image.slidesharecdn.com/mlstudyboostingv0-171128021615/95/boosting-bagging-vs-boosting-14-638.jpg?cb=1511939004)\n\n이런 녀석들이 존재한다.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_c = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n                        learning_rate=0.5, max_depth=7, min_child_samples=20,\n                        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n                        n_jobs=-1, num_leaves=500, objective='binary', random_state=None,\n                        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n                        subsample_for_bin=200000, subsample_freq=0)\n\ncols = [i for i in telcom.columns if i not in Id_col + target_col]\ntelecom_churn_prediction(lgbm_c,os_smote_X,test_X,os_smote_Y,test_Y,\n                         cols,\"features\",threshold_plot = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LGBMClassifier로 lightGBM을 말한다.\n\nboosting_type은 4가지가 존재, gbdt 전통적인 그래디언트 부스팅 디시전트리를 의미.\nrf는 랜덤포레스트,\ndart는 dropouts meet multiple additive regression trees로 드랍아웃 방식을 섞은 친구인가보다.\ngoss는 Gradient-based One-Side Sampling이라고 한다.\n\n![dropout](https://t1.daumcdn.net/cfile/tistory/2237423D57A0299F2A)\n![goss](https://www.msra.cn/wp-content/uploads/2017/12/nips17-20171219-14.jpg)\n\n하나는 드랍아웃에 관련된 내용이고, 하나는 goss에 관련된 내용이다.\n\n드랍아웃이란, 전체 weight를 계산에 참여시키는게 아니라 layer에 포함된 weight중에서 일부만 참여를 시킨다.\n뉴런을 제외하는게 아닌 0으로 만든다.\n\ngoss는 일부만 랜덤하게 샘플링 하여 진행하는 방식이다.\n\nclass_weight는 가중치 값인데, None은 모든 클래스에 하나의 가중치를 갖게하는 것이다. balanced는 자동적으로 클래스의 빈도수에 따라 weight를 결정해 준다.\n\ncolsample_bytree은 각각의 트리를 만들때 feature의 비율을 뜻한다. default로 1이다.\n\n![learning rate](http://postfiles7.naver.net/20160507_70/cattree_studio_1462571290485RH6Lx_GIF/17fig06.gif?type=w773)\nlearning rate는 Gradient Decent 알고리즘에서 Cost가 최소값을 찾아가는 도중 수행을 반복할 시, 이동하는 정도를 말한다.\n위의 그림에서 Iteration이 진행될 때 어느정도로 움직이냐를 결정해 주는 것. \n\nmax_depth는 이전에 설명했다.\n\nmin_child_samples는 나무가 내려갈때 leaf(child)가 생성되는 최소한의 데이터를 의미한다. \n\nmin_child_weight는 leaf(child)에 필요한 최소한의 가중치의 합. 이 가중치의 합 기준보다 적다면, child를 생성하지 않는다.\n\nmin_split_gain는 아래로 내려갈 수록 좀 더 좋은 모델이 되어야 하는데 loss를 줄이는 방향으로 가야함. 그 최소값을 얘기한다.\n\nn_estimators, n_jobs 모두 설명함.\n\nnum_leaves는 트리 leaves의 최대값을 말한다.\n\nobjective는 우리가 분류할 class 개수. \n\nrandom_state는 설명했다.\n\nreg_alpha, reg_lambda는 각각 L1,L2 정규화에 쓰이는 패널티 값. 여기서 L1은 가중치의 절대값에, L2는 가중치의 제곱값에 패널티를 준다.   \n\nsilent 부스팅이 진행되는 동안 메시지를 띄울지 말지.\n\nsubsample은 training 셋의 데이터 샘플 비율\n\nsubsample_for_bin는 bins를 구성하기 위한 샘플 숫자인데 bins가 뭔지 정확히 모르겠음. 추측하기엔 모델을 만들기 위한 데이터 샘플링의 집합? 같은거 같은데.. 정확히 모르겠다. \n\nsubsample_freq는 subsample의 빈도를 말하는데, dafault는 0이다. 이것도 정확히 잘 모르겠음.\n\n##5.13.XGBoost Classifier\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgc = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n                    colsample_bytree=1, gamma=0, learning_rate=0.9, max_delta_step=0,\n                    max_depth = 7, min_child_weight=1, missing=None, n_estimators=100,\n                    n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n                    reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n                    silent=True, subsample=1)\n\n\ntelecom_churn_prediction(xgc,os_smote_X,test_X,os_smote_Y,test_Y,\n                         cols,\"features\",threshold_plot = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"드디어 모델의 마지막인 XGB임.\n\nXGBClassifier를 썼고 base_socre는 모든 데이터에 대해 최초 예측 score를 나타낸 것. default는 0.5고 많은 시행이 지난 후에는 별 의미가 없어진다.\n\ncolsample_bytree는 각각의 tree를 구성할 때 feature들의 비율을 나타냄. 1은 모두를 뜻한다.\n\ngamma는 lightGBM에서의 min_split_gain과 같다. 아래로 내려갈 수록 좀 더 좋은 모델이 되어야 하는데 loss를 줄이는 방향으로 가야함. 그 최소값을 얘기한다. default는 0.\n\nmax_delta_step은 대게 쓰이지 않는 친구 default값이 0이다 하지만 과도하게 불균형일 경우 쓰이게 된다. 불균형일 경우, 가중치가 거의 무한에 가까워지기 때문에 표준화를 통하여 이런 문제점을 해결할 수 있다. 이 일을 해주는게 max_delta_step.\n\nscale_pos_weight은 긍정과 부정의 가중치들을 밸런스 잡아주는 역할을 한다. default는 1\n\nseed는 random number seed. random_state와 같은 것으로 보여진다.\n\n나머지는 LightGBM과 똑같다.\n\n##6.Model Performences"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import cohen_kappa_score\n\n#gives model report in dataframe\ndef model_report(model,training_x,testing_x,training_y,testing_y,name) :\n    model.fit(training_x,training_y)\n    predictions  = model.predict(testing_x)\n    accuracy     = accuracy_score(testing_y,predictions)\n    recallscore  = recall_score(testing_y,predictions)\n    precision    = precision_score(testing_y,predictions)\n    roc_auc      = roc_auc_score(testing_y,predictions)\n    f1score      = f1_score(testing_y,predictions) \n    kappa_metric = cohen_kappa_score(testing_y,predictions)\n    \n    df = pd.DataFrame({\"Model\"           : [name],\n                       \"Accuracy_score\"  : [accuracy],\n                       \"Recall_score\"    : [recallscore],\n                       \"Precision\"       : [precision],\n                       \"f1_score\"        : [f1score],\n                       \"Area_under_curve\": [roc_auc],\n                       \"Kappa_metric\"    : [kappa_metric],\n                      })\n    return df\n\n#outputs for every model\nmodel1 = model_report(logit,train_X,test_X,train_Y,test_Y,\n                      \"Logistic Regression(Baseline_model)\")\nmodel2 = model_report(logit_smote,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"Logistic Regression(SMOTE)\")\nmodel3 = model_report(logit_rfe,train_rf_X,test_rf_X,train_rf_Y,test_rf_Y,\n                      \"Logistic Regression(RFE)\")\ndecision_tree = DecisionTreeClassifier(max_depth = 9,\n                                       random_state = 123,\n                                       splitter  = \"best\",\n                                       criterion = \"gini\",\n                                      )\nmodel4 = model_report(decision_tree,train_X,test_X,train_Y,test_Y,\n                      \"Decision Tree\")\nmodel5 = model_report(knn,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"KNN Classifier\")\nrfc = RandomForestClassifier(n_estimators = 1000,\n                             random_state = 123,\n                             max_depth = 9,\n                             criterion = \"gini\")\nmodel6 = model_report(rfc,train_X,test_X,train_Y,test_Y,\n                      \"Random Forest Classifier\")\nmodel7 = model_report(gnb,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"Naive Bayes\")\nmodel8 = model_report(svc_lin,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"SVM Classifier Linear\")\nmodel9 = model_report(svc_rbf,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"SVM Classifier RBF\")\nmodel10 = model_report(lgbm_c,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"LGBM Classifier\")\nmodel11 = model_report(xgc,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"XGBoost Classifier\")\n\n#concat all models\nmodel_performances = pd.concat([model1,model2,model3,\n                                model4,model5,model6,\n                                model7,model8,model9,\n                                model10,model11],axis = 0).reset_index()\n\nmodel_performances = model_performances.drop(columns = \"index\",axis =1)\n\ntable  = ff.create_table(np.round(model_performances,4))\n\npy.iplot(table)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def output_tracer(metric,color) :\n    tracer = go.Bar(y = model_performances[\"Model\"] ,\n                    x = model_performances[metric],\n                    orientation = \"h\",name = metric ,\n                    marker = dict(line = dict(width =.7),\n                                  color = color)\n                   )\n    return tracer\n\nlayout = go.Layout(dict(title = \"Model performances\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"metric\",\n                                     zerolinewidth=1,\n                                     ticklen=5,gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        margin = dict(l = 250),\n                        height = 780\n                       )\n                  )\n\n\ntrace1  = output_tracer(\"Accuracy_score\",\"#6699FF\")\ntrace2  = output_tracer('Recall_score',\"red\")\ntrace3  = output_tracer('Precision',\"#33CC99\")\ntrace4  = output_tracer('f1_score',\"lightgrey\")\ntrace5  = output_tracer('Kappa_metric',\"#FFCC99\")\n\ndata = [trace1,trace2,trace3,trace4,trace5]\nfig = go.Figure(data=data,layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst    = [logit,logit_smote,decision_tree,knn,rfc,\n          gnb,svc_lin,svc_rbf,lgbm_c,xgc]\n\nlength = len(lst)\n\nmods   = ['Logistic Regression(Baseline_model)','Logistic Regression(SMOTE)',\n          'Decision Tree','KNN Classifier','Random Forest Classifier',\"Naive Bayes\",\n          'SVM Classifier Linear','SVM Classifier RBF', 'LGBM Classifier',\n          'XGBoost Classifier']\n\nfig = plt.figure(figsize=(13,15))\nfig.set_facecolor(\"#F3F3F3\")\nfor i,j,k in itertools.zip_longest(lst,range(length),mods) :\n    plt.subplot(4,3,j+1)\n    predictions = i.predict(test_X)\n    conf_matrix = confusion_matrix(predictions,test_Y)\n    sns.heatmap(conf_matrix,annot=True,fmt = \"d\",square = True,\n                xticklabels=[\"not churn\",\"churn\"],\n                yticklabels=[\"not churn\",\"churn\"],\n                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n    plt.title(k,color = \"b\")\n    plt.subplots_adjust(wspace = .3,hspace = .3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst    = [logit,logit_smote,decision_tree,knn,rfc,\n          gnb,svc_lin,svc_rbf,lgbm_c,xgc]\n\nlength = len(lst)\n\nmods   = ['Logistic Regression(Baseline_model)','Logistic Regression(SMOTE)',\n          'Decision Tree','KNN Classifier','Random Forest Classifier',\"Naive Bayes\",\n          'SVM Classifier Linear','SVM Classifier RBF', 'LGBM Classifier',\n          'XGBoost Classifier']\n\nplt.style.use(\"dark_background\")\nfig = plt.figure(figsize=(12,16))\nfig.set_facecolor(\"#F3F3F3\")\nfor i,j,k in itertools.zip_longest(lst,range(length),mods) :\n    qx = plt.subplot(4,3,j+1)\n    probabilities = i.predict_proba(test_X)\n    predictions   = i.predict(test_X)\n    fpr,tpr,thresholds = roc_curve(test_Y,probabilities[:,1])\n    plt.plot(fpr,tpr,linestyle = \"dotted\",\n             color = \"royalblue\",linewidth = 2,\n             label = \"AUC = \" + str(np.around(roc_auc_score(test_Y,predictions),3)))\n    plt.plot([0,1],[0,1],linestyle = \"dashed\",\n             color = \"orangered\",linewidth = 1.5)\n    plt.fill_between(fpr,tpr,alpha = .4)\n    plt.fill_between([0,1],[0,1],color = \"k\")\n    plt.legend(loc = \"lower right\",\n               prop = {\"size\" : 12})\n    qx.set_facecolor(\"k\")\n    plt.grid(True,alpha = .15)\n    plt.title(k,color = \"b\")\n    plt.xticks(np.arange(0,1,.3))\n    plt.yticks(np.arange(0,1,.3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"모델퍼포먼스를 비교하는 코드들은 이전까지의 친구들과 크게 다르지 않다. 그래서 정리를 그만 하려고 한다. \n\ncohen-kappa score정도만 아래 그림 순서따라가면 아 저게 저거구나 하고 알면 된다. 그럼 이제 정말 끝.\n\n![cohen1](https://mblogthumb-phinf.pstatic.net/20160411_75/y4769_1460381253680MoJRG_PNG/%BD%BD%B6%F3%C0%CC%B5%E55.PNG?type=w800)\n\n![cohen2](https://mblogthumb-phinf.pstatic.net/20160411_79/y4769_1460381253931jgpaU_PNG/%BD%BD%B6%F3%C0%CC%B5%E56.PNG?type=w800)\n\n![cohen3](https://mblogthumb-phinf.pstatic.net/20160411_187/y4769_1460381254179HpXkX_PNG/%BD%BD%B6%F3%C0%CC%B5%E57.PNG?type=w800)\n\n![cohen4](https://mblogthumb-phinf.pstatic.net/20160411_49/y4769_1460381254397pTUCg_PNG/%BD%BD%B6%F3%C0%CC%B5%E58.PNG?type=w800)\n\n![cohen5](https://mblogthumb-phinf.pstatic.net/20160411_268/y4769_1460381254594IAO71_PNG/%BD%BD%B6%F3%C0%CC%B5%E59.PNG?type=w800)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}