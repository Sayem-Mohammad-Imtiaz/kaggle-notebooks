{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport json\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom skimage.filters import unsharp_mask\nfrom keras.utils import to_categorical\nfrom keras.layers import Activation, Convolution2D, Dropout, Conv2D\nfrom keras.layers import AveragePooling2D, BatchNormalization\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.models import Sequential\nfrom keras.layers import Flatten\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import SeparableConv2D\nfrom keras.layers import Dense\nfrom keras import layers\nfrom keras.regularizers import l2\nfrom keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_emotion(emotion_id):\n    \"\"\"\n    Maps emotion ids into emotion strings\n    :param emotion_id:\n    :return:\n    \"\"\"\n    if emotion_id == 0:\n        return 'Anger'\n    elif emotion_id == 1:\n        return 'Disgust'\n    elif emotion_id == 2:\n        return 'Fear'\n    elif emotion_id == 3:\n        return 'Happiness'\n    elif emotion_id == 4:\n        return 'Sadness'\n    elif emotion_id == 5:\n        return 'Surprised'\n    elif emotion_id == 6:\n        return 'Neutral'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"os.listdir(\"../input\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"frame = pd.read_csv('../input/fer2013.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = frame.iloc[:,:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(7):\n    print('{}: {}'.format(get_emotion(i),len(frame.where(frame['emotion']==i).dropna())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anger = data.where(data['emotion']==0).dropna()\nanger = anger.append(anger.head(3000))\nlen(anger)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disgust = data.where(data['emotion']==1).dropna()\ndisgust = disgust.append(disgust)\ndisgust = disgust.append(disgust)\ndisgust = disgust.append(disgust)\ndisgust = disgust.append(disgust)\nlen(disgust)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fear = data.where(data['emotion']==2).dropna()\nfear = fear.append(fear.head(3000))\nlen(fear)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"happiness = data.where(data['emotion']==3).dropna()\nlen(happiness)\n# happiness = happiness.head(1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sadness = data.where(data['emotion']==4).dropna()\nsadness = sadness.append(sadness.head(2000))\nlen(sadness)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"surprised = data.where(data['emotion']==5).dropna()\nsurprised = surprised.append(surprised)\nlen(surprised)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neutral = data.where(data['emotion']==6).dropna()\nneutral = neutral.append(neutral.head(2000))\nlen(neutral)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = anger\ndata = data.append(disgust, ignore_index = True)\ndata = data.append(fear, ignore_index = True)\ndata = data.append(happiness, ignore_index = True)\ndata = data.append(sadness, ignore_index = True)\ndata = data.append(surprised, ignore_index = True)\ndata = data.append(neutral, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.asarray([np.fromstring(\n    frame['pixels'][i], \n    sep=' ', \n).reshape(48, 48, 1) for i in range(len(frame))])\n\n# standardize the values\nX -= np.mean(X, axis=0)\nX /= np.std(X, axis=0)\n\ny = np.asarray(\n    [int(frame['emotion'][i]) for i in range(len(frame))]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = to_categorical(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\nX_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport keras\n\nfrom IPython.display import clear_output\n\n%matplotlib inline\n\nclass PlotLearning(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.i = 0\n        self.x = []\n        self.losses = []\n        self.val_losses = []\n        self.acc = []\n        self.val_acc = []\n        self.fig = plt.figure()\n        self.max_val_acc = 0\n        self.logs = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        self.logs.append(logs)\n        self.x.append(self.i)\n        self.losses.append(logs.get('loss'))\n        self.val_losses.append(logs.get('val_loss'))\n        self.acc.append(logs.get('acc'))\n        self.val_acc.append(logs.get('val_acc'))\n        if self.max_val_acc< logs.get('val_acc'):\n            self.max_val_acc = logs.get('val_acc')\n        self.i += 1\n        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n\n        clear_output(wait=True)\n\n        ax1.set_yscale('log')\n        ax1.plot(self.x, self.losses, label=\"loss\")\n        ax1.plot(self.x, self.val_losses, label=\"val_loss\")\n        ax1.legend()\n\n        ax2.plot(self.x, self.acc, label=\"accuracy\")\n        ax2.plot(self.x, self.val_acc, label=\"validation accuracy,(max: {})\"\n                 .format(round(self.max_val_acc,2)))\n        ax2.legend()\n        print(\"Max validation accuracy {}\".format(self.max_val_acc))\n        plt.show();\n\n\nplot = PlotLearning()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features = 64\nnum_labels = 7\nbatch_size = 64\nepochs = 50\nwidth, height = 48, 48\n\nmodel = Sequential()\n\nmodel.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', input_shape=(width, height, 1), data_format='channels_last', kernel_regularizer=l2(0.01)))\nmodel.add(Conv2D(num_features, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(2*2*2*num_features, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(2*2*2*num_features, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(2*2*num_features, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(2*num_features, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_labels, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer='adam', \n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(\n    X_train, \n    y_train, \n    validation_data=(X_test, y_test), \n    epochs=epochs,\n    callbacks=[plot],\n    verbose=2\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct, samples = 0, 1000\nfor index in range(samples):\n    a = get_emotion(model.predict(np.asarray([X_test[index]]))[0].argmax())\n    b = get_emotion(y_test[index].argmax())\n    if a==b:\n        correct += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('{0:.2f}%'.format((correct/samples)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('er_weights.h5')\n\nwith open('er_arch.json', 'w') as f:\n    f.write(model.to_json())\n\nprint('Model saved.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}