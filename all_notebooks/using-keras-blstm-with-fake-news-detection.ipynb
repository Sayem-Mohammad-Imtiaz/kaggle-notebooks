{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) \n# will list the files in the input directory\n\nimport os\n# print(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# 讀取檔案 (Read Data)\ndata = pd.read_csv('../input/fake-news-detection/data.csv')\n\n# 隨機抽樣 比率為100% (Randomly Smaple data, ratio is 100%)\ndata = data.sample(frac = 1)\n\n# 顯示資料的前五筆 (Show Data)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 新增Length欄位，紀錄每個標題文字總長度\n# (Create a new column called Length that record every Headline length)\ndata['Length'] = [len(headline) for headline in data['Headline']]\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detail = data['Length'].describe()\nprint(detail)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get all true news\nfliter = data['Label'] == 1\npos = data[fliter]\nprint('真新聞的數量(原始)：', len(pos))\n\n# Get all fake news\nfliter = data['Label'] == 0\nneg = data[fliter]\nprint('假新聞的數量(原始)：', len(neg))\n\nthe_mean = min(len(pos), len(neg))\nprint(\"==============================================\")\n\n#抓取所有 Label為1的 資料，並且重新洗牌 (Random Shuffle)\np_data = pos.sample(n = the_mean)\nprint('取樣真新聞資料總數：', len(p_data))\n\n#抓取所有 Label為0的 資料，並且重新洗牌 (Random Shuffle)\nn_data = neg.sample(n = the_mean)\nprint('取樣假新聞資料總數：', len(n_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_split = 0.2\ntrain_split = 1 - test_split\n\n# 隨機抽樣80%的資料當訓練資料 而剩下的20%則當為測試資料\n# (20% for Testing Data, others 80% for Training Data)\np_train_data = p_data.sample(frac = train_split)\np_test_data = p_data.drop(p_train_data.index)\n\nn_train_data = n_data.sample(frac = train_split)\nn_test_data = n_data.drop(n_train_data.index)\n\n# 合併兩個類別的訓練資料與測試資料\n# (Combined fake news and true news)\ntrain_data = pd.concat([p_train_data, n_train_data])\ntest_data = pd.concat([p_test_data, n_test_data])\n\n# 全部隨機洗牌 (Random Shuffle)\ntrain_data = train_data.sample(frac = 1)\ntest_data = test_data.sample(frac = 1)\n\nx_train_data = train_data['Headline'].fillna('')\ny_train_data = train_data['Label']\nx_test_data = test_data['Headline'].fillna('')\ny_test_data = test_data['Label']\n\nprint('Train Data的Feature數量(已混合非假與假新聞)：', len(x_train_data))\nprint('Train Data的Label數量(已混合非假與假新聞)：', len(y_train_data))\nprint('Test Data的Feature數量(已混合非假與假新聞)：', len(x_test_data))\nprint('Test Data的Label數量(已混合非假與假新聞)：', len(y_test_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import sequence\nfrom keras.preprocessing.text import Tokenizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# token字典數量 (最常出現的4000字)  (Create a token dictionary)\ntoken_num = 4000 \n\n# 擷取多少固定長度字數 (抓標題字數的平均值 60個長度)\n# (Get a fix length, we chose the mean of the Headline length)\ndata_length = int(detail['mean'])  \n\n# 輸入向量維度 (Word Embeding output vector dimension)\noutput_length = 32 \n\ndropout = 0.2\nlstm_dim = 256","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"token = Tokenizer(num_words = token_num, filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\ntoken.fit_on_texts(x_train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_seq = token.texts_to_sequences(x_train_data)\nx_test_seq = token.texts_to_sequences(x_test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = sequence.pad_sequences(x_train_seq, maxlen = data_length)\nx_test = sequence.pad_sequences(x_test_seq, maxlen = data_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential, Model\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.layers import Input, Flatten\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.recurrent import LSTM\nfrom keras.layers import Bidirectional, TimeDistributed\nfrom keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(output_dim = output_length, \n                    input_dim = token_num, \n                    input_length = data_length))\nmodel.add(Dropout(dropout))\n\n# using BLSTM (this will be better than LSTM, Avg acc is around 0.85\nmodel.add(Bidirectional(LSTM(lstm_dim), merge_mode = 'sum'))\nmodel.add(Dropout(dropout))\n\n# using LSTM, Avg acc is around 0.84\n# model.add(LSTM(lstm_dim))\n# model.add(Dropout(dropout))\n\nmodel.add(Dense(units = 256, activation = 'relu'))\nmodel.add(Dropout(dropout))\n\nmodel.add(Dense(units = 1, activation = 'sigmoid'))\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 提早結束\nes = EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_history = model.fit(x = x_train,\n                         y = y_train_data,\n                         validation_split = 0.2,\n                         epochs = 20,\n                         batch_size = 200,\n                         verbose = 1,\n                         callbacks = [es])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\ndef show_train_history(train_history, train, validation):\n    plt.plot(train_history.history[train])\n    plt.plot(train_history.history[validation])\n    plt.title('Train History')\n    plt.ylabel(train)\n    plt.xlabel('Epoch')\n    plt.legend(['train', 'validation'], loc = 'upper left')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_train_history(train_history, 'acc', 'val_acc')\nshow_train_history(train_history, 'loss', 'val_loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate(x = x_test, y = y_test_data)\nscores[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"headline = [\"Stars give their tips on getting your music heard\",\n            \"Your Ancestors Didn’t Sleep Like You\",\n            \"Four ways Bob Corker skewered Donald Trump\",\n            \"Black Students Kicked Out Of Team For #TakeAKnee\",\n            \"Photographer killed in Mexico as journalist de...\"]\nseq_headline = token.texts_to_sequences(headline)\nseq_headline = sequence.pad_sequences(seq_headline, maxlen = data_length)\npred1 = model.predict(seq_headline)\npred1 = np.round(np.argmax(pred1, axis=1)).astype(int)\npred1","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}