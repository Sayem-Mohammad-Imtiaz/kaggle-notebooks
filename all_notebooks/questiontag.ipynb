{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\ntag_df = pd.read_csv(\"../input/statsquestions/Tags.csv\")\ntag_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"questions_df = pd.read_csv(\"../input/statsquestions/Questions.csv\",encoding = 'ISO-8859-1')\nquestions_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_df = pd.merge(questions_df,tag_df,on='Id',how='inner')\ntotal_df.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"concat_tag_df = total_df.groupby(['Id'])['Tag'].apply(\",\".join).reset_index()\nconcat_tag_df.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_df = pd.merge(questions_df,concat_tag_df,on='Id',how='inner')[['Title','Body','Tag']]\ninput_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tags_count_df = tag_df.groupby(['Tag']).count()\ntags_count_df_asc = tags_count_df.sort_values(by  = ['Id'])\ntags_count_df_asc.query('Id>=3').head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tags_count_df_desc = tags_count_df.sort_values(by=['Id'],ascending=False)\ntags_count_df_desc.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndef plot_word_cloud(text):\n    word_cloud_instance =    WordCloud(width = 800, height = 800, background_color = 'black',min_font_size = 10).generate(text)\n    \n    plt.figure(figsize = (8,8), facecolor = None)\n    plt.imshow(word_cloud_instance)\n    plt.axis('off')\n    plt.tight_layout(pad = 0)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tags = ' '\nfor index ,row in input_df.iterrows():\n    tags = tags + \" ,\" + row['Tag']\nplot_word_cloud(tags)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_x = input_df[['Title','Body']]\ndf_y = input_df[['Tag']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim import utils\nimport gensim.parsing.preprocessing as gsp\n\n\nfilters =[\n    gsp.strip_tags,\n    gsp.strip_punctuation,\n    gsp.strip_multiple_whitespaces,\n    gsp.strip_numeric,\n    gsp.remove_stopwords,\n    gsp.strip_short,\n    gsp.stem_text\n]\n\ndef clean_text(s):\n    s = s.lower()\n    s = utils.to_unicode(s)\n    for f in filters:\n        s = f(s)\n    return s    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_df.iloc[0,0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_text(input_df.iloc[0,0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_df.iloc[0,1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_text(input_df.iloc[0,1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"titles = ' '\nfor index,row in input_df.iterrows():\n    titles = titles + ' ' + clean_text(row['Title'])\n    \nplot_word_cloud(titles)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bodies = ''\nfor index, row in input_df.iterrows():\n    bodies = bodies + ' ' + clean_text(row['Body'])\n    \nplot_word_cloud(bodies)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_word_cloud_of_body_for_tag(tag_name):\n    tag_specific_body  = ''\n    tag_specific_df = input_df[input_df['Tag'].str.contains(tag_name)]\n    \n    for index,row in tag_specific_df.iterrows():\n        tag_specific_body = tag_specific_body + ' ' + clean_text(row['Body'])\n        \n    plot_word_cloud(tag_specific_body)    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_word_cloud_of_body_for_tag('matlab')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_word_cloud_of_body_for_tag('probability')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\n\ny = []\nfor index,row in df_y.iterrows():\n    y.append(set(row['Tag'].split(',')))\n    \nmlb = MultiLabelBinarizer()\nencoded_y = mlb.fit_transform(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from gensim.models.doc2vec import TaggedDocument,Doc2Vec\nfrom sklearn.base import BaseEstimator\nfrom sklearn import utils as skl_utils\n\nfrom tqdm import tqdm\nimport multiprocessing\nimport numpy as np\n\nclass Doc2VecTransformer(BaseEstimator):\n    def __init__(self,vector_size=100,learning_rate=0.02,epochs=1,field=None):\n        self.learning_rate = learning_rate\n        self.epochs = epochs\n        self._model  = None\n        self.vector_size = vector_size\n        self.workers = multiprocessing.cpu_count() - 1\n        self.field = field\n        \n        \n    def fit(self,df_x,df_y=None):\n        tagged_x = [TaggedDocument(clean_text(row[str(self.field)]).split(), [index]) for index, row in df_x.iterrrows()]\n        model = Doc2Vec(documents=tagged_x, vector_size = self.vector_size, workers = self.workers)\n        \n        for epoch in range(self.epochs):\n            model.train(skl_utils.shuffle([x for x in tqdm(tagged_x)]), total_examples = len(tagged_x), epochs = 1)\n            model.alpha -= self.learning_rate\n            model.min_aplha = model.alpha\n            \n        self._model = model\n        return  self\n    \n    def transform(self,df_x):\n        return np.asmatrix(np.array([self.model.infer_vector(clean_text(row[str(self.field)]).split()) for index,row in df_x.iterrows()]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_x,test_x,train_y,test_y = train_test_split(\n    df_x, encoded_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import FeatureUnion\nfu =  FeatureUnion(transformer_list=[('title_doc2vec',Doc2VecTransformer(field='Title')),\n                                 ('body_doc2vec',Doc2VecTransformer(field = 'Body'))])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import  Pipeline\nfrom skmultilearn.problem_transform import BinaryRelevance\nfrom sklearn.ensemble import  RandomForestClassifier\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"binary_rel_model = BinaryRelevance(RandomForestClassifier(n_jobs=-1))\nmulti_label_rf_br_model = Pipeline(steps=[\n    ('feature_union',fu),\n    ('binary_relevance',binary_rel_model)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.metrics as metrics\ndef hamming_loss(multi_label_model_pipeline,train_x,train_y,test_x,test_y):\n    predictions_test_y = multi_label_model_pipeline.predict(test_x)\n    return metrics.hamming_loss(y_true=y_test, y_pred = predictions_test_y)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}