{"cells":[{"metadata":{"id":"E_pDWibw3HM8","papermill":{"duration":0.007446,"end_time":"2021-04-04T12:51:58.319909","exception":false,"start_time":"2021-04-04T12:51:58.312463","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# A short and sweet modification of the SBERT tutorials \n\nSentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. The initial work is described in the paper Sentence-BERT: [Sentence Embeddings using Siamese BERT-Networks](https://arxiv.org/abs/1908.10084).\n\n\n"},{"metadata":{"execution":{"iopub.execute_input":"2021-04-04T12:51:58.337828Z","iopub.status.busy":"2021-04-04T12:51:58.336376Z","iopub.status.idle":"2021-04-04T12:52:07.75675Z","shell.execute_reply":"2021-04-04T12:52:07.756093Z"},"executionInfo":{"elapsed":3681,"status":"ok","timestamp":1617533535123,"user":{"displayName":"Darragh Caffrey","photoUrl":"","userId":"15949162394673566308"},"user_tz":-180},"id":"ORtoPQoQo-bW","outputId":"e389d3b9-4d74-43e2-fea7-fa08074dddc8","papermill":{"duration":9.430544,"end_time":"2021-04-04T12:52:07.756899","exception":false,"start_time":"2021-04-04T12:51:58.326355","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Install SentenceBert Library\n!pip install -U sentence-transformers","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-04-04T12:52:07.788944Z","iopub.status.busy":"2021-04-04T12:52:07.788284Z","iopub.status.idle":"2021-04-04T12:52:07.900897Z","shell.execute_reply":"2021-04-04T12:52:07.899471Z"},"executionInfo":{"elapsed":3674,"status":"ok","timestamp":1617533535124,"user":{"displayName":"Darragh Caffrey","photoUrl":"","userId":"15949162394673566308"},"user_tz":-180},"id":"kwAwHXSmpLK2","outputId":"8a021214-136f-4ac3-b92a-67bf0db09037","papermill":{"duration":0.132054,"end_time":"2021-04-04T12:52:07.901066","exception":false,"start_time":"2021-04-04T12:52:07.769012","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Import kaggle dataset\nimport pandas as pd\npd.set_option('display.max_colwidth', 500)\n\ndf = pd.read_csv(\"../input/netflix-shows/netflix_titles.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-04-04T12:52:07.930681Z","iopub.status.busy":"2021-04-04T12:52:07.929605Z","iopub.status.idle":"2021-04-04T12:52:07.93145Z","shell.execute_reply":"2021-04-04T12:52:07.931945Z"},"executionInfo":{"elapsed":3660,"status":"ok","timestamp":1617533535124,"user":{"displayName":"Darragh Caffrey","photoUrl":"","userId":"15949162394673566308"},"user_tz":-180},"id":"-Axu-iSYd72T","papermill":{"duration":0.019301,"end_time":"2021-04-04T12:52:07.932092","exception":false,"start_time":"2021-04-04T12:52:07.912791","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Filtering df\ndf = df[['title', 'rating', 'description']]","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-04-04T12:52:07.983376Z","iopub.status.busy":"2021-04-04T12:52:07.982543Z","iopub.status.idle":"2021-04-04T12:52:08.201841Z","shell.execute_reply":"2021-04-04T12:52:08.201384Z"},"executionInfo":{"elapsed":3654,"status":"ok","timestamp":1617533535126,"user":{"displayName":"Darragh Caffrey","photoUrl":"","userId":"15949162394673566308"},"user_tz":-180},"id":"y9kw98P0eSuE","outputId":"bdaa885a-dd71-49c5-973f-38576a3ed11f","papermill":{"duration":0.258491,"end_time":"2021-04-04T12:52:08.201958","exception":false,"start_time":"2021-04-04T12:52:07.943467","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Quick check of description lens (for BERT token len)\nimport matplotlib.pyplot as plt\n\nlens = [len(x.split()) for x in df['description']]\n\nplt.hist(lens, bins=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-04-04T12:52:08.231618Z","iopub.status.busy":"2021-04-04T12:52:08.23085Z"},"executionInfo":{"elapsed":16821,"status":"ok","timestamp":1617533611913,"user":{"displayName":"Darragh Caffrey","photoUrl":"","userId":"15949162394673566308"},"user_tz":-180},"id":"lwc5ah6PpLXH","papermill":{"duration":null,"end_time":null,"exception":false,"start_time":"2021-04-04T12:52:08.214316","status":"running"},"tags":[],"trusted":true},"cell_type":"code","source":"# Import library, utilities \nfrom sentence_transformers import SentenceTransformer, util\nimport torch\n\n# Set embedding model and max_seq_len and push to GPU\nembedder = SentenceTransformer('bert-base-uncased')\nembedder.to('cuda')\n# going a little longer for user inputed synopsis\nembedder.max_seq_len = 128","execution_count":null,"outputs":[]},{"metadata":{"id":"anZxMRuKhBXd","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"cell_type":"code","source":"# Set feature lists for concatonation to sematic asearch results\ntitles = df['title'].tolist()\nratings = df['rating'].tolist()\nstories = df['description'].tolist()\n\n# Fit model to corpus qnd push to GPU\nstory_embeddings = embedder.encode(stories, convert_to_tensor=True)\nstory_embeddings = story_embeddings.to('cuda')","execution_count":null,"outputs":[]},{"metadata":{"id":"elHYZ27c5apS","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"cell_type":"markdown","source":"# Just run the cell below and enter a title or a short synopsis which you would like to find similar results for... "},{"metadata":{"executionInfo":{"elapsed":2458,"status":"ok","timestamp":1617539310734,"user":{"displayName":"Darragh Caffrey","photoUrl":"","userId":"15949162394673566308"},"user_tz":-180},"id":"wIJrYcrHpLZQ","outputId":"18a4d1b7-f7f2-4f3c-c3d2-8037c50861bd","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"cell_type":"code","source":"# Define Semantic Search Function\ndef semantic_search(input_data):\n  # set lists to capture results\n  title_list = []\n  rating_list = []\n  story_list = []\n  score_list = []\n  # empty dataframe to display results \n  results = pd.DataFrame()\n  # Find the closest 5 stories of the corpus for each query sentence based on cosine similarity\n  top_k = min(10, len(story_embeddings))\n  \n  # If the input is too short to be a story or its not in the dataset  \n  if len(input_data) < 20 and input_data not in titles:\n    print('Title Not Found')\n\n  # If input is in the dataset\n  elif input_data in titles:\n    # Load and encode the description for the title match    \n    query_embeddings = embedder.encode(str(df[df['title'] == input_data]['description'])[5:-33], convert_to_tensor=True)\n    query_embeddings = query_embeddings.to('cuda')\n\n    # Use cosine-similarity and torch.topk to find the highest 5 scores\n    cos_scores = util.pytorch_cos_sim(query_embeddings, story_embeddings)[0]\n    top_results = torch.topk(cos_scores, k=top_k)\n    # Format the astory not to run off the cell\n    input_data_2 = input_data.replace('.', '.\\n')\n    print(\"\\n\\n======================\")\n    print(\"\\tSTORY\")\n    print(\"======================\\n\")\n    print('',str(df[df['title'] == input_data]['description'])[5:-33])\n    print(\"\\n\\n======================\")\n    print(\"    TOP RESULTS\")\n    print(\"======================\\n\")\n    \n    # For score, index in torch.topk(cos_scores, k=top_k) use index  locator for feature lists\n    # push score to cpu and convert to 1D array\n    for score, idx in zip(top_results[0], top_results[1]):\n      title_list.append(titles[idx])\n      rating_list.append(ratings[idx])\n      story_list.append(stories[idx])\n      score_list.append(score.cpu().numpy().flatten())\n\n    # Push results to dictionary columns \n    results['Title'] = title_list\n    results['Rating'] = rating_list\n    results['Story'] = story_list\n    results['Score'] = score_list\n    # return dictionary\n    return results.iloc[1:, :]\n\n  # If the input is long enough to be a story which is in the dataset\n  elif len(input_data) > 20 and input_data not in titles:\n    # Find the closest 5 stories of the corpus for each query sentence based on cosine similarity\n    query_embeddings = embedder.encode(input_data, convert_to_tensor=True)\n    query_embeddings = query_embeddings.to('cuda')\n\n    # Use cosine-similarity and torch.topk to find the highest 5 scores\n    cos_scores = util.pytorch_cos_sim(query_embeddings, story_embeddings)[0]\n    top_results = torch.topk(cos_scores, k=top_k)\n\n    input_data = input_data.replace('.', '.\\n')\n    print(\"\\n\\n======================\")\n    print(\"\\tSTORY\")\n    print(\"======================\\n\")\n    print(input_data)\n    print(\"\\n\\n======================\")\n    print(\"    TOP RESULTS\")\n    print(\"======================\\n\")\n    \n    # For score, index in torch.topk(cos_scores, k=top_k) use index  locator for feature lists\n    # push score to cpu and convert to 1D array\n    for score, idx in zip(top_results[0], top_results[1]):\n      title_list.append(titles[idx])\n      rating_list.append(ratings[idx])\n      story_list.append(stories[idx])\n      score_list.append(score.cpu().numpy().flatten())\n\n    # Push results to dictionary columns \n    results['Title'] = title_list\n    results['Rating'] = rating_list\n    results['Story'] = story_list\n    results['Score'] = score_list\n    # return dictionary\n    return results\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Push user input to Semantic Search function\n# Example of user created synopsis\nsemantic_search(\"When CIA analyst Jack Ryan stumbles upon a suspicious series of bank transfers his search for answers pulls him from the safety of his desk job and catapults him into a deadly game of cat and mouse throughout Europe and the Middle East, with a rising terrorist figurehead preparing for a massive attack against the US\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of existing title\nsemantic_search('Chappie')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of incorrect entry\nsemantic_search(\"chappie\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}