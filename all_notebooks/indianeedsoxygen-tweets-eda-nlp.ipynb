{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Load the Dataset**","metadata":{}},{"cell_type":"code","source":"df_tweets = pd.read_csv(\"/kaggle/input/indianeedsoxygen-tweets/IndiaWantsOxygen.csv\")\nprint (df_tweets.shape)\ndf_tweets.head()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **EDA**","metadata":{}},{"cell_type":"markdown","source":"## **Top 12 locations with highest number of Tweets**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14,8))\nsns.set(style='darkgrid')\nsns.countplot(y='user_location', data=df_tweets, order=df_tweets['user_location'].value_counts().index[:12], palette=\"Set2\")\nplt.xlabel(\"Number of Tweets\", weight='bold')\nplt.ylabel(\"User Location\", weight='bold')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **% of verified or non-verified accounts among the tweeters**","metadata":{}},{"cell_type":"code","source":"dict_temp = dict(Counter(df_tweets['user_verified']))\ndict_temp['User Verified'] = dict_temp.pop(True)\ndict_temp['User Non-Verified'] = dict_temp.pop(False)\n\nplt.figure(figsize=(7,7))\nplt.pie(x=dict_temp.values(), labels=dict_temp.keys(), autopct='%1.1f%%', shadow=True, \n        startangle=0, explode = [0.1, 0])\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **% of platform used for tweet**","metadata":{}},{"cell_type":"code","source":"dict_temp = df_tweets['source'].value_counts()[:3].to_dict()\ndict_temp['Others'] = 0\ndict_ = df_tweets['source'].value_counts().to_dict()\nfor key in dict_.keys():\n    if key not in dict_temp.keys():\n        dict_temp['Others'] += dict_[key]\n\nplt.figure(figsize=(7,7))\nplt.pie(x=dict_temp.values(), labels=dict_temp.keys(), autopct='%1.1f%%', shadow=True, \n        startangle=0)\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Heatmap (correlation) among different features**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(7,7))\nsns.heatmap(df_tweets[['user_followers', 'user_friends', 'user_favourites', 'user_verified']].corr(), center=0, annot=True,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Number of Tweets on each date**","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\ndf_tweets['date'] = pd.to_datetime(df_tweets['date'].str.split(' ', expand=True)[0], format='%Y-%m-%d')\n\nplt.figure(figsize=(14,8))\nsns.set(style='darkgrid')\nlist_ = [datetime.date(x) for x in df_tweets['date']]\nsns.countplot(x = list_, order=sorted(set(list_)), palette=\"Set2\")\nplt.xlabel(\"Date\", weight='bold')\nplt.ylabel(\"Number of Tweets\", weight='bold')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **WordCloud of Hashtags**","metadata":{}},{"cell_type":"code","source":"import itertools\nfrom wordcloud import WordCloud\n\nlist_hashtags = df_tweets['hashtags'].dropna().str.lstrip('[').str.rstrip(']').str.replace(\"'\", \"\").str.split(', ').tolist()\nlist_hashtags = list(itertools.chain(*list_hashtags))\n\nwordcloud = WordCloud(background_color=\"black\", width=800, height=500, max_font_size=80, max_words=100, collocations = False, colormap='Set2').generate(\" \".join(list_hashtags))\nplt.figure(figsize=(16,12))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **WordCloud of Tweets**","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nimport string\n\nlist_stopwords = set(stopwords.words('english') + list(punctuation))\ndf_temp = df_tweets[['text']].copy()\ndf_temp['text'] = df_temp['text'].str.lower()\ndf_temp['text'] = df_temp['text'].apply(word_tokenize)\ndf_temp['text'] = df_temp['text'].apply(lambda x: [word for word in x if word not in list_stopwords])\ndf_temp['text'] = df_temp['text'].apply(lambda x : [word.translate(str.maketrans('', '', string.punctuation)) for word in x])\ndf_temp['text'] = df_temp['text'].apply(lambda x : [word for word in x if len(word) > 1])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_text = df_temp['text'].tolist()\nlist_text = list(itertools.chain(*list_text))\n\nplt.figure(figsize=(16,12))\nwordcloud = WordCloud(background_color=\"black\", width=800, height=500, max_font_size=80, max_words=100, collocations = False, colormap='Set2').generate(' '.join(list_text))\nplt.imshow(wordcloud,interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Feel free to <span style=\"color:red\"> Upvote </span> and give <span style=\"color:blue\"> Feedback </span>.**","metadata":{}}]}