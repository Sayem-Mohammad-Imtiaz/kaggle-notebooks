{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e88082ac94029a128311c733e48afd74a29d025a"},"cell_type":"markdown","source":"This Kaggle notebook serves to hold all our data, code,  explanations, machine learning models, and explanations for our Fake News Classifier final project for our data science class.\n\nHere's our multi-part approach for the project.\n\n1. data collection:\n    - have two datasets (fakes news and real news)\n    - explain rationale\n\n2. data preprocessing:\n    - filter and manipulate columns, add labels (fake or real), and merge on selected columns\n\n3. preprocessing the text:\n\n4. text to features conversion:\n\n5. classification + model selection\n\n6. topic modeling\n\n7. conclusions\n\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"fake_news = pd.read_csv(\"../input/fake-news/fake.csv\")\nreal_news = pd.read_csv(\"../input/gathering-real-news-for-oct-dec-2016/real_news.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cfb6797512828349aa6ce08e05fa6822221c922"},"cell_type":"code","source":"#Here are the size of our datasets:\nprint(fake_news.shape)\nprint(real_news.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7239af8d5812eea409fa29347118a14b849b471"},"cell_type":"code","source":"# Let's see what columns we have\nprint(list(fake_news.columns))\nprint(list(real_news.columns))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29f7b8854514ca3cd2634a81a8408030eb34905a"},"cell_type":"markdown","source":"Now let's obtain similar features for both datasets before we combine them.\n\ntitle - title of article  \ncontent - article text  \npublication - which company published this article  \nlabel - real or fake\n\nRegarding publication for both of the datasets, the real news has the publication company in the 'publication' column while the fake news has the publication company embedded in the url in the 'site_url' column.\n\nWe will have to parse the site_urls into publication names before we merge."},{"metadata":{"trusted":true,"_uuid":"73f51630c02ebcd87563bebef6bbdf81342f0ab5"},"cell_type":"code","source":"# now let's obtain similar features for both datasets before we combine them\n# Let's add our label to the dataset \"real\" for real news and \"fake\" for fake news\n\nreal_news2 = real_news[['title', 'content', 'publication']]\nreal_news2['label'] = 'real'\nreal_news2.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"081170165d0d317917d1b2d3ff609e9162154946"},"cell_type":"code","source":"fake_news2 = fake_news[['title', 'text','site_url']]\nfake_news2['label'] = 'fake'\nfake_news2.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65c11d4ba40ff8e7ece713485570909a9cb197ff"},"cell_type":"code","source":"# let's obtain all the unique site_urls\nsite_urls = fake_news2['site_url']\n\n# let's remove the domain extensions\nsite_urls2 = [x.split('.',1)[0] for x in site_urls]\n\n# now let's replace the old site_url column\nfake_news2['site_url'] = site_urls2\nfake_news2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"2a3f978da0e659e2e265338ecc892ba87619f99a"},"cell_type":"code","source":"# let's rename the features in our datasets to be the same\nnewlabels = ['title', 'content', 'publication', 'label']\nreal_news2.columns = newlabels\nfake_news2.columns = newlabels\n\n# let's concatenate the dataframes\nframes = [fake_news2, real_news2]\nnews_dataset = pd.concat(frames)\nnews_dataset","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1911bdc67e1e7071f4bb64901e7c8e3e663a795e"},"cell_type":"markdown","source":"Let's save our data frame as a new csv file called \"news_dataset.csv\"."},{"metadata":{"trusted":true,"_uuid":"148039e8a058c06759d2a7a11da93c6b151ae041"},"cell_type":"code","source":"news_dataset.to_csv('news_dataset.csv', encoding='utf-8')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}