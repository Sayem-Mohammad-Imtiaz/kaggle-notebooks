{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IBM Attrition"},{"metadata":{},"cell_type":"markdown","source":"Kaggle\n\nhttps://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset\n\nUncover the factors that lead to employee attrition and explore important questions such as ‘show me a breakdown of distance from home by job role and attrition’ or ‘compare average monthly income by education and attrition’. This is a fictional data set created by IBM data scientists.\n\nEducation 1 'Below College' 2 'College' 3 'Bachelor' 4 'Master' 5 'Doctor'\n\nEnvironmentSatisfaction 1 'Low' 2 'Medium' 3 'High' 4 'Very High'\n\nJobInvolvement\n1 'Low' 2 'Medium' 3 'High' 4 'Very High'\n\nJobSatisfaction 1 'Low' 2 'Medium' 3 'High' 4 'Very High'\n\nPerformanceRating\n1 'Low' 2 'Good' 3 'Excellent' 4 'Outstanding'\n\nRelationshipSatisfaction\n1 'Low' 2 'Medium' 3 'High' 4 'Very High'\n\nWorkLifeBalance 1 'Bad' 2 'Good' 3 'Better' 4 'Best'"},{"metadata":{},"cell_type":"markdown","source":"### Import Necessary Library"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.style.use('fivethirtyeight')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### View Dataset Information (i.e. null, int, object, shape)"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preview Dataset"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check for Null Values"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Look for Constant Features"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.nunique().sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Drop Constant Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(columns=['EmployeeCount','EmployeeNumber', 'Over18','StandardHours'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analyse Dataset"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot HeatMap to Pick Out Highly Correlated Features"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(30,30))\nsns.heatmap(df.corr(), annot=True, linewidths=0.8);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop highly correlated column\ndf = df.drop(columns=['JobLevel','MonthlyIncome', 'TotalWorkingYears',\n                      'YearsInCurrentRole', 'YearsWithCurrManager', \n                      'YearsSinceLastPromotion'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Replace Target Column Obj with Int"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Attrition'] = df['Attrition'].replace('Yes', 0)\ndf['Attrition'] = df['Attrition'].replace('No', 1)\ndf['Attrition'] = df['Attrition'].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check if Data is Balance"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df.Attrition.value_counts()\n# imbalance\n# target column","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Replace Features Obj with Int"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.Attrition.value_counts())\n\nprint(df.BusinessTravel.value_counts())\nprint(df.Department.value_counts())\nprint(df.EducationField.value_counts())\nprint(df.Gender.value_counts())\nprint(df.JobRole.value_counts())\nprint(df.MaritalStatus.value_counts())\nprint(df.OverTime.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nlabel_encoder = preprocessing.LabelEncoder()\ncolnames_to_encode = ['Attrition','BusinessTravel', 'Department', 'EducationField', \n                      'Gender', 'JobRole', 'MaritalStatus', 'OverTime']\nfor c in colnames_to_encode:\n    df[c] = label_encoder.fit_transform(df[c])\nprint(df.Attrition.value_counts())\nprint(df.BusinessTravel.value_counts())\nprint(df.Department.value_counts())\nprint(df.EducationField.value_counts())\nprint(df.Gender.value_counts())\nprint(df.JobRole.value_counts())\nprint(df.MaritalStatus.value_counts())\nprint(df.OverTime.value_counts())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Move Target to the Last Column for Convenience"},{"metadata":{"trusted":true},"cell_type":"code","source":"target = df.Attrition\ndf = df.drop(labels=['Attrition'], axis=1)\ndf.insert(24,'Attrition',target)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.iloc[:, :-1].values   \ny = df.iloc[:, 24].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Normalise Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Use SMOTE to Over Sample Noting that There is a Lot Less \"Yes\" under \"Attrition\" Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state = 10, ratio=1.0)\nX_train_sm,  y_train_sm = sm.fit_sample(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Use RFE to Select Most Important Feature for Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(solver='lbfgs', random_state=9)\nrfe = RFE(model, 5)\nfit = rfe.fit(X_train_sm, y_train_sm)\nprint(\"Num Features: %s\" % (fit.n_features_))\nprint(\"Selected Features: %s\" % (fit.support_))\nprint(\"Feature Ranking: %s\" % (fit.ranking_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Use .info() to Know Which Column Feature Ranking is Referring"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Drop Less Important Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(columns=['BusinessTravel','DailyRate', 'Department',\n                      'DistanceFromHome', 'Education', 'EducationField', \n                      'NumCompaniesWorked', 'Gender', 'HourlyRate',\n                      'JobRole', 'JobSatisfaction','MonthlyRate', 'PercentSalaryHike',\n                      'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel',\n                      'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Use SMOTE Features and Target to Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train_sm, y_train_sm)\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nmetrics.confusion_matrix(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### High Recall, Low Precision\n\n#### This means the Company is able to sieve out potential people who are going to quit and intervene first."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Put Predictions Back in CSV Excel and Download"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"y_hats = model.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_hats2 = model.predict(X)\n\ndf['y_hats'] = y_hats2\n\ndf.to_csv('data1.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}