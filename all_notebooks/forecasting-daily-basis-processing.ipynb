{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pandas import Series\nfrom math import sqrt\n\n# metrics\nfrom sklearn.metrics import mean_squared_error\n\nimport statsmodels.api as sm\n\n# forecasting model\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\nfrom statsmodels.tsa.arima_model import ARIMA\n\n# for analysis\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom shapely.geometry import LineString\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 12, 7\n\nfrom IPython.display import display, HTML\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_original=pd.read_csv('../input/jetrail-traffic-dataset/Train.csv')\ntest_original=pd.read_csv('../input/jetrail-traffic-dataset/Test.csv')\n\ntrain_original.dropna(inplace=True)\ntest_original.dropna(inplace=True)\ntest_original.drop(test_original.tail(1).index, inplace=True)\n\ntrain_df=train_original.copy()\ntest_df=test_original.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_original['Datetime']=pd.to_datetime(train_original.Datetime, format='%d-%m-%Y %H:%M')\ntest_original['Datetime']=pd.to_datetime(test_original.Datetime, format='%d-%m-%Y %H:%M')\ntrain_df['Datetime']=pd.to_datetime(train_df.Datetime, format='%d-%m-%Y %H:%M')\ntest_df['Datetime']=pd.to_datetime(test_df.Datetime, format='%d-%m-%Y %H:%M')\n\n# generate day, month, year feature\nfor i in (train_original, test_original, train_df, test_df):\n    i['year']=i.Datetime.dt.year\n    i['month']=i.Datetime.dt.month\n    i['day']=i.Datetime.dt.day\n    i['hour']=i.Datetime.dt.hour","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sampling for daily basis\ntrain_df.index=train_df.Datetime\ntest_df.index=test_df.Datetime\n\ntrain_df=train_df.resample('D').mean()\ntest_df=test_df.resample('D').mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split data for training and validation\ntrain=train_df.loc['2012-08-25':'2014-06-24']\nvalid=train_df.loc['2014-06-25':'2014-09-25']\nplt.figure(figsize=(12,7))\ntrain.Count.plot(label='Train')\nvalid.Count.plot(label='valid')\nplt.legend(loc='best')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# determine rolling stats\nrolmean=train.Count.rolling(window=7).mean() #for 7 days\nrolstd=train.Count.rolling(window=7).std()\nrolmean.dropna(inplace=True)\nrolstd.dropna(inplace=True)\n\nplt.figure(figsize=(12,7))\nrolmean.plot(label='Rolmean', color='green')\nrolstd.plot(label='rolstd')\ntrain.Count.plot(label='Train')\nplt.legend(loc='best')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for stationary\ndftest=adfuller(train.Count, autolag='AIC')\ndfout=pd.Series(dftest[0:4], index=['Test statistics', 'p-value', '#Lags used', 'Number of observation used'])\nfor key, val in dftest[4].items():\n    dfout['Critical value (%s)'%key]=val\n\nprint(dfout)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Log Scale Transformation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Log scale tranformation\n# estimating trend\ntrain_count_log=np.log(train.Count)\n# train_count_log.plot()\n# make TS to be stationary\nmoving_avg=train_count_log.rolling(window=7).mean()\nmoving_std=train_count_log.rolling(window=7).std()\n\ntrain_count_log.plot(label='Log Scale')\nmoving_avg.plot(label='moving_avg')\nmoving_std.plot(label='moving_std')\nplt.legend(loc='best')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* logscaleL=stationarypart(L1)+trend(LT)\n* movingavgoflogscaleA=stationarypart(A1)+trend(AT)\n* resultseriesR=L−A=(L1+LT)−(A1+AT)=(L1−A1)+(LT−AT)\n\nSince, L & A are series & it moving avg, their trend will be more or less same, Hence\nLT-AT nearly equals to 0\n\nThus trend component will be almost removed. And we have,\n\nR=L1−A1 , our final non-trend curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dif_log=train_count_log-moving_avg\ndif_log.dropna(inplace=True)\ndif_log.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_stationary(timeseries):\n    # determine roling stats\n    mov_avg=timeseries.rolling(window=7).mean()\n    mov_std=timeseries.rolling(window=7).std()\n    #plot rolling stats\n    plt.figure(figsize=(12,7))\n    timeseries.plot(label='Original')\n    mov_avg.plot(label='Mov avg')\n    mov_std.plot(label='Mov std')\n    plt.legend(loc='best')\n    plt.title('Rolling mean & standard deviation')\n    \n    # dickey-fuller test\n    print('Result of Dickey-fuller test')\n    dftest=adfuller(timeseries, autolag='AIC')\n    dfout=pd.Series(dftest[:4], index=['Test stats', 'p-value', '#Lag used', 'Number of observation used'])\n    for key, val in dftest[4].items():\n        dfout['Critical value (%s)'%key]=val\n    print(dfout)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_stationary(dif_log)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exponential Decay Transformation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,7))\nedw_avg=train_count_log.ewm(halflife=7, min_periods=0, adjust=True).mean()\ntrain_count_log.plot(label='Log scale')\nedw_avg.plot(label='Exponential Decay Weight MA')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ADCF test\ndif_edw=train_count_log-edw_avg\ndif_edw.dropna(inplace=True)\ntest_stationary(dif_edw)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Time Shift Transformation\n\nGiven a set of observation on the time series:\n* x0,x1,x2,x3,....xn \nThe shifted values will be:\n* null,x0,x1,x2,....xn  <---- basically all xi's shifted by 1 pos to right\n\nThus, the time series with time shifted values are:\n* null,(x1−x0),(x2−x1),(x3−x2),(x4−x3),....(xn−xn−1)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dif_shift=train_count_log-train_count_log.shift()\ndif_shift.dropna(inplace=True)\ntest_stationary(dif_shift)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decomposition\nCheck the nature of residual","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# decom=seasonal_decompose(train_count_log)\ndecom=seasonal_decompose(dif_edw)\n\ntrend=decom.trend\nseasonal=decom.seasonal\nresidual=decom.resid\n\nfig=plt.figure(figsize=(12,7))\nplt.subplot(411)\ntrain_count_log.plot(label='Original')\nplt.subplot(412)\ntrend.plot(label='Trend')\nplt.subplot(413)\nseasonal.plot(label='Seasonal')\nplt.subplot(414)\nresidual.plot(label='Residual')\nfig.tight_layout()\n\ndecom_log_data=residual\ndecom_log_data.dropna(inplace=True)\ntest_stationary(decom_log_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting ACF & PACF","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_zero_intersection(y):\n    # find intersection\n    first_line = LineString(np.column_stack((np.arange(len(y)), y)))\n    second_line = LineString(np.column_stack((np.arange(len(y)), [0]*len(y))))\n    intersection = first_line.intersection(second_line)\n    point=list(LineString(intersection).xy[0])\n    return (point, [0]*len(point))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# select Exponential Decay Weight Transformation\nlag_acf=acf(dif_edw, nlags=20)\nlag_pacf=pacf(dif_edw, nlags=20, method='ols')\n\n# plot ACF\nfig=plt.figure(figsize=(12,7))\nplt.subplot(211)\nplt.plot(lag_acf)\nplt.axhline(y=0, linestyle='--', color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(dif_edw)), linestyle='--', color='gray')\nplt.axhline(y=1.96/np.sqrt(len(dif_edw)), linestyle='--', color='gray')\n# find intersection\nx,y=find_zero_intersection(lag_acf)\nplt.plot(x,y,'o')\nplt.title('Autocorrelation Function') \nprint('Q (MA part): ', x[0])\n\n# plot PACF\nplt.subplot(212)\nplt.plot(lag_pacf)\nplt.axhline(y=0, linestyle='--', color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(dif_edw)), linestyle='--', color='gray')\nplt.axhline(y=1.96/np.sqrt(len(dif_edw)), linestyle='--', color='gray')\n# find intersection\nx,y=find_zero_intersection(lag_pacf)\nplt.plot(x,y,'o')\nplt.title('Partial Autocorrelation Function') \nprint('P (AR part): ', x[0])\n\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# AR Model\nmodel=ARIMA(train_count_log, order=(2,1,0))\nresults_AR=model.fit(disp=0)\n\nplt.figure(figsize=(12,7))\ndif_edw.plot(label='Exponentian Decay Differentiation')\nresults_AR.fittedvalues.dropna(inplace=True)\nresults_AR.fittedvalues.plot(label='Results AR')\ndf=pd.concat([results_AR.fittedvalues, dif_edw], axis=1).dropna()\nplt.title('RSS: %.4f'%sum((df[0]-df['Count'])**2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MA Model\nmodel=ARIMA(train_count_log, order=(0,1,2))\nresults_MA=model.fit(disp=0)\n\nplt.figure(figsize=(12,7))\ndif_edw.plot(label='Exponentian Decay Differentiation')\nresults_MA.fittedvalues.dropna(inplace=True)\nresults_MA.fittedvalues.plot(label='Results AR')\ndf=pd.concat([results_MA.fittedvalues, dif_edw], axis=1).dropna()\nplt.title('RSS: %.4f'%sum((df[0]-df['Count'])**2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ARIMA Model\nmodel=ARIMA(train_count_log, order=(2,1,2))\nresults_ARIMA=model.fit(disp=0)\n\nplt.figure(figsize=(12,7))\ndif_edw.plot(label='Exponentian Decay Differentiation')\nresults_ARIMA.fittedvalues.dropna(inplace=True)\nresults_ARIMA.fittedvalues.plot(label='Results AR')\ndf=pd.concat([results_ARIMA.fittedvalues, dif_edw], axis=1).dropna()\nplt.title('RSS: %.4f'%sum((df[0]-df['Count'])**2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction & Reverse Transformations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# using AR model\npred_ar_dif=pd.Series(results_AR.fittedvalues, copy=True)\npred_ar_dif_cumsum=pred_ar_dif.cumsum()\n\npred_ar_log=pd.Series(train_count_log.iloc[0], index=train_count_log.index)\npred_ar_log=pred_ar_log.add(pred_ar_dif_cumsum, fill_value=0)\npred_ar_log.head()\n\n# inverse of log is exp\npred_ar=np.exp(pred_ar_log)\nplt.figure(figsize=(12,7))\ntrain.Count.plot(label='Train')\npred_ar.plot(label='Pred')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Validation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def validation(order):\n    # forecasting for validation\n    valid_count_log=list(np.log(valid.Count).values)\n    history = list(train_count_log.values)\n    model = ARIMA(history, order=order)\n    model_fit = model.fit(disp=0)\n    output = model_fit.forecast(steps=len(valid))\n    mse = mean_squared_error(valid_count_log, output[0])\n    rmse = np.sqrt(mse)\n    print('Test MSE: %.3f' % mse)\n    print('Test RMSE: %.3f' % rmse)\n    \n    fig=plt.figure(figsize=(12,7))\n    # reverse transform\n    pred=np.exp(output[0])\n    pred=pd.Series(pred, index=valid.index)\n    valid.Count.plot(label='Valid')\n    pred.plot(label='Pred')\n    plt.legend(loc='best')\n    \n    fig=plt.figure(figsize=(12,7))\n    train.Count.plot(label='Train')\n    valid.Count.plot(label='Valid')\n    pred.plot(label='Pred', color='black')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation((2,1,0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test forecasting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def arima_predict_hourly(data, arima_order):\n    # forecasting for testing (Hourly based forecasting)\n    history = data\n    model = ARIMA(history, order=arima_order)\n    model_fit = model.fit(disp=0)\n    output = model_fit.forecast(steps=len(test_original))\n\n    submit=test_original.copy()\n    submit.index=submit.ID\n    submit['Count']=np.exp(output[0])\n    submit.drop(['Unnamed: 0','ID','Datetime','year','month','day','hour'], axis=1, inplace=True)\n    \n    # plot result\n    plt.figure(figsize=(12,7))\n    train_original.index=train_original.Datetime\n    submit.index=test_original.Datetime\n\n    train_original.Count.plot(label='Train')\n    submit.Count.plot(label='Pred')\n    return submit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# forecasting for testing (Hourly based forecasting)\nhistory = list(np.log(train_original.Count).values)\nmodel = ARIMA(history, order=(2,1,0))\nmodel_fit = model.fit(disp=0)\noutput = model_fit.forecast(steps=len(test_original))\n\nsubmit=test_original.copy()\nsubmit.index=submit.ID\nsubmit['Count']=np.exp(output[0])\nsubmit.drop(['Unnamed: 0','ID','Datetime','year','month','day','hour'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot result\nplt.figure(figsize=(12,7))\ntrain_original.index=train_original.Datetime\nsubmit.index=test_original.Datetime\n\ntrain_original.Count.plot(label='Train')\nsubmit.Count.plot(label='Pred')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission\n# submit.to_csv('submit2.csv')\n# score 250 (Best Score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convert to hourly basis manually","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# forecasting for testing (Daily based forecasting)\nhistory = list(np.log(train.Count).values)\nmodel = ARIMA(history, order=(2,1,0))\nmodel_fit = model.fit(disp=0)\noutput = model_fit.forecast(steps=len(test_df))\n\ntest_df['pred']=np.exp(output[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_original['ratio']=train_original['Count']/train_original['Count'].sum() \ntemp=train_original.groupby('hour')['ratio'].sum().reset_index()\n\nmerge=pd.merge(test_df, test_original, on=('day','month', 'year'), how='left')\nmerge['hour']=merge.hour_y\nmerge['ID']=merge['ID_y']\nmerge=merge.drop(['Unnamed: 0_x','ID_x','year', 'month','hour_x',\n                  'Unnamed: 0_y','Datetime','hour_y','ID_y'], axis=1) \npred=pd.merge(merge, temp, on='hour', how='left')\n\n# convert the ratio to the original scale\npred['Count']=pred['pred']*pred['ratio']*24","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,7))\nsubmit=pd.DataFrame(pred.Count.values, columns=['Count'], index=pred.ID)\nsubmit.index=test_original.Datetime\ntrain_original.Count.plot(label='Train')\nsubmit.Count.plot(label='Pred')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.index=test_original.ID\n# submit.to_csv('submit6.csv')\n# score 280","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ARIMA PDQ Param Tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate an ARIMA model for a given order (p,d,q)\ndef evaluate_arima_model(arima_order):\n    # forecasting for validation\n    valid_count_log=list(np.log(valid.Count).values)\n    history = list(train_count_log.values)\n    model = ARIMA(history, order=arima_order)\n    model_fit = model.fit(disp=0)\n    output = model_fit.forecast(steps=len(valid))\n    mse = mean_squared_error(valid_count_log, output[0])\n    rmse = np.sqrt(mse)\n#     print('Test MSE: %.3f' % mse)\n#     print('Test RMSE: %.3f' % rmse)\n    return mse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate combinations of p, d and q values for an ARIMA model\ndef evaluate_models(p_values, d_values, q_values):\n    best_score, best_cfg = float(\"inf\"), None\n    for p in p_values:\n        for d in d_values:\n            for q in q_values:\n                order = (p,d,q)\n                try:\n                    mse = evaluate_arima_model(order)\n                    if mse < best_score:\n                        best_score, best_cfg = mse, order\n                    print('ARIMA%s MSE=%.3f' % (order,mse))\n                except:\n                    continue\n    print('Best ARIMA%s MSE=%.3f' % (best_cfg, best_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate parameters\np_values = [0, 1, 2, 4, 6, 8]\nd_values = range(0, 3)\nq_values = range(0, 3)\nwarnings.filterwarnings(\"ignore\")\nevaluate_models(p_values, d_values, q_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation((8,1,2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# forecasting for testing (Hourly based forecasting)\nhistory = list(np.log(train_original.Count).values)\nmodel = ARIMA(history, order=(8,1,2))\nmodel_fit = model.fit(disp=0)\noutput = model_fit.forecast(steps=len(test_original))\n\nsubmit=test_original.copy()\nsubmit.index=submit.ID\nsubmit['Count']=np.exp(output[0])\nsubmit.drop(['Unnamed: 0','ID','Datetime','year','month','day','hour'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot result\nplt.figure(figsize=(12,7))\ntrain_original.index=train_original.Datetime\nsubmit.index=test_original.Datetime\n\ntrain_original.Count.plot(label='Train')\nsubmit.Count.plot(label='Pred')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission\nsubmit.index=test_original.ID\n# submit.to_csv('submit5.csv')\n# score 260","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}