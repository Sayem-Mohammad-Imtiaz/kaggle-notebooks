{"cells":[{"cell_type":"markdown","metadata":{"_uuid":"a750673c7d535d351d5030e104a7fff134902935","collapsed":true,"_cell_guid":"dbba7a05-1517-4d67-80fc-3054acb784bd"},"source":"<font size=5>Taking it slow</font>\n\nThe majority of this kernel is devoted to basic data preprocessing. As I am a beginner, I'm going to take it quite slow. There won't be too many colorful pictures, except at the very end. In this Kernel I will:\n* determine the ratio of missing values (which I named **ResponseRate** for some reason)\n* convert all columns with values on the ordinal scale or higher to numerical values using the power of **ManualLabor(TM)** to construct the neccessary dictionaries \n* look at the column-wise correlations and add some ramblings\n\nThis Kernel is designed as a starting point for people who want to dive deeper into the numerical part of this dataset. In this respect the preprocessing is as exhaustive as I could make it.\n\n\n\n<font size=5>1. Response rate</font>\n\nA simple and effective measure of data quality is the lack of missing values. We'll start by looking at how these are distributed across the columns. To this end, we will start organizing columns based on the first capital word in their name which I will call **Prefix**."},{"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport re\n\nfrom IPython.display import display, HTML\ndf = pd.read_csv('../input/multipleChoiceResponses.csv', encoding=\"ISO-8859-1\", low_memory=False)\nnum_observations = len(df)\ncolumn_prefs =  df.columns.map(lambda x: re.search('(ML|[A-Z])[a-z]*(?=[A-Z]*[a-z]*)', x).group(0))\n\ndf_meta = pd.DataFrame(df.columns,columns=['ColName'])\ndf_meta['Prefix'] = column_prefs\ndf_meta['ResponseRate'] = 1-df.isnull().sum().values/len(df)\ndf_meta['Dtypes'] = df.dtypes.values\n\ndf_meta.set_index(['Prefix','ColName'],inplace=True)","cell_type":"code","metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"57e87705aa73783bfac0a3f45b0fed9bb0da1b49","_cell_guid":"41213052-fd3e-4f29-a75f-ce58762d0635"},"execution_count":87},{"cell_type":"markdown","metadata":{"_uuid":"db1dc11e8bbf157b223e128213bf5baf013a3b21","_cell_guid":"705d504d-5770-4e68-a9de-2c628572d070"},"source":"Looking at the first few values of our new **df_meta**, we can see that a lot of the prefixes are  associated to only one column. Also, most columns have dtype **object** which usually means they contain a mixture of strings and np.nans. "},{"outputs":[],"source":"display(df_meta.head())","cell_type":"code","metadata":{"_kg_hide-input":true,"_uuid":"76aae63badae56583f76d296969fe858f8f044a5","_cell_guid":"845b63a7-c107-4217-8387-858613ba70f8"},"execution_count":88},{"cell_type":"markdown","metadata":{"_uuid":"f820e1da2adeb203974dd6c583e710973bd59a14","_cell_guid":"abd12ec3-23a4-4c4a-a7ac-296de3178f6a"},"source":"For prefixes that are associated with multiple columns, we can query them like this:"},{"outputs":[],"source":"display(df_meta.loc['ML'])","cell_type":"code","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"_uuid":"eb6f5bb74f9d6dbfed6f1c4f2ed233bc3feb1009","_cell_guid":"99fbb23b-5400-400a-860a-c2ad39fd1fe9"},"execution_count":89},{"cell_type":"markdown","metadata":{"_uuid":"abe90af3b6d8811c596b4dcf9ff39999bf4c2ef1","_cell_guid":"5685193a-98f4-47df-b61f-4720d098c60c"},"source":"Let's get a a more concise overview by grouping columns by **Prefix**. This shows us a few things:\n1.  The majority of prefixes is only represented by one column\n2.  There are three prefixes that are represented by a large number of colums: **Learning**(27), **Job**(33) and **Work**(123). For **Learning** and **Work**, the variance in response rate is high so you may want to break them down  into further subgroups\n3.  The **Compensation** columns which have been popular subjects in other kernels have a response rate of around 30%\n4. Based on what your aim is, you may want to drop columns with low response rates (we'll do this below). However, keep in mind that an answer of 'nan' can also be a meaningful answer itself, depending on how the question was formulated."},{"outputs":[],"source":"def get_metameta():\n    grp = df_meta.groupby(['Prefix'])\n    grp_mean = grp.mean()\n    grp_std = grp.std()\n    df_metameta = grp_mean.merge(grp_std, left_index=True, right_index=True)\n    df_metameta.columns = ['Mean','Std']\n\n    unique_vals, counts = np.unique(column_prefs,return_counts=True)\n\n    df_metameta['Counts'] = counts;\n    df_metameta.sort_values('Mean',ascending=False,inplace=True);\n    return df_metameta\n\ndf_metameta = get_metameta()\ndisplay(df_metameta)","cell_type":"code","metadata":{"_kg_hide-input":true,"_uuid":"7eac5cf08022fca630981ba2a5650f04fbfd447a","_cell_guid":"71afb68d-5320-4f83-ab0b-5d86a1ed4a98"},"execution_count":90},{"cell_type":"markdown","metadata":{"_uuid":"8881c955c417b9b9c2a1e3b19b4ee194850b0bb9","_cell_guid":"67f9778d-5717-45d8-829c-f3352467f195"},"source":"<font size=5>2. Identifying categorical and numerical columns</font>\n\nNow that we have everything needed to prune the data based on **ResponseRate**, the next step is the removal and consolidation of redundant data. For numerical data, this is straightforward: Highly correlated columns should be consolidated into a single column. For starters, let's look at the columns containing numeric **dtypes** (which turns out to be equivalent to all columns that are not dtype **object**). This shows us that currently, we have a total of 13 colums containing numeric data:"},{"outputs":[],"source":"numeric_cols = df.columns[~(df.dtypes == 'object')]\ndisplay(numeric_cols)\nprint('Number of numeric cols:',len(numeric_cols))","cell_type":"code","metadata":{"_kg_hide-input":true,"_uuid":"20280766f7696f4edba7e6943d25c31160046e97","_cell_guid":"f45700ba-ec3f-4f18-b419-b14717eb57e2"},"execution_count":91},{"cell_type":"markdown","metadata":{"_uuid":"26327f7d6a1a984dd22133e3d851cfb3cc72eeab","_cell_guid":"47199b2a-8618-471e-b3d0-d0873a88a965"},"source":"Is this list already exhaustive in terms of our oridnal or higher data? No!  For instance, columns like **CompensationAmount** are missing. There can be a several reasons for that:\n1. The numbers were in an incompatible format, e.g. '123,456 ' where the comma will cause pandas.read_csv() to interpret the input as a string. \n2.  The values might be written out in words, e.g. 'one', 'two', 'three', ... or 'weak', 'medium', 'strong', etc.\n\nWe have 232 columns in total and there is no automatic way to determine which columns qualify as numerical (that I am aware of). It's time for some good old **Manual Labor(TM)**. It turns out that the only column where case 1 applies is **CompensationAmount**. We'll deal with it first. Once we're done we'll dive into **schema.csv** in order to construct dictionaries for the remaining columns.."},{"outputs":[],"source":"# First we deal with CompensationAmount separately\n# we'll also prune a few superstars and people that earn 'too little'. No offence intended.\nthres_max = 400000\nthres_min = 10000\n\ndef replace_if_str(s):\n    if isinstance(s,str):\n        return s.replace(',','').replace('-','')\n    else:\n        return s\n        \ndf['CompensationAmount'] = df['CompensationAmount'].apply(lambda s: replace_if_str(s))\ndf['CompensationAmount'] = df['CompensationAmount'].apply(\n    lambda x: pd.to_numeric(x, errors='ignore', downcast='float')).astype(float)\n\ndf_conv = pd.read_csv('../input/conversionRates.csv')\n\nprice_dict = dict(list(zip(df_conv['originCountry'],df_conv['exchangeRate'])))\ndf['CompensationNormalized'] = df['CompensationAmount'] * df['CompensationCurrency'].map(price_dict)\n\nis_outside_range = ((df['CompensationNormalized']>thres_max) \n                    | (df['CompensationNormalized']<thres_min))\ndf.at[is_outside_range,'CompensationNormalized'] = np.nan\n","cell_type":"code","metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"ccbba0296e3fffdfcbd53a3fd686b6236d8f291a","_cell_guid":"2c78f914-8064-49ef-8ee3-87b01a6e28c0"},"execution_count":92},{"outputs":[],"source":"df_schema = pd.read_csv('../input/schema.csv')\ndisplay(df_schema.head())\ndisplay(df_schema['Asked'].unique())","cell_type":"code","metadata":{"_kg_hide-input":true,"_uuid":"d5d7df46481eff49af1231ae58cabb89dca35d6f","_cell_guid":"feaa0a44-65f0-4d44-a0bc-50bae60cac5e"},"execution_count":93},{"cell_type":"markdown","metadata":{"_uuid":"2a59b5a71f264727d56f33fe30a47d698db04f63","_cell_guid":"9bb23f88-5f47-46dd-b454-d79f7100eff3"},"source":"Now that we've fixed **CompensationAmount** we'll take a look at **schema.csv**. We can make the following observations here:\n1. You may not have been aware of it but not all questions were presented to all subjects. This is indicated in the column **Asked** which has 9 unique categories.\n2. If we want to determine what kind fo scale a column is on, we should look at **Question**. For this part, I suggest you open the file locally in Excel, simply because it's more comfortable.\n\nLet's compile a list of of columns that we want to transform into numerical values (Name, index/indices in xls-1, dictionary). Note that I hid the section containing the actual dictionary construction because it's long and boring:"},{"outputs":[],"source":"df_numlis = pd.DataFrame(list(zip(['Age', 'TitleFit', 'LearningPlatformUsefulness', \n                                   'LearningDataScienceTime', 'JobSkillImportance', \n                         'TimeSpentStudying', 'FormalEducation', 'Tenure', 'LearningCategory',\n                         'ParentsEducation', 'EmployerSize', 'EmployerSizeChange','EmployerMLTime',\n                                   'WorkToolsFrequency', 'WorkMethodsFrequency', \n                         'Time', 'AlgorithmUnderstandingLevel', 'WorkChallengeFrequency', 'RemoteWork',\n                         'CompensationAmount','SalaryChange','JobSatisfaction','JobHuntTime',\n                         'JobFactor'], ['4','13','29-47','56','57-66','77','84','87','92-98',\n                                       '103','106', '107', '108','127-174','185-214','221-226','228','232-252',\n                                       '266','267','269','271','274','275-290'])))\ndf_numlis.columns = ['ColName','Idx/Indices']\n\ndf_numlis.set_index('ColName',inplace=True)","cell_type":"code","metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"d7dbc270db49953866d963243e9e6be37215ad3e","_cell_guid":"5735d0d4-3bdd-48b3-bde8-647a270dfde0"},"execution_count":94},{"outputs":[],"source":"did_match = lambda s,pat: not(re.search(pat,s)==None) if isinstance(s,str) else False\ndef make_did_match(pat): return lambda s: did_match(s,pat)\n\n#define dictionaries\n#Age, is already numerical\ndf_numlis['Dict'] = None\n\ndf_numlis.at['TitleFit','Dict']  = dict(list(zip(['Poorly', 'Fine', 'Perfectly', np.nan],[0,1,2,np.nan])))\n\ndf_numlis.at['LearningPlatformUsefulness','Dict'] = dict(list(zip(\n    [np.nan, 'Somewhat useful', 'Very useful', 'Not Useful'],[np.nan,1,2,0])))\n\ndf_numlis.at['LearningDataScienceTime','Dict'] = dict(list(zip(\n    [np.nan, '1-2 years', '< 1 year', '3-5 years', '15+ years',\n       '5-10 years', '10-15 years'],[np.nan, 1, 0, 2, 5, 3, 4])))\n\ndf_numlis.at['JobSkillImportance','Dict'] = dict(list(zip(\n    [np.nan, 'Nice to have', 'Unnecessary', 'Necessary'],[np.nan,1,0,2])))\n\ndf_numlis.at['TimeSpentStudying','Dict'] = dict(list(zip([np.nan, '2 - 10 hours', '0 - 1 hour', \n                                                          '11 - 39 hours', '40+'],\n                                       [np.nan,1,0,2,3])))\n\ndf_numlis.at['FormalEducation','Dict'] = dict(list(zip([\"Bachelor's degree\", \"Master's degree\", 'Doctoral degree', np.nan,\n       \"Some college/university study without earning a bachelor's degree\",\n       'I did not complete any formal education past high school',\n       'Professional degree', 'I prefer not to answer'], \n                                    [2,4,5,np.nan,1,0,3,np.nan]))) # this one is kinda hard to assess\n\ndf_numlis.at['Tenure','Dict'] = dict(list(zip(['More than 10 years', 'Less than a year', '3 to 5 years',\n       '6 to 10 years', '1 to 2 years', np.nan,\n       \"I don't write code to analyze data\"],[4,0,2,3,1,np.nan,np.nan])))\n\n\n#LearningCategory.* is already numerical\n\n\ndf_numlis.at['ParentsEducation','Dict'] = dict_TSS = dict(list(zip(['A doctoral degree', \"A bachelor's degree\", 'High school',\n       'Primary/elementary school', \"A master's degree\", np.nan,\n       \"Some college/university study, no bachelor's degree\",\n       'A professional degree', 'I prefer not to answer',\n       \"I don't know/not sure\", 'No education'],\n                                                [7, 4, 2,\n                                                    1, 6, np.nan,\n                                                    3,\n                                                    5, np.nan,\n                                                 np.nan,0])))\n\ndf_numlis.at['EmployerMLTime','Dict'] = dict(list(zip(['3-5 years', np.nan, \"Don't know\", '6-10 years', '1-2 years',\n       'More than 10 years', 'Less than one year'], [2, np.nan, np.nan, 3, 1, 4, 0])))\n\ndf_numlis.at['EmployerSize','Dict'] = dict(list(zip(['100 to 499 employees', np.nan, '5,000 to 9,999 employees',\n       '500 to 999 employees', '10,000 or more employees',\n       '20 to 99 employees', 'Fewer than 10 employees', \"I don't know\",\n       '1,000 to 4,999 employees', '10 to 19 employees',\n       'I prefer not to answer'],\n                                  [3,np.nan,6,\n                                  4, 7,\n                                  2, 0, np.nan,\n                                  5, 1,\n                                  np.nan])))\n\ndf_numlis.at['EmployerSizeChange','Dict'] = dict(list(zip(['Increased slightly', np.nan, 'Stayed the same',\n       'Increased significantly', 'Decreased significantly',\n       'Decreased slightly'],\n                                  [1, np.nan, 0,\n                                  2, -2,\n                                  -1])))\n\n\ndf_numlis.at['WorkToolsFrequency','Dict']=dict(list(zip([np.nan, 'Sometimes', 'Often', 'Most of the time', 'Rarely'],\n                                [np.nan, 1, 2, 3, 0])))\n\ndf_numlis.at['WorkMethodsFrequency','Dict'] = df_numlis.loc['WorkToolsFrequency','Dict']\n\n# # Time.* is already numerical\n\ndf_numlis.at['AlgorithmUnderstandingLevel','Dict'] = dict(list(zip(['Enough to explain the algorithm to someone non-technical', np.nan,\n       'Enough to refine and innovate on the algorithm',\n       'Enough to tune the parameters properly',\n       'Enough to code it again from scratch, albeit it may run slowly',\n       'Enough to run the code / standard library',\n       'Enough to code it from scratch and it will run blazingly fast and be super efficient'],\n                                     [3,np.nan,\n                                     4,\n                                     1,\n                                     2,\n                                     0,\n                                     5])))\n\ndf_numlis.at['WorkChallengeFrequency','Dict'] = df_numlis.loc['WorkToolsFrequency','Dict']\n\n\ndf_numlis.at['RemoteWork','Dict'] = dict(list(zip(['Always', np.nan, 'Rarely', 'Sometimes', \n                                            'Most of the time', 'Never', \"Don't know\"],\n                                           [4, np.nan, 1, 2, 3, 0, np.nan])))\n\n# CompensationAmount actually has a different problem: commas\n\ndf_numlis.at['SalaryChange','Dict'] = dict(list(zip(['I am not currently employed', np.nan, \n                                                     'Has increased 20% or more',\n       'I do not want to share information about my salary/compensation',\n       'Has stayed about the same (has not increased or decreased more than 5%)',\n       'Has increased between 6% and 19%',\n       'Has decreased between 6% and 19%',\n       'I was not employed 3 years ago', 'Has decreased 20% or more',\n       'Other'],[np.nan, np.nan, 2,\n                np.nan,\n                0,\n                1,\n                -1,\n                np.nan, -2])))\n\n\ndf_numlis.at['JobSatisfaction','Dict'] = dict(list(zip(['5', np.nan, '10 - Highly Satisfied', '2', '8', '7', '6', '9',\n       '1 - Highly Dissatisfied', 'I prefer not to share', '3', '4'],\n                                     [5, np.nan, 10, 2, 8, 7, 6, 9, 1, np.nan, 3, 4])))\n\n\ndf_numlis.at['JobHuntTime','Dict']= dict(list(zip([np.nan, '1-2', '0', '3-5', '11-15', '20+', '6-10', '16-20'],\n                                     [np.nan, 1, 0, 2, 4, 6, 3, 5])))\n\ndf_numlis.at['JobFactor','Dict'] = dict(list(zip([np.nan, 'Very Important', 'Somewhat important', 'Not important'],\n                                     [np.nan, 2, 1, 0])))\n\ndf_numlis","cell_type":"code","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"_uuid":"63afa45392a10f5398bc7c7d5e2446571e401b48","_cell_guid":"664b3de9-a7ec-40f5-a6b2-5e4370d4526c"},"execution_count":95},{"cell_type":"markdown","metadata":{"_uuid":"770d967f1826f29aea43a050ec04be01da7de9b0","_cell_guid":"c85815ce-3186-4c31-b470-6c8afb798554"},"source":"Once we've built the above DF, converting our numerical columns to actual numerical values is pretty simple:"},{"outputs":[],"source":"# A small helper function for finding substrings\ndid_match = lambda pat,s: not(re.search(pat,s)==None) if isinstance(s,str) else False\ndid_match_full = lambda pat,s: re.search(pat,s).group(0)==s if did_match(pat,s) else False\ndef make_did_match(pat): return lambda s: did_match(pat,s)\ndef make_did_match_full(pat): return lambda s: did_match_full(pat,s)\n\ndf_n = df.copy()\nis_single = ~df_numlis['Idx/Indices'].apply(make_did_match('.*-.*')) #when there is a minus\n\n# First, deal with prefixes representing one column\nfor idx in df_numlis.loc[is_single].index:\n     if (df[idx].dtype == 'object'):\n        df_n[idx] = df[idx].map(df_numlis.loc[idx,'Dict'])\n\nall_columns = df_meta.index.get_level_values(1)\n\n# Then, deal with the rest\nfor idx in df_numlis.loc[~is_single].index:    \n    ix = all_columns.map(make_did_match_full(idx +'.*')).values.astype(np.bool_)\n\n    for idx_sub in all_columns[ix]:\n        if (df_n[idx_sub].dtype == 'object'):\n            df_n[idx_sub] = df[idx_sub].map(df_numlis.loc[idx,'Dict'])\n","cell_type":"code","metadata":{"scrolled":true,"_kg_hide-input":true,"collapsed":true,"_uuid":"d107e2f7643f9ece1fd93487cffe006dfd9c2e7b","_cell_guid":"252de28a-9c9c-46e6-9a05-2ea3aa1e731e"},"execution_count":96},{"cell_type":"markdown","metadata":{"_uuid":"04f119db913a2b85d3e69d72a9b33cda235acd1f","_cell_guid":"a5490852-b55a-4a07-b3a3-69ee2cdefc9d"},"source":"It turns out our work is finally paying off: we've now got a lot larger number of numerical columns. Now it's time to actually do something with them. We start with a plot showing the column-wise correlations."},{"outputs":[],"source":"numeric_cols = df_n.columns[~(df_n.dtypes == 'object')]\ndisplay(numeric_cols)\nprint('Number of numeric cols:',len(numeric_cols))","cell_type":"code","metadata":{"_kg_hide-input":true,"_uuid":"33b453a119dc8b5fe1f70608d21c3afaff038329","_cell_guid":"235cf076-faf0-4121-bb84-529b73df007d"},"execution_count":97},{"outputs":[],"source":"import seaborn as sns\n\ndf_nonly = df_n[numeric_cols]\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=[20, 20])\ncorrs=df_nonly.corr()\nmh = sns.heatmap(corrs)\nmh.tick_params(labelsize = 15)","cell_type":"code","metadata":{"_kg_hide-input":true,"_uuid":"6f937988d1bcac3a0c7e4c39a3423bbd93ec9af9","_cell_guid":"ad110920-05b6-4ad5-a83e-421e105761e9"},"execution_count":98},{"cell_type":"markdown","metadata":{"_uuid":"33a29627df07e728c5dbd878f47d0e1b8ae00595","_cell_guid":"a77dde5d-4ee0-468d-9109-9d525695143c"},"source":"Among the mess, we can see that there is a fair amount of pairs that show pretty high correlation. The large blank bars stem from combinations of columns that are mutually exclusive. Accordingly, they contain correlation values of np.nan.\n\nLet's see if we can find out which column pairs exhibit the highest correlation values using [some nice code](https://stackoverflow.com/questions/17778394/list-highest-correlation-pairs-from-a-large-correlation-matrix-in-pandas)."},{"outputs":[],"source":"#code copied from arun's answer\ndef get_redundant_pairs(df):\n    '''Get diagonal and lower triangular pairs of correlation matrix'''\n    pairs_to_drop = set()\n    cols = df.columns\n    for i in range(0, df.shape[1]):\n        for j in range(0, i+1):\n            pairs_to_drop.add((cols[i], cols[j]))\n    return pairs_to_drop\n\ndef get_top_abs_correlations(df, n=5):\n    au_corr = df.corr().unstack()\n    labels_to_drop = get_redundant_pairs(df)\n    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n    return au_corr[0:n]\n\nprint(\"Top Correlations 10\")\nprint(get_top_abs_correlations(df_nonly, 10))","cell_type":"code","metadata":{"_kg_hide-input":true,"_uuid":"a08c18a29778102618ccd1b7aeef4ca692e8e4ea","_cell_guid":"d480a325-4f55-435a-93c6-3816709024d8"},"execution_count":99},{"cell_type":"markdown","metadata":{"_uuid":"9f5699d4147ed8504d1800142cefd4c1a9020354","collapsed":true,"_cell_guid":"cb2129cf-9384-484c-90ee-fe19baad87d7"},"source":"<font size=5>3. Disappointment</font>\n\nThis result is, quite... disappointing. We're observing a lot of exactly correlated (=1) values in the **Work-**prefixed columns. If we think back to our earlier observations, this is not surprising at all: we know that a lot of these columns had low response rates. Most likely, very few subjects responded for these particular questions and left the same response, an event that is quite likely to happen with 1/2 x 123 x 123 column pairs.\n\nTo resolve this issue, we'll try to drop columns that have a response rate lower than 25% to see what kind of difference it makes.\n\n"},{"outputs":[],"source":"respg25 = df_meta[df_meta['ResponseRate']>0.25].index.get_level_values(1)\ndf_nonly_pruned = df_n.loc[:,respg25.intersection(numeric_cols).insert(0,'CompensationNormalized')]\n\n\nprint(\"Top Correlations 50\")\nprint(get_top_abs_correlations(df_nonly_pruned, 50))\ndf_nonly_pruned\n\n#import matplotlib.pyplot as plt\nplt.figure(figsize=[20, 20])\nmh = sns.heatmap(df_nonly_pruned.corr())\nmh.tick_params(labelsize = 15)\n","cell_type":"code","metadata":{"scrolled":true,"_kg_hide-input":true,"_uuid":"d92ebb1c8c3bbb728cdae9485f4172c0f2b483cb","_cell_guid":"c602a926-23da-45ae-8b2d-26e6db805271"},"execution_count":100},{"cell_type":"markdown","metadata":{"_uuid":"6de7f9c7b0ece30af1b9e16455922bdcce530447","_cell_guid":"c9e23cc3-7038-4032-ad61-55cd76ec9219"},"source":"<font size=5>4. Summary: Getting better</font>\n\nNow this looks much more like it! Let's see what we have here:\n* The strongest correlations revolve around **Tenure** which is strongly correlated to other temporal variables such as **LearningDataScienceTime** and **Age**.  This makes sense, obviously. Being longer in the business also means that you get more **CompensationNormalized**. Also, Tenure correlates with variables indicating skill level such as **AlgorithmUnderstandingLevel** and people with long tenure seem to value work experience (**LearningCategoryWork**) which again makes sense.\n* An interesting result concern R and Python:  **WorkToolsFrequencyR** scores its highest correlation value paired with **WorkMethodsFrequencyDataVisualization** whereas **WorkToolsFrequencyPython** is most strongly correlated with **TimeModelBuilding**. From my personal experience, this finding is believable: R is more popular with the analytics/consultant crowd who naturally have higher requirements in terms of visualization. Python on the other hand seems to be the primary language for ML engineers that make use of high level libraries such as TF, Keras, PyTorch and friends.\n* Another interesting line of observation can be found in the **Employer**-prefixed columns. Given the current trends of digital business transformation, it's only natural to see **EmployerSize** strongly correlate with **EmployerMLTime**. There are however, also some points that may be more universal, such as the correlation between **EmployerSize** and **EmployerSizeChange**. The growth of employer size seems to also positively correlate with **JobSatisfaction**.\n* Speaking of **JobSatisfaction**, a pretty interesting result is that it scores the highest when paired with **TitleFit**, when you might naively think that factors such as work environment or compensation might be more important. This might be the perfect place to insert some some cheesy self-perception-happiness-quote. But of course, a data scientist's **JobSatisfaction** is still well-correlated with positive **SalaryChange**.\n* Also, with respect to our original idea of removing columns with high correlations, it turned out that filtering by **ResponseRate** already achieves that\n\nWhat's next?\nAs the Kernel is getting rather long and unwieldy, I'd like to come to an end after taking a look at the correlation values for **JobSatisfaction** and **CompensationNormalized**, because we're all curious to know where they differ and where they're the same, right? \n\nOriginally, I wasn't going to make any comments on them but isn't it interesting that we see negative correlations for **TimeVisualizing** in both plots? Combined with the above, this might imply that **JobSatisfaction**/**CompensationNormalized** is less correlated with **WorkToolsFrequencyR** than with **WorkToolsFrequencyPython**...\n\n\n<font size=4>Thanks for dropping by. Stay tuned for pt. 2!</font>\n"},{"outputs":[],"source":"\ncorrs = df_nonly_pruned.corr()\ndata = (corrs['JobSatisfaction'].sort_values(ascending=False)\n.drop(['JobSatisfaction','LearningDataScienceTime']))\nplt.figure(figsize=[20,25])\nplt.rcParams[\"axes.labelsize\"] = 50\nbh = sns.barplot(data.values,data.index)\nbh.tick_params(labelsize = 25)\nbh.axes.set_title('JobSatisfaction',fontsize=40)\nplt.xlabel('Correlation', fontsize=35)\n\n\ndata = (corrs['CompensationNormalized'].sort_values(ascending=False)\n.drop(['CompensationNormalized','LearningDataScienceTime']))\nplt.figure(figsize=[20,25])\nplt.rcParams[\"axes.labelsize\"] = 50\nbh = sns.barplot(data.values,data.index)\nbh.tick_params(labelsize = 25)\nbh.axes.set_title('CompensationNormalized',fontsize=40)\nplt.xlabel('Correlation', fontsize=35)\n\n\n","cell_type":"code","metadata":{"_kg_hide-input":true,"_uuid":"5b5e0a7a2e32fb36a13ce075ae8db137e3c58e08","_cell_guid":"01f77487-86a2-40f7-a01f-5b8a13d4ea8c"},"execution_count":101},{"outputs":[],"source":"a = corrs.loc['WorkToolsFrequencyPython','JobSatisfaction']\nb = corrs.loc['WorkToolsFrequencyR','JobSatisfaction']\nc = corrs.loc['WorkToolsFrequencyPython','CompensationNormalized']\nd = corrs.loc['WorkToolsFrequencyR','CompensationNormalized']\n\n\nplt.plot([a, c])\nplt.plot([b, d])\nplt.legend(['Python','R'])\nplt.ylabel('correlation',fontsize=14)","cell_type":"code","metadata":{"_kg_hide-input":true,"_uuid":"56cb47caed970c69593d9b6dcd0c6b8d45fcd7a9","_cell_guid":"93594520-84d0-4e8b-93b7-aa02ce61808d"},"execution_count":102},{"cell_type":"markdown","metadata":{"_uuid":"17003d14a6fc07000daf4b238932698503bc412c","_cell_guid":"0cc2d177-cb34-4461-b34e-7371f4236230"},"source":"<font size=5>Bonus:</font>\n\nAn obscure detail from **freeformResponses.csv:**\n"},{"outputs":[],"source":"ffr = pd.read_csv('../input/freeformResponses.csv',low_memory=False)\nffr_gender = ffr['GenderFreeForm']\nffr_gender = ffr_gender[ffr_gender.notnull()]\n\nnum_copters = ffr_gender.apply(lambda s: re.search('.*((h|H)elicopter|AH-64).*',s)).notnull().sum()\nprint('Insight of the day: {0:4.4f}% of Kaggle users sexually identfy themselves as attack helicopters!'.format(100*num_copters/num_observations))\n","cell_type":"code","metadata":{"_uuid":"ced78d93364f3df88bdd067c1d91b2983796acb9","_cell_guid":"9741548b-2582-4383-80af-e448ea992a02"},"execution_count":103}],"nbformat":4,"metadata":{"language_info":{"nbconvert_exporter":"python","pygments_lexer":"ipython3","name":"python","file_extension":".py","mimetype":"text/x-python","version":"3.6.3","codemirror_mode":{"version":3,"name":"ipython"}},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat_minor":1}