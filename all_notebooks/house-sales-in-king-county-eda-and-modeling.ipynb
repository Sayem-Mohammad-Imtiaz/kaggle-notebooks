{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing all the required libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom mlxtend.feature_selection import SequentialFeatureSelector\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nimport os # accessing directory structure\npd.set_option('display.max_columns',None)   #code to dispaly all the columns in the dataframe\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(action='ignore')\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/housesalesprediction/kc_house_data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape\n#21613 rows , 21 columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[~df.apply(np.isreal).any(1)]    #checking for any non real value in the dataset\n#there are no non real values in any column","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#extrating just the year from the date column as we will be using only the year\ndf['new_date']=df['date'].str[:4]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dropping the date column as we made a new_date column which has just the year\ndf.drop(['date','id'],axis=1,inplace=True)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['new_date']=df['new_date'].astype('int')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['age']=np.NaN   #adding a new column 'age' to identify how old is the house","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,j in enumerate(df['yr_renovated']):\n    if(j==0):\n        df['age'][i]=df['new_date'][i]-df['yr_built'][i]\n    else:\n        df['age'][i]=df['new_date'][i]-df['yr_renovated'][i]\n        \n#calculating how old the house is and storing it in the age column","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# as we have used the yr_renovated , yr_built,new_date column to find the age of the house so we drop these column as these are of no use\ndf.drop(['yr_built','yr_renovated','new_date'],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we will not be using the zipcode,lat,long columns\ndf.drop(['lat','zipcode','long'],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the distribution of all the variables\nfor i in df.columns:\n    sns.distplot(df[i])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Almost all the columns have skewness\n#But sqft_lot15,sqft_lot are highly right skewed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,15))\nsns.pairplot(df,diag_kind='kde')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.heatmap(df.corr(),annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sqft_living have a positive linear relationship with the price\n# sqft_above have a positive linear relationship with the price","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#sqft_living15,sqft_above,grade,sqft_living,bathrooms seems to have correlation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking for outliers in the dataset\nfor i in df.columns:\n    sns.boxplot(df[i])\n    plt.show()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The bedroom column has some outliers\n#The bathroom column has some outliers\n#The sqft_living has outliers\n#The sqft_lot column has lot of outliers\n#The floor column has no outliers\n#The grade column has many otliers\n#The sqft_above has lot of outliers\n#The sqft_basement has lot of outliers\n#The sqft_living15 has lot of outliers\n#The sqft_lot15 has lot of outliers\n#The age column has no outliers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building a base model with all the features","metadata":{}},{"cell_type":"code","source":"X=df.drop('price',axis=1)\ny=df['price']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vif_df=pd.DataFrame()   #making a dataframe for the vif of all the columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vif_df['Columns']=X.columns\nvif_df['VIF']=[variance_inflation_factor(X.values,i) for i in range(len(X.columns))]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vif_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Bedroom,bathroom,floors,condition,grade,sqft_living have high multicolinearity\n#sqft_living,sqft_above,sqft_basement have very high multicolinearity","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#splitting data into test set and train set\nxtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.25,random_state=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtrain.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ytrain.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtest.shape","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ytest.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#performing scaling, transformation on the training set and then building a Linear Regression Model\npipe=Pipeline((\n('scale',StandardScaler()),\n('transform',PowerTransformer(method='yeo-johnson')),\n('lr',LinearRegression())\n))\npipe.fit(xtrain,ytrain)\npipe.score(xtest,ytest)\n#the performance of the model is not good","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#building a linear regression model\npipe=Pipeline((\n('lr',LinearRegression()),\n))\npipe.fit(xtrain,ytrain)\nlr_score=pipe.score(xtest,ytest)\n#the model performs better without scaling and transformation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#building a lasso regression model\npipe=Pipeline((\n('lasso',Lasso()),\n))\npipe.fit(xtrain,ytrain)\nlasso_score=pipe.score(xtest,ytest)\n#no improvement in the model with lasso model as well","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#building a ridge regression model\npipe=Pipeline((\n('lasso',Ridge()),\n))\npipe.fit(xtrain,ytrain)\nridge_score=pipe.score(xtest,ytest)\n#no improvement in the model with ridge model as well","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#building a Decision tree regression model\npipe=Pipeline((\n('pt',PowerTransformer()),\n('dt',DecisionTreeRegressor()),\n))\npipe.fit(xtrain,ytrain)\ndt_score=pipe.score(xtest,ytest)\n#no improvement in the model with Decision tree model as well","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#building a RandomForest regression model\npipe=Pipeline((\n('pt',PowerTransformer()),\n('rf',RandomForestRegressor()),\n))\npipe.fit(xtrain,ytrain)\nrf_score=pipe.score(xtest,ytest)\n#the model performed better RandomForest model as well","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#building a GradientBossting regression model\npipe=Pipeline((\n('pt',PowerTransformer()),\n('gb',GradientBoostingRegressor()),\n))\npipe.fit(xtrain,ytrain)\ngb_score=pipe.score(xtest,ytest)\n#we can see that there is an increase in the performance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#building a AdaBoost regression model\npipe=Pipeline((\n('adaboost',AdaBoostRegressor()),\n))\npipe.fit(xtrain,ytrain)\nadgb_score=pipe.score(xtest,ytest)\n#the performace degraded with adaBoost madel","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#building a K-nn regression model\npipe=Pipeline((\n('adaboost',KNeighborsRegressor()),\n))\npipe.fit(xtrain,ytrain)\nknn_score=pipe.score(xtest,ytest)\n#the performace degraded with K-nn madel","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l1=['LinerRegression','Lasso','Ridge','DecisionTree','RandomForest','GradientBoost','AdaBoost','K-nn']\nl2=[lr_score,lasso_score,ridge_score,dt_score,rf_score,gb_score,adgb_score,knn_score]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_df=pd.DataFrame({'Models':l1,'Score':l2})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.barplot(score_df['Models'],score_df['Score'])\nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#as we see from the graph random forest and gradient bossting performs better than other and both have almost equal score\n#so we perform cross-validation to find the best out of the two","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now we perform the k-fold cross validation on RandomForestAlgorithm\nrandomforest_score=cross_val_score(estimator=RandomForestRegressor(),X=X,y=y,cv=10,scoring='r2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"randomforest_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(randomforest_score)\n#mean score for RandomforestRegressor","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now we perform the k-fold cross validation on GradientBoostingRegressorAlgorithm\ngradientboosting_score=cross_val_score(estimator=GradientBoostingRegressor(),X=X,y=y,cv=10,scoring='r2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gradientboosting_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.mean(gradientboosting_score)\n#mean score for RandomforestRegressor","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Out of the RandomForestRegressor and GradiantBoostingRegressor, RandomForestRegressor performs better so we tune the hyperparameters for better result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#finding the best hyperparameters so as to increase the accuracy of the model\nparams={'n_estimators':[10,20,50,100,200,500],'max_depth':[2,5,8,9,12]}\ngrid=GridSearchCV(estimator=RandomForestRegressor(),param_grid=params,cv=10,scoring='r2',n_jobs=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid.fit(xtrain, ytrain)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid.best_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#final model with RandomForestRegressor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X1=df.drop(['price'],axis=1)\ny1=df['price']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtrain1,xtest1,ytrain1,ytest1=train_test_split(X1,y1,test_size=0.25,random_state=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe=Pipeline((\n('pt',PowerTransformer()),\n('rf',RandomForestRegressor(n_estimators=200,max_depth=12)),\n))\npipe.fit(xtrain1,ytrain1)\npipe.score(xtest1,ytest1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Final model with RandomForestRegressor with 74.48% accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"price_pred=pipe.predict(xtest1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.DataFrame({'price_actual':ytest1,'price_predicted':price_pred})\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}