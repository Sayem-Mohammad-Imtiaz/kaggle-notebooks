{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Web Scraping\n\nData scraping is one of the most used ways to collect data. In simple terms it means, to get HTML code for a webpage and scan it for data.  \n![](https://rukminim1.flixcart.com/image/312/312/kfpq5jk0-0/headphone/c/n/6/rockerz-400-rockerz-410-boat-original-imafw45vhyrax3zj.jpeg?q=70)"},{"metadata":{},"cell_type":"markdown","source":"**[Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/)** and **[Selenium](https://www.selenium.dev/)** are most used packages for scanning data.  \nIn this notebook we'll see how to use Beautiful Soup and get reviews of **[boAt Rockerz 400](https://www.flipkart.com/boat-rockerz-400-bluetooth-headset/p/itm14d0416b87d55)**  \n**Let's Get started**"},{"metadata":{},"cell_type":"markdown","source":"## Importing modules\n**[Request](https://requests.readthedocs.io/en/master/)** Module is used to get the HTML code for the URL given.\n\n**Note**: *Not all webpages can be requested. For example most social media does not allow to scrape data due to privacy issues. These pages require special access of Developer APIs to scrape data.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"import requests \nfrom bs4 import BeautifulSoup \nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Setting variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"URL = \"https://www.flipkart.com/boat-rockerz-400-bluetooth-headset/product-reviews/itm14d0416b87d55?pid=ACCEJZXYKSG2T9GS&lid=LSTACCEJZXYKSG2T9GSVY4ZIC&marketplace=FLIPKART&page=1\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Requesting desired Webpage"},{"metadata":{"trusted":true},"cell_type":"code","source":"r = requests.get(URL)    \nsoup = BeautifulSoup(r.content, 'html.parser') \nprint(soup.prettify()[6000:7000])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you're know HTML, this might look familiar.  \nNext we'll see how to get our data."},{"metadata":{},"cell_type":"markdown","source":"# Extracting data\n\nA website can be divided into many components and sub components. At times it is a complex grid structure which needs to decoded.  \n1. You can easily view the structure by `Ctrl + Shift + C`\n2. Now if you hover on any review, you'll notice that each block has name `col._2wzgFH.K0kLPL`\n![](https://github.com/kabirnagpal/Web-Scraping/blob/main/Images/div-name.png?raw=true)\n\n3. Further this is divided into mutiple rows. The first row contains the rating, while the second contains the actual review. \n![](https://github.com/kabirnagpal/Web-Scraping/blob/main/Images/rating.png?raw=true)\n![](https://github.com/kabirnagpal/Web-Scraping/blob/main/Images/review.png?raw=true)\nWe'll follow exact same approach to extract data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting all review blocks\n## Note col._2wzgFH.K0kLPL means 3 entities namely 'col', ' _2wzgFH' and 'K0kLPL' \n## This is written in HTML as 'col _2wzgFH K0kLPL'\n## This can also be seen in Bullet 3\n\nrow = soup.find_all('div',attrs={'class':'col _2wzgFH K0kLPL'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list to store data\ndataset = []\n\n# iteration over all blocks\nfor i in row: \n    \n    # finding all rows within the block\n    sub_row = i.find_all('div',attrs={'class':'row'})\n        \n    # extracting text from 1st and 2nd row\n    rating = sub_row[0].find('div').text\n    review = sub_row[1].find('div').text\n    \n    # appending to data\n    dataset.append({'review': review , 'rating' : rating})\n\ndataset[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Iterating over multiple Pages"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = []\n\n# iterating over 50 pages of reviews\nfor i in tqdm(range(1,50)):\n\n    URL = f\"https://www.flipkart.com/boat-rockerz-400-bluetooth-headset/product-reviews/itm14d0416b87d55?pid=ACCEJZXYKSG2T9GS&lid=LSTACCEJZXYKSG2T9GSVY4ZIC&marketplace=FLIPKART&page={i}\"\n    r = requests.get(URL)    \n    soup = BeautifulSoup(r.content, 'html.parser') \n\n    cols = soup.find_all('div',attrs={'class':'col _2wzgFH K0kLPL'})\n\n    for col in cols:\n        row = col.find_all('div',attrs={'class':'row'})\n\n        rating = row[0].find('div').text\n        review = row[1].find('div').text\n\n        dataset.append({'review': review , 'rating' : rating})\nlen(dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n# pd.DataFrame(dataset).to_csv('data.csv',index=False)\ndata = pd.read_csv('../input/flipkart-customer-review-and-rating/data.csv')\ndata.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}