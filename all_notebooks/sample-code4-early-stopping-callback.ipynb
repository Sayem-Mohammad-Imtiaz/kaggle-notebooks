{"cells":[{"metadata":{},"cell_type":"markdown","source":"このNotebookではKerasのコールバックの１つであるEarlyStoppingを利用して、\n自動で学習を止めるようにします。\n"},{"metadata":{},"cell_type":"markdown","source":"# 調整パラメータ - Config\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"resize_w = 256  # 画像のリサイズ幅を指定\nresize_h = 256  # 画像のリサイズ高さを指定\nchannel = 3  # 画像のカラーチャンネルを指定\n\ntest_size_rate = 0.1 # データセットをTrain/Testに分割する際の、Test dataの比率（0.0〜1.0）\n\nepochs = 500  # 学習回数を指定\nn_batch = 8  # 一度にまとめて学習するデータ数。\n             # 値が大きいと学習が安定し早く進むが、大きすぎると各データの特徴が平均化されるため逆に学習が進まない。\n             # (GPU計算速度の関係で2のn乗を指定するのがおすすめ)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 前準備 - Preprocess code"},{"metadata":{},"cell_type":"markdown","source":"## Preprocess1. 画像処理関数定義 - Image Processing Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\n# 画像が大きいと計算が遅いため、リサイズ縮小\ndef resize(tmp_image):\n    return cv2.resize(tmp_image , (resize_h, resize_w))\n\n# 4次元配列化()　\ndef to_4d(tmp_image):\n    return tmp_image.reshape(1, resize_h, resize_w, channel)   \n\n# 256段階の色調を0.0~1.0にする\ndef normalize(tmp_image):\n    return tmp_image / 255.0\n\n# 画像の前処理付きロード\ndef load_preprocessed_image(image_filepath):\n    tmp_image = cv2.imread(image_filepath)\n    tmp_image = resize(tmp_image)\n    tmp_image = normalize(tmp_image)\n    tmp_image = to_4d(tmp_image)\n\n    return tmp_image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess2. 画像とラベルのロード - Load Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nroot_dir = \"/kaggle/input/mj1-anomaly-images-detection-challenge/\"\ntrain_csv_filepath = root_dir + \"train.csv\"\n\n# ファイルの読み込み\ntrain_df = pd.read_csv(train_csv_filepath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom keras.utils import np_utils\n\nimages = None\nfor fn in train_df['filename']:\n    image_filepath = root_dir + 'train/' + fn\n    tmp_image = load_preprocessed_image(image_filepath)\n    if (images is None):\n        images = tmp_image\n    else:\n        images = np.vstack((images, tmp_image))\n\nanomaly_flags = np.array([flag for flag in train_df['anomaly']])\nanomaly_flags = np_utils.to_categorical(anomaly_flags, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess3. Train/Test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\nsss = StratifiedShuffleSplit(n_splits=1, test_size=test_size_rate, random_state=0)\n\nfor train_index, test_index in sss.split(images, anomaly_flags):\n    X_train = images[train_index]\n    y_train = anomaly_flags[train_index]\n    X_test = images[test_index]\n    y_test = anomaly_flags[test_index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess4. Over Sampling (不均衡な学習データ数を揃える処理）"},{"metadata":{"trusted":true},"cell_type":"code","source":"# over-samplingを試します。\n\ntmp = pd.DataFrame(y_train[:, 1]).value_counts().values\nprint(tmp)\nlabel_ok_num = tmp[0]\nlabel_ng_num = tmp[1]\n\nwhile(label_ok_num != label_ng_num):\n    rand_index = np.random.randint(0, len(y_train))\n\n    label_is_ng = (y_train[rand_index, 1] == 1.0)\n    if label_is_ng:\n        X_train = np.vstack((X_train, [X_train[rand_index]]))\n        y_train = np.vstack((y_train, [y_train[rand_index]]))\n        label_ng_num += 1\n    print(label_ng_num, end='\\r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess5. Augmantation (画像をランダムに変化させて、学習データにバリエーションをもたせる）"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(rotation_range=360)\n\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ※注\n\n学習済モデルのダウンロード  \n> base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(  \n\nの実行時にエラーになる場合があります。  \n\nその場合は、このNoteBook の Internet 設定をオンにすることで、問題が解消されます。  \n詳細は下記のリンクをご確認ください。  \n\nhttps://stackoverflow.com/questions/47378542/kaggle-could-not-download-resnet50-pretrained-model"},{"metadata":{},"cell_type":"markdown","source":"## Preprocess6. モデルの定義"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\n# a. すでに学習済みのオープンな高精度なモデルを用意\n# a. Prepare an accurate open model that has already been trained.  \nbase_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n    weights='imagenet',\n    include_top=False,\n    pooling='avg'\n)\n\n# b. 学習しないようにパラメータ設定 \n# b. Set the parameters so that it does not learn.  \nbase_model.trainable = False\n\n# c. aの下に「2.出力結果を推定する層」を追加\n# c. Add \"2. Estimating the output result layer\" under a. \nmodel = tf.keras.Sequential([\n    base_model,\n    tf.keras.layers.Dense(1024, activation='relu'),\n    tf.keras.layers.Dense(2, activation='softmax')\n])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess7. 学習"},{"metadata":{},"cell_type":"markdown","source":"# ■-- Early Stopping\n\n規定のepochに到達する前に学習しきってしまうと、以降は過学習となってしまい、逆に精度が落ちてしまいます。\nEarly Stoppingは、過学習に陥る前に（規定のepochに到達する前に）自動で学習を止める手法です。\n\nkerasではコールバック関数として用意されているので、fit()あるいはfit_generator()に指定することでEarly Stoppingを実装できます。\n\nEarly Stoppingの判定のために、どうしても少し過学習してしまうため\n学習モデルを適宜保存し、Early Stopping後に保存したモデルをロードすることでカバーします。\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"mkdir ckpt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nes_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=0, mode='auto')\ncheckpoint = os.path.join(\"./ckpt/\", 'MYMODEL_.{epoch:02d}-{val_loss:.2f}.hdf5')\ncp_cb = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(datagen.flow(X_train, y_train, batch_size=n_batch),\n                    steps_per_epoch=len(X_train) / n_batch,\n                    epochs=epochs,\n                    validation_data=(X_test, y_test),\n                    callbacks=[es_cb, cp_cb])\n\ntrain_score = model.evaluate(X_train, y_train, verbose=0)\ntest_score = model.evaluate(X_test, y_test, verbose=0)\nprint('Train Loss:{0:.3f}'.format(train_score[0]))\nprint('Train accuracy:{0:.3}'.format(train_score[1]))\nprint('Test Loss:{0:.3f}'.format(test_score[0]))\nprint('Test accuracy:{0:.3}'.format(test_score[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 最も良かったモデルをロードしなおします。"},{"metadata":{"trusted":true},"cell_type":"code","source":"from glob import glob\n# get the newest model file within a directory\ndef getNewestModel(model, dirname):\n    target = os.path.join(dirname, '*')\n    files = [(f, os.path.getmtime(f)) for f in glob(target)]\n    if len(files) == 0:\n        return model\n    else:\n        newestModel = sorted(files, key=lambda files: files[1])[-1]\n        print(newestModel[0])\n        model.load_weights(newestModel[0])\n        return model\n\nmodel = getNewestModel(model, \"./ckpt/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess8. 判定"},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nfrom pathlib import Path\n\ntest_images = None\ntest_filenames = None\nfor test_filepath in glob.glob('/kaggle/input/mj1-anomaly-images-detection-challenge/test/*.png'):\n    tmp_image = load_preprocessed_image(test_filepath)\n    if (test_images is None):\n        test_images = tmp_image\n        test_filenames = [Path(test_filepath).name]\n    else:\n        test_images = np.vstack((test_images, tmp_image))\n        test_filenames.append(Path(test_filepath).name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_predict = model.predict(test_images)\nresult_predict = np.argmax(result_predict, axis=1)\nresult_predict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 結果をcsvで出力"},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_filepath = \"/kaggle/input/mj1-anomaly-images-detection-challenge/sample_submit.csv\"\nsubmit_df = pd.read_csv(submit_filepath, index_col=0)\n\nfor i, filename in enumerate(test_filenames):\n    submit_df.loc[filename, 'Predicted'] = result_predict[i]\n    \nsubmit_df.to_csv('result_submit.csv')\nsubmit_df[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, filename in enumerate(test_filenames):\n    submit_df.loc[filename, 'Predicted'] = result_predict[i]\nsubmit_df.to_csv('result_submit.csv')\nprint(submit_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}