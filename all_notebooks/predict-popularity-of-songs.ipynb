{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Imports"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.autonotebook import tqdm\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\n\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"tracks_data_df = pd.read_csv('../input/spotify-dataset-19212020-160k-tracks/data.csv')\ntracks_data_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tracks_data_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tracks_data_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"tracks_data_df.hist(figsize=(15, 15), color='black')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 10))\nsns.heatmap(tracks_data_df.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see above, year, danceability, energy, loudness and tempo are important features for predicting popularity."},{"metadata":{},"cell_type":"markdown","source":"Let's take a look on the correlations between these features and popularity:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=\"year\", y=\"popularity\", data=tracks_data_df, alpha=0.03, color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=\"danceability\", y=\"popularity\", data=tracks_data_df, alpha=0.03, color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=\"energy\", y=\"popularity\", data=tracks_data_df, alpha=0.03, color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=\"loudness\", y=\"popularity\", data=tracks_data_df, alpha=0.03, color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=\"tempo\", y=\"popularity\", data=tracks_data_df, alpha=0.03, color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['year', 'danceability', 'energy', 'loudness', 'tempo']\ntracks_data = tracks_data_df.copy()\nfeatures_tracks_data = tracks_data_df[features]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We don't need to worry about outliners, because in this example they barely effect the performance of the model."},{"metadata":{},"cell_type":"markdown","source":"### Data normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(features_tracks_data)\nfeatures_tracks_data = scaler.transform(features_tracks_data)\n\ny_tracks_data = tracks_data.popularity.values / 100\n\nX_train, X_test, y_train, y_test = train_test_split(features_tracks_data, y_tracks_data, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in range(X_train.shape[1]): \n    print(X_train[:, column].min(), X_train[:, column].max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create Random Forest Regressor\n\nI used a Random Forest Regressor as my model because in this case it actually works better than a Decision Tree Regressor or a simple neural network. "},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestRegressor()\nclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = clf.predict(X_test)\n\naccuracy = clf.score(X_test, y_test)\nprint(\"Test Accuracy: {:.4f}\".format(accuracy*100))\n\naverage_error = (abs(y_test - preds)).mean()\nprint(\"{:.4f} average error\".format(average_error))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index in range(len(preds[:100])): \n    \n    pred = preds[index]\n    actual = y_test[index]\n    \n    print(\"Actual / Predicted: {:.4f} / {:.4f}\".format(actual, pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}