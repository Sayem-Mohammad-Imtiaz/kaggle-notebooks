{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CONTENT\nIntroduction to data\nCleaning Data\n     A. Category\n     B. Rating\n     C. Reviews\n     D. Size\n     E. Installs\n     F. Price\n     G. Last Updated\nExploratory Data Analysis\n     A. Category and Reviews\n     B. Category and Installs\n     C. Word Cloud\n     D. Content Rating","metadata":{}},{"cell_type":"markdown","source":"1. INTRODUCTION TO DATA\nFirstly let's get to know data. While I was analyzing the data, I used Pandas library.\n\ninfo(): It informs about data columns and data types.\nhead(): It returns the first five data.\ntail(): It returns the last five data.\ncolumns : It returns data columns\nshape : It gives number of rows and columns in a tuble.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import pandas as pd ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv('../input/googleplaystore/googleplaystore.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.tail(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can combine tables to make it easier to see data. For this, we are gonna use \"concat function\" that is found Pandas library.\n\npd.concat([data frame parameters], axis,ignore_index) : It combines 2 tables.\naxis : It adds the tables as horizontal or vertical. If axis equals 0, it adds as horizontal. If axis equals 1, it adds as vertical.\nignore_index : It ignores index values.","metadata":{}},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of Rows\",data.shape[0])\nprint(\"Number of Columns\",data.shape[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe(include='all')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Cleaning Data\nDataset can contain missing data, numerical string value, various cues. If we can clean them, we can make easy our analysis.\n\nLet's have some fun. :)\n\n\nCategory","metadata":{}},{"cell_type":"code","source":"len(data[data['App'].str.contains('Astrology',case=False)]) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rating","metadata":{}},{"cell_type":"code","source":"data['Rating'].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Category'].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby('Category')['Rating'].mean().sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(data[data['Rating']==5.0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reviews","metadata":{}},{"cell_type":"code","source":"data[data['Reviews']=='3.0M']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can make NaN category value. At that time we can get a clean data. I used shift() method that is found Pandas library.","metadata":{}},{"cell_type":"markdown","source":"Reviews","metadata":{}},{"cell_type":"code","source":"data['Reviews']=data['Reviews'].replace('3.0M',3.0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Reviews']=data['Reviews'].astype('float')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Reviews'].dtype","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Reviews'].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SIZE","metadata":{}},{"cell_type":"code","source":"data['Size'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data type of Size is object. I had to convert the column because it contains the application sizes. Firstly I changed 'Varies with device' value with Nan. After, I dropped 'M' and 'k'. I changed from '1000+' to 1000. Finally, I converted float value.","metadata":{}},{"cell_type":"code","source":"data.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Type'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data['Reviews'].max()==data['Reviews']]['App']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index=data['Reviews'].sort_values(ascending=False).head().index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.iloc[index]['App']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby('Type')['Rating'].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Installs","metadata":{}},{"cell_type":"code","source":"data['Installs'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data type of Size is object. I'm gonna make similar processes, which I made the in 'Size'.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"data['Installs_1']=data['Installs'].str.replace(',','')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[data['Installs_1']=='Free']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Installs_1']=data['Installs'].str.replace('Free','0')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Installs_1'].dtype","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index=data['Installs_1'].sort_values(ascending=False).head().index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Price","metadata":{}},{"cell_type":"code","source":"data['Price'].unique()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data type of Price is object. I have made similar processes, which I made the in 'Size'.","metadata":{}},{"cell_type":"markdown","source":"Last Updated","metadata":{}},{"cell_type":"code","source":"data['Last Updated'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data type of Last Uptated is object. I converted from string to date type.","metadata":{}},{"cell_type":"markdown","source":"Exploratory Data Analysis\nAfter, I prepared to analyze our data, somewhat let's explore the datas. :)\n\ncorr() : It returns correlation.\ndescribe (): It returns number of entries, average of entries, outlier values, standart deviation, minimum and maximum entry.","metadata":{}},{"cell_type":"code","source":"data.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.iloc[index]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Conclusion\nThis is the end of the story. I hope It benefits to you. You can visualize with a lot of different model. Actually, I thought that EDA study could be boring. But It's important for ML models. I'm definitely gonna myself about this subject.  Wish to see you with different datasets.\n\nThank you ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}