{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"DEBUG = True\n","metadata":{"execution":{"iopub.execute_input":"2020-11-30T23:01:25.009002Z","iopub.status.busy":"2020-11-30T23:01:25.007941Z","iopub.status.idle":"2020-11-30T23:01:25.011197Z","shell.execute_reply":"2020-11-30T23:01:25.010622Z"},"papermill":{"duration":0.036503,"end_time":"2020-11-30T23:01:25.011316","exception":false,"start_time":"2020-11-30T23:01:24.974813","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import subprocess\nfrom ast import literal_eval\n\ndef run(command):\n    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n    out, err = process.communicate()\n    print(out.decode('utf-8').strip())\n\nprint('# CPU')\nrun('cat /proc/cpuinfo | egrep -m 1 \"^model name\"')\nrun('cat /proc/cpuinfo | egrep -m 1 \"^cpu MHz\"')\nrun('cat /proc/cpuinfo | egrep -m 1 \"^cpu cores\"')\n\nprint('# RAM')\nrun('cat /proc/meminfo | egrep \"^MemTotal\"')\n\nprint('# GPU')\nrun('lspci | grep VGA')\n\nprint('# OS')\nrun('uname -a')","metadata":{"execution":{"iopub.execute_input":"2020-11-30T23:01:25.078854Z","iopub.status.busy":"2020-11-30T23:01:25.074564Z","iopub.status.idle":"2020-11-30T23:01:25.13167Z","shell.execute_reply":"2020-11-30T23:01:25.132204Z"},"papermill":{"duration":0.094038,"end_time":"2020-11-30T23:01:25.132335","exception":false,"start_time":"2020-11-30T23:01:25.038297","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/sacremoses > /dev/null\n\nimport sys\nsys.path.insert(0, \"../input/transformers/\")","metadata":{"execution":{"iopub.execute_input":"2020-11-30T23:01:25.194109Z","iopub.status.busy":"2020-11-30T23:01:25.193232Z","iopub.status.idle":"2020-11-30T23:01:36.3752Z","shell.execute_reply":"2020-11-30T23:01:36.373525Z"},"papermill":{"duration":11.215745,"end_time":"2020-11-30T23:01:36.375322","exception":false,"start_time":"2020-11-30T23:01:25.159577","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sklearn\nfrom sklearn.model_selection import GroupKFold\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n# import tensorflow_hub as hub\nimport tensorflow as tf\n# import bert_tokenization as tokenization\nimport tensorflow.keras.backend as K\nimport os\nfrom scipy.stats import spearmanr\nfrom math import floor, ceil\nfrom transformers import *\n\nimport seaborn as sns\nimport string\nimport re    #for regex\n\nnp.set_printoptions(suppress=True)\nprint(tf.__version__)","metadata":{"execution":{"iopub.execute_input":"2020-11-30T23:01:36.435926Z","iopub.status.busy":"2020-11-30T23:01:36.435019Z","iopub.status.idle":"2020-11-30T23:01:45.541999Z","shell.execute_reply":"2020-11-30T23:01:45.541321Z"},"papermill":{"duration":9.1404,"end_time":"2020-11-30T23:01:45.54211","exception":false,"start_time":"2020-11-30T23:01:36.40171","status":"completed"},"scrolled":true,"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 1. Read data and tokenizer\n\nRead tokenizer and data, as well as defining the maximum sequence length that will be used for the input to Bert (maximum is usually 512 tokens)","metadata":{"papermill":{"duration":0.026083,"end_time":"2020-11-30T23:01:45.594907","exception":false,"start_time":"2020-11-30T23:01:45.568824","status":"completed"},"tags":[]}},{"cell_type":"code","source":"HAS_ANS = False\n\ndf = pd.read_csv('../input/60k-stack-overflow-questions-with-quality-rate/train.csv')\ndf = pd.read_csv('../input/phd-three-level-feature-extraction/all_features.csv')\ndf['Y0'] = df['Yi'].apply(lambda x: int(x==0))\ndf['Y1'] = df['Yi'].apply(lambda x: int(x==1))\ndf['Y2'] = df['Yi'].apply(lambda x: int(x==2))\ndel df['Y'], df['Yi'], df['Unnamed: 0']\n\n\ndf_train = df.head(45000)\ndf_test = df.tail(15000)\n\nif DEBUG:\n#     df_train = df_train.head(30000)\n    df_test = df_test.head(1000)\n\ndf_sub = df_test.copy()\ndel df_sub['Y0'], df_sub['Y1'], df_sub['Y2']\nprint('train shape =', df_train.shape)\nprint('test shape =', df_test.shape)\n\n","metadata":{"execution":{"iopub.execute_input":"2020-11-30T23:01:45.766948Z","iopub.status.busy":"2020-11-30T23:01:45.76602Z","iopub.status.idle":"2020-11-30T23:01:47.970589Z","shell.execute_reply":"2020-11-30T23:01:47.969961Z"},"papermill":{"duration":2.243644,"end_time":"2020-11-30T23:01:47.970733","exception":false,"start_time":"2020-11-30T23:01:45.727089","status":"completed"},"tags":[],"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_categories = list(df_train.columns[61:])\nTARGET_COUNT = len(output_categories)","metadata":{"execution":{"iopub.execute_input":"2020-11-30T23:01:48.440682Z","iopub.status.busy":"2020-11-30T23:01:48.439714Z","iopub.status.idle":"2020-11-30T23:01:48.4448Z","shell.execute_reply":"2020-11-30T23:01:48.444187Z"},"papermill":{"duration":0.042114,"end_time":"2020-11-30T23:01:48.444913","exception":false,"start_time":"2020-11-30T23:01:48.402799","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_categories = list(df_train.columns[7:61])","metadata":{"execution":{"iopub.execute_input":"2020-11-30T23:01:48.521085Z","iopub.status.busy":"2020-11-30T23:01:48.520116Z","iopub.status.idle":"2020-11-30T23:01:48.525925Z","shell.execute_reply":"2020-11-30T23:01:48.525232Z"},"papermill":{"duration":0.046686,"end_time":"2020-11-30T23:01:48.526024","exception":false,"start_time":"2020-11-30T23:01:48.479338","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## correlation","metadata":{"papermill":{"duration":0.03586,"end_time":"2020-11-30T23:01:48.674734","exception":false,"start_time":"2020-11-30T23:01:48.638874","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train = df_train.copy()","metadata":{"execution":{"iopub.execute_input":"2020-11-30T23:01:48.75104Z","iopub.status.busy":"2020-11-30T23:01:48.749104Z","iopub.status.idle":"2020-11-30T23:01:48.760849Z","shell.execute_reply":"2020-11-30T23:01:48.760231Z"},"papermill":{"duration":0.051624,"end_time":"2020-11-30T23:01:48.760961","exception":false,"start_time":"2020-11-30T23:01:48.709337","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.spatial.distance import cdist\n\ndef calc_corr(df, x_cols, y_cols):\n    arr1 = df[x_cols].T.values\n    arr2 = df[y_cols].T.values\n    corr_df = pd.DataFrame(1 - cdist(arr2, arr1, metric='correlation'), index=y_cols, columns=x_cols)\n    return corr_df\n\nnumber_feature_cols = input_categories[2:]\n\ncorr_df = calc_corr(train, output_categories, number_feature_cols)\nfig, ax = plt.subplots(figsize=(2, 6))\nsns.heatmap(corr_df, ax=ax)\n\nprint(corr_df)","metadata":{"execution":{"iopub.execute_input":"2020-11-30T23:01:48.852039Z","iopub.status.busy":"2020-11-30T23:01:48.838806Z","iopub.status.idle":"2020-11-30T23:01:49.292859Z","shell.execute_reply":"2020-11-30T23:01:49.293429Z"},"papermill":{"duration":0.497755,"end_time":"2020-11-30T23:01:49.293594","exception":false,"start_time":"2020-11-30T23:01:48.795839","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# prep","metadata":{"papermill":{"duration":0.037181,"end_time":"2020-11-30T23:01:49.368087","exception":false,"start_time":"2020-11-30T23:01:49.330906","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n#Particiona o data set originalmente Train em Train(Treino) e Val(validação)\nX_train, X_val, Y_train, Y_val = train_test_split(df_train[input_categories], \n                                                                  df_train[output_categories], \n                                                                  test_size=0.2, \n                                                                  random_state=42)\n\nX_train.shape, Y_train.shape, X_val.shape, Y_val.shape","metadata":{"execution":{"iopub.execute_input":"2020-11-30T23:01:49.454082Z","iopub.status.busy":"2020-11-30T23:01:49.453207Z","iopub.status.idle":"2020-11-30T23:01:49.478588Z","shell.execute_reply":"2020-11-30T23:01:49.479064Z"},"papermill":{"duration":0.074807,"end_time":"2020-11-30T23:01:49.479219","exception":false,"start_time":"2020-11-30T23:01:49.404412","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. models\n\nfrom https://www.kaggle.com/heyytanay/stack-overflow-qa-classification-87-acc#Modelling","metadata":{"papermill":{"duration":0.033483,"end_time":"2020-11-30T23:01:49.546892","exception":false,"start_time":"2020-11-30T23:01:49.513409","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport re\nimport random\nimport warnings\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score, confusion_matrix, plot_confusion_matrix, plot_precision_recall_curve","metadata":{"execution":{"iopub.execute_input":"2020-11-30T23:01:49.622388Z","iopub.status.busy":"2020-11-30T23:01:49.621475Z","iopub.status.idle":"2020-11-30T23:01:51.180559Z","shell.execute_reply":"2020-11-30T23:01:51.181268Z"},"papermill":{"duration":1.600211,"end_time":"2020-11-30T23:01:51.181473","exception":false,"start_time":"2020-11-30T23:01:49.581262","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metric(clf, testX, testY, name):\n    \"\"\"\n    Small function to plot ROC-AUC values and confusion matrix\n    \"\"\"\n    styles = ['bmh', 'classic', 'fivethirtyeight', 'ggplot']\n\n    plt.style.use(random.choice(styles))\n    plot_confusion_matrix(clf, testX, testY)\n    plt.title(f\"Confusion Matrix [{name}]\")","metadata":{"execution":{"iopub.execute_input":"2020-11-30T23:01:51.320911Z","iopub.status.busy":"2020-11-30T23:01:51.319977Z","iopub.status.idle":"2020-11-30T23:01:51.337374Z","shell.execute_reply":"2020-11-30T23:01:51.338171Z"},"papermill":{"duration":0.086748,"end_time":"2020-11-30T23:01:51.338381","exception":false,"start_time":"2020-11-30T23:01:51.251633","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainX = X_train.copy()\ntrainY = Y_train['Y0']\nvalidX = X_val.copy()\nvalidY = Y_val['Y0']","metadata":{"execution":{"iopub.execute_input":"2020-11-30T23:01:51.477893Z","iopub.status.busy":"2020-11-30T23:01:51.477008Z","iopub.status.idle":"2020-11-30T23:01:51.485448Z","shell.execute_reply":"2020-11-30T23:01:51.486372Z"},"papermill":{"duration":0.077585,"end_time":"2020-11-30T23:01:51.486565","exception":false,"start_time":"2020-11-30T23:01:51.40898","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### models","metadata":{"papermill":{"duration":0.057566,"end_time":"2020-11-30T23:01:51.597552","exception":false,"start_time":"2020-11-30T23:01:51.539986","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Define and fit the classifier on the data\nlr_classifier = LogisticRegression(C=1.)\nlr_classifier.fit(trainX, trainY)\n# Print the accuracy score of the classifier\nprint(f\"Validation Accuracy of Logsitic Regression Classifier is: {(lr_classifier.score(validX, validY))*100:.2f}%\")\n\nplot_metric(lr_classifier, validX, validY, \"Logistic Regression\")","metadata":{"execution":{"iopub.execute_input":"2020-11-30T23:01:51.750553Z","iopub.status.busy":"2020-11-30T23:01:51.743574Z","iopub.status.idle":"2020-11-30T23:01:52.732527Z","shell.execute_reply":"2020-11-30T23:01:52.731284Z"},"papermill":{"duration":1.051239,"end_time":"2020-11-30T23:01:52.732664","exception":false,"start_time":"2020-11-30T23:01:51.681425","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define and fit the classifier on the data\nnb_classifier = MultinomialNB()\nnb_classifier.fit(trainX, trainY)\nMultinomialNB()\n# Print the accuracy score of the classifier\nprint(f\"Validation Accuracy of Naive Bayes Classifier is: {(nb_classifier.score(validX, validY))*100:.2f}%\")\n# Also plot the metric\nplot_metric(nb_classifier, validX, validY, \"Naive Bayes\")","metadata":{"execution":{"iopub.execute_input":"2020-11-30T23:01:52.822615Z","iopub.status.busy":"2020-11-30T23:01:52.820809Z","iopub.status.idle":"2020-11-30T23:01:53.269026Z","shell.execute_reply":"2020-11-30T23:01:53.268341Z"},"papermill":{"duration":0.494925,"end_time":"2020-11-30T23:01:53.269141","exception":false,"start_time":"2020-11-30T23:01:52.774216","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}