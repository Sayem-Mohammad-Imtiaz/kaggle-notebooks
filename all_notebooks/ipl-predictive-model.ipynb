{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Team Annihilators- MehulKumar Patel,Dhiraj Patel\n# Emails: dhiru474@gmail.com,mkpatel.p64@gmail.com\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"matches = pd.read_csv('/kaggle/input/skillsay-ai-crickethon-dataset/matches.csv')\ndeliveries = pd.read_csv('/kaggle/input/skillsay-ai-crickethon-dataset/deliveries.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matches.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matches.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *Dealing with Null values*"},{"metadata":{"trusted":true},"cell_type":"code","source":"matches.isnull().sum().sort_values(ascending = False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Umpire3 has 637 nan values and is not required hence we need to drop it.\nmatches.drop(['umpire3'], inplace = True, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matches.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matches[pd.isnull(matches['city'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## By venue it is clear that this null values in city column is of DUBAI hence replacing it with same.\nmatches['city'] = matches['city'].fillna(\"DUBAI\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matches.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matches[pd.isnull(matches['player_of_match'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## For no result no player of match has been assigned hence replacing it with none\nmatches['player_of_match'] = matches['player_of_match'].fillna(\"None\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matches.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Replacing the null values in winner column with draw.\nmatches['winner'] = matches['winner'].fillna(\"DRAW\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matches.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fix null for column - umpire1\nmatches['umpire1'].value_counts() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Replacing umpire1 nan values with highest frequency umpire\nmatches['umpire1'] = matches['umpire1'].fillna('HDPK Dharmasena')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matches.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matches['umpire2'].value_counts() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Replacing umpire2 nan values with highest frequency umpire\nmatches['umpire2'] = matches['umpire2'].fillna('SJA Taufel')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matches.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Drop duplicates from team1 & team2 columns\n(matches['team2'].value_counts() + matches['team1'].value_counts()).drop_duplicates().index[::1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Replace Delhi Daredevils with Delhi capitals as the franchise is same\nmatches.team1.replace({'Delhi Daredevils' : 'Delhi Capitals'},regex=True,inplace=True)\nmatches.team2.replace({'Delhi Daredevils' : 'Delhi Capitals'},regex=True,inplace=True)\nmatches.toss_winner.replace({'Delhi Daredevils' : 'Delhi Capitals'},regex=True,inplace=True)\nmatches.winner.replace({'Delhi Daredevils' : 'Delhi Capitals'},regex=True,inplace=True)\n\n## The following dataset contains multiple name for RPS team so changing all of them to a single distinct name\n\nmatches.team1.replace({'Rising Pune Supergiant' : 'Rising Pune Supergiants'},regex=True,inplace=True)\nmatches.team2.replace({'Rising Pune Supergiant' : 'Rising Pune Supergiants'},regex=True,inplace=True)\nmatches.toss_winner.replace({'Rising Pune Supergiant' : 'Rising Pune Supergiants'},regex=True,inplace=True)\nmatches.winner.replace({'Rising Pune Supergiant' : 'Rising Pune Supergiants'},regex=True,inplace=True)\n\nmatches.team1.replace({'Rising Pune Supergiantss' : 'Rising Pune Supergiants'},regex=True,inplace=True)\nmatches.team2.replace({'Rising Pune Supergiantss' : 'Rising Pune Supergiants'},regex=True,inplace=True)\nmatches.toss_winner.replace({'Rising Pune Supergiantss' : 'Rising Pune Supergiants'},regex=True,inplace=True)\nmatches.winner.replace({'Rising Pune Supergiantss' : 'Rising Pune Supergiants'},regex=True,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matches.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check for HeatMaps:\nThe Heat Map procedure shows the distribution of a quantitative variable over all combinations of 2 categorical factors. If one of the 2 factors represents time, then the evolution of the variable can be easily viewed using the map. A gradient color scale is used to represent the values of the quantitative variable. The correlation between two random variables is a number that runs from -1 through 0 to +1 and indicates a strong inverse relationship, no relationship, and a strong direct relationship, respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\ncorelation_matrix=matches.corr().round(2)\nsns.heatmap(data=corelation_matrix,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Label Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Using Label encoding to convert categorical values (Teams) to numbers.\nmatches.replace(['Mumbai Indians','Kolkata Knight Riders','Royal Challengers Bangalore','Deccan Chargers','Chennai Super Kings',\n                 'Rajasthan Royals','Gujarat Lions','Kings XI Punjab',\n                 'Sunrisers Hyderabad','Rising Pune Supergiants','Kochi Tuskers Kerala','Pune Warriors','Delhi Capitals']\n                ,['MI','KKR','RCB','DC','CSK','RR','GL','KXIP','SRH','RPS','KTK','PW','DCC'],inplace=True)\n\nencode = {'team1': {'MI':1,'KKR':2,'RCB':3,'DC':4,'CSK':5,'RR':6,'GL':7,'KXIP':8,'SRH':9,'RPS':10,'KTK':11,'PW':12,'DCC':13},\n          'team2': {'MI':1,'KKR':2,'RCB':3,'DC':4,'CSK':5,'RR':6,'GL':7,'KXIP':8,'SRH':9,'RPS':10,'KTK':11,'PW':12,'DCC':13},\n          'toss_winner': {'MI':1,'KKR':2,'RCB':3,'DC':4,'CSK':5,'RR':6,'GL':7,'KXIP':8,'SRH':9,'RPS':10,'KTK':11,'PW':12,'DCC':13},\n          'winner': {'MI':1,'KKR':2,'RCB':3,'DC':4,'CSK':5,'RR':6,'GL':7,'KXIP':8,'SRH':9,'RPS':10,'KTK':11,'PW':12,'DCC':13,'DRAW':14}}\nmatches.replace(encode, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Encoding winner column to numbers based on above assigned values.\ndicVal = encode['winner']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating a new Dataframe with required columns\nmatches = matches[['team1','team2','city','toss_decision','toss_winner','venue','winner']]\nmatches.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabel_coder= LabelEncoder()\nmatches['Venue'] =label_coder.fit_transform(matches[\"venue\"])\nmatches","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *Importing all the algorithms for determining the prediction & accuracy*"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *Creating a general model function to predict the accuracy of model using different algorithms*"},{"metadata":{"trusted":true},"cell_type":"code","source":"def classification_model(model, data, predictors, outcome):\n  model.fit(data[predictors],data[outcome])\n  predictions = model.predict(data[predictors])\n  accuracy = metrics.accuracy_score(predictions,data[outcome])\n  print('Accuracy : %s' % '{0:.3%}'.format(accuracy))\n  kf = KFold(data.shape[0], n_splits=7)\n  error = []\n  model.fit(data[predictors],data[outcome])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Calling the function\nprint('Gaussian Naive Bayes')\nmodel = GaussianNB()\noutcome_var = ['winner']\npredictor_var = ['team1', 'team2', 'Venue', 'toss_winner']\nclassification_model(model,matches,predictor_var,outcome_var)\nprint('Logisitc Regression')\nmodel = LogisticRegression()\noutcome_var = ['winner']\npredictor_var = ['team1', 'team2', 'Venue', 'toss_winner']\nclassification_model(model,matches,predictor_var,outcome_var)\nprint('Support Vector Machine')\nmodel = SVC(gamma= 'auto')\noutcome_var = ['winner']\npredictor_var = ['team1', 'team2', 'Venue', 'toss_winner']\nclassification_model(model,matches,predictor_var,outcome_var)\nprint('Decision Tree')\nmodel = DecisionTreeClassifier()\noutcome_var = ['winner']\npredictor_var = ['team1', 'team2', 'Venue', 'toss_winner']\nclassification_model(model,matches,predictor_var,outcome_var)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *Highest accuracy achieved by Decision Tree classifier with 87.3% accuracy and second highest with 78.5% accuracy using Support Vector Machine algorithm.*"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}