{"cells":[{"metadata":{"_uuid":"1ac881db446ac6570a1810940607bf0068e06658"},"cell_type":"markdown","source":"<font size=\"10\" color=\"black\">Introdução à Probabilidade e Estatística</font>\n\nEduardo Chaves Ferreira\n\nAluno: Leonardo Pacheco"},{"metadata":{"_uuid":"85ff87bbd71efb2762b0f6cd2b7dc4d16dc43bd0"},"cell_type":"markdown","source":"## O que será tratado no curso\n\nConceito de incerteza\n\nDiferença entre análise estatística e análise probabilística\n\nDiferença entre probabilidade/estatística e mineração de dados\n\nIntrodução à probabilidade\n\nDistribuições de probabilidade\n\nConceitos de estatística\n\nEstatística Descritiva - Conceitos básicos \n\nInferência Estatística\n\nTeorema do limite central\n\nGrau de certeza e intervalo de confiânça\n\nCorrelação entre Variáveis\n\nAnálise Temporal \n\nOutliers\n\nTeste de hipótese"},{"metadata":{"_uuid":"5dcb48d909b75b5e0da4070159a319ed804b8b2a"},"cell_type":"markdown","source":"## O que não será tratado no curso\n\nMatemática pura\n\nDemonstrações\n\nConceitos aprofundados de probabilidade e estatística"},{"metadata":{"_uuid":"1164385e660aa33afb011ca7c26670067efe02e9"},"cell_type":"markdown","source":"## Onde estamos no processo de mineração de dados?\n\n[--Extração e limpeza--]\n\n           [--Estatística--]\n           \n                   [--Regras determinísticas--]\n                   \n                              [--Mineração de dados--]"},{"metadata":{"_uuid":"941030e79d1e97c748704db360e623a6fd677117"},"cell_type":"markdown","source":"## Importação de bibliotecas usadas nos exemplos"},{"metadata":{"trusted":true,"_uuid":"fc10e265e79347f9d73615725c2fe5ebe86be924"},"cell_type":"code","source":"'''\nAs bibliotecas usadas são:\nrandom\nstatistic\nnumpy.random\nscipy.stats\npandas\nmatplotlib\nstatsmodels\npandas-profiling\n'''\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\nimport random\nimport pandas as pd\nimport scipy.stats as stat\n\nimport os\n\npath = os.environ['PATH']\n\nif path.startswith('C'):\n    IN_KAGGLE = False\nelse:\n    IN_KAGGLE = True","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f04856eb0f6d29bbbcb353428ac6fb383228ae3"},"cell_type":"markdown","source":"## Mantendo a reprodutibilidade dos resultados\n\nAntes da geração de números aleatórios é importante inicializar o gerador de números para que os resultados sejam os mesmos"},{"metadata":{"trusted":true,"_uuid":"6ae9861eb4ab846eccee14077efbba2238e56cab"},"cell_type":"code","source":"# Para uso com funções da biblioteca standard (ex random.randint)\nrandom.seed(1)\n# Para uso com funções da biblioteca numpy (ex np.random.randint)\nnp.random.seed(1)\n\n# Quando for passada como parâmetro a seed\nrandom_state = 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7ffa7a8e241c0b5568f55113a66bb932274fa8b"},"cell_type":"markdown","source":"## Funções gerais usadas nos exemplos"},{"metadata":{"trusted":true,"_uuid":"6b5f75e7cb3f8dead97301ff600a7ca7e119c36f"},"cell_type":"code","source":"# Permutação: possibilidades de colocação de n objetos em n posições = n!\ndef permutacao (n):\n    return math.factorial(n)\n\n# Arranjo: p objetos em n posições, ordem importa = n!/(n-p)!\ndef arranjo (n,p):\n    return math.factorial(n)/math.factorial(n-p)\n\n# Combinação: p objetos em n posições, ordem não importa = n!/(n-p)!p!\ndef combinacao (n,p):\n    return math.factorial(n)/(math.factorial(n-p)*math.factorial(p))\n\n# Variações possíveis havendo n slots e p possibilidades para cada um\ndef possibilidades(n,p):\n    return p**n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a171784304627e542804bbaf42680b60e5b6d79"},"cell_type":"markdown","source":"<font size=\"6\" color=\"red\">Conceito de Incerteza</font>"},{"metadata":{"_uuid":"3d696259dfbcf0de3e51326cbe1e5c2bcab342d0"},"cell_type":"markdown","source":"Há processos que são descritos de forma precisa, por equações analíticas.\n\nExemplo: aceleração de um corpo submetido a uma força\na = F/m\n\nConseguimeos determinar precisamente a aceleração do corpo de acordo com F e m\n\nNeste caso não usamos probabilidade ou estatística\n\nVamos ao exemplo:"},{"metadata":{"trusted":true,"_uuid":"c0b3233db8d063ee9a5f8235ba04033b2c436135"},"cell_type":"code","source":"# Para qualquer valor de F podemos determinar precisamente qual será a aceleração do corpo\n\nm = 1\nF = np.arange(0.0,10.0,1)\na = F/m\n\nfig, ax = plt.subplots(figsize=(10,6))\nplt.plot(F,a,'*')\nplt.plot(F,a)\n\nplt.xlabel('Força')\nplt.ylabel('Aceleração')\nplt.title('Força X Aceleração')\nplt.grid(True)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7234ef83b6f84f01d80d3c491a191bb17d4e20e"},"cell_type":"markdown","source":"Há processos cujo resultado não é determinístico, ou seja, seu resultado pode variar entre execuções.\n\nTais processos são chamados <b>estocásticos</b>.\n\nUm exemplo é o lançamento de uma moeda.\n\nNeste caso podemos usar probabilidade/estatística para quantificar a incerteza do resultado."},{"metadata":{"trusted":true,"_uuid":"8016c61929699677d0526b748e4127a365d0ddf1"},"cell_type":"code","source":"# No lançamento da moeda não podemos prever qualquer resultado específico, \n# mas podemos determinar a probabilidade de cada resultado\n\nrandom.seed(random_state)\n\nescolhas = ['Cara','Coroa']\nlancamentos = 100\nresultados = random.choices(population=escolhas, weights=[6/10,4/10], k=lancamentos)\n\nfig, ax = plt.subplots(figsize=(10,6))\nind = range(1,len(escolhas)+1)\nproporcoes = [resultados.count('Cara')/lancamentos,resultados.count('Coroa')/lancamentos]\nplt.bar(ind,proporcoes,align='center')\nax.set_xticks(ind)\nax.set_xticklabels(escolhas)\n\n\nplt.xlabel('Resultado')\nplt.ylabel('Proporção')\nplt.title('Resultados de lançamentos de moeda não equilibrada')\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7157d32ba1f4f4aa489e69b050214434d2180395"},"cell_type":"markdown","source":"Neste exemplo não podemos garantir o resultado de nenhum lançamento específico, podemos, porém, verificar que temos aproximadamente 0,6 de probabilidade de cara e 0,4 de coroa. \n\nEmbora haja incerteza, conseguimos quantificá-la de alguma forma.\n\n"},{"metadata":{"_uuid":"dbd15eb46ea8e9ab6406cb43f9dc439a56c69665"},"cell_type":"markdown","source":"<font size=\"6\" color=\"red\">Quando usar probabilidade/estatística?</font>"},{"metadata":{"_uuid":"c1b7ed6f00a4dd51f4f00ecfcc8aea6dee2333e0"},"cell_type":"markdown","source":"Se você tem um processo determinístico com regras conhecidas, não usará.\n\nSe você tem um processo determinístico cujas regras não conhece, pode usar estatística descritiva para conhecer melhor o processo e depreender suas regras.\n\nSe você tem um processo estocástico (aleatório), com certeza usará.\n"},{"metadata":{"_uuid":"647c5b2130275c9cdc24b8a451e04971fca5f05f"},"cell_type":"markdown","source":"<font size=\"6\" color=\"red\">Diferença entre análise estatística e análise probabilística</font>"},{"metadata":{"_uuid":"d7d7e3e56dd0bf98253f8c8b21737fc95e847852"},"cell_type":"markdown","source":"Há processos estocásticos sobre os quais conhecemos as <b>probabilidades básicas</b>. \n\nComo exemplo temos o lançamento de uma moeda, que, caso seja equilibrada, tem probabilidade de 0,5 para Cara e Coroa.\n\nNeste caso, usando as probabilidades básicas, podemos inferir o comportamento de eventos complexos. \n\nPor exemplo, a probabilidade de obtermos m caras em n lançamentos.\n\nNessas condições, utilizamos ferramentas de <font color=\"red\">análise probabilística</font>.\n\nHá situações em que temos apenas dados gerados pelo processo estocástico (toda a população ou somente uma amostra), sem conhecer as probabilidades básicas que conduzem o processo. \n\nPor exemplo, temos o resultado de pesquisas eleitorais com pequenas parcelas da população. \n\nNesta situação, usamos <font color=\"red\">análise estatística</font> para analisar os dados e inferir as características do processo.\n\n"},{"metadata":{"_uuid":"120d8fc92bccfc0740d4256e84f48b9b134ca7e9"},"cell_type":"markdown","source":"<font size=\"6\" color=\"red\">Diferença entre estatística e probabidade na prática</font>"},{"metadata":{"_uuid":"507f4b6f74902a6b613be0b952986d02eaec5a93"},"cell_type":"markdown","source":"Probabilidade trata do mundo \"teórico\", quando as probabilidades básicas são bem definidas e seguidas pelos processos, ou seja, quase nunca ocorre no mundo real.\n\nEstatística trata do mundo \"real\", como as coisas acontecem de verdade. Os eventos são afetados por muitas variáveis, dificilmente seguem regras probabilísticas precisas.\n\nProbabilidade traz muitos conceitos que fundamentam a análise estatística, principalmente a inferência estatística.\n"},{"metadata":{"_uuid":"1211cea378a8cd4101dd1865c18adfb289f16e91"},"cell_type":"markdown","source":"<font size=\"6\" color=\"red\">Diferença entre probabilidade/estatística e mineração de dados</font>\n\nComo será apresentado, a estatística descritiva, juntamente com a visualização de dados, permite descobrir informações relevantes sobre cada variável analisada, bem como relações entre elas.\n\nEntretanto, quando a quantidade de variáveis em análise é grande e/ou seu relacionamento complexo, normalmente não linear, não conseguimos inferir corretamente as relações existentes, seja por limitação de nossa capacidade de avaliação, seja pela limitação dos métodos estatísticos.\n\nNesse momento são usadas técnicas de <font color=\"red\">mineração de dados</font> para tentar descobrir as relações complexas presentes nos dados.\n\nAmbas as técnicas (estatística e mineração) atuam sobre dados, buscando extrair informações. \n\nA principal diferença é até onde vai nossa capacidade de interpretação e a partir de onde delegamos a interpretação para a máquina.\n"},{"metadata":{"trusted":true,"_uuid":"57e8c1a3440d3c1beca5c01b4cb07e4c94261fe9"},"cell_type":"code","source":"# exemplo: 3 variáveis de entrada com relacionamento não linear entre elas\n\nnp.random.seed(1)\nx = np.random.random_sample(size=1000)\ny = np.random.random_sample(size=1000)\nz = np.random.random_sample(size=1000)\nw = x**2-y**2+z**3\nw = w/np.max(np.abs(w))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e551f9ccc00d7658626092a349502825a843202e"},"cell_type":"code","source":"plt.subplots(figsize=(14,6))\nplt.plot(x,w,'.')\nplt.xlabel('x')\nplt.ylabel('w')\nplt.title('w = x**2-y**2+z**3')\nplt.grid(True)\nplt.show()\n\nplt.subplots(figsize=(14,6))\nplt.xlabel('w')\nplt.ylabel('Probabilidade')\nplt.title('Distribuição de probabilidade de W')\nplt.grid(True)\nn, bins, patches = plt.hist(w, density=True, facecolor='g', alpha=0.75, bins=50)\nplt.show()\n\n\nprint('Matriz de correlações entre as variáveis')\nprint(np.corrcoef([x,y,z,w]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5eb841d2385db16b2876b7eb54991ff5f1201b4a"},"cell_type":"markdown","source":"A análise do gráfico não permite visualizar o relacionamento entre as variáveis.\n\nA matriz de correlação sugere a existência de dependência entre as variáveis de entrada e saída.\n\nPorém, a definição correta das relações é de difícil concepção sem uso de machine learning."},{"metadata":{"trusted":true,"_uuid":"abb0c93168634a738ee8f40534ddc699ad85adf1"},"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\n\n\nx_ = np.concatenate((np.reshape(x,(-1,1)),np.reshape(y,(-1,1)),np.reshape(z,(-1,1))), axis=1)\ny_ = np.reshape(w,(-1,1))\n\nx_train = x_[0:900,:]\ny_train = y_[0:900,:]\nx_test = x_[900:1000,:]\ny_test = y_[900:1000,:]\n\nestimator = MLPRegressor(\n                              learning_rate = 'adaptive',\n                              random_state = random_state,\n                              verbose=True,\n                                max_iter = 200,\n                            hidden_layer_sizes = [100,50,40,30,20,10],   \n                    solver = 'adam',\n                    alpha = 0.0001,\n                    activation = 'relu'\n                            )\n\nestimator.fit(x_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d136303ec2897d75a2d26d45894bf0959ac6dc41"},"cell_type":"code","source":"\nplt.subplots(figsize=(14,6))\nplt.plot(y_test,'r.')\nplt.plot(estimator.predict(x_test),'b*')\n\nplt.ylabel('w')\nplt.title('w = x**2-y**2+z**3')\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3720352f0bd7b4eb3731f316b86a153bf600af0e"},"cell_type":"markdown","source":"A rede neural conseguiu capturar corretamente o relacionamento não linear entre as variáveis.\n"},{"metadata":{"_uuid":"1f3cbbbb644a9228610725e776eb626aad403798"},"cell_type":"markdown","source":"<font size=\"6\" color=\"red\">Introdução à probabilidade</font>\n\nTeoria matemática para cálculo de probabilidade de eventos complexos considerando as probabilidades de eventos simples que formam o evento complexo.\n\nPor exemplo, o lançamento de uma moeda é um evento simples, com probabilidades conhecidas. O número de caras obtidas em n  lançamentos da mesma moeda é um evento complexo, cujas probabilidades podem ser deduzidas levando-se em conta as probabilidades dos eventos simples. "},{"metadata":{"_uuid":"0bd520e6e3b1ab432772ad3cb1be4d64e0590d04"},"cell_type":"markdown","source":"## Probabilidade - Solução analítica - Contagem\n\nO cálculo das probabilidades de eventos complexos pode ser feito de maneira analítica em sua forma mais simples: contagem.\n\nNo exemplo do lançamento de moedas, a probabilidade de obtermos 15 caras em 30 lançamentos pode ser calculada dividindo o número de eventos favoráveis pelo total de eventos possíveis. Para isso calculamos de quantas maneiras podemos obter 15 caras em 30 lançamentos, dividindo pelo número total de eventos possíveis em 30 lançamentos:\n"},{"metadata":{"trusted":true,"_uuid":"562380a9d20cadc76bf4cca9b9744f6dbbe6ab8f"},"cell_type":"code","source":"# Cálculo analítico baseado em contagem \ncombinacao(30,15)/possibilidades(30,2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ff18cb2a50714fd91727d03e1b559a2cea4a008"},"cell_type":"markdown","source":"## Probabilidade - Solução analítica - Probabilidades simples\n\nO cálculo das probabilidades de eventos complexos pode ser feito de maneira analítica, considerando as probabilidades simples.\n\nNo exemplo do lançamento de moedas, a probabilidade de obtermos m caras em n lançamentos (considerando uma moeda honesta) é dada por:\n\nP(n,m) = Combinação(n,m) x 0,5^m x 0,5^(n-m)\n\nConsiderando 30 lançamentos (n=30), vamos calcular a probabilidade de obtermos m caras: "},{"metadata":{"trusted":true,"_uuid":"3f90289855f3ea7247f24575c11b7a24246f6c54"},"cell_type":"code","source":"# Cálculo analítico baseado na probabilidade básica\nprobabilidades = np.zeros((31,1))\nfor i in range(0,31,1):\n    probabilidades[i]=combinacao(30,i)*((1/2)**(i))*((1/2)**(30-i))\n\nplt.bar(range(0,31,1),probabilidades[:,0], facecolor='g', alpha=0.75)\n\nplt.xlabel('# Caras')\nplt.ylabel('Probabilidade')\nplt.title('Histogram Moeda')\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a241cf7fb3db0b78dfa5b4b478cb6ea1afb430ea"},"cell_type":"markdown","source":"Observa-se que, apesar de termos uma solução analítica, continuamos sem certeza quanto aos resultados.\n\nA solução analítica informa as probabilidades do evento, não o resultado em si."},{"metadata":{"_uuid":"c3ba1a1cbf32c70489a6fed05d6084266ccc24d5"},"cell_type":"markdown","source":"## Probabilidade - Solução numérica\n\nO cálculo das probabilidades de eventos complexos pode ser bastante difícil considerando a solução analítica. Soluções analíticas envolvem o conhecimento de análise combinatória e probabilidade.\n\nEm casos em que não sabemos ou não queremos recorrer à solução analítica, podemos usar simulações computacionais para chegarmos aos mesmos resultados. Tais cálculos são chamados simulações de Monte-Carlo.\n\nNeste caso a probabilida é estimada pela frequência de ocorrências.\n\nVamos resolver o problema anterior (número de caras em 30 lançamentos) simplesmente simulando e estimando as probabilidades:"},{"metadata":{"_uuid":"bad337d6e11f1a8dc59e64853844a2389452ab8d"},"cell_type":"markdown","source":"### 100 simulações"},{"metadata":{"trusted":true,"_uuid":"4217e00bffa6be51969a366287e4c8326bdb44d1"},"cell_type":"code","source":"# Cálculo por simulação - usando probabilidade básica\nCara = 1\nCoroa = 0\nMoeda = [Cara,Coroa]\nEquilibrio = [1/2,1/2]\nlancamentos = 30\nrepeticoes = 100\nnp.random.seed(1)\nresultado = np.random.choice(a=Moeda, p=Equilibrio, replace=True, size=(repeticoes,lancamentos))\nresultado=np.sum(resultado, axis=1)\nprobabilidades,_ = np.histogram(a=resultado, density=True, bins=range(0,31,1))\n\n#n, bins, patches = plt.hist(resultado, density=True, facecolor='g', alpha=0.75, bins=range(0,31,1))\nplt.bar(range(0,30,1),probabilidades, facecolor='g', alpha=0.75)\n\nplt.xlabel('# Caras')\nplt.ylabel('Probabilidade')\nplt.title('Histogram Moeda')\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06c16f660ab532168331028431ab7ba642b488c9"},"cell_type":"markdown","source":"### 1000 simulações"},{"metadata":{"trusted":true,"_uuid":"8eefa384331cfbb145b4f30f530879d5cc1f07ed"},"cell_type":"code","source":"# Cálculo por simulação - usando probabilidade básica\nCara = 1\nCoroa = 0\nMoeda = [Cara,Coroa]\nEquilibrio = [1/2,1/2]\nlancamentos = 30\nrepeticoes = 1000\nnp.random.seed(1)\nresultado = np.random.choice(a=Moeda, p=Equilibrio, replace=True, size=(repeticoes,lancamentos))\nresultado=np.sum(resultado, axis=1)\nprobabilidades,_ = np.histogram(a=resultado, density=True, bins=range(0,31,1))\n\n#n, bins, patches = plt.hist(resultado, density=True, facecolor='g', alpha=0.75, bins=range(0,31,1))\nplt.bar(range(0,30,1),probabilidades, facecolor='g', alpha=0.75)\n\nplt.xlabel('# Caras')\nplt.ylabel('Probability')\nplt.title('Histogram Moeda')\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aceba94f0f4cde5d0fb790d06980bee983e5b6d1"},"cell_type":"markdown","source":"### 10000 simulações"},{"metadata":{"trusted":true,"_uuid":"76dee93c3572c3af9af4d618995c3d8358d07a88"},"cell_type":"code","source":"# Cálculo por simulação - usando probabilidade básica\nCara = 1\nCoroa = 0\nMoeda = [Cara,Coroa]\nEquilibrio = [1/2,1/2]\nlancamentos = 30\nrepeticoes = 10000\nnp.random.seed(1)\nresultado = np.random.choice(a=Moeda, p=Equilibrio, replace=True, size=(repeticoes,lancamentos))\nresultado=np.sum(resultado, axis=1)\nprobabilidades,_ = np.histogram(a=resultado, density=True, bins=range(0,31,1))\n\n#n, bins, patches = plt.hist(resultado, density=True, facecolor='g', alpha=0.75, bins=range(0,31,1))\nplt.bar(range(0,30,1),probabilidades, facecolor='g', alpha=0.75)\n\nplt.xlabel('# Caras')\nplt.ylabel('Probabilidade')\nplt.title('Histogram Moeda')\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c49f526667d5b59d955fa6649be25ec53a3736b9"},"cell_type":"markdown","source":"### 100000 simulações"},{"metadata":{"trusted":true,"_uuid":"ca885066931fda8625f7d3d4ac966c6c65327781"},"cell_type":"code","source":"# Cálculo por simulação - usando probabilidade básica\nCara = 1\nCoroa = 0\nMoeda = [Cara,Coroa]\nEquilibrio = [1/2,1/2]\nlancamentos = 30\nrepeticoes = 100000\nnp.random.seed(1)\nresultado = np.random.choice(a=Moeda, p=Equilibrio, replace=True, size=(repeticoes,lancamentos))\nresultado=np.sum(resultado, axis=1)\nprobabilidades,_ = np.histogram(a=resultado, density=True, bins=range(0,31,1))\n\n#n, bins, patches = plt.hist(resultado, density=True, facecolor='g', alpha=0.75, bins=range(0,31,1))\nplt.bar(range(0,30,1),probabilidades, facecolor='g', alpha=0.75)\n\nplt.xlabel('# Caras')\nplt.ylabel('Probabilidade')\nplt.title('Histogram Moeda')\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f7cb10e469be13cf00a4ecf0e0b5e5acfc47d7d"},"cell_type":"markdown","source":"Com o aumento do número de simulações o resultado numérico converge para o resultado analítico"},{"metadata":{"_uuid":"aa9a14c6036d58c4775dd4c5a615d77afdb458c3"},"cell_type":"markdown","source":"<font size=\"3\" color=\"blue\">Exercício: Se quiséssemos simular o lançamento de dois dados para verificar as probabilidades da soma dos valores, como ficaria o código acima?</font>"},{"metadata":{"trusted":true,"_uuid":"f1a1b040de2eb4b645e845478db098ff2ec9bcb8"},"cell_type":"code","source":"Dado = [1,2,3,4,5,6]\nEquilibrio = [1/6,1/6,1/6,1/6,1/6,1/6]\nrepeticoes = 100\nnp.random.seed(1)\nresultado = np.random.choice(a=Dado, p=Equilibrio, replace=True, size=(2, repeticoes))\nresultado=np.sum(resultado, axis=0)\n\nprobabilidades,_ = np.histogram(a=resultado, density=True, bins=range(2,14,1))\nprobabilidades\n\nn, bins, patches = plt.hist(resultado, density=True, facecolor='g', alpha=0.75, bins=range(2,14,1))\nplt.bar(range(2,13,1), probabilidades*100, facecolor='g', alpha=0.75)\n\nplt.xlabel('Soma dos dados')\nplt.ylabel('Probabilidade%')\nplt.title('Histograma Dados')\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b2074bc9a19bb18464426cf4dbb530656174047"},"cell_type":"markdown","source":"# Probabilidade - Teoria\n\nProbabilidade é a frequência, no longo prazo, de determinado resultado de um processo estocástico.\n\nPor exemplo, o lançamento de uma moeda \"honesta\", realizado várias vezes, produzirá um número de caras e coroas idêntico, ou seja, a frequência de caras será igual à de coroas (50%), que corresponde à probabilidade de obter uma cara ou uma coroa em qualquer lançamento (0,5). \n\nProbabilidade é, então, a medida de certeza com que podemos esperar a ocorrência de determinado evento, resultado de um experimento aleatório. \n\nA probabilidade recebe um número no intervalo de zero a um. Já a frequência e apresentada como percentual, variando de 0 a 100.\n\nA probabilidade não dá certeza alguma sobre um evento específico, apenas garante que, no longo prazo, a frequência se aproximará da probabilidade.\n\nConforme demonstrado no exemplo anterior, quanto maior o número de experimentos, mais a frequência irá se aproximar da probabilidade real. "},{"metadata":{"_uuid":"239a24001e8dcf9c5a17af7a2b35bde422801e39"},"cell_type":"markdown","source":"# Probabilidade - Variáveis aleatórias\n\nVariável aleatória (X) é o resultado de um processo estocástico. Por exemplo, o resultado de um lançamento de um dado é uma variável aleatória.\n\nA variável aleatória pode assumir um conjunto de valores (x), que formam o espaço amostral da variável. No lançamento do dado, os valores possíveis são os números de 1 a 6.\n\nA cada valor possível da variável aleatória podemos associar uma probabilidade, que é a frequência, no longo prazo, que a variável assumirá tal valor. No lançamento do dado (honesto), cada valor possível no espaço amostral tem probabilidade 1/6. Ao conjunto de probabilidades associadas aos valores possíveis, chamamos de distribuição de probabilidade da variável aleatória X.\n\nQuando o espaço amostral é finito ou infinito enumerável é chamado espaço discreto (variável aleatória discreta), por exemplo o lançamento de um dado.\n\nSe o espaço amostral é infinito não-enumerável é chamado espaço não-discreto ou contínuo (variável aleatória contínua), por exemplo a temperatura medida em cada dia do ano.\n\nVeja a representação (Fonte: https://pt.wikipedia.org/wiki/Variável_aleatória):"},{"metadata":{"_uuid":"84267d914272f79ea04009fa6f0b3a19194d9a43"},"cell_type":"markdown","source":"<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b9/Exemplofuncao.png\" height=\"800\" width=\"800\"> "},{"metadata":{"_uuid":"6b79b94877586ac164ddf668e6ad2e1271d6e6ec"},"cell_type":"markdown","source":"<font size=\"6\" color=\"red\">Distribuições de probabilidade</font>\n\n## Probability Mass Function (PMF) e Probability Density Function (PDF)\n\nConforme exposto, é a função que associa a cada valor possível de uma variável aleatória uma probabilidade.\n\nCaso a variável seja discreta, teremos uma <b>PMF</b>, caso a variável seja contínua, teremos uma <b>PDF</b>.\n\nATENÇÃO: a PMF dá a probabilidade de um ponto do espaço amostral, a PDF dá a probabilidade num intervalo, considerando que, para variáveis contínuas, a probabilidade de cada ponto é zero. Entretanto, as funções em python que implementam a PDF estimam a probabilidade do ponto pela probabilidade do intervalo infinitesimal.\n\nTomando como exemplo a variável aleatória que representa o número de caras obtidas em 30 lançamentos de uma moeda honesta (variável discreta), sua PMF é demonstrada a seguir:"},{"metadata":{"trusted":true,"_uuid":"bf216a1edddc6895509e56e37192bf0ce233357d"},"cell_type":"code","source":"# Usando scipy\n\nfrom scipy.stats import binom\ntentativas = 30\nrv = binom(tentativas, 1/2)\n\nresultado = rv.pmf(range(0,31,1))\n\nplt.bar(range(0,31,1),resultado)\n\nplt.xlabel('# Cara')\nplt.ylabel('Probability')\nplt.title('Histogram Moeda')\nplt.grid(True)\nplt.show()\n\nprint('Valor da PMF em 15: {}, correspondente à probabilidade de 15 caras em 30 lançamentos'.format(rv.pmf(15)))\nprint('Valor da PMF em 0: {}, correspondente à probabilidade de 0 caras em 30 lançamentos'.format(rv.pmf(0)))\nprint('Soma das probabilidades {}'.format(sum(resultado)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cfe99daff0ff41792490f1b03fe6d66bec8dd44b"},"cell_type":"markdown","source":" A PMF da distribuição mostra que, em 14,45% das vezes que lançarmos 30 vezes uma moeda, obteremos 15 caras.\n \n Mostra também que, em 0,0000000931% das vezes, obteremos zero caras. Um evento pouco provável, mas possível."},{"metadata":{"_uuid":"34b6dbc75bf29e25ae22408db09c5de241525153"},"cell_type":"markdown","source":"## Função de probabilidade acumulada: Cumulative Distribution Function (CDF)\n\nÉ a probabilidade da variável aleatória assumir um valor menor ou igual à x.\n\nTomando como exemplo a variável aleatória que representa o número de caras obtidas em 30 lançamentos de uma moeda honesta (variável discreta), sua CDF é demonstrada a seguir:"},{"metadata":{"trusted":true,"_uuid":"389ee14365adae62f3d1d97119062de49c5d8355"},"cell_type":"code","source":"# Usando scipy\n\nfrom scipy.stats import binom\ntentativas = 30\nrv = binom(tentativas, 1/2)\n\nresultado = rv.cdf(range(0,31,1))\n\nplt.bar(range(0,31,1),resultado)\n\nplt.xlabel('# Caras')\nplt.ylabel('Probabilidade')\nplt.title('Histogram Moeda')\nplt.grid(True)\nplt.show()\n\nprint('Probabilidade de conseguirmos 15 ou menos caras {}'.format(rv.cdf(15)))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a1d70fc391d43c8410bd4090c86a7fe1a542c08"},"cell_type":"markdown","source":" A CDF da distribuição mostra que há 57,22% de probabilidade da moeda produzir 15 ou menos caras em 30 lançamentos."},{"metadata":{"_uuid":"bee7cefe966aeeae7951d458e53513f846c13d01"},"cell_type":"markdown","source":"## Outras funções de probabilidade\n\nAlém da PMF, PDF e CDF, podemos citar:\n\n-Survival function: 1-CDF\n\n-Interval: pontos da PMF que delimitam um percentual das probabilidades (ver exemplo a seguir)"},{"metadata":{"trusted":true,"_uuid":"8e0c0ff1a86ae0d4dcbc442a3c6af07d6210c2e2"},"cell_type":"code","source":"# Usando scipy\n\nfrom scipy.stats import binom\ntentativas = 30\nrv = binom(tentativas, 1/2)\n\nresultado = rv.cdf(range(0,31,1))\n\nintervalo = rv.interval(0.95)\n\nprint('Com 95% de chance teremos entre {} e {} caras em 30 lançamentos'.format(intervalo[0],intervalo[1]))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b426c2df07ef54ea2da425b93a0ef12bc4ea9a8"},"cell_type":"markdown","source":"## Medidas de tendência, dispersão e dependência para variáveis aleatórias\n\nSão medidas baseadas nos pontos do espaço amostral e na probabilidade de cada ponto.\n\nEm estatística descritiva temos medidas semelhante, só que, como não há informações sobre as probabilidades básicas, os cálculos serão diferentes, não tomando como base as probabilidades (podem usar frequências).\n\nEsperança ou média de X, E(X) - é uma medida de tendência calculada como a soma dos produtos de cada x do espaço amostral pela probabilidade p(x)\n\nVariância de X - é uma medida de dispersão calculada como a esperança do quadrado da diferença entre x e a média\n\nDesvio padrão de X - é uma medida de dispersão calculada como a raiz quadrada da variância. É mais usada como medida de dispersão por estar na mesma unidade da variável X\n\nDadas duas variáveis aleatórias X e Y, define-se como medida de dependência entre elas a covariância e o coeficiente de correlação, que serão estudadas na estatística descritiva."},{"metadata":{"trusted":true,"_uuid":"b9a7e174679fbd9299386942cb2ea9f6b67d6016"},"cell_type":"code","source":"from scipy.stats import binom\ntentativas = 30\nrv = binom(tentativas, 1/2)\n\nmedia = rv.mean()\n\nprint('Média {}'.format(media))\n\nvariancia = rv.var()\n\nprint('Variância {}'.format(variancia))\n\ndesvio_padrao = rv.std()\n\nprint('Desvio padrão {}'.format(desvio_padrao))\n\nprob_media = rv.pmf(media)\n\nprint('Probabilidade da média {} é {}'.format(media,prob_media))\n\ndesv = (rv.cdf(media+desvio_padrao)-rv.cdf(media-desvio_padrao))\n\nprint('Probabilidade do resultado estar afastado até 1 desvio padrão da média é {}'.format(desv))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42c1ca0dd85410058d3052a30bba1ec6298fe0b8"},"cell_type":"markdown","source":"# Distribuições de probabilidade\n\nFonte: http://blog.cloudera.com/blog/2015/12/common-probability-distributions-the-data-scientists-crib-sheet/"},{"metadata":{"_uuid":"a385f75aeb85bc79618d6e85dee48438bf144183"},"cell_type":"markdown","source":"<img src=\"http://blog.cloudera.com/wp-content/uploads/2015/12/distribution.png\" height=\"800\" width=\"800\"> "},{"metadata":{"_uuid":"7ed89ef8ff09248a33ac435be638ac27655ba7d2"},"cell_type":"markdown","source":"# Distribuições discretas\n\nBernoulli - distribuição que representa uma escolha binária, com probabilidades p e 1-p. Como exemplo um lançamento de uma moeda.\n\nBinomial - representa a soma de sucessos em n execuções de um processo binário. Como exemplo o número de caras em n lançamentos de uma moeda. Outro exemplo é o número de bolas pretas retiradas de um cesto contendo bolas brancas e pretas (com reposição).\n\nHipergeométrica - representa a soma de bolas pretas retiradas de um cesto contendo bolas brancas e pretas (sem reposição).\n\nPoisson - número de chamdas recebidas num intervalo de tempo.\n\nDiscrete Uniform - cada ponto do espaço tem igual probabilidade. Como exemplo o lançamento de um dado.\n\nGeométrica - número de fracassos antes de um sucesso. Por exemplo, no lançamento de moeda, o número de coroas antes de uma cara.\n\nBinomial negativa - número de fracassos antes de n sucessos\n\nUniform"},{"metadata":{"_uuid":"75ec729401d666897c5f6a019723bc40faf196e7"},"cell_type":"markdown","source":"# Distribuições contínuas\n\nExponencial - tempo decorrido entre chamadas de um call center, com taxa de chamadas constante.\n\nWeibull - tempo até falha, quando a taxa de falha não é constante no tempo.\n\nChi2 - soma de quadrados de valores normalmente distribuídos\n\nGama - tempo até n eventos ocorrerem\n\nNormal - soma de variáveis aleatórias\n\nLog-normal - utilizada quando o logarítmo dos valores é distribuído segundo a normal. Produto de variáveis aleatórias\n\nUniform"},{"metadata":{"_uuid":"3d4ac6da96ad4c27e16cbb95ac30ebec6d815a94"},"cell_type":"markdown","source":"## Distribuição Normal\n\nPela importância, vamos estudar algumas propriedades da normal"},{"metadata":{"trusted":true,"_uuid":"f8f8692503fd6fde3682219388784f9e3ba7a564"},"cell_type":"code","source":"# Normal\n# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm\n# Equivalente a np.random.normal(loc=0.0, scale=1.0, size=10)\n\nfrom scipy.stats import norm\nfrom scipy.stats import kstest\n\nmean = 0\nstd = 1\nrv = norm(loc=mean, scale=std)\nnp.random.seed(1)\nresultado = rv.rvs(size=1000)\n\nn, bins, patches = plt.hist(resultado, density=True, facecolor='g', alpha=0.75, bins=50)\nintervalo = np.linspace(mean-5*std,mean+5*std, num=50)\n\nplt.plot(intervalo, rv.pdf(intervalo), 'k-', label='pdf')\nplt.xlabel('Valores')\nplt.ylabel('Probabilidade')\n\nplt.title('Distribuição normal')\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5ae80af17fe52b12c813afcf4b3198a978d4d50"},"cell_type":"code","source":"print('Probabilidade do valor 0: {}'.format(rv.pdf(0)))\nprint('Probabilidade de valor menor ou igual a 0: {}'.format(rv.cdf(0)))\nprint('Média: {}'.format(rv.mean()))\nprint('Variância: {}'.format(rv.var()))\nprint('Desvio padrão: {}'.format(rv.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c3eaf4b516aa2189167a87cabd7123eb7f9792a"},"cell_type":"code","source":"\ntamanho_amostra = (len(resultado))\n\ntamanho_amostra_entre_1_desvios = sum( (resultado>(mean-1*std)) & (resultado<(mean+1*std)) )\ntamanho_amostra_entre_2_desvios = sum( (resultado>(mean-2*std)) & (resultado<(mean+2*std)) )\ntamanho_amostra_entre_3_desvios = sum( (resultado>(mean-3*std)) & (resultado<(mean+3*std)) )\n\nprint('Percentual dos dados entre {} desvios: {}'.format(1,tamanho_amostra_entre_1_desvios*100/tamanho_amostra))\nprint('Percentual dos dados entre {} desvios: {}'.format(2,tamanho_amostra_entre_2_desvios*100/tamanho_amostra))\nprint('Percentual dos dados entre {} desvios: {}'.format(3,tamanho_amostra_entre_3_desvios*100/tamanho_amostra))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"572d74071d30bc9f339f360763d4c0b209b2205a"},"cell_type":"code","source":"# Determinação de parâmetros baseado nos dados\n\nmedia, desvio = norm.fit(resultado)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68f363ece1581c3e597bb87ad0dad060c43c0206"},"cell_type":"code","source":"#https://plot.ly/python/normality-test/\n\n# Teste de normalidade\n    \nkstest(resultado, 'norm')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a97563990c59159150974737784f24b0a8048da4"},"cell_type":"markdown","source":"## Distribuição Log-Normal\n\nEm que pese a importância da normal, muitos processos seguem distribuições exponenciais ou lognormais\n\nA log-normal é particularmente interessante por duas propriedades:\n\n-Representa a distribuição da multiplicação de variáveis aleatórias\n\n-Representa a distribuição de variáveis cujo log tem distribuição normal"},{"metadata":{"trusted":true,"_uuid":"80f74ac9c80432148c8c544fe4c21e23ee595afe"},"cell_type":"code","source":"\n\n\n\ns = 0.8\nrepeticoes = 100000\n\nrv = stat.lognorm(s=s)\n\npopulacao = rv.rvs(size=repeticoes, random_state=random_state)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"492743682d3c64e08d0ae6b792b5df7054cca6c1"},"cell_type":"code","source":"n, bins, patches = plt.hist(populacao, density=True, facecolor='g', alpha=0.75, bins=50)\n\n\nplt.title('Distribuição logonormal')\nplt.xlabel('Valores')\nplt.ylabel('Probabilidade')\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3da2c18f78e27428c49380f973f0aa7e1f816b4"},"cell_type":"code","source":"n, bins, patches = plt.hist(np.log(populacao), density=True, facecolor='g', alpha=0.75, bins=50)\n\n\nplt.title('O log da var aleatória logonormal tem distribuição normal')\nplt.xlabel('Valores')\nplt.ylabel('Probabilidade')\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"095c265f3f25c11120dc7ff76a032fc4238872b4"},"cell_type":"code","source":"plt.plot(populacao,'.')\n\nplt.xlabel('Amostra')\nplt.ylabel('Valor')\nplt.title('Distribuição logonormal')\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfe2571581164301a6db0f1fafb659099100efb7"},"cell_type":"markdown","source":"<font size=\"6\" color=\"red\">Conceitos de estatística</font>\n\nEstatística é a ciência que se dedica à coleta, análise e interpretação de dados (https://pt.wikipedia.org/wiki/Estatística)\n\nÉ utilizada quando não conhecemos as probabilidades básicas do processo estocástico em análise, temos apenas os dados gerados na execução do processo.\n\nPor exemplo, no lançamento de moeda não honesta, sobre a qual não conhecemos as probabilidades de Cara e Coroa, podemos registrar o resultado de n lançamentos e realizar análise estatística sobre esses dados.\n\nO ramo da estatística que analisa, descreve e sumariza um conjunto de dados é a <b>estatística descritiva</b>.\n\n<b>População</b> é o conjunto de dados representando todas as observações possíveis, <b>amostra</b> é o conjunto de dados representando apenas uma parte dessas observações. \n\nValores calculados a partir da população são chamados parâmetros populacionais. Quando esses mesmos valores são calculados a partir da amostra denominam-se estatísticas amostrais.\n\n<b>Inferência estatística</b> significa inferir fatos acerca de uma população a partir de resultados observados na amostra. \n\nQuando inferimos fatos sobre a população normalmente não apresentamos simplesmente o valor, informamos também nosso grau de certeza e o intervalo de confiança (ex. pesquisa eleitoral)\n"},{"metadata":{"_uuid":"db12ca140454d703c356d1b84975b6a4aedc0e0e"},"cell_type":"markdown","source":"## Exemplo: Análise estatística sobre o número de caras em n lançamentos de Moeda\n\nO processo estocástico é o lançamento da moeda e a contagem no número de caras em 30 lançamentos\n\nSupomos que não conhecemos os parâmetros do processo (qual probabilidade de cara/coroa), temos apenas amostras"},{"metadata":{"trusted":true,"_uuid":"0391620690365adf8725f7772a61592c7f43bd05"},"cell_type":"code","source":"# Geração da população, esta parte é desconhecida para o estatístico\n\nlancamentos = 30\nrepeticoes = 100000\nnp.random.seed(1)\npopulacao = np.random.binomial(30, 1/4, size=repeticoes)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a558bea2e100d81cc4c099dfc4941beba144802f"},"cell_type":"code","source":"# Estatística descritiva da população\n\nprobabilidades,_ = np.histogram(a=populacao, density=True, bins=range(0,31,1))\n\n#n, bins, patches = plt.hist(resultado, density=True, facecolor='g', alpha=0.75, bins=range(0,31,1))\nplt.bar(range(0,30,1),probabilidades, facecolor='g', alpha=0.75)\n\nplt.xlabel('# Caras')\nplt.ylabel('Probabilidade')\nplt.title('Histogram Moeda')\nplt.grid(True)\nplt.show()\n\nprint('Média: {}'.format(np.mean(populacao)))\nprint('Probabilidade Cara: {}'.format(np.mean(populacao)/lancamentos))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e18dab8bd5f4055d6603c66d8bb052591ac9691"},"cell_type":"markdown","source":"Analisando a população, concluímos que a probabilidade básica da moeda gerar uma cara é 0,25.\n\nNormalmente não possuímos dados sobre toda a população (pode ser caro obter tais dados, o processo de amostragem ser destrutivo, não haver tempo para captura, etc). Neste caso temos que extrair uma amostra da população e, com base na análise da amostra, inferir conclusões sobre toda a população:\n"},{"metadata":{"trusted":true,"_uuid":"fb4782225a10b2056d16ba7a219066a798bb4bca"},"cell_type":"code","source":"# Amostra de 1% da população\nnp.random.seed(1)\namostra = populacao[np.random.randint(0, len(populacao),int(0.01*repeticoes))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"155831a38423994826b18cfda703105a4e9fec3f"},"cell_type":"code","source":"# Estatística descritiva da população\n\nprobabilidades,_ = np.histogram(a=amostra, density=True, bins=range(0,31,1))\n\n#n, bins, patches = plt.hist(resultado, density=True, facecolor='g', alpha=0.75, bins=range(0,31,1))\nplt.bar(range(0,30,1),probabilidades, facecolor='g', alpha=0.75)\n\nplt.xlabel('# Caras')\nplt.ylabel('Probability')\nplt.title('Histogram Moeda')\nplt.grid(True)\nplt.show()\n\nprint('Média: {}'.format(np.mean(amostra)))\nprint('Probabilidade Cara: {}'.format(np.mean(amostra)/lancamentos))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"566c22122be1fb0e3e8e564d3d1775f962586e68"},"cell_type":"markdown","source":"Com base na amostra, calculamos que a probabilidade de Cara é 0,253, bem próxima da probabilidade real de 0,25.\n\nA questão a ser definida é o quanto a informação obtida na amostra está próxima da informação da população e qual tamanho da amostra é necessário para termos confiânça sobre nossas conclusões. Para isso, temos que entender o <b>Teorema do Limite Central</b>.\n\nAntes, porém, vamos estudar a estatística descritiva. Após, no estudo da inferência estatística, veremos o teorema."},{"metadata":{"_uuid":"8f281ecdc59294b4eb8112c663bc118934c123f5"},"cell_type":"markdown","source":"<font size=\"6\" color=\"red\">Estatística Descritiva - Conceitos básicos</font>\n\nConforme já definido, é o ramo da estatística que analisa, descreve e sumariza um conjunto de dados.\n\n<b>Os dados capturados podem ser calssificados como:</b>\n\n-Qualitativos nominais (não numéricos, sem ordem) - ex. sexo\n\n-Qualitativos ordinais (não numéricos, com ordem) - ex. grau de instrução\n\n-Quantitativos contínuos (numéricos não intervalados) - ex. salário\n\n-Quantitativos discretos (numéricos intervalados) - ex. número de filhos\n\n\n<br>Da mesma forma que na análise probabilística, dados qualitativos ordinais (transformados em quantitativos) e dados quantitativos podem ser analisados segundo medidas de posição e dispersão, que podem ser aplicadas tanto à população (parâmetros populacionais) como à amostra (estatísticas amostrais).\n\n<b>São medidas de posição: </b>\n\nModa (valor mais frequente - não funciona corretamente em distribuições contínuas), \n\nMédia (soma de m valores dividida por m), \n\nMediana (valor na posição central de um conjunto ordenado) e \n\nQuartis (reqpresentam as posições 25%-Q1, 50%-Q2 e 75%-Q3)\n\n\n<b>São medidas de dispersão: </b>\n\nAmplitude (máximo-mínimo), \n\nIntervalo-Interquartil (Q3-Q1), \n\nVariância (média dos quadrados das diferenças entre a variável e a média), \n\nDesvio Padrão (raiz da variância) e \n\nCoeficiente de Variação (desvio padrão dividido pela média)\n\n\n<b>São medidas de forma: </b>\n\nCurtose (achatamento, onde 0 caracteriza a normal, maior que 0 representa afunilamento e menor que 0 achatamento) e \n\nAssimetria (skewness, onde 0 caracteriza simetria, maior que 0 caracteriza maior distribuição à direira e menor que 0 caracteriza maior distribuição à esquerda)\n\n<br><b>IMPORTANTE</b>: mediadas de posição e dispersão são relevantes para entendermos os dados em análise, porém, a melhor forma de termos uma visão completa é através das distribuições de frequências, obtidas através do histograma.\n\n<br><b>IMPORTANTE</b>: para ter uma visão consolidade das mediadas de posição e dispersão usar o boxplot."},{"metadata":{"trusted":true,"_uuid":"2dcf625f714cb4db87698b84bfcae275d486b828"},"cell_type":"code","source":"\nrepeticoes = 100000\nmean = 5\nnp.random.seed(1)\n\n# População lognormal\ns = 0.8\nrv_lognorm = stat.lognorm(s=s,loc=mean-1.3)\npopulacao_lognorm = rv_lognorm.rvs(size=repeticoes, random_state=random_state)\n\n# População normal\nstd = 1.3\nrv_norm = stat.norm(loc=mean, scale=std)\npopulacao_norm = rv_norm.rvs(size=repeticoes, random_state=random_state)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cd2e6400abfd38fd3e91b366b4bed7b72a64ba4"},"cell_type":"code","source":"print('\\nPopulação lognormal: \\nmédia {}, \\ndesvio padrão {}, \\nmoda {}, \\nmediana {}, \\nCurtose {}, \\nSimetria {}'.format(\n    np.mean(populacao_lognorm), \n    np.std(populacao_lognorm),\n    stat.mode(populacao_lognorm),\n    np.median(populacao_lognorm),\n    stat.kurtosis(populacao_lognorm),\n    stat.skew(populacao_lognorm)\n))\n\nprint('\\nPopulação normal: \\nmédia {}, \\ndesvio padrão {}, \\nmoda {}, \\nmediana {}, \\nCurtose {}, \\nSimetria {}'.format(\n    np.mean(populacao_norm), \n    np.std(populacao_norm),\n    stat.mode(populacao_norm),\n    np.median(populacao_norm),\n    stat.kurtosis(populacao_norm),\n    stat.skew(populacao_norm)\n))\n\nfig, axs = plt.subplots(1, 2, figsize=(14,6))\n\naxs[0].plot(populacao_lognorm,'.')\naxs[0].grid(True)\naxs[0].set_title('populacao_lognorm')\n\naxs[1].plot(populacao_norm,'.')\naxs[1].grid(True)\naxs[1].set_title('populacao_norm')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4fe483a7d13dc1af57cd25e5f98729c8a8f8d625"},"cell_type":"markdown","source":"Observe que os dois conjuntos de dados possuem médias e desvios muito parecidos, apesar de serem totalmente diferentes.\n\nPor isso a simples análise dos parâmetros populacionais não é suficiente para se ter uma ideia precisa da população em análise."},{"metadata":{"trusted":true,"_uuid":"15ec72eb7cf8491f559f19573f71c7a1bf0ee770"},"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(14,6))\n\naxs[0].hist(populacao_lognorm, density=True, facecolor='g', alpha=0.75, bins=50)\naxs[0].grid(True)\naxs[0].set_title('populacao_lognorm')\n\naxs[1].hist(populacao_norm, density=True, facecolor='g', alpha=0.75, bins=50)\naxs[1].grid(True)\naxs[1].set_title('populacao_norm')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"352667d92112d31085f67041fff9bc4f26ccd90d"},"cell_type":"markdown","source":"A análise das distribuições de frequência permite uma visão muito mais clara da configuração das populações."},{"metadata":{"_uuid":"ada00e213f2a1eeb88e408eb9494f085fbc3494a"},"cell_type":"markdown","source":"### BoxPlot\n\nO BoxPlot traz as seguintes marcas:\n\n-Caixa definida pelo primeiro quartil, mediana e terceiro quartil\n\n-Fios alongados para além da caixa na distância 1,5 X (Q3 - Q1). Para distribuições não simétricas, as medidas inferior e superior do fio são ajustadas, com multiplicadores distintos da relação anterior. Nesses casos, os fios não são simétricos em relação à caixa (Detalhes em https://en.wikipedia.org/wiki/Box_plot).\n\n-Outliers marcados além da extensão do fio"},{"metadata":{"trusted":true,"_uuid":"210afd282383985c1b52d1d7b4b125da54513db4"},"cell_type":"code","source":"dados = np.concatenate((populacao_lognorm, populacao_norm), 0)\ndados = np.reshape(dados,(2,repeticoes))\ndados = dados.T\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56cf5fd38ba6435f0d11ec6014872457026dade5"},"cell_type":"code","source":"fig, axs = plt.subplots(1, 1, figsize=(10,6))\n_ = plt.boxplot(dados,vert =False, labels =['lognorm','norm'], meanline =True)\nplt.title('Boxplot')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"908133a1f2d2d19ec0d917050e20685806becd70"},"cell_type":"markdown","source":"## Teste de normalidade\n\nMuitos métodos em estatística partem do princípio que a distribuição dos dados é normal.\n\nPara que sejam usados com segurança é importante testar os dados quanto à normalidade.\n\nUma das formas mais efetivas é o qqplot.\n\nFonte: https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/"},{"metadata":{"trusted":true,"_uuid":"82b4344783ee4acc9b5882f4c44a03fc50d2c4e4"},"cell_type":"code","source":"from statsmodels.graphics.gofplots import qqplot\n\nfig, axs = plt.subplots(1, 2, figsize=(14,6))\n\nqqplot(populacao_lognorm, line='s', ax=axs[0])\naxs[0].set_title('populacao_lognorm')\n\nqqplot(populacao_norm, line='s', ax=axs[1])\naxs[1].set_title('populacao_norm')\n\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d28323e0bdb965564fc8e20635e724a20dfe3a79"},"cell_type":"markdown","source":"## Observação sobre o cálculo da variância (correção de bessel)\n\nSendo a variância uma média, o esperado seria a divisão por n (número de elementos na amostra)\n\nEntretanto, tal divisão torna o estimador tendencioso, sendo correto dividir por n-1.\n\nCaso n seja muito grande, tal diferença é imperceptível, para amostras menores o valor fica evidente.\n\nEm numpy usar o parâmetro ddof=1.\n\nVamos ao exemplo:"},{"metadata":{"trusted":true,"_uuid":"5f9b7df24dbcc53e7dc117179398c7df47642949"},"cell_type":"code","source":"repeticoes = 100000\nmean = 5\n\n# População lognormal\ns = 0.8\nrv_lognorm = stat.lognorm(s=s,loc=mean-1.3)\npopulacao_lognorm = rv_lognorm.rvs(size=repeticoes, random_state=random_state)\n\namostra_1000 = populacao_lognorm[np.random.randint(0, len(populacao_lognorm),1000)]\namostra_100 = populacao_lognorm[np.random.randint(0, len(populacao_lognorm),100)]\namostra_10 = populacao_lognorm[np.random.randint(0, len(populacao_lognorm),10)]\n\nprint('Desvios real {}\\n'.format(rv_lognorm.std()))\n\nprint('\\nDesvios amostra 1000 sem correção {}'.format(np.std(amostra_1000)))\nprint('Desvios amostra 1000 com correção {}'.format(np.std(amostra_1000, ddof =1)))\n\nprint('\\nDesvios amostra 100 sem correção {}'.format(np.std(amostra_100)))\nprint('Desvios amostra 100 com correção {}'.format(np.std(amostra_100, ddof =1)))\n\nprint('\\nDesvios amostra 10 sem correção {}'.format(np.std(amostra_10)))\nprint('Desvios amostra 10 com correção {}'.format(np.std(amostra_10, ddof =1)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"599915ca4089d3cd8bc4d1bfde0229433530d7c5"},"cell_type":"markdown","source":"<font size=\"6\" color=\"red\">Inferência Estatística</font>\n\nConforme já descrito, a inferência estatística busca estender para a população informações obtidas na amostra.\n\nPara tratarmos de inferência, é preciso primeiro estudar o teorema do limite central."},{"metadata":{"_uuid":"72dd08cd4a1078f4a3c14c0846e94195d75d112d"},"cell_type":"markdown","source":"<font size=\"6\" color=\"red\">Teorema do limite central</font>\n\nO teorema estabelece que a distribuição da soma de variáveis aleatórias <b>iid (independentes e identicamente distribuídas)</b> tende para uma distribuição normal, independente da distribuição original das variáveis. (Fonte: https://en.wikipedia.org/wiki/Central_limit_theorem)\n\nPara compreender melhor o significado do teorema, vamos a um exemplo:"},{"metadata":{"_uuid":"fb497dc927f9358c2064197bc040acb4af36646f"},"cell_type":"markdown","source":"Vamos considerar 100.000 doações feitas para um candidato, cujo valor mínimo de doação foi estabelecido em R$ 48.\n\nO comportamento esperado é que a grande maioria faça a contribuição mínima.\n\nHaverá, porém, contribuições acima do mínimo, em valores diversos e quantidades reduzidas.\n\nCom isso, temos uma distribuição semelhante a uma log-normal ou exponencial, veja o gráfico."},{"metadata":{"trusted":true,"_uuid":"e8838a3a76df274dac73d7e50739da57f1425834"},"cell_type":"code","source":"# Vamos criar uma população distribuída de forma lognormal\n\nrepeticoes = 100000\nmean = 50\n\n# População lognormal\ns = 1\nnp.random.seed(1)\nrv_lognorm = stat.lognorm(s=s,loc=mean-1.3)\npopulacao_lognorm = rv_lognorm.rvs(size=repeticoes, random_state=random_state)\n\n\nprint('Mínimo {}'.format(np.min(populacao_lognorm)))\nprint('Máximo {}'.format(np.max(populacao_lognorm)))\nprint('Média {}'.format(np.mean(populacao_lognorm)))\nprint('Desvio {}'.format(np.std(populacao_lognorm)))\n\nfig, axs = plt.subplots(1, 1, figsize=(14,6))\n\naxs.hist(populacao_lognorm, density=True, facecolor='g', alpha=0.75, bins=100)\naxs.grid(True)\naxs.set_title('populacao_lognorm')\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60fae2ee414923fc1500416ad9809c4dd834e9ba"},"cell_type":"markdown","source":"De toda a \"população\" de doações, vamos retirar várias amostras para estudar seu comportamento.\n\nObservação: Numa situação real, seria extraída apenas uma amostra."},{"metadata":{"trusted":true,"_uuid":"c8aaac6339b683f2c9247dccca9bb6651db2c12e"},"cell_type":"code","source":"# Vamos extrair 1000 amostras e calcular suas médias\namostras = 10000\nnp.random.seed(1)\nmedias = np.zeros((amostras,1))\nfor i in range(0,amostras,1):\n    medias[i]=np.mean(populacao_lognorm[np.random.randint(0, len(populacao_lognorm),amostras)])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d1755cecb101abfe3382c5a2fefbb17d24f4238"},"cell_type":"code","source":"# A distribuição das médias aproxima-se de uma Normal, independente da distribuição original que gerou as amostras\n\nn, bins, patches = plt.hist(medias, density=True, facecolor='g', alpha=0.75, bins=50)\n\nmean_ = np.mean(medias)\nstd_ = np.std(medias)\nprint('Média {}'.format(mean_))\nprint('Desvio {}'.format(std_))\n\nrv = norm(loc=mean_, scale=std_)\n\nintervalo = np.linspace(mean_-3*std_,mean_+3*std_, num=50)\nplt.plot(intervalo, rv.pdf(intervalo), 'k-', label='pdf')\n\nplt.xlabel('Média')\nplt.ylabel('Probabilidade')\nplt.title('Histogram de médias')\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"743ba6587703565284a962307f6764285e1a2832"},"cell_type":"markdown","source":"## Intervalo de confiança\n\nConforme previsto pelo teorema do limite central, a distribuição das médias das amostras (considerando que a média é uma soma de variáveis aleatórias dividida pelo número de elementos) tende para a distribuição normal.\n\nAlém disso, a média dessa distribuição tende para a média da população.\n\nPerceba que, apesar da distribuição original das amostras ter distribuição completamente diferente da normal, as médias das amostras tendem à normal.\n\nUma consequência extremamente importante do teorema é que, dada a distribuição normal, tem-se que, com 95,45% de certeza, a média de qualquer amostra estará a dois desvios padrão da média da população.\n\nNo exemplo em questão, teremos:"},{"metadata":{"trusted":true,"_uuid":"47a17ff3c8079a1f54088a8bc38bbd342679030c"},"cell_type":"code","source":"mean_ = np.mean(medias)\nstd_ = np.std(medias)\nprint('Média amostras {}'.format(mean_))\nprint('Desvio amostras {}'.format(std_))\n\nprint('Intervalo de 95,45% de confiança {} - {}'.format(mean_-2*std_,mean_+2*std_))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"177d5a4f132735d517383c2b65fa71e8607a329d"},"cell_type":"markdown","source":"Reforçando a conclusão acima: podemos garantir com 95,45% de confiança que qualquer amostra terá sua média entre 50,22 e 50,49.\n\nPara testarmos tal conclusão, vamos verificar a média de dez amostras aleatórias:\n"},{"metadata":{"trusted":false,"_uuid":"044d788b999f0d6cab47ba79e7b41677d965cdfa"},"cell_type":"code","source":"np.random.seed(1)\nfor i in range(0,10,1):\n    print('Média da amostra {}: {}'.format(i,\n                                np.mean(populacao_lognorm[np.random.randint(0, len(populacao_lognorm),amostras)])))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02c82d1de05792cab076f342858ab3aa620b2fe5"},"cell_type":"markdown","source":"## Margem de erro\n\nOutra conclusão importante que podemos chegar é a margem de erro.\n\nDado o valor da amostra, podemos estabelecer a margem de erro com 2 desvios padrão (0,27%) para o intervalo de confiança de 95%.\n\nVamos ver os resultados acima considerando a margem de erro e a média real da população (50.36):\n"},{"metadata":{"trusted":true,"_uuid":"da444a6b84a0fbc87e1d45a3162100c2d42ed7ec"},"cell_type":"code","source":"np.random.seed(1)\nfor i in range(0,10,1):\n    media_i = np.mean(populacao_lognorm[np.random.randint(0, len(populacao_lognorm),amostras)])\n    print('Amostra {}, média {}, com margem de erro {} - {}'.format(i,\n                                                                    media_i,\n                                                                   media_i-2*std_,\n                                                                   media_i+2*std_))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd975b7ca543ed28e63c1e48ce45f0a0dcf76b75"},"cell_type":"markdown","source":"Os exemplos acima consideraram uma amostra de 1000, correspondente a 1% da população, uma amostra relativamente grande.\n\nVamos diminuir nossa amostra para 100 e ver o impacto no grau de confiânça e margem de erro:\n"},{"metadata":{"trusted":true,"_uuid":"0a258072173f8993f7563896ef3939100a586e27"},"cell_type":"code","source":"amostras = 1000\nnp.random.seed(1)\nmedias = np.zeros((amostras,1))\nfor i in range(0,amostras,1):\n    medias[i]=np.mean(populacao_lognorm[np.random.randint(0, len(populacao_lognorm),100)])\n\nmean_ = np.mean(medias)\nstd_ = np.std(medias)\nprint('Média amostras {}'.format(mean_))\nprint('Desvio amostras {}'.format(std_))\n\nprint('Intervalo de 95,45% de confiança {} - {}'.format(mean_-2*std_,mean_+2*std_))\n\nprint('Margem de erro: {}'.format(100*2*std_/mean_))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f8bd91875c02605613f93af4737547917ce9a5e0"},"cell_type":"markdown","source":"Para obtermos a mesma margem de erro de 95.45%, a margem de erro cresce de 0,27% (1000 amostras) para 0,86% (100 amostras)"},{"metadata":{"_uuid":"46b2da478bae2a9f114dc7c48a6ea1e7d3c8e31a"},"cell_type":"markdown","source":"## Comparação do desvio das amostras com o desvio da população\n\nO desvio padrão das médias das amostras é igual ao desvio da população dividido pela raiz do tamanho da amostra.\n\nComo a margem de erro é proporcional ao desvio das médias, conclui-se que:\n\n-A margem de erro crece conforme for maior o desvio padrão da população\n\n-A margem de erro diminui com o aumento do número de amostras"},{"metadata":{"_uuid":"2de44bc2824f140471a266bb71ab98f692301691"},"cell_type":"markdown","source":"## Generalizando o resultado\n\nFixado o intervalo de confiânça, estabelecemos a quantidade de desvios padrão.\nPara 95,45%, temos dois desvios padrão.\n\nDada uma amostra, a margem de erro será 2x(desvio_populacao/raiz(tamanho_amostra))/média_amostra (multiplicar por cem para ter percentual)\n\nComo não sabemos o desvio padrão da população, vamos aproximá-lo com o desvio da amostra. Como o desvio da amostra aproxima o desvio da população, devemos, da mesma forma, dividi-la pela raiz(tamanho_amostra).\n\nAssim, a margem de erro será calculada como (2xdesvio_amostra/raiz(tamanho_amostra))/média_amostra.\n\nUm exemplo:"},{"metadata":{"trusted":false,"_uuid":"f87e33b6b7b8a85b6c11a9c1fcc1ebecc11a89f8"},"cell_type":"code","source":"np.random.seed(1)\namostra_100_elementos = populacao_lognorm[np.random.randint(0, len(populacao_lognorm),100)]\nprint('Média amostra {}'.format(np.mean(amostra_100_elementos)))\nprint('Desvio amostra {}'.format(np.std(amostra_100_elementos)))\nprint('Desvio estimado amostras {}'.format(np.std(amostra_100_elementos)/np.sqrt(len(amostra_100_elementos))))\nprint('Margem erro {}'.format(100*2*np.std(amostra_100_elementos)/np.sqrt(len(amostra_100_elementos))/np.mean(amostra_100_elementos)))\n\n\n# o desvio padrão das médias das amostras é desvio da população / sqrt(samples)\n#print(np.std(populacao_lognorm)/np.sqrt(100) )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"edfcf7f1481d0f3b0f6b318f5f4c9691c07c17c3"},"cell_type":"markdown","source":"## E se o intervalo de confiança desejado for diferente do fornecido por um desvio padrão?\n\nUtilizar a função interval para localizar os pontos exatos que indicarão os limites para alcançar a probabilidade indicada.\n\nNo caso de desejar 99% de confiânça, multiplicar por 2,58 o desvio padrão, não por 2 como no caso de 95% de confiança."},{"metadata":{"trusted":false,"_uuid":"0366e9a3a71c89dfd9a678c28950a40b210a2adf"},"cell_type":"code","source":"from scipy.stats import norm\nfrom scipy.stats import kstest\n\nmean = 0\nstd = 1\nrv = norm(loc=mean, scale=std)\n\nprint(rv.std() )\nprint(rv.interval(0.9545))\n\nprint(rv.interval(0.99))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"447e1bc83eeeae7a610c4bd46273e434c5ccd006"},"cell_type":"markdown","source":"## Distribuição t de Student\n\nQuando utilizado o desvio padrão da amostra no lugar do desvio da população, o correto é usar a distribuição t de Student no lugar da distribuição Normal para cálculo do intervalo de confiança.\n\nEntretanto, a distribuição t aproxima-se da Normal para amostras com mais de 30 elementos, por isso mantivemos a distribuição Normal nos cálculos acima.\n\nNo exemplo seguinte, para 100 elementos na amostra (graus de liberdade = amostras-1), os valores são muito semelhantes aos obtidos para a Normal no exemplo acima."},{"metadata":{"trusted":false,"_uuid":"a4993279333cd6cdcf750cdc72fa0f5ab1923193"},"cell_type":"code","source":"from scipy.stats import t\nfrom scipy.stats import kstest\n\n\nrv = t(df=(100-1))\n\nprint(rv.std() )\nprint(rv.interval(0.9545))\n\nprint(rv.interval(0.99))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98328382b436a5147831cf11c83293d59c7d961e"},"cell_type":"markdown","source":"## Teorema do limite central normalizado\n\nDado um conjunto de variáveis aleatórias, realizando a soma, subtraindo por n X média_população e dividindo por (desvio_população X raiz de n), temos uma normal standard"},{"metadata":{"_uuid":"b3b3e0b6e52e5b82bd0227029b1b650ef73b426b"},"cell_type":"markdown","source":"<font size=\"6\" color=\"red\">Correlação entre Variáveis</font>\n\nA correlação analisa possíveis relacionamentos existentes entre variáveis distintas. Procura determinar se são independentes ou dependentes e, no último caso, qual o tipo de dependência.\n\nVamos a um exemplo: o relatório de felicidade por pais da ONU, que mede o índice de felicidade por nação e seus indicadores (fonte: https://www.kaggle.com/unsdsn/world-happiness).\n"},{"metadata":{"trusted":false,"_uuid":"5fe960ea99b69ed7e191c5aee61cb48a23e763b4"},"cell_type":"code","source":"if IN_KAGGLE:\n    df = pd.read_csv(\"../input/2017.csv\")\nelse:\n    df = pd.read_csv(\"2017.csv\")\n    \n\ndf.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"47f9516c5049e017358753687fe54c7690ea2367"},"cell_type":"code","source":"df = df.loc[:,[  'Happiness.Score',  'Economy..GDP.per.Capita.', 'Family',\n       'Health..Life.Expectancy.', 'Freedom', 'Generosity',\n       'Trust..Government.Corruption.','Dystopia.Residual']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7abbb6bab86df48dd9ebc1858eb56586e9dafb6d"},"cell_type":"code","source":"plt.figure(figsize=(14,6))\n\n_ = df['Happiness.Score'].hist( bins=50, density=True)\n\nplt.xlabel('Índice de felicidade')\nplt.ylabel('Probabilidade')\nplt.title('Histogram do índice de felicidade')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c48f402b9c2d3fe32963a0fe10dcd49b573d06df"},"cell_type":"markdown","source":"Vamos calcular o índice de correlação entre as variáveis do relatório.\n\nUma forma visual e simples de analisar correlações é através de scatter plots."},{"metadata":{"trusted":false,"_uuid":"aa14147c9829c4d16d983410ed7315ba4f35c903"},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"716a87254da340ff53d9a6a7501bf8280f5feaaa"},"cell_type":"code","source":"# Aparentemente economia é fortemente correlacionada com felicidade\n\n_ = df.plot(figsize=(14,6), kind='scatter', x='Happiness.Score', y='Economy..GDP.per.Capita.' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f64bd773a7ac5b1443af697a42aef0b97d99b0aa"},"cell_type":"code","source":"# Já a generosidade não apresenta correlação significativa\n\nplt.figure()\n\n_ = df.plot(figsize=(14,6),kind='scatter', x='Happiness.Score', y='Generosity' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ccbd1d2c5e4623ce4354fbaccbae8386aaa66d73"},"cell_type":"code","source":"from pandas.plotting import scatter_matrix\n\n_ = scatter_matrix(df, figsize=(14,10), alpha=0.2, diagonal='kde')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fbad606eadb9d4b67ce15ad3ff9258ab23b49a66"},"cell_type":"markdown","source":"Mais formalmente, as medidas mais usadas de correlação são:\n\nCovariância: mede a variação conjunta das duas variáveis em torno de suas médias\n\nCoeficiente de correlação de Pearson: mede a variação conjunta das variáveis em torno da média, variações normalizadas pelo desvio padrão (mais fácil interpretação porque o resultado fica no intervalo [-1 1])\n\nCoeficiente de correlação de Spearman: calcula o coeficiente de correlação de Pearson utilizando rank order dos elementos dos arrays"},{"metadata":{"trusted":false,"_uuid":"9db85156df003f023f974e52bb725cf89ae81e30"},"cell_type":"code","source":"#df.plot(figsize=(14,6), kind='scatter', x='Happiness.Score', y='Economy..GDP.per.Capita.' )\nnp.cov(df[['Happiness.Score','Economy..GDP.per.Capita.']].values.T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"62ffe65d80a18b83507268d048d2a479f394150d"},"cell_type":"code","source":"#df.plot(figsize=(14,6), kind='scatter', x='Happiness.Score', y='Economy..GDP.per.Capita.' )\nnp.corrcoef(df[['Happiness.Score','Economy..GDP.per.Capita.']].values.T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f3f22b393a7a2ea40d0fa3d41ecd82b0370207fc"},"cell_type":"code","source":"from scipy.stats import spearmanr\n\nrho, pval = spearmanr(df[['Happiness.Score','Economy..GDP.per.Capita.']].values)\nprint(rho)\nprint(pval)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3766a321378a8d244dec3fdb08225a5c315a56c2"},"cell_type":"markdown","source":"## Correlação não linear\n\nAs correlações analisadas até agora são lineares, indicando se ambas as variáveis tem igual variação em torno da média.\n\nEm correlações não lineares o pressuposto acima não se configura, embora haja correlação entre as variáveis.\n\nPor isso há que se ter cuidado com a análise dos indicadores acima."},{"metadata":{"trusted":false,"_uuid":"3853c6b6f48d1240fc7a6b32391222ef13a86993"},"cell_type":"code","source":"x=np.arange(0, 8.1, 0.05)\ny = np.sin(np.pi*x)\n\nfig, ax1 = plt.subplots(figsize=(14,8))\nax1.plot( y)\nplt.grid()\nplt.tight_layout()\nplt.show()\n\nprint(len(x))\n\nprint(np.corrcoef(x,y))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4268dd4af97aed721d2fb6eb427016de88c72d08"},"cell_type":"markdown","source":"## Autocorrelação\n\nÉ a correlação feita com a própria variável, considerando um intervalo, normalmente tempo"},{"metadata":{"trusted":false,"_uuid":"2fd536caae1375d132d6ccac429b1a82487ad4cd"},"cell_type":"code","source":"# https://machinelearningmastery.com/gentle-introduction-autocorrelation-partial-autocorrelation/\n\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\n\nfig, ax = plt.subplots(2,1,figsize=(14,8))\nplot_acf(y,ax=ax[0])\nplot_pacf(y,ax=ax[1])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75aa588005e5bdc94487b28eb82bd2b2a667e069"},"cell_type":"markdown","source":"## Correlação não significa causalidade\n\nA existência de correlação entre variáveis não significa, necessariamente, que uma variável afete diretamente o valor da outra.\n\nA correlação indica que há movimentação conjunta de ambas as variáveis, efeito que pode ser produzido por uma terceira variável.\n\nNo exemplo abaixo, ambas as variáveis (sen e cos) estão fortemente correlacionadas (-1). Porém, o que afeta o valor da ambas é o ângulo original.\n\nPara exemplos concretos, ver o link abaixo.\n\nhttp://www.tylervigen.com/spurious-correlations\n"},{"metadata":{"trusted":false,"_uuid":"8f0ce01e3e1b4881b6a5d597fb8a636961530850"},"cell_type":"code","source":"x=np.arange(0, 8.1, 0.05)\ny1 = np.sin(np.pi*x)\ny2 = np.cos(np.pi*(x+1/2))\n\nfig, ax = plt.subplots(2,1,figsize=(14,8))\nax[0].plot(y1)\nax[1].plot(y2)\nplt.tight_layout()\nplt.show()\n\n\nprint(np.corrcoef(y1,y2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08310f28ed8ba692190d15a9c8660bd51ad5660e"},"cell_type":"markdown","source":"<font size=\"6\" color=\"red\">Análise Temporal</font>\n\nAnálise de séries temporais está fora do escopo deste trabalho.\n\nA questão aqui colocada é simplesmente a verificação se os dados coletados estão variando no tempo ou não, ou seja, se a série é estacionária.\n\nMais formalmente colocando, a maioria das análises feitas até o momento pressupõe que as variáveis aleatórias (amostras) sejam iid, independentes e identicamente distribuídas. Caso as variáveis coletadas sofram mudança ao longo do tempo, deixarão de ser identicamente distribuídas (oriundas da mesma distribuição), o que invalida os testes apresentados.\n\nVejamos um exemplo onde uma distribuição normal é afetada pela passagem do tempo:\n"},{"metadata":{"trusted":false,"_uuid":"23f24e928665538e1ad2d37e5b748afa91d30826"},"cell_type":"code","source":"mean = 0\nstd = 1\nrepeticoes=1000\n\nrv_norm = stat.norm(loc=mean, scale=std)\npopulacao_norm = rv_norm.rvs(size=repeticoes, random_state=random_state)\n\nmean_ = np.mean(populacao_norm)\nstd_ = np.std(populacao_norm)\n\nprint('População normal, média {}, desvio padrão {}'.format(mean_, std_))\n\npopulacao_norm += np.linspace(0.0,5*std,repeticoes)\n\nmean_ = np.mean(populacao_norm)\nstd_ = np.std(populacao_norm)\n\nprint('População normal alterada, média {}, desvio padrão {}'.format(mean_, std_))\n\nrv = norm(loc=mean_, scale=std_)\n\nintervalo = np.linspace(mean_-3*std_,mean_+3*std_, num=50)\n\n\n\nfig, axs = plt.subplots(1, 2, figsize=(14,6))\n\naxs[0].plot(populacao_norm,'.')\naxs[0].grid(True)\naxs[0].set_title('populacao_norm')\n\naxs[1].hist(populacao_norm, density=True, facecolor='g', alpha=0.75, bins=50)\naxs[1].plot(intervalo, rv.pdf(intervalo), 'k-', label='pdf')\naxs[1].grid(True)\naxs[1].set_title('populacao_norm')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77661c43bec74d0148abb69b3b99f433832a2669"},"cell_type":"markdown","source":"Neste exemplo, tanto a simples plotagem dos dados (esquerda), como a distribuição de probabilidade (esquerda) dão indícios de não estacionariedade. Há testes estatísticos para verificação de estacionariedade (ex. Dickey-Fuller).\n\nNeste caso, devem ser usadas técnicas de análise de séries temporais para eliminação da tendência temporal e, só então, fazer a análise da série estacionária resultante."},{"metadata":{"_uuid":"f52185ef7fe8802f65767a82f132c6dffd324a86"},"cell_type":"markdown","source":"<font size=\"6\" color=\"red\">Outliers</font>\n\nOutliers são medidas que se afastam das demais medidas de um conjunto.\n\nPodem derivar de erros de medição ou se tratar de eventos raros.\n\nEm ambos os caso merecem atenção, ou para que sejam corrigidos, no caso de erro, ou para verificar a origem de tais eventos raros.\n\nResumidamente podemos usar duas técnicas para localização de Outliers: desvio padrão e percentis.\n\nIndependente da técnica, a plotagem de um gráfico boxplot é útil para verificarmos sua presença.\n"},{"metadata":{"trusted":false,"_uuid":"31117d1beafe4ef3890b6bc6a32bb55675af22dd"},"cell_type":"code","source":"repeticoes = 1000\n\n# População normal\nmean = 5\nstd = 1.3\nrv_norm = stat.norm(loc=mean, scale=std)\npopulacao_norm = rv_norm.rvs(size=repeticoes, random_state=random_state)\n\nfig, axs = plt.subplots(1, 1, figsize=(10,6))\n_ = plt.boxplot(populacao_norm,vert =False, meanline =True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e97679d767cce6ed68638b27992372bc852cc63d"},"cell_type":"markdown","source":"## Utilizando desvio padrão"},{"metadata":{"trusted":false,"_uuid":"6dad37d08f897a6c9cc09b7cdb07e593a76b5964"},"cell_type":"code","source":"media = np.mean(populacao_norm)\nstd = np.std(populacao_norm)\n\nprint('Média {}, STD {}'.format(media,std))\n\noutliers1 = np.where(populacao_norm > (media+3*std))\noutliers2 = np.where(populacao_norm < (media-3*std))\n\noutliers = np.concatenate( (outliers1,outliers2), axis=1)\n\npopulacao_norm[outliers]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b83b64ca95646531f5812d3261c9a8090e87fb5f"},"cell_type":"markdown","source":"## Utilizando quartis"},{"metadata":{"trusted":false,"_uuid":"01b3fdd54b10bdc538fe61eb7ce444ad223bcd7d"},"cell_type":"code","source":"q25, q75 = np.percentile(populacao_norm, 25), np.percentile(populacao_norm, 75)\n\niqr= q75 - q25\n\noutliers1 = np.where(populacao_norm > (q75+1.5*iqr))\noutliers2 = np.where(populacao_norm < (q25-1.5*iqr))\n\noutliers = np.concatenate( (outliers1,outliers2), axis=1)\n\npopulacao_norm[outliers]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56acd1f0de2d3cbc16133ba736495ef979853bf5"},"cell_type":"markdown","source":"<font size=\"6\" color=\"red\">Teste de Hipótese</font>\n\nFonte: https://machinelearningmastery.com/statistical-hypothesis-tests-in-python-cheat-sheet/\n\nO teste de hipótese refere-se à comparação entre a hipótese nula (H0) e a hipótese alternativa (H1).\n\nQueremos garantir que, dado que H0 esteja correta, a probabilidade de aceitar H1 seja reduzida, normalmente fixada em 0,05 ou 0,01. A esse valor chamamos p value (nível de significância).\n\nSempre haverá possibilidade de erro, ou seja, podemos aceitar H1 mesmo quando H0 esteja correta. Porém a probabilidade do erro deve ser baixa.\n\nAs hipóteses são normalmente de dois tipos: \n\n- 1 sided: o valor de uma distribuição é maior ou menor que outra\n\n- 2 sided: o valor de uma distribuição é diferente de outra, ou seja, é maior ou menor que outra \n\n"},{"metadata":{"_uuid":"320420bef7c6d9e3a03d998fd83b7ac007956595"},"cell_type":"markdown","source":"## Vamos estudar um exemplo passo-a-passo para compreender o conceito\n\nEm 30 lançamentos de uma moeda HONESTA, espera-se que ocorram 15 caras, com desvio padrão de 2,73\n\nVeja o cálculo:"},{"metadata":{"trusted":false,"_uuid":"d7ab519657576ce9dca1574181a0953328bf54ad"},"cell_type":"code","source":"from scipy.stats import binom\ntentativas = 30\nrv_honesta = binom(tentativas, 1/2)\npopulacao_honesta = rv_honesta.rvs(size=1000000)\nprint(rv_honesta.mean())\nprint(rv_honesta.std())\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5c703f37c4afb63514aacd7ab84e6ce2ffc9128"},"cell_type":"markdown","source":"Supondo agora que nos foi dada uma amostra com o 100 resultados (número de caras) de 30 lançamentos, cuja média foi 12,23.\n\nDado que a média foi menor do que seria esperado de uma moeda HONESTA (diferença de 2,7), podemos afirmar que os resultados foram obtidos com uma moeda não honesta?"},{"metadata":{"trusted":false,"_uuid":"66deed3b77bf3f96a10c7b2618cbd31114207277"},"cell_type":"code","source":"rv = binom(tentativas, 1/2.5)\nresultado = rv.rvs(size=100)\nprint(np.mean(resultado))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"521ac79981a183fb77699f3e7720426d2008da93"},"cell_type":"markdown","source":"A hipótese nula (H0) é que a moeda seja realmente honesta e que a diferença deva-se a mero acaso.\n\nA hipótese alternativa (H1) é que a moeda não seja honesta.\n\nComo já aprendemos no teorema do limite central, as amostras de uma moeda HONESTA deveria ter média 15 e desvio igual ao desvio da população dividido pela raiz do tamanho da amosta. Veja o cálculo:"},{"metadata":{"trusted":false,"_uuid":"d5829b5a0660a4c12a573cc129665ba844429b4f"},"cell_type":"code","source":"amostras = 500\nmedias = np.zeros((amostras,1))\nfor i in range(0,amostras,1):\n    medias[i]=np.mean(populacao_honesta[np.random.randint(0, len(populacao_honesta),100)])\n\nprint(medias.mean())\nprint(medias.std())    \n\nfig, axs = plt.subplots(1, 1, figsize=(14,6))\n\n\naxs.hist(medias, density=True, facecolor='g', alpha=0.75, bins=50)\naxs.grid(True)\naxs.set_title('Distribuição das médias')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80125674ac50bb919e65af6d5912b91279e75823"},"cell_type":"markdown","source":"Conforme previsto, a média das amostras (14,988) corresponde à media da população e o desvio das amostras é o da população dividido por 10.\n\nAgora, sendo a moeda honesta, qual a chance de obtermos uma amostra com média 12,23?\n\nVamos calcular a probabilidade de obtermos um valor que seja 12,23 ou menor com uma moeda honesta:"},{"metadata":{"trusted":false,"_uuid":"3ae5e76855e70fa26743b25440c64ae6d8cc0348"},"cell_type":"code","source":"rv_honesta.cdf(12.23)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c91e598d6c0ebea0ec17af4d5e04d83744e867a1"},"cell_type":"markdown","source":"Há 18% de chance de uma moeda honesta produzir uma amostra cuja média seja 12,23 ou menor.\n\nHá 2 x 18% de termos uma média cuja diferença em relação a 15 seja maior que 2,7.\n\nOu seja, se a moeda for honesta (H0), caso afirmemos que é desonesta, estaremos errados em 2 X 18% (36%) das vezes.\n\nSe estabelecermos nosso nível de significância em 5% (admitirmos no máximo 5% de possibilidade de erro), não podemos afirmar que a moeda é desonesta, ou seja, não podemos recusar H0.\n\nConcluindo, apesar da diferença entre a média esperada (15) e a obtida (12,23), continuamos considerando a moeda honesta."},{"metadata":{"_uuid":"4f80192e90a76693538db4e42dcbfcc727a3a6bd"},"cell_type":"markdown","source":"## Vamos estudar um segundo exemplo "},{"metadata":{"trusted":false,"_uuid":"30f5e0204b6af6f8aafd96dbb512003212569f7c"},"cell_type":"code","source":"if IN_KAGGLE:\n    df = pd.read_csv(\"../input/2016.csv\")\nelse:\n    df = pd.read_csv(\"2016.csv\")\ndf.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"69ce5a914e77cb2ee47ba4883805db60c66ac389"},"cell_type":"code","source":"df.Region.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f25c738839fba76badaa8b3f30fa9afd226165c4"},"cell_type":"code","source":"dfWE = df.loc[df.Region == 'Western Europe',['Country', 'Region', 'Happiness Rank', 'Happiness Score',\n       'Lower Confidence Interval', 'Upper Confidence Interval',\n       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',\n       'Freedom', 'Trust (Government Corruption)', 'Generosity',\n       'Dystopia Residual']]\n\ndfLC = df.loc[df.Region == 'Latin America and Caribbean',['Country', 'Region', 'Happiness Rank', 'Happiness Score',\n       'Lower Confidence Interval', 'Upper Confidence Interval',\n       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',\n       'Freedom', 'Trust (Government Corruption)', 'Generosity',\n       'Dystopia Residual']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1f5a7729d0f37644c9920e0a8b0c2d1331b7639d"},"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(14,6))\n\naxs[0].hist(dfWE['Happiness Score'], density=True, facecolor='g', alpha=0.75)\naxs[0].grid(True)\naxs[0].set_title('Western Europe')\n\nprint(dfWE['Happiness Score'].mean())\nprint(dfWE['Happiness Score'].std())\n\naxs[1].hist(dfLC['Happiness Score'], density=True, facecolor='g', alpha=0.75)\naxs[1].grid(True)\naxs[1].set_title('Latin America and Caribbean')\n\nprint(dfLC['Happiness Score'].mean())\nprint(dfLC['Happiness Score'].std())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"18c9ec44f918518486f9c332880aae39e5c6c9d0"},"cell_type":"code","source":"from scipy import stats\n\nstats.ttest_ind(dfWE['Happiness Score'].values,dfLC['Happiness Score'].values, equal_var=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bb9e975516d436bba1b927290700b82a54825ed5"},"cell_type":"code","source":"from scipy import stats \n\nstats.ttest_ind(dfWE['Happiness Score'].values,dfLC['Happiness Score'].values, equal_var=True)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1fc0a9884782a2026f3986af6ebef16711ecfb98"},"cell_type":"markdown","source":"<font size=\"6\" color=\"red\">Anexo I - Funções Úteis</font>"},{"metadata":{"_uuid":"d97e060faa5b21de11a6caa46ff3f8cf223e35fe"},"cell_type":"markdown","source":"## Gerando números aleatórios\n"},{"metadata":{"trusted":false,"_uuid":"7e112cd5684d94cc177dcd613499953cf44a2401"},"cell_type":"code","source":"# Gerando int - biblioteca python standard\nprint(random.randrange(100, 1000, 2))\nprint(random.randint(100, 1000))\n\n# Gerando int - biblioteca numpy\nprint(np.random.randint(100, 1000,2))\n\n# Gerando float - biblioteca python standard\nprint(random.random())\nprint(random.uniform(100, 1000))\nprint(random.normalvariate(1, 1))\n\n# Gerando float - biblioteca numpy\nprint(np.random.random(5))\nprint(np.random.randn(5))\n\nnp.random.random_sample(size=100)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ec370658c245db5e36fedb215a5b48fa2889d8c"},"cell_type":"markdown","source":"## Gerando números não aleatórios"},{"metadata":{"trusted":false,"_uuid":"a96c3b0ba4ccc7756956d9598e1023ed1b1c8d14"},"cell_type":"code","source":"print(np.linspace(0.0,1.0,11))\nprint(np.arange(0.0,10.0,3))\nprint(np.logspace(0.0,10.0,3))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bdbda2b2f6d2a308ea38054b86d57f8fbe301e4d"},"cell_type":"markdown","source":"## Escolha"},{"metadata":{"trusted":false,"_uuid":"3e2bf5d3a6dca3ea8e137933243e7c7df209c741"},"cell_type":"code","source":"# Escolha com reposição\n# usando numpy np.random.choice(10,size=10,replace=True)\n\n\nfaces = list(range(1,7))\nlancamentos = 600\npesos = [1/6,1/6,0.5/6,0.5/6,2/6,1/6]\nresultados = random.choices(population=faces, weights=pesos, k=lancamentos)\n#print(resultados)\nfor i in faces:\n    print('Face {}, peso {}, vezes {}'.format(i,pesos[i-1],resultados.count(i)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4924b74ef5266176396af62ea1c5aa3ac7a9a4f6"},"cell_type":"code","source":"# Escolha sem reposição\n# usando numpy np.random.choice(10,size=10,replace=False)\n\n\nlista = list(range(1,7))\nrandom.sample(population=lista, k=len(lista))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"595300dbec5ced42f0b7f0294ab1b8c772610301"},"cell_type":"markdown","source":"## Embaralhamento"},{"metadata":{"trusted":false,"_uuid":"4c310a7f6c34c32b2ba17400074911f3e3d4b600"},"cell_type":"code","source":"# Embaralhamento\n# usando numpy np.random.choices\n\nlista = list(range(1,7))\nrandom.shuffle(lista)\nlista","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d23753ee4e9539a3a166362f12e0d6fd1c751063"},"cell_type":"markdown","source":"<font size=\"6\" color=\"red\">Anexo II - Referências</font>\n\nTutoriais\n\nhttps://www.youtube.com/watch?v=Iq9DzN6mvYA\n\nhttps://machinelearningmastery.com/how-to-generate-random-numbers-in-python/\n\nhttp://nbviewer.jupyter.org/url/norvig.com/ipython/Probability.ipynb\n\nhttps://www.youtube.com/watch?v=KhAUfqhLakw\n\nhttps://www.analyticsvidhya.com/blog/2017/09/6-probability-distributions-data-science/\n\nhttps://www.datacamp.com/community/tutorials/python-statistics-data-science\n\nhttps://machinelearningmastery.com/\n\n\nDistribuições de probabilidade\n\nhttp://blog.cloudera.com/blog/2015/12/common-probability-distributions-the-data-scientists-crib-sheet/\n\nhttp://www.math.wm.edu/~leemis/chart/UDR/UDR.html\n\nCursos\n\nhttps://courses.edx.org/courses/course-v1:UCSanDiegoX+DSE210x+1T2018/course/#block-v1:UCSanDiegoX+DSE210x+1T2018+type@chapter+block@c1c0e5a497924a40b800bf69e96b4004\n\nDocumentação bibliotecas Python\n\nhttps://docs.python.org/3/library/statistics.html\n\nhttps://docs.python.org/3/library/random.html\n\nDocumentação bibliotecas SciPy\n\nhttps://docs.scipy.org/doc/scipy/reference/stats.html\n\nDocumentação bibliotecas NumPy\n\nhttps://docs.scipy.org/doc/numpy/reference/routines.random.html\n\nhttps://docs.scipy.org/doc/numpy/reference/routines.statistics.html\n\nDataframe\n\nhttp://pandas.pydata.org/pandas-docs/version/0.13/visualization.html\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}