{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predict Loan Eligibility for Dream Housing Finance company\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost.sklearn import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/finance-company-loan-data/train_ctrUa4K.csv')\ntest = pd.read_csv('../input/finance-company-loan-data/test_lAUu6dG.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STEP 1: Data Pre- Processing\n\n# a) Finding the Missing Value Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join both the train and test dataset\ntrain['source']='train'\ntest['source']='test'\n\ndataset = pd.concat([train,test], ignore_index = True)\nprint(\"Train dataset shape:\",train.shape)\nprint(\"Test dataset shape:\",test.shape)\nprint(\"Concatenated dataset shape:\",dataset.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataset['Gender'].unique())\nprint(dataset['Married'].unique())\nprint(dataset['Dependents'].unique())\nprint(dataset['Self_Employed'].unique())\nprint(dataset['LoanAmount'].unique())\nprint(dataset['Loan_Amount_Term'].unique())\nprint(dataset['Credit_History'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# b) replacing missing data with substituted values\n<b>Out of the features with missing NaN values, the missing values in 'Loan_Status' are the Values that need to be predicted by our model. Hence, we need not impute the NaN values in Loan_Status column.\n    \n1) Missing values in Integer and Float dtype columns are replaced by their median \n    \n2) Missing values in Object dtype columns are replaced by their mode</b>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Gender'].fillna(dataset['Gender'].mode()[0], inplace=True)\ndataset['Married'].fillna(dataset['Married'].mode()[0], inplace=True)\ndataset['Dependents'].fillna(dataset['Dependents'].mode()[0], inplace=True)\ndataset['Self_Employed'].fillna(dataset['Self_Employed'].mode()[0], inplace=True)\ndataset['LoanAmount'].fillna(dataset['LoanAmount'].median(), inplace=True)\ndataset['Loan_Amount_Term'].fillna(dataset['Loan_Amount_Term'].median(), inplace=True)\ndataset['Credit_History'].fillna(dataset['Credit_History'].mode()[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(dataset['Gender'].unique()))\nprint(len(dataset['Married'].unique()))\nprint(len(dataset['Dependents'].unique()))\nprint(len(dataset['Self_Employed'].unique()))\nprint(len(dataset['LoanAmount'].unique()))\nprint(len(dataset['Loan_Amount_Term'].unique()))\nprint(len(dataset['Credit_History'].unique()))\nprint(len(dataset['Loan_ID'].unique()))\nprint(len(dataset['Education'].unique()))\nprint(len(dataset['ApplicantIncome'].unique()))\nprint(len(dataset['CoapplicantIncome'].unique()))\nprint(len(dataset['Property_Area'].unique()))\nprint(len(dataset['source'].unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Spliting the train and test set again after replacing all missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Divide into test and train:\ntrain = dataset.loc[dataset['source']==\"train\"]\ntest = dataset.loc[dataset['source']==\"test\"]\n#Drop unnecessary columns:\ntest.drop(['source'],axis=1,inplace=True)\ntrain.drop(['source'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 2: Data Visualization\n\n\n<b> Visualizing Loan_Status </b>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Loan Status Bar Plot')\nplt.xlabel('Loan Status Y - Yes or N- No')\nplt.ylabel('Loan Status Count')\n\ntrain['Loan_Status'].value_counts().plot.bar(color=['green', 'red'],edgecolor='blue')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> Study of categorical features like Gender, Married, Self_Employed and Credit_History </b>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.subplot(2,2,1)\ntrain['Gender'].value_counts(normalize=True).plot.bar(title='Gender')\nplt.subplot(2,2,2)\ntrain['Married'].value_counts(normalize=True).plot.bar(title='Married')\nplt.subplot(2,2,3)\ntrain['Self_Employed'].value_counts(normalize=True).plot.bar(title='Self Employed')\nplt.subplot(2,2,4)\ntrain['Credit_History'].value_counts(normalize=True).plot.bar(title='Credit History')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> Categorical Independent Variable vs Target Variable </b>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,4,figsize = (15,15))\nGender = pd.crosstab(train['Gender'],train['Loan_Status'])\nGender.div(Gender.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, ax=ax[0,0])\n\nMarried = pd.crosstab(train['Married'],train['Loan_Status'])\nMarried.div(Married.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True, ax=ax[0,1])\n\nDependents = pd.crosstab(train['Dependents'],train['Loan_Status'])\nDependents.div(Dependents.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True, ax=ax[0,2])\n\nEducation = pd.crosstab(train['Education'],train['Loan_Status'])\nEducation.div(Education.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True,ax=ax[0,3])\n\nSelf_Employed = pd.crosstab(train['Self_Employed'],train['Loan_Status'])\nSelf_Employed.div(Self_Employed.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True, ax=ax[1,0])\n\nCredit_History = pd.crosstab(train['Credit_History'],train['Loan_Status'])\nCredit_History.div(Credit_History.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True, ax=ax[1,1])\n\nProperty_Area = pd.crosstab(train['Property_Area'],train['Loan_Status'])\nProperty_Area.div(Property_Area.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True,ax=ax[1,2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STEP 3 : Converting the categorical data into numerical data appropriately\n<b> scikit-learn only accepts numerical variables. Hence, we need to convert all categorical variables into numeric types.\n\n\nI am not using LabelEncoder() because this method proved to give very less Accuracy when compared to get_dummies() method</b>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#cols=['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education','Self_Employed','Property_Area']\n#for label in cols:\n#    dataset[label]=LabelEncoder().fit_transform(dataset[label])\n#dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train.drop([\"Loan_Status\",'Loan_ID'],axis=1)\ny=train[\"Loan_Status\"]\n\nX = pd.get_dummies(X,drop_first=True)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train/Test Split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 4: Fitting the dataset to various models\n# 1) Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"logistic_Regression = LogisticRegression(max_iter=1000,random_state=0)\nlogistic_Regression.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = logistic_Regression.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log = accuracy_score(y_pred,y_test)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2) KNN","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=200)\nknn.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_knn = knn.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"KNN = accuracy_score(pred_knn,y_test)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(pred_knn,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(pred_knn,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error=[]\nfor i in range(1,50):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(x_train,y_train)\n    pred1=knn.predict(x_test)\n    error.append(np.mean(pred1!=y_test))\nprint(error)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.plot(range(1,50),error,color='blue',linestyle='dashed',marker = 'o',markerfacecolor='red',markersize=10)\nplt.title('Error rate vs K value')\nplt.xlabel('k')\nplt.ylabel('error rate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3) Naive-Bayes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gnb=GaussianNB()\ngnb.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_gnb = gnb.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GNB = accuracy_score(pred_gnb,y_test)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(pred_gnb,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(pred_gnb,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4) SVM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC()\nsvc.fit(x_train,y_train)\npred_svc = svc.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SVC = accuracy_score(pred_svc,y_test)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(pred_svc,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(pred_svc,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5) Decision Tree - Entropy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree_en = DecisionTreeClassifier(criterion='entropy',splitter='random',max_leaf_nodes=5,min_samples_leaf=10,max_depth=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = dtree_en.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_dt = clf.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DTREE = accuracy_score(pred_dt,y_test)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm=confusion_matrix(y_test,pred_dt)\nprint(cm)\nprint(classification_report(y_test,pred_dt))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6) Decision Tree - Gini","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree = DecisionTreeClassifier(criterion='gini',splitter='random',max_leaf_nodes=5,min_samples_leaf=10,max_depth=5)\ndtree.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_g = dtree.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DTREE_G = accuracy_score(y_test,pred_g)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm=confusion_matrix(y_test,pred_g)\nprint(cm)\nprint(classification_report(y_test,pred_g))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7) Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(criterion='entropy',n_estimators=400)\nrfc.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_rf= rfc.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFC = accuracy_score(y_test,pred_rf)*100\nRFC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(pred_rf,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(pred_rf,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8) AdaBoost (Entropy-Decision Tree)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = DecisionTreeClassifier(criterion='entropy',max_depth=1,random_state=0)\nadaboost = AdaBoostClassifier(n_estimators=80, base_estimator=model,random_state=0)\nadaboost.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = adaboost.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ada = accuracy_score(y_test,pred)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9) AdaBoost (Gini-Decision Tree)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_g = DecisionTreeClassifier(criterion='gini',max_depth=1,random_state=0)\nadaboost1 = AdaBoostClassifier(n_estimators=90, base_estimator=model_g,random_state=0)\nadaboost1.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_gini = adaboost.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = accuracy_score(y_test,pred_gini)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 10) XGBoost ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb =  XGBClassifier(learning_rate =0.000001,n_estimators=1000,max_depth=5,min_child_weight=1,subsample=0.8,colsample_bytree=0.8,nthread=4,scale_pos_weight=1,seed=27)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.fit(x_train, y_train)\npredxg = xgb.predict(x_test)\nxg = accuracy_score(y_test,predxg)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"1)  Logistic Regression    :\",log)\nprint(\"2)  AdaBoost - Entropy     :\",ada)\nprint(\"3)  AdaBoost - Gini        :\",g)\nprint(\"4)  XGBoost                :\",xg)\nprint(\"5)  Decision Tree - Entropy:\",DTREE)\nprint(\"6)  Decision Tree - Gini   :\",DTREE_G)\nprint(\"7)  Random Forest          :\",RFC)\nprint(\"8)  Naive-Bayes            :\",GNB)\nprint(\"9)  KNN                    :\",KNN)\nprint(\"10) SVC                    :\",SVC)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 5: Deciding Best Fit Model\n\n<b> \n    \n    1)  Logistic Regression    : 83.78 %\n    \n    2)  XGBoost                : 82.70 %\n    \n    3)  Decision Tree - Entropy: 82.70 %\n    \n    4)  Decision Tree - Gini   : 82.70 %\n    \n    5)  Naive-Bayes            : 82.16 %\n    \n    6)  AdaBoost - Entropy     : 81.62 %\n    \n    7)  AdaBoost - Gini        : 81.62 %\n    \n    8)  Random Forest          : 78.37 %\n    \n    9)  KNN                    : 72.43 %\n    \n    10) SVC                    : 72.43 % \n    \nThe best fit model for the given dataset is: <b>LOGISTIC REGRESSION</b>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# STEP 6: Predicting the values of Loan_Status for the data given in    test_lAUu6dG.csv","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Applying the Logistic Regression Model to the test dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Xt = test.drop([\"Loan_Status\",\"Loan_ID\"],axis=1)\nXt = pd.get_dummies(Xt,drop_first=True)\n\nXt.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = logistic_Regression.predict(Xt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[\"Loan_Status\"] = test_pred","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = test[[\"Loan_ID\",\"Loan_Status\"]].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('testLR.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}