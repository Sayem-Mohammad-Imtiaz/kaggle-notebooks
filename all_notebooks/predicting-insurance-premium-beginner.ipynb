{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nfrom scipy.stats import norm,skew\nfrom matplotlib.pyplot import figure\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/insurance-premium-prediction/insurance.csv')\ndf.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"There is no null items inside of the data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['expenses'].describe()\nsns.distplot(df['expenses']);\n\n#plot Skewness and Kurtosis\nprint(\"Skewness: %f\" % df['expenses'].skew())\nprint(\"Kurtosis: %f\" % df['expenses'].kurt())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From what we can see, the target feature is postively skewed. to better predict we can actually perform a box-cox transformation"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig =plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.distplot(df['expenses'], fit=norm);\n(mu,sigma)= norm.fit(df['expenses'])\nprint('\\n mu= {:.2f}\\n'.format(mu,sigma))\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=${:.2f})'.format(mu,sigma)],loc='best')\nplt.ylabel('Frequency')\nplt.title('Distribution of Charges')\nplt.subplot(1,2,2)\nres=stats.probplot(df['expenses'],plot=plt)\nplt.suptitle('Before Transformation')\n\ndf.expenses=np.log1p(df.expenses)\ny=df.expenses.values\ny_orig=df.expenses\n\nfig=plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.distplot(df['expenses'], fit=norm);\n(mu,sigma)=norm.fit(df['expenses'])\nprint(' \\n mu={:.2f} and sigma = {:.2f}\\n'.format(mu,sigma))\nplt.legend(['Normal dist. ($\\mu=${:.2f} and $\\sigma=$ {:.2f})'.format(mu,sigma)], loc='best')\nplt.title('Distribution of expenses')\nplt.subplot(1,2,2)\nres=stats.probplot(df['expenses'], plot=plt)\nplt.suptitle('After Transformation')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"it looks better for our prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a dictionary to map the features\nbin_dict = {'yes' :1, 'no': 0}\nbin_dict_2={'female':1, 'male':0}\n#map the category values in our dict\ndf['smoker']= df['smoker'].map(bin_dict)\ndf['sex']=df['sex'].map(bin_dict_2)\n#check if it has been converted\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_dict = {'southwest':1,'southeast':2, 'northwest':3, 'northeast':4}\n#map the category values in our dict\n\ndf['region']=df['region'].map(cat_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"check for duplicate entries and remove them"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature analysis "},{"metadata":{},"cell_type":"markdown","source":"We will try to understand our database and its correlation towards each other and the target features"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.age.plot(kind=\"hist\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.smoker.plot(kind=\"hist\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.children.plot(kind=\"hist\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,8))\ng = sns.countplot(x=\"age\",data=df)\ng.set_title(\"different age groups\", fontsize=20)\ng.set_xlabel(\"age\", fontsize=15)\ng.set_ylabel(\"count\", fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.region.plot(kind=\"hist\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"conclusion: the location is evenly spread out.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# finding correlation\ndf.corr()\ncorrMatrix = df.corr()\nsns.heatmap(corrMatrix,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is clear that smokers have a higher correlation to charges than those who arent"},{"metadata":{"trusted":true},"cell_type":"code","source":"vars = df.columns\n# vars = numerical_features\nfigures_per_time = 4\ncount = 0 \ny = df['expenses']\nfor var in vars:\n    x = df[var]\n    # print(y.shape,x.shape)\n    plt.figure(count//figures_per_time,figsize=(25,5))\n    plt.subplot(1,figures_per_time,np.mod(count,4)+1)\n    plt.scatter(x, y);\n    plt.title('f model: T= {}'.format(var))\n    count+=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see that both age and BMI are indeed correlated however for BMI it seems that there is no correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=df['bmi'], y=df['expenses'], hue=df['smoker'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lmplot(x=\"bmi\", y=\"expenses\", hue=\"smoker\", data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df=['sex', 'region', 'smoker']\nnum_df=['age','bmi','children', 'expenses']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dum_sex = pd.get_dummies(df.sex)\ndum_sex.columns = ['female', 'male']\ndum_region = pd.get_dummies(df.region)\ndum_region.columns = ['southwest','southeast','northwest','northeast']\ndum_smoker = pd.get_dummies(df.smoker)\ndum_smoker.columns = ['smokeryes','smokerno']\ndummies = pd.concat([df, dum_sex,dum_region,dum_smoker],axis='columns')\ndf = dummies.drop(['sex','smoker','region'],axis='columns')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=df.drop(columns='expenses')\ny=df[['expenses']]\nx_train, x_test, y_train, y_test =train_test_split(x,y,test_size=0.30,random_state=17)\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error , make_scorer, mean_squared_error, r2_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom mlxtend.regressor import StackingCVRegressor\nfrom sklearn.linear_model import LinearRegression\n\nfrom xgboost.sklearn import XGBRegressor\nfrom lightgbm import LGBMRegressor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"k_folds = KFold(n_splits =18, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"lightgbm = LGBMRegressor(objective='regression',num_leaves=4,learning_rate=0.01, n_extimators=9000,max_bin=200,bagging_fraction=0.75,bagging_seed=7,feature_fraction=0.2,feature_fraction_seed=7,verbose=-1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ridge Lasso elasticnet "},{"metadata":{"trusted":true},"cell_type":"code","source":"e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\ne_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\nalphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\nalphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n\nridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt,cv=k_folds))\nlasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7,alphas=alphas2, random_state=42, cv=k_folds))\nelasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, \n                                                        alphas=e_alphas, cv=k_folds,l1_ratio=e_l1ratio))\nstack_gen = StackingCVRegressor(regressors=(ridge,lasso,elasticnet,lightgbm), meta_regressor=elasticnet,use_features_in_secondary=True)\n\nsvr= make_pipeline(RobustScaler(), SVR(C=20, epsilon=0.008, gamma=0.0003))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Elasticnet')\nelastic_model = elasticnet.fit(x_train, y_train)\nprint('Lasso')\nlasso_model = lasso.fit(x_train, y_train)\nprint('Ridge')\nridge_model = ridge.fit(x_train, y_train)\nprint('lightgbm')\nlgb_model_full_data = lightgbm.fit(x_train, y_train)\nprint('Svr')\nsvr_model_full_data = svr.fit(x_train, y_train)\nprint('Stack_gen_model')\nstack_gen_model=stack_gen.fit(np.array(x_train), np.array(y_train))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def blend_models_predict(X):\n    return ((0.167 * elastic_model.predict(X)) + \\\n            (0.167 * lasso_model.predict(X)) + \\\n            (0.167 * ridge_model.predict(X)) + \\\n            (0.1 * lgb_model_full_data.predict(X)) + \\\n            (0.1 * svr_model_full_data.predict(X)) + \\\n            (0.30 * stack_gen_model.predict(np.array(X))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Linear Regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LinearRegression()\nmodel.fit(x_train,y_train)\ntrain_predict=model.predict(x_train)\ntest_predict=model.predict(x_test)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"blend_train=blend_models_predict(x_train)\nblend_train=np.expm1(blend_train.mean(axis=0))\nblend_test=blend_models_predict(x_test)\nblend_test=np.expm1(blend_test.mean(axis=0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Validating model"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Predicting the train data\")\nprint(\"Predicting the test data\")\nprint(\"MAE\")\nprint(\"Train : \",mean_absolute_error(np.expm1(y_train),blend_train))\nprint(\"Test  : \",mean_absolute_error(np.expm1(y_test),blend_test))\nprint(\"Train_LR : \",mean_absolute_error(np.expm1(y_train),np.expm1(train_predict)))\nprint(\"Test_LR  : \",mean_absolute_error(np.expm1(y_test),np.expm1(test_predict)))\nprint(\"====================================\")\nprint(\"MSE\")\nprint(\"Train : \",mean_squared_error(np.expm1(y_train),blend_train))\nprint(\"Test  : \",mean_squared_error(np.expm1(y_test),blend_test))\nprint(\"Train_LR : \",mean_squared_error(np.expm1(y_train),np.expm1(train_predict)))\nprint(\"Test_LR  : \",mean_squared_error(np.expm1(y_test),np.expm1(test_predict)))\nprint(\"====================================\")\nprint(\"RMSE\")\nprint(\"Train : \",np.sqrt(mean_squared_error(np.expm1(y_train),blend_train)))\nprint(\"Test  : \",np.sqrt(mean_squared_error(np.expm1(y_test),blend_test)))\nprint(\"Train_LR : \",np.sqrt(mean_squared_error(np.expm1(y_train),np.expm1(train_predict))))\nprint(\"Test_LR  : \",np.sqrt(mean_squared_error(np.expm1(y_test),np.expm1(test_predict))))\nprint(\"====================================\")\nprint(\"R^2\")\nprint(\"Train : \",r2_score(np.expm1(y_train),blend_train))\nprint(\"Test  : \",r2_score(np.expm1(y_test),blend_test))\nprint(\"Train_LR : \",r2_score(y_train,train_predict))\nprint(\"Test_LR  : \",r2_score(y_test,test_predict))\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nplt.title(\"Actual vs. predicted expenses\",fontsize=25)\nplt.xlabel(\"Actual expenses\",fontsize=18)\nplt.ylabel(\"Predicted expenses\", fontsize=18)\nplt.scatter(x=np.expm1(y_test),y=blend_test, c='b', label='Blended')\nplt.scatter(x=np.expm1(y_test),y=np.expm1(test_predict), c='r', label='LinReg')\nplt.plot([0,80000], [0,80000], '-g', label='perfect')\nplt.legend(loc='upper left')\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will try to compare against Logistic regression in time to come. Thank you for reading my kernel. please let me know how i can improve. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}