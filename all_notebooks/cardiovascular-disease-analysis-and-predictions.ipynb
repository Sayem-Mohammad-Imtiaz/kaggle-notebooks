{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Cardiovascular Disease Project Introduction"},{"metadata":{},"cell_type":"markdown","source":"**This is one of my first data science projects. <br>\n<br>\nIn this notebook, I take a look at a dataset containing 70,000 entries of patients' medical information such as height, weight, age, blood pressure, glucose levels, and cholesterol levels. <br>\n<br>\nThe goal of this project is to use these features in order to make predictions if a patient has cardiovascular disease. <br>\nSeveral classification models will be investigated in this project. <br>\n<br>\nAny constructive feedback is welcomed and upvotes would be greately appreciated!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/cardiovascular-disease-dataset/cardio_train.csv', sep=';')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Check for missing values\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df['cardio'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Convert age from days to years\ndf['age'] =  df['age'] / 365","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Rename columns to make features more clearly understood\ndf.rename(columns={'ap_hi': 'systolic', 'ap_lo': 'diastolic', 'gluc': 'glucose', 'alco': 'alcohol', 'cardio': 'cardiovascular disease'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"sns.lmplot(x='weight', y='height', hue='gender', data=df, fit_reg=False, height=6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"sns.countplot(x='gender', data=df, hue='cardiovascular disease')\nplt.show()\n\n# Not much of a difference between females (1) and males (2) and the chance of getting cardiovascular disease.","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note:** Very strange observations in the height and weight. Minimum and maximum values do not look realistic."},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train = df.drop('id', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# 24 Duplicated entries\ndf_train.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df_train[df_train.duplicated()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train.drop_duplicates(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df_train.count()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"sns.countplot(x='gender', hue='cardiovascular disease', data=df_train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"sns.countplot(x='cholesterol', hue='cardiovascular disease', data=df_train)\nplt.show()\n# There appears to be a correlation between higher cholesterol levels and cardiovascular disease\n# chloesterol levels: 1 = normal, 2 = above normal, 3 = well above normal","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(x='glucose', hue='cardiovascular disease', data=df_train)\nplt.show()\n# There appears to be another correlation between higher glucose levels and cardiovascular disease\n# glucose levels: 1 = normal, 2 = above normal, 3 = well above normal","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(x='active', hue='cardiovascular disease', data=df_train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"sns.countplot(x='smoke', hue='cardiovascular disease', data=df_train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"sns.countplot(x='alcohol', hue='cardiovascular disease', data=df_train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"sns.distplot(df_train['weight'], kde=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df_train['weight'].sort_values().head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"sns.distplot(df_train['height'], kde=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df_train['height'].max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This maximum height of 250 cm/8.2 ft seems unlikely "},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df_train['height'].sort_values().head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The minimum height of 55 cm/1.8 ft also seems unlikely and unrealistic. <br>\nThis dataset may not be legitimate; however, we will continue on with the data analysis and model selection."},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"**Body Mass Index (BMI)** is a common metric used for medical evaluation and heart health <br>\nBMI can be calculated by the following: BMI = weight(kg) / height (cm) / height (cm) x 10,000 <br>\n<br>\n**Pulse Pressure** is another indicator of heart health <br>\nPulse Pressure can be calculated by the following: Pulse Pressure = systolic - diastolic <br>\nTypically, a pulse pressure greater than 60 can be a useful predictor of heart attacks or other cardiovascular diseases"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train['BMI'] = df_train['weight'] / df_train['height'] / df_train['height'] * 10000\ndf_train['pulse pressure'] = df_train['systolic'] - df_train['diastolic']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"df_train.head()\n# Quick look at the dataframe to make sure these new features have been added","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(8,4))\nsns.distplot(df_train['BMI'], bins=50, kde=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"df_train[df_train['BMI'] > 100].head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Quick observation to see if extremely high BMI values correlate to cardiovascular disease"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"df_train[(df_train['pulse pressure'] >= 60 ) & (df_train['cholesterol'] == 3)].head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cursory glance at individuals who have both high pulse pressure (>=60) *and* well above normal cholesterol levels (3). <br>\nUpon inspection of the first several entries, having both high pulse pressure and well above normal cholesterol levels correlate to a higher likelihood of having cardiovascular disease."},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(8,4))\nsns.distplot(df_train['height'], kde=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Splitting data into training and testing datasets\nX = df_train.drop(['weight', 'height', 'cardiovascular disease'], axis=1)\ny = df_train['cardiovascular disease']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=17)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"len(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"len(y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Selection"},{"metadata":{},"cell_type":"markdown","source":"We will investigate different classification models and evaluate each to select the best performer.\nThe models that will be evaluted are the following:\n- Random Forest\n- SVM\n- KNN\n- Naive Bayes\n- XGBoost"},{"metadata":{},"cell_type":"markdown","source":"**Random Forest Model Investigation**"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators=100)\nrfc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_rfc = rfc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Random Forest Model Evaluation\nfrom sklearn.metrics import confusion_matrix, classification_report\nprint(confusion_matrix(y_test, y_pred_rfc))\nprint(classification_report(y_test, y_pred_rfc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rfc.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**K-Fold cross-valuidation of Random Forest Model**"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Applying k-Fold Cross Validation\nfrom sklearn.model_selection import cross_val_score\naccuracies_rfc = cross_val_score(estimator=rfc, X=X_train, y=y_train, cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"accuracies_rfc","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"accuracies_rfc.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"accuracies_rfc.std()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SVM Model Investigation**"},{"metadata":{"trusted":false},"cell_type":"code","source":"# SVM\nfrom sklearn.svm import SVC\nsvc = SVC(gamma='auto')\nsvc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_svc = svc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# SVM Model Evaluation\nprint(confusion_matrix(y_test, y_pred_svc))\nprint(classification_report(y_test, y_pred_svc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"svc.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**K-Fold cross-valuidation of SVM model**"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Applying k-Fold Cross Validation\naccuracies_svc = cross_val_score(estimator=svc, X=X_train, y=y_train, cv=10, n_jobs=4)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"accuracies_svc","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"accuracies_svc.mean()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"accuracies_svc.std()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**K-Nearest Neighbor Model Investigation**"},{"metadata":{"trusted":false},"cell_type":"code","source":"# KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=100)\nknn.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_knn = knn.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# KNN Model Evaluation\nprint(confusion_matrix(y_test, y_pred_knn))\nprint(classification_report(y_test, y_pred_knn))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"knn.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**K-Fold cross-valuidation of KNN model**"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Applying k-Fold Cross Validation\naccuracies_knn = cross_val_score(estimator=knn, X=X_train, y=y_train, cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"accuracies_knn","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"accuracies_knn.mean()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"accuracies_knn.std()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Naive Bayes Model Investigation**"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nnbc = GaussianNB()\nnbc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_nbc = nbc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Naive Bayes Model Evaluation\nprint(confusion_matrix(y_test, y_pred_nbc))\nprint(classification_report(y_test, y_pred_nbc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"nbc.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**K-Fold cross-valuidation of Naive Bayes model**"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Applying k-Fold Cross Validation\naccuracies_nbc = cross_val_score(estimator=nbc, X=X_train, y=y_train, cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"accuracies_nbc","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"accuracies_nbc.mean()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"accuracies_nbc.std()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**XGBoost Model Investigation**"},{"metadata":{"trusted":false},"cell_type":"code","source":"# XGBoost Model\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier(learning_rate=0.02, n_estimators=600)\nxgb.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_xgb = xgb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# XGBoost Model Evaluation\nprint(confusion_matrix(y_test, y_pred_xgb))\nprint(classification_report(y_test, y_pred_xgb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"xgb.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**K-Fold cross-valuidation of XGBoost model**"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Applying k-Fold Cross Validation\naccuracies_xgb = cross_val_score(estimator=xgb, X=X_train, y=y_train, cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"accuracies_xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"accuracies_xgb.mean()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"accuracies_xgb.std()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Grid Search for the top two models** <br>\nBased on this investigation so far, the two best performers are the *XGBoost* and *SVM* models with mean accuracy scores of *73.7%* and *72.7%*, respectively. <br>\n**Note:** Grid search has been commented out due to length of processing time."},{"metadata":{"trusted":false},"cell_type":"code","source":"#Applying Grid Search to find the best model and best parameters (XGBoost)\n#from sklearn.model_selection import GridSearchCV\n\n#define set of parameters that will be investigated by Grid Search\n#parameters = {\n#            'learning_rate': [0.01, 0.02, 0.05, 0.1],\n#            'n_estimators': [100, 200, 300, 500],\n#            'min_child_weight': [1, 5, 10],\n#            'gamma': [0.5, 1, 1.5, 2, 5],\n#            'subsample': [0.6, 0.8, 1.0],\n#            'colsample_bytree': [0.6, 0.8, 1.0],\n#            'max_depth': [3, 4, 5]\n#            }","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#grid_search = GridSearchCV(estimator=xgb,\n#                          param_grid = parameters,\n#                          scoring = 'accuracy',\n#                          cv = 10,\n#                          n_jobs = -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#grid_search = grid_search.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Applying Grid Search to find the best model and best parameters (SVM)\n#from sklearn.model_selection import GridSearchCV\n\n#define set of parameters that will be investigated by Grid Search\n#parameters = {'C': [1, 10, 100, 1000], 'kernel': ['rbf']}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#grid_search = GridSearchCV(estimator=svc,\n#                          param_grid = parameters,\n#                          scoring = 'accuracy',\n#                          cv = 10,\n#                          n_jobs = -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#grid_search = grid_search.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion"},{"metadata":{},"cell_type":"markdown","source":"- The XGBoost model was the best performer out of the five models giving us a mean accuracy score of 73.7%. <br>\n- K-Fold cross validation was used to ensure no overfitting was done. <br>\n- Grid search can be further performed on the best model candidates; however, this step can be time intensive, potentially demanding a great deal of CPU usage."},{"metadata":{"trusted":false},"cell_type":"code","source":"model = ['Random Forest', 'SVM', 'KNN', 'Naive Bayes', 'XGBoost']\nscores = [accuracies_rfc.mean(),accuracies_svc.mean(),accuracies_knn.mean(),accuracies_nbc.mean(),accuracies_xgb.mean()]\n\nsummary = pd.DataFrame(data=scores, index=model, columns=['Mean Accuracy'])\nsummary.sort_values(by='Mean Accuracy', ascending=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}