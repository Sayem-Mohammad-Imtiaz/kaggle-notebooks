{"cells":[{"metadata":{"_uuid":"eb3613387e5e11168d01e496fe9b196525b07607"},"cell_type":"markdown","source":"Assignment 6 - Team Members\n1. Prajwal Kiran Kumar - 01FB16ECS260\n2. Rahul Shivaprasad - 01FB16ECS291\n3. Rasya Ramesh - 01FB16ECS299"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b35243d101b828b6c196dc433f1c6c6241b0e140"},"cell_type":"markdown","source":"**Method 1 : Decision Tree**\n\nWe have used the decision tree approach to classify the data. The accuracy provided by this algorithm was consistently higher than those of other classification algorithms. The advantage of this approach would be that we don't need to worry about how many clusters need to be chosen. The disadvantage is that it has the tendency to overfit. Solution to overcome this issue would be to use Random Forest Classification."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\n\ndataset = pd.read_csv('../input/Absenteeism_at_work.csv')\nX = dataset.iloc[:,1:-1]\ny = dataset.iloc[:,-1]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\nprint('accuracy =' ,accuracy_score(y_test, y_pred))\nfrom sklearn.metrics import confusion_matrix,classification_report\ncm = confusion_matrix(y_test, y_pred)\nprint('Confusion Matrix: \\n',cm)\nprint('\\nClassifiction Report : \\n')\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8dd8b78e17c899467f8114a05cd1cf16e8b944d6"},"cell_type":"markdown","source":"**Method 2: K-Nearest Neighbours**\nWe have used KNN method approach to classify the data. Our approach was to try out a few values for k and pick out the value that gives the best accuracy. We found that the k for max accuracy for our dataset was 5."},{"metadata":{"trusted":true,"_uuid":"815cb97b2327133f2fe41540d2a0a374cc386994"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfor k in range(1, 11):\n    classifier = KNeighborsClassifier(n_neighbors = k, metric = 'minkowski', p = 2)\n    classifier.fit(X_train, y_train)\n\n    # Predicting the Test set results\n    y_pred = classifier.predict(X_test)\n\n    # Making the Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)\n    print('for k = ',k,', accuracy = ',accuracy_score(y_test, y_pred))\n\nprint('\\nNoting highest accuracy for k = 5, we fit the classifier and predict.')\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint('for k = ',5,', accuracy = ',accuracy_score(y_test, y_pred))\nprint('\\nConfusion Matrix: \\n',cm)\n\nprint('\\nClassifiction Report : \\n')\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}