{"cells":[{"metadata":{"_cell_guid":"af6fd7d5-043e-43ab-acf6-bb438b779417","_uuid":"06440c19546700dd01d9d649ddc735e03206553c"},"cell_type":"markdown","source":"# Word Embeddings\nWhen applying one-hot encoding to the words in the tweets, we end up with sparse vectors of high dimensionality (here the number of words). On larger data sets this could cause performance issues. Additionally, one-hot encoding does not take into account the semantics of the words. For instance, *plane* and *aircraft* are different words but have a similar meaning. \n\nWord embeddings reduce these two issues. Word embeddings are dense vectors with a much lower dimensionality. Secondly, the semantic relationships between words are reflected in the distance and direction of the vectors.  "},{"metadata":{"_cell_guid":"2afb7748-1536-41f7-a2ad-3dfbdee61263","_uuid":"655d234070fef5815ed4d9618f4e430508b8809d"},"cell_type":"markdown","source":"# Set-up of the project"},{"metadata":{"_cell_guid":"21cee267-f257-4ba3-88e1-d22e2fc57c7e","_uuid":"2fec7805d8d0e999fc405d136beff46ac331b963","trusted":true},"cell_type":"code","source":"# Basic packages\nimport pandas as pd \nimport numpy as np\nimport re\nimport collections\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\n# Packages for data preparation\nfrom sklearn.model_selection import train_test_split\nfrom nltk.corpus import stopwords\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\n\n# Packages for modeling\nfrom keras import models\nfrom keras import layers\nfrom keras import regularizers","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1eeb591e-330a-4177-be9a-466b388cc2a1","_uuid":"6f2221dcf02f8bb28bf295ed95f6cf41c715dab4","trusted":true},"cell_type":"code","source":"NB_WORDS = 10000  # Parameter indicating the number of words we'll put in the dictionary\nVAL_SIZE = 1000  # Size of the validation set\nNB_START_EPOCHS = 20  # Number of epochs we usually start to train with\nBATCH_SIZE = 512  # Size of the batches used in the mini-batch gradient descent\nMAX_LEN = 35  # Maximum number of words in a sequence","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3b631288-d13d-4b59-a7b2-478a1db1622d","_uuid":"d7c067163d94f765212d7979bb657bdac67846aa"},"cell_type":"markdown","source":"# Some helper functions"},{"metadata":{"_cell_guid":"e81467bb-4fc4-42eb-bf2d-733f28ebbfe2","_uuid":"65806a53f6e279fd16c12b986c2fe9d9158de57b","trusted":true},"cell_type":"code","source":"def deep_model(model, X_train, y_train, X_valid, y_valid):\n    '''\n    Function to train a multi-class model. The number of epochs and \n    batch_size are set by the constants at the top of the\n    notebook. \n    \n    Parameters:\n        model : model with the chosen architecture\n        X_train : training features\n        y_train : training target\n        X_valid : validation features\n        Y_valid : validation target\n    Output:\n        model training history\n    '''\n    model.compile(optimizer='rmsprop'\n                  , loss='categorical_crossentropy'\n                  , metrics=['accuracy'])\n    \n    history = model.fit(X_train\n                       , y_train\n                       , epochs=NB_START_EPOCHS\n                       , batch_size=BATCH_SIZE\n                       , validation_data=(X_valid, y_valid)\n                       , verbose=1)\n    return history\n\n\ndef eval_metric(history, metric_name):\n    '''\n    Function to evaluate a trained model on a chosen metric. \n    Training and validation metric are plotted in a\n    line chart for each epoch.\n    \n    Parameters:\n        history : model training history\n        metric_name : loss or accuracy\n    Output:\n        line chart with epochs of x-axis and metric on\n        y-axis\n    '''\n    metric = history.history[metric_name]\n    val_metric = history.history['val_' + metric_name]\n\n    e = range(1, NB_START_EPOCHS + 1)\n\n    plt.plot(e, metric, 'bo', label='Train ' + metric_name)\n    plt.plot(e, val_metric, 'b', label='Validation ' + metric_name)\n    plt.legend()\n    plt.show()\n\ndef test_model(model, X_train, y_train, X_test, y_test, epoch_stop):\n    '''\n    Function to test the model on new data after training it\n    on the full training data with the optimal number of epochs.\n    \n    Parameters:\n        model : trained model\n        X_train : training features\n        y_train : training target\n        X_test : test features\n        y_test : test target\n        epochs : optimal number of epochs\n    Output:\n        test accuracy and test loss\n    '''\n    model.fit(X_train\n              , y_train\n              , epochs=epoch_stop\n              , batch_size=BATCH_SIZE\n              , verbose=0)\n    results = model.evaluate(X_test, y_test)\n    \n    return results\n\ndef remove_stopwords(input_text):\n    '''\n    Function to remove English stopwords from a Pandas Series.\n    \n    Parameters:\n        input_text : text to clean\n    Output:\n        cleaned Pandas Series \n    '''\n    stopwords_list = stopwords.words('english')\n    # Some words which might indicate a certain sentiment are kept via a whitelist\n    whitelist = [\"n't\", \"not\", \"no\"]\n    words = input_text.split() \n    clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n    return \" \".join(clean_words) \n    \ndef remove_mentions(input_text):\n    '''\n    Function to remove mentions, preceded by @, in a Pandas Series\n    \n    Parameters:\n        input_text : text to clean\n    Output:\n        cleaned Pandas Series \n    '''\n    return re.sub(r'@\\w+', '', input_text)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"30b2a5cd-6e5c-4850-9fc3-acbaa34d8640","_uuid":"f6eff68f92d117c2556e403bc97c7800521ce4eb"},"cell_type":"markdown","source":"# Data Preparation\n### Reading and cleaning data"},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_data = pd.read_csv('/kaggle/input/emotions-dataset-for-nlp/train.txt', sep=\";\", \n                  names=[\"sentence\", \"sentiment\"])\nv_data = pd.read_csv('/kaggle/input/emotions-dataset-for-nlp/val.txt', sep=\";\", \n                  names=[\"sentence\", \"sentiment\"])\nt_data = pd.read_csv('/kaggle/input/emotions-dataset-for-nlp/test.txt', sep=\";\", \n                  names=[\"sentence\", \"sentiment\"])\n\ndf = pd.concat([tr_data, v_data,t_data])\ndf.sentence = df.sentence.apply(remove_stopwords).apply(remove_mentions)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"62132bff-f75d-4d9e-b4d5-d9c1ced79e3f","_uuid":"fa8df3743c04dfda0ec297245bc102d9b3227b03"},"cell_type":"markdown","source":"### Train-Test split"},{"metadata":{"_cell_guid":"df742ade-52d3-4b47-80b0-1f7cc26545eb","_uuid":"6ab9296159749e4525244fae6d6f4e6a37121c93","trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df.sentence, df.sentiment, test_size=0.1, random_state=37)\nprint('# Train data samples:', X_train.shape[0])\nprint('# Test data samples:', X_test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b76321cb-6b78-49e5-9f81-72b9ce0c0fff","_uuid":"083757435330306da9b9fa9aae610ba76e20471e"},"cell_type":"markdown","source":"### Converting words to numbers"},{"metadata":{"_cell_guid":"77a831f6-0261-478e-94ec-72734e0373e4","_uuid":"b7dd99fd85fab14bf865f7d984766911f048cdeb","trusted":true},"cell_type":"code","source":"tk = Tokenizer(num_words=NB_WORDS,\n               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n               lower=True,\n               split=\" \")\ntk.fit_on_texts(X_train)\n\nX_train_seq = tk.texts_to_sequences(X_train)\nX_test_seq = tk.texts_to_sequences(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"53358459-0564-4f74-a8d3-53fbb9070260","_uuid":"554f40d8dd9f7f37147731b97d5581da6ad7112d"},"cell_type":"markdown","source":"### Creating word sequences of equal length\nBefore we can compute the word embeddings, we need to make sure the sequences are of equal length. In the example below, we truncate sequences to length MAX_LEN, or pad them with zeroes to achieve this. First, we'll have a look at the length of the (cleaned) tweets."},{"metadata":{"_cell_guid":"1c65a612-b310-4e94-bb90-e98a5543bc1b","_uuid":"ec28cfcc5c7d88d2ac2da645ebd331c4f983d3d6","trusted":true},"cell_type":"code","source":"seq_lengths = X_train.apply(lambda x: len(x.split(' ')))\nseq_lengths.describe()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7fbdae06-3e2d-4e58-beec-b526c4ceb49d","_uuid":"0801bf3d7e2adcc13d07855f052578038d24ba34"},"cell_type":"markdown","source":"Based on the figures above we will set MAX_LEN to 35. So this means we will not be truncating any words, only pad with zeros. This is to avoid to lose information as the tweets are rather short."},{"metadata":{"_cell_guid":"4caee2ba-a258-4908-b58c-c6280a35e436","_uuid":"dde2572f8b73b2ba795e4a5a9a6333b06924990d","trusted":true},"cell_type":"code","source":"X_train_seq_trunc = pad_sequences(X_train_seq, maxlen=MAX_LEN)\nX_test_seq_trunc = pad_sequences(X_test_seq, maxlen=MAX_LEN)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3d2bf008-932b-4b44-bea4-52626876d419","_uuid":"363f55f2218dc983ea5f7aeb605321becbfeb300","trusted":true},"cell_type":"code","source":"X_train_seq_trunc[10]  # Example of padded sequence","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b0188904-9adc-4b01-823b-24a6281b4dc9","_uuid":"afa786f39cdc5a09bb40ffb4a65ea02ff917575c"},"cell_type":"markdown","source":"### Converting the target classes to numbers"},{"metadata":{"_cell_guid":"e8cde24c-641b-474f-a569-fa1a778dec6c","_uuid":"6b2b84b137f44315eade504c8d4675a50bf78bc6","trusted":true},"cell_type":"code","source":"le = LabelEncoder()\ny_train_le = le.fit_transform(y_train)\ny_test_le = le.transform(y_test)\ny_train_oh = to_categorical(y_train_le)\ny_test_oh = to_categorical(y_test_le)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"33c4e935-4d09-45d0-a0db-8e79e24aee09","_uuid":"59cd92aa3bc7417176ce2d8dc1a1907823cb1d83"},"cell_type":"markdown","source":"### Splitting off validation data"},{"metadata":{"_cell_guid":"1ff1d8d2-2d98-4449-9298-e2594bed577d","_uuid":"4cf52b83651a836882276c58b3c5000ba430b443","trusted":true},"cell_type":"code","source":"X_train_emb, X_valid_emb, y_train_emb, y_valid_emb = train_test_split(X_train_seq_trunc, y_train_oh, test_size=0.1, random_state=37)\n\nprint('Shape of validation set:',X_valid_emb.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8101462d-eba1-4fae-9e77-a2a1166aa2c3","_uuid":"c6f2dcdeebbef27add78e0eb54ac76ce19052d96"},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"_cell_guid":"706bdf6e-7248-48e5-9740-3bd16b3d8dfc","_uuid":"0f9fe95cca79087a8cc87396cc62420fe4e41043"},"cell_type":"markdown","source":"### Training word embeddings\nKeras provides an **Embedding layer** which helps us to train specific word embeddings based on our training data. It will convert the words in our vocabulary to multi-dimensional vectors. "},{"metadata":{"_cell_guid":"be7731ff-5fd4-4006-93ab-7935608870a8","_uuid":"9b0f7a95f5ce87f2f63dac719eb47cced4ed5d4b","trusted":true},"cell_type":"code","source":"emb_model = models.Sequential()\nemb_model.add(layers.Embedding(NB_WORDS, 8, input_length=MAX_LEN))\nemb_model.add(layers.Flatten())\nemb_model.add(layers.Dense(6, activation='softmax'))\nemb_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"97113b34-2ee1-4edf-a411-5cfd6c2033e0","_uuid":"1227cf605366f4be25b74dcba1a29389d11ab680","trusted":true},"cell_type":"code","source":"emb_history = deep_model(emb_model, X_train_emb, y_train_emb, X_valid_emb, y_valid_emb)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bfe2670e-9d2e-49f1-a260-45c201e17a92","_uuid":"976697d3ff94e68ccbcef79011598b519230e22c"},"cell_type":"markdown","source":"We have a validation accuracy of about 77%. The number of words in the tweets is rather low, so this result is rather good. \n\nBy comparing the training and validation accuracy and loss, we see that the model starts overfitting from epoch 6.."},{"metadata":{"_cell_guid":"97389a42-d903-4ade-bf58-8a0feb6d84fa","_uuid":"f34fd856c0b4b19c9630e372bcb739ee4c24c2c1","trusted":true},"cell_type":"code","source":"eval_metric(emb_history, 'acc')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"24dc6adb-7368-44c4-836b-5f7a88b89c9c","_uuid":"825b7a981d45c79419f9768d5b30b3a4483380e3","trusted":true},"cell_type":"code","source":"eval_metric(emb_history, 'loss')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b2ee9d54-d504-4cba-9738-fa8acb2af538","_uuid":"41d0e88fa1528fd93253b4a1bdeb3be3b3ba504d","trusted":true},"cell_type":"code","source":"emb_results = test_model(emb_model, X_train_seq_trunc, y_train_oh, X_test_seq_trunc, y_test_oh, 6)\nprint('/n')\nprint('Test accuracy of word embeddings model: {0:.2f}%'.format(emb_results[1]*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"pre-trained word-embeddings"},{"metadata":{"trusted":true},"cell_type":"code","source":"GLOVE_DIM = 50  # Number of dimensions of the GloVe word embeddings\n\nglove_file = 'glove.twitter.27B.' + str(GLOVE_DIM) + 'd.txt'\nglove_dir = '/kaggle/input/glove-global-vectors-for-word-representation/'\nemb_dict = {}\nglove = open(glove_dir+glove_file)\nfor line in glove:\n    values = line.split()\n    word = values[0]\n    vector = np.asarray(values[1:], dtype='float32')\n    emb_dict[word] = vector\nglove.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emb_matrix = np.zeros((NB_WORDS, GLOVE_DIM))\n\nfor w, i in tk.word_index.items():\n    # The word_index contains a token for all words of the training data so we need to limit that\n    if i < NB_WORDS:\n        vect = emb_dict.get(w)\n        # Check if the word from the training data occurs in the GloVe word embeddings\n        # Otherwise the vector is kept with only zeros\n        if vect is not None:\n            emb_matrix[i] = vect\n    else:\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glove_model = models.Sequential()\nglove_model.add(layers.Embedding(NB_WORDS, GLOVE_DIM, input_length=MAX_LEN))\nglove_model.add(layers.Flatten())\nglove_model.add(layers.Dense(6, activation='softmax'))\nglove_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glove_model.layers[0].set_weights([emb_matrix])\nglove_model.layers[0].trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glove_history = deep_model(glove_model, X_train_emb, y_train_emb, X_valid_emb, y_valid_emb)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glove_results = test_model(glove_model, X_train_seq_trunc, y_train_oh, X_test_seq_trunc, y_test_oh, 3)\nprint('/n')\nprint('Test accuracy of word glove model: {0:.2f}%'.format(glove_results[1]*100))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}