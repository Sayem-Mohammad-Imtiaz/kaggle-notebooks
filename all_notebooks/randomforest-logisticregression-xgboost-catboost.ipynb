{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Automobile customer segmentation classification\n### Context\nAn automobile company has plans to enter new markets with their existing products (P1, P2, P3, P4, and P5). After intensive market research, theyâ€™ve deduced that the behavior of the new market is similar to their existing market.\n\nIn their existing market, the sales team has classified all customers into 4 segments (A, B, C, D). Then, they performed segmented outreach and communication for a different segment of customers. This strategy has work e exceptionally well for them. They plan to use the same strategy for the new markets and have identified 2627 new potential customers.\n\nYou are required to help the manager to predict the right group of the new customers.","metadata":{}},{"cell_type":"markdown","source":"### import data library","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### data exploration","metadata":{}},{"cell_type":"code","source":"data_location = r'/kaggle/input/customer-segmentation/'\ndf_raw = pd.read_csv(f'{data_location}/Train.csv')\ntest_raw = pd.read_csv(f'{data_location}/Test.csv')\ndf_raw.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_raw.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create functions for data exploration\ndef plot_numeric(df, col):\n    fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n    sns.histplot(data=df, x=col, ax=ax[0]).set_title(col+'_hist')\n    sns.kdeplot(data=df, x=col, ax=ax[1]).set_title(col+'_kde')\n    sns.boxplot(data=df, y=col, ax=ax[2]).set_title(col+'_box')\n    plt.show()\n    \ndef plot_category(df, col):\n    fig, ax = plt.subplots(figsize=(18,12))\n    sns.countplot(data=df, x=col, ax=ax, order=df[col].value_counts().index).set_title(col+'_count')\n    plt.show()\n    \ndef plot_corr(df):\n    fig, ax = plt.subplots(figsize=(18,12))\n    num_col = df.select_dtypes(include='number').columns.values\n    sns.heatmap(df[num_col].corr(), vmin=-1, vmax=1,\n                annot=True, square=True, ax=ax)\n    plt.title('Correlation Matrix')\n    plt.show()\n\ndef get_corr_list(df):\n    num_col = df.select_dtypes(include='number').columns.values\n    df_corr = df[num_col].corr().unstack().sort_values(ascending=False)\\\n            .drop_duplicates()\n    print(df_corr)\n\ndef get_null(df):\n    print(df.isna().sum())\n\ndef get_describe(df):\n    print(df.describe(include='all'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Training dataset')\nget_null(df_raw)\nprint('Testing dataset')\nget_null(test_raw)\nprint('-'*100, end='\\n\\n')\n\nprint('Training dataset')\nget_describe(df_raw)\nprint('Testing dataset')\nget_describe(test_raw)\n\nprint('-'*100, end='\\n\\n')\nfor col in df_raw.select_dtypes(include='number'):\n    print(col)\n    print('Training dataset')\n    plot_numeric(df_raw, col)\n    print('Testing dataset')\n    plot_numeric(test_raw, col)\n\nprint('-'*100, end='\\n\\n')\nfor col in df_raw.select_dtypes(include='object'):\n    print(col)\n    print('Training dataset')\n    plot_category(df_raw, col)\n    print('Testing dataset')\n    plot_category(test_raw, col)\n    \nprint('-'*100, end='\\n\\n')\nprint('Training dataset')\nplot_corr(df_raw)\nprint('Testing dataset')\nplot_corr(test_raw)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Summary of data exploration\nAfter the above data exploration, I see a big difference between the sample behavior. It is believed that the sampling is not properly done. Hence, I believe the training set cannot represent the population behavior. \n1. Gender: Male is 10%~20% more than female in the training set while 10% female is more than male in the testing set\n2. Ever_Married: Similar to Gender, married status takes over 60% of the population in training set while single dominate the testing set\n3. Graduated: Similar to Gender and Ever_Married situation. Graduated occupied the training dataset and Non-graduate occupied the testing dataset\n\n#### Points to take note for data cleansing\n1. ID should be dropped as it is meaningless\n2. Outlier on Age, Work_Experience and Family_Size\n3. Data Cleansing on Gender, Ever_Married and Graduate should be careful. \n\n#### Points to take note for data modeling\n1. Gender, Ever_married and Graduated could/might be dropped if the validation accuracy is higher but not the testing accuracy.\n2. Age could use bin (Further checking is required)","metadata":{}},{"cell_type":"markdown","source":"### data cleansing\n1. fill empty Ever_Married with No\n2. fill empty Graduated with No\n3. fill empty Profession with Artist (The most common one)\n4. fill empty Var_1 with Cat_6 (The most common one)\n5. fill empty Work_Experience with median then remove outliers by interquantile\n6. fill empty Family_Size with median then remove outliers by interquantile\n7. Drop ID\n8. Map segment into numeric","metadata":{}},{"cell_type":"code","source":"def data_transform(df):\n    # function is created for easy handle for both training and testing dataset\n    def remove_outlier(df, col):\n        lowq, highq = df[col].quantile(.25), df[col].quantile(.75)\n        interq = 1.5 * (highq - lowq)\n        lowq -= interq\n        highq += interq\n        return df[col].apply(lambda x: lowq if x < lowq else highq if x > highq else x)\n    \n    df['Ever_Married'] = df['Ever_Married'].fillna('No')\n    df['Graduated'] = df['Graduated'].fillna('No')\n    for col in ['Profession', 'Var_1']:\n        df[col] = df[col].fillna(df[col].mode().values[0])\n    for col in ['Work_Experience', 'Family_Size']:\n        df[col] = df[col].fillna(df[col].median())\n        df[col] = remove_outlier(df, col)\n    df.drop(columns=['ID'], inplace=True)\n    segment_map = {'A':1, 'B':2, 'C':3, 'D':4}\n    df['Segmentation'] = df['Segmentation'].map(segment_map)\n    for col in df.select_dtypes(exclude='number'):\n        df[col] = df[col].apply(lambda x: str(x).strip())\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleanset = data_transform(df_raw.copy())\ncleanset.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_cleanset = data_transform(test_raw.copy())\ntest_cleanset.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#After I clear it up, I am going to do a data exploration again to review the distribution.\nget_null(cleanset)\nprint('-'*100, end='\\n\\n')\n\nget_describe(cleanset)\n\nprint('-'*100, end='\\n\\n')\nfor col in cleanset.select_dtypes(include='number'):\n    print(col)\n    plot_numeric(cleanset, col)\n\nprint('-'*100, end='\\n\\n')\nfor col in cleanset.select_dtypes(include='object'):\n    print(col)\n    plot_category(cleanset, col)\n    \nprint('-'*100, end='\\n\\n')\nplot_corr(cleanset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### data modeling","metadata":{}},{"cell_type":"code","source":"# RandomForest, Logistic Regression, XGBoost, CatBoost will be validated to figure out the best algorithm for this part.\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score\nfrom sklearn.metrics import classification_report, plot_confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_model_cleansing(df):\n    y = df['Segmentation']\n    df.drop(columns=['Segmentation'], inplace=True)\n    #Seperate checking have completed and find out the creation of Age bin will lose model accuracy. \n    #df['Age'] = pd.cut(df['Age'], bins=[0, 20, 30, 40, 50, 60, 70, 90], \n    #                   labels=['Group_' + str(i) for i in range(20, 81, 10)])\n    for col in df.select_dtypes(exclude='number').columns.values:\n        df = pd.concat([pd.get_dummies(df[col], prefix=col), df], axis=1)\n        df.drop(columns=col, inplace=True)\n    return df, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainset, y = data_model_cleansing(cleanset.copy())\ntrainset.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test, y_test = data_model_cleansing(test_cleanset.copy())\nX_test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tree = RandomForestClassifier(random_state=0)\nlogit = LogisticRegression(random_state=0)\nxgb = XGBClassifier()\ncat = CatBoostClassifier(random_state=0, verbose=0)\n\nalgos = [tree, logit, xgb, cat]\n\ndef ML(algo, x, y, res_dict = dict()):\n    X_train, X_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=0, stratify=y)\n    print(f'Training set size: {X_train.shape}, Validation set size: {X_valid.shape}')\n    \n    model = algo.fit(X_train, y_train)\n    y_pred = model.predict(X_valid)\n    train_acc = model.score(X_train, y_train)\n    valid_acc = model.score(X_valid, y_valid)\n    valid_prec = precision_score(y_true=y_valid, y_pred=y_pred, average='micro')\n    valid_rec = recall_score(y_true=y_valid, y_pred=y_pred, average='micro')\n    cross_val = cross_val_score(model, X_valid, y_valid, cv=3).mean()\n    \n    print(f'Algorithm name: {model.__class__.__name__}')\n    print('-'*100)\n    print(f'Training accuracy: {train_acc:.4f}, Validation accuracy: {valid_acc:.4f}')\n    print(f'Validation precision score: {valid_prec:.4f}, Validation recall score: {valid_rec:.4f}')\n    print(f'Cross validation score: {cross_val:.4f}')\n    print('-'*100)\n    print(classification_report(y_true=y_valid, y_pred=y_pred))\n    print('-'*100)\n    \n    #plot confusion matrix and report\n    plot_confusion_matrix(model, X_valid, y_valid, display_labels=model.classes_,\n                         normalize='true', cmap=plt.cm.Blues, )\n    plt.title('Normalized Confusion Matrix')\n    plt.show()\n    print('-'*100)\n    res_dict[model.__class__.__name__+'_train_acc'] = train_acc\n    res_dict[model.__class__.__name__+'_valid_acc'] = valid_acc\n    res_dict[model.__class__.__name__+'_valid_prec'] = valid_prec\n    res_dict[model.__class__.__name__+'_valid_rec'] = valid_rec\n    res_dict[model.__class__.__name__+'_cross_val'] = cross_val\n    return model, res_dict\n\ndef test_ML(model, X_test, y_test, res_dict):\n    y_pred = model.predict(X_test)\n    test_acc = model.score(X_test, y_test)\n    test_prec = precision_score(y_true=y_test, y_pred=y_pred, average='micro')\n    test_rec = recall_score(y_true=y_test, y_pred=y_pred, average='micro')\n    cross_val = cross_val_score(model, X_test, y_test, cv=3).mean()\n    \n    print(f'Testing Algorithm name: {model.__class__.__name__}')\n    print('-'*100)\n    print(f'Testing accuracy: {test_acc:.4f}, Testing precision: {test_prec:.4f}, Testing recall: {test_rec:.4f}')\n    print(f'Cross validation score: {cross_val:.4f}')\n    print('-'*100)\n    print(classification_report(y_true=y_test, y_pred=y_pred))\n    print('-'*100)\n    #plot confusion matrix and report\n    plot_confusion_matrix(model, X_test, y_test, display_labels=model.classes_,\n                         normalize='true', cmap=plt.cm.Blues, )\n    plt.title('Normalized Confusion Matrix')\n    plt.show()\n    print('-'*100)\n    res_dict[model.__class__.__name__+'_test_acc'] = test_acc\n    res_dict[model.__class__.__name__+'_test_prec'] = test_prec\n    res_dict[model.__class__.__name__+'_test_rec'] = test_rec\n    res_dict[model.__class__.__name__+'_test_cross_val'] = cross_val\n    return res_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = dict()\nfor algo in algos:\n    model, res = ML(algo, trainset, y)\n    res = test_ML(model, X_test, y_test, res)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#show the top 10 important features on the catboost model. \nfeature_list = pd.Series(model.feature_importances_, index=trainset.columns.values).sort_values(ascending=False).nlargest(10)\nfeature_list.sort_values().plot(kind='barh')\nplt.title('Feature list')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[(key, value) for key, value in res.items() if key.startswith(\"Cat\")]\n#res","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Summary of data modeling\nIt can be found that all the performance are generally bad. By listing out the feature importance on catboost (or any other), we can see (1) Working_Experience (2) Profession (3) Graduated and (4) Ever_Married have contributed a significant part of the model. However, we do have a large proportion of data is filled by ourselves. \nRefer to the accuracy list above, CatBoost seems to be the best approach. However, would suggest to have a better sampling again for better data modeling.","metadata":{}},{"cell_type":"markdown","source":"### (Extra) Quick step by using pipeline","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OrdinalEncoder, LabelEncoder, MinMaxScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainset = df_raw.copy()\nx_col = trainset.columns.values.tolist()\nx_col.remove('Segmentation')\nle = LabelEncoder()\ntrainset['Segmentation'] = le.fit_transform(trainset['Segmentation'])\nX_train, X_test, y_train, y_test = train_test_split(trainset[x_col],\n                                                   trainset['Segmentation'],\n                                                   test_size=.2,\n                                                   random_state=0)\nprint(f'Train size: {X_train.shape}, Test size: {X_test.shape}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataframeFunctionTransformer():\n    def __init__(self, func):\n        self.func = func\n        \n    def transform(self, input_df, **transform_params):\n        return self.func(input_df)\n    \n    def fit(self, X, y=None, **fit_params):\n        return self\n\ndef remove_id(input_df):\n    if 'ID' in input_df.columns.values:\n        input_df.drop(columns='ID', inplace=True)\n        return input_df\n    else:\n        return input_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create pipeline\nno_pipeline = Pipeline([\n    ('fillno', SimpleImputer(strategy='constant', fill_value='No')),\n    ('encode', OrdinalEncoder()),\n])\n\ncommon_pipeline = Pipeline([\n    ('fillcommon', SimpleImputer(strategy='most_frequent')),\n    ('encode', OrdinalEncoder()),\n])\n\nnum_pipeline = Pipeline([\n    ('encode', SimpleImputer(strategy='median')),\n    ('minmax', MinMaxScaler()),\n])\n\nrmid_pipeline = Pipeline([\n    ('remove_id', DataframeFunctionTransformer(remove_id)),\n])\n\npreprocessing_pipeline = ColumnTransformer([\n    ('step1,2', no_pipeline, ['Ever_Married', 'Graduated']),\n    ('step3,4', common_pipeline, ['Profession', 'Var_1']),\n    ('step5,6', num_pipeline, ['Work_Experience', 'Family_Size']),\n    #Since Age has no empty rows, only minmax encoder works\n    ('extra1', num_pipeline, ['Age']),\n    # Since gender and spending score has no empty rows, only ordinal encoder works\n    ('extra2', common_pipeline, ['Gender', 'Spending_Score']),\n])\n\ncat_pipeline = Pipeline([\n    ('remove_id', rmid_pipeline),\n    ('preprocessing', preprocessing_pipeline),\n    ('catboost', CatBoostClassifier(random_state=0, verbose=0))\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_pipeline.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_pipeline.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testset = test_raw.copy()\nle = LabelEncoder()\ntestset['Segmentation'] = le.fit_transform(testset['Segmentation'])\nX_test0, y_test0 = testset[x_col], testset['Segmentation']\ncat_pipeline.score(X_test0, y_test0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}