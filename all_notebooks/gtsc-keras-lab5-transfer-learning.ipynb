{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, Conv2DTranspose, ZeroPadding2D, Cropping2D\nfrom tensorflow.keras.models import Model\nfrom shutil import copyfile, rmtree\nfrom timeit import default_timer as timer","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Вспомогательная функция для доступа к файлам относительно корня директория с данными.\nINPUT_ROOT = \"../input/gtsrb-german-traffic-sign\"\ndef from_input(path):\n    return os.path.join(INPUT_ROOT, path)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"# Загружаем таблицу с данными о данных.\ntrain_info = pd.read_csv(from_input(\"Train.csv\"))\ntrain_info.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Посмотрим как выглядят наши данные.\ntrain_info.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# сколько примеров в каждом из классов\ntrain_info.groupby('ClassId')['ClassId'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_info =  pd.read_csv(from_input(\"Test.csv\"))\ntest_info.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_info.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# сколько примеров в каждом из классов\ntest_info.groupby('ClassId')['ClassId'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n# Показываем изображения в сетке 6х8.\nnrows = 8\nncols = 6\n\npic_offset = 0 # Чтобы итерировать по изображениям каждый раз когда запустим код ниже.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def show_images(offset):\n    fig = plt.gcf()\n    fig.set_size_inches(ncols*3, nrows*3)\n\n    for i in range(43):\n        # subplot индексы начинаются с 1\n        sp = plt.subplot(nrows, ncols, i + 1)\n        sp.axis('Off')\n        subdir = os.path.join(from_input('train'), str(i))\n        files = os.listdir(subdir)\n        img_path = os.path.join(subdir, files[offset % len(files)])\n        img = mpimg.imread(img_path)\n        #print(img.shape)\n        plt.imshow(img)\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"show_images(pic_offset)\npic_offset += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Загрузка и подготовка данных:"},{"metadata":{"trusted":false},"cell_type":"code","source":"TARGET_SIZE = (40, 40) # изображения будут изменены до этого размера\nFLATTEN_SIZE = TARGET_SIZE[0] * TARGET_SIZE[1] * 3\nBATCH_SIZE=300","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"paths = train_info['Path'].values\ny_train = train_info['ClassId'].values\n\nindices = np.arange(y_train.shape[0])\nrandgen = random.Random(62)\nrandgen.shuffle(indices)\n\npaths = paths[indices]\ny_train = y_train[indices]\ny_train = to_categorical(y_train, 43)\n\ntrain_data=[]\n\nfor i, f in enumerate(paths):\n    print('\\rLoading data {0:.1f}%...'.format((i / len(paths)) * 100), end = '\\r')\n    image = load_img(os.path.join(from_input('train'), f.replace('Train/', '')), target_size=TARGET_SIZE)\n    train_data.append(img_to_array(image))\n\nprint('Data loaded.              ')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train = tf.keras.applications.vgg16.preprocess_input(np.array(train_data))\ntrain_data = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n\ntrain_generator = train_datagen.flow(X_train,\n                                    y_train,\n                                    batch_size=BATCH_SIZE,\n                                    shuffle=True,\n                                    seed=17)\n\ntrain_aug_datagen = ImageDataGenerator(rescale=1.0/255.0,\n                                       rotation_range = 18,\n                                       width_shift_range = 0.18,\n                                       height_shift_range = 0.18,\n                                       shear_range = 0.18,\n                                       zoom_range = 0.18,\n                                       horizontal_flip = False)\n\ntrain_aug_generator = train_datagen.flow(X_train,\n                                    y_train,\n                                    batch_size=BATCH_SIZE,\n                                    shuffle=True,\n                                    seed=17)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"paths = test_info['Path'].values\ny_test = test_info['ClassId'].values\ny_test = to_categorical(y_test, 43)\n\ntest_data=[]\n\nfor i, f in enumerate(paths):\n    print('\\rLoading data {0:.1f}%...'.format((i / len(paths)) * 100), end = '\\r')\n    image = load_img(os.path.join(from_input('test'), f.replace('Test/', '')), target_size=TARGET_SIZE)\n    test_data.append(img_to_array(image))\n\nprint('Data loaded.              ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_test = tf.keras.applications.vgg16.preprocess_input(np.array(test_data))\ntest_data = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1.0/255.0)\ntest_generator = test_datagen.flow(X_test,\n                                    y_test,\n                                    batch_size=BATCH_SIZE,\n                                    shuffle=False,\n                                    seed=17)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Некоторые вспомогательные функции:"},{"metadata":{"trusted":false},"cell_type":"code","source":"def plot(history, plot_acc = True):\n    %matplotlib inline\n\n    import matplotlib.image  as mpimg\n    import matplotlib.pyplot as plt\n\n    \n    loss=history.history['loss']\n    epochs=range(len(loss))\n    plt.figure()\n    plt.plot(epochs, loss, 'r', \"Training Loss\")\n    plt.xlabel('Epoch')\n    plt.title('Training loss')\n    # validation\n    plt.plot(epochs, history.history['val_loss'], 'b', \"Validation Loss\")\n\n    if plot_acc:\n        acc=history.history['acc']\n        plt.figure()\n        plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n        plt.title('Training accuracy')\n        plt.xlabel('Epoch')\n        plt.plot(epochs, history.history['val_acc'], 'b', \"Validation Accuracy\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def show_layers(model):\n    print('Name\\tOutput shape\\tActivation\\tInitializer')\n    for l in model.layers:\n        print('{0}({1})\\t{2}\\t{3}\\t{4}'\n            .format(l.name,\n              l.__class__.__name__,\n              l.output_shape,\n              l.activation.__name__ if hasattr(l, 'activation') else '<none>',\n              l.kernel_initializer.__class__.__name__ if hasattr(l, 'kernel_initializer') else '<none>'))\n\n\ndef custom_summary(model):\n    model.summary()\n    show_layers(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"VERBOSE=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def train_model(model, optimizer, epochs, train_generator):\n    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n    start_time = timer()\n    history = model.fit_generator(train_generator,\n                        epochs=epochs,\n                        verbose=VERBOSE,\n                        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='acc', min_delta=0.0001, patience=2)],\n                        validation_data=test_generator,\n                        steps_per_epoch= round(X_train.shape[0] / BATCH_SIZE))\n    end_time = timer()\n    \n    print('==============================')\n    print('Optimizer: ', optimizer.__class__.__name__)\n    print('Learning rate: ', optimizer.get_config()['learning_rate'])\n    print('Epochs: ', epochs)\n    print('==============================')\n    print('Trained in {0:.2f} minutes'.format((end_time - start_time) / 60))\n    \n    acc=history.history['acc'][-1]\n    test_acc = model.evaluate_generator(test_generator)[1]\n    \n    print('Results at the end of training: acc={1:.02f}%, test_acc={2:.02f}%'\n          .format(i, acc*100, test_acc*100))\n\n    plot(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def get_classificator_model(base_model, last_output):\n    x = Flatten()(last_output)\n    x = Dropout(0.33)(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.33)(x)\n    x = Dense(128, activation='relu')(x)\n    x = Dense(43, activation='softmax')(x)           \n\n    model = Model(base_model.input, x)\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Запускаем готовую сеть на наших данных."},{"metadata":{},"cell_type":"markdown","source":"**Эксперимент №1**: Реализуем переноса признакового описания."},{"metadata":{"trusted":false},"cell_type":"code","source":"IMG_SHAPE = TARGET_SIZE + (3,)\npretrained_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\n\npretrained_model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В этом эксперименте не хотим тренировать слои уже обученной сети."},{"metadata":{"trusted":false},"cell_type":"code","source":"for layer in pretrained_model.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Не будем использовать последний блок VGG16, так как он наверное слишком приспособлен для задаче на которой тренировался. Начальные слои обычно представляют более общие признаки."},{"metadata":{},"cell_type":"markdown","source":"Тренируем только нашу часть сети. Первую часть VGG16 используем как метод выделения признаков."},{"metadata":{"trusted":false},"cell_type":"code","source":"last_layer = pretrained_model.get_layer('block4_conv3')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\noptimizer=Adam(learning_rate=0.0001)\nepochs=50\ntrain_model(get_classificator_model(pretrained_model, last_output), optimizer, epochs, train_generator)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Получаем сильное переобучение. На тренировочной выборке модель сходится слишком быстро."},{"metadata":{},"cell_type":"markdown","source":"**Эксперимент №2**: Попробуем полностью обучать сеть начиная с уже готовых весов начальных слоёв."},{"metadata":{"trusted":false},"cell_type":"code","source":"pretrained_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\n\nfor layer in pretrained_model.layers:\n    layer.trainable = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"last_layer = pretrained_model.get_layer('block4_conv3')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\noptimizer=Adam(learning_rate=0.00001)\nepochs=50\ntrain_model(get_classificator_model(pretrained_model, last_output), optimizer, epochs, train_generator)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Эксперимент №3**: Попробуем полностью обучать сеть начиная случайной подборки весов всей сети."},{"metadata":{"trusted":false},"cell_type":"code","source":"deep_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights=None)\nfor layer in deep_model.layers:\n    layer.trainable = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"last_layer = deep_model.get_layer('block4_conv3')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\noptimizer=Adam(learning_rate=0.00005)\nepochs=50\ntrain_model(get_classificator_model(deep_model, last_output), optimizer, epochs, train_generator)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Для сравнения, с такими данными запустим самую хорошую модель из педыдущей лабы"},{"metadata":{"trusted":false},"cell_type":"code","source":"optimizer=Adam(learning_rate=0.00001)\nepochs=50\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(256, (7, 7), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, optimizer, epochs, train_generator)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Попробуем ещё улучшить собственную сеть."},{"metadata":{"trusted":false},"cell_type":"code","source":"optimizer=Adam(learning_rate=0.00001)\nepochs=50\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(256, (7, 7), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Dropout(0.33),\n    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Dropout(0.33),\n    tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.33),\n    tf.keras.layers.Dense(1024, activation='tanh'),\n    tf.keras.layers.Dropout(0.33),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, optimizer, epochs, train_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"optimizer=Adam(learning_rate=0.00001)\nepochs=50\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(256, (7, 7), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Dropout(0.33),\n    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Dropout(0.33),\n    tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', input_shape=TARGET_SIZE + (3,)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.33),\n    tf.keras.layers.Dense(1024, activation='tanh'),\n    tf.keras.layers.Dropout(0.33),\n    tf.keras.layers.Dense(43, activation='softmax')\n])\n\ntrain_model(model, optimizer, epochs, train_aug_generator)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}