{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\nFILE_PATH = '../input/heart-disease-uci/heart.csv'\n\ndf = pd.read_csv(FILE_PATH)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns = [\n    'age',\n    'sex',\n    'chest_pain_type',\n    'resting_blood_pressure',\n    'cholesterol',\n    'fasting_blood_sugar',\n    'rest_ecg',\n    'max_heart_rate_achieved',\n    'exercise_induced_angina',\n    'st_depression',\n    'st_slope',\n    'num_major_vessels',\n    'thalassemia',\n    'target'\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sex'][df['sex'] == 0] = 'female'\ndf['sex'][df['sex'] == 1] = 'male'\n\ndf['chest_pain_type'][df['chest_pain_type'] == 0] = 'asymptomatic'\ndf['chest_pain_type'][df['chest_pain_type'] == 1] = 'typical angina'\ndf['chest_pain_type'][df['chest_pain_type'] == 2] = 'atypical angina'\ndf['chest_pain_type'][df['chest_pain_type'] == 3] = 'non-anginal pain'\ndf['chest_pain_type'][df['chest_pain_type'] == 4] = 'asymptomatic'\n\ndf['fasting_blood_sugar'][df['fasting_blood_sugar'] == 0] = 'lower than 120mg/ml'\ndf['fasting_blood_sugar'][df['fasting_blood_sugar'] == 1] = 'greater than 120mg/ml'\n\ndf['rest_ecg'][df['rest_ecg'] == 0] = 'normal'\ndf['rest_ecg'][df['rest_ecg'] == 1] = 'ST-T wave abnormality'\ndf['rest_ecg'][df['rest_ecg'] == 2] = 'left ventricular hypertrophy'\n\ndf['exercise_induced_angina'][df['exercise_induced_angina'] == 0] = 'no'\ndf['exercise_induced_angina'][df['exercise_induced_angina'] == 1] = 'yes'\n\ndf['st_slope'][df['st_slope'] == 1] = 'upsloping'\ndf['st_slope'][df['st_slope'] == 2] = 'flat'\ndf['st_slope'][df['st_slope'] == 3] = 'downsloping'\n\ndf['thalassemia'][df['thalassemia'] == 1] = 'normal'\ndf['thalassemia'][df['thalassemia'] == 2] = 'fixed defect'\ndf['thalassemia'][df['thalassemia'] == 3] = 'reversable defect'\n\ndf.head(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(df.index[df['st_slope']==0], inplace=True)\ndf.drop(df.index[df['thalassemia']==0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = pd.get_dummies(df['sex'], prefix='sex')\nb = pd.get_dummies(df['chest_pain_type'], prefix='chest_pain_type')\nc = pd.get_dummies(df['fasting_blood_sugar'], prefix='fasting_blood_sugar')\nd = pd.get_dummies(df['rest_ecg'], prefix='rest_ecg')\ne = pd.get_dummies(df['exercise_induced_angina'], prefix='exercise_induced_angina')\nf = pd.get_dummies(df['st_slope'], prefix='st_slope')\ng = pd.get_dummies(df['thalassemia'], prefix='thalassemia')\n\nframes = [df, a, b, c, d, e, f, g]\ndf = pd.concat(frames, axis = 1)\ndf = df.drop(columns=[\n    'sex',\n    'chest_pain_type',\n    'fasting_blood_sugar',\n    'rest_ecg',\n    'exercise_induced_angina',\n    'st_slope',\n    'thalassemia'\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nx = df.values\nmin_max_scaler = MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\ndf_scaled = pd.DataFrame(x_scaled, columns=df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('./clean_heart.csv')\ndf_scaled.to_csv('./clean_scaled_heart.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GAN"},{"metadata":{},"cell_type":"markdown","source":"## Dataset Creation"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nx_0 = df_scaled[df_scaled['target']==0].drop(columns='target').values\nx_1 = df_scaled[df_scaled['target']==1].drop(columns='target').values\n\nx_0 = tf.cast(tf.convert_to_tensor(x_0), tf.float32)\nx_1 = tf.cast(tf.convert_to_tensor(x_1), tf.float32)\n\nbatch_size = 32\ndataset_0 = tf.data.Dataset.from_tensor_slices(x_0).shuffle(1000).batch(batch_size)\ndataset_1 = tf.data.Dataset.from_tensor_slices(x_1).shuffle(1000).batch(batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dense\n\ndef build_generator():\n    model = Sequential([\n        Input(shape=16),\n        Dense(16, activation='relu'),\n        Dense(16, activation='relu'),\n        Dense(24, activation='sigmoid'),\n    ])\n    return model\n\n\ndef build_discriminator():\n    model = Sequential([\n        Input(shape=24),\n        Dense(16, activation='relu'),\n        Dense(8, activation='relu'),\n        Dense(1, activation='softmax')\n    ])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_step(real_data, generator, discriminator):\n    random_latent_vectors = tf.random.normal(shape=(batch_size, 16))\n    generated_data = generator(random_latent_vectors)\n    combined_data = tf.concat([generated_data, real_data], axis=0)\n\n    labels = tf.concat(\n        [tf.ones((batch_size, 1)), tf.zeros((real_data.shape[0], 1))], axis=0\n    )\n    labels += 0.05 * tf.random.uniform(labels.shape)\n\n    # Train the discriminator\n    with tf.GradientTape() as tape:\n        predictions = discriminator(combined_data)\n        d_loss = loss_fn(labels, predictions)\n    grads = tape.gradient(d_loss, discriminator.trainable_weights)\n    d_optimizer.apply_gradients(zip(grads, discriminator.trainable_weights))\n\n    random_latent_vectors = tf.random.normal(shape=(batch_size, 16))\n    misleading_labels = tf.zeros((batch_size, 1))\n\n    # Train the generator (note that we should *not* update the weights\n    # of the discriminator)!\n    with tf.GradientTape() as tape:\n        predictions = discriminator(generator(random_latent_vectors))\n        g_loss = loss_fn(misleading_labels, predictions)\n    grads = tape.gradient(g_loss, generator.trainable_weights)\n    g_optimizer.apply_gradients(zip(grads, generator.trainable_weights))\n    return d_loss, g_loss, generated_data\n\ndef train(epochs, dataset, generator, discriminator):\n    for epoch in range(epochs):\n        print(epoch)\n        for step, real_data in enumerate(dataset):\n            d_loss, g_loss, generated_data = train_step(real_data, generator, discriminator)\n            if step % 200 == 0:\n                # Print metrics\n                print(\"discriminator loss at step %d: %.2f\" % (step, d_loss))\n                print(\"adversarial loss at step %d: %.2f\" % (step, g_loss))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create Two Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"generator_0 = build_generator()\ndiscriminator_0 = build_discriminator()\n\ngenerator_1 = build_generator()\ndiscriminator_1 = build_discriminator()\n\nd_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\ng_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n\nloss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 20000\n# train(epochs, dataset_0, generator_0, discriminator_0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 20000\n# train(epochs, dataset_1, generator_1, discriminator_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"synthetic_0 = pd.DataFrame(generator_0(tf.random.normal([20000,16])).numpy(), columns=df.drop(columns='target').columns)\nsynthetic_0.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nlabel_0 = np.zeros((20000,))\nsynthetic_0['target'] = label_0\nsynthetic_0.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"synthetic_1 = pd.DataFrame(generator_1(tf.random.normal([20000,16])).numpy(), columns=df.drop(columns='target').columns)\nsynthetic_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_1 = np.ones((20000,))\nsynthetic_1['target'] = label_1\nsynthetic_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"synthetic_merge = pd.concat([synthetic_0, synthetic_1])\nsynthetic_merge","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# synthetic_merge.to_csv('./synthetic_merge.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction Model"},{"metadata":{},"cell_type":"markdown","source":"## Dataset Creation"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\nsyn_path = '../input/syntheticheartdiseaseuci/synthetic_merge.csv'\ndf_syn = pd.read_csv(syn_path)\ndf_syn.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\nx = df_syn.drop(columns='target').values\ny = df_syn.target.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\n\npca = PCA(n_components=5)\nx = pca.fit_transform(x)\nfor i in range(2):\n  d = x[np.where(y == i)]\n  plt.scatter(d[:,0],d[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nmin_max_scaler = MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\nfor i in range(2):\n  d = x[np.where(y == i)]\n  plt.scatter(d[:,0],d[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.5, random_state=1)\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1)\n\nx_train = tf.cast(tf.convert_to_tensor(x_train), tf.float32)\ny_train = tf.cast(tf.convert_to_tensor(y_train), tf.float32)\nx_val = tf.cast(tf.convert_to_tensor(x_val), tf.float32)\ny_val = tf.cast(tf.convert_to_tensor(y_val), tf.float32)\nx_test = tf.cast(tf.convert_to_tensor(x_test), tf.float32)\ny_test = tf.cast(tf.convert_to_tensor(y_test), tf.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(256)\nval_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).shuffle(10000).batch(256)\ntest_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).shuffle(10000).batch(256)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import Sequential\n\nmodel = Sequential([\n    Input(shape=5),\n    Dense(3, activation='relu'),\n    Dense(1, activation='sigmoid'),\n])\n\noptimizer = tf.keras.optimizers.Adam()\nloss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\ntrain_acc_metric = tf.keras.metrics.BinaryAccuracy()\nval_acc_metric = tf.keras.metrics.BinaryAccuracy()\n\ndef train_step(x, y):\n    with tf.GradientTape() as tape:\n        logits = model(x)\n        loss_val = loss_fn(y, logits)\n    grads = tape.gradient(loss_val, model.trainable_weights)\n    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n    train_acc_metric.update_state(y, logits)\n    return loss_val\n\ndef train(epochs):\n    train_loss_history = []\n    val_loss_history = []\n    train_acc_history = []\n    val_acc_history = []\n    for epoch in range(epochs):\n        for step, (x_train, y_train) in enumerate(train_dataset):\n            train_loss = train_step(x_train, y_train)\n        for step, (x_val, y_val) in enumerate(val_dataset):\n            logits = model(x_val)\n            val_loss = loss_fn(y_val, logits)\n            val_acc_metric.update_state(y_val, logits)\n        print('EPOCH: %d - TRAIN LOSS: %.3f - VAL LOSS: %.3f' % (epoch, train_loss, val_loss))\n        print('EPOCH: %d - TRAIN ACCU: %.3f - VAL ACCU: %.3f' % (epoch, train_acc_metric.result(), val_acc_metric.result()))\n        train_loss_history.append(train_loss)\n        val_loss_history.append(val_loss)\n        train_acc_history.append(train_acc_metric.result())\n        val_acc_history.append(val_acc_metric.result())\n        \n        train_acc_metric.reset_states()\n        val_acc_metric.reset_states()\n    return train_loss_history, val_loss_history, train_acc_history, val_acc_history\n        \ntrain_loss, val_loss, train_acc, val_acc = train(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_acc_metric = tf.keras.metrics.BinaryAccuracy()\n\ndef test():\n    for step, (x_test, y_test) in enumerate(test_dataset):\n        logits = model(x_test)\n        val_loss = loss_fn(y_test, logits)\n        test_acc_metric.update_state(y_test, logits)\n    print('TEST ACCU: %.3f' % (test_acc_metric.result()))\n    test_acc_metric.reset_states()\n\ntest()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_loss)\nplt.plot(val_loss)\nplt.plot(train_acc)\nplt.plot(val_acc)\n\nplt.title('Metrics')\nplt.xlabel('epoch')\nplt.legend(['Train Loss', 'Val Loss', 'Train Accuracy', 'Val Accuracy'])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}