{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://www.pewtrusts.org/-/media/post-launch-images/2018/01/sln_jan23_1/sln_jan23_1_16x9.jpg)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nThe dataset contains Twitter posts (tweets) made during the MeToo movement by various Twitter accounts and some of them as been classifed as non-hateful (0), whilst others are hateful (0). This notebook demonstrates how we can do EDA and make plots with the Plotly libraby.\n\nKey takeaways:\n\n* The data set is imbalanced, as it contains more non-hateful tweets than hateful.\n* Hateful tweets are generally longer than non-hateful tweets (more characters).\n* Hateful tweets tend to get a higher favorite and retweet score than non-hateful tweets.\n\nMore information: <br>\nhttps://medium.com/swlh/forget-matplotlib-you-should-be-using-plotly-ada76b650ff4\n\nMy Naive-Bayes classifer for this data set is here: <br>\nhttps://www.kaggle.com/christianlillelund/find-hate-in-a-pile-of-tweets-naive-bayes\n\nWe start by loading libraries and the data. Loading all tweets (about 700000) causes the kernel here on Kaggle to run out of memory, so instead we load about half the dataset (300000) which will be enough for a demonstration.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport re\nfrom nltk.stem.porter import *\nplt.style.use('seaborn')\nimport plotly.express as px\nfrom plotly import graph_objs as go\nfrom collections import Counter\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\npd.reset_option('^display.', silent=True)\n\n# Load half the data and separate target from predictors\ndf = pd.read_csv('../input/hatred-on-twitter-during-metoo-movement/MeTooHate.csv', nrows=300000, encoding='latin1')\n\n# Drop columns not used for modelling\ncols_to_drop = ['status_id', 'created_at', 'location']\ndf.drop(cols_to_drop, axis=1, inplace=True)\n\n# Convert text to string type\ndf['text'] = df['text'].astype(str)\n\n# Rename category column to be more meaningful\ndf = df.rename(columns={\"category\": \"hateful\"})\n\nprint(\"Total number of samples:\", len(df))\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print a random tweet as a sample\nsample_index = 25\nprint(df.iloc[sample_index])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text preprocessing\n\nNext step is to do some early preprocesing of the tweets to make them easier to work with and reduce overhead. Initial data cleaning requirements that are common for tweets:\n\n* Remove Twitter handles as they give no relevant info.\n* Remove punctuations, numbers and special characters\n* Remove smaller words since they usually don't add value (< 3 characters)\n* Reduce words to their root word (stemming), for example transform \"loves\", \"loving\", \"loveable\" to \"love\".\n\nOnce the initial cleaning is done, we can split every tweet into individual words or tokens which is an essential step in any NLP task.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Helper function to remove unwanted patterns\ndef remove_pattern(input_txt, pattern):\n    r = re.findall(pattern, input_txt)\n    for i in r:\n        input_txt = re.sub(i, '', input_txt)\n    return input_txt\n\n# Remove Twitter handles from the data \ndf['text'] = np.vectorize(remove_pattern)(df['text'], \"@[\\w]*\")\n\n# Remove punctuations, numbers, and special characters\ndf['text'] = df['text'].str.replace(\"[^a-zA-Z#]\", \" \")\n\n# Remove all words below 3 characters\ndf['text'] = df['text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n\n# Tokenize the tweets\ntokenized_tweet = df['text'].apply(lambda x: x.split())\n\n# Stem the tweets\nstemmer = PorterStemmer()\ntokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x])\n\n# Put the processed tweets back in the dataframe\nfor i in range(len(tokenized_tweet)):\n    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\ndf['text'] = tokenized_tweet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data distribution\n\nData distribution shows how many non-hateful/hateful tweets we have got. Notice that is imbalanced here.\nWe use several techniques here to visualize it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df.hateful.value_counts()\n\nfig = px.bar(temp)\nfig.update_layout(\n    title_text='Data distribution for each category',\n    yaxis=dict(\n        title='count'\n    ),\n    xaxis=dict(\n        title='label'\n    )\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df.groupby('hateful').count()['text'].reset_index()\ntemp['label'] = temp['hateful'].apply(lambda x : 'Hateful tweets' if x==1 else 'Non-hateful tweets')\n\nfig = go.Figure(go.Funnelarea(\n    text = temp.label,\n    values = temp.text,\n    title = {\"position\" : \"top center\", \"text\" : \"Funnel Chart for target distribution\"}\n    ))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df.groupby('hateful').count()['text'].reset_index()\nfig = px.pie(temp, values='text', names=['Non-hateful', 'Hateful'],\n             title=\"Pie chart of tweets\")\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Number of words in tweets\n\nThe two histrograms show cleary, that hateful tweets are generally longer than non-hateful tweets.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet_len_non_hateful = df[df['hateful']==0]['text'].str.split().map(lambda x: len(x))\ntweet_len_hateful = df[df['hateful']==1]['text'].str.split().map(lambda x: len(x))\n\nfig = go.Figure()\nfig.add_trace(go.Histogram(x=tweet_len_non_hateful, histfunc='avg', name=\"Non-hateful\", opacity=0.75, histnorm='probability density'))\nfig.add_trace(go.Histogram(x=tweet_len_hateful, histfunc='avg', name=\"Hateful\", opacity=0.75, histnorm='probability density'))\n\nfig.update_layout(\n    title_text='Number of words in tweets', # title of plot\n    xaxis_title_text='Value', # xaxis label\n    yaxis_title_text='Count', # yaxis label\n    bargap=0.2,\n    bargroupgap=0.1,\n    barmode='overlay'\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Popularity of tweets\n\nWe now look at benchmarks to measure popularity of tweets. For example, it shows a clear correlation between favorite count and retweet count and the fact that hateful tweets tend to be more popular then non-hateful tweets on average.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter_matrix(df,\n    dimensions=[\"favorite_count\",\n                \"retweet_count\",\n                \"followers_count\",\n                \"friends_count\",\n                \"statuses_count\"],\n    labels={col:col.replace('_', ' ') for col in df.columns}, # remove underscore\n    color=\"hateful\")\n\nfig.update_layout(\n    title='Scatter matrix of numerical variables',\n    dragmode='select',\n    width=800,\n    height=800,\n    hovermode='closest',\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(df,\n                 x=\"favorite_count\",\n                 y=\"retweet_count\",\n                 color=\"hateful\",\n                 labels={col:col.replace('_', ' ') for col in df.columns},\n                 log_x=True,\n                 log_y=True)\n\nfig.update_layout(\n    title='Favorite count vs retweet count',\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(df,\n                 x=\"favorite_count\",\n                 y=\"followers_count\",\n                 color=\"hateful\",\n                 labels={col:col.replace('_', ' ') for col in df.columns},\n                 log_x=True,\n                 log_y=True)\n\nfig.update_layout(\n    title='Favorite count vs followers count',\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(df,\n                 x=\"favorite_count\",\n                 y=\"statuses_count\",\n                 color=\"hateful\",\n                 labels={col:col.replace('_', ' ') for col in df.columns},\n                 log_x=True,\n                 log_y=True)\n\nfig.update_layout(\n    title='Favorite count vs statuses count',\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Histogram(histfunc=\"count\", y=df['favorite_count'], x=df['hateful'], name=\"count\", histnorm='probability'))\nfig.add_trace(go.Histogram(histfunc=\"sum\", y=df['favorite_count'], x=df['hateful'], name=\"sum\", histnorm='probability'))\nfig.add_trace(go.Histogram(histfunc=\"avg\", y=df['favorite_count'], x=df['hateful'], name=\"avg\", histnorm='probability'))\n\nfig.update_layout(\n    title_text='Count/sum/avg of favorite count', # title of plot\n    xaxis_title_text='Hateful', # xaxis label\n    yaxis_title_text='Count', # yaxis label\n    bargap=0.2,\n    bargroupgap=0.1\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Histogram(histfunc=\"count\", y=df['retweet_count'], x=df['hateful'], name=\"count\", histnorm='probability'))\nfig.add_trace(go.Histogram(histfunc=\"sum\", y=df['retweet_count'], x=df['hateful'], name=\"sum\", histnorm='probability'))\nfig.add_trace(go.Histogram(histfunc=\"avg\", y=df['retweet_count'], x=df['hateful'], name=\"avg\", histnorm='probability'))\n\nfig.update_layout(\n    title_text='Count/sum/avg of retweet count', # title of plot\n    xaxis_title_text='Hateful', # xaxis label\n    yaxis_title_text='Count', # yaxis label\n    bargap=0.2,\n    bargroupgap=0.1\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Histogram(histfunc=\"count\", y=df['followers_count'], x=df['hateful'], name=\"count\", histnorm='probability'))\nfig.add_trace(go.Histogram(histfunc=\"sum\", y=df['followers_count'], x=df['hateful'], name=\"sum\", histnorm='probability'))\nfig.add_trace(go.Histogram(histfunc=\"avg\", y=df['followers_count'], x=df['hateful'], name=\"avg\", histnorm='probability'))\n\nfig.update_layout(\n    title_text='Count/sum/avg of followers count', # title of plot\n    xaxis_title_text='Hateful', # xaxis label\n    yaxis_title_text='Count', # yaxis label\n    bargap=0.2,\n    bargroupgap=0.1\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Histogram(histfunc=\"count\", y=df['friends_count'], x=df['hateful'], name=\"count\", histnorm='probability'))\nfig.add_trace(go.Histogram(histfunc=\"sum\", y=df['friends_count'], x=df['hateful'], name=\"sum\", histnorm='probability'))\nfig.add_trace(go.Histogram(histfunc=\"avg\", y=df['friends_count'], x=df['hateful'], name=\"avg\", histnorm='probability'))\n\nfig.update_layout(\n    title_text='Count/sum/avg of friends count', # title of plot\n    xaxis_title_text='Hateful', # xaxis label\n    yaxis_title_text='Count', # yaxis label\n    bargap=0.2,\n    bargroupgap=0.1\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Histogram(histfunc=\"count\", y=df['statuses_count'], x=df['hateful'], name=\"count\", histnorm='probability'))\nfig.add_trace(go.Histogram(histfunc=\"sum\", y=df['statuses_count'], x=df['hateful'], name=\"sum\", histnorm='probability'))\nfig.add_trace(go.Histogram(histfunc=\"avg\", y=df['statuses_count'], x=df['hateful'], name=\"avg\", histnorm='probability'))\n\nfig.update_layout(\n    title_text='Count/sum/avg of statuses count', # title of plot\n    xaxis_title_text='Hateful', # xaxis label\n    yaxis_title_text='Count', # yaxis label\n    bargap=0.2,\n    bargroupgap=0.1\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Most common words in tweets\n\nPeople use a different set of words when they write in a friendly tone on Twitter, compared to when they are being more mean. The various plots below show the most popular words for the two categories (non-hateful and hateful) and some cool visualisations.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['temp_list'] = df['text'].apply(lambda x:str(x).split())\n\ntop = Counter([item for sublist in df['temp_list'].loc[df['hateful'] == 0] for item in sublist])\ntop_non_hateful = pd.DataFrame(top.most_common(25))\ntop_non_hateful.columns = ['Common_words','count']\n\nfig = px.bar(top_non_hateful, x='count',y='Common_words',title='Common words in non-hateful tweets',orientation='h',width=700,height=700,color='Common_words')\nfig.show()\n\nfig = px.treemap(top_non_hateful, path=['Common_words'], values='count',title='Tree of common words in non-hateful twets')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_non_hateful.columns = ['Common_words','count']\ntop_non_hateful.style.background_gradient(cmap='Purples')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.pie(top_non_hateful,\n             values='count',\n             names='Common_words',\n             title='Word distribution in non-hateful tweets')\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top = Counter([item for sublist in df['temp_list'].loc[df['hateful'] == 1] for item in sublist])\ntop_hateful = pd.DataFrame(top.most_common(25))\ntop_hateful.columns = ['Common_words','count']\nfig = px.bar(top_hateful, x='count',y='Common_words',title='Common words in hateful tweets',orientation='h',width=700,height=700,color='Common_words')\nfig.show()\n\nfig = px.treemap(top_hateful, path=['Common_words'], values='count',title='Tree of common words in hateful twets')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_hateful.columns = ['Common_words','count']\ntop_hateful.style.background_gradient(cmap='Purples')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.pie(top_hateful,\n             values='count',\n             names='Common_words',\n             title='Word distribution in hateful tweets')\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Word cloud of common words\n\nA WordCloud is a cloud filled with lots of words in different sizes, which represent the frequency or the importance of each word. We make two here for the two categories, non-hateful and hateful tweets.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"text = df['text'].loc[df['hateful'] == 0].values\ncloud = WordCloud(stopwords=STOPWORDS,\n                  background_color='white',\n                  max_words=200,\n                  max_font_size=100,\n                  width=400,\n                  height=200,\n                  random_state=0).generate(str(text))\n\nfigure_size=(12,12)\nplt.figure(figsize=figure_size)\nplt.imshow(cloud, interpolation=\"bilinear\");\nplt.title(\"Word cloud of non-hateful tweets\", fontdict={'size': 20, 'color': 'black', \n                           'verticalalignment': 'bottom'})\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = df['text'].loc[df['hateful'] == 1].values\ncloud = WordCloud(stopwords=STOPWORDS,\n                  background_color='white',\n                  max_words=200,\n                  max_font_size=100,\n                  width=400,\n                  height=200,\n                  random_state=0).generate(str(text))\n\nfigure_size=(12,12)\nplt.figure(figsize=figure_size)\nplt.imshow(cloud, interpolation=\"bilinear\");\nplt.title(\"Word cloud of hateful tweets\", fontdict={'size': 20, 'color': 'black', \n                           'verticalalignment': 'bottom'})\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\nHave a look at https://plotly.com/ for more cool plots and graphs for data visualization. Let me know in the comments if you can find of other fun ways to visualize the Twitter data.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}