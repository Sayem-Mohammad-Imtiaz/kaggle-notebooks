{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom sklearn.datasets import load_iris\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt #importing graph plotting functionality\nimport os\nprint(os.listdir(\"../input\"))\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n# Author - Ritvik Khanna \n# Date - 04/05/18 \n# Version - 2.3\n\n# Load dataset\ndf = pd.read_csv(r\"../input/car_evaluation.csv\", names = [\"buying\",\"maint\", \"doors\", \"persons\", \"lug_boot\",\"safety\",\"class\"])\n\n# Any results you write to the current directory are saved as output.","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"26e2d29c6ef4560da43d9cb015edddb48fc174b7"},"cell_type":"markdown","source":"## Preprocessing the data\nHere, the dataset contains of 6 attributes and 1 class column having 4 class values{unacc, acc, good, vgood}. As we are building a neural network we need to provide the neural node values it can read and not bias over a specific value of an attribute. Therefore we convert all the nominal/categorical data into numeric by using pandas.get_dummies function. This function will create additional columns of each values corresponding to each attribute, therefore increasing the number of total columns."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"## get_dummies() implementation\ncategory_col =[\"buying\",\"maint\", \"doors\", \"persons\", \"lug_boot\",\"safety\",\"class\"] \ndf = pd.get_dummies(df, columns=category_col)\n## visualizing processed dataset\nprint(df.shape)\ndf.head(10)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"fcb60c6be599550e7d76ce2be49f2b72b2394381"},"cell_type":"markdown","source":"Dividing the dataset into Attribute and labels, then spliting into train and test using crossvalidation"},{"metadata":{"trusted":true,"_uuid":"1bfd161dbc98b42706f3f995b3d238927a16f608"},"cell_type":"code","source":"X = df.iloc[:, 0:21].values\ny = df.iloc[:, 21:].values\n## Normalizing data - Normalization refers to rescaling real valued numeric attributes into the range 0 and 1.\nX = preprocessing.scale(X)\nfrom sklearn.model_selection import train_test_split\nfeature_train, feature_test, labels_train, labels_test = train_test_split(X, y, random_state = 42)\nprint (\"Train:%d +  Test:%d = Total:%d\"  % (len(feature_train),len(feature_test),len(feature_train)+len(feature_test)))","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"7a1d46656d7e905e99400a33a51dda06ba556e64"},"cell_type":"markdown","source":"## Building the NN classifier using PyTorch"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"d7abac05a75b5d8cd3df62e7480f6228577723a6"},"cell_type":"code","source":"feature_train_v = Variable(torch.FloatTensor(feature_train), requires_grad = False)\nlabels_train_v = Variable(torch.FloatTensor(labels_train), requires_grad = False)\nfeature_test_v = Variable(torch.FloatTensor(feature_test), requires_grad = False)\nlabels_test_v = Variable(torch.FloatTensor(labels_test), requires_grad = False)\n\nclass LinearClassifier(nn.Module):\n    def __init__(self):\n        super(LinearClassifier, self).__init__()\n        self.h_layer = nn.Linear(21, 4) #21 input layers and 4 output layers\n        self.s_layer = nn.Softmax()\n    def forward(self,x):\n        y = self.h_layer(x)\n        p = self.s_layer(y)\n        return p\n#declaring the classifier to an object\nmodel = LinearClassifier()   \n#calculates the loss\nloss_fn = nn.BCELoss()       \noptim = torch.optim.SGD(model.parameters(), lr = 0.01)","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"03a1dec339a977ac52b31c91d7b7121d8d07b50c"},"cell_type":"markdown","source":"Now we fit the raining data into the model, here we do 5000 iterations and collect the loss of each iteration"},{"metadata":{"trusted":true,"_uuid":"eb89f5296182a398f0b75c2932e8fe5ac0a9ffb3"},"cell_type":"code","source":"all_losses = []\nfor num in range(5000): \n    pred = model(feature_train_v) #predict\n    loss = loss_fn(pred, labels_train_v) #calculate loss\n    all_losses.append(loss.data)\n    optim.zero_grad() #zero gradients to not accumulate\n    loss.backward() #update weights based on loss\n    optim.step() #update optimiser for next iteration","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"4335e8265d6499e401d553b6eeeaa0b233735428"},"cell_type":"markdown","source":"## Visualizing the loss per each iteration"},{"metadata":{"trusted":true,"_uuid":"c85ae9dfc2786259cf0f3fc2ba6f31b6017fffb8"},"cell_type":"code","source":"all_losses = np.array(all_losses, dtype = np.float)\nall_losses\nplt.plot(all_losses)\nplt.show()\nprint(pred[3])\nprint(labels_train_v[3])\nprint(all_losses[-1])","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"7329b7e2632ef58afdbebfc2bf7997e02b0b21b2"},"cell_type":"markdown","source":"## Accuracy result from testing data on the model\nNow we fit the test dataset on our model and find the score of each correctly labeled data by the Neural Network model and find the accuracy."},{"metadata":{"trusted":true,"_uuid":"32d7e2fbefb78b40130531ce57a3203f006e250d"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\npredicted_values = []\nfor num in range(len(feature_test_v)):\n    predicted_values.append(model(feature_test_v[num]))\n\n    \nscore = 0\nfor num in range(len(predicted_values)):\n    if np.argmax(labels_test[num]) == np.argmax(predicted_values[num].data.numpy()):\n        score = score + 1\naccuracy = float(score / len(predicted_values)) * 100\nprint ('Testing Accuracy Score is ' + str(accuracy))","execution_count":18,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}