{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-31T10:23:23.411738Z","iopub.execute_input":"2021-05-31T10:23:23.412242Z","iopub.status.idle":"2021-05-31T10:23:23.425824Z","shell.execute_reply.started":"2021-05-31T10:23:23.412133Z","shell.execute_reply":"2021-05-31T10:23:23.424868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Libraries used in this project\n\nimport pandas as pd # Data processing\nimport numpy as np # For linear algebra\n\nimport matplotlib # For data visualisation\nimport seaborn as sns # For data visualisation\n\nimport scipy # For statistical analysis","metadata":{"execution":{"iopub.status.busy":"2021-05-31T10:23:23.428534Z","iopub.execute_input":"2021-05-31T10:23:23.429157Z","iopub.status.idle":"2021-05-31T10:23:23.846533Z","shell.execute_reply.started":"2021-05-31T10:23:23.429111Z","shell.execute_reply":"2021-05-31T10:23:23.845664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display all columns\npd.set_option('display.max_columns', None)\n\nprint(\"Pandas version: \", pd.__version__)\nprint(\"Numpy version: \", np.__version__)\nprint(\"Matplotlib version: \", matplotlib.__version__)\nprint(\"Seaborn version: \", sns.__version__)\nprint(\"Scipy version: \", scipy.__version__)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T10:23:23.847802Z","iopub.execute_input":"2021-05-31T10:23:23.848429Z","iopub.status.idle":"2021-05-31T10:23:23.857454Z","shell.execute_reply.started":"2021-05-31T10:23:23.848387Z","shell.execute_reply":"2021-05-31T10:23:23.856508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the dataframe\nraw_data = pd.read_csv('../input/centrallimittheorem/Clt-data.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T10:23:23.85901Z","iopub.execute_input":"2021-05-31T10:23:23.859293Z","iopub.status.idle":"2021-05-31T10:23:23.888738Z","shell.execute_reply.started":"2021-05-31T10:23:23.859267Z","shell.execute_reply":"2021-05-31T10:23:23.887716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATA INVESTIGATION: Brief Overview\n\"\"\"\nraw_data.head(10)  # In spreadsheet\nraw_data.columns # Column list\nraw_data.info() # Column datatype\n\n\"\"\"\nraw_data.shape # Shape","metadata":{"execution":{"iopub.status.busy":"2021-05-31T10:23:23.892029Z","iopub.execute_input":"2021-05-31T10:23:23.892353Z","iopub.status.idle":"2021-05-31T10:23:23.901129Z","shell.execute_reply.started":"2021-05-31T10:23:23.892321Z","shell.execute_reply":"2021-05-31T10:23:23.899916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From the preliminary data investigation, we understood that the dataset is  a single column numeric dataset consisting of 9000 observations.**","metadata":{}},{"cell_type":"code","source":"# Descriptive statistics : Basic\npd.DataFrame([raw_data.mean(),\n              raw_data.median(), \n              raw_data.std(), \n              raw_data.var()], \n             index=['Mean', 'Median','Std. dev', 'Variance'])","metadata":{"execution":{"iopub.status.busy":"2021-05-31T10:23:23.902754Z","iopub.execute_input":"2021-05-31T10:23:23.903095Z","iopub.status.idle":"2021-05-31T10:23:23.926567Z","shell.execute_reply.started":"2021-05-31T10:23:23.90305Z","shell.execute_reply":"2021-05-31T10:23:23.925392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From the descriptive statistics, the mean and median approximately equal hence there is chance that the dataset seems to follow gaussan distribution.**","metadata":{}},{"cell_type":"code","source":"# More descriptive statistics\nraw_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T10:23:23.927954Z","iopub.execute_input":"2021-05-31T10:23:23.928311Z","iopub.status.idle":"2021-05-31T10:23:23.948008Z","shell.execute_reply.started":"2021-05-31T10:23:23.928281Z","shell.execute_reply":"2021-05-31T10:23:23.947036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From the dataset, we also understood that the dataset ranges from 12.80 to 13.30 with the mean value of 12.80**","metadata":{}},{"cell_type":"code","source":"# Duplicate the data\nduplicate_raw_data = raw_data.copy()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T10:23:23.951628Z","iopub.execute_input":"2021-05-31T10:23:23.95194Z","iopub.status.idle":"2021-05-31T10:23:23.956794Z","shell.execute_reply.started":"2021-05-31T10:23:23.951911Z","shell.execute_reply":"2021-05-31T10:23:23.955415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Now, lets check the overall data distribution of the raw data.\nHere, we visualised via histogram in the subsequent code.**","metadata":{}},{"cell_type":"code","source":"# HISTOGRAM to show the data distribution of the raw dataset\n\nsns.set() # Default seaborn format\nfrom matplotlib import pyplot as plt\nx = duplicate_raw_data['Wall Thickness']\nresult = plt.hist(x, bins=20, color='m', edgecolor='k', alpha=0.9)\nplt.axvline(x.mean(), color='k', linestyle='dashed', linewidth=3)\n\nmin_ylim, max_ylim = plt.ylim()\nplt.ylabel('Frequency OR Count')\nplt.xlabel('Wall Thickness')\nplt.title(\"Histogram of total Population\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T10:23:23.957723Z","iopub.execute_input":"2021-05-31T10:23:23.958011Z","iopub.status.idle":"2021-05-31T10:23:24.290388Z","shell.execute_reply.started":"2021-05-31T10:23:23.957966Z","shell.execute_reply":"2021-05-31T10:23:24.289329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**In test research hypothesis, we work in sample-data. Therefore we created different sample data of different sizes (here i used fractions) and visualised the data distribution of different samples taken from the original input data.**","metadata":{}},{"cell_type":"code","source":"# Create different sample datasets based on RANDOM SAMPLING\n\n# Data with different sample size as fraction\nx_10= duplicate_raw_data['Wall Thickness'].sample(frac=0.1, replace=True, random_state=100)\nx_20= duplicate_raw_data['Wall Thickness'].sample(frac=0.2, replace=True, random_state=1)\nx_30= duplicate_raw_data['Wall Thickness'].sample(frac=0.3, replace=True, random_state=10)\nx_40= duplicate_raw_data['Wall Thickness'].sample(frac=0.4, replace=True, random_state=5)\nx_50= duplicate_raw_data['Wall Thickness'].sample(frac=0.5, replace=True, random_state=42)\nx_60= duplicate_raw_data['Wall Thickness'].sample(frac=0.6, replace=True, random_state=30)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T10:23:24.29175Z","iopub.execute_input":"2021-05-31T10:23:24.292087Z","iopub.status.idle":"2021-05-31T10:23:24.30612Z","shell.execute_reply.started":"2021-05-31T10:23:24.292054Z","shell.execute_reply":"2021-05-31T10:23:24.304861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now, lets visualise the data distribution of different sample-data based on random sampling\n\n# Define figure dimension\n\nplt.figure(figsize=(18,12))\n# get X limits and fix them\nmin_ylim, max_ylim = plt.ylim()\n\n# Fig 1\nplt.subplot(2,3,1) #the figure has 2 row, 3 columns, and this plot is the first plot.\nresult = plt.hist(x_10, bins=20, color='m', edgecolor='k', alpha=0.9)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Frequency/Count')\nplt.xlabel('Wall Thickness')\nplt.title(\"Sample size-10%\")\n\n# Fig 2\nplt.subplot(2,3,2)\nresult = plt.hist(x_20, bins=20, color='m', edgecolor='k', alpha=0.9)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Frequency/Count')\nplt.xlabel('Wall Thickness')\nplt.title(\"Sample size-20%\")\n\n# Fig 3\nplt.subplot(2,3,3)\nresult = plt.hist(x_30, bins=20, color='m', edgecolor='k', alpha=0.9)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Frequency/Count')\nplt.xlabel('Wall Thickness')\nplt.title(\"Sample size-30%\")\n\n# Fig 4\nplt.subplot(2,3,4)\nresult = plt.hist(x_40, bins=20, color='m', edgecolor='k', alpha=0.9)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Frequency/Count')\nplt.xlabel('Wall Thickness')\nplt.title(\"Sample size-40%\")\n\n# Fig 5\nplt.subplot(2,3,5)\nresult = plt.hist(x_50, bins=20, color='m', edgecolor='k', alpha=0.9)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Frequency/Count')\nplt.xlabel('Wall Thickness')\nplt.title(\"Sample size-50%\")\n\n# Fig 6\nplt.subplot(2,3,6)\nresult = plt.hist(x_60, bins=20, color='m', edgecolor='k', alpha=0.9)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Frequency/Count')\nplt.xlabel('Wall Thickness')\nplt.title(\"Sample size-60%\")","metadata":{"execution":{"iopub.status.busy":"2021-05-31T10:23:24.307802Z","iopub.execute_input":"2021-05-31T10:23:24.308345Z","iopub.status.idle":"2021-05-31T10:23:25.801774Z","shell.execute_reply.started":"2021-05-31T10:23:24.308279Z","shell.execute_reply":"2021-05-31T10:23:25.800388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From the random sampling, regardless of the sample size taken, the overall data distribution does not change. Here, the distribution is uniform.**","metadata":{}},{"cell_type":"markdown","source":"**THE CENTRAL LIMIT THEOREM AND DATA DISTRIBUTION**","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**The central limit theorem (CLT) is the backbone of the gaussian/normal distribution. Hence, the basic understanding of the CLT is important. \nFor a given sufficiently large samples with known or unknown distribution , the sampling distribution approximates the gaussian distribution.\nThe concept was originally developed in 1733 by Abraham de Moivre. It was first used by French mathematician, Laplace, in 1810.\nThe name was formally given only in 1930 by Hungarian mathematician George Polya.**\n\n**The understanding of CLT can be understood by visualisation. However, I have not seen the CLT visualization in Python. Hence, I created this workbook to help fellow netizens.**","metadata":{}},{"cell_type":"code","source":"# The CLT gives insight about the nature of the sampling distribution of the sample means under specific condition.\n# The specific condition is random resampling.\n# Here, for a given sample size, the sample mean is taken and the process is repeated k times.\n# It is called as RANDOM RESAMPLING or loosely termed as simulation.\n\n# Perform a random resampling with replacement true and simulation is repeated for 1000 times \nbs_10 = pd.DataFrame({'MeanThickness':[duplicate_raw_data.sample(n=10, replace=True)['Wall Thickness'].mean() for i in range(1000)]})\nbs_20 = pd.DataFrame({'MeanThickness':[duplicate_raw_data.sample(n=20, replace=True)['Wall Thickness'].mean() for i in range(1000)]})\nbs_30 = pd.DataFrame({'MeanThickness':[duplicate_raw_data.sample(n=30, replace=True)['Wall Thickness'].mean() for i in range(1000)]})\nbs_100 = pd.DataFrame({'MeanThickness':[duplicate_raw_data.sample(n=100, replace=True)['Wall Thickness'].mean() for i in range(1000)]})\nbs_900 = pd.DataFrame({'MeanThickness':[duplicate_raw_data.sample(n=900, replace=True)['Wall Thickness'].mean() for i in range(1000)]})\nbs_1800 = pd.DataFrame({'MeanThickness':[duplicate_raw_data.sample(n=1800, replace=True)['Wall Thickness'].mean() for i in range(1000)]})\nbs_2700 = pd.DataFrame({'MeanThickness':[duplicate_raw_data.sample(n=2700, replace=True)['Wall Thickness'].mean() for i in range(1000)]})\n\n# Final resampled data\nx_10 = bs_10.MeanThickness\nx_20 = bs_20.MeanThickness\nx_30 = bs_30.MeanThickness\nx_100 = bs_100.MeanThickness\nx_900 = bs_900.MeanThickness\nx_1800 = bs_1800.MeanThickness\nx_2700 = bs_2700.MeanThickness","metadata":{"execution":{"iopub.status.busy":"2021-05-31T10:23:25.803429Z","iopub.execute_input":"2021-05-31T10:23:25.803843Z","iopub.status.idle":"2021-05-31T10:23:28.3447Z","shell.execute_reply.started":"2021-05-31T10:23:25.803799Z","shell.execute_reply":"2021-05-31T10:23:28.343724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets visualize the data distribution of the RESAMPLED data\n\n# create new figure with size given explicitly\nplt.figure(figsize=(16,20))\n# get X limits and fix them\nmin_ylim, max_ylim = plt.ylim()\n\nplt.subplot(3,3,1) #the figure has 2 row, 3 columns, and this plot is the first plot.\nresult = plt.hist(x_10, bins=20, color='m', edgecolor='k', alpha=0.9)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Frequency/Count')\nplt.xlabel('Wall Thickness')\nplt.title(\"Sample size-10\")\n\nplt.subplot(3,3,2) #the figure has 2 row, 3 columns, and this plot is the second plot.\nresult = plt.hist(x_20, bins=20, color='m', edgecolor='k', alpha=0.9)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Frequency/Count')\nplt.xlabel('Wall Thickness')\nplt.title(\"Sample size-20\")\n\nplt.subplot(3,3,3) #the figure has 2 row, 3 columns, and this plot is the third plot.\nresult = plt.hist(x_30, bins=20, color='m', edgecolor='k', alpha=0.9)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Frequency/Count')\nplt.xlabel('Wall Thickness')\nplt.title(\"Sample size-30\")\n\nplt.subplot(3,3,4) #the figure has 2 row, 3 columns, and this plot is the fourth plot.\nresult = plt.hist(x_100, bins=20, color='m', edgecolor='k', alpha=0.9)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Frequency/Count')\nplt.xlabel('Wall Thickness')\nplt.title(\"Sample size-100\")\n\nplt.subplot(3,3,5) #the figure has 2 row, 3 columns, and this plot is the fifth plot.\nresult = plt.hist(x_900, bins=20, color='m', edgecolor='k', alpha=0.9)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Frequency/Count')\nplt.xlabel('Wall Thickness')\nplt.title(\"Sample size-900\")\n\nplt.subplot(3,3,6) #the figure has 2 row, 3 columns, and this plot is the sixth plot.\nresult = plt.hist(x_1800, bins=20, color='m', edgecolor='k', alpha=0.9)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Frequency/Count')\nplt.xlabel('Wall Thickness')\nplt.title(\"Sample size-1800\")\n\nplt.subplot(3,3,7) #the figure has 2 row, 3 columns, and this plot is the sixth plot.\nresult = plt.hist(x_2700, bins=20, color='m', edgecolor='k', alpha=0.9)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Frequency/Count')\nplt.xlabel('Wall Thickness')\nplt.title(\"Sample size-2700\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T10:23:28.345826Z","iopub.execute_input":"2021-05-31T10:23:28.346102Z","iopub.status.idle":"2021-05-31T10:23:30.160359Z","shell.execute_reply.started":"2021-05-31T10:23:28.346076Z","shell.execute_reply":"2021-05-31T10:23:30.159328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**From the resampled dataset, we came to know that regardless of the sample size (n= 10 to n =2700), we can already see from the histogram that the data distribution has shown the gaussian distribution pattern.**\n\n\n**Our next concern is to draw the probability distribution function on top of the histogram of the resampled dataset.**","metadata":{}},{"cell_type":"code","source":"# Gaussian distribution curve\nfrom scipy.stats import norm # stats function is used from scipy library\n\n# create new figure with size given explicitly\nplt.figure(figsize=(18,20))\n\nplt.subplot(3,3,1) #the figure has 2 row, 3 columns, and this plot is the first plot.\n# Fit a normal distribution to the data:\nmu = np.mean(x_10)\nstd = np.std(x_10)\n# Plot the histogram.\nplt.hist(x_10, density=True, bins=20, color='m', edgecolor='k', alpha=0.9)\n# Plot the PDF.\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = norm.pdf(x, mu, std)\nplt.plot(x, p, 'r', linewidth=3.5)\ntitle = \"N=10: mu = %.2f,  std = %.2f\" % (mu, std)\nplt.title(title)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Probability density function')\nplt.xlabel('Wall Thickness')\n\n\nplt.subplot(3,3,2) #the figure has 2 row, 3 columns, and this plot is the second plot.\n# Fit a normal distribution to the data:\nmu = np.mean(x_20)\nstd = np.std(x_20)\n# Plot the histogram.\nplt.hist(x_20, density=True, bins=20, color='m', edgecolor='k', alpha=0.9)\n# Plot the PDF.\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = norm.pdf(x, mu, std)\nplt.plot(x, p, 'r', linewidth=3.5)\ntitle = \"N=20: mu = %.2f,  std = %.2f\" % (mu, std)\nplt.title(title)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Probability density function')\nplt.xlabel('Wall Thickness')\n\nplt.subplot(3,3,3) #the figure has 2 row, 3 columns, and this plot is the third plot.\n# Fit a normal distribution to the data:\nmu = np.mean(x_30)\nstd = np.std(x_30)\n# Plot the histogram.\nplt.hist(x_30, density=True, bins=20, color='m', edgecolor='k', alpha=0.9)\n# Plot the PDF.\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = norm.pdf(x, mu, std)\nplt.plot(x, p, 'r', linewidth=3.5)\ntitle = \"N=30: mu = %.2f,  std = %.2f\" % (mu, std)\nplt.title(title)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Probability density function')\nplt.xlabel('Wall Thickness')\n\nplt.subplot(3,3,4) #the figure has 2 row, 3 columns, and this plot is the third plot.\n# Fit a normal distribution to the data:\nmu = np.mean(x_100)\nstd = np.std(x_100)\n# Plot the histogram.\nplt.hist(x_100, density=True, bins=20, color='m', edgecolor='k', alpha=0.9)\n# Plot the PDF.\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = norm.pdf(x, mu, std)\nplt.plot(x, p, 'r', linewidth=3.5)\ntitle = \"N=100: mu = %.2f,  std = %.2f\" % (mu, std)\nplt.title(title)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Probability density function')\nplt.xlabel('Wall Thickness')\n\n\nplt.subplot(3,3,5) #the figure has 2 row, 3 columns, and this plot is the fifth plot.\n# Fit a normal distribution to the data:\nmu = np.mean(x_900)\nstd = np.std(x_900)\n# Plot the histogram.\nplt.hist(x_900, density=True, bins=20, color='m', edgecolor='k', alpha=0.9)\n# Plot the PDF.\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = norm.pdf(x, mu, std)\nplt.plot(x, p, 'r', linewidth=3.5)\ntitle = \"N=900: mu = %.2f,  std =  %.2f\" % (mu, std)\nplt.title(title)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Probability density function')\nplt.xlabel('Wall Thickness')\n\n\nplt.subplot(3,3,6) #the figure has 2 row, 3 columns, and this plot is the sixth plot.\n# Fit a normal distribution to the data:\nmu = np.mean(x_1800)\nstd = np.std(x_1800)\n# Plot the histogram.\nplt.hist(x_1800, density=True, bins=20, color='m', edgecolor='k', alpha=0.9)\n# Plot the PDF.\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = norm.pdf(x, mu, std)\nplt.plot(x, p, 'r', linewidth=3.5)\ntitle = \"N=1800: mu = %.2f,  std = %.2f\" % (mu, std)\nplt.title(title)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Probability density function')\nplt.xlabel('Wall Thickness')\n\n\nplt.subplot(3,3,7) #the figure has 2 row, 3 columns, and this plot is the seventh plot.\n# Fit a normal distribution to the data:\nmu = np.mean(x_2700)\nstd = np.std(x_2700)\n# Plot the histogram.\nplt.hist(x_2700, density=True, bins=20, color='m', edgecolor='k', alpha=0.9)\n# Plot the PDF.\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100)\np = norm.pdf(x, mu, std)\nplt.plot(x, p, 'r', linewidth=3.5)\ntitle = \"N=2700: mu = %.2f,  std = %.2f\" % (mu, std)\nplt.title(title)\nplt.axvline(duplicate_raw_data['Wall Thickness'].mean(), color='k', linestyle='dashed', linewidth=3)\nplt.ylabel('Probability density function')\nplt.xlabel('Wall Thickness')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T10:23:30.161966Z","iopub.execute_input":"2021-05-31T10:23:30.162394Z","iopub.status.idle":"2021-05-31T10:23:32.157019Z","shell.execute_reply.started":"2021-05-31T10:23:30.162351Z","shell.execute_reply":"2021-05-31T10:23:32.155843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Hence, we show, here, that regardless of the data distribution, the sampling distribution of the sample mean approximates the normal distribution for a sufficiently large size. As an empirical rule, the minimal sample size is set at n=30.**","metadata":{}},{"cell_type":"markdown","source":"**The utility of CLT is to check the normality test i.e. whether the data distribution follows normal distribution or not.\nIn datascience community, four tests are popular: Q-Q plot, Shapiro-Wilk test, D'Agostino-Pearson's K2 test, and Anderson-Darling test.**\n\n**In subsequent analysis, I will perform these normality tests for a n=10 resampled data as an example.**","metadata":{}},{"cell_type":"code","source":"# NORMALITY TESTS\n\n# 1) Q-Q Plot\nimport scipy.stats as stats\nstats.probplot(x_10 , dist=\"norm\", plot=plt)\n\n# Note: The linear relationship shows that the data distribution approximates the gaussian distribution.","metadata":{"execution":{"iopub.status.busy":"2021-05-31T10:23:32.158185Z","iopub.execute_input":"2021-05-31T10:23:32.158475Z","iopub.status.idle":"2021-05-31T10:23:32.420178Z","shell.execute_reply.started":"2021-05-31T10:23:32.158447Z","shell.execute_reply":"2021-05-31T10:23:32.419056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2) Shapiro-Wilk Test\nfrom scipy.stats import shapiro\n\nShapiro_statistic_value, Shapiro_p_value = shapiro(x_10)\nprint(Shapiro_statistic_value, Shapiro_p_value)\n\n# Since p value is greater than 0.05 hence the data falls under the gaussian distribution. ","metadata":{"execution":{"iopub.status.busy":"2021-05-31T10:23:32.421825Z","iopub.execute_input":"2021-05-31T10:23:32.422302Z","iopub.status.idle":"2021-05-31T10:23:32.42843Z","shell.execute_reply.started":"2021-05-31T10:23:32.422258Z","shell.execute_reply":"2021-05-31T10:23:32.427413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3) D'Agostino-Pearson's K2 test \n# Test for skewness and kurtosis\n\n# Skewness checks the symmetry/assymetry of the gaussian curve.\n# Skewness checks the heavy tails (left (negatively skewed) OR right (positively skewed)\n\n# Kurtosis measures peakness/flatness of the curve.\n# kurtosis is a measure of the outlier (rare, extreme value) characteristic of a distribution or data.\n\nfrom scipy.stats import normaltest\n\nstat, p = normaltest(x_10)\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n\tprint('Sample looks Gaussian (fail to reject H0)')\nelse:\n\tprint('Sample does not look Gaussian (reject H0)')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T10:23:32.430063Z","iopub.execute_input":"2021-05-31T10:23:32.430445Z","iopub.status.idle":"2021-05-31T10:23:32.443907Z","shell.execute_reply.started":"2021-05-31T10:23:32.430405Z","shell.execute_reply":"2021-05-31T10:23:32.442881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4) Anderson-Darling Test\n# It can be used to check whether a data sample is normal.\n# This can provide the basis for a more thorough interpretation of the result.\nfrom scipy.stats import anderson\n\nresult = anderson(x_10)\nprint('Statistic: %.3f' % result.statistic)\np = 0\nfor i in range(len(result.critical_values)):\n\tsl, cv = result.significance_level[i], result.critical_values[i]\n\tif result.statistic < result.critical_values[i]:\n\t\tprint('%.3f: %.3f, data looks normal distributed' % (sl, cv))\n\telse:\n\t\tprint('%.3f: %.3f, data does not look normal distributed' % (sl, cv))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T10:23:32.445478Z","iopub.execute_input":"2021-05-31T10:23:32.445885Z","iopub.status.idle":"2021-05-31T10:23:32.463809Z","shell.execute_reply.started":"2021-05-31T10:23:32.445844Z","shell.execute_reply":"2021-05-31T10:23:32.462852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Final conclusion: Here, we visualize the concept and practically apply the Central Limit Theorem to model the real world problem.","metadata":{"execution":{"iopub.status.busy":"2021-05-31T10:25:16.374846Z","iopub.execute_input":"2021-05-31T10:25:16.375297Z","iopub.status.idle":"2021-05-31T10:25:16.379776Z","shell.execute_reply.started":"2021-05-31T10:25:16.375259Z","shell.execute_reply":"2021-05-31T10:25:16.379049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}