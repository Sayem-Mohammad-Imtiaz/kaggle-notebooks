{"cells":[{"metadata":{},"cell_type":"markdown","source":"Identify the snake breed\nhttps://www.hackerearth.com/challenges/competitive/hackerearth-deep-learning-challenge-snake-breed-detection/machine-learning/identify-the-snake-breed-5-66d9a9f5/\n\nThis is a challenge from HackerEarth.com, and one of the participant from HE has uploaded the dataset on Kaggle. Refer below details on the challenge.\n\n# Problem statement\nThe government has been facing a long-standing issue of wild animals entering residential areas due to various reasons. It's of critical importance that if any such dangerous animal is encountered, the concerned authority should be notified immediately. Reptiles, especially snakes, are among the most dangerous animals and they often enter residential areas.\n\nRecently due to an incident of a youngster getting bitten by a snake, the government decided to install cameras at every corner of the road to detect snakes and other animals.\n\nYou have been hired as a Deep Learning engineer to create a sophisticated model that can detect the breed of a snake from its image."},{"metadata":{},"cell_type":"markdown","source":"# Import Library"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport random, os\n\nimport cv2\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Set Directory Path"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_dir = '../input/hackerearth-deep-learning-identify-the-snake-breed/dataset'\ntrain_img_dir = os.path.join(base_dir, 'train/')\ntrain_images = os.listdir(train_img_dir)\n\ntest_img_dir = os.path.join(base_dir, 'test/')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_img_dir)\nprint(len(train_images))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Target Information from csv file"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(os.path.join(base_dir, 'train.csv'))\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the image_id we do not have image extension, so lets first add the .jpg extension, so that we can refer to the image_id directly and refer to its image."},{"metadata":{"trusted":true},"cell_type":"code","source":"def append_ext(fn):\n    return fn+\".jpg\"\n\ntrain_df[\"image_id\"]=train_df[\"image_id\"].apply(append_ext)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = len(train_df.breed.unique())\nnum_classes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Converting Target (breed) into Numerical"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"breed\"] = train_df[\"breed\"].astype('category')\ntrain_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"label\"] = train_df[\"breed\"].cat.codes\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check Categories.\nLABEL = train_df[\"breed\"].cat.categories\nLABEL","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LABEL[15], LABEL[25]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Class Distribution\nLets visualize the Class distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nax = sns.countplot(x=\"breed\", data=train_df) \nplt.xticks(rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"((train_df.groupby('breed').size()/train_df['breed'].count())*100 ).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we found that 9+% of data belongs to breed \"thamnophis-sirtalis\" and downup to 1+5 for breed \"crotalus-scutulatus\"."},{"metadata":{},"cell_type":"markdown","source":"# Check for Duplicate"},{"metadata":{"trusted":true},"cell_type":"code","source":"uniqueIds = train_df['image_id'].nunique()\n\nif(uniqueIds == len(train_df)):\n    print('There are no repeating Image IDs in the dataset')\nelse:\n    print('There are {len(train_df) - uniqueIds} repeating Image IDs')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize the Images.\nAlready done in my other Notebooks Refer to \n1. https://www.kaggle.com/dskagglemt/identify-the-snake-breed\n2. https://www.kaggle.com/dskagglemt/snake-breed-classification-vgg"},{"metadata":{},"cell_type":"markdown","source":"# Training the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Main parameters\nBATCH_SIZE = 16\nSTEPS_PER_EPOCH = len(train_df)*0.8 / BATCH_SIZE\nVALIDATION_STEPS = len(train_df)*0.2 / BATCH_SIZE\nEPOCHS = 20\nTARGET_SIZE = 300","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.label = train_df.label.astype('str')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    validation_split = 0.2,\n    preprocessing_function = None,\n    rotation_range = 20,\n    zoom_range = 0.2,\n    cval = 0.1,\n    horizontal_flip = True,\n    vertical_flip = True,\n    fill_mode = 'nearest',\n    shear_range = 0.15,\n    height_shift_range = 0.15,\n    width_shift_range = 0.15,\n    featurewise_center = True,\n    featurewise_std_normalization = True\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    directory = train_img_dir,\n    subset = \"training\",\n    x_col = \"image_id\",\n    y_col = \"label\",\n    target_size = (TARGET_SIZE, TARGET_SIZE),\n    batch_size = BATCH_SIZE,\n    class_mode = \"sparse\"\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_datagen = ImageDataGenerator(validation_split = 0.2)\n\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    train_df,\n    directory = train_img_dir,\n    subset = \"validation\",\n    x_col = \"image_id\",\n    y_col = \"label\",\n    target_size = (TARGET_SIZE, TARGET_SIZE),\n    batch_size = BATCH_SIZE,\n    class_mode = \"sparse\"\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_base = EfficientNetB0(\n    include_top = False, \n    weights = 'imagenet',\n    input_shape = (TARGET_SIZE, TARGET_SIZE, 3)\n)\n\nmodel = conv_base.output\nmodel = layers.GlobalAveragePooling2D()(model)\nmodel = layers.Dense(5, activation = \"softmax\")(model)\nmodel = models.Model(conv_base.input, model)\n\nmodel.compile(\n    optimizer = Adam(lr = 0.001),\n    loss = \"sparse_categorical_crossentropy\",\n    metrics = [\"acc\"]\n)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stop = EarlyStopping(\n    monitor = 'val_loss', \n    min_delta = 0.001, \n    patience = 5, \n    mode = 'min', \n    verbose = 1,\n    restore_best_weights = True\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor = 'val_loss', \n    factor = 0.3, \n    patience = 2, \n    min_delta = 0.001, \n    mode = 'min', \n    verbose = 1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_save = ModelCheckpoint(\n    './SnakeBreed_EfficientNetB0_Model_1.h5', \n    save_best_only = True, \n    save_weights_only = True,\n    monitor = 'val_loss', \n    mode = 'min', \n    verbose = 1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    steps_per_epoch = STEPS_PER_EPOCH,\n    epochs = EPOCHS,\n    validation_data = validation_generator,\n    validation_steps = VALIDATION_STEPS,\n#     callbacks = [early_stop, reduce_lr]\n#     callbacks = [model_save, early_stop, reduce_lr]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize the Performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nsns.set_style(\"white\")\nplt.suptitle('Train history', size = 15)\n\nax1.plot(epochs, acc, \"bo\", label = \"Training acc\")\nax1.plot(epochs, val_acc, \"b\", label = \"Validation acc\")\nax1.set_title(\"Training and validation acc\")\nax1.legend()\n\nax2.plot(epochs, loss, \"bo\", label = \"Training loss\", color = 'red')\nax2.plot(epochs, val_loss, \"b\", label = \"Validation loss\", color = 'red')\nax2.set_title(\"Training and validation loss\")\nax2.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction\n\nImage ID : 8b492b973d\t\n\nBreed : pantherophis-vulpinus\n   "},{"metadata":{"trusted":true},"cell_type":"code","source":"# image_path = os.path.join(train_dir,'8b492b973d'+'.jpg')\n# image_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# img = plt.imread(image_path)\n# plt.imshow(img)\n# plt.title('Original Bree --> pantherophis-vulpinus')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# img_for_prediction = load_img(image_path, target_size = input_dim)\n# img_for_prediction = img_to_array(img_for_prediction)\n# img_for_prediction = img_for_prediction.reshape((1, *img_for_prediction.shape))\n# img_for_prediction = preprocess_input(img_for_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predictions = model.predict(img_for_prediction)\n# pred = np.argsort(predictions)[0][-5:]\n# pred \n# # the Order is from 0 to 5 and 5th Position breed is highest.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# le.inverse_transform(pred)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}