{"cells":[{"metadata":{},"cell_type":"markdown","source":"**TRAING MODEL TO PREDICTED RAIN TOMORROW : Logistic Regression**"},{"metadata":{},"cell_type":"markdown","source":"**IMPORT LIBRABRIES**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Main libraries\nimport pandas as pd\nimport numpy as np\n\n# Visual libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.impute import  SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**START THE PREPROCESSING DATA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Start pre processing data\n\n# df = pd.read_csv(\"C:/Users/Kong Be/Desktop/weatherAUS.csv\")\ndf = pd.read_csv(\"../input/weatherAUS.csv\")\ndf = df.drop(columns ='RISK_MM')  # delete feature RISK_MM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(n=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# heat map of correlation of features\ncorrelation_matrix = df.corr()\nfig = plt.figure( num = 'correlation of features', figsize = (10,8))\nsns.heatmap( correlation_matrix , vmax = 0.8 , square = True )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CHOSE THE FEATURES THAT THE CORELATION CONFETIC  > 0.9**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Chose features that correlation confetic >0.9\nfeatures_chose = []\nheight = len(correlation_matrix.index)\nfor i in range(height):\n   for j in range(height):\n          if correlation_matrix.iloc[i,j] < 1 and correlation_matrix.iloc[i,j] > 0.9:\n              features_chose.extend([correlation_matrix.columns.values[j] , correlation_matrix.columns.values[i]])\n# Delete duplicates features\ntarget_features = []\nfor i in features_chose:\n    if features_chose.count(i) > 1 :\n        features_chose.remove(i)\n        target_features.append(i)\nprint(target_features)\n#target_features.append('RainTomorrow')\ndf1 = df.loc[:,target_features]\ndf1.loc[:,'RainTomorrow'] = df.loc[:,'RainTomorrow'].values\ndf1.loc[:,'RainTomorrow'].replace(['Yes','No'],[1,0] , inplace = True)\nprint(\" \\n\\t\\tFive examples of Data Frame\")\nprint(df1.head())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(df1.columns.values))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**STANDARDIZE THE DATA**"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"#Standardize the data\nx = df1.loc[:,target_features].values\ny = df1.loc[:,'RainTomorrow'].values\nx = StandardScaler().fit_transform(x)\n\ndf1 = pd.DataFrame(data = x , columns = target_features )\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CHECKING MISSING VALUES IN DF1 (Data of target_features and labels)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking Missing values --> count missing values\nmissing_matrix = df1.isnull()\ncount_missingValues = df1.isnull().sum().sum()\nprint(count_missingValues)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CHANGE THE MEAN VALUES FOR THE MISSING VALUES **"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Xoá các giá trị NA ( không phải số) để áp dụng đc hàm PCA.fit_transform bằng hàm SimpleImputer\n# (chuyển các NA thành các mean trên từng column)\nimp = SimpleImputer(missing_values=np.nan, strategy='mean')\nx = imp.fit_transform(x)\n#Create a new Dataframe\ndf1_new = pd.DataFrame(data = x , columns = target_features )\nprint(\"Count of the missing values in Data Frame now is \",end = '')\nprint(df1.isnull().sum().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PCA TRANSFORM 2D**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#PCA transformation to 2D\npca = PCA(n_components = 2)\nprincipalComponents = pca.fit_transform(x)\nprincipalDf = pd.DataFrame(data = principalComponents , columns = ['principal component 1','principal component 2'])\nprint(principalDf.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**VISUALATION 2D**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualization 2D\nfig = plt.figure(figsize = (8,8))\nax = fig.add_subplot(1,1,1)\nax.set_xlabel('Principal Component 1', fontsize = 15)\nax.set_ylabel('Principal Component 2', fontsize = 15)\nax.set_title('2 component PCA', fontsize = 20)\ntargets = [0, 1]\ncolors = ['r', 'g']\nfor target, color in zip(targets,colors):\n    indicesToKeep = y == target\n    ax.scatter(principalDf.loc[indicesToKeep, 'principal component 1']\n               , principalDf.loc[indicesToKeep, 'principal component 2']\n               , c = color\n               , s = 50)\nax.legend(targets)\nax.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" **DATA SPLITING**\n* Split Data into the training set and the test set to avoid overfit data "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Splitting\nx_train , x_test , y_train , y_test = train_test_split(principalDf, y , train_size = .85)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** APPLY LOGISTIC REGRESSION ALGORITHM FOR MODEL**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply LogisticRegression\nlogisticRegr = LogisticRegression(solver='lbfgs')\n\nresult = logisticRegr.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fit the training set and labels set to find theta matrix**"},{"metadata":{"trusted":true},"cell_type":"code","source":"logisticRegr.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Show the label of the test set from finded theta matrix**"},{"metadata":{"trusted":true},"cell_type":"code","source":"result = logisticRegr.predict(x_test)\nprint(result)\nprint(\"20 predicted first labels\")\nprint(result[range(20)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Show the accuary of the model **"},{"metadata":{"trusted":true},"cell_type":"code","source":"score = logisticRegr.score(x_test,y_test)\nprint(score)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}