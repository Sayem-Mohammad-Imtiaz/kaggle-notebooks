{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Grocery Dataset Product Image\nhttps://www.kaggle.com/amoghmisra27/grocery"},{"metadata":{},"cell_type":"markdown","source":"# Get a list of all files and subdirectories"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\npath = '../input/grocery/GroceryStoreDataset-master/dataset/train/'\n\nfile_list = []\n\nfor root, dirs, files in os.walk(path):\n#     print('Root : ', root)\n#     print('Dirs : ', dirs)\n#     print('Files : ', files)\n    for file in files:\n        file_list.append(os.path.join(root, file))\n\n        \n# print(file_list)\nprint(len(file_list))\n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/grocery/GroceryStoreDataset-master/dataset/train/Fruit/Apple'\n\nfolder_list = []\n\nfor root, dirs, files in os.walk(path):\n#     print('Root : ', root)\n#     print('Dirs : ', dirs)\n#     print('Files : ', files)\n\n    if len(dirs) > 0:\n        folder_list.append(dirs)\n\n        \nprint(folder_list)\nprint(len(folder_list))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import Library"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np  \nimport pandas as pd  \n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport cv2\nimport glob # to find files recursively\n\nimport keras \nimport tensorflow as tf\n\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fruits = ['Pineapple' , 'Cocos']\n# for x, y in enumerate(fruits):\n#     print(\"X : \", x)\n#     print(\"Y : \", y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1./255., # Rescaling\n    rotation_range = 40, # for augmentation\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = '../input/grocery/GroceryStoreDataset-master/dataset/train/'\nimage_size = (224, 224)\nbatch_size = 32\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_path,\n    batch_size = batch_size,\n    class_mode = 'categorical',\n    target_size = image_size\n)\n\n# https://keras.io/api/preprocessing/image/#flowfromdirectory-method","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator[0][0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n    plt.tight_layout()\n    plt.show()\n    \n    \naugmented_images = [train_generator[0][0][0] for i in range(10)]\nplotImages(augmented_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = (train_generator.class_indices)\nlabels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = dict((v,k) for k,v in labels.items()) \nlabels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_classes = len(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy\nfrom tensorflow.keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the model\nmodel = Sequential()\nmodel.add(Conv2D(16, kernel_size=(5, 5), activation='relu', input_shape=(224, 224, 3)))\nmodel.add(Conv2D(32, kernel_size=(5, 5), activation='relu'))\nmodel.add(Conv2D(64, kernel_size=(5, 5), activation='relu'))\nmodel.add(Conv2D(128, kernel_size=(5, 5), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(no_classes, activation='softmax'))\n\n# Display a model summary\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile the model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(),\n              metrics=['accuracy']\n             )\n\n# Start training\nmodel.fit(\n        train_generator,\n        epochs = 10,\n        shuffle = False\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n\ntest_path = '../input/grocery/GroceryStoreDataset-master/dataset/test/'\n\ntest_generator = test_datagen.flow_from_directory(\n    directory = test_path,\n    batch_size = batch_size,\n    class_mode = 'categorical',\n    target_size = image_size,\n    shuffle = False,\n    seed = 42\n)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict_generator(\n    test_generator,\n    verbose=1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_class_indices=np.argmax(pred,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = [labels[k] for k in predicted_class_indices]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"augmented_images = [test_generator[0][0][0] for i in range(10)]\nplotImages(augmented_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = test_generator.filenames\nresults = pd.DataFrame({\"Filename\":filenames,\n                      \"Predictions\":predictions})\nresults.to_csv(\"results.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results.tail()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}