{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id='0'></a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:250%; text-align:center; border-radius: 15px 50px;\">Credit Card Datasetüñãüìù - EDAüìö & Machine Learning ModelüéØ </p>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.style as style\n\n%matplotlib inline\nimport plotly.offline as py\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\npy.init_notebook_mode(connected=True)\nimport squarify\n\n# import required libraries for clustering\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read data\ndata = pd.read_csv('../input/ccdata/CC GENERAL.csv')\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Count missing variable\ndata.isnull().sum().sort_values(ascending=False).head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split features into Categorical and Numerical \ncatogrical = [x for x in data.columns if data[x].dtype == \"object\"]\nnumeric = [x for x in data.columns if data[x].dtype == \"float64\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#filling null or missing values with more frequent values\nfor i in catogrical:\n    data[i].fillna(data[i].mode()[0], inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# filling null or missing values with mean or average \n\nfor i in numeric:\n    data[i].fillna(data[i].mean(), inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let's check null values again \nsns.heatmap(data.isnull())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dropping CUST_ID feature\ndata.drop(['CUST_ID'], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='2'></a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\">Data Vizualizationüé®</p>","metadata":{}},{"cell_type":"code","source":"# see how the data is distributed.\ndata.hist(figsize = (20,20))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.kdeplot(data['MINIMUM_PAYMENTS'], shade=True) \nplt.title('Kernel Density Estimation Plot') \ndata['MINIMUM_PAYMENTS']=data['MINIMUM_PAYMENTS'].fillna(data['MINIMUM_PAYMENTS'].median())","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dist=data.iloc[:,1:17]\ndata_columns=data_dist.columns\n\nr,c=0,0\nfig, axes=plt.subplots(4,4, figsize=(20,16))\n#plt.tight_layout()\nfor i in data_columns:\n    sns.distplot(data[i], ax=axes[r,c])\n    c += 1\n    if c == 4: \n        r += 1\n        c=0\n    if r == 4: break\nplt.suptitle('Kernel Density Estimation Plot', fontsize=15)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(dpi = 100, figsize = (5,4))\nprint(\"Joint plot of Month of Absence with Other Variables ==> \\n\")\nfor i in  data.columns:\n    if i != 'CASH_ADVANCE' and i != 'PURCHASES':\n        print(f\"Correlation between PURCHASES and {i} ==> \",data.corr().loc['PURCHASES'][i])\n        sns.jointplot(x='PURCHASES',y=i,data=data,kind = 'reg',color = 'purple')\n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_coef=data[1:].corr()\n\n# Heatmap\nplt.figure(figsize=(25, 25))\nsns.heatmap(corr_coef, cmap='Greens', annot=True, annot_kws={'size':14},\n            xticklabels=corr_coef.columns,\n            yticklabels=corr_coef.columns)\nplt.title('Correlation Matrix')\n\n# Find out feature pairs whose coefficient >= 0.7\ncorr_cols=corr_coef.columns.to_list() \nsignif_corr=[]\nfor i in range(len(corr_cols)):\n    col=corr_cols[i]\n    signif_corr.append(abs(corr_coef[col])[abs(corr_coef[col]) >= 0.7])\nsignif_corr_df=pd.DataFrame(signif_corr)\n#signif_corr_df['PURCHASES']['ONEOFF_PURCHASES'] ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas_profiling as pp\n\npp.ProfileReport(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check outliers\nplt.figure(figsize=(10,10))\nsns.boxplot(data=data)\nplt.xticks(rotation=90)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Drop outliers according to z-score\nfrom scipy import stats\nz = np.abs(stats.zscore(data))\nprint(z)\n\nthreshold = 3\nprint(np.where(z > 3))\n\ndata_o = data[(z < 3).all(axis=1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Drop outliers according to z-score\nfrom scipy import stats\nz = np.abs(stats.zscore(data))\nprint(z)\n\nthreshold = 3\nprint(np.where(z > 3))\n\ndata_o = data[(z < 3).all(axis=1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Drop outliers according to z-score\nfrom scipy import stats\nz = np.abs(stats.zscore(data))\nprint(z)\n\nthreshold = 3\nprint(np.where(z > 3))\n\ndata_o = data[(z < 3).all(axis=1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Drop outliers according to z-score\nfrom scipy import stats\nz = np.abs(stats.zscore(data))\nprint(z)\n\nthreshold = 3\nprint(np.where(z > 3))\n\ndata_o = data[(z < 3).all(axis=1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_o.shape\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Normalize\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler, normalize\n\n# Get column names first\nnames = data_o.columns\n# Create the Scaler object\nscaler = preprocessing.StandardScaler()\n# Fit your data on the scaler object\nscaled_df = scaler.fit_transform(data_o)\nscaled_df = pd.DataFrame(scaled_df, columns=names)\n  \n# Normalizing the Data \nnormalized_df = normalize(scaled_df) \n  \n# Converting the numpy array into a pandas DataFrame \nnormalized_df = pd.DataFrame(normalized_df,columns=names) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.boxplot(data=normalized_df)\nplt.xticks(rotation=90)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using Pearson Correlation\nplt.figure(figsize=(12,10))\ncor = normalized_df.corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Correlation with output variable\ncor_target = abs(cor[\"PURCHASES\"])\n#Selecting highly correlated features\nrelevant_features = cor_target[cor_target>0.5]\nrelevant_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Feature Selection using LassoCV\n\nfrom sklearn.linear_model import LassoCV\n\n#Feature Selection\nX = normalized_df.drop(\"BALANCE\",1)   #Feature Matrix\ny = normalized_df[\"BALANCE\"]          #Target Variable\n\nreg = LassoCV()\nreg.fit(X, y)\nprint(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\nprint(\"Best score using built-in LassoCV: %f\" %reg.score(X,y))\ncoef = pd.Series(reg.coef_, index = X.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  \n      str(sum(coef == 0)) + \" variables\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imp_coef = coef.sort_values()\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Feature importance using Lasso Model\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = X.drop([\"PURCHASES\",'PRC_FULL_PAYMENT','CASH_ADVANCE_TRX','INSTALLMENTS_PURCHASES','TENURE','PURCHASES_FREQUENCY'],1)   #Feature Matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#KMeans Clustering\n#Defining WCSS Elbow point\nfrom sklearn.cluster import KMeans\n\nwcss=[]\nfor i in range (1,30):\n    kmeans=KMeans(i)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\nwcss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Elbow Plot\nplt.plot(range(1,30),wcss)\nplt.xlabel('Number of Clusters')\nplt.ylabel('WCSS')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Another Technique to define n_cluster\n\n# Import the KElbowVisualizer method \nfrom yellowbrick.cluster import KElbowVisualizer\n\n# Instantiate a scikit-learn K-Means model\nmodel = KMeans(random_state=0)\n\n# Instantiate the KElbowVisualizer with the number of clusters and the metric \nvisualizer = KElbowVisualizer(model, k=(2,30), metric='silhouette', timings=False)\n\n# Fit the data and visualize\nvisualizer.fit(X)    \nvisualizer.poof()  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k_means_new=KMeans(5)\nkmeans.fit(X)\ncluster_new=X.copy()\ncluster_new['cluster_pred']=k_means_new.fit_predict(X)\ncluster_new.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize cluster shapes in 3d.\n\ncluster1=cluster_new.loc[cluster_new['cluster_pred'] == 0]\ncluster2=cluster_new.loc[cluster_new['cluster_pred'] == 1]\ncluster3=cluster_new.loc[cluster_new['cluster_pred'] == 2]\ncluster4=cluster_new.loc[cluster_new['cluster_pred'] == 3]\ncluster5=cluster_new.loc[cluster_new['cluster_pred'] == 4]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"facet = sns.lmplot(data=cluster_new, x='CREDIT_LIMIT', y='PAYMENTS',hue='cluster_pred', \n                   fit_reg=False, legend=True, legend_out=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hierarchical Clustering","metadata":{}},{"cell_type":"code","source":"# importing all important libraries\nimport scipy.cluster.hierarchy as hcluster\nfrom sklearn.cluster import AgglomerativeClustering\n\n\n# Single linkage: \nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree\n","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features=normalized_df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Average linkage\n\nmergings = linkage(X, method=\"average\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting dendogram\nplt.figure(figsize=(50, 12))\ndend=hcluster.dendrogram(hcluster.linkage(X,method='ward'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting labels from Agglomearative Hierarchical clustering\nhcluster = AgglomerativeClustering(n_clusters=10, affinity='euclidean', linkage='ward')  \nhcluster.fit_predict(X)\nhcluster_label = hcluster.labels_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hcluster_df = pd.DataFrame(X)\n#adding hcluster labels in hcluster_df\nhcluster_df['hcluster'] = hcluster_label\n#first few rows of hcluster_df\nhcluster_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"facet = sns.lmplot(data=hcluster_df, x='CASH_ADVANCE', y='PURCHASES_INSTALLMENTS_FREQUENCY',hue='hcluster', \n                   fit_reg=False, legend=True, legend_out=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Silhouette analysis\nrange_n_clusters = [2, 3, 4, 5, 6, 7, 8,9,10,11]\n\nfor num_clusters in range_n_clusters:\n    # intialise hclustering\n    # Getting labels from Agglomearative Hierarchical clustering\n    hcluster = AgglomerativeClustering(n_clusters=num_clusters, affinity='euclidean', linkage='ward')  \n    hcluster.fit_predict(X)\n    hcluster_label = hcluster.labels_\n    \n    # silhouette score\n    silhouette_avg = silhouette_score(X, hcluster_label)\n    print(\"For n_clusters={0}, the silhouette score is {1}\".format(num_clusters, silhouette_avg))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}