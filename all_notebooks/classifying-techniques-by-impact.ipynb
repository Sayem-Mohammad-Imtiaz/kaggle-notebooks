{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5d0e7c0f-783d-9e03-b4bf-59762b885251"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n%pylab inline\n\nfrom tqdm import tqdm\nfrom scipy.fftpack import fft\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.decomposition import KernelPCA, PCA\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"markdown","metadata":{"_cell_guid":"ab7c90f9-e5f0-b9b1-56d6-e6263b01d077"},"source":"I found the dataset a little difficult to wrap my head around so I split it into multiple parts.  In this notebook we will be:\n\n- Visualizing the raw signal provided to us\n- Classifying the techniques based on the signals.\n- Comparing players and techniques.\n\nNow since we don't know what exactly the sensors measure I'm going to call it Impact."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2493f6e7-be18-ae35-d56f-fb8b0a031dda"},"outputs":[],"source":"def running_mean(x, N):\n    cumsum = numpy.cumsum(numpy.insert(x, 0, 0)) \n    return (cumsum[N:] - cumsum[:-N]) / N \n\ndef get_cm(kernel, data):\n    \"Get the confusion matrix and it's heatmap\"\n    le = LabelEncoder()\n    x, y = data.drop('Target', axis=1), le.fit_transform(data.Target)\n    \n    estimator = OneVsRestClassifier(RandomForestClassifier(n_jobs=-1,\n                                                           n_estimators=500))\n    pca = KernelPCA(kernel=kernel)\n    x = pca.fit_transform(x)\n    \n    p = cross_val_predict(estimator, x, y)\n    cm = pd.DataFrame(confusion_matrix(y, p))\n    cm.index, cm.columns = le.classes_, le.classes_\n    \n    cm = cm / cm.sum(axis=1)\n    sns.heatmap(cm, cmap='gray_r', annot=True)\n    plt.title('With KernelPCA({})'.format(kernel))\n    print(classification_report(y, p))\n    \ndf = pd.read_csv('../input/Taekwondo_Technique_Classification_Stats.csv', index_col=0)\ndf.info()"},{"cell_type":"markdown","metadata":{"_cell_guid":"29cb1b94-6721-d925-2ad8-5922aa012edb"},"source":"## Visualization\n\nLet's pull out the techniques into different variables so that it is a little easier for me to visualize them."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc98820b-ef6e-6f9f-b67f-09ba1785decf"},"outputs":[],"source":"temp = []\nfor technique in 'RBCP':\n    t = df[[col for col in df.columns if technique+'.' in col]][2:].astype(float)\n    temp.append(t)\nR, B, C, P = temp"},{"cell_type":"markdown","metadata":{"_cell_guid":"80af6221-3ba3-eb8b-6515-664f5f1e950a"},"source":"Let's plot the signals as they are. It should make for a nice visual!"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ab2a62e9-07eb-e7dd-0ef6-e4d315b47061"},"outputs":[],"source":"window = 5\nplt.subplots(figsize=(10, 25))\nax1 = plt.subplot(29, 4, 1)\nplt.gca().get_yaxis().set_ticklabels([])\nplt.gca().get_xaxis().set_ticklabels([])\nindex = 1\nfor col in R.columns:\n    plt.subplot(29, 4, index, sharex=ax1)\n    running = running_mean(R[col].values, window)\n    threshold = R[col].mean()\n    plt.plot(running[1100: 3000], color='black', alpha=1, linewidth=0.7)\n    plt.plot([threshold for _ in running[1100:3000]], color='green', linewidth=0.8)\n    plt.gca().get_yaxis().set_ticklabels([])\n    \n    col = col.replace('R', 'B')\n    plt.subplot(29, 4, index+1, sharex=ax1)\n    try:\n        running = running_mean(B[col].values, window)\n        threshold = B[col].mean()\n    except:\n        running = [R[col.replace('B', 'R')].mean() for _ in range(1000)]\n        threshold = R[col.replace('B', 'R')].mean()\n    plt.plot(running[1100: 3000], color='red', alpha=1, linewidth=0.7)\n    plt.plot([threshold for _ in running[1100:3000]], color='green', linewidth=0.8)\n    plt.gca().get_yaxis().set_ticklabels([])\n    \n    col = col.replace('B', 'C')\n    plt.subplot(29, 4, index+2, sharex=ax1)\n    running = running_mean(C[col].values, window)\n    threshold = C[col].mean()\n    plt.plot(running[1100: 3000], color='orange', alpha=1, linewidth=0.7)\n    plt.plot([threshold for _ in running[1100:3000]], color='green', linewidth=0.8)\n    plt.gca().get_yaxis().set_ticklabels([])\n    \n    col = col.replace('C', 'P')\n    plt.subplot(29, 4, index+3, sharex=ax1)\n    running = running_mean(P[col].values, window)\n    threshold = P[col].mean()\n    plt.plot(running[1100: 3000], color='blue', alpha=1, linewidth=0.7)\n    plt.plot([threshold for _ in running[1100:3000]], color='green', linewidth=0.8)\n    plt.gca().get_yaxis().set_ticklabels([])\n    index += 4\ncolors = 'Black: Roundhouse, Red: Back Kick, Orange: Cut, Blue: Punch'\nplt.suptitle('{}\\n (Rolling mean of signal with {} window)'.format(colors, window), fontsize=20)\nplt.subplots_adjust(top=0.95)"},{"cell_type":"markdown","metadata":{"_cell_guid":"b794bbf8-1374-2d73-7160-c1ce6134710f"},"source":"## Classification\n\n- We move on to classifying them. For each signal we calculate it's Fourier transform and take the absolute of the complex number that results as a feature.\n- Based on this we build  a OneVsRest Classifier with a Random Forest at it's heart.\n- Before allowing the classification to occur, we pass the signals through KernelPCA with an RBF kernel. (This kernel was seen to give best results)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c5408e4d-b1eb-2069-3adb-e48c28fc48c2"},"outputs":[],"source":"# Performing FFT on the data\nndf, labels = [], []\nfor consider, name in zip([R, B, C, P], ['Roundhouse', 'Back Kick', 'Cut', 'Punch']):\n    for col in consider.columns:\n        meanval = consider[col].mean()\n        signal = consider[col].fillna(meanval)[1100: 3000]\n        f = fft(signal)\n        power = np.concatenate([f.real, f.imag])\n        power = np.sqrt(np.power(f.real, 2) + np.power(f.imag, 2))\n        ndf.append(power)\n        labels.append(name)\nprint(set(list(map(len, ndf))), 'values are given by the FFT')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"093f9ce7-5a35-1bce-ac71-c8ca9ad5a0ee"},"outputs":[],"source":"# Preparing the data for classification\ndata = pd.DataFrame(ndf)\ndata['Target'] = labels\nprint(data.shape, 'Data shape')"},{"cell_type":"markdown","metadata":{"_cell_guid":"03553db0-e27f-2dd4-ca69-589218c24121"},"source":"How does the variance change with PCA n_components? We plot the n_components with the cumulative sum of the ratios explained. This let's us see how many components we would need to get a good approximation of the dataset."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2a794192-e7bc-624f-abf2-31973ee4c97a"},"outputs":[],"source":"\n# Let's see what vanilla PCA does.\nle = LabelEncoder()\nx, y = data.drop('Target', axis=1), le.fit_transform(data.Target)\n\nprint(x.shape, 'shape before PCA')\npca = PCA()\nx = pca.fit_transform(x)\nprint(x.shape, 'shape after PCA')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f4063beb-6c09-4098-e69a-c16279b6d631"},"outputs":[],"source":"# % Variance explained\nplt.plot(np.cumsum(pca.explained_variance_ratio_), '.-', label='Variance explained')\nplt.plot([0, 120], [1, 1], label='1', color='black')\nplt.title('Variance explained with components')\nplt.legend()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e9f0d5e4-2192-a830-d896-c94883a70030"},"outputs":[],"source":"# get_cm('linear', data)\n# get_cm('poly', data)\n# get_cm('cosine', data)\n# get_cm('sigmoid', data)\nget_cm('rbf', data)"},{"cell_type":"markdown","metadata":{"_cell_guid":"35432bb5-1f37-a637-23ca-26fd0567c0d1"},"source":"An RBF Kernel PCA applied to a OneVsRest Random Forest yields an ok classification for the signals.\n\nThe Back kick is frequently misclassified which is a shame. Perhaps this can be solved with the addition of more data?\n\n## Who/What hits harder?\n\nAs a bonus let's try to find out who hits harder among the people who supplied this data. We might also try to find out which technique hits the hardest."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"282fe4fa-f735-83e2-b913-006225542b44"},"outputs":[],"source":"df.T.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dd8c9c78-46e1-e893-f53f-e55b21c036c5"},"outputs":[],"source":"# We pre process the data a little.\ndft = df.T.copy()\nmeans = dft.drop(['ID', 'Trial #'], axis=1).astype(float).mean(axis=1)\ntemp = dft.drop(['ID', 'Trial #'], axis=1).astype(float).apply(lambda x: abs(x-1026), axis=1)\n\nfor i in range(11):\n    temp = temp.replace(i, np.nan)\n\ntemp.columns = [str(i) for i, v in enumerate(temp.columns)]\ncols_to_drop = []\nfor col in temp.columns:\n    if temp[col].var() == 0:\n        cols_to_drop.append(col)\nprint('{} columns present before drop'.format(temp.shape[1]))\ntemp = temp.drop(cols_to_drop, axis=1)\nprint('{} columns present after drop'.format(temp.shape[1]))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"45007139-a9cd-cae4-8db2-33d2ef0b9de8"},"outputs":[],"source":"# We measure Mean and Max signal strengths\ntemp['Mean_hits'] = temp.mean(axis=1)  # THIS IS WHAT IS BEING MEASURED\ntemp['Max_hits'] = temp.max(axis=1)  # THIS IS WHAT IS BEING MEASURED\ntemp['ID'] = dft.ID\ntemp['Technique'] = dft.index.str[0]\n\nplt.subplots(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nsns.violinplot(x='ID', y='Mean_hits', data=temp, linewidth=1)\nplt.subplot(1, 2, 2)\nsns.violinplot(x='ID', y='Max_hits', data=temp, linewidth=1)\n\nplt.suptitle('Signal strength grouped by player IDs')"},{"cell_type":"markdown","metadata":{"_cell_guid":"958331df-b8ed-ef9e-0aed-e93baf66e071"},"source":"**Player 3** consistently hits with a given impact irrespective of techniques. On the other hand **Player 6** has enormous spread. Let's do a heatmap showing technique and player.\n\nI think **P5** and **P6** are different from the others on some basis. Their max impacts are too spread out as compared to the others."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"04380a2a-fb6a-564e-66d2-6b31df11f6c2"},"outputs":[],"source":"ct = pd.crosstab(temp['ID'], temp['Technique'],\n                        values=temp['Max_hits'], aggfunc=np.mean)\nct"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d1431cc5-571a-9908-db38-cf8e4edc24cf"},"outputs":[],"source":"sns.heatmap(ct / ct.sum(), cmap='gray_r', annot=True, linewidth=0.5, linecolor='black')\nsns.plt.title('Who hits the hardest per technique? (Do not compare across rows)')"},{"cell_type":"markdown","metadata":{"_cell_guid":"fc2ab950-0e0b-0eb9-33c0-f0497c36d1ad"},"source":"**Player 5** hits the hardest when it comes to a Back Kick. **Player 6** Hits the hardest when it comes to other techniques; though to be fair the competition is tough. \n\nWhat if we sum on the other axis? That could tell us which technique is a person's forte. As with columns  before, because of the nature of our computation, comparing rows would be nonsensical this time."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5dff1354-7cf3-f5db-5a3c-a9f6d86250e4"},"outputs":[],"source":"sns.heatmap((ct.T / ct.sum(axis=1)).T, cmap='gray_r',\n            annot=True, linewidth=0.5, linecolor='black')\nsns.plt.title(\"Which technique is a person's best? (Do not compare across cols)\" )"},{"cell_type":"markdown","metadata":{"_cell_guid":"28d4b9c7-9493-9af5-6d05-5a7e9f237893"},"source":"Of all the techniques **Player 1** performed, the back kick and Punch are those which deliver the most impact. **Player 2** has a roundhouse which delivers almost as much impact as all of their other techniques combined.\n\nNobody has got **C** down?! Everyone has at least one technique which is better than the Cut they perform. Then again Punches and Roundhouses are heavy hitters. I suppose those are the things everyone trains the most leading to their good development."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9dacaad8-30a8-6f26-4bf2-a57dd5184c34"},"outputs":[],"source":"# Let's add player info now.\nplayers = pd.read_csv('../input/Table1.csv')\nplayers"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5f49a91a-e596-6aa3-df81-03f2ec013ab4"},"outputs":[],"source":"temp['Participant ID'] = temp['ID']\ntemp2 = pd.merge(temp, players, on='Participant ID', how='left')\n\nsns.factorplot(x='Age', y='Max_hits', data=temp2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"47a2637a-77ad-91e9-dc84-bd41434de2f8"},"outputs":[],"source":"sns.factorplot(x='Weight (kg)', y='Max_hits', data=temp2)"},{"cell_type":"markdown","metadata":{"_cell_guid":"239429f1-e718-a5d3-98a6-843973cbf7de"},"source":"Age and weight do contribute to impact magnitude. But which does more?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19ac62e4-a07f-5100-b338-597f5d253adc"},"outputs":[],"source":"temp2[['Weight (kg)', 'Age', 'Max_hits']].corr()"},{"cell_type":"markdown","metadata":{"_cell_guid":"04b432aa-6497-a271-d485-048c002b625e"},"source":"Weight has a slightly higher effect on the impact magnitude than the Age of a person.\n\nWith that we wrap up for now!"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}