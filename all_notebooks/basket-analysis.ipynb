{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df  = pd.read_csv(\"/kaggle/input/groceries/groceries - groceries.csv\", encoding =\"utf-8\")\ndf.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#need to drop column'items' it skews the results. \ntrans_df = df\ndel trans_df['Item(s)']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trans_df.fillna(0,inplace=True)\ntrans_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dat viz","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom wordcloud import WordCloud\n\nplt.rcParams['figure.figsize'] = (8, 8)\nwordcloud = WordCloud(background_color = 'white', width = 1200,  height = 1200, max_words = 20).generate(str(transactions[0]))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.title('Most Popular Items bought first by the Customers',fontsize = 40)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Apriori and stuff","metadata":{}},{"cell_type":"code","source":"transactions = []\nfor i in range(0, len(trans_df)):\n    transactions.append([str(trans_df.values[i,j]) for j in range(0, 31) if str(trans_df.values[i,j])!='0'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transactions[3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mlxtend.preprocessing import TransactionEncoder\n\nte = TransactionEncoder()\ndata = te.fit_transform(transactions)\ndata = pd.DataFrame(data, columns = te.columns_)\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frequent_itemsets = apriori(data, min_support = 0.03, use_colnames = True)\nfrequent_itemsets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We would apply association rules on frequent itemset. \n# here we are setting based on lift and keeping minimum lift as 1\n\nrules_mlxtend = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\nrules_mlxtend","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# as based business use case we can sort based on confidance and lift.\nrules_mlxtend[ (rules_mlxtend['lift'] >= 1) & (rules_mlxtend['confidence'] >= 0.1) ].head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing the rules distribution color mapped by Lift\nplt.figure(figsize=(8, 6))\nplt.scatter(rules_mlxtend['support'], rules_mlxtend['confidence'], c=rules_mlxtend['lift'], alpha=0.9, cmap='YlOrRd');\nplt.title('Rules distribution color mapped by lift');\nplt.xlabel('Support')\nplt.ylabel('Confidence')\nplt.colorbar();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_rules = rules_mlxtend.sort_values('confidence', ascending = False)[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (10,10))\nax = fig.add_subplot(111)\nax.scatter(top_rules.support, top_rules.confidence, top_rules.lift)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shamlessly borrowed from \n#https://towardsdatascience.com/market-basket-analysis-using-associative-data-mining-and-apriori-algorithm-bddd07c6a71a\nimport networkx as nx\nG1 = nx.DiGraph()\ncolor_map = []\nN = 50\ncolors = np.random.rand(N)\nstrs = ['r0', 'r1', 'r2', 'r3', 'r4', 'r5', 'r6', 'r7', 'r8', 'r9']\nfor i in range(10):\n    G1.add_nodes_from('r'+str(i))\n    for a in top_rules.iloc[i]['antecedents']:\n        G1.add_nodes_from([a])\n        G1.add_edge(a, 'r'+str(i), color = colors[i], weight = 2)\n    for c in top_rules.iloc[i]['consequents']:\n        G1.add_nodes_from([c])\n        G1.add_edge('r'+str(i), c, color = colors[i], weight = 2)\nfor node in G1:\n    found_a_string = False\n    for item in strs:\n        if node == item:\n            found_a_string = True\n    if found_a_string:\n        color_map.append('red')\n    else:\n        color_map.append('black')\nedges = G1.edges()\ncolors = [G1[u][v]['color'] for u,v in edges]\nweights = [G1[u][v]['weight'] for u,v in edges]\npos = nx.spring_layout(G1, k = 16, scale = 1)\nfig = plt.figure(figsize = (12,12))\n#have to remove edges = edges, from the 3rd argument in order to work\nnx.draw(G1, pos,  node_color = color_map, edge_color = colors, width = weights, font_size = 16, with_labels = False)\nfor p in pos:\n    pos[p][1] += 0.07\nnx.draw_networkx_labels(G1, pos)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}