{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport re\nimport random\nimport warnings\nimport tensorflow as tf\n\nfrom tensorflow import keras as ks\nfrom tensorflow.keras import layers\nfrom keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def clean_data(text):\n    text = text.lower()\n    text = re.sub(r'[^(a-zA-Z0-9)\\s\\*\\+-\\/\\(\\)=&|]','', text)\n    return text\n\ntrain = pd.read_csv(\"/kaggle/input/60k-stack-overflow-questions-with-quality-rate/train.csv\")\nvalid = pd.read_csv(\"/kaggle/input/60k-stack-overflow-questions-with-quality-rate/valid.csv\")\n\nmaxlength = 75\n\ntrain['Body'] = train['Body'].apply(clean_data)\nvalid['Body'] = valid['Body'].apply(clean_data)\n\ntrain2=train.copy()\n    \ntokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000, filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n\\r', lower=True, split=\" \")\ntokenizer.fit_on_texts(train['Body'])\ntrain_x = ks.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(train['Body']), maxlen=maxlength)\nvalid_x = ks.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(valid['Body']), maxlen=maxlength)\n\ntrain_y = train['Y'].map({'LQ_CLOSE':0, 'LQ_EDIT':1, 'HQ':2})\nvalid_y = valid['Y'].map({'LQ_CLOSE':0, 'LQ_EDIT':1, 'HQ':2})\n\ntrain_y = ks.utils.to_categorical(train_y, num_classes=3)\nvalid_y = ks.utils.to_categorical(valid_y, num_classes=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tokenizer.word_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ks.Sequential()\nmodel.add(layers.Embedding(input_length=maxlength, input_dim=10000, output_dim=128))    \nmodel.add(layers.LSTM(64, return_sequences=True))\nmodel.add(layers.LSTM(64))\nmodel.add(layers.Dense(3, activation=\"softmax\"))\nmodel.compile(optimizer=ks.optimizers.SGD(learning_rate=(0.55)), loss=ks.losses.CategoricalCrossentropy(), metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_x, train_y, batch_size=128, epochs=25)\nloss, acc = model.evaluate(valid_x, valid_y, verbose=1)\nprint('Loss:\\t\\t', loss, '\\nAccuracy:\\t', acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"rnn\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}