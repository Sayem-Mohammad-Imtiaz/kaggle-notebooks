{"cells":[{"metadata":{},"cell_type":"markdown","source":"# About the dataset\nOcular Disease Intelligent Recognition (ODIR) is a structured ophthalmic database of 5,000 patients with age, color fundus photographs from left and right eyes and doctors' diagnostic keywords from doctors.<br>\n\nThis dataset is meant to represent ‘‘real-life’’ set of patient information collected by Shanggong Medical Technology Co., Ltd. from different hospitals/medical centers in China. In these institutions, fundus images are captured by various cameras in the market, such as Canon, Zeiss and Kowa, resulting into varied image resolutions.<br>\nAnnotations were labeled by trained human readers with quality control management. They classify patient into eight labels including:<br>\n\n* Normal (N),\n* Diabetes (D),\n* Glaucoma (G),\n* Cataract (C),\n* Age related Macular Degeneration (A),\n* Hypertension (H),\n* Pathological Myopia (M),\n* Other diseases/abnormalities (O)"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\n!pip install openpyxl","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os\nimport cv2\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# File structure"},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    print(dirname)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_DIR = '/kaggle/input/ocular-disease-recognition-odir5k/'\nTRAIN_DIR = '/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/Training Images/'\nTEST_DIR = '/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/Testing Images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(BASE_DIR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CSV vs Excel\nLooks like there are 2 files describing the data: one is in CSV format and the other is an Excel sheet. Let's see if there are any differences between the two."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_csv = pd.read_csv(os.path.join(BASE_DIR, \"full_df.csv\"))\nprint(df_csv.shape)\ndf_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_csv.iloc[10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_csv['filepath'][0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each row of this table represents a patient with both their eyes checked. For some reason the last 4 columns only take into account the right eye, but since they don't really add any new information, we can just drop them if we decide to use the csv. <br><br>\nLet's now have a look at the Excel sheet."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_excel = pd.read_excel('/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/data.xlsx')\nprint(df_excel.shape)\ndf_excel.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This looks like the same table but with questionable columns already dropped. Also the number of entries differs from the first table."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'# of entries in the csv: {df_csv.shape}')\nprint(f'# of entries in the excel: {df_excel.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'# of unique IDs in the csv: {len(df_csv.ID.unique())}')\nprint(f'# of unique IDs in the excel: {len(df_excel.ID.unique())}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_csv.ID.unique())\nprint(df_excel.ID.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_csv = df_csv.sort_values(by='ID')\ndf_excel = df_excel.sort_values(by='ID')\n\nprint(df_csv.ID.unique())\nprint(df_excel.ID.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_csv.ID.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_csv.loc[(df_csv.ID == 2895)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_csv.loc[(df_csv.ID == 2400)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The CSV is structured with intention to have a separate entry for each image. This is not a good way to organize such data: \n* a lot of information is being repeated for both eyes\n* it's easy to forget to create entry for the other eye, which is exactly what's going on in this table\n* from medical point of view, both eyes of a patient should be considered together\n<br><br>\nRight now it seems like the Excel sheet is may be the refined version of the CSV:\nit's structured better, it's sorted, the number of the IDs equals to the number of entries which is a round number. Also, the CSV has less unique IDs than the Excel."},{"metadata":{},"cell_type":"markdown","source":"## Image files"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_paths = sorted(os.listdir(TRAIN_DIR))\ntest_paths = sorted(os.listdir(TEST_DIR))\npreprocessed_paths = sorted(os.listdir(os.path.join(BASE_DIR, 'preprocessed_images')))\n\nprint(f'train images: {len(train_paths)}')\nprint(f'test images: {len(test_paths)}')\nprint(f'preprocessed images: {len(preprocessed_paths)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that the number of preprocessed images matches exactly the number of entries in the CSV,<br>\nwhile number of files in the \"Training Images\" folder corresponds to 3500 patients, which is exactly the number of entries in the Excel sheet"},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessed_paths[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_paths[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note how the 1005_left.jpg is missing from the preprocessed images"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_paths[:14]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_csv.loc[(df_csv.ID == 1000)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_excel.loc[(df_csv.ID == 1000)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems like we don't have labels for the test images. We can either try to contact the owner of the data, or just use a fraction of the training folder as test images."},{"metadata":{"trusted":true},"cell_type":"code","source":"heights = []\nwidths = []\nfor file_name in tqdm(train_paths):\n    image = cv2.imread(os.path.join(TRAIN_DIR, file_name))\n    heights.append(image.shape[0])\n    widths.append(image.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heights_pd = pd.Series(heights)\nwidths_pd = pd.Series(widths)\nprint(f'min height: {heights_pd.min()}')\nprint(f'max height: {heights_pd.max()}')\nprint(f'min width: {widths_pd.min()}')\nprint(f'max width: {widths_pd.max()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', None)\nheights_pd.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vertical_images = 0\nhorizontal_images = 0\nsquare_images = 0\nfor i in range(len(heights)):\n    if heights[i] > widths[i]:\n        vertical_images+=1\n    elif heights[i] < widths[i]:\n        horizontal_images+=1\n    else:\n        square_images+=1\nprint(f'vertical images: {vertical_images}')\nprint(f'horizontal images: {horizontal_images}')\nprint(f'square images: {square_images}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}