{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-06-25T00:58:38.643652Z","iopub.execute_input":"2021-06-25T00:58:38.644108Z","iopub.status.idle":"2021-06-25T00:58:38.655871Z","shell.execute_reply.started":"2021-06-25T00:58:38.644Z","shell.execute_reply":"2021-06-25T00:58:38.654781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spam = pd.read_csv('../input/sms-spam-collection-dataset/spam.csv')\nspam.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T00:58:38.657487Z","iopub.execute_input":"2021-06-25T00:58:38.658052Z","iopub.status.idle":"2021-06-25T00:58:38.736262Z","shell.execute_reply.started":"2021-06-25T00:58:38.658007Z","shell.execute_reply":"2021-06-25T00:58:38.735196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spam.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T00:58:38.740767Z","iopub.execute_input":"2021-06-25T00:58:38.741283Z","iopub.status.idle":"2021-06-25T00:58:38.769096Z","shell.execute_reply.started":"2021-06-25T00:58:38.741226Z","shell.execute_reply":"2021-06-25T00:58:38.767864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new = spam[['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']].copy()\nna_string = '-'\nspam['v2'] = spam['v2'].str.cat(new, sep = \", \", na_rep = na_string)\nspam.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace = True)\nspam","metadata":{"execution":{"iopub.status.busy":"2021-06-25T00:58:38.771659Z","iopub.execute_input":"2021-06-25T00:58:38.772274Z","iopub.status.idle":"2021-06-25T00:58:38.801287Z","shell.execute_reply.started":"2021-06-25T00:58:38.772219Z","shell.execute_reply":"2021-06-25T00:58:38.800487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* I join all 3 unnamed columns into v2 because it's still contained with sentences.","metadata":{}},{"cell_type":"markdown","source":"# Text Pre-processing","metadata":{}},{"cell_type":"markdown","source":"### *Convert To Lower Case*","metadata":{}},{"cell_type":"code","source":"def to_lower(text):\n    return text.lower()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T00:58:38.815734Z","iopub.execute_input":"2021-06-25T00:58:38.816151Z","iopub.status.idle":"2021-06-25T00:58:38.824898Z","shell.execute_reply.started":"2021-06-25T00:58:38.816106Z","shell.execute_reply":"2021-06-25T00:58:38.823586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *Expand Contraction*","metadata":{}},{"cell_type":"code","source":"import re\ncontractions_dict = {     \n\"ain't\": \"am not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\", \"'cause\": \"because\",\n\"could've\": \"could have\", \"couldn't\": \"could not\", \"couldn't've\": \"could not have\", \"didn't\": \"did not\", \"doesn't\": \"does not\",\n\"don't\": \"do not\", \"hadn't\": \"had not\", \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n\"he'd\": \"he had\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \"he'll've\": \"he will have\", \"he's\": \"he is\",\n\"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"I'd\": \"I had\", \"I'd've\": \"I would have\",\n\"I'll\": \"I will\", \"I'll've\": \"I will have\", \"I'm\": \"I am\", \"I've\": \"I have\", \"isn't\": \"is not\", \"it'd\": \"it had\",\n\"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"iit will have\", \"it's\": \"it is\", \"let's\": \"let us\",\n\"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\", \"mightn't\": \"might not\", \"mightn't've\": \"might not have\",\n\"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she had\", \"she'd've\": \"she would have\", \"she'll\": \"she will\",\n\"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\", \"so've\": \"so have\", \"so's\": \"so is\", \"that'd\": \"that had\", \"that'd've\": \"that would have\",\n\"that's\": \"that is\", \"there'd\": \"there had\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"they'd\": \"they had\",\n\"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\",\n\"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we had\", \"we'd've\": \"we would have\",\n\"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\n\"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\",\n\"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\",\n\"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\",\n\"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\",\n\"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n\"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\", \"y'all've\": \"you all have\", \"you'd\": \"you had\",\n\"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"\n}\n\ndef expand_contraction(text, contraction_dict):\n    contraction_pattern= re.compile('({})'.format('|'.join(contraction_dict.keys())), flags= re.IGNORECASE | re.DOTALL)\n    \n    def expand_match(contraction):\n        match= contraction.group(0)\n        first_char= match[0]\n        expanded_contraction= contraction_dict.get(match) \\\n            if contraction_dict.get(match) \\\n            else contraction_dict.get(match.lower())\n        expanded_contraction= expanded_contraction\n        return expanded_contraction\n        \n    expanded_text= contraction_pattern.sub(expand_match, text)\n    expanded_text= re.sub(\"'\",\"\", expanded_text)\n    return expanded_text\n\ndef main_contraction(text):\n    text = expand_contraction(text, contractions_dict)\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-06-25T00:58:38.827108Z","iopub.execute_input":"2021-06-25T00:58:38.827578Z","iopub.status.idle":"2021-06-25T00:58:38.849188Z","shell.execute_reply.started":"2021-06-25T00:58:38.827528Z","shell.execute_reply":"2021-06-25T00:58:38.847698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *Remove or Convert Number*","metadata":{}},{"cell_type":"code","source":"def remove_number(text):\n    output = ''.join(c for c in text if not c.isdigit())\n    return output","metadata":{"execution":{"iopub.status.busy":"2021-06-25T00:58:38.851758Z","iopub.execute_input":"2021-06-25T00:58:38.852218Z","iopub.status.idle":"2021-06-25T00:58:38.865936Z","shell.execute_reply.started":"2021-06-25T00:58:38.852167Z","shell.execute_reply":"2021-06-25T00:58:38.864413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *Remove Punctuation*","metadata":{}},{"cell_type":"code","source":"from string import punctuation\ndef remove_punct(text):\n    return \"\".join(c for c in text if c not in punctuation)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T00:58:38.86778Z","iopub.execute_input":"2021-06-25T00:58:38.871547Z","iopub.status.idle":"2021-06-25T00:58:38.881361Z","shell.execute_reply.started":"2021-06-25T00:58:38.871403Z","shell.execute_reply":"2021-06-25T00:58:38.880064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *Remove WhiteSpaces*\n* I also remove a word that only has one letter.","metadata":{}},{"cell_type":"code","source":"def to_strip(text):\n    return \" \".join([c for c in text.split() if len(c)>1])","metadata":{"execution":{"iopub.status.busy":"2021-06-25T00:58:38.883191Z","iopub.execute_input":"2021-06-25T00:58:38.883691Z","iopub.status.idle":"2021-06-25T00:58:38.896615Z","shell.execute_reply.started":"2021-06-25T00:58:38.883642Z","shell.execute_reply":"2021-06-25T00:58:38.894958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *Remove Special Characters*\n* This regex expression states that match the text string for any alphabets from 'small a' to 'small z or 'capital A' to 'capital Z'. I remove spaces again using the \\s pattern, which refers to a single space.","metadata":{}},{"cell_type":"code","source":"def remove_char(text):\n    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-06-25T00:58:38.898827Z","iopub.execute_input":"2021-06-25T00:58:38.89938Z","iopub.status.idle":"2021-06-25T00:58:38.910475Z","shell.execute_reply.started":"2021-06-25T00:58:38.899334Z","shell.execute_reply":"2021-06-25T00:58:38.909202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *Remove Duplicates*\n* Removing multiple characters (duplicates) depends on the noise content in the dataset and it should be performed before removing stopwords. (.) match and capture any single character \\1{2,} then match the same character two or more times. The quantity \\1 represents the first capture group in sub.","metadata":{}},{"cell_type":"code","source":"def remove_duplicate(text):\n    text = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-06-25T00:58:38.91201Z","iopub.execute_input":"2021-06-25T00:58:38.91233Z","iopub.status.idle":"2021-06-25T00:58:38.924916Z","shell.execute_reply.started":"2021-06-25T00:58:38.912296Z","shell.execute_reply":"2021-06-25T00:58:38.923993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *Remove StopWords or Particular Words*","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nstopwords.words('english')\n\ndef remove_stopwords(text):\n    stop_words= stopwords.words('english')\n    \n    return ' '.join(c for c in nltk.word_tokenize(text) if c not in stop_words)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T00:58:38.926208Z","iopub.execute_input":"2021-06-25T00:58:38.926666Z","iopub.status.idle":"2021-06-25T00:58:40.664675Z","shell.execute_reply.started":"2021-06-25T00:58:38.92663Z","shell.execute_reply":"2021-06-25T00:58:40.663399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *Lemmatization*\n* Lemmatization usually refers to doing proper vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word. I prefer to use Lemmatization rather than Stemming in the text normalization process because Lemmatization considers the context and converts the word to its meaningful base form. Sometimes, the same word can have multiple different Lemma.","metadata":{}},{"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\n\nwordnet_lemma = WordNetLemmatizer()\n\ndef lemma(text):\n    lemmatize_words = [wordnet_lemma.lemmatize(word) for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n    return ' '.join(lemmatize_words)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T00:58:40.666284Z","iopub.execute_input":"2021-06-25T00:58:40.666681Z","iopub.status.idle":"2021-06-25T00:58:40.672384Z","shell.execute_reply.started":"2021-06-25T00:58:40.666646Z","shell.execute_reply":"2021-06-25T00:58:40.671135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Result From Text Pre-processing ","metadata":{}},{"cell_type":"code","source":"spam['prep1']= spam['v2'].apply(to_lower)\nspam['prep2']= spam['prep1'].apply(main_contraction)\nspam['prep3']= spam['prep2'].apply(remove_number)\nspam['prep4']= spam['prep3'].apply(remove_punct)\nspam['prep5']= spam['prep4'].apply(to_strip)\nspam['prep6']= spam['prep5'].apply(remove_char)\nspam['prep7']= spam['prep6'].apply(remove_duplicate)\nspam['prep8']= spam['prep7'].apply(remove_stopwords)\nspam['lemma'] = spam['prep8'].apply(lemma)\nspam","metadata":{"execution":{"iopub.status.busy":"2021-06-25T00:58:40.674004Z","iopub.execute_input":"2021-06-25T00:58:40.674629Z","iopub.status.idle":"2021-06-25T00:58:47.733172Z","shell.execute_reply.started":"2021-06-25T00:58:40.674572Z","shell.execute_reply":"2021-06-25T00:58:47.732102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Text Exploration","metadata":{}},{"cell_type":"markdown","source":"### *Length Of Sentence*\n* Identify if spam and ham text can differ in other content, such as length of text.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-06-25T01:00:02.017717Z","iopub.execute_input":"2021-06-25T01:00:02.018143Z","iopub.status.idle":"2021-06-25T01:00:02.114803Z","shell.execute_reply.started":"2021-06-25T01:00:02.018109Z","shell.execute_reply":"2021-06-25T01:00:02.113581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spam['length'] = spam['v2'].apply(len)\n\nplt.figure(figsize = (15, 6))\nspam0 = spam[spam['v1'] == 'ham']\nspam1 = spam[spam['v1'] == 'spam']\nsns.distplot(spam0['length'])\nsns.distplot(spam1['length'])\nplt.legend(['Ham', 'Spam'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T01:00:09.981625Z","iopub.execute_input":"2021-06-25T01:00:09.982055Z","iopub.status.idle":"2021-06-25T01:00:10.56309Z","shell.execute_reply.started":"2021-06-25T01:00:09.98202Z","shell.execute_reply":"2021-06-25T01:00:10.562255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spam['length'] = spam['v2'].apply(len)\n\nplt.figure(figsize = (15, 6))\nspam2= spam[spam['length']<200]\nspam0 = spam2[spam2['v1'] == 'ham']\nspam1 = spam2[spam2['v1'] == 'spam']\nsns.distplot(spam0['length'])\nsns.distplot(spam1['length'])\nplt.legend(['Ham', 'Spam'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T01:00:19.785795Z","iopub.execute_input":"2021-06-25T01:00:19.786346Z","iopub.status.idle":"2021-06-25T01:00:20.19634Z","shell.execute_reply.started":"2021-06-25T01:00:19.786297Z","shell.execute_reply":"2021-06-25T01:00:20.194775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* I try to see the differences in the length of words in every class. From the plots, I can conclude that Spam and Ham almost have an equal length, but the Spam density is higher than the Ham.","metadata":{}},{"cell_type":"markdown","source":"### *Words Frequency*\n* Can be used to check whether or not there are still words frequantly occur but not meaningful","metadata":{}},{"cell_type":"code","source":"def dictionary(check):\n    check = check.str.extractall('([a-zA_Z]+)')\n    check.columns = ['check']\n    b = check.reset_index(drop=True)\n    check = b['check'].value_counts()\n    \n    dictionary = pd.DataFrame({'word': check.index, 'freq': check.values})\n    dictionary.index = dictionary['word']\n    dictionary.drop('word', axis = 1, inplace=True)\n    dictionary.sort_values('freq', inplace= True, ascending= False)\n    \n    return dictionary\n\ndictionary_clean = dictionary(spam['lemma'])\ndictionary_clean[:20].plot(kind = 'barh',figsize = (10,10))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T01:00:51.159316Z","iopub.execute_input":"2021-06-25T01:00:51.159775Z","iopub.status.idle":"2021-06-25T01:00:51.629255Z","shell.execute_reply.started":"2021-06-25T01:00:51.159733Z","shell.execute_reply":"2021-06-25T01:00:51.62811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"### *Data Splitting*","metadata":{"execution":{"iopub.status.busy":"2021-06-25T01:01:16.673083Z","iopub.execute_input":"2021-06-25T01:01:16.673561Z","iopub.status.idle":"2021-06-25T01:01:16.678804Z","shell.execute_reply.started":"2021-06-25T01:01:16.673498Z","shell.execute_reply":"2021-06-25T01:01:16.677183Z"}}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-06-25T01:01:27.900588Z","iopub.execute_input":"2021-06-25T01:01:27.901047Z","iopub.status.idle":"2021-06-25T01:01:27.906094Z","shell.execute_reply.started":"2021-06-25T01:01:27.901004Z","shell.execute_reply":"2021-06-25T01:01:27.90479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The data is indicated for imbalanced but I decide not to process for further because the score is already higher.","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(spam['v1'].value_counts()/spam.shape[0]*100).round(2)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T01:01:34.841188Z","iopub.execute_input":"2021-06-25T01:01:34.84159Z","iopub.status.idle":"2021-06-25T01:01:34.858824Z","shell.execute_reply.started":"2021-06-25T01:01:34.841549Z","shell.execute_reply":"2021-06-25T01:01:34.857891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* *0 = Ham*\n* *1 = Spam*\n\n        - TN: SMS predict with Ham and the actual is Ham\n        - TP: SMS predict with Spam and the actual is Spam\n        - FP: SMS predict with Spam and the actual is Ham\n        - FN: SMS predict with Ham and the actual is Spam\n\nActions:\n* FN: The prediction is inaccurate. The spam SMS will be sent and the receiver will be annoyed because of that although it can be deleted manually.\n* FP: If ham SMS is important, it may be removed as spam based on the prediction.\n\n    -> Of all the results, the metric that I use to determine the score is using f1-score (f1) to anticipate error prediction.","metadata":{}},{"cell_type":"code","source":"text = spam['lemma']\ny = np.where(spam['v1'] == 'spam', 1, 0)\n\ntext.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-25T01:03:49.586128Z","iopub.execute_input":"2021-06-25T01:03:49.58667Z","iopub.status.idle":"2021-06-25T01:03:49.594357Z","shell.execute_reply.started":"2021-06-25T01:03:49.586618Z","shell.execute_reply":"2021-06-25T01:03:49.593607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_train, text_test, y_train, y_test = train_test_split(text, y, \n                                                          stratify = y, \n                                                          test_size = 0.3, \n                                                          random_state = 1672)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T01:04:00.279486Z","iopub.execute_input":"2021-06-25T01:04:00.280092Z","iopub.status.idle":"2021-06-25T01:04:00.292844Z","shell.execute_reply.started":"2021-06-25T01:04:00.280028Z","shell.execute_reply":"2021-06-25T01:04:00.291651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* I use 0.3 as test_size, which means 70% as train data and 30% as test data.","metadata":{}},{"cell_type":"markdown","source":"### *Define Model*\n* Most term frequency is not a good measure of the importance of a word/term to a document's topic. Very common words like \"the\", \"a\", \"to\" is almost always the terms with the highest frequency in the text. To circumvent the elimination of term-frequency, I normalize it by the inverse document frequency (IDF). The result of that is the TF-IDF matrix. The inverse document frequency is a measurement of how much information the word provides, that is, whether the term is common or rare across all documents in the corpus.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.metrics import classification_report, precision_score, accuracy_score, f1_score\nfrom sklearn.pipeline import Pipeline","metadata":{"execution":{"iopub.status.busy":"2021-06-25T01:04:38.004985Z","iopub.execute_input":"2021-06-25T01:04:38.005828Z","iopub.status.idle":"2021-06-25T01:04:38.16713Z","shell.execute_reply.started":"2021-06-25T01:04:38.005767Z","shell.execute_reply":"2021-06-25T01:04:38.166214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf = TfidfVectorizer(analyzer='word', stop_words='english', token_pattern=r'\\w{1,}')\nlogreg = LogisticRegression(random_state = 1672)\nbayes = MultinomialNB()\nlsvc = LinearSVC(random_state = 1672)\nrf = RandomForestClassifier(random_state = 1672)\n\nlogreg_pipe = Pipeline([('vector', tfidf), ('model', logreg)])\nbayes_pipe = Pipeline([('vector', tfidf), ('model', bayes)])\nlsvc_pipe = Pipeline([('vector', tfidf), ('model', lsvc)])\nrf_pipe = Pipeline([('vector', tfidf), ('model', rf)])\n\ndef model_evaluation(model, metric):\n    model_cv = cross_val_score(model, text_train, y_train, cv = StratifiedKFold(n_splits = 5), scoring = metric)\n    return model_cv\n\nlogreg_pipe_cv = model_evaluation(logreg_pipe, 'f1')\nbayes_pipe_cv = model_evaluation(bayes_pipe, 'f1')\nlsvc_pipe_cv = model_evaluation(lsvc_pipe, 'f1')\nrf_pipe_cv = model_evaluation(rf_pipe, 'f1')\n\nscore_cv = [logreg_pipe_cv.round(5), bayes_pipe_cv.round(5), lsvc_pipe_cv.round(5), rf_pipe_cv.round(5)]\nscore_mean = [logreg_pipe_cv.mean(), bayes_pipe_cv.mean(), lsvc_pipe_cv.mean(), rf_pipe_cv.mean()]\nscore_std = [logreg_pipe_cv.std(), bayes_pipe_cv.std(), lsvc_pipe_cv.std(), rf_pipe_cv.std()]\n\nfor model in [logreg_pipe, bayes_pipe, lsvc_pipe, rf_pipe]:\n    model.fit(text_train, y_train)\n\nscore_f1 = [f1_score(y_test, logreg_pipe.predict(text_test)),\n                  f1_score(y_test, bayes_pipe.predict(text_test)),\n                  f1_score(y_test, lsvc_pipe.predict(text_test)),\n                  f1_score(y_test, rf_pipe.predict(text_test))]\n\nmethod_name = ['Logistic Regression Tfidf Vectorizer', 'Multinomial Naive Bayes Tfidf Vectorizer',\n               'Linear SVC Tfidf Vectorizer', 'Random Forest Classifier Tfidf Vectorizer']\n\nsummary = pd.DataFrame({'method': method_name,\n                            'cv score': score_cv,\n                            'mean score': score_mean,\n                            'std score': score_std,\n                            'f1 score': score_f1})\nsummary","metadata":{"execution":{"iopub.status.busy":"2021-06-25T01:04:46.242724Z","iopub.execute_input":"2021-06-25T01:04:46.24352Z","iopub.status.idle":"2021-06-25T01:04:53.953346Z","shell.execute_reply.started":"2021-06-25T01:04:46.243464Z","shell.execute_reply":"2021-06-25T01:04:53.951747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* This is the score that I will use to continue the process. Based on the Linear SVC model with TF-IDF Vectorizer, it has the highest mean score, the std score is the lowest one meaning it's good, and also has the highest f1 score. Let's continue to see how the classification report supports this score.","metadata":{}},{"cell_type":"code","source":"for model, model_name in zip([logreg_pipe, bayes_pipe, lsvc_pipe, rf_pipe],\n                             ['Logistic Regression Tfidf Vectorizer', 'Multinomial Naive Bayes Tfidf Vectorizer',\n                              'Linear SVC Tfidf Vectorizer', 'Random Forest Classifier Tfidf Vectorizer']):\n    model.fit(text_train, y_train)\n    y_pred = model.predict(text_test)\n    print(model_name+ ':')\n    print(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T01:04:56.949576Z","iopub.execute_input":"2021-06-25T01:04:56.950164Z","iopub.status.idle":"2021-06-25T01:04:58.575949Z","shell.execute_reply.started":"2021-06-25T01:04:56.950125Z","shell.execute_reply":"2021-06-25T01:04:58.574646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The highest f1 score based on the classification report is the Linear SVM model with TF-IDF Vectorizer.","metadata":{}},{"cell_type":"markdown","source":"# HyperParameter Tuning","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2021-06-25T01:05:16.841355Z","iopub.execute_input":"2021-06-25T01:05:16.841743Z","iopub.status.idle":"2021-06-25T01:05:16.847082Z","shell.execute_reply.started":"2021-06-25T01:05:16.841708Z","shell.execute_reply":"2021-06-25T01:05:16.846178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* This is one way to improve the f1 score with tuning using Grid Search. I choose this library because Grid Search will give the best improvement score. In fact, Grid Search is heavy to run because it's working with the parameters one by one for each data.","metadata":{}},{"cell_type":"code","source":"lsvc_estimator = Pipeline([('vector', tfidf), ('model', lsvc)])\n\nhyperparam_space = {\n    'vector__analyzer': ['word', 'char','char_wb'],\n    'vector__max_features': [2000, 3000, 5000],\n    'model__C': [0.01, 0.1, 1, 10],\n    'model__multi_class': ['ovr', 'crammer_singer'],\n    'model__class_weight': ['dict', 'balanced'],\n    'model__random_state': [1672]\n}\n\ngrid = GridSearchCV(\n                lsvc_estimator,\n                param_grid = hyperparam_space,\n                cv = StratifiedKFold(n_splits = 5),\n                scoring = 'f1',\n                n_jobs = -1)\n\ngrid.fit(text_train, y_train)\n\nprint('best score', grid.best_score_)\nprint('best param', grid.best_params_)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T01:05:22.442259Z","iopub.execute_input":"2021-06-25T01:05:22.442895Z","iopub.status.idle":"2021-06-25T01:06:11.403728Z","shell.execute_reply.started":"2021-06-25T01:05:22.442858Z","shell.execute_reply":"2021-06-25T01:06:11.402475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* After the tuning process, the f1 score is decreasing.","metadata":{}},{"cell_type":"markdown","source":"# Result Comparison","metadata":{}},{"cell_type":"code","source":"lsvc_pipe.fit(text_train, y_train)\nf1_lsvc = (f1_score(y_test, lsvc_pipe.predict(text_test)))\n\ngrid.best_estimator_.fit(text_train, y_train)\nf1_grid = (f1_score(y_test, grid.predict(text_test)))\n\nscore_list = [f1_lsvc, f1_grid]\nmethod_name = ['Linear SVC Tfidf Vectorizer Before Tuning',\n               'Linear SVC Tfidf Vectorizer After Tuning']\nbest_summary = pd.DataFrame({\n    'method': method_name,\n    'score': score_list\n})\nbest_summary","metadata":{"execution":{"iopub.status.busy":"2021-06-25T01:06:11.405481Z","iopub.execute_input":"2021-06-25T01:06:11.40607Z","iopub.status.idle":"2021-06-25T01:06:11.665428Z","shell.execute_reply.started":"2021-06-25T01:06:11.406022Z","shell.execute_reply":"2021-06-25T01:06:11.664456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model, model_name in zip([lsvc_pipe, grid.best_estimator_],\n                             ['Linear SVC Tfidf Vectorizer Before Tuning',\n                              'Linear SVC Tfidf Vectorizer After Tuning']):\n    model.fit(text_train, y_train)\n    y_pred = model.predict(text_test)\n    print(model_name+ ':')\n    print(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T01:06:11.667193Z","iopub.execute_input":"2021-06-25T01:06:11.667529Z","iopub.status.idle":"2021-06-25T01:06:11.902626Z","shell.execute_reply.started":"2021-06-25T01:06:11.667468Z","shell.execute_reply":"2021-06-25T01:06:11.901094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The score is almost equal between before and after tuning. Still, the highest f1 score is the Linear SVC model with TF-IDF Vectorizer before Tuning.","metadata":{}},{"cell_type":"markdown","source":"# Prediction Testing","metadata":{}},{"cell_type":"code","source":"sms = [\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005.\",\n       \"Too late. I said i have the website. I didn't i have or dont have the slippers\",\n       \"Sir, i am waiting for your call, once free please call me.\",\n       \"how are you? I miss you!\"]","metadata":{"execution":{"iopub.status.busy":"2021-06-25T01:06:11.904409Z","iopub.execute_input":"2021-06-25T01:06:11.904745Z","iopub.status.idle":"2021-06-25T01:06:11.910043Z","shell.execute_reply.started":"2021-06-25T01:06:11.904715Z","shell.execute_reply":"2021-06-25T01:06:11.908654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = lsvc_pipe.predict(sms)\nresult = np.where(predictions == 1, 'Spam', 'Ham')\nresult","metadata":{"execution":{"iopub.status.busy":"2021-06-25T01:06:17.057878Z","iopub.execute_input":"2021-06-25T01:06:17.058306Z","iopub.status.idle":"2021-06-25T01:06:17.069083Z","shell.execute_reply.started":"2021-06-25T01:06:17.058269Z","shell.execute_reply":"2021-06-25T01:06:17.067621Z"},"trusted":true},"execution_count":null,"outputs":[]}]}