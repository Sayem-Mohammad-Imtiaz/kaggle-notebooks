{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](http://res.cloudinary.com/grohealth/image/upload/v1581692228/DCUK/Content/iStock-9217203841.jpg)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ndf = pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-21T06:41:51.712457Z","iopub.execute_input":"2021-07-21T06:41:51.713057Z","iopub.status.idle":"2021-07-21T06:41:51.759463Z","shell.execute_reply.started":"2021-07-21T06:41:51.712969Z","shell.execute_reply":"2021-07-21T06:41:51.758508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-21T06:41:52.180417Z","iopub.execute_input":"2021-07-21T06:41:52.180806Z","iopub.status.idle":"2021-07-21T06:41:52.205242Z","shell.execute_reply.started":"2021-07-21T06:41:52.180772Z","shell.execute_reply":"2021-07-21T06:41:52.204013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No Null values!\nShape is (768,9)","metadata":{}},{"cell_type":"code","source":"#Plot count of outcome variable\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nsns.countplot(x = \"Outcome\", data =df)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T06:41:52.289472Z","iopub.execute_input":"2021-07-21T06:41:52.289812Z","iopub.status.idle":"2021-07-21T06:41:53.2199Z","shell.execute_reply.started":"2021-07-21T06:41:52.289784Z","shell.execute_reply":"2021-07-21T06:41:53.218704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot pregnancies\n\nsns.countplot(x = \"Pregnancies\", data =df)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T06:41:53.221406Z","iopub.execute_input":"2021-07-21T06:41:53.221709Z","iopub.status.idle":"2021-07-21T06:41:53.449504Z","shell.execute_reply.started":"2021-07-21T06:41:53.221679Z","shell.execute_reply":"2021-07-21T06:41:53.44872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting correlation\nplt.figure(figsize = (12,6))  #figsize is made (12,6) so that there is no congestion/overlap of numbers\nsns.heatmap(df.corr(), annot = True) #annot true because we want the numbers on plots","metadata":{"execution":{"iopub.status.busy":"2021-07-21T06:41:53.453027Z","iopub.execute_input":"2021-07-21T06:41:53.453326Z","iopub.status.idle":"2021-07-21T06:41:54.123264Z","shell.execute_reply.started":"2021-07-21T06:41:53.4533Z","shell.execute_reply":"2021-07-21T06:41:54.122247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Age and pregnancies have strong correlation of about 0.54\n#### Outcome and glucose have a pretty good correlation, 0.47\n#### Insulin and skin thickness have a strong correlation of 0.44","metadata":{}},{"cell_type":"code","source":"df.Outcome.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-21T06:41:54.124948Z","iopub.execute_input":"2021-07-21T06:41:54.125346Z","iopub.status.idle":"2021-07-21T06:41:54.135462Z","shell.execute_reply.started":"2021-07-21T06:41:54.125304Z","shell.execute_reply":"2021-07-21T06:41:54.134488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is an imbalanced class, i.e for 1 (diabetes positive) there are only 268 values, whereas for 0 there are 500 values. So a balance is required or else the prediction will be biased towards 0 value.","metadata":{}},{"cell_type":"code","source":"zero  = df[df['Outcome']==0]   #zero values in outcome column\none = df[df['Outcome']==1]  # one values in outcome column\nfrom sklearn.utils import resample\n#minority class that 1, we need to upsample/increase that class so that there is no bias\n#n_samples = 500 means we want 500 sample of class 1, since there are 500 samples of class 0\ndf_minority_upsampled = resample(one, replace = True, n_samples = 500) \n#concatenate\ndf = pd.concat([zero, df_minority_upsampled])\n\nfrom sklearn.utils import shuffle\ndf = shuffle(df) # shuffling so that there is particular sequence","metadata":{"execution":{"iopub.status.busy":"2021-07-21T06:41:54.136709Z","iopub.execute_input":"2021-07-21T06:41:54.137156Z","iopub.status.idle":"2021-07-21T06:41:54.257249Z","shell.execute_reply.started":"2021-07-21T06:41:54.137123Z","shell.execute_reply":"2021-07-21T06:41:54.256561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.corr().abs()['Outcome'].sort_values(ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T06:41:54.258405Z","iopub.execute_input":"2021-07-21T06:41:54.259012Z","iopub.status.idle":"2021-07-21T06:41:54.268397Z","shell.execute_reply.started":"2021-07-21T06:41:54.258969Z","shell.execute_reply":"2021-07-21T06:41:54.267375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop(['Outcome'], axis = 1)\ny = df['Outcome']","metadata":{"execution":{"iopub.status.busy":"2021-07-21T06:41:54.271035Z","iopub.execute_input":"2021-07-21T06:41:54.271958Z","iopub.status.idle":"2021-07-21T06:41:54.277781Z","shell.execute_reply.started":"2021-07-21T06:41:54.27192Z","shell.execute_reply":"2021-07-21T06:41:54.27678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nfeatures= X.columns\nX[features] = sc.fit_transform(X[features])","metadata":{"execution":{"iopub.status.busy":"2021-07-21T06:41:54.279858Z","iopub.execute_input":"2021-07-21T06:41:54.28037Z","iopub.status.idle":"2021-07-21T06:41:54.441161Z","shell.execute_reply.started":"2021-07-21T06:41:54.280341Z","shell.execute_reply":"2021-07-21T06:41:54.44014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#all imports\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n","metadata":{"execution":{"iopub.status.busy":"2021-07-21T06:41:54.442812Z","iopub.execute_input":"2021-07-21T06:41:54.443173Z","iopub.status.idle":"2021-07-21T06:41:54.88505Z","shell.execute_reply.started":"2021-07-21T06:41:54.443135Z","shell.execute_reply":"2021-07-21T06:41:54.883843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.1)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T06:41:54.886276Z","iopub.execute_input":"2021-07-21T06:41:54.88654Z","iopub.status.idle":"2021-07-21T06:41:54.895438Z","shell.execute_reply.started":"2021-07-21T06:41:54.886515Z","shell.execute_reply":"2021-07-21T06:41:54.894369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = LogisticRegression(random_state=42)\n\nknn = KNeighborsClassifier()\n\ndt = DecisionTreeClassifier()\n\nrf = RandomForestClassifier()\n\ncb = CatBoostClassifier(loss_function='Logloss', verbose = 0)\n\npara_knn = {'n_neighbors':np.arange(2, 50)}  #parameters of knn\ngrid_knn = GridSearchCV(knn, param_grid=para_knn, cv=5) #grid search knn for 5 fold cross validation\n\n\n#parameters for decision tree\npara_dt = {'criterion':['gini','entropy'],'max_depth':np.arange(1, 50), 'min_samples_leaf':[1,2,4,5,10,20,30,40,80,100]}\ngrid_dt = GridSearchCV(dt, param_grid=para_dt, cv=5) #grid search decision tree for 5 fold cv\n#\"gini\" for the Gini impurity and “entropy” for the information gain.\n#min_samples_leaf: The minimum number of samples required to be at a leaf node, have the effect of smoothing the model\n\n#parameters for random forest\n#n_estimators: The number of trees in the forest.\nparams_rf = {'n_estimators':[100, 350, 500], 'min_samples_leaf':[2, 10, 30]}\ngrid_rf = GridSearchCV(rf, param_grid=params_rf, cv=5)\n\n\nparams_cb = {'learning_rate': [0.03, 0.1], 'depth': [4, 6, 10], 'l2_leaf_reg': [1, 3, 5, 7, 9]}\nrs_cb = RandomizedSearchCV(cb, param_distributions=params_cb, n_iter=5, scoring='roc_auc', n_jobs=4, cv=3)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T06:41:54.896887Z","iopub.execute_input":"2021-07-21T06:41:54.897247Z","iopub.status.idle":"2021-07-21T06:41:54.913269Z","shell.execute_reply.started":"2021-07-21T06:41:54.897215Z","shell.execute_reply":"2021-07-21T06:41:54.912477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#getting the best parametrs\ngrid_knn.fit(X_train, y_train)\ngrid_dt.fit(X_train, y_train)\ngrid_rf.fit(X_train, y_train)\nrs_cb.fit(X_train, y_train) \n\n\nprint(\"Best parameters for KNN:\", grid_knn.best_params_)\nprint(\"Best parameters for Decision Tree:\", grid_dt.best_params_)\nprint(\"Best parameters for Random Forest:\", grid_rf.best_params_)\nprint(\"Best parameters for CatBoost:\", rs_cb.best_params_)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-21T06:41:54.914348Z","iopub.execute_input":"2021-07-21T06:41:54.914784Z","iopub.status.idle":"2021-07-21T06:43:57.453536Z","shell.execute_reply.started":"2021-07-21T06:41:54.914725Z","shell.execute_reply":"2021-07-21T06:43:57.452598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dt = DecisionTreeClassifier(criterion='entropy', max_depth=28, min_samples_leaf=1, random_state=42)\nknn = KNeighborsClassifier(n_neighbors=3)\nrf = RandomForestClassifier(n_estimators=350, min_samples_leaf=2, random_state=42)\ncb = CatBoostClassifier(learning_rate = 0.03, l2_leaf_reg = 7, depth = 10, loss_function = 'Logloss', verbose = 0)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T06:43:57.455037Z","iopub.execute_input":"2021-07-21T06:43:57.455501Z","iopub.status.idle":"2021-07-21T06:43:57.460419Z","shell.execute_reply.started":"2021-07-21T06:43:57.45545Z","shell.execute_reply":"2021-07-21T06:43:57.459778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn),\n               ('Decision Tree', dt), ('Random Forest', rf), ('CatBoost', cb)]\n\nfor classifier_name, classifier in classifiers:\n \n    # Fit clf to the training set\n    classifier.fit(X_train, y_train)    \n   \n    # Predict y_pred\n    y_pred = classifier.predict(X_test)\n    accuracy = accuracy_score(y_test,y_pred)\n    \n\n   \n    # Evaluate clf's accuracy on the test set\n    print('{:s} : {:.1f}'.format(classifier_name, accuracy))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-21T06:43:57.461483Z","iopub.execute_input":"2021-07-21T06:43:57.461778Z","iopub.status.idle":"2021-07-21T06:44:07.129406Z","shell.execute_reply.started":"2021-07-21T06:43:57.461751Z","shell.execute_reply":"2021-07-21T06:44:07.128306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Catboost is the best performing model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ny_pred_cb= cb.predict(X_test)\nprint(classification_report(y_test, y_pred_cb))","metadata":{"execution":{"iopub.status.busy":"2021-07-21T06:44:07.130995Z","iopub.execute_input":"2021-07-21T06:44:07.13142Z","iopub.status.idle":"2021-07-21T06:44:07.14769Z","shell.execute_reply.started":"2021-07-21T06:44:07.131377Z","shell.execute_reply":"2021-07-21T06:44:07.14664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#XGBoost\nfrom xgboost import XGBClassifier\nmodel= XGBClassifier(n_estimators = 1000,learning_rate = 0.06,max_depth=29,\n                     max_leaves = 31,eval_metric = 'logloss', use_label_encoder = False,\n                     verbosity = 0)\nmodel.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T06:44:07.148932Z","iopub.execute_input":"2021-07-21T06:44:07.149208Z","iopub.status.idle":"2021-07-21T06:44:08.135248Z","shell.execute_reply.started":"2021-07-21T06:44:07.149181Z","shell.execute_reply":"2021-07-21T06:44:08.133927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_xgb = model.predict(X_test)\naccuracy_score(y_test, pred_xgb)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T06:44:08.136753Z","iopub.execute_input":"2021-07-21T06:44:08.137046Z","iopub.status.idle":"2021-07-21T06:44:08.15972Z","shell.execute_reply.started":"2021-07-21T06:44:08.137018Z","shell.execute_reply":"2021-07-21T06:44:08.156123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Catboost performed better than XGBoost","metadata":{}},{"cell_type":"markdown","source":"## Upvote if you like it or fork it :)","metadata":{}}]}