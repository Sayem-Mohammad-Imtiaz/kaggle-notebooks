{"cells":[{"metadata":{},"cell_type":"markdown","source":"This kernel explores about regression and different ways you can improve its accuracy. We're going to try different regression algorithms such as Linear, Lasso, Ridge, and Support Vector Regression. We'll also explore boosting and stacking methods."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom sklearn.svm import SVR\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import GradientBoostingRegressor, StackingRegressor\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As usual, we double check where are our input data is.."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!ls ../input/insurance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"insurance = pd.read_csv('../input/insurance/insurance.csv')\ninsurance.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"insurance.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice that sex and smoker are categorical features with 2 different values each? Let's convert them to a numerical feature--to be specific boolean values. Using the map function, we'll set these values:\n\n- Male = 0; Female = 1\n- Non-somker = 0; Smoker = 1\n\nThen double check if it was indeed converted."},{"metadata":{"trusted":true},"cell_type":"code","source":"insurance['sex'] = insurance['sex'].map({'male': 0, 'female': 1})\ninsurance['smoker'] = insurance['smoker'].map({'yes': 1, 'no': 0})\ninsurance.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"insurance.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next is we check for missing values.."},{"metadata":{"trusted":true},"cell_type":"code","source":"insurance.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So thankfully we didn't have any missing values. If you do encounter however, you have to fix them. You can look at a sample in one of my kernels [here](https://www.kaggle.com/danaelisanicolas/data-cleaning) with how I dealt with this scenario.\n\nNext is we check the correlation of the features."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(insurance.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we know that smoking is the feature who has the most effect on the charges. Followed by age and bmi. Now, notice we're missing region at the heatmap? It's because it's a categorical feature. We can try to convert it to numerical to see if, in our case, affects the charges of each customer.\n\nFirst we check for unique values. We can use pandas unique() function to see this."},{"metadata":{"trusted":true},"cell_type":"code","source":"insurance['region'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we have 4 unique values. We can't easily convert this to boolean obviously. So we use dummy variables. Fortunately, pandas has their get_dummies function so we can do this easily."},{"metadata":{"trusted":true},"cell_type":"code","source":"region = pd.get_dummies(insurance['region'])\nregion.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So now we see northeast, northwest, southeast, and southwest as new columns. It is set to 1 if the specific customer is living in that region. 0 for others. Anyway, since region is on a different dataframe, let's merge it with our original insurance dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"insurance.drop(['region'], axis=1, inplace=True)\ninsurance = pd.merge(insurance, region, on=insurance.index)\ninsurance.drop(['key_0'], axis=1, inplace=True)\ninsurance.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And actually check if region does affect charges."},{"metadata":{"trusted":true},"cell_type":"code","source":"_, ax = plt.subplots(figsize=(10,8))\nsns.heatmap(insurance.corr(), annot=True, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So apparently it does not affect charges at all. Negligible if I may add. So let's just drop it altogether."},{"metadata":{"trusted":true},"cell_type":"code","source":"insurance.drop(['northeast', 'northwest', 'southeast', 'southwest'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And now, let's check the distribution of our data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"insurance['charges'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(insurance['charges'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obviously, our data is not a normal distribution at all. Another thing I should note is that the charges' range are too big. It'll be hard for us to interpret the our models later once we create and fit them.\n\nJust for the purpose of showing let's NOT normalise and transform it. I'll show you what I'm talking about. \n\nFirst, let's just select the highly correlated features which are age, bmi, and if the person is a smoker. Set it as x, then our target which is charges (it's what we're trying to predict after all) is set as y."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature Selection\n#3 features vs all\n\nx = insurance[['age', 'bmi', 'smoker']]\n\ny = insurance['charges']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create our train and test variables using the train_test_split function of scikit-learn. I will be using a test_size of 0.2 because I want a 80-20 split of my train and test. And I will also set the random state for reproducibility."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then create our basic Linear Regression model (without any hyperparameters) and fit our train data. Once fitted, we get y prediction using the x test variable and now compare it with the actual y test. In short, fit with train, and check with the test."},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_model = LinearRegression()\nlr_model.fit(x_train, y_train)\ny_pred = lr_model.predict(x_test)\nprint('r2 score: ' + str(metrics.r2_score(y_test, y_pred)))\nprint('mse: ' + str(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's try if using all features will make a difference. So set our x to all features (removing the target variable of course). Then just repeat what we did above."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = insurance.drop(['charges'], axis=1)\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_model = LinearRegression()\nlr_model.fit(x_train, y_train)\ny_pred = lr_model.predict(x_test)\nprint('r2 score: ' + str(metrics.r2_score(y_test, y_pred)))\nprint('mse: ' + str(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now here's the thing, the MSE scores is waaaay high. How does that even mean? How can we interpret it now. We know that MSE says how far you are with the actual value. In both ways we are getting 35M MSE which means we are 35M away from actual value. However relatively, how far are we? Now we scale the values so we will know.\n\nSo the idea of normalising data is to make it a gaussian curve or what statisticians usually call a normal distribution. It looks like a bell shape. Look at the original charges distribution vs the transformed charges distribution that I will show next:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(insurance['charges'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gaussian curve\ntransformed_charges = np.log(insurance['charges'])\nsns.distplot(transformed_charges)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"See the difference? The 1st one tends to lean on the left side of the graph. After normalising, we see it now as a bell shape. Might not be perfect one but still fairly distributed. And how does the values look like? Let's look at the head of the normalised values."},{"metadata":{"trusted":true},"cell_type":"code","source":"transformed_charges.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So basically it's scaled down having values that range from 5-ish to 12. \n\nNow in that scenario we used np.log in normalising the values of the charges. However there's what we call StandardScaler which can do it for our whole data."},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(insurance)\ninsurance_normed = pd.DataFrame(scaler.transform(insurance), columns=insurance.columns)\ninsurance_normed.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So now we can compare it to our original data and the normalised one."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(insurance)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(insurance_normed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And do the fitting.."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = insurance_normed.drop(['charges'], axis=1)\ny = insurance_normed['charges']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_model = LinearRegression()\nlr_model.fit(x_train, y_train)\ny_pred = lr_model.predict(x_test)\nprint('r2 score: ' + str(metrics.r2_score(y_test, y_pred)))\nprint('mse: ' + str(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now the MSE looks better right? And much more readable. It means we are 0.24 away from our actual values. As MSE is much closer to 0 then that means we are much closer to the actual values.\n\nNow that's just the basic Linear Regression. Let's try exploring our regression models. Looking at SVR, Ridge, and Lasso."},{"metadata":{"trusted":true},"cell_type":"code","source":"s_model = SVR(kernel='linear')\ns_model.fit(x_train, y_train)\ny_pred = s_model.predict(x_test)\nprint('r2 score: ' + str(metrics.r2_score(y_test, y_pred)))\nprint('mse: ' + str(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rd_model = Ridge()\nrd_model.fit(x_train, y_train)\ny_pred = rd_model.predict(x_test)\nprint('r2 score: ' + str(metrics.r2_score(y_test, y_pred)))\nprint('mse: ' + str(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls_model = Lasso()\nls_model.fit(x_train, y_train)\ny_pred = ls_model.predict(x_test)\nprint('r2 score: ' + str(metrics.r2_score(y_test, y_pred)))\nprint('mse: ' + str(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So apparently even with other models, Linear Regression is still the best one we have so far. We can try fine tuning our model by trying out different hyper parameters.\n\nBut what if there's an algorithm that can try and find the best hyperparameters for us? Well, fortunately there is. There's what we call GridSearchCV. You can just list the range of hyperparameters and its values and feed it to GSC. We also need to feed which model and what scoring system will we check for best params.\n\nUnfortunately Linear Regression has limited paramteres. Let's try using GSC in our SVR model since the result is fairly similar to our Linear Regression model."},{"metadata":{"trusted":true},"cell_type":"code","source":"#GridSearch\n#Linear Regression\n\nparameters = {\n    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n    'tol': [0.001, 0.01, 0.1, 1]\n}\n\ns_model = SVR()\ns_regressor = GridSearchCV(s_model, param_grid=parameters, scoring='neg_mean_squared_error')\ngrid_result = s_regressor.fit(x_train, y_train)\nprint(grid_result.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So GSC says our hyperparameters are\n- C = 10\n- kernel = 'rbf'\n- tol = 0.001\n\nSo let's do that and check our accuracy and MSE"},{"metadata":{"trusted":true},"cell_type":"code","source":"s_model = SVR(C=10, gamma='scale', kernel='rbf', tol=0.001)\ns_model.fit(x_train, y_train)\ny_pred = s_model.predict(x_test)\nprint('r2 score: ' + str(metrics.r2_score(y_test, y_pred)))\nprint('mse: ' + str(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nice. So from 70% awhile ago with SVR, we got +17% accuracy from using the best hyperparameters that GSC told us. MSE is also from 0.30 to 0.13.\n\nNow the next thing that we'll try is what we call Boosting. Basically the idea here is to permutate different kinds of combination of data and split then whatever is kind of the 'majority vote' of these splits and permutations, that will be the fit. I'll be using GradientBoostingRegressor for this."},{"metadata":{"trusted":true},"cell_type":"code","source":"gbr_model = GradientBoostingRegressor(n_estimators=3, max_depth=3, learning_rate=1, criterion='mse', random_state=1)\ngbr_model.fit(x_train, y_train)\ny_pred = gbr_model.predict(x_test)\nprint('r2 score: ' + str(metrics.r2_score(y_test, y_pred)))\nprint('mse: ' + str(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Okay so.. SVR with best hyperparams is still our best bet then. But not by far.\n\nNext is we'll try doing what we call stacking. Stacking is basically having different models (regression for this scenario) and fit it to those models. Then whatever is the result or the y_pred of those models will be our new data. Then using the new data we'll fit and train it using the final model or what we call the final estimator. For this, I'll be using GradientBoostingRegressor as my final estimator, and Ridge, Lasso, SVR, and Linear Regression will be my models."},{"metadata":{"trusted":true},"cell_type":"code","source":"estimators = [('ridge', Ridge()),\n              ('lasso', Lasso()),\n              ('svr', SVR()),\n              ('lr', LinearRegression())]\nreg = StackingRegressor(\n    estimators=estimators,\n    final_estimator=GradientBoostingRegressor())\nreg.fit(x_train, y_train)\ny_pred = reg.predict(x_test)\nprint('r2 score: ' + str(metrics.r2_score(y_test, y_pred)))\nprint('mse: ' + str(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So there!\n\nI've shown you different ways of doing regression models. Now for the final step in reporting back to your stakeholders, you should return your scaled data to the original data to get the actual predictions. I might do that on the next commit.\n\nOtherwise if this kernel helped you in anyway, you can help others see this kernel as well by giving an upvote! Thanks!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}