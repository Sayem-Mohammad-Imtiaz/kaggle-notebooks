{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Fake News or Real News\n\n---\n\n## Load in our data","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"true = pd.read_csv('./data/true.csv')\ntrue.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"true.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Finding distribution of title word counts","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"true['title_word_count'] = true['title'].map(lambda x: len(x.split(' ')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.hist(true['title_word_count'], bins = 15, color = 'g')\nplt.title('Distribution of Title Word Counts for Real News')\nplt.xlabel('Word Count')\nplt.ylabel('Number of Titles');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fake = pd.read_csv('./data/fake.csv')\nfake.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fake.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fake['title_word_count'] = fake['title'].map(lambda x: len(x.split(' ')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.hist(fake['title_word_count'], bins = 15, color = 'salmon')\nplt.title('Distribution of Title Word Counts for Fake News')\nplt.xlabel('Word Count')\nplt.ylabel('Number of Titles');","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def most_freq(df):\n    cvec = CountVectorizer(stop_words = 'english')\n    cvec.fit(df['title'])\n    X_train = cvec.transform(df['title'])\n    X_train_df = pd.DataFrame(X_train.toarray(),\n                              columns=cvec.get_feature_names())\n    top_words = {}\n    for i in X_train_df.columns:\n        top_words[i] =  X_train_df[i].sum()\n    return pd.DataFrame(sorted(top_words.items(), key = lambda x: x[1], reverse = True)).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"common_true = most_freq(true)\ncommon_true","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"common_fake = most_freq(fake)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# code inspired by 4.05 classification metrics\n\nplt.figure(figsize = (10, 7))\n\nplt.bar(x = common_true[0],\n        height = common_true[1],\n        color = 'g',\n        alpha = 0.6,\n        label = 'Real news')\nplt.bar(x = common_fake[0],\n        height = common_fake[1],\n        color = 'salmon',\n        alpha = 0.6,\n        label = 'Fake news')\n\nplt.xticks(rotation=45)\nplt.ylabel('Word Count')\nplt.xlabel('Words')\nplt.title('Common Words Used in Real and Fake News', fontsize=18)\n\nplt.legend(fontsize=14);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Concat the two dataframes","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"true['category'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fake['category'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = pd.concat([true, fake])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data cleaning","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df = df.loc[df['date']!= 'https://100percentfedup.com/served-roy-moore-vietnamletter-veteran-sets-record-straight-honorable-decent-respectable-patriotic-commander-soldier/',]\ndf = df.loc[df['date']!= 'https://100percentfedup.com/video-hillary-asked-about-trump-i-just-want-to-eat-some-pie/']\ndf = df.loc[df['date']!= 'https://100percentfedup.com/12-yr-old-black-conservative-whose-video-to-obama-went-viral-do-you-really-love-america-receives-death-threats-from-left/']\ndf = df.loc[df['date']!= 'https://fedup.wpengine.com/wp-content/uploads/2015/04/hillarystreetart.jpg']\ndf = df.loc[df['date']!= 'https://fedup.wpengine.com/wp-content/uploads/2015/04/entitled.jpg']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Dropped a row with a 'date' url\ndf.drop([18933], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Converted 'date' to a datetime pandas format\ndf['date'] = pd.to_datetime(df['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Created another column for weekday\ndf['weekday'] = df['date'].dt.weekday","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train, test, split","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"X = df['title']\ny = df['category']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train.shape, y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_test.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_test.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model #1\n\n- `PorterStemmer()` and `CountVectorizer()`\n- `LogisticRegression()`\n\n`PorterStemmer` code based on [StackOverflow](https://stackoverflow.com/questions/36182502/add-stemming-support-to-countvectorizer-sklearn) question.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"stemmer = PorterStemmer()\nanalyzer = CountVectorizer().build_analyzer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def porter(text):\n    return(stemmer.stem(w) for w in analyzer(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pipe = Pipeline([\n    ('cvec', CountVectorizer(analyzer=porter, stop_words='english')),\n    ('logreg', LogisticRegression(max_iter=1000, solver='liblinear'))\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pipe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pipe.score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pipe.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model #2\n\n- No `PorterStemmer()`","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"pipe = Pipeline([\n    ('cvec', CountVectorizer(stop_words='english')),\n    ('logreg', LogisticRegression(max_iter=1000))\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pipe.fit(X_train, y_train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pipe.score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pipe.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model #3\n\nLucas's code\n\n- `TfidfVectorizer()`\n- `LogisticRegression()`","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"pipe = Pipeline([\n    ('tfidf', TfidfVectorizer()),\n    ('logreg', LogisticRegression(solver = 'liblinear', random_state=42))\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pipe_params = {\n    'tfidf__ngram_range': [(1,2)],\n    'tfidf__stop_words': ['english'],    \n    'logreg__penalty': [ 'l2'],\n    'logreg__C': [ 10],\n    'logreg__max_iter' : [ 1000]\n    \n}\n\ngs = GridSearchCV(pipe,\n                  param_grid = pipe_params,\n                  cv=5,\n                  scoring = 'accuracy',\n                  verbose = 1)\n\ngs.fit(X_train, y_train)\n\nprint(f'Best cross validation score: {gs.best_score_}')\nprint(f'Best parameters to use: {gs.best_params_}')\nprint(f'Testing score: {gs.score(X_test, y_test)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model #4\n\n- `PorterStemmer()`\n- `TfidfVectorizer()`\n- `LogisticRegression()`","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"stemmer = PorterStemmer()\nanalyzer = TfidfVectorizer().build_analyzer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def porter(text):\n    return(stemmer.stem(w) for w in analyzer(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pipe = Pipeline([\n    ('tfidf', TfidfVectorizer(analyzer=porter)),\n    ('logreg', LogisticRegression(solver = 'liblinear'))\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pipe_params = {\n    'tfidf__stop_words': ['english', None],\n    'tfidf__max_features': [12_000],\n    'tfidf__ngram_range': [(1, 2)],\n    'logreg__penalty': ['l2'],\n    'logreg__C': [15],\n    'logreg__max_iter' : [1000]\n    \n}\n\ngs = GridSearchCV(pipe,\n                  param_grid = pipe_params,\n                  cv=5,\n                  scoring = 'accuracy',\n                  verbose = 1)\n\ngs.fit(X_train, y_train)\n\nprint(f'Best cross validation score: {gs.best_score_}')\nprint(f'Best parameters to use: {gs.best_params_}')\nprint(f'Testing score: {gs.score(X_test, y_test)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model #5\n\n- `PorterStemmer()`\n- `TfidfVectorizer()`\n- `RandomForestClassifier()`","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"pipe = Pipeline([\n    ('tfidf', TfidfVectorizer(analyzer=porter)),\n    ('rf', RandomForestClassifier(random_state = 42))\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"params = {\n    'rf__n_estimators': [100],\n    'rf__max_depth': [None, 1, 2],\n    'rf__max_features': ['auto', 'log2']\n}\n\ngs = GridSearchCV(pipe,\n                  param_grid=params,\n                  cv=2,\n                  scoring='accuracy',\n                  verbose=1)\n\ngs.fit(X_train, y_train)\n\nprint(f'Best cross validation score: {gs.best_score_}')\nprint(f'Best parameters to use: {gs.best_params_}')\nprint(f'Testing score: {gs.score(X_test, y_test)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Results\n\n| Estimators/Classifiers | Model 1 | Model 2 | Model 3 | Model 4 | Model 5 |\n|-|:-:|:-:|:-:|:-:|:-:|\n| `PorterStemmer()` | X |  |  | X | X |\n| `CountVectorizer()` | X | X |  |  |  |\n| `TfidfVectorizer()` |  |  | X | X | X |\n| `LogisticRegression()` | X | X | X | X |  |\n| `RandomForestClassifier()` |  |  |  |  | X |\n| Train Score: | 0.9849 | 0.9840 | 0.9505 | 0.9563 | 0.9504 |\n| Test Score: | **0.9660** | 0.9529 | 0.9588 | 0.9643 | 0.9623 |\n\n**Hyperparameters used in best score:**\n\n| Estimator/Transformer | Hyperparameter | Set to: |\n|-|-|-|\n| `CountVectorizer()` | `stop_words` | `english` |\n| `LogisticRegression()` | `max_iter` | 1000 |\n| `LogisticRegression()` | `solver` | `liblinear` |","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}