{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#1.kutuphaneler\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\nfrom sklearn import linear_model, tree, ensemble\nfrom pandas.plotting import scatter_matrix\nfrom sklearn import model_selection\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n#2.veri onisleme\n#2.1.veri yukleme\nveriler = pd.read_csv('../input/wine-customer-segmentation/Wine.csv')\n\n\nprint(veriler)\n#box graph\n#plt kısaltması matplotlib kütüphanesinin kısaltması olarak kullanılır.\n#subplot: grafiklerin düzlemini ve kaçıncı grafik olduğunu gösterir.\nveriler.plot(kind=\"box\",subplots=True, sharex=False, sharey=False)\nplt.show()\n\n#histogram\nveriler.hist()\nplt.show()\n\nscatter_matrix(veriler)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Veriyi eğitim ve test olarak ayıracağım.\n# train/test\n#eğitim ve test olarak ayırmak için genel yaklaşım: %70-80 eğitim, %30-20 test \n\nX=veriler.values[:,0:4]\nY=veriler.values[:,4]\n\nX_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.25, random_state=7)\nprint(\"veri seti:\")\nprint(veriler)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LOGISTIC REGRESSION"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lojistik regresyon, ikili sonuç veren binary değişkenlerin modellenmesinde kullanılmaktadır\n\n\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\n#Yukarıda gördüğünüz kod FutureWarning hatası için kullanıldı.\n\n\nfrom sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()\nlr.fit(X_train,Y_train)\n#Accuracy(Doğruluk): Sistemde doğru olarak yapılan tahminlerin tüm tahminlere oranıdır. \nprint('lr accuracy :', lr.score(X_test,Y_test))\n\n# confusion matrix\n#Modelin başarı metrikleri: Confusion matrix\n#Hata Matrisi ( Confusion Matrix) makine öğrenmesinde kullandığımız sınıflandırma modelinin performansını hesaplarken kullanılıyor.\n#Burada True Positive-TP , True Negative-TN, False Positive – FP ve False Negative-FN isminde kavramlar var.\n#Eğer sonucu doğru olan bir şey doğru tahmin edilirse True Positive olarak adlandırılıken sonucu yanlış olan bir şey doğru olarak tahmin edilirse buna True Negative deniliyor. \n#Aynı şekilde sonucu yanlış olan bir şey doğru olarak tahmin edilirse False Positive, sonucu yanlış olan bir şey yanlış olarak tahmin edilirse False negative deniliyor.\ny_pred = lr.predict(X_test)\ny_true = Y_test\nfrom sklearn.metrics import confusion_matrix\n\ncm_lr = confusion_matrix(y_true,y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"K-Nearest Neighbors"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier(n_neighbors=3)\n#n_neighbors=3 (En yakın 3 komşu içerisindeki yoğunluğa göre karar verecek) \nknn.fit(X_train,Y_train)\nprint('knn accuracy :',knn.score(X_test,Y_test))\n\n# confisioun matrix\n#Modelin başarı metrikleri: Confusion matrix\ny_pred = knn.predict(X_test)\ny_true = Y_test\n\nfrom sklearn.metrics import confusion_matrix\ncm_knn = confusion_matrix(y_true,y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find best k value"},{"metadata":{"trusted":true},"cell_type":"code","source":"score_list=[]\nfor each in range(1,15):\n    knn2=KNeighborsClassifier(n_neighbors=each)\n    knn2.fit(X_train,Y_train)\n    score_list.append(knn2.score(X_test,Y_test))\n#Accuracy(Doğruluk): Sistemde doğru olarak yapılan tahminlerin tüm tahminlere oranıdır. \nprint('bk accuracy :', knn2.score(X_test,Y_test))\nplt.plot(range(1,15),score_list)\nplt.xlabel('k values')\nplt.ylabel('accuracy')\nplt.show()\n\n# confisioun matrix\n#Modelin başarı metrikleri: Confusion matrix\ny_pred = knn2.predict(X_test)\ny_true = Y_test\n\nfrom sklearn.metrics import confusion_matrix\ncm_knn2 = confusion_matrix(y_true,y_pred)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm=SVC(random_state=1)\nsvm.fit(X_train,Y_train)\n#Accuracy(Doğruluk): Sistemde doğru olarak yapılan tahminlerin tüm tahminlere oranıdır. \nprint('svm accuracy :', svm.score(X_test,Y_test))\n\n# confisuon matrix\ny_pred = svm.predict(X_test)\ny_true = Y_test\nfrom sklearn.metrics import confusion_matrix\n\ncm_svm = confusion_matrix(y_true,y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb=GaussianNB()\nnb.fit(X_train,Y_train)\n#Accuracy(Doğruluk): Sistemde doğru olarak yapılan tahminlerin tüm tahminlere oranıdır. \nprint('nb accuracy : ', nb.score(X_test,Y_test))\n\n# confisuon matrix\ny_pred = nb.predict(X_test)\ny_true = Y_test\nfrom sklearn.metrics import confusion_matrix\n\ncm_nb = confusion_matrix(y_true,y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt=DecisionTreeClassifier()\ndt.fit(X_train,Y_train)\n#Accuracy(Doğruluk): Sistemde doğru olarak yapılan tahminlerin tüm tahminlere oranıdır. \nprint('dt.accuracy : ', nb.score(X_test,Y_test))\n\n# confisuon matrix\ny_pred = dt.predict(X_test)\ny_true = Y_test\nfrom sklearn.metrics import confusion_matrix\n\ncm_dt = confusion_matrix(y_true,y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Simdi az once uyguladigim modelleri cross-validation ile uygulayip gorelim."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n\n\nwine_dataset = pd.read_csv(\"../input/wine-customer-segmentation/Wine.csv\")\n\nx=wine_dataset.values[:,0:4]\ny=wine_dataset.values[:,4]\n\nX_train, X_test, Y_train, Y_test = model_selection.train_test_split(x, y, test_size=0.25, random_state=7)\n\n#uygulanacak modelleri models içine koydum.\nmodels=[\n    (\"lR\", LogisticRegression()),\n    (\"KNN\",KNeighborsClassifier()),\n    (\"KN\",KNeighborsClassifier()),\n    (\"SVM\",SVC()),\n    (\"Naive Bayes\",GaussianNB()),\n    (\"DT\",DecisionTreeClassifier()),\n]\nresults=[]\nnames=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\n#Yukarıda gördüğünüz kod FutureWarning hatası için kullanıldı.\n\n\n\n\n#K herhangi bir sayı olabilir, ancak genellikle K = 10 önerilir\n#Dengesiz bir veri kümesiyle uğraşıyorsanız, tahmin edilen özelliklerin sınıflarını dengeleyebilir.\n#Hiperparametre Ayarı: Çapraz Doğrulama, algoritmanın verimliliğini artırmak için hiperparametrelerin optimum değerini bulmaya yardımcı olur\n\nfor name,model in models:\n    kfold=model_selection.KFold(n_splits=10,random_state=7)\n    cv_results=model_selection.cross_val_score(model,X_train,Y_train,cv=kfold,scoring=\"accuracy\")\n    results.append(cv_results)\n    names.append(name)\n    print(\"%s: %f (%f)\" %(name, cv_results.mean(), cv_results.std()))\n   \n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NEDEN CROSS-VALIDATION KULLANMALIYIZ?\n\nÇapraz doğrulama (cross-validation) ise parametre ayarlama sırasında eğitim setinin her seferinde farklı bir kısmı ile doğrulama yapma işlemine denir. Örnek ile açıklamak gerekirse, veri setinin seçilen orandaki kısmı test seti olarak ayrıldıktan sonra kalan kısmın ilk %25’lik kısmını ilk model eğitiminde, ikinci %25’lik kısmını ikinci model eğitiminde… şeklinde sırası ile uygulanarak tüm kısımlar hem doğrulama hem eğitim sırasında kullanılır. Bu sayede doğrulama setinin doğru şekilde seçilip seçilmediği kaygısı ortadan kalkar, parametre seçimi ise her bir çapraz doğrulama (cross-validation) seti ve eğitim (training) seti ile ölçülen metrik skorlarının (hata, doğruluk, f1 vs.) ortalaması alınarak yapılır."},{"metadata":{},"cell_type":"markdown","source":"**Makine Öğrenmesinde Çapraz Doğrulama ve Test**\n\nMakine öğrenmesinde modelleri eğitirken beklenti kullanılan veriyle en iyi genellemeyi yapmasıdır. Eğer eğitilen model yine eğitim sırasında kullanılan veri ile test edilirse model kullanılan veriye overfitting (aşırı uyum) mi yoksa iyi bir genelleme mi anlayamayız.\nÇapraz doğrulama (cross-validation) parametre ayarlama sırasında eğitim setinin her seferinde farklı bir kısmı ile doğrulama yapma işlemidir. Örnek ile açıklamak gerekirse, veri setinin seçilen orandaki kısmı test seti olarak ayrıldıktan sonra kalan kısmın ilk %25’lik kısmını ilk model eğitiminde, ikinci %25’lik kısmını ikinci model eğitiminde… şeklinde sırası ile uygulanarak tüm kısımlar hem doğrulama hem eğitim sırasında kullanılır. Bununla birlikte doğrulama setinin doğru şekilde seçilip seçilmediği kaygısı ortadan kalkar, parametre seçimi ise her bir çapraz doğrulama (cross-validation) seti ve eğitim (training) seti ile ölçülen metrik skorlarının (hata, doğruluk, f1 vs.) ortalaması alınarak yapılır."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}