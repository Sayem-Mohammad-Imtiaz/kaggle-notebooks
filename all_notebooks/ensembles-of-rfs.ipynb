{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Ensemble of RFs - further analysis"},{"metadata":{},"cell_type":"markdown","source":"## Model Summary"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nsummary = pd.DataFrame({'Model': ['RF', 'RF', 'RF', 'Ensemble', 'Ensemble', 'Ensemble', 'RF', 'RF', 'RF', 'RF', 'Ensemble',\n                                 'Ensemble', 'Ensemble'],\n                        'Resolution Status': ['Open', 'Open', 'Open', 'Open', 'Open', 'Open', 'All', 'All', 'All', 'All',\n                                             'All', 'All', 'All'],\n                        'Recovered from Insurer': ['=0', '!=0', '!=0 & nooutliers', '=0 & !=0', '=0 & (!=0 & nooutliers)',\n                                                  'all RFs', 'all data', '=0', '!=0', '!=0 & nooutliers','=0 & !=0', \n                                                   '=0 & (!=0 & nooutliers)','all RFs' ],\n          'Train_Accuracy': [.8399, 0.98217, 0.98057, 0.86248, 0.85091, 0.86116, 0.8681, 0.84334, 0.60847, 0.9843, 0.86581,\n                            0.86709, 0.87985],\n          'Validation_Accuracy': [.54051, 0.63936, 0.64259, 0.55766, 0.85076, 0.85957, 0.56724, 0.54831, 0.61998, 0.63736,\n                                 0.56124, 0.55739, 0.56574],\n          \"Train f1-score ['poor', 'average', 'outstanding']\": [\"[0.7771  0.78983 0.88811]\", \"[0.97278 0.96527 0.98927]\",\n                                                               \"[0.96941 0.96739 0.98753]\", \"[0.8166  0.80315 0.9061 ]\",\n                                                               \"[0.79915 0.78934 0.89836]\",\"[0.80431 0.80663 0.90558]\",\n                                                               \"[0.81022 0.81777 0.91077]\",\"[0.78409 0.78979 0.89073]\",\n                                                               \"[0.27404 0.28235 0.77278]\",\"[0.97572 0.97207 0.99008]\",\n                                                               \"[0.8164  0.81175 0.90917]\",\"[0.81563 0.81283 0.91121]\",\n                                                               \"[0.82805 0.83383 0.91856]\"],\n          \"Validation f1-score ['poor', 'average', 'outstanding']\": [\"0.34549 0.38779 0.68984]\", \"[0.33129 0.38009 0.78421]\",\n                                                                    \"[0.40571 0.29557 0.78446]\", \"[0.39659 0.39121 0.69972]\",\n                                                                    \"[0.79849 0.79979 0.89567]\", \"[0.79421 0.81972 0.90309]\",\n                                                                    \"[0.35744 0.39622 0.71745]\",\"[0.37799 0.39467 0.68947]\",\n                                                                    \"[0.29582 0.25926 0.78027]\",\"[0.39548 0.26804 0.78165]\",\n                                                                    \"[0.39371 0.3921  0.71122]\",\"[0.39647 0.39162 0.70271]\",\n                                                                    \"[0.35685 0.39475 0.71554]\"]}\n                      )\nsummary.index = np.arange(1, len(summary)+1)\nsummary.style.set_properties(subset = ['Recovered from Insurer'], **{'width': '130px'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### RFs are working relatively better on train part of segragated data sets\n#### On an overall perspective the Ensemble model combining 3 RFs on data for Resolution Status = Open is giving the best generalization (Train acc = 0.86116 & Val acc = 0.85957)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Reading and Preview of the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cd = pd.read_csv(\"../input/Train_Complaints-1564659763354.csv\")\ndf_ind = pd.read_csv(\"../input/Train-1564659747836.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combining the dataframes to include the target variable 'DRC' based on key column - 'InsurerID'\ndf = pd.merge(df_cd, df_ind, how='inner', on = 'InsurerID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting DateOfRegistration & DateOfResolution to Date\ndf['DateOfRegistration'] =pd.to_datetime(df.DateOfRegistration, format = '%d-%m-%Y')\ndf['DateOfResolution'] = pd.to_datetime(df.DateOfResolution, format = '%d-%m-%Y')\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checking for NAs"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking column wise NAs\n\nNA_col = pd.DataFrame(df.isna().sum(), columns = ['NA_Count'])\nNA_col['%_of_NA'] = (NA_col.NA_Count/len(df))*100\nNA_col.sort_values(by = ['%_of_NA'], ascending = False, na_position = 'first').head(7)\n\n# Considering threshold of 20% for columnwise NAs, SubCoverage column will be dropped in further analysis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking row wise NAs\n\nNA_row = pd.DataFrame(df.isna().sum(axis=1), columns = ['NA_rw_count'])\nNA_row['%_of_rw_NA'] = (NA_row.NA_rw_count/len(df))*100\nNA_row.sort_values(by = ['%_of_rw_NA'], ascending = False, na_position = 'first').head(7)\n\n# We are good in terms of rowwise NAs w.r.t. no need of row removals","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checking unique values in columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in (df):\n    print(col)\n    print(len(df[col].unique()))\n    \n# Column State will be dropped as it just has 1 unique value\n# ComplaintID column will also be dropped\n# FileNo column will also be dropped\n# Bawsed on the Dataset we can drop Company and use InsurerID ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Dropping of columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['SubCoverage', 'Company','FileNo', 'ComplaintID', 'State'], axis = 1)\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Segragating 66 Sub Reasons into 5 Sections - Claims, Delay, No SubReason, Service, and Underwriting/Sales"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['SubReason'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['SubReason'] = df['SubReason'].replace({'Other [Enter Sub-Reason]':'Other_Enter_Sub_Reason'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"claims = ['Actual Cash Value Dispute', 'Cancellation', 'CPT Code Issue', \n          'CT Continuation 38a-512a', 'Denial of Claim', 'Failed to Remit Premium', 'No Coverage/Premium Paid']\ndf['New_SubReason'] = ['Claims' if x in claims else x for x in df['SubReason']] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['New_SubReason'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delay = [\"Carrier Never Rec'd Appl\", \"Carrier Never Rec'd Claim\", 'Claim Delays', 'Claim Procedure', \n         'Policy Issue Delay', 'Policy Service', 'Policy Service Delay', \n         'Premium Refund Delay', 'Time Delay', 'Underwriting Delays']\ndf['New_SubReason'] = ['Delay' if x in delay else x for x in df['New_SubReason']] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nosubreason = ['No Subreason', 'Other_Enter_Sub_Reason']\ndf['New_SubReason'] = ['No_SubReason' if x in nosubreason else x for x in df['New_SubReason']] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"service = ['Audit','Benefit Extension','Case Management','Classification','Comparative Negligence','Contract Provision',\n'Coordination of Benefit','Discontinuation & Replmnt','Duplicate Coverage','Loss of Use','Misleading Advertising',\n'Mis-Quote','Misrepresentation','Network Adequacy','No Response','Non-Renewal','Provider Contract Issue','Refusal to Insure',\n'Steering','Surprise Billing','Unfair Discrimination','Unprofessional Conduct','Unsatisfactory Offer',\n           'Unsatisfactory Settlement']\ndf['New_SubReason'] = ['Service' if x in service else x for x in df['New_SubReason']] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"undr_sales = ['After Mrkt Prts/Unsat Set','Diminished Value','Eligibility of Provider','Excessive Charges','Labor Rate',\n'Mandated Benefit','Medical Necessity','Other Fees','Pre-Existing Condition','Premium/Notice','Premium/Rate Increase',\n'Producer Handling','Rebate','Replacement','Rescission','Service Fees','Storage Fees','Subrogation','Unapproved Form',\n'Underwrtng/Credit History','Underwrtng/Waivers/Rated','UR Procedure','Usual and Customary Fees']\n\ndf['New_SubReason'] = ['Underwriting/Sales' if x in undr_sales else x for x in df['New_SubReason']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train set with all ResolutionStatus"},{"metadata":{"trusted":true},"cell_type":"code","source":"import copy\ndf_bu = df.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Processing on Train set by dropping 'Re-Opened' & 'Open' ResolutionStatus"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(df[df.ResolutionStatus.isin([\"Re-Opened\", \"Open\"])].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating column that gives the days taken to resolve complaints\n# Going forward DateOfResolution and DateOfRegistration can be dropped\ndf['DaysTakenforResn'] = (df['DateOfResolution'] - df['DateOfRegistration']).dt.days ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading and applying changes to the Test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = df.copy()\ntrain.sort_values(by ='RecoveredFromInsurer', ascending = False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping 'SubReason', 'DateOfRegistration', 'DateOfResolution'\ntrain = train.drop(['SubReason', 'DateOfRegistration', 'DateOfResolution'], axis = 1)\ntrain.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading Test dataset given\ntest = pd.read_csv(\"../input/Test_Complaints-1565162197608.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting DateOfRegistration & DateOfResolution to Date\ntest['DateOfRegistration'] =pd.to_datetime(test.DateOfRegistration, format = '%Y-%m-%d')\ntest['DateOfResolution'] = pd.to_datetime(test.DateOfResolution, format = '%Y-%m-%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.drop(['SubCoverage', 'Company','FileNo', 'ComplaintID', 'State'], axis = 1)\ntest.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['SubReason'] = test['SubReason'].replace({'Other [Enter Sub-Reason]':'Other_Enter_Sub_Reason'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"claims = ['Actual Cash Value Dispute', 'Cancellation', 'CPT Code Issue', \n          'CT Continuation 38a-512a', 'Denial of Claim', 'Failed to Remit Premium', 'No Coverage/Premium Paid']\ntest['New_SubReason'] = ['Claims' if x in claims else x for x in test['SubReason']] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"delay = [\"Carrier Never Rec'd Appl\", \"Carrier Never Rec'd Claim\", 'Claim Delays', 'Claim Procedure', \n         'Policy Issue Delay', 'Policy Service', 'Policy Service Delay', \n         'Premium Refund Delay', 'Time Delay', 'Underwriting Delays']\ntest['New_SubReason'] = ['Delay' if x in delay else x for x in test['New_SubReason']] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nosubreason = ['No Subreason', 'Other_Enter_Sub_Reason']\ntest['New_SubReason'] = ['No_SubReason' if x in nosubreason else x for x in test['New_SubReason']] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"service = ['Audit','Benefit Extension','Case Management','Classification','Comparative Negligence','Contract Provision',\n'Coordination of Benefit','Discontinuation & Replmnt','Duplicate Coverage','Loss of Use','Misleading Advertising',\n'Mis-Quote','Misrepresentation','Network Adequacy','No Response','Non-Renewal','Provider Contract Issue','Refusal to Insure',\n'Steering','Surprise Billing','Unfair Discrimination','Unprofessional Conduct','Unsatisfactory Offer',\n           'Unsatisfactory Settlement']\ntest['New_SubReason'] = ['Service' if x in service else x for x in test['New_SubReason']] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"undr_sales = ['After Mrkt Prts/Unsat Set','Diminished Value','Eligibility of Provider','Excessive Charges','Labor Rate',\n'Mandated Benefit','Medical Necessity','Other Fees','Pre-Existing Condition','Premium/Notice','Premium/Rate Increase',\n'Producer Handling','Rebate','Replacement','Rescission','Service Fees','Storage Fees','Subrogation','Unapproved Form',\n'Underwrtng/Credit History','Underwrtng/Waivers/Rated','UR Procedure','Usual and Customary Fees']\n\ntest['New_SubReason'] = ['Underwriting/Sales' if x in undr_sales else x for x in test['New_SubReason']] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test set with all ResolutionStatus"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_bu = test.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dropping 'Re-Opened' & 'Open' for ResolutionStatus from test for analysis continuation"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.drop(test[test.ResolutionStatus.isin([\"Re-Opened\", \"Open\"])].index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analysis continuation for only 'Closed' ResolutionStatus"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['DaysTakenforResn'] = (test['DateOfResolution'] - test['DateOfRegistration']).dt.days ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping 'SubReason', 'DateOfRegistration', 'DateOfResolution'\ntest = test.drop(['SubReason', 'DateOfRegistration', 'DateOfResolution'], axis = 1)\ntest.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separating the target variable\nX_train = train.copy().drop('DRC', axis = 1)\ny_train = train['DRC']\nprint(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking Train NAs\nX_train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking Test NAs\ntest.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dummies for Categorical Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = ['Coverage', 'Reason', 'EnforcementAction', 'Conclusion', 'ResolutionStatus', 'New_SubReason']\nnum_cols = ['RecoveredFromInsurer', 'DaysTakenforResn']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_num = len(X_train)\ncombined_dataset = pd.concat(objs=[X_train, test], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def impute_with_mode(x):\n    max_x = x.value_counts()\n    mode = max_x[max_x == max_x.max()].index[0]\n    x[x.isna()] = mode\n    return x\n\ncombined_dataset[cat_cols] = combined_dataset[cat_cols].apply(lambda x: impute_with_mode(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined_dataset.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined_dataset = pd.get_dummies(combined_dataset, columns=cat_cols, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = copy.copy(combined_dataset[:X_train_num])\ntest = copy.copy(combined_dataset[X_train_num:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.concat([X_train, y_train], axis =1)\nprint(train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating 3 subsets of the data based on RecoveredFromInsurer\n- 1. Subset with RecoveredFromInsurer == 0\n- 2. Subset with RecoveredFromInsurer != 0\n- 3. Subset with RecoveredFromInsurer !=0 & < 400000"},{"metadata":{},"cell_type":"markdown","source":"### 1. For RecoveredFromInsurer == 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"df0 = train[train['RecoveredFromInsurer'] == 0]\nprint(df0.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test0 = test[test['RecoveredFromInsurer'] == 0]\nprint(test0.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting df0 into train0 and val0\nfrom sklearn.model_selection import train_test_split\n\ntrain0 , val0 = train_test_split(df0, test_size = 0.3, shuffle = True ,random_state = 800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train0 = train0.copy().drop('DRC', axis = 1)\ny_Train0 = train0[['InsurerID','DRC']]\nX_val0 = val0.copy().drop('DRC', axis = 1)\ny_val0 = val0[['InsurerID','DRC']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting InsurerID as the Index\nX_Train0.set_index('InsurerID', inplace = True)\ny_Train0.set_index('InsurerID', inplace = True)\nX_val0.set_index('InsurerID', inplace = True)\ny_val0.set_index('InsurerID', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying Random Forest \nfrom sklearn.ensemble import RandomForestClassifier\nrfc0 = RandomForestClassifier()\nrfc0.fit(X = X_Train0,y = y_Train0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred_rfc0 = rfc0.predict(X_Train0)\ntest_pred_rfc0 = rfc0.predict(X_val0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.metrics import f1_score\nprint(\"\\nRF_Train accuracy\", metrics.accuracy_score(y_Train0, train_pred_rfc0).round(5))\nprint(\"\\nRF_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train0, train_pred_rfc0, average = None).round(5))\nprint(\"\\nRF_Validation accuracy\", metrics.accuracy_score(y_val0, test_pred_rfc0).round(5))\nprint(\"\\nRF_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val0, test_pred_rfc0, average = None).round(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying on Test data\ntest0_new = test0.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test0_new.set_index('InsurerID', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_rfc0 = rfc0.predict(test0_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_rfc0 = pd.DataFrame(y_pred_rfc0, columns = ['DRC'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_rfc0['InsurerID'] = test0['InsurerID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_rfc0.DRC.replace(('poor', 'average', 'outstanding'), (1, 2, 3), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group_RF0_pred = pd.DataFrame(y_pred_rfc0.groupby(['InsurerID'])['DRC'].mean())\ngroup_RF0_pred = group_RF0_pred.round().astype(int)\ngroup_RF0_pred.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. For RecoveredFromInsurer != 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"dfnot0 = train[train['RecoveredFromInsurer'] != 0]\nprint(dfnot0.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfnot0.sort_values(by = 'RecoveredFromInsurer', ascending = False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testnot0 = test[test['RecoveredFromInsurer'] != 0]\nprint(testnot0.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xno0 = dfnot0.copy().drop('DRC', axis = 1)\nyno0 = dfnot0[['DRC']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xno0_num = len(Xno0)\ncombined_dataset_no0 = pd.concat(objs=[Xno0, testnot0], axis=0)\nprint(combined_dataset_no0.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standardization of Numerical Columns\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(combined_dataset_no0.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']])\n\ncombined_dataset_no0.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']]=scaler.transform(\n    combined_dataset_no0.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xno0 = copy.copy(combined_dataset_no0[:Xno0_num])\ntestnot0 = copy.copy(combined_dataset_no0[Xno0_num:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfnot0 = pd.concat([Xno0, yno0], axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dfnot0.shape)\nprint(testnot0.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting dfnot0 into trainnot0 and valnot0\nfrom sklearn.model_selection import train_test_split\n\ntrainnot0 , valnot0 = train_test_split(dfnot0, test_size = 0.3, shuffle = True ,random_state = 800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Trainnot0 = trainnot0.copy().drop('DRC', axis = 1)\ny_Trainnot0 = trainnot0[['InsurerID','DRC']]\nX_valnot0 = valnot0.copy().drop('DRC', axis = 1)\ny_valnot0 = valnot0[['InsurerID','DRC']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting InsurerID as the Index\nX_Trainnot0.set_index('InsurerID', inplace = True)\ny_Trainnot0.set_index('InsurerID', inplace = True)\nX_valnot0.set_index('InsurerID', inplace = True)\ny_valnot0.set_index('InsurerID', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying Random Forest\nrfcnot0 = RandomForestClassifier()\nrfcnot0.fit(X = X_Trainnot0,y = y_Trainnot0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred_rfcnot0 = rfcnot0.predict(X_Trainnot0)\ntest_pred_rfcnot0 = rfcnot0.predict(X_valnot0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.metrics import f1_score\nprint(\"\\nRF_not0_Train accuracy\", metrics.accuracy_score(y_Trainnot0, train_pred_rfcnot0).round(5))\nprint(\"\\nRF_not0_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Trainnot0, train_pred_rfcnot0, average = None).round(5))\nprint(\"\\nRF_not0_Validation accuracy\", metrics.accuracy_score(y_valnot0, test_pred_rfcnot0).round(5))\nprint(\"\\nRF_not0_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_valnot0, test_pred_rfcnot0, average = None).round(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying on Test data\ntestnot0_new = testnot0.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testnot0_new.set_index('InsurerID', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_not0 = rfcnot0.predict(testnot0_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_not0 = pd.DataFrame(y_pred_not0, columns = ['DRC'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_not0['InsurerID'] = testnot0['InsurerID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_not0.DRC.replace(('poor', 'average', 'outstanding'), (1, 2, 3), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group_RF_not0_pred = pd.DataFrame(y_pred_not0.groupby(['InsurerID'])['DRC'].mean())\ngroup_RF_not0_pred = group_RF_not0_pred.round().astype(int)\ngroup_RF_not0_pred.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. For RecoveredFromInsurer != 0 removing outliers (RecoveredFromInsurer >= 400000)"},{"metadata":{"trusted":true},"cell_type":"code","source":"dfnot0_noout = train[(train['RecoveredFromInsurer'] != 0) & (train['RecoveredFromInsurer'] < 400000)]\nprint(dfnot0_noout.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testnot0_noout = test[(test['RecoveredFromInsurer'] != 0) & (test['RecoveredFromInsurer'] < 400000)]\nprint(testnot0_noout.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xno0_noout = dfnot0_noout.copy().drop('DRC', axis = 1)\nyno0_noout = dfnot0_noout[['DRC']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xno0_noout_num = len(Xno0_noout)\ncombined_dataset_no0_noout = pd.concat(objs=[Xno0_noout, testnot0_noout], axis=0)\nprint(combined_dataset_no0_noout.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standardization of Numerical Columns\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(combined_dataset_no0_noout.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']])\n\ncombined_dataset_no0_noout.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']]=scaler.transform(\n    combined_dataset_no0_noout.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xno0_noout = copy.copy(combined_dataset_no0_noout[:Xno0_noout_num])\ntestnot0_noout = copy.copy(combined_dataset_no0_noout[Xno0_noout_num:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfnot0_noout = pd.concat([Xno0_noout, yno0_noout], axis =1)\nprint(dfnot0_noout.shape)\nprint(testnot0_noout.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting dfnot0 into trainnot0 and valnot0\nfrom sklearn.model_selection import train_test_split\n\ntrainnot0_noout , valnot0_noout = train_test_split(dfnot0_noout, test_size = 0.3, shuffle = True ,random_state = 800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Trainnot0_noout = trainnot0_noout.copy().drop('DRC', axis = 1)\ny_Trainnot0_noout = trainnot0_noout[['InsurerID','DRC']]\nX_valnot0_noout = valnot0_noout.copy().drop('DRC', axis = 1)\ny_valnot0_noout = valnot0_noout[['InsurerID','DRC']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting InsurerID as the Index\nX_Trainnot0_noout.set_index('InsurerID', inplace = True)\ny_Trainnot0_noout.set_index('InsurerID', inplace = True)\nX_valnot0_noout.set_index('InsurerID', inplace = True)\ny_valnot0_noout.set_index('InsurerID', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying Random Forest\nrfcnot0_noout = RandomForestClassifier()\nrfcnot0_noout.fit(X = X_Trainnot0_noout,y = y_Trainnot0_noout)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred_rfcnot0_noout = rfcnot0_noout.predict(X_Trainnot0_noout)\ntest_pred_rfcnot0_noout = rfcnot0_noout.predict(X_valnot0_noout)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.metrics import f1_score\nprint(\"\\nRF_not0_noout_Train accuracy\", metrics.accuracy_score(y_Trainnot0_noout, train_pred_rfcnot0_noout).round(5))\nprint(\"\\nRF_not0_noout_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Trainnot0_noout, train_pred_rfcnot0_noout, average = None).round(5))\nprint(\"\\nRF_not0_noout_Validation accuracy\", metrics.accuracy_score(y_valnot0_noout, test_pred_rfcnot0_noout).round(5))\nprint(\"\\nRF_not0_noout_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_valnot0_noout, test_pred_rfcnot0_noout, average = None).round(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying on Test data\ntestnot0_noout_new = testnot0_noout.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testnot0_noout_new.set_index('InsurerID', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_not0_noout = rfcnot0_noout.predict(testnot0_noout_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_not0_noout = pd.DataFrame(y_pred_not0_noout, columns = ['DRC'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_not0_noout['InsurerID'] = testnot0_noout['InsurerID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_not0_noout.DRC.replace(('poor', 'average', 'outstanding'), (1, 2, 3), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group_RF_not0_noout_pred = pd.DataFrame(y_pred_not0_noout.groupby(['InsurerID'])['DRC'].mean())\ngroup_RF_not0_noout_pred = group_RF_not0_noout_pred.round().astype(int)\ngroup_RF_not0_noout_pred.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble with RF for RecoveredFromInsurer == 0 and RF for RecoveredFromInsurer != 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = VotingClassifier(estimators = [('rf1', rfc0), ('rf2', rfcnot0)], voting = 'hard')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train , val = train_test_split(train, test_size = 0.3, shuffle = True ,random_state = 800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train = Train.copy().drop('DRC', axis = 1)\ny_Train = Train[['InsurerID','DRC']]\nX_val = val.copy().drop('DRC', axis = 1)\ny_val = val[['InsurerID','DRC']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train.set_index('InsurerID', inplace = True)\ny_Train.set_index('InsurerID', inplace = True)\nX_val.set_index('InsurerID', inplace = True)\ny_val.set_index('InsurerID', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_Train, y_Train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model_pred = model.predict(X_Train)\ntest_model_pred = model.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\nEn_Train accuracy\", metrics.accuracy_score(y_Train, train_model_pred).round(5))\nprint(\"\\nEn_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train, train_model_pred, average = None).round(5))\nprint(\"\\nEn_Validation accuracy\", metrics.accuracy_score(y_val, test_model_pred).round(5))\nprint(\"\\nEn_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val, test_model_pred, average = None).round(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_en1 = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_en1.set_index('InsurerID', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_en_model1 = model.predict(test_en1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_en_model1 = pd.DataFrame(y_pred_en_model1, columns = ['DRC'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_en_model1['InsurerID'] = test['InsurerID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_en_model1.DRC.replace(('poor', 'average', 'outstanding'), (1, 2, 3), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group_ensemble1_pred = pd.DataFrame(y_pred_en_model1.groupby(['InsurerID'])['DRC'].mean())\ngroup_ensemble1_pred = group_ensemble1_pred.round().astype(int)\ngroup_ensemble1_pred.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(group_ensemble1_pred, columns=['DRC']).to_csv('Prediction_DRC_ensemble1.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble with RF for RecoveredFromInsurer == 0 and RF for RecoveredFromInsurer (!= 0 & <400000)"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_0_noout = VotingClassifier(estimators = [('rf1', rfc0), ('rf3', rfcnot0_noout)], voting = 'hard')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_0_noout.fit(X_Train, y_Train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_modelnoout_pred = model_0_noout.predict(X_Train)\ntest_modelnoout_pred = model_0_noout.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\nEn2_Train accuracy\", metrics.accuracy_score(y_Train, train_modelnoout_pred).round(5))\nprint(\"\\nEn2_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train, train_modelnoout_pred, average = None).round(5))\nprint(\"\\nEn2_Validation accuracy\", metrics.accuracy_score(y_val, test_modelnoout_pred).round(5))\nprint(\"\\nEn2_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val, test_modelnoout_pred, average = None).round(5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble for all RFs"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_all = VotingClassifier(estimators = [('rf1', rfc0), ('rf2', rfcnot0),('rf3', rfcnot0_noout)], voting = 'hard')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_all.fit(X_Train, y_Train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model_all = model_all.predict(X_Train)\ntest_model_all = model_all.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\nEn_all_Train accuracy\", metrics.accuracy_score(y_Train, train_model_all).round(5))\nprint(\"\\nEn_all_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train, train_model_all, average = None).round(5))\nprint(\"\\nEn_all_Validation accuracy\", metrics.accuracy_score(y_val, test_model_all).round(5))\nprint(\"\\nEn_all_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val, test_model_all, average = None).round(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_en_model_all = model_all.predict(test_en1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_en_model_all = pd.DataFrame(y_pred_en_model_all, columns = ['DRC'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_en_model_all['InsurerID'] = test['InsurerID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_en_model_all.DRC.replace(('poor', 'average', 'outstanding'), (1, 2, 3), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group_ensemble_predall = pd.DataFrame(y_pred_en_model_all.groupby(['InsurerID'])['DRC'].mean())\ngroup_ensemble_predall = group_ensemble_predall.round().astype(int)\ngroup_ensemble_predall.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Writing prediction for upload","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_all_new = y_pred_en_model_all.groupby('InsurerID')['DRC'].value_counts()\n# Grouping to count the occurrences for different DRCs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arf_df = y_pred_all_new.unstack()\n# Reshaping data to stack the columns row-wise","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arf_df_pred = arf_df.idxmax(axis=1, skipna = True)\n# Taking the max value based on index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arf_df_pred = pd.DataFrame(arf_df_pred, columns = ['DRC'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(arf_df_pred).to_csv('Ensemble_AllRFs.csv')\narf_df_pred.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analysis with all types of Resolution Status"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bu.ResolutionStatus.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_bu.ResolutionStatus.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bu.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_bu.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\ndf_bu.loc[df_bu['DateOfResolution'].isna(), 'DateOfResolution'] = datetime.datetime.now()\ntest_bu.loc[test_bu['DateOfResolution'].isna(), 'DateOfResolution'] = datetime.datetime.now()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bu.loc[df_bu['DateOfResolution'].isna(), 'DateOfResolution'] = datetime.datetime.now()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bu.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_bu.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bu['DaysTakenforResn'] = (df_bu['DateOfResolution'] - df_bu['DateOfRegistration']).dt.days\ndf_bu.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_bu['DaysTakenforResn'] = (test_bu['DateOfResolution'] - test_bu['DateOfRegistration']).dt.days\ntest_bu.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping 'SubReason', 'DateOfRegistration', 'DateOfResolution'\ndf_bu = df_bu.drop(['SubReason', 'DateOfRegistration', 'DateOfResolution'], axis = 1)\nprint(df_bu.columns)\ntest_bu = test_bu.drop(['SubReason', 'DateOfRegistration', 'DateOfResolution'], axis = 1)\nprint(test_bu.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separating the target variable\nX_train_new = df_bu.copy().drop('DRC', axis = 1)\ny_train_new = df_bu['DRC']\nprint(X_train_new.shape)\nprint(y_train_new.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new_num = len(X_train_new)\ncombined_dataset_new = pd.concat(objs=[X_train_new, test_bu], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined_dataset_new[cat_cols] = combined_dataset_new[cat_cols].apply(lambda x: impute_with_mode(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined_dataset_new = pd.get_dummies(combined_dataset_new, columns=cat_cols, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = copy.copy(combined_dataset_new[:X_train_new_num])\ntest_bu = copy.copy(combined_dataset_new[X_train_new_num:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new = pd.concat([X_train_new, y_train_new], axis =1)\nprint(train_new.shape)\nprint(test_bu.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Basic RF - applying on all the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_brf , val_brf = train_test_split(train_new, test_size = 0.3, shuffle = True ,random_state = 800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train_brf = train_brf.copy().drop('DRC', axis = 1)\ny_Train_brf = train_brf[['InsurerID','DRC']]\nX_val_brf = val_brf.copy().drop('DRC', axis = 1)\ny_val_brf = val_brf[['InsurerID','DRC']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train_brf.set_index('InsurerID', inplace = True)\ny_Train_brf.set_index('InsurerID', inplace = True)\nX_val_brf.set_index('InsurerID', inplace = True)\ny_val_brf.set_index('InsurerID', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying Random Forest\nrf_brf = RandomForestClassifier()\nrf_brf.fit(X = X_Train_brf,y = y_Train_brf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred_brf = rf_brf.predict(X_Train_brf)\ntest_pred_brf = rf_brf.predict(X_val_brf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\nRF_new_Train accuracy\", metrics.accuracy_score(y_Train_brf, train_pred_brf).round(5))\nprint(\"\\nRF_new_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train_brf, train_pred_brf, average = None).round(5))\nprint(\"\\nRF_new_Validation accuracy\", metrics.accuracy_score(y_val_brf, test_pred_brf).round(5))\nprint(\"\\nRF_new_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val_brf, test_pred_brf, average = None).round(5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating 3 subsets of the data based on RecoveredFromInsurer for all type of Resolution Status\n- 1. Subset with RecoveredFromInsurer == 0\n- 2. Subset with RecoveredFromInsurer != 0\n- 3. Subset with RecoveredFromInsurer !=0 & < 400000"},{"metadata":{},"cell_type":"markdown","source":"### 1. For RecoveredFromInsurer == 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"dfnew0 = train_new[train_new['RecoveredFromInsurer'] == 0]\ntestnew0 = test_bu[test_bu['RecoveredFromInsurer'] == 0]\nprint(dfnew0.shape)\nprint(testnew0.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new0, val_new0 = train_test_split(dfnew0, test_size = 0.3, shuffle = True, random_state = 800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train_new0 = train_new0.copy().drop('DRC', axis = 1)\ny_Train_new0 = train_new0[['InsurerID', 'DRC']]\nX_val_new0 = val_new0.copy().drop('DRC', axis = 1)\ny_val_new0 = val_new0[['InsurerID', 'DRC']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train_new0.set_index('InsurerID', inplace = True)\ny_Train_new0.set_index('InsurerID', inplace = True)\nX_val_new0.set_index('InsurerID', inplace = True)\ny_val_new0.set_index('InsurerID', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_0_new = RandomForestClassifier()\nrf_0_new.fit(X_Train_new0, y_Train_new0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred_rf_0_new = rf_0_new.predict(X_Train_new0)\ntest_pred_rf_0_new = rf_0_new.predict(X_val_new0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\nRF_0_new_Train accuracy\", metrics.accuracy_score(y_Train_new0, train_pred_rf_0_new).round(5))\nprint(\"\\nRF_0_new_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train_new0, train_pred_rf_0_new, average = None).round(5))\nprint(\"\\nRF_0_new_Validation accuracy\", metrics.accuracy_score(y_val_new0, test_pred_rf_0_new).round(5))\nprint(\"\\nRF_0_new_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val_new0, test_pred_rf_0_new, average = None).round(5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. For RecoveredFromInsurer != 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"dfnewnot0 = train_new[train_new['RecoveredFromInsurer'] != 0]\ntestnewnot0 = test_bu[test_bu['RecoveredFromInsurer'] != 0]\nprint(dfnewnot0.shape)\nprint(testnewnot0.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dfnewnot0.copy().drop('DRC', axis = 1)\ny = dfnewnot0[['DRC']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_num = len(X)\ncombined_df = pd.concat(objs = [X, testnewnot0], axis = 0)\nprint(combined_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(combined_df.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']])\ncombined_df.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']]=scaler.transform(\n    combined_df.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = copy.copy(combined_df[:X_num])\ntestnewnot0 = copy.copy(combined_df[X_num:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfnewnot0 = pd.concat([X, y], axis=1)\nprint(dfnewnot0.shape)\nprint(testnewnot0.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_newnot0, val_newnot0 = train_test_split(dfnewnot0, test_size = 0.3, shuffle = True, random_state = 800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train_newnot0 = train_newnot0.copy().drop('DRC', axis = 1)\ny_Train_newnot0 = train_newnot0[['InsurerID', 'DRC']]\nX_val_newnot0 = val_newnot0.copy().drop('DRC', axis = 1)\ny_val_newnot0 = val_newnot0[['InsurerID', 'DRC']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train_newnot0.set_index('InsurerID', inplace = True)\ny_Train_newnot0.set_index('InsurerID', inplace = True)\nX_val_newnot0.set_index('InsurerID', inplace = True)\ny_val_newnot0.set_index('InsurerID', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_newnot0 = RandomForestClassifier()\nrf_newnot0.fit(X_Train_newnot0, y_Train_newnot0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred_rf_newnot0 = rf_0_new.predict(X_Train_newnot0)\ntest_pred_rf_newnot0 = rf_0_new.predict(X_val_newnot0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\nRF_new_not0_Train accuracy\", metrics.accuracy_score(y_Train_newnot0, train_pred_rf_newnot0).round(5))\nprint(\"\\nRF_new_not0_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train_newnot0, train_pred_rf_newnot0, average = None).round(5))\nprint(\"\\nRF_new_not0_Validation accuracy\", metrics.accuracy_score(y_val_newnot0, test_pred_rf_newnot0).round(5))\nprint(\"\\nRF_new_not0_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val_newnot0, test_pred_rf_newnot0, average = None).round(5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. For RecoveredFromInsurer != 0 removing outliers (RecoveredFromInsurer >= 400000)"},{"metadata":{"trusted":true},"cell_type":"code","source":"dfnew_no0_noout = train_new[(train_new['RecoveredFromInsurer'] != 0) & (train_new['RecoveredFromInsurer'] < 400000)]\ntestnew_no0_noout = test_bu[(test_bu['RecoveredFromInsurer'] != 0) &(test_bu['RecoveredFromInsurer'] < 400000)]\nprint(dfnew_no0_noout.shape)\nprint(testnew_no0_noout.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dfnew_no0_noout.copy().drop('DRC', axis =1)\ny = dfnew_no0_noout[['DRC']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_num = len(X)\ncombined_df = pd.concat(objs = [X, testnew_no0_noout], axis=0)\nprint(combined_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(combined_df.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']])\n\ncombined_df.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']]=scaler.transform(\n    combined_df.loc[:,['RecoveredFromInsurer', 'DaysTakenforResn']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = copy.copy(combined_df[:X_num])\ntestnew_no0_noout = copy.copy(combined_df[X_num:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfnew_no0_noout = pd.concat([X,y],axis =1)\nprint(dfnew_no0_noout.shape)\nprint(testnew_no0_noout.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t, v = train_test_split(dfnew_no0_noout, test_size = 0.3, shuffle = True, random_state = 800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xt = t.copy().drop('DRC', axis = 1)\nyt = t[['InsurerID', 'DRC']]\nXv = v.copy().drop('DRC', axis = 1)\nyv = v[['InsurerID', 'DRC']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xt.set_index('InsurerID', inplace = True)\nyt.set_index('InsurerID', inplace = True)\nXv.set_index('InsurerID', inplace = True)\nyv.set_index('InsurerID', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF = RandomForestClassifier()\nRF.fit(X=Xt, y= yt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tp = RF.predict(Xt)\nvp = RF.predict(Xv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\nRF_not0_noout_Train accuracy\", metrics.accuracy_score(yt, tp).round(5))\nprint(\"\\nRF_not0_noout_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(yt, tp, average = None).round(5))\nprint(\"\\nRF_not0_noout_Validation accuracy\", metrics.accuracy_score(yv, vp).round(5))\nprint(\"\\nRF_not0_noout_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(yv, vp, average = None).round(5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble with RF for RecoveredFromInsurer == 0 and RF for RecoveredFromInsurer != 0"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = VotingClassifier(estimators = [('rf1', rf_0_new), ('rf2', rf_newnot0)], voting = 'hard')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train , val = train_test_split(train_new, test_size = 0.3, shuffle = True ,random_state = 800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train = Train.copy().drop('DRC', axis = 1)\ny_Train = Train[['InsurerID','DRC']]\nX_val = val.copy().drop('DRC', axis = 1)\ny_val = val[['InsurerID','DRC']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train.set_index('InsurerID', inplace = True)\ny_Train.set_index('InsurerID', inplace = True)\nX_val.set_index('InsurerID', inplace = True)\ny_val.set_index('InsurerID', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.fit(X_Train, y_Train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model1_pred = model1.predict(X_Train)\ntest_model1_pred = model1.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\nEnnew1_Train accuracy\", metrics.accuracy_score(y_Train, train_model1_pred).round(5))\nprint(\"\\nEnnew1_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train, train_model1_pred, average = None).round(5))\nprint(\"\\nEnnew1_Validation accuracy\", metrics.accuracy_score(y_val, test_model1_pred).round(5))\nprint(\"\\nEnnew1_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val, test_model1_pred, average = None).round(5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble with RF for RecoveredFromInsurer == 0 and RF for RecoveredFromInsurer (!= 0 & <400000)"},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = VotingClassifier(estimators = [('rf1', rf_0_new), ('rf2', RF)], voting = 'hard')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.fit(X_Train, y_Train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model2_pred = model2.predict(X_Train)\ntest_model2_pred = model2.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\nEnnew2_Train accuracy\", metrics.accuracy_score(y_Train, train_model2_pred).round(5))\nprint(\"\\nEnnew2_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train, train_model2_pred, average = None).round(5))\nprint(\"\\nEnnew2_Validation accuracy\", metrics.accuracy_score(y_val, test_model2_pred).round(5))\nprint(\"\\nEnnew2_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val, test_model2_pred, average = None).round(5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble with all RFs"},{"metadata":{"trusted":true},"cell_type":"code","source":"model3 = VotingClassifier(estimators = [('rf1', rf_0_new), ('rf2', rf_newnot0), ('rf3', RF)], voting = 'hard')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3.fit(X_Train, y_Train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model3_pred = model3.predict(X_Train)\ntest_model3_pred = model3.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\\nEnnew2_Train accuracy\", metrics.accuracy_score(y_Train, train_model3_pred).round(5))\nprint(\"\\nEnnew2_Train f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_Train, train_model3_pred, average = None).round(5))\nprint(\"\\nEnnew2_Validation accuracy\", metrics.accuracy_score(y_val, test_model3_pred).round(5))\nprint(\"\\nEnnew2_Validation f1-score for class ['poor', 'average', 'outstanding']\", \n      metrics.f1_score(y_val, test_model3_pred, average = None).round(5))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}