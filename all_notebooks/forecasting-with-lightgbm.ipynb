{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_absolute_error\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"np.random.seed(42)\n\ntrain = pd.read_csv('../input/DengAI_Predicting_Disease_Spread_-_Training_Data_Features.csv',\n                    parse_dates=['week_start_date'])\ntest = pd.read_csv('../input/DengAI_Predicting_Disease_Spread_-_Test_Data_Features.csv',\n                   parse_dates=['week_start_date'])\ntrain['cases'] = pd.read_csv('../input/DengAI_Predicting_Disease_Spread_-_Training_Data_Labels.csv', usecols=[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['cases'] = np.log1p(train['cases'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#NULL ANALYSIS\nif train.isnull().sum().any():\n    null_cnt = train.isnull().sum().sort_values()\n    print('TRAIN null count:', null_cnt[null_cnt > 0])\n\nif test.isnull().sum().any():\n    null_cnt = test.isnull().sum().sort_values()\n    print('TEST null count:', null_cnt[null_cnt > 0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.interpolate(method='linear', limit_direction='forward', axis=0, inplace=True)\ntest.interpolate(method='linear', limit_direction='forward', axis=0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ltrain = train.shape[0]\ndf = pd.concat([train,test], sort=False)  \nprint('Combined df shape:{}'.format(df.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop constant column\nconstant_column = [col for col in df.columns if df[col].nunique() == 1]\nprint('drop CONSTANT columns:', constant_column)\ndf.drop(constant_column, axis=1, inplace=True)\n\ncorr_matrix = df.corr().abs()\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nto_drop = [c for c in upper.columns if any(upper[c] > 0.98)]\ndel upper\n\nprint('drop SIMILAR columns:', to_drop)\ndf.drop(to_drop,1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['month'] = df.week_start_date.dt.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = df[:ltrain].copy()\ntest = df[ltrain:].copy()\ndel df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_sj = train[train.city=='sj']['cases']\ny_iq = train[train.city=='iq']['cases']\n\ntrain_sj = train[train.city=='sj'].drop('city',1)\ntrain_iq = train[train.city=='iq'].drop('city',1)\n\ntest_sj = test[test.city=='sj'].drop('city',1)\ntest_iq = test[test.city=='iq'].drop('city',1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_and_predict(tr,te,y_):\n    \n    def create_features(tr_,te_,idx=[]):\n        df = pd.concat([tr_,te_], sort=False).set_index('week_start_date')\n        if len(idx)>0:\n            means_w = tr_.iloc[idx].groupby(['weekofyear'])['cases'].mean().to_frame('meanw').reset_index()\n            medians_w = tr_.iloc[idx].groupby(['weekofyear'])['cases'].median().to_frame('medw').reset_index()\n            means_m = tr_.iloc[idx].groupby(['month'])['cases'].mean().to_frame('meanm').reset_index()\n            medians_m = tr_.iloc[idx].groupby(['month'])['cases'].median().to_frame('medm').reset_index()\n        else:\n            means_w = tr_.groupby(['weekofyear'])['cases'].mean().to_frame('meanw').reset_index()\n            medians_w = tr_.groupby(['weekofyear'])['cases'].median().to_frame('medw').reset_index()\n            means_m = tr_.groupby(['month'])['cases'].mean().to_frame('meanm').reset_index()\n            medians_m = tr_.groupby(['month'])['cases'].median().to_frame('medm').reset_index()\n        df = pd.merge(df, means_w, how='left', on=['weekofyear'])\n        df = pd.merge(df, medians_w, how='left', on=['weekofyear'])\n        df = pd.merge(df, means_m, how='left', on=['month'])\n        df = pd.merge(df, medians_m, how='left', on=['month'])\n        df = df.drop(['year','month','cases'],1)\n        return df[:tr_.shape[0]], df[tr_.shape[0]:]\n\n    x_train, x_test = create_features(tr,te)\n    y_train = y_.clip(0,4).values\n\n    params = {\n        'max_depth': 4,\n        'task': 'train',\n        'boosting_type': 'gbdt',\n        'objective': 'regression_l1',\n        'metric': 'mae',\n        'num_leaves': 9,\n        'learning_rate': 0.05,\n        'feature_fraction': 0.8,\n        'bagging_fraction': 0.8,\n        'bagging_freq': 10,\n        'lambda_l1': 0.06,\n        'lambda_l2': 0.1,\n        'random_state': 42,\n        'verbose': 0\n    }\n\n\n    n_f = 12 # Folds\n\n    tscv = TimeSeriesSplit(n_splits=n_f)\n    fds = tscv.split(x_train)\n    lgbtrain = lgb.Dataset(x_train,y_train)\n    \n    hist = lgb.cv(params,\n                lgbtrain,\n                num_boost_round=2000,\n                folds=fds,\n                shuffle=False,\n                metrics=['l1'],\n                early_stopping_rounds=100,\n                verbose_eval=0, \n                show_stdv=False, \n                seed=42)\n    \n    best_iter = np.array(hist['l1-mean']).argmin()\n    \n    gbm = lgb.train(params, lgbtrain, best_iter)    \n    te['cases'] = gbm.predict(x_test, num_iteration=gbm.best_iteration)\n\n    lgb.plot_importance(gbm,importance_type='gain',figsize=(10, 15))\n    plt.show()\n\n    preds = np.zeros([x_test.shape[0]])\n    oof = np.zeros([x_train.shape[0]])\n    \n    for tr_i, vl_i in tscv.split(x_train):   \n        x_train, x_test = create_features(tr,te,tr_i)\n        lgb_tr = lgb.Dataset(x_train.iloc[tr_i],y_train[tr_i])\n        lgb_vl = lgb.Dataset(x_train.iloc[vl_i],y_train[vl_i])\n        gbm = lgb.train(params, lgb_tr, best_iter, valid_sets=[lgb_vl], verbose_eval=0)    \n        oof[vl_i] = gbm.predict(x_train.iloc[vl_i], num_iteration=best_iter)\n        preds += gbm.predict(x_test, num_iteration=best_iter) / n_f\n\n    te['cases'] = preds\n\n    lt = int(len(tr)/200+0.5)\n    for t in range(lt):\n        preds = np.zeros([x_test.shape[0]])    \n        x_train, x_test = create_features(tr,te)        \n        preds = gbm.predict(x_test, num_iteration=gbm.best_iteration)\n        print('Erro preds :',mean_absolute_error(te['cases'].values,np.floor(preds)))\n        te['cases'] = 0.5*te['cases'] + 0.5*preds\n\n    lf = int(len(tr)/n_f)    \n    print('oof:',mean_absolute_error(y_[lf:],np.floor(oof[lf:])))\n\n    return preds, oof\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_sj, oof_sj = train_and_predict(train_sj,test_sj,y_sj)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sj['cases'] = preds_sj\nplot_all = pd.concat([train_sj, test_sj], sort=True).set_index('week_start_date')\nfig, ax = plt.subplots(1, 1)\n_ = plot_all.iloc[:train_sj.shape[0]].plot(y='cases',ax=ax,color='b',legend=False, figsize=(15, 5))\n_ = plot_all.iloc[train_sj.shape[0]:].plot(y='cases',ax=ax,color='r',legend=False, figsize=(15, 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_iq, oof_iq = train_and_predict(train_iq,test_iq,y_iq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_iq['cases'] = preds_iq\nplot_all = pd.concat([train_iq, test_iq], sort=True).set_index('week_start_date')\nfig, ax = plt.subplots(1, 1)\n_ = plot_all.iloc[:train_iq.shape[0]].plot(y='cases',ax=ax,color='b',legend=False, figsize=(15, 5))\n_ = plot_all.iloc[train_iq.shape[0]:].plot(y='cases',ax=ax,color='r',legend=False, figsize=(15, 5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = np.concatenate((preds_sj, preds_iq), axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['total_cases'] = np.round(np.expm1(preds),0)\ntest[['city','year','weekofyear','total_cases']].to_csv('submission_lgb.csv', float_format='%.0f', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}