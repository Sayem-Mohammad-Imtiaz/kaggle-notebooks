{"cells":[{"metadata":{},"cell_type":"markdown","source":"Este trabalho testa três técnicas diferentes de classificação na base Adult, e ao final compara implementações e resultados.\n\nInicialização dos dados"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nadult = pd.read_csv(\"../input/adult-census-income/adult.csv\", names=[\n        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\", \"Target\"],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")\nadult_test = pd.read_csv(\"../input/us-census-data/adult-test.csv\", names=[\n        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\", \"Target\"],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")\nadult_training = pd.read_csv(\"../input/us-census-data/adult-training.csv\", names=[\n        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\", \"Target\"],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")\n\n# data prep\n\n# remove first line\nadult=adult[1:]\nadult_test=adult_test[1:]\n\n# remove missing data\nnadult = adult.dropna()\nnTestAdult = adult_test.dropna()\nnTrainingAdult = adult_training.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Primeiro classificador testado: Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"# random forest\n\n# data prep\nfrom sklearn import preprocessing\n\nnumTestAdult = nTestAdult.apply(preprocessing.LabelEncoder().fit_transform)\nnumTrainingAdult = nTrainingAdult.apply(preprocessing.LabelEncoder().fit_transform)\n\nXtestAdult = numTestAdult.iloc[:,0:14]\nYtestAdult = numTestAdult.Target\nXtrainingAdult = numTrainingAdult.iloc[:,0:14]\nYtrainingAdult = numTrainingAdult.Target\n\n# train model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import accuracy_score\n\nrf = RandomForestRegressor(n_estimators = 400, random_state = 42)\nrf.fit(XtrainingAdult, YtrainingAdult)\npredictions = rf.predict(XtestAdult)\n\npredictions = np.array(predictions)\nYtestAdult = np.array(YtestAdult)\n\ny = []\nfor i in predictions:\n    if i >= 0.5:\n        y.append(1)\n    else:\n        y.append(0)\ny = np.array(y)\naccuracy_score(YtestAdult, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Segundo classificador testado: Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# linear regression\n\n# data prep\nnumAdult = nadult.apply(preprocessing.LabelEncoder().fit_transform)\nnumTestAdult = nTestAdult.apply(preprocessing.LabelEncoder().fit_transform)\nnumTrainingAdult = nTrainingAdult.apply(preprocessing.LabelEncoder().fit_transform)\nXadult = numAdult.iloc[:,0:14]\nYadult = numAdult.Target\nXtestAdult = numTestAdult.iloc[:,0:14]\nYtestAdult = numTestAdult.Target\nXtrainingAdult = numTrainingAdult.iloc[:,0:14]\nYtrainingAdult = numTrainingAdult.Target\n\n\nYtestAdult = np.array(YtestAdult)\n\n# train model\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(XtrainingAdult, YtrainingAdult)\ny_pred = regressor.predict(XtestAdult)\n\ny = []\nfor i in y_pred:\n    if i >= 0.5:\n        y.append(1)\n    else:\n        y.append(0)\n\ny = np.array(y)\naccuracy_score(y, YtestAdult)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Terceiro classificador testado: K-Means"},{"metadata":{"trusted":true},"cell_type":"code","source":"#k-means\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import accuracy_score\n\n# sem seleção de atributos\n\n# data prep\nXadult = numAdult.iloc[:,0:14]\nXadult = np.array(Xadult)\nYadult = numAdult.Target\nYadult = np.array(Yadult)\n\n# model\nkm = KMeans(n_clusters = 2, init = 'random')\nkm.fit(Xadult)\ny_km = km.predict(Xadult)\ny_km = np.array(y_km)\na = accuracy_score(Yadult,y_km)\nprint(a)\n\n# com seleção de atributos\n\n#data prep\nXadult1 = nadult[[\"Age\",\"Education-Num\",\"Capital Gain\", \"Capital Loss\", \"Hours per week\"]]\nYadult1 = numAdult.Target\n\n# model\nkm1 = KMeans(n_clusters = 2, init = 'random')\nkm1.fit(Xadult1)\ny1_km = km1.predict(Xadult1)\ny1_km = np.array(y1_km)\nb = accuracy_score(Yadult1,y1_km)\nprint(b)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Considerações**\n\nNo trabalho, testou-se três técnicas de classificação na base Adult:\n1. Random Forest\n2. Linear Regression\n3. K-Means\nSendo as duas primeiras técnicas de aprendizado supervisionado e a terceira de aprendizado não supervisionado.\n\nPara a técnica de Random Forest:\nO resultado obtido foi de 84.19% de acertos.\nO pré processamento dos dados consistiu apenas em transformar os dados não numéricos em numéricos. \nO maior fator que influencia o tempo e uso de memória computacional é o número de árvores aleatórias geradas.\nNesse exemplo, foram usadas 400 árvores. Um outro teste feito anteriormente com 200 árvores alterou o resultado em menos de 0.1%.\nFoi necessário transformar os valores de saída em valores binários. Para isso, usou-se a regra:\nSe o valor é >= 0.5, é classificado como 1. Caso contrário, recebe valor 0.\nO classificador foi criado com base no tutorial disponível em: \nhttps://towardsdatascience.com/random-forest-in-python-24d0893d51c0\n\nPara a técnica de Linear Regression:\nO resultado obtido foi de 81.24% de acertos.\nO classificador foi construído utilizando todos os atributos. Uma seleção dos atributos poderia ter melhorado o desempenho.\nO pré processamento dos dados foi bem simples, apenas transformando todos os dados em valores numéricos.\nO tempo computacional foi muito mais rápido que o classificador anterior.\nComo as predições de uma regressão linear são valores contínuos, foi necessário transformá-los em binário: \nPossui valor 1 caso seu valor seja maior que 0.5, ou 0, caso contrário.\nO classificador foi criado com base no tutorial disponível em: \nhttps://towardsdatascience.com/machine-learning-simple-linear-regression-with-python-f04ecfdadc13\n\nPara a técnica de K-Means:\nForam feitos dois testes: sem seleção de atributos e com seleção de atributos.\nPara o teste sem seleção de atributos:\nO resultado obtido foi de aproximadamente 50% de acertos, uma taxa bem menor que os outros testes realizados.\nEsse resultado pode variar aproximadamente 1% devido aos centros que são gerados aleatoriamente a cada vez que o programa é rodado.\nPara o pré processamento dos dados foi necessário transformar os atributos não numéricos em numéricos.\nTentou-se criar dummies para cada atributo, mas a quantidade de variáveis fez o processamento ser inviável.\nComo deve-se classificar o Target, foram usados 2 clusters.\nPode-se notar que o resultado foi bem abaixo do esperado, visto que houve influência a partir da transformação de dados não numéricos, e o classificador trabalhou apenas com os dados crus.\nUm contorno para isso seria pré-selecionar os atributos. Para o teste feito com seleção:\nO resultado obtido foi de aproximadamente 76%.\nPode-se notar uma clara melhora na classificação, mas ainda assim abaixo das outras duas testadas.\nO classificador foi criado com base no tutorial disponível em: \nhttps://towardsdatascience.com/k-means-clustering-with-scikit-learn-6b47a369a83c"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}