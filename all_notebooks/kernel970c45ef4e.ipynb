{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import csv\nimport numpy as np\nimport random\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\n\n\nclass Perceptron:\n\n    ### __init__ function: Implicitly called when an instance of class Perceptron\n    ### is created. This function initializes the train and test dataset etc.\n    ### Parameters :\n    ###         traincsv :string - name of train-dataset(csv) passed as a string\n    ###         testcsv :string - name of test-dataset(csv) passed as a string\n    def __init__(self, traincsv, testcsv):\n        ## Load the train and test csv files into train_data and test_ data\n        ## as numpy array\n        f = open(traincsv,'r')\n        data = csv.reader(f)\n        list_data = list(data)\n\n        self.train_data = np.array(list_data)\n\n        f1 = open(testcsv,'r')\n        data1 = csv.reader(f1)\n        list_data1 = list(data1)\n        self.test_data = np.array(list_data1)\n\n        ### Initialize the weight variable of the dimension 10 x 785  where\n        ### each single row of 1 x 785 is input to one single perceptron for\n        ### a given training example\n        self.weight_arr = np.random.uniform(-0.05,0.05,(10,785))\n\n        ### Set bias unit to one\n        self.bias = 1\n\n        ### train_accuracy and test_accuracy are used to store the accuracy rates\n        ### for training data and test data for each single epoch\n        self.train_accuracy = []\n        self.test_accuracy = []\n        self.lear_rate = 0.001\n        # self.lear_rate = 0.01\n        # self.lear_rate = 0.1\n\n    ### perceptron_learn function : This function is called to train the perceptrons \n    ### and weight updation purposes. The first for loop iterates through each training\n    ### example and the first inner for loop is used to calculate the max w.x i.e the \n    ### prediction for a single training example for a group of 10 perceptrons. The\n    ### second inner for loop does the weight updation for all perceptrons.\n    ### Parameters : \n    ###         epoch    :int   - to run through dataset 50 times\n    ###         input_ds :array - to pass the dataset name - train/test as numpy array\n    ###         set_flag :int   - used for not updating weights for test dataset\n    def perceptron_learn(self, epoch,input_ds,set_flag):\n        pred_list = []\n        actual_list = []\n        for i in range(0,input_ds.shape[0]):\n            #print(input_ds[i,-1])\n            target_class = input_ds[i,0].astype('int')\n            target_list = [0,0,0,0,0,0,0,0,0,0]\n            target_list[target_class] = 1\n            \n            xi = input_ds[i].astype('float16')/255\n            xi[0] = self.bias            ## Set the value of x0 to bias unit = 1\n            xi = xi.reshape(1,785)\n            preact_list = []\n            y_list = []\n            actual_list.append(target_class)\n\n            for p in range(10):\n                preact =np.inner(xi,self.weight_arr[p,:])\n                if(preact <= 0):\n                    prediction = 0\n                else:\n                    prediction = 1\n\n                preact_list.append(preact)\n                y_list.append(prediction)\n            \n\n            preact_arr = np.array(preact_list)\n            pred_list.append(np.argmax(preact_arr))\n            if epoch > 0 and set_flag == 1:\n                for q in range(10):\n                    self.weight_arr[q,:] = self.weight_arr[q,:] + (self.lear_rate * (target_list[q] - y_list[q]) * xi)\n        accur = (np.array(pred_list) == np.array(actual_list)).sum()/float(len(actual_list))*100 \n\n\n        if set_flag == 0:\n            print(\"Confusion matrix for test data for epoch \",epoch)\n            print(confusion_matrix(actual_list,pred_list))       \n        return accur     \n\n\n    ### store_accur function: used to store accuracy for each learning rate for either test/train dataset\n    ### into respective csv files.\n    ### Parameters:\n    ###         accur_index : int       - calculated accuracy index for indicating the epoch no.\n    ###         accur       : int       - calculated accuracy\n    ###         input_ds    : string    - the file name with which to store the file with\n    def store_accur(self, accur_index,accur,input_ds):\n        with open(input_ds, 'a', newline='') as myfile:\n         wr = csv.writer(myfile)\n         wr.writerow([accur_index,accur])\n\n\n\ntraining_data = '../input/mnist-in-csv/mnist_train.csv'\ntesting_data = '../input/mnist-in-csv/mnist_test.csv'\nperceptron = Perceptron(training_data, testing_data) \n\n### Loop through training and test data for 50 epochs. calculate the accuracy and pass it to store_accur\n### function         \n\nfor each in range(50):\n    trn_accuracy = perceptron.perceptron_learn(epoch = 0,input_ds = perceptron.train_data, set_flag = 1)\n    perceptron.train_accuracy.append(trn_accuracy)\n    tst_accuracy = perceptron.perceptron_learn(epoch = each,input_ds = perceptron.test_data, set_flag = 0)\n    perceptron.test_accuracy.append(tst_accuracy)\n    perceptron.store_accur(each,trn_accuracy,'train_output'+str(perceptron.lear_rate)+'.csv')\n    perceptron.store_accur(each,tst_accuracy,'test_output'+str(perceptron.lear_rate)+'.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}