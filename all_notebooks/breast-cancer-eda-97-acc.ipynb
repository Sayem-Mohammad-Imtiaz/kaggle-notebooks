{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-17T06:01:29.326428Z","iopub.execute_input":"2021-06-17T06:01:29.327001Z","iopub.status.idle":"2021-06-17T06:01:29.34481Z","shell.execute_reply.started":"2021-06-17T06:01:29.326909Z","shell.execute_reply":"2021-06-17T06:01:29.343798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing important LIberaries\nfrom sklearn.model_selection import GridSearchCV,StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom imblearn.over_sampling import SMOTE\nfrom lightgbm import LGBMClassifier\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport pandas_profiling as pp\nfrom sklearn.svm import SVC\nimport plotly.express as px\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport warnings\n\nwarnings.simplefilter(action='ignore', category=Warning)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:05:36.147836Z","iopub.execute_input":"2021-06-17T06:05:36.148223Z","iopub.status.idle":"2021-06-17T06:05:39.411219Z","shell.execute_reply.started":"2021-06-17T06:05:36.148193Z","shell.execute_reply":"2021-06-17T06:05:39.410251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading data\ndf = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:01:32.53884Z","iopub.execute_input":"2021-06-17T06:01:32.539192Z","iopub.status.idle":"2021-06-17T06:01:32.60833Z","shell.execute_reply.started":"2021-06-17T06:01:32.539162Z","shell.execute_reply":"2021-06-17T06:01:32.607287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shape of data\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:01:33.043388Z","iopub.execute_input":"2021-06-17T06:01:33.043943Z","iopub.status.idle":"2021-06-17T06:01:33.049219Z","shell.execute_reply.started":"2021-06-17T06:01:33.04391Z","shell.execute_reply":"2021-06-17T06:01:33.048288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data type\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:01:33.397927Z","iopub.execute_input":"2021-06-17T06:01:33.398493Z","iopub.status.idle":"2021-06-17T06:01:33.420271Z","shell.execute_reply.started":"2021-06-17T06:01:33.398459Z","shell.execute_reply":"2021-06-17T06:01:33.419321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking null values\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:01:33.734682Z","iopub.execute_input":"2021-06-17T06:01:33.735245Z","iopub.status.idle":"2021-06-17T06:01:33.743755Z","shell.execute_reply.started":"2021-06-17T06:01:33.735212Z","shell.execute_reply":"2021-06-17T06:01:33.742974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> As we can see that the last column Unnamed: 32 has all NaN value so we will drop this column","metadata":{}},{"cell_type":"code","source":"# Droping Unnamed: 32 Column\ndf.drop('Unnamed: 32', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:01:34.321731Z","iopub.execute_input":"2021-06-17T06:01:34.322206Z","iopub.status.idle":"2021-06-17T06:01:34.327901Z","shell.execute_reply.started":"2021-06-17T06:01:34.322165Z","shell.execute_reply":"2021-06-17T06:01:34.327286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Describing the data // Statistical Data analysis\npd.set_option('precision',5)\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:01:34.643303Z","iopub.execute_input":"2021-06-17T06:01:34.643815Z","iopub.status.idle":"2021-06-17T06:01:34.738775Z","shell.execute_reply.started":"2021-06-17T06:01:34.643782Z","shell.execute_reply":"2021-06-17T06:01:34.737893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"code","source":"# Diagnosis Pie chart\nprint(df.diagnosis.value_counts())\ndf.diagnosis.value_counts().plot.pie();","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:01:35.307846Z","iopub.execute_input":"2021-06-17T06:01:35.308224Z","iopub.status.idle":"2021-06-17T06:01:35.450988Z","shell.execute_reply.started":"2021-06-17T06:01:35.308195Z","shell.execute_reply":"2021-06-17T06:01:35.450305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***For All Data***","metadata":{}},{"cell_type":"code","source":"# Heatmap\nplt.figure(figsize=(30,30))\nsns.heatmap(df.corr(),annot = True, cmap = 'ocean');","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:01:35.92022Z","iopub.execute_input":"2021-06-17T06:01:35.920728Z","iopub.status.idle":"2021-06-17T06:01:40.339725Z","shell.execute_reply.started":"2021-06-17T06:01:35.920697Z","shell.execute_reply":"2021-06-17T06:01:40.338915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting Mean Columns\nm_col = ['diagnosis','radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n# Getting Se Columns\ns_col = ['diagnosis','radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se']\n# Getting Worst column\nw_col = ['diagnosis','radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n       'compactness_worst', 'concavity_worst', 'concave points_worst',\n       'symmetry_worst', 'fractal_dimension_worst']","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:01:40.341461Z","iopub.execute_input":"2021-06-17T06:01:40.341834Z","iopub.status.idle":"2021-06-17T06:01:40.348309Z","shell.execute_reply.started":"2021-06-17T06:01:40.341798Z","shell.execute_reply":"2021-06-17T06:01:40.34736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***For Mean Columns***","metadata":{}},{"cell_type":"code","source":"# Heatmap\nplt.figure(figsize=(15,15))\nsns.heatmap(df[m_col].corr(),annot = True, cmap = 'Blues');","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:01:40.350128Z","iopub.execute_input":"2021-06-17T06:01:40.350547Z","iopub.status.idle":"2021-06-17T06:01:41.141469Z","shell.execute_reply.started":"2021-06-17T06:01:40.350511Z","shell.execute_reply":"2021-06-17T06:01:41.140274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pairplot for mean columns\nsns.pairplot(df[m_col],hue = 'diagnosis', palette='Blues');","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:01:41.143303Z","iopub.execute_input":"2021-06-17T06:01:41.143773Z","iopub.status.idle":"2021-06-17T06:02:07.786744Z","shell.execute_reply.started":"2021-06-17T06:01:41.143724Z","shell.execute_reply":"2021-06-17T06:02:07.785454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***For SE columns***","metadata":{}},{"cell_type":"code","source":"# Heatmap for se columns\nplt.figure(figsize=(15,15))\nsns.heatmap(df[s_col].corr(),annot = True, cmap = 'Greens');","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:02:07.788348Z","iopub.execute_input":"2021-06-17T06:02:07.788718Z","iopub.status.idle":"2021-06-17T06:02:08.557151Z","shell.execute_reply.started":"2021-06-17T06:02:07.788675Z","shell.execute_reply":"2021-06-17T06:02:08.556203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pairplot for se columns\nsns.pairplot(df[m_col],hue = 'diagnosis', palette='Greens');","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:02:08.558772Z","iopub.execute_input":"2021-06-17T06:02:08.559447Z","iopub.status.idle":"2021-06-17T06:02:34.929775Z","shell.execute_reply.started":"2021-06-17T06:02:08.559383Z","shell.execute_reply":"2021-06-17T06:02:34.928609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Worst columns***","metadata":{}},{"cell_type":"code","source":"# Heatmap for Worst columns\nplt.figure(figsize=(15,15))\nsns.heatmap(df[w_col].corr(),annot = True, cmap = 'Oranges');","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:02:34.931151Z","iopub.execute_input":"2021-06-17T06:02:34.931483Z","iopub.status.idle":"2021-06-17T06:02:35.704442Z","shell.execute_reply.started":"2021-06-17T06:02:34.931453Z","shell.execute_reply":"2021-06-17T06:02:35.703488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pairplot for worst columns\nsns.pairplot(df[w_col],hue = 'diagnosis', palette='Oranges');","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:02:35.706213Z","iopub.execute_input":"2021-06-17T06:02:35.706532Z","iopub.status.idle":"2021-06-17T06:03:02.015166Z","shell.execute_reply.started":"2021-06-17T06:02:35.706502Z","shell.execute_reply":"2021-06-17T06:03:02.01397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Modeling","metadata":{}},{"cell_type":"code","source":"# Getting Features\nfeatures = ['radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean','radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se','radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n       'compactness_worst', 'concavity_worst', 'concave points_worst',\n       'symmetry_worst', 'fractal_dimension_worst']\nx = df[features]\n\n# Getting Predicting Value\ny = df['diagnosis']","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:04:20.732121Z","iopub.execute_input":"2021-06-17T06:04:20.732451Z","iopub.status.idle":"2021-06-17T06:04:20.739172Z","shell.execute_reply.started":"2021-06-17T06:04:20.732412Z","shell.execute_reply":"2021-06-17T06:04:20.73812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessing(data,features,labels,test_size = 0.2,random_state =42, tune = 'n',cv_folds = 5):\n    \n    print('Checking if labels or features are categorical! [*]\\n')\n    cat_features=[i for i in features.columns if features.dtypes[i]=='object']\n    if len(cat_features) >= 1 :\n        index = []\n        for i in range(0,len(cat_features)):\n            index.append(features.columns.get_loc(cat_features[i]))\n        print('Features are Categorical\\n')\n        ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), index)], remainder='passthrough')\n        print('Encoding Features [*]\\n')\n        features = np.array(ct.fit_transform(features))\n        print('Encoding Features Done [',u'\\u2713',']\\n')\n    if labels.dtype == 'O':\n        le = LabelEncoder()\n        print('Labels are Categorical [*] \\n')\n        print('Encoding Labels \\n')\n        labels = le.fit_transform(labels)\n        print('Encoding Labels Done [',u'\\u2713',']\\n')\n    else:\n        print('Features and labels are not categorical [',u'\\u2713',']\\n')\n        \n    ## SMOTE ---------------------------------------------------------------------\n    print('Applying SMOTE [*]\\n')\n    \n    sm=SMOTE(k_neighbors=4)\n    features,labels=sm.fit_resample(features,labels)\n    print('SMOTE Done [',u'\\u2713',']\\n')\n    \n    ## Splitting ---------------------------------------------------------------------\n    print('Splitting Data into Train and Validation Sets [*]\\n')\n    \n    x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size= test_size, random_state= random_state)\n    print('Splitting Done [',u'\\u2713',']\\n')\n    \n    ## Scaling ---------------------------------------------------------------------\n    print('Scaling Training and Test Sets [*]\\n')\n    \n    sc = StandardScaler()\n    X_train = sc.fit_transform(x_train)\n    X_val = sc.transform(x_test)\n    print('Scaling Done [',u'\\u2713',']\\n')\n    \n    print('Training All Basic Classifiers on Training Set [*] \\n')\n    \n    parameters_svm= [\n    {'kernel': ['rbf'], 'gamma': [0.1, 0.5, 0.9, 1],\n        'C': np.logspace(-4, 4, 5)},\n    ]\n    parameters_lin = [{\n    'penalty': ['l1', 'l2', ],\n    'solver': ['newton-cg', 'liblinear', ],\n    'C': np.logspace(-4, 4, 5),\n    }]\n    parameters_knn = [{\n    'n_neighbors': list(range(0, 11)),\n    'weights': ['uniform', 'distance'],\n    'algorithm': ['auto', 'kd_tree', 'brute'],\n    }]\n    parameters_dt = [{\n    'criterion': ['gini', 'entropy'],\n    'splitter': ['best', 'random'],\n    'max_depth': [4,  6,  8,  10,  12,  20,  40, 70],\n\n    }]\n    parameters_rfc = [{\n    'criterion': ['gini', 'entropy'],\n    'n_estimators': [100, 300, 500, 750, 1000],\n    'max_features': [2, 3],\n    }]\n    parameters_xgb = [{\n    'max_depth': [4,  6,  8,  10],\n    'learning_rate': [0.3, 0.1],\n    }]\n    parameters_lgbm =  {\n    'learning_rate': [0.005, 0.01],\n    'n_estimators': [8,16,24],\n    'boosting_type' : ['gbdt', 'dart'],\n    'objective' : ['binary'],\n    }\n    paramters_pac = {\n        'C': np.logspace(-4, 4, 20)},\n    \n    \n    param_nb={}\n    parameters_ada={\n            'learning_rate': [0.005, 0.01],\n            'n_estimators': [8,16,24],\n    }\n    paramters_sgdc = [{\n    'penalty': ['l2', 'l1', 'elasticnet'],\n    'loss': ['hinge', 'log'],\n    'alpha':np.logspace(-4, 4, 20),\n    }]\n    models =[(\"LR\", LogisticRegression(), parameters_lin),(\"SVC\", SVC(),parameters_svm),('KNN',KNeighborsClassifier(),parameters_knn),\n    (\"DTC\", DecisionTreeClassifier(),parameters_dt),(\"GNB\", GaussianNB(), param_nb),(\"SGDC\", SGDClassifier(), paramters_sgdc),('RF',RandomForestClassifier(),parameters_rfc),\n    ('ADA',AdaBoostClassifier(),parameters_ada),('XGB',GradientBoostingClassifier(),parameters_xgb),('LGBN', LGBMClassifier(),parameters_lgbm),\n    ('PAC',PassiveAggressiveClassifier(),paramters_pac)]\n\n    results = []\n    names = []\n    finalResults = []\n    accres = []\n\n    for name,model, param in models:\n        \n        model.fit(x_train, y_train)\n        model_results = model.predict(x_test)\n        accuracy = accuracy_score(y_test, model_results)\n        print('Validation Accuracy is :',accuracy)\n        print('Applying K-Fold Cross validation on Model {}[*]'.format(name))\n        accuracies = cross_val_score(estimator=model, X=x_train, y=y_train, cv=cv_folds, scoring='accuracy')\n        print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n        acc = accuracies.mean()*100\n        print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100)) \n        results.append(acc)\n        names.append(name)\n        accres.append((name,acc))\n        if tune == 'y' and not name == 'GNB':\n            print('Applying Grid Search Cross validation for model {} []\\n'.format(name))\n            cv_params = param\n            grid_search = GridSearchCV(\n            estimator=model,\n            param_grid=cv_params,\n            scoring='accuracy',\n            cv=cv_folds,\n            n_jobs=-1,\n            verbose=4,\n                )\n            grid_search.fit(X_train, y_train)\n            best_accuracy = grid_search.best_score_\n            best_parameters = grid_search.best_params_\n            print(\"Best Accuracy for model {}: {:.2f} %\".format(name,best_accuracy*100))\n            print(\"Best Parameters: for model {}\".format(name), best_parameters)\n            print('Applying Grid Search Cross validation Done[',u'\\u2713',']\\n')\n            \n        print('Training Compeleted Showing Predictions [',u'\\u2713','] \\n')\n    accres.sort(key=lambda k:k[1],reverse=True)\n    print(\"\\n The Accuracy of the Models Are:\\n \")\n    tab = pd.DataFrame(accres)\n    print(tab)\n    sns.barplot(x=tab[1], y=tab[0], palette='mako');\n    print(\"\\n\\nModel With Highest Accuracy is: \\n\",accres[0],'\\n\\n')","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:04:22.098282Z","iopub.execute_input":"2021-06-17T06:04:22.098838Z","iopub.status.idle":"2021-06-17T06:04:22.127529Z","shell.execute_reply.started":"2021-06-17T06:04:22.098806Z","shell.execute_reply":"2021-06-17T06:04:22.126477Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessing(df,x,y)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T06:05:45.121805Z","iopub.execute_input":"2021-06-17T06:05:45.122186Z","iopub.status.idle":"2021-06-17T06:05:51.707232Z","shell.execute_reply.started":"2021-06-17T06:05:45.122154Z","shell.execute_reply":"2021-06-17T06:05:51.706461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary\n* ***LightGBN was the best here with the accuracy of 97%***","metadata":{}},{"cell_type":"markdown","source":"# Please do leave your valuable feedbacks in the comments and any improvements or suggestions are welcomed!!!!\n***Dont forgot to upvote :)***","metadata":{}}]}