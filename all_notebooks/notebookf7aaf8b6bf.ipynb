{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nimport statsmodels.api as sm\nfrom sklearn.feature_selection import RFE\nfrom sklearn.metrics import r2_score,accuracy_score\nfrom sklearn.metrics import mean_squared_error \nfrom math import sqrt\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import RandomForestRegressor \nfrom sklearn.ensemble import VotingRegressor\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/car-price-prediction/CarPrice_Assignment.csv')\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()/len(data)*100,2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"data.hist(edgecolor ='black',linewidth = 1.2,figsize =(20,20));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_col = data[['fueltype','aspiration','doornumber','carbody','drivewheel','enginelocation','enginetype','cylindernumber','fuelsystem']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(font_scale=1.2)\nplt.figure(figsize=(30, 30))\n\nfor i, column in enumerate(cat_col, 1):\n    plt.subplot(3, 3, i)\n    g = sns.barplot(x=f\"{column}\", y='price', data=data)\n    g.set_xticklabels(g.get_xticklabels(), rotation=90)\n    plt.ylabel('price',fontsize = 30)\n    plt.xlabel(f'{column}',fontsize = 30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Insights from categorical features visualization\n- 1) Gas type car has high price as comparaed to the diesel\n- 2) car with turbo type aspiration has high price\n- 3) doornumber has no significant difference\n- 4) hardtop and convertable body type cars are expensive than others.\n- 5) price of cars with rwd drivewheel's is almost twice the price of cars with fwd and 4wd.\n- 6) front engine cars are very expensive than the rear once.\n- 7) cars having 3 cylinders are very cheaper than  the  price of other types.\n- 8) cost for the cars with 1bbl and 2bbl fuelsystem are almost the same.\n- 9)'ohc', 'l', 'rotor','ohcf',enginetype cars prices are nearly same and twice lesser than the price of 'dohcv'enginetype."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Renaming the typo errors in Car Company names\n\ndata['CarName'] = data['CarName'].replace({'maxda': 'mazda', 'nissan': 'Nissan', 'porcshce': 'porsche', 'toyouta': 'toyota', \n                            'vokswagen': 'volkswagen', 'vw': 'volkswagen'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['CarName'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = data.corr()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,8))\nsns.heatmap(corrmat, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### It is evident that our independent features are multicolinear."},{"metadata":{"trusted":true},"cell_type":"code","source":"one_hot_encoded_df = pd.get_dummies(cat_col)\none_hot_encoded_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cat = data.drop(['car_ID','CarName','fueltype','aspiration','doornumber','carbody','drivewheel','enginelocation','cylindernumber','fuelsystem','enginetype'],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cat.reset_index(drop=True, inplace=True)\none_hot_encoded_df.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df = pd.concat([num_cat,one_hot_encoded_df], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = final_df.drop('price',axis=1)\ny = final_df['price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 21)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bag_reg = BaggingRegressor()\ndt_reg  = DecisionTreeRegressor()\nrf_reg  = RandomForestRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model:1 (Ensemble.Bagging_regressor)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import BaggingRegressor\n\nbag_reg = BaggingRegressor(DecisionTreeRegressor(),   # here we decided the tree as predictor ans takeb as 500, bootstrap = True means we have selected bagging(without replacement) \n                          n_estimators = 500,   # max_saples = 1 means all the data is taken(pasting regressor)\n                          bootstrap = True,\n                          max_samples = 1.0,\n                          n_jobs  = -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bag_reg.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = bag_reg.predict(X_test)\n\ndf = pd.DataFrame({'Actual':y_test,\n                  'Predicted':y_pred})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\nscore = r2_score(y_test,y_pred)\nprint(\"predict score\",score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_train = bag_reg.predict(X_train)\nscore = r2_score(y_pred_train,y_train)\nprint('train prediction score',score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn import metrics\n# print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n# print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n# print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.plot(y_pred,label = 'Predicted')\nplt.plot(y_test.values,label = 'Actual')\n\nplt.ylabel('price',fontsize = 10)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model:2 (DT_regressor)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor  # Import Decision Tree Regression model\n\ndecision_tree_reg = DecisionTreeRegressor(max_depth=5, random_state=21)  # Create a instance for Decision Tree Regression model\ndecision_tree_reg.fit(X_train, y_train)  # Fit data to the model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction with training dataset:\ny_pred_DTR_train = decision_tree_reg.predict(X_train)\n\n# Prediction with testing dataset:\ny_pred_DTR_test = decision_tree_reg.predict(X_test)\n\n# Find training accuracy for this model:\naccuracy_DTR_train = r2_score(y_train, y_pred_DTR_train)\nprint(\"Training Accuracy for Decision Tree Regression Model: \", accuracy_DTR_train)\n\n# Find testing accuracy for this model:\naccuracy_DTR_test = r2_score(y_test, y_pred_DTR_test)\nprint(\"Testing Accuracy for Decision Tree Regression Model: \", accuracy_DTR_test)\n\n# Find RMSE for training data:\nRMSE_DTR_train = sqrt(mean_squared_error(y_train, y_pred_DTR_train))\nprint(\"RMSE for Training Data: \", RMSE_DTR_train)\n\n# Find RMSE for testing data:\nRMSE_DTR_test = sqrt(mean_squared_error(y_test, y_pred_DTR_test))\nprint(\"RMSE for Testing Data: \", RMSE_DTR_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model:3 (RF_regressor)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor  # Import Random Forest Regression model\n\nrandom_forest_reg = RandomForestRegressor(n_estimators=1500, max_depth=5, random_state=21)  # Create a instance for Random Forest Regression model\nrandom_forest_reg.fit(X_train, y_train)  # Fit data to the model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_forest_reg = RandomForestRegressor(n_estimators=1500, max_depth=5, random_state=21)  # Create a instance for Random Forest Regression model\nrandom_forest_reg.fit(X_train, y_train)  # Fit data to the model\n\n# Prediction with training dataset:\ny_pred_RFR_train = random_forest_reg.predict(X_train)\n\n# Prediction with testing dataset:\ny_pred_RFR_test = random_forest_reg.predict(X_test)\n\n# Find training accuracy for this model:\naccuracy_RFR_train = r2_score(y_train, y_pred_RFR_train)\nprint(\"Training Accuracy for Random Forest Regression Model: \", accuracy_RFR_train)\n\n# Find testing accuracy for this model:\naccuracy_RFR_test = r2_score(y_test, y_pred_RFR_test)\nprint(\"Testing Accuracy for Random Forest Regression Model: \", accuracy_RFR_test)\n\n# Find RMSE for training data:\nRMSE_RFR_train = sqrt(mean_squared_error(y_train, y_pred_RFR_train))\nprint(\"RMSE for Training Data: \", RMSE_RFR_train)\n\n# Find RMSE for testing data:\nRMSE_RFR_test = sqrt(mean_squared_error(y_test, y_pred_RFR_test))\nprint(\"RMSE for Testing Data: \", RMSE_RFR_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\nn_estimators = [100, 500, 1000, 1500]\nmax_features = ['auto', 'sqrt']\nmax_depth = [2, 3, 5]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4, 10]\n\nparams_grid = {'n_estimators': n_estimators, 'max_features': max_features,\n               'max_depth': max_depth, 'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}\n\n\nrf_clf = RandomForestRegressor(random_state=42)\n\nrf_cv = GridSearchCV(rf_clf, params_grid, scoring=\"neg_mean_squared_error\", cv=3, verbose=2, n_jobs=-1)\n\n\nrf_cv.fit(X_train, y_train)\nbest_params = rf_cv.best_params_\nprint(f\"Best parameters: {best_params}\")\n\nrf_clf = RandomForestRegressor(**best_params)\nrf_clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction with training dataset:\ny_pred_RFR_train = rf_clf.predict(X_train)\n\n# Prediction with testing dataset:\ny_pred_RFR_test = rf_clf.predict(X_test)\n\n# Find training accuracy for this model:\naccuracy_RFR_train = r2_score(y_train, y_pred_RFR_train)\nprint(\"Training Accuracy for Random Forest Regression Model: \", accuracy_RFR_train)\n\n# Find testing accuracy for this model:\naccuracy_RFR_test = r2_score(y_test, y_pred_RFR_test)\nprint(\"Testing Accuracy for Random Forest Regression Model: \", accuracy_RFR_test)\n\n# Find RMSE for training data:\nRMSE_RFR_train = sqrt(mean_squared_error(y_train, y_pred_RFR_train))\nprint(\"RMSE for Training Data: \", RMSE_RFR_train)\n\n# Find RMSE for testing data:\nRMSE_RFR_test = sqrt(mean_squared_error(y_test, y_pred_RFR_test))\nprint(\"RMSE for Testing Data: \", RMSE_RFR_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Voting Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor_1 = bag_reg\nregressor_2 = decision_tree_reg\nregressor_3 = rf_clf\n\n# regressor_1.fit(X_train,y_train)\n# regressor_2.fit(X_train,y_train)\n# regressor_3.fit(X_train,y_train)\nvt_reg  = [('Bagging_regressor', regressor_1), ('DT_regressor', regressor_2), ('RF_regressor', regressor_3)]\nvr = VotingRegressor(estimators=vt_reg)\nvr.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(\"Bagging Regressor Train score:\",regressor_1.score(X_train,y_train))\nprint(\"Bagging Regressor Test score:\",regressor_1.score(X_test,y_test))\n\nprint(\"Decision Tree Train score:\",regressor_2.score(X_train,y_train))\nprint(\"Decision Tree Test score:\",regressor_2.score(X_test,y_test))\n\nprint(\"Random Forest Train score:\",regressor_3.score(X_train,y_train))\nprint(\"Random Forest Test score:\",regressor_3.score(X_test,y_test))\n\nprint(\"Voting Regressor Train score:\",vr.score(X_train,y_train))\nprint(\"Voting Regressor Test score:\",vr.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_1 = regressor_1.predict(X_test)\npred_2 = regressor_2.predict(X_test)\npred_3 = regressor_3.predict(X_test)\npred_4 = vr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Finally, we will visualize the predictions. The red stars show the average prediction made by VotingRegressor."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.plot(pred_1, 'gd', label='BaggingRegressor')\nplt.plot(pred_2, 'b^', label='DecisionTreeRegressor')\nplt.plot(pred_3, 'ys', label='RandomForestRegressor')\nplt.plot(pred_4, 'r*', ms=10, label='VotingRegressor')\n\nplt.tick_params(axis='x', which='both', bottom=False, top=False,\n                labelbottom=False)\nplt.ylabel('predicted')\nplt.xlabel('training samples')\nplt.legend(loc=\"best\")\nplt.title('Regressor predictions and their average')\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}