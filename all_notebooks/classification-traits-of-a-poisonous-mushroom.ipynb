{"cells":[{"metadata":{"_uuid":"138c805fb1f4078fe9c7ab8b70c5befe3fa05948"},"cell_type":"markdown","source":"   # <center>Classification of poisonous mushroom</center>\n![](https://kennettmushrooms.com/wp-content/uploads/2017/05/fungi-funnys-570x285.jpg)"},{"metadata":{"_uuid":"50363248d50fecf8fe7fdec51e77fbbc984cce16"},"cell_type":"markdown","source":"## About  Mushroom dataset "},{"metadata":{"_uuid":"711cb62d7bc4045accbbb7a654284842305131f1"},"cell_type":"markdown","source":"First column is a classifier\n0. Class : edible e, poisonous p\n\nRest of the columns are \n1. cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s \n2. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s \n3. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y \n4. bruises?: bruises=t,no=f \n5. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s \n...."},{"metadata":{"_uuid":"c553e46706aa833181d2f2c68dfddef2e0a15aa4"},"cell_type":"markdown","source":"## Approach"},{"metadata":{"_uuid":"1f617c865d359f6ad88409f4f1e57a0b0362ac8b"},"cell_type":"markdown","source":"1. Separate X and y variables \n2. Use Label encoder to replace text data\n3. Design multicolumn one hot encoder\n4. Predict results\n5. Review optimal K \n6. Finding traits of poisonous Mushroom"},{"metadata":{"_uuid":"595c4ba7774516bae67c73b1df9ef7004c37cddf"},"cell_type":"markdown","source":"Notes : \n- There are several columns of categorical variables. We need to avoid dummy variable Trap\n- Find a way to rename the columns after one hot encoder operation is done"},{"metadata":{"trusted":true,"_uuid":"096924ef99c971cfb268902bf7d627c84f6f24ee"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"830260ffc1273ed40754f71c56d7f6cd4b1e1823"},"cell_type":"markdown","source":"## 1. Separate X and y  variables"},{"metadata":{"trusted":true,"_uuid":"a430385e55089fe9caa651cee72042e4c20bfd1d"},"cell_type":"code","source":"add = \"../input/mushrooms.csv\"\ndata = pd.read_csv(add)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0491dbc406755ea49923030ae24534eb899374f"},"cell_type":"code","source":"# seperating X vaules from y values\nX= data.iloc[:,1:]\ny = data.iloc[:,0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3cc093c50771dda1b637d66ed71559b53b5912f7"},"cell_type":"markdown","source":"## 2.Use Label encoder to replace text data"},{"metadata":{"trusted":true,"_uuid":"415c385b6eacd5e9abe17d2455656b901a0ad4ee"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom collections import defaultdict\nd = defaultdict (LabelEncoder)\nXfit = X.apply(lambda x: d[x.name].fit_transform(x))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"164390cfce42484e33e39c482f9f1f7cc635e978"},"cell_type":"code","source":"le_y = LabelEncoder()\nyfit = le_y.fit_transform(y)\n# for x in Xfit.columns:\n#     print(x)\n#     print(Xfit[x].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fad6df3312eaf790e5dec9ae0554905488a09e6f"},"cell_type":"markdown","source":"## 3. Design Multi-column One Hot encoder "},{"metadata":{"_uuid":"23a4b032fbe5f394881ca06f4facc3a681a79edf"},"cell_type":"markdown","source":"- Need to avoid dummy variable trap\n- Using the \"d\" the defaultdictionary to rename columns after one hot encoder\n- appending new columns after encoding into \"final\" variable"},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"ba09b14a787208325506c9e9441687348428ec8c"},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.preprocessing import OneHotEncoder\nohc = defaultdict (OneHotEncoder)\n# Xfit_ohc = Xfit.apply(lambda x: ohc[x.name].fit_transform(x))\nfinal = pd.DataFrame()\n\nfor i in range(22):\n    # transforming the columns using One hot encoder\n    Xtemp_i = pd.DataFrame(ohc[Xfit.columns[i]].fit_transform(Xfit.iloc[:,i:i+1]).toarray())\n   \n    #Naming the columns as per label encoder\n    ohc_obj  = ohc[Xfit.columns[i]]\n    labelEncoder_i= d[Xfit.columns[i]]\n    Xtemp_i.columns= Xfit.columns[i]+\"_\"+labelEncoder_i.inverse_transform(ohc_obj.active_features_)\n    \n    # taking care of dummy variable trap\n    X_ohc_i = Xtemp_i.iloc[:,1:]\n    \n    #appending the columns to final dataframe\n    final = pd.concat([final,X_ohc_i],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"881a4e7601ef0eeac4f77d01f75fa2b31e42d9cf"},"cell_type":"code","source":"final.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d476a9246a6a734317ddf2b25057b31d94073cd"},"cell_type":"code","source":"final.head(20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ada874dc5ad274ce7231f923ee356da58c2ae6e"},"cell_type":"markdown","source":"###  Compare final vs data "},{"metadata":{"trusted":true,"_uuid":"5ab53d6c15fa9025ef564b80859beed441a3bc3f"},"cell_type":"code","source":"final[1:4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2315faa089796eb0db52e8f31a9b6a43d8b2769a"},"cell_type":"code","source":"data[1:4]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"deb67caa4f88038fa74d4a25abbf1495039d06b7"},"cell_type":"markdown","source":"## 4. Predict results"},{"metadata":{"trusted":true,"_uuid":"daea2d372d4765ba9bf717cbae96e710c1ded48d"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(final, yfit, test_size = 0.1, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f38134a4fc3ee89a813c25e198b5535a470a52cc"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nclassifier =  KNeighborsClassifier(n_neighbors=30,p=2, metric='minkowski')\nclassifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95537fbbc7a9ed2cfe2600810652e366c2e6e925"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm= confusion_matrix(y_test,y_pred)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a03226145a9dc2fcbd8508195ce8e1c4db11999"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"204c449becba1d823e30efe954d2d2fb3a1bd61e"},"cell_type":"code","source":"classif =  KNeighborsClassifier(n_neighbors=200,p=2, metric='minkowski')\nclassif.fit(X_train,y_train)\ny_pred = classif.predict(X_test)\naccuracy_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce807b95f9c7e4fb9e8b6da3b88d03c835e71363"},"cell_type":"markdown","source":"## 5. Review optimal K "},{"metadata":{"trusted":true,"_uuid":"ef4bc87fbb959d2f381c47ed8c1fd76a856303d8"},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\n# creating odd list of K for KNN\nmyList = list(range(1,200))\n\n# empty list that will hold cv scores\ncv_scores = []\n\n# perform 10-fold cross validation\nfor k in myList[::2]:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n    cv_scores.append(scores.mean())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"306eb133e872221989e313019f271f70708e9f24"},"cell_type":"code","source":"from matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"173c2cdaaa1790a6a9d1a90773cca61c4131397e"},"cell_type":"code","source":"# changing to misclassification error\nMSE = [1 - x for x in cv_scores]\n\n# determining best k\noptimal_k = myList[::2][MSE.index(min(MSE))]\nprint (\"The optimal number of neighbors is %d\" % optimal_k)\n\n# plot misclassification error vs k\nplt.plot(myList[::2], MSE)\nplt.xlabel('Number of Neighbors K')\nplt.ylabel('Misclassification Error')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"44a09e77f7836a95da1a1ceff08a3418ec1ef0ea"},"cell_type":"markdown","source":"KNN provides us a power classifier but finding optimal value of K is very critical. We can take additional test data sets and measure performance with current K = 30 to calibrate and avoid overfit\n"},{"metadata":{"_uuid":"cc4173a1d33c70718d664610defdc22ab55ae081"},"cell_type":"markdown","source":"## 6.  Finding traits of poisonous mushrooms\n( Feature importance in K-NN )"},{"metadata":{"_uuid":"1354f88281ad257d09b0f4e4b32a4c46e01275d9"},"cell_type":"markdown","source":"##  If I am in the Jungle : How do I survive on mushroom without K-NN\n\nTo answer the above question. We need to find the most significant feature "},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"922e41399e9511452e2114797714fe49e26cdb66"},"cell_type":"code","source":"n_features = final.shape[1]\nclf = KNeighborsClassifier()\nfeature_score = []\n\nfor i in range(n_features):\n    X_feature= np.reshape(final.iloc[:,i:i+1],-1,1)\n    scores = cross_val_score(clf, X_feature, yfit)\n    feature_score.append(scores.mean())\n    print('%40s        %g' % (final.columns[i], scores.mean()))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aecf67458ec7c2ccd988f541f558ebc3709248f7"},"cell_type":"markdown","source":"## The 5 most important factors : to determine poisonous or not"},{"metadata":{"trusted":true,"_uuid":"8d99b9400ca6247fd527fc8b6dbdd54af7dbf579"},"cell_type":"code","source":"feat_imp = pd.Series(data = feature_score, index = final.columns)\nfeat_imp.sort_values(ascending=False, inplace=True)\nfeat_imp[feat_imp>0.7]\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74a7be3e55c19c9553f71152f513a87de63541d9"},"cell_type":"markdown","source":" Question from the Jungle : <b>Should I eat or not ? considering factors</b>\n\nAnswer : Need to deep dive to figure out the positive or negative correlation !\n\n"},{"metadata":{"trusted":true,"_uuid":"14e80f4070c0bea2aae4067a69425cd3df31b262"},"cell_type":"code","source":"columns_imp = feat_imp[feat_imp>0.7].index.values\nfinal_Xy= pd.concat([final,pd.DataFrame(yfit,columns=['class'])], axis=1)\ngrouped = final_Xy.groupby('class')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a506319fdd346547cd5bf549a4c1f22f5418cd2e"},"cell_type":"code","source":"# Edible group of mushrooms\ngrouped.get_group(0)[columns_imp].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"862568ad1a9b2e3ad313258302552ede9c707506"},"cell_type":"code","source":"# Poisonous group of mushrooms\ngrouped.get_group(1)[columns_imp].sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f224a042fce5480cc24f8797b3a3a23f4674650"},"cell_type":"markdown","source":"## Final Conclusion"},{"metadata":{"_uuid":"749e2193c8b48eb587b4e7bc6e8f45c00d0e9221"},"cell_type":"markdown","source":"   # <center>For more clarity on parts of a mushroom</center>\n \n![Parts of mushroom](https://infovisual.info/storage/app/media/01/img_en/024%20Mushroom.jpg)\n\nNow, it is pretty clear that all these factors indicate a poisonous mushroom.\n\n <b> DO NOT EAT A MUSHROOM if : </b>\n1. <b> Odor is foul </b>\n2. <b> Stalk surface above ring is  silky </b>\n3. <b> Stalk surface below ring is  silky </b>\n4. <b> Gill size is narrow </b>\n5. <b> Spore prints are chocolatey in color </b>"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}