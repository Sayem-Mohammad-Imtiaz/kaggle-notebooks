{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1>Вовед</h1>\n\nИмаме податоци кои се класифицирани дали пациентите имаат срцеви заболувања или не според карактеристиките во него. Ќе се обидам да ги искористам овие податоци за да создадам модел што ќе се обиде да предвиди дали пациентот има оваа болест или не. Ќе користам алгоритам за логистичка регресија (класификација)."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Првенствено ги внесуваме сите пакети што ќе ни бидат потребни за анализа на овој датасет\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\n\nimport os\nimport os\nprint(os.listdir(\"../input\"))\n\n# Последниве три реда се автоматски генерирани од Kaggle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Читање на податоците</h1>"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# Ги читаме податоците\nheart = pd.read_csv(\"../input/heart-disease-uci/heart.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Првите 5 реда од податоците\nheart.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Податоците содржат:\n* \n* age - години\n* sex - (1 = машко; 0 = женско)\n* cp - вид на болка во градите(chest pain)\n* trestbps - крвен притисок при одморање (во mm Hg при прием во болница)\n* chol - холестерол во mg/dl\n* fbs - (шеќер во крвта > 120 mg/dl) (1 = точно; 0 = неточно) (кратенка од fasting blood sugar)\n* restecg - резултати од електрокардиограм при одморање\n* thalach - максимален пулс\n* exang - ангина индуцирана при вежбање (1 = да; 0 = не) (exercise induced angina)\n* oldpeak - ST депресија индуцирана од вежбање релативно со одмор\n* slope - наклон на врвот на ST сегментот при вежбање\n* ca - број на главни крвни садови обоени со флуороскопија (0-3) \n* thal - 3 = нормално; 6 = поправен дефект; 7 = реверзибилен дефект\n* target - have disease or not (1=yes, 0=no)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Број на луѓе што ја имаат/немаат заболување\nheart.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# На график ги прикажуваме бројот на луѓето што немаат и имаат заболување\nsns.countplot(x=\"target\", data=heart)\nplt.xlabel(\"Заболување (0 = нема, 1 = има)\")\nplt.ylabel('Број')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Го наоѓаме процентот на пациенти што имаат и немаат заболување\nnema_bolest = len(heart[heart.target == 0])\nima_bolest = len(heart[heart.target == 1])\nbroj_na_zaboleni = len(heart.target)\nprint(\"Процент на пациенти што немаат заболување: {:.2f}%\".format((nema_bolest / broj_na_zaboleni)*100))\nprint(\"Процент на пациенти што имаат заболување: {:.2f}%\".format((ima_bolest / broj_na_zaboleni)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ги претставуваме машките и женските пациенти на график\nsns.countplot(x='sex', data=heart)\nplt.xlabel(\"Пол (0 = женски, 1= машки)\")\nplt.ylabel('Број')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Го наоѓаме процентот на машки и женски пациенти\nbroj_zenski = len(heart[heart.sex == 0])\nbroj_maski = len(heart[heart.sex == 1])\nbroj_pacienti = len(heart.sex)\nprint(\"Процент на женски пациенти: {:.2f}%\".format((broj_zenski / broj_pacienti)*100))\nprint(\"Процент на машки пациенти: {:.2f}%\".format((broj_maski / broj_pacienti)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(heart.age,heart.target).plot(kind=\"bar\",figsize=(20,6))\nplt.title('Зачестеност на срцеви заболувања споредбено со возраста на пациентот')\nplt.xlabel('Возраст')\nplt.ylabel('Зачестеност')\nplt.legend([\"Нема заболување\", \"Има заболување \"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(heart.sex,heart.target).plot(kind=\"bar\",figsize=(20,6))\nplt.title('Зачестеност на срцеви заболувања споредбено со полот на пациентот')\nplt.xlabel('Пол (0 = женски, 1 = машки)')\nplt.xticks(rotation=0)\nplt.legend([\"Нема заболување\", \"Има заболување\"])\nplt.ylabel('Зачестеност')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Создавање на модели</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = heart.target.values\nx_data = heart.drop(['target'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Нормализирање на податоците</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ги менуваме вредностите да бидат во опсегот од 0 до 1\nx = (x_data - np.min(x_data)) / (np.max(x_data) - np.min(x_data)).values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ќе ги поделиме податоците во размер 80:20. 80 проценти ќе бидат користени за тренинг на моделот, а 20 проценти ќе ги искористиме за тест."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Логистичка регресија</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Логистичка регресија (accuracy и f1_score)\naccuracies = {}\nf1_scores = {}\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nlr = LogisticRegression()\nlr.fit(x_train,y_train)\npred_lr = lr.predict(x_test)\nacc = lr.score(x_test,y_test)*100\naccuracies['Logistic Regression'] = acc\nprint(\"Прецизност на моделот со логистичка регресија {:.2f}%\".format(acc))\nf1_score_lr = f1_score(pred_lr, y_test)*100\n\nf1_scores['Logistic Regression F1'] = f1_score_lr\nprint('F1 Score from Logistic Regression: {:.2f}%'.format(f1_score_lr))\n\nlr_scores_cvs = cross_val_score(lr, x_data, y, cv=10, scoring='accuracy')\nprint('Scores from 10 Fold Cross Validation with Logistic Regression',lr_scores_cvs)\n\nprint(max(lr_scores_cvs))\nprint(min(lr_scores_cvs))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Овој модел работи со 85.25% прецизност."},{"metadata":{},"cell_type":"markdown","source":"<h2>Random Forest Класификација</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest Класификација (accuracy, f1_score и feature importances)\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(random_state = 0)\nrf.fit(x_train, y_train)\npred_rf = rf.predict(x_test)\nacc = rf.score(x_test,y_test)*100\naccuracies['Random Forest'] = acc\nprint(\"Прецизност на моделот со Random Forest : {:.2f}%\".format(acc))\nf1_score_rf = f1_score(pred_rf, y_test)*100\nf1_scores['Random Forest F1'] = f1_score_rf\nprint('F1 Score from Logistic Regression: {:.2f}%'.format(f1_score_rf))\n\nrf_scores_cvs = cross_val_score(rf, x_data, y, cv=10, scoring='accuracy')\nprint('Scores from 10 Fold Cross Validation with Random Forest',rf_scores_cvs)\n\nprint(max(rf_scores_cvs))\nprint(min(rf_scores_cvs))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Овој модел работи со 88.52% прецизност."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature importances\nprint('The feature importances using Random Forest Classifier are:',rf.feature_importances_)\n\n#Секоја колона со соодветната важност\nfor i in range(0, len(heart.columns)-1):\n    print(heart.columns[i], rf.feature_importances_[i]*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Support Vector Machine</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Support Vector Machine Класификација (accuracy, и f1_score\n\nfrom sklearn.svm import SVC\nsvm = SVC(random_state = 0)\nsvm.fit(x_train, y_train)\npred_svc = svm.predict(x_test)\nacc = svm.score(x_test,y_test)*100\naccuracies['SVM'] = acc\nprint(\"Прецизност на моделот со SVM Algorithm: {:.2f}%\".format(acc))\nf1_score_svc = f1_score(pred_svc, y_test)*100\nf1_scores['SVC F1'] = f1_score_svc\nprint('F1 Score from Logistic Regression: {:.2f}%'.format(f1_score_svc))\n\nsvc_scores_cvs = cross_val_score(svm, x_data, y, cv=10, scoring='accuracy')\nprint('Scores from 10 Fold Cross Validation with SVM',svc_scores_cvs)\n\nprint(max(svc_scores_cvs))\nprint(min(svc_scores_cvs))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Овој модел работи со 81.97% прецизност"},{"metadata":{},"cell_type":"markdown","source":"<h2>Исцртување на точноста на трите методи</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = [\"purple\", \"green\", \"orange\"]\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(16,5))\nplt.yticks(np.arange(0,100,2))\nplt.ylabel(\"Accuracy %\")\nplt.xlabel(\"Algorithms\")\nplt.ylim(80, 90)\nsns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()), palette=colors)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Исцртување на F1 Scores на трите методи</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = [\"purple\", \"green\", \"orange\"]\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(16,5))\nplt.yticks(np.arange(0,100,2))\nplt.ylim(80, 90)\nplt.ylabel(\"Accuracy %\")\nplt.xlabel(\"F1 Scores\")\nsns.barplot(x=list(f1_scores.keys()), y=list(f1_scores.values()), palette=colors)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Confusion Matrices</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Исцртување на confusion матрица за сите три методи\n\nfrom sklearn.metrics import confusion_matrix\n\ny_lr = lr.predict(x_test)\ny_svm = svm.predict(x_test)\ny_rf = rf.predict(x_test)\n\ncm_lr = confusion_matrix(y_test,y_lr)\ncm_svm = confusion_matrix(y_test,y_svm)\ncm_rf = confusion_matrix(y_test,y_rf)\n\nplt.figure(figsize=(24,12))\nplt.suptitle(\"Confusion Matrices\",fontsize=24)\n\nplt.subplot(1,3,1)\nplt.title(\"Logistic Regression Confusion Matrix\")\nsns.heatmap(cm_lr,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24})\n\nplt.subplot(1,3,2)\nplt.title(\"Support Vector Machine Confusion Matrix\")\nsns.heatmap(cm_svm,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24})\n\nplt.subplot(1,3,3)\nplt.title(\"Random Forest Confusion Matrix\")\nsns.heatmap(cm_rf,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 24})\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Опис на проблемот</h3>\n\nСрцевите заболувања опишуваат низа состојби кои влијаат на срцето. Болести под сферата на срцеви заболувања вклучуваат болести на крвните садови, како што е корорнарна артериска болест; проблеми со срцевиот ритам (аритмии); и срцеви мани, меѓу кои и оние кои се присутни при раѓање (вродени срцеви мани).\n\nТерминот \"срцеви заболувања\" често се користи наизменично со терминот \"кардиоваскуларна болест\". Кардиоваскуларните заболувања обично се однесуваат на состојби кои вклучуваат стеснети или блокирани крвни садови кои можат да доведат до срцев удар, болка во градите (ангина) или мозочен удар. Други срцеви заболувања, како оние што влијаат на срцевиот мускул, вентилите или ритамот, исто така се сметаат за форми на срцеви заболувања.\n\nМногу форми на срцеви заболувања може да се спречат или третираат со здрав избор на живот\n\nСимптомите на кардиоваскуларни заболувања може да бидат различни кај мажите и жените. На пример, мажите имаат поголема веројатност да имаат болка во градите; жените имаат поголема веројатност да имаат други симптоми заедно со непријатност во градите, како што се скратен здив, гадење и екстремен умор.\n\nСимптомите можат да вклучуваат:\n\n* Болка во градите, затегнатост на градите, притисок на градите и непријатност во градите (ангина)\n* Скратен здив\n* Болка, вкочанетост, слабост или студ во нозете или рацете ако крвните садови во тие делови на вашето тело се стеснети\n* Болка во вратот, вилицата, грлото, горниот дел на стомакот или грбот\n\n(Инфомрациите погоре се од Светската Здравствена Организација - СЗО)\n\nПри сите овие информации, битно е да се посочи дека најголемиот убиец на светот се срцевите заболувања. Затоа е многу важно што порано, побрзо и поефикасно да се открие заболувањето, додека има време да се лечи или спречи. Брзиот развој на технологијата ни го овозможува тоа во формата на машинско учење. Притоа, се собираат податоци за луѓето кои имаат и немаат срцеви заболувања и вз база на алгоритам можеме да откриеме со колкава веројатност некој нов пациент би можел да има заболување. Овој датасет е релативно мал но сепак ќе ми послужи како легитимна анализа. Ова е проблем на класификација и има 13 features и 1 target класа, при што има вкупно 303 податоци за пациенти. Од овие 303 пациенти, 165(54.46%) имаат заболување а 138(45.54%) немаат заболување. Бројот на пациентите шти имаат и немаат болест е релативно близок и можам да започнам со обработка на податоците. Притоа, во оваа анализа битен е и полот на пациентот и има 31.68% женски пациенти а 68.32% машки пациенти. Овие податоци се земени од Кливленд и се направени со цел да се индикација за здравјето на срцето.\n\nПритоа, прв чекор кон решавање на овој проблем ми е скалирање на вредостите на целиот датасет во опсег (0,1) со цел олеснување на понатамошниот тек на настани. \n\nВо моето решение на овој проблем, користам три методи на класификација:\n\n* Логистичка регресија\n* Random Forest\n* Support Vector Machine\n\nЗа сите три методи се користат истите четири променливи од функцијијата train_test_split. Со неа целото множество го делам на множество за тестирање и множество за тренинг. Притоа, множеството го делам во размер 80:20. Сите овие три методи се всушност алгоритми за класификација и даваат одреден резултат за нивната прецизност. Заедно со тоа пресметувам и f1 score со кој дознавам колку има true positives/false negatives. Во принцип, не сакам овој аглоритам да означи здрав човек со срцево заболување ниту пак болен човек како здрав. Процентот на f1 score ми кажува колку можам да бидам сигурен во тоа дека прецизноста е сосем точна. Освен тоа, правам и Cross Validation. Ова е доста класична и основна техника за евалуација на моделот. На пример, во мојот слчај ја правам оваа метода 10 пати. Множеството за тренинг тогаш се дели на 10 еднакви дела од кои самиот алгоритам бира еден. Тогаш алгоритмот се тренира на останатите 9 поделоци и се тестира на последниот, и целата оваа постапка се извршува 10 пати. Притоа, ни го враќа процентот на прецизност од секоја итерација. Доколку оваа метода ми даде подобри резултати од нашето првично мерење, можам да ги менувам параметрите и да го достигнам тоа ниво на прецизност. Исто така оваа техника помага многу во однос на тоа дали станува збор за overfitting. \n\n<h3>Логистичка регресија</h3>\n\nОва е првиот статистички модел кој го правам. Имено, кога имаме бинарни множества, во случајот дали пациент има или нема болест, еден од најдобрите модели е самата логистичка регресија. Сите податоци може да се најдат на одредено место на одредена сигмоидна функција во вид на издолжено Ѕ по х - оската. Оваа функција дава вредности од 0 до 1 и ни кажува со колкава веројатност новиот пациент би можел да има или да нема заболување врз база на претходниот тренинг. Притоа во моето решение со самиот овој метод добив вредност на точност 85.25%, f1 score 87.32%. Дополнително од 10 Fold Cross Validation сите 10 добиени вредности се во опсегот од 69% до 90% точност. Од тука прозилегува дека сепак не станува збор за overfitting и дека логистичката регресија дава добри резултати и истовремено поставува висока конкуренција за останатите модели.\n\n<h3>Random Forest</h3>\n\nОвој метод претставува подобрена верзија на Decision Tree моделот. Самиот Random Forest може да се класифицира како повеќе дрва на одлуки во едно. Во овој метод по случаен избор се бираат карактеристиките и се прават многу дрва на одлуки. Откако тоа е направено, секој од новите тест пациенти од податочната база поминуваат низ сите овие дрва на одлуки. Откако тоа е завршено, секое дрво го класифицира пациентот, дали има заболување или нема. Потоа се собираат сите информации од сите дрвја и се избира поголемиот број и тогаш новиот пациент се декларира со заболување или без. Бидејќи има многу дрва на одлуки, самиот модел наликува на шума и ние можеме да избереме колку дрва ќе има во неа. Единствено нешто во кое ние не можеме да имаме никаков удел е случајноста на подредувањето на карактеристиките. Ова го прави моделот подобар бидејќи нема да има многу биас во моделот, а со самото тоа може и да се реши проблемот на overfitting. Овој метод, во мојот случај дава точност од 88.52%, f1 score 89.55%, а 10 Fold Cross Validation е од опсег 65% до 94%.\n\n<h3>Support Vector Machine</h3>\n\n\nSVM е модел кој со оглед на обележаните податоци за обука (надгледувано учење), алгоритмот испорачува оптимална функција која категоризира нови примери. На два димензионални простори, овој функција е линија што ја дели рамнината на два дела каде во секоја класа лежи или на едната или другата страна. На пример во овој случај алгоритамот ги дели пациентите на оние кои имаат заболување или немаат заболување со строга граница. Врз база на пациентите од тренинг множетвото тоа ни кажува во кој дел ќе спаѓаат новите пациенти. Овој метод дава точност од 81.97%, f1 score 84.93% а 10 Fold Cross Validation е од опсег 53% до 55%. Гледаме дека процентот на точност опаѓа кога правам cross validation. Тоа е бидејќи датасетот е доста мал (има само 303 примероци). Златното правило во овие случаји е да се добијат повеќе податоци за да може подобро да се определи прецизноста.\n\n<h3>Заклучок</h3>\n\nНа самите графици се приметува дека Random Forest е најдобриот модел од овие три. Тој ги дава најдобрите резултати како и најдобра вредност за f1 score. Исто така, самата Cross Validation ни кажува дека може да се достигне прецизност од 94% што значително би го подобрило моделот. Самите графици и нумерички резултати ни го потврдуваат ова. Бидејќи немам доволно податоци, Cross Validation ни дава доста голем опсег на прецизностите."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}