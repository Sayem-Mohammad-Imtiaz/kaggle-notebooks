{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install imageai --upgrade\n!pip install efficientnet","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport requests\nfrom zipfile import ZipFile\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras import models\nfrom imageai.Detection import ObjectDetection\nimport efficientnet.keras as efn\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"fb = pd.read_csv('../input/facebookdata/age_gender_fb.csv')\nfb = fb.set_index('_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '../input/facebookdata/fbdata/fbdata'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle \n\nbb_d = {}\nfor i in range(5):\n  fn = '../input/facebookdata/bb'+str(i)+'.pickle'\n  with open(fn,'rb') as handle:\n    b = pickle.load(handle)\n    bb_d.update(b)\n    \nimport copy\n\ntemp = copy.deepcopy(bb_d)\nbb_d = {}\nfor k,v in temp.items():\n  if k in fb.index.to_numpy():\n    bb_d[k] = v","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_hist(a,title):\n    pd.Series(np.array(a)).value_counts().sort_index().plot(kind='bar',title=title)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Info"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_hist(fb.compress_age,'Histogram of age class')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = [len(v) for k,v in bb_d.items()]\nplot_hist(l,'Histogram of number of bounding boxes')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = [v[0][4] for k,v in bb_d.items() if len(v)>0]\nplt.hist(l,bins=40)\nplt.title('Histogram of confidence');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random visualize image Ã²f ids\ndef visualize(ids,labels=None,size=None,n_imgs=16):\n    plt.figure(figsize=(15,15))\n    for k in range(n_imgs):\n        i = np.random.randint(len(ids))\n        id = ids[i]\n        img = plt.imread(os.path.join(data_dir,str(id)+'.jpg'))\n        if size:\n            img = cv2.resize(img,(size,size))\n        plt.subplot(4,4,k+1)\n        plt.imshow(img)\n        if labels is not None:\n            plt.title(labels[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_id_with_nbb(nb=1):\n  ids = np.array(list(bb_d.keys()))\n  bs = list(bb_d.values())\n  l = np.array([len(b) for b in bs])\n\n  id_nb = ids[l==nb]\n  return id_nb\n\ndef get_id_with_age(ids,a):\n    idx = fb.loc[ids].compress_age.to_numpy()==a\n    return ids[idx]\n\ndef get_age_with_ids(ids):\n    return fb.loc[ids].compress_age.to_numpy()\n\nimg_size = 128\ndatagen = ImageDataGenerator(\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    rotation_range=12,\n    zoom_range=0.1,\n    horizontal_flip=True\n)\n\ndef generate_data(img_folder,name,age,batch_size=8,is_train=True):\n    \n    if is_train:\n      indices = np.random.permutation(len(name))\n    else:\n      indices = np.arange(len(name))\n    n_batch = int(np.ceil(len(name)/batch_size))\n    j = 0\n    X,y,g = [],[],[]\n    for i in range(len(name)):\n      \n      j += 1\n      filename = name[indices[i]]\n      g.append(filename)\n#       new_name = img_folder + str(filename)+'.jpg'\n      new_name = os.path.join(img_folder, \"{}.jpg\".format(filename))\n#       print(new_name)\n      img = cv2.imread(new_name)\n      img_h, img_w, _ = np.shape(img)\n      for d in bb_d[filename]:\n        x1, y1, x2, y2 = d[0],d[1],d[2]+1,d[3]+1\n        w,h = x2-x1,y2-y1\n        xw1 = max(int(x1 - 0.4 * w), 0)\n        yw1 = max(int(y1 - 0.6 * h), 0)\n        xw2 = min(int(x2 + 0.4 * w), img_w - 1)\n        yw2 = min(int(y2 + 0.2 * h), img_h - 1)\n        img = cv2.resize(img[yw1:yw2 + 1, xw1:xw2 + 1, :], (img_size, img_size))\n        break\n\n      if is_train:\n        img = datagen.random_transform(img)\n      X.append(img/255)\n      y.append(age[indices[i]])\n      if j>=batch_size:\n        yield np.array(X),np.array(y),np.array(g)\n        X,y,g = [],[],[]\n        j = 0\n    if j >0:\n      yield np.array(X),np.array(y),np.array(g)\n    \ndef generate_data2(img_folder,name,age,batch_size=8,is_train=True):\n    \n    if is_train:\n      indices = np.random.permutation(len(name))\n    else:\n      indices = np.arange(len(name))\n    n_batch = int(np.ceil(len(name)/batch_size))\n    j = 0\n    X,y,g = [],[],[]\n    for i in range(len(name)):\n      \n      j += 1\n      filename = name[indices[i]]\n      g.append(filename)\n#       new_name = img_folder + str(filename)+'.jpg'\n      new_name = os.path.join(img_folder, \"{}.jpg\".format(filename))\n#       print(new_name)\n      img = cv2.imread(new_name)\n      img_h, img_w, _ = np.shape(img)\n      for d in bb_d[filename]:\n        x1, y1, x2, y2 = d[0],d[1],d[2]+1,d[3]+1\n        w,h = x2-x1,y2-y1\n        xw1 = max(int(x1 - 0.4 * w), 0)\n        yw1 = max(int(y1 - 0.6 * h), 0)\n        xw2 = min(int(x2 + 0.4 * w), img_w - 1)\n        yw2 = min(int(y2 + 0.2 * h), img_h - 1)\n        img = cv2.resize(img[yw1:yw2 + 1, xw1:xw2 + 1, :], (64, 64))\n        break\n\n      if is_train:\n        img = datagen.random_transform(img)\n      X.append(img)\n      y.append(age[indices[i]])\n      if j>=batch_size:\n        yield np.array(X),np.array(y),np.array(g)\n        X,y,g = [],[],[]\n        j = 0\n    if j >0:\n      yield np.array(X),np.array(y),np.array(g)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization\n\nImages for 0 bounding boxs"},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = get_id_with_nbb(1)\nl = get_age_with_ids(ids)\nvisualize(ids,l,n_imgs=16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Images for 2 bounding boxs"},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = get_id_with_nbb(0)\nvisualize(ids,n_imgs=16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualize images in range of confidence"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_id_with_conf(low=0,high=0.4):\n  ids = [(k,v[0][4]) for k,v in bb_d.items() if len(v)==1 and v[0][4]>=low and v[0][4]<high]\n  return ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r = np.array(get_id_with_conf(0,0.4))\nids,c = r[:,0].astype(int),r[:,1]\nvisualize(ids,c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r = np.array(get_id_with_conf(1,10))\nids,c = r[:,0].astype(int),r[:,1]\na = get_age_with_ids(ids)\ntitle = [str(x)+' , '+str(y) for x,y in zip(a,c)]\nvisualize(ids,title)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extract data"},{"metadata":{"trusted":true},"cell_type":"code","source":"r = np.array(get_id_with_conf(1.02,10))\ntrain_ids,train_c = r[:,0].astype(int),r[:,1]\ntrain_a = get_age_with_ids(train_ids)\nprint(len(train_ids))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize(train_ids,train_a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"age_ids = [get_id_with_age(train_ids,a) for a in np.arange(6)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"visualize(age_ids[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load models"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = models.load_model('../input/model-megaage/model_imp_2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import logging\nimport sys\nimport numpy as np\nfrom keras.models import Model\nfrom keras.layers import Input, Activation, add, Dense, Flatten, Dropout\nfrom keras.layers.convolutional import Conv2D, AveragePooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.regularizers import l2\nfrom keras import backend as K\n\nsys.setrecursionlimit(2 ** 20)\nnp.random.seed(2 ** 10)\n\n\nclass WideResNet:\n    def __init__(self, image_size, depth=16, k=8):\n        self._depth = depth\n        self._k = k\n        self._dropout_probability = 0\n        self._weight_decay = 0.0005\n        self._use_bias = False\n        #self._weight_init = \"he_normal\"\n\n        if K.image_data_format() == \"th\":\n            logging.debug(\"image_dim_ordering = 'th'\")\n            self._channel_axis = 1\n            self._input_shape = (3, image_size, image_size)\n        else:\n            logging.debug(\"image_dim_ordering = 'tf'\")\n            self._channel_axis = -1\n            self._input_shape = (image_size, image_size, 3)\n\n    # Wide residual network http://arxiv.org/abs/1605.07146\n    def _wide_basic(self, n_input_plane, n_output_plane, stride):\n        def f(net):\n            # format of conv_params:\n            #               [ [kernel_size=(\"kernel width\", \"kernel height\"),\n            #               strides=\"(stride_vertical,stride_horizontal)\",\n            #               padding=\"same\" or \"valid\"] ]\n            # B(3,3): orignal <<basic>> block\n            conv_params = [[3, 3, stride, \"same\"],\n                           [3, 3, (1, 1), \"same\"]]\n\n            n_bottleneck_plane = n_output_plane\n\n            # Residual block\n            for i, v in enumerate(conv_params):\n                if i == 0:\n                    if n_input_plane != n_output_plane:\n                        net = BatchNormalization(axis=self._channel_axis)(net)\n                        net = Activation(\"relu\")(net)\n                        convs = net\n                    else:\n                        convs = BatchNormalization(axis=self._channel_axis)(net)\n                        convs = Activation(\"relu\")(convs)\n\n                    convs = Conv2D(n_bottleneck_plane, kernel_size=(v[0], v[1]),\n                                          strides=v[2],\n                                          padding=v[3],\n                                          #kernel_initializer=self._weight_init,\n                                          kernel_regularizer=l2(self._weight_decay),\n                                          use_bias=self._use_bias)(convs)\n                else:\n                    convs = BatchNormalization(axis=self._channel_axis)(convs)\n                    convs = Activation(\"relu\")(convs)\n                    if self._dropout_probability > 0:\n                        convs = Dropout(self._dropout_probability)(convs)\n                    convs = Conv2D(n_bottleneck_plane, kernel_size=(v[0], v[1]),\n                                          strides=v[2],\n                                          padding=v[3],\n                                          #kernel_initializer=self._weight_init,\n                                          kernel_regularizer=l2(self._weight_decay),\n                                          use_bias=self._use_bias)(convs)\n\n            # Shortcut Connection: identity function or 1x1 convolutional\n            #  (depends on difference between input & output shape - this\n            #   corresponds to whether we are using the first block in each\n            #   group; see _layer() ).\n            if n_input_plane != n_output_plane:\n                shortcut = Conv2D(n_output_plane, kernel_size=(1, 1),\n                                         strides=stride,\n                                         padding=\"same\",\n                                         #kernel_initializer=self._weight_init,\n                                         kernel_regularizer=l2(self._weight_decay),\n                                         use_bias=self._use_bias)(net)\n            else:\n                shortcut = net\n\n            return add([convs, shortcut])\n\n        return f\n\n\n    # \"Stacking Residual Units on the same stage\"\n    def _layer(self, block, n_input_plane, n_output_plane, count, stride):\n        def f(net):\n            net = block(n_input_plane, n_output_plane, stride)(net)\n            for i in range(2, int(count + 1)):\n                net = block(n_output_plane, n_output_plane, stride=(1, 1))(net)\n            return net\n\n        return f\n\n#    def create_model(self):\n    def __call__(self):\n        logging.debug(\"Creating model...\")\n\n        assert ((self._depth - 4) % 6 == 0)\n        n = (self._depth - 4) / 6\n\n        inputs = Input(shape=self._input_shape)\n\n        n_stages = [16, 16 * self._k, 32 * self._k, 64 * self._k]\n\n        conv1 = Conv2D(filters=n_stages[0], kernel_size=(3, 3),\n                              strides=(1, 1),\n                              padding=\"same\",\n                              #kernel_initializer=self._weight_init,\n                              kernel_regularizer=l2(self._weight_decay),\n                              use_bias=self._use_bias)(inputs)  # \"One conv at the beginning (spatial size: 32x32)\"\n\n        # Add wide residual blocks\n        block_fn = self._wide_basic\n        conv2 = self._layer(block_fn, n_input_plane=n_stages[0], n_output_plane=n_stages[1], count=n, stride=(1, 1))(conv1)\n        conv3 = self._layer(block_fn, n_input_plane=n_stages[1], n_output_plane=n_stages[2], count=n, stride=(2, 2))(conv2)\n        conv4 = self._layer(block_fn, n_input_plane=n_stages[2], n_output_plane=n_stages[3], count=n, stride=(2, 2))(conv3)\n        batch_norm = BatchNormalization(axis=self._channel_axis)(conv4)\n        relu = Activation(\"relu\")(batch_norm)\n\n        # Classifier block\n        pool = AveragePooling2D(pool_size=(8, 8), strides=(1, 1), padding=\"same\")(relu)\n        flatten = Flatten()(pool)\n        predictions_a = Dense(units=6, #kernel_initializer=self._weight_init,\n                              use_bias=self._use_bias,\n                              kernel_regularizer=l2(self._weight_decay), activation=\"softmax\")(flatten)\n\n        model = Model(inputs=inputs, outputs=predictions_a)\n        #model = Model(inputs=inputs, outputs=predictions_a)\n        return model\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model1 = WideResNet(64, depth=16, k=8)()\nweight_file = '../input/model-megaage/WRN_16_8.h5'\n#model1.load_weights(weight_file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = [{}]*6\npreds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for a in range(6):    \n    for X,y,ids in generate_data(data_dir,age_ids[a],[a]*len(age_ids[a]),batch_size=2048,is_train=False):\n        p = model1.predict(X[0])\n        preds[a].update({k:v for k,v in zip(ids,p)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = {}\nfor a in range(6):\n    p.update(preds[a])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(6):\n  fn = 'pred'+'.pickle'\n  with open(fn,'wb') as handle:\n    pickle.dump(p,handle)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(preds[5]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize_with_age(a,low,high):\n    ids = [k for k,v in preds[a].items() if np.argmax(v)==a and np.max(v)>low and np.max(v)<=high]\n    conf = [str(np.max(v))+' '+str(k) for k,v in preds[a].items() if np.argmax(v)==a and np.max(v)>low and np.max(v)<=high]\n    visualize(ids,conf)\n    print(len(ids))\n    return ids\n    \ndef hist_with_age(a):\n    conf = [np.max(v) for k,v in preds[a].items() if np.argmax(v)==a]\n    plt.hist(conf,bins=100)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Clean data for training"},{"metadata":{"trusted":true},"cell_type":"code","source":"t_ids = [[]]*6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"a = 5\nlow = 0.89\nhigh = 1\nt_ids[5] = visualize_with_age(a,low,high)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_with_age(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = 4\nlow = 0.58\nhigh = 1\nt_ids[4] = visualize_with_age(a,low,high)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_with_age(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_with_age(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = 3\nlow = 0.58\nhigh = 1\nt_ids[3] = visualize_with_age(a,low,high)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_with_age(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = 2\nlow = 0.5\nhigh = 1\nt_ids[2] = visualize_with_age(a,low,high)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = 1\nlow = 0.58\nhigh = 1\nt_ids[1] = visualize_with_age(a,low,high)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = 0\nlow = 0.95\nhigh = 1\nt_ids[0] = visualize_with_age(a,low,high)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_with_age(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(6):\n  fn = 'train_ids_'+str(i)+'.pickle'\n  with open(fn,'wb') as handle:\n    pickle.dump(t_ids[i],handle)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}