{"cells":[{"metadata":{},"cell_type":"markdown","source":"# STATUS: MARKED AS FINAL"},{"metadata":{},"cell_type":"markdown","source":"# House Price Prediction Challenge\n\nWelcome to the House Price Prediction Challenge, you will test your regression skills by designing an algorithm to accurately predict the house prices in India. Accurately predicting house prices can be a daunting task. The buyers are just not concerned about the size(square feet) of the house and there are various other factors that play a key role to decide the price of a house/property. It can be extremely difficult to figure out the right set of attributes that are contributing to understanding the buyer's behavior as such. This dataset has been collected across various property aggregators across India. In this competition, provided the 12 influencing factors your role as a data scientist is to predict the prices as accurately as possible.\n\nAlso, in this competition, you will get a lot of room for feature engineering and mastering advanced regression techniques such as Random Forest, Deep Neural Nets, and various other ensembling techniques. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/house-price-prediction-challenge/train.csv')\ntest = pd.read_csv('/kaggle/input/house-price-prediction-challenge/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/house-price-prediction-challenge/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# First look at data\n\nThe following are the features available in the dataset:\n\n1. POSTED_BY \t         - Category marking who has listed the property\n2. UNDER_CONSTRUCTION    - Under Construction or Not\n3. RERA \t- Real Estate (Regulation and Development) Act, 2016\n4. BHK_NO \t- Number of Rooms\n5. BHKORRK \t- Type of property -  Room and Kitchen (RK) or Bedroom, Hall, Kitchen (BHK)\n6. SQUARE_FT \t- Total area of the house in square feet\n7. READYTOMOVE - \tCategory marking Ready to move or Not\n8. RESALE \t- Category marking Resale or not\n9. ADDRESS \t- Address of the property\n10. LONGITUDE - \tLongitude of the property\n11. LATITUDE - \tLatitude of the property\n\nThe target column is the Price in Lacs."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"My main interest in the dataset will be how the different features affect the price and then building some kind of a model for prediction.\n\nAll the features are categorical expect Square feet.\n\nAs a side task, I will also try to create some kind of a map using the Longitudes and Latitudes features.\n\nSince the test dataset has no actuals available, I will further split the train dataset into test and train dataset for testing the accuracy of the model."},{"metadata":{},"cell_type":"markdown","source":"# Exploring the data\n\n## Taking a look at the price column\n\nLooks like there is an outlier in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(data=train, y='TARGET(PRICE_IN_LACS)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The difference between the median and the mean clearly shows the outliers. The maximum price is 30,000  Lacs. Is this a data error? "},{"metadata":{"trusted":true},"cell_type":"code","source":"train['TARGET(PRICE_IN_LACS)'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I found three houses with price which I will classify as outliers. They are located in Bangalore and have a huge area covering. In fact these are the only ones which have an area of more than 10,000,000 square feet."},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['TARGET(PRICE_IN_LACS)']>3999]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Taking a look at houses of area more than 10,000,000:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['SQUARE_FT']>10000000]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Area covered and relation to price"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1,1,figsize=(15,5))\nsns.scatterplot(data=train, x='SQUARE_FT', y='TARGET(PRICE_IN_LACS)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(1,2,figsize=(15,5))\nsns.scatterplot(data=train[train['SQUARE_FT']<399999], x='SQUARE_FT', y='TARGET(PRICE_IN_LACS)', ax=axes[0])\nsns.scatterplot(data=train[train['SQUARE_FT']>399999], x='SQUARE_FT', y='TARGET(PRICE_IN_LACS)', ax=axes[1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extracting the cities"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_city_name(address):\n    return address[address.find(',')+1:]\n\ntrain['CITY'] = train['ADDRESS'].apply(get_city_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train['CITY'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Converting more than 5 BHK to 5 BHK"},{"metadata":{"trusted":true},"cell_type":"code","source":"def BHK(BHK_NO):\n    if BHK_NO > 5:\n        return 5\n    else:\n        return BHK_NO\n\ntrain['BHK_NO.'] = train['BHK_NO.'].apply(BHK)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['BHK_NO.']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The other categorical features"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['POSTED_BY', 'UNDER_CONSTRUCTION', 'RERA', 'BHK_NO.', \n            'BHK_OR_RK', 'READY_TO_MOVE', 'RESALE']\n\nfor feature in features:\n\n    f, axes = plt.subplots(1,2,figsize=(15,5))\n\n    sns.countplot(data=train, x=feature, ax=axes[0])\n    sns.violinplot(data=train, x=feature, y='TARGET(PRICE_IN_LACS)', ax=axes[1])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train and test data\n\nI will further split the train data available to test and train.\n\nI will experiment with the different type of data transformations.\n\nIn all scenarios, the decision tree regressor is gving a better accuracy."},{"metadata":{},"cell_type":"markdown","source":"## The lazy model\n\nUsing the dataset as it is, the winner is decision tree regressor. The linear regression has a r2 score in negative.."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/house-price-prediction-challenge/train.csv')\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\ncategorical_columns = []\n\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        categorical_columns.append(column)\n        \ndf = pd.get_dummies(df,columns=categorical_columns, dtype=int, drop_first=True)\ndf.fillna(0, inplace=True)\n\ny = df['TARGET(PRICE_IN_LACS)']\nX = df.drop(labels = ['TARGET(PRICE_IN_LACS)'], axis = 1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodels = [DecisionTreeRegressor(), LinearRegression(), Ridge(),  Lasso()]\n\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    from sklearn import metrics\n    print('Model:', model)\n    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n    print('r2_score:', metrics.r2_score (y_test, y_pred))\n    print('-------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dropping the latitude and logitude columns\n\n\nThe decision tree regressor has improved. The linear regression still has a r2 score in negative.. Ridge and Lasso is almost the same as before.."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/house-price-prediction-challenge/train.csv')\ndf.drop(labels=['LONGITUDE','LATITUDE'],axis=1, inplace=True)\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\ncategorical_columns = []\n\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        categorical_columns.append(column)\n        \ndf = pd.get_dummies(df,columns=categorical_columns, dtype=int, drop_first=True)\ndf.fillna(0, inplace=True)\n\ny = df['TARGET(PRICE_IN_LACS)']\nX = df.drop(labels = ['TARGET(PRICE_IN_LACS)'], axis = 1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodels = [DecisionTreeRegressor(), LinearRegression(), Ridge(),  Lasso()]\n\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    from sklearn import metrics\n    print('Model:', model)\n    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n    print('r2_score:', metrics.r2_score (y_test, y_pred))\n    print('-------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dropping the address, latitude and logitude columns\n\nThe linear regression model has improved a lot, however a long way to coming closer to the decision tree regressor. Ridge and lasso still has no change. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/house-price-prediction-challenge/train.csv')\ndf.drop(labels=['LONGITUDE','LATITUDE', 'ADDRESS'],axis=1, inplace=True)\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\ncategorical_columns = []\n\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        categorical_columns.append(column)\n        \ndf = pd.get_dummies(df,columns=categorical_columns, dtype=int, drop_first=True)\ndf.fillna(0, inplace=True)\n\ny = df['TARGET(PRICE_IN_LACS)']\nX = df.drop(labels = ['TARGET(PRICE_IN_LACS)'], axis = 1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodels = [DecisionTreeRegressor(), LinearRegression(), Ridge(),  Lasso()]\n\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    from sklearn import metrics\n    print('Model:', model)\n    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n    print('r2_score:', metrics.r2_score (y_test, y_pred))\n    print('-------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using only the area of the house\n\nAll the r2 scores are worse than the previous scenario. However, this can be because of the outliers present in both the price and area."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/house-price-prediction-challenge/train.csv')\ndf.drop(labels=['LONGITUDE','LATITUDE', 'ADDRESS'],axis=1, inplace=True)\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\ncategorical_columns = []\n\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        categorical_columns.append(column)\n        \ndf = pd.get_dummies(df,columns=categorical_columns, dtype=int, drop_first=True)\ndf.fillna(0, inplace=True)\n\ny = df['TARGET(PRICE_IN_LACS)']\nX = df['SQUARE_FT'].to_numpy().reshape(-1, 1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodels = [DecisionTreeRegressor(), LinearRegression(), Ridge(),  Lasso()]\n\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    from sklearn import metrics\n    print('Model:', model)\n    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n    print('r2_score:', metrics.r2_score (y_test, y_pred))\n    print('-------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extracting city out of address"},{"metadata":{},"cell_type":"markdown","source":"Hmm.. This actually showed slightly reduced performance compared to when we were using full addresses.."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/house-price-prediction-challenge/train.csv')\n\ndef get_city_name(address):\n    return address[address.find(',')+1:]\n\ntrain['CITY'] = train['ADDRESS'].apply(get_city_name)\n\ndf.drop(labels=['LONGITUDE','LATITUDE', 'ADDRESS'],axis=1, inplace=True)\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\ncategorical_columns = []\n\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        categorical_columns.append(column)\n        \ndf = pd.get_dummies(df,columns=categorical_columns, dtype=int, drop_first=True)\ndf.fillna(0, inplace=True)\n\ny = df['TARGET(PRICE_IN_LACS)']\nX = df.drop(labels = ['TARGET(PRICE_IN_LACS)'], axis = 1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodels = [DecisionTreeRegressor(), LinearRegression(), Ridge(),  Lasso()]\n\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    from sklearn import metrics\n    print('Model:', model)\n    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n    print('r2_score:', metrics.r2_score (y_test, y_pred))\n    print('-------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using transformed BHK feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/house-price-prediction-challenge/train.csv')\n\ndef get_city_name(address):\n    return address[address.find(',')+1:]\n\n\n\ntrain['CITY'] = train['ADDRESS'].apply(get_city_name)\n\ndef BHK(BHK_NO):\n    if BHK_NO > 5:\n        return 5\n    else:\n        return BHK_NO\n\ntrain['BHK_NO.'] = train['BHK_NO.'].apply(BHK)\n\ndf.drop(labels=['LONGITUDE','LATITUDE', 'ADDRESS'],axis=1, inplace=True)\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\ncategorical_columns = []\n\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        categorical_columns.append(column)\n        \ndf = pd.get_dummies(df,columns=categorical_columns, dtype=int, drop_first=True)\ndf.fillna(0, inplace=True)\n\ny = df['TARGET(PRICE_IN_LACS)']\nX = df.drop(labels = ['TARGET(PRICE_IN_LACS)'], axis = 1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodels = [DecisionTreeRegressor(), LinearRegression(), Ridge(),  Lasso()]\n\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    from sklearn import metrics\n    print('Model:', model)\n    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n    print('r2_score:', metrics.r2_score (y_test, y_pred))\n    print('-------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/house-price-prediction-challenge/train.csv')\n\n\ndef BHK(BHK_NO):\n    if BHK_NO > 5:\n        return 5\n    else:\n        return BHK_NO\n\ntrain['BHK_NO.'] = train['BHK_NO.'].apply(BHK)\n\ndf.drop(labels=['LONGITUDE','LATITUDE', 'ADDRESS'],axis=1, inplace=True)\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\ncategorical_columns = []\n\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        categorical_columns.append(column)\n        \ndf = pd.get_dummies(df,columns=categorical_columns, dtype=int, drop_first=True)\ndf.fillna(0, inplace=True)\n\ny = df['TARGET(PRICE_IN_LACS)']\nX = df.drop(labels = ['TARGET(PRICE_IN_LACS)'], axis = 1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodels = [DecisionTreeRegressor(), LinearRegression(), Ridge(),  Lasso()]\n\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    from sklearn import metrics\n    print('Model:', model)\n    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n    print('r2_score:', metrics.r2_score (y_test, y_pred))\n    print('-------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# And the winner is:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/house-price-prediction-challenge/train.csv')\ndf.drop(labels=['LONGITUDE','LATITUDE', 'ADDRESS'],axis=1, inplace=True)\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\n\ncategorical_columns = []\n\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        categorical_columns.append(column)\n        \ndf = pd.get_dummies(df,columns=categorical_columns, dtype=int, drop_first=True)\ndf.fillna(0, inplace=True)\n\ny = df['TARGET(PRICE_IN_LACS)']\nX = df.drop(labels = ['TARGET(PRICE_IN_LACS)'], axis = 1)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n\nmodels = [DecisionTreeRegressor()]\n\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    from sklearn import metrics\n    print('Model:', model)\n    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n    print('r2_score:', metrics.r2_score (y_test, y_pred))\n    print('-------------------------------------')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}