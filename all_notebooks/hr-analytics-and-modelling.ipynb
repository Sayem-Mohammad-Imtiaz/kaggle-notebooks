{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.feature_selection import SelectPercentile, univariate_selection, RFE\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_score, RepeatedStratifiedKFold,\\\nStratifiedKFold\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.metrics import classification_report, plot_confusion_matrix, precision_recall_curve, plot_precision_recall_curve, confusion_matrix\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE\nimport category_encoders as ce\nfrom scipy import stats\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Context and Content**\n\nA company which is active in Big Data and Data Science wants to hire data scientists among people who successfully pass some courses which conduct by the company. Many people signup for their training. Company wants to know which of these candidates are really wants to work for the company after training or looking for a new employment because it helps to reduce the cost and time as well as the quality of training or planning the courses and categorization of candidates. Information related to demographics, education, experience are in hands from candidates signup and enrollment.\n\nThis dataset designed to understand the factors that lead a person to leave current job for HR researches too. By model(s) that uses the current credentials,demographics,experience data you will predict the probability of a candidate to look for a new job or will work for the company, as well as interpreting affected factors on employee decision.\n\nThe whole data divided to train and test . Target isn't included in test but the test target values data file is in hands for related tasks. A sample submission correspond to enrollee_id of test set provided too with columns : enrollee _id , target\n\n***Note:***\n\n* The dataset is imbalanced.\n* Most features are categorical (Nominal, Ordinal, Binary), some with high cardinality.\n* Missing imputation can be a part of your pipeline as well.\n* Features\n\nenrollee_id : Unique ID for candidate\n\ncity: City code\n\ncity_ development _index : Developement index of the city (scaled)\n\ngender: Gender of candidate\n\nrelevent_experience: Relevant experience of candidate\n\nenrolled_university: Type of University course enrolled if any\n\neducation_level: Education level of candidate\n\nmajor_discipline :Education major discipline of candidate\n\nexperience: Candidate total experience in years\n\ncompany_size: No of employees in current employer's company\n\ncompany_type : Type of current employer\n\nlastnewjob: Difference in years between previous job and current job\n\ntraining_hours: training hours completed\n\ntarget: 0 – Not looking for job change, 1 – Looking for a job change\n\n***Inspiration***\n* Predict the probability of a candidate will work for the company\n* Interpret model(s) such a way that illustrate which features affect candidate decision"},{"metadata":{},"cell_type":"markdown","source":"According to toggl.com, they took a research example from the Society for Human Resource Management, the average cost of recruiting new employees is USD 4,129, assuming that filling positions can take place within 42 days.\n\nAccording to research from Glassdoor, the average cost for a new employee recuit is USD 4,000, assuming a position fill takes place within 50 days.\n\nMeanwhile, the cost of training for Data Science, we can take the most reasonable cost, which is USD 2,950 (Track 1 to Track 4). This training is conducted by the Data Science Council of America (DASCA): Principal Data Science (PDS). This training is quite complete with fundamental learning to advanced data science concepts such as big data best practices, business strategies for data, building cross-organizational support, machine learning, natural language processing, scholastic modeling and more.\n\nThis means that we can conclude that **the cost of recruiting one new employee is around 1.37x higher than the cost of training one employee.**"},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation and Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"emp = pd.read_csv('/kaggle/input/hr-analytics-job-change-of-data-scientists/aug_train.csv')\nemp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop unnecessary feature\nemp.drop('enrollee_id', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emp.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_desc = emp.describe()\nnum_desc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"obj_desc = emp.select_dtypes(include='object').describe()\nobj_desc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(emp.isna().sum()/len(emp)*100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see from the results above that, many columns still have empty data. So that we can start to create a data imputation strategy."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(emp.isna())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emp['gender'].value_counts().plot(kind='pie')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a bit strange, because someone has filled the gender column with other. We have to decide whether this other is NaN or indeed some other category. Let's see first, how many others are in gender."},{"metadata":{"trusted":true},"cell_type":"code","source":"len(emp[emp['gender'] == 'Other']) / len(emp) * 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It turns out that the number of gender with 'Other' value is not up to 1 percent. If we want to stay informed from this data, we can change this value to NaN and then impute it later. Or if we feel that this is small data and doesn't seem to have a significant impact, we can delete it. But for now I will try to convert it to NaN and I will impute it later."},{"metadata":{},"cell_type":"markdown","source":"## Gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"emp['gender'].replace({'Other': np.nan}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emp['gender'].isna().sum()/len(emp)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emp[emp['gender'].isna()==True]['education_level'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emp[emp['education_level']=='Graduate']['gender'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the results above, it can be seen that, the majority of gender that is not known is mostly from the education level: Graduate. And at that level of education, male gender is dominated. Then we will impute the `gender` column with the value Male."},{"metadata":{},"cell_type":"markdown","source":"## Enrolled Uni and Education Level"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(emp['enrolled_university education_level'.split()].isna())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there is no correlation between missing value between education levels and enrolled universities. So that we can impute them separately or not in pairs."},{"metadata":{"trusted":true},"cell_type":"code","source":"emp[emp['enrolled_university'].isna() == True]['city'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emp[emp['enrolled_university'].isna() == True]['education_level'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emp[emp['city'] == 'city_21']['enrolled_university'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emp[emp['education_level'].isna() == True]['city'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emp[emp['education_level'].isna() == True]['enrolled_university'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emp[emp['city'] == 'city_103']['education_level'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the results above, we can conclude. For the column `enrolled_university`, I will fill it with 'no enrollment'. As for the `education_level` column, I will fill it with 'Graduate'."},{"metadata":{},"cell_type":"markdown","source":"## Major Discipline"},{"metadata":{"trusted":true},"cell_type":"code","source":"emp['major_discipline'].value_counts(normalize=True).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"More than 80% of employees come from STEM (Science, Technology, Engineering, Mathematics) majors. We will try to fill in this column based on the `city_id` column."},{"metadata":{"trusted":true},"cell_type":"code","source":"emp[emp['major_discipline'].isna() == True]['city'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emp[emp['city'] == 'city_103']['major_discipline'].mode()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It turned out that the city that lost the most data on its graduates was city_103 and most employees from city_103 took STEM majors. So we will impute `major_discipline` with STEM."},{"metadata":{},"cell_type":"markdown","source":"## Experience"},{"metadata":{"trusted":true},"cell_type":"code","source":"round(emp.isna().sum()/len(emp)*100, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Because the `experience` column only loses less than half a percent of data, I will delete data for employees who do not have experience data."},{"metadata":{},"cell_type":"markdown","source":"## Company Size and Type"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(emp['company_size company_type'.split()].isna())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we look at the results above. Almost all data that is missing in the `company_size` column will also be lost in the` company_type` column. We will try to observe these pairs."},{"metadata":{"trusted":true},"cell_type":"code","source":"both_nan_comp = emp[(emp['company_size'].isna()==True) & (emp['company_type'].isna()==True)]\nboth_nan_comp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"either_nan_comp = emp[(emp['company_size'].isna()==True) | (emp['company_type'].isna()==True)]\neither_nan_comp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Paired NaN from company_size and company_type:', len(both_nan_comp)/len(either_nan_comp)*100, '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"both_nan_comp['city'].value_counts(normalize=True).sort_values(ascending=False).head(10).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"both_nan_comp[both_nan_comp['company_size'].isna()==True]['city'].mode()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Most frequent company size from city_103:', emp[emp['city']=='city_103']['company_size'].mode()[0])\nprint('Most frequent company type from city_103:', emp[emp['city']=='city_103']['company_type'].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emp[(emp['company_type']=='Pvt Ltd') & (emp['city']=='city_103')]['company_size'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll try to fill in all the NaNs in these 2 columns with 'Pvt Ltd' and '10000+' for `company_type` and` company_size` respectively."},{"metadata":{},"cell_type":"markdown","source":"## Last New Job"},{"metadata":{"trusted":true},"cell_type":"code","source":"emp['last_new_job'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to the documentation, `last_new_job` column is about: Difference in years between previous job and current job"},{"metadata":{"trusted":true},"cell_type":"code","source":"emp[emp['last_new_job'].isna() == True]['city'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emp[emp['city'] == 'city_21']['last_new_job'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With this we will fill in the column `last_new_job` with value 1. Or in other words, employees who just moved 1 year ago."},{"metadata":{},"cell_type":"markdown","source":"## The conclusion of the imputation strategy:\n1. `gender` = 'Male'\n1. `enrolled_university` = 'no_enrollment'\n1. `education_level` = 'Graduate'\n1. `major_discipline` = 'STEM'\n1. `experience` =` drop.na() `\n1. `company_size` = '10000+'\n1. `company_type` = 'Pvt Ltd'\n1. `last_new_job` = '1'"},{"metadata":{},"cell_type":"markdown","source":"To be continued.."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}