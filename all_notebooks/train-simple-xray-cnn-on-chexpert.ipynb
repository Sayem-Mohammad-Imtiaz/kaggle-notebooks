{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Goal\nThe goal is to use a simple model to classify x-ray images in Keras, the notebook how to use the ```flow_from_dataframe``` to deal with messier datasets","metadata":{"_cell_guid":"19ff9d0b-d32d-4325-a19f-2ccbfa7d2dff","_uuid":"9206c5863724e1af01281071e0f0ee5109ef431b"}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom glob import glob\n%matplotlib inline\nimport matplotlib.pyplot as plt","metadata":{"_cell_guid":"f42f6560-edf0-4efb-85a6-6e945e50895b","_uuid":"3300a1edbf2e8122d88093998eb503a6fab8a719","execution":{"iopub.status.busy":"2021-07-30T12:16:57.903619Z","iopub.execute_input":"2021-07-30T12:16:57.903978Z","iopub.status.idle":"2021-07-30T12:16:57.929012Z","shell.execute_reply.started":"2021-07-30T12:16:57.903912Z","shell.execute_reply":"2021-07-30T12:16:57.92825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"../input/chexpert-dataset/\"","metadata":{"execution":{"iopub.status.busy":"2021-07-30T12:17:00.679602Z","iopub.execute_input":"2021-07-30T12:17:00.680292Z","iopub.status.idle":"2021-07-30T12:17:00.684624Z","shell.execute_reply.started":"2021-07-30T12:17:00.680198Z","shell.execute_reply":"2021-07-30T12:17:00.683522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/modified-chexpert/modifiedv2_train.csv')\nvalid_df = pd.read_csv('../input/modified-chexpert/modifiedv2_valid.csv')\ntrain_df[\"path\"] = path + train_df[\"Path\"]\nvalid_df[\"path\"] = path + valid_df[\"Path\"]\n# all_image_paths = {os.path.basename(x): x for x in \n#                    glob(os.path.join('..', 'input', 'images*', '*', '*.png'))}\n# print('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\n# all_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\n# all_xray_df['Patient Age'] = all_xray_df['Patient Age'].map(lambda x: int(x[:-1]))\ndfs = [train_df, valid_df]\nall_xray_df = pd.concat(dfs)\nall_xray_df.sample(3)","metadata":{"_cell_guid":"9a342cdc-0823-490d-9a3a-a53fb7c33727","_uuid":"fe804e7c294e2d290e27b037bf1ba56177abab70","execution":{"iopub.status.busy":"2021-07-30T12:17:02.791931Z","iopub.execute_input":"2021-07-30T12:17:02.79222Z","iopub.status.idle":"2021-07-30T12:17:04.230526Z","shell.execute_reply.started":"2021-07-30T12:17:02.79217Z","shell.execute_reply":"2021-07-30T12:17:04.229486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing Labels\nHere we take the labels and make them into a more clear format. The primary step is to see the distribution of findings and then to convert them to simple binary labels","metadata":{"_cell_guid":"0d674a43-170f-4ca6-a9b4-edc64ab89c35","_uuid":"9a1669750b7cffcae1b7a2eb4307b85472dff192"}},{"cell_type":"code","source":"label_counts = all_xray_df['Finding Labels'].value_counts()[:15]\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\n_ = ax1.set_xticklabels(label_counts.index, rotation = 90)","metadata":{"_cell_guid":"d75ed03e-986d-4f3f-81af-c910d194f390","_uuid":"0c5123f65edf349f8ad2e5c5f55ac484d974f5c7","execution":{"iopub.status.busy":"2021-07-30T12:14:40.031871Z","iopub.execute_input":"2021-07-30T12:14:40.03217Z","iopub.status.idle":"2021-07-30T12:14:40.49497Z","shell.execute_reply.started":"2021-07-30T12:14:40.032117Z","shell.execute_reply":"2021-07-30T12:14:40.494298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_xray_df = all_xray_df[all_xray_df[\"Finding Labels\"].notnull()]","metadata":{"execution":{"iopub.status.busy":"2021-07-30T12:17:08.218004Z","iopub.execute_input":"2021-07-30T12:17:08.218463Z","iopub.status.idle":"2021-07-30T12:17:08.250587Z","shell.execute_reply.started":"2021-07-30T12:17:08.218421Z","shell.execute_reply":"2021-07-30T12:17:08.249217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_xray_df.shape, valid_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\nfrom itertools import chain\nall_labels = np.unique(list(chain(*all_xray_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\nall_labels = [x for x in all_labels if len(x)>0]\nprint('All Labels ({}): {}'.format(len(all_labels), all_labels))\nfor c_label in all_labels:\n    if len(c_label)>1: # leave out empty labels\n        all_xray_df[c_label] = all_xray_df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\nall_xray_df.sample(3)","metadata":{"_cell_guid":"a9ff3a04-254d-4667-b0a3-869bbd92b08b","_uuid":"78b4425b0a8932bb33864b5a3712611004687a48","execution":{"iopub.status.busy":"2021-07-30T12:17:09.513899Z","iopub.execute_input":"2021-07-30T12:17:09.514294Z","iopub.status.idle":"2021-07-30T12:17:11.077671Z","shell.execute_reply.started":"2021-07-30T12:17:09.514223Z","shell.execute_reply":"2021-07-30T12:17:11.07637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Clean categories\nSince we have too many categories, we can prune a few out by taking the ones with only a few examples","metadata":{"_cell_guid":"05b6c7d9-4869-40b5-a70b-53957c69f021","_uuid":"64653f9f57d3a5b952f1f1a709eb70ca38761a0d"}},{"cell_type":"code","source":"# keep at least 1000 cases\nMIN_CASES = 1000\nall_labels = [c_label for c_label in all_labels if all_xray_df[c_label].sum()>MIN_CASES]\nprint('Clean Labels ({})'.format(len(all_labels)), \n      [(c_label,int(all_xray_df[c_label].sum())) for c_label in all_labels])","metadata":{"_cell_guid":"dd273e26-63ab-4d76-925d-9c1c2c1ba69c","_uuid":"9f368f9ea8947d8fc1dacf3988c58b6a2bf5fffc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# since the dataset is very unbiased, we can resample it to be a more reasonable collection\n# weight is 0.1 + number of findings\n# sample_weights = all_xray_df['Finding Labels'].map(lambda x: len(x.split('|')) if len(x)>0 else 0).values + 4e-2\n# sample_weights /= sample_weights.sum()\n# all_xray_df = all_xray_df.sample(40000, weights=sample_weights)\n\n# label_counts = all_xray_df['Finding Labels'].value_counts()[:15]\n# fig, ax1 = plt.subplots(1,1,figsize = (12, 8))\n# ax1.bar(np.arange(len(label_counts))+0.5, label_counts)\n# ax1.set_xticks(np.arange(len(label_counts))+0.5)\n# _ = ax1.set_xticklabels(label_counts.index, rotation = 90)","metadata":{"_cell_guid":"01478f44-5beb-4a6c-aa27-77db4b9abf10","_uuid":"cf071cfa49f2886d9795cdf6067a8afdafd6f458","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_counts = 100*np.mean(all_xray_df[all_labels].values,0)\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\nax1.set_xticklabels(all_labels, rotation = 90)\nax1.set_title('Adjusted Frequency of Diseases in Patient Group')\n_ = ax1.set_ylabel('Frequency (%)')","metadata":{"_cell_guid":"277caf38-f13d-4939-9eef-55efaf73020e","_uuid":"cb9f18a64740580e1c541b8631d45720be5f36fe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Training Data\nHere we split the data into training and validation sets and create a single vector (disease_vec) with the 0/1 outputs for the disease status (what the model will try and predict)","metadata":{"_cell_guid":"a1367d63-4c7b-4e47-b19f-9a26d1f89476","_uuid":"6ed6489bbd618fb419ceca2bbd8c300694f1d4ed"}},{"cell_type":"code","source":"all_xray_df['disease_vec'] = all_xray_df.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])\n# valid_df['disease_vec'] = valid_df.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])","metadata":{"_cell_guid":"185ae07c-17a2-46d3-81ca-4007e88cbf86","_uuid":"6f82e5ae33e1c0fcfa33ac51a26885cb5a0e6bb1","execution":{"iopub.status.busy":"2021-07-30T12:17:15.175162Z","iopub.execute_input":"2021-07-30T12:17:15.175492Z","iopub.status.idle":"2021-07-30T12:18:18.58316Z","shell.execute_reply.started":"2021-07-30T12:17:15.175426Z","shell.execute_reply":"2021-07-30T12:18:18.582057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df, valid_df = train_test_split(all_xray_df, \n                                   test_size = 0.25, \n                                   random_state = 2018,\n                                   stratify = all_xray_df['Finding Labels'].map(lambda x: x[:4]))\nprint('train', train_df.shape[0], 'validation', valid_df.shape[0])","metadata":{"_cell_guid":"5feddc96-7958-4d34-81f1-10eba94ab1b6","_uuid":"8c7dc722de08243cc763d23928708f9c040bbdc6","execution":{"iopub.status.busy":"2021-07-30T12:18:18.584429Z","iopub.execute_input":"2021-07-30T12:18:18.584707Z","iopub.status.idle":"2021-07-30T12:18:19.974815Z","shell.execute_reply.started":"2021-07-30T12:18:18.584663Z","shell.execute_reply":"2021-07-30T12:18:19.973936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_xray_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-30T11:50:27.798201Z","iopub.execute_input":"2021-07-30T11:50:27.7985Z","iopub.status.idle":"2021-07-30T11:50:27.804103Z","shell.execute_reply.started":"2021-07-30T11:50:27.798448Z","shell.execute_reply":"2021-07-30T11:50:27.803207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Data Generators\nHere we make the data generators for loading and randomly transforming images","metadata":{"_cell_guid":"7178cb8d-f220-4422-93ae-2469f0c97493","_uuid":"0115346eb989e7eaeffa3643d05c654ec5ceb7c2"}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nIMG_SIZE = (128, 128)\ncore_idg = ImageDataGenerator(samplewise_center=True, \n                              samplewise_std_normalization=True, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range= 0.05, \n                              width_shift_range=0.1, \n                              rotation_range=5, \n                              shear_range = 0.1,\n                              fill_mode = 'reflect',\n                              zoom_range=0.15)","metadata":{"_cell_guid":"30eaf01b-8ec0-4407-9d25-f87ca1f48e8a","_uuid":"b5e42124376584390e925a06c4cee564285e43b3","execution":{"iopub.status.busy":"2021-07-30T12:18:39.082594Z","iopub.execute_input":"2021-07-30T12:18:39.082873Z","iopub.status.idle":"2021-07-30T12:18:41.658118Z","shell.execute_reply.started":"2021-07-30T12:18:39.082835Z","shell.execute_reply":"2021-07-30T12:18:41.657126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip list | grep Keras","metadata":{"execution":{"iopub.status.busy":"2021-07-30T12:00:03.717399Z","iopub.execute_input":"2021-07-30T12:00:03.71779Z","iopub.status.idle":"2021-07-30T12:00:03.72361Z","shell.execute_reply.started":"2021-07-30T12:00:03.717748Z","shell.execute_reply":"2021-07-30T12:00:03.722751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen","metadata":{"_cell_guid":"b67dc5fa-d91b-420a-aaa7-b3991313127a","_uuid":"dbb93f7f8248031563ec7042d978650c0c957c1f","execution":{"iopub.status.busy":"2021-07-30T12:18:44.403218Z","iopub.execute_input":"2021-07-30T12:18:44.403515Z","iopub.status.idle":"2021-07-30T12:18:44.422697Z","shell.execute_reply.started":"2021-07-30T12:18:44.403478Z","shell.execute_reply":"2021-07-30T12:18:44.421745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = flow_from_dataframe(core_idg, train_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = 32)\n\nvalid_gen = flow_from_dataframe(core_idg, valid_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = 256) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(flow_from_dataframe(core_idg, \n                               valid_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = 1024)) # one big batch","metadata":{"_cell_guid":"dc4d027c-f5c4-48b8-8ab6-b41971ad514f","_uuid":"cc92b74f28987fee4971e60a71f74660693f4278","execution":{"iopub.status.busy":"2021-07-30T12:18:44.978763Z","iopub.execute_input":"2021-07-30T12:18:44.979081Z","iopub.status.idle":"2021-07-30T12:19:14.159933Z","shell.execute_reply.started":"2021-07-30T12:18:44.979025Z","shell.execute_reply":"2021-07-30T12:19:14.159095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x, y in train_gen:\n    print(x[0].shape)\n    plt.imshow(x[0].squeeze(axis=2))\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nkeras.__version__","metadata":{"execution":{"iopub.status.busy":"2021-07-30T12:01:46.84979Z","iopub.execute_input":"2021-07-30T12:01:46.85016Z","iopub.status.idle":"2021-07-30T12:01:46.856111Z","shell.execute_reply.started":"2021-07-30T12:01:46.850122Z","shell.execute_reply":"2021-07-30T12:01:46.85524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_x, t_y = next(train_gen)\nfig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone', vmin = -1.5, vmax = 1.5)\n    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(all_labels, c_y) \n                             if n_score>0.5]))\n    c_ax.axis('off')","metadata":{"_cell_guid":"0621048f-3d4c-4eb7-aaee-0c53f7cbf26a","_uuid":"2852ef2fe07eb6d8e2caf056d1428d153afad65f","execution":{"iopub.status.busy":"2021-07-30T12:19:14.160955Z","iopub.execute_input":"2021-07-30T12:19:14.161188Z","iopub.status.idle":"2021-07-30T12:19:16.797127Z","shell.execute_reply.started":"2021-07-30T12:19:14.161147Z","shell.execute_reply":"2021-07-30T12:19:16.796452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create a simple model\nHere we make a simple model to train using MobileNet as a base and then adding a GAP layer (Flatten could also be added), dropout, and a fully-connected layer to calculate specific features","metadata":{"_cell_guid":"cce3c89c-4292-4092-9317-ca066d72e354","_uuid":"5b0ec78f2ffa8137dce37744f38a40782aafb54d"}},{"cell_type":"code","source":"from keras.applications.mobilenet import MobileNet\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\nfrom keras.models import Sequential\nbase_mobilenet_model = MobileNet(input_shape =  t_x.shape[1:], \n                                 include_top = False, weights = None)\nmulti_disease_model = Sequential()\nmulti_disease_model.add(base_mobilenet_model)\nmulti_disease_model.add(GlobalAveragePooling2D())\nmulti_disease_model.add(Dropout(0.5))\nmulti_disease_model.add(Dense(512))\nmulti_disease_model.add(Dropout(0.5))\nmulti_disease_model.add(Dense(len(all_labels), activation = 'sigmoid'))\nmulti_disease_model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n                           metrics = ['binary_accuracy', 'mae'])\nmulti_disease_model.summary()","metadata":{"_cell_guid":"235846d4-3ef1-4888-a276-6134ad572415","_uuid":"a447f8cc7274c06555849a40881fb903aca7001a","execution":{"iopub.status.busy":"2021-07-30T12:19:20.665678Z","iopub.execute_input":"2021-07-30T12:19:20.66619Z","iopub.status.idle":"2021-07-30T12:19:24.909905Z","shell.execute_reply.started":"2021-07-30T12:19:20.666138Z","shell.execute_reply":"2021-07-30T12:19:24.908961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_nabil_weights.best.hdf5\".format('xray_class')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=3)\ncallbacks_list = [checkpoint, early]","metadata":{"_cell_guid":"1acd1753-dae2-440d-a9d5-f3bbebfe446f","_uuid":"90a131f99bea8b77fba54024e261a97e24dfc6c1","execution":{"iopub.status.busy":"2021-07-30T12:19:31.636209Z","iopub.execute_input":"2021-07-30T12:19:31.636514Z","iopub.status.idle":"2021-07-30T12:19:31.659952Z","shell.execute_reply.started":"2021-07-30T12:19:31.636464Z","shell.execute_reply":"2021-07-30T12:19:31.658585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# First Round\nHere we do a first round of training to get a few initial low hanging fruit results","metadata":{"_cell_guid":"e5ad629e-15a3-4c96-ac74-db8077b101fe","_uuid":"eba5247e4a767def4b4ead6e2f02f3c334edbbf0"}},{"cell_type":"code","source":"multi_disease_model.fit_generator(train_gen, \n                                  steps_per_epoch=100,\n                                  validation_data = (test_X, test_Y), \n                                  epochs = 10, \n                                  callbacks = callbacks_list)","metadata":{"_cell_guid":"c269083c-7617-4c16-8f96-353c1f3d8eef","_uuid":"cbdfcf827510dfb3bdba6ab08ff60e21838d6987","execution":{"iopub.status.busy":"2021-07-30T12:19:54.126252Z","iopub.execute_input":"2021-07-30T12:19:54.126684Z","iopub.status.idle":"2021-07-30T13:11:39.251437Z","shell.execute_reply.started":"2021-07-30T12:19:54.126616Z","shell.execute_reply":"2021-07-30T13:11:39.249927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check Output\nHere we see how many positive examples we have of each category","metadata":{"_cell_guid":"571df602-c0f1-4ba0-9f1e-0c9fdc10eff3","_uuid":"392f3973459dcbb3fc998191baca4d047995d351"}},{"cell_type":"code","source":"for c_label, s_count in zip(all_labels, 100*np.mean(test_Y,0)):\n    print('%s: %2.2f%%' % (c_label, s_count))","metadata":{"_cell_guid":"d9f519ef-4b4f-4bd9-8989-643b21cb8904","_uuid":"308a85cd454ad05e451ec1db99432c6fe85e8e41","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_Y = multi_disease_model.predict(test_X, batch_size = 32, verbose = True)","metadata":{"_cell_guid":"73a8dba1-3d8e-47ec-b945-3101ad57dcef","_uuid":"0878962d872569c57b0f959751c522ae928f92e3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ROC Curves\nWhile a very oversimplified metric, we can show the ROC curve for each metric","metadata":{"_cell_guid":"7a0fc649-158c-4844-9b05-f6a62214009f","_uuid":"4acd4919e0ba24e2d06ef75fbb054a907a582c7a"}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\nfor (idx, c_label) in enumerate(all_labels):\n    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nfig.savefig('barely_trained_net.png')","metadata":{"_cell_guid":"cc076f02-0bf2-4d3f-a6ab-f192bed9e6a9","_uuid":"d7168d90928d842c295c64e2446e84eb068fd391"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Continued Training\nNow we do a much longer training process to see how the results improve","metadata":{"_cell_guid":"6c2fe734-8f87-4537-81e0-d0ce68bc2545","_uuid":"8a03574bc1f2b3441538c2408fc158324d6d23df"}},{"cell_type":"code","source":"multi_disease_model.fit_generator(train_gen, \n                                  steps_per_epoch = 100,\n                                  validation_data =  (test_X, test_Y), \n                                  epochs = 5, \n                                  callbacks = callbacks_list)","metadata":{"_cell_guid":"80b6ede7-052b-4fa2-ab97-bed0199db681","_uuid":"0b35cd7ef77680d2aa180812622d89388b8fff63"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the best weights\nmulti_disease_model.load_weights(weight_path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_Y = multi_disease_model.predict(test_X, batch_size = 32, verbose = True)","metadata":{"_cell_guid":"97dd6d26-8d12-4aa5-8544-6bde2f8200a6","_uuid":"2f358c745432e497adfac31c6d97abc8b61bd0eb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# look at how often the algorithm predicts certain diagnoses \nfor c_label, p_count, t_count in zip(all_labels, \n                                     100*np.mean(pred_Y,0), \n                                     100*np.mean(test_Y,0)):\n    print('%s: Dx: %2.2f%%, PDx: %2.2f%%' % (c_label, t_count, p_count))","metadata":{"_cell_guid":"3e754b40-8492-4f5b-a19f-a0bfd2c9b4f4","_uuid":"db77f749926ac5936e860617b22713715a69157a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\nfor (idx, c_label) in enumerate(all_labels):\n    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nfig.savefig('trained_net.png')","metadata":{"_cell_guid":"31990e46-1437-4945-aaa5-b31b377d6538","_uuid":"a5dd26025391067cd0220b7502b193e5e095edbd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Show a few images and associated predictions","metadata":{"_cell_guid":"a50931b1-4d88-4b2f-93f7-ad3c9de31e5c","_uuid":"8ad061d6b08b9ff383f682c35c8b55f30fb560a1"}},{"cell_type":"code","source":"sickest_idx = np.argsort(np.sum(test_Y, 1)<1)\nfig, m_axs = plt.subplots(4, 2, figsize = (16, 32))\nfor (idx, c_ax) in zip(sickest_idx, m_axs.flatten()):\n    c_ax.imshow(test_X[idx, :,:,0], cmap = 'bone')\n    stat_str = [n_class[:6] for n_class, n_score in zip(all_labels, \n                                                                  test_Y[idx]) \n                             if n_score>0.5]\n    pred_str = ['%s:%2.0f%%' % (n_class[:4], p_score*100)  for n_class, n_score, p_score in zip(all_labels, \n                                                                  test_Y[idx], pred_Y[idx]) \n                             if (n_score>0.5) or (p_score>0.5)]\n    c_ax.set_title('Dx: '+', '.join(stat_str)+'\\nPDx: '+', '.join(pred_str))\n    c_ax.axis('off')\nfig.savefig('trained_img_predictions.png')","metadata":{"_cell_guid":"714ada59-850d-4d88-b983-2f9107f36e70","_uuid":"e5191706a55a5ab8b68773d0b881aac4b020795a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train MobileNet on NIH Chest X-ray dataset","metadata":{"_cell_guid":"48aff5bd-c927-44ae-abd3-1de884969d3b","_uuid":"817ed988ed86bc7941065eeac676d1b50cef5d0b"}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom glob import glob\n%matplotlib inline\nimport matplotlib.pyplot as plt","metadata":{"_cell_guid":"68354276-ebbb-46ca-acd6-9e8cd1354bba","_uuid":"6c186e1070db679fb62a4a08e4f42a7ece925aff","execution":{"iopub.status.busy":"2021-08-02T05:31:17.517035Z","iopub.execute_input":"2021-08-02T05:31:17.517608Z","iopub.status.idle":"2021-08-02T05:31:17.541966Z","shell.execute_reply.started":"2021-08-02T05:31:17.517557Z","shell.execute_reply":"2021-08-02T05:31:17.541193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_xray_df = pd.read_csv('../input/data/Data_Entry_2017.csv')\nall_image_paths = {os.path.basename(x): x for x in \n                   glob(os.path.join('..', 'input', 'data', 'images*', '*', '*.png'))}\nprint('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\nall_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\n# all_xray_df['Patient Age'] = all_xray_df['Patient Age'].map(lambda x: int(x[:-1]))\nall_xray_df.sample(3)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T05:45:53.515418Z","iopub.execute_input":"2021-08-02T05:45:53.515752Z","iopub.status.idle":"2021-08-02T05:45:54.523152Z","shell.execute_reply.started":"2021-08-02T05:45:53.515692Z","shell.execute_reply":"2021-08-02T05:45:54.52217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\nfrom itertools import chain\nall_labels = np.unique(list(chain(*all_xray_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\nall_labels = [x for x in all_labels if len(x)>0]\nprint('All Labels ({}): {}'.format(len(all_labels), all_labels))\nfor c_label in all_labels:\n    if len(c_label)>1: # leave out empty labels\n        all_xray_df[c_label] = all_xray_df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\nall_xray_df.sample(3)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T05:46:26.759572Z","iopub.execute_input":"2021-08-02T05:46:26.759907Z","iopub.status.idle":"2021-08-02T05:46:28.103682Z","shell.execute_reply.started":"2021-08-02T05:46:26.759849Z","shell.execute_reply":"2021-08-02T05:46:28.102858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_xray_df['disease_vec'] = all_xray_df.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-02T05:49:42.604627Z","iopub.execute_input":"2021-08-02T05:49:42.605027Z","iopub.status.idle":"2021-08-02T05:50:41.416563Z","shell.execute_reply.started":"2021-08-02T05:49:42.604954Z","shell.execute_reply":"2021-08-02T05:50:41.415714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df, valid_df = train_test_split(all_xray_df, \n                                   test_size = 0.25, \n                                   random_state = 2018,\n                                   stratify = all_xray_df['Finding Labels'].map(lambda x: x[:4]))\nprint('train', train_df.shape[0], 'validation', valid_df.shape[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-02T05:51:00.739159Z","iopub.execute_input":"2021-08-02T05:51:00.739581Z","iopub.status.idle":"2021-08-02T05:51:01.947183Z","shell.execute_reply.started":"2021-08-02T05:51:00.739509Z","shell.execute_reply":"2021-08-02T05:51:01.946157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nIMG_SIZE = (128, 128)\ncore_idg = ImageDataGenerator(samplewise_center=True, \n                              samplewise_std_normalization=True, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range= 0.05, \n                              width_shift_range=0.1, \n                              rotation_range=5, \n                              shear_range = 0.1,\n                              fill_mode = 'reflect',\n                              zoom_range=0.15)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T05:51:11.041905Z","iopub.execute_input":"2021-08-02T05:51:11.042268Z","iopub.status.idle":"2021-08-02T05:51:13.66962Z","shell.execute_reply.started":"2021-08-02T05:51:11.042206Z","shell.execute_reply":"2021-08-02T05:51:13.668733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen","metadata":{"execution":{"iopub.status.busy":"2021-08-02T05:51:20.997861Z","iopub.execute_input":"2021-08-02T05:51:20.998245Z","iopub.status.idle":"2021-08-02T05:51:21.017947Z","shell.execute_reply.started":"2021-08-02T05:51:20.998168Z","shell.execute_reply":"2021-08-02T05:51:21.017032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = flow_from_dataframe(core_idg, train_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = 32)\n\nvalid_gen = flow_from_dataframe(core_idg, valid_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = 256) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(flow_from_dataframe(core_idg, \n                               valid_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = 1024)) # one big batch","metadata":{"execution":{"iopub.status.busy":"2021-08-02T05:51:36.063612Z","iopub.execute_input":"2021-08-02T05:51:36.064193Z","iopub.status.idle":"2021-08-02T05:53:22.129561Z","shell.execute_reply.started":"2021-08-02T05:51:36.064138Z","shell.execute_reply":"2021-08-02T05:53:22.128604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t_x, t_y = next(train_gen)\nfig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone', vmin = -1.5, vmax = 1.5)\n    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(all_labels, c_y) \n                             if n_score>0.5]))\n    c_ax.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-08-02T05:54:56.850265Z","iopub.execute_input":"2021-08-02T05:54:56.851157Z","iopub.status.idle":"2021-08-02T05:55:00.033933Z","shell.execute_reply.started":"2021-08-02T05:54:56.851099Z","shell.execute_reply":"2021-08-02T05:55:00.033099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.mobilenet import MobileNet\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\nfrom keras.models import Sequential\nbase_mobilenet_model = MobileNet(input_shape =  t_x.shape[1:], \n                                 include_top = False, weights = None)\nmulti_disease_model = Sequential()\nmulti_disease_model.add(base_mobilenet_model)\nmulti_disease_model.add(GlobalAveragePooling2D())\nmulti_disease_model.add(Dropout(0.5))\nmulti_disease_model.add(Dense(512))\nmulti_disease_model.add(Dropout(0.5))\nmulti_disease_model.add(Dense(len(all_labels), activation = 'sigmoid'))\nmulti_disease_model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n                           metrics = ['binary_accuracy', 'mae'])\nmulti_disease_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T05:55:49.06992Z","iopub.execute_input":"2021-08-02T05:55:49.070308Z","iopub.status.idle":"2021-08-02T05:55:53.519167Z","shell.execute_reply.started":"2021-08-02T05:55:49.070254Z","shell.execute_reply":"2021-08-02T05:55:53.517475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_nih_pretrained.hdf5\".format('xray_class')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min')\n\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=3)\ncallbacks_list = [checkpoint, early]","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:00:02.642171Z","iopub.execute_input":"2021-08-02T06:00:02.642536Z","iopub.status.idle":"2021-08-02T06:00:02.653603Z","shell.execute_reply.started":"2021-08-02T06:00:02.642485Z","shell.execute_reply":"2021-08-02T06:00:02.6526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multi_disease_model.fit_generator(train_gen, \n                                  steps_per_epoch=100,\n                                  validation_data = (test_X, test_Y), \n                                  epochs = 15, \n                                  callbacks = callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T06:00:03.988483Z","iopub.execute_input":"2021-08-02T06:00:03.989029Z","iopub.status.idle":"2021-08-02T07:42:17.719935Z","shell.execute_reply.started":"2021-08-02T06:00:03.988984Z","shell.execute_reply":"2021-08-02T07:42:17.71897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_preds = multi_disease_model.predict(test_X)\ny_preds.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-02T08:02:27.274277Z","iopub.execute_input":"2021-08-02T08:02:27.274954Z","iopub.status.idle":"2021-08-02T08:03:08.127706Z","shell.execute_reply.started":"2021-08-02T08:02:27.27489Z","shell.execute_reply":"2021-08-02T08:03:08.126883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T08:03:58.032915Z","iopub.execute_input":"2021-08-02T08:03:58.033268Z","iopub.status.idle":"2021-08-02T08:03:58.040542Z","shell.execute_reply.started":"2021-08-02T08:03:58.03322Z","shell.execute_reply":"2021-08-02T08:03:58.039436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}