{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hr-analytics-job-change-of-data-scientists/aug_train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Encode categorical columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_data(df_new):\n\n    #Encode experience column\n    df_new.loc[df_new['experience'] == '>20', 'experience'] = '21'\n    df_new.loc[df_new['experience'] == '<1', 'experience'] = '0'\n    df_new['experience'] = df_new['experience'].astype(float)\n\n    #Encode education_level column\n    # Using pandas factorize method for ordinal data\n    categories = pd.Categorical(df_new['education_level'], categories=['Primary School', 'High School', 'Graduate', 'Masters', 'Phd'], ordered=True)\n    # Order of labels set for data\n    print(categories)\n    # Factorizing the column data\n    labels, unique = pd.factorize(categories, sort=True)\n    df_new['education_level'] = labels\n\n    #Encode last_new_job column\n    categories = pd.Categorical(df_new['last_new_job'], categories=['never', '1', '2', '3', '4', '>4'], ordered=True)\n    # Order of labels set for data\n    print(categories)\n    # Factorizing the column data\n    labels, unique = pd.factorize(categories, sort=True)\n    df_new['last_new_job'] = labels\n\n    #Encode company_size column\n    categories = pd.Categorical(df_new['company_size'], categories=['<10', '10/49', '50-99', '100-500', '500-999', '1000-4999', '5000-9999', '10000+'], ordered=True)\n    # Order of labels set for data\n    print(categories)\n    # Factorizing the column data\n    labels, unique = pd.factorize(categories, sort=True)\n    df_new['company_size'] = labels\n    \n    #Fill the missing values in categorical columns\n    df_new = df_new.fillna(df_new.mode().iloc[0])\n    df_new.head()\n    \n    return df_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encode the experience column\ndf_new = preprocess_data(df.copy())\ndf_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_mat = df_new.corr()\n#print(corr_mat)\ncorr_mat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot the correlation matrix heat map\nsns.heatmap(corr_mat, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature - Target correlation based insights\n1. Candidates working in Companies situated in the cities with higher development index (More developed cities) are less likely to switch their jobs.\n2. Candidates with higher work experience are less likely to swith their jobs.\n3. Candidates with higher work experience like to live in cities with higher higher development index.\n4. Candidates with higher work experience has higher education level\n5. Candidates working in large companies are less likely to switch their jobs"},{"metadata":{},"cell_type":"markdown","source":"# Model Training with Weighted Logistic Regressi"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_state = 0\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, recall_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate labelencoder object\nle = LabelEncoder()\n\n# Categorical boolean mask\ncategorical_feature_mask = df_new.dtypes==object\nprint(categorical_feature_mask)\n# filter categorical columns using mask and turn it into a list\ncategorical_cols = df_new.columns[categorical_feature_mask].tolist()\nprint(categorical_cols)\n# apply le on categorical feature columns\n#df_new = df.copy()\ndf_new[categorical_cols] = df_new[categorical_cols].apply(lambda col: le.fit_transform(col))\ndf_new.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['target'] = df['target'].astype(int)\n#check the class distribution\ndf['target'].value_counts()/df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> From the above cell we can see that target class disctribution is imbalanced."},{"metadata":{"trusted":true},"cell_type":"code","source":"#get the dependent and independent variables\n#df_new = df_new.drop(columns=['enrollee_id'])\ndf_new = df_new.drop(['enrollee_id'], axis=1)\ndf_features = df_new[df_new.columns[0:-1]]\ndf_target = df_new['target']\nx_train, x_val, y_train, y_val = train_test_split(df_features, df_target, test_size=0.2, random_state=random_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Standardize the features\nfrom sklearn import preprocessing\nnorm = preprocessing.StandardScaler()\ndf_features=norm.fit_transform(df_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Weighted logistic regression\nw = {0:2, 1:7} #use the inverse of class ratios as class weights\nlr_model_weighted = LogisticRegression(random_state=random_state, class_weight=w)\nlr_model_weighted.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_model(model, x_test, y_test):\n    predictions = model.predict(x_test)\n    print(\"Predictions:\")\n    print(predictions)\n    # performance\n    print(f'Accuracy Score: {accuracy_score(y_test,predictions)}')\n    print(f'Area Under Curve: {roc_auc_score(y_test, predictions)}')\n    print(f'Recall score: {recall_score(y_test, predictions)}')\n    print(\"Classification report: \")\n    print(classification_report(y_test, predictions))\n    cm = confusion_matrix(y_test, predictions)\n    print(\"Confusion Matrix Plot: \\n{}\".format(cm))\n    sns.heatmap(cm, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_model(lr_model_weighted, x_val, y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#/kaggle/input/hr-analytics-job-change-of-data-scientists/sample_submission.csv\n#/kaggle/input/hr-analytics-job-change-of-data-scientists/aug_test.csv\ndf_test = pd.read_csv(\"/kaggle/input/hr-analytics-job-change-of-data-scientists/aug_test.csv\")\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_new = preprocess_data(df_test.copy())\ndf_test_new = df_test_new.drop(['enrollee_id'], axis=1)\n# instantiate labelencoder object\nle = LabelEncoder()\n\n# Categorical boolean mask\ncategorical_feature_mask = df_test_new.dtypes==object\nprint(categorical_feature_mask)\n# filter categorical columns using mask and turn it into a list\ncategorical_cols = df_test_new.columns[categorical_feature_mask].tolist()\nprint(categorical_cols)\n# apply le on categorical feature columns\n#df_new = df.copy()\ndf_test_new[categorical_cols] = df_test_new[categorical_cols].apply(lambda col: le.fit_transform(col))\n\n#Standardize the features\nfrom sklearn import preprocessing\nnorm = preprocessing.StandardScaler()\ndf_test_new=norm.fit_transform(df_test_new)\n\n#df_test_new.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pr = lr_model_weighted.predict(df_test_new)\nprint(pr)\ndf_test['target'] = pr\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_out = df_test[['enrollee_id','target']]\nfinal_out.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_out.to_csv('./subm.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}