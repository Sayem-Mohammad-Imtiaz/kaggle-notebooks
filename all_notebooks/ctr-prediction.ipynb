{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \n#import xlearn as xl","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\n\ntrain = pd.read_csv(\"../input/avazu-ctr-train/train.csv\", nrows = 20000000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#无缺失值\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns',None)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#查看数据型特征和类别型特征\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nparams = {'legend.fontsize':'x-large',\n         'figure.figsize':(30,30),\n         'axes.labelsize':'x-large',\n         'axes.titlesize':'x-large',\n         'xtick.labelsize':'x-large',\n         'ytick.labelsize':'x-large'}\n\nsns.set_style('whitegrid')\nsns.set_context('talk')\n\nplt.rcParams.update(params)\npd.options.display.max_colwidth = 600","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_features =['hour','C1','C14','C15','C16','C17','C18','C19','C20','C21','click']\ntrain[numerical_features].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrMatt = train[['C1','C14','C15','C16','C17','C18','C19','C20','C21','click','banner_pos','hour']].corr()\nmask = np.array(corrMatt)\nmask[np.tril_indices_from(mask)] = False\nsns.heatmap(corrMatt,mask=mask,vmax=.8,square=True,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"主要相关性特征\nC14和C17:0.98\nC17 C21:0.44\nC14 C21:0.42\nC18 C21:-0.57\nC19和C14 C17:-0.31\nC19 C21:-0.26\nC18和C14 C17:-0.24 -0.25"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.DataFrame(columns = [\"id\",\"click\",\"hour\", \"banner_pos\", \"site_id\", \"site_domain\", \"site_category\",\"app_id\", \"app_domain\", \"app_category\",\n                             \"device_id\",\"device_ip\",\"device_model\",\"device_type\",\"device_conn_type\",\"C14\",\"C15\",\"C16\",\"C17\",\"C18\",\"C19\",\"C20\",\"C21\"])\n\n#train_data\nhour_index = 14102200\n\nwhile(hour_index < 14102224):\n    data = train.loc[train['hour'] == hour_index]\n    train_data = pd.concat([train_data,data])\n    hour_index = hour_index + 1\n    \ndel hour_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.stripplot(x=\"banner_pos\",y=\"click\",data=train_data)\nplt.title(\"2014年10月22日24个时段散点图\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item = train_data['hour'].value_counts()\nitem.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for hour_index in item.index:\n#     data = train_data.loc[train_data['hour'] == hour_index]\n#     sns.stripplot(x=\"banner_pos\",y=\"click\",data=data)\n#     plt.title(hour_index)\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train['day']=np.round(train,hour%10000/100)\n#train['day'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train['week']=np.round(train,（hour%10000/100+4）%7)\n#train['week'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train['hour']=np.round(train,hour%100)\n# train['hour'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sns.countplot(x=\"hour1\", hue=\"click\",data=train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sns.countplot(x=\"day\", hue=\"click\",data=train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"time\"]=train[\"hour\"]%100\ntrain[\"week\"]=np.int64(((train[\"hour\"]%10000)/100+4)%7)\ntrain[\"day\"]=np.int64((train[\"hour\"]/100)%100)\nprint(\"新建特征time week day完毕\")\ntrain['size']=train['C15'].astype('str')+'_'+train['C16'].astype('str')\nprint(\"新建特征size完毕\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#创建计数特征\nfor feature in ['device_ip','device_id']:\n    grp1 = train.groupby(data[feature])\n    cnt1 = grp1[feature].aggregate(np.size)\n    _cnt = cnt1[train[feature]].values\n#    _cnt[np.isnan(_cnt)]=False\n    new_name=feature+'_count'\n    train[new_name]=_cnt\nprint(\"新建特征计数特征完毕\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import hashlib\n#garbage collector\nimport gc\nimport time\nfrom sklearn.preprocessing import StandardScaler\n\nNR_BINS = 1000000\n\ndef hashstr(input):\n    return str(int(hashlib.md5(input.encode('utf8')).hexdigest(), 16)%(NR_BINS-1)+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#用户的历史点击率特征\ndata1=train.groupby(by='device_ip').click.mean()\n_data=data1[train['device_ip']].values\ntrain['click_rate']=_data\n    \nprint(\"开始哈希编码\")\n# ## 哈希编码 \nhash_list=['site_id', 'site_domain', 'app_id', 'app_domain', 'device_id', 'device_ip',\n            'device_model']\nfor item in hash_list:\n    feats = []\n    for row in train[item]:\n        feats.append(hashstr(row))\n    newname =item +'_hashed'\n    train[newname]=feats\n    #del feats\n    #data.drop([row],inplace=True,axis=1)\ntrain.drop(hash_list,inplace = True, axis = 1)\nprint(\"哈希编码完成\")\n\nx_3 = train['click']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One_hot编码\nprint(\"开始onehot编码\")\ncategorical_features=['week','C1','banner_pos','site_category','app_category','device_type','device_conn_type','C18','C19','C21','size']\nx_1 = train[categorical_features]\n#更改数据类型\nx_1 = pd.DataFrame(data=x_1, dtype='object')\n#get_dummies进行编码\nx_1 = pd.get_dummies(x_1)\nprint(\"onehot编码完成\")\n\n#丢弃特征\ndrop_feats=['click','week','C1','banner_pos','site_category','app_category','device_type','device_conn_type','C15','C16','C18','C19','C21','size']\ntrain.drop(drop_feats, inplace = True, axis = 1)\n#标准化    \n# 初始化特征的标准化器\nss_X = StandardScaler()\n# 分别对训练和测试数据的特征进行标准化处理\nx_2 = ss_X.fit_transform(train)\nx_2 = pd.DataFrame(x_2)\nprint(\"标准化处理\")\n\n#将数据连接在一起\ndata_final = pd.concat([x_3,x_2,x_1], axis = 1)\ndel x_1,x_2,x_3,data\nsavename = \"fe_train.csv\"\nsavenameI = \"fe_test.csv\"\nsavenameII = \"fe_names.csv\"\nsavenameIII = \"fe_validation.csv\"\n    \ndata_final_I  = data_final.iloc[0:40428967]\n    \n#打乱顺序\ndata_final_I.sample(frac=1, replace=True)\n    \ndata_train_  = data_final_I.iloc[0:36000000]\n\ndata_validation_ = data_final_I.iloc[36000000:40428967]\n        \ndata_test_ = data_final.iloc[-4577464:]\ncolumn_names = data_final.iloc[0:10]\n    \nprint(\"data_final shape\",data_final.shape)\nprint(\"data_train shape\",data_train_.shape)\nprint(\"data_validation shape\",data_validation_.shape)\nprint(\"data_test shape\",data_test_.shape)\n   \n    \ncolumn_names.to_csv(savenameII,index=False)\ndata_train_.to_csv(savename,sep=' ',index=False,header=False)\ndata_test_.to_csv(savenameI,sep=' ',index=False,header=False)\ndata_validation_.to_csv(savenameIII,sep=' ',index=False,header=False)\ndel data_final,data_final_I,data_train_,data_test_,data_validation_,column_names\ngc.collect()\n    \nprint(\"The times finish\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}