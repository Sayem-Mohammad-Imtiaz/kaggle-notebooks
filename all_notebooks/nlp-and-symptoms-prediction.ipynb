{"cells":[{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install flair\n!pip install transformers\n!pip install node2vec\n!pip install wordcloud #https://github.com/amueller/word_cloud","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom flair.models import SequenceTagger\nfrom flair.data import Sentence\nfrom transformers import pipeline\npd.set_option('display.max_columns', 30)\nfrom collections import Counter \nimport nltk\nimport matplotlib.pyplot as plt\nimport re\nfrom tqdm.autonotebook import tqdm\nimport networkx as nx\nfrom wordcloud import WordCloud\nfrom sklearn.cluster import DBSCAN\n\nimport plotly.graph_objects as go\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenizer(text):\n    text = text.split(',')\n    res = []\n    for t in text:\n        res.extend(nltk.word_tokenize(t))\n        \n    return res","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/novel-corona-virus-2019-dataset/COVID19_line_list_data.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = data.summary.dropna().values\nprint(f\"Text lenght: {len(text)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"symptoms = data.symptom.dropna().tolist()\nprint(len(symptoms))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Total dataset len: {len(data)}\")\nprint(f\"Death: {len(data.loc[data.death == '1'])}\")\nprint(f\"Recovered: {len(data.loc[data.recovered == '1'])}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NLP"},{"metadata":{},"cell_type":"markdown","source":"## Question answering"},{"metadata":{},"cell_type":"markdown","source":"We can collect some data using NLP question answering. Adding more questions, and filtering by confidesce score we can fill some missing walues"},{"metadata":{"trusted":true},"cell_type":"code","source":"ner_tagger = SequenceTagger.load('ner')\n\nnlp_qa = pipeline('question-answering')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Look like NER is not useful for us, if we want parse dates its better to use regular expressions."},{"metadata":{"trusted":true},"cell_type":"code","source":"match = re.findall(r'(\\d+/\\d+/\\d+)',text[1])\nprint(match)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence = Sentence(text[1])\nner_tagger.predict(sentence)\nprint(sentence.to_tagged_string())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Try to use question answering. \nSome sample questions"},{"metadata":{"trusted":true},"cell_type":"code","source":"questions = [\n    'How old?',\n    'Gender?',\n    'Where from?',\n    'When symptoms onset?',\n    'When Hospitalized?',\n    'When quarantined?',\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(text[0])\nfor q in questions:\n    print(f\"Question: {q}, answer: {nlp_qa(context = text[0], question=q)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wordcloud basic"},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud = WordCloud().generate(' '.join(symptoms))\n\nplt.figure(figsize=[10, 6])\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from flair.embeddings import WordEmbeddings, DocumentRNNEmbeddings\n\nglove_embedding = WordEmbeddings('glove')\n\ndocument_embeddings = DocumentRNNEmbeddings([glove_embedding])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings = np.empty((len(text), 128))\nfor idx, t in tqdm(enumerate(text)):\n    sentence = Sentence(t)\n    document_embeddings.embed(sentence)\n    embeddings[idx, :] = (sentence.get_embedding().detach().numpy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Clustering"},{"metadata":{"trusted":true},"cell_type":"code","source":"dbscan=DBSCAN(eps=0.08, min_samples=2,metric='cosine' ).fit(embeddings)\n\ndf_cluster = pd.DataFrame({\"text\":text, \"cluster\":dbscan.labels_})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cluster.cluster.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cluster.loc[df_cluster['cluster'] == 31].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\n\ndef plot_pca(train,y, text=\"Plot\", algo = 'TSNE', size = 2):\n    \"\"\"Function visualizating PCA/TSNE\"\"\"\n\n    plt.figure(figsize=(20,8))\n    if algo == 'PCA':\n        pca = PCA(n_components = 2,copy=False)\n    elif algo == 'TSNE':\n        pca = TSNE(n_components = 2)\n    else:\n        print('Unknown algo, using PCA...')\n        pca = PCA(n_components = 2, copy=False)\n        \n    train_pca = pca.fit_transform(train)\n\n    plt.scatter(train_pca[:,0], train_pca[:,1],c=y, edgecolor='none', alpha=0.9,\n            cmap=plt.cm.get_cmap('seismic', size))\n    plt.title(text)\n    plt.xlabel('component 1')\n    plt.ylabel('component 2')\n    plt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(dbscan.labels_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pca(embeddings, dbscan.labels_, size = len(np.unique(dbscan.labels_)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''plt.figure(figsize=[10, 8])\nplt.title(\"Text embedding\")\nplt.scatter(transformed[:,0], transformed[:,1], edgecolor='none', alpha=0.9,)\nplt.xlabel('X-comp')\nplt.ylabel('Y-comp')\nplt.show()'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Look like we have some clusters at document embedding space"},{"metadata":{},"cell_type":"markdown","source":"# Symptoms Node2Vec"},{"metadata":{},"cell_type":"markdown","source":"Create symptoms graph and Node2Vec model for finding similar symptom and get a probability of next potential symptoms"},{"metadata":{"trusted":true},"cell_type":"code","source":"symptoms[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counter = Counter()\nlinks = dict(dict())\n\nfor row in symptoms:\n    \n    row = tokenizer(row)    \n    \n    for symptome in row:\n        counter[symptome] += 1\n        \n    for subsymptome in row:\n        if not(symptome in links.keys()):\n            links[symptome] = dict()\n            \n        if not(subsymptome in links[symptome].keys()):\n            links[symptome][subsymptome] = 0\n            \n        if symptome != subsymptome:    \n            links[symptome][subsymptome] += 1\n            \nfor key1 in links.keys():\n    for key2 in links[key1].keys():\n        links[key1][key2] /= counter[key1]\n        \nlinks_dict = dict()\nfor key1, val1 in links.items():\n    for key2, val2 in links[key1].items():\n        #if val2 >= 0.5:\n        if key1 != key2:\n            links_dict[(key1, key2)] = val2\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counter.most_common(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"size_df = pd.DataFrame.from_dict(counter, orient='index').reset_index()\nsize_df.columns = ['label', 'size']\n\nlinks_df = pd.DataFrame([[list(key)[0], val, list(key)[1]] for key, val in links_dict.items() if list(key)[0] != list(key)[1]], columns = ['source', 'weight', 'target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"G = nx.Graph()\nfor idx, row in size_df.iterrows():\n    G.add_node(row['label'], size = float(row['size']))\n\nfor idx, row in links_df.iterrows():\n    G.add_edge(row['source'], row['target'], weight=float(row['weight']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Nodes len: {len(list(G.nodes()))}\")\nprint(f\"Edges len: {len(list(G.edges()))}\")\n# %%\nplt.figure(figsize=[20, 8])\n\nparams = {\n    'edge_color'    : '#FFDEA2',\n    'width'         : 1,\n    'with_label'    : True,\n    'font_weight'   : 'regular'\n}\n\nnode_list = [i*10 for i in size_df['label'].values]\nnode_size = [i*10 for i in size_df['size'].values]\nnx.draw_networkx(G,node_list = node_list,node_size=node_size, **params)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create node2vec for symptomes prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"from node2vec import Node2Vec\n\nn2v = Node2Vec(G, dimensions=15, num_walks=100, workers=4)\nnode_model = n2v.fit(size=3, window=2, seed=42, iter=1, sg=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"node_model.most_similar(['fever'], topn=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"node_model.most_similar(['fever', 'cough'], topn=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}