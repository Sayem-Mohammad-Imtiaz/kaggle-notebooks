{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\npath = \"../input\"+'/'+os.listdir(\"../input\")[0]\ncontent = pd.read_csv(path)\n# to check the data has been loaded successfully\nprint(content.head())\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# to have a glance of the general information\nprint( content.describe() )\nprint( content.columns )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c0f08359bf7e4fa668e43d3337bb039f0f8d2ca"},"cell_type":"code","source":"## to figure out the integrity of the dataset\nnull_count = content.isnull().sum()\npercentage = null_count / len(content) *100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d7b455a789b569f56fc8198045e5d84f59d5fbb"},"cell_type":"code","source":"# to plot the percentage of empty data\nimport matplotlib.pyplot as plt\nplt.figure( figsize=(4,4) )\npercentage.plot( kind='bar',label='the percentage of NULL values' )\nplt.ylim(0.0,100.0)\nplt.legend()\nplt.show( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df650ee26b748358ca229f3872e89f3c0d6df8ff"},"cell_type":"code","source":"\n# to drop useless features\ncontent.drop( columns=['id','Unnamed: 32'],inplace=True )\nprint(content.columns)\nprint( content.dtypes )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bbedf5b4701384c0af3f6255e928fe6d6108ac3"},"cell_type":"code","source":"\n# to check the distribution of the diagnose feature\nlabel = content[ 'diagnosis' ]\nplt.figure( figsize=[10,5] )\nplt.subplot(121)\nplt.pie( x= label.value_counts(),labels=label.unique(),colors=['b','r'],explode=[0.1,0.1],autopct='%.2f' )\nplt.title( 'the distribution of labels' )\nplt.subplot(122)\nplt.bar( x = [ 0.2,1 ],height =label.value_counts() ,width=0.6,color=['lightskyblue','gold'] )\nplt.xticks( range(2),label.unique() )\nplt.title( 'the number of labels' )\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45671cd9f2f9497d58f597d585f19ec138cb30e3"},"cell_type":"code","source":"\n# to convert the category features\nprint( content['diagnosis'].unique() )\ncontent['diagnosis']=content['diagnosis'].map( { 'M':0,'B':1 } )\nprint( content.dtypes )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb2202eaf9e54358e8d0146f56b12ea97695b89f"},"cell_type":"code","source":"\n# to visualize the distribution of different labels\nB = content[ content['diagnosis']==1 ]\nM = content[ content['diagnosis']==0 ]\n\nimport seaborn as sns\n\ndef plot_distribution ( feature ):\n    global B\n    global M\n    b = B[feature]\n    m = M[feature]\n    group_labels = ['benign','malignant']\n    colors = ['#FFD700', '#7EC0EE']\n    plt.figure( figsize=[4,4] )\n    sns.distplot( b,color=colors[0],label=group_labels[0] )\n    sns.distplot( m,color=colors[1],label=group_labels[1] )\n    plt.title(feature)\n    plt.legend(  )\n    plt.show()\n\nplot_distribution('radius_mean')\nplot_distribution('texture_mean')\nplot_distribution('perimeter_mean')\nplot_distribution('area_mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a04c5d4f00dee993b1c469d95740f51da9e7f06"},"cell_type":"code","source":"\n# correlation matrix\ncorrelation = content.corr()\ncor_col = correlation.columns.tolist()\nplt.figure(figsize=[8,8])\nsns.heatmap(correlation,cmap='viridis',linewidths=0.05,linecolor='white')\nplt.title('the correlation between different features')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc22274615fac433635bff2318c95b1eabf0d728"},"cell_type":"code","source":"\n# to visualize the positive relationships between other features\ndef plot_fvfin_malignant ( feature1,feature2 ):\n    global M\n    global B\n    x_m = M[feature1]\n    y_m = M[feature2]\n    x_b = B[feature1]\n    y_b = B[feature2]\n\n    plt.scatter( x=x_m, y=y_m,edgecolors=['#848484','#848484'] )\n    plt.scatter( x=x_b, y=y_b,edgecolors=['#848484','#848484'] )\n    plt.title( feature1+'  vs  '+feature2 )\n    plt.legend( [ 'Malignant','Benign' ] )\n    #plt.imshow()\n\n\nplt.figure( figsize=[10,10] )\nplt.subplot( 221 )\nplot_fvfin_malignant('perimeter_mean','radius_worst')\nplt.subplot( 222 )\nplot_fvfin_malignant('area_mean','radius_worst')\nplt.subplot( 223 )\nplot_fvfin_malignant('texture_mean','texture_worst')\nplt.subplot( 224 )\nplot_fvfin_malignant('area_worst','radius_worst')\n#plt.legend(  )\nplt.suptitle(' positive corelationship ')\nplt.show( )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"783688b7a522826ffd26d84a31a47fde3df39882"},"cell_type":"code","source":"\n# to visualize the negative relationships between features\n\n\nplt.figure( figsize=[10,10] )\nplt.subplot( 221 )\nplot_fvfin_malignant('area_mean','fractal_dimension_mean')\nplt.subplot( 222 )\nplot_fvfin_malignant('radius_mean','fractal_dimension_mean')\nplt.subplot( 223 )\nplot_fvfin_malignant('area_mean','smoothness_se')\nplt.subplot( 224 )\nplot_fvfin_malignant('smoothness_se','perimeter_mean')\n#plt.legend(  )\nplt.suptitle(' negative corelationship ')\nplt.show( )\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9688bc15640568556426f196644d151c2f7fe45c"},"cell_type":"code","source":"\n# to normalize the dataset with standardscale\n\ntarget = content['diagnosis']\nraw_data = content.drop( columns=['diagnosis'] )\nfrom sklearn.preprocessing import StandardScaler\nconv = StandardScaler()\nstd_data = conv.fit_transform( raw_data )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a89a27f0ec7cb8f2262d5633f0f23a7d2e6d99f"},"cell_type":"code","source":"\n# use PCA to reduce dimensionality\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=30,svd_solver='full')\ntransformed_data = pca.fit_transform( std_data )\nprint( transformed_data.shape )\nprint( pca.explained_variance_ratio_*100 )\nprint( pca.explained_variance_ )\n\nthreshold = 0.80\nfor_test = 0\norder = 0\nfor index,ratio in  enumerate (pca.explained_variance_ratio_):\n    if threshold>for_test:\n        for_test+= ratio\n    else:\n        order = index + 1\n        break\n\nprint( 'the first %d features could represent 85 percents of the viarance' % order )\nprint( pca.explained_variance_ratio_[:order].sum() )\ncom_col = [ 'com'+str(i+1) for i in range(order) ]\ncom_col.append('others')\ncom_value = [ i for i in pca.explained_variance_ratio_[:order] ]\ncom_value.append( 1-pca.explained_variance_ratio_[:order].sum() )\ncom_colors = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue', 'lightgrey', 'orange', 'white']\nplt.figure( figsize=[4,4] )\nplt.pie( x=com_value,labels=com_col,colors=com_colors,autopct='%.2f' )\nplt.title( 'the first 6 components' )\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48c45a66867256acaad99763d6cdabdedce4064b"},"cell_type":"code","source":"\n# to define the confusion_matrix and learning_curve\nfrom sklearn.metrics import confusion_matrix\ndef plot_confusion_matrix (  label,pred,classes = [0,1] ,cmap = plt.cm.Blues,title='confusion matrix' ):\n    con_m = confusion_matrix( label,pred )\n    plt.imshow( con_m,interpolation = 'nearest',cmap=cmap )\n    plt.title(title)\n    plt.colorbar()\n    thres = con_m.max() / 2\n    for j in range( con_m.shape[0] ):\n        for i in range( con_m.shape[1] ):\n            plt.text( i,j,con_m[j,i],\n                      horizontalalignment = 'center',\n                      color='white' if con_m[i,j]>thres else 'black')\n\n    plt.ylabel( 'true label' )\n    plt.xlabel( 'predicted label' )\n    plt.xticks(  classes,classes )\n    plt.yticks(  classes,classes )\n    plt.tight_layout()\n\ndef print_matrix(  label,pred ):\n    tn, fp, fn, tp = confusion_matrix( label,pred ).ravel()\n    print( 'Accuracy rate = %.2f' %(( tp+tn )/( tn+fp+fn+tp )) )\n    print('Precision rate = %.2f' % ((tp ) / (fp + tp)))\n    print('Recall rate = %.2f' % ((tp ) / (fn + tp)))\n    print('F1 score = %.2f' % ( 2*(((tp/(tp+fp))*(tp/(tp+fn)))/\n                                                 ((tp/(tp+fp))+(tp/(tp+fn)))) ))\n\ndef plot_ROC( label,pred ):\n    from sklearn.metrics import roc_curve\n    fpr, tpr,t = roc_curve( label,pred )\n    plt.plot(fpr, tpr, label='ROC curve', linewidth=2)\n    plt.plot([0, 1], [0, 1], 'k--', linewidth=2)\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve ')\n    print( 'the threshold is ', t )\n    plt.show()\n\n\nfrom sklearn.model_selection import learning_curve\ndef plot_learning_curve( estimator,title,x,y,train_sizes = np.linspace(.1, 1.0, 5),n_job = 1 ):\n    plt.figure( figsize=[4,4] )\n    plt.title(title)\n    plt.xlabel( 'Training examples' )\n    plt.ylabel( 'Score' )\n\n    train_size,train_score,test_score = learning_curve(estimator,x,y,n_jobs=n_job,train_sizes=train_sizes)\n\n\n    train_scores_mean = np.mean(train_score, axis = 1)\n    train_scores_std = np.std(train_score, axis = 1)\n    test_scores_mean = np.mean(test_score, axis = 1)\n    test_scores_std = np.std(test_score, axis = 1)\n    plt.grid()\n    plt.fill_between(train_size, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_size, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha = 0.1, color = \"g\")\n    plt.plot(train_size, train_scores_mean, 'o-', color = \"r\",\n             label = \"Training score\")\n    plt.plot(train_size, test_scores_mean, 'o-', color = \"g\",\n             label = \"Cross-validation score\")\n    plt.legend(loc = \"best\")\n    return plt\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b5bed41f6f7dd359ef6ef1bca2a857b48e0bc29"},"cell_type":"code","source":"\n# to pick the best estimator\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nrandom_seed = 42\nX_train, X_test, y_train, y_test = train_test_split(transformed_data, target, test_size = 0.12, random_state = random_seed)\nlogistic_reg = LogisticRegression( random_state=random_seed )\npara_grid = {\n            'penalty':['l1','l2'],\n            'C':[0.001,0.01,0.1,1.0,10,100,1000]\n            }\nCV_log_reg = GridSearchCV( estimator=logistic_reg,param_grid=para_grid,n_jobs=-1 )\nCV_log_reg.fit( X_train,y_train )\nbest_para = CV_log_reg.best_params_\nprint( 'the best parameters are ',best_para )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68435efa4a5ab75638249a29a69294885ddab1bb"},"cell_type":"code","source":"\n# now using the best parameters to log the regression model\nlogistic_reg = LogisticRegression( C=best_para['C'],penalty=best_para['penalty'],random_state=random_seed )\nlogistic_reg.fit( X_train,y_train )\ny_pred = logistic_reg.predict( X_test )\n\nplot_confusion_matrix( y_test,y_pred )\nplt.show( )\nprint_matrix(y_test,y_pred)\nplot_ROC(y_test,y_pred)\nplt.show( )\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}