{"cells":[{"metadata":{},"cell_type":"markdown","source":"## EDA ON Text Data"},{"metadata":{},"cell_type":"markdown","source":"## E-Commerce Clothing Reviews "},{"metadata":{},"cell_type":"markdown","source":"Clothing ID: Integer Categorical variable that refers to the specific piece being reviewed.\n    \nAge: Positive Integer variable of the reviewers age.\n\nTitle: String variable for the title of the review.\n\nReview Text: String variable for the review body.\n\nRating: Positive Ordinal Integer variable for the product score granted by the customer from 1 Worst, to 5 Best.\n\nRecommended IND: Binary variable stating where the customer recommends the product where 1 is recommended, 0 is not recommended.\n\nPositive Feedback Count: Positive Integer documenting the number of other customers who found this review positive.\n\nDivision Name: Categorical name of the product high level division.\n\nDepartment Name: Categorical name of the product department name.\n\nClass Name: Categorical name of the product class name."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly.offline import iplot\nimport plotly as py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cufflinks as cf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"py.offline.init_notebook_mode(connected=True)\ncf.go_offline()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/womens-ecommerce-clothing-reviews/Womens Clothing E-Commerce Reviews.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(labels=['Title','Clothing ID'], axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(subset=['Review Text','Division Name'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"contractions = contractions = { \n\"ain't\": \"am not\",\n\"aren't\": \"are not\",\n\"can't\": \"cannot\",\n\"can't've\": \"cannot have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he will\",\n\"he'll've\": \"he will have\",\n\"he's\": \"he is\",\n\"how'd\": \"how did\",\n\"how'd'y\": \"how do you\",\n\"how'll\": \"how will\",\n\"how's\": \"how is\",\n\"I'd\": \"I would\",\n\"I'd've\": \"I would have\",\n\"I'll\": \"I will\",\n\"I'll've\": \"I will have\",\n\"I'm\": \"I am\",\n\"I've\": \"I have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it would\",\n\"it'd've\": \"it would have\",\n\"it'll\": \"it will\",\n\"it'll've\": \"it will have\",\n\"it's\": \"it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"mightn't've\": \"might not have\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"needn't\": \"need not\",\n\"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\",\n\"oughtn't\": \"ought not\",\n\"oughtn't've\": \"ought not have\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"shan't've\": \"shall not have\",\n\"she'd\": \"she would\",\n\"she'd've\": \"she would have\",\n\"she'll\": \"she will\",\n\"she'll've\": \"she will have\",\n\"she's\": \"she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"so've\": \"so have\",\n\"so's\": \"so as / so is\",\n\"that'd\": \"that would\",\n\"that'd've\": \"that would have\",\n\"that's\": \"that is\",\n\"there'd\": \"there would\",\n\"there'd've\": \"there would have\",\n\"there's\": \"there is\",\n\"they'd\": \"they would\",\n\"they'd've\": \"they would have\",\n\"they'll\": \"they will\",\n\"they'll've\": \"they will have\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"to've\": \"to have\",\n\"wasn't\": \"was not\",\n\"we'd\": \"we would\",\n\"we'd've\": \"we would have\",\n\"we'll\": \"we will\",\n\"we'll've\": \"we will have\",\n\"we're\": \"we are\",\n\"we've\": \"we have\",\n\"weren't\": \"were not\",\n\"what'll\": \"what will\",\n\"what'll've\": \"what will have\",\n\"what're\": \"what are\",\n\"what's\": \"what is\",\n\"what've\": \"what have\",\n\"when's\": \"when is\",\n\"when've\": \"when have\",\n\"where'd\": \"where did\",\n\"where's\": \"where is\",\n\"where've\": \"where have\",\n\"who'll\": \"who will\",\n\"who'll've\": \"who will have\",\n\"who's\": \"who is\",\n\"who've\": \"who have\",\n\"why's\": \"why is\",\n\"why've\": \"why have\",\n\"will've\": \"will have\",\n\"won't\": \"will not\",\n\"won't've\": \"will not have\",\n\"would've\": \"would have\",\n\"wouldn't\": \"would not\",\n\"wouldn't've\": \"would not have\",\n\"y'all\": \"you all\",\n\"y'all'd\": \"you all would\",\n\"y'all'd've\": \"you all would have\",\n\"y'all're\": \"you all are\",\n\"y'all've\": \"you all have\",\n\"you'd\": \"you would\",\n\"you'd've\": \"you would have\",\n\"you'll\": \"you will\",\n\"you'll've\": \"you will have\",\n\"you're\": \"you are\",\n\"you've\": \"you have\"\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cont_to_exp(x):\n    if type(x) is str:\n        x = x.replace('\\\\','')\n        for key in contractions:\n            value = contractions[key]\n            x = x.replace(key,value)\n        return x\n    else:\n        return x\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Review Text']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering\n- In this process we will be calculating the features before visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"from textblob import TextBlob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Polarity'] = df['Review Text'].apply(lambda x: TextBlob(x).sentiment.polarity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['review_len'] = df['Review Text'].apply(lambda x: len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['word_count'] = df['Review Text'].apply(lambda x: len(x.split()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## create function for finding average length of words per row\n\ndef get_avg_word_len(x):\n    words = x.split()\n    word_len = 0\n    for word in words:\n        word_len = word_len + len(word)\n        \n    return word_len / len(words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['avg_word_len'] = df['Review Text'].apply(lambda x: get_avg_word_len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Distribution of Sentiment Polarity"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Polarity'].iplot(kind = \"hist\", colors = 'red', bins = 50,\n                     xTitle = 'Polarity', yTitle = 'Count', title = 'Sentiment Polarity Distribution')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribution of Reviews Rating and Reviewers Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Rating'].iplot(kind = 'hist' , xTitle = 'Rating' , yTitle = 'Count' ,\n                  title = 'Review Rating Distribution')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Age'].iplot(kind = 'hist' , bins = 40 , xTitle = 'Age' , yTitle = 'Count' ,\n               title = 'Reviewers Age Distribution' , colors = 'yellow' , linecolor = 'black')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribution of Review Text Length and Word Length"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['review_len'].iplot(kind = 'hist' , xTitle = 'Review Length' , yTitle = 'Count' ,\n                      title = 'Review Text Length Distribution' , colors = 'red' ,\n                      linecolor = 'black')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['word_count'].iplot(kind = 'hist' , xTitle = 'Number of Words' , yTitle = 'Count' ,\n                      title = 'Word Count Distribution' , linecolor = 'black')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndf['avg_word_len'].iplot(kind = 'hist' , xTitle = 'Average' , yTitle = 'Count' ,\n                        title = 'Review Text Average Word Length')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribution of Department, Division, and Class"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('Department Name')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##  We are using inbuilt function value_counts() for finding total values for each group\n\ndf['Department Name'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Department Name'].value_counts().iplot(kind = 'bar' , xTitle = 'Department' , yTitle = 'Count' ,\n                                          title = \"Bar Chart of Department's Name\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Division Name'].value_counts().iplot(kind = 'bar' , xTitle = 'Division' , yTitle = 'Count' ,\n                                         title = \"Bar Chart of Division's Name\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Class Name'].value_counts().iplot(kind = 'bar' , xTitle = 'Class' , yTitle = 'Count' ,\n                                     title = \"Bar Chart of Classe's Name\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribution of Unigram, Bigram and Trigram"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Actual function \n\ndef get_top_n_words(x, n):\n    vec = CountVectorizer().fit(x)\n    bow = vec.transform(x)\n    sum_of_words = bow.sum(axis = 0)\n    words_freq = [(words, sum_of_words[0,idx]) for words , idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x : x[1], reverse=True)\n    return words_freq[:n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribution of Unigram, Bigram and Trigram without Stop Words\n\n### Stop Words are nothing but, the words like this,what,if,is,etc.."},{"metadata":{},"cell_type":"markdown","source":"## Unigram analysis without Stopword"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Actual function \n\ndef get_top_n_words(x, n):\n    vec = CountVectorizer(ngram_range=(1, 1) , stop_words = 'english').fit(x)\n    bow = vec.transform(x)\n    sum_of_words = bow.sum(axis = 0)\n    words_freq = [(words, sum_of_words[0,idx]) for words , idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x : x[1], reverse=True)\n    return words_freq[:n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review_freq = get_top_n_words(df['Review Text'], 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review_freq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting review_freq into **dataframe** for visualization\n\ndf1 = pd.DataFrame(review_freq, columns = ['Unigram', 'Frequency'])\ndf1 = df1.set_index('Unigram')\ndf1.iplot(kind = 'bar' , xTitle = 'Unigram' , yTitle = 'Count', title = 'Top 20 Unigram Words')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Bigram analysis without Stopword"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Actual function \n\ndef get_top_n_words(x, n):\n    vec = CountVectorizer(ngram_range=(2, 2) , stop_words = 'english').fit(x)\n    bow = vec.transform(x)\n    sum_of_words = bow.sum(axis = 0)\n    words_freq = [(words, sum_of_words[0,idx]) for words , idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x : x[1], reverse=True)\n    return words_freq[:n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review_freq = get_top_n_words(df['Review Text'], 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review_freq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting review_freq into **dataframe** for visualization\n\ndf1 = pd.DataFrame(review_freq, columns = ['Bigram', 'Frequency'])\ndf1 = df1.set_index('Bigram')\ndf1.iplot(kind = 'bar' , xTitle = 'Bigram' , yTitle = 'Count', title = 'Top 20 Bigram Words' ,\n         color = 'lightgreen')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Trigram analysis without Stopword"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Actual function \n\ndef get_top_n_words(x, n):\n    vec = CountVectorizer(ngram_range=(3, 3) , stop_words='english').fit(x)\n    bow = vec.transform(x)\n    sum_of_words = bow.sum(axis = 0)\n    words_freq = [(words, sum_of_words[0,idx]) for words , idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x : x[1], reverse=True)\n    return words_freq[:n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review_freq = get_top_n_words(df['Review Text'], 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"review_freq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting review_freq into **dataframe** for visualization\n\ndf1 = pd.DataFrame(review_freq, columns = ['Trigram', 'Frequency'])\ndf1 = df1.set_index('Trigram')\ndf1.iplot(kind = 'bar' , xTitle = 'Trigram' , yTitle = 'Count', title = 'Top 20 Trigram Words',\n         color = 'lightviolet')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Distribution of Top 20 Parts-of-Speech POS Tags"},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Use **TextBlob** package fot solving tasks such as 'parts of speech tagging', 'noun phrase extraction' ,'sentiment analysis',etc\n\nblob = TextBlob(str(df['Review Text']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"blob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('tagsets')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## This statement is used to provide all tags with their abbrevation\n\nnltk.help.upenn_tagset()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"blob.tags","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Convert blob variable into DataFrame \n## POS - Parts of Speech\n\npos_df = pd.DataFrame(blob.tags , columns = ['Words' , 'POS'])\npos_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## We are calculating total number of occurence of each parts os speech (POS)\n\npos_df = pos_df['POS'].value_counts()\npos_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plotting pos_df value_counts\n\npos_df.iplot(kind = 'bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bivariate Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## We can have clear idea of all numerical datas with each columns\n\nsns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x = 'Division Name' , y = 'Polarity' , data = df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distribution of Sentiment Polarity of Reviews Based on the Recommendation"},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nimport plotly.graph_objects as go","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are going to select table where there is **Recommended IND =1** for recommending the product to others and **Recommended IND =0** for not recommending the product"},{"metadata":{"trusted":true},"cell_type":"code","source":"x1 = df[df['Recommended IND'] == 1]['Polarity']\nx0 = df[df['Recommended IND'] == 0]['Polarity']\nx1,x0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace0 = go.Histogram(x = x0 , name = 'Not Recommended' , opacity = 0.7)\ntrace1 = go.Histogram(x = x1 , name = 'Recommended' , opacity = 0.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [trace0 , trace1]\nlayout = go.Layout(barmode = 'overlay' , title = 'Distribution of Sentiment Polarity of Reviews Based on the Recommendation')\nfig = go.Figure(data = data , layout = layout)\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above Plot we could clearly see that **customers who recommend the product also gives negative review and vice versa**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distribution of Ratings Based on the Recommendation"},{"metadata":{},"cell_type":"markdown","source":"We are going to select table where there is **Recommended IND =1** for recommending the product to others and **Recommended IND =0** for not recommending the product"},{"metadata":{"trusted":true},"cell_type":"code","source":"x1 = df[df['Recommended IND'] == 1]['Rating']\nx0 = df[df['Recommended IND'] == 0]['Rating']\nx1,x0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace0 = go.Histogram(x = x0 , name = 'Not Recommended' , opacity = 0.7)\ntrace1 = go.Histogram(x = x1 , name = 'Recommended' , opacity = 0.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [trace0 , trace1]\nlayout = go.Layout(barmode = 'overlay' , title = 'Distribution of Reviews Rating Based on the Recommendation')\nfig = go.Figure(data = data , layout = layout)\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above Plot we could clearly see that **Rating with 5-stars full 100% recommend products whereas Ratings between (1,2) there no recommendation for products and Rating with 3-stars contains both subset of recommending and not-recommending**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x = 'Polarity' , y = 'review_len' , data = df , kind = 'kde' , color = 'blue')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above plot the **Polarity** is around **0.25** with **review-length** as **500**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x = 'Polarity' , y = 'Age' , data = df , kind = 'kde' , color = 'blue')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above plot the **Polarity** is around **0.25** with **Age** is in between **35 to 40**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}