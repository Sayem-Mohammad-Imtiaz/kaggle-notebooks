{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Natural Language Processing: Yelp Reviews\n\nIn this NLP project, we will be classifying Yelp Reviews into 1 star or 5 star categories based off the text content in the reviews. We will utilize the pipeline methods for more complex tasks.\n\nEach observation in the data set is a review of a particular business by a particular user.\n\nThe \"stars\" column is the number of stars (1 through 5) assigned by the reviewer to the business. (Higher stars is better.) In other words, it is the rating of the business by the person who wrote the review.\n\nThe \"cool\" column is the number of \"cool\" votes this review received from other Yelp users. \n\nAll reviews start with 0 \"cool\" votes, and there is no limit to how many \"cool\" votes a review can receive. In other words, it is a rating of the review itself, not a rating of the business.\n\nThe \"useful\" and \"funny\" columns are similar to the \"cool\" column.","metadata":{}},{"cell_type":"markdown","source":"## Importing libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('white')\n%matplotlib inline\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.feature_extraction.text import  TfidfTransformer\nfrom sklearn.pipeline import Pipeline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data set importing","metadata":{}},{"cell_type":"code","source":"yelp = pd.read_csv('../input/yelp-reviews/yelp.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking the head of the Data Frame:","metadata":{}},{"cell_type":"code","source":"yelp.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking the column info of the Data Frame:","metadata":{}},{"cell_type":"code","source":"yelp.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking the statistical summary of the Data Frame:","metadata":{}},{"cell_type":"code","source":"yelp.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's create a new column called \"text length\":","metadata":{}},{"cell_type":"code","source":"yelp['text length'] = yelp['text'].apply(len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We can use FacetGrid from the seaborn library to create a grid of 5 histograms of text length based off of the star ratings:","metadata":{}},{"cell_type":"code","source":"g = sns.FacetGrid(yelp,col='stars');\ng.map(plt.hist,'text length');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Also, we can create a boxplot of text length for each star category:","metadata":{}},{"cell_type":"code","source":"sns.boxplot(x='stars',y='text length',data=yelp,palette='rainbow');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now, we can create a countplot of the number of occurrences for each type of star rating:","metadata":{}},{"cell_type":"code","source":"sns.countplot(x='stars',data=yelp,palette='rainbow');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We can use groupby to get the mean values of the numerical columns:","metadata":{}},{"cell_type":"code","source":"stars = yelp.groupby('stars').mean()\nstars","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Using the corr() method on that groupby dataframe to determine the correlation between the variables:","metadata":{}},{"cell_type":"code","source":"stars.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Then we can use seaborn to create a heatmap based off that .corr() dataframe:","metadata":{}},{"cell_type":"code","source":"sns.heatmap(stars.corr(),cmap='coolwarm',annot=True);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's move on to the actual classification task. To make things a little easier, let's only grab reviews that were either 1 star or 5 stars:","metadata":{}},{"cell_type":"code","source":"yelp_class = yelp[(yelp.stars==1) | (yelp.stars==5)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's create two objects X and y. X will be the 'text' column of yelp_class and y will be the 'stars' column of yelp_class:","metadata":{}},{"cell_type":"code","source":"X = yelp_class['text']\ny = yelp_class['stars']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We can import CountVectorizer and create a CountVectorizer object:","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now, let's use the fit_transform method on the CountVectorizer object and pass in X (the 'text' column) and also save this result by overwriting X:","metadata":{}},{"cell_type":"code","source":"X = cv.fit_transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Test Split\n\n### Let's split our data into training and testing data.\n\n### Using train_test_split to split up the data, using test_size=0.3 and random_state=101:","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=101)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training a Model\n\n### Let's import MultinomialNB (Naive Bayes), create an instance of the estimator and call it nb:","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nnb = MultinomialNB()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fitting nb using the training data:","metadata":{}},{"cell_type":"code","source":"nb.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predictions and Evaluations\n\n### Using the predict method off of nb to predict labels from X_test:","metadata":{}},{"cell_type":"code","source":"predictions = nb.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's now create a confusion matrix and classification report using these predictions and y_test:","metadata":{}},{"cell_type":"code","source":"print(confusion_matrix(y_test,predictions))\nprint('\\n')\nprint(classification_report(y_test,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We can see that the model fits nicely! Let's see what happens if we try to include TF-IDF to this process using a pipeline.","metadata":{}},{"cell_type":"markdown","source":"# Using Text Processing","metadata":{}},{"cell_type":"markdown","source":"### Let's create a pipeline with the following steps: CountVectorizer(), TfidfTransformer(),MultinomialNB():","metadata":{}},{"cell_type":"code","source":"pipeline = Pipeline([\n    ('bow', CountVectorizer()),  # strings to token integer counts\n    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using the Pipeline\n\n### Time to use the pipeline. Remember this pipeline has all our pre-process steps in it already, meaning we'll need to re-split the original data (Remember that we overwrote X as the CountVectorized version. What we need is just the text.","metadata":{}},{"cell_type":"code","source":"X = yelp_class['text']\ny = yelp_class['stars']\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=101)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's now fit the pipeline to the training data. We can't use the same training data as last time because that data has already been vectorized. We need to pass in just the text and labels:","metadata":{}},{"cell_type":"code","source":"pipeline.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predictions and Evaluation\n\n### Now let's use the pipeline to predict from the X_test and create a classification report and confusion matrix:","metadata":{}},{"cell_type":"code","source":"predictions = pipeline.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_matrix(y_test,predictions))\nprint(classification_report(y_test,predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Looks like Tf-Idf actually made things worse, since the accuracy dropped significantly.","metadata":{}}]}