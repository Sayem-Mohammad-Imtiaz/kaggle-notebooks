{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b635be347963f00f2da66b1db3540b7cece7a9af"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import svm\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/winequality-red.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd272770055bf642d4d9e0a77dc8d509dcf22033"},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ce87d42eb5f989e25e28745a1588bfaa7eb2668"},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"84ca953b91193a065d5bff5354575cad641d9e3d"},"cell_type":"markdown","source":"Scale data for visualization"},{"metadata":{"trusted":true,"_uuid":"7e1b4d78dd4404c3c50ce9eb202886a46d589dce"},"cell_type":"code","source":"scaler = StandardScaler()\nd = scaler.fit_transform(df) \nd = pd.DataFrame(data=d, columns=df.columns)\nprint(scaler.mean_)\n# scaler.transform(d)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b4507854b4b48ee5e5172d068bb8625dbc5eb23"},"cell_type":"markdown","source":"Pair plot of all features"},{"metadata":{"trusted":true,"_uuid":"bfb424b8d92ebfbb42711b0edc03124662c56afa"},"cell_type":"code","source":"sns.pairplot(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4edbad3e94e896bd2ecfe18da35c25509cf40bbf"},"cell_type":"code","source":"# g = sns.PairGrid(d)\n# g.map_diag(plt.hist)\n# g.map_offdiag(plt.scatter);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98880ca621117a1cd6202884a9f62d96ed67fb61"},"cell_type":"markdown","source":"Cluster map of all features"},{"metadata":{"trusted":true,"_uuid":"96e0635eddc4a0b13beb103d669cea563661bbc6"},"cell_type":"code","source":"g = sns.clustermap(d, \n#                    method='average',\n#                    metric='euclidean', \n                   z_score=None, \n                   standard_scale=1, \n                   figsize=None, \n                   row_cluster=True, \n                   col_cluster=True, \n                   row_linkage=None, \n                   col_linkage=None, \n                   row_colors=None, \n                   col_colors=None, \n                   mask=None,\n#                    cmap=\"mako\"\n                   robust=True\n                  )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db044eade77d27df2bdee95cd3a35fa2be227fc7"},"cell_type":"markdown","source":"Cluster map of scaled feature correleation  "},{"metadata":{"trusted":true,"_uuid":"5bc8dc522bc629724b650b1d2f04971242eff1a9"},"cell_type":"code","source":"sns.set(style=\"white\")\nsns.clustermap(d.corr(), \n               pivot_kws=None, \n#                method='average', \n#                metric='euclidean', \n               z_score=None, \n               standard_scale=None,\n               figsize=None,\n               cbar_kws=None, \n               row_cluster=True, \n               col_cluster=True, \n               row_linkage=None, \n               col_linkage=None,\n               row_colors=None, \n               col_colors=None, \n               mask=None,\n               center=0,\n               cmap=\"vlag\",\n               linewidths=.75, \n#                figsize=(13, 13)\n              )\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1963b009ac895997961189266114c9f3a798d712"},"cell_type":"markdown","source":"Heatmap of scaled feature correleation  "},{"metadata":{"trusted":true,"_uuid":"48ed2d85607251b0472e11997b40c0eedaf53a4c"},"cell_type":"code","source":"# Compute the correlation matrix\ncorr = d.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\nsns.set(style=\"white\")\nsns.heatmap(corr,\n         vmin=None,\n         vmax=None,\n         cmap=cmap,\n         center=None,\n         robust=True,\n         annot=True, \n#          fmt='.2g',\n         annot_kws=None, \n#          linewidths=0.5, \n#          linecolor='white',\n         cbar=True,\n         cbar_kws={\"shrink\": .5},\n         cbar_ax=None, \n         square=True, \n         xticklabels='auto',\n         yticklabels='auto', \n         mask=mask, \n         ax=None)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64317f924b699eacd93acfaedfdd023b57406cd4"},"cell_type":"markdown","source":"**Training**"},{"metadata":{"trusted":true,"_uuid":"7959ba228a8143178527289c2a074a98975fe24d"},"cell_type":"code","source":"y = df[\"quality\"]\ndf.drop([\"quality\"], axis=1)\nX = df.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9748a9972a1485c32b8ecfafa3e98108b569806f"},"cell_type":"code","source":"def print_performance(clf):\n    # print(\"*\"*100)\n    # print(\"{}{}{}\".format(\"*\"*40,\"Performance\", \"*\"*40))\n    print(\"{}\".format(\"Performance\"))\n    print(\"*\"*100)\n    print(\"Score            : {}\".format(clf.score(X, y)))\n    print(\"Best Estimator   : {}\".format(clf.best_estimator_))\n    print(\"Best Score       : {}\".format(clf.best_score_))\n    print(\"Best Params      : {}\".format(clf.best_params_))\n    print(\"Best Index       : {}\".format(clf.best_index_))\n    # print(\"Scorer           : {}\".format(clf.scorer_))\n    print(\"Refit Time       : {}\".format(clf.refit_time_))\n    # print(\"CV Results       : {}\".format(clf.cv_results_))\n\n    params = clf.get_params()\n    best_estimator = clf.best_estimator_\n    cv_results = clf.cv_results_\n    \n    return params, best_estimator, cv_results","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"155e0e832fbe27720f711e597038d194bfee9059"},"cell_type":"markdown","source":"Grid search for best estimator and parameters for linear and radial kernel"},{"metadata":{"trusted":true,"_uuid":"150657267c44c950f36ef3f4a1bc740e59289ff3"},"cell_type":"code","source":"# parameters = {'kernel':('linear', 'poly', 'rbf', 'sigmoid', 'precomputed'), \n#               'degree': np.arrange(10),\n#               'C':np.arrange(10)}\n\nparameters = {'kernel':('linear', 'rbf'), \n              'degree': [1, 10],\n              'C': [1, 10]}\n\n# svr = svm.SVR(kernel='rbf',\n#               degree=3, \n#               gamma='auto',\n#               coef0=0.0,\n#               tol=0.001,\n#               C=1.0, \n#               epsilon=0.1,\n#               shrinking=True,\n#               cache_size=200, \n#               verbose=False, \n#               max_iter=-1)\n\n\nsvr = svm.SVR(gamma='auto')\n\nclf = GridSearchCV(estimator=svr, \n                   param_grid=parameters,\n                   scoring=None, \n                   fit_params=None, \n                   n_jobs=None,\n                   iid='warn',\n                   refit=True,\n                   cv=5,\n                   verbose=0,\n                   pre_dispatch='2*n_jobs',\n                   error_score='raise-deprecating',\n                   return_train_score='warn')\n\nclf.fit(X, y)\n \nparams, best_estimator, cv_results = print_performance(clf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6485e49a7ebd27e67c349d7cb79b110e9faad987"},"cell_type":"markdown","source":"Grid search for best estimator and parameters in a range - (1, 10) for linear and radial kernel"},{"metadata":{"trusted":true,"_uuid":"4455a690a1ae78af120d45429f7b3f26882c3c0f"},"cell_type":"code","source":"parameters = {'kernel':('linear', 'rbf'), \n              'degree': np.arange(1, 10),\n              'C': np.arange(1, 10)}\n\n# svr = svm.SVR(kernel='rbf',\n#               degree=3, \n#               gamma='auto',\n#               coef0=0.0,\n#               tol=0.001,\n#               C=1.0, \n#               epsilon=0.1,\n#               shrinking=True,\n#               cache_size=200, \n#               verbose=False, \n#               max_iter=-1)\n\nsvr = svm.SVR(gamma='auto')\n\nclf = GridSearchCV(estimator=svr, \n                   param_grid=parameters,\n                   scoring=None, \n                   fit_params=None, \n                   n_jobs=-1,\n                   iid='warn',\n                   refit=True,\n                   cv=5,\n                   verbose=1,\n                   pre_dispatch='2*n_jobs',\n                   error_score='raise-deprecating',\n                   return_train_score='warn')\n\n\nclf.fit(X, y)\n\nparams, best_estimator, cv_results = print_performance(clf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8799fec09ea8bb1532deb677b83fe78225267f8c"},"cell_type":"markdown","source":"Linear regression has shown much better result"},{"metadata":{"trusted":true,"_uuid":"806ea37f84acadbf76a7634cedcd41ddee26ecc6","_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\nreg = LinearRegression()\n\n# svr = svm.SVR(kernel='linear',\n#               degree=3, \n#               gamma='auto',\n#               coef0=0.0,\n#               tol=0.001,\n#               C=1.0, \n#               epsilon=0.1,\n#               shrinking=True,\n#               cache_size=200, \n#               verbose=False, \n#               max_iter=-1)\n\n# best estimator found using grid search cv\nsvr = svm.SVR(C=1, cache_size=200, coef0=0.0, degree=1, epsilon=0.1, gamma='auto',\n  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n\n# clf = svr\nclf = reg\n\nprint(\"Cross Val Score            : {}\".format(cross_val_score(clf, X, y, cv=5)))\n\nclf.fit(X_train, y_train)\nprint(\"Score (training data only) : {}\".format(clf.score(X_train, y_train)))\n\ny_pred = clf.predict(X_test)\nprint(\"Mean Squared Error         : {}\".format(mean_squared_error(y_test, y_pred)))\n      ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29032ff0a8e73413ec3a7fbf3a778447093d99a9"},"cell_type":"markdown","source":"Plot of difference between actual value and predicted value without scaling"},{"metadata":{"trusted":true,"_uuid":"0b93cb61038d86a785ca6fe0fdad9a9df8c93e36"},"cell_type":"code","source":"x = np.arange(len(y_pred))\nplt.plot(x, y_test-y_pred)\nplt.title(\"Prediction Difference (le-14)\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}