{"cells":[{"metadata":{"trusted":false,"_uuid":"54d131a64010bc97210ec3def45f461de8406e83"},"cell_type":"code","source":"\n#### Importing Libraries ####\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sn\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f4777a3eebd31c6d9da3299133ac7e465250fdc6"},"cell_type":"code","source":"### Data Preprocessing ###\n\ndataset = pd.read_csv('../input/financial_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5fd4f9042f7d74648937e28ac339fd82f1dd2b33"},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d4e661f391a391e8df7d2e636fabbb3ab037630f"},"cell_type":"code","source":"# Feature Engineering\n\ndataset = dataset.drop(columns = ['months_employed'])\ndataset['personal_account_months'] = (dataset.personal_account_m + (dataset.personal_account_y * 12))\ndataset[['personal_account_m', 'personal_account_y', 'personal_account_months']].head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2d2623929d3fa3e89f7155ce475e6e18d95b55f1"},"cell_type":"code","source":"dataset = dataset.drop(columns = ['personal_account_m', 'personal_account_y'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"623229e2a26cf30039a345a7db494a00d43abad3"},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ce2fc36666fae1cefb6016d7a07a6ef8671ee864"},"cell_type":"code","source":"# One Hot Encoding\ndataset = pd.get_dummies(dataset)\ndataset.columns\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"457ee61ec5082809e327d8d26266324ff91e25b1"},"cell_type":"code","source":"dataset = dataset.drop(columns = ['pay_schedule_semi-monthly'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e647a28735c9ebb6e09867506cc5525b2bf07140"},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e81f880fe144b6719ec1a49f6c8c71a62fddb9fc"},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e1bb5e3ab47ba901929151c8facc4836351e7acf"},"cell_type":"code","source":"# Removing extra columns\nresponse = dataset[\"e_signed\"]\nusers = dataset['entry_id']\ndataset = dataset.drop(columns = [\"e_signed\", \"entry_id\"])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a2d5abe12a647518b8af1cdc0232a6bf2b4b5e33"},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"252372228c851a2f8798c0da170ea1075f355034"},"cell_type":"code","source":"# Splitting into Train and Test Set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(dataset,\n                                                    response,\n                                                    test_size = 0.2,\n                                                    random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"568ec8984ea55a6806097e7be36514031e8085b3"},"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_X= StandardScaler()\nX_train2 = pd.DataFrame(sc_X.fit_transform(X_train))\nX_test2 = pd.DataFrame(sc_X.transform(X_test))\nX_train2.columns = X_train.columns.values\nX_test2.columns = X_test.columns.values\nX_train2.index = X_train.index.values\nX_test2.index = X_test.index.values\nX_train = X_train2\nX_test = X_test2","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a7312e80786c32241f0d1febc6d59476d3c0bd24"},"cell_type":"code","source":"# Part 2 - Now let's make the ANN!\n\n# Importing the Keras libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n# Initialising the ANN\nclassifier = Sequential()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e25f679d0603d9f9facbd1c9e9c3ad5b2ad6f592"},"cell_type":"code","source":"# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'relu', input_dim = 19))\n\n# Adding the second hidden layer\nclassifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'relu'))\n\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3956cff92fe33cc50a4ef6d9102f900724f3b907"},"cell_type":"code","source":"# Fitting the ANN to the Training set\nclassifier.fit(X_train, y_train, batch_size = 10, epochs = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b1ba913d18721068f90f7c5430d2cc7af64830f2"},"cell_type":"code","source":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"76389e437807d09c0227093c657176daa32b0586"},"cell_type":"code","source":"## EXTRA: Confusion Matrix\nfrom sklearn.metrics import confusion_matrix,accuracy_score\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\nplt.figure(figsize = (10,7))\nsn.set(font_scale=1.4)\nsn.heatmap(df_cm, annot=True, fmt='g')\nprint(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f34e4ea82e67c99dec4048147fc29915bd00c54d"},"cell_type":"code","source":"#Let's see how our model performed\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9c8996e114db7c622d44b1a3d59399ca5c83cfa0"},"cell_type":"code","source":"# Formatting Final Results\n\nfinal_results = pd.concat([y_test, users], axis = 1).dropna()\nfinal_results['predictions'] = y_pred\nfinal_results = final_results[['entry_id', 'e_signed', 'predictions']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f0bdf4ecc102bf73b8a705d6d76cf35cda7715ec"},"cell_type":"code","source":"final_results.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f7507adeaa39ca3f419ebcd70f301c0d09b27b63"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":1}