{"cells":[{"metadata":{},"cell_type":"markdown","source":"- **Business understanding**\n\nBuild a Machine Learning template to determine if an employee will stay or leave the company. We’re dealing with a classification issue. We will use two of the most used algorithms to solve this problem: Neural Network and Logistic Regression.\n\n**Turnover** designates in an enterprise the renewal of the workforce, following recruitment and departures of the staff. It is a valuable indicator which can quite easily reflect the work environment within the company. Machine Learning can help to analyze and predict this rate and thus make the Right decisions."},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing the algorithme library\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\n\n#The others library\nfrom  sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn import model_selection\n\n#this library import all library like pandas, numpy, matplotlib,seaborn.\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\n#Evaluate our algorithme\nfrom sklearn.metrics import roc_auc_score, roc_curve, accuracy_score,confusion_matrix,classification_report","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/ibm-attrition-analysis/WA_Fn-UseC_-HR-Employee-Attrition.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list of numeric variable\nnum_vars = [var for var in data.columns if data[var].dtypes != 'O']\n\nprint('Number of variable numeric: ', len(num_vars))\n\n# show\ndata[num_vars].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# list of categorical variable\ncat_vars = [var for var in data.columns if data[var].dtypes == 'O']\n\nprint('Number of variable categoric: ', len(cat_vars))\n\n# show\ndata[cat_vars].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#display each values for each variable\nfor var in cat_vars:\n    print(var, len(data[var].unique()), ' categories')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Age\"].mode()\ndata[\"Age\"].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculate the %(move) and %(stay) in Dataset\nmove = data[data['Attrition'] == \"Yes\"]\nstay = data[data['Attrition'] == \"No\"]\nprint(\"moves: %i (%.1f%%)\" %(len(move),(len(move)) / len(data)*100))\nprint(\"stay: %i (%.1f%%)\" %(len(stay),(len(stay)) / len(data)*100))\nprint(\"Total: %i\" %len(data))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The enterprise recorded only 237 departures either **16.1%** against 1233 or **(83.9%)** out of a total of 1470. For the modelling of our model we can say gold and already that the dataset is unbalanced. In the following sections, if necessary, we will use the **smote()** technique to balance the dataset in order to make it efficient in order to have a better **accuracy**."},{"metadata":{},"cell_type":"markdown","source":"- **Data Viz**\n\nAs a Data Scientist, your job is not only to interpret and analyze the data, but also to communicate and present your findings. That’s why it’s very important for you to have those skills."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Viz\nimport matplotlib.ticker as mtick\nax = (data['Attrition'].value_counts()*100.0 /len(data))\\\n.plot.pie(autopct='%.1f%%', labels = ['Stay', 'Move'],figsize =(5,5), fontsize = 12 )                                                                           \nax.yaxis.set_major_formatter(mtick.PercentFormatter())\nax.set_ylabel('Attrition',fontsize = 12)\nax.set_title('% Statistique RH', fontsize = 12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let’s create some interesting viz on the impact of attritions compared to other variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(data[\"Department\"],data[\"Attrition\"]).plot(kind='bar')\nplt.title('Attrition par Departement')\nplt.xlabel('Department')\nplt.ylabel('Fréquence')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We note more departures in the RD department. This can be explained in the extent that half of the employees are in this department."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Department\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"table=pd.crosstab(data[\"EducationField\"], data[\"Attrition\"])\ntable.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\nplt.title(\"Attrition en fonction de l'education\")\nplt.xlabel('Education')\nplt.ylabel('Proportion Employé')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- **Data Processing**\n\n\nAn important part of data science is the manual collection and cleaning of data. This process is also known as Data Wrangling Although exciting it is very important to know that it is a tedious task that can take up 80% of the work of a Data Scientist."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Identified the nan values\ndata_nan = pd.isnull(data).sum()\ndata_nan","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our dataset is clean. Actually I didn’t expect it. In the real world you probably won’t have data that clean.\n\nThank you IBM!!!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"#find the outliers\ndef find_outliers(df, var):\n    df = df.copy()\n    \n    if 0 in data[var].unique():\n        pass\n    else:\n        df[var] = np.log(df[var])\n        df.boxplot(column=var)\n        plt.title(var)\n        plt.ylabel(var)\n        plt.show()\n    \nfor var in num_vars:\n    find_outliers(data, var)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some variables have extremes. This is the case of Dailyrate, Employeenumber. However, it is important to know that the management of its outliers requires an understanding of the business and this is often subjective. From my little experience, I always left its values because they did not interfere with the performance of my models all the more if we make the scaling up In our case, we decide to keep them in our model."},{"metadata":{},"cell_type":"markdown","source":"- **Transforming the data in the right format**\n\nWe use LabelEncoder technique"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nlb = LabelEncoder() \ndata['Attrition'] = lb.fit_transform(data['Attrition'])\ndata['BusinessTravel'] = lb.fit_transform(data['BusinessTravel'])\ndata['Department'] = lb.fit_transform(data['Department'])\ndata['EducationField'] = lb.fit_transform(data['EducationField'])\ndata['Gender'] = lb.fit_transform(data['Gender'])\ndata['JobRole'] = lb.fit_transform(data['JobRole'])\ndata['MaritalStatus'] = lb.fit_transform(data['MaritalStatus'])\ndata['Over18'] = lb.fit_transform(data['Over18'])\ndata['OverTime'] = lb.fit_transform(data['OverTime'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"it is good, all my categorical variables are transforming in numerical type"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop([\"Attrition\"], axis = 1)\ny = data[\"Attrition\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#function for normalizing our data\n\ndef normalisation(train_df, test_df):\n    from sklearn.preprocessing import StandardScaler\n    sc_X = StandardScaler()\n    train_df = sc_X.fit_transform(train_df)\n    test_df =  sc_X.transform(test_df)\n    return train_df, test_df\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Machine Learning\n\nIn this section, we will create our **ML models** and also **evaluate them**. \n\nlet’s go"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split our dataset in train ans test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalize\nX_train, X_test = normalisation(X_train, X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclassifier_log =  LogisticRegression(solver='liblinear', C = 0.38, max_iter = 200, random_state = 0)\nclassifier_log.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#prédict on test set\ny_pred_log = classifier_log.predict(X_test)\ny_pred_proba = classifier_log.predict_proba(X_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#score\naccurancy_log = round(classifier_log.score(X_test, y_test) * 100)\nprint(str(accurancy_log )+ ' %')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It’s just amazing. The model has an accuracy of **89%**. \n\nHowever, you can always compare the score of the train and the test in order to check if there is not a big gap. I also advise you to explore the cross_val_score method."},{"metadata":{},"cell_type":"markdown","source":"- Evaluate LR"},{"metadata":{"trusted":true},"cell_type":"code","source":"#matrixof confusion\ncm_log = confusion_matrix(y_test, y_pred_log)\nsns.heatmap(cm_log, annot=True,fmt='3.0f',cmap=\"cubehelix\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model was wrong on 33 employees. In fact, we call data science the **False Positive**. Nevertheless, 313 employees will remain (**True positive**)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Classification Report\nprint(classification_report(y_test,y_pred_log))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ROC AUC\nprobs = classifier_log.predict_proba(X_test)\nprobs = probs[:, 1]\n\nauc_log = roc_auc_score(y_test, probs)\nprint('AUC - Test Set: %.2f%%' % (auc_log*100))\n\n# calculons roc curve\nfpr, tpr, thresholds = roc_curve(y_test, probs)\n\nplt.plot([0, 1], [0, 1], linestyle='--')\n# plot the roc curve for the model\nplt.plot(fpr, tpr, marker='.')\n# show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Having an **AUC of 78.24%** is not bad at all content of dataset size."},{"metadata":{},"cell_type":"markdown","source":"- Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nmlp = MLPClassifier(hidden_layer_sizes=(14,14,14), activation='relu', solver='adam', max_iter=100)\nmlp.fit(X_train,y_train)\ny_pred_mlp = mlp.predict(X_test)\ny_proba_mlp = mlp.predict_proba(X_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accurancy_neural = round(mlp.score(X_test, y_test) * 100, 2)\nprint(str(accurancy_neural) + ' %')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Evaluate Neural Network\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm_mlp = confusion_matrix(y_test, y_pred_mlp)\nimport seaborn as sns\nsns.heatmap(cm_mlp, annot=True,fmt='3.0f',cmap=\"cubehelix\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is clear that neural networks are able to better predict the employees who will leave 18 (True Negative) contrary to logistic regression . In fact, he was wrong only about 30 employees.\n\nHowever, is this the model to remember?"},{"metadata":{"trusted":true},"cell_type":"code","source":"#classification report\nprint(classification_report(y_test,y_pred_mlp))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ROC AUC\nprobs = mlp.predict_proba(X_test)\nprobs = probs[:, 1]\nauc_mlp = roc_auc_score(y_test, probs)\nprint('AUC - Test Set: %.2f%%' % (auc_mlp*100))\n\n\nfpr, tpr, thresholds = roc_curve(y_test, probs)\nplt.plot([0, 1], [0, 1], linestyle='--')\n\nplt.plot(fpr, tpr, marker='.')\n# show the plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Resume"},{"metadata":{"trusted":true},"cell_type":"code","source":"Result = pd.DataFrame({\n    'Model': ['Logistic Regression','Neural Network', ],\n      'Score': [accurancy_log,accurancy_neural]})\nResult.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Compare our predictions and real values\nResult_logistic = pd.DataFrame({\n        \"True data\": y_test,\n        \"Predict data\": y_pred_log,\n        \"Proba data\":y_pred_proba\n    })\n#Result_logistic.head(40)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Conclusion\n\nIn view of our results we can think that logistic regression is the best model. However, I would ask you to analyze in depth in order to identify the best model in particular by making a comparison of all metrics (Matrix confusion, ROC curve and classification_rapport.\n\nAs for me, I do not want to give my point of view. I am open to your suggestions, contributions and advice and thank you for reading me to the end.\nAIDARA Chamsedine\n\nStudent in MBA 2 Big Data\n\nData scientist at Expresso Senegal(Telco Company)\n\naidarachamsedine10@gmail.com"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}