{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NOTES:\n* Change VOCAB_TYPE for specific experiment\n* DATASET_DIST: select specific dataset for the experiment\n\n```\nsynth: synthetic data only \nbs   : boise_state data only\nbw   : bangla writing data only\nbh   : BN-HTR data only\nall  : NOT FOR Research/Paper Case\n```\n* MODEL_NAME: The specific model to use\n* USE_PRETRAINED : use pretrained model with synthetic data \n* EARLY_STOP  :   Stop the training early\n# TODO:\n- [x] add synthetic weights auto-loading for experiments\n- [ ] add HTR models\n    - [ ] Bluche\n    - [ ] flor\n    - [ ] Puigcerver\n    - [ ] Puigcerver_octconv\n    - [x] vgg_crnn\n- [ ] CER might need double checking","metadata":{}},{"cell_type":"code","source":"#------------------------------------\n# variables to consider\n#------------------------------------\nEPOCHS       = 30\nVOCAB_TYPE   =\"unicode\" # @param[\"grapheme\",\"unicode\"]\nDATASET_DIST =\"bw\" # @param[\"synth\",\"bs\",\"bw\",\"bh\",\"all\"] \nMODEL_NAME   =\"dense_crnn\" # param [dense_crnn,vgg_crnn] \nUSE_PRETRAINED   =True\nEARLY_STOP       =True","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:51:54.341474Z","iopub.execute_input":"2021-08-26T08:51:54.34193Z","iopub.status.idle":"2021-08-26T08:51:54.353579Z","shell.execute_reply.started":"2021-08-26T08:51:54.341867Z","shell.execute_reply":"2021-08-26T08:51:54.352623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-------------------\n# fixed params\n#------------------\nimg_height  =  64\nimg_width   =  512\nnb_channels =  3\n        \n#----------------\n# imports\n#---------------\nimport tensorflow as tf\nimport random\nimport json\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ast import literal_eval\nfrom kaggle_datasets import KaggleDatasets\nfrom glob import glob\nimport cv2\nfrom itertools import groupby\n%matplotlib inline\n#-------------\n# reproduceable \n#-------------\n\nseed_value=42\nos.environ['PYTHONHASHSEED']=str(seed_value)\nrandom.seed(seed_value)\nnp.random.seed(seed_value)\ntf.random.set_seed(seed_value)\n#-------------\n# config-globals\n#-------------\nwith open('../input/pgvu-crnn-ctc-tfrecords/vocab.json') as f:\n    vocab = json.load(f)\n    \ngvocab=vocab[\"gvocab\"]\ncvocab=vocab[\"cvocab\"]\n    \nif VOCAB_TYPE==\"unicode\":\n    vocab     =cvocab\n    pos_max   =20\n    LSTM_UNIT =128\n    POOL_LEVEL=3\nelse:\n    vocab  =gvocab\n    pos_max=10\n    LSTM_UNIT =1024\n    POOL_LEVEL=4\n    \nprint(\"Vocab len:\",len(vocab))\nprint(\"Label len:\",pos_max)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:51:54.358844Z","iopub.execute_input":"2021-08-26T08:51:54.35921Z","iopub.status.idle":"2021-08-26T08:51:59.258905Z","shell.execute_reply.started":"2021-08-26T08:51:54.359176Z","shell.execute_reply":"2021-08-26T08:51:59.257833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#----------------------------------------------------------\n# Detect hardware, return appropriate distribution strategy\n#----------------------------------------------------------\n# TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    tf.config.optimizer.set_jit(True)\n    print('Accelerated Linear Algebra enabled')\nelse:\n    strategy = tf.distribute.get_strategy() \n    # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:51:59.26136Z","iopub.execute_input":"2021-08-26T08:51:59.261841Z","iopub.status.idle":"2021-08-26T08:52:04.768Z","shell.execute_reply.started":"2021-08-26T08:51:59.261789Z","shell.execute_reply":"2021-08-26T08:52:04.766837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#--------------------------\n# GCS Paths and tfrecords\n#-------------------------\ndef get_tfrecs(_path):\n    gcs_pattern=os.path.join(_path,'*.tfrecord')\n    file_paths = tf.io.gfile.glob(gcs_pattern)\n    random.shuffle(file_paths)\n    return file_paths\n    \n\nGCS_PATH= KaggleDatasets().get_gcs_path('pgvu-crnn-ctc-tfrecords')+\"/crnn/tfrecords/\"\n\n#---------------------------------\n# dataset\n#---------------------------------\ngpbw_train=GCS_PATH+\"bw.train/\"\ngpbw_eval =GCS_PATH+\"bw.test/\"\n\ngpbh_train=GCS_PATH+\"bh.train/\"\ngpbh_eval =GCS_PATH+\"bh.test/\"\n\ngpbs_train=GCS_PATH+\"bs.train/\"\ngpbs_eval =GCS_PATH+\"bs.test/\"\ngpbn_synth=GCS_PATH+\"synth/\"\n\nbw_train_recs  =get_tfrecs(gpbw_train)\nbw_eval_recs   =get_tfrecs(gpbw_eval)\nbh_train_recs  =get_tfrecs(gpbh_train)\nbh_eval_recs   =get_tfrecs(gpbh_eval)\nbs_train_recs  =get_tfrecs(gpbs_train)\nbs_eval_recs   =get_tfrecs(gpbs_eval)\nbn_synth_recs  =get_tfrecs(gpbn_synth)\nprint(\"Synthetic Data:\",len(bn_synth_recs)*1024)\nprint(\"Bangla Writing Train Data:\",len(bw_train_recs)*1024)\nprint(\"Bangla Writing Eval Data:\",len(bw_eval_recs)*1024)\nprint(\"Boise State Train Data:\",len(bs_train_recs)*1024)\nprint(\"Boise State Eval Data:\",len(bs_eval_recs)*1024)\nprint(\"BN-HTR Train Data:\",len(bh_train_recs)*1024)\nprint(\"BN-HTR Eval Data:\",len(bh_eval_recs)*1024)\n\n#-------------\n# train-eval split\n#-------------\nprint(\"---------------------------------------------------------------\")\nprint(\"section:train-eval split\")\nprint(\"---------------------------------------------------------------\")\nif DATASET_DIST==\"synth\":\n    eval_recs=bn_synth_recs[:2]\n    train_recs=bn_synth_recs[2:]\nelif DATASET_DIST==\"bw\":\n    train_recs=bw_train_recs\n    eval_recs =bw_eval_recs\nelif DATASET_DIST==\"bs\":\n    train_recs=bs_train_recs\n    eval_recs =bs_eval_recs\nelif DATASET_DIST==\"bh\":\n    train_recs=bh_train_recs\n    eval_recs =bh_eval_recs\n\n\n# numbers\nnb_train  =int(len(train_recs)*1024)\nnb_eval   =int(len(eval_recs)*1024)\nprint(\"Train Data:\",nb_train,len(train_recs))\nprint(\"Eval Data:\",nb_eval,len(eval_recs))","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:52:04.769248Z","iopub.execute_input":"2021-08-26T08:52:04.769521Z","iopub.status.idle":"2021-08-26T08:52:05.677024Z","shell.execute_reply.started":"2021-08-26T08:52:04.769494Z","shell.execute_reply":"2021-08-26T08:52:05.675945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-------------------------------------\n# batching , strategy and steps\n#-------------------------------------\nif strategy.num_replicas_in_sync==1:\n    BATCH_SIZE = 32\nelse:\n    BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\n# set    \nTOTAL_DATA      = nb_train+nb_eval\nSTEPS_PER_EPOCH = TOTAL_DATA//BATCH_SIZE\nEVAL_STEPS      = (nb_eval)//BATCH_SIZE\nprint(\"Steps:\",STEPS_PER_EPOCH)\nprint(\"Batch Size:\",BATCH_SIZE)\nprint(\"Eval Steps:\",EVAL_STEPS)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:52:05.678755Z","iopub.execute_input":"2021-08-26T08:52:05.679221Z","iopub.status.idle":"2021-08-26T08:52:05.687427Z","shell.execute_reply.started":"2021-08-26T08:52:05.679169Z","shell.execute_reply":"2021-08-26T08:52:05.686315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#------------------------------\n# parsing tfrecords basic\n#------------------------------\ndef data_input_fn(recs): \n    '''\n      This Function generates data from gcs\n      * The parser function should look similiar now because of datasetEDA\n    '''\n    def _parser(example):   \n        feature ={  'image'  : tf.io.FixedLenFeature([],tf.string) ,\n                    'clabel'  : tf.io.FixedLenFeature([20],tf.int64),\n                    'glabel'  : tf.io.FixedLenFeature([10],tf.int64),\n        }    \n        parsed_example=tf.io.parse_single_example(example,feature)\n        # image\n        image_raw=parsed_example['image']\n        image=tf.image.decode_png(image_raw,channels=nb_channels)\n        image=tf.cast(image,tf.float32)/255.0\n        image=tf.reshape(image,(img_height,img_width,nb_channels))\n        #image=tf.image.resize(image, [img_height//2,img_width//2])\n        \n        # label\n        if VOCAB_TYPE==\"unicode\":\n            label=parsed_example['clabel']\n        else:\n            label=parsed_example['glabel']\n        label=tf.cast(label, tf.float32)    \n        \n        return image,label\n    \n      \n\n    # fixed code (for almost all tfrec training)\n    dataset = tf.data.TFRecordDataset(recs)\n    dataset = dataset.map(_parser)\n    dataset = dataset.shuffle(2048,reshuffle_each_iteration=True)\n    dataset = dataset.repeat()\n    dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n    return dataset\n\ntrain_ds  =   data_input_fn(train_recs)\neval_ds  =   data_input_fn(eval_recs)\n\n\n\n#------------------------\n# visualizing data\n#------------------------\n\n\nfor x,y in train_ds.take(1):\n    data=np.squeeze(x[0])\n    plt.imshow(data)\n    plt.show()\n    print(\"---------------------------------------------------------------\")\n    print(\"label:\",y[0])\n    print(\"---------------------------------------------------------------\")\n    print('Image Batch Shape:',x.shape)\n    print(\"---------------------------------------------------------------\")\n    print('Target Batch Shape:',y.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:52:05.689339Z","iopub.execute_input":"2021-08-26T08:52:05.689812Z","iopub.status.idle":"2021-08-26T08:52:06.97353Z","shell.execute_reply.started":"2021-08-26T08:52:05.689764Z","shell.execute_reply":"2021-08-26T08:52:06.972244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{"papermill":{"duration":0.011211,"end_time":"2021-07-10T04:37:08.885329","exception":false,"start_time":"2021-07-10T04:37:08.874118","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# #-----------------------\n# # CTC\n# #-----------------------\nimport tensorflow as tf\nfrom tensorflow import keras\n\n\nclass CTCLoss(keras.losses.Loss):\n    \"\"\" A class that wraps the function of tf.nn.ctc_loss. \n    \n    Attributes:\n        logits_time_major: If False (default) , shape is [batch, time, logits], \n            If True, logits is shaped [time, batch, logits]. \n        blank_index: Set the class index to use for the blank label. default is\n            -1 (num_classes - 1). \n    \"\"\"\n\n    def __init__(self, logits_time_major=False, name='ctc_loss'):\n        super().__init__(name=name)\n        self.logits_time_major = logits_time_major\n\n    def call(self, y_true, y_pred):\n        \"\"\" \n            Computes CTC (Connectionist Temporal Classification) loss. \n        \"\"\"\n        y_true = tf.cast(y_true, tf.int32)\n        logit_length = tf.fill([tf.shape(y_pred)[0]], tf.shape(y_pred)[1])\n        label_length = tf.fill([tf.shape(y_true)[0]], tf.shape(y_true)[1])\n        loss = tf.nn.ctc_loss(\n            labels=y_true,\n            logits=y_pred,\n            label_length=label_length,\n            logit_length=logit_length,\n            logits_time_major=self.logits_time_major,\n            blank_index=0)\n        return tf.math.reduce_mean(loss)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:52:06.977044Z","iopub.execute_input":"2021-08-26T08:52:06.977395Z","iopub.status.idle":"2021-08-26T08:52:06.987443Z","shell.execute_reply.started":"2021-08-26T08:52:06.977359Z","shell.execute_reply":"2021-08-26T08:52:06.986278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\ndef densenet_style(x):\n    feat=tf.keras.applications.DenseNet121(input_tensor=x,weights=None,include_top=False)\n    x=feat.get_layer(name=f\"pool{POOL_LEVEL}_conv\").output\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    return x\n\ndef vgg_style(x):\n    \"\"\"\n    The original feature extraction structure from CRNN paper.\n    Related paper: https://ieeexplore.ieee.org/abstract/document/7801919\n    \"\"\"\n    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n    x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n    x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n    x = layers.MaxPool2D(pool_size=(2,2))(x)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n    x = layers.Conv2D(256, 3, padding='same',activation='relu')(x)\n    x = layers.MaxPool2D(pool_size=(2,2))(x)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.Conv2D(512, 3, padding='same', activation='relu')(x)\n    x = layers.Conv2D(512, 3, padding='same',activation='relu')(x)\n    x = layers.MaxPool2D(pool_size=(2,2))(x)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.Conv2D(512, 3, padding='same', activation='relu')(x)\n    x = layers.Conv2D(512, 3, padding='same',activation='relu')(x)\n    if VOCAB_TYPE ==\"grapheme\":\n        x = layers.MaxPool2D(pool_size=(2,2))(x)\n    x = layers.BatchNormalization()(x)\n    \n    if VOCAB_TYPE ==\"grapheme\":\n        x = layers.Conv2D(512, 3, padding='same', activation='relu')(x)\n        x = layers.Conv2D(512, 3, padding='same',activation='relu')(x)\n        x = layers.BatchNormalization()(x)\n\n    return x\n\ndef build_model(feat_extractor,inp,model_name):\n    x = tf.keras.layers.Permute((2, 1, 3))(inp)\n    x=feat_extractor(x)\n    # reshape\n    bs,d1,d2,d3=x.shape\n    reshape_dim=(d1,int(d2*d3))\n    x = tf.keras.layers.Reshape(reshape_dim)(x) \n    # bi-lstm\n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=LSTM_UNIT, return_sequences=True), name='bi_lstm1')(x)\n    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=LSTM_UNIT, return_sequences=True), name='bi_lstm2')(x)\n    # logits\n    logits = layers.Dense(units=len(vocab), name='logits')(x)\n    \n    model= tf.keras.Model(inputs=inp, outputs=logits, name=model_name)\n    return model\n\n\n\n# # permute\n# x = keras.layers.Permute((2, 1, 3))(inp)\n\ndef get_model(model_name):\n    if model_name==\"dense_crnn\":\n        inp=tf.keras.layers.Input(shape=(img_height,img_width,nb_channels))\n        model=build_model(densenet_style,inp,model_name)\n        \n    else:\n        inp=tf.keras.layers.Input(shape=(img_height,img_width,nb_channels))\n        model=build_model(vgg_style,inp,model_name)\n    if USE_PRETRAINED:\n        print(\"loading synthetic weights\")\n        model.load_weights(f\"../input/pgvu-weights-and-histories/{MODEL_NAME}_{VOCAB_TYPE}_synth.h5\")\n    return model","metadata":{"papermill":{"duration":0.021578,"end_time":"2021-07-10T04:37:08.918623","exception":false,"start_time":"2021-07-10T04:37:08.897045","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-26T08:52:06.991342Z","iopub.execute_input":"2021-08-26T08:52:06.991831Z","iopub.status.idle":"2021-08-26T08:52:07.016735Z","shell.execute_reply.started":"2021-08-26T08:52:06.99178Z","shell.execute_reply":"2021-08-26T08:52:07.015253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=get_model(MODEL_NAME)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:52:07.019136Z","iopub.execute_input":"2021-08-26T08:52:07.019493Z","iopub.status.idle":"2021-08-26T08:52:13.08284Z","shell.execute_reply.started":"2021-08-26T08:52:07.01945Z","shell.execute_reply":"2021-08-26T08:52:13.077049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#---------------\n# callbacks\n#---------------\n# weight file path\nweight_path=f\"{MODEL_NAME}_{VOCAB_TYPE}_{DATASET_DIST}.h5\"\n\n# reduces learning rate on plateau\nlr_reducer = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1,\n                                                  cooldown= 10,\n                                                  patience=10,\n                                                  verbose =1,\n                                                  min_lr=0.1e-7)\n# saves the model\nmodel_autosave = tf.keras.callbacks.ModelCheckpoint(filepath=weight_path, \n                                                   monitor='val_loss', \n                                                   verbose=1, \n                                                   save_best_only=True, \n                                                   mode='min')\n\n# early stopping\nearly_stopping = tf.keras.callbacks.EarlyStopping(patience=30, \n                                                  verbose=1, \n                                                  mode = 'auto') \ncallbacks= [model_autosave,lr_reducer]\nif EARLY_STOP:\n    print(\"Early Stopping Enabled\")\n    callbacks+=[early_stopping]","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:52:13.084703Z","iopub.execute_input":"2021-08-26T08:52:13.085152Z","iopub.status.idle":"2021-08-26T08:52:13.093624Z","shell.execute_reply.started":"2021-08-26T08:52:13.085093Z","shell.execute_reply":"2021-08-26T08:52:13.092727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    # optimizer\n    optimizer = tf.keras.optimizers.Adam(lr=0.00001)\n    model=get_model(MODEL_NAME)\n    # compile\n    model.compile(optimizer=optimizer,loss=CTCLoss())","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:52:13.094621Z","iopub.execute_input":"2021-08-26T08:52:13.095011Z","iopub.status.idle":"2021-08-26T08:52:33.420324Z","shell.execute_reply.started":"2021-08-26T08:52:13.094866Z","shell.execute_reply":"2021-08-26T08:52:33.419105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_ds,\n                    epochs=EPOCHS,\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    verbose=1, \n                    validation_data=eval_ds,\n                    validation_steps=EVAL_STEPS, \n                    callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:52:33.421958Z","iopub.execute_input":"2021-08-26T08:52:33.422287Z","iopub.status.idle":"2021-08-26T08:59:30.765187Z","shell.execute_reply.started":"2021-08-26T08:52:33.422257Z","shell.execute_reply":"2021-08-26T08:59:30.763765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ncurves={}\nfor key in history.history.keys():\n    curves[key]=history.history[key]\ncurves=pd.DataFrame(curves)\ncurves.to_csv(f\"{MODEL_NAME}_{VOCAB_TYPE}_{DATASET_DIST}.csv\",index=False)\n\n","metadata":{"papermill":{"duration":0.0206,"end_time":"2021-07-10T04:37:08.950989","exception":false,"start_time":"2021-07-10T04:37:08.930389","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-26T08:59:30.767054Z","iopub.execute_input":"2021-08-26T08:59:30.767453Z","iopub.status.idle":"2021-08-26T08:59:30.77949Z","shell.execute_reply.started":"2021-08-26T08:59:30.767412Z","shell.execute_reply":"2021-08-26T08:59:30.778281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(f\"{MODEL_NAME}_{VOCAB_TYPE}_{DATASET_DIST}.csv\")","metadata":{"papermill":{"duration":35.68876,"end_time":"2021-07-10T07:02:59.123681","exception":false,"start_time":"2021-07-10T07:02:23.434921","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-08-26T08:59:30.780868Z","iopub.execute_input":"2021-08-26T08:59:30.781164Z","iopub.status.idle":"2021-08-26T08:59:30.79417Z","shell.execute_reply.started":"2021-08-26T08:59:30.781136Z","shell.execute_reply":"2021-08-26T08:59:30.793034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(weight_path)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:59:30.796182Z","iopub.execute_input":"2021-08-26T08:59:30.797004Z","iopub.status.idle":"2021-08-26T08:59:30.809041Z","shell.execute_reply.started":"2021-08-26T08:59:30.796953Z","shell.execute_reply":"2021-08-26T08:59:30.808035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom tqdm.auto import tqdm\ntqdm.pandas()\n\n#-----------------------------------------------\n# eval params\n#-----------------------------------------------\neval_dir=\"../input/pgvu-eval-dataset/crnn/crnn/\"\neval_batch_size=128\neval_dfs=[]\n#-----------------------------------------------\n# eval functions\n#-----------------------------------------------\ndef process_batch_images(bdf):\n    images=[]\n    for i in range(len(bdf)):\n        img=cv2.imread(bdf.iloc[i,0])\n        img=np.expand_dims(img,axis=0)\n        images.append(img)\n    data=np.vstack(images)\n    data=data/255.0\n    return data\n#-----------------------------------------------\n# decoding\n#-----------------------------------------------\ndef ctc_decoder(predictions,vocab):\n    '''\n    input: given batch of predictions from text rec model\n    output: return lists of raw extracted text\n\n    '''\n    text_list = []\n    pred_vocab= []\n    pred_indcies = np.argmax(predictions, axis=2)\n    \n    for i in range(pred_indcies.shape[0]):\n        ans = \"\"\n        _vocab=[]\n        ## merge repeats\n        merged_list = [k for k,_ in groupby(pred_indcies[i])]\n        \n        ## remove blanks\n        for p in merged_list:\n            if p != len(vocab):\n                ans += vocab[int(p)]\n                _vocab.append(vocab[int(p)])\n     \n        text_list.append(ans)\n        pred_vocab.append(_vocab)\n        \n    return text_list,pred_vocab\n\n#--------------------------------------\n# CER\n#---------------------------------------\ndef levenshtein(u, v):\n    prev = None\n    curr = [0] + [i for i in range(1, len(v) + 1)]\n    # Operations: (SUB, DEL, INS)\n    prev_ops = None\n    curr_ops = [(0, 0, i) for i in range(len(v) + 1)]\n    for x in range(1, len(u) + 1):\n        prev, curr = curr, [x] + ([None] * len(v))\n        prev_ops, curr_ops = curr_ops, [(0, x, 0)] + ([None] * len(v))\n        for y in range(1, len(v) + 1):\n            delcost = prev[y] + 1\n            addcost = curr[y - 1] + 1\n            subcost = prev[y - 1] + int(u[x - 1] != v[y - 1])\n            curr[y] = min(subcost, delcost, addcost)\n            if curr[y] == subcost:\n                (n_s, n_d, n_i) = prev_ops[y - 1]\n                curr_ops[y] = (n_s + int(u[x - 1] != v[y - 1]), n_d, n_i)\n            elif curr[y] == delcost:\n                (n_s, n_d, n_i) = prev_ops[y]\n                curr_ops[y] = (n_s, n_d + 1, n_i)\n            else:\n                (n_s, n_d, n_i) = curr_ops[y - 1]\n                curr_ops[y] = (n_s, n_d, n_i + 1)\n    return curr[len(v)], curr_ops[len(v)]\n\n\n\n#-----------------------------------------------\n# eval\n#-----------------------------------------------\nif DATASET_DIST in [\"synth\",\"all\"]:\n    print(\"No evaluation is designed\")\nelse:\n    #--------------------------------\n    # access eval data\n    #-------------------------------\n    img_dir =os.path.join(eval_dir,DATASET_DIST,\"images\")\n    data_csv=os.path.join(eval_dir,DATASET_DIST,\"data.csv\")\n    df=pd.read_csv(data_csv)\n    df[\"img_path\"]=df.filename.progress_apply(lambda x: os.path.join(img_dir,x))\n    df[\"labels\"]=df[\"labels\"].progress_apply(lambda x:literal_eval(x))\n    if VOCAB_TYPE==\"grapheme\":\n        df[\"gt_comp\"]=df[\"labels\"]\n    else:\n        df[\"gt_comp\"]=df[\"labels\"].progress_apply(lambda x:[i for i in \"\".join(x)])\n    df[\"gt_word\"]=df[\"labels\"].progress_apply(lambda x:\"\".join(x))\n    df=df[[\"img_path\",\"gt_word\",\"gt_comp\"]]\n    #--------------------------------\n    # batch evaluation\n    #-------------------------------\n    for idx in tqdm(range(0,len(df),eval_batch_size)):\n        bdf=df[idx:idx+eval_batch_size]\n        data=process_batch_images(bdf)\n        preds=model.predict(data)\n        preds,comps=ctc_decoder(preds,vocab)\n        bdf[\"pred_word\"]=preds\n        bdf[\"pred_comp\"]=comps\n        \n        eval_dfs.append(bdf)\n\n    eval_df=pd.concat(eval_dfs,ignore_index=True)\n    wrong_word_count=0\n    cer_s, cer_i, cer_d, cer_n = 0, 0, 0, 0\n    for i in tqdm(range(len(eval_df))):\n        gt_word  =eval_df.iloc[i,1]\n        pred_word=eval_df.iloc[i,3]\n        gt_comp  =eval_df.iloc[i,2]\n        pred_comp=eval_df.iloc[i,4]\n        if gt_word!=pred_word:wrong_word_count+=1\n        # update CER statistics\n        _, (s, i, d) = levenshtein(gt_comp,pred_comp)\n        cer_s += s\n        cer_i += i\n        cer_d += d\n        cer_n += len(gt_comp)\n\n    print(\"---------------------------------------------\")\n    print(\"WER:\",wrong_word_count/len(eval_df))\n    print(\"CER:\",(cer_s + cer_i + cer_d) / cer_n)\n    print(\"---------------------------------------------\")","metadata":{"execution":{"iopub.status.busy":"2021-08-26T08:59:30.81108Z","iopub.execute_input":"2021-08-26T08:59:30.811914Z","iopub.status.idle":"2021-08-26T09:00:15.544555Z","shell.execute_reply.started":"2021-08-26T08:59:30.811859Z","shell.execute_reply":"2021-08-26T09:00:15.543799Z"},"trusted":true},"execution_count":null,"outputs":[]}]}