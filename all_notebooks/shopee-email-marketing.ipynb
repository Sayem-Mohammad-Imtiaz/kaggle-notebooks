{"cells":[{"metadata":{},"cell_type":"markdown","source":"__Shopee Email Campaign Analysis__\n\nThe aim of this project is to build a model that can predict whether a user opens the emails sent by Shopee. Predict 'open_flag' feature","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"__Task Metric__\n\nMatthews Correlation Coefficient (MCC)\n\n- sklearn.metrics.matthews_corrcoef(y_true, y_pred, *, sample_weight=None)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split\nimport gc\n\nfrom sklearn.metrics import matthews_corrcoef\nfrom sklearn.preprocessing import LabelEncoder\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n\nfor dirname, _, filenames in os.walk('/kaggle/input/shopee-code-league-20/_DA_Marketing_Analytics'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom time import time, strftime, gmtime\n\nstart = time()\nprint(start)\n\nimport datetime\nprint(str(datetime.datetime.now()))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/shopee-code-league-20/_DA_Marketing_Analytics/train.csv')\nprint(train.shape)\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/shopee-code-league-20/_DA_Marketing_Analytics/test.csv')\nprint(test.shape)\ntest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"users = pd.read_csv('/kaggle/input/shopee-code-league-20/_DA_Marketing_Analytics/users.csv')\nprint(users.shape)\nusers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['grass_date'] = pd.to_datetime(train['grass_date']).dt.date\ntest['grass_date'] = pd.to_datetime(test['grass_date']).dt.date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"users.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"users.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Target Count__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10, 10))\nsns.countplot(train['open_flag'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neg = train['open_flag'].value_counts().values[0]\npos = train['open_flag'].value_counts().values[1]\ntrain['open_flag'].value_counts(normalize = True), pos, neg","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The dataset is clearly imbalanced, should take necessary measures to account for it.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"__User age distribution__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10, 10))\nsns.distplot(users['age'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__User age Boxplot__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10, 10))\nsns.boxplot(users['age'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Need to take care of the outliers in age","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"__Country Code plot__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lbls, freqs = np.unique(train['country_code'].values, return_counts = True)\n#print(list(zip(lbls, freqs)))\n\nplt.figure(figsize = (10, 10))\nplt.title('Train - Country Code')\nplt.pie(freqs, labels = lbls, autopct = '%1.1f%%', shadow = False, startangle = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lbls, freqs = np.unique(test['country_code'].values, return_counts = True)\n#print(list(zip(lbls, freqs)))\n\nplt.figure(figsize = (10, 10))\nplt.title('Test - Country Code')\nplt.pie(freqs, labels = lbls, autopct = '%1.1f%%', shadow = False, startangle = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10, 10))\ntrain['grass_date'].hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check for null values in columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('***Checking Null values..***')\nfor col in train.columns:\n    #print('****' * 10, col, '****' * 10)\n    print('Train - ', col, ' : ', train[col].isnull().all())\nprint()\nfor col in test.columns:\n    #print('****' * 10, col, '****' * 10)\n    print('Test - ', col, ' : ', test[col].isnull().all())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Use pd.to_numeric to convert the 'object' columns to numeric.\n- Also check all the columns for any str value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in train.columns:\n    print('Train - ', col, ' : ', pd.to_numeric(train[col], errors = 'coerce').notnull().all())\nprint()    \nfor col in test.columns:\n    print('Test - ', col, ' : ', pd.to_numeric(train[col], errors = 'coerce').notnull().all())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Another way to find the row index where the str appears\n#train[~train.applymap(lambda x: isinstance(x, (int, float)))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- So the 3 columns - last_open_day, last_login_day, last_checkout_day has str value in it. \n- Use Pandas.replace to change it to 0","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['last_open_day'] = train['last_open_day'].replace('Never open', 0)\ntrain['last_login_day'] = train['last_login_day'].replace('Never login', 0)\ntrain['last_checkout_day'] = train['last_checkout_day'].replace('Never checkout', 0)\n\ntest['last_open_day'] = test['last_open_day'].replace('Never open', 0)\ntest['last_login_day'] = test['last_login_day'].replace('Never login', 0)\ntest['last_checkout_day'] = test['last_checkout_day'].replace('Never checkout', 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Checking to confirm__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['last_open_day', 'last_login_day', 'last_checkout_day']:\n    print('Train - ', col, ' : ', pd.to_numeric(train[col], errors = 'coerce').notnull().all())\nprint()    \nfor col in ['last_open_day', 'last_login_day', 'last_checkout_day']:\n    print('Test - ', col, ' : ', pd.to_numeric(train[col], errors = 'coerce').notnull().all())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Checking Users data__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in users.columns:\n    print('Users - ', col, ' : ', users[col].isnull().all())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in users.columns:\n    print(users[col].value_counts(dropna = False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- There are too many NaNs in 'attr_1'. One option is we can remove the column entirely and the other option is make the NaN values as another value like '2', so that the 'attr_1' has 3 values 0, 1, 2\n\n- 'attr_2' has very few NaNs comparitively, we can assume it to be 1 or do same as above\n\n- The NaNs in 'age' column can be imputed with mean age. Also, the there are some outlier values that needs to be taken care off - make them as NaNs and impute. \n\n- For 'attr_3' impute with most frequent value\n\n- Same for domain - most frequent value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"users['attr_1'].fillna(2.0, inplace = True)\nusers['attr_2'].fillna(users['attr_2'].value_counts().index[0], inplace = True)\nusers['attr_3'].fillna(users['attr_3'].value_counts().index[0], inplace = True)\nusers['domain'].fillna(users['domain'].value_counts().index[0], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median = round(users['age'].median())\nstd = users['age'].std()\noutliers = (users['age'] - median).abs() > std\nusers['age'][outliers] = np.nan\nusers['age'].fillna(median, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in users.columns:\n    print(users[col].value_counts(dropna = False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Merge users data with train and test__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape, test.shape)\ntrain = pd.merge(train, users, on = 'user_id')\ntest = pd.merge(test, users, on = 'user_id')\nprint(train.shape, test.shape)\ndisplay(train.head(), test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['year'] = pd.to_datetime(train['grass_date']).dt.year\ntrain['month'] = pd.to_datetime(train['grass_date']).dt.month\ntrain['day'] = pd.to_datetime(train['grass_date']).dt.day\n\ntest['year'] = pd.to_datetime(test['grass_date']).dt.year\ntest['month'] = pd.to_datetime(test['grass_date']).dt.month\ntest['day'] = pd.to_datetime(test['grass_date']).dt.day\n\ndel train['grass_date'], test['grass_date'], train['user_id'], test['user_id'], train['row_id'], test['row_id']\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = train['open_flag'].copy()\ndel train['open_flag']\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Change dtype to int, float or bool for Lgbm__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in train.columns:\n    if train[col].dtype == 'object' and col != 'domain':\n        train[col] = train[col].astype(np.int32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in test.columns:\n    if test[col].dtype == 'object' and col != 'domain':\n        test[col] = test[col].astype(np.int32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = ['country_code', 'domain', 'year', 'month', 'day', 'attr_1', 'attr_2', 'attr_3']\nnum_features = [col for col in train.columns if col not in cat_features]\nprint(cat_features, num_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Encoding Categorical features__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lbl = LabelEncoder()\nfor feature in cat_features:\n    lbl.fit(list(train[feature].astype(str).values) + list(test[feature].astype(str).values))\n    train[feature] = lbl.transform(list(train[feature].astype(str).values))\n    test[feature] = lbl.transform(list(test[feature].astype(str).values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Train_Test Split__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtrain, Xvalid, ytrain, yvalid = train_test_split(train, target, test_size = 0.2, random_state = 42)\nprint(Xtrain.shape, ytrain.shape, Xvalid.shape, yvalid.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Baseline LGBM Model__","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgbm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_neg = np.sqrt(neg / pos)\npos_neg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'num_leaves': 120,\n          'min_child_weight': 0.001,\n          'min_child_samples': 20,\n          'feature_fraction': 0.379,\n          'bagging_fraction': 0.8,\n          'min_data_in_leaf': 50,\n          'objective': 'binary',\n          'max_depth': 10,\n          'learning_rate': 0.002,\n          \"boosting_type\": \"gbdt\",\n          \"bagging_seed\": 11,\n          \"metric\": {'auc'},\n          \"verbosity\": -1,\n          'reg_alpha': 0.389,\n          'reg_lambda': 0.648,\n          'scale_pos_weight': pos_neg,\n          'random_state': 47,\n         }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lgb_mcc_score(y_pred, data):\n    y_true = data.get_label()\n    y_pred = np.round(y_pred)\n    return 'mcc', matthews_corrcoef(y_true, y_pred), True\n\ndef lgb_mcc(preds, train_data):\n    THRESHOLD = 0.5\n    labels = train_data.get_label()\n    return 'mcc', matthews_corrcoef(labels, preds >= THRESHOLD)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ltrain = lgbm.Dataset(Xtrain, label = ytrain, categorical_feature = cat_features)\nlvalid = lgbm.Dataset(Xvalid, label = yvalid, categorical_feature = cat_features)\n\nevals_result = {}\n\nclf = lgbm.train(params, ltrain, 12000, valid_sets = [ltrain, lvalid], \n                 feval = lgb_mcc_score, evals_result = evals_result,\n                 verbose_eval = 200, early_stopping_rounds = 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm.plot_metric(evals_result, metric = 'mcc')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"100 - 0.881083\n200 - 0.8804\n120 - 0.881131","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_imp = pd.DataFrame(sorted(zip(clf.feature_importance(), train.columns)), columns = ['Value','Features'])\n\nplt.figure(figsize = (20, 10))\nsns.barplot(x = \"Value\", y = \"Features\", data = feature_imp.sort_values(by = \"Value\", ascending = False))\nplt.title('LightGBM Features)')\nplt.tight_layout()\nplt.show()\n#plt.savefig('lgbm_importances-01.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Model run with only 'auc' as metric\n\nFrom the above feature importance chart we can see users' features attr_1 and attr_2 doesn't contribute much to the model, we can try removing them and rerun the model to see if any perf improvement.\n\n- Model with MCC metric looks more realistic with *subject_line* as major factor for opening the email which is true in most cases. We will rerun the model with *user_id* and *row_id* removed","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = clf.predict(test, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub = pd.read_csv('/kaggle/input/shopee-code-league-20/_DA_Marketing_Analytics/sample_submission_0_1.csv')\nsample_sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub['open_flag'] = np.where(predictions > 0.5, 1, 0)\nsample_sub.to_csv('./sample_sub_ShopeeEmail.csv', index = False)\nsample_sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub['open_flag'].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10, 10))\nsns.countplot(sample_sub['open_flag'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finish = time()\nprint(strftime(\"%H:%M:%S\", gmtime(finish - start)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}