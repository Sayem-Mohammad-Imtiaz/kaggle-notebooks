{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# import necessary libraries","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/uci-online-news-popularity-data-set/OnlineNewsPopularity.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing duplicates\ndf=df.drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape  # there are no duplicates","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for all variables that contain missing values\nn=df.isna().sum()\nn[n>0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# there are no duplicates","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.hist(figsize=(20,20))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cor=df.corr()\n#ns.heatmap(cor)\nplt.figure(figsize=(15,15))\ndf_lt = cor.where(np.tril(np.ones(cor.shape)).astype(np.bool))\nsns.heatmap(df_lt,cmap='Blues')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing Space Character from Feature names\ndf.columns=df.columns.str.replace(\" \",\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# n_tokens_content represents Number of words in the content\n# However its minimum value to be 0. Means that there are articles that do not have any content.\n# Such records should be dropped as their related attributes add no meaning to our analysis\n\n# find number of rows that contain 0 for n_tokens_content\nnum_of_nowords=df[df['n_tokens_content']==0].index\nprint('number of news items with no words',num_of_nowords.size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop these items or rows with n_tokens_content = 0\n\ndf = df[df['n_tokens_content'] != 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since URL is a non-numeric attribute and will not add value to our analysis so dropping it from the dataset\n# Also timedelta is a non-predictive attribute and not a feature of the data set so we can drop it from the dataset\n# Drop highly correlated attributes \"n_non_stop_unique_tokens\",\"n_non_stop_words\",\"kw_avg_min\"\ndf = df.drop('url',axis=1)\ndf = df.drop('timedelta',axis=1)\ndf= df.drop([\"n_non_stop_unique_tokens\",\"n_non_stop_words\",\"kw_avg_min\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Understanding target variable distribution\ndf['shares'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['shares'].median()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Hence, to set a threshold for deciding whether an article is popular, I choose the median number of shares in the dataset. All the articles with 1400 or more shares are marked as popular and all the articles with less than 1400 shares are considered to be unpopular","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a new target variable\ndf['popularity'] = df['shares'].apply(lambda x: 0 if x <1400 else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.hist(column='popularity');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of words in content vs Number of shares\n\nplt.figure(figsize=(10,5))\nax = sns.scatterplot(y='shares', x='n_tokens_content', data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of words in title vs Number of shares\n\nplt.figure(figsize=(10,5))\nax = sns.scatterplot(y='shares', x='n_tokens_title', data=df,palette='muted');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a,b = df['shares'].mean(),df['shares'].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Mean article shares = {a}')\nprint(f'Median article share = {b}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Wday = df.columns.values[26:33]\nWday","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Unpop=df[df['shares']<a]\nPop=df[df['shares']>=a]\nUnpop_day = Unpop[Wday].sum().values\nPop_day = Pop[Wday].sum().values\n\nfig = plt.figure(figsize = (13,5))\nplt.title(\"Count of popular/unpopular news over different day of week (Mean)\", fontsize = 16)\n\nplt.bar(np.arange(len(Wday)),Pop_day,width=0.3,align='center',color='g',label='Popular')\nplt.bar(np.arange(len(Wday))-0.3,Unpop_day,width=0.3,align='center',color='#00A0A0',label='Unpopular')\n\nplt.xticks(np.arange(len(Wday)),Wday)\nplt.ylabel('COUNT',fontsize=15)\nplt.xlabel('Day of Week',fontsize=17)\n#for i, v in enumerate(Pop_day):\n#    fig.text(i+25, \n#              v/Pop_day[i]+50, \n#              Pop_day[i], \n#              fontsize=5)\n\nplt.legend(loc = 'upper right')\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Unpop=df[df['shares']<b]\nPop=df[df['shares']>=b]\nUnpop_day = Unpop[Wday].sum().values\nPop_day = Pop[Wday].sum().values\n\nfig = plt.figure(figsize = (13,5))\nplt.title(\"Count of popular/unpopular news over different day of week (Median)\", fontsize = 16)\n\nplt.bar(np.arange(len(Wday)),Pop_day,width=0.3,align='center',color='g',label='Popular')\nplt.bar(np.arange(len(Wday))-0.3,Unpop_day,width=0.3,align='center',color='#00A0A0',label='Unpopular')\n\nplt.xticks(np.arange(len(Wday)),Wday)\nplt.ylabel('COUNT',fontsize=15)\nplt.xlabel('Day of Week',fontsize=17)\n#for i, v in enumerate(Pop_day):\n#    fig.text(i+25, \n#              v/Pop_day[i]+50, \n#              Pop_day[i], \n#              fontsize=5)\n\nplt.legend(loc = 'upper right')\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Dc=df.columns[9:15]\nDc\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Unpop3=df[df['shares']<a]\nPop3=df[df['shares']>=a]\nUnpop_day3 = Unpop3[Dc].sum().values\nPop_day3 = Pop3[Dc].sum().values\nfig = plt.figure(figsize = (13,5))\nplt.title(\"Count of popular/unpopular news over different data channel (Mean)\", fontsize = 16)\nplt.bar(np.arange(len(Dc)), Pop_day3, width = 0.3, align=\"center\", color = 'g', \\\n          label = \"popular\")\nplt.bar(np.arange(len(Dc)) - 0.3, Unpop_day3, width = 0.3, align = \"center\", color = '#00A0A0', \\\n          label = \"unpopular\")\nplt.xticks(np.arange(len(Dc)), Dc)\nplt.ylabel(\"Count\", fontsize = 12)\nplt.xlabel(\"Days of week\", fontsize = 12)\n    \nplt.legend(loc = 'upper right')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Unpop4=df[df['shares']<b]\nPop4=df[df['shares']>=b]\nUnpop_day4 = Unpop4[Dc].sum().values\nPop_day4 = Pop4[Dc].sum().values\nfig = plt.figure(figsize = (13,5))\nplt.title(\"Count of popular/unpopular news over different data channel (Median)\", fontsize = 16)\nplt.bar(np.arange(len(Dc)), Pop_day4, width = 0.3, align=\"center\", color = 'g', \\\n          label = \"popular\")\nplt.bar(np.arange(len(Dc)) - 0.3, Unpop_day4, width = 0.3, align = \"center\", color = '#00A0A0', \\\n          label = \"unpopular\")\nplt.xticks(np.arange(len(Dc)), Dc)\nplt.ylabel(\"Count\", fontsize = 12)\nplt.xlabel(\"Days of week\", fontsize = 12)\n    \nplt.legend(loc = 'upper right')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Outlier Treatment","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = df.select_dtypes(['int64','float64']).columns\nfor i in range(len(num_cols)):\n    sns.boxplot(df[num_cols[i]])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfor column in num_cols:    \n    q1 = df[column].quantile(0.25)    # First Quartile\n    q3 = df[column].quantile(0.75)    # Third Quartile\n    IQR = q3 - q1                            # Inter Quartile Range\n\n    llimit = q1 - 1.5*IQR                       # Lower Limit\n    ulimit = q3 + 1.5*IQR                        # Upper Limit\n\n    outliers = df[(df[column] < llimit) | (df[column] > ulimit)]\n    print('Number of outliers in \"' + column + '\" : ' + str(len(outliers)))\n    print(llimit)\n    print(ulimit)\n    print(IQR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can remove this ouliers after applying transformation","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scaling of Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# df2_num  dataframe contains numerical feaures.\n\ndf2_num=df.drop([\"weekday_is_monday\",\"weekday_is_tuesday\",\"weekday_is_wednesday\",\"weekday_is_thursday\",\n                  \"weekday_is_friday\",\"weekday_is_saturday\",\"weekday_is_sunday\",\"is_weekend\",                  \n                  \"data_channel_is_lifestyle\",\"data_channel_is_entertainment\",\"data_channel_is_bus\",\n                  \"data_channel_is_socmed\",\"data_channel_is_tech\",\"data_channel_is_world\"],axis=1)\n\n# df2_cat dataframe contains catagoricl features.\n\ndf2_cat=df[[\"weekday_is_monday\",\"weekday_is_tuesday\",\"weekday_is_wednesday\",\"weekday_is_thursday\",\n             \"weekday_is_friday\",\"weekday_is_saturday\",\"weekday_is_sunday\",\"is_weekend\",            \n             \"data_channel_is_lifestyle\",\"data_channel_is_entertainment\",\"data_channel_is_bus\",\n                  \"data_channel_is_socmed\",\"data_channel_is_tech\",\"data_channel_is_world\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will check distribution of attributes to decide the method of scaling\n\n# Drop target variable from df2_num\n\ndf2_num = df2_num.drop('shares',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2_num.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding negative values.\n\nnegcols=df2_num.columns[(df2_num<=0).any()]\nnegcols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use box-cox method of scaling because the distribution of attributes is not normal and has a lot of negative values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting negative values to positive values for applying Box-Cox method and creating new feature.\n\nfor i in negcols:\n    m=df2_num[i].min()\n    name=i +'_new'\n    df2_num[name]=((df2_num[i]+1)-m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2_num.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Droping old negative column\n\nfor i in negcols:\n    df2_num.drop(i,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking negative columns\n\nnegcols=df2_num.columns[(df2_num<=0).any()]\nnegcols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\npt=preprocessing.PowerTransformer(method='box-cox',standardize=False)\ndf2_num_add=pt.fit_transform(df2_num)\ndf2_num_add=(pd.DataFrame(df2_num_add,columns=df2_num.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Treating outlier :  \n\nfor col in df2_num_add.columns:\n    percentiles = df2_num_add[col].quantile([0.01,0.99]).values\n    df2_num_add[col][df2_num_add[col] <= percentiles[0]] = percentiles[0]\n    df2_num_add[col][df2_num_add[col] >= percentiles[1]] = percentiles[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking outliers again\n\nnum_cols = df2_num_add.select_dtypes(['int64','float64']).columns\n\nfor column in num_cols:    \n    q1 = df2_num_add[column].quantile(0.25)    # First Quartile\n    q3 = df2_num_add[column].quantile(0.75)    # Third Quartile\n    IQR = q3 - q1                            # Inter Quartile Range\n\n    llimit = q1 - 1.5*IQR                       # Lower Limit\n    ulimit = q3 + 1.5*IQR                        # Upper Limit\n\n    outliers = df2_num_add[(df2_num_add[column] < llimit) | (df2_num_add[column] > ulimit)]\n    print('Number of outliers in \"' + column + '\" : ' + str(len(outliers)))\n    print(llimit)\n    print(ulimit)\n    print(IQR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = df2_num_add.select_dtypes(['int64','float64']).columns\nfor i in range(len(num_cols)):\n    sns.boxplot(df2_num_add[num_cols[i]])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df2_num_add.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2_cat.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combining numeric features and catogorical features.\n\ndf_final=pd.concat([df2_num_add,df2_cat],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final['popularity'] = df['shares'].apply(lambda x: 0 if x <1400 else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final=df_final.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification Model :","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## BASE MODEL: AdaBoost Classifier,Logistic Regression,Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"modelscore=[]\nX=df_final.drop(['popularity','popularity_new'],axis=1)\ny=df_final['popularity']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 0)\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n    '''\n    inputs:\n       - learner: the learning algorithm to be trained and predicted on\n       - sample_size: the size of samples (number) to be drawn from training set\n       - X_train: features training set\n       - y_train: income training set\n       - X_test: features testing set\n       - y_test: income testing set\n    '''\n    \n    results = {}\n    \n    start = time() # Get start time\n    learner.fit(X_train[:sample_size], y_train[:sample_size])\n    end = time() # Get end time\n\n    results['train_time'] = end-start\n        \n    # Get predictions on the first 4000 training samples\n    start = time() # Get start time\n    predictions_test = learner.predict(X_test)\n    predictions_train = learner.predict(X_train[:4000])\n    end = time() # Get end time\n    \n    # Calculate the total prediction time\n    results['pred_time'] = end-start\n            \n    # Compute accuracy on the first 4000 training samples\n    results['acc_train'] = accuracy_score(y_train[:4000],predictions_train)\n        \n    # Compute accuracy on test set\n    results['acc_test'] = accuracy_score(y_test,predictions_test)\n    \n    # Compute F-score on the the first 4000 training samples\n    results['f_train'] = fbeta_score(y_train[:4000],predictions_train,beta=1)\n        \n    # Compute F-score on the test set\n    results['f_test'] = fbeta_score(y_test,predictions_test,beta=1)\n    \n    # Compute AUC on the the first 4000 training samples\n    results['auc_train'] = roc_auc_score(y_train[:4000],predictions_train)\n        \n    # Compute AUC on the test set\n    results['auc_test'] = roc_auc_score(y_test,predictions_test)\n       \n    # Success\n    print (\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n    print (\"{} with accuracy {}, F1 {} and AUC {}.\".format(learner.__class__.__name__,\\\n          results['acc_test'],results['f_test'], results['auc_test']) )\n    # Return the results\n    #cm=confusion_matrix(y_test,predictions_test)\n    #df_cm = pd.DataFrame(cm, range(2), range(2))\n    # plt.figure(figsize=(10,7))\n    #sns.set(font_scale=1.4) # for label size\n    #sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n\n    #plt.show()\n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.patches as mpatches\ndef evaluate(results,name):\n    \"\"\"\n    Visualization code to display results of various learners.\n    \n    inputs:\n      - learners: a list of supervised learners\n      - stats: a list of dictionaries of the statistic results from 'train_predict()'\n      - accuracy: The score for the naive predictor\n      - f1: The score for the naive predictor\n    \"\"\"\n  \n    # Create figure\n    fig, ax = plt.subplots(2, 4, figsize = (16,7))\n\n    # Constants\n    bar_width = 0.3\n    colors = ['#A00000','#00A0A0','#00A000']\n    \n    # Super loop to plot four panels of data\n    for k, learner in enumerate(results.keys()):\n        for j, metric in enumerate(['train_time', 'acc_train', 'f_train', 'auc_train','pred_time', 'acc_test',\\\n                                    'f_test', 'auc_test']):\n            for i in np.arange(3):\n                \n                # Creative plot code\n                ax[j//4, j%4].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])\n                ax[j//4, j%4].set_xticks([0.45, 1.45, 2.45])\n                ax[j//4, j%4].set_xticklabels([\"1%\", \"10%\", \"100%\"])\n                ax[j//4, j%4].set_xlim((-0.1, 3.0))\n    \n    # Add labels\n    ax[0, 0].set_ylabel(\"Time (in seconds)\")\n    ax[0, 1].set_ylabel(\"Accuracy Score\")\n    ax[0, 2].set_ylabel(\"F-score\")\n    ax[0, 3].set_ylabel(\"AUC\")\n    ax[1, 0].set_ylabel(\"Time (in seconds)\")\n    ax[1, 1].set_ylabel(\"Accuracy Score\")\n    ax[1, 2].set_ylabel(\"F-score\")\n    ax[1, 3].set_ylabel(\"AUC\")\n    ax[1, 0].set_xlabel(\"Training Set Size\")\n    ax[1, 1].set_xlabel(\"Training Set Size\")\n    ax[1, 2].set_xlabel(\"Training Set Size\")\n    ax[1, 3].set_xlabel(\"Training Set Size\")\n    \n    # Add titles\n    ax[0, 0].set_title(\"Model Training\")\n    ax[0, 1].set_title(\"Accuracy Score on Training Subset\")\n    ax[0, 2].set_title(\"F-score on Training Subset\")\n    ax[0, 3].set_title(\"AUC on Training Subset\")\n    ax[1, 0].set_title(\"Model Predicting\")\n    ax[1, 1].set_title(\"Accuracy Score on Testing Set\")\n    ax[1, 2].set_title(\"F-score on Testing Set\")\n    ax[1, 3].set_title(\"AUC on Testing Subset\")\n    \n    # Set y-limits for score panels\n    ax[0, 1].set_ylim((0, 1))\n    ax[0, 2].set_ylim((0, 1))\n    ax[0, 3].set_ylim((0, 1))\n    ax[1, 1].set_ylim((0, 1))\n    ax[1, 2].set_ylim((0, 1))\n    ax[1, 3].set_ylim((0, 1))\n\n    # Create patches for the legend\n    patches = []\n    for i, learner in enumerate(results.keys()):\n        patches.append(mpatches.Patch(color = colors[i], label = learner))\n    plt.legend(handles = patches,  bbox_to_anchor = (-1.4, 2.54),\\\n               loc = 'upper center', borderaxespad = 0., ncol = 3, fontsize = 'x-large')\n    \n    # Aesthetics\n    plt.suptitle(\"Performance Metrics for Three Supervised Learning Models\", fontsize = 16, y = 1.10)\n    plt.savefig(name)\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the three supervised learning models from sklearn\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom time import time\nfrom IPython.display import display\nfrom sklearn.metrics import accuracy_score, fbeta_score, roc_curve, auc, roc_auc_score\n\n# Initialize the three models\nclf_A = AdaBoostClassifier(random_state=0)\nclf_B = LogisticRegression(random_state=0,C=1.0)\nclf_C = RandomForestClassifier(random_state=0)\n\n# Calculate the number of samples for 1%, 10%, and 100% of the training data\nsamples_1 = int(X_train.shape[0]*0.01)\nsamples_10 = int(X_train.shape[0]*0.1)\nsamples_100 = X_train.shape[0]\n\n# Collect results on the learners\nresults = {}\nfor clf in [clf_A, clf_B, clf_C]:\n    clf_name = clf.__class__.__name__\n    results[clf_name] = {}\n    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n        if clf == clf_A:\n            results[clf_name][i] = \\\n            train_predict(clf, samples, X_train, y_train, X_test, y_test)\n        elif clf == clf_B:\n            results[clf_name][i] = \\\n            train_predict(clf, samples, X_train, y_train, X_test, y_test)\n        else:\n            results[clf_name][i] = \\\n            train_predict(clf, samples, X_train, y_train, X_test, y_test)\n\n# Run metrics visualization for the three supervised learning models chosen\nevaluate(results,'perf_unopt.pdf')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize the three models\nimport sklearn\nfrom sklearn.neighbors import KNeighborsClassifier\nclf_A =GaussianNB()\nclf_B = SVC(random_state=0,C=1.0)\nclf_C = sklearn.neighbors.KNeighborsClassifier(n_neighbors=5)\n\n# Calculate the number of samples for 1%, 10%, and 100% of the training data\nsamples_1 = int(X_train.shape[0]*0.01)\nsamples_10 = int(X_train.shape[0]*0.1)\nsamples_100 = X_train.shape[0]\n\n# Collect results on the learners\nresults = {}\nfor clf in [clf_A, clf_B, clf_C]:\n    clf_name = clf.__class__.__name__\n    results[clf_name] = {}\n    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n        if clf == clf_A:\n            results[clf_name][i] = \\\n            train_predict(clf, samples, X_train, y_train, X_test, y_test)\n        elif clf == clf_B:\n            results[clf_name][i] = \\\n            train_predict(clf, samples, X_train, y_train, X_test, y_test)\n        else:\n            results[clf_name][i] = \\\n            train_predict(clf, samples, X_train, y_train, X_test, y_test)\n\n# Run metrics visualization for the three supervised learning models chosen\nevaluate(results,'perf_unopt1.pdf')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import Lightgbm as lgb\n\nclf_A =SGDClassifier()\nclf_B = BaggingClassifier(random_state=0)\nclf_C = DecisionTreeClassifier(random_state=0)\n\n# Calculate the number of samples for 1%, 10%, and 100% of the training data\nsamples_1 = int(X_train.shape[0]*0.01)\nsamples_10 = int(X_train.shape[0]*0.1)\nsamples_100 = X_train.shape[0]\n\n# Collect results on the learners\nresults = {}\nfor clf in [clf_A, clf_B, clf_C]:\n    clf_name = clf.__class__.__name__\n    results[clf_name] = {}\n    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n        if clf == clf_A:\n            results[clf_name][i] = \\\n            train_predict(clf, samples, X_train, y_train, X_test, y_test)\n        elif clf == clf_B:\n            results[clf_name][i] = \\\n            train_predict(clf, samples, X_train, y_train, X_test, y_test)\n        else:\n            results[clf_name][i] = \\\n            train_predict(clf, samples, X_train, y_train, X_test, y_test)\n\n# Run metrics visualization for the three supervised learning models chosen\nevaluate(results,'perf_unopt1.pdf')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LIGHTGBM MODEL:\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm=lgb.LGBMClassifier()\nlgbm.fit(X_train,y_train)\n#y_test1=np.array_test).reshape(-1,1)\ny_pred=lgbm.predict(X_test)\n#print('Score on train set ',score(X_train,y_train))\nprint('accuracy on test set ',accuracy_score(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Selection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature selection\n# USING BACKWARD ELIMINATION\nfrom sklearn.feature_selection import RFE\ncols=df_final.columns\nmodel=RandomForestClassifier()\nrfe=RFE(model,57)\n#Transforming data using RFE\nX_rfe = rfe.fit_transform(X,y)  \n#Fitting the data to model\nmodel.fit(X_rfe,y)\nprint(rfe.support_)\nprint(rfe.ranking_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Best model till now :Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import  train_test_split\nx_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=1)\n\nrf=RandomForestClassifier()\nrf.fit(x_train,y_train)\ny_pred_train=rf.predict(x_train)\ny_prob_train=rf.predict_proba(x_train)[:,1]\n\ny_pred=rf.predict(x_test)\ny_prob=rf.predict_proba(x_test)[:,1]  #used to find AUC of train and test\n\nfrom sklearn.metrics import accuracy_score,roc_curve,roc_auc_score\n\nprint('Accuracy of Random forest train :',accuracy_score(y_pred_train,y_train))\nprint('Accuracy of Random forest test:',accuracy_score(y_pred,y_test))\n\n\nprint('AUC of Random forest train :',roc_auc_score(y_train,y_prob_train))\nprint('AUC of Random forest test :',roc_auc_score(y_test,y_prob))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,y_pred)\nconf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\nplt.figure(figsize = (8,5))\nsns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hyperparameter tuning of random forest  #randomsearch","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import randint as sp_randint\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV\nrf=RandomForestClassifier(random_state=1)\n\nparams={'n_estimators':sp_randint(5,25),\n       'criterion':['gini','entropy'],\n       'max_depth':sp_randint(2,10),\n       'min_samples_split':sp_randint(2,20),\n       'min_samples_leaf':sp_randint(1,20),\n       'max_features':sp_randint(2,15)}\nrand_search_rfc=RandomizedSearchCV(rf,param_distributions=params,cv=3,random_state=1)\n\nrand_search_rfc.fit(X,y)\n\nprint(rand_search_rfc.best_params_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf=RandomForestClassifier(**rand_search_rfc.best_params_)\nrf.fit(x_train,y_train)\ny_pred_train=rf.predict(x_train)\ny_prob_train=rf.predict_proba(x_train)[:,1]\n\ny_pred=rf.predict(x_test)\ny_prob=rf.predict_proba(x_test)[:,1]  #used to find AUC of train and test\n\nfrom sklearn.metrics import accuracy_score,roc_curve,roc_auc_score\n\nprint('Accuracy of Random forest train :',accuracy_score(y_pred_train,y_train))\nprint('Accuracy of random forest test :',accuracy_score(y_pred,y_test))\n\n\nprint('AUC of random forest train :',roc_auc_score(y_train,y_prob_train))\nprint('AUC of random forest test :',roc_auc_score(y_test,y_prob))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr,tpr,threshold=roc_curve(y_test,y_prob)\nplt.plot(fpr,tpr)\nplt.plot(fpr,fpr,'r-')\nplt.xlabel('FPR')\nplt.ylabel('TPR')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}