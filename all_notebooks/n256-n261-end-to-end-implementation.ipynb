{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Detecting Maclicious URLs using Machine Learning<br>\nThe malicious urls can be detected using the lexical features along with tokenization of the url strings. I aim to build a basic binary classifier which would help classify the URLs as malicious or benign.","metadata":{}},{"cell_type":"markdown","source":"Steps followed in building the machine learning classifier<br>\n1. Data Preprocessing / Feature Engineering\n2. Data Visualization\n3. Building Machine Learning Models using Lexical Features.\n4. Building Machine Learning Models using Lexical Features and Tokenization. (Will Update this part)","metadata":{}},{"cell_type":"markdown","source":"Importing The Dependencies","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nprint(os.listdir(\"../input\"))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install catboost","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install xgboost","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata = pd.read_csv(\"../input/urldata.csv\")","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing the unnamed columns as it is not necesary.\nurldata = urldata.drop('Unnamed: 0',axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking Missing Values","metadata":{}},{"cell_type":"code","source":"urldata.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No missing values in any column.","metadata":{}},{"cell_type":"markdown","source":"# 1. DATA PREPROCESSING","metadata":{}},{"cell_type":"markdown","source":"The following features will be extracted from the URL for classification. <br>\n<ol>\n    <li>Length Features\n    <ul>\n        <li>Length Of Url</li>\n        <li>Length of Hostname</li>\n        <li>Length Of Path</li>\n        <li>Length Of First Directory</li>\n        <li>Length Of Top Level Domain</li>\n    </ul>\n    </li>\n    <br>\n   <li>Count Features\n    <ul>\n    <li>Count Of  '-'</li>\n    <li>Count Of '@'</li>\n    <li>Count Of '?'</li>\n    <li>Count Of '%'</li>\n    <li>Count Of '.'</li>\n    <li>Count Of '='</li>\n    <li>Count Of 'http'</li>\n    <li>Count Of 'www'</li>\n    <li>Count Of Digits</li>\n    <li>Count Of Letters</li>\n    <li>Count Of Number Of Directories</li>\n    </ul>\n    </li>\n    <br>\n    <li>Binary Features\n    <ul>\n        <li>Use of IP or not</li>\n        <li>Use of Shortening URL or not</li>\n    </ul>\n    </li>\n    \n</ol>\n\nApart from the lexical features, we will use TFID - Term Frequency Inverse Document as well.","metadata":{}},{"cell_type":"markdown","source":"### 1.1 Length Features","metadata":{}},{"cell_type":"code","source":"!pip install tld","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importing dependencies\nfrom urllib.parse import urlparse\nfrom tld import get_tld\nimport os.path","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Length of URL\nurldata['url_length'] = urldata['url'].apply(lambda i: len(str(i)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Hostname Length\nurldata['hostname_length'] = urldata['url'].apply(lambda i: len(urlparse(i).netloc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Path Length\nurldata['path_length'] = urldata['url'].apply(lambda i: len(urlparse(i).path))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#First Directory Length\ndef fd_length(url):\n    urlpath= urlparse(url).path\n    try:\n        return len(urlpath.split('/')[1])\n    except:\n        return 0\n\nurldata['fd_length'] = urldata['url'].apply(lambda i: fd_length(i))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Length of Top Level Domain\nurldata['tld'] = urldata['url'].apply(lambda i: get_tld(i,fail_silently=True))\ndef tld_length(tld):\n    try:\n        return len(tld)\n    except:\n        return -1\n\nurldata['tld_length'] = urldata['tld'].apply(lambda i: tld_length(i))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata = urldata.drop(\"tld\",1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataset after extracting length features","metadata":{}},{"cell_type":"code","source":"urldata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.2 Count Features","metadata":{}},{"cell_type":"code","source":"urldata['count-'] = urldata['url'].apply(lambda i: i.count('-'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata['count@'] = urldata['url'].apply(lambda i: i.count('@'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata['count?'] = urldata['url'].apply(lambda i: i.count('?'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata['count%'] = urldata['url'].apply(lambda i: i.count('%'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata['count.'] = urldata['url'].apply(lambda i: i.count('.'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata['count='] = urldata['url'].apply(lambda i: i.count('='))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata['count-http'] = urldata['url'].apply(lambda i : i.count('http'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata['count-https'] = urldata['url'].apply(lambda i : i.count('https'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urldata['count-www'] = urldata['url'].apply(lambda i: i.count('www'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def digit_count(url):\n    digits = 0\n    for i in url:\n        if i.isnumeric():\n            digits = digits + 1\n    return digits\nurldata['count-digits']= urldata['url'].apply(lambda i: digit_count(i))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def letter_count(url):\n    letters = 0\n    for i in url:\n        if i.isalpha():\n            letters = letters + 1\n    return letters\nurldata['count-letters']= urldata['url'].apply(lambda i: letter_count(i))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def no_of_dir(url):\n    urldir = urlparse(url).path\n    return urldir.count('/')\nurldata['count_dir'] = urldata['url'].apply(lambda i: no_of_dir(i))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data after extracting Count Features","metadata":{}},{"cell_type":"code","source":"urldata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.3 Binary Features","metadata":{}},{"cell_type":"code","source":"import re","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Use of IP or not in domain\ndef having_ip_address(url):\n    match = re.search(\n        '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n        '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4\n        '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\/)' # IPv4 in hexadecimal\n        '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}', url)  # Ipv6\n    if match:\n        # print match.group()\n        return -1\n    else:\n        # print 'No matching pattern found'\n        return 1\nurldata['use_of_ip'] = urldata['url'].apply(lambda i: having_ip_address(i))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def shortening_service(url):\n    match = re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n                      'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n                      'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n                      'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n                      'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n                      'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n                      'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|'\n                      'tr\\.im|link\\.zip\\.net',\n                      url)\n    if match:\n        return -1\n    else:\n        return 1\nurldata['short_url'] = urldata['url'].apply(lambda i: shortening_service(i))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data after extracting Binary Features","metadata":{}},{"cell_type":"code","source":"urldata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Visualization","metadata":{}},{"cell_type":"code","source":"#Heatmap\ncorrmat = urldata.corr()\nf, ax = plt.subplots(figsize=(25,19))\nsns.heatmap(corrmat, square=True, annot = True, annot_kws={'size':10})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.countplot(x='label',data=urldata)\nplt.title(\"Count Of URLs\",fontsize=20)\nplt.xlabel(\"Type Of URLs\",fontsize=18)\nplt.ylabel(\"Number Of URLs\",fontsize=18)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Percent Of Malicious URLs:{:.2f} %\".format(len(urldata[urldata['label']=='malicious'])/len(urldata['label'])*100))\nprint(\"Percent Of Benign URLs:{:.2f} %\".format(len(urldata[urldata['label']=='benign'])/len(urldata['label'])*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data shows a class imbalance to some extent.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,5))\nplt.hist(urldata['url_length'],bins=50,color='LightBlue')\nplt.title(\"URL-Length\",fontsize=20)\nplt.xlabel(\"Url-Length\",fontsize=18)\nplt.ylabel(\"Number Of Urls\",fontsize=18)\nplt.ylim(0,1000)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,5))\nplt.hist(urldata['hostname_length'],bins=50,color='Lightgreen')\nplt.title(\"Hostname-Length\",fontsize=20)\nplt.xlabel(\"Length Of Hostname\",fontsize=18)\nplt.ylabel(\"Number Of Urls\",fontsize=18)\nplt.ylim(0,1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,5))\nplt.hist(urldata['tld_length'],bins=50,color='Lightgreen')\nplt.title(\"TLD-Length\",fontsize=20)\nplt.xlabel(\"Length Of TLD\",fontsize=18)\nplt.ylabel(\"Number Of Urls\",fontsize=18)\nplt.ylim(0,1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.title(\"Number Of Directories In Url\",fontsize=20)\nsns.countplot(x='count_dir',data=urldata)\nplt.xlabel(\"Number Of Directories\",fontsize=18)\nplt.ylabel(\"Number Of URLs\",fontsize=18)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.title(\"Number Of Directories In Url\",fontsize=20)\nsns.countplot(x='count_dir',data=urldata,hue='label')\nplt.xlabel(\"Number Of Directories\",fontsize=18)\nplt.ylabel(\"Number Of URLs\",fontsize=18)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.title(\"Use Of IP In Url\",fontsize=20)\nplt.xlabel(\"Use Of IP\",fontsize=18)\n\nsns.countplot(urldata['use_of_ip'])\nplt.ylabel(\"Number of URLs\",fontsize=18)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.title(\"Use Of IP In Url\",fontsize=20)\nplt.xlabel(\"Use Of IP\",fontsize=18)\nplt.ylabel(\"Number of URLs\",fontsize=18)\nsns.countplot(urldata['use_of_ip'],hue='label',data=urldata)\nplt.ylabel(\"Number of URLs\",fontsize=18)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.title(\"Use Of http In Url\",fontsize=20)\nplt.xlabel(\"Use Of IP\",fontsize=18)\nplt.ylim((0,1000))\nsns.countplot(urldata['count-http'])\nplt.ylabel(\"Number of URLs\",fontsize=18)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.title(\"Use Of http In Url\",fontsize=20)\nplt.xlabel(\"Count Of http\",fontsize=18)\nplt.ylabel(\"Number of URLs\",fontsize=18)\nplt.ylim((0,1000))\nsns.countplot(urldata['count-http'],hue='label',data=urldata)\nplt.ylabel(\"Number of URLs\",fontsize=18)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.title(\"Use Of http In Url\",fontsize=20)\nplt.xlabel(\"Count Of http\",fontsize=18)\n\nsns.countplot(urldata['count-http'],hue='label',data=urldata)\n\nplt.ylabel(\"Number of URLs\",fontsize=18)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.title(\"Use Of WWW In URL\",fontsize=20)\nplt.xlabel(\"Count Of WWW\",fontsize=18)\nsns.countplot(urldata['count-www'])\nplt.ylim(0,1000)\nplt.ylabel(\"Number Of URLs\",fontsize=18)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.title(\"Use Of WWW In URL\",fontsize=20)\nplt.xlabel(\"Count Of WWW\",fontsize=18)\n\nsns.countplot(urldata['count-www'],hue='label',data=urldata)\nplt.ylim(0,1000)\nplt.ylabel(\"Number Of URLs\",fontsize=18)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Building Models Using Lexical Features Only","metadata":{}},{"cell_type":"markdown","source":"\n<br>1. Logistic Regression\n<br>2. XGBoost Classifier\n<br>3. Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n\nfrom xgboost.sklearn import XGBClassifier\n\nfrom sklearn.linear_model import LogisticRegression\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Independent Variables\nx = urldata[['hostname_length',\n       'path_length', 'fd_length', 'tld_length', 'count-', 'count@', 'count?',\n       'count%', 'count.', 'count=', 'count-http','count-https', 'count-www', 'count-digits',\n       'count-letters', 'count_dir', 'use_of_ip']]\n\n#Dependent Variable\ny = urldata['result']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.1 Train test split","metadata":{}},{"cell_type":"code","source":"#Oversampling using SMOTE\nfrom imblearn.over_sampling import SMOTE\n\nx_sample, y_sample = SMOTE().fit_sample(x, y.values.ravel())\n\nx_sample = pd.DataFrame(x_sample)\ny_sample = pd.DataFrame(y_sample)\n\n# checking the sizes of the sample data\nprint(\"Size of x-sample :\", x_sample.shape)\nprint(\"Size of y-sample :\", y_sample.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train test split\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x_sample, y_sample, test_size = 0.2, random_state = 1234)\nprint(\"Shape of x_train: \", x_train.shape)\nprint(\"Shape of x_valid: \", x_test.shape)\nprint(\"Shape of y_train: \", y_train.shape)\nprint(\"Shape of y_valid: \", y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 XGBoost Classifier","metadata":{}},{"cell_type":"code","source":"#XGBoost Classifier\nxgb_model = XGBClassifier()\nxgb_model.fit(x_train,y_train)\n\nxg_predictions = xgb_model.predict(x_test)\naccuracy_score(y_test,xg_predictions)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = pd.DataFrame(confusion_matrix(y_test,xg_predictions))\ncm.columns = ['Predicted 0', 'Predicted 1']\ncm = cm.rename(index = {0:'Actual 0',1:'Actual 1'})\ncm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 Random Forest","metadata":{}},{"cell_type":"code","source":"#Random Forest\nrfc = RandomForestClassifier()\nrfc.fit(x_train, y_train)\n\nrfc_predictions = rfc.predict(x_test)\naccuracy_score(y_test, rfc_predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = pd.DataFrame(confusion_matrix(y_test,rfc_predictions))\ncm.columns = ['Predicted 0', 'Predicted 1']\ncm = cm.rename(index = {0:'Actual 0',1:'Actual 1'})\ncm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.4 Logistic Regression","metadata":{}},{"cell_type":"code","source":"#Logistic Regression\nlog_model = LogisticRegression()\nlog_model.fit(x_train,y_train)\n\nlog_predictions = log_model.predict(x_test)\naccuracy_score(y_test,log_predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm_df = pd.DataFrame(confusion_matrix(y_test,log_predictions))\ncm_df.columns = ['Predicted 0', 'Predicted 1']\ncm_df = cm_df.rename(index = {0:'Actual 0',1:'Actual 1'})\ncm_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Overall Accuracy table\nimport numpy as np\nmodel = np.array(['XGBClassifier', 'Random Forest', 'Logistic Regression'])\nscr = np.array([accuracy_score(y_test,xg_predictions)*100, accuracy_score(y_test, rfc_predictions)*100, accuracy_score(y_test,log_predictions)*100])\ntbl = pd.DataFrame({\"Model\": model,\"Accuracy Score\": scr})\ntbl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Overall all the models showed great results with decent accuracy and low error rate.<br>\nThe high accuracy can be due to the class imbalance situation which is not fixed yet.","metadata":{}}]}