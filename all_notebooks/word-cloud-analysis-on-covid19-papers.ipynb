{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Coronavirus Online Paper Search by Using Keywords"},{"metadata":{},"cell_type":"markdown","source":"*by Yusuf Güven*"},{"metadata":{},"cell_type":"markdown","source":"This notebook helps to find most frequent words in the Kaggle coronavirus article database. The articles are eligible for search if they include all the keywords. The chosen article is splitted into words and frequency of each word is counted among all eligible article group. The most frequent words are listed and visualized in a wordcloud."},{"metadata":{},"cell_type":"markdown","source":"Red colored fonts shows the parameters that can be set freely to reach the desired results."},{"metadata":{},"cell_type":"markdown","source":"## 1. Setting the Environment and Understanding the Data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory     \n# Any results you write to the current directory are saved as output.\n\nimport os\n\n# files is the dataframe that contains file name and full path of all json formatted articles.\nfiles=pd.DataFrame(columns=[\"name\",\"path\"])\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        files=files.append({\"name\":filename,\"path\":os.path.join(dirname, filename)}, ignore_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df is the dataframe of the metadata file given in the covid 19 open research database\ndf=pd.read_csv(\"../input/CORD-19-research-challenge/metadata.csv\")\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only .json files are needed for the analysis. Below the files with other extensions are removed from the data frame."},{"metadata":{"trusted":true},"cell_type":"code","source":"indices=files[files.name.str.contains(\".json\")==False].index \nfiles.drop(index=indices, inplace=True)\nfiles.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files.reset_index(inplace=True)\nfiles.drop(\"index\",axis=1, inplace=True)\nfiles.head(3) # We have name of the all files in json format and the path (including the name of the file).","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Seaching Through Files with Keywords"},{"metadata":{"trusted":true},"cell_type":"code","source":"# necessary modules for keyword search and visualization\nimport json\nfrom pandas.io.json import json_normalize\nimport collections\n#!pip install wordcloud \n# if not installed install wordcloud by uncommeting the above line\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nstopwords = set(STOPWORDS) #stopwords are the words like \"the\", \"he'll\", \"i\", etc that won't be used in the search.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Any keyword for the search can be added by separeting with commas. The search will look if all the words exist in the article. If one of them is missing the article is excluded in the search."},{"metadata":{},"cell_type":"markdown","source":"**<font color=\"red\"> Update the keywords below for iterations: </font>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"key_words=[\"pseudoknots\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This function searches the title and the body of the article for the keywords.\ndef article_search(path, key_words):\n    with open(path) as f:\n      article_json = json.load(f)\n    title = json_normalize(article_json['metadata'])\n    article = title.title[0].lower()+\"\\n\"\n    article_title = title.title[0].lower()\n    text = json_normalize(article_json['body_text']) \n    for j in range(text.shape[0]):\n        article=article+\"\\n\"+text.text[j].lower()\n    \n    # Check whether article contains all keywords\n    key_word_count = len(key_words)\n    article_chosen=False\n    for key_word in (key_words):\n        if key_word in article:\n            key_word_count -= 1\n    if key_word_count == 0:\n        article_chosen=True\n        return article_chosen, article_title, article\n    else:\n        return article_chosen, \"\", \"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The articles that contain all the keywords are eligible for the analysis. Each word in the selected articles are splitted and counted. At the end they are sorted from the most common word to the rarest one in a dictionary. Actually, last word(s) in the dictionary expected to be seen only once. "},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcount={} # defining dictionary\narticle_titles=[] # will be used for listing the selected articles at the end of the notebook\nfor i in range(files.shape[0]):\n    path=files.loc[i,\"path\"]\n    contains_keywords, article_title, article = article_search(path, key_words)\n    \n    if contains_keywords:\n        article_titles.append(article_title)\n        for word in article.split():\n            word = word.replace(\".\",\"\")\n            word = word.replace(\",\",\"\")\n            word = word.replace(\"\\\"\",\"\")\n            word = word.replace(\"“\",\"\")\n            word = word.replace(\"(\",\"\")\n            word = word.replace(\")\",\"\")\n            word = word.replace(\"<\",\"\")\n            word = word.replace(\">\",\"\")\n            if word not in stopwords:\n                if word not in wordcount:\n                    wordcount[word] = 1\n                else:\n                    wordcount[word] += 1\n            \nword_dict = collections.Counter(wordcount) # final dictionary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(word_dict) # number of words in the dictionary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<font color=\"red\"> Update the starting and ending words range below for iterations: </font>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = 0 #starting number of word. 0 is most common. Negative values can be given to search from the rarest words.\nend = 100 #ending number of word. It should be greater than start","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The list of words in selected range are listed below. It's possible to look for the rare words also by determining the range accordingly. Important rare words shoud be added to the keywords to look them in the other articles. The search can be iterative by changing the keywords and dictionary range."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor word, count in word_dict.most_common()[start:end]:\n    print(word, \": \", count)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Visualization"},{"metadata":{},"cell_type":"markdown","source":"The code below blocks create a word cloud of the words in the selected range above to visualize the search."},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate a word cloud object\nword_cloud_source=\"\"\nfor word, count in word_dict.most_common()[start:end]:\n    word_cloud_source=word_cloud_source+(word+\" \")*count\n\nword_cloud = WordCloud(\n    background_color='white',\n    max_words=abs(end-start),\n    stopwords=stopwords,\n    collocations=False\n)\n\n# generate the word cloud\nword_cloud.generate(word_cloud_source)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display the cloud\nfig = plt.figure()\nfig.set_figwidth(30) # set width\nfig.set_figheight(25) # set height\n\nplt.imshow(word_cloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## 4. The List of Related Articles"},{"metadata":{},"cell_type":"markdown","source":"When the second part generated desired results it is possible to look for the details of the articles selected. Below code will generate this list."},{"metadata":{"trusted":true},"cell_type":"code","source":"indices = df[df.title.str.lower().isin(article_titles)].index\nindices\ndf.loc[indices]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of files in the data directory is larger than the articles listed in metadata csv. Because of this reason these is check below which controls if any other article remained in article titles. And remaining titles, the titles exists in the file directory but not exist in the metadata file, are listed below:"},{"metadata":{"trusted":true},"cell_type":"code","source":"remaining_titles=pd.Series(article_titles)\nremaining_indices= remaining_titles[~remaining_titles.isin(df.loc[indices,\"title\"].str.lower())]\nremaining_titles.loc[remaining_indices]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}