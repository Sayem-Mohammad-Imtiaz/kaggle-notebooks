{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 创建输出文件夹********"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\nos.mkdir('./train_ttf')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ****# bboxes变换"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import cv2 \nimport numpy as np\n\n\ndef draw_rect(im, cords, color = None):\n    \"\"\"Draw the rectangle on the image\n    \n    Parameters\n    ----------\n    \n    im : numpy.ndarray\n        numpy image \n    \n    cords: numpy.ndarray\n        Numpy array containing bounding boxes of shape `N X 4` where N is the \n        number of bounding boxes and the bounding boxes are represented in the\n        format `x1 y1 x2 y2`\n        \n    Returns\n    -------\n    \n    numpy.ndarray\n        numpy image with bounding boxes drawn on it\n        \n    \"\"\"\n    \n    im = im.copy()\n    \n    cords = cords[:,:4]\n    cords = cords.reshape(-1,4)\n    if not color:\n        color = [255,255,255]\n    for cord in cords:\n        \n        pt1, pt2 = (cord[0], cord[1]) , (cord[2], cord[3])\n                \n        pt1 = int(pt1[0]), int(pt1[1])\n        pt2 = int(pt2[0]), int(pt2[1])\n    \n        im = cv2.rectangle(im.copy(), pt1, pt2, color, int(max(im.shape[:2])/200))\n    return im\n\ndef bbox_area(bbox):\n    return (bbox[:,2] - bbox[:,0])*(bbox[:,3] - bbox[:,1])\n        \ndef clip_box(bbox, clip_box, alpha):\n    \"\"\"Clip the bounding boxes to the borders of an image\n    \n    Parameters\n    ----------\n    \n    bbox: numpy.ndarray\n        Numpy array containing bounding boxes of shape `N X 4` where N is the \n        number of bounding boxes and the bounding boxes are represented in the\n        format `x1 y1 x2 y2`\n    \n    clip_box: numpy.ndarray\n        An array of shape (4,) specifying the diagonal co-ordinates of the image\n        The coordinates are represented in the format `x1 y1 x2 y2`\n        \n    alpha: float\n        If the fraction of a bounding box left in the image after being clipped is \n        less than `alpha` the bounding box is dropped. \n    \n    Returns\n    -------\n    \n    numpy.ndarray\n        Numpy array containing **clipped** bounding boxes of shape `N X 4` where N is the \n        number of bounding boxes left are being clipped and the bounding boxes are represented in the\n        format `x1 y1 x2 y2` \n    \n    \"\"\"\n    ar_ = (bbox_area(bbox))\n    x_min = np.maximum(bbox[:,0], clip_box[0]).reshape(-1,1)\n    y_min = np.maximum(bbox[:,1], clip_box[1]).reshape(-1,1)\n    x_max = np.minimum(bbox[:,2], clip_box[2]).reshape(-1,1)\n    y_max = np.minimum(bbox[:,3], clip_box[3]).reshape(-1,1)\n    \n    bbox = np.hstack((x_min, y_min, x_max, y_max, bbox[:,4:]))\n    \n    delta_area = ((ar_ - bbox_area(bbox))/ar_)\n    \n    mask = (delta_area < (1 - alpha)).astype(int)\n    \n    bbox = bbox[mask == 1,:]\n\n\n    return bbox\n\n\ndef rotate_im(image, angle):\n    \"\"\"Rotate the image.\n    \n    Rotate the image such that the rotated image is enclosed inside the tightest\n    rectangle. The area not occupied by the pixels of the original image is colored\n    black. \n    \n    Parameters\n    ----------\n    \n    image : numpy.ndarray\n        numpy image\n    \n    angle : float\n        angle by which the image is to be rotated\n    \n    Returns\n    -------\n    \n    numpy.ndarray\n        Rotated Image\n    \n    \"\"\"\n    # grab the dimensions of the image and then determine the\n    # centre\n    (h, w) = image.shape[:2]\n    (cX, cY) = (w // 2, h // 2)\n\n    # grab the rotation matrix (applying the negative of the\n    # angle to rotate clockwise), then grab the sine and cosine\n    # (i.e., the rotation components of the matrix)\n    M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n    cos = np.abs(M[0, 0])\n    sin = np.abs(M[0, 1])\n\n    # compute the new bounding dimensions of the image\n    nW = int((h * sin) + (w * cos))\n    nH = int((h * cos) + (w * sin))\n\n    # adjust the rotation matrix to take into account translation\n    M[0, 2] += (nW / 2) - cX\n    M[1, 2] += (nH / 2) - cY\n\n    # perform the actual rotation and return the image\n    image = cv2.warpAffine(image, M, (nW, nH))\n\n#    image = cv2.resize(image, (w,h))\n    return image\n\ndef get_corners(bboxes):\n    \n    \"\"\"Get corners of bounding boxes\n    \n    Parameters\n    ----------\n    \n    bboxes: numpy.ndarray\n        Numpy array containing bounding boxes of shape `N X 4` where N is the \n        number of bounding boxes and the bounding boxes are represented in the\n        format `x1 y1 x2 y2`\n    \n    returns\n    -------\n    \n    numpy.ndarray\n        Numpy array of shape `N x 8` containing N bounding boxes each described by their \n        corner co-ordinates `x1 y1 x2 y2 x3 y3 x4 y4`      \n        \n    \"\"\"\n    width = (bboxes[:,2] - bboxes[:,0]).reshape(-1,1)\n    height = (bboxes[:,3] - bboxes[:,1]).reshape(-1,1)\n    \n    x1 = bboxes[:,0].reshape(-1,1)\n    y1 = bboxes[:,1].reshape(-1,1)\n    \n    x2 = x1 + width\n    y2 = y1 \n    \n    x3 = x1\n    y3 = y1 + height\n    \n    x4 = bboxes[:,2].reshape(-1,1)\n    y4 = bboxes[:,3].reshape(-1,1)\n    \n    corners = np.hstack((x1,y1,x2,y2,x3,y3,x4,y4))\n    \n    return corners\n\ndef rotate_box(corners,angle,  cx, cy, h, w):\n    \n    \"\"\"Rotate the bounding box.\n    \n    \n    Parameters\n    ----------\n    \n    corners : numpy.ndarray\n        Numpy array of shape `N x 8` containing N bounding boxes each described by their \n        corner co-ordinates `x1 y1 x2 y2 x3 y3 x4 y4`\n    \n    angle : float\n        angle by which the image is to be rotated\n        \n    cx : int\n        x coordinate of the center of image (about which the box will be rotated)\n        \n    cy : int\n        y coordinate of the center of image (about which the box will be rotated)\n        \n    h : int \n        height of the image\n        \n    w : int \n        width of the image\n    \n    Returns\n    -------\n    \n    numpy.ndarray\n        Numpy array of shape `N x 8` containing N rotated bounding boxes each described by their \n        corner co-ordinates `x1 y1 x2 y2 x3 y3 x4 y4`\n    \"\"\"\n\n    corners = corners.reshape(-1,2)\n    corners = np.hstack((corners, np.ones((corners.shape[0],1), dtype = type(corners[0][0]))))\n    \n    M = cv2.getRotationMatrix2D((cx, cy), angle, 1.0)\n    \n    \n    cos = np.abs(M[0, 0])\n    sin = np.abs(M[0, 1])\n    \n    nW = int((h * sin) + (w * cos))\n    nH = int((h * cos) + (w * sin))\n    # adjust the rotation matrix to take into account translation\n    M[0, 2] += (nW / 2) - cx\n    M[1, 2] += (nH / 2) - cy\n    # Prepare the vector to be transformed\n    calculated = np.dot(M,corners.T).T\n    \n    calculated = calculated.reshape(-1,8)\n    \n    return calculated\n\n\ndef get_enclosing_box(corners):\n    \"\"\"Get an enclosing box for ratated corners of a bounding box\n    \n    Parameters\n    ----------\n    \n    corners : numpy.ndarray\n        Numpy array of shape `N x 8` containing N bounding boxes each described by their \n        corner co-ordinates `x1 y1 x2 y2 x3 y3 x4 y4`  \n    \n    Returns \n    -------\n    \n    numpy.ndarray\n        Numpy array containing enclosing bounding boxes of shape `N X 4` where N is the \n        number of bounding boxes and the bounding boxes are represented in the\n        format `x1 y1 x2 y2`\n        \n    \"\"\"\n    x_ = corners[:,[0,2,4,6]]\n    y_ = corners[:,[1,3,5,7]]\n    \n    xmin = np.min(x_,1).reshape(-1,1)\n    ymin = np.min(y_,1).reshape(-1,1)\n    xmax = np.max(x_,1).reshape(-1,1)\n    ymax = np.max(y_,1).reshape(-1,1)\n    \n    final = np.hstack((xmin, ymin, xmax, ymax,corners[:,8:]))\n    \n    return final\n\n\ndef letterbox_image(img, inp_dim):\n    '''resize image with unchanged aspect ratio using padding\n    \n    Parameters\n    ----------\n    \n    img : numpy.ndarray\n        Image \n    \n    inp_dim: tuple(int)\n        shape of the reszied image\n        \n    Returns\n    -------\n    \n    numpy.ndarray:\n        Resized image\n    \n    '''\n\n    inp_dim = (inp_dim, inp_dim)\n    img_w, img_h = img.shape[1], img.shape[0]\n    w, h = inp_dim\n    new_w = int(img_w * min(w/img_w, h/img_h))\n    new_h = int(img_h * min(w/img_w, h/img_h))\n    resized_image = cv2.resize(img, (new_w,new_h))\n    \n    canvas = np.full((inp_dim[1], inp_dim[0], 3), 0)\n\n    canvas[(h-new_h)//2:(h-new_h)//2 + new_h,(w-new_w)//2:(w-new_w)//2 + new_w,  :] = resized_image\n    \n    return canvas","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # # Aug变换****"},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport sys\nimport os\n\nlib_path = os.path.join(os.path.realpath(\".\"), \"data_aug\")\nsys.path.append(lib_path)\n\n\nclass RandomHorizontalFlip(object):\n\n    \"\"\"Randomly horizontally flips the Image with the probability *p*\n\n    Parameters\n    ----------\n    p: float\n        The probability with which the image is flipped\n\n\n    Returns\n    -------\n\n    numpy.ndaaray\n        Flipped image in the numpy format of shape `HxWxC`\n\n    numpy.ndarray\n        Tranformed bounding box co-ordinates of the format `n x 4` where n is\n        number of bounding boxes and 4 represents `x1,y1,x2,y2` of the box\n\n    \"\"\"\n\n    def __init__(self, p=0.5):\n        self.p = p\n\n    def __call__(self, img, bboxes):\n            img_center = np.array(img.shape[:2])[::-1]/2\n            img_center = np.hstack((img_center, img_center))\n            if random.random() < self.p:\n                img = img[:, ::-1, :]\n                bboxes[:, [0, 2]] += 2*(img_center[[0, 2]] - bboxes[:, [0, 2]])\n\n                box_w = abs(bboxes[:, 0] - bboxes[:, 2])\n\n                bboxes[:, 0] -= box_w\n                bboxes[:, 2] += box_w\n\n            return img, bboxes\n\n\nclass HorizontalFlip(object):\n\n    \"\"\"Randomly horizontally flips the Image with the probability *p*\n\n    Parameters\n    ----------\n    p: float\n        The probability with which the image is flipped\n\n\n    Returns\n    -------\n\n    numpy.ndaaray\n        Flipped image in the numpy format of shape `HxWxC`\n\n    numpy.ndarray\n        Tranformed bounding box co-ordinates of the format `n x 4` where n is\n        number of bounding boxes and 4 represents `x1,y1,x2,y2` of the box\n\n    \"\"\"\n\n    def __init__(self):\n        pass\n\n    def __call__(self, img, bboxes):\n        img_center = np.array(img.shape[:2])[::-1]/2\n        img_center = np.hstack((img_center, img_center))\n\n        img = img[:, ::-1, :]\n        bboxes[:, [0, 2]] += 2*(img_center[[0, 2]] - bboxes[:, [0, 2]])\n\n        box_w = abs(bboxes[:, 0] - bboxes[:, 2])\n\n        bboxes[:, 0] -= box_w\n        bboxes[:, 2] += box_w\n\n        return img, bboxes\n\n\nclass RandomScale(object):\n    \"\"\"Randomly scales an image    \n    \n    \n    Bounding boxes which have an area of less than 25% in the remaining in the \n    transformed image is dropped. The resolution is maintained, and the remaining\n    area if any is filled by black color.\n    \n    Parameters\n    ----------\n    scale: float or tuple(float)\n        if **float**, the image is scaled by a factor drawn \n        randomly from a range (1 - `scale` , 1 + `scale`). If **tuple**,\n        the `scale` is drawn randomly from values specified by the \n        tuple\n        \n    Returns\n    -------\n    \n    numpy.ndaaray\n        Scaled image in the numpy format of shape `HxWxC`\n    \n    numpy.ndarray\n        Tranformed bounding box co-ordinates of the format `n x 4` where n is \n        number of bounding boxes and 4 represents `x1,y1,x2,y2` of the box\n        \n    \"\"\"\n\n    def __init__(self, scale = 0.2, diff = False):\n        self.scale = scale\n\n        \n        if type(self.scale) == tuple:\n            assert len(self.scale) == 2, \"Invalid range\"\n            assert self.scale[0] > -1, \"Scale factor can't be less than -1\"\n            assert self.scale[1] > -1, \"Scale factor can't be less than -1\"\n        else:\n            assert self.scale > 0, \"Please input a positive float\"\n            self.scale = (max(-1, -self.scale), self.scale)\n        \n        self.diff = diff\n\n        \n\n    def __call__(self, img, bboxes):\n    \n        \n        #Chose a random digit to scale by \n        \n        img_shape = img.shape\n        \n        if self.diff:\n            scale_x = random.uniform(*self.scale)\n            scale_y = random.uniform(*self.scale)\n        else:\n            scale_x = random.uniform(*self.scale)\n            scale_y = scale_x\n            \n    \n        \n        resize_scale_x = 1 + scale_x\n        resize_scale_y = 1 + scale_y\n        \n        img=  cv2.resize(img, None, fx = resize_scale_x, fy = resize_scale_y)\n        \n        bboxes[:,:4] *= [resize_scale_x, resize_scale_y, resize_scale_x, resize_scale_y]\n        \n        \n        \n        canvas = np.zeros(img_shape, dtype = np.uint8)\n        \n        y_lim = int(min(resize_scale_y,1)*img_shape[0])\n        x_lim = int(min(resize_scale_x,1)*img_shape[1])\n        \n        \n        canvas[:y_lim,:x_lim,:] =  img[:y_lim,:x_lim,:]\n        \n        img = canvas\n        bboxes = clip_box(bboxes, [0,0,1 + img_shape[1], img_shape[0]], 0.25)\n    \n    \n        return img, bboxes\n\n\nclass Scale(object):\n    \"\"\"Scales the image    \n        \n    Bounding boxes which have an area of less than 25% in the remaining in the \n    transformed image is dropped. The resolution is maintained, and the remaining\n    area if any is filled by black color.\n    \n    \n    Parameters\n    ----------\n    scale_x: float\n        The factor by which the image is scaled horizontally\n        \n    scale_y: float\n        The factor by which the image is scaled vertically\n        \n    Returns\n    -------\n    \n    numpy.ndaaray\n        Scaled image in the numpy format of shape `HxWxC`\n    \n    numpy.ndarray\n        Tranformed bounding box co-ordinates of the format `n x 4` where n is \n        number of bounding boxes and 4 represents `x1,y1,x2,y2` of the box\n        \n    \"\"\"\n\n    def __init__(self, scale_x = 0.2, scale_y = 0.2):\n        self.scale_x = scale_x\n        self.scale_y = scale_y\n        \n\n    def __call__(self, img, bboxes):\n    \n        \n        #Chose a random digit to scale by \n        \n        img_shape = img.shape\n        \n        \n        resize_scale_x = 1 + self.scale_x\n        resize_scale_y = 1 + self.scale_y\n        \n        img=  cv2.resize(img, None, fx = resize_scale_x, fy = resize_scale_y)\n        \n        bboxes[:,:4] *= [resize_scale_x, resize_scale_y, resize_scale_x, resize_scale_y]\n        \n        \n        \n        canvas = np.zeros(img_shape, dtype = np.uint8)\n        \n        y_lim = int(min(resize_scale_y,1)*img_shape[0])\n        x_lim = int(min(resize_scale_x,1)*img_shape[1])\n        \n        \n        canvas[:y_lim,:x_lim,:] =  img[:y_lim,:x_lim,:]\n        \n        img = canvas\n        bboxes = clip_box(bboxes, [0,0,1 + img_shape[1], img_shape[0]], 0.25)\n\n    \n        return img, bboxes  \n    \n\nclass RandomTranslate(object):\n    \"\"\"Randomly Translates the image    \n    \n    \n    Bounding boxes which have an area of less than 25% in the remaining in the \n    transformed image is dropped. The resolution is maintained, and the remaining\n    area if any is filled by black color.\n    \n    Parameters\n    ----------\n    translate: float or tuple(float)\n        if **float**, the image is translated by a factor drawn \n        randomly from a range (1 - `translate` , 1 + `translate`). If **tuple**,\n        `translate` is drawn randomly from values specified by the \n        tuple\n        \n    Returns\n    -------\n    \n    numpy.ndaaray\n        Translated image in the numpy format of shape `HxWxC`\n    \n    numpy.ndarray\n        Tranformed bounding box co-ordinates of the format `n x 4` where n is \n        number of bounding boxes and 4 represents `x1,y1,x2,y2` of the box\n        \n    \"\"\"\n\n    def __init__(self, translate = 0.2, diff = False):\n        self.translate = translate\n        \n        if type(self.translate) == tuple:\n            assert len(self.translate) == 2, \"Invalid range\"  \n            assert self.translate[0] > 0 & self.translate[0] < 1\n            assert self.translate[1] > 0 & self.translate[1] < 1\n\n\n        else:\n            assert self.translate > 0 and self.translate < 1\n            self.translate = (-self.translate, self.translate)\n            \n            \n        self.diff = diff\n\n    def __call__(self, img, bboxes):        \n        #Chose a random digit to scale by \n        img_shape = img.shape\n        \n        #translate the image\n        \n        #percentage of the dimension of the image to translate\n        translate_factor_x = random.uniform(*self.translate)\n        translate_factor_y = random.uniform(*self.translate)\n        \n        if not self.diff:\n            translate_factor_y = translate_factor_x\n            \n        canvas = np.zeros(img_shape).astype(np.uint8)\n    \n    \n        corner_x = int(translate_factor_x*img.shape[1])\n        corner_y = int(translate_factor_y*img.shape[0])\n        \n        \n        \n        #change the origin to the top-left corner of the translated box\n        orig_box_cords =  [max(0,corner_y), max(corner_x,0), min(img_shape[0], corner_y + img.shape[0]), min(img_shape[1],corner_x + img.shape[1])]\n    \n        \n        \n    \n        mask = img[max(-corner_y, 0):min(img.shape[0], -corner_y + img_shape[0]), max(-corner_x, 0):min(img.shape[1], -corner_x + img_shape[1]),:]\n        canvas[orig_box_cords[0]:orig_box_cords[2], orig_box_cords[1]:orig_box_cords[3],:] = mask\n        img = canvas\n        \n        bboxes[:,:4] += [corner_x, corner_y, corner_x, corner_y]\n        \n        \n        bboxes = clip_box(bboxes, [0,0,img_shape[1], img_shape[0]], 0.25)\n        \n    \n        \n    \n        \n        return img, bboxes\n    \n\nclass Translate(object):\n    \"\"\"Randomly Translates the image    \n    \n    \n    Bounding boxes which have an area of less than 25% in the remaining in the \n    transformed image is dropped. The resolution is maintained, and the remaining\n    area if any is filled by black color.\n    \n    Parameters\n    ----------\n    translate: float or tuple(float)\n        if **float**, the image is translated by a factor drawn \n        randomly from a range (1 - `translate` , 1 + `translate`). If **tuple**,\n        `translate` is drawn randomly from values specified by the \n        tuple\n        \n    Returns\n    -------\n    \n    numpy.ndaaray\n        Translated image in the numpy format of shape `HxWxC`\n    \n    numpy.ndarray\n        Tranformed bounding box co-ordinates of the format `n x 4` where n is \n        number of bounding boxes and 4 represents `x1,y1,x2,y2` of the box\n        \n    \"\"\"\n\n    def __init__(self, translate_x = 0.2, translate_y = 0.2, diff = False):\n        self.translate_x = translate_x\n        self.translate_y = translate_y\n\n        assert self.translate_x > 0 and self.translate_x < 1\n        assert self.translate_y > 0 and self.translate_y < 1\n \n\n    def __call__(self, img, bboxes):        \n        #Chose a random digit to scale by \n        img_shape = img.shape\n        \n        #translate the image\n        \n        #percentage of the dimension of the image to translate\n        translate_factor_x = self.translate_x\n        translate_factor_y = self.translate_y\n        \n            \n        canvas = np.zeros(img_shape).astype(np.uint8)\n\n        \n        #get the top-left corner co-ordinates of the shifted box \n        corner_x = int(translate_factor_x*img.shape[1])\n        corner_y = int(translate_factor_y*img.shape[0])\n        \n        \n        \n        #change the origin to the top-left corner of the translated box\n        orig_box_cords =  [max(0,corner_y), max(corner_x,0), min(img_shape[0], corner_y + img.shape[0]), min(img_shape[1],corner_x + img.shape[1])]\n\n        \n        \n\n        mask = img[max(-corner_y, 0):min(img.shape[0], -corner_y + img_shape[0]), max(-corner_x, 0):min(img.shape[1], -corner_x + img_shape[1]),:]\n        canvas[orig_box_cords[0]:orig_box_cords[2], orig_box_cords[1]:orig_box_cords[3],:] = mask\n        img = canvas\n        \n        bboxes[:,:4] += [corner_x, corner_y, corner_x, corner_y]\n        \n        \n        bboxes = clip_box(bboxes, [0,0,img_shape[1], img_shape[0]], 0.25)\n        \n\n        \n\n        \n        return img, bboxes\n    \n    \nclass RandomRotate(object):\n    \"\"\"Randomly rotates an image    \n    \n    \n    Bounding boxes which have an area of less than 25% in the remaining in the \n    transformed image is dropped. The resolution is maintained, and the remaining\n    area if any is filled by black color.\n    \n    Parameters\n    ----------\n    angle: float or tuple(float)\n        if **float**, the image is rotated by a factor drawn \n        randomly from a range (-`angle`, `angle`). If **tuple**,\n        the `angle` is drawn randomly from values specified by the \n        tuple\n        \n    Returns\n    -------\n    \n    numpy.ndaaray\n        Rotated image in the numpy format of shape `HxWxC`\n    \n    numpy.ndarray\n        Tranformed bounding box co-ordinates of the format `n x 4` where n is \n        number of bounding boxes and 4 represents `x1,y1,x2,y2` of the box\n        \n    \"\"\"\n\n    def __init__(self, angle = 10):\n        self.angle = angle\n        \n        if type(self.angle) == tuple:\n            assert len(self.angle) == 2, \"Invalid range\"  \n            \n        else:\n            self.angle = (-self.angle, self.angle)\n            \n    def __call__(self, img, bboxes):\n    \n        angle = random.uniform(*self.angle)\n    \n        w,h = img.shape[1], img.shape[0]\n        cx, cy = w//2, h//2\n    \n        img = rotate_im(img, angle)\n    \n        corners = get_corners(bboxes)\n    \n        corners = np.hstack((corners, bboxes[:,4:]))\n    \n    \n        corners[:,:8] = rotate_box(corners[:,:8], angle, cx, cy, h, w)\n    \n        new_bbox = get_enclosing_box(corners)\n    \n    \n        scale_factor_x = img.shape[1] / w\n    \n        scale_factor_y = img.shape[0] / h\n    \n        img = cv2.resize(img, (w,h))\n    \n        new_bbox[:,:4] /= [scale_factor_x, scale_factor_y, scale_factor_x, scale_factor_y] \n    \n        bboxes  = new_bbox\n    \n        bboxes = clip_box(bboxes, [0,0,w, h], 0.25)\n    \n        return img, bboxes\n\n    \nclass Rotate(object):\n    \"\"\"Rotates an image    \n    \n    \n    Bounding boxes which have an area of less than 25% in the remaining in the \n    transformed image is dropped. The resolution is maintained, and the remaining\n    area if any is filled by black color.\n    \n    Parameters\n    ----------\n    angle: float\n        The angle by which the image is to be rotated \n        \n        \n    Returns\n    -------\n    \n    numpy.ndaaray\n        Rotated image in the numpy format of shape `HxWxC`\n    \n    numpy.ndarray\n        Tranformed bounding box co-ordinates of the format `n x 4` where n is \n        number of bounding boxes and 4 represents `x1,y1,x2,y2` of the box\n        \n    \"\"\"\n\n    def __init__(self, angle):\n        self.angle = angle\n        \n\n    def __call__(self, img, bboxes):\n        \"\"\"\n        Args:\n            img (PIL Image): Image to be flipped.\n\n        Returns:\n            PIL Image: Randomly flipped image.\n            \n            \n        \"\"\"\n        \n        angle = self.angle\n        print(self.angle)\n        \n        w,h = img.shape[1], img.shape[0]\n        cx, cy = w//2, h//2\n        \n        corners = get_corners(bboxes)\n        \n        corners = np.hstack((corners, bboxes[:,4:]))\n\n        img = rotate_im(img, angle)\n        \n        corners[:,:8] = rotate_box(corners[:,:8], angle, cx, cy, h, w)\n        \n        \n        \n        \n        new_bbox = get_enclosing_box(corners)\n        \n        \n        scale_factor_x = img.shape[1] / w\n        \n        scale_factor_y = img.shape[0] / h\n        \n        img = cv2.resize(img, (w,h))\n        \n        new_bbox[:,:4] /= [scale_factor_x, scale_factor_y, scale_factor_x, scale_factor_y] \n        \n        \n        bboxes  = new_bbox\n\n        bboxes = clip_box(bboxes, [0,0,w, h], 0.25)\n        \n        return img, bboxes\n        \n\n\nclass RandomShear(object):\n    \"\"\"Randomly shears an image in horizontal direction   \n    \n    \n    Bounding boxes which have an area of less than 25% in the remaining in the \n    transformed image is dropped. The resolution is maintained, and the remaining\n    area if any is filled by black color.\n    \n    Parameters\n    ----------\n    shear_factor: float or tuple(float)\n        if **float**, the image is sheared horizontally by a factor drawn \n        randomly from a range (-`shear_factor`, `shear_factor`). If **tuple**,\n        the `shear_factor` is drawn randomly from values specified by the \n        tuple\n        \n    Returns\n    -------\n    \n    numpy.ndaaray\n        Sheared image in the numpy format of shape `HxWxC`\n    \n    numpy.ndarray\n        Tranformed bounding box co-ordinates of the format `n x 4` where n is \n        number of bounding boxes and 4 represents `x1,y1,x2,y2` of the box\n        \n    \"\"\"\n\n    def __init__(self, shear_factor = 0.2):\n        self.shear_factor = shear_factor\n        \n        if type(self.shear_factor) == tuple:\n            assert len(self.shear_factor) == 2, \"Invalid range for scaling factor\"   \n        else:\n            self.shear_factor = (-self.shear_factor, self.shear_factor)\n        \n        shear_factor = random.uniform(*self.shear_factor)\n        \n    def __call__(self, img, bboxes):\n    \n        shear_factor = random.uniform(*self.shear_factor)\n    \n        w,h = img.shape[1], img.shape[0]\n    \n        if shear_factor < 0:\n            img, bboxes = HorizontalFlip()(img, bboxes)\n    \n        M = np.array([[1, abs(shear_factor), 0],[0,1,0]])\n    \n        nW =  img.shape[1] + abs(shear_factor*img.shape[0])\n    \n        bboxes[:,[0,2]] += ((bboxes[:,[1,3]]) * abs(shear_factor) ).astype(int) \n    \n    \n        img = cv2.warpAffine(img, M, (int(nW), img.shape[0]))\n    \n        if shear_factor < 0:\n        \timg, bboxes = HorizontalFlip()(img, bboxes)\n    \n        img = cv2.resize(img, (w,h))\n    \n        scale_factor_x = nW / w\n    \n        bboxes[:,:4] /= [scale_factor_x, 1, scale_factor_x, 1] \n    \n    \n        return img, bboxes\n        \nclass Shear(object):\n    \"\"\"Shears an image in horizontal direction   \n    \n    \n    Bounding boxes which have an area of less than 25% in the remaining in the \n    transformed image is dropped. The resolution is maintained, and the remaining\n    area if any is filled by black color.\n    \n    Parameters\n    ----------\n    shear_factor: float\n        Factor by which the image is sheared in the x-direction\n       \n    Returns\n    -------\n    \n    numpy.ndaaray\n        Sheared image in the numpy format of shape `HxWxC`\n    \n    numpy.ndarray\n        Tranformed bounding box co-ordinates of the format `n x 4` where n is \n        number of bounding boxes and 4 represents `x1,y1,x2,y2` of the box\n        \n    \"\"\"\n\n    def __init__(self, shear_factor = 0.2):\n        self.shear_factor = shear_factor\n        \n    \n    def __call__(self, img, bboxes):\n        \n        shear_factor = self.shear_factor\n        if shear_factor < 0:\n            img, bboxes = HorizontalFlip()(img, bboxes)\n\n        \n        M = np.array([[1, abs(shear_factor), 0],[0,1,0]])\n                \n        nW =  img.shape[1] + abs(shear_factor*img.shape[0])\n        \n        bboxes[:,[0,2]] += ((bboxes[:,[1,3]])*abs(shear_factor)).astype(int) \n        \n\n        img = cv2.warpAffine(img, M, (int(nW), img.shape[0]))\n        \n        if shear_factor < 0:\n             img, bboxes = HorizontalFlip()(img, bboxes)\n             \n        \n        return img, bboxes\n    \nclass Resize(object):\n    \"\"\"Resize the image in accordance to `image_letter_box` function in darknet \n    \n    The aspect ratio is maintained. The longer side is resized to the input \n    size of the network, while the remaining space on the shorter side is filled \n    with black color. **This should be the last transform**\n    \n    \n    Parameters\n    ----------\n    inp_dim : tuple(int)\n        tuple containing the size to which the image will be resized.\n        \n    Returns\n    -------\n    \n    numpy.ndaaray\n        Sheared image in the numpy format of shape `HxWxC`\n    \n    numpy.ndarray\n        Resized bounding box co-ordinates of the format `n x 4` where n is \n        number of bounding boxes and 4 represents `x1,y1,x2,y2` of the box\n        \n    \"\"\"\n    \n    def __init__(self, inp_dim):\n        self.inp_dim = inp_dim\n        \n    def __call__(self, img, bboxes):\n        w,h = img.shape[1], img.shape[0]\n        img = letterbox_image(img, self.inp_dim)\n    \n    \n        scale = min(self.inp_dim/h, self.inp_dim/w)\n        bboxes[:,:4] *= (scale)\n    \n        new_w = scale*w\n        new_h = scale*h\n        inp_dim = self.inp_dim   \n    \n        del_h = (inp_dim - new_h)/2\n        del_w = (inp_dim - new_w)/2\n    \n        add_matrix = np.array([[del_w, del_h, del_w, del_h]]).astype(int)\n    \n        bboxes[:,:4] += add_matrix\n    \n        img = img.astype(np.uint8)\n    \n        return img, bboxes \n    \n\nclass RandomHSV(object):\n    \"\"\"HSV Transform to vary hue saturation and brightness\n    \n    Hue has a range of 0-179\n    Saturation and Brightness have a range of 0-255. \n    Chose the amount you want to change thhe above quantities accordingly. \n    \n    \n    \n    \n    Parameters\n    ----------\n    hue : None or int or tuple (int)\n        If None, the hue of the image is left unchanged. If int, \n        a random int is uniformly sampled from (-hue, hue) and added to the \n        hue of the image. If tuple, the int is sampled from the range \n        specified by the tuple.   \n        \n    saturation : None or int or tuple(int)\n        If None, the saturation of the image is left unchanged. If int, \n        a random int is uniformly sampled from (-saturation, saturation) \n        and added to the hue of the image. If tuple, the int is sampled\n        from the range  specified by the tuple.   \n        \n    brightness : None or int or tuple(int)\n        If None, the brightness of the image is left unchanged. If int, \n        a random int is uniformly sampled from (-brightness, brightness) \n        and added to the hue of the image. If tuple, the int is sampled\n        from the range  specified by the tuple.   \n    \n    Returns\n    -------\n    \n    numpy.ndaaray\n        Transformed image in the numpy format of shape `HxWxC`\n    \n    numpy.ndarray\n        Resized bounding box co-ordinates of the format `n x 4` where n is \n        number of bounding boxes and 4 represents `x1,y1,x2,y2` of the box\n        \n    \"\"\"\n    \n    def __init__(self, hue = None, saturation = None, brightness = None):\n        if hue:\n            self.hue = hue \n        else:\n            self.hue = 0\n            \n        if saturation:\n            self.saturation = saturation \n        else:\n            self.saturation = 0\n            \n        if brightness:\n            self.brightness = brightness\n        else:\n            self.brightness = 0\n            \n            \n\n        if type(self.hue) != tuple:\n            self.hue = (-self.hue, self.hue)\n            \n        if type(self.saturation) != tuple:\n            self.saturation = (-self.saturation, self.saturation)\n        \n        if type(brightness) != tuple:\n            self.brightness = (-self.brightness, self.brightness)\n    \n    def __call__(self, img, bboxes):\n\n        hue = random.randint(*self.hue)\n        saturation = random.randint(*self.saturation)\n        brightness = random.randint(*self.brightness)\n        \n        img = img.astype(int)\n        \n        a = np.array([hue, saturation, brightness]).astype(int)\n        img += np.reshape(a, (1,1,3))\n        \n        img = np.clip(img, 0, 255)\n        img[:,:,0] = np.clip(img[:,:,0],0, 179)\n        \n        img = img.astype(np.uint8)\n\n        \n        \n        return img, bboxes\n    \nclass Sequence(object):\n\n    \"\"\"Initialise Sequence object\n    \n    Apply a Sequence of transformations to the images/boxes.\n    \n    Parameters\n    ----------\n    augemnetations : list \n        List containing Transformation Objects in Sequence they are to be \n        applied\n    \n    probs : int or list \n        If **int**, the probability with which each of the transformation will \n        be applied. If **list**, the length must be equal to *augmentations*. \n        Each element of this list is the probability with which each \n        corresponding transformation is applied\n    \n    Returns\n    -------\n    \n    Sequence\n        Sequence Object \n        \n    \"\"\"\n    def __init__(self, augmentations, probs = 1):\n\n        \n        self.augmentations = augmentations\n        self.probs = probs\n        \n    def __call__(self, images, bboxes):\n        for i, augmentation in enumerate(self.augmentations):\n            if type(self.probs) == list:\n                prob = self.probs[i]\n            else:\n                prob = self.probs\n                \n            if random.random() < prob:\n                images, bboxes = augmentation(images, bboxes)\n        return images, bboxes\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ****TTF操作（作展示用）"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport cv2 \nimport matplotlib.pyplot as plt \nimport pickle as pkl\n\n\"\"\"\n#使用TTA之前确保两件事情：1、将图片格式一定要是（HWC）的格式。\n                        2、box的格式（N, 5） #N是框数；5代表左上角x, 左上角y, 右下角x, 右下角y，类别。\n\"\"\"                     \n\nimg = cv2.imread(\"../input/ttf-github/DataAugmentationForObjectDetection-master/messi.jpg\")[:,:,::-1]   #opencv loads images in bgr. the [:,:,::-1] does bgr -> rgb\nbboxes = pkl.load(open(\"../input/ttf-github/DataAugmentationForObjectDetection-master/messi_ann.pkl\", \"rb\"))\n\nprint(img.shape)\n#inspect the bounding boxes\nprint(bboxes.shape)\nprint(bboxes)\n\n#origin(直接根据图片画框和label)\nplotted_img = draw_rect(img, bboxes)\nplt.imshow(plotted_img)\nplt.show()\n\n#随机水平翻转，参数p为翻转的概率。\nimg_, bboxes_ = RandomHorizontalFlip(p=1)(img.copy(), bboxes.copy())\nprint(bboxes_.shape)\nplotted_img = draw_rect(img_, bboxes_)\nplt.imshow(plotted_img)\n# plt.show()\n\n#随机放缩，随机放缩区间为（1-scale, 1+scale）, diff是是否等比例放缩 \nimg_, bboxes_ = RandomScale(scale = 0.3, diff = True)(img.copy(), bboxes.copy())\nplotted_img = draw_rect(img_, bboxes_)\nplt.imshow(plotted_img)\n# plt.show()\n\n#没看懂什么操作 有点类似于随机放缩\nimg_, bboxes_ = RandomTranslate(translate = 0.3, diff = True)(img.copy(), bboxes.copy())\nplotted_img = draw_rect(img_, bboxes_)\nplt.imshow(plotted_img)\n# plt.show()\n\n#随机旋转(-angle, +angle)\nimg_, bboxes_ = RandomRotate(angle = 20)(img.copy(), bboxes.copy())\nplotted_img = draw_rect(img_, bboxes_)\nplt.imshow(plotted_img)\n# plt.show()\n\n#水平裁剪(-shear_factor, +shear_factor)\nimg_, bboxes_ = RandomShear(shear_factor = 0.2)(img.copy(), bboxes.copy())\nplotted_img = draw_rect(img_, bboxes_)\nplt.imshow(plotted_img)\n# plt.show()\n\n#Resize，锁定长宽比, 参数为长边的resize后长度。（要放在最后面一个操作！！！）\nimg_, bboxes_ = Resize(608)(img.copy(), bboxes.copy())\nplotted_img = draw_rect(img_, bboxes_)\nplt.imshow(plotted_img)\nplt.show()\nprint(img.shape)\n\n#随机生成颜色HSV，如果参数是None,则不改变。如果是int，则（-int,+int）元组的话就是在元组范围内。H（0,179） S和B都是（0,255）\nimg_, bboxes_ = RandomHSV(100, 100, 100)(img.copy(), bboxes.copy())\nplotted_img = draw_rect(img_, bboxes_)\nplt.imshow(plotted_img)\nplt.show()\n\n#combine\nseq = Sequence([RandomHSV(40, 40, 30),RandomHorizontalFlip(), RandomScale(), RandomTranslate(), RandomRotate(10), RandomShear()])\nimg_, bboxes_ = seq(img.copy(), bboxes.copy())\nplotted_img = draw_rect(img_, bboxes_)\nplt.imshow(plotted_img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 对vinbigdagta数据变换****"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\ndim = 512 #512, 256, 'original'\nfold = 4\nimport cv2 \nimport matplotlib.pyplot as plt \nimport pickle as pkl\nfrom tqdm import tqdm\n\n#病名称和序号的字典建立\nbing_list = ['Aortic enlargement','Atelectasis','Calcification','Cardiomegaly','Consolidation','ILD','Infiltration','Lung Opacity','Nodule/Mass','Other lesion','Pleural effusion','Pleural thickening','Pneumothorax','Pulmonary fibrosis']\nid2word = {}\nword2id = {}\nfor i,data in enumerate(bing_list):\n    data=data.strip()\n    id2word[i]=data\n    word2id[data]=i\n\n#读取文件\ntrain_df = pd.read_csv('../input/vinbigdata-512-image-dataset/vinbigdata/train.csv')\n#获取图片路径\ntrain_df['image_path'] = f'../input/vinbigdata-512-image-dataset/vinbigdata/train/' + train_df.image_id+('.png' if dim!='original' else '.jpg')\n#去掉no finding\ntrain_df = train_df[train_df.class_id!=14].reset_index(drop = True)\n\n# 做归一化，把左上右下四个点的坐标，计算成中心点坐标和w/h，然后乘上现在的维度，还原成绝对坐标\ntrain_df['x_min'] = train_df.apply(lambda row: (row.x_min)/row.width * dim, axis =1)\ntrain_df['y_min'] = train_df.apply(lambda row: (row.y_min)/row.height * dim, axis =1)\n\ntrain_df['x_max'] = train_df.apply(lambda row: (row.x_max)/row.width * dim, axis =1)\ntrain_df['y_max'] = train_df.apply(lambda row: (row.y_max)/row.height * dim, axis =1)\n# print(train_df.head())\n\n\n#combine\nseq = Sequence([RandomHSV(40, 40, 30),RandomHorizontalFlip(), RandomScale(), RandomTranslate(), RandomRotate(5), RandomShear()])\n# seq = Sequence([RandomHSV(40, 40, 30),RandomHorizontalFlip(), RandomScale(), RandomTranslate(), RandomShear()])\n\n#建立小dataframe,i是指第几次调用，比如一张图我们要增广成2个。\ndef ttf_data(img, bboxes, i):\n    img_, bboxes_ = seq(img.copy(), bboxes.copy())#ttf变换\n    # plotted_img = draw_rect(img_, bboxes_)\n    # plt.imshow(plotted_img)\n    # plt.show()\n    df = pd.DataFrame(bboxes_, index=None, columns = ['x_min','y_min','x_max','y_max','class_id','rad_id', 'image_id','class_name'])\n    df['width'] = dim\n    df['height'] = dim\n    order = ['image_id', 'class_name', 'class_id','rad_id', 'x_min','y_min','x_max','y_max','width', 'height']\n    df = df[order]\n    df['image_path'] = './train_ttf/{}_ttf_{}.png'.format(df['image_id'].values[0], i)\n    cv2.imwrite(df['image_path'].values[0], img_[:,:,::-1]) #保存的时候恢复bgr的格式\n    # df['image_id'] = '7eda1e28e4cee7d8016276c87b76259f'\n    # df['class_name'] = df.apply(lambda row: id2word[row.class_id], axis=1)\n    return df\n\n#获取去掉nofinding后的所有有病的图片id\nimage_id_all = train_df['image_id'].unique()\n#创建空的df\ndf = pd.DataFrame()\n#记录增广失败的图片个数\nnum_error_photo = 0\nid_error_photo = []\nfor image_id in tqdm(image_id_all, desc='ttf loop', ncols=75):\n    try:\n        temp_df = train_df.loc[train_df['image_id'] == image_id]\n        img = cv2.imread(temp_df['image_path'].values[0])[:,:,::-1]   #opencv loads images in bgr. the [:,:,::-1] 最后一个维度是channel, does bgr -> rgb\n        bboxes = temp_df[['x_min','y_min','x_max','y_max','class_id','rad_id', 'image_id','class_name']].values #原图的盒子\n        print(image_id)\n        df1 = ttf_data(img, bboxes, 0)\n        df2 = ttf_data(img, bboxes, 1)\n        df = pd.concat([df,df1,df2], ignore_index= True) #忽略原始的index\n    except:\n        print('error: {}'.format(image_id))\n        num_error_photo += 1\n        id_error_photo.append(image_id) \n        pass\n\ndf.to_csv('./ttf_data.csv',index=0) #不保存行索引\nprint(df)\nprint('\\n转换完毕: {}张图片出错！'.format(num_error_photo))\nprint('错误的图片id: {}'.format(id_error_photo))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}