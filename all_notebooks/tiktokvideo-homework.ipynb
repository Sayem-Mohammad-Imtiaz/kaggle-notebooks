{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n# This notebook is the realization of a homework assigned to me in college.\n# The goal is to extract some analytics by formulating a series of queries \n# based on the data contained within this dataset.\n\n# The project involves the use of three different tools to answer the same \n# analytics: MongoDB, Neo4j and Apache Spark.\n# In this notebook I will implement the results obtained using Apache Spark.\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install pyspark","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import required modules\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nimport pandas as pd\nfrom wordcloud import WordCloud,STOPWORDS\nimport matplotlib.pyplot as plt\n\n# Create a SparkSession\nspark = SparkSession.builder.appName(\"TikTokHomework\").getOrCreate()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the schema to correctly define the columns (variables)\nschema = [StructField(\"comment_id\",StringType(),False),\n         StructField(\"text\",StringType(),False),\n         StructField(\"video_id\",StringType(),False),\n         StructField(\"create_time\",StringType(),False),\n         StructField(\"like_count\",IntegerType(),False),\n         StructField(\"status\",BooleanType(),False),\n         StructField(\"author.unique_id\",StringType(),False),\n         StructField(\"author.nickname\",StringType(),False),\n         StructField(\"author.is_private\",BooleanType(),False),\n         StructField(\"author.language\",StringType(),False),\n         StructField(\"author.signature\",StringType(),False),\n         StructField(\"author.custom_verify\",BooleanType(),False),\n         StructField(\"author.uid\",StringType(),False),\n         StructField(\"author.sec_uid\",StringType(),False),\n         StructField(\"author.avatar_thumb\",StringType(),False),\n         StructField(\"author.region\",StringType(),False),\n         StructField(\"author.ins_id\",StringType(),False),\n         StructField(\"author.youtube_channel_title\",StringType(),False),\n         StructField(\"author.youtube_channel_id\",StringType(),False),\n         StructField(\"author.twitter_id\",StringType(),False),\n         ]\n\nfinal_schema = StructType(fields=schema)\n\n# Reading TikTok Video Comments dataset\ndat = spark.read.csv(\"../input/tiktok-video-comments-david-dobriks-top-videos/final_data.csv\", header=True, multiLine=True, escape=\"\\\"\", schema=final_schema)\ndat.createOrReplaceTempView('''Comments''')\n\n# Format create_time column in Date type\ndat = dat.withColumn(\"create_time\", from_unixtime(\"create_time\", \"yyyy-MM-dd HH:mm:ss\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. How much content per author?\ndat.groupBy(\"`author.unique_id`\").count().sort('count',ascending=False).show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. How many likes per author?\ndat.groupBy(\"`author.unique_id`\").sum(\"`like_count`\").sort(sum('`like_count`'),ascending=False).show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3. TagCloud of terms\n\ntmpDF = dat.withColumn(\"WORD\", explode(split(col(\"text\"), \" \"))).groupBy(\"WORD\").count().sort(\"count\", ascending=False)\n\n# Convert SparkDataframe to a PandasDataFrame for iterate the elements\npandasDF = tmpDF.toPandas()\n\ncomments=''\nstopwords=set(STOPWORDS)\n\nfor index, row in pandasDF.iterrows():\n    tokens=row[\"WORD\"]\n    comments+=tokens+\" \"\n\n# Generate the TagCloud\nwordcloud=WordCloud(width=800, height=800, background_color='white', stopwords=stopwords, min_font_size=10).generate(comments)\n\n# Visualize the TagCloud\nplt.figure(figsize=(8,8), facecolor=None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4. What are the top 5 most adopted terms by each author?\n\ntmpDF = dat.withColumn(\"WORD\", explode(split(col(\"text\"), \" \"))).groupBy(\"WORD\", \"`author.unique_id`\").count().sort(\"count\", ascending=False)\ntmpDF = tmpDF.groupBy(\"`author.unique_id`\").agg({\"WORD\" : \"collect_list\"})\nfinDF = tmpDF.withColumn(\"TOP5WORDS\", slice(\"collect_list(WORD)\", 1, 5))\nfinDF.select(col(\"`author.unique_id`\").alias(\"USER\"), col(\"TOP5WORDS\")).show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5. What are the 5 most frequently used terms in each of the daily time slots (i.e., Morning, Afternoon, Evening, Night)?\n\ntmpDF = dat.withColumn(\"Time_Slot\", when((hour(\"create_time\")>=0) & (hour(\"create_time\")<6),\"Night\")\n                                            .when((hour(\"create_time\")>=6) & (hour(\"create_time\")<12),\"Morning\")\n                                            .when((hour(\"create_time\")>=12) & (hour(\"create_time\")<18),\"Afternoon\")\n                                            .otherwise(\"Evening\"))\ntmpDF = tmpDF.withColumn(\"WORD\", explode(split(col(\"text\"), \" \"))).groupBy(\"WORD\", \"Time_Slot\").count().sort(\"count\", ascending=False)\ntmpDF = tmpDF.groupBy(\"Time_Slot\").agg({\"WORD\" : \"collect_list\"})\nfinDF = tmpDF.withColumn(\"TOP5WORDS\", slice(\"collect_list(WORD)\", 1, 5))\nfinDF.select(col(\"Time_Slot\"), col(\"TOP5WORDS\")).show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6. Distribution of contents in the various languages\n\ndat.groupBy(\"`author.language`\").count().show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 7. Authors, in alphabetical order, who have received more than 100 likes\n\ndat.groupBy(\"`author.unique_id`\").sum(\"`like_count`\").where(\"sum(`like_count`) > 100\").sort(\"`author.unique_id`\", ascending=True).show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 8. Given as input a term, show the graph of its use over time\n\n# Input\n# input_term = str(input(\"Enter a term: \"))\n# For this example we'll use: david\ninput_term = \"david\"\n\ntmpDF = dat.withColumn(\"MONTH\", month(\"create_time\")).withColumn(\"WORD\", explode(split(col(\"text\"), \" \"))).groupBy(\"WORD\", \"MONTH\").count().where(\"WORD == '{0}'\".format(input_term)).sort(\"MONTH\", ascending=True)\n\n# Convert SparkDataframe to a PandasDataFrame for iterate the elements\npandasDF = tmpDF.toPandas()\n\n# Arrays for store x (month) and y (frequency) values\nx = []\ny = []\n\n# Loop for store the values\nfor index, row in pandasDF.iterrows():\n    x.append(row[\"MONTH\"])\n    y.append(row[\"count\"])\n\n# Checking if there is actually data (i.e. if the term exists)\nif len(x) == 0:\n    print(\"Termine non presente.\")\nelse:\n    # Plot the graphs\n    fig = plt.figure()\n    plt.plot(x, y, marker = \"o\", color = \"red\")\n    fig.suptitle(\"Term: {0}\".format(input_term))\n    plt.xlabel(\"Month\")\n    plt.ylabel(\"Frequency\")\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 9. Given a time slot as input, show the TagCloud of the terms used\n\n# We will use the same results as in the fifth query\ntmpDF = dat.withColumn(\"Time_Slot\", when((hour(\"create_time\")>=0) & (hour(\"create_time\")<6),\"Night\")\n                                            .when((hour(\"create_time\")>=6) & (hour(\"create_time\")<12),\"Morning\")\n                                            .when((hour(\"create_time\")>=12) & (hour(\"create_time\")<18),\"Afternoon\")\n                                            .otherwise(\"Evening\"))\ntmpDF = tmpDF.withColumn(\"WORD\", explode(split(col(\"text\"), \" \"))).groupBy(\"WORD\", \"Time_Slot\").count().sort(\"count\", ascending=False)\ntmpDF = tmpDF.groupBy(\"Time_Slot\").agg({\"WORD\" : \"collect_list\"})\nfinDF = tmpDF.withColumn(\"TOP5WORDS\", slice(\"collect_list(WORD)\", 1, 5))\nfinDF.select(col(\"Time_Slot\"), col(\"TOP5WORDS\"))\n\n# Convert SparkDataframe to a PandasDataFrame for iterate the elements\npandasDF = finDF.toPandas()\n\n# Time slot input\n# input_hour = input(\"Enter a time slot (Night, Morning, Afternoon, Evening): \")\n# For this example we'll use: Night\ninput_hour = \"Night\"\n\n# Checking the validity of the input\nwhile input_hour != \"Night\" and input_hour != \"Morning\" and input_hour != \"Evening\" and input_hour != \"Afternoon\":\n    input_hour = input(\"Error! Enter a time slot (Night, Morning, Afternoon, Evening):\")\n\nfrom wordcloud import WordCloud,STOPWORDS\ncomment_words = \"\"\nstopwords = set(STOPWORDS)\n\n# Loop to find the time slot given as input and access related terms\nfor index, row in pandasDF.iterrows():\n    if input_hour == row[\"Time_Slot\"]:\n        for value in row[\"collect_list(WORD)\"]:\n            comment_words += value + \" \"\n        # Generate the TagCloud\n        wordcloud=WordCloud(width=800, height=800, background_color='white', \n                            stopwords=stopwords, min_font_size=10).generate(comment_words)\n\n\n# Visualize the TagCloud\nplt.figure(figsize=(8,8), facecolor=None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}