{"cells":[{"metadata":{"_uuid":"914f5c64855ac9c9fa3d26f5465fedf9da3e6416","_cell_guid":"8d1cc764-4c02-cddd-339c-803e101ca47f","trusted":false,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ce757b509d5de00e089ef92cb3433627bef7d47","_cell_guid":"4d87f099-a821-21ae-4172-5eef3db1b6e0","trusted":true},"cell_type":"code","source":"aliases = pd.read_csv(\"../input/Aliases.csv\")\naliases.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f3c967c661af0e88f1727c1244b8088d39d7989","_cell_guid":"824c4a2c-911b-28d1-d139-d02a037c6a8b","trusted":true},"cell_type":"code","source":"email_receivers = pd.read_csv(\"../input/EmailReceivers.csv\")\nemail_receivers.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c968d909b66640c6fa01b5df57f72f748caa1a1","_cell_guid":"32cbefdb-e8fe-4105-a905-725f7887b732","trusted":true},"cell_type":"code","source":"persons = pd.read_csv(\"../input/Persons.csv\")\npersons.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f2106e26c0b306db660777e1085d065edd07bf0","_cell_guid":"3ee83ba4-432f-fa19-961f-e32a27f6b619","trusted":true},"cell_type":"code","source":"emails = pd.read_csv(\"../input/Emails.csv\")\nprint(emails.shape)\nprint(emails[pd.isnull(emails['ExtractedBodyText']) == True].shape)\n\nemail_doc = emails[pd.isnull(emails['ExtractedBodyText']) == False]['ExtractedBodyText']\nemail_doc.head()\n\nemail_doc[1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f6ce0d9a5926a663f47cdaef2245054265ea4a3"},"cell_type":"code","source":"import spacy\n\nnlp = spacy.load('en_core_web_sm')\ndoc = nlp(email_doc[1])\n\nfor ent in doc.ents:\n    print(ent.text, ent.start_char, ent.end_char, ent.label_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d056b0e3718140079559cf91d5e0d6eb8122bdaa"},"cell_type":"code","source":"doc.ents[1]","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"7779f4e91a80adff169de980508eb3f5e1989b06","scrolled":true,"_cell_guid":"0acbb8e3-a652-4799-aaab-fca2f48b3bb3","trusted":true},"cell_type":"code","source":"import gensim\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk.stem import SnowballStemmer\nimport string\n\nstop = set(stopwords.words('english'))\nexclude = set(string.punctuation)\n#stemmer = SnowballStemmer('english')\nlemma = WordNetLemmatizer()\ndef clean(doc):\n    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n    #stemmed = \" \".join(stemmer.stem(word) for word in punc_free.split())    \n    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n    return normalized\n\ndoc_clean = [clean(doc).split() for doc in email_doc] ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"43e748fa8bdeb3b1f644a42d2a1b60beae6c9eec","_cell_guid":"990f7ed6-732b-404a-aad5-ba85b1c4645a","trusted":true},"cell_type":"code","source":"doc_clean[3]","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"17ed51607d6b4ecbce218b3fddc638b7bdcfe88e","_cell_guid":"bdaa5d6f-8b8c-4400-8fa7-dcba89d597ca","trusted":false},"cell_type":"code","source":"from gensim import corpora\ndictionary = corpora.Dictionary(doc_clean)\ndoc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"693a0885aaaecad608abc1fc6b72c43bcbee4ad9","_cell_guid":"56a4c3e0-4b8a-4665-be60-43f951ec4b59","trusted":false,"collapsed":true},"cell_type":"code","source":"Lda = gensim.models.ldamodel.LdaModel\n\n# Running and Trainign LDA model on the document term matrix.\nldamodel = Lda(doc_term_matrix, num_topics=5, id2word = dictionary, passes=50)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fda78454eec9b80799847fbd60edace0c74983e2","trusted":false,"collapsed":true},"cell_type":"code","source":"print(ldamodel.print_topics(num_topics=5, num_words=5))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"fe31aa8d29f36767fae83b771d57d9968ad4ac46","_cell_guid":"44a1a02e-86ca-4433-9900-8ca46df90d6b","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"_is_fork":false,"_change_revision":0,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}