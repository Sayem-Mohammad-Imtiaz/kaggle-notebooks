{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\nimport pandas\nimport numpy\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import TensorBoard\nimport matplotlib.pyplot as plt\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir log\n!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\n\nLOG_DIR = './log/' \nget_ipython().system_raw(\n    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n    .format(LOG_DIR)\n)\nget_ipython().system_raw('./ngrok http 6006 &')\n! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"def show_all(arg):\n    import math\n    plt.figure(figsize=(10,10))\n    index = 1\n    myLen = len(arg)\n    row = math.ceil(math.sqrt(myLen))\n    myCol = myLen // row\n    for i in range(myCol + 1):\n        for j in range(row):\n            #print(myCol + 1, row)\n            if i * row + j < myLen :\n                t_img = arg[i * row + j]\n                plt.subplot(myCol + 1, row, i * row + j + 1)\n                plt.imshow(t_img)\n                plt.title(index)\n                index += 1\n                plt.xticks([]), plt.yticks([])\n            else:\n                plt.show()\n                return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_generator(path, classes, size):\n    image_data_generator=ImageDataGenerator(\n        rescale=1./255.)\n    training_generator = image_data_generator.flow_from_directory(\n        classes = classes,\n        directory = path,\n        batch_size = 1,\n        seed = 42,\n        shuffle = True,\n        target_size = size)\n    return training_generator\npainting_generator = get_generator('../input/art-images-drawings-painting-sculpture-engraving/dataset',None, (100, 100))\nindoor_generator = get_generator('../input/indoor-training-set-its-residestandard', ['clear'],(200, 200))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pic_generator = get_generator('../input/painting', ['╤╣╦⌡'],(200, 200))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_back():\n    back = next(indoor_generator)[0].reshape((200, 200, 3))\n    back = cv2.cvtColor(back, cv2.COLOR_RGB2RGBA)\n    return back\ndef load_front():\n    front = next(painting_generator)[0].reshape((100, 100, 3))\n    front = cv2.cvtColor(front, cv2.COLOR_RGB2RGBA)\n    transparent_layer = numpy.zeros((200, 200, 4))\n    transparent_layer[50:150, 50:150] = front\n    transparent_layer = transparent_layer.astype(numpy.float32)\n    return transparent_layer\ndef transform(front):\n    from random import uniform\n    raw_points = numpy.float32([ [50,50], [50,149], [149,149], [149,50] ])\n    new_points = numpy.float32([ \n        [uniform(10, 60), uniform(10, 60)], \n        [uniform(10, 60), uniform(140, 190)], \n        [uniform(140, 190), uniform(140, 190)],  \n        [uniform(140, 190), uniform(10, 60)]\n    ])\n    M = cv2.getPerspectiveTransform(raw_points, new_points)\n    front = cv2.warpPerspective(front, M, (200, 200), flags=cv2.INTER_NEAREST)\n    # front = cv2.GaussianBlur(front,(3,3),0)\n    return (front, new_points.reshape((8,)))\ndef merge(back, front):\n    ret, mask = cv2.threshold(cv2.split(front)[-1],0.5,1,cv2.THRESH_BINARY_INV)\n    mask = mask.astype(numpy.uint8)\n    back = cv2.bitwise_and(back,back,mask = mask)\n    del mask\n    img = cv2.add(back, front)\n    return cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\ndef canny(mat, ksize):\n    gray = cv2.cvtColor(mat,cv2.COLOR_RGB2GRAY)\n    gauss = cv2.GaussianBlur(gray, (ksize, ksize), 0.3*((ksize-1)*0.5-1)+0.8)\n    edged = cv2.Canny(gauss, 50, 60)\n    return edged\ndef process_img(img):\n#     raw = img.copy() \n#     ksize = 7\n# #     epsilon = 3\n#     img = img*255\n#     img = img.astype(numpy.uint8)\n#     img = canny(img, ksize)\n#     lines = cv2.HoughLinesP(img, 1, numpy.pi / 360, 30,minLineLength=30,maxLineGap=6)\n# #     print(lines)\n#     for line in lines:\n#         x1, y1, x2, y2 = line[0]\n#         cv2.line(raw, (x1, y1), (x2, y2), (255, 255, 0), 2)\n#     cnts = Countours(img)\n#     img = approxPoly(img, cnts, epsilon)\n#     mask = draw_mask(img)\n#     img = cv2.GaussianBlur(img,(3,3),0)*255\n#     img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY).astype(numpy.uint8)\n#     img = cv2.Canny(img, 50, 150)\n#     img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)/255\n#     img = img.astype(numpy.float32)\n#     img = cv2.add(img, raw)\n    return img\ndef get_an_img():\n    back = load_back()\n    front = load_front()\n    front, points = transform(front)\n    img = merge(back, front)\n    del back\n    del front\n    img = process_img(img)\n    return (img, points)\nshow_all([get_an_img()[0]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n# sys.getsizeof([get_an_img() for i in range(100)])\ntest_x = []\ntest_y = []\nfor i in range(100):\n    try:\n        img, points = get_an_img()\n        test_x.append(img)\n        test_y.append(points/200)\n#         print(i)\n    except:\n        print(i, \"XXXXXXXXXXXXXXXXXXXXXXXXXXXX\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n# sys.getsizeof([get_an_img() for i in range(100)])\nx = []\ny = []\nfor i in range(4000):\n    try:\n        img, points = get_an_img()\n        x.append(img)\n        y.append(points/200)\n#         print(i)\n    except:\n        print(i, \"XXXXXXXXXXXXXXXXXXXXXXXXXXXX\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications import VGG16\nconv_base = VGG16(weights='imagenet',\n                  include_top=False,\n                  input_shape=(200, 200, 3))\n# conv_base.trainable = False\nconv_base.trainable = True \n# set_trainable = False \n# for layer in conv_base.layers:     \n#     if layer.name == 'block5_conv1':         \n#         set_trainable = True     \n#     if set_trainable:         \n#         layer.trainable = True     \n#     else:         \n#         layer.trainable = False\nmodel = models.Sequential()\nmodel.add(conv_base)\n# model.add(layers.Conv2D(32, (3, 3), activation='relu',\n#                         input_shape=(100, 100, 3)))\n# model.add(layers.MaxPooling2D((2, 2)))\n# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n# model.add(layers.MaxPooling2D((2, 2)))\n# model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n# model.add(layers.MaxPooling2D((2, 2)))\n# model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n# model.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\n# model.add(layers.Dense(2048, activation='relu'))\n# model.add(layers.Dropout(0.4))\nmodel.add(layers.Dense(1024, activation='relu'))\nmodel.add(layers.Dropout(0.4))\nlayers.BatchNormalization()\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dropout(0.3))\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dropout(0.4))\nlayers.BatchNormalization()\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.3))\nmodel.add(layers.Dense(8, activation='sigmoid'))\nmodel.compile(\n    loss='mae',\n    optimizer=optimizers.RMSprop(lr=1e-5),\n    metrics=['mae'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import Callback\nimport random\ndef draw_points(img, points):\n    import copy\n    point_size = 5\n    point_color = (0,255,0)\n    thickness = -1\n    points = points*200\n    image = copy.deepcopy(img)\n    cv2.circle(image, (points[0], points[1]), point_size, point_color, thickness)\n    cv2.circle(image, (points[2], points[3]), point_size, point_color, thickness)\n    cv2.circle(image, (points[4], points[5]), point_size, point_color, thickness)\n    cv2.circle(image, (points[6], points[7]), point_size, point_color, thickness)\n    return image\nclass Show_effect(Callback):\n    def __init__(self):\n        super(Show_effect, self).__init__()\n        self.epoch = -1\n    def on_epoch_end(self, batch, logs={}):\n        self.epoch = self.epoch + 1\n        if(self.epoch % 8 ==0):\n            data_for_test = [random.choice(test_x) for i in range(4)]\n            for i in range(4):\n                data_for_test.append(process_img(next(pic_generator)[0].reshape((200,200,3))))\n            show_all([draw_points(img,model.predict(numpy.expand_dims(img,axis=0)).reshape((8,))) for img in data_for_test])\nshow_effect = Show_effect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=numpy.array(x)\ny=numpy.array(y)\nmodel.fit(\n    x,\n    y,\n    batch_size=64,\n    epochs=1000,\n    validation_split=0.3,\n    callbacks=[TensorBoard(log_dir='./log'),show_effect])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_for_test = [random.choice(test_x)  for i in range(4)]\nfor i in range(4):                     \n    data_for_test.append(process_img(next(pic_generator)[0].reshape((200,200,3))))\nshow_all([draw_points(img,model.predict(numpy.expand_dims(img,axis=0)).reshape((8,))) for img in data_for_test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=numpy.array(x)\np=model.predict(x[:1]) \nt=y[:1]\nprint(p-t)\nprint(sum((p-t)*(p-t))) \nprint(p)\nprint(t) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"image.h5\") ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}