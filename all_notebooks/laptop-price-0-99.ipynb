{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"os.chdir(\"../input\")\nos.listdir()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Data Read**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndf=pd.read_csv(\"../input/laptop-price/laptop_price.csv\",encoding='latin-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **DATA CLEANING AND PREPERATÄ°ON**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Ram\"] = df[\"Ram\"].str.replace('GB', '') ## remove 'GB'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Weight\"] = df[\"Weight\"].str.replace('kg', '') ## remove 'kg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Memory'] = df['Memory'].astype(str).replace('\\.0', '', regex=True) ## '.0' part remove ex; '1.0'---> '1' ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Memory\"] = df[\"Memory\"].str.replace('GB', '') ## remove 'GB'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Memory\"] = df[\"Memory\"].str.replace('TB', '000') # convert to TB to GB values ex; 1TB=1000GB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new2 = df[\"Memory\"].str.split(\"+\", n = 1, expand = True) # seperate according to '+'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making separate first name column from new data frame \ndf[\"first\"]= new2[0]\ndf[\"first\"]=df[\"first\"].str.strip() # First part of Memory","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making separate last name column from new data frame \ndf[\"second\"]= new2[1] # Second part of Memory","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Categorization of first part and second part of Memory\n# Categorization of first part of Memory\n\ndf[\"Layer1HDD\"] = df[\"first\"].apply(lambda x: 1 if \"HDD\" in x else 0)\ndf[\"Layer1SSD\"] = df[\"first\"].apply(lambda x: 1 if \"SSD\" in x else 0)\ndf[\"Layer1Hybrid\"] = df[\"first\"].apply(lambda x: 1 if \"Hybrid\" in x else 0)\ndf[\"Layer1Flash_Storage\"] = df[\"first\"].apply(lambda x: 1 if \"Flash Storage\" in x else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Cleaning for first part unwanted charecters \ndf['first'] = df['first'].str.replace(r'\\D', '')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For Consisting of one part Memory fill the Na values with 0\ndf[\"second\"].fillna(\"0\", inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorization of second part of Memory\ndf[\"Layer2HDD\"] = df[\"second\"].apply(lambda x: 1 if \"HDD\" in x else 0)\ndf[\"Layer2SSD\"] = df[\"second\"].apply(lambda x: 1 if \"SSD\" in x else 0)\ndf[\"Layer2Hybrid\"] = df[\"second\"].apply(lambda x: 1 if \"Hybrid\" in x else 0)\ndf[\"Layer2Flash_Storage\"] = df[\"second\"].apply(lambda x: 1 if \"Flash Storage\" in x else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Data Cleaning for second part unwanted charecters \ndf['second'] = df['second'].str.replace(r'\\D', '')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert to integer first and second parts \ndf[\"first\"] = df[\"first\"].astype(int)\ndf[\"second\"] = df[\"second\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculation of Total Memory\ndf[\"Total_Memory\"]=(df[\"first\"]*(df[\"Layer1HDD\"]+df[\"Layer1SSD\"]+df[\"Layer1Hybrid\"]+df[\"Layer1Flash_Storage\"])+df[\"second\"]*(df[\"Layer2HDD\"]+df[\"Layer2SSD\"]+df[\"Layer2Hybrid\"]+df[\"Layer2Flash_Storage\"]))\ndf[\"Memory\"]=df[\"Total_Memory\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculation of Category HDD,SSD,Hybrid,Flash Storage\ndf[\"HDD\"]=(df[\"first\"]*df[\"Layer1HDD\"]+df[\"second\"]*df[\"Layer2HDD\"])\ndf[\"SSD\"]=(df[\"first\"]*df[\"Layer1SSD\"]+df[\"second\"]*df[\"Layer2SSD\"])\ndf[\"Hybrid\"]=(df[\"first\"]*df[\"Layer1Hybrid\"]+df[\"second\"]*df[\"Layer2Hybrid\"])\ndf[\"Flash_Storage\"]=(df[\"first\"]*df[\"Layer1Flash_Storage\"]+df[\"second\"]*df[\"Layer2Flash_Storage\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperate Screen Resolution Part according to 'x' character\n# new data frame with split value columns \nnew = df[\"ScreenResolution\"].str.split(\"x\", n = 1, expand = True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X resolution \n# making separate first name column from new data frame \ndf[\"X_res\"]= new[0] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Y resolution \n# making separate last name column from new data frame \ndf[\"Y_res\"]= new[1] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Y_res\"]=pd.to_numeric(df[\"Y_res\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Y_res\"] = df[\"Y_res\"].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Cleaning for X_res part unwanted charecters \ndf[\"X_res\"]=(df['X_res'].str.replace(',','').str.findall(r'(\\d+\\.?\\d+)').apply(lambda x: pd.Series(x).astype(int)).mean(1))\ndf[\"X_res\"]=pd.to_numeric(df[\"X_res\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculation of PPI from X_res,Y_res,Inches\ndf[\"PPI\"]=(((df[\"X_res\"]**2+df[\"Y_res\"]**2)**(1/2))/df[\"Inches\"]).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Update the ScreenResolution now this coloumn is numeric value\ndf[\"ScreenResolution\"]=(df[\"X_res\"]*df[\"Y_res\"]).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Object value convert to numeric values\ndf[\"Ram\"] = df[\"Ram\"].astype(int)\ndf[\"Weight\"] = df[\"Weight\"].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop unused columns from the Dataframe \ndf=df.drop(['laptop_ID','first','second','Layer1HDD','Layer1SSD','Layer1Hybrid','Layer1Flash_Storage','Layer2HDD','Layer2SSD','Layer2Hybrid','Layer2Flash_Storage','Total_Memory'],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparation of Model Data and Scaling of Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df.drop(['Price_euros'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Log transform of y values\ny=np.log(df['Price_euros'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=pd.concat([X,pd.get_dummies(X)],axis=1)\nprint(X.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_=X.select_dtypes(exclude=['object'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cleaning duplicate columns ..\nX_ = X_.loc[:,~X_.columns.duplicated()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalization of Features\nX=(X_-np.min(X_))/(np.max(X_)-np.min(X_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{},"cell_type":"markdown","source":"## LINEAR REGRESSION"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n# Let's see what is the prediction error of our model.\n\n\ny_pred_lr = lin_reg.predict(X)\nlin_mse = mean_squared_error(y, y_pred_lr)\nlin_rmse = np.sqrt(lin_mse)\nprint(\"Linear Regression MSE: \",lin_mse)\nprint(\"Linear Regression RMSE: \",lin_rmse)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see how accurate is our model.\nfrom sklearn import metrics\naccuracy_lin = metrics.r2_score(y, y_pred_lr)\nprint(\"Linear Regression r2: \",accuracy_lin)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n\nlin_mae = mean_absolute_error(y, y_pred_lr)\nprint(\"Linear Regression MAE: \",lin_mae)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DECISION TREE"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ntree_reg=DecisionTreeRegressor()\ntree_reg.fit(X,y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see what is the prediction error of our model.\n\ny_pred_dt=tree_reg.predict(X)\n\ndt_mse = mean_squared_error(y, y_pred_dt)\ndt_rmse = np.sqrt(dt_mse)\nprint(\"Decision Tree Regression MSE: \",dt_mse)\nprint(\"Decision Tree Regression RMSE: \",dt_rmse)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see how accurate is our model.\n\naccuracy_dt = metrics.r2_score(y, y_pred_dt)\nprint(\"Decision Tree Regression r2: \",accuracy_dt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_mae = mean_absolute_error(y, y_pred_dt)\nprint(\"Decision Tree Regression MAE: \",dt_mae)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## RANDOM FOREST REGRESSION"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\n\nx_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.4,random_state=42)\n\nrf=RandomForestRegressor(n_estimators=100,random_state=42)\n\nrf.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see what is the prediction error of our model.\n\ny_pred_rf=rf.predict(x_test)\n\nrf_mse = mean_squared_error(y_test, y_pred_rf)\nrf_rmse = np.sqrt(rf_mse)\n\nprint(\"Random Forest Regression MSE: \",rf_mse)\nprint(\"Random Forest Regression RMSE: \",rf_rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see how accurate is our model.\n\naccuracy_rf=metrics.r2_score(y_test,y_pred_rf)\n\nprint(\"Random Forest Regression r2: \",accuracy_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_mae = mean_absolute_error(y_test, y_pred_rf)\nprint(\"Random Forest Regression  MAE: \",rf_mae)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}