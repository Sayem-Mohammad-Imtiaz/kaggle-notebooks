{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Library Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader as DL\nfrom torch.utils.data import Dataset\nfrom torch.nn.utils import weight_norm as WN\nimport torch.nn.functional as F\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, f1_score\n\nfrom time import time\nimport random as r\n\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\nn_folds = 4\n\nsc_X = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Helper Functions"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def breaker():\n    print(\"\\n\" + 30*\"-\" + \"\\n\")\n\ndef head(x, no_of_ele=5):\n    breaker()\n    print(x[:no_of_ele])\n    breaker()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Handling"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv(\"../input/heart-disease-uci/heart.csv\")\n\nbreaker()\nprint(dataset.shape)\nbreaker()\n\nX = dataset.iloc[:, :-1].copy().values\ny = dataset.iloc[:, -1].copy().values\n\nX = sc_X.fit_transform(X)\nnum_features = X.shape[1]\nnum_obs_test = X.shape[0]\n\ndel dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dataset Template**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DS(Dataset):\n    def __init__(this, X=None, y=None, mode=\"train\"):\n        this.X = X\n        this.mode = mode\n        if mode == \"train\":\n            this.y = y\n        \n    def __len__(this):\n        return this.X.shape[0]\n    \n    def __getitem__(this, idx):\n        if this.mode == \"train\":\n            return torch.FloatTensor(this.X[idx]), torch.FloatTensor(this.y[idx])\n        else:\n            return torch.FloatTensor(this.X[idx])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ANN"},{"metadata":{},"cell_type":"markdown","source":"**Config**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ANN_CFG():\n    batch_size = 64\n    epochs = 50\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    IL = num_features\n    HL = [128, 128]\n    OL = 1\n    \ncfg = ANN_CFG()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Setup**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ANN(nn.Module):\n    def __init__(this, IL=None, HL=None, OL=None):\n        super(ANN, this).__init__()\n        \n        this.DP_1 = nn.Dropout(p=0.2)\n        this.DP_2 = nn.Dropout(p=0.5)\n        \n        this.BN1 = nn.BatchNorm1d(IL)\n        this.FC1 = WN(nn.Linear(IL, HL[0]))\n        \n        this.BN2 = nn.BatchNorm1d(HL[0])\n        this.FC2 = WN(nn.Linear(HL[0], HL[1]))\n        \n        this.BN3 = nn.BatchNorm1d(HL[1])\n        this.FC3 = WN(nn.Linear(HL[1], OL))\n    \n    def getOptimizer(this):\n        return optim.Adam(this.parameters(), lr=1e-3, weight_decay=0)\n    \n    def forward(this, x):\n        x = this.BN1(x)\n        x = F.relu(this.FC1(x))\n        x = this.BN2(x)\n        x = F.relu(this.FC2(x))\n        x = this.BN3(x)\n        x = torch.sigmoid(this.FC3(x))\n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ANN Helpers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_fn(X=None, y=None, n_folds=None):\n    breaker()\n    print(\"Training...\")\n    LP = []\n    name_getter = []\n    fold = 0\n    bestLoss = {\"train\" : np.inf, \"valid\" : np.inf}\n    \n    start_time = time()\n    breaker()\n    for tr_idx, va_idx in KFold(n_splits=n_folds, shuffle=True, random_state=0).split(X, y):\n        print(\"Processing Fold {fold} ...\".format(fold=fold+1))\n        X_train, X_valid, y_train, y_valid = X[tr_idx], X[va_idx], y[tr_idx], y[va_idx]\n        \n        tr_data_setup = DS(X_train, y_train.reshape(-1,1))\n        va_data_setup = DS(X_valid, y_valid.reshape(-1,1))\n        \n        dataloaders = {\"train\" : DL(tr_data_setup, batch_size=cfg.batch_size, shuffle=True, generator=torch.manual_seed(0)),\n                       \"valid\" : DL(va_data_setup, batch_size=cfg.batch_size, shuffle=False)\n                      }\n        \n        torch.manual_seed(0)\n        model = ANN(cfg.IL, cfg.HL, cfg.OL)\n        model.to(cfg.device)\n        \n        optimizer = model.getOptimizer()\n        \n        for e in range(cfg.epochs):\n            epochLoss = {\"train\" : 0, \"valid\" : 0}\n            for phase in [\"train\", \"valid\"]:\n                if phase == \"train\":\n                    model.train()\n                else:\n                    model.eval()\n                lossPerPass = 0\n                \n                for feat, lbls in dataloaders[phase]:\n                    feat, lbls = feat.to(cfg.device), lbls.to(cfg.device)\n                    \n                    optimizer.zero_grad()\n                    with torch.set_grad_enabled(phase == \"train\"):\n                        output = model(feat)\n                        loss   = nn.BCELoss()(output, lbls)\n                        if phase == \"train\":\n                            loss.backward()\n                            optimizer.step()\n                    lossPerPass += (loss.item()/lbls.shape[0])\n                epochLoss[phase] = lossPerPass\n            LP.append(epochLoss)\n            if epochLoss[\"valid\"] < bestLoss[\"valid\"]:\n                bestLoss = epochLoss\n                name = \"./Model_Fold_{fold}.pt\".format(fold=fold)\n                name_getter.append(name)\n                torch.save(model.state_dict(), name)\n        fold += 1\n    \n    breaker()\n    print(\"Time taken to train {fold} folds for {e} epochs : {:.2f} minutes\".format((time()-start_time)/60, fold=n_folds, e=cfg.epochs))\n    breaker()\n    print(\"Best Loss :\", repr(bestLoss))\n    breaker()\n    print(\"Training Complete\")\n    breaker()\n    \n    return LP, name_getter, model\n\ndef eval_fn(model=None, names=None, dataloader=None):\n    final_Pred = np.zeros((num_obs_test, 1))\n    \n    for name in names:\n        Pred = torch.zeros(cfg.batch_size, 1).to(cfg.device)\n        model.load_state_dict(torch.load(name))\n        model.eval()\n        for X, y in dataloader:\n            X = X.to(cfg.device)\n            with torch.no_grad():\n                Prob = model(X)\n            Pred = torch.cat((Pred, Prob), dim=0)\n        Pred = Pred[cfg.batch_size:]\n        Pred = Pred.cpu().numpy()\n        final_Pred = np.add(final_Pred, Pred)\n        \n    final_Pred = np.divide(final_Pred, len(names))\n    final_Pred[np.argwhere(final_Pred > 0.5)[:, 0]]  = int(1)\n    final_Pred[np.argwhere(final_Pred <= 0.5)[:, 0]] = int(0)\n    return final_Pred.reshape(-1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Training**"},{"metadata":{"trusted":true},"cell_type":"code","source":"LP, Names, Network = train_fn(X=X, y=y, n_folds=n_folds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plots**"},{"metadata":{"trusted":true},"cell_type":"code","source":"LPV = []\nLPT = []\nfor i in range(len(LP)):\n  LPT.append(LP[i][\"train\"])\n  LPV.append(LP[i][\"valid\"])\n\nxAxis = [i+1 for i in range(cfg.epochs)]\nplt.figure(figsize=(20, 25))\nfor fold in range(n_folds):\n    plt.subplot(n_folds, 1, fold+1)\n    plt.plot(xAxis, LPT[fold*cfg.epochs:(fold+1)*cfg.epochs], \"b\", label=\"Training Loss\")\n    plt.plot(xAxis, LPV[fold*cfg.epochs:(fold+1)*cfg.epochs], \"r--\", label=\"Validation Loss\")\n    plt.legend()\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Fold {fold}\".format(fold=fold+1))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Evaluation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_data_setup = DS(X, y.reshape(-1,1))\nts_data = DL(ts_data_setup, batch_size=cfg.batch_size, shuffle=False)\n\ny_pred = eval_fn(Network, Names, ts_data)\n\nbreaker()\nprint(\"Accuracy : {:.5f} %\".format(accuracy_score(y, y_pred) * 100))\nbreaker()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}