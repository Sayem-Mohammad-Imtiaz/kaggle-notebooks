{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"### imported by jim 4/26/20\n### super slow, but who cares it only has to run once\n#streamlined into functional structure 5/02/20 jchd\n#forked and modified into noise analysis ~5/03/20\nfrom scipy.special import comb\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # this is why I'm using kaggle, pyplot isn't installing on yuffa machine (rabbit)\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom random import random\nimport seaborn as sns\nimport os\nimport gc\n#!pip install joypy\n#import joypy\n\ntrain_data=pd.read_csv('../input/data-without-drift/train_clean.csv')\ntest_data=pd.read_csv('../input/data-without-drift/test_clean.csv')\nwavebase=pd.read_csv('../input/new-baseline-all-and-synth-2mil-lgbmoofs/submission_wavenet.csv')\ntest_data['open_channels']=wavebase.open_channels\n#create dictionaries for train,test,wavenet dataframes\nwavebase_dict={}\nfor i in range(0,20):\n    wavebase_dict[i]=wavebase[100000*i:(i+1)*100000]\n    wavebase_dict[i].reset_index(inplace=True,drop=True)\ntest_dict={}\nfor i in range(0,20):\n    test_dict[i]=test_data[100000*i:(i+1)*100000]\n    test_dict[i].reset_index(inplace=True,drop=True)\ntrain_dict={}\nfor i in range(0,10):\n    train_dict[i]=train_data[i*500000:(i+1)*500000]\n    train_dict[i].reset_index(inplace=True,drop=True)\n\n    \n#let's look at our oofs on train and test\ntrain_oof_data=pd.read_csv('../input/oofs-g94/oofset_train.csv')\ntest_oof_data=pd.read_csv('../input/oofs-g94/oofs_test.csv')\ntest_oof_dict={}\nfor i in range(0,20):\n    test_oof_dict[i]=test_oof_data[100000*i:(i+1)*100000]\n    test_oof_dict[i].reset_index(inplace=True,drop=True)\n    test_oof_dict[i]['signal']=test_dict[i]['signal']\ntrain_oof_dict={}\nfor i in range(0,10):\n    train_oof_dict[i]=train_oof_data[i*500000:(i+1)*500000]\n    train_oof_dict[i].reset_index(inplace=True,drop=True)\n    train_oof_dict[i]['signal']=train_dict[i]['signal']\n#simple check on oofs, should see high correlation between oofs and train open channels\nfor i in range(0,10):\n    print(train_oof_dict[i].oofs.corr(train_dict[i].open_channels))\n    print(train_oof_dict[i].signal.corr(train_dict[i].signal))\n    print(test_oof_dict[i].signal.corr(test_dict[i].signal))\n\n#create signalp and noisep columns for train dataframes\nfor group in range(0,10):\n    train_dict[group]['signalp']=train_dict[group].open_channels #placeholder, gets overwritten\n    for i in range(0,11):\n        train_dict[group].loc[train_dict[group].open_channels==i,'signalp']=train_dict[group][train_dict[group].open_channels==i].signal.mean()\n    train_dict[group]['noisep']=train_dict[group].signal-train_dict[group].signalp\n\nfor group in range(0,20):\n    test_dict[group]['signalp']=test_dict[group].open_channels #placeholder, gets overwritten\n\n    for i in range(0,11):\n        test_dict[group].loc[test_dict[group].open_channels==i,'signalp']=test_dict[group][test_dict[group].open_channels==i].signal.mean()\n    test_dict[group]['noisep']=test_dict[group].signal-test_dict[group].signalp\n\nfor group in range(0,20):\n    test_oof_dict[group]['signalp']=test_oof_dict[group].open_channels #placeholder, gets overwritten\n    for i in range(0,11):\n        test_oof_dict[group].loc[test_oof_dict[group].open_channels==i,'signalp']=test_oof_dict[group][test_oof_dict[group].open_channels==i].signal.mean()\n    test_oof_dict[group]['noisep']=test_oof_dict[group].signal-test_oof_dict[group].signalp\n\n\nclass model1():\n    def __init__(self,rates, size=10):\n        self.size=size\n        self.rates=rates\n        self.channels=[]\n        for i in range(0,self.size):\n            self.channels.append('a')\n    def reset(self):\n        self.channels=[]\n        for i in range(0,self.size):\n            self.channels.append('a')\n    def value(self):\n        return self.channels.count('a')+self.channels.count('b')+self.channels.count('c')\n    def get_state(self):\n        x=[]\n        for i in ['a','b','c','d','e','f']:\n            x.append(self.channels.count(i))\n        return(x)\n    def wiggle(self):\n        #print('old state:',self.channels)\n        #print(self.value())\n        choices=['a','b','c','d','e','f']\n        psum=9813.5\n        for i in range(0,len(self.channels)):\n            if self.channels[i]=='a':\n                \n                np.rand(1)\n        for i in range(0,len(self.channels)):\n            if self.channels[i]=='a':\n                newstate=np.random.choice(choices,1,p=self.rates[0])[0]\n            if self.channels[i]=='b':\n                newstate=np.random.choice(choices,1,p=self.rates[1])[0]\n            if self.channels[i]=='c':\n                newstate=np.random.choice(choices,1,p=self.rates[2])[0]\n            if self.channels[i]=='d':\n                newstate=np.random.choice(choices,1,p=self.rates[3])[0]\n            if self.channels[i]=='e':\n                newstate=np.random.choice(choices,1,p=self.rates[4])[0]\n            if self.channels[i]=='f':\n                newstate=np.random.choice(choices,1,p=self.rates[5])[0] \n            self.channels[i]=newstate\n        #print('new state:',self.channels)\n        #print(self.value())\n    def run(self,n):\n        x=[]\n        for i in range(0,n):\n            x.append(self.value())\n            self.wiggle()\n        return(x)\n    def state_run(self,n):\n        x=[]\n        for i in range(0,n):\n            x.append(self.get_state())\n            self.wiggle()\n        y=pd.DataFrame(x,columns=['a','b','c','d','e','f'])\n        y['open_channels']=y.a+y.b+y.c\n\n        return(y)\n\nrates1=[[0.997, 3.060e-3, 2.946e-5, 3.618e-6, 1.020e-8, 5.018e-12],\n       [1.283e-3, 0.978, 1.788e-2, 3.279e-3, 1.264e-5, 7.872e-9],\n       [2.267e-5, 0.033, 0.699, 0.266, 1.637e-3, 1.393e-6],\n       [2.763e-6, 5.972e-3, 0.264, 0.721, 9.047e-3, 1.144e-5],\n       [1.872e-8, 5.532e-5, 3.904e-3, 2.175e-2, 0.972, 2.344e-3],\n       [7.291e-11, 2.728e-7, 2.630e-5, 2.176e-4, 1.855e-2, 0.981]]\n#fix this bullshit normalization below and just normalize the columns!!\nfor i in range(0,len(rates1)):\n    rowsum=0\n    for j in range(0,len(rates1[i])):\n        if i!=j:\n            rates1[i][j]=round(rates1[i][j],5)\n            rowsum=rowsum+rates1[i][j]  \n    rates1[i][i]=1-rowsum\n\n#rates2 seem superior\nrates2=[[0.997, 3.159e-3, 3.042e-5, 3.728e-6, 1.052e-8, 4.957e-12],\n  [1.185e-3, 0.978, 1.789e-2, 3.272e-3, 1.262e-5, 7.532e-9],\n  [2.093e-5, 0.033, 0.7, 0.265, 1.633e-3, 1.332e-6],\n  [2.598e-6, 6.080e-3, 0.269, 0.716, 9.018e-3, 1.093e-5],\n  [1.761e-8, 5.635e-5, 3.974e-3, 2.168e-2, 0.972, 2.245e-3],\n  [7.220e-11, 2.925e-7, 2.820e-5, 2.285e-4, 1.952e-2, 0.98]]\n\nfor i in range(0,len(rates2)):\n    tot=0\n    for j in range(0,len(rates2[i])):\n        tot=tot+rates2[i][j]\n    for j in range(0,len(rates2[i])):\n        rates2[i][j]=rates2[i][j]/tot\n\n\n#fix this bullshit normalization below and just normalize the columns!!\n#for i in range(0,len(rates2)):\n#    rowsum=0\n#    for j in range(0,len(rates2[i])):\n#        if i!=j:\n#            rates2[i][j]=round(rates2[i][j],5)\n#            rowsum=rowsum+rates2[i][j]  \n#    rates2[i][i]=1-rowsum\n\n#adds/overwrites pure signal column for synthetic in column name as argument, averages traingroup arguments for values\ndef generate_pure_signal(synthx,name,traingroup1,traingroup2):\n    print('creating signal column for synth based on signalp in group',str(traingroup1),'and',str(traingroup2))\n    train_data1=train_dict[traingroup1]#[0:100000]\n    train_data2=train_dict[traingroup2]#[0:100000]\n    synthx[name]=synthx.open_channels #placeholder, gets overwritten\n    for i in range(0,11):\n        synthx.loc[synthx.open_channels==i,name]=(train_data1[train_data1.open_channels==i].signal.mean()+train_data2[train_data2.open_channels==i].signal.mean())/2.\n    synthx.reset_index(drop=True,inplace=True)\n    gc.collect()\n\ndef add_noise_make_signal(synth,name,traingroup,reverse=False):\n    print('adding noise from',str(traingroup))\n    synth[name]=synth.signalp+train_dict[traingroup].noisep #placeholder, should overwrite\n    if reverse:\n            synth[name]=synth.signalp+train_dict[traingroup].noisep.values[::-1] #placeholder, should overwrite\n\ndef check_synth_signal(synth,traingroup):\n    plt.plot(synth.signal[0:100000])\n    plt.plot(train_dict[traingroup].signal[0:100000])\n    plt.show()\n    plt.hist(synth.open_channels,bins=30)\n    plt.hist(train_dict[traingroup].open_channels,bins=80)\n    plt.show()\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generatetrainautocorr(train_data,max=1000):\n    train_autocorr_dict={}\n    for group in range(0,10):\n        orig = train_dict[group][0:100000]\n        origautocorr=[]\n        for i in range(1,1000):\n            origautocorr.append(orig.open_channels.diff(i).value_counts()[0])\n        print('generated autocorr to max',str(max),'for train group',group)\n        train_autocorr_dict[group]=origautocorr\n    return(train_autocorr_dict)\n        \ndef checkrun(synth,group=False,train=False):\n    #length=len(synth)\n    if group:\n        print('comparing synth(blue) to train_autocorr group',str(group),'(orange)')\n        orig =train_dict[group][0:100000]\n        orig.reset_index(inplace=True,drop=True)\n        orig.reset_index(inplace=True,drop=True)\n        origautocorr=train_autocorr_dict[group]\n    #for i in range(0,len(origautocorr)):\n    #    origautocorr[i]=origautocorr[i]/length\n    if not group:\n        orig =train\n        print('no group given, comparing synth(blue) to input set(orange)')\n        origautocorr=[]\n        for i in range(1,1000):\n            origautocorr.append(train.open_channels.diff(i).value_counts()[0])\n        print('generated trainautocorr')\n    synthautocorr=[]\n    for i in range(1,1000):\n        synthautocorr.append(synth.open_channels.diff(i).value_counts()[0])\n    print('generated synthautocorr')\n    synthautocorr=[]\n    for i in range(1,1000):\n        synthautocorr.append(synth.open_channels.diff(i).value_counts()[0])\n    print('generated synthautocorr')\n    #for i in range(0,len(synthautocorr)):\n    #    synthautocorr[i]=synthautocorr[i]/length\n    \n    plt.plot(synthautocorr,linewidth=3)#[0:500000])\n    plt.plot(origautocorr)\n    plt.xlim(-10, 10)\n    plt.show()\n    plt.plot(synthautocorr,linewidth=3)#[0:500000])\n    plt.plot(origautocorr)\n    plt.xlim(-10, 70)\n    plt.show()\n    plt.plot(synthautocorr,linewidth=3)#[0:500000])\n    plt.plot(origautocorr)\n    plt.xlim(-10, 200)\n    plt.show()\n    plt.plot(synthautocorr,linewidth=3)#[0:500000])\n    plt.plot(origautocorr)\n    plt.xlim(-10, 1000)\n    plt.show()\n    plt.xlim(-1, 16)\n    plt.hist(synth.open_channels,range=[0,50],bins=50)\n    plt.hist(orig.open_channels,bins=30)\n    plt.show()\n    \n    \ntrain_autocorr_dict=generatetrainautocorr(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_synthetic(length=500000,size=10,rates=rates2,puregroups=[4,9],noisegroup=9,reverse=False,usetestnoise=False):\n    mm=model1(rates,size=size)\n    synth=mm.state_run(length)\n    checkrun(synth,group=puregroups[0])\n    checkrun(synth,group=puregroups[1])\n    generate_pure_signal(synth,'signalp',puregroups[0],puregroups[1])\n    add_noise_make_signal(synth,'signal',noisegroup,reverse=reverse)\n    check_synth_signal(synth,puregroups[0])\n    check_synth_signal(synth,puregroups[1])\n    print(synth.head())\n    return synth\n\ndef create_synthetic_hack(length=100000,size=10,rates=rates2,puregroups=[4,9],noisegroup=9,reverse=False,usetestnoise=False):\n    print('HACK VERSION ONLY CREATES runs of 100000')\n    mm=model1(rates,size=size)\n    synth=mm.state_run(length)\n    #checkrun(synth,group=puregroups[0])\n    #checkrun(synth,group=puregroups[1])\n    print('NOT Making autocorrelation check plots! (DONT worrry duude, rates are fine)')\n    generate_pure_signal_hack(synth,'signalp',puregroups[0],puregroups[1])\n    add_noise_make_signal_hack(synth,'signal',noisegroup,reverse=reverse)\n    #check_synth_signal(synth,puregroups[0])\n    #check_synth_signal(synth,puregroups[1])\n    print('NOT running check_synth_signal, - not informative')\n    check_synth_vs_test5_hack(synth)\n    compare_synth_test5_50Hz(synth)\n    print(synth.head())\n    return synth\n\ndef generate_pure_signal_hack(synthx,name,traingroup1,traingroup2):\n    print('creating signalp column for synth based the list thats hardcoded right here!')\n    signalp_list=(-5.5,-4.4,\n     -3.1005879806196607,\n     -1.6904845933226527,\n     -0.5866951569088326,\n     0.6522344081285519,\n     1.8921235881801317,\n     3.1403901473484637,\n     4.378914822039075,\n     5.601466304727297,\n     6.870557241519672)\n    synthx[name]=synthx.open_channels #placeholder, gets overwritten\n    for i in range(0,11):\n        synthx.loc[synthx.open_channels==i,name]=signalp_list[i]\n    synthx.reset_index(drop=True,inplace=True)\n    gc.collect()\n\ndef add_noise_make_signal_hack(synth,name,traingroup,reverse=False):\n    print('adding noise based on sin fits to 50Hz and gaussian noise!')\n    length=synth.shape[0]\n    noise_std=0.4119683951753552\n    gaussian_noise=np.random.normal(0,noise_std*.983,size=length)\n    print('original std on noise (train):',noise_std)\n    print('gaussian component of synthetic noise',gaussian_noise.std())\n    x_50Hz=np.arange(0,length)\n    A=np.linspace(0.04742,0.1475,length)\n    signal_50Hz=0.942*A*np.sin(np.pi/(100)*0.997807*x_50Hz+1.3-5/100)\n    synth['noisep']=gaussian_noise+signal_50Hz\n    synth[name]=synth.signalp+gaussian_noise+signal_50Hz\n    print('total synth noisep std:',(gaussian_noise+signal_50Hz).std())\n\n    synth[name]=synth.signalp+train_dict[traingroup].noisep #placeholder, should overwrite\n    if reverse:\n            synth[name]=synth.signalp+train_dict[traingroup].noisep.values[::-1] #placeholder, should overwrite\n\ndef check_synth_vs_test5_hack(synth):\n    fig = plt.figure(figsize = (18, 6))\n    ax = fig.add_subplot()\n\n    bins1=150\n    n_train, bins_train, patches_train = ax.hist(synth.signal, bins = bins1, color='blue',stacked = False, density = True)\n    n_test, bins_test, patches_test = ax.hist(test_dict[5].signal, bins = bins_train, color='red',stacked = False, density = True,alpha=0.6)\n    print(test_dict[5].shape)\n    print(synth.shape)\n\n    ax.set_xlabel(\"Signal\") \n    ax.set_ylabel(\"Density\")\n    ax.set_title('set 5 test (red) and synth (blue) max channel 10 sets')\n    handles, labels = ax.get_legend_handles_labels()\n    plt.show()\n    \ndef compare_synth_test5_50Hz(synth):\n    #shows 50Hz signal in test data\n    length=synth.shape[0]\n    range1=12800\n    fig = plt.figure(figsize = (18, 6))\n    ax = fig.add_subplot()\n    for j in [0]:\n        period=200\n        synth['phase']=synth.index+j\n        synth['phase']=synth.phase.mod(period)\n        averagenoise=[]\n        for i in range(0,int(100000/range1)):\n            averagenoise=[]\n            sett=synth[int(i*range1):int((i+1)*range1)]\n            for p in range(0,period):\n                averagenoise.append(sett[sett.phase==p].noisep.mean())\n            ax.plot(np.arange(i*period,(i+1)*period),averagenoise)\n    period=200\n    x=np.arange(0,100000)\n    A=np.linspace(0.04742,0.1475,100000)\n    y=0.942*A*np.sin(np.pi/(100)*0.997807*x+1.3-5/100)\n    sinsynth=pd.DataFrame({'x':x,'y':y})\n    sinsynth['phase']=sinsynth.x.mod(period)\n    averagenoise=[]\n\n    for i in range(0,int(100000/range1)):\n        averagenoise=[]\n        sett=sinsynth[int(i*range1):int((i+1)*range1)]\n        for p in range(0,period):\n            averagenoise.append(sett[sett.phase==p].y.mean())\n        ax.plot(np.arange(i*period,(i+1)*period),averagenoise)\n    ax.set_xlabel(\"Signal\") \n    ax.set_ylabel(\"Time (averaged, full run)\")\n    ax.set_title('synthetic data 50Hz sin component')\n    \n    range1=12800\n    fig = plt.figure(figsize = (18, 6))\n    ax = fig.add_subplot()\n    for j in [0]:\n        group=5\n        period=200\n        test_dict[group]['phase']=test_dict[group].index+j\n        test_dict[group]['phase']=test_dict[group].phase.mod(period)\n        averagenoise=[]\n        for i in range(0,int(100000/range1)):\n            averagenoise=[]\n            sett=test_dict[group][int(i*range1):int((i+1)*range1)]\n            for p in range(0,period):\n                averagenoise.append(sett[sett.phase==p].noisep.mean())\n            ax.plot(np.arange(i*period,(i+1)*period),averagenoise)\n\n\n#create a signal (no noise), plot by same method as above, see if plot looks the same (but without noise)\n    period=200\n    x=np.arange(0,100000)\n    A=np.linspace(0.04742,0.1475,100000)\n    y=0.942*A*np.sin(np.pi/(100)*0.997807*x+1.3-5/100)\n    sinsynth=pd.DataFrame({'x':x,'y':y})\n    sinsynth['phase']=sinsynth.x.mod(period)\n    #shows 50Hz signal in test data\n    averagenoise=[]\n\n    for i in range(0,int(100000/range1)):\n        averagenoise=[]\n        sett=sinsynth[int(i*range1):int((i+1)*range1)]\n        for p in range(0,period):\n            averagenoise.append(sett[sett.phase==p].y.mean())\n        ax.plot(np.arange(i*period,(i+1)*period),averagenoise)\n        ax.set_title('Test set 5 50Hz sin component'+str(j))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"real=pd.read_csv('../input/ion-real-synth1/astr1.csv',header=None)\nreal['open_channels']=real[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkrun(real,group=5,train=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rates4=[[10932, 31,0 , 0, 0,   0],#(with T) low then matches ave ok(?)\n        [11.5, 10932, 218, 0, 0,   0],\n        [0, 353, 10932, 3368, 0, 0],\n        [0, 0, 4799, 10932, 109, 0],\n        [0, 0, 0, 262, 10932,  24],\n        [0, 0, 0, 0, 638,   10932]]\n31+11.5+218+353+3368+4799+109+262+24+638","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#generate train autocorr has been modifed to only work on 100000 point sets\n#check run also modifed to only work on 100000 point sets\n\nrates3=[[0.997, 3.159e-3, 3.042e-5, 3.728e-6, 1.052e-8, 4.957e-12],\n  [1.185e-3, 0.978, 1.789e-2, 3.272e-3, 1.262e-5, 7.532e-9],\n  [2.093e-5, 0.033, 0.7, 0.265, 1.633e-3, 1.332e-6],\n  [2.598e-6, 6.080e-3, 0.269, 0.716, 9.018e-3, 1.093e-5],\n  [1.761e-8, 5.635e-5, 3.974e-3, 2.168e-2, 0.972, 2.245e-3],\n  [7.220e-11, 2.925e-7, 2.820e-5, 2.285e-4, 1.952e-2, 0.98]]\nratest=[[0.997, 3.159e-3, 3.042e-5, 3.728e-6, 1.052e-8, 4.957e-12],\n  [1.185e-3, 0.978, 1.789e-2, 3.272e-3, 1.262e-5, 7.532e-9],\n  [2.093e-5, 0.033, 0.7, 0.265, 1.633e-3, 1.332e-6],\n  [2.598e-6, 6.080e-3, 0.269, 0.716, 9.018e-3, 1.093e-5],\n  [1.761e-8, 5.635e-5, 3.974e-3, 2.168e-2, 0.972, 2.245e-3],\n  [7.220e-11, 2.925e-7, 2.820e-5, 2.285e-4, 1.952e-2, 0.98]]\nmid=4000\n\nratesz=[[10000-(11.5), 11.5,0 , 0, 0,   0],#similar to below (with T)\n        [31, 10000-(353+31), 353, 0, 0,   0],\n        [0, 218, 10000-(218+4799), 4799, 0, 0],\n        [0, 0, 3368, 10000-(3368+262), 262, 0],\n        [0, 0, 0, 109, 10000-(109+638),  638],\n        [0, 0, 0, 0, 24,   10000-(24)]]\nratesas=[[10000, 11.5,0 , 0, 0,   0],#low (not horrible), then a tiny bit high. ave bit too high\n        [31, 10000, 353, 0, 0,   0],#low diff one on autocorr (with T)\n        [0, 218, 10000, 4799, 0, 0],\n        [0, 0, 3368, 10000, 262, 0],\n        [0, 0, 0, 109, 10000,  638],\n        [0, 0, 0, 0, 24,   10000]]\nrates4=[[9813.5, 11.5,0 , 0, 0,   0],#(with T) low then matches ave ok(?)\n        [31, 9813.5, 353, 0, 0,   0],\n        [0, 218, 9813.5, 4799, 0, 0],\n        [0, 0, 3368, 9813.5, 262, 0],\n        [0, 0, 0, 109, 9813.5,  638],\n        [0, 0, 0, 0, 24,   9813.5]]\nratest=[[6313.5, 11.5,0 , 0, 0,   0],#\n        [31, 6313.5, 353, 0, 0,   0],\n        [0, 218, 6313.5, 4799, 0, 0],\n        [0, 0, 3368, 6313.5, 262, 0],\n        [0, 0, 0, 109, 6313.5,  638],\n        [0, 0, 0, 0, 24,   6313.5]]\nratesx=[[(11.5), 11.5,0 , 0, 0,   0],#way too low everywhere (with T)\n        [31, (31+353), 353, 0, 0,   0],\n        [0, 218, (218+4799), 4799, 0, 0],\n        [0, 0, 3368, (3368+262), 262, 0],\n        [0, 0, 0, 109, (109+638),  638],\n        [0, 0, 0, 0, 24,   (24)]]\nratest=[[0.997, 3.060e-3, 3.005e-5, 3.075e-6, 8.678e-9, 4.240e-12],#original rates from qub(their model)\n  [1.135e-3, 0.978, 1.842e-2, 2.781e-3, 1.074e-5, 6.635e-9],#matches at first, quickly is too high\n  [1.805e-5, 2.983e-2, 0.744, 0.225, 1.388e-3, 1.170e-6],#(no T) ave too high\n  [2.632e-6, 6.419e-3, 0.32, 0.664, 8.693e-3, 1.096e-5],\n  [1.786e-8, 5.957e-5, 4.755e-3, 2.089e-2, 0.972, 2.292e-3],\n  [2.319e-10, 9.785e-7, 1.065e-4, 7.004e-4, 0.061, 0.938]]\nratesz=[[0.997, 3.060e-3, 0, 0, 0, 0],#original rates from qub(their model) (with zeros)\n  [1.135e-3, 0.978, 1.842e-2, 0, 0, 0],#about same as above, maybe not quite as high\n  [0, 2.983e-2, 0.744, 0.225, 0, 0],#(no T) ave too high\n  [0, 0, 0.32, 0.664, 8.693e-3, 0],\n  [0, 0, 0, 2.089e-2, 0.972, 2.292e-3],\n  [0, 0, 0, 0, 0.061, 0.938]]\nratesl=[[0.997, 3.060e-3, 3.005e-5, 3.075e-6, 8.678e-9, 4.240e-12],#decrease d to c\n  [1.135e-3, 0.978, 1.842e-2, 2.781e-3, 1.074e-5, 6.635e-9],#pretty good, first slightly high\n  [1.805e-5, 2.983e-2, 0.744, 0.225, 1.388e-3, 1.170e-6],#\n  [2.632e-6, 6.419e-3, 0.22, 0.664, 8.693e-3, 1.096e-5],\n  [1.786e-8, 5.957e-5, 4.755e-3, 2.089e-2, 0.972, 2.292e-3],\n  [2.319e-10, 9.785e-7, 1.065e-4, 7.004e-4, 0.061, 0.938]]\nratesl=[[0.997, 3.060e-3, 3.005e-5, 3.075e-6, 8.678e-9, 4.240e-12],#decrease d to c\n  [1.135e-3, 0.978, 1.842e-2, 2.781e-3, 1.074e-5, 6.635e-9],#pretty good, first slightly high, then low\n  [1.805e-5, 2.983e-2, 0.744, 0.225, 1.388e-3, 1.170e-6],#ave too high\n  [2.632e-6, 6.419e-3, 0.32-8.693e-3, 0.664, 8.693e-3, 1.096e-5],\n  [1.786e-8, 5.957e-5, 4.755e-3, 2.089e-2, 0.972, 2.292e-3],\n  [2.319e-10, 9.785e-7, 1.065e-4, 7.004e-4, 0.061, 0.938]]\n\nrates4=[[10932, 31,0 , 0, 0,   0],#(with T) low then matches ave ok(?)\n        [11.5, 10932, 218, 0, 0,   0],\n        [0, 353, 10932, 3368, 0, 0],\n        [0, 0, 4799, 10932, 109, 0],\n        [0, 0, 0, 262, 10932,  24],\n        [0, 0, 0, 0, 638,   10932]]\nrates4=np.array(rates4).T.tolist()\ndef normalize_rates(rates):\n    for i in range(0,len(rates)):\n        tot=0\n        for j in range(0,len(rates[i])):\n            tot=tot+rates[i][j]\n        for j in range(0,len(rates[i])):\n            rates[i][j]=rates[i][j]/tot\n    return(rates)\nrates5=[[0.997, 3.060e-3, 0, 0, 0, 0],\n  [1.086e-3, 0.978, 1.842e-2, 0, 0, 0],\n  [0, 2.983e-2, 0.744, 0.225, 0, 0],\n  [0, 0, 0.32, 0.664, 8.693e-3, 0],\n  [0, 0, 0, 2.089e-2, 0.972, 2.292e-3],\n  [0, 0, 0, 0, 0.061, 0.938]]\nsynth1=create_synthetic(length=100000,size=5,puregroups=[5,8],noisegroup=8,reverse=False,rates=normalize_rates(rates4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rates \nrates3=[[0.997, 3.159e-3, 3.042e-5, 3.728e-6, 1.052e-8, 4.957e-12],\n  [1.185e-3, 0.978, 1.789e-2, 3.272e-3, 1.262e-5, 7.532e-9],\n  [2.093e-5, 0.033, 0.7, 0.265, 1.633e-3, 1.332e-6],\n  [2.598e-6, 6.080e-3, 0.269, 0.716, 9.018e-3, 1.093e-5],\n  [1.761e-8, 5.635e-5, 3.974e-3, 2.168e-2, 0.972, 2.245e-3],\n  [7.220e-11, 2.925e-7, 2.820e-5, 2.285e-4, 1.952e-2, 0.98]]\n\nfor i in range(0,len(rates2)):\n    tot=0\n    for j in range(0,len(rates2[i])):\n        tot=tot+rates2[i][j]\n    for j in range(0,len(rates2[i])):\n        rates2[i][j]=rates2[i][j]/tot\n        \nsynth1=create_synthetic(length=500000,size=10,puregroups=[4,9],noisegroup=4,reverse=False,rates=rates3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"runlength=100000\nsynth_5_5=pd.DataFrame()\n#for i in range(0,50):\n#    print(i)\nsynth1=create_synthetic_hack(length=runlength,size=10,puregroups=[4,9],noisegroup=4,reverse=False)\n    #synth_5_5=pd.concat([synth_5_5,synth1])\n    #synth_5_5.reset_index(inplace=True,drop=True)\n#synth_5_5.to_csv('synth5M_5_5.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''### add 5 and 5 to get extra 10 channel set\nsynth5p5_1=pd.DataFrame()\nsynth5p5_2=pd.DataFrame()\nsynth5p5_1['open_channels']=train_dict[5].open_channels+train_dict[8].open_channels\nsynth5p5_2['open_channels']=train_dict[5].open_channels+train_dict[8].open_channels\nsynth5psynth_1=pd.DataFrame()\nsynth5psynth_2=pd.DataFrame()\nsynth5psynth_3=pd.DataFrame()\nsynth5psynth_4=pd.DataFrame()\nsynth5psynth_1['open_channels']=train_dict[5].open_channels+synth5_1.open_channels\nsynth5psynth_2['open_channels']=train_dict[8].open_channels+synth5_2.open_channels\nsynth5psynth_3['open_channels']=train_dict[5].open_channels+synth5_3.open_channels\nsynth5psynth_4['open_channels']=train_dict[8].open_channels+synth5_4.open_channels\ncheckrun(synth5p5_1,group=9)\ncheckrun(synth5p5_2,group=4)\ncheckrun(synth5psynth_1,group=9)\ncheckrun(synth5psynth_2,group=4)\n\ngenerate_pure_signal(synth5p5_1,'signalp',4,9)\ngenerate_pure_signal(synth5p5_2,'signalp',4,9)\ngenerate_pure_signal(synth5psynth_1,'signalp',4,9)\ngenerate_pure_signal(synth5psynth_2,'signalp',4,9)\ngenerate_pure_signal(synth5psynth_3,'signalp',4,9)\ngenerate_pure_signal(synth5psynth_4,'signalp',4,9)\n\nadd_noise_make_signal(synth5p5_1,'signal',4,reverse=False)\nadd_noise_make_signal(synth5p5_2,'signal',9,reverse=False)\nadd_noise_make_signal(synth5psynth_1,'signal',4,reverse=False)\nadd_noise_make_signal(synth5psynth_2,'signal',9,reverse=False)\nadd_noise_make_signal(synth5psynth_3,'signal',4,reverse=False)\nadd_noise_make_signal(synth5psynth_4,'signal',9,reverse=False)\n    \ncheck_synth_signal(synth5p5_1,4)\ncheck_synth_signal(synth5p5_2,4)\ncheck_synth_signal(synth5psynth_1,4)\ncheck_synth_signal(synth5psynth_2,4)\ncheck_synth_signal(synth5psynth_3,4)\ncheck_synth_signal(synth5psynth_4,4)\n\n\nsynth5p5_1[['signal','open_channels']].to_csv('synth5p5_4noise_500k.csv')\nsynth5p5_2[['signal','open_channels']].to_csv('synth5p5_9noise_500k.csv')\nsynth5psynth_1[['signal','open_channels']].to_csv('synth5psynth1_4noise_500k.csv')\nsynth5psynth_2[['signal','open_channels']].to_csv('synth5psynth2_9noise_500k.csv')\nsynth5psynth_3[['signal','open_channels']].to_csv('synth5psynth3_4noise_500k.csv')\nsynth5psynth_4[['signal','open_channels']].to_csv('synth5psynth4_9noise_500k.csv')\n\nadd_noise_make_signal(synth5p5_1,'signal',4,reverse=True)\nadd_noise_make_signal(synth5p5_2,'signal',9,reverse=True)\nadd_noise_make_signal(synth5psynth_1,'signal',4,reverse=True)\nadd_noise_make_signal(synth5psynth_2,'signal',9,reverse=True)\nadd_noise_make_signal(synth5psynth_3,'signal',4,reverse=True)\nadd_noise_make_signal(synth5psynth_4,'signal',9,reverse=True)\n\ncheck_synth_signal(synth5p5_1,4)\ncheck_synth_signal(synth5p5_2,4)\ncheck_synth_signal(synth5psynth_1,4)\ncheck_synth_signal(synth5psynth_2,4)\ncheck_synth_signal(synth5psynth_3,4)\ncheck_synth_signal(synth5psynth_4,4)\n\nsynth5p5_1[['signal','open_channels']].to_csv('synth5p5_4noisereversed_500k.csv')\nsynth5p5_2[['signal','open_channels']].to_csv('synth5p5_9noisereversed_500k.csv')\nsynth5psynth_1[['signal','open_channels']].to_csv('synth5psynth1_4noisereversed_500k.csv')\nsynth5psynth_2[['signal','open_channels']].to_csv('synth5psynth2_9noisereversed_500k.csv')\nsynth5psynth_3[['signal','open_channels']].to_csv('synth5psynth3_4noisereversed_500k.csv')\nsynth5psynth_4[['signal','open_channels']].to_csv('synth5psynth4_9noisereversed_500k.csv')\n\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''train_like_shit=pd.concat([train_dict[4],train_dict[9],synth5p5_1,synth5psynth_1,synth5psynth_2,synth5psynth_3,synth5psynth_4,synth1,synth2,synth3])\ntrain_like_shit.reset_index(inplace=True,drop=True)\ntrain_like_shit[['signal','open_channels']].to_csv('train49_5M.csv')'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#verify that train and test have similar autocorrelation in group 4/9\n'''testautocorr=[]\ntrainautocorr=[]\nfor i in range(1,1000):\n    testautocorr.append(test_dict[5].signal.diff(i).round(1).value_counts()[0])\n    trainautocorr.append(train_dict[4][0:100000].signal.diff(i).round(1).value_counts()[0])\nprint('ok')\nfig =  plt.figure(figsize = (20,10))\naxes = fig.add_subplot(111)\nplt.plot(testautocorr,linewidth=3)\nplt.plot(trainautocorr)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checkrun(wavebase_dict[5],train=train_dict[9][0:100000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checkrun(pd.concat([wavebase_dict[7],wavebase_dict[5]]),train=train_dict[9][0:200000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''for i in range(0,10):\n    print(i)\n    print(train_dict[i].groupby('open_channels').noisep.std())\n    print(train_dict[i].groupby('open_channels').noisep.mean())\n\nprint(test_dict[5].groupby('open_channels').noisep.std())\nprint(test_dict[5].groupby('open_channels').noisep.mean())'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dict[7].open_channels.corr(train_dict[8].open_channels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_pred7=pd.read_csv('../input/liverpool-10channels-from-5-subtract-signal/predictions_570_580.csv')\nnew1_pred7=pd.read_csv('../input/liverpool-10channels-from-5/predictions_570_580.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(test_dict[7].open_channels==new1_pred7.open_channels).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"5674/len(test_dict[7])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,10):\n\n    print(test_dict[i].open_channels.corr(new1_pred7.open_channels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,10):\n    print(test_dict[i].open_channels.corr(new_pred7.open_channels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n=5\nr=6\ncomb(n+r-1,r-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"value_counts_dict=dict(train_dict[5].open_channels.value_counts())\nmax_chan=5\nr=3\nconsistent_state_dict={}\nfraction_n_dict={}\ntotal_data=len(train_dict[5])\n\nfor n in range(0,6):\n    consistent_states=comb(n+r-1,r-1)*comb((max_chan-n)+r-1,r-1)\n    consistent_state_dict[n]=consistent_states\n    fraction_n_dict[n]=value_counts_dict[n]/total_data\n    print('open_channels =',n,'has',consistent_states,'consistent states')\n    print('percent of data with',n, 'open channels is',fraction_n_dict[n])\nave_consistent_states=0\nfor n in range(0,6):\n    ave_consistent_states=ave_consistent_states+fraction_n_dict[n]*consistent_state_dict[n]\nprint()\nprint('average number of consistent states is',ave_consistent_states)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"46**3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(fraction_n_dict.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=dict(train_dict[5].open_channels.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}