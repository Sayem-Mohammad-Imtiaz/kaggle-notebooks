{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# India House Price Prediction Challenge"},{"metadata":{},"cell_type":"markdown","source":"This is a regression problem because we have a continuous target variable and the feautures with which we shall use to train our model.\nBelow are the 12 variables which are contained in the datasets.\n"},{"metadata":{},"cell_type":"markdown","source":"* This Dataset has the following variables:\n\nColumn and it's                                       Description\n* POSTED_BY  -                                 Category marking who has listed the property\n* UNDER_CONSTRUCTION -                        Under Construction or Not\n* RERA -                                       Rera approved or Not\n* BHK_NO -                                     Number of Rooms\n* BHKORRK -                                    Type of property\n* SQUARE_FT -                                  Total area of the house in square feet\n* READYTOMOVE -                                Category marking Ready to move or Not\n* RESALE -                                     Category marking Resale or not\n* ADDRESS -                                    Address of the property\n* LONGITUDE -                                  Longitude of the property\n* LATITUDE -                                   Latitude of the property\n* TARGET -                                     Price in lacs"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nsns.set_style(\"whitegrid\")\nplt.style.use(\"fivethirtyeight\")\nfrom sklearn.preprocessing import  StandardScaler\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV,train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainD=pd.read_csv('../input/house-price-prediction-challenge/train.csv')\ntestD =pd.read_csv('../input/house-price-prediction-challenge/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#getting to know the kind of data we have\ntrainD.shape,testD.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainD.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testD.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#displaying some more detials about the data\ntrainD.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above display, we can note that there are no rows with missing values among other information\nthat we can extract such as the various data types of the columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"#brief statistics  about numerical variables\ntrainD.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above code shows that we have  houses with very high prices of about 30000 lacs. These could be probably fancy ones. The median price is about 62 implying that most houses are relatively cheaper."},{"metadata":{"trusted":true},"cell_type":"code","source":"#brief statistics  about categorical variables\ntrainD.describe(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The code above shows us that we have 3 categorical variables, very many records with unique addresses\namong other information that is extractable"},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets examine the count of  values in the posted_by categorical variable.\nposted_counts= pd.value_counts(trainD.POSTED_BY)\nposted_counts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above code shows us that most house records have been posted by dealers, followed by owners and then builders post the least."},{"metadata":{},"cell_type":"markdown","source":"****Lets do an exploratory data analysis on the data to train our models.****"},{"metadata":{"trusted":true},"cell_type":"code","source":"# A categorical plot of POSTED_BY variable\nplt.figure(figsize=(10,8))\nax=sns.catplot(x='POSTED_BY',kind='count',data=trainD)\nplt.xlabel('POSTED_BY')\nplt.ylabel('Count of Posted_By Records')\nplt.title('A count distribution of Posted_by category ')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"UNDER_CONSTRUCTION_counts= pd.value_counts(trainD.UNDER_CONSTRUCTION)\nUNDER_CONSTRUCTION_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A plot of UNDER_CONSTRUCTION categories\nplt.figure(figsize=(10,8))\nax=sns.catplot(x='UNDER_CONSTRUCTION',kind='count',data=trainD)\nplt.xlabel('UNDER_CONSTRUCTION')\nplt.ylabel('Count of UNDER_CONSTRUCTION ')\nplt.title('A count distribution of UNDER_CONSTRUCTION categories')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above code and visualisation shows that we have about 24k records of houses not under construction  and about 5k records of houses under construction."},{"metadata":{"trusted":true},"cell_type":"code","source":"RERA_counts= pd.value_counts(trainD.RERA)\nRERA_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A plot of RERA categories\nplt.figure(figsize=(10,8))\nax=sns.catplot(x='RERA',kind='count',data=trainD)\nplt.xlabel('RERA')\nplt.ylabel('Count of RERA records')\nplt.title('A count distribution of UNDER_CONSTRUCTION categories')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The code above and visualisation shows that we have about 20k recordes that are not approved by RERA and about 10k records  approved by RERA"},{"metadata":{"trusted":true},"cell_type":"code","source":"BHK_NO_counts= pd.value_counts(trainD['BHK_NO.'])\nBHK_NO_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A plot of BHK_NO categories\nplt.figure(figsize=(10,8))\nax=sns.catplot(x='BHK_NO.',kind='count',data=trainD)\nplt.xlabel('number of Rooms.')\nplt.ylabel('Count of houses')\nplt.title('A count distribution of number of Room categories')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above code shows us that most  houses are majorly built with 2 rooms or 3 then followed by 1,4,5. the other number of rooms are highly skewed with few records"},{"metadata":{"trusted":true},"cell_type":"code","source":"BHK_OR_RKcounts= pd.value_counts(trainD['BHK_OR_RK'])\nBHK_OR_RKcounts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A plot of property type\nplt.figure(figsize=(10,8))\nax=sns.catplot(x='BHK_OR_RK',kind='count',data=trainD)\nplt.xlabel('Type of Property.')\nplt.ylabel('Count of Property')\nplt.title('A count distribution of Type of Property')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above code shows that the major property type is BHK with close to 30k records constituting almost all the records posted"},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualise the square feet of the data using seaborn distribution plot.\nax=sns.distplot(trainD.SQUARE_FT,kde=True)\nplt.title('A Square feet distribution ')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# decreasing the skewness in square feet feature using log transformation in both train and test data\ntrainD['SQUARE_FT'] = np.log(trainD['SQUARE_FT'])\ntestD['SQUARE_FT'] = np.log(testD['SQUARE_FT'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Aplot close to normal distribution as a result of decrease in skewness\nax=sns.distplot(trainD.SQUARE_FT,kde=True)\nplt.title('A Square feet distribution of Total area of the house ')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"READY_TO_MOVE_counts= pd.value_counts(trainD['READY_TO_MOVE'])\nREADY_TO_MOVE_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A plot of Category marking Ready to move or Not\nplt.figure(figsize=(10,8))\nax=sns.catplot(x='READY_TO_MOVE',kind='count',data=trainD)\nplt.xlabel('Category marking Ready to move or Not.')\nplt.ylabel('Count of Category marking')\nplt.title('A count distribution of Category marking Ready to move or Not')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Resale_counts= pd.value_counts(trainD['RESALE'])\nResale_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A plot of Resale records or not\nplt.figure(figsize=(10,8))\nax=sns.catplot(x='RESALE',kind='count',data=trainD)\nplt.xlabel('Category marking Resale or not')\nplt.ylabel('Count of marking Resale or not ')\nplt.title('A distribution of Resale or not ')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above code and visual shows that over 90% of houses are available for resale  and just a few not available for  resale."},{"metadata":{},"cell_type":"markdown","source":"**For my analysis here, i won't include the address variable.It needs further manipulation before it can become more informative  and be used in our modelling since it's a text variable yet our models work best with numbers.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualise the square feet of the data using seaborn distribution plot.\nax=sns.distplot(trainD.LONGITUDE,kde=True)\nplt.title('A Longitude distribution ')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualise the square feet of the data using seaborn distribution plot.\nax=sns.distplot(trainD.LATITUDE,kde=True)\nplt.title('A Latitude distribution ')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualise the square feet of the data using seaborn distribution plot.\nax=sns.distplot(trainD['TARGET(PRICE_IN_LACS)'],kde=True)\nplt.title('A Price distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainD['TARGET(PRICE_IN_LACS)'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets examine the house with the highest price\ntrainD[trainD['TARGET(PRICE_IN_LACS)']==30000]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The code above shows that the highest house price was posted by category dealer, it's available for resale,it has got 3 rooms and  it goes for upto 30000 lacs ."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets examine the house with the lowest price\ntrainD[trainD['TARGET(PRICE_IN_LACS)']==0.25]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The code above shows that the lowest house price was posted by category owner,it's not under construction, it has got 3 rooms , it's available for resale and it's ready to be occupied"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.heatmap(trainD.corr(),vmax=0.8, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see from the above heat map that the target is more correlated to the square feet feature than any other numerical columns.\nwe will probably use all these features in our modeling process"},{"metadata":{},"cell_type":"markdown","source":"**Lets investigate if there is a relationship between number of rooms  and the prices**"},{"metadata":{"trusted":true},"cell_type":"code","source":"BHK_NO_counts= pd.value_counts(trainD['BHK_NO.'])\nBHK_NO_counts = list(BHK_NO_counts[BHK_NO_counts.values > 1000].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BHK_NO_counts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot of distribution of sprices for rooms\nplt.figure(figsize=(8,6))\n\n# Plot each room distribution of prices\nfor BHK in BHK_NO_counts:\n    # Select the room category\n    subset = trainD[trainD['BHK_NO.'] == BHK]\n    \n    # Density plot of prices\n    sns.kdeplot(subset['TARGET(PRICE_IN_LACS)'],label = BHK,shade = False, alpha = 0.8);\n    \n# label the plot\nplt.xlabel('House prices', size = 10); plt.ylabel('Density', size = 10); \nplt.title('Density Plot of house prices by rooms', size = 8);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The room price distribution is largely skewed to the right with room category 4 having a high density distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets investigate the relationship between posted_by and prices.\nposted_counts= pd.value_counts(trainD.POSTED_BY)\nposts=posted_counts.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot of distribution of Prices for Posted_By\nplt.figure(figsize=(8,6))\n\n# Plot each Posted_by distribution of prices\nfor post in posts:\n    # Select the posted_by type\n    subset = trainD[trainD['POSTED_BY'] == post]\n    \n    # Density plot of prices\n    sns.kdeplot(subset['TARGET(PRICE_IN_LACS)'],label = post,shade = False, alpha = 0.8);\n    \n# label the plot\nplt.xlabel('House prices', size = 10); plt.ylabel('Density', size = 10); \nplt.title('Density Plot of house prices by Posted ', size = 10);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution of posted_by variable is largely skewed to the right with dealers having generaly high prices, with the builder category having more prices centered around median thus having a high density distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_features = ['POSTED_BY','UNDER_CONSTRUCTION','RERA','BHK_NO.','BHK_OR_RK','SQUARE_FT','LONGITUDE','LATITUDE']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = trainD[base_features]\ntest_data=   testD[base_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape,test_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = trainD['TARGET(PRICE_IN_LACS)']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = [cname for cname in train_data.columns \n                    if  train_data[cname].dtype == \"object\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_cat_colsOH= pd.get_dummies(train_data[cat_cols])\nTest_cat_colsOH= pd.get_dummies(test_data[cat_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Select numerical columns\nnum_cols = [cname for cname in train_data.columns \n            if train_data[cname].dtype in ['int64', 'float64']]\n\nscaler = StandardScaler()\ntrain_data[num_cols] = scaler.fit_transform(train_data[num_cols] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data[num_cols] = scaler.transform(test_data[num_cols] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_num_data = pd.DataFrame(train_data[num_cols])\ntest_num_data = pd.DataFrame(test_data[num_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data =pd.concat([Train_cat_colsOH, train_num_data],axis=1) \ntest_data =pd.concat([Test_cat_colsOH, test_num_data],axis=1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split validation set from training data\nX_train, X_val, y_train, y_val =train_test_split(train_data,y,test_size=0.2,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to  train a given  model and evaluate it on the validation set\ndef fit_and_evaluate(model):\n    \n    # Train the model\n    model.fit(X_train, y_train)\n    y_pred=model.predict(X_val)\n    mea = mean_absolute_error(y_val,y_pred)\n    R2_score =r2_score(y_val,y_pred)\n    rmse = np.sqrt((mean_squared_error(y_val, y_pred)))\n    print(\"The root mean squared error generated...is {:.2f}\".format(rmse))\n    print(\"The R2_score value .....................is {:.4f}\".format(R2_score))\n    print(\"The mean absolute  error generated is .......is {:.2f}\".format(mea))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Ridge_model = Ridge()\n\nfit_and_evaluate(Ridge_model) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_model = LinearRegression()\n\nfit_and_evaluate(linear_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_forest = RandomForestRegressor(random_state=0)\n\nfit_and_evaluate(random_forest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gradient_boosted = GradientBoostingRegressor(random_state=4)\n\nfit_and_evaluate(gradient_boosted) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The metric am caring more about is the model with the a least considerable root mean sqaured value,therefore am going to take the gradient boosting model for this prediction since it has more paramters to tune than the random forest. However, for me to furture improve on my accuracy, am going to user another metric of mean absolute error generated using the random search as the baseline then fine tune with gridsearch basing on the variation in the number of estimators.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of trees used in the boosting process\nn_estimators = [100, 500, 900, 1100, 1500]\n\n#loss function to be minimized\nloss = ['ls', 'lad', 'huber']\n\n# Maximum depth of each tree\nmax_depth = [2, 3, 5, 10, 15]\n#how much the contribution of each tree will shrink.\n\nlearning_rate = [0.005,0.01,0.05,0.1,0.5]\n\n# Minimum number of samples to split a node\nmin_samples_split = [2, 4, 6, 10]\n\n# Maximum number of features to consider for making splits\nmax_features = ['auto', 'sqrt', 'log2', None]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the grid of hyperparameters to search\nhyperparameter_grid = {'loss': loss,\n                       'learning_rate':learning_rate,\n                       'n_estimators': n_estimators,\n                       'max_depth': max_depth,\n                       'min_samples_split': min_samples_split,\n                       'max_features': max_features}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = GradientBoostingRegressor(random_state=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_cv = RandomizedSearchCV(estimator=model,\n                               param_distributions=hyperparameter_grid,\n                               scoring='neg_mean_absolute_error',\n                               cv=5, n_iter=30, \n                               n_jobs = -1, verbose = 1, \n                               return_train_score = True,\n                               random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_cv.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get all of the cv results and sort by the test performance\nrandom_results = pd.DataFrame(random_cv.cv_results_).sort_values('mean_test_score', ascending = False)\nrandom_results.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_cv.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a range of trees to evaluate\nparam_grid = {'n_estimators': [200,300,400,500, 800,1000 ]}\nmodel =  GradientBoostingRegressor( max_depth =15,\n                                   loss = 'ls',\n                                   alpha=0.9,\n                                   learning_rate=0.1,\n                                  min_samples_leaf = 1,\n                                  min_samples_split = 6,\n                                  max_features ='auto',\n                                  max_leaf_nodes=None,\n                                  random_state = 4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grid Search Object using the trees range and the random forest model\ngrid_search = GridSearchCV(estimator = model, param_grid=param_grid, cv = 5, \n                           scoring = 'neg_mean_absolute_error', verbose = 1,\n                           n_jobs = -1, return_train_score = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the results into a dataframe\nresults = pd.DataFrame(grid_search.cv_results_)\n\n# Plot the training and testing error vs number of trees\nplt.figure(figsize=(8, 8))\nplt.style.use('fivethirtyeight')\nplt.plot(results['param_n_estimators'], -1 * results['mean_test_score'], label = 'Test_Err')\nplt.plot(results['param_n_estimators'], -1 * results['mean_train_score'], label = 'Train_Err')\nplt.xlabel('Number of Trees'); plt.ylabel('Mean Abosolute Error'); plt.legend(\"best\");\nplt.title('Performance vs Number of Trees');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We realise that as we increase the number of trees, the model starts overfitting \nhowever, we shall consider the optimum value of the model before it starts to overfit with 200 estimators"},{"metadata":{"trusted":true},"cell_type":"code","source":"results.sort_values('mean_test_score', ascending = False).head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the best model\nfinal_modelGBR = grid_search.best_estimator_\nfinal_modelGBR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#final model performance\n\nfit_and_evaluate(final_modelGBR)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**After fitting my final model, my model performance price prediction greatly improved to approximately within 30 points from the  true market price with a root mean squared error of 129 and an R2_score accuracy value of 96%**"},{"metadata":{"trusted":true},"cell_type":"code","source":"SalesPrediction = final_modelGBR.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'Id': test_data.index, 'SalePrice': SalesPrediction})\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head(10).set_index('Id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All comments are welcome! there is always room for improvement."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}