{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=pd.read_csv(\"../input/jobathon-analytics-vidhya/train.csv\")\ntest_data=pd.read_csv(\"../input/jobathon-analytics-vidhya/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Checking if any new values are there in test data:\nHere we check whether there are any same class both in train and test class or any new class has been added.**","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"count=0\nfor col in train_data.columns:\n    if col not in [\"ID\",\"Reco_Policy_Premium\",\"Response\"]:\n        for val in test_data[col].unique():\n            if val not in train_data[col].unique():\n                print(col,val)\n                count+=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Here, we got to know that Region code is having many new classes******","metadata":{}},{"cell_type":"code","source":"train_data[\"Region_Code\"].nunique(),test_data[\"Region_Code\"].nunique(),count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There are total 225 new classes**","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize=(15,10))\nsns.heatmap(train_data.isnull(),yticklabels=False,cmap=\"viridis\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Holding_Policy_Cat,Holding_Policy_Type,Health Indicator contains Null values. So we need to check amount of missing values.**","metadata":{}},{"cell_type":"code","source":"# Number of of null values in each column\ncount=round(train_data.isnull().sum(),2)\npercent=round((train_data.isnull().sum()/train_data.shape[0])*100,2)\ndata=pd.concat([count,percent],axis=1)\ndata.reset_index(inplace=True)\ndata.rename(columns={0: 'Missing Values Count',1: 'Missing Values %'},inplace=True)\ndata[data['Missing Values Count']!=0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Null values Imputations**","metadata":{}},{"cell_type":"code","source":"train_data[\"Health Indicator\"].isnull().sum(),test_data[\"Health Indicator\"].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**While dealing with Health Indicator these indicators are taken from users. As for null values the user has not inputed any data . So we can take mode of previous values.Â¶**","metadata":{}},{"cell_type":"code","source":"train_data['Health Indicator'].fillna(train_data['Health Indicator'].mode()[0], inplace=True)\ntest_data['Health Indicator'].fillna(test_data['Health Indicator'].mode()[0], inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The null vaues for holding policy Duration & Type means there is non extisting customer.So, we can fill the NA by Zero.**","metadata":{}},{"cell_type":"code","source":"train_data[\"Holding_Policy_Duration\"].fillna(0,inplace=True)\ntest_data[\"Holding_Policy_Duration\"].fillna(0,inplace=True)\ntrain_data[\"Holding_Policy_Type\"].fillna(0,inplace=True)\ntest_data[\"Holding_Policy_Type\"].fillna(0,inplace=True)\ntrain_data[\"Holding_Policy_Duration\"]=train_data[\"Holding_Policy_Duration\"].replace('14+','15')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax=plt.subplots(figsize=(8,5))\nsns.set_style(\"whitegrid\")\nsns.countplot(x=\"Accomodation_Type\",hue='Response',data=train_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Both rented and owned owners shows same responses**","metadata":{}},{"cell_type":"code","source":"sns.catplot(x=\"Response\",y=\"Reco_Policy_Premium\",kind=\"violin\",data=train_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax = sns.countplot(x=\"Is_Spouse\", data=train_data,\n                   facecolor=(0, 0, 0, 0),\n                   linewidth=5,\n                   edgecolor=sns.color_palette(\"dark\", 3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Applying Label Encoder to both train & test data**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlef=LabelEncoder()\ntrain_data[\"City_Code\"]=LabelEncoder().fit_transform(train_data[\"City_Code\"])\ntrain_data[\"Accomodation_Type\"]=LabelEncoder().fit_transform(train_data[\"Accomodation_Type\"])\ntrain_data[\"Reco_Insurance_Type\"]=lef.fit_transform(train_data[\"Reco_Insurance_Type\"])\ntrain_data[\"Is_Spouse\"]=train_data[\"Is_Spouse\"].map({\"Yes\":1,\"No\":0})\ntrain_data[\"Health Indicator\"]=lef.fit_transform(train_data[\"Health Indicator\"])\ntrain_data[\"Holding_Policy_Duration\"]=train_data[\"Holding_Policy_Duration\"].astype(float).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data[\"Is_Spouse\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data[\"City_Code\"]=LabelEncoder().fit_transform(test_data[\"City_Code\"])\ntest_data[\"Accomodation_Type\"]=LabelEncoder().fit_transform(test_data[\"Accomodation_Type\"])\ntest_data[\"Reco_Insurance_Type\"]=lef.fit_transform(test_data[\"Reco_Insurance_Type\"])\ntest_data[\"Is_Spouse\"]=test_data[\"Is_Spouse\"].map({\"Yes\":1,\"No\":0})\ntest_data[\"Holding_Policy_Duration\"]=test_data[\"Holding_Policy_Duration\"].replace('14+','15')\ntest_data[\"Health Indicator\"]=lef.fit_transform(test_data[\"Health Indicator\"])\ntest_data[\"Holding_Policy_Duration\"]=test_data[\"Holding_Policy_Duration\"].astype(float).astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=train_data.drop('Response',axis=1)\nY=train_data[\"Response\"]\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model Buildings**","metadata":{}},{"cell_type":"code","source":"## Hyperparameter optimization using RandomizedSearchCV,GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nimport xgboost","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**USE HYPERPARAMETER OPTIMIZATION USING RANDOMIZED SEARCH CV TO SELECT BEST PARAMETERS FOR XGBOOSTS **","metadata":{}},{"cell_type":"code","source":"classifier=xgboost.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.7, gamma=0.4, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.05, max_delta_step=0, max_depth=6,\n              min_child_weight=1,monotone_constraints='()',\n              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n              objective='binary:logistic', random_state=0, reg_alpha=0,\n              reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier.fit(X_train,Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nXGB_accuracies = cross_val_score(estimator = classifier, X = X_train, y = Y_train, cv = 10)\nprint(\"Mean_XGB_Acc : \", XGB_accuracies.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xg_preds = classifier.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nprint(metrics.classification_report(Y_test, xg_preds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier()\nclf = clf.fit(X_train,Y_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DT_accuracies = cross_val_score(estimator = clf, X = X_train, y = Y_train, cv = 10)\nprint(\"Mean_DT_Acc : \", DT_accuracies.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DT_pred = clf.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Accuracy:\",metrics.accuracy_score(Y_test, DT_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf1= DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\nclf1 = clf1.fit(X_train,Y_train)\nDTE_accuracies = cross_val_score(estimator = clf1, X = X_train, y = Y_train, cv = 10)\nprint(\"Mean_DTE_Acc : \", DTE_accuracies.mean())\nMean_DTE_Acc :  0.7579245872963088\nDTE_pred = clf.predict(X_test)\nprint(\"Accuracy:\",metrics.accuracy_score(Y_test,DTE_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**KNN MODEL**","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier(n_neighbors=7)\nknn.fit(X_train, Y_train)\nKNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n                     weights='uniform')\nknn_accuracies = cross_val_score(estimator = knn, X = X_train, y = Y_train, cv = 10)\nprint(\"knn_DTE_Acc : \", knn_accuracies.mean())\nknn_DTE_Acc :  0.7254399736618911\nknn_pred=knn.predict(X_test)\nprint(\"KNN_Accuracy:\",metrics.accuracy_score(Y_test,knn_pred))\nKNN_Accuracy: 0.7281362594169669\nprint(metrics.classification_report(Y_test, knn_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_pred =knn.predict(test_data)\ntest_data_pred\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Final Submission**","metadata":{}},{"cell_type":"code","source":"sub_fn=test_data.iloc[:,0:1].copy()\nsub_fn[\"Prediction\"]=pd.DataFrame(test_data_pred)\nsub_fn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}