{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom statsmodels.graphics.mosaicplot import mosaic\n\n\nfrom mpl_toolkits.basemap import Basemap\nfrom matplotlib import cm\n\nfrom sklearn.cluster import KMeans\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n\nimport math\nimport re\nimport datetime","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing the CVS file"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"../input/aviation-accident-database-synopses/AviationData.csv\",encoding = \"ISO-8859-1\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Time Series Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting date field in the components\n\ndf['Year'] = df['Event.Date'].apply(lambda d: datetime.datetime.strptime(d, \"%Y-%m-%d\").year)\ndf['Month'] = df['Event.Date'].apply(lambda d: datetime.datetime.strptime(d, \"%Y-%m-%d\").month)\ndf['Day'] = df['Event.Date'].apply(lambda d: datetime.datetime.strptime(d, \"%Y-%m-%d\").day)\n\ndf_timeseries = df[df['Year'] >= 1982]\n\n# For the time series charts I start sorting data\ndf_timeseries = df_timeseries.sort_values(by=['Year', 'Month', 'Day'], ascending=True)\n\nyears = np.arange(1982, 2017)\n\nsns.set(style=\"darkgrid\")\n\nplt.subplot(211)\n\ng = sns.countplot(x=\"Year\", data=df_timeseries, palette=\"GnBu_d\", order=years)\ng.set_xticklabels(labels=years)\na = plt.setp(g.get_xticklabels(), rotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Initial Exporatory Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2, ncols=2,figsize=(15, 10))\nfig.subplots_adjust(hspace=.6)\ncolors = ['#99cc33', '#a333cc', '#333dcc']\ndf['Broad.Phase.of.Flight'].value_counts().plot(ax=axes[0,0], kind='bar', title='Phase of Flight')\ndf['Broad.Phase.of.Flight'].value_counts().plot(ax=axes[0,1], kind='pie', title='Phase of Flight')\ndf['Weather.Condition'].value_counts().plot(ax=axes[1,0], kind='pie', colors=colors, title='Weather Condition')\n# TODO: clean up to add \"other\"\n# ds['cleaned.make'].value_counts().plot(ax=axes[1,1], kind='pie', title='Aircraft Make')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cleaning the Data Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"#cleaning the predcitors \ndf['Make'] = df[\"Make\"].str.lower()\ndf['Engine.Type'].fillna('None',inplace = True)\ndf['Weather.Condition'].fillna('unknown',inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cleaning outcome y \ndf.loc[(df['Injury.Severity'] != \"Non-Fatal\") & (df['Injury.Severity'] != \"Incident\"), 'Injury.Severity'] = 'Fatal'\ndf.loc[(df['Injury.Severity'] == \"Incident\"), 'Injury.Severity'] = 'Fatal'\ndf['Injury.Severity'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Import Decision Tree Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import graphviz\nfrom sklearn.tree import export_graphviz\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.tree import export_graphviz","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One Hot Encoding the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#splitting the data\npredictors = ['Weather.Condition','Engine.Type','Make']\none_hot_data = pd.get_dummies(df[predictors],drop_first=True)\n# Train Set : 1100 samples\ndf_train = pd.DataFrame(df[:67409])\nhot_predictor_train = pd.DataFrame(one_hot_data[:67409])\ny_train = pd.DataFrame(df_train['Injury.Severity'])\nX_train = hot_predictor_train \n\n# Test Set : 360 samples\ndf_test = pd.DataFrame(df[-16853:])\nhot_predictor_test = pd.DataFrame(one_hot_data[-16853:])\ny_test = pd.DataFrame(df_test['Injury.Severity'])\nX_test = hot_predictor_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree using Train Data\ndectree = DecisionTreeClassifier(max_depth = 3)  # create the decision tree object\ndectree.fit(X_train, y_train)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dectree_pred(X_train,X_test) :\n    # Predict Response corresponding to Predictors\n    y_train_pred = dectree.predict(X_train)\n    y_test_pred = dectree.predict(X_test)\n\n    # Check the Goodness of Fit (on Train Data)\n    print(\"Goodness of Fit of Model \\tTrain Dataset\")\n    print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n    print()\n\n    listall_train = confusion_matrix(y_train, y_train_pred)\n    listtop_train = listall_train[0]\n    listbot_train = listall_train[1]\n    fpr_train= listtop_train[1]/(sum(listtop_train))\n    fnr_train = listbot_train[0]/(sum(listbot_train))\n    print('The False Positive Rate is \\t:{0:2f}'.format(fpr_train))\n    print('The False Negative Rate is \\t:{0:2f}'.format(fnr_train))\n    print()\n\n    # Check the Goodness of Fit (on Test Data)\n    print(\"Goodness of Fit of Model \\tTest Dataset\")\n    print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n    print()\n\n    listall_test = confusion_matrix(y_test, y_test_pred)\n    listtop_test = listall_test[0]\n    listbot_test = listall_test[1]\n    fpr_test= listtop_test[1]/(sum(listtop_test))\n    fnr_test = listbot_test[0]/(sum(listbot_test))\n    print('The False Positive Rate is \\t:{0:2f}'.format(fpr_test))\n    print('The False Negative Rate is \\t:{0:2f}'.format(fnr_test))\n\n\n    # Plot the Confusion Matrix for Train and Test\n    f, axes = plt.subplots(1, 2, figsize=(12, 4))\n    sns.heatmap(confusion_matrix(y_train, y_train_pred),\n               annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n    sns.heatmap(confusion_matrix(y_test, y_test_pred), \n               annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n\n#1 is substantial , 0 is Fatal\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dectree_pred(X_train,X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Export the Decision Tree as a dot object\ntreedot = export_graphviz(dectree,                                      # the model\n                          feature_names = X_test.columns,          # the features \n                          out_file = None,                              # output file\n                          filled = True,                                # node colors\n                          rounded = True,                               # make pretty\n                          special_characters = True)                    # postscript\n\n# Render using graphviz\nimport graphviz\ngraphviz.Source(treedot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decision Tree for Secondary Outcome of Aircraft Damage "},{"metadata":{},"cell_type":"markdown","source":"Cleaning the outcome "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Aircraft.Damage'].fillna('unknown',inplace = True)\ndf.loc[(df['Aircraft.Damage'] != \"Destroyed\") , 'Aircraft.Damage'] = 'Substantial'\ndf['Aircraft.Damage'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = pd.DataFrame(df_train['Aircraft.Damage'])\ny_test = pd.DataFrame(df_test['Aircraft.Damage'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree using Train Data\ndectree = DecisionTreeClassifier(max_depth = 3)  # create the decision tree object\ndectree.fit(X_train, y_train)                    # train the decision tree model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dectree_pred(X_train,X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Export the Decision Tree as a dot object\ntreedot = export_graphviz(dectree,                                      # the model\n                          feature_names = X_test.columns,          # the features \n                          out_file = None,                              # output file\n                          filled = True,                                # node colors\n                          rounded = True,                               # make pretty\n                          special_characters = True)                    # postscript\n\n# Render using graphviz\nimport graphviz\ngraphviz.Source(treedot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Correlation of Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\ndef cramers_corrected_stat(confusion_matrix, correction: bool) -> float:\n    \"\"\"Calculate the Cramer's V corrected stat for two variables.\n\n    Args:\n        confusion_matrix: Crosstab between two variables.\n        correction: Should the correction be applied?\n\n    Returns:\n        The Cramer's V corrected stat for the two variables.\n    \"\"\"\n    chi2 = stats.chi2_contingency(confusion_matrix, correction=correction)[0]\n    n = confusion_matrix.sum().sum()\n    phi2 = chi2 / n\n    r, k = confusion_matrix.shape\n\n    # Deal with NaNs later on\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        phi2corr = max(0.0, phi2 - ((k - 1.0) * (r - 1.0)) / (n - 1.0))\n        rcorr = r - ((r - 1.0) ** 2.0) / (n - 1.0)\n        kcorr = k - ((k - 1.0) ** 2.0) / (n - 1.0)\n        corr = np.sqrt(phi2corr / min((kcorr - 1.0), (rcorr - 1.0)))\n    return corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Location'] = df[\"Location\"].str.upper() #making all CAPS\ndf['Location'].fillna('unknown',inplace = True) #removing nan\n#removing locations with frequency less than 100 for faster computing \ncol = 'Location'  # 'bar'\nn = 100  # 2\ndf_filtered  = df[df.groupby(col)[col].transform('count').ge(n)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing Useless variables that do not describe air crash"},{"metadata":{"trusted":true},"cell_type":"code","source":"#droping columns that do not hold any true value to prediction or clustering\nlist_to_drop = ['Event.Id','Investigation.Type','Accident.Number','Event.Date','Country','Report.Status','Publication.Date']\ndf_filtered = df_filtered.drop(list_to_drop, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a confusion matrix \ndf_cramer = pd.DataFrame()\ncount = 0 \nfor n in df_filtered:\n    for i in df_filtered:\n        confusion_matrix = pd.crosstab(df_filtered[n], df_filtered[i]).values\n        value = cramers_corrected_stat(confusion_matrix,True)\n        df_cramer.loc[n,i] = value\n        count += 1 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(figsize=(10, 10))\nax = sns.heatmap(df_cramer, vmin=0, vmax=1, square = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting Mosaic Plots to show general relation of locations and injury"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(figsize=(20, 25))\nax  = mosaic(df_filtered, ['Location', 'Injury.Severity'], title='DataFrame as Source', gap = 0.001 ,ax= axes ,horizontal = False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(figsize=(20, 25))\nax  = mosaic(df_filtered, ['Location', 'Aircraft.Damage'], title='DataFrame as Source', gap = 0.001 ,ax= axes , axes_label = True , horizontal = False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Selecting variables for clustering "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Selecting variables for clustering \ndf_cluster = df[['Location','Injury.Severity','Aircraft.Damage','Make','Amateur.Built','Engine.Type']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing NAN\ndf_cluster = df_cluster.replace(np.nan, 'Unknown', regex=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Initialising Kmodes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from kmodes.kmodes import KModes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using K-Mode with \"Cao\" initialization"},{"metadata":{"trusted":true},"cell_type":"code","source":"km_cao = KModes(n_clusters=2, init = \"Cao\", n_init = 1, verbose=1)\nfitClusters_cao = km_cao.fit_predict(df_cluster)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fitClusters_cao","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clusterCentroidsDf = pd.DataFrame(km_cao.cluster_centroids_)\nclusterCentroidsDf.columns = df_cluster.columns\nclusterCentroidsDf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using K-Mode with \"Huang\" initialization"},{"metadata":{"trusted":true},"cell_type":"code","source":"km_huang = KModes(n_clusters=2, init = \"Huang\", n_init = 1, verbose=1)\nfitClusters_huang = km_huang.fit_predict(df_cluster)\nfitClusters_huang","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cost = []\nfor num_clusters in list(range(1,5)):\n    kmode = KModes(n_clusters=num_clusters, init = \"Cao\", n_init = 1, verbose=1)\n    kmode.fit_predict(df_cluster)\n    cost.append(kmode.cost_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = np.array([i for i in range(1,5,1)])\nplt.plot(y,cost)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"km_cao = KModes(n_clusters=2, init = \"Cao\", n_init = 1, verbose=1)\nfitClusters_cao = km_cao.fit_predict(df_cluster)\nfitClusters_cao","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clustersDf = pd.DataFrame(fitClusters_cao)\nclustersDf.columns = ['cluster_predicted']\ncombinedDf = pd.concat([df_cluster, clustersDf], axis = 1).reset_index()\ncombinedDf = combinedDf.drop(['index'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting outcome into cluster dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster_0 = combinedDf[combinedDf['cluster_predicted'] == 0]\ncluster_1 = combinedDf[combinedDf['cluster_predicted'] == 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploratory Analysis on clusters"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(6,2 ,figsize=(20, 10))\n\nsns.countplot(x ='Injury.Severity' , data =cluster_0 , ax = axes[0,0] )\nsns.countplot(x ='Aircraft.Damage' , data =cluster_0 , ax = axes[1,0] )\nsns.countplot(x ='Make' , data =cluster_0 , ax = axes[2,0] ,order = pd.value_counts(cluster_0['Make']).iloc[:5].index)\nsns.countplot(x ='Amateur.Built' , data =cluster_0 , ax = axes[3,0] )\nsns.countplot(x ='Engine.Type' , data =cluster_0 , ax = axes[4,0],order = pd.value_counts(cluster_0['Engine.Type']).iloc[:5].index)\nsns.countplot(x ='Location' , data =cluster_0 , ax = axes[5,0],order = pd.value_counts(cluster_0['Location']).iloc[:5].index)\n\n\nsns.countplot(x ='Injury.Severity' , data =cluster_1 , ax = axes[0,1] )\nsns.countplot(x ='Aircraft.Damage' , data =cluster_1 , ax = axes[1,1] )\nsns.countplot(x ='Make' , data =cluster_1 , ax = axes[2,1] ,order = pd.value_counts(cluster_1['Make']).iloc[:5].index)\nsns.countplot(x ='Amateur.Built' , data =cluster_1 , ax = axes[3,1] )\nsns.countplot(x ='Engine.Type' , data =cluster_1 , ax = axes[4,1],order = pd.value_counts(cluster_1['Engine.Type']).iloc[:5].index)\nsns.countplot(x ='Location' , data =cluster_1 , ax = axes[5,1],order = pd.value_counts(cluster_1['Location']).iloc[:5].index)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['cluster_predicted'] = combinedDf['cluster_predicted']\n\ndf_location_data = df[['Location','Latitude','Longitude','cluster_predicted']]\ndf_location_data = df_location_data.dropna()\n\ncluster0_locs =  df_location_data[df_location_data['cluster_predicted'] == 0]\ncluster1_locs =  df_location_data[df_location_data['cluster_predicted'] == 1]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Libraries for Location Visualisation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from mpl_toolkits.basemap import Basemap\nfrom matplotlib import cm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"centroid_region0 = cluster0_locs.loc[cluster0_locs['Location'] == clusterCentroidsDf.at[0, 'Location']]\ncentroid_region1 = cluster1_locs.loc[cluster1_locs['Location'] == clusterCentroidsDf.at[1, 'Location']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cluster 0 Visualisation"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nplt.figure(figsize=(15,15))\n\nm = Basemap(\n    llcrnrlon=-165,\n    llcrnrlat=20,\n    urcrnrlon=-40,\n    urcrnrlat=70,\n    projection='cyl',\n    resolution='c',\n    area_thresh=None,\n    rsphere=6370997.0,\n    no_rot=False,\n    suppress_ticks=True,\n    satellite_height=35786000,\n    boundinglat=None,\n    fix_aspect=True,\n    anchor='C',\n    celestial=False,\n    round=False,\n    epsg=None,\n    ax=None,\n)\nx, y = m(cluster0_locs['Longitude'].values, cluster0_locs['Latitude'].values)\nm.drawcoastlines()\nm.drawcountries()\nm.hexbin(x, y, gridsize=1000, bins='log', cmap=cm.YlOrRd)\nm.scatter(centroid_region0['Longitude'], centroid_region0['Latitude'], 50, color='g')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cluster 1 Visualisation"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nplt.figure(figsize=(15,15))\n\nm = Basemap(\n    llcrnrlon=-165,\n    llcrnrlat=20,\n    urcrnrlon=-40,\n    urcrnrlat=70,\n    projection='cyl',\n    resolution='c',\n    area_thresh=None,\n    rsphere=6370997.0,\n    no_rot=False,\n    suppress_ticks=True,\n    satellite_height=35786000,\n    boundinglat=None,\n    fix_aspect=True,\n    anchor='C',\n    celestial=False,\n    round=False,\n    epsg=None,\n    ax=None,\n)\nx, y = m(cluster1_locs['Longitude'].values, cluster1_locs['Latitude'].values)\nm.drawcoastlines()\nm.drawcountries()\nm.hexbin(x, y, gridsize=1000, bins='log', cmap=cm.YlOrRd)\nm.scatter(centroid_region1['Longitude'], centroid_region1['Latitude'], 50, color='g')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clustering Based on Location only"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latlon = df_location_data[['Longitude', 'Latitude']]\nlatlon.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding Optimum Number of Clusters"},{"metadata":{"trusted":true},"cell_type":"code","source":"Sum_of_squared_distances = []\nK = range(1,15)\nfor k in K:\n    km = KMeans(n_clusters=k)\n    km = km.fit(latlon)\n    Sum_of_squared_distances.append(km.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(K, Sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Sum_of_squared_distances')\nplt.title('Elbow Method For Optimal k')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=3)\nkmodel = kmeans.fit(latlon)\ncentroids = kmodel.cluster_centers_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"centroids\nlons, lats = zip(*centroids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nplt.figure(figsize=(15,15))\nnorth, south, east, west = 71.39, 24.52, -66.95, 172.5\nm = Basemap(\n    llcrnrlon=-135,\n    llcrnrlat=-20,\n    urcrnrlon=86,\n    urcrnrlat=60,\n    projection='cyl',\n    resolution='c',\n    area_thresh=None,\n    rsphere=6370997.0,\n    no_rot=False,\n    suppress_ticks=True,\n    satellite_height=35786000,\n    boundinglat=None,\n    fix_aspect=True,\n    anchor='C',\n    celestial=False,\n    round=False,\n    epsg=None,\n    ax=None,\n)\nx, y = m(df_location_data['Longitude'].values, df_location_data['Latitude'].values)\nm.drawcoastlines()\nm.drawcountries()\nm.hexbin(x, y, gridsize=1000, bins='log', cmap=cm.YlOrRd)\ncx, cy = m(lons, lats)\nm.scatter(cx, cy, 50, color='g')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}