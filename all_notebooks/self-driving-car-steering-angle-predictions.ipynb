{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Importing Modules**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\n\nfrom keras import layers\n\nfrom keras import models\n\nfrom keras.layers import (Input, Dense, Activation, ZeroPadding2D,\nBatchNormalization, Flatten, Conv2D, concatenate, Lambda)\n\nfrom keras.layers import (AveragePooling2D, MaxPooling2D, Dropout,\nGlobalMaxPooling2D, GlobalAveragePooling2D)\n\nfrom keras.models import Model, load_model\nfrom keras import regularizers, optimizers\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.utils import to_categorical\n\nprint(os.listdir(\"../input\"))\nprint(os.listdir('../input/self driving car training data/data'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reading Driving Data from driving_log.csv**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"path = '../input/self driving car training data/data'\npath = os.path.join(path,'driving_log.csv')\n\ndata_frame = pd.read_csv(path)\ncenter = data_frame[data_frame.columns[0]].values\nleft = data_frame[data_frame.columns[1]].values\nright = data_frame[data_frame.columns[2]].values\nsteering = data_frame[data_frame.columns[3]].values\n\nno_of_examples = len(steering)\nprint(no_of_examples)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Helper Function for data Augmentation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_flip(image, steering_angle):\n    \n    image = cv2.flip(image, 1)\n    steering_angle = -steering_angle\n    \n    return image, steering_angle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Collecting the Training Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = []\ntrain_y = []\n\nimg_folder = '../input/self driving car training data/data/IMG'\nstear_adjust_factor = 0.2\nIMAGE_HEIGHT = 100 \nIMAGE_WIDTH = 100\n\nfor i in range(no_of_examples):\n    \n    for choice in range(3):\n        \n        if choice == 0: #Center\n            img = cv2.imread(os.path.join(img_folder,center[i].split('IMG/')[1]))\n            steering_angle = steering[i]\n\n        elif choice == 1: #Left\n            img = cv2.imread(os.path.join(img_folder,left[i].split('IMG/')[1]))\n            steering_angle = steering[i] + stear_adjust_factor\n\n        elif choice == 2: #Right\n            img = cv2.imread(os.path.join(img_folder,right[i].split('IMG/')[1]))\n            steering_angle = steering[i] - stear_adjust_factor\n        \n        img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)[:,:,1]\n        img = cv2.resize(img,(IMAGE_HEIGHT,IMAGE_WIDTH))\n        \n        train_x.append(img)\n        train_y.append(steering_angle)\n        \n        flip_img,steering_angle = random_flip(img,steering_angle)\n                \n        train_x.append(flip_img)\n        train_y.append(steering_angle)\n        \n\ntrain_x = np.array(train_x)\ntrain_x = np.reshape(train_x,[train_x.shape[0],train_x.shape[1],train_x.shape[2],1])\n\ntrain_y = np.array(train_y)\ntrain_y = np.reshape(train_y,[train_y.shape[0],1])\n\nprint(train_x.shape)\nprint(train_y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Splitting the Training Data into Train and Test sets**"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(train_x,train_y,random_state=42,test_size=.20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Neural Network Architecture**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def model(height,width):\n        \n    x_input = Input(shape=(height,width,1))\n    \n    x = Lambda(lambda x: x/127.5-1.0)(x_input)\n    \n    x = Conv2D(32,(3,3),activation='relu',padding='same')(x_input)\n    \n    x = Conv2D(32,(3,3),activation='relu',padding='same')(x)\n    x = MaxPooling2D((2,2),padding='valid')(x)\n    \n    x = Conv2D(64,(3,3),activation='relu',padding='same')(x)\n    \n    x = Conv2D(64,(3,3),activation='relu',padding='same')(x)\n    x = MaxPooling2D((2,2),padding='valid')(x)\n    \n    x = Conv2D(128,(3,3),activation='relu',padding='same')(x)\n    x = MaxPooling2D((2,2),padding='valid')(x)\n    \n    x = Conv2D(128,(3,3),activation='relu',padding='same')(x)\n    x = MaxPooling2D((2,2),padding='valid')(x)\n    \n    x = Flatten()(x)\n    x = Dropout(0.5)(x)\n       \n    x = BatchNormalization()(x)\n    x = Dense(512)(x)\n    x = Dense(256)(x)\n    x = Dense(64)(x)\n    x = Dense(1)(x)\n    \n    model = Model(inputs=x_input,outputs=x,name='model')\n    \n    return model\n    \nmodel = model(IMAGE_HEIGHT,IMAGE_WIDTH)\nprint(model.summary())\n\nopt = optimizers.Adam(lr=0.0001)\nmodel.compile(loss='mse',\n             optimizer=opt,\n             metrics=['mse'])\n\nhist = model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=32,epochs=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Saving the Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('Saved_Model.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualization**"},{"metadata":{"trusted":true},"cell_type":"code","source":"img = cv2.imread(os.path.join(img_folder,center[1000].split('IMG/')[1]))\n\nlayer_outputs = [layer.output for layer in model.layers[1:19]] \nactivation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n\nimg = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\nimg = img[:,:,1]\nimg = cv2.resize(img,(IMAGE_HEIGHT,IMAGE_WIDTH))\nimg = np.reshape(img,[1,IMAGE_HEIGHT,IMAGE_WIDTH,1])\n\nactivations = activation_model.predict(img)\n\nlayer_names = []\nfor layer in model.layers[1:19]:\n    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n    \nimages_per_row = 16\n\nfor layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n    \n    try:\n        n_features = layer_activation.shape[-1] # Number of features in the feature map\n        size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n        n_cols = n_features // images_per_row # Tiles the activation channels in this matrix\n        display_grid = np.zeros((size * n_cols, images_per_row * size))\n        for col in range(n_cols): # Tiles each filter into a big horizontal grid\n            for row in range(images_per_row):\n\n                try:\n                    channel_image = layer_activation[0,\n                                                     :, :,\n                                                     col * images_per_row + row]\n                    channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable\n                    channel_image /= channel_image.std()\n                    channel_image *= 64\n                    channel_image += 128\n                    channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n                    display_grid[col * size : (col + 1) * size, # Displays the grid\n                                 row * size : (row + 1) * size] = channel_image\n                except:\n                    continue\n\n        scale = 1. / size\n        plt.figure(figsize=(scale * display_grid.shape[1],\n                            scale * display_grid.shape[0]))\n        plt.title(layer_name)\n        plt.grid(False)\n        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n        \n    except:\n        continue","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}