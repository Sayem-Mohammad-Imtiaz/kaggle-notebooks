{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ABSTRACT\nThis project analyzes Airbnb listings in the city of  New York to better understand how different\nattributes such as bedrooms, location, house type amongst others can be used to accurately predict\nthe price of listing that is optimal in terms of the hostâ€™s profitability yet affordable to their guests. \n\n*This model is intended to be helpful to the internal pricing tools that Airbnb provides to its hosts.*\n\n### Objective of the PROJECT is to find:\n- Estimate listing price based on provided amenities\n- How review scores effect price of listing\n- how cancellation policy effects price of listing\n\n\n### dataset\ncollected from InsideAirBnB website for NewYork City(NYC) from jan-mar 2020\nhttp://insideairbnb.com/get-the-data.html\n\n## Data Dictionary\n\n- id - listing identifier that can be used to create a join with other files\n- last_scraped - data scrapped date\n- name -name of the listing\n- host_id -unique id given to host\n- host_since - joining date of host can be used to calculate host experience based on duration since the first listing\n- host_is_superhost - categorical t or f - describing highly rated and relaible hosts (https://www.airbnb.co.uk/superhost)\n- host_identity_verified - categorical t or f - another credibility metric\n- host_response_rate -  response rate is the percentage of new enquiries and reservation requests you responded to (by either     accepting/pre-approving or declining) within 24 hours in the past 30 days\n- host_listings_count - total listing host have\n- neighbourhood_group- Burough of NYC\n- neighbourhood_cleansed -neighbourhoods in a burough zipcode\n- latitude - we will use it later to visualise the data on the map\n- longitude - we will use it later to visualise the data on the map\n- property_type -description of property ex:appartment,privatehome\n- room_type - type of room ex:shared room\n- accommodates - discrete value describing property number people can accomodate\n- bathrooms - another discrete value describing property\n- bedrooms - another discrete value describing property\n- beds - another discrete value describing property\n- bed_type - categorical value describing property type of bed ex: realbed or couch\n- amenities - wifi tv dryer so on...\n- price - price per night for number of included guests\n- security_deposit - another continous value assiociated with the cost\n- cleaning_fee - additional cost at the top of rent\n- guests_included - number of guest that can be allowed on the price\n- extra_people - cost of additional person per night\n- minimum_nights - another discrete value that is cost related.Listing with high value of minimum nights are likely sublettings\n- maximun nights -property availability\n- availablitiy 365-availability of the listing from scrapped date to next 365 days\n- first_review - first review date\n- last_review - last review date\n- number_of_reviews - total number of reviews in entire listing history\n- review_scores_accuracy - discrete value - numbers between 2 and 10\n- review_scores_value - discrete value - numbers between 2 and 10\n- review_scores_rating - this value is calculated as weighted sum of other scores\n- reviews_per_month - given reviews in a month \n- instant_bookable - categorical value - t or false\n- cancellation_policy - ordinal value with 5 categories that can be ordered from lowest to highest level of flexibility","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import pyforest\nimport statistics\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nimport random\n\nfrom mpl_toolkits.mplot3d import Axes3D\nimport plotly.graph_objs as go\n\n# import statistical libraries\nfrom scipy.stats import norm,skew, boxcox_normmax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abm1 =  pd.read_csv('../input/airbnb-new-york-city-with-106-features/airbnbmark1.csv')\nabm1.head(3)\nprint('abm1.shape',abm1.shape)\nprint('abm1.size',abm1.size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <center>Steps Followed<center>\n    \n##   I. Data Processing\n##  II. EDA\n## III. Feature Engineering\n##  IV. Feature Selection\n##   V. Model Building  \n\n \n --------------------------------------------------------------------------------------------------------------------------  \n# I. Data Processing \n **We will do these following steps in Data Processing part:**\n\n- 1. Data Cleaning for special characters,spaces,nan and Checking Data types\n- 2. Extracting new features from existing features\n- 3. Imputing Missing Values\n- 4. Check Numerical, Categorical Values","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Initial Dropping of Unnecessary columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping columns that are irrelevant to our analysis \n\n# Created New Variable abm2 for dataset after dropping columns\n\nabm = abm1.drop(columns = ['id','name',\n                'summary','access','interaction',\n                'listing_url','scrape_id','last_scraped',\n                'space','description','experiences_offered',\n                'neighborhood_overview','notes','transit',\n                'house_rules','thumbnail_url','medium_url',\n                'picture_url','xl_picture_url','host_url',\n                'host_name','host_location','host_about',\n                'host_acceptance_rate','host_thumbnail_url','host_picture_url',\n                'host_neighbourhood','host_verifications','host_has_profile_pic',\n                'market','city','smart_location','country_code','is_location_exact',\n                'square_feet','minimum_minimum_nights','maximum_minimum_nights',\n                'minimum_maximum_nights','maximum_maximum_nights','minimum_nights_avg_ntm',\n                'maximum_nights_avg_ntm','calendar_updated','zipcode',\n                'neighbourhood','state',\n                'street','host_listings_count',#'neighbourhood',\n                'country','availability_30','availability_60','availability_90','host_id',\n                'calendar_last_scraped','weekly_price','monthly_price',\n                'review_scores_cleanliness','review_scores_checkin','review_scores_communication',\n                'review_scores_location','review_scores_value','license',\n                'jurisdiction_names','reviews_per_month','number_of_reviews','requires_license',\n                'is_business_travel_ready','require_guest_profile_picture','require_guest_phone_verification',\n                'calculated_host_listings_count','calculated_host_listings_count_entire_homes',\n                'calculated_host_listings_count_private_rooms',\n                'calculated_host_listings_count_shared_rooms','has_availability'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abm1.shape # new dataset after removing features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abm1 = abm1.drop_duplicates()\nprint('abm1.shape after dropping duplicate rows: ',abm1.shape)\nprint('abm1.size:  ',abm1.size)\nprint('DataTypes wise size: \\n', abm1.dtypes.value_counts())\nabm1.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note1: We are left with 38 features after dropping initial columns which are repetative counts, irrelevant to anaysis, long text data, URL's and 1,22,818 rows after dropping duplicates**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 1. Data Cleaning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"abm1.replace(('11249\\n11249'),11249,inplace=True)\nabm1.replace((' '),np.nan,inplace=True)\nabm1.host_response_rate = abm1.host_response_rate.str[:-1].astype('float64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_data(df):\n    \n    for i in ['price','cleaning_fee','security_deposit', 'extra_people']:\n        df[i]=df[i].str.replace('$','').str.replace(',', '').astype(float)\n        \n    df.replace('', np.nan, inplace=True)\n    \n    return df.head(2)\nclean_data(abm1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting Price our TARGET VAR into FLOAT\nabm1['price']=abm1['price'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing columns with f/t with 0/1\nabm1.replace({'f': 0, 't': 1}, inplace=True) \n\n#host_super host,instantbookable,identityverified,has_availabilty,requires licence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting Host_since dtype to datetime and creating new column host_days_active_years\nfrom datetime import datetime\n\nabm1.host_since = pd.to_datetime(abm1.host_since)\nabm1.first_review = pd.to_datetime(abm1.first_review)\nabm1.last_review = pd.to_datetime(abm1.last_review)\n\n# Calculating the number of years and days\nabm1['host_days_active_years'] = (datetime(2020, 4, 1) - abm1.host_since).astype('timedelta64[Y]')\nabm1['host_listing_since'] = (abm1.last_review - abm1.first_review).astype('timedelta64[Y]')\n#abm1['host_days_active_days'] = (datetime(2020, 4, 1) - abm1.host_since).astype('timedelta64[D]')\n# Printing mean and median\n#print(\"Mean of host_years:\", round(abm1['host_days_active_years'].mean(),0))\n#print(\"Median of host_years:\", abm1['host_days_active_years'].median())\n#print(\"Mode of host_years:\", abm1['host_days_active_years'].mode())\n\n#print('-------------')\n\n#print(\"Mean of host_days:\", round(abm1['host_days_active_days'].mean(),0))\n#print(\"Median of host_days:\", abm1['host_days_active_days'].median())\n#print(\"Mode of host_days:\", abm1['host_days_active_days'].mode())\n\n\n# print('\\nValueCounts:\\n',df['host_days_active_days'].value_counts(normalize=False))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting amenities feature \n\namenities_list = list(abm1.amenities)\namenities_list_string = \" \".join(amenities_list)\namenities_list_string = amenities_list_string.replace('{', '')\namenities_list_string = amenities_list_string.replace('}', ',')\namenities_list_string = amenities_list_string.replace('\"', '')\namenities_set = [x.strip() for x in amenities_list_string.split(',')]\namenities_set = set(amenities_set)\nprint('\\n Number of amenities present in total:',len(amenities_set))\n\nabm1.loc[abm1['amenities'].str.contains('Air conditioning|Central air conditioning'), 'air_conditioning'] = 1\nabm1.loc[abm1['amenities'].str.contains('Amazon Echo|Apple TV|Game console|Netflix|Projector and screen|Smart TV'), 'high_end_electronics'] = 1\nabm1.loc[abm1['amenities'].str.contains('BBQ grill|Fire pit|Propane barbeque'), 'bbq'] = 1\nabm1.loc[abm1['amenities'].str.contains('Balcony|Patio'), 'balcony'] = 1\nabm1.loc[abm1['amenities'].str.contains('Beach view|Beachfront|Lake access|Mountain view|Ski-in/Ski-out|Waterfront'), 'nature_and_views'] = 1\nabm1.loc[abm1['amenities'].str.contains('Bed linens'), 'bed_linen'] = 1\nabm1.loc[abm1['amenities'].str.contains('Breakfast'), 'breakfast'] = 1\nabm1.loc[abm1['amenities'].str.contains('TV'), 'tv'] = 1\nabm1.loc[abm1['amenities'].str.contains('Coffee maker|Espresso machine'), 'coffee_machine'] = 1\nabm1.loc[abm1['amenities'].str.contains('Cooking basics'), 'cooking_basics'] = 1\nabm1.loc[abm1['amenities'].str.contains('Dishwasher|Dryer|Washer'), 'white_goods'] = 1\nabm1.loc[abm1['amenities'].str.contains('Elevator'), 'elevator'] = 1\nabm1.loc[abm1['amenities'].str.contains('Exercise equipment|Gym|gym'), 'gym'] = 1\nabm1.loc[abm1['amenities'].str.contains('Family/kid friendly|Children|children'), 'child_friendly'] = 1\nabm1.loc[abm1['amenities'].str.contains('parking'), 'parking'] = 1\nabm1.loc[abm1['amenities'].str.contains('Garden|Outdoor|Sun loungers|Terrace'), 'outdoor_space'] = 1\nabm1.loc[abm1['amenities'].str.contains('Host greets you'), 'host_greeting'] = 1\nabm1.loc[abm1['amenities'].str.contains('Hot tub|Jetted tub|hot tub|Sauna|Pool|pool'), 'hot_tub_sauna_or_pool'] = 1\nabm1.loc[abm1['amenities'].str.contains('Internet|Pocket wifi|Wifi'), 'internet'] = 1\nabm1.loc[abm1['amenities'].str.contains('Long term stays allowed'), 'long_term_stays'] = 1\nabm1.loc[abm1['amenities'].str.contains('Pets|pet|Cat(s)|Dog(s)'), 'pets_allowed'] = 1\nabm1.loc[abm1['amenities'].str.contains('Private entrance'), 'private_entrance'] = 1\nabm1.loc[abm1['amenities'].str.contains('Safe|Security system'), 'secure'] = 1\nabm1.loc[abm1['amenities'].str.contains('Self check-in'), 'self_check_in'] = 1\nabm1.loc[abm1['amenities'].str.contains('Smoking allowed'), 'smoking_allowed'] = 1\nabm1.loc[abm1['amenities'].str.contains('Step-free access|Wheelchair|Accessible'), 'accessible'] = 1\nabm1.loc[abm1['amenities'].str.contains('Suitable for events'), 'event_suitable'] = 1\nabm1.loc[abm1['amenities'].str.contains('24-hour check-in'), 'check_in_24h'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Amenities Column Names:\\n',abm1.columns[35:],'\\n')\nprint(' Number of Amenities columns after categorizing under same names:',abm1.columns[35:].shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note 2:\nAbove are the Columns after categorizing amenieties with similar names we are left with 28 features from 148 columns in amenities set**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"frequent_amenities = []\ninfrequent_amenities=[]\nfor col in abm1.iloc[:,35:].columns:\n    if abm1[col].sum() > len(abm1)/5:\n        frequent_amenities.append(col)\n    else:\n        infrequent_amenities.append(col)\nprint('Common_amenities: \\n',frequent_amenities)\nprint('-----------------------')\nprint('Special_amenities: \\n',infrequent_amenities)\nprint('frequent_amenities',len(frequent_amenities))\nprint('infrequent_amenities',len(infrequent_amenities))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decreasig the value_counts in cancellation policy \nabm1.cancellation_policy.replace({\n    'super_strict_30': 'strict',\n    'super_strict_60': 'strict',\n    'strict_14_with_grace_period': 'strict'}, inplace=True)\nabm1.cancellation_policy.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decreasig the value_counts in property_type\nabm1['property_type'].value_counts()\n\nabm1['property_type'].value_counts()/abm1['property_type'].value_counts().sum()*100\n\n#With 10 categories we account for 98% of the listings\n\n(abm1['property_type'].value_counts()/abm1['property_type'].value_counts().sum()*100)[0:5].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Mod_prop_type=abm1['property_type'].value_counts()[5:len(abm1['property_type'].value_counts())].index.tolist()\n\ndef change_prop_type(label):\n    if label in Mod_prop_type:\n        label='Other'\n    return label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abm1.loc[:,'property_type'] = abm1.loc[:,'property_type'].apply(change_prop_type)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abm1['property_type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note3: We are going to create new column that sums up the total number of ameniteis present by each host**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"abm1['special_amenities']=abm1[['high_end_electronics','bbq','balcony','nature_and_views','breakfast','gym',\n 'outdoor_space',\n 'host_greeting',\n 'hot_tub_sauna_or_pool',\n 'pets_allowed',\n 'secure',\n 'smoking_allowed',\n#  'PH_Accessible',\n 'event_suitable',\n 'check_in_24h',\n#  'Private bathroom',\n#  'Baby protection'\n        ]].sum(axis=1)\nabm1['special_amenities'].isnull().sum()\nabm1.columns\nabm1['special_amenities'].astype(float)\n#abm1['special_amenities']=abm1['special_amenities'].mask(abm1['special_amenities']>0,1)\nabm1['special_amenities']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abm1.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## code for merging amenities into special features and if one amenity is present the value is 1 else 0\nabm1['common_amenities']=abm1[['bed_linen',\n 'tv',\n 'coffee_machine',\n 'cooking_basics',\n 'white_goods',\n 'elevator',\n 'child_friendly',\n 'parking',\n 'internet',\n 'long_term_stays',\n 'private_entrance',\n 'self_check_in',\n#  'Toiletries',\n#  'Safety'\n                               ]].sum(axis=1)\nabm1['common_amenities'].isnull().sum()\nabm1.columns\nabm1['common_amenities'].astype(float)\n# abm1['common_amenities']=abm1['common_amenities'].mask(abm1['common_amenities']>0,1)\nabm1['common_amenities']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abm1.columns[35:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping the actual columns\nabm1.drop(['air_conditioning', 'high_end_electronics', 'bbq', 'balcony',\n       'nature_and_views', 'bed_linen', 'breakfast', 'tv', 'coffee_machine',\n       'cooking_basics', 'white_goods', 'elevator', 'gym', 'child_friendly',\n       'parking', 'outdoor_space', 'host_greeting', 'hot_tub_sauna_or_pool',\n       'internet', 'long_term_stays', 'pets_allowed', 'private_entrance',\n       'secure', 'self_check_in', 'smoking_allowed', 'accessible',\n       'event_suitable', 'check_in_24h','first_review',\n        'last_review','host_since','amenities'],axis=1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_col = pd.DataFrame(columns=['avg_price_property_type'])\nnew_col['avg_price_property_type'] = abm1.groupby(['neighbourhood_cleansed','property_type'])['price'].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color=blue> new name is given to the dataframe \"abm2\" after adding new cols","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"abm2 = abm1.merge(new_col,left_on=['neighbourhood_cleansed','property_type'],right_on=['neighbourhood_cleansed','property_type'],how='left')\nprint(abm2.shape)\nprint(abm2.size)\nabm2.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color=blue> new name is given to the dataframe \"abm3\" after adding new cols","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_col1 = pd.DataFrame(columns=['avg_review_score'])\nnew_col1['avg_review_score'] = abm2.groupby(['neighbourhood_cleansed','property_type'])['review_scores_rating'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abm3 = abm2.merge(new_col1,left_on=['neighbourhood_cleansed','property_type'],right_on=['neighbourhood_cleansed','property_type'],how='left')\nprint(abm3.shape)\nprint(abm3.size)\nabm3.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# neighbourhood_group_cleansed is renamed as Borough\n#abm3['Borough'] = abm3['neighbourhood_group_cleansed']\n\n# guests_included is renamed as Num_of_guests_incl_forprice\n#abm3['Num_of_guests_incl_forprice'] = abm3['guests_included']\n\n# extra_people is renamed as price_per_extra_people\n#abm3['price_per_extra_people'] = abm3['extra_people']\n\nabm3=abm3.rename(columns={\"neighbourhood_group_cleansed\": \"Borough\", \"guests_included\": \"Num_of_guests_incl_forprice\"\n                    ,'extra_people':'price_per_extra_people'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abm3.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## IMPUTING MISSING NAN VALUES","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"abm3.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abm3.bedrooms.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import KNNImputer\n\nimputer = KNNImputer(missing_values=np.nan,n_neighbors=2, weights=\"uniform\")\n\nabm3['host_total_listings_count'] = imputer.fit_transform(abm3[['host_total_listings_count']])\n#abm1['host_days_active_years'] = imputer.fit_transform(abm1[['host_days_active_years']])\n#abm1['host_days_active_days'] = imputer.fit_transform(abm1[['host_days_active_days']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Group by neighborhood_cleansed and property_type fill in missing value by the median.\n\n# abm3[\"security_deposit\"] = abm3.groupby(['neighbourhood_cleansed','property_type'])[\"security_deposit\"].transform(\n#     lambda x: x.fillna(x.median()))\n\n# abm3[\"cleaning_fee\"] = abm3.groupby(['neighbourhood_cleansed','property_type'])[\"cleaning_fee\"].transform(\n#     lambda x: x.fillna(x.median()))\n\nabm3[\"beds\"] = abm3.groupby(['neighbourhood_cleansed','property_type'])[\"beds\"].transform(\n    lambda x: x.fillna(x.mode()))\n\nabm3[\"bathrooms\"] = abm3.groupby(['neighbourhood_cleansed','property_type'])[\"bathrooms\"].transform(\n    lambda x: x.fillna(x.mode()[0]))\n\nabm3[\"bedrooms\"] = abm3.groupby(['neighbourhood_cleansed','property_type'])[\"bedrooms\"].transform(\n    lambda x: x.fillna(x.mode()))\n\nabm3[\"review_scores_rating\"] = abm3.groupby(['neighbourhood_cleansed','property_type'])[\"review_scores_rating\"].transform(\n    lambda x: x.fillna(x.mean()))\n\n# abm3[\"review_scores_accuracy\"] = abm3.groupby(['neighbourhood_cleansed','property_type'])[\"review_scores_accuracy\"].transform(\n#     lambda x: x.fillna(x.mean()))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Group by neighborhood_cleansed and property_type fill in missing value by the mode.\nabm3[\"host_listing_since\"] = abm3.groupby(['neighbourhood_cleansed'])[\"host_listing_since\"].transform(\n    lambda x: x.fillna(x.mode()))\n\n\nabm3[\"host_is_superhost\"] = abm3.groupby(['neighbourhood_cleansed'])[\"host_is_superhost\"].transform(\n    lambda x: x.fillna(x.mode()))\n\n\nabm3[\"host_identity_verified\"] = abm3.groupby(['neighbourhood_cleansed'])[\"host_identity_verified\"].transform(\n    lambda x: x.fillna(x.mode()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_nan_remove=['host_response_time']\nfor i in features_nan_remove:\n    abm3[i]=abm3[i].astype('str').str.replace(\"nan\", \"unknown\").astype(str)\n    print('{}:{}'.format(i,abm2[i].isna().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_nan_remove=['review_scores_rating','host_response_rate','review_scores_accuracy','cleaning_fee','bedrooms','security_deposit','host_identity_verified','beds','host_days_active_years','review_scores_rating','host_is_superhost','host_listing_since','avg_review_score']\nfor i in features_nan_remove:\n    abm3[i]=abm3[i].astype('str').str.replace(\"nan\", \"100000000\").astype('float')\n    print('{}:{}'.format(i,abm3[i].isna().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_nan_remove=['review_scores_rating','host_response_rate','review_scores_accuracy','cleaning_fee','bedrooms','security_deposit','host_identity_verified','beds','host_days_active_years','review_scores_rating','host_is_superhost','host_listing_since','avg_review_score']\nfor i in features_nan_remove:\n    abm3[i]=abm3[i].replace(100000000, abm3[i].median())\n    print('{}:{}'.format(i,abm3[i].isna().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abm3.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abm3.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# seperating categorical and numerical dtypes\ncategorical_types=abm3.select_dtypes(include=['object']).columns\nprint('categorical_types: \\n',categorical_types)\n\nprint('-------------')\n\nnumerical_types=abm3._get_numeric_data().columns\nprint('numerical_types: \\n',numerical_types)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  II. EDA\n- Exploring the Data.\n- Getting Business Insights from the data\n- Cardinality of Categorical features(PLOTS)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#numerical varibles further breaking down \n# CONTINOUS AND DISCRETE VARIABLES\n\nDiscrete_features=[i for i in numerical_types if len(abm3[i].unique())<25]\nprint(Discrete_features)\nprint(len(Discrete_features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#relationship between discrete var and price\nfor i in Discrete_features:\n    abm3.groupby(i)['price'].mean().plot.bar()\n    plt.xlabel(i)\n    plt.ylabel('price')\n    plt.title(i)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Points to be taken from above:\n- from the above we can see the relationship being a superhost or not doesnot affect price\n- accomodates has a linear increase in price with increase in accomadates\n- special features also does not affect price much until special amenities count is greater than 7\n- common amenities present properties have same price regardless of neighbourhood.\n- review scores does not effect price of the property. So, we can drop review_score_accuracy.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets compare the difference between years and price\nplt.scatter(abm3.host_days_active_years,abm3.price)\nplt.title('Host_active_years Vs Price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note6:We can see that aas the number of years a host is registered and active the price is decreasing**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"abm3.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Continuous var\nContinous_features=[i for i in numerical_types if i not in Discrete_features]\nContinous_features[1:] #since Host_id is not required","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ploting continous var\nfor i in Continous_features[1:]:\n    data=abm3.copy()\n    if 0 in data[i].unique():\n        pass\n    elif i in ['zipcode','latitude','longitude']:\n        pass\n    else:\n#         data[i]=np.log(data[i])\n        data[i].hist(bins=25)\n        plt.xlabel(i)\n        plt.ylabel('count')\n        plt.title(i)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note: From the above plots we observe the data is either right positively or negatively skewed, and also not normally distributed.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### - Avg age of listings group by borough","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(abm3.groupby(['Borough'])['host_days_active_years'].mean().sort_values())\nplt.figure(figsize=(20,8))\nsns.countplot(x ='host_days_active_years',hue = \"Borough\",data = abm3)\nplt.title(\"Hosting since across boroughs\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Brooklyn and Manhattan have the oldest listings by nearly 4 years.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### -price distribution of various room types across neighbourhood groups","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- It is clearly seen that hotel rooms are much costlier than entire house in manhattan and brooklyn region \n- overall entire apt/home price is higher than private room\n- Also it is seen that staten island and bronx do not have any hotel rooms","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(abm3.groupby(['room_type','Borough'])['price'].mean().sort_values())\nsns.set(rc={'figure.figsize': (16, 5)})\nax = sns.barplot(x = 'Borough', y = 'price', hue = 'room_type', data =abm3, \n                 palette ='plasma_r', ci = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Highly reviewed of every feature based on Number of reviews(last twelve months).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- In entire city we have more number of Appartment listings\n- Except for brooklyn every Borough has more Appartments than other property types.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(abm3.groupby(['property_type'])['number_of_reviews_ltm'].mean())\nsns.set(rc={'figure.figsize': (16, 5)})\nax = sns.barplot(x = 'Borough', y = 'number_of_reviews_ltm', hue = 'property_type', data =abm3, \n                 palette ='plasma_r', ci = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(abm3.groupby(['room_type'])['number_of_reviews_ltm'].mean())\nsns.set(rc={'figure.figsize': (16, 5)})\nax = sns.barplot(x = 'Borough', y = 'number_of_reviews_ltm', hue = 'room_type', data =abm3, \n                 palette ='plasma_r', ci = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from mpl_toolkits.mplot3d import Axes3D\n# from plotly.subplots import make_subplots\n# import plotly.graph_objs as go\n# from mpl_toolkits.mplot3d import Axes3D\n# from plotly import tools\n\n# fig = px.scatter_mapbox(abm3, \n#                         hover_data = ['price','minimum_nights','room_type'],\n#                         hover_name = 'neighbourhood_cleansed',\n#                         lat=\"latitude\", \n#                         lon=\"longitude\", \n#                         color=\"Borough\", \n#                         size=\"price\", \n#                         size_max=30, \n#                         opacity = .70,\n#                         zoom=10,\n#                        )\n# fig.layout.mapbox.style = 'stamen-terrain'\n# fig.update_layout(title_text = 'Airbnb by Borough in NYC<br>(Click legend to toggle borough)', height = 800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig = px.scatter_mapbox(abm3,\n#                         hover_data=['price','property_type','room_type','number_of_reviews_ltm'], \n#                         lat=\"latitude\", \n#                         lon=\"longitude\", \n#                         color=\"neighbourhood_cleansed\", \n#                         size_max=30, \n#                         opacity = .70,\n#                         zoom=12,\n#                        )\n# fig.layout.mapbox.style = 'carto-positron'\n# fig.update_layout(title_text = 'NYC Airbnb by Neighbourhood<br>(Click legend to toggle neighbourhood)', height = 800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# temp_bk = abm3[abm3.Borough == 'Brooklyn']\n# temp_qn = abm3[abm3.Borough == 'Queens']\n# temp_mn = abm3[abm3.Borough == 'Manhattan']\n# temp_bx = abm3[abm3.Borough == 'Bronx']\n# temp_si = abm3[abm3.Borough == 'Staten Island']\n\n# labels = abm3.room_type.value_counts().index.to_list()\n\n# fig = make_subplots(1, 5, specs=[[{'type':'domain'}, {'type':'domain'}, {'type':'domain'},{'type':'domain'},{'type':'domain'}]],\n#                     subplot_titles=['Manhattan', 'Brooklyn', 'Queens','Bronx','Staten Island'])\n# fig1= fig.add_trace(go.Pie(labels=labels, values=temp_mn.room_type.value_counts().reset_index().sort_values(by = 'index').room_type.tolist(), scalegroup='one',\n#                      name=\"Manhattan\"),1,1)\n# fig2= fig.add_trace(go.Pie(labels=labels, values=temp_bk.room_type.value_counts().reset_index().sort_values(by = 'index').room_type.tolist(), scalegroup='one',\n#                      name=\"Brooklyn\"),1,2)\n# fig3= fig.add_trace(go.Pie(labels=labels, values=temp_qn.room_type.value_counts().reset_index().sort_values(by = 'index').room_type.tolist(), scalegroup='one',\n#                      name=\"Queens\"),1,3)\n# fig4= fig.add_trace(go.Pie(labels=labels, values=temp_bx.room_type.value_counts().reset_index().sort_values(by = 'index').room_type.tolist(), scalegroup='one',\n#                      name=\"Bronx\"),1,4)\n# fig5= fig.add_trace(go.Pie(labels=labels, values=temp_si.room_type.value_counts().reset_index().sort_values(by = 'index').room_type.tolist(), scalegroup='one',\n#                      name=\"Staten Island\"),1,5)\n\n# fig.update_layout(title_text='room types in Boroughs')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### - Cardinality of categorical features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":" for i in categorical_types:\n        print('feature-{} & number of categories-{}'.format(i,len(abm3[i].unique())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#relationship b/w categorical and dependent var\nfor i in categorical_types:\n    if len(data[i].unique())>40:\n        pass\n    elif len(data[i].unique())==1:\n        pass\n    else:\n        data.groupby(i)['price'].mean().plot.bar()\n        plt.xlabel(i)\n        plt.ylabel('price')\n        plt.title(i)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- from the above we can observe relationship between categorical feature and price feature and also we can reduce the labels","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Statistics Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":" Objective: To perform Statistical Analysis on the data set by implementing various stats modules (on New York AirBnb data) such as Hypothesis Testing, Tests of Mean (Kruskal Wallis Test, ANOVA - one way and two way), Tests of Proportion (z test and chi-squared test) and Tests of Variance (F-test, Levene test), after checking for the three assumptions of (i) Normality of target variable (ii) Randomness of Sampling (iii) Equal variance across categories. The level of significance is assumed to be 5 percent (i.e. alpha = 0.05) If assumptions are satisfied, parametric tests(assumes already distribution is present(ANOVA) can be performed, else non-parametric tests(do not rely on any distributions(CHI-SQUARE) have to be performed. The results of the tests performed will enable us to find the associativity and dependability of different features on one-another.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cont = pd.crosstab(abm3.Borough,abm3.room_type)\ncont","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Testing the assumptions:\n- Randomness of Data\n- Normality Test\n- Variance Test\n\nThe target variable being the price.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.distplot(abm2.price,color='r')\nplt.xlabel(\"Price\")\nplt.title(\"Distribution of Price of among property types\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Shapiro Test (for checking Normality)\n\n- H0 (Null Hypothesis) : Distribution is normal\n\n- H1 (Alternate Hypothesis): Distribution is not normal","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.stats as st\nst.shapiro(abm2.price)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Levene Test (for testing of variance)\nH0 (null hypothesis): variance(private_room) = variance(shared_room) = variance(entire_home)=variance(hotel_room)\n\nH1 (alternate hypothesis): variance(private_room) != variance(shared_room) != variance(entire_home)!=variance(hotel_room)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pvt = abm3[abm3['room_type'] == 'Private room']\nshare = abm3[abm3['room_type'] == 'Shared room']\napt = abm3[abm3['room_type'] == 'Entire home/apt']\nhotel=abm3[abm3['room_type'] == 'Hotel room']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"st.levene(pvt.price, share.price, apt.price,hotel.price)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here P-value is less than 0.5 and therefore we can reject null hypothesis and can say that price varies in different room types","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### price vs neighbourhood\nH0 (null hypothesis): mean_price(Brooklyn) = mean_price(Manhattan) = ..... = mean_price(Bronx)\n\nH1 (null hypothesis): mean_price(Brooklyn) != mean_price(Manhattan) != ..... != mean_price(Bronx)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import  scipy.stats as stats\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom statsmodels.stats.anova import anova_lm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## one way anova\nmod = ols('price ~ Borough', data =abm3).fit()\naov_table = sm.stats.anova_lm(mod, typ=1)\nprint(aov_table)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here pvalue obtained is greater than 0.5, so we fail to reject null hypothesis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Room Type vs Neighbourhood Group","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Since both the variables Room Type and Neighbourhood Group are categorical having more than two categories, we can peform Chi-squared test.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Chi Squared Test\n- H0 (null hypothesis): There is no association between Room Type and Neighbourhood Group.\n- H1 (alternate hypothesis): There is an association between Room Type and Neighbourhood Group.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tab = pd.crosstab(abm3['room_type'],abm3['Borough'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"st.chi2_contingency(tab)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ct = pd.crosstab(abm3['room_type'],abm3['Borough'])\nct.plot.bar(stacked=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### price vs review scores rating","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mod = ols('price ~ review_scores_rating', data =abm3).fit()\naov_table = sm.stats.anova_lm(mod, typ=1)\nprint(aov_table)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"here Pvalue obtained is less than 0.5, so we can reject null hypothesis and can say that reviews have an effect on price","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### price vs cancellation policy","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mod = ols('price ~ cancellation_policy', data =abm3).fit()\naov_table = sm.stats.anova_lm(mod, typ=1)\nprint(aov_table)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"here Pvalue obtained is less than 0.5, so we can reject null hypothesis and can say that cancellation policy have an effect on price","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### price vs availability_365","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mod = ols('price ~ availability_365', data =abm3).fit()\naov_table = sm.stats.anova_lm(mod, typ=1)\nprint(aov_table)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### chi2 on response rate and property type, borough etc","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tab = pd.crosstab(abm3['host_response_rate'],abm3['property_type'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"st.chi2_contingency(tab)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tab = pd.crosstab(abm3['host_response_rate'],abm3['Borough'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"st.chi2_contingency(tab)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"abm3.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical=[i for i in abm3.columns if abm3[i].dtypes!='O']\nlen(numerical)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cor = abm3.corr()\n\n#Correlation with output variable\ncor_target = abs(cor[\"price\"])\n\n# Selecting highly correlated features\nrelevant_features = cor_target[cor_target>0.0]\nrelevant_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_corr_features = cor.index[abs(cor[\"price\"])>0.0]\n# plt.figure(figsize=(10,15))\nsns.heatmap(abm3[top_corr_features].corr(), annot = True, \n                cbar = True,square=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Since we can see except avg_price_property_type is the only feature with above 0.3 correlation we are dropping none features and moving with feature Engineering and Selection**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# condition check for Multicollinearity  between 2 newly extracted features\nprint(abm3[[\"avg_review_score\",\"avg_price_property_type\"]].corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## III. Feature Engineering\n\n- Reducing Labels in the Object features\n- Handling Outliers\n- Transforming data\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking objects in Categorical variable.\nprint('host_response_time: \\n',abm3['host_response_time'].value_counts()/abm3['host_response_time'].value_counts().sum()*100)\nprint('=================================================')\nprint('cancellation_policy: \\n',abm3.cancellation_policy.value_counts()/abm3['cancellation_policy'].value_counts().sum()*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reducig labdels in Host_response_time.\nabm3.replace({'within an hour':'Hour','within a few hours':'One Day','within a day':'Days'},inplace=True)\n\n# Decreasig the value_counts in property_type\n\n#With 10 categories we account for 95% of the listings\n(abm3['property_type'].value_counts()/abm3['property_type'].value_counts().sum()*100)[0:5].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Mod_prop_type=abm3['property_type'].value_counts()[5:len(abm1['property_type'].value_counts())].index.tolist()\n\ndef change_prop_type(label):\n    if label in Mod_prop_type:\n        label='Other'\n    return label\n# Mod_prop_type\nabm3.loc[:,'property_type'] = abm3.loc[:,'property_type'].apply(change_prop_type)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abm3.property_type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_types","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handling outliers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cap_df = abm3.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def features_plot(feat,df):\n    plt.rcParams['figure.figsize']=(15,15)\n    plt.style.use(style='ggplot')\n    xxx,sub=plt.subplots(5,6)\n    xxx.subplots_adjust(hspace=0.5)\n    sub=sub.flatten()\n    for i in range(len(feat)):\n        sub[i].scatter(x=df[feat[i]], y=np.log1p(abm3[\"price\"]),s=4)\n        sub[i].set_title('{}'.format(feat[i],fontsize=10))\n        sub[i].set_ylabel('log(Price)',fontsize=10)\n        sub[i].tick_params(labelsize=10)\n    plt.show()\n    \n\nNumerical_cols=[i for i in cap_df.columns if cap_df[i].dtypes=='float64']\nlen(Numerical_cols)\nNumerical_cols = list(Numerical_cols)\n# Numerical_cols.remove('price')\nfeatures_plot(sorted(Numerical_cols),cap_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cap_data(df):\n    for col in df.columns:\n#         print(\"capping the \",col)\n        if (((df[col].dtype)=='float64') | ((df[col].dtype)=='int64')):\n            percentiles = df[col].quantile([0.25,0.75]).values\n            df[col][df[col] <= percentiles[0]] = percentiles[0]\n            df[col][df[col] >= percentiles[1]] = percentiles[1]\n            print(percentiles)\n        else:\n            df[col]=df[col]\n    return df\n\n# abm3 = cap_data(abm2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Capping outliers at lower and upper viscor\ncap_df = cap_data(cap_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def features_plot(feat,df):\n    plt.rcParams['figure.figsize']=(15,15)\n    plt.style.use(style='ggplot')\n    xxx,sub=plt.subplots(5,6)\n    xxx.subplots_adjust(hspace=0.5)\n    sub=sub.flatten()\n    for i in range(len(feat)):\n        sub[i].scatter(x=df[feat[i]], y=np.log1p(df[\"price\"]),s=4)\n        sub[i].set_title('{}'.format(feat[i],fontsize=10))\n        sub[i].set_ylabel('log(Price)',fontsize=10)\n        sub[i].tick_params(labelsize=10)\n    plt.show()\n    \n\nNumerical_cols=[i for i in cap_df.columns if cap_df[i].dtypes=='float64']\nlen(Numerical_cols)\nNumerical_cols = list(Numerical_cols)\n# Numerical_cols.remove('price')\nfeatures_plot(sorted(Numerical_cols),cap_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Feature transformation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_columns = ['host_is_superhost', 'host_total_listings_count',\n       'host_identity_verified', 'accommodates',\n       'bathrooms', 'bedrooms', 'beds', 'price']\nnum_columns1 = ['price', 'availability_365','number_of_reviews_ltm', 'review_scores_rating','review_scores_accuracy', \n               'instant_bookable', 'host_days_active_years','host_listing_since']\n\nnum_columns2 = ['special_amenities', \n               'common_amenities', 'avg_price_property_type', 'avg_review_score','price', 'security_deposit',\n       'cleaning_fee', 'Num_of_guests_incl_forprice', 'price_per_extra_people','minimum_nights', 'maximum_nights']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=cap_df[num_columns],height=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=cap_df[num_columns1],height=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=cap_df[num_columns2],height=3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df = cap_df[numerical_types].drop(['latitude','longitude'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the skew of all numerical features\nskewed_feats = final_df.apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkew in numerical features: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import modules \nimport numpy as np \nfrom scipy import stats \n\n# plotting modules \nimport seaborn as sns \nimport matplotlib.pyplot as plt \n\n# generate non-normal data (exponential) \nfinal_df = np.random.exponential(size = 1000) \n\n# transform training data & save lambda value \nfitted_data, fitted_lambda = stats.boxcox(final_df) \n\n# creating axes to draw plots \nfig, ax = plt.subplots(1, 2) \n\n# plotting the original data(non-normal) and \n# fitted data (normal) \nsns.distplot(final_df, hist = False, kde = True, \n\tkde_kws = {'shade': True, 'linewidth': 2}, \n\tlabel = \"Non-Normal\", color =\"green\", ax = ax[0]) \n\nsns.distplot(fitted_data, hist = False, kde = True, \n\tkde_kws = {'shade': True, 'linewidth': 2}, \n\tlabel = \"Normal\", color =\"green\", ax = ax[1]) \n\n# adding legends to the subplots \nplt.legend(loc = \"upper right\") \n\n# rescaling the subplots \nfig.set_figheight(5) \nfig.set_figwidth(10) \n\nprint(f\"Lambda value used for Transformation: {fitted_lambda}\") \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the skew of all numerical features\nskewed_feats = pd.DataFrame(fitted_data).apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkew in numerical features: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encoding Categorical Vars","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_types","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cap_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # # Bin into 5 categories\ncap_df['host_response_rate'].value_counts(bins=5,sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bin into five categories\ncap_df['host_response_rate_bins'] = pd.cut(cap_df.host_response_rate, bins=[50,60,70,80,100], labels=['49-60%', '50-89%', '90-99%', '100%'], include_lowest=True)\n\n# Converting to string\ncap_df['host_response_rate_bins'] = cap_df['host_response_rate_bins'].astype('str')\n\n# Replace nulls with 'unknown'\n#cap_df['host_response_rate_bins'].replace('nan', 'unknown', inplace=True)\n\n# Category counts\ncap_df['host_response_rate_bins'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfe = pd.DataFrame(cap_df,columns = ['property_type','room_type','cancellation_policy','host_response_rate_bins','bed_type'])\ndfe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = dfe.select_dtypes(['object']).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cat_cols:\n    freqs = dfe[col].value_counts()\n    k = freqs.index[freqs>20][:6]\n    for cat in k:\n        name = col+'_'+cat\n        dfe[name]=(dfe[col]==cat).astype(int)\n    del dfe[col]\n    print(col)\n    \nprint(dfe.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abmen = pd.concat((dfe,cap_df),axis=1)\nabmen.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df = pd.DataFrame()\nfinal_df = abmen.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df.drop(['host_response_time', 'host_response_rate','host_response_rate_bins', 'neighbourhood_cleansed',\n       'Borough', 'property_type', 'room_type', 'bed_type',\n       'cancellation_policy'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# seperating categorical and numerical dtypes\ncategorical_cols=final_df.select_dtypes(include=['object']).columns\nprint('categorical_types: \\n',categorical_cols)\n\nprint('-------------')\n\nnumerical_cols=final_df._get_numeric_data().columns\nprint('numerical_types: \\n',numerical_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df.drop(['longitude','latitude'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  IV. Feature Selection","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### RFE ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting Data Ready\nX = final_df.drop('price', axis=1)\ny= final_df['price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Initializing RFE model\nrfe = RFE(model, 40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transforming data using RFE\nX_rfe = rfe.fit_transform(X,y)  \n#Fitting the data to model\nmodel.fit(X_rfe,y)\nprint(rfe.support_)\nprint(rfe.ranking_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.drop(['bedrooms', 'review_scores_accuracy'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#no of features\nnof_list=np.arange(1,47)            \nhigh_score=0\n#Variable to store the optimum features\nnof=0           \nscore_list =[]\nfor n in range(len(nof_list)):\n    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n    model = LinearRegression()\n    rfe = RFE(model,nof_list[n])\n    X_train_rfe = rfe.fit_transform(X_train,y_train)\n    X_test_rfe = rfe.transform(X_test)\n    model.fit(X_train_rfe,y_train)\n    score = model.score(X_test_rfe,y_test)\n    score_list.append(score)\n    if(score>high_score):\n        high_score = score\n        nof = nof_list[n]\nprint(\"Optimum number of features: %d\" %nof)\nprint(\"Score with %d features: %f\" % (nof, high_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## V. Model Building","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Raw linear regression model\nX = final_df.drop('price', axis=1)\ny= final_df['price']\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\nprint(f'Coefficients: {lin_reg.coef_}')\nprint(f'Intercept: {lin_reg.intercept_}')\nprint(f'R^2 score: {lin_reg.score(X, y)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test , y_train, y_test = train_test_split(X,y, test_size = 0.30, random_state = 1)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_reg = LinearRegression()\nmodel = lin_reg.fit(X_train,y_train)\nprint(f'R^2 score for train: {lin_reg.score(X_train, y_train)}')\nprint(f'R^2 score for test: {lin_reg.score(X_test, y_test)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Raw OLS Model\nX = final_df.drop(['price'],axis=1)\ny = final_df.price\nX_constant = sm.add_constant(X)\nlin_reg = sm.OLS(y,X_constant).fit()\nlin_reg.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Assumption 1- No autocorrelation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.tsa.api as smt\n\nacf = smt.graphics.plot_acf(lin_reg.resid, lags=40 , alpha=0.05)\nacf.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Assumption 2- Normality of Residuals\nfrom scipy import stats\nprint(stats.jarque_bera(lin_reg.resid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nsns.distplot(lin_reg.resid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Asssumption 3 - Linearity of residuals\nHere we have 2 options. Either we can plot the observed values Vs predicted values and plot the Residual Vs predicted values and see the linearity of residuals.\nOR\nWe can go for rainbow test. Let's look both of them one by one.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Rainbow test \nIt is done to check the linearity of the residuals for a linear regression model.\nLinearity of residuals is preferred.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nsm.stats.diagnostic.linear_rainbow(res=lin_reg, frac=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.stats as stats\nimport pylab\nfrom statsmodels.graphics.gofplots import ProbPlot\nst_residual = lin_reg.get_influence().resid_studentized_internal\nstats.probplot(st_residual, dist=\"norm\", plot = pylab)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_reg.resid.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"very close to 0 so linearity is present.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Assumption 4 -  Homoscedasticity_test(using goldfeld test) OR (Beusch-Wagon Test)\n\n# goldfeld test\nfrom statsmodels.compat import lzip\nimport numpy as np\nfrom statsmodels.compat import lzip\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport statsmodels.stats.api as sms\n\nmodel = lin_reg\nfitted_vals = model.predict()\nresids = model.resid\nresids_standardized = model.get_influence().resid_studentized_internal\n\nname = ['F statistic', 'p-value']\ntest = sms.het_goldfeldquandt(model.resid, model.model.exog)\nlzip(name, test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Assumption 4 -  Homoscedasticity_test(using goldfeld test) OR (Beusch-Wagon Test)\n\n##### breuschpagan Test\nimport statsmodels.api as sm\nfrom statsmodels.compat import lzip\nname = ['Lagrange multiplier statistic', 'p-value',\n        'f-value', 'f p-value']\ntest = sms.het_breuschpagan(lin_reg.resid, lin_reg.model.exog)\nlzip(name, test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### so from above p- value we know that the data is heteroscedastic","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"##### Assumption 5- NO  MULTI COLLINEARITY","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Assumption 5- NO  MULTI COLLINEARITY\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = [variance_inflation_factor(X_constant.values, i) for i in range(X_constant.shape[1])]\npd.DataFrame({'vif': vif[0:]}, index=X.columns).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#So, multicollinearity exists.\nNote : This vif column has be built with the help of X_constant and not the X_values. Because we built our model by adding Constant.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dict(pd.DataFrame({'vif': vif[0:]}, index=X.columns).T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##  removed like correlated variables\nX = final_df[['property_type_Apartment', 'property_type_House', 'property_type_Other',\n       'property_type_Townhouse', 'property_type_Condominium',\n       'room_type_Entire home/apt', 'room_type_Private room',\n       'room_type_Shared room', 'room_type_Hotel room',\n       'cancellation_policy_strict', 'cancellation_policy_flexible', 'host_response_rate_bins_100%',\n       'bed_type_Real Bed', 'bed_type_Pull-out Sofa',\n       'bed_type_Airbed', 'bed_type_Couch', 'host_is_superhost',\n       'host_total_listings_count', 'host_identity_verified', 'accommodates',\n       'bathrooms', 'bedrooms', 'beds', 'security_deposit',\n       'cleaning_fee', 'Num_of_guests_incl_forprice', 'price_per_extra_people',\n       'minimum_nights', 'maximum_nights', 'availability_365',\n       'number_of_reviews_ltm', 'review_scores_rating',\n       'review_scores_accuracy', 'instant_bookable', 'host_days_active_years',\n       'host_listing_since', 'special_amenities', 'common_amenities',\n       'avg_price_property_type', 'avg_review_score']]\ny = final_df['price']\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\nprint(f'Coefficients: {lin_reg.coef_}')\nprint(f'Intercept: {lin_reg.intercept_}')\nprint(f'R^2 score: {lin_reg.score(X, y)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings \nwarnings.filterwarnings('ignore')\nimport statsmodels.api as sm\n\nX_constant = sm.add_constant(X)\nlin_reg = sm.OLS(y,X_constant).fit()\nlin_reg.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove 4 more parameters from the input\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = [variance_inflation_factor(X_constant.values, i) for i in range(X_constant.shape[1])]\npd.DataFrame({'vif': vif[0:]}, index=X.columns).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##  removed like correlated variables\nX = final_df[['room_type_Entire home/apt', 'room_type_Private room',\n       'room_type_Shared room', 'room_type_Hotel room',\n       'cancellation_policy_strict', 'cancellation_policy_flexible', 'host_response_rate_bins_100%',\n       'bed_type_Real Bed', 'bed_type_Pull-out Sofa',\n       'bed_type_Airbed', 'bed_type_Couch', \n       'host_total_listings_count',  'accommodates',\n       'bathrooms', 'bedrooms', 'beds',  'security_deposit',\n       'cleaning_fee', 'Num_of_guests_incl_forprice', 'price_per_extra_people',\n       'minimum_nights', 'maximum_nights', 'availability_365',\n       'number_of_reviews_ltm', 'review_scores_rating',\n       'review_scores_accuracy', 'instant_bookable', 'host_days_active_years',\n       'host_listing_since', 'special_amenities', 'common_amenities',\n       'avg_price_property_type', 'avg_review_score']]\ny = final_df['price']\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\nprint(f'Coefficients: {lin_reg.coef_}')\nprint(f'Intercept: {lin_reg.intercept_}')\nprint(f'R^2 score: {lin_reg.score(X, y)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings \nwarnings.filterwarnings('ignore')\nimport statsmodels.api as sm\n\nX_constant = sm.add_constant(X)\nlin_reg = sm.OLS(y,X_constant).fit()\nlin_reg.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove 4 more parameters from the input\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = [variance_inflation_factor(X_constant.values, i) for i in range(X_constant.shape[1])]\npd.DataFrame({'vif': vif[0:]}, index=X.columns).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##  removed like correlated variables\nX = final_df[['room_type_Entire home/apt',\n       'room_type_Shared room',\n       'cancellation_policy_strict', 'cancellation_policy_flexible', 'host_response_rate_bins_100%',\n       'bed_type_Real Bed', 'bed_type_Pull-out Sofa',\n       'bed_type_Airbed', 'bed_type_Couch', \n       'host_total_listings_count',  'accommodates',\n       'bathrooms', 'bedrooms', 'beds',  'security_deposit',\n       'cleaning_fee', 'Num_of_guests_incl_forprice', 'price_per_extra_people',\n       'minimum_nights', 'maximum_nights', 'availability_365',\n       'number_of_reviews_ltm', 'review_scores_rating',\n       'review_scores_accuracy', 'instant_bookable', 'host_days_active_years',\n       'host_listing_since', 'special_amenities', 'common_amenities',\n       'avg_price_property_type', 'avg_review_score']]\ny = final_df['price']\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\nprint(f'Coefficients: {lin_reg.coef_}')\nprint(f'Intercept: {lin_reg.intercept_}')\nprint(f'R^2 score: {lin_reg.score(X, y)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings \nwarnings.filterwarnings('ignore')\nimport statsmodels.api as sm\n\nX_constant = sm.add_constant(X)\nlin_reg = sm.OLS(y,X_constant).fit()\nlin_reg.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove 4 more parameters from the input\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = [variance_inflation_factor(X_constant.values, i) for i in range(X_constant.shape[1])]\npd.DataFrame({'vif': vif[0:]}, index=X.columns).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##  removed like correlated variables\nX = final_df[['room_type_Entire home/apt',\n       'room_type_Shared room',\n       'cancellation_policy_strict', 'cancellation_policy_flexible', 'host_response_rate_bins_100%',\n       'bed_type_Real Bed', 'bed_type_Pull-out Sofa',\n       'bed_type_Airbed', 'bed_type_Couch', \n       'host_total_listings_count',  'accommodates',\n       'bathrooms', 'bedrooms', 'beds',  'security_deposit',\n       'cleaning_fee', 'Num_of_guests_incl_forprice', 'price_per_extra_people',\n       'minimum_nights', 'availability_365',\n       'number_of_reviews_ltm', 'review_scores_rating',\n       'review_scores_accuracy', 'instant_bookable', 'host_days_active_years',\n       'host_listing_since', 'special_amenities', 'common_amenities',\n       'avg_price_property_type', 'avg_review_score']]\ny = final_df['price']\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\nprint(f'Coefficients: {lin_reg.coef_}')\nprint(f'Intercept: {lin_reg.intercept_}')\nprint(f'R^2 score: {lin_reg.score(X, y)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings \nwarnings.filterwarnings('ignore')\nimport statsmodels.api as sm\n\nX_constant = sm.add_constant(X)\nlin_reg = sm.OLS(y,X_constant).fit()\nlin_reg.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove 4 more parameters from the input\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = [variance_inflation_factor(X_constant.values, i) for i in range(X_constant.shape[1])]\npd.DataFrame({'vif': vif[0:]}, index=X.columns).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict(pd.DataFrame({'vif': vif[0:]}, index=X.columns).T)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Linear Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"##  removed like correlated variables\nX = final_df[['room_type_Entire home/apt',\n       'room_type_Shared room',\n       'cancellation_policy_strict', 'cancellation_policy_flexible', 'host_response_rate_bins_100%',\n       'bed_type_Real Bed', 'bed_type_Pull-out Sofa',\n       'bed_type_Airbed', 'bed_type_Couch', \n       'host_total_listings_count',  'accommodates',\n       'bathrooms', 'bedrooms', 'beds',  'security_deposit',\n       'cleaning_fee', 'Num_of_guests_incl_forprice', 'price_per_extra_people',\n       'minimum_nights', 'availability_365',\n       'number_of_reviews_ltm', 'review_scores_rating',\n       'review_scores_accuracy', 'instant_bookable', 'host_days_active_years',\n       'host_listing_since', 'special_amenities', 'common_amenities',\n       'avg_price_property_type', 'avg_review_score']]\ny = final_df['price']\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X, y)\n\nprint(f'Coefficients: {lin_reg.coef_}')\nprint(f'Intercept: {lin_reg.intercept_}')\nprint(f'R^2 score: {lin_reg.score(X, y)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Finally let's check for overfit and underfit condition","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test , y_train, y_test = train_test_split(X,y, test_size = 0.30, random_state = 1)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_reg = LinearRegression()\nmodel = lin_reg.fit(X_train,y_train)\nprint(f'R^2 score for train: {lin_reg.score(X_train, y_train)}')\nprint(f'R^2 score for test: {lin_reg.score(X_test, y_test)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Apply StandardScaler train and test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_scaler = scaler.fit_transform(X_train)\nX_test_scaler = scaler.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# modeling\n# libraries\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import Ridge, Lasso, ElasticNet, RidgeCV, LassoCV, ElasticNetCV, LinearRegression\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.ensemble import RandomForestRegressor\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Linear reg","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting Data Ready\n##  removed like correlated variables\nX = final_df[['room_type_Entire home/apt',\n       'room_type_Shared room',\n       'cancellation_policy_strict', 'cancellation_policy_flexible', 'host_response_rate_bins_100%',\n       'bed_type_Real Bed', 'bed_type_Pull-out Sofa',\n       'bed_type_Airbed', 'bed_type_Couch', \n       'host_total_listings_count',  'accommodates',\n       'bathrooms', 'bedrooms', 'beds',  'security_deposit',\n       'cleaning_fee', 'Num_of_guests_incl_forprice', 'price_per_extra_people',\n       'minimum_nights', 'availability_365',\n       'number_of_reviews_ltm', 'review_scores_rating',\n       'review_scores_accuracy', 'instant_bookable', 'host_days_active_years',\n       'host_listing_since', 'special_amenities', 'common_amenities',\n       'avg_price_property_type', 'avg_review_score']]\ny = final_df['price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_x, test_x , train_y, test_y = train_test_split(X,y, test_size = 0.30, random_state = 1)\nprint(train_x.shape)\nprint(test_x.shape)\nprint(test_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LinearRegression()\n\n# fit the model with the training data\nmodel.fit(train_x,train_y)\n\n# coefficeints of the trained model\nprint('\\nCoefficient of model :', model.coef_)\n\n# intercept of the model\nprint('\\nIntercept of model',model.intercept_)\n\n# predict the target on the test dataset\npredict_train = model.predict(train_x)\n\n# Root Mean Squared Error on training dataset\nrmse_train = mean_squared_error(train_y,predict_train)**(0.5)\nprint('\\nRMSE on train dataset : ', rmse_train)\n\n# predict the target on the testing dataset\npredict_test = model.predict(test_x) \n\n# Root Mean Squared Error on testing dataset\nrmse_test = mean_squared_error(test_y,predict_test)**(0.5)\nprint('\\nRMSE on test dataset : ', rmse_test)\n\nprint(f'R^2 score for train: {lin_reg.score(X_train, y_train)}')\nprint(f'R^2 score for test: {lin_reg.score(X_test, y_test)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature selection\n## Raw OLS Model\nX = final_df.drop(['price'],axis=1)\ny = final_df.price\nfeature_select = LassoCV(precompute=True)\nfeature_select.fit(X, y)\nprint(\"Best alpha using built-in LassoCV: %f\" % feature_select.alpha_)\nprint(\"Best score using built-in LassoCV: %f\" %feature_select.score(X,y))\ncoef = pd.Series(feature_select.coef_, index = X.columns)\nprint(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef < 0)) + \" variables\")\nimp_coef = coef.sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_coef=imp_coef[coef!=0]\nimp_coef","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_new = final_df[['minimum_nights','number_of_reviews_ltm','maximum_nights','security_deposit','availability_365','cleaning_fee',\n                  'review_scores_rating',\n                  'avg_price_property_type','common_amenities','accommodates','room_type_Entire home/apt']]\ny_new= final_df['price']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrainx, testx , trainy, testy = train_test_split(X_new,y_new, test_size = 0.30, random_state = 1)\nprint(trainx.shape)\nprint(testx.shape)\nprint(testy.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#linear reg after feature selectio\n# fit the model with the training data\nmodel.fit(trainx,trainy)\n\n# coefficeints of the trained model\nprint('\\nCoefficient of model :', model.coef_)\n\n# intercept of the model\nprint('\\nIntercept of model',model.intercept_)\n\n# predict the target on the test dataset\npredict_train = model.predict(trainx)\n\n# Root Mean Squared Error on training dataset\nrmse_train = mean_squared_error(trainy,predict_train)**(0.5)\nprint('\\nRMSE on train dataset : ', rmse_train)\n\n# predict the target on the testing dataset\npredict_test = model.predict(testx) \n\n# Root Mean Squared Error on testing dataset\nrmse_test = mean_squared_error(testy,predict_test)**(0.5)\nprint('\\nRMSE on test dataset : ', rmse_test)\n\nprint(f'R^2 score for train: {model.score(trainx, trainy)}')\nprint(f'R^2 score for test: {model.score(testx, testy)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting Data Ready\n##  removed like correlated variables\nX = final_df[['room_type_Entire home/apt',\n       'room_type_Shared room',\n       'cancellation_policy_strict', 'cancellation_policy_flexible', 'host_response_rate_bins_100%',\n       'bed_type_Real Bed', 'bed_type_Pull-out Sofa',\n       'bed_type_Airbed', 'bed_type_Couch', \n       'host_total_listings_count',  'accommodates',\n       'bathrooms', 'bedrooms', 'beds',  'security_deposit',\n       'cleaning_fee', 'Num_of_guests_incl_forprice', 'price_per_extra_people',\n       'minimum_nights', 'availability_365',\n       'number_of_reviews_ltm', 'review_scores_rating',\n       'review_scores_accuracy', 'instant_bookable', 'host_days_active_years',\n       'host_listing_since', 'special_amenities', 'common_amenities',\n       'avg_price_property_type', 'avg_review_score']]\ny = final_df['price']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Ridge Reg","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ridge basic model\n\ntrain_x = X_train\ntrain_y = y_train\ntest_x = X_test\ntest_y = y_test\n\nrr = Ridge(alpha=0.01)\nrr.fit(train_x, train_y) \npred_train_rr= rr.predict(train_x)\nprint('train_rmse: ',np.sqrt(mean_squared_error(train_y,pred_train_rr)))\nprint('train_r2 score: ',r2_score(train_y, pred_train_rr))\nprint('-------------------------')\npred_test_rr= rr.predict(test_x)\nprint('test_rmse: ',np.sqrt(mean_squared_error(test_y,pred_test_rr))) \nprint('test_r2 score: ',r2_score(test_y, pred_test_rr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature selected\n\nrr = Ridge(alpha=0.01)\nrr.fit(trainx, trainy) \npred_train_rr= rr.predict(trainx)\nprint('ytrain_rmse: ',np.sqrt(mean_squared_error(trainy,pred_train_rr)))\nprint('ytrain_r2 score: ',r2_score(trainy, pred_train_rr))\nprint('-------------------------')\npred_test_rr= rr.predict(testx)\nprint('test_rmse: ',np.sqrt(mean_squared_error(testy,pred_test_rr))) \nprint('test_r2 score: ',r2_score(testy, pred_test_rr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### lasso Reg","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# lasso\nmodel_lasso = Lasso(alpha=0.01)\nmodel_lasso.fit(train_x, train_y) \npred_train_lasso= model_lasso.predict(train_x)\nprint('train_rmse: ',np.sqrt(mean_squared_error(train_y,pred_train_lasso)))\nprint('train_r2 score: ',r2_score(train_y, pred_train_lasso))\nprint('-------------------------')\npred_test_lasso= model_lasso.predict(test_x)\nprint('test_rmse: ',np.sqrt(mean_squared_error(test_y,pred_test_lasso))) \nprint('test_r2 score: ',r2_score(test_y, pred_test_lasso))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Selected\nmodel_lasso = Lasso(alpha=0.01)\nmodel_lasso.fit(trainx, trainy) \npred_train_lasso= model_lasso.predict(trainx)\nprint('train_rmse: ',np.sqrt(mean_squared_error(trainy,pred_train_lasso)))\nprint('train_r2 score: ',r2_score(trainy, pred_train_lasso))\nprint('-------------------------')\npred_test_lasso= model_lasso.predict(testx)\nprint('test_rmse: ',np.sqrt(mean_squared_error(testy,pred_test_lasso))) \nprint('test_r2 score: ',r2_score(testy, pred_test_lasso))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Elastic Net","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Elastic Net\nmodel_enet = ElasticNet(alpha = 0.01)\nmodel_enet.fit(trainx, trainy) \npred_train_enet= model_enet.predict(trainx)\nprint('train_rmse: ',np.sqrt(mean_squared_error(trainy,pred_train_enet)))\nprint('train_r2 score: ',r2_score(trainy, pred_train_enet))\n\npred_test_enet= model_enet.predict(testx)\nprint('test_rmse: ',np.sqrt(mean_squared_error(testy,pred_test_enet)))\nprint('test_r2 score: ',r2_score(testy, pred_test_enet))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Boosting techniques","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import make_regression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.ensemble import GradientBoostingRegressor\n# define dataset\nX, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=7)\n# define the model\nmodel = GradientBoostingRegressor()\n# define the evaluation procedure\ncv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n# evaluate the model\nn_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n# report performance\nprint('MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 1. Gradient Boosting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# gradient boosting ensemble for making predictions for regression\nfrom sklearn.datasets import make_regression\nfrom sklearn.ensemble import GradientBoostingRegressor\n# define dataset\nX, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=7)\n# define the model\nmodel = GradientBoostingRegressor()\n# fit the model on the whole dataset\nmodel.fit(trainx, trainy)\n# make a single prediction\n\nyhat = model.predict(testx)\n# summarize prediction\n\nprint('test_rmse: ',np.sqrt(mean_squared_error(testy,yhat)))\nprint('test_r2 score: ',r2_score(testy, yhat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# VIF selected\nfrom sklearn.datasets import make_regression\nfrom sklearn.ensemble import GradientBoostingRegressor\n# define dataset\nX, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=7)\n# define the model\nmodel = GradientBoostingRegressor()\n# fit the model on the whole dataset\nmodel.fit(train_x, train_y)\n# make a single prediction\n\nyhat = model.predict(test_x)\n# summarize prediction\n\nprint('test_rmse: ',np.sqrt(mean_squared_error(test_y,yhat)))\nprint('test_r2 score: ',r2_score(test_y, yhat))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2. XG Boost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost\nfrom xgboost import plot_importance\nxgb_model = xgboost.XGBRegressor(\n                 max_depth=3,\n                 n_estimators=100,                                                    \n                 seed=42)\nxgb_model.fit(train_x,train_y)\nyhat = xgb_model.predict(test_x)\n# summarize prediction\n\nprint('test_rmse: ',np.sqrt(mean_squared_error(test_y,yhat)))\nprint('test_r2 score: ',r2_score(test_y, yhat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost\nfrom xgboost import plot_importance\nxgb_model = xgboost.XGBRegressor(\n                 max_depth=3,\n                 n_estimators=100,                                                    \n                 seed=42)\nxgb_model.fit(trainx,trainy)\nyhat = xgb_model.predict(testx)\n# summarize prediction\n\nprint('test_rmse: ',np.sqrt(mean_squared_error(testy,yhat)))\nprint('test_r2 score: ',r2_score(testy, yhat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, X, y, title):\n    predictions = model.predict(X)\n    errors = abs(np.expm1(predictions) - np.expm1(y))\n    mape = 100 * np.mean(errors / np.expm1(y))\n    accuracy = 100 - mape\n    score_gbr = model.score(X,y)\n    #rsquared = r2_score(y,predictions)\n    rmse_gbr = np.sqrt(mean_squared_error((y),(predictions)))\n    \n    print(title)\n    print('R^2: {:0.4f}'.format(score_gbr))\n#     print('R^2: {:0.4f}'.format(rsquared))\n    print('RMSE: ${:0.4f} '.format(rmse_gbr))\n#     print('Average Error: ${:0.4f}'.format(np.mean(errors)))\n#     print('Accuracy = {:0.3f}%.'.format(accuracy),'\\n')\n    \n    return predictions\n\n    \ndef scatter_plot(prediction,y,title):\n    plt.rcParams['figure.figsize']=(10,4)\n    plt.style.use(style='ggplot')\n    plt.scatter(x=prediction, y=y, alpha=.75)\n    plt.ylabel('log(input price)',fontsize=16)\n    plt.xlabel('log(predicted price)',fontsize=16)\n    plt.tick_params(labelsize=16)\n    plt.title(title,fontsize=16)\n    plt.show()    \n    \ndef feature_extraction(importances,title):\n    plt.rcParams['figure.figsize']=(12,6)\n#     importances[0:15].iloc[::-1].plot(kind='barh',legend=False,fontsize=16)\n#     #importances.plot(kind='barh',legend=False,fontsize=16)\n# #     plt.tick_params(labelsize=18)\n# #     plt.ylabel(\"Feature\",fontsize=20)\n# #     plt.xlabel(\"Importance viariable\",fontsize=20)\n# #     plt.title(title,fontsize=20)\n#     plt.show()\n    \ndef scatter_plot2(prediction1,y1,prediction2,y2,title):\n    a=min(min(prediction1),min(y1),min(prediction2),min(y2))-0.2\n    b=max(max(prediction1),max(y1),max(prediction2),max(y2))+0.2\n    plt.rcParams['figure.figsize']=(10,4)\n    plt.style.use(style='ggplot')\n    plt.scatter(x=prediction1, y=prediction1-y1, color='red',label='Training data',alpha=.75)\n    plt.scatter(x=prediction2, y=prediction2-y2, color='blue', marker='s', label='Test data',alpha=.75)\n    plt.hlines(y = 0, xmin = a, xmax = b, color = \"black\")\n    plt.ylabel('log(input price)',fontsize=16)\n    plt.xlabel('log(predicted price)',fontsize=16)\n    plt.tick_params(labelsize=16)\n    plt.title(title,fontsize=16)\n    plt.legend(fontsize=16)\n    plt.show()    \ndef scatter_plot3(prediction1,y1,prediction2,y2,title):\n    a=min(min(prediction1),min(y1),min(prediction2),min(y2))-0.2\n    b=max(max(prediction1),max(y1),max(prediction2),max(y2))+0.2\n    plt.rcParams['figure.figsize']=(10,4)\n    plt.style.use(style='ggplot')\n    plt.scatter(x=prediction1, y=y1, color='red',label='Training data',alpha=.75)\n    plt.scatter(x=prediction2, y=y2, color='blue', marker='s', label='Test data',alpha=.75)\n    plt.plot([a, b], [a, b], c = \"black\")\n    plt.ylabel('log(input price)',fontsize=16)\n    plt.xlabel('log(predicted price)',fontsize=16)\n    plt.tick_params(labelsize=16)\n    plt.title(title,fontsize=16)\n    plt.legend(fontsize=16)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf= RandomForestRegressor(random_state=1, n_jobs=-2, max_features='log2')\n\nparam_grid = dict(n_estimators=[100,50],\n                  max_depth=[None,3],\n                  min_samples_leaf=[1,2])\n\ngrid_rf=GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_squared_error')\n\ngrid_rf.fit(X_train,y_train)\n\n#print(\"Random forest grid.cv_results_ {}\".format(grid_rf.cv_results_))\nprint(\"Random forest grid.best_score_ {}\".format(grid_rf.best_score_))\nprint(\"Random forest grid.best_params_ {}\".format(grid_rf.best_params_))\nprint(\"Random forest grid.best_estimator_ {}\".format(grid_rf.best_estimator_))\n\nmodel_rf = grid_rf.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title0='Random Forest Regression:'\nmodel_tmp = model_rf\n\ntitle=title0 + ' training set model performance'\nprediction_train=evaluate(model_tmp, X_train, y_train,title)\n\ntitle=title0 + ' test set model performance'\nprediction_test=evaluate(model_tmp, X_test, y_test,title)\n\n\nscatter_plot2(prediction_train,y_train,prediction_test,y_test,title)\n\ntitle=title0 + ' performance evaluation'\nscatter_plot3(prediction_train,y_train,prediction_test,y_test,title)\n\nimportances_train = pd.DataFrame({'Feature':X_train.columns, 'Importance':model_rf.feature_importances_})\nimportances_train = importances_train.sort_values('Importance',ascending=False).set_index('Feature')\nfeature_extraction(importances_train,'Random Forest Regression: Training set feature importance')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gradient boosting hyperparameter tuned\n# Hyperparameter tuned gradient boosting Regression\ngbr = GradientBoostingRegressor(min_samples_split=2,\n                                min_samples_leaf=2,\n                                subsample=0.8,\n                                random_state=1,\n                               learning_rate=0.01,\n                               max_features='sqrt')\n#param_grid = {\"n_estimators\":np.arange(1000,10000,1000),'learning_rate':[0.01,0.05,0.1,0.25,0.5]}\nparam_grid = dict(n_estimators=[100,600], max_depth=[1,3,8])\n\ngrid_gbr=GridSearchCV(gbr, param_grid, cv=5, scoring='neg_mean_squared_error',n_jobs=-2)\n\ngrid_gbr.fit(X_train,y_train)\n\n#print(\"Random forest grid.cv_results_ {}\".format(grid_gbr.cv_results_))\nprint(\"Random forest grid.best_score_ {}\".format(grid_gbr.best_score_))\nprint(\"Random forest grid.best_params_ {}\".format(grid_gbr.best_params_))\nprint(\"Random forest grid.best_estimator_ {}\".format(grid_gbr.best_estimator_))\n\nmodel_gbr = grid_gbr.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title0='Gradient Boosting Regression:'\nmodel_tmp = model_gbr\n\ntitle=title0 + ' training set model performance'\nprediction_train=evaluate(model_tmp, X_train, y_train,title)\n\ntitle=title0 + ' test set model performance'\nprediction_test=evaluate(model_tmp, X_test, y_test,title)\n\ntitle=title0 + ' residual plot'\nscatter_plot2(prediction_train,y_train,prediction_test,y_test,title)\n\ntitle=title0 + ' performance evaluation'\nscatter_plot3(prediction_train,y_train,prediction_test,y_test,title)\n\nimportances_train = pd.DataFrame({'Feature':X_train.columns, 'Importance':model_tmp.feature_importances_})\nimportances_train = importances_train.sort_values('Importance',ascending=False).set_index('Feature')\nfeature_extraction(importances_train,'Gradient Boosting Regression: Training set feature importance')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## FINAL REPORT :\n\n**Linear Reg**\nRFE Feature selection:\n\nR^2 score for train: 0.6369799616222565\nR^2 score for test: 0.635412119637978\n\nAfter applying Standard scaler:\n\nR^2 score for train: 0.6369799616222565\nR^2 score for test: 0.635412119637978\n\n**Ridge reg:**\n\nRFE Feature selection:\n\ntrain_rmse:  27.063829839500183\ntrain_r2 score:  0.6369799616214836\ntest_rmse:  27.122013030869358\ntest_r2 score:  0.6354121243730774\n\nLasso cv Feature selection:\n \nytrain_rmse:  27.262963919522388\nytrain_r2 score:  0.6316181474690495\ntest_rmse:  27.31931774864737\ntest_r2 score:  0.6300882894100244\n\n\n**Lasso Reg:**\n\nRFE Feature selection:\n\ntrain_rmse:  27.06526953410705\ntrain_r2 score:  0.6369413379754045\ntest_rmse:  27.121916828518213\ntest_r2 score:  0.6354147107702295\n\nLasso cv Feature selection:\n\ntrain_rmse:  27.26297648274075\ntrain_r2 score:  0.6316178079562413\ntest_rmse:  27.319375560168037\ntest_r2 score:  0.6300867238379024\n\n**Elastic_Net:**\nRFE Feature selection:\n\ntrain_rmse:  27.26657574369064\ntrain_r2 score:  0.6315205338260843\ntest_rmse:  27.323278460597063\ntest_r2 score:  0.6299810231926983\n\n**Gradient Boosting**\n\nRFE Feature selection:\n\ntest_rmse:  25.981896947224925\ntest_r2 score:  0.6654199102825642\n\nLasso cv Feature selection:\n\ntest_rmse:  25.49278693944052\ntest_r2 score:  0.677898302118356\n\n\n\n**XG Boost:**\n\nRFE Feature selection:\n\ntest_rmse:  24.90947071759183\ntest_r2 score:  0.6924700760810385\n\nLasso cv Feature selection:\n\ntest_rmse:  25.593941826859893\ntest_r2 score:  0.6753370440057858\n\n\n**Random Forest:**\n\nRandom Forest Regression: training set model performance\nR^2: 0.9761\nRandom Forest Regression: test set model performance\nR^2: 0.8481\n\n**Gradient Boosting Regression: training set model performance:**\nR^2: 0.7548\n\nGradient Boosting Regression: test set model performance\nR^2: 0.7272","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}