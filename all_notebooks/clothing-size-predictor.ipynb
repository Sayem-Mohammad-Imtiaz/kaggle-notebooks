{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n**Name:** Clothing Size Predictor\n\n**Author:** Sharome Burton\n\n**Date:** 07/18/2021\n\n**Description:** Machine learning model used to predict women's clothing sizes based on historical data on age, weight and height\n\n## 1. Problem definition\n> How well can we predict the appropriate clothing size of for an individual, given age, weight and height?\n\n## 2. Data\nThe data file for this project `final_test.csv` can be downloaded from the clothing-size prediction dataset on Kaggle : https://www.kaggle.com/tourist55/clothessizeprediction\n\n   \n## 3. Evaluation \n\n> **Goal:** Predict the clothing size of an individual with >95% accuracy\n\n## 4. Features\n\n* weight (kg)\n* age (years)\n* height (cm)","metadata":{}},{"cell_type":"markdown","source":"### Import libraries","metadata":{}},{"cell_type":"code","source":"# Regular EDA (exploratory data analysis) and plotting libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n# Models from Scikit-learn\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Model Evaluations\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:02.561038Z","iopub.execute_input":"2021-07-19T05:50:02.561446Z","iopub.status.idle":"2021-07-19T05:50:02.572369Z","shell.execute_reply.started":"2021-07-19T05:50:02.561414Z","shell.execute_reply":"2021-07-19T05:50:02.571018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import data","metadata":{}},{"cell_type":"code","source":"df_raw = pd.read_csv(\"../input/clothessizeprediction/final_test.csv\")\ndf_raw","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:02.574069Z","iopub.execute_input":"2021-07-19T05:50:02.574428Z","iopub.status.idle":"2021-07-19T05:50:02.66585Z","shell.execute_reply.started":"2021-07-19T05:50:02.574394Z","shell.execute_reply":"2021-07-19T05:50:02.664783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_raw.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:02.667487Z","iopub.execute_input":"2021-07-19T05:50:02.667774Z","iopub.status.idle":"2021-07-19T05:50:02.694654Z","shell.execute_reply.started":"2021-07-19T05:50:02.667748Z","shell.execute_reply":"2021-07-19T05:50:02.693714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exploratory data analysis (EDA)","metadata":{}},{"cell_type":"code","source":"df_raw.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:02.696389Z","iopub.execute_input":"2021-07-19T05:50:02.696692Z","iopub.status.idle":"2021-07-19T05:50:02.731439Z","shell.execute_reply.started":"2021-07-19T05:50:02.696662Z","shell.execute_reply":"2021-07-19T05:50:02.730439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of occurences for each size (target variable)\ndf_raw[\"size\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:02.732889Z","iopub.execute_input":"2021-07-19T05:50:02.733182Z","iopub.status.idle":"2021-07-19T05:50:02.768601Z","shell.execute_reply.started":"2021-07-19T05:50:02.733154Z","shell.execute_reply":"2021-07-19T05:50:02.767374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of occurences for each size (target variable)\nsns.countplot(x=df_raw[\"size\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:02.769846Z","iopub.execute_input":"2021-07-19T05:50:02.770174Z","iopub.status.idle":"2021-07-19T05:50:03.078922Z","shell.execute_reply.started":"2021-07-19T05:50:02.77012Z","shell.execute_reply":"2021-07-19T05:50:03.077765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Size `M` is the most common","metadata":{}},{"cell_type":"code","source":"# Age distribution\nsns.displot(df_raw[\"age\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:03.083151Z","iopub.execute_input":"2021-07-19T05:50:03.083463Z","iopub.status.idle":"2021-07-19T05:50:04.335449Z","shell.execute_reply.started":"2021-07-19T05:50:03.083435Z","shell.execute_reply":"2021-07-19T05:50:04.334111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Large fraction of population seems to be around the ages of `25 to 35 years old`","metadata":{}},{"cell_type":"code","source":"# Weight distribution\nsns.displot(df_raw[\"weight\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:04.337286Z","iopub.execute_input":"2021-07-19T05:50:04.337705Z","iopub.status.idle":"2021-07-19T05:50:05.263982Z","shell.execute_reply.started":"2021-07-19T05:50:04.337664Z","shell.execute_reply":"2021-07-19T05:50:05.262916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# height distribution\nsns.displot(df_raw[\"height\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:05.265307Z","iopub.execute_input":"2021-07-19T05:50:05.265606Z","iopub.status.idle":"2021-07-19T05:50:06.226233Z","shell.execute_reply.started":"2021-07-19T05:50:05.265575Z","shell.execute_reply":"2021-07-19T05:50:06.225055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Population weight and height seem to show reasonable normal distributions","metadata":{}},{"cell_type":"markdown","source":"### Removing outliers (z-score)","metadata":{}},{"cell_type":"code","source":"# Removing Outliers\ndfs = []\nsizes = []\nfor size_type in df_raw['size'].unique():\n    sizes.append(size_type)\n    ndf = df_raw[['age','height','weight']][df_raw['size'] == size_type]\n    zscore = ((ndf - ndf.mean())/ndf.std())\n    dfs.append(zscore)\n    \nfor i in range(len(dfs)):\n    dfs[i]['age'] = dfs[i]['age'][(dfs[i]['age']>-3) & (dfs[i]['age']<3)]\n    dfs[i]['height'] = dfs[i]['height'][(dfs[i]['height']>-3) & (dfs[i]['height']<3)]\n    dfs[i]['weight'] = dfs[i]['weight'][(dfs[i]['weight']>-3) & (dfs[i]['weight']<3)]\n\nfor i in range(len(sizes)):\n    dfs[i]['size'] = sizes[i]\ndf_raw = pd.concat(dfs)\ndf_raw.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:06.228106Z","iopub.execute_input":"2021-07-19T05:50:06.228547Z","iopub.status.idle":"2021-07-19T05:50:06.503577Z","shell.execute_reply.started":"2021-07-19T05:50:06.2285Z","shell.execute_reply":"2021-07-19T05:50:06.502386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Filling missing data","metadata":{}},{"cell_type":"code","source":"# Check for missing values\ndf_raw.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:06.505879Z","iopub.execute_input":"2021-07-19T05:50:06.506224Z","iopub.status.idle":"2021-07-19T05:50:06.529568Z","shell.execute_reply.started":"2021-07-19T05:50:06.506195Z","shell.execute_reply":"2021-07-19T05:50:06.528218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling missing data\ndf_raw[\"age\"] = df_raw[\"age\"].fillna(df_raw['age'].median())\ndf_raw[\"height\"] = df_raw[\"height\"].fillna(df_raw['height'].median())\ndf_raw[\"weight\"] = df_raw[\"weight\"].fillna(df_raw['weight'].median())","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:06.531355Z","iopub.execute_input":"2021-07-19T05:50:06.531846Z","iopub.status.idle":"2021-07-19T05:50:06.550501Z","shell.execute_reply.started":"2021-07-19T05:50:06.531785Z","shell.execute_reply":"2021-07-19T05:50:06.549019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mapping clothes size from strings to numeric\ndf_raw['size'] = df_raw['size'].map({\"XXS\": 1,\n                                     \"S\": 2,\n                                     \"M\" : 3,\n                                     \"L\" : 4,\n                                     \"XL\" : 5,\n                                     \"XXL\" : 6,\n                                     \"XXXL\" : 7})","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:06.554602Z","iopub.execute_input":"2021-07-19T05:50:06.554946Z","iopub.status.idle":"2021-07-19T05:50:06.576944Z","shell.execute_reply.started":"2021-07-19T05:50:06.554915Z","shell.execute_reply":"2021-07-19T05:50:06.575807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for missing values\ndf_raw.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:06.578639Z","iopub.execute_input":"2021-07-19T05:50:06.578961Z","iopub.status.idle":"2021-07-19T05:50:06.59251Z","shell.execute_reply.started":"2021-07-19T05:50:06.57893Z","shell.execute_reply":"2021-07-19T05:50:06.591277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_raw","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:06.59376Z","iopub.execute_input":"2021-07-19T05:50:06.594246Z","iopub.status.idle":"2021-07-19T05:50:06.613064Z","shell.execute_reply.started":"2021-07-19T05:50:06.594214Z","shell.execute_reply":"2021-07-19T05:50:06.612025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering\nWe will create two new features to help model training effectiveness:\n* `bmi` (body-mass index) - medically accepted measure of obesity\n* `weight-squared` - value increases exponentially with increase in `weight`","metadata":{}},{"cell_type":"code","source":"df_raw[\"bmi\"] = df_raw[\"height\"]/df_raw[\"weight\"]\ndf_raw[\"weight-squared\"] = df_raw[\"weight\"] * df_raw[\"weight\"]","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:06.614635Z","iopub.execute_input":"2021-07-19T05:50:06.615083Z","iopub.status.idle":"2021-07-19T05:50:06.630226Z","shell.execute_reply.started":"2021-07-19T05:50:06.615041Z","shell.execute_reply":"2021-07-19T05:50:06.629155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_raw","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:06.631899Z","iopub.execute_input":"2021-07-19T05:50:06.632513Z","iopub.status.idle":"2021-07-19T05:50:06.660083Z","shell.execute_reply.started":"2021-07-19T05:50:06.632466Z","shell.execute_reply":"2021-07-19T05:50:06.659066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation matrix","metadata":{}},{"cell_type":"code","source":"corr = sns.heatmap(df_raw.corr(), annot=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:06.66153Z","iopub.execute_input":"2021-07-19T05:50:06.662045Z","iopub.status.idle":"2021-07-19T05:50:07.149393Z","shell.execute_reply.started":"2021-07-19T05:50:06.66201Z","shell.execute_reply":"2021-07-19T05:50:07.148156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clothing `size` seems much more highly dependent on `weight` than `age` or `height`, and seems to be have a strong inverse correlation with `bmi`","metadata":{}},{"cell_type":"markdown","source":"### Splitting data into training and validation datasets\nThe target variable is clothing `size`, and we will let the validation set be 10% of the total population.","metadata":{}},{"cell_type":"code","source":"# Features\nX = df_raw.drop(\"size\", axis=1)\n\n# Target\ny = df_raw[\"size\"]","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:07.153846Z","iopub.execute_input":"2021-07-19T05:50:07.154189Z","iopub.status.idle":"2021-07-19T05:50:07.166915Z","shell.execute_reply.started":"2021-07-19T05:50:07.154157Z","shell.execute_reply":"2021-07-19T05:50:07.165558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:07.168981Z","iopub.execute_input":"2021-07-19T05:50:07.169401Z","iopub.status.idle":"2021-07-19T05:50:07.184847Z","shell.execute_reply.started":"2021-07-19T05:50:07.169358Z","shell.execute_reply":"2021-07-19T05:50:07.183629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:07.186535Z","iopub.execute_input":"2021-07-19T05:50:07.186965Z","iopub.status.idle":"2021-07-19T05:50:07.201812Z","shell.execute_reply.started":"2021-07-19T05:50:07.186922Z","shell.execute_reply":"2021-07-19T05:50:07.200665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting data into training set and validation set\n\nX_train, X_test, y_train, y_test, = train_test_split(X,y, test_size=0.10)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:07.20311Z","iopub.execute_input":"2021-07-19T05:50:07.203398Z","iopub.status.idle":"2021-07-19T05:50:07.229987Z","shell.execute_reply.started":"2021-07-19T05:50:07.203371Z","shell.execute_reply":"2021-07-19T05:50:07.228793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_train), len(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:07.231349Z","iopub.execute_input":"2021-07-19T05:50:07.231637Z","iopub.status.idle":"2021-07-19T05:50:07.238592Z","shell.execute_reply.started":"2021-07-19T05:50:07.231609Z","shell.execute_reply":"2021-07-19T05:50:07.2372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training Model\nWe will try:\n* Logistic Regression\n* K-Nearest Neighbors\n* Random Forest Classifier\n* Decision Tree Classifier","metadata":{}},{"cell_type":"code","source":"# Put models in a dictionary\nmodels = {\"Logistic Regression\": LogisticRegression(),\n         \"KNN\": KNeighborsClassifier(),\n         \"Random Forest\": RandomForestClassifier(),\n         \"Decision Tree\": DecisionTreeClassifier()}\n\n# Create a function to fit and score models\ndef fit_and_score(models, X_train, X_test, y_train, y_test):\n   \n    \"\"\"\n   Fits and evaluates given machine learning models.\n   models: a dict of different Scikit_Learn machine learning models\n   X_train: training data (no labels)\n   X_test: testing data (no labels)\n   y_train: training labels\n   y_test: test labels\n   \"\"\" \n    # Set random seed\n    np.random.seed(18)\n    # Make a dictionary to keep model scores\n    model_scores = {}\n    # Loop through models\n    for name, model in models.items():\n        # Fit model to data\n        model.fit(X_train, y_train)\n        # Evaluate model and append its score to model_scores\n        model_scores[name] = model.score(X_test, y_test)\n\n    return model_scores","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:07.240143Z","iopub.execute_input":"2021-07-19T05:50:07.240519Z","iopub.status.idle":"2021-07-19T05:50:07.251669Z","shell.execute_reply.started":"2021-07-19T05:50:07.240481Z","shell.execute_reply":"2021-07-19T05:50:07.25057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_scores = fit_and_score(models,X_train,X_test,y_train,y_test)\n\n# model_scores","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:07.253004Z","iopub.execute_input":"2021-07-19T05:50:07.253648Z","iopub.status.idle":"2021-07-19T05:50:07.269776Z","shell.execute_reply.started":"2021-07-19T05:50:07.253597Z","shell.execute_reply":"2021-07-19T05:50:07.268698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_compare = pd.DataFrame(model_scores, index=[\"accuracy\"])\n# model_compare.T.plot.bar();","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:07.27115Z","iopub.execute_input":"2021-07-19T05:50:07.271552Z","iopub.status.idle":"2021-07-19T05:50:07.283545Z","shell.execute_reply.started":"2021-07-19T05:50:07.27151Z","shell.execute_reply":"2021-07-19T05:50:07.282579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model evaluation\nWe will continue with the DecisionTreeClassifier model, which scored highest in initial tests with `99.9749%` accuracy.\n","metadata":{}},{"cell_type":"code","source":"model = DecisionTreeClassifier()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:07.284795Z","iopub.execute_input":"2021-07-19T05:50:07.285151Z","iopub.status.idle":"2021-07-19T05:50:07.635231Z","shell.execute_reply.started":"2021-07-19T05:50:07.285119Z","shell.execute_reply":"2021-07-19T05:50:07.634128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix\nprint(confusion_matrix(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:07.636647Z","iopub.execute_input":"2021-07-19T05:50:07.636957Z","iopub.status.idle":"2021-07-19T05:50:07.664483Z","shell.execute_reply.started":"2021-07-19T05:50:07.636927Z","shell.execute_reply":"2021-07-19T05:50:07.663026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classification report\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:07.666186Z","iopub.execute_input":"2021-07-19T05:50:07.666633Z","iopub.status.idle":"2021-07-19T05:50:07.705496Z","shell.execute_reply.started":"2021-07-19T05:50:07.666587Z","shell.execute_reply":"2021-07-19T05:50:07.704285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Conclusion","metadata":{}},{"cell_type":"markdown","source":"The trained model shows a weighted average accuracy of `99.9%`, so the evaluation metric of >95% has been met.","metadata":{}},{"cell_type":"markdown","source":"### Feature Importance","metadata":{}},{"cell_type":"code","source":"# Find feature importance of ideal model\nlen(model.feature_importances_)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:07.706902Z","iopub.execute_input":"2021-07-19T05:50:07.707177Z","iopub.status.idle":"2021-07-19T05:50:07.716543Z","shell.execute_reply.started":"2021-07-19T05:50:07.707148Z","shell.execute_reply":"2021-07-19T05:50:07.715392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.feature_importances_","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:07.71826Z","iopub.execute_input":"2021-07-19T05:50:07.718598Z","iopub.status.idle":"2021-07-19T05:50:07.73028Z","shell.execute_reply.started":"2021-07-19T05:50:07.718567Z","shell.execute_reply":"2021-07-19T05:50:07.729305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Helper function for plotting feature importance\ndef plot_features(columns, importances,n=20):\n    df = (pd.DataFrame({\"features\": columns,\n                       \"feature_importances\": importances})\n         .sort_values(\"feature_importances\", ascending=False)\n         .reset_index(drop=True))\n    # Plot dataframe\n    fix, ax = plt.subplots()\n    ax.barh(df[\"features\"][:n], df[\"feature_importances\"][:20])\n    ax.set_ylabel(\"Features\")\n    ax.set_xlabel(\"Feature Importance\")\n    ax.invert_yaxis()\n    \nplot_features(X_train.columns, model.feature_importances_)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T05:50:07.731606Z","iopub.execute_input":"2021-07-19T05:50:07.732059Z","iopub.status.idle":"2021-07-19T05:50:07.914266Z","shell.execute_reply.started":"2021-07-19T05:50:07.732014Z","shell.execute_reply":"2021-07-19T05:50:07.912939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`weight` seems to be an extremely significant determinant for the model relative to the other features","metadata":{}}]}