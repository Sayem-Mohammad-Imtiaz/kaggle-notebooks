{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**PREDICTING BREAST CANCER USING VARIOUS CLASSIFICATION MODELS.**\n* The features that have been computed from digitized images of the cell nuclei, which can be used to build a model to predict whether a tumor is benign or malignant.\n* 1 = Malignant (Cancerous) - Present (M)\n* 0  = Benign (Not Cancerous) -Absent (B)","metadata":{}},{"cell_type":"code","source":"#importing libaries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing dataset\nds = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reviewing dataset\npd.set_option('display.max_columns',None)\nds.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dropping unnecessary features\nds.drop(['id', 'Unnamed: 32'], axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking type of feaures\nds.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dataset has 569 rows and 31 columns\nds.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking for null values\nds.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NO MISSING DATA**","metadata":{}},{"cell_type":"code","source":"#taking care of categorical values\nfrom sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\nds['diagnosis']=le.fit_transform(ds['diagnosis'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,14))\nsns.heatmap(ds.corr(), cmap='Blues', annot = True)\nplt.title(\"Correlation Map\", fontweight = \"bold\", fontsize=16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**WE CAN EITHER REMOVE THE HIGH CORRELATED FEATURES OR WE CAN USE ALL THE FEATURES, I AM USING ALL FEATURES.**\n* **REMOVING CORRELATED FEATURES MAY INCREASE ACCURACY**","metadata":{}},{"cell_type":"code","source":"#defining dependent and independent variables\nx = ds.drop('diagnosis', axis=1)\ny = ds['diagnosis']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#splitting data into training and testing set\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**APPLYING FEATURE SCALING MAY IMPROVE ACCURACY**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.fit_transform(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**APPLYING MODELS**","metadata":{}},{"cell_type":"code","source":"#training model\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(max_iter = 10000)\nlr.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = lr.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nlra = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',lra)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training model\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski',p = 2)\nknn.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = knn.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nknna = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training model\nfrom sklearn.svm import SVC\nsvc = SVC(kernel = 'linear')\nsvc.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = svc.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nsva =accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training model\nfrom sklearn.svm import SVC\nsvc = SVC(kernel = 'rbf')\nsvc.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = svc.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nsva2 = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training model\nfrom sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = nb.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nnba = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training model\nfrom sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(criterion = 'entropy')\ndt.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = dt.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\ndta = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training model\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 60, criterion = 'entropy',random_state = 0)\nrf.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = rf.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nrfa = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#comparing accuracies\nplt.figure(figsize= (8,7))\nac = [lra,knna,sva,sva2,nba,dta,rfa]\nname = ['Logistic Regression','knn','svm','Kernel Svm','Naive Bayes','Decision Tree', 'Random Forest']\nsns.barplot(x = ac,y = name,palette='pastel')\nplt.title(\"Plotting the Model Accuracies\", fontsize=16, fontweight=\"bold\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**THERE WAS A TIE BETWEEN RANDOM FOREST AND KERNEL SVM WITH AN ACCURACY OF 98.2 %**","metadata":{}}]}