{"cells":[{"metadata":{"_uuid":"f0fe4aac65ecf46e6cedf76cc0405cfcfbb73feb"},"cell_type":"markdown","source":" **Mean Team**\n<br>Midhush Manohar: 01FB16ECS208\n<br>Naveen Suresh: 01FB16ECS222\n<br>Srikumar Subramanian: 01FB16ECS396"},{"metadata":{"_uuid":"ca783ef7550065a6c87cdd3fc73eb8ca1bff1c08"},"cell_type":"markdown","source":"**Importing Required Libraries**"},{"metadata":{"trusted":true,"_uuid":"7c8ae2079fca253b4b1ef1699d400fd86d71ae9d"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.neighbors import KNeighborsClassifier  \nimport operator\nimport random\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be5405d886aa94170e2046c742e060fc3b73b07c"},"cell_type":"markdown","source":"**Setting the seed to produce consistent results**"},{"metadata":{"trusted":true,"_uuid":"a08dc5740f7289c5901c3225703a649cc53e64ee"},"cell_type":"code","source":"random.seed(3) # To get the same train-test datasets","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"48d656c9a664ab65e4527a40f6010be5392813cc"},"cell_type":"markdown","source":"**Reading from File**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"input_file = '../input/Absenteeism_at_work.csv'\ndf = pd.read_csv(input_file)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb1a5f91044cc8c9e5bb4b44a5293d45a9a63d36"},"cell_type":"markdown","source":"**Basic Stock Taking**"},{"metadata":{"trusted":true,"_uuid":"69b1c4c4c725fb711a61196ed165bc7dc5791058"},"cell_type":"code","source":"print(df.head())\nprint((np.unique(np.array(df.iloc[:,14]))))\nprint(df.isna().sum())\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f7de488bb9e54d31ac2b6983de21e9f10f7ca86"},"cell_type":"markdown","source":"**Pre-Processing**"},{"metadata":{"trusted":true,"_uuid":"610bf08adc1335a1c5855a5917e3193d302c46f4"},"cell_type":"code","source":"l = []\nl.append(df.index[df['Absenteeism time in hours'] == 7].tolist()[0])\nl.append(df.index[df['Absenteeism time in hours'] == 48].tolist()[0])\nl.append(df.index[df['Absenteeism time in hours'] == 104].tolist()[0])\ndf_temp = df.iloc[df.index[l]]\ndf.drop(df.index[l], inplace = True)\ndf_train, df_test = train_test_split(df.iloc[:, 0:15],  stratify = df.iloc[:,14]) # 25% test and 75% train\ndf_train = df_train.append(df_temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ca028000951de9ed1731f1435c343ee2d2d990d"},"cell_type":"code","source":"cat_indices = [1, 2, 3, 4, 11, 12]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c27eb116e56eb18e5cf0b2c9343164b92001ae5"},"cell_type":"code","source":"for i in cat_indices:\n    labelEncoder = LabelEncoder()\n    labelEncoder.fit(np.unique(np.array(df.iloc[:,i])))\n    df_train.iloc[:,i] = labelEncoder.transform(df_train.iloc[:,i])\n    df_test.iloc[:,i] = labelEncoder.transform(df_test.iloc[:,i])\n    \n#     Alternative:\n#     labelEncoder = LabelEncoder()\n#     df_train.iloc[:,i] = labelEncoder.fit_transform(df_train.iloc[:,i])\n#     df_test.iloc[:,i] = labelEncoder.fit_transform(df_test.iloc[:,i])\n#     oneHotEncoder = OneHotEncoder()\n#     df_train.iloc[:,i] = oneHotEncoder.fit_transform(df_train.iloc[:,i].values.reshape(-1,1)).toarray()\n#     df_test.iloc[:,i] = oneHotEncoder.fit_transform(df_test.iloc[:,i].values.reshape(-1,1)).toarray()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e19ce0f615967666368fcdee0030ee69efe92655"},"cell_type":"code","source":"X_train = np.array(df_train.drop(['Absenteeism time in hours'], 1).astype(float))\ny_train = np.array(df_train['Absenteeism time in hours'])\n\nX_test = np.array(df_test.drop(['Absenteeism time in hours'], 1).astype(float))\ny_test = np.array(df_test['Absenteeism time in hours'])\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a17ab07ccd89f202db6b8d81e5cca31780f4af7f"},"cell_type":"code","source":"scaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\n\nscaler = MinMaxScaler()\nX_test_scaled = scaler.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49293f556ad21d3284563c88ac9ed9935caaa8d1"},"cell_type":"markdown","source":"**k-Means Clustering**"},{"metadata":{"trusted":true,"_uuid":"1a2b9648f98b79a25fb6e937976320cef3c9e58a"},"cell_type":"code","source":"k_list = [i for i in range(2,50)]                 #Trying for values of k from 2 to 49\ntrain_acc = {}\ntest_acc = {}\nsse = {}\n\n\nfor no_clusters in k_list:\n    kmeans = KMeans(n_clusters=no_clusters, random_state = 3)       #Using sklearn function for k-Means clustering, calling k-Means class\n    kmeans.fit(X_train_scaled)                    #Fitting model with the scaled given data\n    \n    l = []\n    for i in range(no_clusters):                  #Finding the number of occurences of each class for each cluster\n        temp = {}\n        for k in np.unique(np.array(df_train.iloc[:,14])):\n            temp[k] = 0\n        for j in range(len(kmeans.labels_)):\n            if(kmeans.labels_[j] == i):\n               temp[df_train.iloc[j, 14]] += 1\n        l.append(temp)\n    \n    op = []\n    for i in range(no_clusters):                  #Choosing max no. of occurences of the class as the label for the cluster\n        op.append(max(l[i].items(), key=operator.itemgetter(1))[0])\n        \n    correct = 0\n    for i in range(len(X_train_scaled)):          #Training Data Accuracy\n        indiv_record = np.array(X_train_scaled[i].astype(float))\n        indiv_record = indiv_record.reshape(-1, len(indiv_record))\n        prediction = kmeans.predict(indiv_record)\n        prediction = op[prediction[0]]\n        if prediction == y_train[i]:\n            correct += 1\n    train_acc[no_clusters] = (correct/len(X_train_scaled))\n    \n    \n    correct = 0\n    sse[no_clusters] = 0\n    for i in range(len(X_test_scaled)):                       #Testing Data Accuracy\n        indiv_record = np.array(X_test_scaled[i].astype(float))\n        indiv_record = indiv_record.reshape(-1, len(indiv_record))\n        prediction = kmeans.predict(indiv_record)\n        prediction = op[prediction[0]]\n        if prediction == y_test[i]:\n            correct += 1\n        sse[no_clusters] += (prediction - y_test[i])**2          #SSE Calc\n    test_acc[no_clusters] = (correct/len(X_test_scaled))\n    \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fcf3f1126da7157d3c28e137d661a3faf0cdf32d"},"cell_type":"markdown","source":"Accuracy Comparison Between Training and Testing Sets"},{"metadata":{"trusted":true,"_uuid":"620ccb6ba9622ffdb56e56bd1b8a735afc122a09"},"cell_type":"code","source":"lists = sorted(train_acc.items()) \nx1, y1 = zip(*lists)\nh1, = plt.plot(x1,y1,label='Training')\n\nlists = sorted(test_acc.items()) \nx2, y2 = zip(*lists)\nh2, = plt.plot(x2,y2,label='Testing')\nplt.title(\"Train and Test Accuracies for Varying K\")\nplt.xlabel(\"K\")\nplt.ylabel(\"Accuracy Percentage\")\nplt.legend(handles = [h1, h2])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ca135ed32217934d9502cd7ada1557e5f1247f3"},"cell_type":"markdown","source":"SSE Error for Different Ks"},{"metadata":{"trusted":true,"_uuid":"18d7109207408ff743baff1067fc06251b2f68f4"},"cell_type":"code","source":"lists = sorted(sse.items()) \nx, y = zip(*lists)\nplt.plot(np.array(x),np.array(y))\nplt.title(\"SSE for Varying K\")\nplt.xlabel(\"K\")\nplt.ylabel(\"SSE Error\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8cfe660b6e89d1ea84ce9f357a156ad788d95407"},"cell_type":"code","source":"plt.plot(np.array(x2), np.array(y2) - np.array(y1))\nplt.title(\"Difference in Predicted values and ground truth for Varying K\")\nplt.xlabel(\"K\")\nplt.ylabel(\"Difference\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c92692a459f416567fa91b2425223c4f687e519b"},"cell_type":"code","source":"#Hence we use k = 24, minimum value for SSE, and the train and test accuracies are amongst the highest\nno_clusters = 24\nprint(\"Train Accuracy: \", train_acc[no_clusters])\nprint(\"Test Accuracy: \", test_acc[no_clusters])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"436d3adf2df56c45ff56d9bb1a40423355535ef3"},"cell_type":"code","source":"kmeans = KMeans(n_clusters=no_clusters, random_state = 3)       #Using sklearn function for k-Means clustering, calling k-Means class\nkmeans.fit(X_train_scaled)                    #Fitting model with the scaled given data\n\nl = []\nresults = []\nfor i in range(no_clusters):                  #Finding the number of occurences of each class for each cluster\n    temp = {}\n    for k in np.unique(np.array(df_train.iloc[:,14])):\n        temp[k] = 0\n    for j in range(len(kmeans.labels_)):\n        if(kmeans.labels_[j] == i):\n           temp[df_train.iloc[j, 14]] += 1\n    l.append(temp)\n\nop = []\nfor i in range(no_clusters):                  #Choosing max no. of occurences of the class as the label for the cluster\n    op.append(max(l[i].items(), key=operator.itemgetter(1))[0])\n\n\nfor i in range(len(X_test_scaled)):                       #Testing Data Accuracy\n    indiv_record = np.array(X_test_scaled[i].astype(float))\n    indiv_record = indiv_record.reshape(-1, len(indiv_record))\n    prediction = kmeans.predict(indiv_record)\n    results.append(op[prediction[0]])\n    \n\nprint(confusion_matrix(y_test, results))\nprint(classification_report(y_test, results))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39a0dabcf14ab5270dad396f9bb7ed0188d77293"},"cell_type":"markdown","source":"**Knn**"},{"metadata":{"trusted":true,"_uuid":"7b6a653464db84c0635bc9a88d6d95c802ceacc6"},"cell_type":"code","source":"mean_error = []\ntest_acc = []\n\nk = [x for x in range(1,41)]\n\nfor num_neighbors in k:     # Evaluating metrics for different values of k from 1 to 39\n    knn = KNeighborsClassifier(n_neighbors=num_neighbors)\n    knn.fit(X_train_scaled, y_train)\n    pred_i = knn.predict(X_test_scaled)\n    mean_error.append(np.mean(pred_i != y_test))\n    test_acc.append(np.mean(pred_i == y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b33a70b74eab7b073c42c87bdda399c773510b25"},"cell_type":"markdown","source":"**Plot of mean-error versus k**\n\nSSE Error not very useful because the number of clusters is equal to the number of unique values in Y_train"},{"metadata":{"trusted":true,"_uuid":"ad2b235279f5ecc7c054ceebbae3a0c5113b76bc"},"cell_type":"code","source":"# Plotting the graph for mean-error for varying k\nplt.figure(figsize=(12, 6))  \nplt.plot(range(1, 41), mean_error, color='orange', linestyle='dashed', marker='o',  \n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate K Value')  \nplt.xlabel('K Value')  \nplt.ylabel('Mean Error')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3e2fd813e46bdaf4f50a0cdcbf8ddc4b0202830"},"cell_type":"markdown","source":"**Plot of Testing accuracy versus K**"},{"metadata":{"trusted":true,"_uuid":"e72ef66cfc0a1f664d533f7cbf0d0ea39b95a0a1"},"cell_type":"code","source":"# Plotting the graph for Testing accuracy for varying k\nplt.figure(figsize=(12, 6))  \nplt.plot(range(1, 41), test_acc, color='green', linestyle='dashed', marker='o',  \n         markerfacecolor='yellow', markersize=10)\nplt.title('Testing accuarcy  K Value')  \nplt.xlabel('K Value')  \nplt.ylabel('Testing accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e40c6e5ced3ab4ac78db43d32ceabf2864e503fc"},"cell_type":"code","source":"# Finding the value of k with the lowest mean error or highest test accuracy from 1 to 40\nnum_neighbors = np.argmin(mean_error)\nprint(\"The value of K the gives the lowest error is: \", num_neighbors+1)\nprint(\"The value of error is: \", mean_error[num_neighbors])\nprint(\"The value of testing accuracy is: \", test_acc[num_neighbors])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90cee10893ae210be1a7468f50a688307fd8b93c"},"cell_type":"code","source":"# Classification report and confusion matrix for k\nknn = KNeighborsClassifier(n_neighbors=num_neighbors+1)\nknn.fit(X_train_scaled, y_train)\npredict = knn.predict(X_test_scaled)\n\nprint(\"The confusion matrix for the optimum value of k\")\nprint(confusion_matrix(y_test, predict))  \nprint(\"The classification metrics when using the optimum value of k found\")\nprint(classification_report(y_test, predict))  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd9e76ee96b8dd5af898d40dce689e6f12ebc40b"},"cell_type":"markdown","source":"**Comparing K-Means with KNN**\n\nK-Means (K-Means Clustering) and KNN (K-Nearest Neighbour) are often confused with each other in Machine Learning. K-Means is an Unsupervised learning technique which is used for Clustering, whereas KNN is a Supervised learning technique used for Classification (and sometimes for Regression). \nThe 'K' in K-Means is for the number of clusters the algorithm is trying to identify/learn from the data. The 'K' in KNN, on the other hand, is for the number of nearest neighbours used in classifying a test sample.\nFor this dataset, KNN works out to be better as the given data is already labelled. The percentage accuracy reflects this conclusion, with the value for KNN being higher than that of K-Means.\n"},{"metadata":{"trusted":true,"_uuid":"89622bf6f528a30913ee9c2fccf0a45d49c64a73"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61429a41db8e39ca9becf55c5d0a3e28e231eeba"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}