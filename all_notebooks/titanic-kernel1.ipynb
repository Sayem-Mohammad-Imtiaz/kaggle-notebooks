{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import Imputer, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import precision_score,recall_score,confusion_matrix, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import VotingClassifier\nfrom xgboost import XGBClassifier\n\nimport seaborn as sns\n%matplotlib inline\n\n##Train Data set Details\n#Survived : 0= No ; 1 = Yes\n#pClass: Passenger Class: 1, 2 or 3\n#Name, Sex, Age\n#SibSp: No of siblings/spouses onboard\n#Parch: No of parents/children onboard\n#Tickets, Fare, Cabin\n#Embarked: Port where embarked. C: Cherboug, Q: Queenstown, S: Southampton\n#Read the csv files\ntrain_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\n#Create a consolidated data set for better accuracy for Impute\ntot_df = train_df.append(test_df)\nprint(train_df.shape)\nprint(test_df.shape)\ntrain_df.describe(include = 'all')\n\n#Keeping the Test DF Passenger Id for prediction at later stage.\npassenger_id = test_df['PassengerId']\n#Drop PassengerId as this doesn't add value. \ntrain_df.drop(['PassengerId'], axis = 1, inplace = True)\ntest_df.drop(['PassengerId'], axis = 1, inplace = True)\ntot_df.drop(['PassengerId'], axis = 1, inplace = True)\n\n#Since only one Fare is null, replaced it with mean\ntest_df.Fare.fillna(test_df.Fare.mean(),inplace = True)\nprint(\"Count of Nulls by Field Name in Train set\")\nprint(train_df.isnull().sum())\nprint(\"Count of Nulls by Field Name in Test set\")\nprint(test_df.isnull().sum())\n\n#Setting Sex as 1 or 0 for Correlation Plot. \ntrain_df['Sex'] = train_df.Sex.apply(lambda x: 0 if x == \"female\" else 1)\ntest_df['Sex'] = test_df.Sex.apply(lambda x: 0 if x == \"female\" else 1)\ntot_df['Sex'] = tot_df.Sex.apply(lambda x: 0 if x == \"female\" else 1)\n\n#Boxplot to check Fare outlier data by Class\nsns.boxplot(x='Pclass',y='Fare', data = train_df)\n\n#Since only one record is an outlier, we consider all other records in the train set\n#train_df = train_df[train_df['Fare']<300]\ntrain_df.shape\n\n#For age calculation, we should take the consolidated dataframe\n#If we try to separate the Title from name, we might get an indicator of age\nfor nm in tot_df['Name']:\n    tot_df['Title'] = tot_df['Name'].str.extract('([A-Za-z]+)\\.',expand = True)\n\ntot_df['Title'].value_counts()\n\n#There are multiple titles with little count of occurrence. We'll map them to existing Titles\n#Mlle : French for little Madame\n#Dona: honor word for ladies\n#Johnkheer: lowest rank within nobility\n#Reverend and Dr are assumed to have higher age and hence not mapped to Mr\nmapping = { 'Col': 'Mr', 'Major': 'Mr','Mlle':'Miss','Ms': 'Miss','Capt': 'Mr', 'Countess': 'Mrs', \n            'Lady': 'Mrs','Sir': 'Mr', 'Don': 'Mr', 'Dona': 'Mrs', 'Jonkheer': 'Mr', 'Mme': 'Miss'}\ntot_df.replace({'Title': mapping}, inplace=True)\n\n#Distribute the titles on train and test dataset\ntrain_df['Title']=tot_df['Title'][:891]\ntest_df['Title']=tot_df['Title'][891:]\ntot_df['Title'].value_counts()\n\n#Grouping the Age by titles, we take the median age for each title. \ntitles = ['Mr','Miss','Mrs','Master','Dr','Rev']\nfor title in titles:\n    age_imp = tot_df.groupby('Title')['Age'].median()[titles.index(title)]\n    tot_df.loc[(tot_df['Age'].isnull()) & (tot_df['Title'] == title), 'Age'] = age_imp \ntot_df.isnull().sum()\n\n#Setting the Imputed values on Train and Test Data\ntrain_df['Age']=tot_df['Age'][:891]\ntest_df['Age'] = tot_df['Age'][891:]\ntrain_df.isnull().sum()\n\n#There are two nulls for Embarked Location. \ntot_df.fillna(tot_df['Embarked'].value_counts().index[0])\ntot_df.isnull().sum()\n\n#Setting Embarked value for Tot DF. Not required for Test DF as there are no nulls. \ntrain_df['Embarked'] = tot_df['Embarked'][:891]\ntrain_df.isnull().sum()\n\n#There are lot of nulls in Cabin. Creating HasCabin column for those passengers who have been allotted Cabins. #\ntrain_df['HasCabin'] = train_df.Cabin.apply(lambda x: 0 if pd.isnull(x) else 1)\ntest_df['HasCabin'] = test_df.Cabin.apply(lambda x: 0 if pd.isnull(x) else 1)\n\ntrain_df.describe(include='all')\n\ntrain_df.groupby('Survived').mean()\n\ntrain_df.groupby('Sex').mean()\n\n#Checking to see the correlation plots on Train set\nplt.subplots(figsize = (15,8))\nsns.heatmap(train_df.corr(), annot=True,cmap=\"BrBG\")\n\n#Getting a Pairplot to observe behaviour by feature pairs.\npp = sns.pairplot(train_df[[u'Survived', u'Pclass', u'Sex', u'Age',u'SibSp', u'Parch', u'Fare', u'Embarked',\n       u'HasCabin', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\npp.set(xticklabels=[])\n\n\nplt.subplots(figsize = (15,8))\nsns.set(style=\"darkgrid\")\nbp = sns.barplot(x = \"Sex\", y = \"Survived\", data=train_df)\nplt.title(\"Survived Passengers\", fontsize = 25)\nlabels = ['Female', 'Male']\nplt.ylabel(\"% of Passengers survived\", fontsize = 15)\nplt.xlabel(\"Gender\",fontsize = 15)\n#plt.xticks(sorted(train_df.Sex.unique()), labels)\nfor p in bp.patches:\n    height = p.get_height()\n    bp.text(p.get_x()+p.get_width()/2.,height+0.04, '{:1.2f}'.format(height),ha=\"center\") \n\nplt.subplots(figsize = (15,8))\nsns.set(style=\"darkgrid\")\nbp = sns.barplot(x = \"Pclass\", y = \"Survived\", data=train_df)\nplt.title(\"Survived Passengers\", fontsize = 25)\nlabels = ['1', '2','3']\nplt.ylabel(\"% of Passengers survived\", fontsize = 15)\nplt.xlabel(\"Passenger Class\",fontsize = 15)\nfor p in bp.patches:\n    height = p.get_height()\n    bp.text(p.get_x()+p.get_width()/2.,height+0.05, '{:1.2f}'.format(height),ha=\"center\") \n\nplt.subplots(figsize = (15,8))\nplt.title(\"Survived Passengers vs Fare\", fontsize = 25)\nsns.kdeplot(train_df.loc[(train_df['Survived']==0),'Fare'], color ='r',shade = True, label = \"Did not Survive\")\nsns.kdeplot(train_df.loc[(train_df['Survived']==1),'Fare'], color ='b',shade = True, label = \"Survived\")\n\nplt.subplots(figsize = (15,8))\nplt.title(\"Survived Passengers vs Age\", fontsize = 25)\nsns.kdeplot(train_df.loc[(train_df['Survived']==0),'Age'], color ='r',shade = True, label = \"Did not Survive\")\nsns.kdeplot(train_df.loc[(train_df['Survived']==1),'Age'], color ='b',shade = True, label = \"Survived\")\n\nplt.subplots(figsize = (15,8))\nplt.title(\"Survived Passengers vs Sibling & Spouse\", fontsize = 25)\nsns.kdeplot(train_df.loc[(train_df['Survived']==0),'SibSp'], color ='r',shade = True, label = \"Did not Survive\")\nsns.kdeplot(train_df.loc[(train_df['Survived']==1),'SibSp'], color ='b',shade = True, label = \"Survived\")\n\n#Define a function to identify family type based on number of members in family\ndef family_type(count):\n    ftype = ''\n    if(count <=1):\n        ftype = 'Single'\n    elif(count <=4):\n        ftype = 'Small'\n    elif(count >4):\n        ftype = 'Large'\n    return ftype\n#Count of self, SiblingSpouse and ParentsChildren\ntrain_df['Family_Type']= (train_df['SibSp']+train_df['Parch']+1).map(family_type)\ntest_df['Family_Type']= (test_df['SibSp']+test_df['Parch']+1).map(family_type)\n\n#Define a function to identify Age Group based on Age\ndef age_group_fun(age):\n    agroup = ''\n    if age <=1:\n        agroup = 'Infant'\n    elif age <=3:\n        agroup = 'Toddler'\n    elif age <=12:\n        agroup = 'Child'\n    elif age <=18:\n        agroup = 'Teen'\n    elif age <=30:\n        agroup = 'Young'\n    elif age <=45:\n        agroup = 'Adult'\n    elif age <=65:\n        agroup = 'Middle_Age'\n    else:\n        agroup = 'Old'\n    return agroup\n\n#Setting the Age Group by calling the function\ntrain_df['Age_Group']= (train_df['Age']).map(age_group_fun)\ntest_df['Age_Group']= (test_df['Age']).map(age_group_fun)\n\nplt.subplots(figsize = (15,8))\nsns.set(style=\"darkgrid\")\nbp = sns.barplot(x = \"Family_Type\", y = \"Fare\", data=train_df)\nplt.title(\"Fare vs Family type\", fontsize = 25)\nplt.ylabel(\"Fare\", fontsize = 15)\nplt.xlabel(\"Family Type\",fontsize = 15)\nfor p in bp.patches:\n    height = p.get_height()\n    bp.text(p.get_x()+p.get_width()/2.,height+0.05, '{:1.2f}'.format(height),ha=\"center\") \n    \nplt.subplots(figsize = (15,8))\nsns.set(style=\"darkgrid\")\nbp = sns.barplot(x = \"Family_Type\", y = \"Survived\", data=train_df)\nplt.title(\"Survived Passengers\", fontsize = 25)\nplt.ylabel(\"% of Passengers survived\", fontsize = 15)\nplt.xlabel(\"Family Type\",fontsize = 15)\nfor p in bp.patches:\n    height = p.get_height()\n    bp.text(p.get_x()+p.get_width()/2.,height+0.05, '{:1.2f}'.format(height),ha=\"center\") \n    \ntrain_df['Average_Fare'] = train_df.Fare/(train_df.SibSp+train_df.Parch+1)\ntest_df['Average_Fare'] = test_df.Fare/(test_df.SibSp+test_df.Parch+1)\n\n#Running the above plot for the AverageFare\nplt.subplots(figsize = (15,8))\nsns.set(style=\"darkgrid\")\nbp = sns.barplot(x = \"Family_Type\", y = \"Average_Fare\", data=train_df)\nplt.title(\"Average Fare vs Family type\", fontsize = 25)\nplt.ylabel(\"Avg Fare\", fontsize = 15)\nplt.xlabel(\"Family Type\",fontsize = 15)\nfor p in bp.patches:\n    height = p.get_height()\n    bp.text(p.get_x()+p.get_width()/2.,height+0.05, '{:1.2f}'.format(height),ha=\"center\") \n    \n    \n#checking box plot for Average Fares. Looks like Singles from 1st class paid higher fares.\nprint(\"Mean\", train_df.Average_Fare.mean())\nprint(\"Median\", train_df.Average_Fare.median())\nprint(\"Mode\",train_df.Average_Fare.mode())\nplt.subplots(figsize = (15,8))\nsns.boxplot(x='Family_Type',y='Average_Fare', data = train_df)\n\n#Define a function to identify Fare Group based on Fare\ndef fare_group_fun(fare):\n    fgroup = ''\n    if fare <=8:\n        fgroup = 'Low'\n    elif fare <=19:\n        fgroup = 'Medium'\n    elif fare <=50:\n        fgroup = 'High'\n    else:\n        fgroup = 'Exorbitant'\n    return fgroup\n\n#Setting the Age Group by calling the function\ntrain_df['Fare_Group']= (train_df['Average_Fare']).map(fare_group_fun)\ntest_df['Fare_Group']= (test_df['Average_Fare']).map(fare_group_fun)\n\ntrain_df = pd.get_dummies(train_df, columns=['Pclass','Embarked','Title', 'Family_Type','Age_Group', 'Fare_Group'], drop_first=True)\ntest_df = pd.get_dummies(test_df, columns=['Pclass','Embarked','Title', 'Family_Type','Age_Group', 'Fare_Group'], drop_first=True)\ntrain_df.drop(['Name','SibSp','Parch','Cabin','Ticket','Fare'], axis=1, inplace=True)\ntest_df.drop(['Name','SibSp','Parch','Cabin','Ticket','Fare'], axis=1, inplace=True)\n\ny = train_df['Survived']\ntrain_df_reg = train_df.drop('Survived', 1)\n\ntrain_df_reg = StandardScaler().fit_transform(train_df_reg)\ntest_df_reg = StandardScaler().fit_transform(test_df)\n\n\n#Splitting Train set into Train and Validate\nX_train, X_validate, y_train, y_validate = train_test_split(train_df_reg,y,test_size = 0.20, random_state = 1000)\n\nlogreg = LogisticRegression(solver='liblinear', penalty='l1')\nlogreg.fit(X_train,y_train)\npredict=logreg.predict(X_validate)\nprint(accuracy_score(y_validate,predict))\nprint(confusion_matrix(y_validate,predict))\nprint(precision_score(y_validate,predict))\nprint(recall_score(y_validate,predict))\n\ndectree = DecisionTreeClassifier( criterion=\"entropy\",\n                                 max_depth=5,\n                                class_weight = 'balanced',\n                                min_weight_fraction_leaf = 0.009,\n                                random_state=2000)\ndectree.fit(X_train, y_train)\npredict = dectree.predict(X_validate)\nprint(accuracy_score(y_validate, predict))\nprint(confusion_matrix(y_validate,predict))\nprint(precision_score(y_validate,predict))\nprint(recall_score(y_validate,predict))\n\n\nrandomforest = RandomForestClassifier(n_estimators=100,max_depth=5,min_samples_split=20,max_features=0.2, min_samples_leaf=8,random_state=20)\nrandomforest.fit(X_train, y_train)\npredict = randomforest.predict(X_validate)\nprint(accuracy_score(y_validate, predict))\nprint(confusion_matrix(y_validate,predict))\nprint(precision_score(y_validate,predict))\nprint(recall_score(y_validate,predict))\n\nxgb=XGBClassifier(max_depth=2, n_estimators=700, learning_rate=0.009,nthread=-1,subsample=1,colsample_bytree=0.8)\nxgb.fit(X_train,y_train)\npredict=logreg.predict(X_validate)\nprint(accuracy_score(y_validate,predict))\nprint(confusion_matrix(y_validate,predict))\nprint(precision_score(y_validate,predict))\nprint(recall_score(y_validate,predict))\n\nsvc=SVC(probability=True)\nsvc.fit(X_train,y_train)\npredict=logreg.predict(X_validate)\nprint(accuracy_score(y_validate,predict))\nprint(confusion_matrix(y_validate,predict))\nprint(precision_score(y_validate,predict))\nprint(recall_score(y_validate,predict))\n\nvoting_classifier = VotingClassifier(estimators=[\n    ('logreg',logreg), \n    ('decision_tree',dectree), \n    ('random_forest', randomforest),\n    ('XGB Classifier', xgb)])\nvoting_classifier.fit(X_train,y_train)\npredict = voting_classifier.predict(X_validate)\nprint(accuracy_score(y_validate,predict))\nprint(confusion_matrix(y_validate,predict))\nprint(precision_score(y_validate,predict))\nprint(recall_score(y_validate,predict))\n\ny_predict=dectree.predict(test_df_reg)\nprediction = pd.DataFrame(pd.DataFrame({\n        \"PassengerId\": passenger_id,\n        \"Survived\": y_predict\n    }))\n\nprediction.to_csv(\"Predictions.csv\", index = False)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}