{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Ensure that you have the following datasets added:\n\nIf performing inference (generating predictions):\ntil21r1cv\n\nIf training using TIL images (yolo format):\nnotebook27ee0a2e82\n\nIf training using open images (yolo format):\nopenimagestoyolov5\nopenimagestoyololabels","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5  # clone repo\n# !cp -r ../input/x6-resume-2/yolov5 /kaggle/working/ # if continuing on progress, do not clone repo # actually m6resume is x6resume (renamed x6resume as it contains progress from running x6)\n%cd /kaggle/working/yolov5\n!pip install -r requirements.txt  # install","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:27:20.302152Z","iopub.execute_input":"2021-06-22T03:27:20.302522Z","iopub.status.idle":"2021-06-22T03:27:26.688539Z","shell.execute_reply.started":"2021-06-22T03:27:20.302484Z","shell.execute_reply":"2021-06-22T03:27:26.687394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile /kaggle/working/yolov5/train.py\n\"\"\"Train a YOLOv5 model on a custom dataset\n\nUsage:\n    $ python path/to/train.py --data coco128.yaml --weights yolov5s.pt --img 640\n\"\"\"\n\nimport argparse\nimport logging\nimport math\nimport os\nimport random\nimport sys\nimport time\nimport warnings\nfrom copy import deepcopy\nfrom pathlib import Path\nfrom threading import Thread\n\nimport numpy as np\nimport torch.distributed as dist\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\nimport torch.utils.data\nimport yaml\nfrom torch.cuda import amp\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nfrom torch.utils.tensorboard import SummaryWriter\nfrom tqdm import tqdm\n\nFILE = Path(__file__).absolute()\nsys.path.append(FILE.parents[0].as_posix())  # add yolov5/ to path\n\nimport test  # for end-of-epoch mAP\nfrom models.experimental import attempt_load\nfrom models.yolo import Model\nfrom utils.autoanchor import check_anchors\nfrom utils.datasets import create_dataloader\nfrom utils.general import labels_to_class_weights, increment_path, labels_to_image_weights, init_seeds, \\\n    fitness, strip_optimizer, get_latest_run, check_dataset, check_file, check_git_status, check_img_size, \\\n    check_requirements, print_mutation, set_logging, one_cycle, colorstr\nfrom utils.google_utils import attempt_download\nfrom utils.loss import ComputeLoss\nfrom utils.plots import plot_images, plot_labels, plot_results, plot_evolution\nfrom utils.torch_utils import ModelEMA, select_device, intersect_dicts, torch_distributed_zero_first, de_parallel\nfrom utils.wandb_logging.wandb_utils import WandbLogger, check_wandb_resume\n\nlogger = logging.getLogger(__name__)\nLOCAL_RANK = int(os.getenv('LOCAL_RANK', -1))  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv('RANK', -1))\nWORLD_SIZE = int(os.getenv('WORLD_SIZE', 1))\n\n\ndef train(hyp,  # path/to/hyp.yaml or hyp dictionary\n          opt,\n          device,\n          ):\n    save_dir, epochs, batch_size, weights, single_cls, evolve, data, cfg, resume, notest, nosave, workers, = \\\n        opt.save_dir, opt.epochs, opt.batch_size, opt.weights, opt.single_cls, opt.evolve, opt.data, opt.cfg, \\\n        opt.resume, opt.notest, opt.nosave, opt.workers\n\n    # Directories\n    save_dir = Path(save_dir)\n    wdir = save_dir / 'weights'\n    wdir.mkdir(parents=True, exist_ok=True)  # make dir\n    last = wdir / 'last.pt'\n    best = wdir / 'best.pt'\n    results_file = save_dir / 'results.txt'\n\n    # Hyperparameters\n    if isinstance(hyp, str):\n        with open(hyp) as f:\n            hyp = yaml.safe_load(f)  # load hyps dict\n    logger.info(colorstr('hyperparameters: ') + ', '.join(f'{k}={v}' for k, v in hyp.items()))\n\n    # Save run settings\n    with open(save_dir / 'hyp.yaml', 'w') as f:\n        yaml.safe_dump(hyp, f, sort_keys=False)\n    with open(save_dir / 'opt.yaml', 'w') as f:\n        yaml.safe_dump(vars(opt), f, sort_keys=False)\n\n    # Configure\n    plots = not evolve  # create plots\n    cuda = device.type != 'cpu'\n    init_seeds(2 + RANK)\n    with open(data) as f:\n        data_dict = yaml.safe_load(f)  # data dict\n\n    # Loggers\n    loggers = {'wandb': None, 'tb': None}  # loggers dict\n    if RANK in [-1, 0]:\n        # TensorBoard\n        if not evolve:\n            prefix = colorstr('tensorboard: ')\n            logger.info(f\"{prefix}Start with 'tensorboard --logdir {opt.project}', view at http://localhost:6006/\")\n            loggers['tb'] = SummaryWriter(str(save_dir))\n\n        # W&B\n        opt.hyp = hyp  # add hyperparameters\n        run_id = torch.load(weights).get('wandb_id') if weights.endswith('.pt') and os.path.isfile(weights) else None\n        run_id = run_id if opt.resume else None  # start fresh run if transfer learning\n        wandb_logger = WandbLogger(opt, save_dir.stem, run_id, data_dict)\n        loggers['wandb'] = wandb_logger.wandb\n        if loggers['wandb']:\n            data_dict = wandb_logger.data_dict\n            weights, epochs, hyp = opt.weights, opt.epochs, opt.hyp  # may update weights, epochs if resuming\n\n    nc = 1 if single_cls else int(data_dict['nc'])  # number of classes\n    names = ['item'] if single_cls and len(data_dict['names']) != 1 else data_dict['names']  # class names\n    assert len(names) == nc, '%g names found for nc=%g dataset in %s' % (len(names), nc, data)  # check\n    is_coco = data.endswith('coco.yaml') and nc == 80  # COCO dataset\n\n    # Model\n    pretrained = weights.endswith('.pt')\n    if pretrained:\n        with torch_distributed_zero_first(RANK):\n            weights = attempt_download(weights)  # download if not found locally\n        ckpt = torch.load(weights, map_location=device)  # load checkpoint\n        model = Model(cfg or ckpt['model'].yaml, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create\n        exclude = ['anchor'] if (cfg or hyp.get('anchors')) and not resume else []  # exclude keys\n        state_dict = ckpt['model'].float().state_dict()  # to FP32\n        state_dict = intersect_dicts(state_dict, model.state_dict(), exclude=exclude)  # intersect\n        model.load_state_dict(state_dict, strict=False)  # load\n        logger.info('Transferred %g/%g items from %s' % (len(state_dict), len(model.state_dict()), weights))  # report\n    else:\n        model = Model(cfg, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create\n    with torch_distributed_zero_first(RANK):\n        check_dataset(data_dict)  # check\n    train_path = data_dict['train']\n    test_path = data_dict['val']\n\n    # Freeze\n    freeze = ['model.%s.' % x for x in range(10)]  # parameter names to freeze (full or partial)\n    for k, v in model.named_parameters():\n        v.requires_grad = True  # train all layers\n        if any(x in k for x in freeze):\n            print('freezing %s' % k)\n            v.requires_grad = False\n\n    # Optimizer\n    nbs = 64  # nominal batch size\n    accumulate = max(round(nbs / batch_size), 1)  # accumulate loss before optimizing\n    hyp['weight_decay'] *= batch_size * accumulate / nbs  # scale weight_decay\n    logger.info(f\"Scaled weight_decay = {hyp['weight_decay']}\")\n\n    pg0, pg1, pg2 = [], [], []  # optimizer parameter groups\n    for k, v in model.named_modules():\n        if hasattr(v, 'bias') and isinstance(v.bias, nn.Parameter):\n            pg2.append(v.bias)  # biases\n        if isinstance(v, nn.BatchNorm2d):\n            pg0.append(v.weight)  # no decay\n        elif hasattr(v, 'weight') and isinstance(v.weight, nn.Parameter):\n            pg1.append(v.weight)  # apply decay\n\n    if opt.adam:\n        optimizer = optim.Adam(pg0, lr=hyp['lr0'], betas=(hyp['momentum'], 0.999))  # adjust beta1 to momentum\n    else:\n        optimizer = optim.SGD(pg0, lr=hyp['lr0'], momentum=hyp['momentum'], nesterov=True)\n\n    optimizer.add_param_group({'params': pg1, 'weight_decay': hyp['weight_decay']})  # add pg1 with weight_decay\n    optimizer.add_param_group({'params': pg2})  # add pg2 (biases)\n    logger.info('Optimizer groups: %g .bias, %g conv.weight, %g other' % (len(pg2), len(pg1), len(pg0)))\n    del pg0, pg1, pg2\n\n    # Scheduler https://arxiv.org/pdf/1812.01187.pdf\n    # https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html#OneCycleLR\n    if opt.linear_lr:\n        lf = lambda x: (1 - x / (epochs - 1)) * (1.0 - hyp['lrf']) + hyp['lrf']  # linear\n    else:\n        lf = one_cycle(1, hyp['lrf'], epochs)  # cosine 1->hyp['lrf']\n    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n    # plot_lr_scheduler(optimizer, scheduler, epochs)\n\n    # EMA\n    ema = ModelEMA(model) if RANK in [-1, 0] else None\n\n    # Resume\n    start_epoch, best_fitness = 0, 0.0\n    if pretrained:\n        # Optimizer\n        if ckpt['optimizer'] is not None:\n            optimizer.load_state_dict(ckpt['optimizer'])\n            best_fitness = ckpt['best_fitness']\n\n        # EMA\n        if ema and ckpt.get('ema'):\n            ema.ema.load_state_dict(ckpt['ema'].float().state_dict())\n            ema.updates = ckpt['updates']\n\n        # Results\n        if ckpt.get('training_results') is not None:\n            results_file.write_text(ckpt['training_results'])  # write results.txt\n\n        # Epochs\n        start_epoch = ckpt['epoch'] + 1\n        if resume:\n            assert start_epoch > 0, '%s training to %g epochs is finished, nothing to resume.' % (weights, epochs)\n        if epochs < start_epoch:\n            logger.info('%s has been trained for %g epochs. Fine-tuning for %g additional epochs.' %\n                        (weights, ckpt['epoch'], epochs))\n            epochs += ckpt['epoch']  # finetune additional epochs\n\n        del ckpt, state_dict\n\n    # Image sizes\n    gs = max(int(model.stride.max()), 32)  # grid size (max stride)\n    nl = model.model[-1].nl  # number of detection layers (used for scaling hyp['obj'])\n    imgsz, imgsz_test = [check_img_size(x, gs) for x in opt.img_size]  # verify imgsz are gs-multiples\n\n    # DP mode\n    if cuda and RANK == -1 and torch.cuda.device_count() > 1:\n        logging.warning('DP not recommended, instead use torch.distributed.run for best DDP Multi-GPU results.\\n'\n                        'See Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.')\n        model = torch.nn.DataParallel(model)\n\n    # SyncBatchNorm\n    if opt.sync_bn and cuda and RANK != -1:\n        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model).to(device)\n        logger.info('Using SyncBatchNorm()')\n\n    # Trainloader\n    dataloader, dataset = create_dataloader(train_path, imgsz, batch_size // WORLD_SIZE, gs, single_cls,\n                                            hyp=hyp, augment=True, cache=opt.cache_images, rect=opt.rect, rank=RANK,\n                                            workers=workers,\n                                            image_weights=opt.image_weights, quad=opt.quad, prefix=colorstr('train: '))\n    mlc = np.concatenate(dataset.labels, 0)[:, 0].max()  # max label class\n    nb = len(dataloader)  # number of batches\n    assert mlc < nc, 'Label class %g exceeds nc=%g in %s. Possible class labels are 0-%g' % (mlc, nc, data, nc - 1)\n\n    # Process 0\n    if RANK in [-1, 0]:\n        testloader = create_dataloader(test_path, imgsz_test, batch_size // WORLD_SIZE * 2, gs, single_cls,\n                                       hyp=hyp, cache=opt.cache_images and not notest, rect=True, rank=-1,\n                                       workers=workers,\n                                       pad=0.5, prefix=colorstr('val: '))[0]\n\n        if not resume:\n            labels = np.concatenate(dataset.labels, 0)\n            c = torch.tensor(labels[:, 0])  # classes\n            # cf = torch.bincount(c.long(), minlength=nc) + 1.  # frequency\n            # model._initialize_biases(cf.to(device))\n            if plots:\n                plot_labels(labels, names, save_dir, loggers)\n                if loggers['tb']:\n                    loggers['tb'].add_histogram('classes', c, 0)  # TensorBoard\n\n            # Anchors\n            if not opt.noautoanchor:\n                check_anchors(dataset, model=model, thr=hyp['anchor_t'], imgsz=imgsz)\n            model.half().float()  # pre-reduce anchor precision\n\n    # DDP mode\n    if cuda and RANK != -1:\n        model = DDP(model, device_ids=[LOCAL_RANK], output_device=LOCAL_RANK,\n                    # nn.MultiheadAttention incompatibility with DDP https://github.com/pytorch/pytorch/issues/26698\n                    find_unused_parameters=any(isinstance(layer, nn.MultiheadAttention) for layer in model.modules()))\n\n    # Model parameters\n    hyp['box'] *= 3. / nl  # scale to layers\n    hyp['cls'] *= nc / 80. * 3. / nl  # scale to classes and layers\n    hyp['obj'] *= (imgsz / 640) ** 2 * 3. / nl  # scale to image size and layers\n    hyp['label_smoothing'] = opt.label_smoothing\n    model.nc = nc  # attach number of classes to model\n    model.hyp = hyp  # attach hyperparameters to model\n    model.gr = 1.0  # iou loss ratio (obj_loss = 1.0 or iou)\n    model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device) * nc  # attach class weights\n    model.names = names\n\n    # Start training\n    t0 = time.time()\n    nw = max(round(hyp['warmup_epochs'] * nb), 1000)  # number of warmup iterations, max(3 epochs, 1k iterations)\n    # nw = min(nw, (epochs - start_epoch) / 2 * nb)  # limit warmup to < 1/2 of training\n    maps = np.zeros(nc)  # mAP per class\n    results = (0, 0, 0, 0, 0, 0, 0)  # P, R, mAP@.5, mAP@.5-.95, val_loss(box, obj, cls)\n    scheduler.last_epoch = start_epoch - 1  # do not move\n    scaler = amp.GradScaler(enabled=cuda)\n    compute_loss = ComputeLoss(model)  # init loss class\n    logger.info(f'Image sizes {imgsz} train, {imgsz_test} test\\n'\n                f'Using {dataloader.num_workers} dataloader workers\\n'\n                f'Logging results to {save_dir}\\n'\n                f'Starting training for {epochs} epochs...')\n    for epoch in range(start_epoch, epochs):  # epoch ------------------------------------------------------------------\n        model.train()\n\n        # Update image weights (optional)\n        if opt.image_weights:\n            # Generate indices\n            if RANK in [-1, 0]:\n                cw = model.class_weights.cpu().numpy() * (1 - maps) ** 2 / nc  # class weights\n                iw = labels_to_image_weights(dataset.labels, nc=nc, class_weights=cw)  # image weights\n                dataset.indices = random.choices(range(dataset.n), weights=iw, k=dataset.n)  # rand weighted idx\n            # Broadcast if DDP\n            if RANK != -1:\n                indices = (torch.tensor(dataset.indices) if RANK == 0 else torch.zeros(dataset.n)).int()\n                dist.broadcast(indices, 0)\n                if RANK != 0:\n                    dataset.indices = indices.cpu().numpy()\n\n        # Update mosaic border\n        # b = int(random.uniform(0.25 * imgsz, 0.75 * imgsz + gs) // gs * gs)\n        # dataset.mosaic_border = [b - imgsz, -b]  # height, width borders\n\n        mloss = torch.zeros(4, device=device)  # mean losses\n        if RANK != -1:\n            dataloader.sampler.set_epoch(epoch)\n        pbar = enumerate(dataloader)\n        logger.info(('\\n' + '%10s' * 8) % ('Epoch', 'gpu_mem', 'box', 'obj', 'cls', 'total', 'labels', 'img_size'))\n        if RANK in [-1, 0]:\n            pbar = tqdm(pbar, total=nb)  # progress bar\n        optimizer.zero_grad()\n        for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n            ni = i + nb * epoch  # number integrated batches (since train start)\n            imgs = imgs.to(device, non_blocking=True).float() / 255.0  # uint8 to float32, 0-255 to 0.0-1.0\n\n            # Warmup\n            if ni <= nw:\n                xi = [0, nw]  # x interp\n                # model.gr = np.interp(ni, xi, [0.0, 1.0])  # iou loss ratio (obj_loss = 1.0 or iou)\n                accumulate = max(1, np.interp(ni, xi, [1, nbs / batch_size]).round())\n                for j, x in enumerate(optimizer.param_groups):\n                    # bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0\n                    x['lr'] = np.interp(ni, xi, [hyp['warmup_bias_lr'] if j == 2 else 0.0, x['initial_lr'] * lf(epoch)])\n                    if 'momentum' in x:\n                        x['momentum'] = np.interp(ni, xi, [hyp['warmup_momentum'], hyp['momentum']])\n\n            # Multi-scale\n            if opt.multi_scale:\n                sz = random.randrange(imgsz * 0.5, imgsz * 1.5 + gs) // gs * gs  # size\n                sf = sz / max(imgs.shape[2:])  # scale factor\n                if sf != 1:\n                    ns = [math.ceil(x * sf / gs) * gs for x in imgs.shape[2:]]  # new shape (stretched to gs-multiple)\n                    imgs = F.interpolate(imgs, size=ns, mode='bilinear', align_corners=False)\n\n            # Forward\n            with amp.autocast(enabled=cuda):\n                pred = model(imgs)  # forward\n                loss, loss_items = compute_loss(pred, targets.to(device))  # loss scaled by batch_size\n                if RANK != -1:\n                    loss *= WORLD_SIZE  # gradient averaged between devices in DDP mode\n                if opt.quad:\n                    loss *= 4.\n\n            # Backward\n            scaler.scale(loss).backward()\n\n            # Optimize\n            if ni % accumulate == 0:\n                scaler.step(optimizer)  # optimizer.step\n                scaler.update()\n                optimizer.zero_grad()\n                if ema:\n                    ema.update(model)\n\n            # Print\n            if RANK in [-1, 0]:\n                mloss = (mloss * i + loss_items) / (i + 1)  # update mean losses\n                mem = '%.3gG' % (torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0)  # (GB)\n                s = ('%10s' * 2 + '%10.4g' * 6) % (\n                    f'{epoch}/{epochs - 1}', mem, *mloss, targets.shape[0], imgs.shape[-1])\n                pbar.set_description(s)\n\n                # Plot\n                if plots and ni < 3:\n                    f = save_dir / f'train_batch{ni}.jpg'  # filename\n                    Thread(target=plot_images, args=(imgs, targets, paths, f), daemon=True).start()\n                    if loggers['tb'] and ni == 0:  # TensorBoard\n                        with warnings.catch_warnings():\n                            warnings.simplefilter('ignore')  # suppress jit trace warning\n                            loggers['tb'].add_graph(torch.jit.trace(de_parallel(model), imgs[0:1], strict=False), [])\n                elif plots and ni == 10 and loggers['wandb']:\n                    wandb_logger.log({'Mosaics': [loggers['wandb'].Image(str(x), caption=x.name) for x in\n                                                  save_dir.glob('train*.jpg') if x.exists()]})\n\n            # end batch ------------------------------------------------------------------------------------------------\n\n        # Scheduler\n        lr = [x['lr'] for x in optimizer.param_groups]  # for loggers\n        scheduler.step()\n\n        # DDP process 0 or single-GPU\n        if RANK in [-1, 0]:\n            # mAP\n            ema.update_attr(model, include=['yaml', 'nc', 'hyp', 'gr', 'names', 'stride', 'class_weights'])\n            final_epoch = epoch + 1 == epochs\n            if not notest or final_epoch:  # Calculate mAP\n                wandb_logger.current_epoch = epoch + 1\n                results, maps, _ = test.run(data_dict,\n                                            batch_size=batch_size // WORLD_SIZE * 2,\n                                            imgsz=imgsz_test,\n                                            model=ema.ema,\n                                            single_cls=single_cls,\n                                            dataloader=testloader,\n                                            save_dir=save_dir,\n                                            save_json=is_coco and final_epoch,\n                                            verbose=nc < 50 and final_epoch,\n                                            plots=plots and final_epoch,\n                                            wandb_logger=wandb_logger,\n                                            compute_loss=compute_loss)\n\n            # Write\n            with open(results_file, 'a') as f:\n                f.write(s + '%10.4g' * 7 % results + '\\n')  # append metrics, val_loss\n\n            # Log\n            tags = ['train/box_loss', 'train/obj_loss', 'train/cls_loss',  # train loss\n                    'metrics/precision', 'metrics/recall', 'metrics/mAP_0.5', 'metrics/mAP_0.5:0.95',\n                    'val/box_loss', 'val/obj_loss', 'val/cls_loss',  # val loss\n                    'x/lr0', 'x/lr1', 'x/lr2']  # params\n            for x, tag in zip(list(mloss[:-1]) + list(results) + lr, tags):\n                if loggers['tb']:\n                    loggers['tb'].add_scalar(tag, x, epoch)  # TensorBoard\n                if loggers['wandb']:\n                    wandb_logger.log({tag: x})  # W&B\n\n            # Update best mAP\n            fi = fitness(np.array(results).reshape(1, -1))  # weighted combination of [P, R, mAP@.5, mAP@.5-.95]\n            if fi > best_fitness:\n                best_fitness = fi\n            wandb_logger.end_epoch(best_result=best_fitness == fi)\n\n            # Save model\n            if (not nosave) or (final_epoch and not evolve):  # if save\n                ckpt = {'epoch': epoch,\n                        'best_fitness': best_fitness,\n                        'training_results': results_file.read_text(),\n                        'model': deepcopy(de_parallel(model)).half(),\n                        'ema': deepcopy(ema.ema).half(),\n                        'updates': ema.updates,\n                        'optimizer': optimizer.state_dict(),\n                        'wandb_id': wandb_logger.wandb_run.id if loggers['wandb'] else None}\n\n                # Save last, best and delete\n                torch.save(ckpt, last)\n                if best_fitness == fi:\n                    torch.save(ckpt, best)\n                if loggers['wandb']:\n                    if ((epoch + 1) % opt.save_period == 0 and not final_epoch) and opt.save_period != -1:\n                        wandb_logger.log_model(last.parent, opt, epoch, fi, best_model=best_fitness == fi)\n                del ckpt\n\n        # end epoch ----------------------------------------------------------------------------------------------------\n    # end training -----------------------------------------------------------------------------------------------------\n    if RANK in [-1, 0]:\n        logger.info(f'{epoch - start_epoch + 1} epochs completed in {(time.time() - t0) / 3600:.3f} hours.\\n')\n        if plots:\n            plot_results(save_dir=save_dir)  # save as results.png\n            if loggers['wandb']:\n                files = ['results.png', 'confusion_matrix.png', *[f'{x}_curve.png' for x in ('F1', 'PR', 'P', 'R')]]\n                wandb_logger.log({\"Results\": [loggers['wandb'].Image(str(save_dir / f), caption=f) for f in files\n                                              if (save_dir / f).exists()]})\n\n        if not evolve:\n            if is_coco:  # COCO dataset\n                for m in [last, best] if best.exists() else [last]:  # speed, mAP tests\n                    results, _, _ = test.run(data,\n                                             batch_size=batch_size // WORLD_SIZE * 2,\n                                             imgsz=imgsz_test,\n                                             conf_thres=0.001,\n                                             iou_thres=0.7,\n                                             model=attempt_load(m, device).half(),\n                                             single_cls=single_cls,\n                                             dataloader=testloader,\n                                             save_dir=save_dir,\n                                             save_json=True,\n                                             plots=False)\n\n            # Strip optimizers\n            for f in last, best:\n                if f.exists():\n                    strip_optimizer(f)  # strip optimizers\n            if loggers['wandb']:  # Log the stripped model\n                loggers['wandb'].log_artifact(str(best if best.exists() else last), type='model',\n                                              name='run_' + wandb_logger.wandb_run.id + '_model',\n                                              aliases=['latest', 'best', 'stripped'])\n        wandb_logger.finish_run()\n\n    torch.cuda.empty_cache()\n    return results\n\n\ndef parse_opt(known=False):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--weights', type=str, default='yolov5s.pt', help='initial weights path')\n    parser.add_argument('--cfg', type=str, default='', help='model.yaml path')\n    parser.add_argument('--data', type=str, default='data/coco128.yaml', help='dataset.yaml path')\n    parser.add_argument('--hyp', type=str, default='data/hyp.scratch.yaml', help='hyperparameters path')\n    parser.add_argument('--epochs', type=int, default=300)\n    parser.add_argument('--batch-size', type=int, default=16, help='total batch size for all GPUs')\n    parser.add_argument('--img-size', nargs='+', type=int, default=[640, 640], help='[train, test] image sizes')\n    parser.add_argument('--rect', action='store_true', help='rectangular training')\n    parser.add_argument('--resume', nargs='?', const=True, default=False, help='resume most recent training')\n    parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')\n    parser.add_argument('--notest', action='store_true', help='only test final epoch')\n    parser.add_argument('--noautoanchor', action='store_true', help='disable autoanchor check')\n    parser.add_argument('--evolve', action='store_true', help='evolve hyperparameters')\n    parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')\n    parser.add_argument('--cache-images', action='store_true', help='cache images for faster training')\n    parser.add_argument('--image-weights', action='store_true', help='use weighted image selection for training')\n    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n    parser.add_argument('--multi-scale', action='store_true', help='vary img-size +/- 50%%')\n    parser.add_argument('--single-cls', action='store_true', help='train multi-class data as single-class')\n    parser.add_argument('--adam', action='store_true', help='use torch.optim.Adam() optimizer')\n    parser.add_argument('--sync-bn', action='store_true', help='use SyncBatchNorm, only available in DDP mode')\n    parser.add_argument('--workers', type=int, default=8, help='maximum number of dataloader workers')\n    parser.add_argument('--project', default='runs/train', help='save to project/name')\n    parser.add_argument('--entity', default=None, help='W&B entity')\n    parser.add_argument('--name', default='exp', help='save to project/name')\n    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n    parser.add_argument('--quad', action='store_true', help='quad dataloader')\n    parser.add_argument('--linear-lr', action='store_true', help='linear LR')\n    parser.add_argument('--label-smoothing', type=float, default=0.0, help='Label smoothing epsilon')\n    parser.add_argument('--upload_dataset', action='store_true', help='Upload dataset as W&B artifact table')\n    parser.add_argument('--bbox_interval', type=int, default=-1, help='Set bounding-box image logging interval for W&B')\n    parser.add_argument('--save_period', type=int, default=-1, help='Log model after every \"save_period\" epoch')\n    parser.add_argument('--artifact_alias', type=str, default=\"latest\", help='version of dataset artifact to be used')\n    parser.add_argument('--local_rank', type=int, default=-1, help='DDP parameter, do not modify')\n    opt = parser.parse_known_args()[0] if known else parser.parse_args()\n    return opt\n\n\ndef main(opt):\n    set_logging(RANK)\n    if RANK in [-1, 0]:\n        print(colorstr('train: ') + ', '.join(f'{k}={v}' for k, v in vars(opt).items()))\n        check_git_status()\n        check_requirements(exclude=['thop'])\n\n    # Resume\n    wandb_run = check_wandb_resume(opt)\n    if opt.resume and not wandb_run:  # resume an interrupted run\n        ckpt = opt.resume if isinstance(opt.resume, str) else get_latest_run()  # specified or most recent path\n        assert os.path.isfile(ckpt), 'ERROR: --resume checkpoint does not exist'\n        with open(Path(ckpt).parent.parent / 'opt.yaml') as f:\n            opt = argparse.Namespace(**yaml.safe_load(f))  # replace\n        opt.cfg, opt.weights, opt.resume = '', ckpt, True  # reinstate\n        logger.info('Resuming training from %s' % ckpt)\n    else:\n        # opt.hyp = opt.hyp or ('hyp.finetune.yaml' if opt.weights else 'hyp.scratch.yaml')\n        opt.data, opt.cfg, opt.hyp = check_file(opt.data), check_file(opt.cfg), check_file(opt.hyp)  # check files\n        assert len(opt.cfg) or len(opt.weights), 'either --cfg or --weights must be specified'\n        opt.img_size.extend([opt.img_size[-1]] * (2 - len(opt.img_size)))  # extend to 2 sizes (train, test)\n        opt.name = 'evolve' if opt.evolve else opt.name\n        opt.save_dir = str(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok | opt.evolve))\n\n    # DDP mode\n    device = select_device(opt.device, batch_size=opt.batch_size)\n    if LOCAL_RANK != -1:\n        from datetime import timedelta\n        assert torch.cuda.device_count() > LOCAL_RANK, 'insufficient CUDA devices for DDP command'\n        torch.cuda.set_device(LOCAL_RANK)\n        device = torch.device('cuda', LOCAL_RANK)\n        dist.init_process_group(backend=\"nccl\" if dist.is_nccl_available() else \"gloo\", timeout=timedelta(seconds=60))\n        assert opt.batch_size % WORLD_SIZE == 0, '--batch-size must be multiple of CUDA device count'\n        assert not opt.image_weights, '--image-weights argument is not compatible with DDP training'\n\n    # Train\n    if not opt.evolve:\n        train(opt.hyp, opt, device)\n        if WORLD_SIZE > 1 and RANK == 0:\n            _ = [print('Destroying process group... ', end=''), dist.destroy_process_group(), print('Done.')]\n\n    # Evolve hyperparameters (optional)\n    else:\n        # Hyperparameter evolution metadata (mutation scale 0-1, lower_limit, upper_limit)\n        meta = {'lr0': (1, 1e-5, 1e-1),  # initial learning rate (SGD=1E-2, Adam=1E-3)\n                'lrf': (1, 0.01, 1.0),  # final OneCycleLR learning rate (lr0 * lrf)\n                'momentum': (0.3, 0.6, 0.98),  # SGD momentum/Adam beta1\n                'weight_decay': (1, 0.0, 0.001),  # optimizer weight decay\n                'warmup_epochs': (1, 0.0, 5.0),  # warmup epochs (fractions ok)\n                'warmup_momentum': (1, 0.0, 0.95),  # warmup initial momentum\n                'warmup_bias_lr': (1, 0.0, 0.2),  # warmup initial bias lr\n                'box': (1, 0.02, 0.2),  # box loss gain\n                'cls': (1, 0.2, 4.0),  # cls loss gain\n                'cls_pw': (1, 0.5, 2.0),  # cls BCELoss positive_weight\n                'obj': (1, 0.2, 4.0),  # obj loss gain (scale with pixels)\n                'obj_pw': (1, 0.5, 2.0),  # obj BCELoss positive_weight\n                'iou_t': (0, 0.1, 0.7),  # IoU training threshold\n                'anchor_t': (1, 2.0, 8.0),  # anchor-multiple threshold\n                'anchors': (2, 2.0, 10.0),  # anchors per output grid (0 to ignore)\n                'fl_gamma': (0, 0.0, 2.0),  # focal loss gamma (efficientDet default gamma=1.5)\n                'hsv_h': (1, 0.0, 0.1),  # image HSV-Hue augmentation (fraction)\n                'hsv_s': (1, 0.0, 0.9),  # image HSV-Saturation augmentation (fraction)\n                'hsv_v': (1, 0.0, 0.9),  # image HSV-Value augmentation (fraction)\n                'degrees': (1, 0.0, 45.0),  # image rotation (+/- deg)\n                'translate': (1, 0.0, 0.9),  # image translation (+/- fraction)\n                'scale': (1, 0.0, 0.9),  # image scale (+/- gain)\n                'shear': (1, 0.0, 10.0),  # image shear (+/- deg)\n                'perspective': (0, 0.0, 0.001),  # image perspective (+/- fraction), range 0-0.001\n                'flipud': (1, 0.0, 1.0),  # image flip up-down (probability)\n                'fliplr': (0, 0.0, 1.0),  # image flip left-right (probability)\n                'mosaic': (1, 0.0, 1.0),  # image mixup (probability)\n                'mixup': (1, 0.0, 1.0)}  # image mixup (probability)\n\n        with open(opt.hyp) as f:\n            hyp = yaml.safe_load(f)  # load hyps dict\n        assert LOCAL_RANK == -1, 'DDP mode not implemented for --evolve'\n        opt.notest, opt.nosave = True, True  # only test/save final epoch\n        # ei = [isinstance(x, (int, float)) for x in hyp.values()]  # evolvable indices\n        yaml_file = Path(opt.save_dir) / 'hyp_evolved.yaml'  # save best result here\n        if opt.bucket:\n            os.system('gsutil cp gs://%s/evolve.txt .' % opt.bucket)  # download evolve.txt if exists\n\n        for _ in range(300):  # generations to evolve\n            if Path('evolve.txt').exists():  # if evolve.txt exists: select best hyps and mutate\n                # Select parent(s)\n                parent = 'single'  # parent selection method: 'single' or 'weighted'\n                x = np.loadtxt('evolve.txt', ndmin=2)\n                n = min(5, len(x))  # number of previous results to consider\n                x = x[np.argsort(-fitness(x))][:n]  # top n mutations\n                w = fitness(x) - fitness(x).min()  # weights\n                if parent == 'single' or len(x) == 1:\n                    # x = x[random.randint(0, n - 1)]  # random selection\n                    x = x[random.choices(range(n), weights=w)[0]]  # weighted selection\n                elif parent == 'weighted':\n                    x = (x * w.reshape(n, 1)).sum(0) / w.sum()  # weighted combination\n\n                # Mutate\n                mp, s = 0.8, 0.2  # mutation probability, sigma\n                npr = np.random\n                npr.seed(int(time.time()))\n                g = np.array([x[0] for x in meta.values()])  # gains 0-1\n                ng = len(meta)\n                v = np.ones(ng)\n                while all(v == 1):  # mutate until a change occurs (prevent duplicates)\n                    v = (g * (npr.random(ng) < mp) * npr.randn(ng) * npr.random() * s + 1).clip(0.3, 3.0)\n                for i, k in enumerate(hyp.keys()):  # plt.hist(v.ravel(), 300)\n                    hyp[k] = float(x[i + 7] * v[i])  # mutate\n\n            # Constrain to limits\n            for k, v in meta.items():\n                hyp[k] = max(hyp[k], v[1])  # lower limit\n                hyp[k] = min(hyp[k], v[2])  # upper limit\n                hyp[k] = round(hyp[k], 5)  # significant digits\n\n            # Train mutation\n            results = train(hyp.copy(), opt, device)\n\n            # Write mutation results\n            print_mutation(hyp.copy(), results, yaml_file, opt.bucket)\n\n        # Plot results\n        plot_evolution(yaml_file)\n        print(f'Hyperparameter evolution complete. Best results saved as: {yaml_file}\\n'\n              f'Command to train a new model with these hyperparameters: $ python train.py --hyp {yaml_file}')\n\n\ndef run(**kwargs):\n    # Usage: import train; train.run(imgsz=320, weights='yolov5m.pt')\n    opt = parse_opt(True)\n    for k, v in kwargs.items():\n        setattr(opt, k, v)\n    main(opt)\n\n\nif __name__ == \"__main__\":\n    opt = parse_opt()\n    main(opt)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-22T03:27:26.690836Z","iopub.execute_input":"2021-06-22T03:27:26.691091Z","iopub.status.idle":"2021-06-22T03:27:26.708835Z","shell.execute_reply.started":"2021-06-22T03:27:26.691065Z","shell.execute_reply":"2021-06-22T03:27:26.707208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Uncomment if training til YOLO version images:\n!ln -s /kaggle/input/qwertyuiop-ch3-yolo /kaggle/working/data # Soft link the folder containing train ","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:27:26.710789Z","iopub.execute_input":"2021-06-22T03:27:26.711885Z","iopub.status.idle":"2021-06-22T03:27:27.468838Z","shell.execute_reply.started":"2021-06-22T03:27:26.711292Z","shell.execute_reply":"2021-06-22T03:27:27.467919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !ls /kaggle/input/98jj9ynki87tfvbjiuytr56yhgfty/images/train/ | wc -l\n# !ls /kaggle/input/98jj9ynki87tfvbjiuytr56yhgfty/images/val/ | wc -l\n# !ls /kaggle/input/098uhnkiu789o2k3ejrifiuo3-labels/train/ | wc -l\n# !ls /kaggle/input/098uhnkiu789o2k3ejrifiuo3-labels/val/ | wc -l\n# !ls /kaggle/input/098uhnkiu789o2k3ejrifiuo3-labels/test/ | wc -l","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:27:27.472137Z","iopub.execute_input":"2021-06-22T03:27:27.472393Z","iopub.status.idle":"2021-06-22T03:27:27.476085Z","shell.execute_reply.started":"2021-06-22T03:27:27.472365Z","shell.execute_reply":"2021-06-22T03:27:27.474976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !rm -r /kaggle/working/data","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:27:27.477572Z","iopub.execute_input":"2021-06-22T03:27:27.478176Z","iopub.status.idle":"2021-06-22T03:27:27.486249Z","shell.execute_reply.started":"2021-06-22T03:27:27.478138Z","shell.execute_reply":"2021-06-22T03:27:27.485237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ## Uncomment if training openimages:\n# !mkdir -p /kaggle/working/data/labels\n# !mkdir -p /kaggle/working/data/images\n# for split in ['train','val','test']:\n# # for split in ['val','test']:\n#     !ln -s /kaggle/input/098uhnkiu789o2k3ejrifiuo3-labels/{split} /kaggle/working/data/labels/\n#     !ln -s /kaggle/input/098uhnkiu789o2k3ejrifiuo3-images/{split} /kaggle/working/data/images/","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-22T03:27:27.487668Z","iopub.execute_input":"2021-06-22T03:27:27.488138Z","iopub.status.idle":"2021-06-22T03:27:27.496947Z","shell.execute_reply.started":"2021-06-22T03:27:27.488101Z","shell.execute_reply":"2021-06-22T03:27:27.496048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile /kaggle/working/yolov5/coco.yaml\ntrain: /kaggle/working/data/images/train/\nval: /kaggle/working/data/images/val/\n\n# number of classes\nnc: 8\n\n# class names\nnames: ['background', 'cat','dog', \"bird\", \"chicken\", \"snake\", 'elephant', 'dinosaur']","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:27:27.498372Z","iopub.execute_input":"2021-06-22T03:27:27.498817Z","iopub.status.idle":"2021-06-22T03:27:27.508501Z","shell.execute_reply.started":"2021-06-22T03:27:27.498778Z","shell.execute_reply":"2021-06-22T03:27:27.507546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from utils.general import strip_optimizer\nstrip_optimizer(f='/kaggle/input/x6-resume-2/yolov5/runs/train/exp/weights/best.pt', s='/kaggle/working/yolov5/strippedyolov5x6.pt') # f is latest weight, s is stripped version of f","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:27:27.512082Z","iopub.execute_input":"2021-06-22T03:27:27.512403Z","iopub.status.idle":"2021-06-22T03:27:29.163098Z","shell.execute_reply.started":"2021-06-22T03:27:27.512367Z","shell.execute_reply":"2021-06-22T03:27:29.162075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install wandb\nimport wandb\nwandb.login(key=\"5f73d65df29ceb8cfb3624fbb5bc5f3114eccf1c\") # Use your own key","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:27:29.164908Z","iopub.execute_input":"2021-06-22T03:27:29.165423Z","iopub.status.idle":"2021-06-22T03:27:34.987622Z","shell.execute_reply.started":"2021-06-22T03:27:29.165384Z","shell.execute_reply":"2021-06-22T03:27:34.986743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !ls /kaggle/working/data/images/val","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:27:34.98918Z","iopub.execute_input":"2021-06-22T03:27:34.98954Z","iopub.status.idle":"2021-06-22T03:27:34.994921Z","shell.execute_reply.started":"2021-06-22T03:27:34.989498Z","shell.execute_reply":"2021-06-22T03:27:34.992878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !cat /kaggle/working/yolov5/coco.yaml","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:27:34.996359Z","iopub.execute_input":"2021-06-22T03:27:34.996868Z","iopub.status.idle":"2021-06-22T03:27:35.004536Z","shell.execute_reply.started":"2021-06-22T03:27:34.996831Z","shell.execute_reply":"2021-06-22T03:27:35.003701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %cd /kaggle/working/yolov5\n# Set the desired parameters # yolov5m 10 epochs in 50min # yolov5m6 2 epochs in 11 min 50 in 4h\n!python /kaggle/working/yolov5/train.py --img 640 --batch 48 --epochs 30 --data /kaggle/working/yolov5/coco.yaml --weights /kaggle/working/yolov5/strippedyolov5x6.pt --workers 4 --device 0 # run this to start (weights is stripped)\n# !python /kaggle/working/yolov5/train.py --img 640 --batch 16 --epochs 15 --data /kaggle/working/yolov5/coco.yaml --weights /kaggle/input/yolotilv1train/yolov5/runs/train/exp/weights/best.pt --workers 4 # run this to continue","metadata":{"execution":{"iopub.status.busy":"2021-06-22T03:27:35.005812Z","iopub.execute_input":"2021-06-22T03:27:35.006413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %cd /kaggle/working/yolov5\n# !python /kaggle/working/yolov5/train.py --resume","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Post training. Predictions","metadata":{}},{"cell_type":"code","source":"# !ln -s /kaggle/input/98jj9ynki87tfvbjiuytr56yhgfty /kaggle/working/data # Soft link the folder containing train ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python detect.py --weights /kaggle/working/yolov5/runs/train/exp/weights/best.pt --img 832 --source /kaggle/input/qwertyuiop-ch3-yolo/images --augment --save-txt --save-conf --half\n!ls /kaggle/working/yolov5/runs/detect/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/working/yolov5/runs/detect/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working\n!pip install imagesize\nimport imagesize\nimport json\nimport os\nlabels_dir=\"/kaggle/working/yolov5/runs/detect/exp/labels/\" # Change the exp4 to the exp directory\noutput_file_name='challenge_1_team_TeamP.json'\nfiles=os.listdir(labels_dir)\ndetections=[]\nfor filename in files:\n    with open(labels_dir+filename,'r') as f:\n        iw,ih=imagesize.get(f'/kaggle/input/qwertyuiop-ch3/challenge_3_test_dataset/images{filename[:-3]}jpg')\n        for line in f.readlines():\n            label,x,y,w,h,score=map(float,line.split())\n            x1,y1,w,h=map(int,[(x-w/2)*iw,(y-h/2)*ih,w*iw,h*ih])\n            detections.append({\"image_id\":int(filename[:-4]),\"category_id\":int(label),\"bbox\":[x1,y1,w,h],'score':score})\nwith open(output_file_name, 'w') as f:\n    json.dump(detections, f)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check submission file format and visualise preds","metadata":{}},{"cell_type":"code","source":"detections","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run once.\n!pip install pycocotools\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\ntil_test_root=\"/kaggle/input/qwertyuiop-ch3/challenge_3_test_dataset\"\nsample_json_path = os.path.join(til_test_root, \"c3_test_sample.json\")\ncoco_gt = COCO(sample_json_path)\ncoco_dt = coco_gt.loadRes(output_file_name)\ncocoEval = COCOeval(cocoGt=coco_gt, cocoDt=coco_dt, iouType='bbox')\ncocoEval.evaluate()\ncocoEval.accumulate()\ncocoEval.summarize()\n\nimport random\nfrom PIL import Image, ImageDraw\nfrom IPython.display import display\nfrom pycocotools.coco import COCO\nclass DisplayPreds():\n    def __init__(self,anno_file=\"/kaggle/input/qwertyuiop-ch3/challenge_3_training_dataset/train.json\", thickness=2):\n        coco = COCO(anno_file)\n        self.categories={}\n        for _ in coco.loadCats(coco.getCatIds()):\n            self.categories[_['id']]=_['name']\n        distinct_colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n                   for i in range(len(self.categories))]\n        self.label_color_map  = {k: distinct_colors[i] for i, k in enumerate(self.categories.keys())} \n    \n    def visualize_bbox(self, image, preds,keep_idx,det_threshold):\n        draw = ImageDraw.Draw(image)\n        if len(keep_idx)==0:\n            keep_idx=range(len(preds))\n        for idx in keep_idx:\n            pred=preds[idx]\n            if pred['scores']>det_threshold:\n                id=int(pred['labels'])\n                text=f'{self.categories[id]}: {pred[\"scores\"]}'\n                box=pred['boxes']\n                draw.rectangle(xy=box, outline=self.label_color_map[id])\n                draw.text((box[0]+5, box[1]+5), text)\n        display(image)\n\n    def __call__(self, filename, preds, keep_idx=[],det_threshold = 0.5):\n        image = Image.open(filename, mode='r')\n        self.visualize_bbox(image.copy(), preds=preds, keep_idx=keep_idx, det_threshold=det_threshold)\nd=DisplayPreds()\nfilesit=iter(files)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Just keep running this and the image will change\nfilename=next(filesit)\nwith open(labels_dir+filename,'r') as f:\n    iw,ih=imagesize.get(f'/kaggle/input/qwertyuiop-ch3/challenge_3_test_dataset/images/{filename[:-3]}jpg')\n    dt=[]\n    for line in f.readlines():\n        label,x,y,w,h,score=map(float,line.split())\n        x1,y1,w,h=map(int,[(x-w/2)*iw,(y-h/2)*ih,(x+w/2)*iw,(y+h/2)*ih])\n        dt.append({\"image_id\":int(filename[:-4]),\"labels\":int(label),\"boxes\":[x1,y1,w,h],'scores':score})\n    d(f\"/kaggle/input/qwertyuiop-ch3/challenge_3_test_dataset/images/{filename[:-3]}jpg\",dt,det_threshold=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}