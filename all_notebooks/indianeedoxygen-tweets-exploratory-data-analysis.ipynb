{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://pbs.twimg.com/media/Ezx0LvZUcAQ6nuH.jpg)","metadata":{}},{"cell_type":"markdown","source":"## Installing Necessary Packages","metadata":{}},{"cell_type":"code","source":"!pip -q install bs4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Libraries Import","metadata":{}},{"cell_type":"code","source":"import re\nimport spacy\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom bs4 import BeautifulSoup\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom textblob import TextBlob\nfrom textblob.sentiments import NaiveBayesAnalyzer\nfrom spacy.lang.en.stop_words import STOP_WORDS as stopwords\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('ggplot')","metadata":{"id":"sQnK28g1Cj89","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reading The Data & Preparing It","metadata":{}},{"cell_type":"code","source":"#converting into standard datetime format\ndataset = pd.read_csv('../input/indianeedsoxygen-tweets/IndiaWantsOxygen.csv', engine='python')\nfrom dateutil import parser\ndataset['Date'] = pd.to_datetime(dataset['date']).dt.date\ndataset['Date'] = dataset['Date'].apply(lambda x : parser.parse(str(x)))\ndataset['Date'] = pd.to_datetime(dataset['Date']).dt.date\ndataset['Time'] = pd.to_datetime(dataset['date']).dt.time\ndataset['Time'] = dataset['Time'].apply(lambda x : parser.parse(str(x)))\ndataset.drop(['date'], axis=1, inplace=True)\ndataset.head(5)","metadata":{"id":"BdnDfmoKCx_x","outputId":"3b6e72e9-c188-46cc-80f8-d82c077571f3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Number of Tweets Each Day","metadata":{}},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = [10,6]\nplt.rcParams['figure.dpi'] = 90\n\nsns.set(style='darkgrid')\ndates = [date for date in dataset['Date']]\nsns.countplot(x = dates, order=sorted(set(dates)), palette=\"Set2\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Number of Tweets\")\nplt.title('Number of Tweets Each Day')\nplt.xticks(rotation=50) \nplt.show()","metadata":{"id":"5ykSGCQFGLgs","outputId":"680e3590-eacd-4dc0-cd41-2700cc4111a8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Frequency of Tweets Each Day","metadata":{}},{"cell_type":"code","source":"data = dataset['Date'].groupby([dataset.Date]).agg('count')\ndata = data.to_frame(name='Number of Tweets Each Day')\nsns.lineplot(data=data, x=data.index, y=\"Number of Tweets Each Day\", color='red', linewidth=1.5)\nplt.title('Frequency of Tweets Each Day')\nplt.show()","metadata":{"id":"34ASoHN-KpRq","outputId":"1c36ed6a-1300-4275-b400-7db10500e237","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Top Thirteen Locations With Max Number Of Tweets","metadata":{}},{"cell_type":"code","source":"sns.countplot(x='user_location', data=dataset, order=dataset['user_location'].value_counts().index[:13])\nplt.ylabel(\"Number of Tweets\")\nplt.xlabel(\"User Location\")\nplt.xticks(rotation=50, horizontalalignment='right', x=1.0) \nplt.title('Top Thirteen Locations With Max Number Of Tweets')\nplt.show()","metadata":{"id":"VmKjmu0fM6RM","outputId":"c5eb893b-1fbc-4ec8-cbd8-5a5d2617b1c9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Popular HashTags","metadata":{}},{"cell_type":"code","source":"sns.catplot(data = dataset, kind = \"bar\", x = dataset.hashtags.value_counts().head().index, y = dataset.hashtags.value_counts().head().values)\nplt.ylabel(\"Number of Tweets\")\nplt.xlabel(\"Popular Hastags\")\nplt.xticks(rotation=50, horizontalalignment='right', x=1.0)\nplt.title('Popular HashTags')\nplt.show()","metadata":{"id":"JqduYnusu9_H","outputId":"d241d9f2-a0f3-447a-918e-e7c4288d33f0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Top Plotform Used To Make Tweet","metadata":{}},{"cell_type":"code","source":"platform = dataset['source'].value_counts()[:3].to_dict()\nplatform['Others'] = 0\ndict_ = dataset['source'].value_counts().to_dict()\nfor key in dict_.keys():\n    if key not in platform.keys():\n        platform['Others'] += dict_[key]\n\nplt.pie(x=platform.values(), labels=platform.keys(), autopct='%1.2f%%', shadow=False, startangle=0)\nplt.legend(bbox_to_anchor=(.9,.9))\nplt.title('Top Plotform Used To Make Tweet', x=0.5, y=0.95)\nplt.show()","metadata":{"id":"YKx-mqcJQxyA","outputId":"2affba1f-faac-48a3-cecf-f901f6ca4474","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Text Cleaning","metadata":{}},{"cell_type":"code","source":"!pip -q install contractions\nimport contractions\nimport unicodedata","metadata":{"id":"7nQa_zNfXXAI","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_accented(x):\n  x = unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n  return x","metadata":{"id":"yxfihbL8Xc3R","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_clean(X):\n    X = str(X).lower().replace('\\\\', ' ').replace('_', ' ').replace('.', ' ').replace(':', '')\n    X = X.replace('#', \"\")\n    X = re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?',\"\",  X)\n    X = re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?',\"\",  X)\n    X = re.sub(r'[^\\w\\d\\s]+','', X)\n    X = ' '.join(X.split())\n    X = BeautifulSoup(X, 'lxml').get_text().strip()\n    X = remove_accented(X)\n    X = re.sub(r'[^\\w ]+','',X)\n    X = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", X)\n    X = contractions.fix(X)\n    #X = ' '.join([word for word  in X.split() if word not in  stopwords])\n    return X","metadata":{"id":"mLcUJ5lQSO2k","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['text'] = dataset['text'].apply(lambda x: get_clean(x)) ","metadata":{"id":"zcwBd2p1WDx6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Word Cloud Representation","metadata":{}},{"cell_type":"code","source":"word_cloud = WordCloud(width=700, height=600, max_font_size=180).generate(str(dataset['text']))\nplt.imshow(word_cloud)\nplt.title('Word Cloud Representation')\nplt.axis('off')\nplt.show()","metadata":{"id":"z5oKT2ftYvNq","outputId":"9ebece37-1418-48e2-d38a-63b31bce23cc","trusted":true},"execution_count":null,"outputs":[]}]}