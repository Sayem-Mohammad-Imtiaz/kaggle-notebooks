{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"629c4c4e-45f2-907b-75e5-2d4a2b1a6830","_active":false},"source":"This is my first kernel :P\n\nMost of the code has been taken from http://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/","outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"_cell_guid":"1c17d5c9-35f6-44f6-5158-35cc6e682e9f","_active":false},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport datetime as dt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input/realAWSCloudwatch/realAWSCloudwatch\"]).decode(\"utf8\"))","execution_state":"idle"},{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"727e2e3b-d040-93a4-f8fc-edf248d29c80","_active":false,"collapsed":false},"outputs":[],"source":"fpath = \"../input/realAWSCloudwatch/realAWSCloudwatch/\"\nfname = \"ec2_cpu_utilization_825cc2.csv\"\n\nfullPath = fpath + fname\n\ndata = pd.read_csv(fullPath)\ndata.head()","execution_state":"idle"},{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"4e88fe19-236a-ee43-d85c-2c15427d4041","_active":false},"outputs":[],"source":"x = [dt.datetime.strptime(d,\"%Y-%m-%d %H:%M:%S\").date() for d in data[\"timestamp\"]]\ny = data[\"value\"]\n\nplt.plot(x,y)\nplt.show()","execution_state":"idle"},{"cell_type":"code","execution_count":9,"metadata":{"_cell_guid":"54bf53a0-11c5-d18b-4644-0fffca5d918b","_active":false},"outputs":[],"source":"from statsmodels.tsa.arima_model import ARIMA\nfrom matplotlib import pyplot\nfrom pandas import DataFrame\n \ndef parser(x):\n\treturn dt.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")\n \ndata = pd.read_csv(fullPath, header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n\narimaM = ARIMA(data, order=(5,1,0))\narimaMfit = arimaM.fit(disp=0)\nprint(arimaMfit.summary())\n# plot residual errors\nerrors = DataFrame(arimaMfit.resid)\nerrors.plot()\npyplot.show()\nerrors.plot(kind='kde')\npyplot.show()\nprint(errors.describe())","execution_state":"idle"},{"cell_type":"code","execution_count":10,"metadata":{"_cell_guid":"277a0bdd-be62-f400-cb33-63f85bc72026","_active":true},"outputs":[],"source":"from pandas import datetime\nfrom matplotlib import pyplot\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom sklearn.metrics import mean_squared_error\n \ndef parser(x):\n\treturn dt.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")\n \ndata = pd.read_csv(fullPath, header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\nX = data.values\nsize = int(len(X) * 0.66)\nlimitCount = 50\ntrain, test = X[0:size], X[size:size+limitCount]\nhistory = [x for x in train]\npredictions = list()\nfor t in range(len(test)):\n\tmodel = ARIMA(history, order=(5,1,0))\n\tmodel_fit = model.fit(disp=0)\n\toutput = model_fit.forecast()\n\tyhat = output[0]\n\tpredictions.append(yhat)\n\tobs = test[t]\n\thistory.append(obs)\n\tprint('pred=%f, exp=%f' % (yhat, obs))\nerror = mean_squared_error(test, predictions)\nprint('Mean Squared Error: %.3f' % error)\n# plot\npyplot.plot(test)\npyplot.plot(predictions, color='red')\npyplot.show()","execution_state":"idle"}]}