{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datetime import datetime\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\nimport os\nimport random\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom scipy import sparse\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.metrics import mean_squared_error\n\n\nimport xgboost as xgb\nfrom surprise import Reader, Dataset\nfrom surprise import BaselineOnly\nfrom surprise import KNNBaseline\nfrom surprise import SVD\nfrom surprise import SVDpp\nfrom surprise.model_selection import GridSearchCV","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-24T02:42:04.316606Z","iopub.execute_input":"2021-05-24T02:42:04.317039Z","iopub.status.idle":"2021-05-24T02:42:05.590775Z","shell.execute_reply.started":"2021-05-24T02:42:04.317Z","shell.execute_reply":"2021-05-24T02:42:05.589473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Reading and Storing Data","metadata":{}},{"cell_type":"code","source":"if not os.path.isfile(\"../NetflixRatings.csv\"): \n#This line: \"os.path.isfile(\"../NetflixRatings.csv\")\" simply checks that is there a file with the name \"NetflixRatings.csv\" in the \n#in the folder \"/Data/\". If the file is present then it return true else false\n    startTime = datetime.now()\n    data = open(\"../NetflixRatings.csv\", mode = \"w\") #this line simply creates the file with the name \"NetflixRatings.csv\" in \n    #write mode in the folder \"Data\".\n#     files = ['../Data/combined_data_1.txt','../Data/combined_data_2.txt', '../Data/combined_data_3.txt', '../Data/combined_data_4.txt']\n    files = ['../input/netflix-prize-data/combined_data_2.txt', '../input/netflix-prize-data/combined_data_4.txt']\n    for file in files:\n        print(\"Reading from file: \"+str(file)+\"...\")\n        with open(file) as f:  #you can think of this command \"with open(file) as f\" as similar to 'if' statement or a sort of \n            #loop statement. This command says that as long as this file is opened, perform the underneath operation.\n            for line in f:\n                line = line.strip() #line.strip() clears all the leading and trailing spaces from the string, as here each line\n                #that we are reading from a file is a string.\n                #Note first line consist of a movie id followed by a semi-colon, then second line contains custID,rating,date\n                #then third line agains contains custID,rating,date which belong to that movie ID and so on. The format of data\n                #is exactly same as shown above with the heading \"Example Data Point\". Check out above.\n                if line.endswith(\":\"):\n                    movieID = line.replace(\":\", \"\") #this will remove the trailing semi-colon and return us the leading movie ID.\n                else:\n                    #here, in the below code we have first created an empty list with the name \"row \"so that we can insert movie ID \n                    #at the first position and rest customerID, rating and date in second position. After that we have separated all \n                    #four namely movieID, custID, rating and date with comma and converted a single string by joining them with comma.\n                    #then finally written them to our output \".csv\" file.\n                    row = [] \n                    row = [x for x in line.split(\",\")] #custID, rating and date are separated by comma\n                    row.insert(0, movieID)\n                    data.write(\",\".join(row))\n                    data.write(\"\\n\")\n        print(\"Reading of file: \"+str(file)+\" is completed\\n\")\n    data.close()\n    print(\"Total time taken for execution of this code = \"+str(datetime.now() - startTime))","metadata":{"execution":{"iopub.status.busy":"2021-05-24T02:42:05.592616Z","iopub.execute_input":"2021-05-24T02:42:05.59308Z","iopub.status.idle":"2021-05-24T02:44:01.77221Z","shell.execute_reply.started":"2021-05-24T02:42:05.593046Z","shell.execute_reply":"2021-05-24T02:44:01.771074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating data frame from our output csv file.\nif not os.path.isfile(\"../NetflixData.pkl\"):\n    startTime = datetime.now()\n    Final_Data = pd.read_csv(\"../NetflixRatings.csv\", sep=\",\", names = [\"MovieID\",\"CustID\", \"Ratings\", \"Date\"])\n    Final_Data[\"Date\"] = pd.to_datetime(Final_Data[\"Date\"])\n    Final_Data.sort_values(by = \"Date\", inplace = True)\n    print(\"Time taken for execution of above code = \"+str(datetime.now() - startTime))","metadata":{"execution":{"iopub.status.busy":"2021-05-24T02:44:01.774079Z","iopub.execute_input":"2021-05-24T02:44:01.774375Z","iopub.status.idle":"2021-05-24T02:44:48.397014Z","shell.execute_reply.started":"2021-05-24T02:44:01.774346Z","shell.execute_reply":"2021-05-24T02:44:48.395669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# storing pandas dataframe as a picklefile for later use\nif not os.path.isfile(\"../NetflixData.pkl\"):\n    Final_Data.to_pickle(\"../NetflixData.pkl\")\nelse:\n    Final_Data = pd.read_pickle(\"../NetflixData.pkl\")","metadata":{"execution":{"iopub.status.busy":"2021-05-24T02:44:48.398733Z","iopub.execute_input":"2021-05-24T02:44:48.399042Z","iopub.status.idle":"2021-05-24T02:44:52.57041Z","shell.execute_reply.started":"2021-05-24T02:44:48.399015Z","shell.execute_reply":"2021-05-24T02:44:52.569629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Final_Data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T02:44:52.571666Z","iopub.execute_input":"2021-05-24T02:44:52.572187Z","iopub.status.idle":"2021-05-24T02:44:52.59061Z","shell.execute_reply.started":"2021-05-24T02:44:52.572155Z","shell.execute_reply":"2021-05-24T02:44:52.589887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Final_Data.describe()[\"Ratings\"]","metadata":{"execution":{"iopub.status.busy":"2021-05-24T02:44:52.591984Z","iopub.execute_input":"2021-05-24T02:44:52.59227Z","iopub.status.idle":"2021-05-24T02:45:02.007227Z","shell.execute_reply.started":"2021-05-24T02:44:52.592243Z","shell.execute_reply":"2021-05-24T02:45:02.005967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting Data into Train and Test","metadata":{}},{"cell_type":"code","source":"if not os.path.isfile(\"../TrainData.pkl\"):\n    Final_Data.iloc[:int(Final_Data.shape[0]*0.80)].to_pickle(\"../TrainData.pkl\")\n    Train_Data = pd.read_pickle(\"../TrainData.pkl\")\n    Train_Data.reset_index(drop = True, inplace = True)\nelse:\n    Train_Data = pd.read_pickle(\"../TrainData.pkl\")\n    Train_Data.reset_index(drop = True, inplace = True)\n\nif not os.path.isfile(\"../TestData.pkl\"):\n    Final_Data.iloc[int(Final_Data.shape[0]*0.80):].to_pickle(\"../TestData.pkl\")\n    Test_Data = pd.read_pickle(\"../TestData.pkl\")\n    Test_Data.reset_index(drop = True, inplace = True)\nelse:\n    Test_Data = pd.read_pickle(\"../TestData.pkl\")\n    Test_Data.reset_index(drop = True, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T02:45:44.515647Z","iopub.execute_input":"2021-05-24T02:45:44.516224Z","iopub.status.idle":"2021-05-24T02:45:52.786939Z","shell.execute_reply.started":"2021-05-24T02:45:44.516174Z","shell.execute_reply":"2021-05-24T02:45:52.785645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"def changingLabels(number):\n    return str(number/10**6) + \"M\"","metadata":{"execution":{"iopub.status.busy":"2021-05-24T02:46:47.801801Z","iopub.execute_input":"2021-05-24T02:46:47.802406Z","iopub.status.idle":"2021-05-24T02:46:47.8088Z","shell.execute_reply.started":"2021-05-24T02:46:47.802364Z","shell.execute_reply":"2021-05-24T02:46:47.807564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nax = sns.countplot(x=\"Ratings\", data=Train_Data)\n\nax.set_yticklabels([changingLabels(num) for num in ax.get_yticks()])\n\nplt.tick_params(labelsize = 15)\nplt.title(\"Distribution of Ratings in train data\", fontsize = 20)\nplt.xlabel(\"Ratings\", fontsize = 20)\nplt.ylabel(\"Number of Ratings(Millions)\", fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T02:46:49.584324Z","iopub.execute_input":"2021-05-24T02:46:49.584675Z","iopub.status.idle":"2021-05-24T02:46:54.63061Z","shell.execute_reply.started":"2021-05-24T02:46:49.584645Z","shell.execute_reply":"2021-05-24T02:46:54.629483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Creating USER-ITEM sparse matrix from data frame","metadata":{}},{"cell_type":"code","source":"startTime = datetime.now()\nprint(\"Creating USER_ITEM sparse matrix for train Data\")\nif os.path.isfile(\"../TrainUISparseData.npz\"):\n    print(\"Sparse Data is already present in your disk, no need to create further. Loading Sparse Matrix\")\n    TrainUISparseData = sparse.load_npz(\"../TrainUISparseData.npz\")\n    print(\"Shape of Train Sparse matrix = \"+str(TrainUISparseData.shape))\n    \nelse:\n    print(\"We are creating sparse data\")\n    TrainUISparseData = sparse.csr_matrix((Train_Data.Ratings, (Train_Data.CustID, Train_Data.MovieID)))\n    print(\"Creation done. Shape of sparse matrix = \"+str(TrainUISparseData.shape))\n    print(\"Saving it into disk for furthur usage.\")\n    sparse.save_npz(\"../TrainUISparseData.npz\", TrainUISparseData)\n    print(\"Done\\n\")\n\nprint(datetime.now() - startTime)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T02:54:24.999982Z","iopub.execute_input":"2021-05-24T02:54:25.000459Z","iopub.status.idle":"2021-05-24T02:54:53.897858Z","shell.execute_reply.started":"2021-05-24T02:54:25.000425Z","shell.execute_reply":"2021-05-24T02:54:53.896604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"startTime = datetime.now()\nprint(\"Creating USER_ITEM sparse matrix for test Data\")\nif os.path.isfile(\"../TestUISparseData.npz\"):\n    print(\"Sparse Data is already present in your disk, no need to create further. Loading Sparse Matrix\")\n    TestUISparseData = sparse.load_npz(\"../TestUISparseData.npz\")\n    print(\"Shape of Test Sparse Matrix = \"+str(TestUISparseData.shape))\nelse:\n    print(\"We are creating sparse data\")\n    TestUISparseData = sparse.csr_matrix((Test_Data.Ratings, (Test_Data.CustID, Test_Data.MovieID)))\n    print(\"Creation done. Shape of sparse matrix = \"+str(TestUISparseData.shape))\n    print(\"Saving it into disk for furthur usage.\")\n    sparse.save_npz(\"../TestUISparseData.npz\", TestUISparseData)\n    print(\"Done\\n\")\n\nprint(datetime.now() - startTime)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T02:55:33.876318Z","iopub.execute_input":"2021-05-24T02:55:33.8767Z","iopub.status.idle":"2021-05-24T02:55:42.154604Z","shell.execute_reply.started":"2021-05-24T02:55:33.876666Z","shell.execute_reply":"2021-05-24T02:55:42.15359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finding Global average of all movie ratings, Average rating per user, and Average rating per movie","metadata":{}},{"cell_type":"code","source":"def getAverageRatings(sparseMatrix, if_user):\n    ax = 1 if if_user else 0\n    #axis = 1 means rows and axis = 0 means columns \n    sumOfRatings = sparseMatrix.sum(axis = ax).A1  #this will give an array of sum of all the ratings of user if axis = 1 else \n    #sum of all the ratings of movies if axis = 0\n    noOfRatings = (sparseMatrix!=0).sum(axis = ax).A1  #this will give a boolean True or False array, and True means 1 and False \n    #means 0, and further we are summing it to get the count of all the non-zero cells means length of non-zero cells\n    rows, cols = sparseMatrix.shape\n    averageRatings = {i: sumOfRatings[i]/noOfRatings[i] for i in range(rows if if_user else cols) if noOfRatings[i]!=0}\n    return averageRatings","metadata":{"execution":{"iopub.status.busy":"2021-05-24T02:59:05.047128Z","iopub.execute_input":"2021-05-24T02:59:05.047551Z","iopub.status.idle":"2021-05-24T02:59:05.054262Z","shell.execute_reply.started":"2021-05-24T02:59:05.047515Z","shell.execute_reply":"2021-05-24T02:59:05.052864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Global Average Rating","metadata":{}},{"cell_type":"code","source":"Global_Average_Rating = TrainUISparseData.sum()/TrainUISparseData.count_nonzero()\nprint(\"Global Average Rating {}\".format(Global_Average_Rating))","metadata":{"execution":{"iopub.status.busy":"2021-05-24T02:59:11.37656Z","iopub.execute_input":"2021-05-24T02:59:11.376958Z","iopub.status.idle":"2021-05-24T02:59:11.587368Z","shell.execute_reply.started":"2021-05-24T02:59:11.376924Z","shell.execute_reply":"2021-05-24T02:59:11.586362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Average Rating Per User","metadata":{}},{"cell_type":"code","source":"AvgRatingUser = getAverageRatings(TrainUISparseData, True)\nprint(\"Average rating of user 25 = {}\".format(AvgRatingUser[25]))","metadata":{"execution":{"iopub.status.busy":"2021-05-24T02:59:52.939221Z","iopub.execute_input":"2021-05-24T02:59:52.939615Z","iopub.status.idle":"2021-05-24T02:59:55.716339Z","shell.execute_reply.started":"2021-05-24T02:59:52.939581Z","shell.execute_reply":"2021-05-24T02:59:55.715339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Average Rating Per Movie","metadata":{}},{"cell_type":"code","source":"AvgRatingMovie = getAverageRatings(TrainUISparseData, False)\nprint(\"Average rating of movie 4500 = {}\".format(AvgRatingMovie[4500]))","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:02:14.37651Z","iopub.execute_input":"2021-05-24T03:02:14.376933Z","iopub.status.idle":"2021-05-24T03:02:14.820817Z","shell.execute_reply.started":"2021-05-24T03:02:14.376895Z","shell.execute_reply":"2021-05-24T03:02:14.819965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Computing Movie-Movie Similarity Matrix","metadata":{}},{"cell_type":"code","source":"start = datetime.now()\n\nif not os.path.isfile(\"../m_m_similarity.npz\"):\n    print(\"Movie-Movie Similarity file does not exist in your disk. Creating Movie-Movie Similarity Matrix...\")\n    \n    m_m_similarity = cosine_similarity(TrainUISparseData.T, dense_output = False)\n    print(\"Done\")\n    print(\"Dimension of Matrix = {}\".format(m_m_similarity.shape))\n    print(\"Storing the Movie Similarity matrix on disk for further usage\")\n    sparse.save_npz(\"../m_m_similarity.npz\", m_m_similarity)\nelse:\n    print(\"File exists in the disk. Loading the file...\")\n    m_m_similarity = sparse.load_npz(\"../m_m_similarity.npz\")\n    print(\"Dimension of Matrix = {}\".format(m_m_similarity.shape))\n    \nprint(datetime.now() - start)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:15:39.990919Z","iopub.execute_input":"2021-05-24T03:15:39.991288Z","iopub.status.idle":"2021-05-24T03:18:02.793454Z","shell.execute_reply.started":"2021-05-24T03:15:39.991258Z","shell.execute_reply":"2021-05-24T03:18:02.792123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Modeling","metadata":{}},{"cell_type":"code","source":"def get_sample_sparse_matrix(sparseMatrix, n_users, n_movies):\n    startTime = datetime.now()\n    users, movies, ratings = sparse.find(sparseMatrix)\n    uniq_users = np.unique(users)\n    uniq_movies = np.unique(movies)\n    np.random.seed(15)   #this will give same random number everytime, without replacement\n    userS = np.random.choice(uniq_users, n_users, replace = False)\n    movieS = np.random.choice(uniq_movies, n_movies, replace = False)\n    mask = np.logical_and(np.isin(users, userS), np.isin(movies, movieS))\n    sparse_sample = sparse.csr_matrix((ratings[mask], (users[mask], movies[mask])), \n                                                     shape = (max(userS)+1, max(movieS)+1))\n    print(\"Sparse Matrix creation done. Saving it for later use.\")\n    sparse.save_npz(path, sparse_sample)\n    print(\"Done\")\n    print(\"Shape of Sparse Sampled Matrix = \"+str(sparse_sample.shape))\n    \n    print(datetime.now() - start)\n    return sparse_sample","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:22:38.653935Z","iopub.execute_input":"2021-05-24T03:22:38.656184Z","iopub.status.idle":"2021-05-24T03:22:38.673186Z","shell.execute_reply.started":"2021-05-24T03:22:38.655771Z","shell.execute_reply":"2021-05-24T03:22:38.671636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"../TrainUISparseData_Sample.npz\"\nif not os.path.isfile(path):\n    print(\"Sample sparse matrix is not present in the disk. We are creating it...\")\n    train_sample_sparse = get_sample_sparse_matrix(TrainUISparseData, 4000, 400)\nelse:\n    print(\"File is already present in the disk. Loading the file...\")\n    train_sample_sparse = sparse.load_npz(path)\n    print(\"File loading done.\")\n    print(\"Shape of Train Sample Sparse Matrix = \"+str(train_sample_sparse.shape))","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:23:36.392201Z","iopub.execute_input":"2021-05-24T03:23:36.392591Z","iopub.status.idle":"2021-05-24T03:23:55.383184Z","shell.execute_reply.started":"2021-05-24T03:23:36.39253Z","shell.execute_reply":"2021-05-24T03:23:55.382027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"../TestUISparseData_Sample.npz\"\nif not os.path.isfile(path):\n    print(\"Sample sparse matrix is not present in the disk. We are creating it...\")\n    test_sample_sparse = get_sample_sparse_matrix(TestUISparseData, 2000, 200)\nelse:\n    print(\"File is already present in the disk. Loading the file...\")\n    test_sample_sparse = sparse.load_npz(path)\n    print(\"File loading done.\")\n    print(\"Shape of Test Sample Sparse Matrix = \"+str(test_sample_sparse.shape))","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:24:32.380208Z","iopub.execute_input":"2021-05-24T03:24:32.380556Z","iopub.status.idle":"2021-05-24T03:24:36.932098Z","shell.execute_reply.started":"2021-05-24T03:24:32.380527Z","shell.execute_reply":"2021-05-24T03:24:36.930961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"globalAvgMovies = getAverageRatings(train_sample_sparse, False)\nprint(\"Average move rating for movie 14890 is {}\".format(globalAvgMovies[14890]))\n\nglobalAvgUsers = getAverageRatings(train_sample_sparse, True)\nprint(\"Average user rating for user 16879 is {}\".format(globalAvgMovies[16879]))","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:26:49.323511Z","iopub.execute_input":"2021-05-24T03:26:49.323917Z","iopub.status.idle":"2021-05-24T03:26:51.199797Z","shell.execute_reply.started":"2021-05-24T03:26:49.323884Z","shell.execute_reply":"2021-05-24T03:26:51.198689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_train_users, sample_train_movies, sample_train_ratings = sparse.find(train_sample_sparse)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:24:36.933889Z","iopub.execute_input":"2021-05-24T03:24:36.934183Z","iopub.status.idle":"2021-05-24T03:24:36.944893Z","shell.execute_reply.started":"2021-05-24T03:24:36.934156Z","shell.execute_reply":"2021-05-24T03:24:36.943861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if os.path.isfile(\"../Ttrain_Regression.csv\"):\n    print(\"File is already present in your disk. You do not have to prepare it again.\")\nelse:\n    startTime = datetime.now()\n    print(\"Preparing Train csv file for {} rows\".format(len(sample_train_ratings)))\n    with open(\"../Train_Regression.csv\", mode = \"w\") as data:\n        count = 0\n        for user, movie, rating in zip(sample_train_users, sample_train_movies, sample_train_ratings):\n            row = list()\n            row.append(user)  #appending user ID\n            row.append(movie) #appending movie ID\n            row.append(train_sample_sparse.sum()/train_sample_sparse.count_nonzero()) #appending global average rating\n\n#----------------------------------Ratings given to \"movie\" by top 5 similar users with \"user\"--------------------#\n            similar_users = cosine_similarity(train_sample_sparse[user], train_sample_sparse).ravel()\n            similar_users_indices = np.argsort(-similar_users)[1:]\n            similar_users_ratings = train_sample_sparse[similar_users_indices, movie].toarray().ravel()\n            top_similar_user_ratings = list(similar_users_ratings[similar_users_ratings != 0][:5])\n            top_similar_user_ratings.extend([globalAvgMovies[movie]]*(5-len(top_similar_user_ratings)))\n            #above line means that if top 5 ratings are not available then rest of the ratings will be filled by \"movie\" average\n            #rating. Let say only 3 out of 5 ratings are available then rest 2 will be \"movie\" average rating.\n            row.extend(top_similar_user_ratings)\n            \n #----------------------------------Ratings given by \"user\" to top 5 similar movies with \"movie\"------------------#\n            similar_movies = cosine_similarity(train_sample_sparse[:,movie].T, train_sample_sparse.T).ravel()\n            similar_movies_indices = np.argsort(-similar_movies)[1:]\n            similar_movies_ratings = train_sample_sparse[user, similar_movies_indices].toarray().ravel()\n            top_similar_movie_ratings = list(similar_movies_ratings[similar_movies_ratings != 0][:5])\n            top_similar_movie_ratings.extend([globalAvgUsers[user]]*(5-len(top_similar_movie_ratings)))\n            #above line means that if top 5 ratings are not available then rest of the ratings will be filled by \"user\" average\n            #rating. Let say only 3 out of 5 ratings are available then rest 2 will be \"user\" average rating.\n            row.extend(top_similar_movie_ratings)\n            \n #----------------------------------Appending \"user\" average, \"movie\" average & rating of \"user\"\"movie\"-----------#\n            row.append(globalAvgUsers[user])\n            row.append(globalAvgMovies[movie])\n            row.append(rating)\n            \n#-----------------------------------Converting rows and appending them as comma separated values to csv file------#\n            data.write(\",\".join(map(str, row)))\n            data.write(\"\\n\")\n    \n            count += 1\n            if count % 2000 == 0:\n                print(\"Done for {}. Time elapsed: {}\".format(count, (datetime.now() - startTime)))\n                \n    print(\"Total Time for {} rows = {}\".format(len(sample_train_ratings), (datetime.now() - startTime)))","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:27:49.96216Z","iopub.execute_input":"2021-05-24T03:27:49.962785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_Reg = pd.read_csv(\"../Train_Regression.csv\", names = [\"User_ID\", \"Movie_ID\", \"Global_Average\", \"SUR1\", \"SUR2\", \"SUR3\", \"SUR4\", \"SUR5\", \"SMR1\", \"SMR2\", \"SMR3\", \"SMR4\", \"SMR5\", \"User_Average\", \"Movie_Average\", \"Rating\"])\nTrain_Reg.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T03:27:17.08121Z","iopub.execute_input":"2021-05-24T03:27:17.081727Z","iopub.status.idle":"2021-05-24T03:27:17.111691Z","shell.execute_reply.started":"2021-05-24T03:27:17.08169Z","shell.execute_reply":"2021-05-24T03:27:17.110572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_test_users, sample_test_movies, sample_test_ratings = sparse.find(test_sample_sparse)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if os.path.isfile(\"../Test_Regression.csv\"):\n    print(\"File is already present in your disk. You do not have to prepare it again.\")\nelse:\n    startTime = datetime.now()\n    print(\"Preparing Test csv file for {} rows\".format(len(sample_test_ratings)))\n    with open(\"../Test_Regression.csv\", mode = \"w\") as data:\n        count = 0\n        for user, movie, rating in zip(sample_test_users, sample_test_movies, sample_test_ratings):\n            row = list()\n            row.append(user)  #appending user ID\n            row.append(movie) #appending movie ID\n            row.append(train_sample_sparse.sum()/train_sample_sparse.count_nonzero()) #appending global average rating\n\n#-----------------------------Ratings given to \"movie\" by top 5 similar users with \"user\"-------------------------#\n            try:\n                similar_users = cosine_similarity(train_sample_sparse[user], train_sample_sparse).ravel()\n                similar_users_indices = np.argsort(-similar_users)[1:]\n                similar_users_ratings = train_sample_sparse[similar_users_indices, movie].toarray().ravel()\n                top_similar_user_ratings = list(similar_users_ratings[similar_users_ratings != 0][:5])\n                top_similar_user_ratings.extend([globalAvgMovies[movie]]*(5-len(top_similar_user_ratings)))\n                #above line means that if top 5 ratings are not available then rest of the ratings will be filled by \"movie\" \n                #average rating. Let say only 3 out of 5 ratings are available then rest 2 will be \"movie\" average rating.\n                row.extend(top_similar_user_ratings)\n            #########Cold Start Problem, for a new user or a new movie#########    \n            except(IndexError, KeyError):\n                global_average_train_rating = [train_sample_sparse.sum()/train_sample_sparse.count_nonzero()]*5\n                row.extend(global_average_train_rating)\n            except:\n                raise\n                \n #-----------------------------Ratings given by \"user\" to top 5 similar movies with \"movie\"-----------------------#\n            try:\n                similar_movies = cosine_similarity(train_sample_sparse[:,movie].T, train_sample_sparse.T).ravel()\n                similar_movies_indices = np.argsort(-similar_movies)[1:]\n                similar_movies_ratings = train_sample_sparse[user, similar_movies_indices].toarray().ravel()\n                top_similar_movie_ratings = list(similar_movies_ratings[similar_movies_ratings != 0][:5])\n                top_similar_movie_ratings.extend([globalAvgUsers[user]]*(5-len(top_similar_movie_ratings)))\n                #above line means that if top 5 ratings are not available then rest of the ratings will be filled by \"user\" \n                #average rating. Let say only 3 out of 5 ratings are available then rest 2 will be \"user\" average rating.\n                row.extend(top_similar_movie_ratings)\n            #########Cold Start Problem, for a new user or a new movie#########\n            except(IndexError, KeyError):\n                global_average_train_rating = [train_sample_sparse.sum()/train_sample_sparse.count_nonzero()]*5\n                row.extend(global_average_train_rating)\n            except:\n                raise\n                \n #-----------------------------Appending \"user\" average, \"movie\" average & rating of \"user\"\"movie\"----------------#\n            try:        \n                row.append(globalAvgUsers[user])\n            except (KeyError):\n                global_average_train_rating = train_sample_sparse.sum()/train_sample_sparse.count_nonzero()\n                row.append(global_average_train_rating)\n            except:\n                raise\n                \n            try:\n                row.append(globalAvgMovies[movie])\n            except(KeyError):\n                global_average_train_rating = train_sample_sparse.sum()/train_sample_sparse.count_nonzero()\n                row.append(global_average_train_rating)\n            except:\n                raise\n                \n            row.append(rating)\n            \n#------------------------------Converting rows and appending them as comma separated values to csv file-----------#\n            data.write(\",\".join(map(str, row)))\n            data.write(\"\\n\")\n    \n            count += 1\n            if count % 100 == 0:\n                print(\"Done for {}. Time elapsed: {}\".format(count, (datetime.now() - startTime)))\n                \n    print(\"Total Time for {} rows = {}\".format(len(sample_test_ratings), (datetime.now() - startTime)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_Reg = pd.read_csv(\"../Test_Regression.csv\", names = [\"User_ID\", \"Movie_ID\", \"Global_Average\", \"SUR1\", \"SUR2\", \"SUR3\", \"SUR4\", \"SUR5\", \"SMR1\", \"SMR2\", \"SMR3\", \"SMR4\", \"SMR5\", \"User_Average\", \"Movie_Average\", \"Rating\"])\nTest_Reg.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reader = Reader(rating_scale=(1, 5))\n\ndata = Dataset.load_from_df(Train_Reg[['User_ID', 'Movie_ID', 'Rating']], reader)\n\ntrainset = data.build_full_trainset()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testset = list(zip(Test_Reg[\"User_ID\"].values, Test_Reg[\"Movie_ID\"].values, Test_Reg[\"Rating\"].values))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error_table = pd.DataFrame(columns = [\"Model\", \"Train RMSE\", \"Train MAPE\", \"Test RMSE\", \"Test MAPE\"])\nmodel_train_evaluation = dict()\nmodel_test_evaluation = dict()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_table(model_name, rmse_train, mape_train, rmse_test, mape_test):\n    global error_table\n    #All variable assignments in a function store the value in the local symbol table; whereas variable references first look \n    #in the local symbol table, then in the global symbol table, and then in the table of built-in names. Thus, global variables \n    #cannot be directly assigned a value within a function (unless named in a global statement), \n    #although they may be referenced.\n    error_table = error_table.append(pd.DataFrame([[model_name, rmse_train, mape_train, rmse_test, mape_test]], columns = [\"Model\", \"Train RMSE\", \"Train MAPE\", \"Test RMSE\", \"Test MAPE\"]))\n    error_table.reset_index(drop = True, inplace = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def error_metrics(y_true, y_pred):\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    mape = np.mean(abs((y_true - y_pred)/y_true))*100\n    return rmse, mape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_test_xgboost(x_train, x_test, y_train, y_test, model_name):\n    startTime = datetime.now()\n    train_result = dict()\n    test_result = dict()\n    \n    clf = xgb.XGBRegressor(n_estimators = 100, silent = False, n_jobs  = 10)\n    clf.fit(x_train, y_train)\n    \n    print(\"-\"*50)\n    print(\"TRAIN DATA\")\n    y_pred_train = clf.predict(x_train)\n    rmse_train, mape_train = error_metrics(y_train, y_pred_train)\n    print(\"RMSE = {}\".format(rmse_train))\n    print(\"MAPE = {}\".format(mape_train))\n    print(\"-\"*50)\n    train_result = {\"RMSE\": rmse_train, \"MAPE\": mape_train, \"Prediction\": y_pred_train}\n    \n    print(\"TEST DATA\")\n    y_pred_test = clf.predict(x_test)\n    rmse_test, mape_test = error_metrics(y_test, y_pred_test)\n    print(\"RMSE = {}\".format(rmse_test))\n    print(\"MAPE = {}\".format(mape_test))\n    print(\"-\"*50)\n    test_result = {\"RMSE\": rmse_test, \"MAPE\": mape_test, \"Prediction\": y_pred_test}\n        \n    print(\"Time Taken = \"+str(datetime.now() - startTime))\n    \n    plot_importance(xgb, clf)\n    \n    make_table(model_name, rmse_train, mape_train, rmse_test, mape_test)\n    \n    return train_result, test_result","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_importance(model, clf):\n    fig = plt.figure(figsize = (8, 6))\n    ax = fig.add_axes([0,0,1,1])\n    model.plot_importance(clf, ax = ax, height = 0.3)\n    plt.xlabel(\"F Score\", fontsize = 20)\n    plt.ylabel(\"Features\", fontsize = 20)\n    plt.title(\"Feature Importance\", fontsize = 20)\n    plt.tick_params(labelsize = 15)\n    \n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_ratings(predictions):\n    actual = np.array([pred.r_ui for pred in predictions])\n    predicted = np.array([pred.est for pred in predictions])\n    return actual, predicted\n#in surprise prediction of every data point is returned as dictionary like this:\n#\"user: 196        item: 302        r_ui = 4.00   est = 4.06   {'actual_k': 40, 'was_impossible': False}\"\n#In this dictionary, \"r_ui\" is a key for actual rating and \"est\" is a key for predicted rating","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_error(predictions):\n    actual, predicted = get_ratings(predictions)\n    rmse = np.sqrt(mean_squared_error(actual, predicted)) \n    mape = np.mean(abs((actual - predicted)/actual))*100\n    return rmse, mape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_seed = 15\nrandom.seed(my_seed)\nnp.random.seed(my_seed)\n\ndef run_surprise(algo, trainset, testset, model_name):\n    startTime = datetime.now()\n    \n    train = dict()\n    test = dict()\n    \n    algo.fit(trainset)\n    #You can check out above function at \"https://surprise.readthedocs.io/en/stable/getting_started.html\" in \n    #\"Train-test split and the fit() method\" section\n    \n#-----------------Evaluating Train Data------------------#\n    print(\"-\"*50)\n    print(\"TRAIN DATA\")\n    train_pred = algo.test(trainset.build_testset())\n    #You can check out \"algo.test()\" function at \"https://surprise.readthedocs.io/en/stable/getting_started.html\" in \n    #\"Train-test split and the fit() method\" section\n    #You can check out \"trainset.build_testset()\" function at \"https://surprise.readthedocs.io/en/stable/FAQ.html#can-i-use-my-own-dataset-with-surprise-and-can-it-be-a-pandas-dataframe\" in \n    #\"How to get accuracy measures on the training set\" section\n    train_actual, train_predicted = get_ratings(train_pred)\n    train_rmse, train_mape = get_error(train_pred)\n    print(\"RMSE = {}\".format(train_rmse))\n    print(\"MAPE = {}\".format(train_mape))\n    print(\"-\"*50)\n    train = {\"RMSE\": train_rmse, \"MAPE\": train_mape, \"Prediction\": train_predicted}\n    \n#-----------------Evaluating Test Data------------------#\n    print(\"TEST DATA\")\n    test_pred = algo.test(testset)\n    #You can check out \"algo.test()\" function at \"https://surprise.readthedocs.io/en/stable/getting_started.html\" in \n    #\"Train-test split and the fit() method\" section\n    test_actual, test_predicted = get_ratings(test_pred)\n    test_rmse, test_mape = get_error(test_pred)\n    print(\"RMSE = {}\".format(test_rmse))\n    print(\"MAPE = {}\".format(test_mape))\n    print(\"-\"*50)\n    test = {\"RMSE\": test_rmse, \"MAPE\": test_mape, \"Prediction\": test_predicted}\n    \n    print(\"Time Taken = \"+str(datetime.now() - startTime))\n    \n    make_table(model_name, train_rmse, train_mape, test_rmse, test_mape)\n    \n    return train, test","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = Train_Reg.drop([\"User_ID\", \"Movie_ID\", \"Rating\"], axis = 1)\n\nx_test = Test_Reg.drop([\"User_ID\", \"Movie_ID\", \"Rating\"], axis = 1)\n\ny_train = Train_Reg[\"Rating\"]\n\ny_test = Test_Reg[\"Rating\"]\n\ntrain_result, test_result = train_test_xgboost(x_train, x_test, y_train, y_test, \"XGBoost_13\")\n\nmodel_train_evaluation[\"XGBoost_13\"] = train_result\nmodel_test_evaluation[\"XGBoost_13\"] = test_result","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"$ \\large\\hat{r}_{ui} = \\mu + b_u + b_i $","metadata":{}},{"cell_type":"markdown","source":"### Surpise(Library) Baseline Model","metadata":{}},{"cell_type":"code","source":"bsl_options = {\"method\":\"sgd\", \"learning_rate\":0.01, \"n_epochs\":25}\n\nalgo = BaselineOnly(bsl_options=bsl_options)\n#You can check the docs of above used functions at:https://surprise.readthedocs.io/en/stable/prediction_algorithms.html#baseline-estimates-configuration\n#at section \"Baselines estimates configuration\".\n\ntrain_result, test_result = run_surprise(algo, trainset, testset, \"BaselineOnly\")\n\nmodel_train_evaluation[\"BaselineOnly\"] = train_result\nmodel_test_evaluation[\"BaselineOnly\"] = test_result","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"$ \\large \\hat{r}_{ui} = b_{ui} + \\frac{ \\sum\\limits_{v \\in N^k_i(u)} \\text{sim}(u, v) \\cdot (r_{vi} - b_{vi})} {\\sum\\limits_{v \\in N^k_i(u)} \\text{sim}(u, v)} $","metadata":{}},{"cell_type":"markdown","source":"### Surprise KNN-Baseline with Item-Item Similarity","metadata":{}},{"cell_type":"code","source":"param_grid  = {'sim_options':{'name': [\"pearson_baseline\"], \"user_based\": [False], \"min_support\": [2], \"shrinkage\": [60, 80, 80, 140]}, 'k': [5, 20, 40, 80]}\n\ngs = GridSearchCV(KNNBaseline, param_grid, measures=['rmse', 'mae'], cv=3)\n\ngs.fit(data)\n\n# best RMSE score\nprint(gs.best_score['rmse'])\n\n# combination of parameters that gave the best RMSE score\nprint(gs.best_params['rmse'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sim_options = {'name':'pearson_baseline', 'user_based':False, 'min_support':2, 'shrinkage':gs.best_params['rmse']['sim_options']['shrinkage']}\n\nbsl_options = {'method': 'sgd'} \n\nalgo = KNNBaseline(k = gs.best_params['rmse']['k'], sim_options = sim_options, bsl_options=bsl_options)\n\ntrain_result, test_result = run_surprise(algo, trainset, testset, \"KNNBaseline_Item\")\n\nmodel_train_evaluation[\"KNNBaseline_Item\"] = train_result\nmodel_test_evaluation[\"KNNBaseline_Item\"] = test_result","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}