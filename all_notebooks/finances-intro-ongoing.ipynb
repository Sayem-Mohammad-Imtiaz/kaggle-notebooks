{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-06T02:19:29.024765Z","iopub.execute_input":"2021-06-06T02:19:29.025138Z","iopub.status.idle":"2021-06-06T02:19:29.031846Z","shell.execute_reply.started":"2021-06-06T02:19:29.025108Z","shell.execute_reply":"2021-06-06T02:19:29.030172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pip install --upgrade mplfinance","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:19:31.017872Z","iopub.execute_input":"2021-06-06T02:19:31.01823Z","iopub.status.idle":"2021-06-06T02:19:31.022952Z","shell.execute_reply.started":"2021-06-06T02:19:31.018189Z","shell.execute_reply":"2021-06-06T02:19:31.021719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install bs4","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:19:31.786811Z","iopub.execute_input":"2021-06-06T02:19:31.787184Z","iopub.status.idle":"2021-06-06T02:19:42.714125Z","shell.execute_reply.started":"2021-06-06T02:19:31.787154Z","shell.execute_reply":"2021-06-06T02:19:42.713205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install yfinance","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:19:45.233662Z","iopub.execute_input":"2021-06-06T02:19:45.234034Z","iopub.status.idle":"2021-06-06T02:19:55.3241Z","shell.execute_reply.started":"2021-06-06T02:19:45.234004Z","shell.execute_reply":"2021-06-06T02:19:55.322801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install yfinance -U","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:19:56.395979Z","iopub.execute_input":"2021-06-06T02:19:56.396328Z","iopub.status.idle":"2021-06-06T02:20:03.245713Z","shell.execute_reply.started":"2021-06-06T02:19:56.396295Z","shell.execute_reply":"2021-06-06T02:20:03.244465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime as dt\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\n#import mplfinance as mpf\nimport pandas_datareader.data as pdr\nimport matplotlib.dates as mdates\nimport bs4 as bs\nimport pickle\nimport requests\nimport datetime as dt\n#import fix_yahoo_finance as yf","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:20:30.586485Z","iopub.execute_input":"2021-06-06T02:20:30.587092Z","iopub.status.idle":"2021-06-06T02:20:30.591878Z","shell.execute_reply.started":"2021-06-06T02:20:30.587055Z","shell.execute_reply":"2021-06-06T02:20:30.590885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nstyle.use('ggplot')\nstart=dt.datetime(2000,1,1)\nend=dt.datetime(2020,12,31)\ndf=web.DataReader('TSLA','yahoo',start,end)\nprint(df.head())\ndf.plot()\nplt.show()\n#df['100ma']=df['Adj Close'].rolling(window=100,min_periods=0).mean()\n#df.dropna(inplace=True)\n#print(df.head())\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-06-06T01:02:13.86126Z","iopub.execute_input":"2021-06-06T01:02:13.861805Z","iopub.status.idle":"2021-06-06T01:02:13.870998Z","shell.execute_reply.started":"2021-06-06T01:02:13.861768Z","shell.execute_reply":"2021-06-06T01:02:13.86889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_sp500_tickers():\n    resp=requests.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n    soup=bs.BeautifulSoup(resp.text,'lxml')\n    table=soup.find('table',{'class':\"wikitable sortable\"})\n    #print(table)\n    tickers=[]\n    for row in table.findAll('tr')[1:]:\n        ticker=row.findAll('td')[0].text\n        tickers.append(ticker)\n    with open(\"sp500tickers.pickle\",'wb') as f:\n        pickle.dump(tickers,f)\n        #print(tickers)\n        str1 = \" \"\n        label=str1.join(tickers)\n        label=label.replace('\\n',\"\")\n        tickers= list(label.split(\" \"))\n        return tickers    \n\n#save_sp500_tickers()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T01:25:22.071867Z","iopub.execute_input":"2021-06-06T01:25:22.072142Z","iopub.status.idle":"2021-06-06T01:25:22.080864Z","shell.execute_reply.started":"2021-06-06T01:25:22.072118Z","shell.execute_reply":"2021-06-06T01:25:22.079399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data_from_yahoo(reload_sp500=False):\n    if reload_sp500:\n        tickers=save_sp500_tickers()\n    else:\n        with open('sp500tickers.pickle','rb') as f:\n            tickers = pickle.load(f)\n            \n    if not os.path.exists('stock_dfs'):\n        os.makedirs(\"stock_dfs\")\n        \n    start = dt.datetime(2000,1,1)\n    end= dt.datetime(2020,12,31)\n    failed = []\n    passed = []\n    data = pd.DataFrame()\n    for ticker in tickers:\n        #print(ticker)\n         if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n            df = web.get_data_yahoo(ticker, start, end)\n            df.reset_index(inplace=True)\n            df.set_index(\"Date\", inplace=True)\n            df.to_csv('stock_dfs/{}.csv'.format(ticker))\n         else:\n            print('Alredy have{}'.format(ticker))\n            \nget_data_from_yahoo()        \n            \n            ","metadata":{"execution":{"iopub.status.busy":"2021-06-06T01:10:53.2377Z","iopub.execute_input":"2021-06-06T01:10:53.237985Z","iopub.status.idle":"2021-06-06T01:10:54.309151Z","shell.execute_reply.started":"2021-06-06T01:10:53.23796Z","shell.execute_reply":"2021-06-06T01:10:54.306835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data_from_yahoo(reload_sp500=False):\n    if reload_sp500:\n        tickers=save_sp500_tickers()\n    else:\n        with open('sp500tickers.pickle','rb') as f:\n            tickers = pickle.load(f)\n            \n    if not os.path.exists('stock_dfs'):\n        os.makedirs(\"stock_dfs\")\n        \n    start = dt.datetime(2000,1,1)\n    end= dt.datetime(2020,12,31)\n    failed = []\n    passed = []\n    data = pd.DataFrame()\n    for ticker in tickers[:10]:\n        try:\n            data[ticker] = web.DataReader(ticker, data_source= \"yahoo\", start = \"2019-1-1\")[\"Adj Close\"]\n            passed.append(x)\n        except (IOError, KeyError):\n            msg = 'Failed to read symbol: {0!r}, replacing with NaN.'\n            failed.append(ticker)\n        else:\n            print('Alredy have{}'.format(ticker))\n            \nget_data_from_yahoo()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-06T01:20:10.491488Z","iopub.execute_input":"2021-06-06T01:20:10.491859Z","iopub.status.idle":"2021-06-06T01:20:20.592587Z","shell.execute_reply.started":"2021-06-06T01:20:10.491823Z","shell.execute_reply":"2021-06-06T01:20:20.591457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_data_from_yahoo()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T01:23:15.285499Z","iopub.execute_input":"2021-06-06T01:23:15.285835Z","iopub.status.idle":"2021-06-06T01:23:26.60165Z","shell.execute_reply.started":"2021-06-06T01:23:15.285808Z","shell.execute_reply":"2021-06-06T01:23:26.600301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"failed=[]\npassed=[]\n\ndef collect_data(tickers):\n  mydata = pd.DataFrame()\n  for t in tickers:\n    try:\n      mydata[t] = wb.DataReader(t,data_source='yahoo',start='01-10-2019')['Adj Close']\n      passed.append(t)\n    except (IOError, KeyError):\n      msg= 'NaN'\n      failed.append(t)\n\n  print(mydata)\n  return mydata\n\ncollect_data(tickers)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T01:25:30.743331Z","iopub.execute_input":"2021-06-06T01:25:30.743695Z","iopub.status.idle":"2021-06-06T01:25:30.763064Z","shell.execute_reply.started":"2021-06-06T01:25:30.743665Z","shell.execute_reply":"2021-06-06T01:25:30.762116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = dt(2016, 12, 31)\nend = dt.now()\nINPX = data.DataReader('INPX', 'yahoo', start, end)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T01:27:25.011585Z","iopub.execute_input":"2021-06-06T01:27:25.012023Z","iopub.status.idle":"2021-06-06T01:27:25.026694Z","shell.execute_reply.started":"2021-06-06T01:27:25.011982Z","shell.execute_reply":"2021-06-06T01:27:25.024968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fin_prod_data = pdr.get_data_yahoo(symbol.upper(), start_date, end_date)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:20:40.996028Z","iopub.execute_input":"2021-06-06T02:20:40.996591Z","iopub.status.idle":"2021-06-06T02:20:41.015195Z","shell.execute_reply.started":"2021-06-06T02:20:40.996549Z","shell.execute_reply":"2021-06-06T02:20:41.013832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nimport pandas as pd\nimport datetime\nimport numpy as np\nfrom pandas_datareader import data, wb\nimport pandas_datareader as pdr\nfrom collections import defaultdict\n \ndef Print_Market_Profile(symbol, height_precision = 1, \n    frequency='m', start_date=None, end_date=None):\n\n    # We will look at stock prices over the past year\n    if start_date == None:\n        # get a year's worth of data from today\n        start_date = datetime.date.today() - datetime.timedelta(days=365.24)\n        # set date to first of month\n        start_date = start_date.replace(day=1)\n    if end_date == None:\n        end_date = datetime.date.today() \n\n    fin_prod_data = pdr.get_data_google(symbol.upper(), start_date, end_date)\n    fin_prod_data[('High')] = fin_prod_data[('High')] * height_precision\n    fin_prod_data[('Low')] = fin_prod_data[('Low')] * height_precision\n    fin_prod_data = fin_prod_data.round({'Low': 0, 'High': 0})  \n     \n    time_groups = fin_prod_data.groupby(pd.TimeGrouper(freq=frequency))['Adj Close'].mean()\n    current_time_group_index=0\n       \n    from collections import defaultdict\n    mp = defaultdict(str)\n    char_mark = 64\n\n    # build dictionary with all needed prices\n    tot_min_price=min(np.array(fin_prod_data['Low']))\n    tot_max_price=max(np.array(fin_prod_data['High']))\n    for price in range(int(tot_min_price), int(tot_max_price)):\n        mp[price]+=('\\t')\n\n    # add max price as it will be ignored in for range loop above\n    mp[tot_max_price] = '\\t' + str(time_groups.index[current_time_group_index])[5:7] + '/' + str(time_groups.index[current_time_group_index])[3:4]\n             \n    for x in range(0, len(fin_prod_data)):\n        if fin_prod_data.index[x] > time_groups.index[current_time_group_index]:\n            # new time period\n            char_mark=64\n            # buffer and tab all entries\n            buffer_max = max([len(v) for k,v in mp.iteritems()])\n            current_time_group_index += 1\n            for k,v in mp.iteritems():\n                mp[k] += (chr(32) * (buffer_max - len(mp[k]))) + '\\t'\n            mp[tot_max_price] += str(time_groups.index[current_time_group_index])[5:7] + '/' + str(time_groups.index[current_time_group_index])[3:4]\n            \n\n        char_mark += 1\n        min_price=fin_prod_data['Low'][x]\n        max_price=fin_prod_data['High'][x]\n        for price in range(int(min_price), int(max_price)):\n            mp[price]+=(chr(char_mark))\n \n    sorted_keys = sorted(mp.keys(), reverse=True)\n    for x in sorted_keys:\n        # buffer each list\n        print(str(\"{0:.2f}\".format((x * 1.0) / height_precision)) + ': \\t' + ''.join(mp[x]))\n \ndef main():\n    # customize ingestion of agruments to handle\n    # frequency: http://nullege.com/codes/search/pandas.TimeGrouper\n\n    if (len(sys.argv[1:]) == 1):\n        symbol = sys.argv[1:][0]\n        Print_Market_Profile(symbol)\n    elif (len(sys.argv[1:]) == 2):\n        symbol = sys.argv[1:][0]\n        height_precision = sys.argv[1:][1]\n        Print_Market_Profile(symbol, height_precision)\n    elif (len(sys.argv[1:]) == 3):\n        symbol = sys.argv[1:][0]\n        height_precision = sys.argv[1:][1]\n        frequency = sys.argv[1:][2]\n        Print_Market_Profile(symbol, height_precision, frequency)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:24:23.260569Z","iopub.execute_input":"2021-06-06T02:24:23.261071Z","iopub.status.idle":"2021-06-06T02:24:23.313299Z","shell.execute_reply.started":"2021-06-06T02:24:23.261041Z","shell.execute_reply":"2021-06-06T02:24:23.311798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"git clone https://github.com/pydata/pandas-datareader","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:25:38.352571Z","iopub.execute_input":"2021-06-06T02:25:38.353289Z","iopub.status.idle":"2021-06-06T02:25:38.358769Z","shell.execute_reply.started":"2021-06-06T02:25:38.353246Z","shell.execute_reply":"2021-06-06T02:25:38.357532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}