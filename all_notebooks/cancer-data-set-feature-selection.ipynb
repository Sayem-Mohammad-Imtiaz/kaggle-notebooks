{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/breast-cancer-wisconsin-data/data.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we need understand the data for this purpose we look at the first 5 colums of data "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"creating new variable we say that is x \n\nwe need to clear the data first of all chose useless variable \n\n-id \n-unnamed\n\nwe drob to this variable in data also we select diagnosis and we create again new variable it is y \n\ny is equal to diagnoses colums"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data.diagnosis\n\nx_drop = [\"id\",\"Unnamed: 32\",\"diagnosis\"]\n\nx = data.drop(x_drop,axis=1)\n\nx.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"how many B and M clas in y "},{"metadata":{"trusted":true},"cell_type":"code","source":"B,M = y.value_counts()\nprint(\"number of Beling :\",B )\nprint(\"number of Malignant : \",M)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"seperate data train and test "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 42)\n\nprint(\"shape of x train : \",x_train.shape)\nprint(\"shape of y train : \",y_train.shape)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we need to chose how many feature we use "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import preprocessing\n\nx_train_1 = preprocessing.normalize(x_train,norm =\"l2\")\n\nclf_rf = RandomForestClassifier()\n\nrfe = RFE(estimator= clf_rf,n_features_to_select= 5,step = 1)\nrfe = rfe.fit(x_train_1,y_train)\n\nprint(\"chosen 5  feature is  : \",x_train.columns[rfe.support_])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"assess the data "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFECV\n\nclf_rf_2 = RandomForestClassifier()\n\nrfecv = RFECV(estimator=clf_rf_2,step = 1 ,cv = 5 ,scoring= \"accuracy\")\n\nrfecv_result = rfecv.fit(x_train,y_train)\n\nprint(\"optimal feature : \",rfecv_result.n_features_)\nprint(\"best feature : \",x_train.columns[rfecv_result.support_])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure()\nplt.xlabel(\"number of feature\")\nplt.ylabel(\"cross validation score of number of selected feature\")\nplt.plot(range(1,len(rfecv_result.grid_scores_)+1),rfecv_result.grid_scores_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"PCA Method \n\nuse feature expansion princible component analysis first normalize data "},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_N = (x_train - x_train.mean())/(x_train.max() - x_train.min())\nx_test_N = (x_test - x_test.mean())/(x_test.max() - x_test.min())\n\n\n\nfrom sklearn.decomposition import PCA\n\npca = PCA()\npca = pca.fit(x_train_N)\n\nplt.figure(1,figsize=(14,13))\nplt.clf()\nplt.axes([.2,.2,.7,.7])\nplt.plot(pca.explained_variance_ratio_ , linewidth = 2)\nplt.axis(\"tight\")\nplt.xlabel(\"n compenent\")\nplt.ylabel(\"explained varience ratio \")\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"thanks for helping Dataiteam \ni use their source"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}