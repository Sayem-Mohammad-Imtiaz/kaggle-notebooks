{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SVM + RoBERTa-large","metadata":{}},{"cell_type":"markdown","source":"Datasetlink(model): \n\n'../input/svm-robertalarge-pretrain/clrp_roberta_large' -> https://www.kaggle.com/joechan619/svm-robertalarge-pretrain\n\n'../input/svm-robertalarge' -> https://www.kaggle.com/joechan619/svm-robertalarge\n","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport cv2\nimport math\nimport time\nimport tqdm\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.svm import SVR\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import Adam, lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import (AutoModel, AutoTokenizer, \n                          AutoModelForSequenceClassification)\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\n\nfrom colorama import Fore, Back, Style\ny_ = Fore.YELLOW\nr_ = Fore.RED\ng_ = Fore.GREEN\nb_ = Fore.BLUE\nm_ = Fore.MAGENTA\nc_ = Fore.CYAN\nsr_ = Style.RESET_ALL","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-13T12:19:44.865126Z","iopub.execute_input":"2021-08-13T12:19:44.865469Z","iopub.status.idle":"2021-08-13T12:19:52.871861Z","shell.execute_reply.started":"2021-08-13T12:19:44.865392Z","shell.execute_reply":"2021-08-13T12:19:52.870879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nsample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n\nnum_bins = int(np.floor(1 + np.log2(len(train_data))))\ntrain_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\n\ntarget = train_data['target'].to_numpy()\nbins = train_data.bins.to_numpy()\n\ndef rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:19:52.873489Z","iopub.execute_input":"2021-08-13T12:19:52.873815Z","iopub.status.idle":"2021-08-13T12:19:53.025833Z","shell.execute_reply.started":"2021-08-13T12:19:52.873778Z","shell.execute_reply":"2021-08-13T12:19:53.024975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\n    'batch_size':128,\n    'max_len':256,\n    'nfolds':10,\n    'seed':42,\n}\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed=config['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:19:53.027707Z","iopub.execute_input":"2021-08-13T12:19:53.028207Z","iopub.status.idle":"2021-08-13T12:19:53.03907Z","shell.execute_reply.started":"2021-08-13T12:19:53.028116Z","shell.execute_reply":"2021-08-13T12:19:53.038114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CLRPDataset(Dataset):\n    def __init__(self,df,tokenizer):\n        self.excerpt = df['excerpt'].to_numpy()\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],return_tensors='pt',\n                                max_length=config['max_len'],\n                                padding='max_length',truncation=True)\n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:19:53.040876Z","iopub.execute_input":"2021-08-13T12:19:53.041239Z","iopub.status.idle":"2021-08-13T12:19:53.048435Z","shell.execute_reply.started":"2021-08-13T12:19:53.041203Z","shell.execute_reply":"2021-08-13T12:19:53.047436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AttentionHead(nn.Module):\n    def __init__(self, in_features, hidden_dim, num_targets):\n        super().__init__()\n        self.in_features = in_features\n        self.middle_features = hidden_dim\n\n        self.W = nn.Linear(in_features, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        self.out_features = hidden_dim\n\n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n\n        score = self.V(att)\n\n        attention_weights = torch.softmax(score, dim=1)\n\n        context_vector = attention_weights * features\n        context_vector = torch.sum(context_vector, dim=1)\n\n        return context_vector","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:19:53.051196Z","iopub.execute_input":"2021-08-13T12:19:53.051685Z","iopub.status.idle":"2021-08-13T12:19:53.060628Z","shell.execute_reply.started":"2021-08-13T12:19:53.051648Z","shell.execute_reply":"2021-08-13T12:19:53.059785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model,self).__init__()\n        self.roberta = AutoModel.from_pretrained('../input/svm-robertalarge-pretrain/clrp_roberta_large')    \n        #changed attentionHead Dimension from 768 to 1024 by changing model from roberta-base to roberta-large\n        self.head = AttentionHead(1024,1024,1)\n        self.dropout = nn.Dropout(0.1)\n        self.linear = nn.Linear(self.head.out_features,1)\n\n    def forward(self,**xb):\n        x = self.roberta(**xb)[0]\n        x = self.head(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:19:53.063643Z","iopub.execute_input":"2021-08-13T12:19:53.063905Z","iopub.status.idle":"2021-08-13T12:19:53.071879Z","shell.execute_reply.started":"2021-08-13T12:19:53.063882Z","shell.execute_reply":"2021-08-13T12:19:53.071065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_embeddings(df,path,plot_losses=True, verbose=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n            \n    model = Model()\n    model.load_state_dict(torch.load(path))\n    model.to(device)\n    model.eval()\n    \n    tokenizer = AutoTokenizer.from_pretrained('../input/svm-robertalarge-pretrain/clrp_roberta_large')\n    \n    ds = CLRPDataset(df,tokenizer)\n    dl = DataLoader(ds,\n                  batch_size = config[\"batch_size\"],\n                  shuffle=False,\n                  num_workers = 4,\n                  pin_memory=True,\n                  drop_last=False\n                 )\n        \n    embeddings = list()\n    with torch.no_grad():\n        for i, inputs in tqdm(enumerate(dl)):\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n            outputs = model(**inputs)\n            outputs = outputs.detach().cpu().numpy()\n            embeddings.extend(outputs)\n    return np.array(embeddings)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:19:53.075031Z","iopub.execute_input":"2021-08-13T12:19:53.075299Z","iopub.status.idle":"2021-08-13T12:19:53.0852Z","shell.execute_reply.started":"2021-08-13T12:19:53.07527Z","shell.execute_reply":"2021-08-13T12:19:53.084491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## svm","metadata":{}},{"cell_type":"code","source":"def get_preds_svm(X,y,X_test,bins=bins,nfolds=10,C=10,kernel='rbf'):\n    scores = list()\n    train_preds = np.zeros((X.shape[0]))\n    preds = np.zeros((X_test.shape[0]))\n    \n    kfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\n    for k, (train_idx,valid_idx) in enumerate(kfold.split(X,bins)):\n        model = SVR(C=C,kernel=kernel,gamma='auto')\n        X_train,y_train = X[train_idx], y[train_idx]\n        X_valid,y_valid = X[valid_idx], y[valid_idx]\n        \n        model.fit(X_train,y_train)\n        prediction = model.predict(X_valid)\n        train_preds[valid_idx] = prediction\n        score = rmse_score(prediction,y_valid)\n        print(f'Fold {k} , rmse score: {score}')\n        scores.append(score)\n        preds += model.predict(X_test)\n        \n    print(\"mean rmse\",np.mean(scores))\n    return train_preds,np.array(preds)/nfolds","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:19:53.089137Z","iopub.execute_input":"2021-08-13T12:19:53.089469Z","iopub.status.idle":"2021-08-13T12:19:53.09985Z","shell.execute_reply.started":"2021-08-13T12:19:53.089444Z","shell.execute_reply":"2021-08-13T12:19:53.099038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_svm(fold):\n    model_path = f'../input/svm-robertalarge/model{fold}/model{fold}.bin'\n    train_embeddings =  get_embeddings(train_data,model_path)\n    test_embeddings = get_embeddings(test_data,model_path)\n    train_svm,svm_preds = get_preds_svm(train_embeddings,target,test_embeddings)\n    return train_svm,svm_preds","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:19:53.102082Z","iopub.execute_input":"2021-08-13T12:19:53.102398Z","iopub.status.idle":"2021-08-13T12:19:53.111893Z","shell.execute_reply.started":"2021-08-13T12:19:53.102364Z","shell.execute_reply":"2021-08-13T12:19:53.111072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_svm_list = []\ntest_svm_list = []\nfor fold in range(5):\n    train_svm,svm_preds = get_svm(fold)\n    train_svm_list.append(train_svm)\n    test_svm_list.append(svm_preds)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:19:53.114895Z","iopub.execute_input":"2021-08-13T12:19:53.115178Z","iopub.status.idle":"2021-08-13T12:33:00.89381Z","shell.execute_reply.started":"2021-08-13T12:19:53.11515Z","shell.execute_reply":"2021-08-13T12:33:00.89103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_svm = np.array(train_svm_list).mean(axis=0)\ntest_svm = np.array(test_svm_list).mean(axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:33:00.902588Z","iopub.execute_input":"2021-08-13T12:33:00.902872Z","iopub.status.idle":"2021-08-13T12:33:00.91278Z","shell.execute_reply.started":"2021-08-13T12:33:00.90284Z","shell.execute_reply":"2021-08-13T12:33:00.911747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\ndef rmse(targets, preds):\n    return round(np.sqrt(mean_squared_error(targets, preds)), 4)\nprint('SVM + RoBERTa CV’s RMSE:{}'.format(rmse(np.array(train_data.target.values), train_svm)))","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:33:00.914234Z","iopub.execute_input":"2021-08-13T12:33:00.914585Z","iopub.status.idle":"2021-08-13T12:33:00.931687Z","shell.execute_reply.started":"2021-08-13T12:33:00.914551Z","shell.execute_reply":"2021-08-13T12:33:00.930405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 4\n\nDatasetlink(model):\n\n\"../input/clrp-roberta-base/clrp_roberta_base\" -> https://www.kaggle.com/maunish/clrp-roberta-base\n\n\"../input/commonlit-roberta-0467/\" -> https://www.kaggle.com/andretugan/commonlit-roberta-0467","metadata":{}},{"cell_type":"code","source":"import os\nimport math\nimport random\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModel\nfrom transformers import AutoConfig\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport gc\ngc.enable()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:33:00.933132Z","iopub.execute_input":"2021-08-13T12:33:00.933607Z","iopub.status.idle":"2021-08-13T12:33:01.553051Z","shell.execute_reply.started":"2021-08-13T12:33:00.933568Z","shell.execute_reply":"2021-08-13T12:33:01.552227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 32\nMAX_LEN = 248\nEVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n\nROBERTA_PATH = \"../input/clrp-roberta-base/clrp_roberta_base\"\nTOKENIZER_PATH = \"../input/clrp-roberta-base/clrp_roberta_base\"\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n\ntrain_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/train.csv\")\nprint(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index)\n# Remove incomplete entries if any.\ntrain_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n              inplace=True)\ntrain_df.reset_index(drop=True, inplace=True)\n\ntest_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\nsubmission_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:33:01.556238Z","iopub.execute_input":"2021-08-13T12:33:01.556543Z","iopub.status.idle":"2021-08-13T12:33:01.98607Z","shell.execute_reply.started":"2021-08-13T12:33:01.556515Z","shell.execute_reply":"2021-08-13T12:33:01.985286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DATASET\nclass LitDataset(Dataset):\n    def __init__(self, df, inference_only=False):\n        super().__init__()\n\n        self.df = df        \n        self.inference_only = inference_only\n        self.text = df.excerpt.tolist()\n        #self.text = [text.replace(\"\\n\", \" \") for text in self.text]\n        \n        if not self.inference_only:\n            self.target = torch.tensor(df.target.values, dtype=torch.float32)        \n    \n        self.encoded = tokenizer.batch_encode_plus(\n            self.text,\n            padding = 'max_length',            \n            max_length = MAX_LEN,\n            truncation = True,\n            return_attention_mask=True\n        )        \n \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):        \n        input_ids = torch.tensor(self.encoded['input_ids'][index])\n        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n        \n        if self.inference_only:\n            return (input_ids, attention_mask)            \n        else:\n            target = self.target[index]\n            return (input_ids, attention_mask, target)\n# MODEL\nclass LitModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        config = AutoConfig.from_pretrained(ROBERTA_PATH)\n        config.update({\"output_hidden_states\":True, \n                       \"hidden_dropout_prob\": 0.0,\n                       \"layer_norm_eps\": 1e-7})                       \n        \n        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n            \n        self.attention = nn.Sequential(            \n            nn.Linear(768, 512),            \n            nn.Tanh(),                       \n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )        \n\n        self.regressor = nn.Sequential(                        \n            nn.Linear(768, 1)                        \n        )\n        \n\n    def forward(self, input_ids, attention_mask):\n        roberta_output = self.roberta(input_ids=input_ids,\n                                      attention_mask=attention_mask)        \n\n        # There are a total of 13 layers of hidden states.\n        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n        # We take the hidden states from the last Roberta layer.\n        last_layer_hidden_states = roberta_output.hidden_states[-1]\n\n        # The number of cells is MAX_LEN.\n        # The size of the hidden state of each cell is 768 (for roberta-base).\n        # In order to condense hidden states of all cells to a context vector,\n        # we compute a weighted average of the hidden states of all cells.\n        # We compute the weight of each cell, using the attention neural network.\n        weights = self.attention(last_layer_hidden_states)\n                \n        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n        # Now we compute context_vector as the weighted average.\n        # context_vector.shape is BATCH_SIZE x 768\n        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n        \n        # Now we reduce the context vector to the prediction score.\n        return self.regressor(context_vector)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:33:01.987461Z","iopub.execute_input":"2021-08-13T12:33:01.987811Z","iopub.status.idle":"2021-08-13T12:33:02.000076Z","shell.execute_reply.started":"2021-08-13T12:33:01.987775Z","shell.execute_reply":"2021-08-13T12:33:01.999253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse(targets, preds):\n    return round(np.sqrt(mean_squared_error(targets, preds)), 4)\n\ndef set_random_seed(random_seed):\n    random.seed(random_seed)\n    np.random.seed(random_seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n\n    torch.manual_seed(random_seed)\n    torch.cuda.manual_seed(random_seed)\n    torch.cuda.manual_seed_all(random_seed)\n\n    torch.backends.cudnn.deterministic = True\n        \ndef predict(model, data_loader,is_test=False):\n    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n    model.eval()\n\n    result = np.zeros(len(data_loader.dataset))    \n    index = 0\n    if is_test:\n        with torch.no_grad():\n            for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n                input_ids = input_ids.to(DEVICE)\n                attention_mask = attention_mask.to(DEVICE)\n\n                pred = model(input_ids, attention_mask)                        \n\n                result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n                index += pred.shape[0]\n    else:\n        with torch.no_grad():\n            for batch_num, (input_ids, attention_mask, target) in enumerate(data_loader):\n                input_ids = input_ids.to(DEVICE)\n                attention_mask = attention_mask.to(DEVICE)\n\n                pred = model(input_ids, attention_mask)                        \n\n                result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n                index += pred.shape[0]\n            \n\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:33:02.001295Z","iopub.execute_input":"2021-08-13T12:33:02.001806Z","iopub.status.idle":"2021-08-13T12:33:02.014873Z","shell.execute_reply.started":"2021-08-13T12:33:02.001768Z","shell.execute_reply":"2021-08-13T12:33:02.013968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\nNUM_FOLDS = 5\nSEED = 1000\nkfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\nvalid_prediction = np.zeros(len(train_df))\n\nfor fold, (train_indices, val_indices) in enumerate(kfold.split(train_df)):    \n    model_path = f\"../input/commonlit-roberta-0467/model_{fold + 1}.pth\"\n    print(f\"\\nUsing {model_path}\")\n                        \n    model = LitModel()\n    model.load_state_dict(torch.load(model_path, map_location=DEVICE))    \n    model.to(DEVICE)\n        \n    set_random_seed(SEED + fold)\n\n    val_dataset = LitDataset(train_df.loc[val_indices])     \n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n                            drop_last=False, shuffle=False, num_workers=2)    \n    \n    set_random_seed(SEED + fold)   \n    \n    pred = predict(model,val_loader)\n    \n    valid_prediction[val_indices] = pred\n        \n    del model\n    gc.collect()\nprint('CV’s RMSE:{}'.format(rmse(train_df.target.values, valid_prediction)))","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:33:02.016353Z","iopub.execute_input":"2021-08-13T12:33:02.016711Z","iopub.status.idle":"2021-08-13T12:34:35.021402Z","shell.execute_reply.started":"2021-08-13T12:33:02.016675Z","shell.execute_reply":"2021-08-13T12:34:35.020378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In the training process, the author deleted the 106\n# To match the dim in the training set of meta model\n# we put the real target in the training set of meta model\nimport copy\nfor_meta = copy.deepcopy(valid_prediction)\nfor_meta = np.insert(for_meta,106,0)  ","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:34:35.022754Z","iopub.execute_input":"2021-08-13T12:34:35.023255Z","iopub.status.idle":"2021-08-13T12:34:35.028161Z","shell.execute_reply.started":"2021-08-13T12:34:35.023215Z","shell.execute_reply":"2021-08-13T12:34:35.02724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_MODELS = 5\n\nall_predictions = np.zeros((NUM_MODELS, len(test_df)))\n\ntest_dataset = LitDataset(test_df, inference_only=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n                         drop_last=False, shuffle=False, num_workers=2)\n\nfor model_index in range(NUM_MODELS):            \n    model_path = f\"../input/commonlit-roberta-0467/model_{model_index + 1}.pth\"\n    print(f\"\\nUsing {model_path}\")\n                        \n    model = LitModel()\n    model.load_state_dict(torch.load(model_path, map_location=DEVICE))    \n    model.to(DEVICE)\n    # blending fold 4 in meta-level\n    if (model_index + 1) != 4:\n        all_predictions[model_index] = predict(model, test_loader,is_test=True)\n    else:\n        pred = (predict(model, test_loader,is_test=True) * 0.7 + test_svm * 0.3)\n        all_predictions[model_index] = pred\n                \n    del model\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:34:35.029589Z","iopub.execute_input":"2021-08-13T12:34:35.030068Z","iopub.status.idle":"2021-08-13T12:35:23.444503Z","shell.execute_reply.started":"2021-08-13T12:34:35.03003Z","shell.execute_reply":"2021-08-13T12:35:23.44355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 19\n\nDatasetlink(model):\n\n'../input/roberta-large-5fold-aux' -> https://www.kaggle.com/joechan619/roberta-large-5fold-aux\n\n'../input/tokenizers/roberta-tokenizer.pt' -> https://www.kaggle.com/chamecall/tokenizers","metadata":{}},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport pandas as pd\nfrom sklearn import model_selection\ntrain_df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\n\ndef create_folds(data, num_splits):\n    data[\"fold\"] = -1\n    kf = model_selection.KFold(n_splits=num_splits, shuffle=True, random_state=2021)\n    for f, (t_, v_) in enumerate(kf.split(X=data)):\n        data.loc[v_, 'fold'] = f\n    return data\nkfold_df = create_folds(train_df, num_splits=5)\n\nin_folder_path = Path('../input/roberta-large-5fold-aux')\nscripts_dir = Path(in_folder_path / 'scripts')\nos.chdir(scripts_dir)\nexec(Path(\"imports.py\").read_text())\nexec(Path(\"config.py\").read_text())\nexec(Path(\"dataset.py\").read_text())\nexec(Path(\"model.py\").read_text())\nos.chdir('/kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:35:23.446135Z","iopub.execute_input":"2021-08-13T12:35:23.446499Z","iopub.status.idle":"2021-08-13T12:35:29.78712Z","shell.execute_reply.started":"2021-08-13T12:35:23.446457Z","shell.execute_reply":"2021-08-13T12:35:29.786177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_dataloader(data, tokenizer, is_train=True):\n    if is_train:\n        dataset = CLRPDataset(data, tokenizer=tokenizer)\n        sampler = RandomSampler(dataset)\n    else:\n        dataset = CLRPDataset(data, tokenizer=tokenizer,max_len=Config.max_len,is_test=True)\n        sampler = SequentialSampler(dataset)\n    batch_dataloader = DataLoader(dataset, sampler=sampler, batch_size=Config.batch_size)\n    return batch_dataloader\n\ndef get_preds_k(dl,model_num,models_folder_path):\n    model = torch.load(models_folder_path / f'best_model_{model_num}.pt').to(Config.device)\n    model.eval()\n          \n    embeddings = list()\n    with torch.no_grad():\n        for i, inputs in tqdm(enumerate(dl)):\n            inputs = {key:val.reshape(val.shape[0],-1).to(Config.device) for key,val in inputs.items()}\n            outputs = model(**inputs)\n#             outputs = outputs.detach().cpu().numpy()\n            outputs = outputs.cpu().detach().numpy().ravel().tolist()\n            embeddings.extend(outputs)\n    return np.array(embeddings)\n\ndef stacking_get_pred_k(models_folder_path):\n    tokenizer = torch.load('../input/tokenizers/roberta-tokenizer.pt')\n#     models_folder_path = Path(in_folder_path / 'models')\n    models_preds = []\n    n_models = 5\n    test_preds = np.zeros((test_df.shape[0]))\n    train_preds = np.zeros((train_df.shape[0]))\n\n    for model_num in range(n_models):\n        print(f'Inference#{model_num+1}/{n_models}')\n        test_dataloader = make_dataloader(test_df, tokenizer, is_train=False)\n        test_pred = get_preds_k(test_dataloader,model_num,models_folder_path)\n        # blending fold 4 in meta-level\n        if model_num == 3:\n            test_pred = (test_pred * 0.7 + test_svm * 0.3)\n            test_preds += test_pred\n        else:\n            test_preds += test_pred\n\n        val_dl = make_dataloader(kfold_df[kfold_df.fold==model_num], tokenizer, is_train=False)\n        val_index = kfold_df[kfold_df.fold==model_num].index.tolist()\n        val_preds = get_preds_k(val_dl,model_num,models_folder_path)\n        train_preds[val_index] = val_preds\n    return train_preds,test_preds","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:35:29.788364Z","iopub.execute_input":"2021-08-13T12:35:29.788688Z","iopub.status.idle":"2021-08-13T12:35:29.802063Z","shell.execute_reply.started":"2021-08-13T12:35:29.788653Z","shell.execute_reply":"2021-08-13T12:35:29.801245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_folder_path = Path(in_folder_path / 'models')\ntrain_preds_k_19,test_preds_k_19 = stacking_get_pred_k(models_folder_path)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:35:29.803463Z","iopub.execute_input":"2021-08-13T12:35:29.804042Z","iopub.status.idle":"2021-08-13T12:39:57.134313Z","shell.execute_reply.started":"2021-08-13T12:35:29.804003Z","shell.execute_reply":"2021-08-13T12:39:57.131281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacking","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\n\ndef create_folds(data, num_splits):\n    data[\"kfold\"] = -1\n    kf = model_selection.KFold(n_splits=num_splits, shuffle=True, random_state=2021)\n    for f, (t_, v_) in enumerate(kf.split(X=data)):\n        data.loc[v_, 'kfold'] = f\n    return data\ntrain = create_folds(train_df, num_splits=5)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:39:57.147405Z","iopub.execute_input":"2021-08-13T12:39:57.147696Z","iopub.status.idle":"2021-08-13T12:39:57.321338Z","shell.execute_reply.started":"2021-08-13T12:39:57.147666Z","shell.execute_reply":"2021-08-13T12:39:57.320417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Blending Fold 4 in base level","metadata":{}},{"cell_type":"code","source":"i = 3\ntrain_idx, val_idx = train.index[train['kfold'] != i].tolist(), train.index[train['kfold'] == i].tolist()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:39:57.322858Z","iopub.execute_input":"2021-08-13T12:39:57.323215Z","iopub.status.idle":"2021-08-13T12:39:57.32948Z","shell.execute_reply.started":"2021-08-13T12:39:57.323177Z","shell.execute_reply":"2021-08-13T12:39:57.328234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for_meta[val_idx] = (for_meta[val_idx] * 0.7 + train_svm[val_idx] * 0.3)\ntrain_preds_k_19[val_idx] = (train_preds_k_19[val_idx] * 0.7 + train_svm[val_idx] * 0.3)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:39:57.331098Z","iopub.execute_input":"2021-08-13T12:39:57.33148Z","iopub.status.idle":"2021-08-13T12:39:57.341029Z","shell.execute_reply.started":"2021-08-13T12:39:57.331442Z","shell.execute_reply":"2021-08-13T12:39:57.340201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_train = pd.DataFrame()\n# oof_train['model1'] = oof_roberta_base_i\n# oof_train['model2'] = oof_roberta_large_itpt\n# oof_train['model3'] = oof_roberta_large_ii\noof_train['model4'] = for_meta\n# oof_train['model5'] = clrp_train_preds\n# oof_train['model6'] = clrp_tpu_train_preds\n# oof_train['model7'] = k_train_pred\n# oof_train['model8'] = train_preds_8\n# oof_train['model9'] = distil_train\n# oof_train['model10'] = distil_aux_train\n# oof_train['model11'] = distil_no_aux_train\n# oof_train['model12'] = train_preds_k_12\n# oof_train['model13'] = train_all_predictions\n# oof_train['model15'] = train_preds_k\n# oof_train['model18'] = k_train_pred_18\noof_train['model19'] = train_preds_k_19\noof_train['target'] = train.target.values\noof_train = create_folds(oof_train, num_splits=5)\ndisplay(oof_train.shape)\noof_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:39:57.342462Z","iopub.execute_input":"2021-08-13T12:39:57.343078Z","iopub.status.idle":"2021-08-13T12:39:57.392287Z","shell.execute_reply.started":"2021-08-13T12:39:57.343038Z","shell.execute_reply":"2021-08-13T12:39:57.391575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_oof_train = oof_train[['model4','model19']]\nx_oof_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:39:57.393506Z","iopub.execute_input":"2021-08-13T12:39:57.393882Z","iopub.status.idle":"2021-08-13T12:39:57.406263Z","shell.execute_reply.started":"2021-08-13T12:39:57.393845Z","shell.execute_reply":"2021-08-13T12:39:57.405263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_test = pd.DataFrame()\n# oof_test['model1'] = pred_df1.mean(axis=1)\n# oof_test['model2'] = pred_df2.mean(axis=1)\n# oof_test['model3'] = pred_df3.mean(axis=1)\noof_test['model4'] = all_predictions.mean(axis=0)\n# oof_test['model5'] = clrp_test_preds/5\n# oof_test['model6'] = clrp_tpu_test_preds/5\n# oof_test['model7'] = k_test_pred/5\n# oof_test['model8'] = test_preds_8/5\n# oof_test['model9'] = distil_test/5\n# oof_test['model10'] = distil_aux_test/5\n# oof_test['model11'] = distil_no_aux_test/5\n# oof_test['model12'] = test_preds_k_12/5\n# oof_test['model13'] = test_all_predictions\n# oof_test['model15'] = test_preds_k/5\n# oof_test['model18'] = k_test_pred_18/5\noof_test['model19'] = test_preds_k_19/5\ndisplay(oof_test.shape)\noof_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:39:57.407893Z","iopub.execute_input":"2021-08-13T12:39:57.408713Z","iopub.status.idle":"2021-08-13T12:39:57.426263Z","shell.execute_reply.started":"2021-08-13T12:39:57.408555Z","shell.execute_reply":"2021-08-13T12:39:57.425242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stacking_preds = []\noof_rmses = []\n\nFOLDS = 5\nfor fold in range(FOLDS):\n    print(f'\\nTraining Fold {fold + 1} / {FOLDS}')\n    \n    train_idx, val_idx = oof_train.index[oof_train['kfold']!=fold].tolist(), oof_train.index[oof_train['kfold']==fold].tolist()\n    x_train, y_train = x_oof_train.iloc[list(train_idx)], oof_train.target.iloc[train_idx]\n    x_val, y_val = x_oof_train.iloc[list(val_idx)], oof_train.target.iloc[val_idx]\n    from sklearn.linear_model import Ridge\n    reg = Ridge(alpha = 1)\n#     from sklearn.linear_model import BayesianRidge\n#     reg = BayesianRidge(n_iter=300, verbose=True)\n    reg.fit(x_train, y_train)\n    \n    val_pred = reg.predict(x_val)\n    oof_rmse = rmse(val_pred, oof_train.target[val_idx].values)\n    oof_rmses.append(oof_rmse)\n    print(f\"Fold {fold+1} train OOF RMSE: {oof_rmse}\")\n    \n    stacking_preds.append(reg.predict(oof_test))\n\nprint('Stacking Regressor: Mean OOF RMSE = {}'.format(np.mean(oof_rmses)))","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:39:57.427834Z","iopub.execute_input":"2021-08-13T12:39:57.428202Z","iopub.status.idle":"2021-08-13T12:39:57.530974Z","shell.execute_reply.started":"2021-08-13T12:39:57.428163Z","shell.execute_reply":"2021-08-13T12:39:57.530202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")\nsubmission.target = np.mean(stacking_preds,0)\nprint(submission)\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-13T12:39:57.532261Z","iopub.execute_input":"2021-08-13T12:39:57.532617Z","iopub.status.idle":"2021-08-13T12:39:57.599182Z","shell.execute_reply.started":"2021-08-13T12:39:57.532578Z","shell.execute_reply":"2021-08-13T12:39:57.597775Z"},"trusted":true},"execution_count":null,"outputs":[]}]}