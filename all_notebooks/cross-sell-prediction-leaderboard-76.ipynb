{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Concepts included in this notebook:\n    \n 1)  Data Analysis\n \n 2)  Encoding \n \n 3)  Handling imbalenced classes \n \n 4)  Training a catboost classifier"},{"metadata":{},"cell_type":"markdown","source":"# Importing necessary libraries\n\nRandomOverSampler and SMOTE(Synthetic Minority Oversampling Technique) are used to treat imbalanced datasets. \n\nRandomOverSampler duplicates the minority class data until minority class data reaches specified proportion of majority class data.\n\nSMOTE generates synthetic data of minority classes and ensures that the data doesn't overfit."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom imblearn.over_sampling import RandomOverSampler,SMOTE\nfrom imblearn.under_sampling  import RandomUnderSampler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction/test.csv')\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking the percentages of 1's and 0's in target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Response.value_counts()\n\nprint(data.Response.value_counts()/data.shape[0] *100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping ID column as it has too many discrete values"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop('id',axis=1,inplace=True)\nID = test['id']\ntest.drop('id',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data['Vehicle_Age'].value_counts(),test['Vehicle_Age'].value_counts())\nprint(data['Region_Code'].value_counts(),test['Region_Code'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To replace region code, summing the number of positive responses for each region code and transforming it into dictionary."},{"metadata":{"trusted":true},"cell_type":"code","source":"region_code = data.groupby(['Region_Code'])['Response'].sum().sort_values().to_dict()\npolicy_channel = data.groupby(['Policy_Sales_Channel'])['Response'].sum().sort_values().to_dict()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Label encoding all categorical features.\n\nGender is a nominal variable but since it has only two genders, Male and Female, doing one-hot encoding with drop first as True and label encoding will fetch same results. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder \nl = LabelEncoder()\ndata['Gender'] = l.fit_transform(data['Gender'])\ndata['Vehicle_Age'] = l.fit_transform(data['Vehicle_Age'])\ndata['Vehicle_Damage'] = l.fit_transform(data['Vehicle_Damage'])\n#data['Policy_Sales_Channel'] = l.fit_transform(data['Policy_Sales_Channel'])\n\ntest['Gender'] = l.fit_transform(test['Gender'])\ntest['Vehicle_Age'] = l.fit_transform(test['Vehicle_Age'])\ntest['Vehicle_Damage'] = l.fit_transform(test['Vehicle_Damage'])\ntest['Vehicle_Age'] = l.fit_transform(test['Vehicle_Age'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Region_Code'].replace(region_code,inplace=True)\ndata['Policy_Sales_Channel'].replace(policy_channel,inplace=True)\n\ntest['Region_Code'].replace(region_code,inplace=True)\ntest['Policy_Sales_Channel'].replace(policy_channel,inplace=True)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# as you can see the correlation of region code with response has increased\ndata.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 15))\n\nfor i, col in enumerate(data.columns,1):\n    plt.subplot(5,4, i)\n    sns.boxplot(y=col,data=data)\n    plt.xlabel(col)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Annual_Premium'].hist(bins=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Applying logarithmic transformation on Annual Premium to reduce the skewness of the data and also to scale down the values."},{"metadata":{"trusted":true},"cell_type":"code","source":"## Annual Premium has many ouliers so applying log transformation\ndata['Annual_Premium'] = np.log(data['Annual_Premium'])\ntest['Annual_Premium'] = np.log(test['Annual_Premium'])\ndata[['Annual_Premium']].boxplot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Annual_Premium'].hist(bins=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier,VotingClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold,cross_val_score,GridSearchCV,RandomizedSearchCV,train_test_split\nfrom sklearn import svm\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport xgboost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.iloc[:,:-1]\ny = data.iloc[:,-1]\n\noversample = RandomOverSampler(sampling_strategy=0.5)\nX, y = oversample.fit_resample(X, y)\n\nprint(X.shape)\nscale = StandardScaler()\nX = scale.fit_transform(X)\ntest = scale.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier, Pool","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostClassifier(learning_rate=0.03,iterations=800,depth=6,\n                           eval_metric='AUC',task_type=\"GPU\",devices='0:1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X,\n          y,\n          eval_set=None,\n          verbose=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below are the parameter weights.\n\nYou can see that Previously Insured feature as played a crucial role of all in predicting the output."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.get_feature_importance()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_probs = model.predict_proba(test)\ny_probs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_probs = y_probs[:,1]\nsub_cat = pd.DataFrame({'id':ID,'Response':y_probs})\nsub_cat.set_index('id',inplace=True)\nsub_cat","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}