{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport numpy.random as npr\nimport pandas as pd\nimport plotly.graph_objects as go\nimport scipy.stats as sps\nfrom plotly.subplots import make_subplots\nfrom datetime import datetime\n\ncve = pd.read_csv('../input/cve-common-vulnerabilities-and-exposures/cve.csv', header=0, index_col=0)\nproducts = pd.read_csv('../input/cve-common-vulnerabilities-and-exposures/products.csv', header=0, index_col=0)\nvendors = pd.read_csv('../input/cve-common-vulnerabilities-and-exposures/vendors.csv', header=0, index_col=0)\n\ncve.pub_date = pd.to_datetime(cve.pub_date)\nnpr.seed(42)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"vc = products.vulnerable_product.value_counts()\nvc = vc[vc.values >= 256]\n\ndef get_ccf(p):\n    times = products[products.vulnerable_product == p].join(cve.pub_date).pub_date.sort_values().dropna()\n    delay = (times.to_numpy()[1:] - times.to_numpy()[:-1]).astype('timedelta64[D]').astype('float')\n    return np.corrcoef(pd.to_numeric(times[:-1]), delay)[0,1]\n\nccf = pd.Series(vc.index.map(get_ccf), index=vc.index).sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 0. Overview\n\nTime series data provides an ordering for list entries. This ordering allows us to analyze features as an ordered 1-D array. Histograms are a data summary that breaks one dimensional data into K distinct buckets. By breaking up data according to time, we can identify key points in time where a variable underwent large scale, sustained change.\n\nNOTE: Histograms, as defined here, can (and usually do) have variable width buckets"},{"metadata":{},"cell_type":"markdown","source":"# 1. A Naive Algorithm, Dynamic Programming\n\nV-optimality is a condition that states that the optimal K-bucket histogram has the minimum cumulative weighted variance across all K buckets. A O(n²k) dynamic programming solution first precomputes the variance of all possible intervals."},{"metadata":{"trusted":true},"cell_type":"code","source":"def v_optimal_dp(X, K=2):\n    # Precompute subinterval variance\n    N = len(X)\n    cost = [[np.std(X[i:j]) for i in range(j)] for j in range(1,N+1)]\n    \n    # Naive-DP solution in O(n²k) time\n    d = np.full((len(X), K+1), np.inf)\n    src = np.full((len(X), K+1), -1)\n    d[0][0] = 0.\n    for k in range(K+1):\n        for j in range(N):\n            for i in range(j):\n                d[j][k] = min(d[j][k], d[i][k-1] + cost[j][i+1])\n                if d[j][k] == d[i][k-1] + cost[j][i+1]:\n                    src[j][k] = i\n                    \n    # Backtracking\n    cur = N - 1\n    bp = [0,N]\n    for k in range(K,1,-1):\n        bp.append(src[cur][k])\n        cur = src[cur][k]\n        \n    return sorted(bp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def variable_width_distplot_factory(X, cats, bins, text, y=[]):\n    # X - the data\n    # cats - a list of pd.Interval where \n    #       left is the index of the left data point\n    #       and right is the index of the right data point\n    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, row_heights=[600, 100], vertical_spacing=0)\n    N = len(X)\n    \n    for i, cat in enumerate(cats):\n        l = X[min(cat.right, N-1)] - X[min(cat.left, N-1)]\n        x = [X[min(cat.left, N-1)] + l/2]\n        fig.add_trace(go.Bar(\n                x=x,\n                y=[len(X[bins == cat])] if len(y) == 0 else [y[i]],\n                width=l if not type(l) == pd.Timedelta else l.total_seconds() * 1000,\n                marker=dict(color=\"#cccccc\"),\n                text=\"{}\".format(len(X[bins == cat]) if len(y) == 0 else y[i]),\n                textposition='outside',\n                name='',\n                cliponaxis=False\n            ),\n            row=1,\n            col=1\n        )\n    \n    fig.add_trace(go.Scatter(\n            x=X,\n            y=np.ones(N),\n            mode='markers',\n            marker=dict(\n                color=\"#586e75\"\n            ),\n            text=text,\n            name=\"\"\n        ),\n        row=2,\n        col=1,\n    )\n    \n    fig.update_layout(\n        \n        xaxis=dict(\n            showgrid=False\n        ),\n        yaxis=dict(\n            showgrid=False,\n            showticklabels=False\n        ),\n        yaxis2=dict(\n            showgrid=False,\n            showticklabels=False\n        ),  \n        showlegend=False,\n        paper_bgcolor='rgba(0,0,0,0)',\n        plot_bgcolor='rgba(0,0,0,0)',\n        bargap=0.,\n        font=dict(\n            family=\"Arial\",\n            size=14,\n            color=\"#586e75\"\n        )\n    )\n    \n    return fig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"X = ccf.sort_values().reindex()\nbps = v_optimal_dp(X, K=6)\nbins = pd.cut(pd.Index(np.arange(len(X))), bps, include_lowest=True, right=False)\ncats = bins.categories\n\nfig = variable_width_distplot_factory(X, cats, bins, ccf.index)\n\nfig.update_layout(\n    title=dict(\n        text=\"How delay correlates with time\",\n        xref=\"paper\",\n        x=0., y=1.\n    ),\n    annotations = [\n        dict(\n            xref='paper',\n            yref='paper',\n            x=0., y=1.2,\n            showarrow=False,\n            text ='This is a V-optimal histogram with 6 buckets for the correlation coefficient between delay (the time between CVE entries)' + \n            '<br>and time for the top-50 products. Lower values indicate that the number of exploits increases as time goes on;<br>' +\n            'higher values indicate the opposite.',\n            valign='top',\n            align='left'\n        )\n    ]\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Approximation 1: Exponentially-distributed data\nFor exponentially distributed data, we can use the approximation from "},{"metadata":{"trusted":true},"cell_type":"code","source":"def approx_histogram_expon(a):\n    # Segmentation approximation for exponentially distributed time series\n    bp = [0,1]\n    for i in range(2, len(a)):\n        if np.mean(a[bp[-2]:bp[-1]]) < np.mean(a[bp[-1]:i]):\n            while len(bp) > 1 and np.mean(a[bp[-2]:bp[-1]]) < np.mean(a[bp[-1]:i]):\n                bp.pop()\n        bp.append(i)\n    bp.append(len(a))\n    return np.array(bp)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ps = ['android', 'internet_explorer', 'windows_xp']\nfor product, title in zip(ps, map(lambda x: ' '.join([s.title() if len(s) > 2 else s.upper() for s in x.split('_')]), ps)):\n    # Delay\n    p = pd.to_datetime(products[products.vulnerable_product == product].join(cve.pub_date).pub_date.sort_values().dropna())\n    X = (p.iloc[1:].values - p.iloc[:-1].values).astype('timedelta64[m]')\n\n    # Exponential segmentation\n    bps = approx_histogram_expon(X)\n    bins = pd.cut(pd.Index(np.arange(len(X))), bps, include_lowest=True, right=False)\n    cats = bins.categories\n    ys = np.array([np.mean(X[bins==cat]) for cat in cats])\n    \n    fig = variable_width_distplot_factory(p.iloc[:-1], cats, bins, p.index[:-1], np.round(ys.astype('float')/60/24, 2))\n    fig.update_layout(\n        title=title + \" delay segmentation\",\n        yaxis=dict(type='log', showticklabels=True, title='Average Delay (in days)', dtick=1)\n    )\n    fig.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}