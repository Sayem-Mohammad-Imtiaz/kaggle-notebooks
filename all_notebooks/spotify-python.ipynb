{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","collapsed":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nsongs = pd.read_csv(\"../input/data.csv\")\n# Drop the numberings, song_title and artist(there are 1343 unique artists out of 2017 songs, the size of the dataset is not large enough to analyze this user's preferences to different artists)\nsongs=songs.drop(columns=['Unnamed: 0', 'song_title', 'artist']).reset_index(drop=True)","execution_count":1,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8062035582228e22284b07919bf6c1ce6674b4f1"},"cell_type":"code","source":"from pandas.plotting import scatter_matrix\nscatter_matrix(songs, alpha=0.2, figsize=(20,20), diagonal='kde')\nsongs.corr(method='pearson', min_periods=1)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c4d50bbf-ed1a-41a3-861a-1b5c38b08e45","_uuid":"17cd1588593ae6175fae6bb671fb6b8150cb5e6a","trusted":true,"collapsed":true},"cell_type":"code","source":"# From the plot and the correlations we can see that the parameter \"energy\" is highly correlated with both \"acousticness\" and \"loudness\"\n# Thus the latter two parameters should be removed in order to avoid the problem of overfitting\nsongs=songs.drop(columns=['acousticness','loudness'])\n\n# The parameter \"key\", \"mode\" are presented as integer, however, they should be defined as unordered categories.\nsongs['key'] = songs['key'].astype('category')\nsongs['mode'] = songs['mode'].astype('category')\nsongs_tree = songs.copy()","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Method1 ANN\n# we should encode the categorical variable as a series of dummy variables.\nsongs = pd.get_dummies(songs)\n\n# split the dataset into train and test\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nX = songs.drop(columns=['target'])\nY = songs['target']\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3,random_state=2017)\ncolname=X_train.columns\n\n# standardization\nscaler = preprocessing.StandardScaler().fit(X_train)\nX_train = pd.DataFrame(scaler.transform(X_train))\nX_test = pd.DataFrame(scaler.transform(X_test))\nY_train = Y_train.reset_index(drop=True)\nY_test = Y_test.reset_index(drop=True)\nX_train.columns = colname\nX_test.columns = colname","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"a5371d85-cbc1-42d8-98da-47cf405588aa","_uuid":"fbce5b33b13607730b5279949e50c7e0c8dcb239","trusted":true},"cell_type":"code","source":"# use 5-fold cv to decide the number of hidden units in each layer (Let set alpha to be 0.06, in order to reduce the number of models we fit to the training dataset)\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nkf = KFold(n_splits=5)\nscores = pd.DataFrame(0, index=np.arange(5), columns=['(12,8)','(12,7)','(12,6)','(12,5)','(12,4)'])\nfold=0\nfor train_index, test_index in kf.split(X_train):\n    train = X_train.iloc[train_index]\n    train_target = Y_train[train_index]\n    test = X_train.iloc[test_index]\n    test_target = Y_train[test_index]\n    \n    #Fit the models\n    clf0 = MLPClassifier(hidden_layer_sizes=(12,8),activation='logistic', solver='adam', alpha=0.06, max_iter=400)\n    clf0.fit(train,train_target)\n    scores.iloc[fold,0]=clf0.score(test,test_target)\n    \n    clf1 = MLPClassifier(hidden_layer_sizes=(12,7),activation='logistic', solver='adam', alpha=0.06, max_iter=400)\n    clf1.fit(train,train_target)\n    scores.iloc[fold,1]=clf1.score(test,test_target)\n    \n    clf2 = MLPClassifier(hidden_layer_sizes=(12,6),activation='logistic', solver='adam', alpha=0.06, max_iter=400)\n    clf2.fit(train,train_target)\n    scores.iloc[fold,2]=clf2.score(test,test_target)\n    \n    clf3 = MLPClassifier(hidden_layer_sizes=(12,5),activation='logistic', solver='adam', alpha=0.06, max_iter=400)\n    clf3.fit(train,train_target)\n    scores.iloc[fold,3]=clf3.score(test,test_target)\n    \n    clf4 = MLPClassifier(hidden_layer_sizes=(12,4),activation='logistic', solver='adam', alpha=0.06, max_iter=400)\n    clf4.fit(train,train_target)\n    scores.iloc[fold,4]=clf4.score(test,test_target)\n    \n    fold=fold+1\n\nprint(scores.mean(axis=0))\n\n# From the scores we can see that the neural network with 2 layers, with 12 and 4 hidden units produce the highest prediction accuracy","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"6135a02f-3b0b-4cab-bc65-f33ffa85c117","_uuid":"e9ef9eb6df423ff878f9820a6c10981da30c2bc8","trusted":true},"cell_type":"code","source":"# Now fit the model to the entire training dataset\nclf = MLPClassifier(hidden_layer_sizes=(12,4),activation='logistic', solver='adam', alpha=0.06, max_iter=400)\nclf.fit(X_train, Y_train)\npredictions=clf.predict(X_test)\nscore = clf.score(X_test,Y_test)\nprint(\"The prediction accuracy is:\", score)\nprint(confusion_matrix(Y_test,predictions))\n\n#The prediction accuracy is relatively low, which might be due to the use of inappropriate number of hidden layers, hidden units and alpha, since only a few models were trained in order to save computational effort.\n#In addition, all the models that were fitted to our dataset are fully connected, ANN with other structure might be able to produce more accurate predictions.","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"4b87911ca0ebe749a423531a3008d24f2c1c9624","_cell_guid":"d1b78f50-8cf5-4381-a79d-e9d518736aa6","trusted":true},"cell_type":"code","source":"# Method 2 Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\n# split the dataset into train and test\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nX = songs_tree.drop(columns=['target'])\nY = songs_tree['target']\nX_tree_train, X_tree_test, Y_tree_train, Y_tree_test = train_test_split(X,Y,test_size=0.3,random_state=2017)\n\nclf_tree = RandomForestClassifier(n_estimators=50,criterion='gini',bootstrap=True)\nclf_tree.fit(X_tree_train,Y_tree_train)\npredictions_tree = clf_tree.predict(X_tree_test)\n\nimportances=pd.DataFrame(clf_tree.feature_importances_,index=X.columns,columns=['importances']).sort_values(by=['importances'],ascending=False)\nprint(importances)\nprint(confusion_matrix(Y_tree_test,predictions_tree))\nprint(\"The prediction accuracy is:\", clf_tree.score(X_tree_test,Y_tree_test))","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"cbb7ae2fe945dd3aaa72588719f43a5dcae335a7","_cell_guid":"eccab88e-6173-4e13-b624-ace78ff284f7","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}