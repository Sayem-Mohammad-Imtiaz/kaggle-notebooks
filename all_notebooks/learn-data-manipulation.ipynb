{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data Manipulation with Pandas\n\nPandas is the most widely used library of python for data science. It is incredibly helpful in manipulating the data so that you can derive better insights and build great machine learning models.\n\nIn this notebook, we will have a look at some of the intermediate concepts of working with pandas.\n\n\n## Table of Contents\n\n1. Sorting dataframes\n2. Merging dataframes\n\n### Loading dataset\n\n***In this notebook we will use the Big Mart Sales Data. You can download the data from : https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/download/train-file*** "},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# read the dataset\ndata_BM = pd.read_csv('../input/big-mart-sales/train_v9rqX0R.csv')\n# drop the null values\ndata_BM = data_BM.dropna(how=\"any\")\n# view the top results\ndata_BM.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. Sorting dataframes\n\nPandas data frame has two useful functions\n\n- **sort_values()**: to sort pandas data frame by one or more columns\n- **sort_index()**: to sort pandas data frame by row index\n\nEach of these functions come with numerous options, like sorting the data frame in specific order (ascending or descending), sorting in place, sorting with missing values, sorting by specific algorithm etc.\n\nSuppose you want to sort the dataframe by \"Outlet_Establishment_Year\" then you will use **sort_values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort by year\nsorted_data = data_BM.sort_values(by='Outlet_Establishment_Year')\n# print sorted data\nsorted_data[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Now `sort_values` takes multiple options like:\n    - `ascending`: The default sorting order is ascending, when you pass False here then it sorts in descending order.\n    - `inplace`: whether to do inplace sorting or not"},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort in place and descending order\ndata_BM.sort_values(by='Outlet_Establishment_Year', ascending=False, inplace=True)\ndata_BM[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You might want to sort a data frame based on the values of multiple columns. \nWe can specify the columns we want to sort by as a list in the argument for sort_values().\n"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# read the dataset\ndata_BM = pd.read_csv('../input/big-mart-sales/train_v9rqX0R.csv')\n# drop the null values\ndata_BM = data_BM.dropna(how=\"any\")\n\n# sort by multiple columns\ndata_BM.sort_values(by=['Outlet_Establishment_Year', 'Item_Outlet_Sales'], ascending=False)[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Note that when sorting by multiple columns, pandas sort_value() uses the first variable first and second variable next. \n- We can see the difference by switching the order of column names in the list."},{"metadata":{"trusted":true},"cell_type":"code","source":"# changed the order of columns\ndata_BM.sort_values(by=['Item_Outlet_Sales', 'Outlet_Establishment_Year'], ascending=False, inplace=True)\ndata_BM[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We can use **sort_index()** to sort pandas dataframe to sort by row index or names. \n- In this example, row index are numbers and in the earlier example we sorted data frame by 'Item_Outlet_Sales', 'Outlet_Establishment_Year' and therefore the row index are jumbled up. \n- We can sort by row index (with inplace=True option) and retrieve the original dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort by index\ndata_BM.sort_index(inplace=True)\ndata_BM[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Merging dataframes\n\n- Joining and merging DataFrames is the core process to start with data analysis and machine learning tasks. \n- It is one of the toolkits which every Data Analyst or Data Scientist should master because in almost all the cases data comes from multiple source and files.\n- Pandas has two useful functions for merging dataframes:\n    - **concat()**\n    - **merge()** \n    \n#### Creating dummy data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create dummy data\ndf1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n                     'B': ['B0', 'B1', 'B2', 'B3'],\n                     'C': ['C0', 'C1', 'C2', 'C3'],\n                     'D': ['D0', 'D1', 'D2', 'D3']},\n                    index=[0, 1, 2, 3])\n \n\ndf2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n                     'B': ['B4', 'B5', 'B6', 'B7'],\n                     'C': ['C4', 'C5', 'C6', 'C7'],\n                     'D': ['D4', 'D5', 'D6', 'D7']},\n                    index=[4, 5, 6, 7])\n \n\ndf3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n                     'B': ['B8', 'B9', 'B10', 'B11'],\n                     'C': ['C8', 'C9', 'C10', 'C11'],\n                     'D': ['D8', 'D9', 'D10', 'D11']},\n                    index=[8, 9, 10, 11])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### a. concat() for combining dataframes\n- Suppose you have the following three dataframes: df1, df2 and df3 and you want to combine them **\"row-wise\"** so that they become a single dataframe like the given image:\n![](concat_1_a.png)\n- You can use **concat()** here. You will have to pass the names of the DataFrames in a list as the argument to the concat(). "},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine dataframes\nresult = pd.concat([df1, df2, df3])\nresult","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- pandas also provides you with an option to label the DataFrames, after the concatenation, with a key so that you may know which data came from which DataFrame.\n- You can achieve the same by passing additional argument **keys** specifying the label names of the DataFrames in a list."},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine dataframes\nresult = pd.concat([df1, df2, df3], keys=['x', 'y', 'z'])\nresult","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Mentioning the keys also makes it easy to retrieve data corresponding to a particular DataFrame. \n- You can retrieve the data of DataFrame df2 which had the label `y` by using the `loc` method."},{"metadata":{"trusted":true},"cell_type":"code","source":"# get second dataframe\nresult.loc['y']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- When gluing together multiple DataFrames, you have a choice of how to handle the other axes (other than the one being concatenated). This can be done in the following three ways:\n\n    - Take the union of them all, `join='outer'`. This is the default option as it results in zero information loss.\n    - Take the intersection, `join='inner'`.\n    - Use a specific index, as passed to the `join_axes` argument.\n\n- Here is an example of each of these methods. First, the default `join='outer'` behavior:\n![](concat_2.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df4 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],\n                        'D': ['D2', 'D3', 'D6', 'D7'],\n                        'F': ['F2', 'F3', 'F6', 'F7']},\n                       index=[2, 3, 6, 7])\n    \n\nresult = pd.concat([df1, df4], axis=1, sort=False)\nresult","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Here is the same thing with `join='inner'`:\n![](concat_3.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.concat([df1, df4], axis=1, join='inner')\nresult","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Lastly, suppose we just wanted to `reuse the exact index` from the original DataFrame:\n![](concat_4.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.concat([df1, df4], axis=1)\nresult = result.reindex(df1.index)\nresult","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### b. merge() for combining dataframes using SQL like joins\n\n- Another ubiquitous operation related to DataFrames is the merging operation. \n- Two DataFrames might hold different kinds of information about the same entity and linked by some common feature/column.\n- We can use **merge()** to combine such dataframes in pandas.\n\n#### Creating dummy data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create dummy data\ndf_a = pd.DataFrame({\n        'subject_id': ['1', '2', '3', '4', '5'],\n        'first_name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'], \n        'last_name': ['Anderson', 'Ackerman', 'Ali', 'Aoni', 'Atiches']})\n\ndf_b = pd.DataFrame({\n        'subject_id': ['4', '5', '6', '7', '8'],\n        'first_name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'], \n        'last_name': ['Bonder', 'Black', 'Balwner', 'Brice', 'Btisan']})\n\ndf_c = pd.DataFrame({\n        'subject_id': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11'],\n        'test_id': [51, 15, 15, 61, 16, 14, 15, 1, 61, 16]})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now these are our dataframes:\n![](merge_4.png)\n\n- Let's start with a basic join, we want to combine `df_a` with `df_c` based on the `subject_id` column."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.merge(df_a, df_c, on='subject_id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Now that we have done a basic join, let's get into **some commmon SQL joins.**\n\n#### Merge with outer join\n\n- “Full outer join produces the set of all records in Table A and Table B, with matching records from both sides where available. If there is no match, the missing side will contain null.”\n![](merge_8.png)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.merge(df_a, df_b, on='subject_id', how='outer')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Merge with inner join\n\n- “Inner join produces only the set of records that match in both Table A and Table B.”\n![](merge_5.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.merge(df_a, df_b, on='subject_id', how='inner')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Merge with right join\n\n- “Right outer join produces a complete set of records from Table B, with the matching records (where available) in Table A. If there is no match, the left side will contain null.”\n\n![](merge_7.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.merge(df_a, df_b, on='subject_id', how='right')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Merge with left join\n\n- “Left outer join produces a complete set of records from Table A, with the matching records (where available) in Table B. If there is no match, the right side will contain null.”\n![](merge_6.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.merge(df_a, df_b, on='subject_id', how='left')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Merge OR Concat : Which to use when?\n\n1. After learning both of the functions in detail, chances are that you might be confused which to use when. \n2. One major difference is that `merge()` is used to combine dataframes on the basis of values of **common columns**. While`concat()` is used to **append dataframes** one below the other (or sideways, depending on whether the axis option is set to 0 or 1).\n3. Exact usage depends upon the kind of data you have and analysis you want to perform."},{"metadata":{},"cell_type":"markdown","source":"# Binning in Pandas\n\n**When dealing with continuous numeric data, it is often helpful to bin the data into multiple buckets for further analysis. There are several different terms for binning including bucketing, discrete binning and discretization.\nPandas supports these approaches using the cut and function. In this section you will learn how to use the pandas functions to convert continuous data to a set of discrete buckets.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ages = pd.DataFrame({'age': np.random.randint(21, 51, 8)})\ndf_ages","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ages['age_bins'] = pd.cut(x=df_ages['age'], bins=[20, 29, 39, 49])\ndf_ages\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ages['age_bins'].unique()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ages['age_by_decade'] = pd.cut(x=df_ages['age'], bins=[20, 29, 39, 49], labels=['20s', '30s', '40s'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ages","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}