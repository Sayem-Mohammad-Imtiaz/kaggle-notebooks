{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Product Category Prediction\n\n##### Hi, \n###### Welcome to this repository! The objective of this repository is to best understand Naive Bayes . The data used in this repo has been taken from Kaggle (link below). \nhttps://www.kaggle.com/PromptCloudHQ/flipkart-products\n\n\n### About project Mechanic of Machine Learning:\nI am a mechanical engineer by education. Now, I want to deep dive in the world of Machine Learning, hence the name, mechanic of ML :D. I have taken up this project to understand the in-depth mathematics involved in regularly used ML algorithms. Under this project, I will be sharing useful material and links as I explore this domain. The objective is to learn and spread the same. Stay tuned to my GitHub for updates!\n\n### Business Case: \nAn online retailer wants to classify data based on description provided by seller. Generate a model to facilitate this ask. \n### Notebook objectives:\n* To understand and implement naive bayes \n\n\n### Assumptions:\n\n* Only five category data is considered from the total set \n\n### References:\n* GDA and NB: https://www.youtube.com/watch?v=nt63k3bfXS0\n* NB: https://www.youtube.com/watch?v=O2L2Uv9pdDA\n* Gaussian NB:https://www.youtube.com/watch?v=H3EjCKtlVog\n* Building NB from scratch: https://towardsdatascience.com/na%C3%AFve-bayes-from-scratch-using-python-only-no-fancy-frameworks-a1904b37222d\n* Notes and source code: https://github.com/ArindamRoy23/Product-Prediction_GDA-NB_Mechanic-of-ML\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nImporting packages\n\n'''\n\n\nimport numpy as np \nimport pandas as pd \nimport re \nimport nltk \nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import classification_report\nfrom sklearn.feature_extraction.text import TfidfVectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef preprocess_string(str_arg):\n    '''\n    input: str_arg --> Takes string to clean\n    output: cleaned_str --> Gives back cleaned string\n    This fuction cleans the text in the mentioned ways as comments after the line.This has been copied from some other kernel.\n\n    '''\n    cleaned_str=re.sub('[^a-z\\s]+',' ',str_arg,flags=re.IGNORECASE) #every char except alphabets is replaced\n    cleaned_str=re.sub('(\\s+)',' ',cleaned_str) #multiple spaces are replaced by single space\n    cleaned_str=cleaned_str.lower() #converting the cleaned string to lower case\n    \n    return cleaned_str # Returning the preprocessed string in tokenized form","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nThis code block is for reading and cleaning data.\n\n'''\nimport_df = pd.read_csv('../input/flipkart-products/flipkart_com-ecommerce_sample.csv')\n# Reading relevant data\nimport_df['product_category_tree'] = import_df['product_category_tree'].apply(lambda x : x.split('>>')[0][2:].strip())\n# Category processing. (Check data to understand)\ntop_fiv_gen = list(import_df.groupby('product_category_tree').count().sort_values(by='uniq_id',ascending=False).head(5).index)\n# Taking only top 5 categories for example sake\nprocessed_df = import_df[import_df['product_category_tree'].isin(top_fiv_gen)][['product_category_tree','description']]\n# Selecting only relevant columns\nprocessed_df['description'] = processed_df['description'].astype('str').apply(preprocess_string)\n# Cleaning strings\ncat_list = list(processed_df['product_category_tree'].unique())\n# Creating a list of categories for later use\nprint(cat_list)\n# Printing the list of top 5 categories\nle = preprocessing.LabelEncoder()\ncategory_encoded=le.fit_transform(processed_df['product_category_tree'])\nprocessed_df['product_category_tree'] = category_encoded\n# Encoding the product category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nThis code block is for spliting train test data\n\n'''\nX_train, X_test, y_train, y_test = train_test_split(processed_df['description'],processed_df['product_category_tree'],test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nThis code block is for converting the training data to vectorized form\n\n'''\nvect = CountVectorizer(stop_words = 'english')\n# Removing stop words\nX_train_matrix = vect.fit_transform(X_train) \n# Converting the train data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nThis code block is for training vectorized data and predicting & scoring test data\n\n'''\nclf=MultinomialNB()\n# Defining model\nclf.fit(X_train_matrix, y_train)\n# Fitting to multinomial NB model \nprint(clf.score(X_train_matrix, y_train))\n# Scoring the trained model (Expected to be above 95 percent)\nX_test_matrix = vect.transform(X_test) \n# Converting the test data\nprint (clf.score(X_test_matrix, y_test))\n# Scoring for the test data\npredicted_result=clf.predict(X_test_matrix)\nprint(classification_report(y_test,predicted_result))\n# Printing score ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nThis code block is for converting the training data to Tf-Idf form\n\n'''\nvectorizer = TfidfVectorizer(stop_words = 'english')\n# Removing stop words\nX_train_tfidf = vectorizer.fit_transform(X_train)\n# Converting the train data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nThis code block is for training, predicting & scoring test data\n\n'''\nclf2=MultinomialNB()\n# Defining model\nclf2.fit(X_train_tfidf, y_train)\n# Fitting to multinomial NB model \nprint(clf2.score(X_train_tfidf, y_train))\n# Scoring the trained model (Expected to be above 95 percent)\nX_test_tfidf = vectorizer.transform(X_test) \n# Converting the test data\nprint (clf2.score(X_test_tfidf, y_test))\n# Printing score ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nTesting Block: Test your sting. Replace the 'car' string to test\n'''\nle.inverse_transform(clf.predict(vect.transform(['car'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion \n Naive Bayes works very well for this data set with an above 99% accuracy. This is a business ready model to deploy. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}