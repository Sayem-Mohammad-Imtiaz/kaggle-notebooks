{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the DataSet","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The dataset we are using for Emotion Detection for Facial Expressions is \"FER2013\"  ","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot\nimport scipy.misc \nfrom math import sqrt \nimport itertools\nfrom IPython.display import display\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loading the dataset\ndata= pd.read_csv('../input/facial-expression-recognitionferchallenge/fer2013/fer2013/fer2013.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number of training samples of each emotions\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 15, 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Assigning Names to Emotions in labels\n\nnum_classes = 7\nwidth = 48\nheight = 48\nemotion_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\nclasses=np.array((\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"))\ndata.Usage.value_counts() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualisation of Dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"depth = 1\nheight = int(sqrt(len(data.pixels[0].split()))) \nwidth = int(height)\nfor i in range(0, 10): \n    array = np.mat(data.pixels[i]).reshape(height, width) \n    image = scipy.misc.toimage(array, cmin=0.0) \n    display(image)\n    print(emotion_labels[data.emotion[i]]) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = data[(data.Usage == 'Training')] \nval_set = data[(data.Usage == 'PublicTest')]\ntest_set = data[(data.Usage == 'PrivateTest')] \nX_train = np.array(list(map(str.split, train_set.pixels)), np.float32) \nX_val = np.array(list(map(str.split, val_set.pixels)), np.float32) \nX_test = np.array(list(map(str.split, test_set.pixels)), np.float32) \nX_train = X_train.reshape(X_train.shape[0], 48, 48, 1) \nX_val = X_val.reshape(X_val.shape[0], 48, 48, 1)\nX_test = X_test.reshape(X_test.shape[0], 48, 48, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_train = X_train.shape[0]\nnum_val = X_val.shape[0]\nnum_test = X_test.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train_set.emotion \ny_train = np_utils.to_categorical(y_train, num_classes) \ny_val = val_set.emotion \ny_val = np_utils.to_categorical(y_val, num_classes) \ny_test = test_set.emotion \ny_test = np_utils.to_categorical(y_test, num_classes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image Preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator( \n    rescale=1./255,\n    rotation_range = 10,\n    horizontal_flip = True,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    fill_mode = 'nearest')\n\ntestgen = ImageDataGenerator( \n    rescale=1./255\n    )\ndatagen.fit(X_train)\nbatch_size = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n    for i in range(0, 9): \n        pyplot.axis('off') \n        pyplot.subplot(330 + 1 + i) \n        pyplot.imshow(X_batch[i].reshape(48, 48), cmap=pyplot.get_cmap('gray'))\n    pyplot.axis('off') \n    pyplot.show() \n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_flow = datagen.flow(X_train, y_train, batch_size=batch_size) \nval_flow = testgen.flow(X_val, y_val, batch_size=batch_size) \ntest_flow = testgen.flow(X_test, y_test, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Neural Network Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import plot_model\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam, SGD\nfrom keras.regularizers import l1, l2\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def FER_Model(input_shape=(48,48,1)):\n#     # first input model\n#     visible = Input(shape=input_shape, name='input')\n#     num_classes = 7\n#     #the 1-st block\n#     conv1_1 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_1')(visible)\n#     conv1_1 = BatchNormalization()(conv1_1)\n#     conv1_2 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_2')(conv1_1)\n#     conv1_2 = BatchNormalization()(conv1_2)\n#     pool1_1 = MaxPooling2D(pool_size=(2,2), name = 'pool1_1')(conv1_2)\n#     drop1_1 = Dropout(0.3, name = 'drop1_1')(pool1_1)\n\n#     #the 2-nd block\n#     conv2_1 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_1')(drop1_1)\n#     conv2_1 = BatchNormalization()(conv2_1)\n#     conv2_2 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_2')(conv2_1)\n#     conv2_2 = BatchNormalization()(conv2_2)\n#     conv2_3 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_3')(conv2_2)\n#     conv2_2 = BatchNormalization()(conv2_3)\n#     pool2_1 = MaxPooling2D(pool_size=(2,2), name = 'pool2_1')(conv2_3)\n#     drop2_1 = Dropout(0.3, name = 'drop2_1')(pool2_1)\n\n#      #the 3-rd block\n#     conv3_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_1')(drop2_1)\n#     conv3_1 = BatchNormalization()(conv3_1)\n#     conv3_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_2')(conv3_1)\n#     conv3_2 = BatchNormalization()(conv3_2)\n#     conv3_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_3')(conv3_2)\n#     conv3_3 = BatchNormalization()(conv3_3)\n#     conv3_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_4')(conv3_3)\n#     conv3_4 = BatchNormalization()(conv3_4)\n#     pool3_1 = MaxPooling2D(pool_size=(2,2), name = 'pool3_1')(conv3_4)\n#     drop3_1 = Dropout(0.3, name = 'drop3_1')(pool3_1)\n\n#     #the 4-th block\n#     conv4_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_1')(drop3_1)\n#     conv4_1 = BatchNormalization()(conv4_1)\n#     conv4_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_2')(conv4_1)\n#     conv4_2 = BatchNormalization()(conv4_2)\n#     conv4_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_3')(conv4_2)\n#     conv4_3 = BatchNormalization()(conv4_3)\n#     conv4_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_4')(conv4_3)\n#     conv4_4 = BatchNormalization()(conv4_4)\n#     pool4_1 = MaxPooling2D(pool_size=(2,2), name = 'pool4_1')(conv4_4)\n#     drop4_1 = Dropout(0.3, name = 'drop4_1')(pool4_1)\n    \n#     #the 5-th block\n#     conv5_1 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_1')(drop4_1)\n#     conv5_1 = BatchNormalization()(conv5_1)\n#     conv5_2 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_2')(conv5_1)\n#     conv5_2 = BatchNormalization()(conv5_2)\n#     conv5_3 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_3')(conv5_2)\n#     conv5_3 = BatchNormalization()(conv5_3)\n#     conv5_4 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_4')(conv5_3)\n#     conv5_3 = BatchNormalization()(conv5_3)\n#     pool5_1 = MaxPooling2D(pool_size=(2,2), name = 'pool5_1')(conv5_4)\n#     drop5_1 = Dropout(0.3, name = 'drop5_1')(pool5_1)\n\n#     #Flatten and output\n#     flatten = Flatten(name = 'flatten')(drop5_1)\n#     ouput = Dense(num_classes, activation='sigmoid', name = 'output')(flatten)\n\n#     # create model \n#     model = Model(inputs =visible, outputs = ouput)\n#     # summary layers\n#     print(model.summary())\n    \n#     return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers.core import Flatten, Dense, Dropout\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\nfrom keras.optimizers import SGD\nfrom keras.optimizers import Adam\nimport cv2, numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def FER_Model(input_shape=(48,48,1)):\n    # first input model\n    visible = Input(shape=input_shape, name='input')\n    num_classes = 7\n    #the 1-st block\n    conv1_1 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_1')(visible)\n    conv1_1 = BatchNormalization()(conv1_1)\n    conv1_2 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_2')(conv1_1)\n    conv1_2 = BatchNormalization()(conv1_2)\n    pool1_1 = MaxPooling2D(pool_size=(2,2), name = 'pool1_1')(conv1_2)\n    drop1_1 = Dropout(0.3, name = 'drop1_1')(pool1_1)\n\n    #the 2-nd block\n    conv2_1 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_1')(drop1_1)\n    conv2_1 = BatchNormalization()(conv2_1)\n    conv2_2 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_2')(conv2_1)\n    conv2_2 = BatchNormalization()(conv2_2)\n    conv2_3 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_3')(conv2_2)\n    conv2_2 = BatchNormalization()(conv2_3)\n    pool2_1 = MaxPooling2D(pool_size=(2,2), name = 'pool2_1')(conv2_3)\n    drop2_1 = Dropout(0.3, name = 'drop2_1')(pool2_1)\n    #the 3-rd block\n    conv3_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_1')(drop2_1)\n    conv3_1 = BatchNormalization()(conv3_1)\n    conv3_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_2')(conv3_1)\n    conv3_2 = BatchNormalization()(conv3_2)\n    conv3_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_3')(conv3_2)\n    conv3_3 = BatchNormalization()(conv3_3)\n    conv3_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_4')(conv3_3)\n    conv3_4 = BatchNormalization()(conv3_4)\n    pool3_1 = MaxPooling2D(pool_size=(2,2), name = 'pool3_1')(conv3_4)\n    drop3_1 = Dropout(0.3, name = 'drop3_1')(pool3_1)\n  #the 4-th block\n    conv4_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_1')(drop3_1)\n    conv4_1 = BatchNormalization()(conv4_1)\n    conv4_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_2')(conv4_1)\n    conv4_2 = BatchNormalization()(conv4_2)\n    conv4_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_3')(conv4_2)\n    conv4_3 = BatchNormalization()(conv4_3)\n    conv4_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_4')(conv4_3)\n    conv4_4 = BatchNormalization()(conv4_4)\n    pool4_1 = MaxPooling2D(pool_size=(2,2), name = 'pool4_1')(conv4_4)\n    drop4_1 = Dropout(0.3, name = 'drop4_1')(pool4_1)\n    #the 5-th block\n    conv5_1 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_1')(drop4_1)\n    conv5_1 = BatchNormalization()(conv5_1)\n    conv5_2 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_2')(conv5_1)\n    conv5_2 = BatchNormalization()(conv5_2)\n    conv5_3 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_3')(conv5_2)\n    conv5_3 = BatchNormalization()(conv5_3)\n    conv5_4 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_4')(conv5_3)\n    conv5_3 = BatchNormalization()(conv5_3)\n    pool5_1 = MaxPooling2D(pool_size=(2,2), name = 'pool5_1')(conv5_4)\n    drop5_1 = Dropout(0.3, name = 'drop5_1')(pool5_1)\n\n    #Flatten and output\n    flatten = Flatten(name = 'flatten')(drop5_1)\n    ouput = Dense(num_classes, activation='softmax', name = 'output')(flatten)\n\n    # create model \n    model = Model(inputs =visible, outputs = ouput)\n    # summary layers\n    print(model.summary())\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def VGG_16():\n#     model = Sequential()\n#     model.add(ZeroPadding2D((1,1),input_shape=(48,48,1)))\n#     model.add(Conv2D(64,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(64,(3, 3), activation='relu'))\n#     model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2),dim_ordering=\"th\"))\n# #     model.add(MaxPooling2D((2,2), strides=(2,2),dim_ordering=\"th\"))\n\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(128,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(128,(3, 3), activation='relu'))\n#   #  model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2),dim_ordering=\"th\"))\n#     model.add(MaxPooling2D((2,2), strides=(2,2),dim_ordering=\"th\"))\n\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(256,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(256,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(256,(3, 3), activation='relu'))\n# #    model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2),dim_ordering=\"th\"))\n#     model.add(MaxPooling2D((2,2), strides=(2,2),dim_ordering=\"th\"))\n\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(512,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(512,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(512,(3, 3), activation='relu'))\n#     model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2),dim_ordering=\"th\"))\n#   #  model.add(MaxPooling2D((2,2), strides=(2,2),dim_ordering=\"th\"))\n\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(512,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(512,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(512,(3, 3), activation='relu'))\n#     model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2),dim_ordering=\"th\"))\n#  #   model.add(MaxPooling2D((2,2), strides=(2,2),dim_ordering=\"th\"))\n\n#     model.add(Flatten())\n#     model.add(Dense(4096, activation='relu'))\n#     model.add(Dropout(0.5))\n#     model.add(Dense(4096, activation='relu'))\n#     model.add(Dropout(0.5))\n#     model.add(Dense(7, activation='softmax'))\n#     return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def VGG_19():\n#     model = Sequential()\n#     model.add(ZeroPadding2D((1,1),input_shape=(48,48,1)))\n#     model.add(Conv2D(64,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(64,(3, 3), activation='relu'))\n#     model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2),dim_ordering=\"th\"))\n# #     model.add(MaxPooling2D((2,2), strides=(2,2),dim_ordering=\"th\"))\n\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(128,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(128,(3, 3), activation='relu'))\n#   #  model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2),dim_ordering=\"th\"))\n#     model.add(MaxPooling2D((2,2), strides=(2,2),dim_ordering=\"th\"))\n\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(256,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(256,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(256,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(256,(3, 3), activation='relu'))\n# #    model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2),dim_ordering=\"th\"))\n#     model.add(MaxPooling2D((2,2), strides=(2,2),dim_ordering=\"th\"))\n\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(512,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(512,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(512,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(512, (3, 3), activation='relu'))\n#     model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2),dim_ordering=\"th\"))\n#   #  model.add(MaxPooling2D((2,2), strides=(2,2),dim_ordering=\"th\"))\n\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(512,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(512,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(512,(3, 3), activation='relu'))\n#     model.add(ZeroPadding2D((1,1)))\n#     model.add(Conv2D(512,(3, 3), activation='relu'))\n#     model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2),dim_ordering=\"th\"))\n#  #   model.add(MaxPooling2D((2,2), strides=(2,2),dim_ordering=\"th\"))\n\n#     model.add(Flatten())\n#     model.add(Dense(4096, activation='relu'))\n#     model.add(Dropout(0.5))\n#     model.add(Dense(4096, activation='relu'))\n#     model.add(Dropout(0.5))\n#     model.add(Dense(7, activation='softmax'))\n#     return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = FER_Model()\n# sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n# opt = Adam(lr=0.0001, decay=1e-6)\nopt = Adam(lr=0.0001, decay=1e-6)\nopt = Adam()\nmodel.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = FER_Model()\n# opt = Adam(lr=0.0001, decay=1e-6)\n# model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\nfilepath=\"weights_min_loss.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we iterate 200 times over the entire training set\nnum_epochs = 50\n# history = model.fit_generator(train_flow, \n#                     steps_per_epoch=len(X_train) / batch_size, \n#                     epochs=num_epochs,  \n#                     verbose=2,  \n#                     callbacks=callbacks_list,\n#                     validation_data=val_flow,  \n#                     validation_steps=len(X_val) / batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(np.array(X_train), np.array(y_train),\n          batch_size=batch_size,\n          epochs=num_epochs,\n          verbose=1,\n          validation_data=(np.array(X_val), np.array(y_val)),\n          shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking the performance of the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('../working/Fer2013_VGG19adam0005.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(y_test, y_pred, classes,\n                          normalize=False,\n                          title='Unnormalized confusion matrix',\n                          cmap=plt.cm.Blues):\n    cm = confusion_matrix(y_test, y_pred)\n    \n    if normalize:\n        cm = np.round(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], 2)\n        \n    np.set_printoptions(precision=2)\n        \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.min() + (cm.max() - cm.min()) / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True expression')\n    plt.xlabel('Predicted expression')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_ = model.predict(X_test, verbose=1)\ny_pred = np.argmax(y_pred_, axis=1)\nt_te = np.argmax(y_test, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plot_confusion_matrix(y_test=t_te, y_pred=y_pred,\n                      classes=classes,\n                      normalize=True,\n                      cmap=plt.cm.Greys,\n                      title='Average accuracy: ' + str(np.sum(y_pred == t_te)/len(t_te)) + '\\n')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}