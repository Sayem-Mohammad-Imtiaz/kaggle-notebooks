{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Content\n\nThis dataset contains Measured/Calculated wave parameters. Measured and derived wave data from data collected by oceanographic wave measuring buoys anchored at Mooloolaba. Coverage period: 30 months.\n\n### Acknowledgements\n\nThis data comes from Queensland Government Data - https://data.qld.gov.au/dataset.\n\n* Date/Time: Date\n* Hs: Significant wave height, an average of the highest third of the waves in a record\n* Hmax: The maximum wave height in the record\n* Tz: The zero upcrossing wave period\n* Tp: The peak energy wave period\n* Peak Direction: Direction (related to true north) from which the peak period waves are coming from\n* SST: Approximation of sea surface temperature"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import warning\n# warning.filterwarnings('ignore')\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.keras as K\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import optimize, signal, interpolate\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.listdir('/kaggle/input/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf = pd.read_csv('/kaggle/input/Coastal Data System - Waves (Mooloolaba) 01-2017 to 06 - 2019.csv')\ndf.head()\n# df.info","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var = np.array(df['SST'])\n# plt.plot(var)\ntime = np.arange(len(var))\nvar[np.where(var<-90)] = np.nan\n# sst = np.ma.masked_where(var < -90, var)\n# print(~np.isnan(var),var[-3:])\ntry:\n    sst = interpolate.interp1d(time[~np.isnan(var)], var[~np.isnan(var)], time)\nexcept:\n    for _ in range(len(var)):\n        if np.isnan(var[_]):\n            if _ < 20:\n                var[_] = np.nanmean(var[:_+20])\n            else:\n                var[_] = np.nanmean(var[_-20:_+20])\n    \n    sst = var\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"split_time = round(len(var) * 0.8 / 1000) * 1000\nprint(split_time)\nvar[np.where(var < -90)] = np.nan\nsst = var\n\ntime_train = time[:split_time]\nx_train = sst[:split_time]\ntime_valid = time[split_time:]\nx_valid = sst[split_time:]\nplt.figure(figsize=(10, 6))\nplt.plot(time_train, x_train)\nplt.show()\n\nplt.figure(figsize=(10, 6))\nplt.plot(time_valid, x_valid)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n  dataset = tf.data.Dataset.from_tensor_slices(series)\n  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n  dataset = dataset.batch(batch_size).prefetch(1)\n  return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"window_size = 20\nbatch_size = 32\nshuffle_buffer_size = 1000\n\ndataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(100, input_shape=[window_size], activation=\"relu\"), \n    tf.keras.layers.Dense(10, activation=\"relu\"), \n    tf.keras.layers.Dense(1)\n])\n\nmodel.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(lr=1e-6, momentum=0.9), metrics=['mean_squared_error'])\n# model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(lr=0.2, momentum=0.9), metrics=['accuracy'])\nhistory = model.fit(dataset,epochs=20,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast = []\nfor _ in range(len(sst) - window_size):\n  forecast.append(model.predict(sst[_:_ + window_size][np.newaxis]))\n\nforecast = forecast[split_time-window_size:]\nresults = np.array(forecast)[:, 0, 0]\n\n\nplt.figure(figsize=(10, 6))\n\nplt.plot(time_valid, x_valid, color='#00FFFF')\nplt.plot(time_valid, results, color='#FF69B4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import pearsonr\n# covariance = np.cov(x_valid, results)\ncorr, _ = pearsonr(x_valid, results)\nprint(corr,_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nacc=history.history['mean_squared_error']\nloss=history.history['loss']\nepochs=range(len(acc)) # Get number of epochs\n\n\n\nplt.plot(epochs, loss, 'r', \"Training loss\")\nplt.title('Training and validation loss')\nplt.ylim([0.03,0.06])\nplt.figure()\n# print(loss)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### define seasonality\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def linf(x,a,b):\n    return a * x + b\nparamsl,params_covariance = optimize.curve_fit(linf, time, sst , maxfev = 10000)\nbaseline = linf(np.arange(len(var)), paramsl[0], paramsl[1]) ;\n\ndef func(x, a, b, c, d):\n    return a * (np.sin(b * x * np.pi/(360*24*2) + c)) + d\n\n# Para = leastsq(error, p0, args=(x, y), maxfev=500000)\nparams,params_covariance = optimize.curve_fit(func, time, sst - baseline, maxfev = 10000)\n\n\nplt.figure(figsize=(10,4))\nplt.plot(np.arange(len(var)),sst - baseline,color='#00FFFF')\n# plt.plot(np.arange(len(var)),baseline,color='#00FFFF')\nplt.plot(func(time, params[0], params[1], params[2], params[3]),\n         color='#FF69B4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nremove_ssn = sst - linf(np.arange(len(var)), paramsl[0], paramsl[1]) \\\n            - func(np.arange(len(var)), params[0], params[1], params[2], params[3])\n\ntime_train = time[:split_time]\nx_train = remove_ssn[:split_time]\ntime_valid = time[split_time:]\nx_valid = remove_ssn[split_time:]\nplt.figure(figsize=(10, 6))\nplt.plot(time_train, x_train)\nplt.show()\n\nplt.figure(figsize=(10, 6))\nplt.plot(time_valid, x_valid)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"window_size = 20\nbatch_size = 32\nshuffle_buffer_size = 1000\n\ndataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(100, input_shape=[window_size], activation=\"relu\"), \n    tf.keras.layers.Dense(10, activation=\"relu\"), \n    tf.keras.layers.Dense(1)\n])\n\nmodel.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(lr=1e-6, momentum=0.9), metrics=['mean_squared_error'])\n# model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(lr=0.2, momentum=0.9), metrics=['accuracy'])\nhistory = model.fit(dataset,epochs=20,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast = []\nfor _ in range(len(sst) - window_size):\n  forecast.append(model.predict(remove_ssn[_:_ + window_size][np.newaxis]))\n\nforecast = forecast[split_time-window_size:]\nresults = np.array(forecast)[:, 0, 0]\n\n\nplt.figure(figsize=(10, 6))\n\nplt.plot(time_valid, x_valid, color='#00FFFF')\nplt.plot(time_valid, results, color='#FF69B4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# covariance = np.cov(x_valid, results)\ncorr, _ = pearsonr(x_valid, results)\nprint(corr, _)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc=history.history['mean_squared_error']\nloss=history.history['loss']\nepochs=range(len(acc)) # Get number of epochs\n\n\n\nplt.plot(epochs, loss, 'r', \"Training loss\")\nplt.title('Training and validation loss')\nplt.ylim([0.02,0.2])\nplt.figure()\n# print(loss)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n\nIt seems the simplest model can predict the SST, but we can not find the physical reasons.\n\nfurther more, It seems the result almost the same whether trend and seasonality were removed or not"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}