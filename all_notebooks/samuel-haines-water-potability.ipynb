{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Welcome! My name is Samuel Haines and I will be creating a model to predict whether or not a certain body of water is safe for human consumption using nine different features. The link to this dataset as well as a further description about the features is here https://www.kaggle.com/adityakadiwal/water-potability.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Visualizations Libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly\nimport plotly.offline as pyo\nimport plotly.express as px\nimport plotly.graph_objs as go\npyo.init_notebook_mode()\nimport plotly.figure_factory as ff\nimport missingno as msno\ncolors_blue = [\"#132C33\", \"#264D58\", '#17869E', '#51C4D3', '#B4DBE9']\ncolors_dark = [\"#1F1F1F\", \"#313131\", '#636363', '#AEAEAE', '#DADADA']\ncolors_green = ['#01411C','#4B6F44','#4F7942','#74C365','#D0F0C0']\nsns.palplot(colors_blue)\nsns.palplot(colors_green)\nsns.palplot(colors_dark)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-27T21:06:40.40441Z","iopub.execute_input":"2021-07-27T21:06:40.40479Z","iopub.status.idle":"2021-07-27T21:06:40.820011Z","shell.execute_reply.started":"2021-07-27T21:06:40.404758Z","shell.execute_reply":"2021-07-27T21:06:40.819192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will start by importing and examining the data. I'm going to drop all of the columns with missing values as I don't want to risk messing up the dataset by trying to fill them in with the mean/median.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/water-potability/water_potability.csv') # import the data\ndf = df.rename(columns={'ph':'pH'}) # rename column one from ph to pH\ndf = df.dropna() # drops all columns with missing values\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T20:58:22.516562Z","iopub.execute_input":"2021-07-27T20:58:22.516882Z","iopub.status.idle":"2021-07-27T20:58:22.601897Z","shell.execute_reply.started":"2021-07-27T20:58:22.51685Z","shell.execute_reply":"2021-07-27T20:58:22.600826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d= pd.DataFrame(df['Potability'].value_counts())\nfig = px.pie(d,values='Potability',names=['Not Potable','Potable'],hole=0.4,opacity=0.6,\n            color_discrete_sequence=[colors_green[3],colors_blue[3]],\n             labels={'label':'Potability','Potability':'No. Of Samples'})\nfig.update_traces(textposition='outside', textinfo='percent+label')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T21:04:22.738214Z","iopub.execute_input":"2021-07-27T21:04:22.73859Z","iopub.status.idle":"2021-07-27T21:04:22.801242Z","shell.execute_reply.started":"2021-07-27T21:04:22.738558Z","shell.execute_reply":"2021-07-27T21:04:22.800454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.scatter_matrix(df,df.drop('Potability',axis=1),height=1250,width=1250,template='plotly_white',opacity=0.7,\n                        color_discrete_sequence=[colors_blue[3],colors_green[3]],color='Potability',\n                       symbol='Potability',color_continuous_scale=[colors_green[3],colors_blue[3]])\n\nfig.update_layout(font_family='monospace',font_size=10,\n                  coloraxis_showscale=False,\n                 legend=dict(x=0.02,y=1.07,bgcolor=colors_dark[4]),\n                 title=dict(text='Scatter Plot Matrix b/w Features',x=0.5,y=0.97,\n                   font=dict(color=colors_dark[2],size=24)))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T21:05:18.478027Z","iopub.execute_input":"2021-07-27T21:05:18.478623Z","iopub.status.idle":"2021-07-27T21:05:18.762439Z","shell.execute_reply.started":"2021-07-27T21:05:18.47858Z","shell.execute_reply":"2021-07-27T21:05:18.761318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we will set up the prediction target as well as the features.","metadata":{}},{"cell_type":"code","source":"y = df.Potability # makes Potability the target we want to predict","metadata":{"execution":{"iopub.status.busy":"2021-07-27T20:58:22.603821Z","iopub.execute_input":"2021-07-27T20:58:22.604122Z","iopub.status.idle":"2021-07-27T20:58:22.610238Z","shell.execute_reply.started":"2021-07-27T20:58:22.604091Z","shell.execute_reply":"2021-07-27T20:58:22.609332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_features = ['pH', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity',\n               'Organic_carbon', 'Trihalomethanes', 'Turbidity']","metadata":{"execution":{"iopub.status.busy":"2021-07-27T20:58:22.611817Z","iopub.execute_input":"2021-07-27T20:58:22.612084Z","iopub.status.idle":"2021-07-27T20:58:22.621863Z","shell.execute_reply.started":"2021-07-27T20:58:22.612058Z","shell.execute_reply":"2021-07-27T20:58:22.620999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df[df_features] # sets up the features\nX.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T20:58:22.623059Z","iopub.execute_input":"2021-07-27T20:58:22.623397Z","iopub.status.idle":"2021-07-27T20:58:22.647213Z","shell.execute_reply.started":"2021-07-27T20:58:22.623368Z","shell.execute_reply":"2021-07-27T20:58:22.646124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix\n\n# split into validation and training data\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.2, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-27T20:58:22.648899Z","iopub.execute_input":"2021-07-27T20:58:22.649318Z","iopub.status.idle":"2021-07-27T20:58:22.662171Z","shell.execute_reply.started":"2021-07-27T20:58:22.649274Z","shell.execute_reply":"2021-07-27T20:58:22.661135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will start off by using a decision tree classifier. Initally, I will use the default model but then I will see how changing the max_leaf_nodes affects the accuracy.","metadata":{}},{"cell_type":"code","source":"# specify model\npotability_model = DecisionTreeClassifier(random_state=1)\n# fit model\npotability_model.fit(train_X, train_y)\n\n# make validation predictions and calculating accuracy\nval_predictions = potability_model.predict(val_X)\nval_acc = accuracy_score(val_predictions, val_y)\nprint(\"Validation accuracy when not specifying max_leaf_nodes: {:.5}\".format(val_acc))\n\n# recalculating the accuracy while changing the max_leaf_nodes\npotability_model = DecisionTreeClassifier(max_leaf_nodes=33, random_state=1)\npotability_model.fit(train_X, train_y)\nval_predictions = potability_model.predict(val_X)\nval_acc = accuracy_score(val_predictions, val_y)\nprint(\"Validation accuracy for best value of max_leaf_nodes: {:,.5}\".format(val_acc))","metadata":{"execution":{"iopub.status.busy":"2021-07-27T20:58:22.663533Z","iopub.execute_input":"2021-07-27T20:58:22.663811Z","iopub.status.idle":"2021-07-27T20:58:22.730261Z","shell.execute_reply.started":"2021-07-27T20:58:22.663783Z","shell.execute_reply":"2021-07-27T20:58:22.729295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef make_confusion_matrix(cf,\n                          group_names=None,\n                          categories='auto',\n                          count=True,\n                          percent=True,\n                          cbar=True,\n                          xyticks=True,\n                          xyplotlabels=True,\n                          sum_stats=True,\n                          figsize=None,\n                          cmap='Blues',\n                          title=None):\n    blanks = ['' for i in range(cf.size)]\n\n    if group_names and len(group_names)==cf.size:\n        group_labels = [\"{}\\n\".format(value) for value in group_names]\n    else:\n        group_labels = blanks\n\n    if count:\n        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n    else:\n        group_counts = blanks\n\n    if percent:\n        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n    else:\n        group_percentages = blanks\n\n    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n\n\n    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n    if sum_stats:\n        #Accuracy is sum of diagonal divided by total observations\n        accuracy  = np.trace(cf) / float(np.sum(cf))\n\n        #if it is a binary confusion matrix, show some more stats\n        if len(cf)==2:\n            #Metrics for Binary Confusion Matrices\n            precision = cf[1,1] / sum(cf[:,1])\n            recall    = cf[1,1] / sum(cf[1,:])\n            f1_score  = 2*precision*recall / (precision + recall)\n            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n                accuracy,precision,recall,f1_score)\n        else:\n            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n    else:\n        stats_text = \"\"\n\n\n    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n    if figsize==None:\n        #Get default figure size if not set\n        figsize = plt.rcParams.get('figure.figsize')\n\n    if xyticks==False:\n        #Do not show categories if xyticks is False\n        categories=False\n    # MAKE THE HEATMAP VISUALIZATION\n    plt.figure(figsize=figsize)\n    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n\n    if xyplotlabels:\n        plt.ylabel('True Label')\n        plt.xlabel('Predicted Label' + stats_text)\n    else:\n        plt.xlabel(stats_text)\n    \n    if title:\n        plt.title(title)\n\n   ","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2021-07-27T20:58:22.732385Z","iopub.execute_input":"2021-07-27T20:58:22.732696Z","iopub.status.idle":"2021-07-27T20:58:22.749086Z","shell.execute_reply.started":"2021-07-27T20:58:22.732665Z","shell.execute_reply":"2021-07-27T20:58:22.748376Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cf_matrix = confusion_matrix(val_y, val_predictions)\nlabels = ['True Neg.','False Pos.','False Neg.','True Pos.']\ncategories = ['Zero', 'One']\n# creating confusion matrix using template from Dennis T.\nmake_confusion_matrix(cf_matrix, \n                      group_names=labels,\n                      categories=categories, \n                      cmap='Blues')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T20:58:22.750478Z","iopub.execute_input":"2021-07-27T20:58:22.750902Z","iopub.status.idle":"2021-07-27T20:58:23.022691Z","shell.execute_reply.started":"2021-07-27T20:58:22.750857Z","shell.execute_reply":"2021-07-27T20:58:23.021917Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we can see that initally we got an accuracy at about 0.596 which isn't terrible for a first run but it's definitely not great. I messed around with the max_leaf_nodes and I was able to achieve an accuracy score of 0.700 score using 33 nodes which is shown above in the confusion matrix. That's a huge jump of around 10% accuracy just by changing one parameter. I'm very happy with that result but I'm going to test some other models to see if I can get any better results.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# specify model\npotability_model = RandomForestClassifier(random_state=1)\n# fit model\npotability_model.fit(train_X, train_y)\n\n# make validation predictions and calculating accuracy\nval_predictions = potability_model.predict(val_X)\nval_acc = accuracy_score(val_predictions, val_y)\nprint(\"Validation accuracy: {:.5}\".format(val_acc))\n\n# recalculating the accuracy while changing the n_estimators\npotability_model = RandomForestClassifier(n_estimators=30, random_state=1)\npotability_model.fit(train_X, train_y)\nval_predictions = potability_model.predict(val_X)\nval_acc = accuracy_score(val_predictions, val_y)\nprint(\"Validation accuracy for best value of n_estimators: {:,.5}\".format(val_acc))","metadata":{"execution":{"iopub.status.busy":"2021-07-27T20:58:23.02388Z","iopub.execute_input":"2021-07-27T20:58:23.024342Z","iopub.status.idle":"2021-07-27T20:58:23.850229Z","shell.execute_reply.started":"2021-07-27T20:58:23.024291Z","shell.execute_reply":"2021-07-27T20:58:23.84924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cf_matrix2 = confusion_matrix(val_y, val_predictions)\nlabels = ['True Neg.','False Pos.','False Neg.','True Pos.']\ncategories = ['Zero', 'One']\n# creating confusion matrix using template from Dennis T.\nmake_confusion_matrix(cf_matrix2, \n                      group_names=labels,\n                      categories=categories, \n                      cmap='Blues')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T20:58:23.851682Z","iopub.execute_input":"2021-07-27T20:58:23.852004Z","iopub.status.idle":"2021-07-27T20:58:24.074538Z","shell.execute_reply.started":"2021-07-27T20:58:23.851972Z","shell.execute_reply":"2021-07-27T20:58:24.0734Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now get the accuracy score up to 0.715! That's a nice 0.015 jump from where we began but I'm still not content. Let's try one more model and see how it lines up.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\n\n# specify model\npotability_model = ExtraTreesClassifier(random_state=1)\n# fit model\npotability_model.fit(train_X, train_y)\n\n# make validation predictions and calculating accuracy\nval_predictions = potability_model.predict(val_X)\nval_acc = accuracy_score(val_predictions, val_y)\nprint(\"Validation accuracy: {:.5}\".format(val_acc))\n\n# recalculating the accuracy while changing the n_estimators\npotability_model = ExtraTreesClassifier(n_estimators=87, random_state=1)\npotability_model.fit(train_X, train_y)\nval_predictions = potability_model.predict(val_X)\nval_acc = accuracy_score(val_predictions, val_y)\nprint(\"Validation accuracy for best value of n_estimators: {:,.5}\".format(val_acc))","metadata":{"execution":{"iopub.status.busy":"2021-07-27T20:58:24.07602Z","iopub.execute_input":"2021-07-27T20:58:24.076361Z","iopub.status.idle":"2021-07-27T20:58:24.674622Z","shell.execute_reply.started":"2021-07-27T20:58:24.076329Z","shell.execute_reply":"2021-07-27T20:58:24.673633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cf_matrix3 = confusion_matrix(val_y, val_predictions)\nlabels = ['True Neg.','False Pos.','False Neg.','True Pos.']\ncategories = ['Zero', 'One']\n# creating confusion matrix using template from Dennis T.\nmake_confusion_matrix(cf_matrix3, \n                      group_names=labels,\n                      categories=categories, \n                      cmap='Blues')","metadata":{"execution":{"iopub.status.busy":"2021-07-27T20:58:24.675974Z","iopub.execute_input":"2021-07-27T20:58:24.676282Z","iopub.status.idle":"2021-07-27T20:58:24.909348Z","shell.execute_reply.started":"2021-07-27T20:58:24.67625Z","shell.execute_reply":"2021-07-27T20:58:24.908346Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We're now up to 0.732 using the ExtraTreesClassifier. I am very happy with this score as this dataset did not seem to have a lot of great features.","metadata":{}}]}