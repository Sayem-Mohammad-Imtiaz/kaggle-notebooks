{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Collingswood ADA Curb Ramp Analysis\n---\nAn inspection of every curb ramp within a half-mile radius of the PATCO train station in Collingswood, NJ was conducted to rate each one's compliance with The Americans with Disabilities Act of 1990 (ADA).  Reasons to rate a ramp as non-compliant include but are not limited to:\n\n- No detectable warning surface (DWS)/damaged DWS\n- Running slope too steep (>5%)\n- Cross slope too steep (>2%)\n- Misaligned ramp/DWS\n- No ramp\n\nOver 400 ramps/corners were observed, and more than 280 were deemed non-compliant.  The purpose of this notebook is to accurately map all inspected ramps--down to the corner of the specified intersection, if possible--and depict them in various visualizations to gain any potential geospatial insight from the data.\n\nAn additional functionality would consist of using the data to plot most efficient, ADA-compliant routes from any given point within the half-mile radius to the train station.\n\n\nLast Update: 8/28/2021","metadata":{}},{"cell_type":"code","source":"# (seemingly) required for pandas.read_excel()\n!pip install openpyxl","metadata":{"execution":{"iopub.status.busy":"2021-08-28T20:41:50.470312Z","iopub.execute_input":"2021-08-28T20:41:50.470817Z","iopub.status.idle":"2021-08-28T20:42:00.602876Z","shell.execute_reply.started":"2021-08-28T20:41:50.470776Z","shell.execute_reply":"2021-08-28T20:42:00.601833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport geopandas as gpd\n\nfrom geopandas.tools import geocode\nimport folium\n\nagent = \"my_colls_app\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-28T20:42:05.82445Z","iopub.execute_input":"2021-08-28T20:42:05.824861Z","iopub.status.idle":"2021-08-28T20:42:05.830488Z","shell.execute_reply.started":"2021-08-28T20:42:05.824828Z","shell.execute_reply":"2021-08-28T20:42:05.829463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Skip\n**If Checkpoint \\#1 has been reached (below), skip down and run from there.**\n\nEverything between here and Checkpoint \\#1:\n\n1. Reads in the raw data\n2. Renames and reorders columns\n3. Handles NaNs\n4. Cleans and standardizes cross-street location data\n5. Automatically geocodes as many locations as possible using GoogleMaps API\n6. Returns new csv with most locations geocoded (to minimize API calls)","metadata":{}},{"cell_type":"code","source":"ramp_path = '../input/rampdatalog/RampDataLog.xlsm'\nramp_df = pd.read_excel(ramp_path, sheet_name='data')\nramp_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T20:42:12.953374Z","iopub.execute_input":"2021-08-28T20:42:12.953796Z","iopub.status.idle":"2021-08-28T20:42:13.331678Z","shell.execute_reply.started":"2021-08-28T20:42:12.953762Z","shell.execute_reply":"2021-08-28T20:42:13.330639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Input\nThe raw data consist of five columns:\n- Cross Street 1: First location identifier\n- Cross Street 2: Second location identifier (if applicable)\n- Corner: Cardinal direction indicating which corner of the intersection was inspected\n- Compliance: \"Y\" or \"N\" deeming compliance with ADA\n- Notes: Reasons, if any, for marking ramp as compliant or not","metadata":{}},{"cell_type":"code","source":"# Rename cross street columns to shorten and get rid of spaces\nramp_df.rename(columns={'Cross Street 1': 'CS_1', 'Cross Street 2': 'CS_2'}, inplace=True)\nramp_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T20:42:17.309182Z","iopub.execute_input":"2021-08-28T20:42:17.309645Z","iopub.status.idle":"2021-08-28T20:42:17.332543Z","shell.execute_reply.started":"2021-08-28T20:42:17.309565Z","shell.execute_reply":"2021-08-28T20:42:17.3315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Locations\nWhile most locations were simply intersections of two cross streets, a handful did not fit into this format so easily.  Some occurred at crosswalks halfway between blocks (Haddon Ave between Washington Ave and Irvin Ave).  Some occurred at non-standard locations (Wawa exit, alleyway).  Others were observed at misaligned four-way intersections (i.e. Maple Ave west of Woodlawn Ave is not in line with Maple Ave east of Woodlawn Ave), hence cardinal corners like \"SE (to NE)\" and \"NW (to SW).\"","metadata":{}},{"cell_type":"code","source":"# raw data QA/QC\nfor col in ramp_df.columns.tolist()[:-1]:\n    print(ramp_df[col].unique())","metadata":{"execution":{"iopub.status.busy":"2021-08-28T20:42:20.676478Z","iopub.execute_input":"2021-08-28T20:42:20.676881Z","iopub.status.idle":"2021-08-28T20:42:20.688214Z","shell.execute_reply.started":"2021-08-28T20:42:20.67685Z","shell.execute_reply":"2021-08-28T20:42:20.686982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# \"NE\" appears twice; one with leading whitespace\nramp_df.replace(' NE', 'NE', inplace=True) #correct instance\nramp_df.Notes.fillna('None', inplace=True) #fill blank notes fields\n\nramp_df.head(20)","metadata":{"execution":{"iopub.status.busy":"2021-08-28T20:44:15.293073Z","iopub.execute_input":"2021-08-28T20:44:15.293516Z","iopub.status.idle":"2021-08-28T20:44:15.319381Z","shell.execute_reply.started":"2021-08-28T20:44:15.293484Z","shell.execute_reply":"2021-08-28T20:44:15.317758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Cleaning\n### Unique Street Name Cases\n\n* Two-worded streets (N Atlantic)\n* Three-worded streets (S Newton Lake)\n* No second cross-street (PATCO Entrance)\n* Entries \"between\" cross-streets (Haddon btw Washington to Irvin)\n* Street suffixes already present (Maple Terr)\n* Unique second cross-street cases:\n    * \"alleyway\"\n    * \"Wawa exit\"\n* Cardinal direction in parentheses in second cross-street (Park (N))\n\n**Assume street suffix is \"Ave\" unless otherwise specified**","metadata":{}},{"cell_type":"code","source":"import math\n\n# Combine cross streets into one intersection, if applicable\ndef cs_comb_str(cs1, cs2):\n    \"\"\"\n    Take an intersection's cross streets as arguments and return\n    a string of the complete location\n    \"\"\"\n    \n    inter = \"\"\n    suffixes = ['Ave', 'Ln', 'Terr'] # list of all street suffixes observed\n    \n    # Add \"Ave\" suffix before \"between\" descriptor\n    if 'btw' in cs1:\n        inter = cs1.split('btw')[0] + 'Ave btw ' + cs2\n    # If second location is NaN, use only the first location\n    elif type(cs2) != str:\n        inter = cs1\n    # Add \"Ave\" suffix before cardinal direction descriptor\n    elif '(' in cs2:\n        inter = cs1 + ' Ave and ' + cs2.split()[0] + ' Ave ' + cs2.split()[1]\n    else:\n        # If first location doesn't have a specified suffix, assume \"Ave\"\n        if not any([suf in cs1 for suf in suffixes]):\n            cs1 += ' Ave'\n        \n        # If second location doesn't have a specified suffix, special location, or cardinal identifer, append an \"Ave\"\n        if (not any([suf in cs2 for suf in suffixes]) and\n            not any([landmark in cs2 for landmark in ['alleyway', 'exit']]) and\n            len(cs2.split()[-1]) > 1):\n            cs2 += ' Ave'\n        \n        inter = ' and '.join([cs1, cs2])\n        \n    return inter","metadata":{"execution":{"iopub.status.busy":"2021-08-28T21:15:34.867392Z","iopub.execute_input":"2021-08-28T21:15:34.868308Z","iopub.status.idle":"2021-08-28T21:15:34.881922Z","shell.execute_reply.started":"2021-08-28T21:15:34.86826Z","shell.execute_reply":"2021-08-28T21:15:34.881143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ramp_df['Inter'] = ramp_df.apply(lambda row: cs_comb_str(row['CS_1'], row['CS_2']), axis=1)\n\nramp_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T21:15:49.690698Z","iopub.execute_input":"2021-08-28T21:15:49.691363Z","iopub.status.idle":"2021-08-28T21:15:49.727719Z","shell.execute_reply.started":"2021-08-28T21:15:49.691307Z","shell.execute_reply":"2021-08-28T21:15:49.726642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Geocoding\n***Note:*** *This portion of the notebook has been run only **once** to minimize repeat calls to the GoogleMaps API*\n\nUsing a secure API key provided by GoogleMaps, each location of a standard format (\"XYZ Ave and ABC Ave\") is passed to the GoogleMaps API via a URL request.  The resulting JSON is parsed to receive the corresponding latitude and longitude for each location.  All non-standard locations are assigned NaN for the time being.","metadata":{}},{"cell_type":"code","source":"# GEOCODE INTERSECTIONS USING GOOGLE MAPS API #\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\napi_key = user_secrets.get_secret(\"api_key\")","metadata":{"execution":{"iopub.status.busy":"2021-08-20T14:45:08.685873Z","iopub.execute_input":"2021-08-20T14:45:08.686332Z","iopub.status.idle":"2021-08-20T14:45:08.826471Z","shell.execute_reply.started":"2021-08-20T14:45:08.686286Z","shell.execute_reply":"2021-08-20T14:45:08.825296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests\n\nlat = []\nlong = []\n\nurl_boiler = 'https://maps.googleapis.com/maps/api/geocode/json?address='\n# Ignore any non-standard location formats for automated geocoding\nunusual_phrases = ['btw', '\\(', 'alleyway', 'exit']\n\nfor intersection in ramp_df.Inter:\n    if not any([phrase in intersection for phrase in unusual_phrases]):\n        url_address = '+'.join(intersection.split()) + ',+Collingswood,+NJ'\n        url_complete = url_boiler + url_address + '&key=' + api_key\n        \n        response = requests.get(url_complete)\n        resp_json = response.json()\n        \n        lat.append(resp_json['results'][0]['geometry']['location']['lat'])\n        long.append(resp_json['results'][0]['geometry']['location']['lng'])\n    else:\n        lat.append(np.nan)\n        long.append(np.nan)","metadata":{"execution":{"iopub.status.busy":"2021-08-20T15:18:03.951935Z","iopub.execute_input":"2021-08-20T15:18:03.952336Z","iopub.status.idle":"2021-08-20T15:19:02.00225Z","shell.execute_reply.started":"2021-08-20T15:18:03.952304Z","shell.execute_reply":"2021-08-20T15:19:02.000839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ramp_df[\"Lat\"] = pd.Series(lat)\nramp_df[\"Long\"] = pd.Series(long)\n\n# Rearrange columns\ncols = ramp_df.columns.tolist()\ncols = cols[:2] + cols[-3:] + cols[2:5]\nramp_df = ramp_df[cols]","metadata":{"execution":{"iopub.status.busy":"2021-08-20T15:46:24.202071Z","iopub.execute_input":"2021-08-20T15:46:24.202476Z","iopub.status.idle":"2021-08-20T15:46:24.225192Z","shell.execute_reply.started":"2021-08-20T15:46:24.202442Z","shell.execute_reply":"2021-08-20T15:46:24.224061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Export as checkpoint so Google Maps API doesn't need to be requested again\nramp_df.to_csv('CollingswoodADA_LatLong_checkpoint.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-20T15:48:44.136756Z","iopub.execute_input":"2021-08-20T15:48:44.137215Z","iopub.status.idle":"2021-08-20T15:48:44.152155Z","shell.execute_reply.started":"2021-08-20T15:48:44.137181Z","shell.execute_reply":"2021-08-20T15:48:44.151022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checkpoint \\#1\n---\nStart from here by importing cleaned data with latitudes and longitudes, rather than querying Google Maps API every time","metadata":{}},{"cell_type":"code","source":"ramp_df = pd.read_csv('../input/collingswoodada-clean-latlong/CollingswoodADA_LatLong_checkpoint.csv')\nramp_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-28T22:00:27.980297Z","iopub.execute_input":"2021-08-28T22:00:27.980782Z","iopub.status.idle":"2021-08-28T22:00:28.0347Z","shell.execute_reply.started":"2021-08-28T22:00:27.980743Z","shell.execute_reply":"2021-08-28T22:00:28.033332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Geocoding Shortcut Functions\nThe `geo_short()` function is a shortcut of the GeoPandas geocoding tool using the Nominatim software to call OpenStreetMap for additional (and free) geocoding requests.\n\n*This may be eventually replaced with either a GoogleMaps API request or hardcoding the lat/long if only used for a few locations.  In general, Nominatim has trouble geocoding cross streets and is less accurate than the GoogleMaps API.*\n\nThe `basemap_with_buffer()` function establishes a Folium basemap using OpenStreetMap tiles.  The map is centered around a given location, and a circle of a given radius (in miles) is drawn around that point.  This function should be called each time a new map representation is desired (i.e. rather than appending new markers to a current basemap).","metadata":{}},{"cell_type":"code","source":"def geo_short(location):\n    \"\"\"\n    Take address, cross-street, etc. and return geocoded point at which\n    lat/long can conveniently accessed.  Uses Nominatim.\n    \"\"\"\n    pt = geocode(location, provider=\"nominatim\", user_agent=agent)\n    return pt.geometry.iloc[0]","metadata":{"execution":{"iopub.status.busy":"2021-08-28T22:11:30.802939Z","iopub.execute_input":"2021-08-28T22:11:30.803303Z","iopub.status.idle":"2021-08-28T22:11:30.807796Z","shell.execute_reply.started":"2021-08-28T22:11:30.803274Z","shell.execute_reply":"2021-08-28T22:11:30.807132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def basemap_with_buffer(location, buffer_radius_miles):\n    centerpoint = geo_short(location)\n    basemap = folium.Map(location=[centerpoint.y, centerpoint.x], tiles=\"openstreetmap\", zoom_start=15)\n    \n    buffer_radius_meters = buffer_radius_miles * 5280 / 3.28084 # miles to feet to meters\n    basemap_buffer = folium.Circle(location=[centerpoint.y, centerpoint.x],\n                                   radius=buffer_radius_meters).add_to(basemap)\n    \n    return basemap","metadata":{"execution":{"iopub.status.busy":"2021-08-28T22:15:11.338538Z","iopub.execute_input":"2021-08-28T22:15:11.338999Z","iopub.status.idle":"2021-08-28T22:15:11.347452Z","shell.execute_reply.started":"2021-08-28T22:15:11.338964Z","shell.execute_reply":"2021-08-28T22:15:11.346384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Geospatial Data Visualization\nNow that latitudes/longitudes have been acquired for most of the curb ramp data, they can now be visualized on a map using various tools provided by Folium.\n\nFirst, the basemap is displayed below, including the half-mile radius centered around the Collingswood PATCO Station.","metadata":{}},{"cell_type":"code","source":"patco_address = \"100 Lees Ave, Collingswood, NJ 08108\"\npatco_base = basemap_with_buffer(patco_address, 0.5)\npatco_base","metadata":{"execution":{"iopub.status.busy":"2021-08-28T22:20:51.112284Z","iopub.execute_input":"2021-08-28T22:20:51.112691Z","iopub.status.idle":"2021-08-28T22:20:51.542401Z","shell.execute_reply.started":"2021-08-28T22:20:51.112658Z","shell.execute_reply":"2021-08-28T22:20:51.541644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Establish a fresh basemap\npatco_base = basemap_with_buffer(patco_address, 0.5)\n\n# For each location that's not NaN, add a generic marker to the basemap.\n# Enable the hover functionality for intersection data for QA/QC purposes.\nfor i, location in ramp_df.iterrows():\n    if not np.isnan(location.Lat) and not np.isnan(location.Long):\n        folium.Marker(location=[location.Lat, location.Long],tooltip=location.Inter).add_to(patco_base)\n\npatco_base","metadata":{"execution":{"iopub.status.busy":"2021-08-28T22:35:15.915301Z","iopub.execute_input":"2021-08-28T22:35:15.915751Z","iopub.status.idle":"2021-08-28T22:35:16.674269Z","shell.execute_reply.started":"2021-08-28T22:35:15.91571Z","shell.execute_reply":"2021-08-28T22:35:16.672896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Location Markers\nAs can be seen above, most of the locations have been accurately mapped, but a small handful appear clearly out of place, as evidenced by their distance outside the circle.  Hovering over these points, one can see which intersection the API was *trying* to geocode.  It appears that most of the problem points are ones involving Park Avenue.\n\n*Note that a few markers are correctly mapped outside of the circle but only because the inspection was conservative in its data collection.*\n\nAnother way of visualizing the data is using a Folium plugin known as `MarkerCluster()`.  Depending on the zoom level, this tool will group markers of close proximity together, label the quantity grouped, and color code them based on the quantity.  This representation is also more accurate as it will include *all* data points, whereas the marker map above only shows one if many are found to be in the same spot.  Click on any cluster to have it display the markers it contains.","metadata":{}},{"cell_type":"code","source":"from folium.plugins import MarkerCluster\n\n# Establish a fresh basemap so as not to overlap previous markers\npatco_base = basemap_with_buffer(patco_address, 0.5)\nmarker_cluster = folium.plugins.MarkerCluster()\n\nfor i, location in ramp_df.iterrows():\n    if not np.isnan(location.Lat) and not np.isnan(location.Long):\n        marker_cluster.add_child(folium.Marker([location.Lat, location.Long], tooltip=location.Inter))\n\npatco_base.add_child(marker_cluster)\npatco_base","metadata":{"execution":{"iopub.status.busy":"2021-08-28T22:35:52.407473Z","iopub.execute_input":"2021-08-28T22:35:52.407947Z","iopub.status.idle":"2021-08-28T22:35:53.177824Z","shell.execute_reply.started":"2021-08-28T22:35:52.407907Z","shell.execute_reply":"2021-08-28T22:35:53.176715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preliminary Analysis\nThe simplest way of gaining even a little insight out of the data is to color-code the mapped locations based on their compliance with ADA.  The code cell below maps locations as circles: green if compliant (Y) and red if not (N).  From here, any groupings or patterns can be observed.\n\nThis data can and must be improved, however.  Not every ramp is displayed here: only one per location is currently portrayed.  Further, the locations with non-standard formats, as explained above, have still not been included.  We will come back to this after some more data cleaning.","metadata":{}},{"cell_type":"code","source":"patco_base = basemap_with_buffer(patco_address, 0.5)\n\nfor i, location in ramp_df.iterrows():\n    if not np.isnan(location.Lat) and not np.isnan(location.Long):\n        color = \"green\" if location.Compliance == \"Y\" else \"red\"\n        folium.Circle(location=[location.Lat, location.Long], radius=10,\n                      color=color, tooltip=location.Inter).add_to(patco_base)\n\npatco_base","metadata":{"execution":{"iopub.status.busy":"2021-08-28T22:37:37.851348Z","iopub.execute_input":"2021-08-28T22:37:37.851956Z","iopub.status.idle":"2021-08-28T22:37:38.671929Z","shell.execute_reply.started":"2021-08-28T22:37:37.851917Z","shell.execute_reply":"2021-08-28T22:37:38.670962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# THIS IS TO BE UPDATED TO ACCOUNT FOR ALL MISCODED LOCATIONS #\n\n# Only non-compliant locations are displayed below.  Miscoded locations seen above have been hard-coded\n# with their respective latitudes and longitudes for simplicity purposes.\npatco_base = basemap_with_buffer(patco_address, 0.5)\n\nfor i, location in ramp_df.iterrows():\n    if not np.isnan(location.Lat) and not np.isnan(location.Long) and location.Compliance == \"N\":\n        color = \"green\" if location.Compliance == \"Y\" else \"red\"\n        if location.CS_1 == \"Park\":\n            if location.CS_2 == \"Cuthbert\":\n                lat = 39.9103431\n                lng = -75.0586094\n            elif location.CS_2 == \"Ogden\":\n                lat = 39.9109968\n                lng = -75.0606443\n            elif location.CS_2 == \"Conard\":\n                lat = 39.9115682\n                lng = -75.062489\n        elif location.CS_1 == \"Laurel\" and location.CS_2 == \"Lincoln\":\n            lat = 39.9201176\n            lng = -75.0627509\n        elif location.CS_1 == \"Cuthbert\" and location.CS_2 == \"Lindisfarne\":\n            lat = 39.9121536\n            lng = -75.0576633\n        else:\n            lat = location.Lat\n            lng = location.Long\n                \n        folium.Circle(location=[lat, lng], radius=10,\n                      color=color, tooltip=location.Inter).add_to(patco_base)\n\npatco_base","metadata":{"execution":{"iopub.status.busy":"2021-08-28T22:38:16.668395Z","iopub.execute_input":"2021-08-28T22:38:16.668784Z","iopub.status.idle":"2021-08-28T22:38:17.258725Z","shell.execute_reply.started":"2021-08-28T22:38:16.668753Z","shell.execute_reply":"2021-08-28T22:38:17.257848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sandbox\nBelow are cells of code acting as notes for future developments of the dataset's analysis.","metadata":{}},{"cell_type":"code","source":"dummy = [\"951 Oriental Ave\", \"103 E Linden Ave\", \"100 E Homestead Ave\", \"101 E Stiles Ave\", \"900 Haddon Ave\"]\ndummy = [dummy[i] + \", Collingswood, NJ 08108\" for i in range(len(dummy))]\n\nfor add in dummy:\n    add_pt = geo_short(add)\n    folium.Circle(location=[add_pt.y, add_pt.x], radius=5, tooltip=add.split(',')[0], color='red').add_to(patco_base)\n\nfolium.PolyLine(([geo_short(dummy[1]).y, geo_short(dummy[1]).x], [geo_short(dummy[2]).y, geo_short(dummy[2]).x])).add_to(patco_base)\n\npatco_base","metadata":{"execution":{"iopub.status.busy":"2021-08-28T22:53:12.859497Z","iopub.execute_input":"2021-08-28T22:53:12.859902Z","iopub.status.idle":"2021-08-28T22:53:17.061569Z","shell.execute_reply.started":"2021-08-28T22:53:12.85987Z","shell.execute_reply":"2021-08-28T22:53:17.06058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy_df = pd.DataFrame({\n    'Address_Long': dummy,\n    'Address_Short': [dum.split(',')[0] for dum in dummy],\n    'Town': [dum.split(',')[1].strip() for dum in dummy],\n    'State': [dum.split(',')[2].split(' ')[1] for dum in dummy],\n    'Zip': [dum.split(',')[2].split(' ')[2] for dum in dummy],\n    'Lat': [geo_short(dum).y for dum in dummy],\n    'Long': [geo_short(dum).x for dum in dummy]\n})\n\ndummy_gdf = gpd.GeoDataFrame(dummy_df, geometry=gpd.points_from_xy(dummy_df.Long, dummy_df.Lat))","metadata":{"execution":{"iopub.status.busy":"2021-08-02T02:06:47.648442Z","iopub.execute_input":"2021-08-02T02:06:47.649042Z","iopub.status.idle":"2021-08-02T02:06:54.056675Z","shell.execute_reply.started":"2021-08-02T02:06:47.64899Z","shell.execute_reply":"2021-08-02T02:06:54.055509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from shapely.geometry import Point, LineString","metadata":{"execution":{"iopub.status.busy":"2021-08-02T02:18:15.670987Z","iopub.execute_input":"2021-08-02T02:18:15.671505Z","iopub.status.idle":"2021-08-02T02:18:15.67681Z","shell.execute_reply.started":"2021-08-02T02:18:15.671463Z","shell.execute_reply":"2021-08-02T02:18:15.675567Z"},"trusted":true},"execution_count":null,"outputs":[]}]}