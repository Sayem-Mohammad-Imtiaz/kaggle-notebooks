{"cells":[{"metadata":{},"cell_type":"markdown","source":"#  Time Series Forecasting with the Long Short-Term Memory Network (LSTM)  \n\nThe Long Short-Term Memory network, or LSTM network, is a recurrent neural network that is trained using Backpropagation Through Time and overcomes the vanishing gradient problem.\nAs such, it can be used to create large recurrent networks that in turn can be used to address difficult sequence problems in machine learning and achieve state-of-the-art results.\nInstead of neurons, LSTM networks have memory blocks that are connected through layers.\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport requests\nimport numpy as np\nimport pandas as pd\nimport io\nimport numpy\nimport matplotlib.pyplot as plt\nfrom pandas import read_csv\nimport math\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load Time Series Data\n\n\nfilename = (\"/kaggle/input/ece657aw20asg4coronavirus/time_series_covid19_confirmed_global.csv\")\ndata = pd.read_csv(filename)\ndata.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"Canada_confirmed = data.loc[data['Country/Region'] == 'Canada']\nCanada_confirmed \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing a time series\n\nfrom matplotlib import pyplot\npyplot.figure(figsize=(20,10)) \n\nfor r in Canada_confirmed['Province/State']:  \n        pyplot.plot(range(len(Canada_confirmed.columns)-4), Canada_confirmed.loc[Canada_confirmed['Province/State']==r].iloc[0,4:], label = r) \n        \n         \npyplot.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\npyplot.title('Total Number of COVID-19 Confirmed Cases in pronvices of Canada')\npyplot.xlabel('Day')\npyplot.ylabel('Number of Cases')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Canada_TS is the summation of all pronvises confirmed cases\n\nfrom pandas import DataFrame\nCanada_TS=0\n\nfor i in range(len (Canada_confirmed['Province/State'])):\n     Canada_TS = Canada_confirmed.iloc[i,4:]+ Canada_TS\n        \nprint (Canada_TS.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" # fix random seed for reproducibility\nnumpy.random.seed(7)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the dataset\n\ndataframe=np.resize(Canada_TS,(len(Canada_TS),1))\ndataset = dataframe.astype('float32')\nprint(dataframe.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data preprocessing\n\nLSTMs are sensitive to the scale of the input data. It would be good to rescale the data to the range of 0-to-1, also called normalizing. I used MinMaxScaler preprocessing class from the scikit-learn library.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalize the dataset\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)\nprint(dataset.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" The code below calculates the index of the split point and separates the data into the training datasets to train our model, leaving the remaining 14 days for testing the model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# split into train and test sets\ntrain_size = (len(dataset) - 14)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\nprint(len(train), len(test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transforming the data to a supervised learning problem:\nSingle column of data is converted into a two-column dataset: the first column X is containing the number of confirmed cases at a given time (t) and Y is the number of confirmed cases at the next time (t + 1). \n ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert an array of values into a dataset matrix\n\ndef create_dataset(dataset, look_back=1):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1):\n        a = dataset[i:(i+look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return numpy.array(dataX), numpy.array(dataY)\n\n\n# reshape into X=t and Y=t+1\nlook_back = 1\ntrainX, trainY = create_dataset(train, look_back)\ntestX, testY = create_dataset(test, look_back)\n\n# reshape input to be [samples, time steps, features]\ntrainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LSTM Model  \n\nThe network has a visible layer with 1 input, a hidden layer with 4 LSTM blocks or neurons, and an output layer that makes a single value prediction. The default sigmoid activation function is used for the LSTM blocks. The network is trained for 100 epochs and a batch size of 1 is used.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# create and fit the LSTM network\nmodel = Sequential()\nmodel.add(LSTM(50, input_shape=(1, look_back)))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainY[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions\ntrainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n#calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# plot\n\ntrainPredictPlot = numpy.empty_like(dataset)\ntrainPredictPlot[:, :] = numpy.nan\ntrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n \ntestPredictPlot = numpy.empty_like(dataset)\ntestPredictPlot[:, :] = numpy.nan\ntestPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n# plot baseline and predictions\n\n\nplt.figure(2, figsize=(12,9))\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot, marker='.')\nplt.plot(testPredictPlot, marker='.')\nplt.xlabel('Day Number', fontsize=14)\nplt.ylabel('Number of Confirmed cases in Canada',fontsize=14)\nplt.legend()\nplt.title('Daily Prediction of COVID-19 Time confirmed cases in Canada ', fontsize=20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler(feature_range=(0, 1))\ndataset1 = scaler.fit_transform(np.resize(Canada_TS,(len(Canada_TS),1)))\n#print(dataset1)\n#Canada_TS.values.shape\n\n#raw_seq =dataset1\n#l=len(raw_seq)\n\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# define input sequence\n\n\ndataset1 = dataset[0:len(dataset),0]\n\nraw_seq =dataset1\nl=len(raw_seq)\n\n# demonstrate prediction\n#x_input = array([raw_seq[l-3], raw_seq[l-2], raw_seq[l-1]])\nx_input = np.array([raw_seq[l-1]])\nx_input = x_input.reshape((1, 1, 1))\nyhat = model.predict(x_input)\ntrainPredict1 = scaler.inverse_transform(yhat)\nprint(trainPredict1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#window=np.zeros((3,),np.float32)\n#print(l)\nfor i in range(l-1,l+5):\n    x_input = np.array([raw_seq[i]])\n    x_input = x_input.reshape((1, 1, 1))\n    yhat = model.predict(x_input)\n    trainPredict1 = scaler.inverse_transform(yhat)\n    #print(i,len(raw_seq))\n    if i+1==len(raw_seq):\n        raw_seq=np.append(raw_seq,yhat)\n    else:\n        raw_seq[i+1]=yhat\n    print(i+1,'day '+str(i-l+2),trainPredict1[0]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quick ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}