{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook uses random forest to do the classification**\n\nThe main content is train and tune the random forest model\n","metadata":{"_cell_guid":"d7a71f50-2d95-5715-7c97-8e4baf788bfb"}},{"cell_type":"code","source":"# load data\nimport os\nimport mxnet as mx\nfrom mxnet.image import imread, imresize\nfrom mxnet import gluon, init, nd, autograd\nfrom mxnet.gluon import nn\nfrom mxnet.gluon.data.vision import transforms\nfrom mxnet.gluon.loss import SoftmaxCrossEntropyLoss\nfrom gluoncv import model_zoo\n\ntransform_train = transforms.Compose([\n    transforms.Resize(224),\n    transforms.ToTensor(),\n    transforms.Normalize()\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize(224),\n    transforms.ToTensor(),\n    transforms.Normalize()\n])\n\nbatch_size = 16\n\npath = '../input/case-classification/final_project_dataset'\ntrain_path = os.path.join(path, 'train')\nval_path = os.path.join(path, 'validate')\ntest_path = os.path.join(path, 'test')\n\ntrain_loader = gluon.data.DataLoader(\n    gluon.data.vision.ImageFolderDataset(train_path).transform_first(transform_train),\n    batch_size=batch_size, shuffle=True)\n\nvalidation_loader = gluon.data.DataLoader(\n    gluon.data.vision.ImageFolderDataset(val_path).transform_first(transform_test),\n    batch_size=batch_size, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nim1 = imread(train_path + \"/class_1/B003AOIJ74.jpg\")\nim2 = imread(train_path + \"/class_4/B002GQRGOY.jpg\")\n\nplt.imshow(im1.asnumpy())\nplt.title(\"Two Wheels\")\nplt.show()\nplt.imshow(im2.asnumpy())\nplt.title(\"Zero Wheels\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def FineTuneAlexnet(classes, ctx):\n    '''\n    classes: number of the output classes \n    ctx: training context (CPU or GPU)\n    '''\n    finetune_net = gluon.model_zoo.vision.alexnet(classes=classes, pretrained=False, ctx=ctx)\n    finetune_net.initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)\n    pretrained_net = gluon.model_zoo.vision.alexnet(pretrained=True, ctx=ctx)\n    finetune_net.features = pretrained_net.features\n    \n    return finetune_net","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ctx = mx.gpu() # Set this to CPU or GPU depending on your training instance\nepochs = 20\nlearning_rate = 0.001\nnum_outputs = 6  # 6 output classes\nnet = model_zoo.get_model('ResNet50_v1', pretrained=True, ctx=ctx)\nnet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"softmax_cross_etropy_loss = gluon.loss.SoftmaxCrossEntropyLoss()\ntrainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': learning_rate})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def finetune_accuracy(output, label):\n    # output: (batch, num_output) float32 ndarray\n    # label: (batch, ) int32 ndarray\n    return (output.argmax(axis=1) == label.astype('float32')).mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Starting the outer loop, we will have 10 epochs (10 full pass through our dataset)\nfor epoch in range(epochs):\n    \n    train_loss, val_loss, train_acc, valid_acc = 0., 0., 0., 0.\n    \n    # Training loop: (with autograd and trainer steps, etc.)\n    # This loop does the training of the neural network (weights are updated)\n    for i, (data, label) in enumerate(train_loader):\n        data = data.as_in_context(ctx)\n        label = label.as_in_context(ctx)\n        with autograd.record():\n            output = net(data)\n            loss = softmax_cross_etropy_loss(output, label)\n        loss.backward()\n        train_acc += finetune_accuracy(output, label)\n        train_loss += loss.mean()\n        trainer.step(data.shape[0])\n    \n    # Validation loop:\n    # This loop tests the trained network on validation dataset\n    # No weight updates here\n    for i, (data, label) in enumerate(validation_loader):\n        data = data.as_in_context(ctx)\n        label = label.as_in_context(ctx)\n        output = net(data)\n        valid_acc += finetune_accuracy(output, label)\n        val_loss += softmax_cross_etropy_loss(output, label).mean()\n        \n    # Take averages\n    train_loss /= len(train_loader)\n    train_acc /= len(train_loader)\n    val_loss /= len(validation_loader)\n    valid_acc /= len(validation_loader)\n    \n    print(\"Epoch %d: train loss %.3f, train acc %.3f, val loss %.3f, val acc %.3f\" % (\n        epoch, train_loss.asnumpy()[0], train_acc.asnumpy()[0], val_loss.asnumpy()[0], valid_acc.asnumpy()[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ids = test_df[\"ID\"].values.tolist()\ntest_image_files = [file + \".jpg\" for file in test_df[\"ASIN\"].values.tolist()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = nd.zeros((len(os.listdir(test_path)), 224, 224, 3))\nfor idx, im_name in enumerate(test_image_files):\n    test_images[idx] = imresize(imread(os.path.join(test_path, im_name)), 224, 224)\n\n# make sure shuffle=False\ntest_loader = gluon.data.DataLoader(\n    transform_test(test_images),\n    batch_size=batch_size, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ctx = mx.gpu() # Set this to CPU or GPU depending on your training instance\ntest_preds = []\nfor i, data in enumerate(test_loader):\n    data = data.as_in_context(ctx)\n    pred = net(data)\n    test_preds += pred.argmax(axis=1).asnumpy().tolist()\nprint(test_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ntest_subm_df = pd.DataFrame({\"ID\": test_ids,\n                             \"label\": test_preds})\n\ntest_subm_df.to_csv(\"final_project.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}