{"cells":[{"metadata":{"_cell_guid":"635ba0f6-66eb-4743-b83d-9a25277b4968","_uuid":"3abbc49d2ccbaefc1f47f8111a208f8814b4ee9b"},"cell_type":"markdown","source":"# Wk 2. Walmart, Rik's sandbox\n\nTODO:\n* V clean up date/index shit\n* ... submit results\n* ... clean up code\n* V graph plot submission numbers into known data for evaluation\n","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"a229a5da-2d43-46c2-8551-f3c5be8a1521","_uuid":"a50db2beaca5e2ce4361624a3ff805fa39731a86","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom keras.layers import Dense, Activation, BatchNormalization, Dropout\nimport keras.models\nfrom keras import regularizers\nfrom keras import optimizers\n\nimport re, datetime, time\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"06a25e3a-14e8-48f9-be71-9f714b1dd2de","_uuid":"e498185e895a8a46e90b329c011496069517e9b1","trusted":true},"cell_type":"code","source":"print(datetime.datetime.now())","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"37e18e30-5860-41b2-8f1e-506e3994c33e","_uuid":"ee5a6a9d2e7a3ce0056dfa7b5582f55948539a78","trusted":true},"cell_type":"code","source":"def add_datepart(df, fldname, drop=True):\n    \"\"\"add_datepart converts a column of df from a datetime64 to many columns containing\n    the information from the date. This applies changes inplace.\n\n    Parameters:\n    -----------\n    df: A pandas data frame. df gain several new columns.\n    fldname: A string that is the name of the date column you wish to expand.\n        If it is not a datetime64 series, it will be converted to one with pd.to_datetime.\n    drop: If true then the original date column will be removed.\n\n    Examples:\n    ---------\n\n    >>> df = pd.DataFrame({ 'A' : pd.to_datetime(['3/11/2000', '3/12/2000', '3/13/2000'], infer_datetime_format=False) })\n    >>> df\n\n        A\n    0   2000-03-11\n    1   2000-03-12\n    2   2000-03-13\n\n    >>> add_datepart(df, 'A')\n    >>> df\n\n        AYear AMonth AWeek ADay ADayofweek ADayofyear AIs_month_end AIs_month_start AIs_quarter_end AIs_quarter_start AIs_year_end AIs_year_start AElapsed\n    0   2000  3      10    11   5          71         False         False           False           False             False        False          952732800\n    1   2000  3      10    12   6          72         False         False           False           False             False        False          952819200\n    2   2000  3      11    13   0          73         False         False           False           False             False        False          952905600\n    \n    Acknowledgment: Fast.ai ML library https://github.com/fastai/fastai/blob/master/fastai/structured.py\n    Jeremy howard c.s.\n    \"\"\"\n# Rik disabled a few attributes because our dates are Fridays only\n#               'Dayofweek', \n#               'Day', \n#               'Is_month_end', \n#               'Is_month_start', \n#               'Is_quarter_end', \n#               'Is_quarter_start', \n#               'Is_year_end', \n#               'Is_year_start'\n\n    fld = df[fldname]\n    if not np.issubdtype(fld.dtype, np.datetime64):\n        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n    targ_pre = re.sub('[Dd]ate$', '', fldname)\n    for n in ('Year', \n              'Month', \n              'Week', \n              'Dayofyear',\n             ):\n        df[targ_pre+n] = getattr(fld.dt,n.lower())\n    df[targ_pre+'Elapsed'] = fld.astype(np.int64) // 10**9\n    if drop: df.drop(fldname, axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6744355d-9408-4072-aa11-4094ca35719d","_uuid":"195dd6f20e7015db70a57cd79b2d4f937761bfd4"},"cell_type":"markdown","source":"## load data from CSV and organize","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"da5d69ca-ecf2-464c-940d-3002f1d55296","_uuid":"e6cdd5045707ec32e115e7c361b17fd7aa2b8449","trusted":true},"cell_type":"code","source":"# @rik: the only reason you indexed Date is to produce a plot\n# with blanks in it at all the right places\n\n# dateparse = lambda x: datetime.datetime.strptime(x, '%Y-%m-%d').date()\n# , date_parser=dateparse\n# , parse_dates=['Date']\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n# train.sort_values(['Date'], inplace=True)\n# test.sort_values(['Date'], inplace=True)\n\nlen_train = len(train)\nlen_test = len(test)\n\ndf = pd.concat([train,test],axis=0) # Join train and test\npristine = df.copy()\n# df['Date'] = pd.to_datetime(df['Date'])  ## FIXME if .fit() croaks\npristine['Date'] = pd.to_datetime(df['Date'])\n#### DO NOT SORT concatenated df: this will make the cat irreversible!!!!!!!!!!!!!!!!!!!!!!!\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cf0575ed-7d8f-47e5-9762-0d0404be3f18","_uuid":"cb7affb72d75ab5e49adc3645cda8a46379a0217","trusted":true},"cell_type":"code","source":"df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"c80126c5-5982-40f3-8c5f-81352914b5df","_uuid":"331970210b3d8dc4f4f60923fdcc93bc30fc2ff7","trusted":true},"cell_type":"code","source":"# engineer this:\n# list of KNOWN holidays\n# for all dates in our range, search nearest holiday: remember its name/date\n# for all dates, compute distance (pos or neg) to nearest holiday\n# engineer the distance into a number that goes high as HD nears and goes low as HD passes\n# clip this number to about 3 weeks\n# fill new column (named 'Nearest_HD') in df with name of nearest holiday\n# dummify the Nearest_HD column\n# fill column Nearest_HD in df with distance number\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"ee0891bb-1240-4714-a10f-162eeee9bdd8","_uuid":"3c42f0f159989da15c3f41cea0fa9d0c1de55809","trusted":true},"cell_type":"code","source":"def nearest_hd(d):\n    us_holidays = [\n        'xmas09',\n        'sbowl10',\n        'lday10',\n        'tnxg10',\n        'xmas10',\n        'sbowl11',\n        'lday11',\n        'tnxg11',\n        'xmas11',\n        'sbowl12',\n        'lday12',\n        'tnxg12',\n    ]\n\n    us_holidates = [\n        pd.to_datetime(\"2009, 12, 25\"),\n        pd.to_datetime(\"2010,  2,  7\"),\n        pd.to_datetime(\"2010,  9,  6\"),\n        pd.to_datetime(\"2010, 11, 25\"),\n        pd.to_datetime(\"2010, 12, 25\"),\n        pd.to_datetime(\"2011,  2,  6\"),\n        pd.to_datetime(\"2011,  9,  5\"),\n        pd.to_datetime(\"2011, 11, 24\"),\n        pd.to_datetime(\"2011, 12, 25\"),\n        pd.to_datetime(\"2012,  2,  5\"),\n        pd.to_datetime(\"2012,  9,  3\"),\n        pd.to_datetime(\"2012, 11, 22\"),\n    ]\n    \n    shortest = (datetime.datetime(2010,12,31) - datetime.datetime(2001,1,1)) # kick off with a 10 year distance\n    nearest = len(us_holidates)\n    \n    for h in range(len(us_holidates)):\n        dist = (us_holidates[h] - d)\n        if abs(dist) <= abs(shortest):\n            shortest = dist\n            nearest = us_holidays[h]\n    return(nearest, shortest.days)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1cd28248-9038-4102-847d-7da8c62b4ace","_uuid":"44bd4b9f01d82327cbf2a4b16ba8bc117ca0baed"},"cell_type":"markdown","source":"# de volgende twee cellen nog samenvoegen @rik","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"9f5e4003-c657-462c-a7cc-80c4818d9819","_uuid":"51812f6276e80adbc85b33594e203c74607d22e1","trusted":true},"cell_type":"code","source":"# for all dates in our range, search nearest holiday: remember its name/date\n# for all dates, compute distance (pos or neg) to nearest holiday\n# engineer the distance into a number that goes far negative as HD nears and\n# goes up positive at HD and lowers back to zero as HD passes\n# clip this number to about 3 weeks\n\n# all days in range dataframe (column 'Date')\nalldays = pd.unique(df['Date'])\nholi_dist = {}  # new dict\nall_holidays = [] # new array\n\n# iterate over all days;the disorfderof alldaysis irrelevant (right?!)\nfor d in alldays:\n    # compute distance proper\n    nearest, distance = nearest_hd( pd.to_datetime(d) )   # , infer_datetime_format=True\n    # engineer some number that starts at 0, goes negative as HD approaches,\n    # then at deepest negative value on the HD, goes high positive, then sissles out back to 0\n    distance = (-365 / (distance + 1e-10)) # epsilon prevents divbyzero\n    if abs(distance) < 365/21:  # clip at +/- 21 days\n        distance = 0.\n    holi_dist[d] = [nearest, distance]\n    if not nearest in all_holidays:\n        all_holidays.append(nearest)\n\nall_holidays","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"scrolled":true,"_cell_guid":"4b26fd31-7ac8-4ea7-bc9c-2b96f2979c15","_uuid":"1c6f5058ff110d4a8e6d67bcde822883001de711","trusted":true},"cell_type":"code","source":"alldays = pd.unique(df['Date'])\n\n# iterate over all dates in use,\n# lookup what holiday is nearest and what the distance is (this was precomputed, dunno why anymore)\n# stick the distance value in the column named for the holiday\nfor d in alldays:\n    nearest, distance = holi_dist[d]\n    # fill the rows with this Date in corresponding holiday-column with the computed \"distance\"\n    df.loc[ df['Date'] == d, nearest] = distance \n\n# fill NANs with 0s\nfor holiday in all_holidays:\n    df[holiday].fillna(0., inplace=True)  # this appears to miss the tnxg12 column somehow?!?!\n\n# the following may not be good: \"A value is trying to be set on a copy of a slice from a DataFrame\"\n# df[all_holidays].fillna(0, inplace=True) # fill NAs with zeroes\n\n# we might as wel drop IsHoliday from dataframe altogether\n# if 'IsHoliday' in df.columns:\n#     df.drop('IsHoliday', inplace=True, axis=1)\n\nif \"nan\" in df.columns:\n    print(\"We have NaNs as column labels now!!\")\n#     df.drop('nan', inplace=True, axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"041e5d4e-78bd-41c3-9126-f5cf7fb89878","_uuid":"18a9b312de0f6a6c8d656c67498dab4593a24d68","trusted":true,"collapsed":true},"cell_type":"code","source":"# # show results\n# where = (df['Store'] == 1) & (df['Dept'] == 1) \n# # select = ['Weekly_Sales', 'IsHoliday']\n# rik = df.loc[where, all_holidays]\n# rik.iloc[:10]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"df27858a-960c-4f49-a8bc-e781fc146ea4","_uuid":"f0f6ce15863857f887f5e1ba1d5fee94ef5dd6e3","trusted":true},"cell_type":"code","source":"# This clever function adds numerical and boolean fields for every(?) conceivable attribute of a Date object as new colums to df\nadd_datepart(df, 'Date')\ndf['Week'][:4]","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"d2894937-b495-472a-8806-51768e7708b3","_uuid":"4d5beb736e6235265b6e16d5b458414278c6e4fa","trusted":true},"cell_type":"code","source":"# Markdown engineering:\n\n# create 5 new boolean features for the 5 different markdowns\ndf = df.assign(md1_present = df.MarkDown1.notnull())\ndf = df.assign(md2_present = df.MarkDown2.notnull())\ndf = df.assign(md3_present = df.MarkDown3.notnull())\ndf = df.assign(md4_present = df.MarkDown4.notnull())\ndf = df.assign(md5_present = df.MarkDown5.notnull())","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"6df1ba49-b6fb-44db-aa7b-07dbe5891428","_uuid":"e8fff96f0c7ea5d6e12f52db02719672b6d71f95","trusted":true},"cell_type":"code","source":"# standardize the following numerical columns\nstdnums = [\n    \"Temperature\",\n    \"Unemployment\",\n    \"CPI\",\n    \"Fuel_Price\",\n    \"MarkDown1\",\n    \"MarkDown2\",\n    \"MarkDown3\",\n    \"MarkDown4\",\n    \"MarkDown5\",\n    \"Size\",\n    'Year', \n    'Month', \n    'Week', \n    'Dayofyear',\n#     'xmas09',\n    'sbowl10',\n    'lday10',\n    'tnxg10',\n    'xmas10',\n    'sbowl11',\n    'lday11',\n    'tnxg11',\n    'xmas11',\n    'sbowl12',\n    'lday12',\n    'tnxg12',\n]\n\nfor n in stdnums:\n    df[n] = (df[n] - df[n].mean())/(df[n].std())\n\n# # rescale the following numerical columns\n# normnums = [\n#     \"Week\",\n#     \"Dayofyear\",\n#     \"Elapsed\",\n# ]\n# for n in normnums:\n#     df[n] = (df[n] - df[n].mean()) / abs(1e-16 + df[n].max() - df[n].min())\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"5083e1ee-0147-4fc0-9e0f-0fc319f824cd","_uuid":"c7e8f8e5a9be131a70a7aaf51ea67b3a6bf39200","trusted":true},"cell_type":"code","source":"# create dummy features/columns for categorical data\n\ncatcats = [\n#     \"Year\",\n#     \"Month\",\n    \"Type\",\n    \"Store\",\n    \"Dept\",\n]\n\nfor c in catcats:\n    df[c] = c + df[c].map(str)\n    temp_dummies = pd.get_dummies(df[c])\n    df = pd.concat([df, temp_dummies], axis=1)\n    del df[c]\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"09e1d269-b94f-44ed-8263-b7e49d2ea255","_uuid":"7c8ac7811f94fd39d0b81d121e33a0d0aef71df7"},"cell_type":"markdown","source":"# one more feature: mean weekly sales\n\nper Store, per Dept, the mean Weekly_Sales is ca 10445. Let's introduce that number as one input in the mix, so the model has something to scale by. Do not standardize/normalize this input!","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"7d5a10c3-84a4-4519-b0ac-96bb880956c9","_uuid":"62b4cf5349a3e57b41059e0a1038cdd33ed0b5c7","trusted":true},"cell_type":"code","source":"df['MWS'] = 10445","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a1636431-b16a-4b75-80ff-fab63f47415d","_uuid":"014874f23c28ed578397c5f0caf564a6ac51b149","trusted":true},"cell_type":"code","source":"# show results\nwhere = (df['Store1'] == 1) & (df['Dept90'] == 1) \ndf.loc[where][:12]","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"1eb50987-eb3a-414a-ba30-7340bd87b924","_uuid":"b0071029a653078d21734cf41498c21fe0439c9a","trusted":true},"cell_type":"code","source":"# plots sales and holidays in time for specific Store/Dept\ndef plot_store_dept(plotme):\n    wsm = plotme.Weekly_Sales.mean()\n    fig, ax = plt.subplots(figsize=(13,5))\n    ax.set_ylabel(\"Weekly_Sales\")\n    ax.bar(x=plotme.index, height=plotme[\"Weekly_Sales\"],width=7, label=\"known sales\")\n    ax.axhline(y=wsm, c='c', label=\"known sales mean\")\n    ax.plot_date(x=plotme.index, y=(plotme[\"IsHoliday\"] * wsm), fmt='*m')\n    ax.legend()\n    plt.title(f\"Store: {store}\\nDept: {dept}\")\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"72324a94-7b67-48a2-90ee-baaa4b2ef512","_uuid":"2131b1840089e5f69b42e6c0fd44dc06586c963f","trusted":true},"cell_type":"code","source":"store=1\ndept=0","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"_cell_guid":"b3374b5f-f936-4650-83d8-d47cb64955f7","_uuid":"78fddcab4edab136b08f19618c92a7f2d4abb35f","trusted":true},"cell_type":"code","source":"dept += 1\nwhere = (pristine[\"Store\"] == store) & (pristine[\"Dept\"] == dept) \nselect = ['Date', 'Weekly_Sales', 'IsHoliday']\nplotme = pristine.loc[where, select]\nplotme.set_index('Date', inplace=True)\nplot_store_dept(plotme)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1f4a6e21-6673-4252-8c17-ef8d4ade7b7a","_uuid":"dc8046f5661871f86985fec1764fc64c5e2a49d2","trusted":true},"cell_type":"code","source":"len(df)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"5efef214-dc4b-49f0-9378-3b29a504ee5c","_uuid":"2a68eacb355c4a72a3119a01738f466c833348ed","trusted":true},"cell_type":"code","source":"# .isnull() does NOT return zeroes! it returns NaNs\n# df.isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"e3d2b2c8-a4fc-4f35-8b3a-48ec211d5943","_uuid":"9f38dae1f64db70322010e3b95002f0b1eb35748","trusted":true},"cell_type":"code","source":"if 'Date' in df.columns:\n    df.drop('Date', inplace=True, axis=1)\n# df.head()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"1dd157e7-7394-4916-afc6-d5384c54977c","_uuid":"1b6b9893fbb85f019c7423ff103af85093b68498","trusted":true},"cell_type":"code","source":"df.fillna(0, inplace=True) # fill NAs with zeroes","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"b1f8df7c-34c2-4feb-b866-981acd3ac1a7","_uuid":"cb1db2914570a81fdfccaab34ee3988618ded304","trusted":true},"cell_type":"code","source":"train = df.iloc[:len_train]\ntest = df.iloc[len_train:]\n\ntest = test.drop('Weekly_Sales',axis=1) # We should remove the nonsense values from test\n\ny = train['Weekly_Sales'].values\nX = train.drop('Weekly_Sales',axis=1).values","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"1b0c15ca-ffe9-4471-8dd2-ce1f99cd71d1","_uuid":"0fb1f7b311a935468bee012e59dc2adfd1d4b070","trusted":true},"cell_type":"code","source":"# train.iloc[1]","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"8ffc9d36-ecdd-4255-9488-ae5b32eb03ae","_uuid":"29e9bea1bc40aa340c3ec84a965c1ddba905e299","trusted":true},"cell_type":"code","source":"# train.to_csv('train_featured.csv',index=False)\n# test.to_csv('test_featured.csv',index=False)\n# ! ls -l *csv","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"d1a018a2-1b83-4fe1-b2ce-31f7212ff528","_uuid":"812b812dccdf0a179310857ef086f141650c59e0","trusted":true},"cell_type":"code","source":"# Split separate numpy arrays for train and test\n# or, alternatively: order .fit() to take its own splits\n\n# np.random.seed(0)\n# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.0020, random_state=0)\n# X=X_train\n# y=y_train\n# print(X.shape, X_val.shape)\n# m_val,n_val = X_val.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1fc2009-1d3a-4704-b6da-00424182aac9","_uuid":"cd78d92d6885fc8b44b0a8fd4020aa456fcd9ac7","trusted":true},"cell_type":"code","source":"# last sanity check\nwhere = (df['Store1'] == 1) & (df['Dept90'] == 1) \n# select = ['Weekly_Sales', 'IsHoliday']\ndf.loc[where][:12]","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"cf9bc712-f960-41f1-9006-31cba4c636a4","_uuid":"970696b8efa21d3f8793aa117920c6baf6db9b8a","trusted":true},"cell_type":"code","source":"m,n = X.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dd1bf05a-1eff-4ac8-87eb-8dc284dba25d","_uuid":"01012332a7257684c42313aec2d71f0830e5011d"},"cell_type":"markdown","source":"## Tweak your hyper parameters here","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"4af64497-aca2-4234-b40f-3df13b979daa","_uuid":"17f0be861b367944be90baa3afe2663752e06dd9","trusted":true},"cell_type":"code","source":"lamb = .01   # regularization rate\ndrop = 0.10  # dropout rate","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"0c6c1b13-2619-42a4-aa5a-bfdc835d69e4","_uuid":"969608483f32f3fbd3c21731c0e0b9a2e0babd35","trusted":true},"cell_type":"code","source":"model = keras.models.Sequential()\n\n#, kernel_regularizer = regularizers.l2(lamb)\n\nmodel.add(Dense(units=n//5, input_dim=n))\n# model.add(BatchNormalization())\nmodel.add(Activation('tanh'))\n# model.add(Dropout(rate=drop))\n\nmodel.add(Dense(units=n//10))\n# model.add(BatchNormalization())\nmodel.add(Activation('tanh'))\n# model.add(Dropout(rate=drop))\n\nmodel.add(Dense(units=n//10))\n# model.add(BatchNormalization())\nmodel.add(Activation('tanh'))\n# model.add(Dropout(rate=drop))\n\nmodel.add(Dense(units=n//15))\n# model.add(BatchNormalization())\nmodel.add(Activation('tanh'))\n# model.add(Dropout(rate=drop))\n\nmodel.add(Dense(units=1))\nmodel.add(Activation('linear'))\n\nmodel.compile(optimizer=optimizers.adam(lr=28), loss='mae')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_cell_guid":"03a6e800-359b-4d08-a016-a48e5f1346f1","_uuid":"5b69dd7ec45ae919c9fd347c34df63e5b9d47ed1","trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"df8b8301-d60c-40a0-bec6-c24be5f53e46","_uuid":"de797f67c50f2d77fa4513a5f6f6326076efe247"},"cell_type":"markdown","source":"## alpha, batchsize, epochs","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"b037f095-4de1-44f3-8d54-4aca0c645395","_uuid":"eeb75625a4b039b6db5bafdeb14db7ab79ce7635","trusted":true},"cell_type":"code","source":"# these hyper parameters can be tweaked after compiling the model\n# this is useful for retraining an existing model under different params\nalpha = 10    # learning rate\nbs = min(2**14, m//2)  # batch size: maxed at half size testset\nepochs = 5  # number of epochs per training round","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"af2e1ef8-c211-48bd-ac63-972240289689","_uuid":"18fd830fea36a322b23657e20397a915e31a1cd0","trusted":true},"cell_type":"code","source":"model.optimizer.lr = alpha","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"02c45326-ab77-4ac3-8d08-5b6b936c6642","_uuid":"45262d845573697904740953fbed911139e06a7e","trusted":true},"cell_type":"code","source":"# evaluate model on training and validation sets\nprint(\"Loss by Mean Absolute Error\")\n\nprint(\"train:      \", model.evaluate(x=X,     y=y,     verbose=1, batch_size=bs))\n# print(\"validation: \", model.evaluate(x=X_val, y=y_val, verbose=0, batch_size=bs))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2a85f91c-3bfa-4db5-9ae0-7f47cc04157b","_uuid":"eb0ab186bbf856181584a6c41609f9884fd2cbf4"},"cell_type":"markdown","source":"# start training","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"3b56a94e-a08b-4fcd-9053-49e9a2cc9af9","_uuid":"0d3ad1ed29b2ddda056f028c806abb49ee4ef22d","trusted":true},"cell_type":"code","source":"timestart = datetime.datetime.now()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_cell_guid":"fcd69f31-9ccd-46b5-9232-24289ecf66d0","_uuid":"36adb66470ba4ade2b76c2023760f2059dbc28bd","trusted":true},"cell_type":"code","source":"# def keepon_training():\nprint(\"Learning Rate: %f, BatchSize: %i \"% (alpha, bs))\nhistory = model.fit(X,y,batch_size=bs,epochs=epochs, validation_split=0.1, verbose =1)\nloss = int(model.evaluate(x=X,     y=y,     verbose=0, batch_size=bs))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"293456b85d1d0c4c8fbd23025fc9044f73bfa7e0"},"cell_type":"code","source":"# fname = f\"nearest_holiday_model_loss_{loss}.h5\"\n# model.save(fname)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f88e1f1a-e382-4f26-9496-2d3f6e511ad2","_uuid":"8bb2f5b1cddc4e6eecf0afcd0ac5251cc0f58634","trusted":true},"cell_type":"code","source":"timedone = datetime.datetime.now()\nruntime = timedone - timestart\nprint(runtime)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d85e1b44-5c10-403d-b511-75914756e5d1","_uuid":"7f1cbd935fc7f628a5a0eed0accd537ece64da37"},"cell_type":"markdown","source":"# stop training","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"b46649c8-8da6-456e-8a6e-3221e6d82ac3","_uuid":"a3e2360547ebdd08f83c4a6b6c1ccc99b4be960e","trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.title('model loss (mae)')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"930ed539-6347-4cf7-a096-ad66631a6f74","_uuid":"dddfb7b90934a964a0941c982b2753b2846552b5","trusted":true},"cell_type":"code","source":"# evaluate model on training and validation sets\n# bs_eval = min(m, m_val)\nprint(\"Loss by Mean Absolute Error\")\nprint(\"train:      \", loss)\n# print(\"validation: \", model.evaluate(x=X_val, y=y_val, verbose=0, batch_size=bs_eval))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"fb3b8bbf-bc56-47df-a8d9-aaf512acbdb2","_uuid":"79a5eed1275737fec7e776ed73bc3e7ddc056d61","trusted":true},"cell_type":"code","source":"X_test = test.values\ny_pred = model.predict(X_test,batch_size=bs)\ntestfile = pd.read_csv('../input/test.csv')\nsubmission = pd.DataFrame({'id':testfile['Store'].map(str) + '_' + testfile['Dept'].map(str) + '_' + testfile['Date'].map(str),\n                          'Weekly_Sales':y_pred.flatten()})\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"33aed7c2-51ba-439e-9543-618ed5f45029","_uuid":"52e55b27d39df5d049d36998601ff89c4b655574","trusted":true},"cell_type":"code","source":"! ls -l submission.csv\n! wc -l submission.csv","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_cell_guid":"8cc189f0-b870-4ea7-a4f6-cd3a158885e9","_uuid":"8a5393a5905db625bad683f9b4fcb5fb8635eb64","trusted":true,"collapsed":true},"cell_type":"code","source":"# submission.head(20)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dfc2cd2b-6723-4c01-a792-85ab5e19ec87","_uuid":"fc8475b58cff860ecb2b222ed049c87157842f18","trusted":true,"collapsed":true},"cell_type":"code","source":"predicted = testfile.copy()\npredicted['Weekly_Prediction'] = y_pred\npredicted = pd.concat([predicted,pristine],axis=0) # Join predicted and pristine\n# df['time'] = df['time'].astype('datetime64[ns]')\npredicted['Date'] = predicted['Date'].astype('datetime64[ns]')\npredicted.set_index(['Date'], inplace=True)\n# predicted.Weekly_Prediction *= 15 # cause we're desprt\n# predicted.index","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"1eb50987-eb3a-414a-ba30-7340bd87b924","_uuid":"b0071029a653078d21734cf41498c21fe0439c9a","trusted":true},"cell_type":"code","source":"# plots sales and predicted sales in time for specific Store/Dept\ndef plot_store_dept_pred(plotme):\n    wpm = int(plotme.Weekly_Prediction.mean())\n    wsm = int(plotme.Weekly_Sales.mean())\n    fig, ax = plt.subplots(figsize=(13,4))\n    ax.set_ylabel(\"Sales\")\n    ax.bar(x=plotme.index, height=plotme[\"Weekly_Sales\"],width=7, label=\"known sales\")\n    ax.axhline(y=wsm, c='c', label=f\"known sales mean {wsm}\")\n    ax.bar(x=plotme.index, height=plotme[\"Weekly_Prediction\"],width=5, \n           label=\"predicted sales\", color='r')\n    ax.axhline(y=wpm, c='g', label=f\"predicted sales mean {wpm}\")\n    ax.plot_date(x=plotme.index, y=(plotme[\"IsHoliday\"] * wsm), fmt='*m')\n    ax.legend()\n#     ax.xaxis_date()\n    plt.title(f\"Store: {store}\\nDept: {dept}\")\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"239e46ef-a7b5-4d71-8238-b22dfcce9685","_uuid":"07582274767bba9a26847c7d638dbc5ceea3092a","trusted":true},"cell_type":"code","source":"store=0\ndept=10","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_cell_guid":"225dd30c-4a42-47ac-aa76-79f615828f6d","_uuid":"33de4e324596d2448d8067a3f88eafd09252bf1d","trusted":true},"cell_type":"code","source":"store += 1\n# dept  += 1\n\nwhere = (predicted['Store'] == store) & (predicted['Dept'] == dept)\nselect = ['Date', 'Weekly_Prediction', 'Weekly_Sales', 'IsHoliday']\nplotme = predicted.loc[where, select]\nplot_store_dept_pred(plotme)\n# print(plotme.Weekly_Prediction.mean(),plotme.Weekly_Sales.mean())\n# print(plotme.Weekly_Prediction.count(),plotme.Weekly_Sales.count())","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"9749a530-7c5a-4212-a5a8-da23a470ccef","_uuid":"982afaf0d75f83c6af3b6978441fba522f668269","trusted":true},"cell_type":"code","source":"# undertow cells in notebook?","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"9749a530-7c5a-4212-a5a8-da23a470ccef","_uuid":"982afaf0d75f83c6af3b6978441fba522f668269","trusted":true},"cell_type":"code","source":"# undertow cells in notebook?","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"9749a530-7c5a-4212-a5a8-da23a470ccef","_uuid":"982afaf0d75f83c6af3b6978441fba522f668269","trusted":false},"cell_type":"code","source":"# undertow cells in notebook?","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"9749a530-7c5a-4212-a5a8-da23a470ccef","_uuid":"982afaf0d75f83c6af3b6978441fba522f668269","trusted":false},"cell_type":"code","source":"# undertow cells in notebook?","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"9749a530-7c5a-4212-a5a8-da23a470ccef","_uuid":"982afaf0d75f83c6af3b6978441fba522f668269","trusted":false},"cell_type":"code","source":"# undertow cells in notebook?","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"cd252dd0-2f05-4959-8752-5bed8e5ce1a3","_uuid":"73b8557ae1efebe6934e7760670961a72c7ba895","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}