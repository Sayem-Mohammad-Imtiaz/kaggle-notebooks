{"cells":[{"metadata":{},"cell_type":"markdown","source":"# iSpam - Spam Message Detector\n### Developed By : Harsh Navin Gupta","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\ndataset_path = \"\"\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        dataset_path = os.path.join(dirname, filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv(dataset_path, delimiter=',', encoding='latin-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['Category'] = dataset['v1']\ndataset['Message'] = dataset['v2']\ndataset.drop(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msgs = dataset['Message']\ncategory = dataset['Category']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msgs_len = []\nfor m in msgs:\n    msgs_len.append(len(m))\nfig = go.Figure(data=[go.Histogram(x=msgs_len)])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since most of the messages have a length less than or equal to 200 words, all the entries in the dataset, which have the length > 200 are removed from the dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset[dataset['Message'].map(len) <= 200]\nmsgs = dataset['Message']\ncategory = dataset['Category']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"category.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Label Encoding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nencoder.fit(category)\ncategory = encoder.fit_transform(category)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bag Of Words Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Train & Test Split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = msgs\ny = category\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X Train Shape : ' + str(X_train.shape))\nprint('Y Train Shape : ' + str(y_train.shape))\nprint('X Test Shape : ' + str(X_test.shape))\nprint('Y Test Shape : ' + str(y_test.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Vectorization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer()\nvectorizer.fit(X_train)\nX_train = vectorizer.transform(X_train)\nX_test = vectorizer.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X Train Shape After Vectorization : ' + str(X_train.shape))\nprint('X Test Shape After Vectorization : ' + str(X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training Neural Network","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\n\nmodel = Sequential()\nmodel.add(Dense(32, input_dim=7310, activation='relu'))\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(4, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='adam',\n             loss='binary_crossentropy',\n             metrics = ['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 50\nhistory = model.fit(X_train, y_train,\n                   validation_data = (X_test, y_test),\n                   epochs = num_epochs,\n                   batch_size = 200,\n                   verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch_range = list(range(1, num_epochs + 1))\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=epoch_range, y=acc, name='Train Accuracy', mode='lines+markers'))\nfig.add_trace(go.Scatter(x=epoch_range, y=val_acc, name='Test Accuracy', mode='lines+markers'))\nfig.update_layout(title='Train & Test Accuracy Trend',\n                   xaxis_title='Epochs',\n                   yaxis_title='Accuracy Of Model')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=epoch_range, y=loss, name='Train Loss', mode='lines+markers'))\nfig.add_trace(go.Scatter(x=epoch_range, y=val_loss, name='Test Loss', mode='lines+markers'))\nfig.update_layout(title='Train & Test Loss Trend',\n                   xaxis_title='Epochs',\n                   yaxis_title='Loss')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Best Number Of Epochs Is : 7","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bw_model = Sequential()\nbw_model.add(Dense(32, input_dim=7310, activation='relu'))\nbw_model.add(Dense(16, activation='relu'))\nbw_model.add(Dense(4, activation='relu'))\nbw_model.add(Dense(1, activation='sigmoid'))\n\nbw_model.compile(optimizer='adam',\n             loss='binary_crossentropy',\n             metrics = ['accuracy'])\n\nnum_epochs = 7\nhistory = bw_model.fit(X_train, y_train,\n                   validation_data = (X_test, y_test),\n                   epochs = num_epochs,\n                   batch_size = 200,\n                   verbose=False)\n\nloss, train_acc = bw_model.evaluate(X_train, y_train, verbose=False)\nloss, test_acc = bw_model.evaluate(X_test, y_test, verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training Accuracy : ' + str(train_acc))\nprint('Testing Accuracy : ' + str(test_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\npred = bw_model.predict_classes(X_train)\ntrain_f1 = f1_score(y_train, pred)\npred = bw_model.predict_classes(X_test)\ntest_f1 = f1_score(y_test, pred)\n\nprint('Train F1 Score : ' + str(train_f1))\nprint('Test F1 Score : ' + str(test_f1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bw_model_json = bw_model.to_json()\nwith open(\"bw_model.json\", \"w\") as json_file:\n    json_file.write(bw_model_json)\nbw_model.save_weights(\"bw_model.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using Word Embeddings","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Train & Test Split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = msgs\ny = category\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X Train Shape : ' + str(X_train.shape))\nprint('Y Train Shape : ' + str(y_train.shape))\nprint('X Test Shape : ' + str(X_test.shape))\nprint('Y Test Shape : ' + str(y_test.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tokenization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\ntokenizer = Tokenizer(num_words = 10000)\ntokenizer.fit_on_texts(X_train)\n\nX_train = tokenizer.texts_to_sequences(X_train)\nX_test = tokenizer.texts_to_sequences(X_test)\n\nvocab_size = len(tokenizer.word_index) + 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Padding Sequences","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\nmaxlen = 200\n\nX_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\nX_test = pad_sequences(X_test, padding='post', maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_dim = 300\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, GlobalMaxPool1D, Embedding\n\nmodel = Sequential()\nmodel.add(Embedding(input_dim = vocab_size,\n                   output_dim = embedding_dim,\n                   input_length = maxlen))\nmodel.add(GlobalMaxPool1D())\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(4, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n             optimizer='adam',\n             metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 50\nhistory = model.fit(X_train, y_train,\n                   epochs=num_epochs,\n                   validation_data = (X_test, y_test),\n                   batch_size = 200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch_range = list(range(1, num_epochs + 1))\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=epoch_range, y=acc, name='Train Accuracy', mode='lines+markers'))\nfig.add_trace(go.Scatter(x=epoch_range, y=val_acc, name='Test Accuracy', mode='lines+markers'))\nfig.update_layout(title='Train & Test Accuracy Trend',\n                   xaxis_title='Epochs',\n                   yaxis_title='Accuracy Of Model')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=epoch_range, y=loss, name='Train Loss', mode='lines+markers'))\nfig.add_trace(go.Scatter(x=epoch_range, y=val_loss, name='Test Loss', mode='lines+markers'))\nfig.update_layout(title='Train & Test Loss Trend',\n                   xaxis_title='Epochs',\n                   yaxis_title='Loss')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Best Number Of Epochs Is 21","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"embedding_dim = 300\n\nem_model = Sequential()\nem_model.add(Embedding(input_dim = vocab_size,\n                   output_dim = embedding_dim,\n                   input_length = maxlen))\nem_model.add(GlobalMaxPool1D())\nem_model.add(Dense(16, activation='relu'))\nem_model.add(Dense(4, activation='relu'))\nem_model.add(Dense(1, activation='sigmoid'))\n\nem_model.compile(loss='binary_crossentropy',\n             optimizer='adam',\n             metrics=['accuracy'])\n\nnum_epochs = 21\nhistory = em_model.fit(X_train, y_train,\n                   epochs=num_epochs,\n                   validation_data = (X_test, y_test),\n                   batch_size = 200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, train_acc = em_model.evaluate(X_train, y_train, verbose=False)\nloss, test_acc = em_model.evaluate(X_test, y_test, verbose=False)\n\nprint('Train Accuracy : ' + str(train_acc))\nprint('Test Accuracy : ' + str(test_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\npred = em_model.predict_classes(X_train)\ntrain_f1 = f1_score(y_train, pred)\npred = em_model.predict_classes(X_test)\ntest_f1 = f1_score(y_test, pred)\n\nprint('Train F1 Score : ' + str(train_f1))\nprint('Test F1 Score : ' + str(test_f1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"em_model_json = em_model.to_json()\nwith open(\"em_model.json\", \"w\") as json_file:\n    json_file.write(em_model_json)\nem_model.save_weights(\"em_model.h5\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}