{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom warnings import filterwarnings\n\nfrom matplotlib.pyplot import figure\nfrom pandas import read_csv\nfrom seaborn import heatmap\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom catboost import CatBoostRegressor\nfrom tqdm.notebook import tqdm\n\n\nfilterwarnings(\"ignore\")\ntqdm.pandas()\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Support class and functions*"},{"metadata":{"trusted":true},"cell_type":"code","source":"class FreqEncoder:\n    \"\"\"Simple encoding categorical features by frequency.\"\"\"\n    \n    def __init__(self):\n        self._freqs = None\n            \n    def _freq_encoding(self, data, column):\n        \"\"\"Use frequency as encoding value\"\"\"\n        self._freqs[column] = data.groupby(column).size() / len(data)\n    \n    def fit(self, data):\n        \"\"\"Compute freq for each columns\"\"\"\n        self._freqs = {}\n        for column in data.columns:\n            freq_encoding(data)\n    \n    def transform(self, data):\n        \"\"\"Transform columns\"\"\"\n        if not self._freqs:\n            raise ValueError(\"Encoder didn't fit.\\n\")\n        for column in data.columns:\n            data[column] = data[column].map(self._freqs[column])\n        return data\n    \n    def fit_transform(self, data):\n        \"\"\"Compute freq and transform for each columns\"\"\"\n        self._freqs = {}\n        for column in data.columns:\n            self._freq_encoding(data, column)\n            data[column] = data[column].map(self._freqs[column])\n        return data\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def weird_division(num, divisor):\n    \"\"\"Function form unique and resplendent notebook.\"\"\"\n    return num / divisor if divisor else 0\n\n\ndef prepcoress_data(data, drop_columns):\n    \"\"\"Create target, drop unnecessary columns.\"\"\"\n    data[\"viewable/measurable\"] = data.progress_apply(\n        lambda row: weird_division(row[\"viewable_impressions\"], row[\"measurable_impressions\"]),\n        axis=1\n    )\n    data[\"CPM\"] = data.progress_apply(\n        lambda row: weird_division(row[drop_columns[-2]] * 100, row[drop_columns[-1]]) * 1000,\n        axis=1\n    )\n    data = data[data[\"CPM\"] >= 0]\n    # drop unnecesary columns\n    data.drop(labels=drop_columns, axis=1, inplace=True)\n    return data\n\n\ndef freq_encoding(dataset, column):\n    \"\"\"Use frequency as encoding value\"\"\"\n    freq = dataset.groupby(column).size() / len(dataset)\n    data[column] = data[column].map(freq)\n    return data\n\n\ndef train_test(dataset, mask, train_cut=(.025, .975)):\n    \"\"\"Split data on train test validate.\"\"\"\n    # split train test\n    train = dataset[mask]\n    test = dataset[~mask]\n    # cut train 2.5% to 97.5% by default\n    quantile = (train[\"CPM\"].quantile(train_cut[0]), train[\"CPM\"].quantile(train_cut[1]))\n    train = train[train[\"CPM\"].between(*quantile)]\n    # cut test 0% to 95%\n    test = test[test[\"CPM\"] < test[\"CPM\"].quantile(.95)]\n    return train, test\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Read dataset*"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data = read_csv(\"/kaggle/input/real-time-advertisers-auction/Dataset.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Preprocess dataset (create target, drop unnecessary colummns)*"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"drop_columns = [\n    \"integration_type_id\", \"revenue_share_percent\",\n    \"viewable_impressions\",\n    \"total_revenue\", \"measurable_impressions\"\n]\ndata = prepcoress_data(data, drop_columns)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(f\"Count not NaN:\\n{data.notna().count()}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Split data on train and test. Cut test by 95 percentile, train quantile can be configure*"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"mask = (data[\"date\"] < \"2019-06-22 00:00:00\")\ntrain, test = train_test(data, mask, train_cut=(.06, 0.94))\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Compute rank correleation*"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"columns = train.columns\ncat_columns = [column for column in columns if \"id\" in column]\ncat_corr = train[cat_columns].corr(method=\"spearman\")\nfigure(figsize=(14, 8))\nheatmap(cat_corr, square=True, annot= True, cmap=\"seismic\", vmin=0, vmax=1);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Drop columns with high correlation*"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(labels=[\"site_id\"], axis=1, inplace=True)\ncolumns = train.columns\ncat_columns = [column for column in columns if \"id\" in column]\ncat_corr = train[cat_columns].corr(method=\"spearman\")\nfigure(figsize=(14, 8))\nheatmap(cat_corr, square=True, annot= True, cmap=\"seismic\", vmin=0, vmax=1);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Apply frequency encoding to categorical columns*"},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = FreqEncoder()\ncolumns = train.columns\ncat_columns = [column for column in columns if \"id\" in column]\ntrain[cat_columns] = encoder.fit_transform(train[cat_columns])\ntest[cat_columns] = encoder.transform(test[cat_columns])\ntrain.drop(labels=[\"date\"], axis=1, inplace=True)\ntest.drop(labels=[\"date\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"corr = train[cat_columns].corr(method=\"spearman\")\nfigure(figsize=(14, 8))\nheatmap(corr, square=True, annot= True, cmap=\"seismic\", vmin=0, vmax=1);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Split train datset on split_train, split_validate*"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = train.columns\nsplit_train, split_validate = train_test_split(\n    train, test_size=0.1, shuffle=True, random_state=42\n)\nsplit_x_train, split_y_train = split_train[columns[: -1]], split_train[\"CPM\"]\nsplit_x_validate, split_y_validate = split_validate[columns[: -1]], split_validate[\"CPM\"]\nx_test, y_test = test[columns[: -1]], test[\"CPM\"]\nprint(\n    f\"Split x_tran: {split_x_train.shape}\", f\"Split y_tran: {split_y_train.shape}\",\n    f\"Split x_validate: {split_x_validate.shape}\", f\"Split y_validate: {split_y_validate.shape}\",\n    f\"Split x_test: {x_test.shape}\", f\"Split y_test: {y_test.shape}\", sep=\"\\n\"\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Train with validate dataset*"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"model = CatBoostRegressor(random_state=42, verbose=200, iterations=3000)\nmodel.fit(\n    split_x_train, split_y_train, eval_set=(split_x_validate, split_y_validate),\n    use_best_model=True, early_stopping_rounds=20\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Feature importances:\")\nfor name, importance in zip(model.feature_names_, model.feature_importances_):\n    print(f\"  -{name}: {round(importance, 4)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Predict by model which was fited with validte dataset*"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(x_test)\nprint(f\"MSE: {mean_squared_error(y_test, y_pred)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Train without validate dataset*"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostRegressor(random_state=42, verbose=200, iterations=3000)\nx_train, y_train = train[columns[: -1]], train[\"CPM\"]\nmodel.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Feature_importances\")\nfor name, importance in zip(model.feature_names_, model.feature_importances_):\n    print(f\"  -{name}: {round(importance, 4)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Predict by model which was fited on full train dataset*"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(x_test)\nprint(f\"MSE: {mean_squared_error(y_test, y_pred)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}