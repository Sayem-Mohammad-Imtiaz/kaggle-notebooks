{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"demo = pd.read_csv('/kaggle/input/yeh-concret-data/Concrete_Data_Yeh.csv')\ndemo.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(demo.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = demo[[\"cement\",\"superplasticizer\",\"age\",\"water\",\"flyash\",\"coarseaggregate\",\"fineaggregate\",\"slag\"]]\ny = demo[[\"csMPa\"]]\nx_train,x_test,y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=10)\nfrom sklearn.linear_model import LinearRegression\nmodel2 = LinearRegression()\nmodel2.fit(x_train,y_train)\nprint(model2.coef_)\nprint(model2.intercept_)\nprint(\"What is the Testing R2\")\nprint(model2.score(x_test,y_test))\nprint(\"What is the Training R2\")\nprint(model2.score(x_train,y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = demo[[\"cement\"]]\ny = demo[[\"csMPa\"]]\nx_train,x_test,y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=10)\nfrom sklearn.linear_model import LinearRegression\nmodel2 = LinearRegression()\nmodel2.fit(x_train,y_train)\nprint(model2.coef_)\nprint(model2.intercept_)\nprint(\"What is the Testing R2\")\nprint(model2.score(x_test,y_test))\nprint(\"What is the Training R2\")\nprint(model2.score(x_train,y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = demo[[\"superplasticizer\"]]\ny = demo[[\"csMPa\"]]\nx_train,x_test,y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=10)\nfrom sklearn.linear_model import LinearRegression\nmodel2 = LinearRegression()\nmodel2.fit(x_train,y_train)\nprint(model2.coef_)\nprint(model2.intercept_)\nprint(\"What is the Testing R2\")\nprint(model2.score(x_test,y_test))\nprint(\"What is the Training R2\")\nprint(model2.score(x_train,y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [\"cement\",\"superplasticizer\",\"age\",\"water\",\"flyash\",\"coarseaggregate\",\"fineaggregate\",\"slag\"]\nfrom sklearn.linear_model import LinearRegression\nmodel2 = LinearRegression()\n    \nfor feature in features:\n    print(feature)\n    x = demo[[feature]]\n    y = demo[[\"csMPa\"]]\n    x_train,x_test,y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=10)    \n   \n    model2.fit(x_train,y_train)\n    print(model2.coef_)\n    print(model2.intercept_)\n    print(\"What is the Testing R2\")\n    print(model2.score(x_test,y_test))\n    print(\"What is the Training R2\")\n    print(model2.score(x_train,y_train))\n    print('#############################')\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX=demo.drop('csMPa',axis=1)\ny=demo['csMPa']\nXtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size= .20,random_state=10)\nlr=LinearRegression()\nlr.fit(Xtrain,ytrain)\nprint(\"Training R2\")\nprint(lr.score(Xtrain,ytrain))\nprint(\"Testing R2\")\nprint(lr.score(Xtest,ytest))\npredicted = lr.predict(Xtest)\nprint(\"RMSE\")\nprint(np.sqrt(mean_squared_error(predicted, ytest)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import combinations\nfeatures2 = list(combinations(features,2))\nprint(list(features2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [\"cement\",\"superplasticizer\",\"age\",\"water\",\"flyash\",\"coarseaggregate\",\"fineaggregate\",\"slag\"]\nfrom sklearn.linear_model import LinearRegression\nmodel2 = LinearRegression()\n\nmax_testdata = 0\nmax_traindata = 0\n    \nfor feature in features:\n    print(feature)\n    x = demo[[feature]]\n    y = demo[[\"csMPa\"]]\n    x_train,x_test,y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=10)    \n   \n    model2.fit(x_train,y_train)\n    print(model2.coef_)\n    print(model2.intercept_)\n    print(\"What is the Testing R2\")\n    print(model2.score(x_test,y_test))\n    test_score = model2.score(x_test,y_test)\n    if(test_score >= max_testdata):\n        max_testdata = test_score\n        feature_data = feature       \n        \n    print(\"What is the Training R2\")\n    print(model2.score(x_train,y_train))  \n    train_score = model2.score(x_train,y_train)\n    if(train_score >= max_traindata):\n        max_traindata = train_score\n        feature_train_data = feature \n    print('#############################')\n    \nprint(max_testdata)  \n\nfrom itertools import combinations\nfor i in range(2, 9):  # adjust range for more combinations, Min range = 2, max Range = maximuminputs   \n    features2 = list(combinations(features, i)) \n    for feature in features2:\n        print(feature)\n        x = demo[list(feature)]\n        y = demo[[\"csMPa\"]]\n        x_train,x_test,y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=10)    \n\n        model2.fit(x_train,y_train)\n        print(model2.coef_)\n        print(model2.intercept_)\n        print(\"What is the Testing R2\")\n        print(model2.score(x_test,y_test))\n        print(\"What is the Training R2\")\n        print(model2.score(x_train,y_train))\n        test_score = model2.score(x_test,y_test)\n        if(test_score >= max_testdata):\n            max_testdata = test_score\n            feature_data = feature\n        train_score = model2.score(x_train,y_train)\n        if(train_score >= max_traindata):\n            max_traindata = train_score\n            feature_train_data = feature \n        print('#############################')\n        \nprint(\"What is the max Test score\")\nprint(max_testdata) \nprint(\"Features related to the max Test score\")\nprint(feature_data)\n\nprint(\"What is the max Train score\")\nprint(max_traindata) \nprint(\"Features related to the max Train score\")\nprint(feature_train_data) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Polynomial Regression [Non-Linear Regression]\npoly = PolynomialFeatures(degree=3)\npolytrain = poly.fit_transform(Xtrain)\npolytest = poly.transform(Xtest)\nlr=LinearRegression()\nlr.fit(polytrain,ytrain)\nprint(\"Training R2\")\nprint(lr.score(polytrain,ytrain))\nprint(\"Testing R2\")\nprint(lr.score(polytest,ytest))\nprint(Xtrain.shape)\nprint(polytrain.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = demo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [\"cement\",\"superplasticizer\",\"age\",\"water\",\"flyash\",\"coarseaggregate\",\"fineaggregate\",\"slag\"]\nfrom sklearn.linear_model import LinearRegression\nmodel2 = LinearRegression()\n\nmax_testdata = 0\nmax_traindata = 0\nmax_degreedata = 0\nfor max_degree in range(1, 6):    \n    for feature in features:\n        print(feature)\n        x = data[[feature]]\n        y = data[[\"csMPa\"]]\n        x_train,x_test,y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=10)    \n        #Polynomial Regression [Non-Linear Regression]\n        poly = PolynomialFeatures(degree=max_degree)\n        polytrain = poly.fit_transform(x_train)\n        polytest = poly.transform(x_test)    \n        model2.fit(polytrain,y_train)\n        print(\"Training R2\")\n        print(model2.score(polytrain,y_train))\n        print(\"Testing R2\")\n        print(model2.score(polytest,y_test))  \n\n\n        test_score = model2.score(polytest,y_test)\n        if(test_score >= max_testdata):\n            max_testdata = test_score\n            feature_data = feature\n            max_degreedata = max_degree\n            max_testdata_traindata = model2.score(polytrain,y_train)\n\n        train_score = model2.score(polytrain,y_train)\n        if(train_score >= max_traindata):\n            max_traindata = train_score\n            feature_train_data = feature \n            max_degreetraindata = max_degree\n            max_traindata_testdata = model2.score(polytest,y_test)\n        print('#############################')\n\n\n    from itertools import combinations\n    for i in range(2, 9):  # adjust range for more combinations, Min range = 2, max Range = maximuminputs   \n        features2 = list(combinations(features, i)) \n        for feature in features2:\n            print(feature)\n            x = data[list(feature)]\n            y = data[[\"csMPa\"]]\n            x_train,x_test,y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=10)    \n\n            #Polynomial Regression [Non-Linear Regression]\n            poly = PolynomialFeatures(degree=max_degree)\n            polytrain = poly.fit_transform(x_train)\n            polytest = poly.transform(x_test)    \n            model2.fit(polytrain,y_train)\n            print(\"Training R2\")\n            print(model2.score(polytrain,y_train))\n            print(\"Testing R2\")\n            print(model2.score(polytest,y_test))  \n\n\n            test_score = model2.score(polytest,y_test)\n            if(test_score >= max_testdata):\n                max_testdata = test_score\n                feature_data = feature\n                max_degreedata = max_degree\n                max_testdata_traindata = model2.score(polytrain,y_train)\n\n            train_score = model2.score(polytrain,y_train)\n            if(train_score >= max_traindata):\n                max_traindata = train_score\n                feature_train_data = feature \n                max_degreetraindata = max_degree\n                max_traindata_testdata = model2.score(polytest,y_test)\n            print('#############################')\n        \nprint(\"What is the max Test score\")\nprint(max_testdata) \nprint(\"What is the  Train score for max Test score\")\nprint(max_testdata_traindata) \nprint(\"Features related to the max Test score\")\nprint(feature_data)\nprint(\"maximum degree\")\nprint(max_degreedata)\n\nprint(\"What is the max Train score\")\nprint(max_traindata) \nprint(\"What is the  Test score for max Train score\")\nprint(max_traindata_testdata)\nprint(\"Features related to the max Train score\")\nprint(feature_train_data) \nprint(\"maximum degree\")\nprint(max_degreetraindata)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"What is the max Test score\")\nprint(max_testdata) \nprint(\"What is the  Train score for max Test score\")\nprint(max_testdata_traindata) \nprint(\"Features related to the max Test score\")\nprint(feature_data)\nprint(\"maximum degree\")\nprint(max_degreedata)\n\nprint(\"What is the max Train score\")\nprint(max_traindata) \nprint(\"What is the  Test score for max Train score\")\nprint(max_traindata_testdata)\nprint(\"Features related to the max Train score\")\nprint(feature_train_data) \nprint(\"maximum degree\")\nprint(max_degreetraindata)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PowerTransformer\nX=demo.drop('csMPa',axis=1)\ny=demo['csMPa']\nXtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size= .20,random_state=10)\npipe = Pipeline((\n(\"pt\",PowerTransformer()),\n(\"poly\",PolynomialFeatures(degree=1)),\n(\"lr\", LinearRegression()),\n))\npipe.fit(Xtrain,ytrain)\nprint(\"Training R2\")\nprint(pipe.score(Xtrain,ytrain))\nprint(\"Testing R2\")\nprint(pipe.score(Xtest,ytest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pt = PowerTransformer()\npoly = PolynomialFeatures(degree=1)\npowertrain = pt.fit_transform(Xtrain)\npowertest = pt.transform(Xtest)\npolytrain = poly.fit_transform(powertrain)\npolytest = poly.transform(powertest)\nlr=LinearRegression()\nlr.fit(polytrain,ytrain)\nprint(\"Training R2\")\nprint(lr.score(polytrain,ytrain))\nprint(\"Testing R2\")\nprint(lr.score(polytest,ytest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX=demo.drop('csMPa',axis=1)\ny=demo['csMPa']\ntrainacc = []\ntestacc = []\nfor i in range(1,10):\n    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size= .20,random_state=i)\n    lr=LinearRegression()\n    lr.fit(Xtrain,ytrain)\n    trainacc.append(lr.score(Xtrain,ytrain))\n    testacc.append(lr.score(Xtest,ytest))\nprint(testacc)\nprint(\"Average Testing R2\")\nprint(np.mean(testacc))\nprint(\"SD of Testing R2\")\nprint(np.std(testacc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX=demo.drop('csMPa',axis=1)\ny=demo['csMPa']\ntrainacc = []\ntestacc = []\nfor i in range(10):\n    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size= .20,random_state=i)\n    lr=LinearRegression()\n    lr.fit(Xtrain,ytrain)\n    trainacc.append(lr.score(Xtrain,ytrain))\n    testacc.append(lr.score(Xtest,ytest))\nprint(testacc)\nprint(\"Average Testing R2\")\nprint(np.mean(testacc))\nprint(\"SD of Testing R2\")\nprint(np.std(testacc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PowerTransformer\npt = PowerTransformer()\npoly = PolynomialFeatures(degree=1)\npowertrain = pt.fit_transform(Xtrain)\npowertest = pt.transform(Xtest)\npolytrain = poly.fit_transform(powertrain)\npolytest = poly.transform(powertest)\nlr=LinearRegression()\nlr.fit(polytrain,ytrain)\nprint(\"Training R2\")\nprint(lr.score(polytrain,ytrain))\nprint(\"Testing R2\")\nprint(lr.score(polytest,ytest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Build Final Model\nfrom sklearn.model_selection import cross_val_score\nscoresbg = cross_val_score(lr, Xtrain, ytrain, cv=10)\nprint(scoresbg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PowerTransformer\nX=demo.drop('csMPa',axis=1)\ny=demo['csMPa']\nXtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size= .20,random_state=10)\npipe = Pipeline((\n(\"pt\",PowerTransformer()),\n(\"poly\",PolynomialFeatures(degree=3)),\n(\"lr\", LinearRegression()),\n))\npipe.fit(Xtrain,ytrain)\nprint(\"Training R2\")\nprint(pipe.score(Xtrain,ytrain))\nprint(\"Testing R2\")\nprint(pipe.score(Xtest,ytest))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainacc = []\ntestacc = []\nfor i in range(10):\n    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size= .20,random_state=i)\n    pipe.fit(Xtrain,ytrain)\n    trainacc.append(pipe.score(Xtrain,ytrain))\n    testacc.append(pipe.score(Xtest,ytest))\nprint(testacc)\nprint(\"Average Testing R2\")\nprint(np.mean(testacc))\nprint(\"SD of Testing R2\")\nprint(np.std(testacc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nX=demo.drop('csMPa',axis=1)\ny=demo['csMPa']\nXtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size= .20,random_state=10)\npipe = Pipeline((\n(\"pt\",PowerTransformer()),\n(\"dt\", DecisionTreeRegressor(max_depth=8)),\n))\ntrainacc = []\ntestacc = []\nfor i in range(10):\n    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size= .20,random_state=i)\n    pipe.fit(Xtrain,ytrain)\n    trainacc.append(pipe.score(Xtrain,ytrain))\n    testacc.append(pipe.score(Xtest,ytest))\nprint(testacc)\nprint(\"Average Testing R2\")\nprint(np.mean(testacc))\nprint(\"SD of Testing R2\")\nprint(np.std(testacc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.ensemble import GradientBoostingRegressor\nX=demo.drop('csMPa',axis=1)\ny=demo['csMPa']\nXtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size= .20,random_state=10)\npipe = Pipeline((\n(\"pt\",PowerTransformer()),\n(\"gb\", GradientBoostingRegressor(n_estimators=800)),\n))\ntrainacc = []\ntestacc = []\nfor i in range(10):\n    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size= .20,random_state=i)\n    pipe.fit(Xtrain,ytrain)\n    trainacc.append(pipe.score(Xtrain,ytrain))\n    testacc.append(pipe.score(Xtest,ytest))\nprint(testacc)\nprint(\"Average Testing R2\")\nprint(np.mean(testacc))\nprint(\"SD of Testing R2\")\nprint(np.std(testacc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[‎12/‎21/‎2020 11:17 AM]  Sayan:  \nhttps://scikit-learn.org/stable/auto_examples/model_selection/plot_validation_curve.html#sphx-glr-auto-examples-model-selection-plot-validation-curve-py\n \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Build Final Model\nfrom sklearn.model_selection import cross_val_score\nscoresbg = cross_val_score(lr, Xtrain, ytrain, cv=10)\nprint(scoresbg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(__doc__)\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.datasets import load_digits\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import validation_curve\nfrom sklearn.ensemble import BaggingRegressor\n\nparam_range = np.arange(1,1000,50)\ntrain_scores, test_scores = validation_curve(\nBaggingRegressor(), X, y, param_name=\"n_estimators\", param_range=param_range, n_jobs=1)\ntrain_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\n\nplt.title(\"Validation Curve with Bagging Regressor\")\nplt.xlabel(\"Estimators\")\nplt.ylabel(\"Score\")\nplt.ylim(0.0, 1.1)\nlw = 2\nplt.semilogx(param_range, train_scores_mean, label=\"Training score\",\ncolor=\"darkorange\", lw=lw)\nplt.fill_between(param_range, train_scores_mean - train_scores_std,\ntrain_scores_mean + train_scores_std, alpha=0.2,\ncolor=\"darkorange\", lw=lw)\nplt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\ncolor=\"navy\", lw=lw)\nplt.fill_between(param_range, test_scores_mean - test_scores_std,\ntest_scores_mean + test_scores_std, alpha=0.2,\ncolor=\"navy\", lw=lw)\nplt.legend(loc=\"best\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}