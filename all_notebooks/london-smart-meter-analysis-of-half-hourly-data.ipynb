{"cells":[{"metadata":{},"cell_type":"markdown","source":"In your class work, you will be collecting energy consumption data from your school and using AI to gain more insight from the data. \n\nIn this activity, you can compare data collected from households across London to the data you've collected, and look at how a popular time-series modelling method breaks this data down into different time components. \n\nThis notebook is linked to a dataset containing data on a sample of 5,567 London Households that took part in the UK Power Networks led Low Carbon London project between November 2011 and February 2014. \n\nThis analysis is adapted from this notebook: https://www.kaggle.com/ryuheeeei/smart-home-energy-analysis-with-prophet/log.\n"},{"metadata":{},"cell_type":"markdown","source":"# Reading in and preparing the data\n\nWe will start off by preparing our environment to run the analysis:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport calendar\n\nimport datetime, time\nfrom datetime import timedelta\nimport matplotlib.dates as mdates\nfrom matplotlib.dates import AutoDateFormatter, AutoDateLocator\nsns.set()\n%matplotlib inline\n\nfrom fbprophet import Prophet\nfrom fbprophet.diagnostics import cross_validation, performance_metrics\nfrom fbprophet.plot import plot_seasonality, plot_weekly, plot_yearly\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we will read in part of the publicly available dataset. The dataset consists of smartmeter readings for different households across London. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choose only 1 house by LCLid \"MAC000002\"\nalldata = pd.read_csv(\"../input/smart-meters-in-london/halfhourly_dataset/halfhourly_dataset/block_0.csv\")\nprint('A sample of household IDs:', alldata.LCLid.unique()[:10])\nhousehold = \"MAC000002\"\n\ndf = alldata[alldata[\"LCLid\"] == household ]\ndf.reset_index(drop=True, inplace=True)\nprint(df.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This dataset has some useful info about homes (LCLid), timestamps (tstp) and energy consumption (energy(kWh/hh)). \n\nThe timestamp data are easy for humans to read and interpret, but need to be converted to an interpretable form so that comupters can understand them. Python has a 'datetime' format for doing this. We will convert each of these timestamps into datetime format, then pull out different time components (day, week, month..) from these to help us visualise and understand the data. "},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# process datetime info to pull out different components\nfor i in range(df.shape[0]):\n    df.loc[i,'datetime'] = datetime.datetime.strptime(df.loc[i,'tstp'].replace('.0000000', ''), '%Y-%m-%d %H:%M:%S')\n    df.loc[i,'date'] = df.loc[i,'datetime'].date()\n    df.loc[i,'month'] = df.loc[i,'datetime'].strftime(\"%B\")\n    df.loc[i,'day_of_month'] = df.loc[i,'datetime'].strftime(\"%d\")\n    df.loc[i,'time'] = df.loc[i,'datetime'].strftime('%X')\n    df.loc[i,'weekday'] = df.loc[i,'datetime'].strftime('%A')\n    time = df.datetime[i] - datetime.datetime.combine(df.date[i], datetime.datetime.min.time())\n    df.loc[i,'day_seconds'] = time.total_seconds()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# order the weekdays and months correctly\ndf.loc[:,'weekday'] = pd.Categorical(df['weekday'], categories= ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'], ordered=True)\ndf.loc[:,'month'] = pd.Categorical(df['month'], categories=calendar.month_name[1:], ordered=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What date range do the data cover?"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Earliest date:', df.date.min())\nprint('Latest date:', df.date.max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set energy consumption data to numeric type\ndf = df[df[\"energy(kWh/hh)\"] != \"Null\"]\ndf.loc[:,\"energy\"] = df[\"energy(kWh/hh)\"].astype(\"float64\")\n\n# calculate the cumulative energy use over time for each date\ndf.loc[:,\"cumulative_sum\"] = df.groupby('date')[\"energy\"].cumsum()\ndf = df.set_index(\"datetime\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What does half-hourly energy use look like over a week?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.plot(y=\"energy\", figsize=(15, 4), xlim=('2012-10-13', '2012-10-20'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling the data\n\nWhen we look at the data, we can see some regular patterns in energy usage over time. These patterns can be modelled mathematically, and used to predict energy usage into the future. \n\nTo explore this possibility, will be using Prophet, a popular time-series modelling Python package developed by Facebook. We will use it to model this data and predict energy usage by breaking the trends in the data down into different periodic patterns. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = int(0.8 * len(df))\nX_train, X_test = df[:train_size].index, df[train_size:].index\ny_train, y_test = df[:train_size][\"energy\"].values, df[train_size:][\"energy\"].values\n\ntrain_data = pd.concat([pd.Series(X_train), pd.Series(y_train)], axis=1, keys=[\"ds\", \"y\"])\ntest_data = pd.concat([pd.Series(X_test), pd.Series([0]*len(y_test))], axis=1, keys=[\"ds\", \"y\"])\nanswer_data = pd.concat([pd.Series(X_test), pd.Series(y_test)], axis=1, keys=[\"ds\", \"y\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below, we build the model, including time trends for days, weeks and years:"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Prophet(daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=True)\nmodel.fit(train_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can then plot some of the energy usage predicted by the model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast = model.predict(test_data)\nfig = model.plot(forecast)\nforecast_start = test_data.ds[0]\naxlim1 = forecast_start - timedelta(days=6)\naxlim2 = forecast_start + timedelta(days=6)\nplt.xlim(axlim1, axlim2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The real data is shown here as black dots, and the model predictions are shown as blue lines, with a halo of uncertainty around them. We can see that the model predicts less variability than what we see in the real data, because the cause of the different extreme power usage events is not captured in this data. Below is a longer time-horizon for the predictions:"},{"metadata":{},"cell_type":"markdown","source":"# Exploring time components of the model\n\nIt seems that the daily trend is accompanied by a predicted drop in energy use at Christmas, and a rise in power use after mid-February. We can start to explain these predictions by pulling apart the components of the forecasting model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = model.plot_components(forecast)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first component in this model's breakdown of the data shows the 'trend' - the general direction the data are moving in once the seasonal components have been taken out. It looks like over the 2 years of the data collection, overall power usage was going up slightly.\n\nNow, let's look at each of the seasonal components compared to the data. \n\nThe model pulled out a daily pattern of fluctuating power use:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(figsize=(12,7))\nplt.scatter(x='time', y='energy', data=df)\nplt.gcf().autofmt_xdate(rotation=90)\nfig.fmt_xdata = mdates.DateFormatter('%Y-%m-%d')\n\nfig = plot_seasonality(model, 'daily')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This appears to match the real data. The model has correctly identified a dip in power consumption in the early hours of the morning and two peaks at around lunchtime and dinnertime. "},{"metadata":{},"cell_type":"markdown","source":"Next, let's look at the weekly component the model has identified:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('weekday').mean().plot(y='energy', figsize=(10,6), title=\"Real energy use data mean\")\n\nplot_weekly(model, weekly_start=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This trend is harder to see in the data, because the differences in power usage across days is so small, but the mean power usage for each weekday fits the differences the model identified, with dips in average power use for Tuesday and Thursday, and highest use on Sunday. "},{"metadata":{},"cell_type":"markdown","source":"Below, we can look at energy use across the day, by day of the week. A major reason for the higher power use on Fridays, Saturdays and Sundays seems to be continued power use between lunch and dinner, while on other days this drops off in between meals. "},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(df, row=\"weekday\", aspect=4.5, height=2, sharey=False)\ng.map(sns.scatterplot, 'day_seconds', \"energy\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we will look at the yearly trend:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(figsize=(10,7))\nsns.stripplot(x='month', y='cumulative_sum', data=df, color='black')\n\nfig = plot_yearly(model)\n\ndf.groupby('month').mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model has correctly identified higher power usage in the winter months and lower usage in summer. The biggest spike in power use is in March. "},{"metadata":{},"cell_type":"markdown","source":"# How much data do we need for a good model?\n\nWhat happens if we can only collect a month's worth of data? Can we still build a good model? Let's see:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = df.loc['2012-10-13':'2012-11-13'].index\ny_train = df.loc['2012-10-13':'2012-11-13']['energy'].values\ntrain_data = pd.concat([pd.Series(X_train), pd.Series(y_train)], axis=1, keys=[\"ds\", \"y\"])\n\nX_test = df.loc['2012-11-14':'2012-11-28'].index\ny_test = df.loc['2012-11-14':'2012-11-28']['energy'].values\ntest_data = pd.concat([pd.Series(X_test), pd.Series([0]*len(y_test))], axis=1, keys=[\"ds\", \"y\"])\n\nmodel = Prophet(daily_seasonality=True, weekly_seasonality=True)\nmodel.fit(train_data)\n\nforecast = model.predict(test_data)\nfig = model.plot_components(forecast)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Next steps\n\nNext, try running the same modelling process on a different household - how do the time components change?\n\nHow well do you think these models would work to predict power usage at your school?"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}