{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pyspark","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from pyspark.sql import SparkSession\nspark = SparkSession.builder.master(\"local\").appName(\"Retail Data Analytics\").config(\"spark.some.config.option\", \"some-value\").getOrCreate()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"importing datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"features=spark.read.csv('../input/Features data set.csv',header=True,inferSchema=True)\nsales=spark.read.csv('../input/sales data-set.csv',header=True,inferSchema=True)\nstores=spark.read.csv('../input/stores data-set.csv',header=True,inferSchema=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nConverting Date Feature from String to Date type and extracting year feature from that."},{"metadata":{"trusted":true},"cell_type":"code","source":"features .show(5)\nsales.show(5)\nstores.show(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark.sql.functions import *\nformat='dd/MM/yy'\ncol=to_date(features['Date'], format).cast('date')\nfeatures=features.withColumn('Date',col)\n#features=features.withColumn('Date',to_date('Date'))\nfeatures=features.withColumn('year',year('Date'))\n#features.select('Date').distinct().orderBy('Date').show(200)                              #8190       #182\n#features.select('Store','Date').distinct().count()                                        #8190       #45\n\ncoll=to_date(sales['Date'], 'dd/MM/yyyy').cast('date')\nsales=sales.withColumn('Date', coll)\n#sales.select('Date').distinct().orderBy('Date').show(200)                                #421570       #143\n#sales.select('Store','Date').distinct().count()                                           #421570            #45\n\n\nsales=sales.withColumn('year',year('Date'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#features.show(3)\n#features.dtypes\n#sales.dtypes\n#features.select(features['year']).distinct().show()\n#sales.select(sales['year']).distinct().show()\n#sales.show(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"joining Sales & features DataSets...and selecting only 2010 data for 36 store alone."},{"metadata":{"trusted":true},"cell_type":"code","source":"df0=df=sales.join(features, ['Date','Store','IsHoliday'], 'left_outer').drop(features['year'])\ndf=df.filter(df['year']=='2012')\ndf36=df.filter(df['Store']=='36')\n#df36.show(5)\n#df36.printSchema()\ndf.show(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Converting MarkDown from string to  integer type and evalating for null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark.sql.types import *\ndf36=df36.withColumn('MarkDown1', df36['MarkDown1'].cast(IntegerType()))\ndf36=df36.withColumn('MarkDown2', df36['MarkDown2'].cast(IntegerType()))\ndf36=df36.withColumn('MarkDown3', df36['MarkDown3'].cast(IntegerType()))\ndf36=df36.withColumn('MarkDown4', df36['MarkDown4'].cast(IntegerType()))\ndf36=df36.withColumn('MarkDown5', df36['MarkDown5'].cast(IntegerType()))\n\nfrom pyspark.sql.functions import *\n#df36.filter(df36['MarkDown1'].rlike('[0-9]')).show()\n\ndf36.select([count(when(isnull(mshc),'mshc')).alias(mshc) for mshc in df36.columns]).show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Weekly_Sales "},{"metadata":{"trusted":true},"cell_type":"code","source":"df36.describe('Weekly_Sales').show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df36.filter(df['Weekly_Sales'] <= '0').count()                                  # 1 record found\ndf36=df36.filter(df['Weekly_Sales']>='0')                                        # filtering the remaining records\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df36.filter(df['Dept']=='30').show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df36.filter(df['Weekly_Sales']>='20000').show(5)   \ndf36.describe('Weekly_Sales').show()\ndf36.agg(corr('Dept','Weekly_Sales')).show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdf36=df36.groupby('Dept','Date').sum('Weekly_Sales').orderBy('Dept')\n\npdf36.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\npdf=df36.toPandas()\n#15,19,22,27,28,30\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark.sql.functions import *\npdf.shape\npdf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfig,ax = plt.subplots(figsize=(36,50))\nsns.boxplot(x='Dept',y='Weekly_Sales',data=pdf,ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdf.groupby(['Dept'])['Weekly_Sales'].sum().plot(kind='bar',figsize=(30,10),fontsize=12,grid='True')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"markdownrecored selection\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#2010\ndfm.count()\ndfm.show(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfm.filter(df['MarkDown1'and'MarkDown2'and'MarkDown3'and'MarkDown4'and'MarkDown5']!='NA').count()  #4032 #2921 #3613 #3464 #4050","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df11.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}