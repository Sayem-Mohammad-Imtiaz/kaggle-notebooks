{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-03T06:03:23.415216Z","iopub.execute_input":"2021-09-03T06:03:23.415838Z","iopub.status.idle":"2021-09-03T06:03:23.440764Z","shell.execute_reply.started":"2021-09-03T06:03:23.415749Z","shell.execute_reply":"2021-09-03T06:03:23.440023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt, seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\n\nfrom stop_words import get_stop_words\n\nimport nltk\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import stopwords\nimport re","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:55:59.104609Z","iopub.execute_input":"2021-09-03T06:55:59.105138Z","iopub.status.idle":"2021-09-03T06:55:59.110631Z","shell.execute_reply.started":"2021-09-03T06:55:59.105109Z","shell.execute_reply":"2021-09-03T06:55:59.109688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweets = pd.read_csv('/kaggle/input/bitcoin-tweets-16m-tweets-with-sentiment-tagged/mbsa.csv')\ntweets.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:03:25.248799Z","iopub.execute_input":"2021-09-03T06:03:25.249084Z","iopub.status.idle":"2021-09-03T06:05:03.307456Z","shell.execute_reply.started":"2021-09-03T06:03:25.249057Z","shell.execute_reply":"2021-09-03T06:05:03.306444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweets = tweets.iloc[:,1:]\ntweets.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:05:03.30879Z","iopub.execute_input":"2021-09-03T06:05:03.30904Z","iopub.status.idle":"2021-09-03T06:05:03.318289Z","shell.execute_reply.started":"2021-09-03T06:05:03.309016Z","shell.execute_reply":"2021-09-03T06:05:03.317376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweets.Sentiment = tweets.Sentiment.apply(lambda x: str(x).lower())\ntweets.Sentiment = tweets.Sentiment.map(lambda x: 1 if x=='positive' else 0)\ntweets.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:05:03.319441Z","iopub.execute_input":"2021-09-03T06:05:03.319683Z","iopub.status.idle":"2021-09-03T06:05:19.430499Z","shell.execute_reply.started":"2021-09-03T06:05:03.31966Z","shell.execute_reply":"2021-09-03T06:05:19.429695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(tweets)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:05:19.431584Z","iopub.execute_input":"2021-09-03T06:05:19.431835Z","iopub.status.idle":"2021-09-03T06:05:19.436865Z","shell.execute_reply.started":"2021-09-03T06:05:19.431811Z","shell.execute_reply":"2021-09-03T06:05:19.435919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A sample of datapoints are selected\ndf = tweets.sample(50000)\nlen(df)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:05:19.43791Z","iopub.execute_input":"2021-09-03T06:05:19.438158Z","iopub.status.idle":"2021-09-03T06:05:20.635539Z","shell.execute_reply.started":"2021-09-03T06:05:19.438127Z","shell.execute_reply":"2021-09-03T06:05:20.634696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:05:20.636654Z","iopub.execute_input":"2021-09-03T06:05:20.636909Z","iopub.status.idle":"2021-09-03T06:05:20.645767Z","shell.execute_reply.started":"2021-09-03T06:05:20.636884Z","shell.execute_reply":"2021-09-03T06:05:20.645021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"languages = ['french','spanish','russian','portuguese']\nstop_words = get_stop_words('english')\nfor i in languages:\n    stop_words = stop_words + get_stop_words(i)\n    \nlen(stop_words)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:05:20.64791Z","iopub.execute_input":"2021-09-03T06:05:20.648401Z","iopub.status.idle":"2021-09-03T06:05:20.663086Z","shell.execute_reply.started":"2021-09-03T06:05:20.648346Z","shell.execute_reply":"2021-09-03T06:05:20.661894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stop words from different languages are added\n# Source : Github\njap = '''あそこ\nあっ\nあの\nあのかた\nあの人\nあり\nあります\nある\nあれ\nい\nいう\nいます\nいる\nう\nうち\nえ\nお\nおよび\nおり\nおります\nか\nかつて\nから\nが\nき\nここ\nこちら\nこと\nこの\nこれ\nこれら\nさ\nさらに\nし\nしかし\nする\nず\nせ\nせる\nそこ\nそして\nその\nその他\nその後\nそれ\nそれぞれ\nそれで\nた\nただし\nたち\nため\nたり\nだ\nだっ\nだれ\nつ\nて\nで\nでき\nできる\nです\nでは\nでも\nと\nという\nといった\nとき\nところ\nとして\nとともに\nとも\nと共に\nどこ\nどの\nな\nない\nなお\nなかっ\nながら\nなく\nなっ\nなど\nなに\nなら\nなり\nなる\nなん\nに\nにおいて\nにおける\nについて\nにて\nによって\nにより\nによる\nに対して\nに対する\nに関する\nの\nので\nのみ\nは\nば\nへ\nほか\nほとんど\nほど\nます\nまた\nまたは\nまで\nも\nもの\nものの\nや\nよう\nより\nら\nられ\nられる\nれ\nれる\nを\nん\n何\n及び\n彼\n彼女\n我々\n特に\n私\n私達\n貴方\n貴方方'''\n\n\nkorean = '''…\n、\n。\n〈\n〉\n《\n》\n가\n가까스로\n가령\n각\n각각\n각자\n각종\n갖고말하자면\n같다\n같이\n개의치않고\n거니와\n거바\n거의\n것\n것과 같이\n것들\n게다가\n게우다\n겨우\n견지에서\n결과에 이르다\n결국\n결론을 낼 수 있다\n겸사겸사\n고려하면\n고로\n곧\n공동으로\n과\n과연\n관계가 있다\n관계없이\n관련이 있다\n관하여\n관한\n관해서는\n구\n구체적으로\n구토하다\n그\n그들\n그때\n그래\n그래도\n그래서\n그러나\n그러니\n그러니까\n그러면\n그러므로\n그러한즉\n그런 까닭에\n그런데\n그런즉\n그럼\n그럼에도 불구하고\n그렇게 함으로써\n그렇지\n그렇지 않다면\n그렇지 않으면\n그렇지만\n그렇지않으면\n그리고\n그리하여\n그만이다\n그에 따르는\n그위에\n그저\n그중에서\n그치지 않다\n근거로\n근거하여\n기대여\n기점으로\n기준으로\n기타\n까닭으로\n까악\n까지\n까지 미치다\n까지도\n꽈당\n끙끙\n끼익\n나\n나머지는\n남들\n남짓\n너\n너희\n너희들\n네\n넷\n년\n논하지 않다\n놀라다\n누가 알겠는가\n누구\n다른\n다른 방면으로\n다만\n다섯\n다소\n다수\n다시 말하자면\n다시말하면\n다음\n다음에\n다음으로\n단지\n답다\n당신\n당장\n대로 하다\n대하면\n대하여\n대해 말하자면\n대해서\n댕그\n더구나\n더군다나\n더라도\n더불어\n더욱더\n더욱이는\n도달하다\n도착하다\n동시에\n동안\n된바에야\n된이상\n두번째로\n둘\n둥둥\n뒤따라\n뒤이어\n든간에\n들\n등\n등등\n딩동\n따라\n따라서\n따위\n따지지 않다\n딱\n때\n때가 되어\n때문에\n또\n또한\n뚝뚝\n라 해도\n령\n로\n로 인하여\n로부터\n로써\n륙\n를\n마음대로\n마저\n마저도\n마치\n막론하고\n만 못하다\n만약\n만약에\n만은 아니다\n만이 아니다\n만일\n만큼\n말하자면\n말할것도 없고\n매\n매번\n메쓰겁다\n몇\n모\n모두\n무렵\n무릎쓰고\n무슨\n무엇\n무엇때문에\n물론\n및\n바꾸어말하면\n바꾸어말하자면\n바꾸어서 말하면\n바꾸어서 한다면\n바꿔 말하면\n바로\n바와같이\n밖에 안된다\n반대로\n반대로 말하자면\n반드시\n버금\n보는데서\n보다더\n보드득\n본대로\n봐\n봐라\n부류의 사람들\n부터\n불구하고\n불문하고\n붕붕\n비걱거리다\n비교적\n비길수 없다\n비로소\n비록\n비슷하다\n비추어 보아\n비하면\n뿐만 아니라\n뿐만아니라\n뿐이다\n삐걱\n삐걱거리다\n사\n삼\n상대적으로 말하자면\n생각한대로\n설령\n설마\n설사\n셋\n소생\n소인\n솨\n쉿\n습니까\n습니다\n시각\n시간\n시작하여\n시초에\n시키다\n실로\n심지어\n아\n아니\n아니나다를가\n아니라면\n아니면\n아니었다면\n아래윗\n아무거나\n아무도\n아야\n아울러\n아이\n아이고\n아이구\n아이야\n아이쿠\n아하\n아홉\n안 그러면\n않기 위하여\n않기 위해서\n알 수 있다\n알았어\n앗\n앞에서\n앞의것\n야\n약간\n양자\n어\n어기여차\n어느\n어느 년도\n어느것\n어느곳\n어느때\n어느쪽\n어느해\n어디\n어때\n어떠한\n어떤\n어떤것\n어떤것들\n어떻게\n어떻해\n어이\n어째서\n어쨋든\n어쩔수 없다\n어찌\n어찌됏든\n어찌됏어\n어찌하든지\n어찌하여\n언제\n언젠가\n얼마\n얼마 안 되는 것\n얼마간\n얼마나\n얼마든지\n얼마만큼\n얼마큼\n엉엉\n에\n에 가서\n에 달려 있다\n에 대해\n에 있다\n에 한하다\n에게\n에서\n여\n여기\n여덟\n여러분\n여보시오\n여부\n여섯\n여전히\n여차\n연관되다\n연이서\n영\n영차\n옆사람\n예\n예를 들면\n예를 들자면\n예컨대\n예하면\n오\n오로지\n오르다\n오자마자\n오직\n오호\n오히려\n와\n와 같은 사람들\n와르르\n와아\n왜\n왜냐하면\n외에도\n요만큼\n요만한 것\n요만한걸\n요컨대\n우르르\n우리\n우리들\n우선\n우에 종합한것과같이\n운운\n월\n위에서 서술한바와같이\n위하여\n위해서\n윙윙\n육\n으로\n으로 인하여\n으로서\n으로써\n을\n응\n응당\n의\n의거하여\n의지하여\n의해\n의해되다\n의해서\n이\n이 되다\n이 때문에\n이 밖에\n이 외에\n이 정도의\n이것\n이곳\n이때\n이라면\n이래\n이러이러하다\n이러한\n이런\n이럴정도로\n이렇게 많은 것\n이렇게되면\n이렇게말하자면\n이렇구나\n이로 인하여\n이르기까지\n이리하여\n이만큼\n이번\n이봐\n이상\n이어서\n이었다\n이와 같다\n이와 같은\n이와 반대로\n이와같다면\n이외에도\n이용하여\n이유만으로\n이젠\n이지만\n이쪽\n이천구\n이천육\n이천칠\n이천팔\n인 듯하다\n인젠\n일\n일것이다\n일곱\n일단\n일때\n일반적으로\n일지라도\n임에 틀림없다\n입각하여\n입장에서\n잇따라\n있다\n자\n자기\n자기집\n자마자\n자신\n잠깐\n잠시\n저\n저것\n저것만큼\n저기\n저쪽\n저희\n전부\n전자\n전후\n점에서 보아\n정도에 이르다\n제\n제각기\n제외하고\n조금\n조차\n조차도\n졸졸\n좀\n좋아\n좍좍\n주룩주룩\n주저하지 않고\n줄은 몰랏다\n줄은모른다\n중에서\n중의하나\n즈음하여\n즉\n즉시\n지든지\n지만\n지말고\n진짜로\n쪽으로\n차라리\n참\n참나\n첫번째로\n쳇\n총적으로\n총적으로 말하면\n총적으로 보면\n칠\n콸콸\n쾅쾅\n쿵\n타다\n타인\n탕탕\n토하다\n통하여\n툭\n퉤\n틈타\n팍\n팔\n퍽\n펄렁\n하\n하게될것이다\n하게하다\n하겠는가\n하고 있다\n하고있었다\n하곤하였다\n하구나\n하기 때문에\n하기 위하여\n하기는한데\n하기만 하면\n하기보다는\n하기에\n하나\n하느니\n하는 김에\n하는 편이 낫다\n하는것도\n하는것만 못하다\n하는것이 낫다\n하는바\n하더라도\n하도다\n하도록시키다\n하도록하다\n하든지\n하려고하다\n하마터면\n하면 할수록\n하면된다\n하면서\n하물며\n하여금\n하여야\n하자마자\n하지 않는다면\n하지 않도록\n하지마\n하지마라\n하지만\n하하\n한 까닭에\n한 이유는\n한 후\n한다면\n한다면 몰라도\n한데\n한마디\n한적이있다\n한켠으로는\n한항목\n할 따름이다\n할 생각이다\n할 줄 안다\n할 지경이다\n할 힘이 있다\n할때\n할만하다\n할망정\n할뿐\n할수있다\n할수있어\n할줄알다\n할지라도\n할지언정\n함께\n해도된다\n해도좋다\n해봐요\n해서는 안된다\n해야한다\n해요\n했어요\n향하다\n향하여\n향해서\n허\n허걱\n허허\n헉\n헉헉\n헐떡헐떡\n형식으로 쓰여\n혹시\n혹은\n혼자\n훨씬\n휘익\n휴\n흐흐\n흥\n힘입어'''\n\n\nchinese = '''一\n一个\n一些\n一何\n一切\n一则\n一方面\n一旦\n一来\n一样\n一种\n一般\n一转眼\n七\n万一\n三\n上\n上下\n下\n不\n不仅\n不但\n不光\n不单\n不只\n不外乎\n不如\n不妨\n不尽\n不尽然\n不得\n不怕\n不惟\n不成\n不拘\n不料\n不是\n不比\n不然\n不特\n不独\n不管\n不至于\n不若\n不论\n不过\n不问\n与\n与其\n与其说\n与否\n与此同时\n且\n且不说\n且说\n两者\n个\n个别\n中\n临\n为\n为了\n为什么\n为何\n为止\n为此\n为着\n乃\n乃至\n乃至于\n么\n之\n之一\n之所以\n之类\n乌乎\n乎\n乘\n九\n也\n也好\n也罢\n了\n二\n二来\n于\n于是\n于是乎\n云云\n云尔\n五\n些\n亦\n人\n人们\n人家\n什\n什么\n什么样\n今\n介于\n仍\n仍旧\n从\n从此\n从而\n他\n他人\n他们\n他们们\n以\n以上\n以为\n以便\n以免\n以及\n以故\n以期\n以来\n以至\n以至于\n以致\n们\n任\n任何\n任凭\n会\n似的\n但\n但凡\n但是\n何\n何以\n何况\n何处\n何时\n余外\n作为\n你\n你们\n使\n使得\n例如\n依\n依据\n依照\n便于\n俺\n俺们\n倘\n倘使\n倘或\n倘然\n倘若\n借\n借傥然\n假使\n假如\n假若\n做\n像\n儿\n先不先\n光\n光是\n全体\n全部\n八\n六\n兮\n共\n关于\n关于具体地说\n其\n其一\n其中\n其二\n其他\n其余\n其它\n其次\n具体地说\n具体说来\n兼之\n内\n再\n再其次\n再则\n再有\n再者\n再者说\n再说\n冒\n冲\n况且\n几\n几时\n凡\n凡是\n凭\n凭借\n出于\n出来\n分\n分别\n则\n则甚\n别\n别人\n别处\n别是\n别的\n别管\n别说\n到\n前后\n前此\n前者\n加之\n加以\n区\n即\n即令\n即使\n即便\n即如\n即或\n即若\n却\n去\n又\n又及\n及\n及其\n及至\n反之\n反而\n反过来\n反过来说\n受到\n另\n另一方面\n另外\n另悉\n只\n只当\n只怕\n只是\n只有\n只消\n只要\n只限\n叫\n叮咚\n可\n可以\n可是\n可见\n各\n各个\n各位\n各种\n各自\n同\n同时\n后\n后者\n向\n向使\n向着\n吓\n吗\n否则\n吧\n吧哒\n含\n吱\n呀\n呃\n呕\n呗\n呜\n呜呼\n呢\n呵\n呵呵\n呸\n呼哧\n咋\n和\n咚\n咦\n咧\n咱\n咱们\n咳\n哇\n哈\n哈哈\n哉\n哎\n哎呀\n哎哟\n哗\n哟\n哦\n哩\n哪\n哪个\n哪些\n哪儿\n哪天\n哪年\n哪怕\n哪样\n哪边\n哪里\n哼\n哼唷\n唉\n唯有\n啊\n啐\n啥\n啦\n啪达\n啷当\n喂\n喏\n喔唷\n喽\n嗡\n嗡嗡\n嗬\n嗯\n嗳\n嘎\n嘎登\n嘘\n嘛\n嘻\n嘿\n嘿嘿\n四\n因\n因为\n因了\n因此\n因着\n因而\n固然\n在\n在下\n在于\n地\n基于\n处在\n多\n多么\n多少\n大\n大家\n她\n她们\n好\n如\n如上\n如上所述\n如下\n如何\n如其\n如同\n如是\n如果\n如此\n如若\n始而\n孰料\n孰知\n宁\n宁可\n宁愿\n宁肯\n它\n它们\n对\n对于\n对待\n对方\n对比\n将\n小\n尔\n尔后\n尔尔\n尚且\n就\n就是\n就是了\n就是说\n就算\n就要\n尽\n尽管\n尽管如此\n岂但\n己\n已\n已矣\n巴\n巴巴\n年\n并\n并且\n庶乎\n庶几\n开外\n开始\n归\n归齐\n当\n当地\n当然\n当着\n彼\n彼时\n彼此\n往\n待\n很\n得\n得了\n怎\n怎么\n怎么办\n怎么样\n怎奈\n怎样\n总之\n总的来看\n总的来说\n总的说来\n总而言之\n恰恰相反\n您\n惟其\n慢说\n我\n我们\n或\n或则\n或是\n或曰\n或者\n截至\n所\n所以\n所在\n所幸\n所有\n才\n才能\n打\n打从\n把\n抑或\n拿\n按\n按照\n换句话说\n换言之\n据\n据此\n接着\n故\n故此\n故而\n旁人\n无\n无宁\n无论\n既\n既往\n既是\n既然\n日\n时\n时候\n是\n是以\n是的\n更\n曾\n替\n替代\n最\n月\n有\n有些\n有关\n有及\n有时\n有的\n望\n朝\n朝着\n本\n本人\n本地\n本着\n本身\n来\n来着\n来自\n来说\n极了\n果然\n果真\n某\n某个\n某些\n某某\n根据\n欤\n正值\n正如\n正巧\n正是\n此\n此地\n此处\n此外\n此时\n此次\n此间\n毋宁\n每\n每当\n比\n比及\n比如\n比方\n没奈何\n沿\n沿着\n漫说\n点\n焉\n然则\n然后\n然而\n照\n照着\n犹且\n犹自\n甚且\n甚么\n甚或\n甚而\n甚至\n甚至于\n用\n用来\n由\n由于\n由是\n由此\n由此可见\n的\n的确\n的话\n直到\n相对而言\n省得\n看\n眨眼\n着\n着呢\n矣\n矣乎\n矣哉\n离\n秒\n称\n竟而\n第\n等\n等到\n等等\n简言之\n管\n类如\n紧接着\n纵\n纵令\n纵使\n纵然\n经\n经过\n结果\n给\n继之\n继后\n继而\n综上所述\n罢了\n者\n而\n而且\n而况\n而后\n而外\n而已\n而是\n而言\n能\n能否\n腾\n自\n自个儿\n自从\n自各儿\n自后\n自家\n自己\n自打\n自身\n至\n至于\n至今\n至若\n致\n般的\n若\n若夫\n若是\n若果\n若非\n莫不然\n莫如\n莫若\n虽\n虽则\n虽然\n虽说\n被\n要\n要不\n要不是\n要不然\n要么\n要是\n譬喻\n譬如\n让\n许多\n论\n设使\n设或\n设若\n诚如\n诚然\n该\n说\n说来\n请\n诸\n诸位\n诸如\n谁\n谁人\n谁料\n谁知\n贼死\n赖以\n赶\n起\n起见\n趁\n趁着\n越是\n距\n跟\n较\n较之\n边\n过\n还\n还是\n还有\n还要\n这\n这一来\n这个\n这么\n这么些\n这么样\n这么点儿\n这些\n这会儿\n这儿\n这就是说\n这时\n这样\n这次\n这般\n这边\n这里\n进而\n连\n连同\n逐步\n通过\n遵循\n遵照\n那\n那个\n那么\n那么些\n那么样\n那些\n那会儿\n那儿\n那时\n那样\n那般\n那边\n那里\n都\n鄙人\n鉴于\n针对\n阿\n除\n除了\n除外\n除开\n除此之外\n除非\n随\n随后\n随时\n随着\n难道说\n零\n非\n非但\n非徒\n非特\n非独\n靠\n顺\n顺着\n首先'''\n\nstop_words = stop_words + jap.split('\\n') + korean.split('\\n') + chinese.split('\\n')\nlen(stop_words)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:05:20.665334Z","iopub.execute_input":"2021-09-03T06:05:20.665668Z","iopub.status.idle":"2021-09-03T06:05:20.681111Z","shell.execute_reply.started":"2021-09-03T06:05:20.665638Z","shell.execute_reply":"2021-09-03T06:05:20.680076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ps = PorterStemmer()\ncorpus = []\nfor i in df.text:\n    new = re.sub('[^a-zA-z]', ' ',i)\n    new = new.lower()\n    new = nltk.word_tokenize(new)\n    new = [ps.stem(i) for i in new if i not in stop_words]\n    new = ' '.join(new)\n    corpus.append(new)\n    \ndf.text = corpus\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:05:20.682507Z","iopub.execute_input":"2021-09-03T06:05:20.682778Z","iopub.status.idle":"2021-09-03T06:06:10.616885Z","shell.execute_reply.started":"2021-09-03T06:05:20.682751Z","shell.execute_reply":"2021-09-03T06:06:10.615883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train,test = train_test_split(df, train_size=0.7, stratify=df.Sentiment, random_state=100)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:06:10.617981Z","iopub.execute_input":"2021-09-03T06:06:10.618229Z","iopub.status.idle":"2021-09-03T06:06:10.652323Z","shell.execute_reply.started":"2021-09-03T06:06:10.618205Z","shell.execute_reply":"2021-09-03T06:06:10.651416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = train.text\ny_train = train.Sentiment\n\nX_test = test.text\ny_test = test.Sentiment","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:06:10.653509Z","iopub.execute_input":"2021-09-03T06:06:10.653777Z","iopub.status.idle":"2021-09-03T06:06:10.659765Z","shell.execute_reply.started":"2021-09-03T06:06:10.653749Z","shell.execute_reply":"2021-09-03T06:06:10.659093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# mnb = Pipeline([('cnt',CountVectorizer()),\n#                ('mnb',MultinomialNB())])\n# cv_score = cross_val_score(mnb, X_train, y_train, cv=folds)\n# cv_score.mean()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T07:02:45.255838Z","iopub.execute_input":"2021-09-03T07:02:45.256198Z","iopub.status.idle":"2021-09-03T07:02:45.260052Z","shell.execute_reply.started":"2021-09-03T07:02:45.256161Z","shell.execute_reply":"2021-09-03T07:02:45.258986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # help(MultinomialNB)\n# hyp = [{'cnt__ngram_range':[(1,1),(1,2),(2,1),(2,2)],\n#        'mnb__alpha': [0.0005,0.001,0.01,0.1,0.13,0.15,0.16,0.18,0.2,0.4,0.6,0.8,1.0,1.2,1.5,1.7,2]}]\n\n# grid = GridSearchCV(estimator=mnb, param_grid=hyp, cv=folds, n_jobs=-1, scoring='accuracy',\n#                    verbose=True, return_train_score=True)\n# grid.fit(X_train,y_train)\n\n# grid.best_score_, grid.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:06:10.669713Z","iopub.execute_input":"2021-09-03T06:06:10.669974Z","iopub.status.idle":"2021-09-03T06:06:10.67822Z","shell.execute_reply.started":"2021-09-03T06:06:10.669949Z","shell.execute_reply":"2021-09-03T06:06:10.677259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Neural Network","metadata":{}},{"cell_type":"code","source":"vec = CountVectorizer(max_features=5000)\nX_train_transformed = vec.fit_transform(X_train)\nX_test_transformed = vec.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:06:10.67962Z","iopub.execute_input":"2021-09-03T06:06:10.67991Z","iopub.status.idle":"2021-09-03T06:06:11.548489Z","shell.execute_reply.started":"2021-09-03T06:06:10.679885Z","shell.execute_reply":"2021-09-03T06:06:11.547617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = pd.DataFrame(X_train_transformed.toarray(),columns=vec.vocabulary_)\nX_test = pd.DataFrame(X_test_transformed.toarray(),columns=vec.vocabulary_)\nX_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:06:11.549703Z","iopub.execute_input":"2021-09-03T06:06:11.549953Z","iopub.status.idle":"2021-09-03T06:06:12.71961Z","shell.execute_reply.started":"2021-09-03T06:06:11.549928Z","shell.execute_reply":"2021-09-03T06:06:12.718735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def one_hot(lst):\n    q = np.zeros([2,len(lst)])\n    for i in enumerate(lst):\n        if i[1]==1:\n            q[1][i[0]] = 1\n        elif i[1]==0:\n            q[0][i[0]] = 1\n    return q.T","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:06:12.720733Z","iopub.execute_input":"2021-09-03T06:06:12.721148Z","iopub.status.idle":"2021-09-03T06:06:12.726337Z","shell.execute_reply.started":"2021-09-03T06:06:12.721115Z","shell.execute_reply":"2021-09-03T06:06:12.725312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_trans = one_hot(y_train)\ny_test_trans = one_hot(y_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:06:12.727497Z","iopub.execute_input":"2021-09-03T06:06:12.727777Z","iopub.status.idle":"2021-09-03T06:06:12.770585Z","shell.execute_reply.started":"2021-09-03T06:06:12.727733Z","shell.execute_reply":"2021-09-03T06:06:12.769746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:06:12.771612Z","iopub.execute_input":"2021-09-03T06:06:12.771866Z","iopub.status.idle":"2021-09-03T06:06:18.535471Z","shell.execute_reply.started":"2021-09-03T06:06:12.771841Z","shell.execute_reply":"2021-09-03T06:06:18.534114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(10000, input_dim=5000, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(600, activation='relu'))\nmodel.add(Dense(400, activation='relu'))\nmodel.add(Dense(200, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dense(2, activation='softmax'))\n\nmodel.compile(loss='BinaryCrossentropy', optimizer='adam', metrics='accuracy')\n\nmodel.fit(np.array(X_train),y_train_trans, batch_size=25, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:07:14.071811Z","iopub.execute_input":"2021-09-03T06:07:14.072138Z","iopub.status.idle":"2021-09-03T06:53:06.78651Z","shell.execute_reply.started":"2021-09-03T06:07:14.072109Z","shell.execute_reply":"2021-09-03T06:53:06.785399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(np.array(X_train), y_train_trans)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T07:00:35.635499Z","iopub.execute_input":"2021-09-03T07:00:35.636008Z","iopub.status.idle":"2021-09-03T07:01:33.042845Z","shell.execute_reply.started":"2021-09-03T07:00:35.635958Z","shell.execute_reply":"2021-09-03T07:01:33.041784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(np.array(X_test), y_test_trans)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:59:32.77796Z","iopub.execute_input":"2021-09-03T06:59:32.778277Z","iopub.status.idle":"2021-09-03T06:59:57.599208Z","shell.execute_reply.started":"2021-09-03T06:59:32.778248Z","shell.execute_reply":"2021-09-03T06:59:57.597729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}