{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# No warnings about setting value on copy of slice\npd.options.mode.chained_assignment = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display up to 60 columns of a dataframe\npd.set_option('display.max_columns', 60)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Matplotlib visualization\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set default font size\nplt.rcParams['font.size'] = 24","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Internal ipython tool for setting figure size\nfrom IPython.core.pylabtools import figsize","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seaborn for visualization\nimport seaborn as sns\nsns.set(font_scale = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read in data into a dataframe \ndata = pd.read_csv('../input/buildingenergydata/Energy_and_Water_Data_Disclosure_for_Local_Law_84_2017__Data_for_Calendar_Year_2016_.csv')\n\n# Display top of dataframe\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# See the column data types and non-missing values\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace all occurrences of Not Available with numpy not a number\ndata = data.replace({'Not Available': np.nan})\n\n# Iterate through the columns\nfor col in list(data.columns):\n    # Select columns that should be numeric\n    if ('ft²' in col or 'kBtu' in col or 'Metric Tons CO2e' in col or 'kWh' in \n        col or 'therms' in col or 'gal' in col or 'Score' in col):\n        # Convert the data type to float\n        data[col] = data[col].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Statistics for each column\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to calculate missing values by column\ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values_table(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the columns with > 50% missing\nmissing_df = missing_values_table(data);\nmissing_columns = list(missing_df[missing_df['% of Total Values'] > 50].index)\nprint('We will remove %d columns.' % len(missing_columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop the columns\ndata = data.drop(columns = list(missing_columns))\n\n# For older versions of pandas (https://github.com/pandas-dev/pandas/issues/19078)\n# data = data.drop(list(missing_columns), axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_values_table(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figsize(8, 8)\n\n# Rename the score \ndata = data.rename(columns = {'ENERGY STAR Score': 'score'})\n\n# Histogram of the Energy Star Score\nplt.style.use('fivethirtyeight')\nplt.hist(data['score'].dropna(), bins = 100, edgecolor = 'k');\nplt.xlabel('Score'); plt.ylabel('Number of Buildings'); \nplt.title('Energy Star Score Distribution');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram Plot of Site EUI\nfigsize(8, 8)\nplt.hist(data['Site EUI (kBtu/ft²)'].dropna(), bins = 20, edgecolor = 'black');\nplt.xlabel('Site EUI'); \nplt.ylabel('Count'); plt.title('Site EUI Distribution');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Site EUI (kBtu/ft²)'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Site EUI (kBtu/ft²)'].dropna().sort_values().tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[data['Site EUI (kBtu/ft²)'] == 869265, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate first and third quartile\nfirst_quartile = data['Site EUI (kBtu/ft²)'].describe()['25%']\nthird_quartile = data['Site EUI (kBtu/ft²)'].describe()['75%']\n\n# Interquartile range\niqr = third_quartile - first_quartile\n\n# Remove outliers\ndata = data[(data['Site EUI (kBtu/ft²)'] > (first_quartile - 3 * iqr)) &\n            (data['Site EUI (kBtu/ft²)'] < (third_quartile + 3 * iqr))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram Plot of Site EUI\nfigsize(8, 8)\nplt.hist(data['Site EUI (kBtu/ft²)'].dropna(), bins = 20, edgecolor = 'black');\nplt.xlabel('Site EUI'); \nplt.ylabel('Count'); plt.title('Site EUI Distribution');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figsize(8, 8)\n\n# Rename the score \ndata = data.rename(columns = {'ENERGY STAR Score': 'score'})\n\n# Histogram of the Energy Star Score\nplt.style.use('fivethirtyeight')\nplt.hist(data['score'].dropna(), bins = 100, edgecolor = 'k');\nplt.xlabel('Score'); plt.ylabel('Number of Buildings'); \nplt.title('Energy Star Score Distribution');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a list of buildings with more than 100 measurements\ntypes = data.dropna(subset=['score'])\ntypes = types['Largest Property Use Type'].value_counts()\ntypes = list(types[types.values > 100].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot of distribution of scores for building categories\nfigsize(12, 10)\n\n# Plot each building\nfor b_type in types:\n    # Select the building type\n    subset = data[data['Largest Property Use Type'] == b_type]\n    \n    # Density plot of Energy Star scores\n    sns.kdeplot(subset['score'].dropna(),\n               label = b_type, shade = False, alpha = 0.8);\n    \n# label the plot\nplt.xlabel('Energy Star Score', size = 20); plt.ylabel('Density', size = 20); \nplt.title('Density Plot of Energy Star Scores by Building Type', size = 28);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a list of boroughs with more than 100 observations\nboroughs = data.dropna(subset=['score'])\nboroughs = boroughs['Borough'].value_counts()\nboroughs = list(boroughs[boroughs.values > 100].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot of distribution of scores for boroughs\nfigsize(12, 10)\n\n# Plot each borough distribution of scores\nfor borough in boroughs:\n    # Select the building type\n    subset = data[data['Borough'] == borough]\n    \n    # Density plot of Energy Star scores\n    sns.kdeplot(subset['score'].dropna(),\n               label = borough);\n    \n# label the plot\nplt.xlabel('Energy Star Score', size = 20); plt.ylabel('Density', size = 20); \nplt.title('Density Plot of Energy Star Scores by Borough', size = 28);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find all correlations and sort \ncorrelations_data = data.corr()['score'].sort_values()\n\n# Print the most negative correlations\nprint(correlations_data.head(15), '\\n')\n\n# Print the most positive correlations\nprint(correlations_data.tail(15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the numeric columns\nnumeric_subset = data.select_dtypes('number')\n\n# Create columns with square root and log of numeric columns\nfor col in numeric_subset.columns:\n    # Skip the Energy Star Score column\n    if col == 'score':\n        next\n    else:\n        numeric_subset['sqrt_' + col] = np.sqrt(numeric_subset[col])\n        numeric_subset['log_' + col] = np.log(numeric_subset[col])\n\n# Select the categorical columns\ncategorical_subset = data[['Borough', 'Largest Property Use Type']]\n\n# One hot encode\ncategorical_subset = pd.get_dummies(categorical_subset)\n\n# Join the two dataframes using concat\n# Make sure to use axis = 1 to perform a column bind\nfeatures = pd.concat([numeric_subset, categorical_subset], axis = 1)\n\n# Drop buildings without an energy star score\nfeatures = features.dropna(subset = ['score'])\n\n# Find correlations with the score \ncorrelations = features.corr()['score'].dropna().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display most negative correlations\ncorrelations.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display most positive correlations\ncorrelations.tail(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figsize(12, 10)\n\n# Extract the building types\nfeatures['Largest Property Use Type'] = data.dropna(subset = ['score'])['Largest Property Use Type']\n\n# Limit to building types with more than 100 observations (from previous code)\nfeatures = features[features['Largest Property Use Type'].isin(types)]\n\n# Use seaborn to plot a scatterplot of Score vs Log Source EUI\nsns.lmplot('Site EUI (kBtu/ft²)', 'score', \n          hue = 'Largest Property Use Type', data = features,\n          scatter_kws = {'alpha': 0.8, 's': 60}, fit_reg = False,\n          size = 12, aspect = 1.2);\n\n# Plot labeling\nplt.xlabel(\"Site EUI\", size = 28)\nplt.ylabel('Energy Star Score', size = 28)\nplt.title('Energy Star Score vs Site EUI', size = 36);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract the columns to  plot\nplot_data = features[['score', 'Site EUI (kBtu/ft²)', \n                      'Weather Normalized Source EUI (kBtu/ft²)', \n                      'log_Total GHG Emissions (Metric Tons CO2e)']]\n\n# Replace the inf with nan\nplot_data = plot_data.replace({np.inf: np.nan, -np.inf: np.nan})\n\n# Rename columns \nplot_data = plot_data.rename(columns = {'Site EUI (kBtu/ft²)': 'Site EUI', \n                                        'Weather Normalized Source EUI (kBtu/ft²)': 'Weather Norm EUI',\n                                        'log_Total GHG Emissions (Metric Tons CO2e)': 'log GHG Emissions'})\n\n# Drop na values\nplot_data = plot_data.dropna()\n\n# Function to calculate correlation coefficient between two columns\ndef corr_func(x, y, **kwargs):\n    r = np.corrcoef(x, y)[0][1]\n    ax = plt.gca()\n    ax.annotate(\"r = {:.2f}\".format(r),\n                xy=(.2, .8), xycoords=ax.transAxes,\n                size = 20)\n\n# Create the pairgrid object\ngrid = sns.PairGrid(data = plot_data, size = 3)\n\n# Upper is a scatter plot\ngrid.map_upper(plt.scatter, color = 'red', alpha = 0.6)\n\n# Diagonal is a histogram\ngrid.map_diag(plt.hist, color = 'red', edgecolor = 'black')\n\n# Bottom is correlation and density plot\ngrid.map_lower(corr_func);\ngrid.map_lower(sns.kdeplot, cmap = plt.cm.Reds)\n\n# Title for entire plot\nplt.suptitle('Pairs Plot of Energy Data', size = 36, y = 1.02);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy the original data\nfeatures = data.copy()\n\n# Select the numeric columns\nnumeric_subset = data.select_dtypes('number')\n\n# Create columns with log of numeric columns\nfor col in numeric_subset.columns:\n    # Skip the Energy Star Score column\n    if col == 'score':\n        next\n    else:\n        numeric_subset['log_' + col] = np.log(numeric_subset[col])\n        \n# Select the categorical columns\ncategorical_subset = data[['Borough', 'Largest Property Use Type']]\n\n# One hot encode\ncategorical_subset = pd.get_dummies(categorical_subset)\n\n# Join the two dataframes using concat\n# Make sure to use axis = 1 to perform a column bind\nfeatures = pd.concat([numeric_subset, categorical_subset], axis = 1)\n\nfeatures.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_data = data[['Weather Normalized Site EUI (kBtu/ft²)', 'Site EUI (kBtu/ft²)']].dropna()\n\nplt.plot(plot_data['Site EUI (kBtu/ft²)'], plot_data['Weather Normalized Site EUI (kBtu/ft²)'], 'bo')\nplt.xlabel('Site EUI'); plt.ylabel('Weather Norm EUI')\nplt.title('Weather Norm EUI vs Site EUI, R = %0.4f' % np.corrcoef(data[['Weather Normalized Site EUI (kBtu/ft²)', 'Site EUI (kBtu/ft²)']].dropna(), rowvar=False)[0][1]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_collinear_features(x, threshold):\n    '''\n    Objective:\n        Remove collinear features in a dataframe with a correlation coefficient\n        greater than the threshold. Removing collinear features can help a model\n        to generalize and improves the interpretability of the model.\n        \n    Inputs: \n        threshold: any features with correlations greater than this value are removed\n    \n    Output: \n        dataframe that contains only the non-highly-collinear features\n    '''\n    \n    # Dont want to remove correlations between Energy Star Score\n    y = x['score']\n    x = x.drop(columns = ['score'])\n    \n    # Calculate the correlation matrix\n    corr_matrix = x.corr()\n    iters = range(len(corr_matrix.columns) - 1)\n    drop_cols = []\n    \n    # Iterate through the correlation matrix and compare correlations\n    for i in iters:\n        for j in range(i):\n            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n            col = item.columns\n            row = item.index\n            val = abs(item.values)\n            \n            # If correlation exceeds the threshold\n            if val >= threshold:\n                # Print the correlated features and the correlation value\n                # print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n                drop_cols.append(col.values[0])\n\n    # Drop one of each pair of correlated columns\n    drops = set(drop_cols)\n    x = x.drop(columns = drops)\n    x = x.drop(columns = ['Weather Normalized Site EUI (kBtu/ft²)', \n                          'Water Use (All Water Sources) (kgal)',\n                          'log_Water Use (All Water Sources) (kgal)',\n                          'Largest Property Use Type - Gross Floor Area (ft²)'])\n    \n    # Add the score back in to the data\n    x['score'] = y\n               \n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove the collinear features above a specified correlation coefficient\nfeatures = remove_collinear_features(features, 0.6);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove any columns with all na values\nfeatures  = features.dropna(axis=1, how = 'all')\nfeatures.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract the buildings with no score and the buildings with a score\nno_score = features[features['score'].isna()]\nscore = features[features['score'].notnull()]\n\nprint(no_score.shape)\nprint(score.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data into training and testing\nfrom sklearn.model_selection import train_test_split\n\n# Separate out the features and targets\nfeatures = score.drop(columns='score')\ntargets = pd.DataFrame(score['score'])\n\n# Replace the inf and -inf with nan (required for later imputation)\nfeatures = features.replace({np.inf: np.nan, -np.inf: np.nan})\n\n# Split into 70% training and 30% testing set\nX, X_test, y, y_test = train_test_split(features, targets, test_size = 0.3, random_state = 42)\n\nprint(X.shape)\nprint(X_test.shape)\nprint(y.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to calculate mean absolute error\ndef mae(y_true, y_pred):\n    return np.mean(abs(y_true - y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"baseline_guess = np.median(y)\n\nprint('The baseline guess is a score of %0.2f' % baseline_guess)\nprint(\"Baseline Performance on the test set: MAE = %0.4f\" % mae(y_test, baseline_guess))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the no scores, training, and testing data\nno_score.to_csv('no_score.csv', index = False)\nX.to_csv('training_features.csv', index = False)\nX_test.to_csv('testing_features.csv', index = False)\ny.to_csv('training_labels.csv', index = False)\ny_test.to_csv('testing_labels.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pandas and numpy for data manipulation\nimport pandas as pd\nimport numpy as np\n\n# No warnings about setting value on copy of slice\npd.options.mode.chained_assignment = None\npd.set_option('display.max_columns', 60)\n\n# Matplotlib for visualization\nimport matplotlib.pyplot as plt\n\n# Set default font size\nplt.rcParams['font.size'] = 24\n\nfrom IPython.core.pylabtools import figsize\n\n# Seaborn for visualization\nimport seaborn as sns\nsns.set(font_scale = 2)\n\n# Imputing missing values and scaling values\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.impute import SimpleImputer as Imputer\n\n# Machine Learning Models\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\n\n# Hyperparameter tuning\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read in data into dataframes \ntrain_features = pd.read_csv('training_features.csv')\ntest_features = pd.read_csv('testing_features.csv')\ntrain_labels = pd.read_csv('training_labels.csv')\ntest_labels = pd.read_csv('testing_labels.csv')\n\n# Display sizes of data\nprint('Training Feature Size: ', train_features.shape)\nprint('Testing Feature Size:  ', test_features.shape)\nprint('Training Labels Size:  ', train_labels.shape)\nprint('Testing Labels Size:   ', test_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.head(12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figsize(8, 8)\n\n# Histogram of the Energy Star Score\nplt.style.use('fivethirtyeight')\nplt.hist(train_labels['score'].dropna(), bins = 100);\nplt.xlabel('Score'); plt.ylabel('Number of Buildings'); \nplt.title('ENERGY Star Score Distribution');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create an imputer object with a median filling strategy\nimputer = Imputer(strategy='median')\n\n# Train on the training features\nimputer.fit(train_features)\n\n# Transform both training data and testing data\nX = imputer.transform(train_features)\nX_test = imputer.transform(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Missing values in training features: ', np.sum(np.isnan(X)))\nprint('Missing values in testing features:  ', np.sum(np.isnan(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make sure all values are finite\nprint(np.where(~np.isfinite(X)))\nprint(np.where(~np.isfinite(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the scaler object with a range of 0-1\nscaler = MinMaxScaler(feature_range=(0, 1))\n\n# Fit on the training data\nscaler.fit(X)\n\n# Transform both the training and testing data\nX = scaler.transform(X)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert y to one-dimensional array (vector)\ny = np.array(train_labels).reshape((-1, ))\ny_test = np.array(test_labels).reshape((-1, ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to calculate mean absolute error\ndef mae(y_true, y_pred):\n    return np.mean(abs(y_true - y_pred))\n\n# Takes in a model, trains the model, and evaluates the model on the test set\ndef fit_and_evaluate(model):\n    \n    # Train the model\n    model.fit(X, y)\n    \n    # Make predictions and evalute\n    model_pred = model.predict(X_test)\n    model_mae = mae(y_test, model_pred)\n    \n    # Return the performance metric\n    return model_mae","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LinearRegression()\nlr_mae = fit_and_evaluate(lr)\n\nprint('Linear Regression Performance on the test set: MAE = %0.4f' % lr_mae)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm = SVR(C = 1000, gamma = 0.1)\nsvm_mae = fit_and_evaluate(svm)\n\nprint('Support Vector Machine Regression Performance on the test set: MAE = %0.4f' % svm_mae)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_forest = RandomForestRegressor(random_state=60)\nrandom_forest_mae = fit_and_evaluate(random_forest)\n\nprint('Random Forest Regression Performance on the test set: MAE = %0.4f' % random_forest_mae)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gradient_boosted = GradientBoostingRegressor(random_state=60)\ngradient_boosted_mae = fit_and_evaluate(gradient_boosted)\n\nprint('Gradient Boosted Regression Performance on the test set: MAE = %0.4f' % gradient_boosted_mae)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsRegressor(n_neighbors=10)\nknn_mae = fit_and_evaluate(knn)\n\nprint('K-Nearest Neighbors Regression Performance on the test set: MAE = %0.4f' % knn_mae)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nfigsize(8, 6)\n\n# Dataframe to hold the results\nmodel_comparison = pd.DataFrame({'model': ['Linear Regression', 'Support Vector Machine',\n                                           'Random Forest', 'Gradient Boosted',\n                                            'K-Nearest Neighbors'],\n                                 'mae': [lr_mae, svm_mae, random_forest_mae, \n                                         gradient_boosted_mae, knn_mae]})\n\n# Horizontal bar chart of test mae\nmodel_comparison.sort_values('mae', ascending = False).plot(x = 'model', y = 'mae', kind = 'barh',\n                                                           color = 'red', edgecolor = 'black')\n\n# Plot formatting\nplt.ylabel(''); plt.yticks(size = 14); plt.xlabel('Mean Absolute Error'); plt.xticks(size = 14)\nplt.title('Model Comparison on Test MAE', size = 20);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loss function to be optimized\nloss = ['ls', 'lad', 'huber']\n\n# Number of trees used in the boosting process\nn_estimators = [100, 500, 900, 1100, 1500]\n\n# Maximum depth of each tree\nmax_depth = [2, 3, 5, 10, 15]\n\n# Minimum number of samples per leaf\nmin_samples_leaf = [1, 2, 4, 6, 8]\n\n# Minimum number of samples to split a node\nmin_samples_split = [2, 4, 6, 10]\n\n# Maximum number of features to consider for making splits\nmax_features = ['auto', 'sqrt', 'log2', None]\n\n# Define the grid of hyperparameters to search\nhyperparameter_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf\n                      }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the model to use for hyperparameter tuning\nmodel = RandomForestRegressor(random_state = 42)\n\n# Set up the random search with 4-fold cross validation\nrandom_cv = RandomizedSearchCV(estimator = model, \n                               param_distributions = hyperparameter_grid, \n                               n_iter = 25, \n                               cv = 4,\n                               scoring = 'neg_mean_absolute_error',\n                               verbose=2, \n                               random_state=42, \n                               n_jobs = -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit on the training data\nrandom_cv.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get all of the cv results and sort by the test performance\nrandom_results = pd.DataFrame(random_cv.cv_results_).sort_values('mean_test_score', ascending = False)\n\nrandom_results.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_cv.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a range of trees to evaluate\ntrees_grid = {'n_estimators': [650, 700, 750, 800, 850, 900, 950, 1000]}\n\nmodel = RandomForestRegressor(max_depth = 15,\n                                  min_samples_leaf = 2,\n                                  min_samples_split = 6,\n                                  max_features = None,\n                                  random_state = 42)\n\n# Grid Search Object using the trees range and the random forest model\ngrid_search = GridSearchCV(estimator = model, param_grid=trees_grid, cv = 4, \n                           scoring = 'neg_mean_absolute_error', verbose = 1,\n                           n_jobs = -1, return_train_score = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the grid search\ngrid_search.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the results into a dataframe\nresults = pd.DataFrame(grid_search.cv_results_)\n\n# Plot the training and testing error vs number of trees\nfigsize(8, 8)\nplt.style.use('fivethirtyeight')\nplt.plot(results['param_n_estimators'], -1 * results['mean_test_score'], label = 'Testing Error')\nplt.plot(results['param_n_estimators'], -1 * results['mean_train_score'], label = 'Training Error')\nplt.xlabel('Number of Trees'); plt.ylabel('Mean Abosolute Error'); plt.legend();\nplt.title('Performance vs Number of Trees');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results.sort_values('mean_test_score', ascending = False).head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Default model\ndefault_model = RandomForestRegressor(random_state = 42)\n\n# Select the best model\nfinal_model = grid_search.best_estimator_\n\nfinal_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%timeit -n 1 -r 5\ndefault_model.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%timeit -n 1 -r 5\nfinal_model.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"default_pred = default_model.predict(X_test)\nfinal_pred = final_model.predict(X_test)\n\nprint('Default model performance on the test set: MAE = %0.4f.' % mae(y_test, default_pred))\nprint('Final model performance on the test set:   MAE = %0.4f.' % mae(y_test, final_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figsize(8, 8)\n\n# Density plot of the final predictions and the test values\nsns.kdeplot(final_pred, label = 'Predictions')\nsns.kdeplot(y_test, label = 'Values')\n\n# Label the plot\nplt.xlabel('Energy Star Score'); plt.ylabel('Density');\nplt.title('Test Values and Predictions');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figsize = (6, 6)\n\n# Calculate the residuals \nresiduals = final_pred - y_test\n\n# Plot the residuals in a histogram\nplt.hist(residuals, color = 'red', bins = 20,\n         edgecolor = 'black')\nplt.xlabel('Error'); plt.ylabel('Count')\nplt.title('Distribution of Residuals');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\n\n# LIME for explaining predictions\nimport lime \nimport lime.lime_tabular","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract the feature importances into a dataframe\nfeature_results = pd.DataFrame({'feature': list(train_features.columns), \n                                'importance': final_model.feature_importances_})\n\n# Show the top 10 most important\nfeature_results = feature_results.sort_values('importance', ascending = False).reset_index(drop=True)\n\nfeature_results.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figsize = (12, 10)\nplt.style.use('fivethirtyeight')\n\n# Plot the 10 most important features in a horizontal bar chart\nfeature_results.loc[:9, :].plot(x = 'feature', y = 'importance', \n                                 edgecolor = 'k',\n                                 kind='barh', color = 'blue');\nplt.xlabel('Relative Importance', size = 20); plt.ylabel('')\nplt.title('Feature Importances from Random Forest', size = 30);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract the names of the most important features\nmost_important_features = feature_results['feature'][:10]\n\n# Find the index that corresponds to each feature name\nindices = [list(train_features.columns).index(x) for x in most_important_features]\n\n# Keep only the most important features\nX_reduced = X[:, indices]\nX_test_reduced = X_test[:, indices]\n\nprint('Most important training features shape: ', X_reduced.shape)\nprint('Most important testing  features shape: ', X_test_reduced.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LinearRegression()\n\n# Fit on full set of features\nlr.fit(X, y)\nlr_full_pred = lr.predict(X_test)\n\n# Fit on reduced set of features\nlr.fit(X_reduced, y)\nlr_reduced_pred = lr.predict(X_test_reduced)\n\n# Display results\nprint('Linear Regression Full Results: MAE =    %0.4f.' % mae(y_test, lr_full_pred))\nprint('Linear Regression Reduced Results: MAE = %0.4f.' % mae(y_test, lr_reduced_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the model with the same hyperparamters\nmodel_reduced = GradientBoostingRegressor(loss='lad', max_depth=5, max_features=None,\n                                  min_samples_leaf=6, min_samples_split=6, \n                                  n_estimators=800, random_state=42)\n\n# Fit and test on the reduced set of features\nmodel_reduced.fit(X_reduced, y)\nmodel_reduced_pred = model_reduced.predict(X_test_reduced)\n\nprint('Gradient Boosted Reduced Results: MAE = %0.4f' % mae(y_test, model_reduced_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the residuals\nresiduals = abs(model_reduced_pred - y_test)\n    \n# Exact the worst and best prediction\nwrong = X_test_reduced[np.argmax(residuals), :]\nright = X_test_reduced[np.argmin(residuals), :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a lime explainer object\nexplainer = lime.lime_tabular.LimeTabularExplainer(training_data = X_reduced, \n                                                   mode = 'regression',\n                                                   training_labels = y,\n                                                   feature_names = list(most_important_features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display the predicted and true value for the wrong instance\nprint('Prediction: %0.4f' % model_reduced.predict(wrong.reshape(1, -1)))\nprint('Actual Value: %0.4f' % y_test[np.argmax(residuals)])\n\n# Explanation for wrong prediction\nwrong_exp = explainer.explain_instance(data_row = wrong, \n                                       predict_fn = model_reduced.predict)\n\n# Plot the prediction explaination\nwrong_exp.as_pyplot_figure();\nplt.title('Explanation of Prediction', size = 28);\nplt.xlabel('Effect on Prediction', size = 22);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wrong_exp.show_in_notebook(show_predicted_value=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display the predicted and true value for the wrong instance\nprint('Prediction: %0.4f' % model_reduced.predict(right.reshape(1, -1)))\nprint('Actual Value: %0.4f' % y_test[np.argmin(residuals)])\n\n# Explanation for wrong prediction\nright_exp = explainer.explain_instance(right, model_reduced.predict, num_features=10)\nright_exp.as_pyplot_figure();\nplt.title('Explanation of Prediction', size = 28);\nplt.xlabel('Effect on Prediction', size = 22);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"right_exp.show_in_notebook(show_predicted_value=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract a single tree\nsingle_tree = model_reduced.estimators_[105][0]\n\ntree.export_graphviz(single_tree, out_file = 'tree.dot',\n                     rounded = True, \n                     feature_names = most_important_features,\n                     filled = True,\n                    max_depth = 3)\n\nsingle_tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert to a png\nimport pydot\n\n(graph,) = pydot.graph_from_dot_file('tree.dot')\ngraph.write_png('tree.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(\"tree.png\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}