{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Classification of Malwares by PE Headers\n\n![HP](https://store.hp.com/app/assets/images/uploads/prod/how-to-remove-malware-on-windows-pc-hero1581530134837100.png)\n\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nimport lightgbm as LGBM\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\n\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import accuracy_score\nimport optuna\nfrom optuna.samplers import TPESampler\n\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\nsns.set_theme(style=\"whitegrid\")\nsns.set(rc={'figure.figsize':(10,10)})\n\nimport warnings\nfrom sklearn.exceptions import ConvergenceWarning\n\nwarnings.simplefilter('always')\nwarnings.filterwarnings(\"ignore\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/classification-of-malwares/ClaMP_Integrated-5184.csv')\npd.set_option('display.max_columns',None)\npd.set_option('display.max_rows',None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"col = [i for i in df.columns if df[i].dtype != 'object' ]\nfile_header = [i for i in df.columns if 'FH_char' in i]\nOH_DLL = [i for i in df.columns if 'OH_DLL' in i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df.corr().stack().reset_index(name=\"correlation\")\ng = sns.relplot(\n    data=corr,\n    x=\"level_0\", y=\"level_1\", hue=\"correlation\", size=\"correlation\",\n    palette=\"vlag\", hue_norm=(-1, 1), edgecolor=\".7\",\n    height=10, sizes=(50, 250), size_norm=(-.2, .8))\ng.set(xlabel=\"\", ylabel=\"\", aspect=\"equal\")\ng.despine(left=True, bottom=True)\ng.ax.margins(.02)\nfor label in g.ax.get_xticklabels():\n    label.set_rotation(90)\nfor artist in g.legend.legendHandles:\n    artist.set_edgecolor(\".7\")\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install dabl\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import dabl\ndabl.plot(df,'class')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['class']\nX = df[col].drop(columns=['class'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test, y_train,y_test = train_test_split(X,y,test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CatBoost Hyperparameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''import optuna\ndef objective(trial):\n\n    param = {\n        \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n        \"depth\": trial.suggest_int(\"depth\", 1, 12),\n        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n        \"bootstrap_type\": trial.suggest_categorical(\n            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n        ),\n        \"used_ram_limit\": \"3gb\",\n    }\n\n    if param[\"bootstrap_type\"] == \"Bayesian\":\n        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n\n    gbm = CatBoostClassifier(**param)\n\n    gbm.fit(X_train, y_train, verbose=0, early_stopping_rounds=100)\n\n    preds = gbm.predict(X_test)\n    pred_labels = np.rint(preds)\n    accuracy = accuracy_score(y_test, pred_labels)\n    return accuracy\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=15, timeout=600)\ntrial = study.best_trial\ncat_params = trial.params'''\n\ncat_params = {'objective': 'CrossEntropy',\n 'colsample_bylevel': 0.07720247769141655,\n 'depth': 10,\n 'boosting_type': 'Ordered',\n 'bootstrap_type': 'Bayesian',\n 'bagging_temperature': 8.769937329955644}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LGBM Hyperparameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''import optuna\ndef objective1(trial):\n    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)\n    dtrain = lgbm.Dataset(X_train, label=y_train)\n\n    param = {\n        \"objective\": \"binary\",\n        \"metric\": \"binary_logloss\",\n        \"verbosity\": -1,\n        \"boosting_type\": \"gbdt\",\n        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n    }\n\n    gbm = lgbm.train(param, dtrain)\n    preds = gbm.predict(X_test)\n    pred_labels = np.rint(preds)\n    accuracy = accuracy_score(y_test, pred_labels)\n    return accuracy\nstudy1 = optuna.create_study(direction=\"maximize\")\nstudy1.optimize(objective1, n_trials=100)\ntrial1 = study1.best_trial\nlgbm_params = trial1.params'''\n\n\nlgbm_params = {'lambda_l1': 2.9518538351373698e-08,\n 'lambda_l2': 0.07086960074688683,\n 'num_leaves': 131,\n 'feature_fraction': 0.5523182028151434,\n 'bagging_fraction': 0.6074722133685865,\n 'bagging_freq': 4,\n 'min_child_samples': 26}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"cb = CatBoostClassifier(**cat_params)\nlgbm = LGBMClassifier(**lgbm_params)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LGBM Tree"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"LGBM.plot_tree(lgbm.fit(X_train,y_train),figsize=(100,100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stacking"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier\nest = [('catboost', cb),('lgbm', lgbm)]\nsclf = StackingClassifier(estimators=est,final_estimator=cb)\nsclf.fit(X_train,y_train);\nprint('Stacking Completed')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,sclf.predict(X_test)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}