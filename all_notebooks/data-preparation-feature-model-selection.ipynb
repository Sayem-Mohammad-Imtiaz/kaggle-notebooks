{"cells":[{"metadata":{},"cell_type":"markdown","source":"# The analysis contains three parts: \n# 1. data preparation\n# 2. fearure and model selection\n# 3. model finishing"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\ndf = pd.read_csv('../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf = pd.read_csv('/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\nprint(df.head())\nprint('Data frame shape',df.shape)\n\nsns.countplot(x=df['quality'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"----------------------------------------------------------------------------------------------------\n# The duplicated rows are cleaned in this part."},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate duplicates\nprint('Data frame shape before duplicate cleaning', df.shape)\ndups = df.duplicated()\n# report if there are any duplicates\nprint('\\nany duplicates:',dups.any())\n# list all duplicate rows\n#print('\\nlist all duplicate rows:',df[dups])\n\n# delete duplicate rows\ndf.drop_duplicates(inplace=True)\n\nprint('Data frame shape after duplicate cleaning',df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n----------------------------------------------------------------------------------------------------\n# A test for a normality/ a normal distribution of the data shows the data are not normal distrubuted and a transformation is needed."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import normaltest\n\nprint(df.shape)\n# normality test\nfor ix in df.columns.values:\n    stat, p = normaltest(df[ix])\n    print(ix)\n    print('Statistics=%.3f, p=%.3f' % (stat, p))\n    # interpret\n    alpha = 0.05\n    if p > alpha:\n     print('Sample looks Gaussian (fail to reject H0)')\n    else:\n     print('Sample does not look Gaussian (reject H0)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize the number of unique values in each column\nprint('\\nnumber of unique values in each column:',print(df.nunique()))\n\n# summarize the number of unique values in each column\nfor ix in df.columns.values:\n    num = len(np.unique(df[ix]))\n    percentage = float(num) / df.shape[0] * 100\n    print('{}, {}, {}%'.format(ix, num, percentage))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"----------------------------------------------------------------------------------------------------\n# Graphic of the raw data distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"# histogram of the data\nplt.figure(figsize=(10, 6))\ndfg = df.values\ndfg = dfg[:, :-1]\nfor ix in range(dfg.shape[1]):\n    plt.subplot(3,4,ix+1)\n    plt.hist(dfg[:,ix], bins=25)\nplt.grid(True)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"----------------------------------------------------------------------------------------------------\n# A test for normality is preformed with statmodels and the results are the same as the test preformed with scipy."},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.stats.diagnostic as ssd\n\n#### NORMALITY TEST\nprint(df.shape)\nfor ix in df.columns.values:\n    p_val=ssd.kstest_normal(df[ix].values)\n    print('p-value for {} = {:.4f}'.format(ix,p_val[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prepation of the input and output."},{"metadata":{"trusted":true},"cell_type":"code","source":"# retrieve the array of data\ndata = df.values\n# separate into input and output columns\nX = data[:, :-1]\ny = data[:, -1]\n\nprint('X',X[0:2,:])\nprint('y',y[0:2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"----------------------------------------------------------------------------------------------------\n# A cleaning of the outliers with a IsolationForest method."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import IsolationForest\n\n# summarize the shape of the training dataset\nprint('\\ndataset before outlier cleaning:',X.shape, y.shape)\n# identify outliers\niforest = IsolationForest()\nyhat = iforest.fit_predict(X)\n# select all rows that are not outliers\nmask = yhat != -1\nX, y = X[mask, :], y[mask]\n# summarize the shape of the updated training dataset\nprint('dataset after outlier cleaning:',X.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"----------------------------------------------------------------------------------------------------\n# Data normalization is performed."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import PowerTransformer\n\nX = np.delete(X, np.s_[7], axis=1) \n\n# power transform the raw data\npower = PowerTransformer(method='yeo-johnson', standardize=True)\nX_trans = power.fit_transform(X)\n\n# histogram of the transformed data\nplt.figure(figsize=(10, 6))\nfor ix in range(X_trans.shape[1]):\n    plt.subplot(3,4,ix+1)\n    plt.hist(X_trans[:,ix], bins=25)\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"----------------------------------------------------------------------------------------------------\n# It looks better but the normality test shows that the data isn't normal distributed after the transformation. \n# This means the results from the analysis may be not valid."},{"metadata":{"trusted":true},"cell_type":"code","source":"#### NORMALITY TEST\nprint(X_trans.shape)\nprint(X_trans.shape[1])\nfor ix in range(X_trans.shape[1]):\n    p_val=ssd.kstest_normal(X_trans[:,ix])\n    print('p-value for {} = {:.4f}'.format(ix,p_val[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"----------------------------------------------------------------------------------------------------\n# The multi-colinearity is removed from the data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\n# remove the colinearity from X\nfor i in np.arange(0,X_trans.shape[1]):\n    vif = [variance_inflation_factor(X_trans, ix) for ix in range(X_trans.shape[1])]\n    maxloc = vif.index(max(vif))\n    print('maxloc',maxloc)\n    if max(vif) > 10:\n        #print('vif :', vif)\n        print('dropping at index:  ' + str(maxloc))\n        #del list_factors[maxloc]\n        X_trans = np.delete(X_trans, np.s_[maxloc], axis=1) \n    else:\n        break\n#print('Final variables:', list_factors)\nprint(X_trans.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"----------------------------------------------------------------------------------------------------\n# Feature selection and model selection is performed in one step. \n# f_classif or mutual_info_classif is used for feature selection wuth every algorithm.\n# The models performance are measured with negative log loss and  accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import cross_val_score\n\n# define the evaluation method\ncv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=200)\n\nresults = []\nlogloss_resu = []\nnames = []\n\n# Algorithms\nmodels = []\nmodels.append(('LR', LogisticRegression(solver='liblinear')))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC(gamma='auto',probability=True)))\n\n\n\n# define the pipeline to evaluate\nfor name,model in models:\n    fs = SelectKBest()\n    pipeline = Pipeline(steps=[('anova',fs), ('model', model)])\n    # define the grid\n    grid = {'anova__k':[i+1 for i in range(X.shape[1])],'anova__score_func':[f_classif,mutual_info_classif]}\n    # define the grid search\n    search = RandomizedSearchCV(pipeline, grid, scoring='neg_log_loss', n_jobs=-1, cv=cv)\n    # perform the search\n    result = search.fit(X_trans, y)\n\n    print('\\nModel name:',name)\n\n    means = search.cv_results_['mean_fit_time']\n    stds = search.cv_results_['std_fit_time']\n    params = search.cv_results_['mean_score_time']\n    timem = search.cv_results_['std_score_time']\n\n    # measure calculation time\n    #for mean, stdev, param in zip(means, stds, params):\n        #print(\"mean_fit_time:%f std_fit_time:%f  mean_score_time:%f std_score_time:%f\" % (mean.sum(), stdev.sum(), param.sum(),timem.sum()))\n\n    logloss_results = cross_val_score(search.best_estimator_,X_trans,y, cv=cv,scoring='neg_log_loss')\n    logloss_resu.append(logloss_results)\n\n    cv_results = cross_val_score(search.best_estimator_,X_trans,y, cv=cv,scoring='accuracy')\n    results.append(cv_results)\n\n    names.append(name)\n    # summarize best\n\n    print('Best Mean Log-loss: %.3f' % result.best_score_)\n    print('Best Config: %s' % result.best_params_)\n    msg = \"accuracy -> %s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n\n# Compare Algorithms\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(121)\nax.set_title('accuracy')\nplt.boxplot(results)\nax.set_xticklabels(names)\nax.set_ylim(0, 1)\nax = fig.add_subplot(122)\nax.set_title('neg_log_loss')\nplt.boxplot(logloss_resu)\nax.set_xticklabels(names)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"----------------------------------------------------------------------------------------------------\n# Enseble methods are used for the analysis in this section."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom scipy.stats import randint\n\n# ensembles\nensembles = []\nensembles.append(('AB', AdaBoostClassifier()))\nensembles.append(('GBM', GradientBoostingClassifier()))\nensembles.append(('RF', RandomForestClassifier()))\nensembles.append(('ET', ExtraTreesClassifier()))\nresults = []\nlogloss_resu = []\nnames = []\nfor name, model in ensembles:\n    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=200)\n    fs = SelectKBest(score_func=f_classif)\n    pipeline = Pipeline(steps=[('anova',fs), ('model', model)])\n    # define the grid\n    grid = {'anova__k':[i+1 for i in range(X.shape[1])],'model__n_estimators':randint(10,400)}\n    # define the grid search\n    search = RandomizedSearchCV(pipeline, grid, scoring='neg_log_loss', n_jobs=-1, cv=cv, random_state=500)\n    search.fit(X_trans, y)\n    print('\\n',name)\n    print ('Best Parameters: ', search.best_params_)\n\n    cv_results = cross_val_score(search.best_estimator_, X_trans, y, cv=cv, scoring='accuracy')\n    logloss_results = cross_val_score(search.best_estimator_, X_trans, y, cv=cv, scoring='neg_log_loss')\n    results.append(cv_results)\n    logloss_resu.append(logloss_results)\n    names.append(name)\n    msg = \"accuracy -> %s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n    msg = \"logloss -> %s: %f (%f)\" % (name, logloss_results.mean(), logloss_results.std())\n    print(msg)\n\n# Compare Algorithms\nfig = plt.figure()\nfig.suptitle('Ensemble Algorithm Comparison')\nax = fig.add_subplot(121)\nax.set_title('accuracy')\nplt.boxplot(results)\nax.set_xticklabels(names)\nax.set_ylim(0, 1)\nax = fig.add_subplot(122)\nax.set_title('neg_log_loss')\nplt.boxplot(logloss_resu)\nax.set_xticklabels(names)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"----------------------------------------------------------------------------------------------------\n# Model finishing: the performance of the models is checked."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n# feature selection\ndef select_features(X, y):\n    fs = SelectKBest(score_func=f_classif, k=9)\n    fs.fit(X, y)\n    X = fs.transform(X)\n    return X\n\n# define the evaluation method\nX_trans = select_features(X_trans, y)\n\n\ncv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=200)\nmodel = ExtraTreesClassifier(n_estimators = 337)\nmodel.fit(X_trans,y)\ncv_results = cross_val_score(model, X_trans, y, cv=cv, scoring='accuracy')\nmsg = \"%s: %f (%f)\" % ('GMB', cv_results.mean(), cv_results.std())\nprint(msg)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}