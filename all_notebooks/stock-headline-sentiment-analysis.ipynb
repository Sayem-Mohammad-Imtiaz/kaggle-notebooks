{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_excel('/kaggle/input/selective-stock-headlines-sentiment/Project6500.xlsx')\ndf['datetime'] = pd.to_datetime(df['datetime'])\ndf['headline'][2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state = 1\ndf = df.sample(frac=1,random_state=state)\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop =['i', 'me', 'my', 'myself',\n 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he',\n 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', \n 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', \n 'being', 'a', 'an', 'the', 'and', 'to', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain','at','of','for','in','v'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Preprocessing\ndf['headline_mod'] = df['headline']\ndf['headline_mod'] = df['headline_mod'].replace(to_replace='\\@+[a-zA-Z]+', value='', regex=True).replace(to_replace='\\#+[a-zA-Z]+', value='', regex=True).replace(to_replace='[a-zA-Z]+\\…', value='', regex=True).replace(to_replace='…', value='', regex=False).apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\ndf = df[['datetime', 'headline', 'headline_mod', 'ticker','sentiment']]\ndf.drop_duplicates(keep ='first',inplace=True)\ndf.reset_index(inplace=True, drop=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\ntop_word = 10000\nmax_words = 50\nsplitting_num = 8000\ntok = Tokenizer(num_words=top_word)\ntok.fit_on_texts(df['headline_mod'][:splitting_num])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Experiment cond.\nX_train = tok.texts_to_sequences(df['headline_mod'][:splitting_num])\nX_test = tok.texts_to_sequences(df['headline_mod'][splitting_num:])\n\n#Data to be prediceted\nY_train = df['sentiment'][:splitting_num]\nY_test = df['sentiment'][splitting_num:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\n# One-hot category\nY_train = to_categorical(Y_train)\nY_test = to_categorical(Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = sequence.pad_sequences(X_train, maxlen=max_words)\nX_test  = sequence.pad_sequences(X_test,  maxlen=max_words)\nprint(\"X_train.shape: \", X_train.shape)\nprint(\"X_test.shape: \", X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, Conv1D, MaxPooling1D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model 1 \ndef model_1():\n    model = Sequential()\n    model.add(Embedding(top_word, 32, input_length=max_words))\n    model.add(Dropout(0.5))\n    model.add(LSTM(64,return_sequences = True))\n    model.add(LSTM(64))\n    model.add(Dropout(0.25))\n    model.add(Dense(128, activation=\"relu\"))\n    model.add(Dropout(0.25))\n    model.add(Dense(2, activation=\"softmax\"))\n    \n    return(model)\n\n#Model 2\ndef model_2():\n    model = Sequential()\n    model.add(Embedding(top_word, 32, input_length=max_words))\n    model.add(Dropout(0.5))\n    model.add(Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'))\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Dropout(0.25))\n    model.add(LSTM(64,return_sequences = True))\n    model.add(LSTM(64))\n    model.add(Dropout(0.25))\n    model.add(Dense(128, activation=\"relu\"))\n    model.add(Dropout(0.25))\n    model.add(Dense(2, activation=\"softmax\"))\n    \n    return(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_setup(model,X_train,Y_train,X_test, Y_test):\n    #Model setting up\n    model.summary()\n    # Model compiling\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    # Model training\n    history = model.fit(X_train, Y_train, validation_split=0.2, epochs=10, batch_size=32, verbose=2)\n    # Model Evaluation\n    loss, accuracy = model.evaluate(X_test, Y_test,verbose=0)\n    print(\"-----------------------------------------\")\n    print(\"Accuracy of the Training Dataset = {:.2f}\".format(accuracy))\n    print(\"Report End\")\n    return(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def result_eva (loss,val_loss,acc,val_acc):\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    \n    epochs = range(1,len(loss)+1)\n    plt.plot(epochs, loss,'b-', label ='Training Loss')\n    plt.plot(epochs, val_loss,'r--', label ='Validation Loss')\n    plt.title(\"Training and Validation Loss\")\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n    \n    epochs = range(1, len(acc)+1)\n    plt.plot(epochs, acc, \"b-\", label=\"Training Acc\")\n    plt.plot(epochs, val_acc, \"r--\", label=\"Validation Acc\")\n    plt.title(\"Training and Validation Accuracy\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model_1()\nhistory = model_setup(model,X_train,Y_train,X_test, Y_test)\nresult_eva(history.history['loss'], history.history['val_loss'], history.history['accuracy'], history.history['val_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Prediction\nY_pred = model.predict_classes(X_test,batch_size=10,verbose=2)\nY_target = df['sentiment'][splitting_num:].astype(int)\n#print(Y_pred)\n#print(Y_target)\ntb = pd.crosstab(Y_target,Y_pred,rownames=['label'],colnames=['predict'])\nprint(tb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = model_2()\nhistory2 = model_setup(model2,X_train,Y_train,X_test, Y_test)\nresult_eva(history2.history['loss'], history2.history['val_loss'], history2.history['accuracy'], history2.history['val_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Prediction\nY_pred = model2.predict_classes(X_test,batch_size=10,verbose=2)\nY_target = df['sentiment'][splitting_num:].astype(int)\ntb = pd.crosstab(Y_target,Y_pred,rownames=['label'],colnames=['predict'])\nprint(tb)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}