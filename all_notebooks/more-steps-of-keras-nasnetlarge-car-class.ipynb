{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"> Это пример решения задачи с использованием Keras. Вы можете использовать этот кернер для дальнейших исследований и экспериментов.\n# Классификация изображений\n\n### Основная идея этого решения: взять предобученую на ImageNet сеть Xception и дообучить под нашу задачу. \nПо ходу решения мы будем давать вам рекомендации, которые помогут улучшить качество модели. \n\n\nУдачи и Поехали!","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-09T19:39:28.908715Z","iopub.execute_input":"2021-07-09T19:39:28.909053Z","iopub.status.idle":"2021-07-09T19:39:29.573137Z","shell.execute_reply.started":"2021-07-09T19:39:28.909007Z","shell.execute_reply":"2021-07-09T19:39:29.572262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\n\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.applications import NASNetLarge\nfrom tensorflow.keras.layers import *\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#увеличим дефолтный размер графиков\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#графики в svg выглядят более четкими\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint(os.listdir(\"../input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-07-09T19:42:40.572346Z","iopub.execute_input":"2021-07-09T19:42:40.572698Z","iopub.status.idle":"2021-07-09T19:42:40.60143Z","shell.execute_reply.started":"2021-07-09T19:42:40.572664Z","shell.execute_reply":"2021-07-09T19:42:40.60054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Работаем с Tensorflow v2**","metadata":{}},{"cell_type":"code","source":"!pip freeze > requirements.txt","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-09T19:39:38.456891Z","iopub.execute_input":"2021-07-09T19:39:38.457266Z","iopub.status.idle":"2021-07-09T19:39:40.841467Z","shell.execute_reply.started":"2021-07-09T19:39:38.457234Z","shell.execute_reply":"2021-07-09T19:39:40.840441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Основные настройки","metadata":{}},{"cell_type":"code","source":"# В setup выносим основные настройки: так удобнее их перебирать в дальнейшем.\n\nEPOCHS               = 7  # эпох на обучение\nBATCH_SIZE           = 20 # уменьшаем batch если сеть большая, иначе не влезет в память на GPU\nLR                   = 1.6e-5\nVAL_SPLIT            = 0.15 # сколько данных выделяем на тест = 15%\n\nCLASS_NUM            = 10  # количество классов в нашей задаче\nIMG_SIZE             = 331 # какого размера подаем изображения в сеть\nIMG_CHANNELS         = 3   # у RGB 3 канала\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '../input/sf-dl-car-classification/'\nPATH = \"../working/car/\" # рабочая директория","metadata":{"execution":{"iopub.status.busy":"2021-07-09T19:45:07.596789Z","iopub.execute_input":"2021-07-09T19:45:07.59719Z","iopub.status.idle":"2021-07-09T19:45:07.603155Z","shell.execute_reply.started":"2021-07-09T19:45:07.597157Z","shell.execute_reply":"2021-07-09T19:45:07.602006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Устаналиваем конкретное значение random seed для воспроизводимости\nos.makedirs(PATH,exist_ok=False)\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-09T19:39:42.264237Z","iopub.execute_input":"2021-07-09T19:39:42.264489Z","iopub.status.idle":"2021-07-09T19:39:42.270804Z","shell.execute_reply.started":"2021-07-09T19:39:42.264464Z","shell.execute_reply":"2021-07-09T19:39:42.269991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA / Анализ данных","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T19:39:45.335822Z","iopub.execute_input":"2021-07-09T19:39:45.336254Z","iopub.status.idle":"2021-07-09T19:39:45.415863Z","shell.execute_reply.started":"2021-07-09T19:39:45.336212Z","shell.execute_reply":"2021-07-09T19:39:45.414922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T19:39:46.47664Z","iopub.execute_input":"2021-07-09T19:39:46.476934Z","iopub.status.idle":"2021-07-09T19:39:46.496256Z","shell.execute_reply.started":"2021-07-09T19:39:46.476904Z","shell.execute_reply":"2021-07-09T19:39:46.494859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.Category.value_counts()\n# распределение классов достаточно равномерное - это хорошо","metadata":{"execution":{"iopub.status.busy":"2021-07-09T19:39:49.676661Z","iopub.execute_input":"2021-07-09T19:39:49.677019Z","iopub.status.idle":"2021-07-09T19:39:49.685737Z","shell.execute_reply.started":"2021-07-09T19:39:49.67695Z","shell.execute_reply":"2021-07-09T19:39:49.684633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Распаковываем картинки')\n# Will unzip the files so that you can see them..\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(DATA_PATH+data_zip,\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","metadata":{"execution":{"iopub.status.busy":"2021-07-09T19:40:26.888726Z","iopub.execute_input":"2021-07-09T19:40:26.889099Z","iopub.status.idle":"2021-07-09T19:40:54.405496Z","shell.execute_reply.started":"2021-07-09T19:40:26.889064Z","shell.execute_reply":"2021-07-09T19:40:54.403619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Пример картинок (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = train_df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PATH+f'train/{random_image_cat[index]}/{path}')\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-09T19:40:54.407128Z","iopub.execute_input":"2021-07-09T19:40:54.40759Z","iopub.status.idle":"2021-07-09T19:40:55.291214Z","shell.execute_reply.started":"2021-07-09T19:40:54.407549Z","shell.execute_reply":"2021-07-09T19:40:55.286063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посмотрим на примеры картинок и их размеры чтоб понимать как их лучше обработать и сжимать.","metadata":{}},{"cell_type":"code","source":"image = PIL.Image.open(PATH+'/train/0/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","metadata":{"execution":{"iopub.status.busy":"2021-07-09T19:40:55.293275Z","iopub.execute_input":"2021-07-09T19:40:55.29373Z","iopub.status.idle":"2021-07-09T19:40:55.483475Z","shell.execute_reply.started":"2021-07-09T19:40:55.293691Z","shell.execute_reply":"2021-07-09T19:40:55.482497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Уже догадываетесь, что означают классы?","metadata":{}},{"cell_type":"markdown","source":"# Подготовка данных","metadata":{}},{"cell_type":"markdown","source":"### Аугментация данных","metadata":{}},{"cell_type":"code","source":"# Вы помните, что аугментация данных важна, когда мы работаем с небольшим датасетом. Это как раз наш случай.\n# Чтобы лучше понять работу параметров, попробуйте их изменить. К какому результату это приведет?\n# Официальная документация: https://keras.io/preprocessing/image/\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    rotation_range = 10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    validation_split=VAL_SPLIT, # set validation split\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\n#Рекомендация Подключите более продвинутые библиотеки аугментации изображений (например: albumentations или imgaug, для них есть специальные \"обертки\" под Keras, например: https://github.com/mjkvaak/ImageDataAugmentor)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T19:41:05.838103Z","iopub.execute_input":"2021-07-09T19:41:05.838457Z","iopub.status.idle":"2021-07-09T19:41:05.844581Z","shell.execute_reply.started":"2021-07-09T19:41:05.838427Z","shell.execute_reply":"2021-07-09T19:41:05.843536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Генерация данных","metadata":{}},{"cell_type":"code","source":"# Завернем наши данные в генератор:\n\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train/',      # директория где расположены папки с картинками \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)\n\n# Обратите внимание, что для сабмита мы используем другой источник test_datagen.flow_from_dataframe. Как вы думаете, почему?","metadata":{"execution":{"iopub.status.busy":"2021-07-09T19:41:14.363849Z","iopub.execute_input":"2021-07-09T19:41:14.364204Z","iopub.status.idle":"2021-07-09T19:41:15.303456Z","shell.execute_reply.started":"2021-07-09T19:41:14.364173Z","shell.execute_reply":"2021-07-09T19:41:15.302696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator[0][1].shape","metadata":{"execution":{"iopub.status.busy":"2021-07-09T19:41:15.382042Z","iopub.execute_input":"2021-07-09T19:41:15.38229Z","iopub.status.idle":"2021-07-09T19:41:15.880313Z","shell.execute_reply.started":"2021-07-09T19:41:15.382265Z","shell.execute_reply":"2021-07-09T19:41:15.87921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Построение модели","metadata":{}},{"cell_type":"markdown","source":"### Загружаем предобученную сеть NasNetLarge:","metadata":{}},{"cell_type":"code","source":"# base_model = NASNetLarge(weights='imagenet', include_top=False, input_shape = input_shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T06:10:49.668944Z","iopub.execute_input":"2021-07-07T06:10:49.669266Z","iopub.status.idle":"2021-07-07T06:11:01.99132Z","shell.execute_reply.started":"2021-07-07T06:10:49.669234Z","shell.execute_reply":"2021-07-07T06:11:01.990537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#base_model.summary()\n# Рекомендация: Попробуйте и другие архитектуры сетей","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-07T06:11:03.828996Z","iopub.execute_input":"2021-07-07T06:11:03.829337Z","iopub.status.idle":"2021-07-07T06:11:03.832947Z","shell.execute_reply.started":"2021-07-07T06:11:03.829306Z","shell.execute_reply":"2021-07-07T06:11:03.831864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Устанавливаем новую \"голову\" (head)\n\n# x = base_model.output\n# x = GlobalAveragePooling2D()(x)\n# # let's add a fully-connected layer\n# x = Dense(256, activation='relu')(x)\n# x = Dropout(0.25)(x)\n# x = Dense(128, activation='relu')(x)\n# x = Dropout(0.25)(x)\n# x = Dense(64, activation='relu')(x)\n# x = Dropout(0.25)(x)\n# # and a logistic layer -- let's say we have 10 classes\n# predictions = Dense(CLASS_NUM, activation='softmax')(x)\n\n# # this is the model we will train\n# model = Model(inputs=base_model.input, outputs=predictions)\n# model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"]) #learning_rate=LR","metadata":{"execution":{"iopub.status.busy":"2021-07-07T06:11:04.29024Z","iopub.execute_input":"2021-07-07T06:11:04.290582Z","iopub.status.idle":"2021-07-07T06:11:04.423823Z","shell.execute_reply.started":"2021-07-07T06:11:04.290546Z","shell.execute_reply":"2021-07-07T06:11:04.422985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.summary()\n# Рекомендация: Попробуйте добавить Batch Normalization","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-09T19:43:33.974795Z","iopub.execute_input":"2021-07-09T19:43:33.975161Z","iopub.status.idle":"2021-07-09T19:43:33.981242Z","shell.execute_reply.started":"2021-07-09T19:43:33.975129Z","shell.execute_reply":"2021-07-09T19:43:33.9804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model('../input/model-18/NasNetLarge.hdf5')","metadata":{"execution":{"iopub.status.busy":"2021-07-09T19:42:50.100106Z","iopub.execute_input":"2021-07-09T19:42:50.100454Z","iopub.status.idle":"2021-07-09T19:43:16.864909Z","shell.execute_reply.started":"2021-07-09T19:42:50.100422Z","shell.execute_reply":"2021-07-09T19:43:16.86404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Обучение модели","metadata":{}},{"cell_type":"markdown","source":"Добавим ModelCheckpoint чтоб сохранять прогресс обучения модели и можно было потом подгрузить и дообучить модель.","metadata":{}},{"cell_type":"code","source":"def scheduler(epoch, lr):\n    return lr * tf.math.exp(-0.1)\n\ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nlr_sched = LearningRateScheduler(scheduler, verbose = 1)\ncallbacks_list = [checkpoint, lr_sched]\n\n# Рекомендация 1. Добавьте другие функции из https://keras.io/callbacks/\n# Рекомендация 2. Используйте разные техники управления Learning Rate\n# https://towardsdatascience.com/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6 (eng)\n# http://teleported.in/posts/cyclic-learning-rate/ (eng)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T19:45:29.15353Z","iopub.execute_input":"2021-07-09T19:45:29.153929Z","iopub.status.idle":"2021-07-09T19:45:29.159059Z","shell.execute_reply.started":"2021-07-09T19:45:29.153883Z","shell.execute_reply":"2021-07-09T19:45:29.158179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Обучаем:","metadata":{}},{"cell_type":"code","source":"history = model.fit_generator(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)\n\n# Рекомендация: попробуйте применить transfer learning с fine-tuning","metadata":{"execution":{"iopub.status.busy":"2021-07-09T19:45:32.725649Z","iopub.execute_input":"2021-07-09T19:45:32.726002Z","iopub.status.idle":"2021-07-09T19:46:09.190019Z","shell.execute_reply.started":"2021-07-09T19:45:32.725945Z","shell.execute_reply":"2021-07-09T19:46:09.187544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# сохраним итоговую сеть и подгрузим лучшую итерацию в обучении (best_model)\nmodel.save('../working/model_last.hdf5')\nmodel.load_weights('best_model.hdf5')","metadata":{"execution":{"iopub.status.busy":"2021-06-27T16:46:24.267425Z","iopub.status.idle":"2021-06-27T16:46:24.267965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T16:46:24.268901Z","iopub.status.idle":"2021-06-27T16:46:24.269503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В Итоге точность нашей модели составила 93%. \nУчитывая что классов 10 - это Очень хороший результат!     \nПосмотрим графики обучения:","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T16:46:24.27059Z","iopub.status.idle":"2021-06-27T16:46:24.27117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Предсказание на тестовых данных","metadata":{}},{"cell_type":"code","source":"test_sub_generator.samples","metadata":{"execution":{"iopub.status.busy":"2021-06-27T16:46:24.272365Z","iopub.status.idle":"2021-06-27T16:46:24.273036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sub_generator.reset()\npredictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","metadata":{"execution":{"iopub.status.busy":"2021-06-27T16:46:24.274129Z","iopub.status.idle":"2021-06-27T16:46:24.274738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload/','')\nsubmission.to_csv('submission.csv', index=False)\nprint('Save submit')\n\n# Рекомендация: попробуйте добавить Test Time Augmentation (TTA)\n# https://towardsdatascience.com/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d","metadata":{"execution":{"iopub.status.busy":"2021-06-27T16:46:24.275978Z","iopub.status.idle":"2021-06-27T16:46:24.276589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T16:46:24.277819Z","iopub.status.idle":"2021-06-27T16:46:24.278484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clean PATH\nimport shutil\nshutil.rmtree(PATH)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-27T16:46:24.279723Z","iopub.status.idle":"2021-06-27T16:46:24.280309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Интересно, к какому классу модель отнесет вот эти автомобили?","metadata":{}},{"cell_type":"markdown","source":"# Что можно сделать, чтобы улучшить результат:","metadata":{}},{"cell_type":"markdown","source":"* Примените transfer learning с fine-tuning\n* Настройте LR, optimizer, loss\n* Подберите другие переменные (размер картинки, батч и т.д.)\n* Попробуйте и другие архитектуры сетей (а не только Xception) или их ансамбли. Примеры SOTA на ImageNet  \n* \n* Добавьте Batch Normalization и поэкспериментируйте с архитектурой “головы”\n* Примените другие функции callback Keras https://keras.io/callbacks/ \n* Добавьте TTA (Test Time Augmentation)\n* Дополнительно*: Используйте разные техники управления Learning Rate (https://towardsdatascience.com/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6 (eng) http://teleported.in/posts/cyclic-learning-rate/ (eng))\n* Дополнительно*: Добавьте более продвинутые библиотеки аугментации изображений (например, Albumentations )\n\n### Удачи в соревновании!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}