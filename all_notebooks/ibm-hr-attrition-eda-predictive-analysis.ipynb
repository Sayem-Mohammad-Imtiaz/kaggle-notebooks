{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import confusion_matrix , classification_report , accuracy_score\nfrom sklearn.ensemble import GradientBoostingClassifier\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"at = pd.read_csv('/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#columns that are Catagorical\nat.select_dtypes(include=['object']).columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#droping not necessary columns and columns with Homogineus Data\nat.drop(['Over18' , 'StandardHours' ,'EmployeeCount','EmployeeNumber' ] , inplace=True , axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting heat map of the corelation matrix \nplt.figure(figsize=(13,9))\nsns.heatmap(at.corr(),vmax=0.8,linewidth=0.1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the Attrition Row \nvals = [at.Attrition[at.Attrition=='Yes'].count() , at.Attrition[at.Attrition=='No'].count()]\nlabel = [\"Yes\" , \"No\"]\nplt.pie(vals , labels=label , autopct = '%1.0f%%' , explode=(0 , 0.1));\nplt.title(\"Attrition  Percentage\");\n#Here we can see that the data contains 2 classed they are Yes and No , So here the there only 16% yes Record and 84%No record.\n#There is an imbalance between both the class.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ploting Age vs Attrition \nplt.figure(figsize=(10,5))\nsns.boxplot(y='Age' , x='Attrition' , data=at )\nplt.title(\"Age vs Attrition\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.histplot(x='Age' ,hue='Attrition' , data=at ,element=\"poly\", palette=('#24b1d1', '#ae24d1') );\nplt.title(\"Age Vs Atrrition Histogram\")\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Attrition and renumeration quality \n#Monthly Income and Attrition Box plot \n#Checking How Attrition is effected by Monthly Income\nplt.figure(figsize=(10,5))\nsns.boxplot(y = 'MonthlyIncome' , x='Attrition' , data=at)\nplt.title(\"Monthly Income Vs Attrition\");\n#from the plot it is clearly evident that people with less monthly income have higher tendency to leave","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.histplot(x='MonthlyIncome' ,hue='Attrition' , data=at ,element=\"poly\", palette=('#24b1d1', '#ae24d1') )\nplt.title(\"Monthly income and Attrition Histogram\")\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking How Attrition is effected by Daily Rates \nplt.figure(figsize=(10 , 5))\nplt.title(\"Daily Rate Vs Attrition\")\nsns.boxplot(y = 'DailyRate' , x='Attrition' , data=at)\n\n#Here we can see that people less daily rate have higher chances of Attrition","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking How Attrition is effected by Monthly Rates \nplt.figure(figsize=(10 , 5))\nsns.boxplot(y = 'MonthlyRate' , x='Attrition' , data=at)\nplt.title(\"Montly Rate vs atrition\");\n#Here we can see that ther is no evident relation between mothly rates and Attrition ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking How Attrition is effected by Hourly rates\nplt.figure(figsize=(10 , 5))\nsns.boxplot(y = 'HourlyRate' , x='Attrition' , data=at)\nplt.title(\"Hourly Rate vs atrition\");\n#Here we can see that ther is no evident relation between mothly rates and Attrition ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Relation between People Leaving and OverTime \nvalues = [at.Attrition[(at.Attrition == 'Yes')&(at.OverTime == 'Yes')].count() ,at.Attrition[(at.Attrition == 'Yes')&(at.OverTime == 'No')].count()]\nplt.pie(values , labels=['Takes Over Time ' , 'Does not Take over Time '] , autopct='%1.0f%%' );\nplt.title(\"People leaving Over Time \");\n#Here 54% of the people who are leaving are taking over time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"values = [at.Attrition[(at.Attrition == 'No')&(at.OverTime == 'Yes')].count() ,at.Attrition[(at.Attrition == 'No')&(at.OverTime == 'No')].count()]\nplt.pie(values , labels=['Takes Over Time ' , 'Does not Take over Time '] , autopct='%1.0f%%' , explode=(0,0.1));\nplt.title(\"People Not leaving Over Time \");\n#Here only 23% of the people who are not leaving takes over time ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Here we can see that percent of people who are taking overtime is more in Attrition yes ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Total Working years and Attrition histogram\nplt.figure(figsize=(10,5))\nsns.histplot(x='TotalWorkingYears' ,hue='Attrition' , data=at ,element=\"poly\", palette=('#24b1d1', '#ae24d1'))\nplt.title(\"Total Working years and Attrition histogram\")\nplt.grid();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Years at Company vs Jobrole vs Attrition \nplt.figure(figsize=(10,5))\nsns.histplot(x='JobRole' ,hue='Attrition' , data=at , multiple='stack',palette=('#24b1d1', '#ae24d1'), edgecolor='white')\nplt.title(\" Job Role vs Attrition\")\nplt.xticks(rotation=90)\nplt.grid()\n#here we can see the effect of years at company and jobrole on Attrition ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Here we can see How Distance from home is effecting Attretion \nplt.figure(figsize=(10,5))\nsns.histplot(x='DistanceFromHome' ,hue='Attrition' , data=at ,palette=('#24b1d1', '#ae24d1'), element='poly',edgecolor='white')\nplt.grid()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Here \nplt.figure(figsize=(10 , 5))\nsns.histplot(x='BusinessTravel' , hue='Attrition' ,data=at , multiple='stack' ,palette=('#24b1d1', '#ae24d1') , edgecolor='white' , shrink=0.8);\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(10 ,  5))\nsns.boxplot(y='YearsAtCompany' , hue='Attrition' , x='JobRole' , data=at)\nplt.grid()\nplt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.histplot(x='NumCompaniesWorked' , hue='Attrition' , data=at  ,multiple='stack' , palette=('#24b1d1', '#ae24d1'), edgecolor='white')\nplt.grid()\n#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Here from the graphs build above we can see that  who components like Age , Monthly Income ,Distance From Home  , NumCompaniesWorked , \n#job Role, etc effect the Attrition of a company","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building a Predictive Classification Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"at = pd.read_csv('/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')\n#use only when required \nat.Attrition.replace({\"Yes\":1 , \"No\":0} , inplace=True)\n#labeled to numerical\nle=LabelEncoder()\nat[at.select_dtypes(include=['object']).columns]  = at[at.select_dtypes(include=['object']).columns].apply(le.fit_transform)\n#columns to be dropped\nat.drop(['Over18' , 'StandardHours' ,'EmployeeCount','EmployeeNumber' ] , inplace=True , axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing Outliers in monthly income column \ndef remove_outliers(df , col , k):\n    mean= df[col].mean()\n    sd=df[col].std()\n    global df1\n    final_list = [x for x in df[col] if (x>mean-k*sd)]\n    final_list = [x for x in final_list if (x<mean+k*sd)]\n    df1 = df.loc[df[col].isin(final_list)];\n    return df1\nat =remove_outliers(at , 'MonthlyIncome' ,2.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sampling\nat_train , at_test = train_test_split(at , test_size=0.2 , random_state=6)\nat_train[at_train.Attrition ==1].shape\nat_train_x = at_train.drop(['Attrition'] , axis=1 )\nat_train_y = at_train.Attrition\nat_test_x = at_test.drop(['Attrition'] , axis=1)\nat_test_y = at_test.Attrition\n#upsampling-class-1\ndf1 = at_train[at_train.Attrition == 1]\nat_train = pd.concat([at_train,df1,df1,df1,df1] , axis=0 )\nat_train_x = at_train.drop(['Attrition'] , axis=1 )\nat_train_y = at_train.Attrition","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#downSamling for Class 0 - Use if Necessary \ndf3=  at_train[at_train.Attrition==0].iloc[1:800,:]\ndf4=  at_train[at_train.Attrition == 1]\nat_train = pd.concat([df3 , df4] , axis=0)\nat_train_x = at_train.drop(['Attrition'] , axis=1 )\nat_train_y = at_train.Attrition","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest with adaptive Boosting\nrfc = RandomForestClassifier(n_estimators=500  , criterion='entropy' , max_depth=3)\nadc = AdaBoostClassifier(rfc)\nadc.fit(at_train_x , at_train_y)\npred_test_arf = adc.predict(at_test_x)\n\n\n\n\n#confution Matrix\ntab_arf = confusion_matrix(pred_test_arf , at_test_y)\nprint(tab_arf)\n\n#Full Classification Report\nreport = classification_report(at_test_y , pred_test_arf)\nprint(report)\n\n#Accuracy \naccuracy_rfa = np.sum(np.diag(tab_arf))*100/np.sum(tab_arf)\nprint(\"Accuracy_rf with adb :\" , accuracy_rfa)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the Feature Importance \nfeature_importance = pd.DataFrame({\"Feature \" : at_train_x.columns , \"Importance\": adc.feature_importances_})\nfeature_importance.sort_values(['Importance'] , ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nrfc = RandomForestClassifier(n_estimators=600  , criterion='entropy' , max_depth=5)\nrfc.fit(at_train_x , at_train_y)\npred_test_rf = rfc.predict(at_test_x)\n\n\n\ntab1 = confusion_matrix(pred_test_rf , at_test_y)\nprint(tab1)\n\n\nreport = classification_report(at_test_y , pred_test_rf)\nprint(report)\n\n\naccuracy_rf = accuracy_score(pred_test_rf , at_test_y)\nprint(\"Accuracy_rf :\" , accuracy_rf*100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the Feature Importance \nfeature_importance = pd.DataFrame({\"Feature \" : at_train_x.columns , \"Importance\": rfc.feature_importances_})\nfeature_importance.sort_values(['Importance'] , ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gdc = GradientBoostingClassifier()\ngdc.fit(at_train_x , at_train_y)\npredict = gdc.predict(at_test_x)\n\n\ntab_grad= confusion_matrix(predict , at_test_y)\nprint(tab_grad)\n\n\nreport_grad = classification_report(at_test_y , predict)\nprint(report_grad)\n\naccuracy_grad = accuracy_score(pred_test_rf , at_test_y)\nprint(\"Accuracy gradient: \" , accuracy_grad)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}