{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing libraries for data exploration and anlysis\nimport sklearn as sk\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#Model from SciKit-Learn\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn import feature_selection\nfrom sklearn.impute import SimpleImputer\n\n# Model Evaluations from SciKit Learn\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix,precision_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import precision_score\n\n\n# for displaying graph in the notebook\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# [Real or Fake] : Fake Job Description Prediction\n*  This dataset contains 18K job descriptions out of which about 800 are fake. The data consists of both textual information and meta-information about the jobs. The dataset can be used to create classification models which can learn the job descriptions which are fraudulent.\n\n### Kaggle\n    * https://www.kaggle.com/shivamb/real-or-fake-fake-jobposting-prediction\n\n### Data Source \n     * Employment Scam Aegean Dataset \n\n### Execution Strategy  - An end-to-end Scikit-Learn worfklow\n     1. Getting the data ready\n     2. Handling NaN data and convert categorical data into Numeric\n     3. Choosing the right maching learning estimator/aglorithm/model for this problem\n     4. Fitting your chosen machine learning model to data and using it to make a prediction\n     5. Evaluting a machine learning model\n     6. Improving predictions through experimentation (hyperparameter tuning)\n     7. Feature Importance Evaluations","metadata":{}},{"cell_type":"code","source":"#load data\ndf_job=pd.read_csv('/kaggle/input/real-or-fake-fake-jobposting-prediction/fake_job_postings.csv')\ndf_job.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Data Conversation - Handling Missing Date {Sample Imputer}","metadata":{}},{"cell_type":"code","source":"# Calculating NUll data\ndf_job.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reviewing data structure\ndf_job.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filling the Categorical values with 'missing'\ndata_cat_imp=SimpleImputer(strategy=\"constant\",fill_value=\"Missing\")\ncat_imp_feature=[\"title\",\"location\",\"department\",\"salary_range\",\"company_profile\",\"description\",\"requirements\",\"benefits\",\n                 \"employment_type\",\"required_experience\",\"required_education\",\"industry\",\"function\"]\n\n# Filling the Numerical values through existing value\ndata_num_imp=SimpleImputer(strategy=\"constant\",fill_value=None)\nnum_imp_feature =[\"job_id\",\"telecommuting\",\"has_company_logo\",\"has_questions\",\"fraudulent\"]\n\n# Transforming into column\ndata_imp_trans=ColumnTransformer([(\"data_cat_imp\",data_cat_imp,cat_imp_feature),\n                                 (\"data_num_imp\",data_num_imp,num_imp_feature)])\n\n# Transforming and assigning the data\ntransformed_data=data_imp_trans.fit_transform(df_job)\ntransformed_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Transforming the data into data frame\ndf_job_transformed_data=pd.DataFrame(transformed_data,\n                         columns=[\"title\",\"location\",\"department\",\"salary_range\",\"company_profile\",\"description\",\n                                  \"requirements\",\"benefits\", \"employment_type\",\"required_experience\",\"required_education\",\n                                  \"industry\",\"function\",\"job_id\",\"telecommuting\",\"has_company_logo\",\"has_questions\",\n                                  \"fraudulent\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#viewing transformed data\ndf_job_transformed_data.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# verify the NaN/missing values\ndf_job_transformed_data.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reviewing the columns\ndf_job_transformed_data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#random seed\nnp.random.seed(42)\n\n#data split into feature(X) and label(y)\nX_trans = df_job_transformed_data.drop(\"fraudulent\",axis=1)\ny_trans = df_job_transformed_data.fraudulent\ny_trans=y_trans.astype('int')\n\n#shape(row,column) of features and label\nX_trans.shape, y_trans.shape,X_trans.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Conversation - Encode Categorical Data {OneHotEncoder}Â¶","metadata":{}},{"cell_type":"code","source":"# Instantation of One Hot Encoder for categorical data tarnsformatio into Numeric \none_hot=OneHotEncoder()\nclf_trans=ColumnTransformer([(\"one_hot\",one_hot,cat_imp_feature)],remainder=\"passthrough\")\nX_trans_fin=clf_trans.fit_transform(X_trans)\nnp.array(X_trans_fin)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#splitting the data into train and test with 23% reserved for testing and 77% for training\nX_train,X_test,y_train,y_test=train_test_split(X_trans_fin,y_trans,test_size=0.23, random_state=42)\nX_train.shape,X_test.shape,y_train.shape,y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Selecting right Estimator or Aglorithm - Applying Classification Models","metadata":{}},{"cell_type":"code","source":"#Lets fit the model\nnp.random.seed(42)\n\n#Applying Random Forest Classifier Model\nmodel_rfm=RandomForestClassifier()\n\n#fitting the data into model\nmodel_rfm.fit(X_train,y_train,sample_weight=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scoring the Random Forest Classifier Model\nprint(f\"Fake Job Random Forest Model Accuracy : {model_rfm.score(X_test,y_test)*100:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting label data through Random Forest Classifier Model\ny_pred_rfm=model_rfm.predict(X_test)\ny_pred_rfm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Applying Logistic Regression Classification Algorithm\nmodel_lrm=LogisticRegression(solver='liblinear')\n\n#fitting the data into model\nmodel_lrm.fit(X_train,y_train,sample_weight=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scoring the Logistic Regression Model\nprint(f\"Fake Job Logistic Regression Model Accuracy :{model_lrm.score(X_test,y_test)*100:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting label data through Random Forest Classifier Model\ny_pred_lrm=model_lrm.predict(X_test)\ny_pred_lrm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_lrm.get_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Applying Metrics\n    * To quantifying the quality of predictions\n    * score measures how many labels the model got right out of the total number of predictions","metadata":{}},{"cell_type":"code","source":"#accuracy metrics of Random forest\nprint(f\"Accuracy Score ~ :{accuracy_score(y_test,y_pred_rfm)*100:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#precision score of Random forest\nprint(f\"Precision Score~ :{precision_score(y_test,y_pred_rfm)*100:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#classification report\nprint(classification_report(y_test,y_pred_rfm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix - It's compare to the label model predict and the actual label it suppossed to predict, \n# its offer an ideal where the model is getting confused.\nrfm_data=confusion_matrix(y_test,y_pred_rfm)\nsns.set(font_scale=1)\nsns.heatmap(rfm_data, center=0,annot=True,cmap=\"YlGnBu\");\nplt.xlabel(\"Actual Label\")\nplt.ylabel(\"Predicted Label\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{}},{"cell_type":"code","source":"#accuracy metrics of logistic\nprint(f\"Accuracy Score ~ :{accuracy_score(y_test,y_pred_lrm)*100:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#precision score of logistic\nprint(f\"Precision Score~ :{precision_score(y_test,y_pred_lrm)*100:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#classification report\nprint(classification_report(y_test,y_pred_lrm))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix - It's compare to the label model predict and the actual label it suppossed to predict, \n# its offer an ideal where the model is getting confused.\nlrm_data=confusion_matrix(y_test,y_pred_lrm)\nsns.set(font_scale=1)\nsns.heatmap(lrm_data, center=0,annot=True,cmap=\"YlOrBr\");\nplt.xlabel(\"Actual Label\")\nplt.ylabel(\"Predicted Label\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Turnning Hyperparameters ~ LogisticRegression()\n *  The model needs to be tuned as ~91% corrected predicted values needs improvement\n *  RandomizedSearchCV can sample a given number of candidates from a parameter space with a specified distribution","metadata":{}},{"cell_type":"code","source":"# optimal parameters using LogisticRegression() for classification\nrandom_grid = {\"C\": np.logspace(-4,4,20),\n               \"solver\" : [\"liblinear\"]\n               }\n\n#displaying the random grid parameters for the estimator ~ Logistic Regression\nrandom_grid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Use the random grid to search for optomised hyperparameters for LogisticRegression()\nrf = LogisticRegression()\n\n# Random search of parameters, using 3 fold cross validation,and search across 2 different combinations\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n                               n_iter = 10, cv = 3, verbose=True)\n\n# Fitting the RandomizedSearchCV model\nrf_random.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Optimised parameters\nrf_random.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fitting the LogisticRegression() model with optimsed parameters\nmodel_lrm_ideal=LogisticRegression(C=545.5594781168514,\n                                   solver='liblinear',\n                                    verbose=True)\n#fitting the model\nmodel_lrm_ideal.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scoring the ideal LogisticRegression() Model\nmodel_lrm_ideal.score(X_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting data through LogisticRegression() Model\ny_pred_lrm_ideal=model_lrm_ideal.predict(X_test)\ny_pred_lrm_ideal","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#accuracy score of post optimization of LogisticRegression() Model\nprint(f\"Accuracy Score~ :{accuracy_score(y_test,y_pred_lrm_ideal)*100:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Comparing Actual vs Predicted Fraudlent result","metadata":{}},{"cell_type":"code","source":"# formatting in the desired format\ndf_job_pred=pd.DataFrame()\ndf_job_pred[\"Actual Fraudulent\"]=y_test\ndf_job_pred[\"Predicted Fraudulent\"]=y_pred_rfm\ndf_job_pred.to_csv(\"/kaggle/working/predict.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importance Evaluations\n*Feature importance to assign a score to input features based on how useful they are in prediction.","metadata":{}},{"cell_type":"code","source":"#creating dictory to map the column with optimal feature rating\nfeature_dict=dict(zip((df_job.columns),list(model_rfm.feature_importances_)))\nfeature_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visulaization of Important features\nfeature_df=pd.DataFrame(feature_dict,index=[0])\nfeature_df.T.plot.line(title=\"EmploymentScamAegean Dataset - Feature Importance\",legend=False,color='orange');","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}