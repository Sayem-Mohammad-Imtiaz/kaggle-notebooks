{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nMain file for training Yolo model on Pascal VOC dataset\n\"\"\"\n\nimport torch\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport torchvision.transforms.functional as FT\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\nfrom model import Yolov1\nfrom dataset import VOCDataset\nfrom utils import (\n    non_max_suppression,\n    mean_average_precision,\n    intersection_over_union,\n    cellboxes_to_boxes,\n    get_bboxes,\n    plot_image,\n    save_checkpoint,\n    load_checkpoint,\n)\nfrom loss import YoloLoss\n\nseed = 123\ntorch.manual_seed(seed)\n\n# Hyperparameters etc. \nLEARNING_RATE = 2e-5\nDEVICE = \"cuda\" if torch.cuda.is_available else \"cpu\"\nBATCH_SIZE = 16 # 64 in original paper but I don't have that much vram, grad accum?\nWEIGHT_DECAY = 0\nEPOCHS = 1000\nNUM_WORKERS = 2\nPIN_MEMORY = True\nLOAD_MODEL = False\nLOAD_MODEL_FILE = \"overfit.pth.tar\"\nIMG_DIR = \"data/images\"\nLABEL_DIR = \"data/labels\"\n\n\nclass Compose(object):\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, img, bboxes):\n        for t in self.transforms:\n            img, bboxes = t(img), bboxes\n\n        return img, bboxes\n\n\ntransform = Compose([transforms.Resize((448, 448)), transforms.ToTensor(),])\n\n\ndef train_fn(train_loader, model, optimizer, loss_fn):\n    loop = tqdm(train_loader, leave=True)\n    mean_loss = []\n\n    for batch_idx, (x, y) in enumerate(loop):\n        x, y = x.to(DEVICE), y.to(DEVICE)\n        out = model(x)\n        loss = loss_fn(out, y)\n        mean_loss.append(loss.item())\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # update progress bar\n        loop.set_postfix(loss=loss.item())\n\n    print(f\"Mean loss was {sum(mean_loss)/len(mean_loss)}\")\n\n\ndef main():\n    model = Yolov1(split_size=7, num_boxes=2, num_classes=20).to(DEVICE)\n    optimizer = optim.Adam(\n        model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n    )\n    loss_fn = YoloLoss()\n\n    if LOAD_MODEL:\n        load_checkpoint(torch.load(LOAD_MODEL_FILE), model, optimizer)\n\n    train_dataset = VOCDataset(\n        \"data/100examples.csv\",\n        transform=transform,\n        img_dir=IMG_DIR,\n        label_dir=LABEL_DIR,\n    )\n\n    test_dataset = VOCDataset(\n        \"data/test.csv\", transform=transform, img_dir=IMG_DIR, label_dir=LABEL_DIR,\n    )\n\n    train_loader = DataLoader(\n        dataset=train_dataset,\n        batch_size=BATCH_SIZE,\n        num_workers=NUM_WORKERS,\n        pin_memory=PIN_MEMORY,\n        shuffle=True,\n        drop_last=True,\n    )\n\n    test_loader = DataLoader(\n        dataset=test_dataset,\n        batch_size=BATCH_SIZE,\n        num_workers=NUM_WORKERS,\n        pin_memory=PIN_MEMORY,\n        shuffle=True,\n        drop_last=True,\n    )\n\n    for epoch in range(EPOCHS):\n        # for x, y in train_loader:\n        #    x = x.to(DEVICE)\n        #    for idx in range(8):\n        #        bboxes = cellboxes_to_boxes(model(x))\n        #        bboxes = non_max_suppression(bboxes[idx], iou_threshold=0.5, threshold=0.4, box_format=\"midpoint\")\n        #        plot_image(x[idx].permute(1,2,0).to(\"cpu\"), bboxes)\n\n        #    import sys\n        #    sys.exit()\n\n        pred_boxes, target_boxes = get_bboxes(\n            train_loader, model, iou_threshold=0.5, threshold=0.4\n        )\n\n        mean_avg_prec = mean_average_precision(\n            pred_boxes, target_boxes, iou_threshold=0.5, box_format=\"midpoint\"\n        )\n        print(f\"Train mAP: {mean_avg_prec}\")\n\n        #if mean_avg_prec > 0.9:\n        #    checkpoint = {\n        #        \"state_dict\": model.state_dict(),\n        #        \"optimizer\": optimizer.state_dict(),\n        #    }\n        #    save_checkpoint(checkpoint, filename=LOAD_MODEL_FILE)\n        #    import time\n        #    time.sleep(10)\n\n        train_fn(train_loader, model, optimizer, loss_fn)\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"6f72e6c5-ce0d-4dba-9ae1-d16431b2db05","_cell_guid":"2a08f791-e07f-461e-b585-4f81a7d4dbbc","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}