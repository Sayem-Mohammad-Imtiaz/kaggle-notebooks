{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\nimport spacy\nimport seaborn as sns\nfrom spacy.util import minibatch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = \"/kaggle/input/sms-spam-collection-dataset/spam.csv\"\ndata = pd.read_csv(data_path, encoding=\"ISO-8859-1\")\nprint(data.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(data_path, encoding=\"ISO-8859-1\")\nobservations = len(data.index)\nprint(f\"Size of Dataset: {observations}\\n\")\nprint(data['v1'].value_counts())\nprint()\nprint(data['v1'].value_counts() / len(data.index) * 100.0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.blank(\"en\")\n\ntext_cat = nlp.create_pipe(\n            \"textcat\",\n            config={\n                \"exclusive_classes\": True,\n                \"architecture\": \"bow\"})\n\nnlp.add_pipe(text_cat)\n\ntext_cat.add_label(\"ham\")\ntext_cat.add_label(\"spam\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(\n        data['v2'], data['v1'], test_size=0.33, random_state=7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_lables = [{'cats': {'ham': label == 'ham',\n                          'spam': label == 'spam'}} for label in y_train]\n\ntest_lables = [{'cats': {'ham': label == 'ham',\n                          'spam': label == 'spam'}} for label in y_test]\n\ntrain_data = list(zip(x_train, train_lables))\ntest_data = list(zip(x_test, train_lables))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, train_data, optimizer, batch_size, epochs=10):\n    losses = {}\n    random.seed(1)\n\n    for epoch in range(epochs):\n        random.shuffle(train_data)\n\n        batches = minibatch(train_data, size=batch_size)\n        for batch in batches:\n            \n            texts, labels = zip(*batch)\n\n            \n            model.update(texts, labels, sgd=optimizer, losses=losses)\n        print(\"Loss: {}\".format(losses['textcat']))\n\n    return losses['textcat']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = nlp.begin_training()\nbatch_size = 5\nepochs = 3\n\n\ntrain_model(nlp, train_data, optimizer, batch_size, epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data[0])\nsample_test = nlp(train_data[0][0])\nprint(sample_test.cats)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictions(model, texts):\n    \n    docs = [model.tokenizer(text) for text in texts]\n\n    \n    textcat = model.get_pipe('textcat')\n    scores, _ = textcat.predict(docs)\n\n    \n    predicted_labels = scores.argmax(axis=1)\n    predicted_class = [textcat.labels[label] for label in predicted_labels]\n\n    return predicted_class","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_predictions = get_predictions(nlp, x_train)\ntest_predictions = get_predictions(nlp, x_test)\n\ntrain_accuracy = accuracy_score(y_train, train_predictions)\ntest_accuracy = accuracy_score(y_test, test_predictions)\n\nprint(f\"Train accuracy: {train_accuracy}\")\nprint(f\"Test accuracy: {test_accuracy}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"TRAIN:\")\ncf_train_matrix = confusion_matrix(y_train, train_predictions)\nplt.figure(figsize=(10,8))\nsns.heatmap(cf_train_matrix, annot=True, fmt='d')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"TEST:\")\ncf_test_matrix = confusion_matrix(y_test, test_predictions)\nplt.figure(figsize=(10,8))\nsns.heatmap(cf_test_matrix, annot=True, fmt='d')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}