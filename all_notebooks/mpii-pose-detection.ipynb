{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**分析**\n\n导入库并定义使用 matplotlib 绘制数据的函数。 根据数据，并非所有绘图都会被绘制。","metadata":{}},{"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom scipy import io as spio\nfrom keras.layers import Dense\nimport matplotlib.image as mpimg\nfrom keras.layers import Dropout\nfrom keras.models import Sequential\nfrom sklearn.utils import class_weight\nfrom IPython.display import Image, display\n\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-06-14T09:21:59.102803Z","iopub.execute_input":"2021-06-14T09:21:59.103192Z","iopub.status.idle":"2021-06-14T09:21:59.109906Z","shell.execute_reply.started":"2021-06-14T09:21:59.103159Z","shell.execute_reply":"2021-06-14T09:21:59.108694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"当前版本的数据集有 1 个 csv 文件：","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames[0:10]:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T09:22:01.055448Z","iopub.execute_input":"2021-06-14T09:22:01.055772Z","iopub.status.idle":"2021-06-14T09:22:21.475173Z","shell.execute_reply.started":"2021-06-14T09:22:01.05574Z","shell.execute_reply":"2021-06-14T09:22:21.474067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, dimentions = os.listdir('../input/mpii-dataset-for-python/dataset/images'), 1\nplt.subplots(figsize=(35,25))\nnumber=0\nfor i in range(3):\n    for image in images:\n        if dimentions == 15:\n            break\n        number += 1\n        cur_img = mpimg.imread(\"../input/mpii-dataset-for-python/dataset/images/\"+image)\n        ax = plt.subplot(1, 15, dimentions)\n        ax.set_xticks([]), ax.set_yticks([])\n        plt.imshow(cur_img)\n        dimentions += 1","metadata":{"execution":{"iopub.status.busy":"2021-06-14T09:22:21.476769Z","iopub.execute_input":"2021-06-14T09:22:21.47741Z","iopub.status.idle":"2021-06-14T09:22:24.231007Z","shell.execute_reply.started":"2021-06-14T09:22:21.47736Z","shell.execute_reply":"2021-06-14T09:22:24.228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"准备好读入数据并使用绘图函数来可视化数据。\n\n检查文件/kaggle/input/dataset/mpii_dataset.csv","metadata":{}},{"cell_type":"code","source":"annots = spio.loadmat('../input/matfile/mpii_human_pose_v1_u12_1.mat')\n\nDF = pd.DataFrame(index=range(0,len(annots['RELEASE'][0][0][0][0])),columns=['Image','Category','Activity'])\nDF.dataframeName = 'mpii_human_pose_v1_u12_1.mat'\n\nfor i in range(0,len(annots['RELEASE'][0][0][0][0])):\n    DF.loc[[i,0],'Image'] = annots[\"RELEASE\"][\"annolist\"][0,0][0][i]['image']['name'][0, 0][0]\n    try: DF.loc[[i,1],'Category'] = annots[\"RELEASE\"][\"act\"][0,0][:,0][i][\"cat_name\"][0]\n    except Exception: pass\n    try: DF.loc[[i,2],'Activity'] = annots[\"RELEASE\"][\"act\"][0,0][:,0][i][\"act_name\"][0]\n    except Exception: pass\n    DF.loc[[i,3],'Train'] = annots[\"RELEASE\"][\"img_train\"][0,0][0][i]\nDF.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T09:22:30.943464Z","iopub.execute_input":"2021-06-14T09:22:30.943779Z","iopub.status.idle":"2021-06-14T09:23:44.912721Z","shell.execute_reply.started":"2021-06-14T09:22:30.943749Z","shell.execute_reply":"2021-06-14T09:23:44.911674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"定义了绘制数据的函数。","metadata":{}},{"cell_type":"code","source":"# Distribution graphs (histogram/bar graph) of column data\n# 列数据的分布图（直方图/条形图）\nfrequencies = DF['Category'].value_counts().sort_index().values\nfreq_series = pd.Series(frequencies)\ny_labels = DF['Category'].value_counts().sort_index().index\nplt.figure(1, figsize = (15,8))\nax = freq_series.plot(kind='barh', color=(0.2, 0.4, 0.6, 0.6), width=0.9)\nax.set_title('Categories Distribution in Data')\nax.set_xlabel('Images per Class')\nax.set_ylabel('Classes')\nax.set_yticklabels(y_labels)\nrects = ax.patches\n\nfor rect in rects:\n    x_value = rect.get_width()\n    y_value = rect.get_y() + rect.get_height() / 2\n    space = 5\n    ha = 'left'\n    label = \"{:.4f}\".format(x_value/18000)\n    plt.annotate(label, (x_value, y_value), xytext=(space, 0), textcoords=\"offset points\", va='center', ha=ha) ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T09:23:51.915088Z","iopub.execute_input":"2021-06-14T09:23:51.91542Z","iopub.status.idle":"2021-06-14T09:23:52.315493Z","shell.execute_reply.started":"2021-06-14T09:23:51.915389Z","shell.execute_reply":"2021-06-14T09:23:52.314657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation matrix\n# 相关矩阵\ndef plotCorrelationMatrix(df, graphWidth):\n    filename = df.dataframeName\n    df = df.dropna('columns') # drop columns with NaN\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    if df.shape[1] < 2:\n        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n        return\n    corr = df.corr()\n    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n    corrMat = plt.matshow(corr, fignum = 1)\n    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n    plt.yticks(range(len(corr.columns)), corr.columns)\n    plt.gca().xaxis.tick_bottom()\n    plt.colorbar(corrMat)\n    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n    plt.show()\n\n    \n# plotCorrelationMatrix(DF, 8)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T09:23:55.060928Z","iopub.execute_input":"2021-06-14T09:23:55.061288Z","iopub.status.idle":"2021-06-14T09:23:55.069038Z","shell.execute_reply.started":"2021-06-14T09:23:55.061257Z","shell.execute_reply":"2021-06-14T09:23:55.067833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Cat_DF = pd.DataFrame(DF['Category'].value_counts(), columns=['index', 'Category']).sort_index()\nAct_DF = pd.DataFrame(DF['Activity'].value_counts(), columns=['index', 'Activity']).sort_index()\n\nplt.figure(1, figsize = (18,8)) \nplt.subplot(221)  \nplt.bar(Cat_DF.index, Cat_DF.Category, color=(0.2, 0.4, 0.6, 0.6))\nplt.xticks([])\nplt.title('Categories Distribution in Data')  \nplt.xlabel(str(len(DF['Category'].value_counts())) + ' Categories Found in Data')\nplt.ylabel('Images per Class')\n    \nplt.subplot(222)  \nplt.bar(Act_DF.index, Act_DF.Activity, color=(0.2, 0.4, 0.6, 0.6))\nplt.xticks([])\nplt.title('Activities Distribution in Data')  \nplt.xlabel(str(len(DF['Activity'].value_counts())) + ' Activities Found in Data')\nplt.ylabel('Images per Class')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T09:24:01.097557Z","iopub.execute_input":"2021-06-14T09:24:01.097884Z","iopub.status.idle":"2021-06-14T09:24:02.172385Z","shell.execute_reply.started":"2021-06-14T09:24:01.097846Z","shell.execute_reply":"2021-06-14T09:24:02.171512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL VGG16\n\n","metadata":{}},{"cell_type":"markdown","source":"构建训练集、验证集图像数据生成器","metadata":{}},{"cell_type":"code","source":"# from keras.preprocessing.image import ImageDataGenerator\n# from keras.callbacks import ModelCheckpoint\n\n# Train_DF, Test_DF = DF[DF['Train'] == 1].dropna(), DF[DF['Train'] == 0]\n# Train_DF = Train_DF.sample(frac=1).reset_index(drop=True)\n\n# datagen = ImageDataGenerator(rescale=1./255,\n#                              validation_split=0.2)\n\n# Training   = datagen.flow_from_dataframe(dataframe = Train_DF, \n#                                          directory=\"../input/mpii-dataset-for-python/dataset/images\", \n#                                          x_col=\"Image\", \n#                                          y_col=\"Category\", \n#                                          subset=\"training\",\n#                                          batch_size=50, \n#                                          class_mode=\"sparse\", \n#                                          target_size=(224,224))\n\n# Validation = datagen.flow_from_dataframe(dataframe = Train_DF, \n#                                          directory=\"../input/mpii-dataset-for-python/dataset/images\", \n#                                          x_col=\"Image\", \n#                                          y_col=\"Category\", \n#                                          subset=\"validation\", \n#                                          batch_size=50, \n#                                          class_mode=\"sparse\", \n#                                          target_size=(224,224))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T10:43:37.18666Z","iopub.execute_input":"2021-06-07T10:43:37.186996Z","iopub.status.idle":"2021-06-07T10:43:40.937018Z","shell.execute_reply.started":"2021-06-07T10:43:37.186968Z","shell.execute_reply":"2021-06-07T10:43:40.936155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A1 [10 Epochs][50 Batch][Shuffling][-10][+layers] - Training & Validation: [93][73]","metadata":{}},{"cell_type":"code","source":"# from tensorflow.keras.applications.vgg16 import VGG16\n# from tensorflow.keras.optimizers import Adam\n\n# vgg16 = VGG16(include_top = False, weights='imagenet', pooling='avg', classes=20)\n# model_vgg = Sequential()\n# model_vgg.add(vgg16)\n# model_vgg.add(keras.layers.Flatten())\n# model_vgg.add(Dense(512, activation='relu'))\n# model_vgg.add(Dropout(0.5))\n# model_vgg.add(Dense(20, activation = 'softmax'))\n\n# for layer in vgg16.layers[:-10]:\n#         layer.trainable = False\n\n# adam = Adam(lr=0.0001)\n# model_vgg.compile(optimizer = adam, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n# cb_checkpointer_vgg = ModelCheckpoint(filepath = 'best_vgg.h5', monitor = 'val_loss', save_best_only = True)\n# fit_history = model_vgg.fit(Training, epochs = 10, validation_data=Validation, callbacks=[cb_checkpointer_vgg])","metadata":{"execution":{"iopub.status.busy":"2021-06-07T10:44:20.366797Z","iopub.execute_input":"2021-06-07T10:44:20.367154Z","iopub.status.idle":"2021-06-07T16:10:45.934954Z","shell.execute_reply.started":"2021-06-07T10:44:20.367124Z","shell.execute_reply":"2021-06-07T16:10:45.932102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.figure(1, figsize = (15,8)) \n      \n# plt.subplot(221)  \n# plt.plot(fit_history.history['accuracy'])  \n# plt.plot(fit_history.history['val_accuracy'])  \n# plt.title('model accuracy')  \n# plt.ylabel('accuracy')  \n# plt.xlabel('epoch')  \n# plt.legend(['train', 'val']) \n    \n# plt.subplot(222)  \n# plt.plot(fit_history.history['loss'])  \n# plt.plot(fit_history.history['val_loss'])  \n# plt.title('model loss')  \n# plt.ylabel('loss')  \n# plt.xlabel('epoch')  \n# plt.legend(['train', 'val']) \n\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T05:08:15.192323Z","iopub.execute_input":"2021-06-08T05:08:15.192648Z","iopub.status.idle":"2021-06-08T05:08:15.256819Z","shell.execute_reply.started":"2021-06-08T05:08:15.192574Z","shell.execute_reply":"2021-06-08T05:08:15.255361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL Xception\n","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\n\nTrain_DF, Test_DF = DF[DF['Train'] == 1].dropna(), DF[DF['Train'] == 0]\nTrain_DF = Train_DF.sample(frac=1).reset_index(drop=True)\n\ndatagen = ImageDataGenerator(rescale=1./255,\n                             validation_split=0.10)\n\n\nTraining   = datagen.flow_from_dataframe(dataframe = Train_DF,\n                                         directory=\"../input/mpii-dataset-for-python/dataset/images\",\n                                         x_col=\"Image\",\n                                         y_col=\"Category\",\n                                         subset=\"training\",\n                                         batch_size=100,\n                                         class_mode=\"sparse\",\n                                         target_size=(299,299))\n\n\nValidation = datagen.flow_from_dataframe(dataframe = Train_DF,\n                                         directory=\"../input/mpii-dataset-for-python/dataset/images\",\n                                         x_col=\"Image\",\n                                         y_col=\"Category\",\n                                         subset=\"validation\",\n                                         batch_size=100,\n                                         class_mode=\"sparse\",\n                                         target_size=(299,299))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T09:24:07.098264Z","iopub.execute_input":"2021-06-14T09:24:07.0986Z","iopub.status.idle":"2021-06-14T09:24:13.102569Z","shell.execute_reply.started":"2021-06-14T09:24:07.098569Z","shell.execute_reply":"2021-06-14T09:24:13.101652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xception = keras.applications.xception.Xception(include_top=False, weights='imagenet', pooling='avg', classes=20)\nFlatten  = keras.layers.Flatten()\nOutput  = keras.layers.Dense(20, activation=\"softmax\")\n\nfor layer in Xception.layers[:-47]:\n    layer.trainable = False\n\nXModelxx = tf.keras.Sequential([ Xception, Flatten, Output])\n\nXModelxx.compile(optimizer='adam',\n                 loss='sparse_categorical_crossentropy',\n                 metrics=['accuracy'])\n\ncallback = keras.callbacks.EarlyStopping(patience=10,\n                                         restore_best_weights=True)\n\nhistory = XModelxx.fit(Training,\n                       epochs=30,\n                       callbacks=[callback],\n                       validation_data=Validation)\n\nXModelxx.save(\"XModelxx.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-06-14T09:24:29.26041Z","iopub.execute_input":"2021-06-14T09:24:29.260733Z","iopub.status.idle":"2021-06-14T09:42:05.949109Z","shell.execute_reply.started":"2021-06-14T09:24:29.2607Z","shell.execute_reply":"2021-06-14T09:42:05.948157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(history.history)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T09:42:46.403779Z","iopub.execute_input":"2021-06-14T09:42:46.404153Z","iopub.status.idle":"2021-06-14T09:42:46.411299Z","shell.execute_reply.started":"2021-06-14T09:42:46.404118Z","shell.execute_reply":"2021-06-14T09:42:46.410299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(1, figsize = (15,8)) \n      \nplt.subplot(221)  \nplt.plot(history.history['accuracy'])  \nplt.plot(history.history['val_accuracy'])  \nplt.title('model accuracy')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'val']) \n    \nplt.subplot(222)  \nplt.plot(history.history['loss'])  \nplt.plot(history.history['val_loss'])  \nplt.title('model loss')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'val']) \n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T09:43:33.776321Z","iopub.execute_input":"2021-06-14T09:43:33.77665Z","iopub.status.idle":"2021-06-14T09:43:34.034881Z","shell.execute_reply.started":"2021-06-14T09:43:33.77662Z","shell.execute_reply":"2021-06-14T09:43:34.033937Z"},"trusted":true},"execution_count":null,"outputs":[]}]}