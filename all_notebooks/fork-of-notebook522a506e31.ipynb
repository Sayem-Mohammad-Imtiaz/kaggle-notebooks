{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"1388bc6c-128c-44b9-f7c9-82a97106ea7d"},"source":"This is my first kernel !\nTentative for basic data graphical exploration"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ee5eda6e-eda2-89ac-23a4-b448282f91ca"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Load the file\ndf = pd.read_csv('../input/HPI_master.csv')\n\n# Describe dataset and basic statistcs\n#print(df.head())\n#print(df.tail())\nprint(\"===================================================================\")\n\nprint(\"Dataframe size:\\n\", df.count())\n\nprint(\"===================================================================\")\n\n\nfor x in df.columns:\n    print(x,df[x].unique())\n\nprint(\"===================================================================\")\nprint(df.describe())"},{"cell_type":"markdown","metadata":{"_cell_guid":"511cec73-6873-129a-0061-6a0e2d07abb4"},"source":"Now we are starting to look graphically at the data we have"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1630d908-f0e1-d5cc-958e-b712603e84b3"},"outputs":[],"source":"import matplotlib.pyplot as plt\n\nplt.style.use('ggplot')\n#%matplotlib inline\n\nfig, ax = plt.subplots(figsize=(6,4))\nax.hist(df['yr'], color='black')\nax.set_ylabel('Count per Year', fontsize=16)\nax.set_xlabel('Year', fontsize=16)\nplt.title('Number of points per year', fontsize=18, y=1.01)"},{"cell_type":"markdown","metadata":{"_cell_guid":"dcee8531-a27b-ee2c-e5bf-447a7cb24654"},"source":"Let's plot price evolution per year"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"34c49534-212a-b3c4-b006-b45c19936882"},"outputs":[],"source":"fig, ax = plt.subplots(figsize=(6,6))\nax.scatter(df['yr'], df['index_nsa'], color='green')\nax.set_xlabel('Year', fontsize=16)\nax.set_ylabel('Price index', fontsize=16)\nplt.title('Price index evolution over year', fontsize=18, y=1.01)"},{"cell_type":"markdown","metadata":{"_cell_guid":"597eaaab-952f-b0e2-ac38-030ad3eba0bf"},"source":"Ok, so now, this is clear based on the 2 graphs that:\n -  all cities does not have same price history\n - there is some variation in the price with high and low peaks\n\nLet's extract for each place the number of distinct year covered"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d9e65b6e-3421-c640-9820-5f82a7f1c19d"},"outputs":[],"source":"pd.pivot_table(df,index=[\"place_name\"],values=[\"yr\"],aggfunc=lambda x: len(x.unique())).sort_values(\"yr\",ascending=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c596a2f4-1bcd-3b6c-4fbb-d5bde42aacf6"},"outputs":[],"source":"df.query('place_name == [\"Florida\"] and hpi_flavor == [\"all-transactions\"] and yr == 1975')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"74e781c6-3ecb-c431-b48c-463626fbfb13"},"outputs":[],"source":"import datetime as dt\ndf_Florida = df.query('place_name == [\"Florida\"] and hpi_flavor == [\"all-transactions\"] and hpi_type == [\"traditional\"]')\ndf_Florida['date_intermediate'] = df_Florida['yr'].map(str) + \"-\" + df_Florida['period'].apply(lambda x: 1+3*(x - 1)).map(str)\ndf_Florida['date'] = df_Florida['date_intermediate'].apply(lambda x: pd.to_datetime(x, format='%Y-%m'))\ndel df_Florida['date_intermediate']\ndf_Florida.sort_values('date')\n#df_Florida['internal_id'] = range(1, len(df_Florida) + 1)\ndf_Florida = df_Florida.reset_index()\ndf_Florida['internal_id'] = df_Florida.index\ndf_Florida.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ccecb7a9-9825-3c7c-900f-ef8f9aa3c68e"},"outputs":[],"source":"plt.plot_date(df_Florida['date'], df_Florida['index_nsa'], xdate=True, ydate=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"d96041a3-2c60-47f3-0dda-678ce3a241c6"},"source":"We see in this graph that there are 4 periods:\n\n - a first period with linear price increase\n - a huge increase like a bubble\n - followed by a crash\n - then a restart of a linear increase but mich steaper than during teh first period of stability\nLet's detect automatically these intervals"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"47dda55a-8cae-4088-fbcb-ce70f3f6ea47"},"outputs":[],"source":"fig, ax1 = plt.subplots()\nax1.plot(df_Florida['index_nsa'], color='r')\nax1.set_xlabel('periods')\nax1.set_ylabel('index_nsa')\nax1.tick_params('y', colors='r')\n\nimport numpy\nx = df_Florida['internal_id']\ny = df_Florida['index_nsa']\ndydx = numpy.diff(y) / numpy.diff(x)\ndf_Florida_Derivative = pd.DataFrame(dydx)\n\nax2 = ax1.twinx()\nax2.plot(df_Florida_Derivative, color='b')\nax2.set_ylabel('index_nsa derivative')\nax2.tick_params('y', colors='b')\n\nfig.tight_layout()"},{"cell_type":"markdown","metadata":{"_cell_guid":"a70fdd1f-e253-b670-b007-9fe899f99022"},"source":"Let's try to work on a method to smoothen derivative curve"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d9fc55d8-eaae-8dcc-c042-e14d8984007f"},"outputs":[],"source":"import numpy\nx = df_Florida['internal_id']\ny = df_Florida['index_nsa']\ndydx = numpy.diff(y) / numpy.diff(x)\ndf_Florida_Derivative = pd.DataFrame(dydx)\n\nfrom scipy.signal import savgol_filter\ndydx_smoothen = savgol_filter(dydx, 11, 1)\ndf_Florida_Derivative_smoothen = pd.DataFrame(dydx_smoothen)\n\ndf_Florida_Derivative_mean = [numpy.mean(dydx,0) for i in range(len(dydx))]\n\nfig, ax1 = plt.subplots()\nax1.plot(df_Florida_Derivative, color='r')\nax1.plot(df_Florida_Derivative_smoothen, color='b')\nax1.plot(df_Florida_Derivative_mean, color='g')\nax1.set_xlabel('periods')\nax1.set_ylabel('index_nsa derivative')\nax1.tick_params('y', colors='r')\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"a18f9a9b-a6f6-41dd-5355-66af3b1ae55d"},"source":"Now we have a pretty smoothed derivative, let's try to auto detect \"out of mean periods\" i.e. something like price bubble phenomenon or price crash"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7bc2cde6-7108-959f-466b-aaa16fb20fb7"},"outputs":[],"source":"distance_mean = [dydx_smoothen[i] - numpy.mean(dydx,0) for i in range(len(dydx))]\nthreshold = 4*numpy.mean(dydx,0)\nfor i in range(len(distance_mean)):\n    if distance_mean[i] < threshold and (i+1<len(distance_mean) and abs(distance_mean[i+1]) < threshold):\n        distance_mean[i] = 0\n\nflag=False\nstartIndex=0\nstopIndex=0\nPriceBubble=[]\nPriceCrash=[]\nfor i in range(len(distance_mean)):\n    if flag==False and distance_mean[i]!=0:\n        flag=True\n        startIndex=i\n    if flag==True and distance_mean[i]==0:\n        flag=False\n        stopIndex=i-1\n        if distance_mean[stopIndex] > 0:\n            PriceBubble.append([startIndex, stopIndex])\n        else:\n            PriceCrash.append([startIndex, stopIndex])\n\nprint(\"Price Bubble:\")\nfor i in range(len(PriceBubble)):\n    print(str(df_Florida['date'][PriceBubble[i][0]])+\"  /  \"+str(df_Florida['date'][PriceBubble[i][1]]))\nprint(\"\\n\")\nprint(\"Price Crash:\")\nfor i in range(len(PriceCrash)):\n    print(str(df_Florida['date'][PriceCrash[i][0]])+\"  /  \"+str(df_Florida['date'][PriceCrash[i][1]]))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}