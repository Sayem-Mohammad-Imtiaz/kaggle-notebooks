{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Avatar : The Last Airbender - EDA\n\nThis notebook analyses all transcipts downloaded via the scrape_episode_urls.py script. \n\nNote on the vocabulary used: A \"Book\" is equivalent to a season. An \"utterance\" or \"line\" is one or more sentences spoken by the same character; one line in the CSV files will correspond to one utterance.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install spacy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!python -m spacy download en_core_web_sm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!python -m spacy validate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#all necessary imports\nimport spacy\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom collections import defaultdict\nimport glob\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = glob.glob('../input/avatar-the-last-airbender-transcripts-subtitles/*.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_book_number(item):\n    m = re.search(\"_(\\d)_(\\d*).*\\.csv\",item)\n    return int(m.string[m.start(1):m.end(1)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_eisode_number(item):\n    m = re.search(\"_(\\d)_(\\d*).*\\.csv\",item)\n    return int(m.string[m.start(2):m.end(2)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files.sort(key=get_eisode_number)\nfiles.sort(key=get_book_number)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_list = []\nfor f in files:\n    df = pd.read_csv(f, sep=\",\", header=None, names=[\"Character\", \"Utterance\"])\n    episode_number = get_eisode_number(f)\n    book_number = get_book_number(f)\n    df[\"Book\"] = book_number\n    df[\"Episode\"] = episode_number\n    df_list.append(df)\n    \ntranscripts = pd.concat(df_list, axis=0, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exploring the data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"There are 9912 total lines and 61 episodes split over 3 Books (seasons). ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"transcripts.sample(3, random_state=20)['Utterance'].to_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transcripts[['Book','Episode']].drop_duplicates().shape[0]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"transcripts.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.barplot(x=\"Book\", y=\"Utterance\", data=transcripts.groupby('Book').count().reset_index())\nax.set_title(\"Total number of lines per book\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_lines_per_person = transcripts.groupby(\"Character\").count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_15_characters_lines = total_lines_per_person.sort_values(by=\"Utterance\", ascending=False).head(15).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,4))\nax = sns.barplot(x=\"Character\", y=\"Utterance\", data=top_15_characters_lines)\nax.set_title(\"Top 15 characters with the most lines overall\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Unsurprisingly, it's the main trio (Aang, Sokka & Katara) that speak the most.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"top_15_characters = top_15_characters_lines['Character'].to_list()\ntotal_lines_per_book = transcripts.groupby([\"Character\", \"Book\"]).count().loc[top_15_characters].reindex(top_15_characters, level=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,4))\nax = sns.barplot(x=\"Character\", y=\"Utterance\", hue=\"Book\", data=total_lines_per_book.reset_index(), palette=\"rocket\")\nax.set_title(\"Number of lines per Book for the same top 15 characters\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using spacy's medium-sized English language model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_verbs_adj_noun(texts):\n    verb_count = defaultdict(int)\n    adj_count = defaultdict(int)\n    noun_count = defaultdict(int)\n\n    for line in texts:\n        doc = nlp(line)\n        for token in doc:\n            if token.is_stop:\n                continue\n            if token.pos_ == 'VERB':\n                verb_count[token.lemma_] += 1\n            elif token.pos_ == 'ADJ':\n                adj_count[token.lemma_] += 1\n            elif token.pos_ == 'NOUN':\n                noun_count[token.lemma_] += 1\n    return verb_count, adj_count, noun_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def top_10_tokens(tokens_dict):\n    return sorted(tokens_dict.items(), key=lambda kv: kv[1], reverse=True)[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"verb_count, adj_count, noun_count = count_verbs_adj_noun(transcripts['Utterance'].to_list())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_10_verbs = top_10_tokens(verb_count)\ntop_10_adjectives = top_10_tokens(adj_count)\ntop_10_nouns = top_10_tokens(noun_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 3, figsize=(26, 6))\naxes[0].bar([x[0] for x in top_10_verbs], [x[1] for x in top_10_verbs])\naxes[0].set_title(\"Top 10 verbs\")\naxes[1].bar([x[0] for x in top_10_adjectives], [x[1] for x in top_10_adjectives])\naxes[1].set_title(\"Top 10 adjectives\")\naxes[2].bar([x[0] for x in top_10_nouns], [x[1] for x in top_10_nouns])\naxes[2].set_title(\"Top 10 nouns\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zuko_lines = transcripts[transcripts[\"Character\"] == \"Zuko\"][\"Utterance\"].to_list()\nzuko_verb_count, zuko_adj_count, zuko_noun_count = count_verbs_adj_noun(zuko_lines)\nzuko_top_10_verbs = top_10_tokens(zuko_verb_count)\nzuko_top_10_adjectives = top_10_tokens(zuko_adj_count)\nzuko_top_10_nouns = top_10_tokens(zuko_noun_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 3, figsize=(26, 6))\naxes[0].bar([x[0] for x in zuko_top_10_verbs], [x[1] for x in zuko_top_10_verbs])\naxes[0].set_title(\"Top 10 verbs spoken by Zuko\")\naxes[1].bar([x[0] for x in zuko_top_10_adjectives], [x[1] for x in zuko_top_10_adjectives])\naxes[1].set_title(\"Top 10 adjectives spoken by Zuko\")\naxes[2].bar([x[0] for x in zuko_top_10_nouns], [x[1] for x in zuko_top_10_nouns])\naxes[2].set_title(\"Top 10 nouns spoken by Zuko\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's interesting to see that Zuko's most-used nouns include the words \"father\", \"uncle\" and \"honor\".","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_non_punct_tokens(text):\n    count = 0\n    doc = nlp(text)\n    for token in doc:\n        if not token.is_punct:\n            count += 1\n    return count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transcripts[\"Word_count\"] = transcripts[\"Utterance\"].apply(count_non_punct_tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"longest_lines = transcripts.sort_values(by=\"Word_count\", ascending=False).head(10).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nax = sns.barplot(x=longest_lines[\"Word_count\"], y=longest_lines.index, orient='h')\nax.set_xlabel(\"Word count\")\nax.set_title(\"10 longest lines\")\nax.set_yticklabels(longest_lines[\"Character\"].to_list())\nfor index, item in enumerate(longest_lines[\"Utterance\"].to_list()):\n    ax.text(3, index, item[:175 + (-index)*6] + \"...\", color='white')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}