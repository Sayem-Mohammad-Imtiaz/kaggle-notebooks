{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Abbreviation Disambiguation in Medical Texts - Data Modeling\n\nThis Notebook is in continuation of the notebook- 'Step 2- Data Preprocessing' and lists down:\n\n1. Modeling Preprocessed data using: GridSearchCV on Logistic Regression, SVM and XG Boost.\n2. Testing the models using Test set.\n3. Comparing the models and identifying the Next Steps"},{"metadata":{},"cell_type":"markdown","source":"## Step# 1: Loading Dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Importing the Required Python Packages\nimport shutil\nimport string\nimport numpy as np\nimport pandas as pd\nimport pickle\nfrom tqdm import tqdm\nimport ast\nfrom sklearn import utils\nfrom gensim.models import Doc2Vec\nfrom gensim.models.doc2vec import TaggedDocument\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import f1_score, accuracy_score, classification_report\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\npd.set_option('display.max_colwidth', None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Lets load the train dataset.\ntrain = pd.read_csv('Train/train_final.csv')\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Lets load validation and test datasets as well\nvalid = pd.read_csv('Validation/valid_final.csv')\ntest = pd.read_csv('Test/test_final.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"valid.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets keep only relevant records in Valid and test set."},{"metadata":{"trusted":false},"cell_type":"code","source":"    abbrev = list(train['ABV'].unique())\n    valid = valid[valid['ABV'].isin(abbrev)]\n    test = test[test['ABV'].isin(abbrev)]\n    labels = list(train['LABEL'].unique())\n    valid = valid[valid['LABEL'].isin(labels)]\n    test = test[test['LABEL'].isin(labels)]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets drop 'ABV' column"},{"metadata":{"trusted":false},"cell_type":"code","source":"train.drop(columns='ABV', inplace = True)\nvalid.drop(columns='ABV', inplace = True)\ntest.drop(columns='ABV', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Convert TOKEN column from string to list\ntrain['TOKEN'] = train['TOKEN'].apply(lambda x: ast.literal_eval(x))\nvalid['TOKEN'] = valid['TOKEN'].apply(lambda x: ast.literal_eval(x))\ntest['TOKEN'] = test['TOKEN'].apply(lambda x: ast.literal_eval(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets tag every Token List with its Label"},{"metadata":{"trusted":false},"cell_type":"code","source":"train_tagged = train.apply(lambda x: TaggedDocument(words = x['TOKEN'], tags = [x['LABEL']]), axis=1)\nvalid_tagged = valid.apply(lambda x: TaggedDocument(words = x['TOKEN'], tags = [x['LABEL']]), axis=1)\ntest_tagged = test.apply(lambda x: TaggedDocument(words = x['TOKEN'], tags = [x['LABEL']]), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_tagged.values[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step# 2: Apply Doc2vec vectorizer on the Dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"vectorize = Doc2Vec(dm=0, vector_size=100, min_count=2, window = 2)\nvectorize.build_vocab(train_tagged.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"vectorize.train(train_tagged.values, total_examples=len(train_tagged.values), epochs=30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building the Final Vector Feature Classifier"},{"metadata":{"trusted":false},"cell_type":"code","source":"def vec_for_learning(model, tagged_docs):\n    sents = tagged_docs.values\n    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=30)) for doc in sents])\n    return targets, regressors","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_train, X_train = vec_for_learning(vectorize, train_tagged)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model# 1: Logistic Classifier"},{"metadata":{},"cell_type":"markdown","source":"### Lets perform a Grid Search to get the best possible combination of Hyperparameters for Logistic Regression Model"},{"metadata":{"trusted":false},"cell_type":"code","source":"param_grid = {'C':[0.001, 0.01, 0.1, 1, 10, 100]}\ngrid_model = GridSearchCV(LogisticRegression(n_jobs=-1), param_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"### Best parameters for the Grid Search\ngrid_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"### Accuracy Score\ngrid_model.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Apply the best parameters to Logistic Regression and train the model."},{"metadata":{"trusted":false},"cell_type":"code","source":"logreg = LogisticRegression(n_jobs=-1, C=1)\nlogreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"### Apply the above Model on Validation Set\ny_valid, X_valid = vec_for_learning(vectorize, valid_tagged)\ny_pred_valid = logreg.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('Validation Accuracy:', accuracy_score(y_valid, y_pred_valid))\nprint('Validation F1-Score:', f1_score(y_valid, y_pred_valid, average='weighted'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As per the above analysis of validation set, it can be seen that the Logistic Classification model gives\n1. F1- Score of: 0.68\n2. Accuracy of: 69%\n\nHence, lets apply this model to our Test set and check its performance metrics."},{"metadata":{"trusted":false},"cell_type":"code","source":"### Apply the above Model on Test Set\ny_test, X_test = vec_for_learning(vectorize, test_tagged)\ny_pred_test = logreg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets calculate some Performance Metrics on the Test predictions."},{"metadata":{"trusted":false},"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_pred_test)\nf1_scr = f1_score(y_test, y_pred_test, average='weighted')\nprint('Test Accuracy:', accuracy)\nprint('Test F1-Score:', f1_scr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_unique = list(set(y_test))\ncr = classification_report(y_test, y_pred_test, target_names=y_unique)\nprint(cr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Thus, from the above Report it can be seen:\n1. Average Precision: 0.69\n2. Average Recall: 0.70"},{"metadata":{},"cell_type":"markdown","source":"## Model# 2: SVM"},{"metadata":{},"cell_type":"markdown","source":"### Lets perform a Grid Search to get the best possible combination of Hyperparameters for SVM's"},{"metadata":{"trusted":false},"cell_type":"code","source":"param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']}\ngrid_svm = GridSearchCV(SVC(), param_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"grid_svm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"### Best parameters for the Grid Search\ngrid_svm.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"### Accuracy Score\ngrid_svm.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Apply the best parameters to SVC and train the model"},{"metadata":{"trusted":false},"cell_type":"code","source":"svcModel = SVC(C=10, gamma=0.01, kernel='rbf')\nsvcModel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"### Apply the above Model on Validation Set\ny_valid, X_valid = vec_for_learning(vectorize, valid_tagged)\ny_pred_valid = svcModel.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('SVM Validation Accuracy:', accuracy_score(y_valid, y_pred_valid))\nprint('SVM Validation F1-Score:', f1_score(y_valid, y_pred_valid, average='weighted'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As per the above analysis of validation set, it can be seen that the SVC Classification model gives\n1. F1- Score of: 0.71\n2. Accuracy of: 70%\n\nHence, lets apply this model to our Test set and check its performance metrics."},{"metadata":{"trusted":false},"cell_type":"code","source":"### Apply the above Model on Test Set\ny_test, X_test = vec_for_learning(vectorize, test_tagged)\ny_pred_test = svcModel.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets calculate some Performance Metrics on the Test predictions."},{"metadata":{"trusted":false},"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_pred_test)\nf1_scr = f1_score(y_test, y_pred_test, average='weighted')\nprint('SVM Test Accuracy:', accuracy)\nprint('SVM Test F1-Score:', f1_scr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_unique = list(set(y_test))\ncr = classification_report(y_test, y_pred_test, target_names=y_unique)\nprint(cr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Thus, from the above Report it can be seen:\n1. Average Precision: 0.71\n2. Average Recall: 0.71"},{"metadata":{},"cell_type":"markdown","source":"## Model# 3: XGBoost"},{"metadata":{},"cell_type":"markdown","source":"### Lets create a parameter grid for XGBoost Model"},{"metadata":{"trusted":false},"cell_type":"code","source":"param_grid = {'n_estimators':[100, 500, 1000], 'max_depth':[5, 6, 7], 'min_child_weight': [3, 5, 8]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"unique = list(set(y_train))\nX_train = pd.DataFrame(X_train)\ny_train = np.asarray(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"XGBgrid = GridSearchCV(XGBClassifier(learning_rate= 0.1, gamma= 0, objective= 'multi:softmax', num_classes= len(unique), seed= 27), param_grid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"XGBgrid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"### Best parameters for the Grid Search\nXGBgrid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"### Accuracy Score\ngrid_svm.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train a XGBoost Classifier"},{"metadata":{"trusted":false},"cell_type":"code","source":"XGBModel = XGBClassifier(\n learning_rate =0.1,\n n_estimators=1000,\n max_depth=7,\n min_child_weight=4,\n gamma=0,\n objective= 'multi:softmax',\n seed=27)   \nXGBModel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"### Apply the above Model on Validation Set\ny_valid, X_valid = vec_for_learning(vectorize, valid_tagged)\nX_valid = pd.DataFrame(X_valid)\ny_valid = np.asarray(y_valid)\ny_pred_valid = XGBModel.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('XGBoost Validation Accuracy:', accuracy_score(y_valid, y_pred_valid))\nprint('XGBoost Validation F1-Score:', f1_score(y_valid, y_pred_valid, average='weighted'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As per the above analysis of validation set, it can be seen that the XGBoost Classification model gives\n1. F1- Score of: 0.58\n2. Accuracy of: 59.1%\n\nHence, lets apply this model to our Test set and check its performance metrics."},{"metadata":{"trusted":false},"cell_type":"code","source":"### Apply the above Model on Test Set\ny_test, X_test = vec_for_learning(vectorize, test_tagged)\nX_test = pd.DataFrame(X_test)\ny_test = np.asarray(y_test)\ny_pred_test = XGBModel.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets calculate some Performance Metrics on the Test predictions."},{"metadata":{"trusted":false},"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_pred_test)\nf1_scr = f1_score(y_test, y_pred_test, average='weighted')\nprint('XGBoost Test Accuracy:', accuracy)\nprint('XGBoost Test F1-Score:', f1_scr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_unique = list(set(y_test))\ncr = classification_report(y_test, y_pred_test, target_names=y_unique)\nprint(cr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Thus, from the above Report it can be seen:\n1. Average Precision: 0.59\n2. Average Recall: 0.59"},{"metadata":{},"cell_type":"markdown","source":"# Next Steps"},{"metadata":{},"cell_type":"markdown","source":"## We can see that a basic Logistic Classification implementation gives 70% Accurate results hence, for next steps we can:\n1. Try tuning the Doc2Vec vectorizer's Hyperparameters.\n2. Try some other Classification Algorithms like SVN, Random Forrest and compare results.\n3. Present model has been trained to disambiguate 20 'Medical Abbreviations' but this same model can be generalized to be used in other fields as well. Some including Scientific Researches and Internet Slags."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}