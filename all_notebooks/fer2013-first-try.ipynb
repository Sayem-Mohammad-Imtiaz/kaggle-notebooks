{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['image-labels', 'clahe-images', 'frontalized-images', 'fer2013', 'raw-images', 'new-train-raw']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Activation, Convolution2D, Dropout, Conv2D, Dense\nfrom keras.layers import AveragePooling2D, BatchNormalization\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.models import Sequential\nfrom keras.layers import Flatten\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import SeparableConv2D\nfrom keras import layers\nfrom keras.regularizers import l2\n\n# metric to balance precision and recall\ndef fbeta(y_true, y_pred, threshold_shift=0):\n    beta = 1\n\n    # just in case of hipster activation at the final layer\n    y_pred = K.clip(y_pred, 0, 1)\n\n    # shifting the prediction threshold from .5 if needed\n    y_pred_bin = K.round(y_pred + threshold_shift)\n\n    tp = K.sum(K.round(y_true * y_pred_bin), axis=1) + K.epsilon()\n    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)), axis=1)\n    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)), axis=1)\n\n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n\n    beta_squared = beta ** 2\n    return K.mean((beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon()))\n\ndef preprocess_input(x):\n    x = x.astype('float32')\n    x = x / 255.0\n    return x\n\ndef get_model2():\n    model = Sequential()\n\n    model.add(Convolution2D(64, (3, 3), padding='same', input_shape=(48, 48, 1)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n    model.add(Dropout(0.25))\n\n    model.add(Convolution2D(128, (5, 5), padding='same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n    model.add(Dropout(0.25))\n\n    model.add(Convolution2D(512, (3, 3), padding='same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n    model.add(Dropout(0.25))\n\n    model.add(Convolution2D(512, (3, 3), padding='same'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='same'))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n\n    model.add(Dense(256))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.25))\n\n    model.add(Dense(512))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.25))\n\n    model.add(Dense(7))\n    model.add(Activation('softmax'))\n\n    return model\n\ndef mini_XCEPTION(input_shape, num_classes, l2_regularization=0.01):\n    regularization = l2(l2_regularization)\n\n    # base\n    img_input = Input(input_shape)\n    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n               use_bias=False)(img_input)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n               use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    # module 1\n    residual = Conv2D(16, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = SeparableConv2D(16, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = SeparableConv2D(16, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n    x = layers.add([x, residual])\n\n    # module 2\n    residual = Conv2D(32, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = SeparableConv2D(32, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = SeparableConv2D(32, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n    x = layers.add([x, residual])\n\n    # module 3\n    residual = Conv2D(64, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = SeparableConv2D(64, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = SeparableConv2D(64, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n    x = layers.add([x, residual])\n\n    # module 4\n    residual = Conv2D(128, (1, 1), strides=(2, 2),\n                      padding='same', use_bias=False)(x)\n    residual = BatchNormalization()(residual)\n\n    x = SeparableConv2D(128, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = SeparableConv2D(128, (3, 3), padding='same',\n                        kernel_regularizer=regularization,\n                        use_bias=False)(x)\n    x = BatchNormalization()(x)\n\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n    x = layers.add([x, residual])\n\n    x = Conv2D(num_classes, (3, 3),\n               # kernel_regularizer=regularization,\n               padding='same')(x)\n    x = GlobalAveragePooling2D()(x)\n    output = Activation('softmax', name='predictions')(x)\n\n    model = Model(img_input, output)\n    return model","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport cv2\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\nimport seaborn as sns\nfrom math import sqrt\nimport scipy.io as io\nimport tensorflow as tf\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\n\nimport random as rnd\n\nfrom keras import backend as K\nfrom keras.utils import np_utils\nfrom keras.callbacks import CSVLogger\nfrom keras.models import load_model\nfrom keras.utils import np_utils as npu\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\n# some hyperparameters\nBATCH_SIZE = 64\nNUM_EPOCHS = 10000\n\nemotion_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\nnum_classes = len(emotion_labels)\n\n# loading the np arrays with image labels\n\n# print(os.listdir(\"../input\"))\n\ndata = np.load(\"../input/image-labels/Y_train.npz\")\ny_train = data['a']\n\ndata = np.load(\"../input/image-labels/Y_val.npz\")\ny_val = data['a']\n\ndata = np.load(\"../input/image-labels/Y_test.npz\")\ny_test = data['a']\n\n# loading the np arrays with frontalized images\ndata = np.load(\"../input/new-train-raw/X_train_raw.npz\")\nX_train_raw = data['a']\n\ndata = np.load(\"../input/raw-images/X_val_raw.npz\")\nX_val_raw = data['a']\n\ndata = np.load(\"../input/raw-images/X_test_raw.npz\")\nX_test_raw = data['a']\n\nnum_train = X_train_raw.shape[0]\nnum_validation = X_val_raw.shape[0]\nnum_test = X_test_raw.shape[0]\n\nprint(num_train)\nprint(num_validation)\nprint(num_test)\n\n# starting from the frontalized set\n# boosted sets\nX_train_boost_1 = X_train_raw.copy().astype(np.uint8)\ny_train_boost_1 = y_train.copy()\n\nX_train_boost_2 = X_train_raw.copy().astype(np.uint8)\ny_train_boost_2 = y_train.copy()\n\nX_train_boost_3 = X_train_raw.copy().astype(np.uint8)\ny_train_boost_3 = y_train.copy()\n\nX_train_boost_4 = X_train_raw.copy().astype(np.uint8)\ny_train_boost_4 = y_train.copy()\n\nX_train_boost_5 = X_train_raw.copy().astype(np.uint8)\ny_train_boost_5 = y_train.copy()\n\nX_train_boost_6 = X_train_raw.copy().astype(np.uint8)\ny_train_boost_6 = y_train.copy()\n\nX_train_boost_7 = X_train_raw.copy().astype(np.uint8)\ny_train_boost_7 = y_train.copy()\n\nX_train_boost_8 = X_train_raw.copy().astype(np.uint8)\ny_train_boost_8 = y_train.copy()\n\nX_train_boost_9 = X_train_raw.copy().astype(np.uint8)\ny_train_boost_9 = y_train.copy()\n\nX_train_boost_10 = X_train_raw.copy().astype(np.uint8)\ny_train_boost_10 = y_train.copy()\n\nfor x in range(0, X_train_raw.shape[0]):\n    idx = rnd.randint(0, X_train_raw.shape[0]-1)\n    X_train_boost_1[x] = X_train_raw[idx]\n    y_train_boost_1[x] = y_train[idx]\n\n#loading models\nbag_model_1 = mini_XCEPTION((48,48,1),7)\n#bag_model_2 = mini_XCEPTION((48,48,1),7)\n#bag_model_3 = mini_XCEPTION((48,48,1),7)\n#bag_model_4 = mini_XCEPTION((48,48,1),7)\n#bag_model_5 = mini_XCEPTION((48,48,1),7)\n#bag_model_6 = mini_XCEPTION((48,48,1),7)\n#bag_model_7 = mini_XCEPTION((48,48,1),7)\n#bag_model_8 = mini_XCEPTION((48,48,1),7)\n\n# augment and fit all datasets\ndatagen = ImageDataGenerator(\n  featurewise_center=False,\n  samplewise_center=False,\n  featurewise_std_normalization=False,\n  samplewise_std_normalization=False,\n  zca_whitening=False,\n  rotation_range=40,\n  width_shift_range=0.2,\n  height_shift_range=0.2,\n  shear_range=0,\n  zoom_range=0.1,\n  horizontal_flip=True,\n  vertical_flip=False)\ndatagen.fit(X_train_boost_1)\ndatagen.fit(X_val_raw)\n\n# to be applied during training\nreduce_lr = ReduceLROnPlateau(\n  monitor='val_loss', factor=0.1,\n  patience=int(50/4), verbose=0)\nearly_stop = EarlyStopping(\n  monitor='val_loss', min_delta=0, patience=50,\n  verbose=0, mode='auto')\n\n# compiling models\nbag_model_1.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=[fbeta, 'accuracy'])\n\n# Training\ntrain_flow_1 = datagen.flow(X_train_boost_1, y_train_boost_1, batch_size=BATCH_SIZE, shuffle=False)\n#train_flow_2 = datagen.flow(X_train_boost_2, y_train_boost_2, batch_size=BATCH_SIZE, shuffle=False)\n#train_flow_3 = datagen.flow(X_train_boost_3, y_train_boost_3, batch_size=BATCH_SIZE, shuffle=False)\n#train_flow_4 = datagen.flow(X_train_boost_4, y_train_boost_4, batch_size=BATCH_SIZE, shuffle=False)\n#train_flow_5 = datagen.flow(X_train_boost_5, y_train_boost_5, batch_size=BATCH_SIZE, shuffle=False)\n#train_flow_6 = datagen.flow(X_train_boost_6, y_train_boost_6, batch_size=BATCH_SIZE, shuffle=False)\n#train_flow_7 = datagen.flow(X_train_boost_7, y_train_boost_7, batch_size=BATCH_SIZE, shuffle=False)\n#train_flow_8 = datagen.flow(X_train_boost_8, y_train_boost_8, batch_size=BATCH_SIZE, shuffle=False)\n\nhistory1 = bag_model_1.fit_generator(\n    train_flow_1,\n    steps_per_epoch=num_train / BATCH_SIZE,\n    epochs=NUM_EPOCHS,\n    verbose=0,\n    validation_data=(X_val_raw,y_val),\n    validation_steps=num_validation / BATCH_SIZE,\n    callbacks=[reduce_lr, early_stop])\nbag_model_1.save('miniXCEPTION_raw.h5')\n\nX_validation = np.vstack((X_val_raw,X_test_raw))\ny_validation = np.vstack((y_val,y_test))\nnum_validation = num_validation*2\n\n# evaluate\nscore = bag_model_1.evaluate(X_validation, y_validation, steps=int(num_validation / BATCH_SIZE))\nprint('miniXCEPTION raw Evaluation Loss: ', score[0])\nprint('miniXCEPTION raw Evaluation Accuracy: ', score[1])\n\n# Print Model Stats\nprint('Training accuracy')\nprint(max(history1.history['acc']))\n#print(max(history2.history['acc']))\n#print(max(history3.history['acc']))\n#print(max(history4.history['acc']))\n#print(max(history5.history['acc']))\n#print(max(history6.history['acc']))\n#print(max(history7.history['acc']))\n#print(max(history8.history['acc']))\n\nprint('Validation accuracy')\nprint(max(history1.history['val_acc']))\n#print(max(history2.history['val_acc']))\n#print(max(history3.history['val_acc']))\n#print(max(history4.history['val_acc']))\n#print(max(history5.history['val_acc']))\n#print(max(history6.history['val_acc']))\n#print(max(history7.history['val_acc']))\n#print(max(history8.history['val_acc']))\n\nplt.figure()\nplt.plot(history1.history['acc'], color='C0', label='Training acc')\n#plt.plot(history2.history['acc'], color='C1', label='M2 Training acc')\n#plt.plot(history3.history['acc'], color='C2', label='M3 Training acc')\n#plt.plot(history4.history['acc'], color='C3', label='M4 Training acc')\n#plt.plot(history5.history['acc'], color='C4', label='M5 Training acc')\n#plt.plot(history6.history['acc'], color='C5', label='M6 Training acc')\n#plt.plot(history7.history['acc'], color='C6', label='M7 Training acc')\n#plt.plot(history8.history['acc'], color='C7', label='M8 Training acc')\nplt.title('one miniXCEPTION raw Training Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(loc='lower right')\nplt.show()\n\nplt.figure()\nplt.plot(history1.history['loss'], color='C0', label='Training loss')\n#plt.plot(history2.history['loss'], color='C1', label='M2 Training loss')\n#plt.plot(history3.history['loss'], color='C2', label='M3 Training loss')\n#plt.plot(history4.history['loss'], color='C3', label='M4 Training loss')\n#plt.plot(history5.history['loss'], color='C4', label='M5 Training loss')\n#plt.plot(history6.history['loss'], color='C5', label='M6 Training loss')\n#plt.plot(history7.history['loss'], color='C6', label='M7 Training loss')\n#plt.plot(history8.history['loss'], color='C7', label='M8 Training loss')\nplt.title('one miniXCEPTION raw Training Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(loc='upper right')\nplt.show()\n\ny_pred = bag_model_1.predict(X_test_raw)\ny_pred = np.argmax(y_pred,axis=1)\ny_true = np.asarray([np.argmax(i) for i in y_test])\nprint(y_pred.shape)\nprint(y_true.shape)\n\ncm = confusion_matrix(y_true, y_pred)\ncm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\nsns.set(font_scale=1.5)\nfig, ax = plt.subplots(figsize=(10,10))\nax = sns.heatmap(\n    cm_norm, annot=True, linewidths=0, square=False, cmap='Greens',\n    yticklabels=emotion_labels, xticklabels=emotion_labels,\n    vmin=0, vmax=np.max(cm_norm), fmt='.2f',\n    annot_kws={'size': 20}\n)\nax.set(xlabel='Predicted Label', ylabel='Actual Label', title='miniXCEPTION frontalized CM')\nplt.show()\n","execution_count":3,"outputs":[{"output_type":"stream","text":"28698\n3589\n3589\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-3cb0c2ab3b16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;31m#loading models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \u001b[0mbag_model_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmini_XCEPTION\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;31m#bag_model_2 = mini_XCEPTION((48,48,1),7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#bag_model_3 = mini_XCEPTION((48,48,1),7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-4d7ea6399230>\u001b[0m in \u001b[0;36mmini_XCEPTION\u001b[0;34m(input_shape, num_classes, l2_regularization)\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         use_bias=False)(x)\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/layers/normalization.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'moving_variance'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoving_variance_initializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             trainable=False)\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         weight = K.variable(initializer(shape),\n\u001b[0m\u001b[1;32m    250\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/initializers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant_v1\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    177\u001b[0m   \"\"\"\n\u001b[1;32m    178\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=verify_shape,\n\u001b[0;32m--> 179\u001b[0;31m                         allow_broadcast=False)\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    287\u001b[0m       attrs={\"value\": tensor_value,\n\u001b[1;32m    288\u001b[0m              \"dtype\": dtype_value},\n\u001b[0;32m--> 289\u001b[0;31m       name=name).outputs[0]\n\u001b[0m\u001b[1;32m    290\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconst_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mis_in_graph_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIS_IN_GRAPH_MODE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_PRINT_DEPRECATION_WARNINGS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0minvalid_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0mnamed_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcallargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeprecated_positions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m           if (spec.position < len(args) and\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py\u001b[0m in \u001b[0;36mgetcallargs\u001b[0;34m(func, *positional, **named)\u001b[0m\n\u001b[1;32m    262\u001b[0m   \u001b[0margspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m   \u001b[0mcall_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnamed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m   \u001b[0mthis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'im_self'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__self__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mpositional\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}