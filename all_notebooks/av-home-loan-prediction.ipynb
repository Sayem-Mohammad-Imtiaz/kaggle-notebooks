{"cells":[{"metadata":{},"cell_type":"markdown","source":"## [Home Loan Prediction](https://datahack.analyticsvidhya.com/contest/practice-problem-loan-prediction-iii/#ProblemStatement)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import libraries & read data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.filterwarnings(action='ignore',category=DeprecationWarning)\nwarnings.filterwarnings(action='ignore',category=FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read datasets \ntrain = pd.read_csv('../input/loan-prediction-practice-av-competition/train_csv.csv')  \ntest = pd.read_csv('../input/loan-prediction-practice-av-competition/test.csv.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop duplicate rows, if any - no duplicates found\nprint(train.shape)\ntrain =train.drop_duplicates(subset = None, keep = 'first')\nprint(train.shape)\n\nprint(test.shape)\ntest =test.drop_duplicates(subset = None, keep = 'first')\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Missing value treatment","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for missing values in test + train dataset\nprint(\"TRAIN DATA\\n\")\nprint(train.isnull().sum())\nprint(\"\")\nprint(\"TEST DATA\\n\")\nprint(test.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#combine train and test for missing value treatment (not the most optimal way, unless test/train are from same source)\n\ntrain['source'] = 'train'\ntest['source'] = 'test'\ntest['Loan_Status'] = np.nan # emply column for test dataset (we have to predict this)\n\nframes = [test,train]\ncombined = pd.concat(frames, sort = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# missing values as % of nrows\nper_missing = round((combined.drop('Loan_Status',axis =1).isnull().sum()/combined.drop('Loan_Status',axis = 1).isnull().count())*100,1)\nprint('% Missing Values for each column :')\nper_missing.sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace non-numeric with mode, replace numeric with median\n\n#median \ncombined.loc[:,'Credit_History'].fillna(combined.loc[:,'Credit_History'].median(),inplace = True)\ncombined.loc[:,'LoanAmount'].fillna(combined.loc[:,'LoanAmount'].median(),inplace = True)\ncombined.loc[:,'Loan_Amount_Term'].fillna(combined.loc[:,'Loan_Amount_Term'].median(),inplace = True)\n\n#mode\ncombined.loc[:,'Self_Employed'].fillna(combined.loc[:,'Self_Employed'].mode()[0],inplace = True)\ncombined.loc[:,'Dependents'].fillna(combined.loc[:,'Dependents'].mode()[0],inplace = True)\ncombined.loc[:,'Gender'].fillna(combined.loc[:,'Gender'].mode()[0],inplace = True)\ncombined.loc[:,'Married'].fillna(combined.loc[:,'Married'].mode()[0],inplace = True)\n\n\nper_missing = round((combined.drop('Loan_Status',axis =1).isnull().sum()/combined.drop('Loan_Status',axis = 1).isnull().count())*100,1)\nprint('% Missing Values for each column :')\nper_missing.sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA with Visuals\n### Plotting Loan Status vs Other Variables ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# separate train from combined for visualization\ntrain = combined.loc[combined.source == 'train'].copy() #add copy() to create copy instead of view\n\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorical Variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# gender\neda_gender_proportion = round(pd.crosstab(train.loc[:,'Gender'],train.loc[:,'Loan_Status']).apply(lambda r: r/r.sum(), axis=1)*100,1)\n\n# married\neda_married_proportion = round(pd.crosstab(train.loc[:,'Married'],train.loc[:,'Loan_Status']).apply(lambda r: r/r.sum(), axis=1)*100,1)\n\n# dependents\neda_dependents_proportion = round(pd.crosstab(train.loc[:,'Dependents'],train.loc[:,'Loan_Status']).apply(lambda r: r/r.sum(), axis=1)*100,1)\n\n# education\neda_education_proportion = round(pd.crosstab(train.loc[:,'Education'],train.loc[:,'Loan_Status']).apply(lambda r: r/r.sum(), axis=1)*100,1)\n\n# employment\neda_self_employed_proportion = round(pd.crosstab(train.loc[:,'Self_Employed'],train.loc[:,'Loan_Status']).apply(lambda r: r/r.sum(), axis=1)*100,1)\n\n# property\neda_self_property_proportion = round(pd.crosstab(train.loc[:,'Property_Area'],train.loc[:,'Loan_Status']).apply(lambda r: r/r.sum(), axis=1)*100,1)\n\n# credit history\neda_credit_proportion = round(pd.crosstab(train.loc[:,'Credit_History'],train.loc[:,'Loan_Status']).apply(lambda r: r/r.sum(), axis=1)*100,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(3,3)\nfig.set_size_inches(15, 15)\n\np1 = eda_gender_proportion.plot.bar(stacked=True,ax = axes[0,0])\np2 = eda_married_proportion.plot.bar(stacked=True,ax = axes[0,1])\np3 = eda_dependents_proportion.plot.bar(stacked=True,ax = axes[0,2])\np4 = eda_education_proportion.plot.bar(stacked=True,ax = axes[1,0])\np5 = eda_self_employed_proportion.plot.bar(stacked=True,ax = axes[1,1])\np6 = eda_self_property_proportion.plot.bar(stacked=True,ax = axes[1,2])\np7 = eda_credit_proportion.plot.bar(stacked=True,ax = axes[2,0])\n\n\np1.get_legend().remove()\np2.get_legend().remove()\n#p3.get_legend().remove() #modify p3 legend to mark loan_status outside the graph\np4.get_legend().remove()\np5.get_legend().remove()\np6.get_legend().remove()\np7.get_legend().remove()\n\nplt.subplots_adjust(hspace = 0.5)\np3.legend(loc='center left', bbox_to_anchor=(1,0.8),title = 'Loan Status') #modifying p3 legend\n\nfig.delaxes(axes[2,1]) #deleting additional empty graph areas \nfig.delaxes(axes[2,2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Continuous Variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#create bins - bucket continuous variables, plot by Loan_Status \n\n# ApplicantIncome \n\n# train.loc[:,'ApplicantIncome'].max() #- 81000\n# train.loc[:,'ApplicantIncome'].min() #- 150\n# train.loc[:,'ApplicantIncome'].mean() #- 5403\n# train.loc[:,'ApplicantIncome'].median() #- 3813\n\nbins_applicant=[0,3000,6000,9000,81000]\ngroup_applicant=['Low','Medium','High','Very High']\ntrain['ApplicantIncome_bin']=pd.cut(train['ApplicantIncome'],bins_applicant,labels=group_applicant,include_lowest =True)\n\n\n# print(train.groupby('ApplicantIncome_bin')['Loan_ID'].count())\n# print(train.groupby('ApplicantIncome_bin')['ApplicantIncome'].mean())\n\n\n# # CoapplicantIncome \n\n# train.loc[:,'CoapplicantIncome'].max() #- 41667\n# train.loc[:,'CoapplicantIncome'].min() #- 0\n# train.loc[:,'CoapplicantIncome'].mean() #- 1621\n# train.loc[:,'CoapplicantIncome'].median() #- 1189\n\nbins_coapplicant=[0,1000,2000,4000,41667]\ngroup_coapplicant=['Low','Medium','High','Very High']\ntrain['CoapplicantIncome_bin']=pd.cut(train.loc[:,'CoapplicantIncome'],bins_coapplicant,labels=group_coapplicant,include_lowest = True)\n\n\n# print(train.groupby('CoapplicantIncome_bin')['Loan_ID'].count())\n# print(train.groupby('CoapplicantIncome_bin')['CoapplicantIncome'].mean())\n\n# # LoanAmount\n\n# train.loc[:,'LoanAmount'].max() #- 700\n# train.loc[:,'LoanAmount'].min() #- 9\n# train.loc[:,'LoanAmount'].mean() #- 146\n# train.loc[:,'LoanAmount'].median() #- 128\n\nbins_loan_amt=[0,100,200,700]\ngroup_loan_amt=['Low','Medium','High']\ntrain['LoanAmount_bin']=pd.cut(train.loc[:,'LoanAmount'],bins_loan_amt,labels=group_loan_amt,include_lowest = True)\n\n\n# print(train.groupby('LoanAmount_bin')['Loan_ID'].count())\n# print(train.groupby('LoanAmount_bin')['LoanAmount'].mean())\n\n\n# Loan_Amount_Term\n\n# train.loc[:,'Loan_Amount_Term'].max() #- 480\n# train.loc[:,'Loan_Amount_Term'].min() #- 12\n# train.loc[:,'Loan_Amount_Term'].mean() #- 342\n# train.loc[:,'Loan_Amount_Term'].median() #- 360\n\nbins_loan_term=[0,300,480]\ngroup_loan_term=['<300 months ','> 300 months']\ntrain['Loan_Amount_Term_bin']=pd.cut(train.loc[:,'Loan_Amount_Term'],bins_loan_term,labels=group_loan_term,include_lowest = True)\n\n\n# print(train.groupby('Loan_Amount_Term_bin')['Loan_ID'].count())\n# print(train.groupby('Loan_Amount_Term_bin')['Loan_Amount_Term'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\neda_applicant_proportion = round(pd.crosstab(train.loc[:,'ApplicantIncome_bin'],train.loc[:,'Loan_Status']).apply(lambda r: r/r.sum(), axis=1)*100,1)\neda_coapplicant_proportion = round(pd.crosstab(train.loc[:,'CoapplicantIncome_bin'],train.loc[:,'Loan_Status']).apply(lambda r: r/r.sum(), axis=1)*100,1)\neda_loan_amt_proportion = round(pd.crosstab(train.loc[:,'LoanAmount_bin'],train.loc[:,'Loan_Status']).apply(lambda r: r/r.sum(), axis=1)*100,1)\neda_loan_term_proportion = round(pd.crosstab(train.loc[:,'Loan_Amount_Term_bin'],train.loc[:,'Loan_Status']).apply(lambda r: r/r.sum(), axis=1)*100,1)\n\n# print(eda_applicant_proportion)\n# print(eda_coapplicant_proportion)\n# print(eda_loan_amt_proportion)\n# print(eda_loan_term_proportion)\n\n\nfig, axes = plt.subplots(2,2)\nfig.set_size_inches(15, 10)\n\np1 = eda_applicant_proportion.plot.bar(stacked=True,ax = axes[0,0])\np2 = eda_coapplicant_proportion.plot.bar(stacked=True,ax = axes[0,1])\np3 = eda_loan_amt_proportion.plot.bar(stacked=True,ax = axes[1,0])\np4 = eda_loan_term_proportion.plot.bar(stacked=True,ax = axes[1,1])\n\n\np1.get_legend().remove()\np2.get_legend().remove() #modify p2 legend to mark loan_status outside the graph\np3.get_legend().remove() \np4.get_legend().remove()\n\nplt.subplots_adjust(hspace = 0.5)\np2.legend(loc='center left', bbox_to_anchor=(1,0.8),title = 'Loan Status') #modifying p2 legend","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check data skewness \n\nfig, axes = plt.subplots(2,2)\nfig.set_size_inches(15, 10)\n\ncp1 = sns.distplot(train.loc[:,'ApplicantIncome'],ax = axes[0,0],kde = False)\ncp2 = sns.distplot(train.loc[:,'CoapplicantIncome'],ax = axes[0,1],kde = False)\ncp3 = sns.distplot(train.loc[:,'LoanAmount'],ax = axes[1,0],kde = False)\ncp4 = sns.distplot(train.loc[:,'Loan_Amount_Term'], ax = axes[1,1],kde = False)\n\nplt.subplots_adjust(hspace = 0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CoapplicantIncome has a lot of zeroes, check proportion\nprint('Proportion of entries where Coapplicant Income is zero:',round(train.loc[:,'CoapplicantIncome'][train.CoapplicantIncome==0].count()/train.loc[:,'CoapplicantIncome'].count()*100,1),'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering \n#### It is done on imputed combined dataset so that we don't have to repeat for test/train individually -> has its drawbacks, but we'll keep it simple for this problem","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature 1 \n#Total Household Income = Applicant Income + CoApplicant Income \ncombined['TotalIncome'] = combined['ApplicantIncome'] + combined['CoapplicantIncome']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature 2\n# EMI : [P x R x (1+R)^N]/[(1+R)^N-1] ; assume 8% p.a rate of interest \n\nP = combined.loc[:,'LoanAmount']\nR = 0.08\nN = combined.loc[:,'Loan_Amount_Term']\n\ncombined['EMI'] = (P*R*(1+R)**N)/((1+R)**(N-1))\n\ncombined['EMI'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature 3\n# Loan Amount to Income Ratio\ncombined['Loan_to_income'] = combined.loc[:,'LoanAmount']/combined.loc[:,'TotalIncome']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop extra columns \ncombined = combined.drop(['Loan_ID','ApplicantIncome','CoapplicantIncome','Loan_Amount_Term'],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### One Hot Encoding for categorical variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert Loan_Status, Source into numeric before applying encoding\n\ncombined['Loan_Status'].replace('Y',1,inplace = True)\ncombined['Loan_Status'].replace('N',0,inplace = True)\n\ncombined['source'].replace('train',0,inplace = True)\ncombined['source'].replace('test',1,inplace = True)\n\ncombined.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# one hot encoding \ncombined_onehot = pd.get_dummies(combined)\n\n# we only need n-1 columns ; for example, if there are two genders, M & F, if Gender_Male column is 1, we don't need another Gender_Female column as it will always be zero for this record\n# drop redundant one hot encoded columns \n\ncombined_onehot = combined_onehot.drop(['Gender_Male','Married_No','Dependents_3+','Education_Not Graduate','Self_Employed_Yes','Property_Area_Urban'],axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined_onehot.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model 1 - Logistic Regression","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Log Transform the numerical variables, followed by Standardizing ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# log transform numeric variables\n\n# Loan Amount \ncombined_onehot['LoanAmount_log'] = np.log(1+combined_onehot.loc[:,'LoanAmount'])\n\n# Total Income \ncombined_onehot['TotalIncome_log'] = np.log(1+combined_onehot.loc[:,'TotalIncome'])\n\n# EMI \ncombined_onehot['EMI_log'] = np.log(1+combined_onehot.loc[:,'EMI'])\n\n# Loan To Income \ncombined_onehot['Loan_to_income_log'] = np.log(1+combined_onehot.loc[:,'Loan_to_income'])\n\n# drop orignal non-transformed variables\ncombined_onehot = combined_onehot.drop(['LoanAmount','TotalIncome','EMI','Loan_to_income'],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scaling data\nfrom sklearn.preprocessing import RobustScaler\nscaler = RobustScaler()\n\nfeatures_to_be_scaled = ['LoanAmount_log','TotalIncome_log','EMI_log','Loan_to_income_log']\n\ncombined_onehot.loc[:,features_to_be_scaled] = scaler.fit_transform(combined_onehot.loc[:,features_to_be_scaled])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(combined_onehot.loc[:,features_to_be_scaled].mean()) # should be 0 if standard scalar, robust scalar ignores outliers for the calulations\nprint(combined_onehot.loc[:,features_to_be_scaled].std()) # should be 1, if standard scalar, robust scalar ignores outliers for the calulations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# separate test and train before modeling \n\n\ntrain_model = combined_onehot[combined_onehot['source'] == 0].copy()\ntrain_model = train_model.drop(['source'],axis = 1).copy()\n\ntest_model = combined_onehot[combined_onehot['source'] == 1].copy()\ntest_model = test_model.drop(['source','Loan_Status'],axis = 1).copy()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# store feature matrix and response vector in two different datasets \ntrain_features = train_model.loc[:,train_model.columns != 'Loan_Status'].copy()\ntrain_labels = np.ravel(train_model.loc[:,train_model.columns == 'Loan_Status'].copy()) #ravel() converts df y to flattened array","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### [Refer : Baligh Mnassri's Notebook](https://www.kaggle.com/mnassrib/titanic-logistic-regression-with-python)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Model 1.1 : Logistic Refression Using Test/Train split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score \nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss\n\n# store feature matrix and response vector in two different datasets \ntrain_features = train_model.loc[:,train_model.columns != 'Loan_Status'].copy()\ntrain_labels = np.ravel(train_model.loc[:,train_model.columns == 'Loan_Status'].copy()) #ravel() converts df y to flattened array\n\n\nX_train, X_validate, y_train, y_validate = train_test_split(train_features, train_labels, test_size=0.2, random_state=3)\n\n# check classification scores of logistic regression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_validate)\ny_pred_proba = logreg.predict_proba(X_validate)[:, 1]\n[fpr, tpr, thr] = roc_curve(y_validate, y_pred_proba)\n\nprint('Train/Test split results:')\nprint(logreg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_validate, y_pred))\nprint(logreg.__class__.__name__+\" log_loss is %2.3f\" % log_loss(y_validate, y_pred_proba))\nprint(logreg.__class__.__name__+\" auc is %2.3f\" % auc(fpr, tpr))\n\nidx = np.min(np.where(tpr > 0.95)) # index of the first threshold for which the sensibility > 0.95\n\nplt.figure()\nplt.plot(fpr, tpr, color='coral', label='ROC curve (area = %0.3f)' % auc(fpr, tpr))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot([0,fpr[idx]], [tpr[idx],tpr[idx]], 'k--', color='blue')\nplt.plot([fpr[idx],fpr[idx]], [0,tpr[idx]], 'k--', color='blue')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (1 - specificity)', fontsize=14)\nplt.ylabel('True Positive Rate (recall)', fontsize=14)\nplt.title('Receiver operating characteristic (ROC) curve')\nplt.legend(loc=\"lower right\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# output file\npred_test = logreg.predict(test_model)\npred_test_df = pd.DataFrame()\npred_test_df['Loan_ID'] = test['Loan_ID']\npred_test_df['Loan_Status'] = np.vectorize(lambda s: 'Y' if s==1 else 'N')(pred_test)\npred_test_df[['Loan_ID','Loan_Status']].to_csv('new_simple_logistic.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model 1.2 Logistic Regression using GridSearchCV (multiple scorers)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nX = train_features\ny = train_labels\n\nparam_grid = {'C': np.arange(1e-05, 3, 0.1)}\nscoring = {'Accuracy': 'accuracy', 'AUC': 'roc_auc', 'Log_loss': 'neg_log_loss'}\n\ngs = GridSearchCV(LogisticRegression(), return_train_score=True,\n                  param_grid=param_grid, scoring=scoring, cv=10, refit='Accuracy')\n\ngs.fit(X, y)\nresults = gs.cv_results_\n\nprint('='*20)\nprint(\"best params: \" + str(gs.best_estimator_))\nprint(\"best params: \" + str(gs.best_params_))\nprint('best score:', gs.best_score_)\nprint('='*20)\n\nplt.figure(figsize=(10, 10))\nplt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\",fontsize=16)\n\nplt.xlabel(\"Inverse of regularization strength: C\")\nplt.ylabel(\"Score\")\nplt.grid()\n\nax = plt.axes()\nax.set_xlim(0, param_grid['C'].max()) \nax.set_ylim(0.35, 0.95)\n\n# Get the regular numpy array from the MaskedArray\nX_axis = np.array(results['param_C'].data, dtype=float)\n\nfor scorer, color in zip(list(scoring.keys()), ['g', 'k', 'b']): \n    for sample, style in (('train', '--'), ('test', '-')):\n        sample_score_mean = -results['mean_%s_%s' % (sample, scorer)] if scoring[scorer]=='neg_log_loss' else results['mean_%s_%s' % (sample, scorer)]\n        sample_score_std = results['std_%s_%s' % (sample, scorer)]\n        ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n                        sample_score_mean + sample_score_std,\n                        alpha=0.1 if sample == 'test' else 0, color=color)\n        ax.plot(X_axis, sample_score_mean, style, color=color,\n                alpha=1 if sample == 'test' else 0.7,\n                label=\"%s (%s)\" % (scorer, sample))\n\n    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n    best_score = -results['mean_test_%s' % scorer][best_index] if scoring[scorer]=='neg_log_loss' else results['mean_test_%s' % scorer][best_index]\n        \n    # Plot a dotted vertical line at the best score for that scorer marked by x\n    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n\n    # Annotate the best score for that scorer\n    ax.annotate(\"%0.2f\" % best_score,\n                (X_axis[best_index], best_score + 0.005))\n\nplt.legend(loc=\"best\")\nplt.grid('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# output file\npred_test = gs.predict(test_model)\npred_test_df = pd.DataFrame()\npred_test_df['Loan_ID'] = test['Loan_ID']\npred_test_df['Loan_Status'] = np.vectorize(lambda s: 'Y' if s==1 else 'N')(pred_test)\npred_test_df[['Loan_ID','Loan_Status']].to_csv('new_GSCV_logistic.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model 2 - Random Forest (w/ GridSearchCV)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"##### [Refer : ZlatanKremonic's Kaggle Notebook](https://www.kaggle.com/zlatankr/titanic-random-forest-82-78/notebook)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Transformation/Scaling not very critical for tree based algorithms, but let's use the same dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\n\nparam_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10], \"min_samples_split\" : [2, 4, 10, 12, 16], \"n_estimators\": [50, 100, 400, 700, 1000]}\n\ngs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n\ngs = gs.fit(train_features, train_labels)\n\n\nprint(gs.best_score_)\nprint(gs.best_params_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(gs.best_score_)\nprint(gs.best_params_)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train rf model using the best_params_ from gridsearch\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(criterion='entropy', \n                             n_estimators=50,\n                             min_samples_split=10,\n                             min_samples_leaf=1,\n                             max_features='auto',\n                             oob_score=True,\n                             random_state=1,\n                             n_jobs=-1)\nrf.fit(train_features, train_labels)\nprint(\"%.4f\" % rf.oob_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat((pd.DataFrame(train_features.columns, columns = ['variable']), \n           pd.DataFrame(rf.feature_importances_, columns = ['importance'])), \n          axis = 1).sort_values(by='importance', ascending = False)[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# output file\npred_test = rf.predict(test_model)\npred_test_df = pd.DataFrame()\npred_test_df['Loan_ID'] = test['Loan_ID']\npred_test_df['Loan_Status'] = np.vectorize(lambda s: 'Y' if s==1 else 'N')(pred_test)\npred_test_df[['Loan_ID','Loan_Status']].to_csv('new_rf_GSCV.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model 2 - xGBoost (w/ GridSearchCV)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.metrics import make_scorer\n\n\nparam_test = {\n    'n_estimators': [10,50,100],\n    'max_depth': [3,5,7],\n    'min_child_weight': [1,3],\n    'gamma':[i/10.0 for i in range(0,5)],\n    'subsample':[0.5,0.75,1],\n    'colsample_bytree':[0.5,0.75,1],\n    'learning_rate': [0.01, 0.05, 0.1]\n}\n\nscoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n\ngs = GridSearchCV(estimator = XGBClassifier(), \n                       param_grid = param_test, \n                       scoring=scoring,\n                       iid=False,\n                       cv=5, \n                       verbose = 1, \n                       refit='Accuracy',\n                       n_jobs = -1)\n\ngs.fit(train_features, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(gs.best_score_)\nprint(gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train xBG model using the best_params_ from gridsearch\n\n# split into train and validate\nX_train, X_validate, y_train, y_validate = train_test_split(train_features, train_labels, test_size=0.2, random_state=3,stratify = y)\n\n# train xBG on train\nfrom xgboost import XGBClassifier\n\nxGB = XGBClassifier(colsample_bytree=0.75, \n                             gamma=0.0,\n                             learning_rate=0.05,\n                             max_depth=3,\n                             min_child_weight=3,\n                             n_estimators=10,\n                             subsample = 1,\n                             random_state=1,\n                             n_jobs=-1)\n\nxGB.fit(X_train, y_train)\n\n# predict validate\n\ny_pred = xGB.predict(X_validate)\ny_pred_proba = xGB.predict_proba(X_validate)[:, 1]\n\n[fpr, tpr, thr] = roc_curve(y_validate, y_pred_proba)\nprint('Train/Test split results:')\nprint(xGB.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_validate, y_pred))\nprint(xGB.__class__.__name__+\" log_loss is %2.3f\" % log_loss(y_validate, y_pred_proba))\nprint(xGB.__class__.__name__+\" auc is %2.3f\" % auc(fpr, tpr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# output file\npred_test = xGB.predict(test_model)\npred_test_df = pd.DataFrame()\npred_test_df['Loan_ID'] = test['Loan_ID']\npred_test_df['Loan_Status'] = np.vectorize(lambda s: 'Y' if s==1 else 'N')(pred_test)\npred_test_df[['Loan_ID','Loan_Status']].to_csv('new_xGB_GSCV.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Models with Mean Encoding (non-regularized)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert Loan_Status, Source into numeric before applying encoding\n\ncombined['Loan_Status'].replace('Y',1,inplace = True)\ncombined['Loan_Status'].replace('N',0,inplace = True)\n\ncombined['source'].replace('train',0,inplace = True)\ncombined['source'].replace('test',1,inplace = True)\n\ncombined.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# separate test and train before modeling \n\ntrain_model = combined[combined['source'] == 0].copy()\ntrain_model = train_model.drop(['source'],axis = 1).copy()\n\ntest_model = combined[combined['source'] == 1].copy()\ntest_model = test_model.drop(['source','Loan_Status'],axis = 1).copy()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_mean_encoded = ['Gender','Married','Dependents','Education','Self_Employed','Property_Area']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_mean_encoded = train_model\ntest_mean_encoded = test_model\n\nfor col in cols_mean_encoded:\n    mean = train_mean_encoded.groupby(col)['Loan_Status'].mean()\n    train_mean_encoded['mean_encoded_'+col] =train_mean_encoded.loc[:,col].map(mean)\n    test_mean_encoded['mean_encoded_'+col] =test_mean_encoded.loc[:,col].map(mean)\n\n# drop original columns \n\ntrain_mean_encoded = train_mean_encoded.drop(cols_mean_encoded,axis = 1)\ntest_mean_encoded = test_mean_encoded.drop(cols_mean_encoded,axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# store feature matrix and response vector in two different datasets \ntrain_features = train_mean_encoded.loc[:,train_mean_encoded.columns != 'Loan_Status'].copy()\ntrain_labels = np.ravel(train_mean_encoded.loc[:,train_mean_encoded.columns == 'Loan_Status'].copy()) #ravel() converts df y to flattened array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train, validate split\nfrom sklearn.model_selection import train_test_split\nX_train, X_validate, y_train, y_validate = train_test_split(train_features, train_labels, test_size=0.2, random_state=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### RandomForest with GridSearchCV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\n\nparam_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10], \"min_samples_split\" : [2, 4, 10, 12, 16], \"n_estimators\": [50, 100, 400, 700, 1000]}\n\ngs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n\ngs = gs.fit(train_features, train_labels)\n\n\nprint(gs.best_score_)\nprint(gs.best_params_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train rf model using the best_params_ from gridsearch\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(criterion='gini', \n                             n_estimators=100,\n                             min_samples_split=12,\n                             min_samples_leaf=5,\n                             max_features='auto',\n                             oob_score=True,\n                             n_jobs=-1)\nrf.fit(train_features, train_labels)\nprint(\"%.4f\" % rf.oob_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat((pd.DataFrame(train_features.columns, columns = ['variable']), \n           pd.DataFrame(rf.feature_importances_, columns = ['importance'])), \n          axis = 1).sort_values(by='importance', ascending = False)[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# output file\npred_test = rf.predict(test_mean_encoded)\npred_test_df = pd.DataFrame()\npred_test_df['Loan_ID'] = test['Loan_ID']\npred_test_df['Loan_Status'] = np.vectorize(lambda s: 'Y' if s==1 else 'N')(pred_test)\npred_test_df[['Loan_ID','Loan_Status']].to_csv('new_rf_GSCV_encoded.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### xGB with GridSearchCV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.metrics import make_scorer, accuracy_score, roc_curve\n\n\nparam_test = {\n    'n_estimators': [10,50,100],\n    'max_depth': [3,5,7],\n    'min_samples_split': [50,100,500],\n    'max_features':['sqrt'],\n    'subsample':[0.8],\n    'colsample_bytree':[0.5,1],\n    'learning_rate': [0.05, 0.1],\n    'random_state': [1]\n}\n\nscoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n\ngs = GridSearchCV(estimator = XGBClassifier(), \n                       param_grid = param_test, \n                       scoring=scoring,\n                       iid=False,\n                       cv=5, \n                       verbose = 1, \n                       refit='Accuracy',\n                       n_jobs = -1)\n\ngs.fit(train_features, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(gs.best_score_)\nprint(gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train xBG model using the best_params_ from gridsearch\nfrom sklearn.metrics import make_scorer, accuracy_score, roc_curve,log_loss,auc\n# split into train and validate\nX_train, X_validate, y_train, y_validate = train_test_split(train_features, train_labels, test_size=0.2, random_state=3,stratify = y)\n\n# train xBG on train\nxGB = XGBClassifier(colsample_bytree=1, \n                             gamma=0.0,\n                             learning_rate=0.01,\n                             max_depth=3,\n                             min_child_weight=3,\n                             n_estimators=50,\n                             subsample = 1,\n                             n_jobs=-1)\n\nxGB.fit(X_train, y_train)\n\n# predict validate\n\ny_pred = xGB.predict(X_validate)\ny_pred_proba = xGB.predict_proba(X_validate)[:, 1]\n\n[fpr, tpr, thr] = roc_curve(y_validate, y_pred_proba)\nprint('Train/Test split results:')\nprint(xGB.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_validate, y_pred))\nprint(xGB.__class__.__name__+\" log_loss is %2.3f\" % log_loss(y_validate, y_pred_proba))\nprint(xGB.__class__.__name__+\" auc is %2.3f\" % auc(fpr, tpr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# output file\npred_test = xGB.predict(test_mean_encoded)\npred_test_df = pd.DataFrame()\npred_test_df['Loan_ID'] = test['Loan_ID']\npred_test_df['Loan_Status'] = np.vectorize(lambda s: 'Y' if s==1 else 'N')(pred_test)\npred_test_df[['Loan_ID','Loan_Status']].to_csv('new_xGB_GSCV_encoded.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}