{"nbformat_minor":1,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py","name":"python","version":"3.6.3","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python"}},"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CAR INSURANCE COLD CALLS - REPORT","metadata":{"_cell_guid":"41113cd7-3df5-4502-a2d1-717246af5f97","_uuid":"8790b69d89f8e041a05414e0562bff3f5ddc18a6"}},{"cell_type":"markdown","source":"<img src=\"https://media.giphy.com/media/xTiTnjBP7yCsrEqbHq/giphy.gif\" style=\"float:left;\" />","metadata":{"_cell_guid":"0bfaa107-774a-422b-92a4-f2966c335c4c","_uuid":"809c47f72bd2cd49004e1e03c4240fc6f5991ab5"}},{"cell_type":"markdown","source":"### ABOUT THE DATASET\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">\nThis is a dataset from a bank in the United States. Besides usual services, this bank also provides carinsurance services. The bank organizes regular campaigns to attract new clients.The bank has potential customers data, and bank’s employees call them for advertising available car insurance options. We are provided with general information about clients (age, job, etc.) as well as more specific information about the current insurance sell campaign (communication, last contact day) and previous campaigns(attributes like previous attempts, outcome).\n</span>","metadata":{"_cell_guid":"c9697481-d29a-44f0-9f03-12f9d580af3f","_uuid":"943d1515a3d126b30a18d8659e31212a82494c0e"}},{"cell_type":"markdown","source":"<img src=\"https://media.giphy.com/media/3oEduRCITWQ5BruE8g/giphy.gif\" style=\"float:left;\"/>","metadata":{"_cell_guid":"ee94f51f-4690-42b4-bdb6-9e8544270d71","_uuid":"54db2894175f5106d404a964d99baec87c45cc03"}},{"cell_type":"markdown","source":"### CLIENT\nSTAR Bank is our Client, located in United States they operate in almost all states and they try to convert already existing insurance customers from a different agency to STAR by their marketing campaigns mostly ***Cold Call***","metadata":{"_cell_guid":"bec28797-506f-4e0b-951a-867dbc03c7be","_uuid":"d1b4b87cdde27183febb7c147e547836a2acdfb2"}},{"cell_type":"markdown","source":"### PROBLEM(S) TO SOLVE\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">\nThe client wants to know the most important factor which determines cold call success so that they can work on it and further improve their business using the cold call data.The problem I am trying to solve involves creating predictive models and choosing the best model among them using model validation techniques to gain more insights about the key factors which contributes to cold call success and provide recommendations to improve cold call success as well. Further the model implementation can improve their business and help them on concentarting on the key areas to their success</span>","metadata":{"_cell_guid":"4e1ac20a-9e29-45dd-868d-4ab2ad345678","_uuid":"525ba328046df031ed0c260af63180ec73e533fc"}},{"cell_type":"markdown","source":"<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">Lets look at the features of the dataset and understand what each attribute/feature is about.The table below shows a brief description of the dataset and whether the variables are continuous, categorical or binary.</span>\n\n|Feature          | Description                                                           | Example                            |\n|:----------------|:----------------------------------------------------------------------|:-----------------------------------|\n|Id               | Unique ID number. Predictions file should contain this feature.       |“1” … “5000”                        |\n|Age              | Age of the client                                                     |                                    |\n|Job              | Job of the client.                                                    | \"admin.\", \"blue-collar\", etc.      |\n|Marital          | Marital status of the client                                          | \"divorced\", \"married\", \"single\"    |\n|Education        | Education level of the client                                         | \"primary\", \"secondary\", etc.       |\n|Default          | Has credit in default?                                                | \"yes\" - 1,\"no\" - 0                 |\n|Balance          | Average yearly balance, in USD                                        |                                    |\n|HHInsurance      | Is household insured                                                  | \"yes\" - 1,\"no\" - 0                 |\n|CarLoan          | Has the client a car loan                                             | \"yes\" - 1,\"no\" - 0                 | \n|Communication    | Contact communication type                                            | \"cellular\", \"telephone\", “NA”      |\n|LastContactMonth | Month of the last contact                                             | \"jan\", \"feb\", etc.                 |\n|LastContactDay   | Day of the last contact                                               |                                    |\n|CallStart        | Start time of the last call (HH:MM:SS)                                |  12:43:15                          |\n|CallEnd          | End time of the last call (HH:MM:SS)                                  | 12:43:15                           |\n|NoOfContacts     | Number of contacts performed uring this campaign for this client      |                                    |\n|DaysPassed       |  Number of days that passed by after the client was last contacted    |                                    |\n|                 |   from a previous campaign (numeric; -1 means client was not          |                                    |\n|                 |   previously contacted)                                               |                                    |\n|PrevAttempts     | Number of contacts performed before this campaign and for this client |                                    |\n|Outcome          | Outcome of the previous marketing campaign                            | \"failure\", \"other\", \"success\", “NA”|\n|CarInsurance     | Has the client subscribed a CarInsurance?                             | \"yes\" - 1,\"no\" - 0                 |","metadata":{"_cell_guid":"10a7934c-d994-4fc8-88d1-ffaef8040a7d","_uuid":"31673e649c30cd4bc2046e76a58d71e279c97300"}},{"cell_type":"markdown","source":"<img src=\"https://media.giphy.com/media/3orif6jx0qkH5vU2f6/giphy.gif\" style=\"float: left;\"/>","metadata":{"_cell_guid":"40fa5d3d-bebb-4a94-8c12-5b2e5f300700","_uuid":"7ab19684cf94f2d5020009c6489ebe1f24dd7955"}},{"cell_type":"markdown","source":"### DATA WRANGLING / DATA MUNGING","metadata":{"_cell_guid":"a2c78ab9-758b-4be8-8f1d-5d2b27827918","_uuid":"808756e4e1675f73034d20112c01a0e25545003c"}},{"cell_type":"markdown","source":"<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\"> Data Wrangling or Data Munging is the process of converting data from one form to another to better understand it. Here in our case our data is availabe to us as a CSV file and lets use our powerful python data science libraries to load it into a dataframe. Well I never thought it would look so easy !!</span>","metadata":{"_cell_guid":"359ccf3f-4592-4bba-bc58-601f89e42829","_uuid":"71ec24cb521c946d96594850973ae5d01b6e9712"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"a72b80c3-7d8d-4865-a116-d890d5d3e92e","_uuid":"da358cf545a154939326c6e4df8da79a4300df10"},"outputs":[],"source":"# Importing Data Science Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split,cross_val_score,KFold,cross_val_predict\nfrom sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score,confusion_matrix,precision_recall_curve,roc_curve\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import ExtraTreesClassifier,RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.neighbors  import KNeighborsClassifier\nfrom sklearn import svm,tree"},{"cell_type":"markdown","source":"<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\"> Here indexing already existing column saves a lot of time and hassle. Trust me</span>","metadata":{"_cell_guid":"83a40db7-dd96-4b5a-8acd-a17c29f40c85","_uuid":"60700747dc59e237e7e47cda5c4a83391c66f38e"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"45112a05-f3af-422b-a28d-c4cc1fc288c0","_uuid":"7ba14740a8c420fca9e6bcf787429297b4405f54"},"outputs":[],"source":"# Reading Csv file\ndf = pd.read_csv('../input/carInsurance_train.csv',index_col = 'Id')"},{"cell_type":"markdown","source":"<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\"> Sneak peek into our top 5 rows of the dataframe. Well, our data looks too good </span>","metadata":{"_cell_guid":"472e1cf4-5a40-4170-adda-9985eb1e75ea","_uuid":"da0122afe12bbd7c22aca60d1a93a274cf659949"}},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79ad56ee-7634-49e7-a6cb-ba1dea25db01","_uuid":"653687c82f343bfa1e7b821241a1b83bb57eee45"},"outputs":[],"source":"# Top rows\ndf.head()"},{"cell_type":"markdown","source":"<img src=\"https://media.giphy.com/media/l41Yl108BMSthoqXu/giphy.gif\" style=\"float:left;\"/>","metadata":{"_cell_guid":"d815855a-6d7d-4cc7-b911-d786c5522daf","_uuid":"c022acb67e0e5626329dbdcf1f21513d1422c7fc"}},{"cell_type":"markdown","source":"### EXPLORATORY DATA ANALYSIS","metadata":{"_cell_guid":"64fde450-dad4-4476-8dcc-7dea159abc53","_uuid":"babda9ba2ef46e72e2eac9fe152152fc3578abc3"}},{"cell_type":"markdown","source":"<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\"> Exploring is always fun and the new insights you can find is always interesting. Starting from the shape of the dataset to knowing about the columns, datatypes and the statistics part of it gives us a lot more of understanding and deep dive into the data. By having a look at the Balance amount in our dataset 75% of the field is 1619 and the max is 98417. Nice, we are exploring !! </span>","metadata":{"_cell_guid":"b44fd065-8cc7-4080-8650-c4b86ae00711","_uuid":"62d47703445f07c96bb9abea153e545a10c525a4"}},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ee206b36-3b8f-4e05-9919-7a34243f9a4a","_uuid":"57aae840c7ded66b43bbae71b3cce2f6fc697a15"},"outputs":[],"source":"# Shape of dataframe\ndf.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2b108b74-ffc7-43d8-bf05-b349b02a5bfa","_uuid":"0e5b36cdf4837fbfb0ea89088843e4492638b45c"},"outputs":[],"source":"# Columns in dataset\ndf.columns"},{"cell_type":"markdown","source":"<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\"> Looking at our Numerical columns Default, HHInsurance, CarLoan,CarInsurance are binary having 0's' and 1's'</span>","metadata":{"_cell_guid":"23abec68-4985-408e-b9b5-772c937817cd","_uuid":"4f6e827e57dbc0ccd9fc42e9f2bfd4bf82e14ff1"}},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a1de352c-3e4b-4d11-b88f-9fb649ebbe09","_uuid":"38bda6d4094a3391449d8e56c884e504d4acb622"},"outputs":[],"source":"# Statistics of numerical columns\ndf.describe()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3780f28c-0f1f-4df5-b6a0-4a53b9ef91a7","_uuid":"73bd4d7d8402a4e48823ae55e7c369038112843e"},"outputs":[],"source":"# Datatypes of columns in dataset\ndf.dtypes"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9b9c08d5-c2b3-42fc-91f2-c57bc4c492e1","_uuid":"8a856c96695e87af207c4e69cb557f8c15b16d1a"},"outputs":[],"source":"# Statistics of categorical features\ndf.describe(include=['O'])"},{"cell_type":"markdown","source":"<img src=\"https://media.giphy.com/media/pEgip3gXxoIVi/giphy.gif\" style=\"float:left;\"/>","metadata":{"_cell_guid":"f16d2631-023d-4f69-af52-1d743b14a4e3","_uuid":"f6513626bf9b4331bbeb251bd053d28a15d967e5"}},{"cell_type":"markdown","source":"### OUTLIER ANALYSIS\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\"> An Outlier is usually an observation which typically lies farthest from the mean. According to Statistical theory if any observation is 3*IQR(Inter Quartile Range) from the mean then its called an Outlier. Sometimes values are distributed randomly such as a Balance amount - from our boxplot below looks like more values have crossed the whisker. One particular data point is too far when compared to the other points in the data and the outlier is dropped from the dataset. ","metadata":{"_cell_guid":"1ddf71dd-b518-4ba1-b96a-3dfd6933c98f","_uuid":"92f01f37a3dab11ec4bf507339a1aa0e9f69bf34"}},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7391efb8-1a50-4c85-bb9f-ed7c6dd36e8a","_uuid":"ee5ba429c5aa5484183003ba751e20a5849df5fa"},"outputs":[],"source":"# Plotting Balance field as a Boxplot using Seaborn\nsns.boxplot(x='Balance',data=df,palette='hls');"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7f33e8b0-1e0a-4dd3-a35b-f36c9b4a01bd","_uuid":"90fac8be66717dcc44be229c3596fc2821c24848"},"outputs":[],"source":"# Maximum value in Balance field\ndf.Balance.max()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2d2ed6a7-94a8-46c8-98a3-29ed864ca0af","_uuid":"e5bb4cd49ec77a8e8c99fff0718927d145f9a6d0"},"outputs":[],"source":"# Looking at the particular maximum value in the dataframe\ndf[df['Balance'] == 98417]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"faecbadb-63d8-4f7b-84aa-5baf32eb976d","_uuid":"fc9b823effd55edb856eafd17652bd60ae11fb23"},"outputs":[],"source":"# Dropping the index value corresponding to the outlier\ndf_new = df.drop(df.index[1742]);"},{"cell_type":"markdown","source":"<img src=\"https://media.giphy.com/media/l2JehQ2GitHGdVG9y/giphy.gif\" style=\"float:left;\"/>","metadata":{"_cell_guid":"6b9c1da0-8161-4135-b536-43145e834108","_uuid":"f2f89ed2fd642c4b2b1ecd2b7c6a71f1d3368929"}},{"cell_type":"markdown","source":"### HANDLING MISSING VALUES\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">  Missing values are a major concern with data analysis and dealing them is another hurdle. Python treats missing data as NaN but doesnot include it into calcualtions and visulizations. Also predictive models cannot be built without treating missing values. In our case missing values occurs mostly in Outcome and Communication fields. Job and Education have considerable amount of missing values.</span>\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">  \n\n**IMPUTING MISSING VALUES**\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">  \nThe missing values like Job and Education are very few and can imputed using backfill/frontfill pad method in python .Outcome and Communication have quite a lot missing values and hence they are imputed using None for NaN values.\n</span>","metadata":{"_cell_guid":"c7101f1f-d8ba-469d-a705-d29c5cf07435","_uuid":"f37710d1b3aaf7f5266add30f29ff44808d0dc04"}},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0757ddda-35d7-4ec3-a7af-a959f9cad422","_uuid":"32bba9bec47762ba71f7218a66c1b57916b9d48d"},"outputs":[],"source":"#checking for missing values using isnull() method\ndf_new.isnull().sum()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"0edad470-316b-42df-ab3b-6611dbe6ba85","_uuid":"9318c66bed8cb921e6cdf63f46d906c049410f7a"},"outputs":[],"source":"# Using frontfill to fill the missing values in Job and Education fields\ndf_new['Job'] = df_new['Job'].fillna(method ='pad')\ndf_new['Education'] = df_new['Education'].fillna(method ='pad')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"1667677c-9205-4e4a-91ed-7d0429ee00cc","_uuid":"f56545ae7a2577d83951e557925dcae432e9c1bc"},"outputs":[],"source":"# Using none to fill Nan values in Communication and Outcome fields\ndf_new['Communication'] = df_new['Communication'].fillna('none')\ndf_new['Outcome'] = df_new['Outcome'].fillna('none')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"664e3373-286a-4fc5-aff6-62865c32df8d","_uuid":"7086090ef00af00c02058666648d2d447931f3da"},"outputs":[],"source":"#Looks like all missing values have been imputed\ndf_new.isnull().sum()"},{"cell_type":"markdown","source":"<img src=\"https://media.giphy.com/media/l2Je34w7WkZ84f3os/giphy.gif\" style=\"float:left;\"/>","metadata":{"_cell_guid":"1ac44c59-460e-44ce-a90b-c62bfe919ea4","_uuid":"d56a054c452dbc3a9718cc1b0fc03259e3ae1428"}},{"cell_type":"markdown","source":"### CORRELATION\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">\nCorrelation is used to determine the relationship between two variables/ fields. Correlation varies from -1 to 1; if the Correlation is 1 then the fields are positively correlated, 0 having no correlation and -1 is negatively correlated. Lets see how each atttribute correlates with one another using Heatmap. Looks like there is not much of a correlation among variables but DaysPassed and PrevAttempts have a positive Correlation with each other.\n</span>","metadata":{"_cell_guid":"55bb6275-bc7d-4e45-a812-588c94e2e904","_uuid":"009b18e690369763d2378e58dfa0fd7da7074cb4"}},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6f84e946-cb5c-4833-bb18-6f5bee597b97","_uuid":"538fc3d51280c86ecd7801379c63c0b9e3f177e4"},"outputs":[],"source":"#Setting up correlation for our dataframe and passing it to seaborn heatmap function\nsns.set(style=\"white\")\ncorr = df_new.corr()\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nf, ax = plt.subplots(figsize=(11, 9))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr,annot=True, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5});"},{"cell_type":"markdown","source":"<img src=\"https://media.giphy.com/media/3ohryitJOzSTrCnBe0/giphy.gif\" style=\"float:left;\"/>","metadata":{"_cell_guid":"68d6c6df-4690-4e84-8e81-c7584b910d70","_uuid":"ae86047d3d367dfdb77c290f812dafc446f438f4"}},{"cell_type":"markdown","source":"### DATA VISUALIZATION\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">\nVisualization is an important aspect of Data Science without which its pretty diffcult to arrive at an outcome easily.Eventhough the result is determined in tables there is a painpoint in looking at each values and coming to a conclusion. Charts/Graphs are much helpful to accomplish those tasks with ease even to a non-technical person. Executives and managers love to look at a report with visualization so that they can easily come up with complex decisions.Below is a pairplot which pairs fields of interest and plots them. The variables for the Pairplot are selected from the heatmap which have an impact on the outcome\n       \n**Key takeaways from the Pairplot**\n\n    *Older people are more likely to Buy Car Insurance.                                                                              \n    *People having prior Car Insurance and Home Insurance are less likely to purchase.                                                \n    *People give a positive sign if the days passed (time before they were contacted) increases.                                       \n    *When you contact persons frequently their buying tendency increases after 20+ contacts.                                          \n    *No.of contacts and PrevAttempts work the same , more the better i.e increases Car Insurance purchase.\n    </span>","metadata":{"_cell_guid":"f4dcbff8-2fae-402a-9e19-0c2811980140","_uuid":"394e3cdd14c3235fc1de69cd515b7f350419417f"}},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b83ee20a-e51e-4487-a197-3c8468baa678","_uuid":"1578f3bd408bda4834f3380fe5bbc4f5e058abe8"},"outputs":[],"source":"# Plotting paired fields of intrest using Seaborn pairplot\ndf_sub = ['Age','Balance','HHInsurance', 'CarLoan','NoOfContacts','DaysPassed','PrevAttempts','CarInsurance']\nsns.pairplot(df_new[df_sub],hue='CarInsurance',size=1.5);"},{"cell_type":"markdown","source":"<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">\nPairGrid helps us to view relationships between CarInsurance,Balance and Categorical variables such as Education,Marital Status and Job.Students and Retired people have purchased the most Car Insurances with Former leading the Latter                      People with single status and who are highly educated dominate the charts.</span>                                                                             ","metadata":{"_cell_guid":"e2e43b32-0d6c-4fce-b70e-b1854d852bb5","_uuid":"05aab7fb83936ebc893d98b8b464ac726bcf797b"}},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ce7d5700-4aed-4325-b478-51a7a303fa70","_uuid":"7881358ad59cc538afa6e94d435c786a9df88c8a"},"outputs":[],"source":"#Uses multiple x and y variables to form pair grid of categorical values passed\ng = sns.PairGrid(df_new,\n                 x_vars=[\"Education\",\"Marital\", \"Job\"],\n                 y_vars=[\"CarInsurance\", \"Balance\"],\n                 aspect=.75, size=6)\nplt.xticks(rotation=90)\ng.map(sns.barplot, palette=\"pastel\");"},{"cell_type":"markdown","source":"<img src=\"http://static.socialitelife.com/uploads/2014/04/04/robert-downey-jr-gifs-04042014-11.gif\" style=\"float:left;\"/>","metadata":{"_cell_guid":"6795cce5-ae6f-4ce0-8207-f12837c554ae","_uuid":"03a5ee3d50f9ca1798fd5d193f8fea271d89e7bf"}},{"cell_type":"markdown","source":"### LOOKS INTERESTING\n\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">Violin plot has bulges near value 1 in y axis shows that Mar, Sep, Oct and Dec are the desired months for people buying Car Insurance.The Count plot below has more missing previous campaign outcome where majority said **No** to car insurance.</span>","metadata":{"_cell_guid":"e10e8297-9b08-47ce-bc7a-1cfcaf41b16c","_uuid":"7261738e6e07dab1bf42c74382ffe3845e7eb282"}},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dc5794f8-0190-451b-9b31-bff80d04ef46","_uuid":"827594562d0293e645d94716962322956bbb8d11"},"outputs":[],"source":"#Seaborn violin plot for LastContactMonth and CarInsurance fields\nsns.violinplot(x=\"LastContactMonth\",y='CarInsurance',data=df_new);"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"426de1a6-f112-4515-8eb5-96781caadad2","_uuid":"5865811effa6048f7dceab28aed3e07304046fe7"},"outputs":[],"source":"#Count of CarInsurance against Outcome i.e previous campaign outcome\nsns.countplot(x=\"Outcome\",hue='CarInsurance',data=df_new);"},{"cell_type":"markdown","source":"<img src=\"http://www.cowi.in/menu/services/geographicalinformationandIT/Mapsandgeodataproducts/2Dfeatureextraction/PublishingImages/2d.gif\" style=\"float:left;\"/>","metadata":{"_cell_guid":"be7c10cf-0a0a-480b-b7b8-1239c1bcc410","_uuid":"8b327baead7b42464a8ebc04890b3f30c8e990ae"}},{"cell_type":"markdown","source":"### FEATURE ENGINEERING/ FEATURE EXTRACTION","metadata":{"_cell_guid":"16011612-67d0-4e4b-94b0-214f005fc9e0","_uuid":"095a9dca14958dc2bec050cb226b550a231e6f50"}},{"cell_type":"markdown","source":"<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">Feature Engineering is an essential element to a Machine Learning Problem. Picking a feature from a set of attribute determines\nhow well the algorithm will work in making predictions, so this part is a crucial one. In our problem there are a list of \ncontinuous variables like Age and Balance and they need to be binned. The Age and Balance continuous variables are bucketed \nusing quartile cut function into 5 segments.</span>","metadata":{"_cell_guid":"b5bc16c7-22d3-4613-976d-d936bbd69a5a","_uuid":"aee4be31fcacae111f4c98354448e1d7c2de7969"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"a3766479-100e-4377-9686-7fb86b979f01","_uuid":"8bf2a73391b6fbed77a554fd7f04f07d27646c2d"},"outputs":[],"source":"#Qcut splits both the attribute into 5 buckets\ndf_new['AgeBinned'] = pd.qcut(df_new['Age'], 5 , labels = False)\ndf_new['BalanceBinned'] = pd.qcut(df_new['Balance'], 5,labels = False)"},{"cell_type":"markdown","source":"<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">There seems to be a unique problem with respect to the CallStart and CallEnd attributes and are recorded as object variables \nwhich can be computed easily using the datetime function, so converting it to datetime function and subtracting them arrives at\nthe actual CallTime which can be further binned as above.</span>","metadata":{"_cell_guid":"44b92e3c-699a-471e-a2e9-996a66d64493","_uuid":"b7e0df5822a90391ab2dfe83ef506683d78bd3f3"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"88716126-174e-4fd5-8e5e-020ebf9f7e87","_uuid":"50fc361c64a108ab77b2f22932ea9ddcfb81aa17"},"outputs":[],"source":"#Converting CallStart and CallEnd to datetime datatype\ndf_new['CallStart'] = pd.to_datetime(df_new['CallStart'] )\ndf_new['CallEnd'] = pd.to_datetime(df_new['CallEnd'] )\n#Subtracting both the Start and End times to arrive at the actual CallTime\ndf_new['CallTime'] = (df_new['CallEnd'] - df_new['CallStart']).dt.total_seconds()\n#Binning the CallTime\ndf_new['CallTimeBinned'] = pd.qcut(df_new['CallTime'], 5,labels = False)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"fc14687a-2ef8-4f77-88c3-7ddc5252be8c","_uuid":"2ba1d5e583a0ed3f8a9fc8dbd8dd6213b32eaa4e"},"outputs":[],"source":"#Dropping the original columns of the binned, just to make things easy\ndf_new.drop(['Age','Balance','CallStart','CallEnd','CallTime'],axis = 1,inplace = True)"},{"cell_type":"markdown","source":"<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">Categorical variables can also paricipate in model building provided that they get their dummy values inorder to be included.\nWell, we would have more columns included to our dataframe by this procedure.</span>","metadata":{"_cell_guid":"88c7b2ab-a8df-491f-82ae-ab46e402c827","_uuid":"df9115f186691bc87798d2852d875083ce0af103"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"a5e54f9e-73ce-496d-9583-69bd342284ff","_uuid":"dd03a40588bbecdb9c6300e2f66c152af3db0ce1"},"outputs":[],"source":"# Using get_dummies function to assign binary values to each value in the categorical column\nJob = pd.get_dummies(data = df_new['Job'],prefix = \"Job\")\nMarital= pd.get_dummies(data = df_new['Marital'],prefix = \"Marital\")\nEducation= pd.get_dummies(data = df_new['Education'],prefix=\"Education\")\nCommunication = pd.get_dummies(data = df_new['Communication'],prefix = \"Communication\")\nLastContactMonth = pd.get_dummies(data = df_new['LastContactMonth'],prefix= \"LastContactMonth\")\nOutcome = pd.get_dummies(data = df_new['Outcome'],prefix = \"Outcome\")"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"023ad450-ee40-4600-b750-0f3a1331d1b2","_uuid":"d9db493996e6ad54b3b5008338f447c998590569"},"outputs":[],"source":"# Dropping the categorical columns which have been assigned dummies\ndf_new.drop(['Job','Marital','Education','Communication','LastContactMonth','Outcome'],axis=1,inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"94844a20-1c5f-4450-9326-055d1ce33d3c","_uuid":"6d876a7d6a7aea4e0c24672eb9daef7388600883"},"outputs":[],"source":"#Concatenating the dataframe with the categorical dummy columns\ndf = pd.concat([df_new,Job,Marital,Education,Communication,LastContactMonth,Outcome],axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ba323a60-bc4c-48f0-a145-870759d09360","_uuid":"0f48c5ef8495b848bac20fa09230f60c955edc52"},"outputs":[],"source":"# The dataframe has some new additions resulting from the categorical dummies added\ndf.columns"},{"cell_type":"markdown","source":"<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">**TEST TRAIN SPLIT**\n\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">The Train Test Split is usually done to evaluate our model by Training it on the known output(labeled data) so that the model can learn on it and Testing using unlabeled data so that the predictive accuracy of the model can be determined.</span>","metadata":{"_cell_guid":"0d801ffe-241d-456c-847a-1d925d558ac8","_uuid":"6227173ec6b10e49e6e2d5b598a5e5f478b9c762"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"a056666d-75ed-41f0-a767-37dee16fe7ac","_uuid":"4b2e72ad5fdf6b68592758b29876594069a060fd"},"outputs":[],"source":"# Dropping the Target for X\nX= df.drop(['CarInsurance'],axis=1).values\n# Including only the Target for y\ny=df['CarInsurance'].values\n#Splitting the Training and Testing data having 20% of Test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=42, stratify = y)"},{"cell_type":"markdown","source":"<img src=\"https://media.giphy.com/media/3Gm1ATv2eFCjS/giphy.gif\" style=\"float:left;\"/>","metadata":{"_cell_guid":"3d9909c4-d874-4039-bc0b-1e761ed60cf0","_uuid":"564a69b10f711054ae9e235eea445f9f86c458af"}},{"cell_type":"markdown","source":"### PREDICTIVE MODEL BUILDING AND VALIDATION","metadata":{"_cell_guid":"938f61e3-e9a6-4712-8df6-c52c72380b53","_uuid":"2cb72bbb3e21adbca6c2e6ba2bca1e97abaaa24a"}},{"cell_type":"markdown","source":"<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">\n**PREDICTIVE MODELS**\n\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">\nPredictive Models are built to correctly classify the unknown label inputs, the models are trained using the labeled outputs so\nthat it can learn from them and correctly classify the non labeled items. There are a lot of Classification Predictor Algorithms \nincorporated into sklearn and in our case we have utilized most of the classification algorithms related to our problem.\nOur Classifiers include</span>\n1. kNN\n2. Logistic Regression\n3. SVM\n4. Decision Tree\n5. Random Forest\n6. AdaBoost\n7. XGBoost\n\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">\n**CROSS VALIDATION**\n\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">\nCross-validation is used to split the data into training and test sets to evaluate how the model performs. In KFold, K determins the number of partitions to be made on the data and from which 1 sample is used for training and 10-1 in our case 9 is used for the validation purposes. Each model's cross validation score is obtained by evaluating the model by splitting it into 10 Folds.\n\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">**MODEL VALIDATION**\n\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">\nValidating our models built is a key component which helps in determining how our model's predictive power. Starting from the\nmost common accuracy score, cross validation score to classification report(precision, recall, f1-score,support), ROC curves \nand Confusion matrix , the models have gone through extensive validation to choose the best predictor.\n\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">**BEST MODEL** \n\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">\nThe best model is a tie between **Random Forest** and **XGBoost** both doing their part well with good accuracy scores, less \nfalse positives and true negatives.","metadata":{"_cell_guid":"c820900d-ade4-461e-bd61-482fb6277d71","_uuid":"605e56392bf38d9437b695e88c8b0dd8676d93fd"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"029387df-8541-4b4e-b8d7-a563ee220595","_uuid":"a85f51c532c9ce443c43737c4393af4a58c54ae2"},"outputs":[],"source":"#The code for the below matrix is taken from sklearn documentation\n#Defining the confusion matrix function\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \n   \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    \n\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n        \n        \n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n#Using Success and Failure for 0 and 1    \nclass_names = ['Success','Failure']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"658f591e-3339-449f-ae8e-9f1e46e6fdb4","_uuid":"88aeae9fcca90895480b5788bdb6bc3be30c7c01"},"outputs":[],"source":"# Defining the kNNClassifier with 6 neighbors\nknn = KNeighborsClassifier(n_neighbors = 6)\n#Fitting the classifier to the training set\nknn.fit(X_train,y_train)\nprint (\"kNN Accuracy is %2.2f\" % accuracy_score(y_test, knn.predict(X_test)))\n#The cross validation score is obtained for kNN using 10 folds\nscore_knn = cross_val_score(knn, X, y, cv=10).mean()\nprint(\"Cross Validation Score = %2.2f\" % score_knn)\ny_pred= knn.predict(X_test)\nprint(classification_report(y_test, y_pred))\n#Defining the confusion matrix\ncm = confusion_matrix(y_test,y_pred)\n#Plotting the confusion matrix\nplot_confusion_matrix(cm, classes=class_names, title='Confusion matrix')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"14aef862-6804-48b3-ad0a-3f6215d8030e","_uuid":"19ae44e97f6a8ec0c5aebc83f7802c27f53d7832"},"outputs":[],"source":"#Logistic Regression Classifier\nLR = LogisticRegression()\nLR.fit(X_train,y_train)\nprint (\"Logistic Accuracy is %2.2f\" % accuracy_score(y_test, LR.predict(X_test)))\nscore_LR = cross_val_score(LR, X, y, cv=10).mean()\nprint(\"Cross Validation Score = %2.2f\" % score_LR)\ny_pred = LR.predict(X_test)\nprint(classification_report(y_test, y_pred))\n# Confusion matrix for LR\ncm = confusion_matrix(y_test,y_pred)\nplot_confusion_matrix(cm, classes=class_names, title='Confusion matrix')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f1a0e407-97cc-4edd-acf5-4fd04bd2bd9b","_uuid":"5f24ab3e41b2e4ddbfe371449c04e7b16f4cf365"},"outputs":[],"source":"#SVM Classifier\nSVM = svm.SVC()\nSVM.fit(X_train, y_train)\nprint (\"SVM Accuracy is %2.2f\" % accuracy_score(y_test, SVM.predict(X_test)))\nscore_svm = cross_val_score(SVM, X, y, cv=10).mean()\nprint(\"Cross Validation Score = %2.2f\" % score_svm)\ny_pred = SVM.predict(X_test)\nprint(classification_report(y_test,y_pred))\n#Confusion matrix for SVM\ncm = confusion_matrix(y_test,y_pred)\nplot_confusion_matrix(cm, classes=class_names, title='Confusion matrix')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"899841f2-2ef8-45fd-b35f-d9d4c4607036","_uuid":"31cd7d1e744cd1592eb687086888517ba597a411"},"outputs":[],"source":"# Decision Tree Classifier\nDT = tree.DecisionTreeClassifier(random_state = 0,class_weight=\"balanced\",\n    min_weight_fraction_leaf=0.01)\nDT = DT.fit(X_train,y_train)\nprint (\"Decision Tree Accuracy is %2.2f\" % accuracy_score(y_test, DT.predict(X_test)))\nscore_DT = cross_val_score(DT, X, y, cv=10).mean()\nprint(\"Cross Validation Score = %2.2f\" % score_DT)\ny_pred = DT.predict(X_test)\nprint(classification_report(y_test, y_pred))\n# Confusion Matrix for Decision Tree\ncm = confusion_matrix(y_test,y_pred)\nplot_confusion_matrix(cm, classes=class_names, title='Confusion matrix')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d4b294d8-428d-4194-9bfe-47fb05f8b136","_uuid":"8fe81d30672c2ca14640524410ce04da5fb66657"},"outputs":[],"source":"#Random Forest Classifier\nrfc = RandomForestClassifier(n_estimators=1000, max_depth=None, min_samples_split=10,class_weight=\"balanced\")\nrfc.fit(X_train, y_train)\nprint (\"Random Forest Accuracy is %2.2f\" % accuracy_score(y_test, rfc.predict(X_test)))\nscore_rfc = cross_val_score(rfc, X, y, cv=10).mean()\nprint(\"Cross Validation Score = %2.2f\" % score_rfc)\ny_pred = rfc.predict(X_test)\nprint(classification_report(y_test,y_pred ))\n#Confusion Matrix for Random Forest\ncm = confusion_matrix(y_test,y_pred)\nplot_confusion_matrix(cm, classes=class_names, title='Confusion matrix')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"989b3ee7-3234-487a-866b-59eaf251105f","_uuid":"0256987d5c7d2dc92afb8814feba74195fe3a683"},"outputs":[],"source":"#AdaBoost Classifier\nada = AdaBoostClassifier(n_estimators=400, learning_rate=0.1)\nada.fit(X_train,y_train)\nprint (\"AdaBoost Accuracy= %2.2f\" % accuracy_score(y_test,ada.predict(X_test)))\nscore_ada = cross_val_score(ada, X, y, cv=10).mean()\nprint(\"Cross Validation Score = %2.2f\" % score_ada)\ny_pred = ada.predict(X_test)\nprint(classification_report(y_test,y_pred ))\n#Confusion Marix for AdaBoost\ncm = confusion_matrix(y_test,y_pred)\nplot_confusion_matrix(cm, classes=class_names, title='Confusion matrix')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"91583e78-085a-40b8-82e6-eea7c3c6a05b","_uuid":"05fa8183e4e3830a14f8230e13d247e633ca6cd3"},"outputs":[],"source":"#XGBoost Classifier\nxgb = GradientBoostingClassifier(n_estimators=1000,learning_rate=0.01)\nxgb.fit(X_train,y_train)\nprint (\"GradientBoost Accuracy= %2.2f\" % accuracy_score(y_test,xgb.predict(X_test)))\nscore_xgb = cross_val_score(xgb, X, y, cv=10).mean()\nprint(\"Cross Validation Score = %2.2f\" % score_ada)\ny_pred = xgb.predict(X_test) \nprint(classification_report(y_test,y_pred))\n#Confusion Matrix for XGBoost Classifier\ncm_xg = confusion_matrix(y_test,y_pred)\nplot_confusion_matrix(cm_xg, classes=class_names, title='Confusion matrix')"},{"cell_type":"markdown","source":"<img src=\"https://media.giphy.com/media/53iQruN6nEEvK/giphy.gif\" style=\"float:left;\"/>","metadata":{"_cell_guid":"a7d3b208-88ec-4ef6-ae3d-9e16bc24d10d","_uuid":"03f75bed87e9453243fb5d8a3ca0bd32d8873dca"}},{"cell_type":"markdown","source":"### ROC CURVES","metadata":{"collapsed":true,"_cell_guid":"658541f4-992d-43f7-a717-b961c80f3fe2","_uuid":"d9a9f6214ae7f21574daad33e4096b15cc56a547"}},{"cell_type":"markdown","source":"<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">Another important visual model validation technique is the Reciever Operating Characteristic(ROC) Curves, which plots the true\npositive rate and the false postive rates. The curve is a good validator of the models and helps us determine whether our model \nworks best. When the AOC( Area Under Curve) is maximum and when its towards the upper left then the model works best. The ROC\nhas all the models plotted and Gradient Boosting(XGBoost) and Randomforest towards the upper left showing that those predictor\nmodels are the best.</span>","metadata":{"_cell_guid":"7a5f4b2b-63ed-4a6f-adcb-2d769f3b16fb","_uuid":"3804c52c4a7f01c0a0e0dcb0b6b27666af9fd7df"}},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f6fb9f38-1f46-4ce3-8722-b84e4dba3ee3","_uuid":"d85bf00d3b9d9a106f7effc0e809f27314fe4fa7"},"outputs":[],"source":"#Obtaining False Positive Rate, True Positive Rate and Threshold for all classifiers\nfpr, tpr, thresholds = roc_curve(y_test, knn.predict_proba(X_test)[:,1])\nLR_fpr, LR_tpr, thresholds = roc_curve(y_test, LR.predict_proba(X_test)[:,1])\n#SVM_fpr, SVM_tpr, thresholds = roc_curve(y_test, SVM.predict_proba(X_test)[:,1])\nDT_fpr, DT_tpr, thresholds = roc_curve(y_test, DT.predict_proba(X_test)[:,1])\nrfc_fpr, rfc_tpr, thresholds = roc_curve(y_test, rfc.predict_proba(X_test)[:,1])\nada_fpr, ada_tpr, thresholds = roc_curve(y_test, ada.predict_proba(X_test)[:,1])\nxgb_fpr, xgb_tpr, thresholds = roc_curve(y_test, xgb.predict_proba(X_test)[:,1])\n#PLotting ROC Curves for all classifiers\nplt.plot(fpr, tpr, label='KNN' )\nplt.plot(LR_fpr, LR_tpr, label='Logistic Regression')\n#plt.plot(SVM_fpr, SVM_tpr, label='SVM')\nplt.plot(DT_fpr, DT_tpr, label='Decision Tree')\nplt.plot(rfc_fpr, rfc_tpr, label='Random Forest')\nplt.plot(ada_fpr, ada_tpr, label='AdaBoost')\nplt.plot(xgb_fpr, xgb_tpr, label='GradientBoosting')\n# Plot Base Rate ROC\nplt.plot([0,1],[0,1],label='Base Rate')\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Graph')\nplt.legend(loc=\"lower right\")\nplt.show()"},{"cell_type":"markdown","source":"<img src=\"https://media.giphy.com/media/O2E7D6IoABdYI/giphy.gif\" style=\"float:left;\"/>","metadata":{"_cell_guid":"cf13ea88-3f52-498f-8169-790b55b1d0ba","_uuid":"ae9e8c443fa82ec4b0383adedb6ab5f23b72ca67"}},{"cell_type":"markdown","source":"<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">**FEATURE IMPORTANCES**\n\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">Knowing which feature has a major part in determining the output can be very useful and help in working on them to increase \nthe output of the solution. Finding the important features can be very handy when making important decisions and conclusions.\nThe Important feature identification is done by using models such as Logistic Regression and Decision trees. Both of them\nprovide very good clarity in identifying the features. The Graph below shows the most important features determined by the\nExtraTreesClassifier and the top 10 features are\n\n1. CallTime\n2. LastContactDay\n3. Balance\n4. NoofContacts\n5. Outcome_success\n6. Age\n7. HHInsurance\n8. Communication_none\n9. Dayspassed\n10. Outcome_none","metadata":{"_cell_guid":"eea3e9f8-dad5-4a76-be09-b722c1770644","_uuid":"e587f81f51169fb8c4868ea875a40f9c8ba82587"}},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"29b7f19f-1add-4a75-a0da-3d9cb2b1451d","_uuid":"0f6fe8e636043e691af82b4a9f86e050c49025d5"},"outputs":[],"source":"# Using Recursive Feature Elimination Function and fitting it in a Logistic Regression Model\nmodell = LogisticRegression()\nrfe = RFE(modell, 5)\nrfe = rfe.fit(X_train,y_train)\n# Displays the feature rank\nrfe.ranking_"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a37539ce-5321-4041-893c-bbc6be6db0d0","_uuid":"ec2a12f787b087dcc481bacf0aac96c3f2f9f5ab"},"outputs":[],"source":"# Using ExtraTreesClassifier model function\nmodel = ExtraTreesClassifier()\nmodel.fit(X_train, y_train)\n# Printing important features in the model\nprint(model.feature_importances_)\nimportances = model.feature_importances_\nfeat_names = df.drop(['CarInsurance'],axis=1).columns\n\n# Displaying the feature importances as a chart by sorting it in the order of importances\nindices = np.argsort(importances)[::-1]\nplt.figure(figsize=(12,6))\nplt.title(\"Feature importances\")\nplt.bar(range(len(indices)), importances[indices], color='lightblue',  align=\"center\")\nplt.step(range(len(indices)), np.cumsum(importances[indices]), where='mid', label='Cumulative')\nplt.xticks(range(len(indices)), feat_names[indices], rotation='vertical',fontsize=14)\nplt.xlim([-1, len(indices)])\nplt.show()"},{"cell_type":"markdown","source":"<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">\n**CUMULATIVE LIFT AND GAIN CHARTS**\n\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">\nCumulative Gain chart is used to determine how well the model does the Classification task in identifying the positives,(i.e) Cold Call Success. The chart is drawn between the Cumulative % of the Population(the people contacted in our case) to the Positive responses(Cold Call Success). It is one of the very useful validator in business and can help in determining the accuracy of our model classification results. \n\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">\n So for the first decile which has 10% of the customers contacted,20% of positive results has been obtained giving us a **Lift** of 2 which means that we get twice the positive results by using a predictive model rather than just using no model.Let's say for every cold call success the company generates a revenue of $100, by using the predictive model we designed its possible to double the revenue. Isn't it a great advantage? ","metadata":{"_cell_guid":"a597f7ab-bbb7-455a-8c22-7ce45984177d","_uuid":"d563e48747c5c713da46fc77d0c760ddea13b608"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"8d5e8532-a541-4e69-85c7-baddfe92e33d","_uuid":"5b24ec8cdc68504dc217b639bcf69cc864baa7ef"},"outputs":[],"source":"rfc = RandomForestClassifier(n_estimators=1000, max_depth=None, min_samples_split=10,class_weight=\"balanced\")\ny_proba = cross_val_predict(rfc, X, y, cv=10, n_jobs=-1, method='predict_proba')\nresults = pd.DataFrame({'y': y, 'y_proba': y_proba[:,1]})\nresults = results.sort_values(by='y_proba', ascending=False).reset_index(drop=True)\nresults.index = results.index + 1\nresults.index = results.index / len(results.index) * 100"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7976b321-be1f-441a-ab8f-22d18762d30b","_uuid":"a1d1ad350fdffe8439640c4fe90a073704ab663a"},"outputs":[],"source":"sns.set_style('darkgrid')\npred = results\npred['Lift Curve'] = pred.y.cumsum() / pred.y.sum() * 100\npred['Baseline'] = pred.index\nbase_rate = y.sum() / len(y) * 100\npred[['Lift Curve', 'Baseline']].plot(style=['-', '--', '--'])\npd.Series(data=[0, 100, 100], index=[0, base_rate, 100]).plot(style='--')\nplt.title('Cumulative Gains')\nplt.xlabel('% of Customers Contacted')\nplt.ylabel(\"% of Positive Results\")\nplt.legend(['Lift Curve', 'Baseline', 'Ideal']);"},{"cell_type":"markdown","source":"<img src=\"https://media.giphy.com/media/Qrjc3clJyAQU0/giphy.gif\" style=\"float:left;\"/>","metadata":{"_cell_guid":"4544cb83-5f2f-4021-8d78-a5eff33d879e","_uuid":"43e6e3fe7378535d1d8eadc514356d7c23dc9d0a"}},{"cell_type":"markdown","source":"### CONNECTING THE DOTS","metadata":{"_cell_guid":"d606f0e9-4db5-44b7-aa2d-df198583cc33","_uuid":"4d58f0a7fbaef2c22926172d8214b65490e889b9"}},{"cell_type":"markdown","source":"<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">The major problem we tried to address is cold call success and below are some key result interpretations. Cold Call Success is tied with the CallTime, when the representative engages with the customer and creates a rapport with them then most people say yes to the CarInsurance. LastContactDay also plays a crucial part in determining the Cold Call Success (i.e) following up with a customer after a Cold Call. Their account balance can be more of a sign since people having more balance have opted for the CarInsurance.\n\n<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">NoofContacts -how many times the person has been contacted also determines the cold call success. More times the better, which closely related to following up on a continuous basis. Previous campaign outcome success is also a major factor. Older People have more tendency to buy Car Insurance than younger people so that major importance can be given to the older age groups.The Best Model predicts whether the Cold Call will be a Success or not and hence by working on the above mentioned points and trying to improve the important features like CallTime and following up can improve the results to a farer extent. ","metadata":{"_cell_guid":"174c7386-a1c9-4b0e-adb3-db3f667a0d92","_uuid":"f78c8496aad56539a32cee7db28216bacf632039"}},{"cell_type":"markdown","source":"### POSSIBLE SOLUTIONS","metadata":{"_cell_guid":"993048d4-352a-475a-ab7e-1037bb3d99ea","_uuid":"397db25ab24cb4de454dbdc44ea76fc7befc32c1"}},{"cell_type":"markdown","source":"**1. Train the employees working in the Call Center with people skills so that during call they can be more friendly and engaging**\n\n**2. Maintain a tracker which reminds of follow-ups so that the representative can talk to the person again and try to convince\nthem in purchasing Car Insurance**\n\n**3. Select people having good credit score and account balance so that the time invested in them is useful**\n\n**4. Concentrate on Older People with age above 40 because compromising them for a new plan is easy as per the previous data**\n\n**5. Contact persons from the previous campaign who responded since they are more likely to buy Insurance**\n","metadata":{"_cell_guid":"a48377b4-15dd-4dd3-8cba-2e8407b3faa1","_uuid":"22c1eeef909fa82f3b9b69b4af3a2437279af429"}},{"cell_type":"markdown","source":"<span style=\"color: black; font-family: Malgun Gothic; font-size: 14px;\">Please upvote this workbook if you liked my work. Thank you.","metadata":{"_cell_guid":"11416a62-0e5f-4332-bb77-370a52cc25ed","_uuid":"e1c811ed093931934710c684350d1f9706fd2b8f"}}]}