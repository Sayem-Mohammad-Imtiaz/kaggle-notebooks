{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/bike-sharing-dataset/hour.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hours spread from 00 (midnight) to 23 (11 pm)\ndata.hr.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\nimport plotly_express as px\nimport seaborn as sns\nimport math","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We already have relevant info on date with yr, month and hour\n# and we want only the total count\n# also instant is the irrelevant for prediction\npre_dropped = [\"dteday\", \"casual\", \"registered\", \"instant\"]\ndata_prep = data.drop(pre_dropped, axis=1)\ndata_prep.isnull().sum() # no missing data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_prep.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's plot the distributions of the different columns\ndata_prep.hist(rwidth=0.9, figsize=(20, 20))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"cnt distribution is not normal, might need a change of variable"},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# there's a few numerical columns\ndata_prep.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nplt.subplot(2, 2, 1)\nplt.title(\"Demand = f(Temperature)\")\nplt.scatter(x=data_prep.temp, y=data_prep.cnt, s=2, c=\"magenta\")\n##\nplt.subplot(2, 2, 2)\nplt.title(\"Demand = f(Feeled Temperature)\")\nplt.scatter(x=data_prep.atemp, y=data_prep.cnt, s=2, c=\"blue\")\n##\nplt.subplot(2, 2, 3)\nplt.title(\"Demand = f(Humidity)\")\nplt.scatter(x=data_prep.hum, y=data_prep.cnt, s=2, c=\"green\")\n##\nplt.subplot(2, 2, 4)\nplt.title(\"Demand = f(Wind speed)\")\nplt.scatter(x=data_prep.windspeed, y=data_prep.cnt, s=2, c=\"red\")\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can spot some dependency for all of these features, except maybe for humidity."},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation degree of all the numerical features wrt to the total count of bike.\ndata_prep[[\"temp\", \"atemp\", \"hum\", \"windspeed\", \"cnt\"]].corr()[\"cnt\"].plot(kind=\"bar\", title=\"Correlation of variable features wrt to total number of bikes\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"windspeed is maybe less related to how much bikes are used. Let's keep that in mind."},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's plot the evolution of total number of bikes wrt the different categorical features\ncm = matplotlib.cm.get_cmap(\"rainbow\")\nfig, ax = plt.subplots(3, 3, figsize=(15, 15))\ndata_prep.groupby(\"season\").mean()[\"cnt\"].plot(ax=ax[0,0], kind=\"bar\", color=cm(data_prep.groupby(\"season\").mean()[\"cnt\"]/np.max(data_prep.groupby(\"season\").mean()[\"cnt\"])))\ndata_prep.groupby(\"yr\").mean()[\"cnt\"].plot(ax=ax[0,1], kind=\"bar\", color=cm(data_prep.groupby(\"yr\").mean()[\"cnt\"]/np.max(data_prep.groupby(\"yr\").mean()[\"cnt\"])))\ndata_prep.groupby(\"mnth\").mean()[\"cnt\"].plot(ax=ax[0,2], kind=\"bar\", color=cm(data_prep.groupby(\"mnth\").mean()[\"cnt\"]/np.max(data_prep.groupby(\"mnth\").mean()[\"cnt\"])))\ndata_prep.groupby(\"hr\").mean()[\"cnt\"].plot(ax=ax[1,0], kind=\"bar\", color=cm(data_prep.groupby(\"hr\").mean()[\"cnt\"]/np.max(data_prep.groupby(\"hr\").mean()[\"cnt\"])))\ndata_prep.groupby(\"holiday\").mean()[\"cnt\"].plot(ax=ax[1,1], kind=\"bar\", color=cm(data_prep.groupby(\"holiday\").mean()[\"cnt\"]/np.max(data_prep.groupby(\"holiday\").mean()[\"cnt\"])))\ndata_prep.groupby(\"weekday\").mean()[\"cnt\"].plot(ax=ax[1,2], kind=\"bar\", color=cm(data_prep.groupby(\"weekday\").mean()[\"cnt\"]/np.max(data_prep.groupby(\"weekday\").mean()[\"cnt\"])))\ndata_prep.groupby(\"workingday\").mean()[\"cnt\"].plot(ax=ax[2,0], kind=\"bar\", color=cm(data_prep.groupby(\"workingday\").mean()[\"cnt\"]/np.max(data_prep.groupby(\"workingday\").mean()[\"cnt\"])))\ndata_prep.groupby(\"weathersit\").mean()[\"cnt\"].plot(ax=ax[2,1], kind=\"bar\", color=cm(data_prep.groupby(\"weathersit\").mean()[\"cnt\"]/np.max(data_prep.groupby(\"weathersit\").mean()[\"cnt\"])))\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Weekday seems irrelevant in that case, same for workday, we should drop these features. The year is also a dangerous feature, since the data only spreads across 2 years (statistically this is not relevant). Other features seem relevant."},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's look at the hourly distribution\ndata_prep.groupby(\"hr\").mean()[\"cnt\"].plot(kind=\"bar\", figsize=(16, 8), color=cm(data_prep.groupby(\"hr\").mean()[\"cnt\"]/np.max(data_prep.groupby(\"hr\").mean()[\"cnt\"])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bike demand has a peek in the morning (8 am), most certainsly for people going to work. There's also a peak around 5-6 pm when people are leaving work."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data=data_prep, x=\"cnt\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the data is contained between 0 to ~650."},{"metadata":{"trusted":true},"cell_type":"code","source":"# another way to show this\ndata_prep.cnt.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the boxplot in more details. print quartiles from 5% to 99% to check out outliers.\ndata_prep.quantile(np.append(np.arange(0.05, 0.96, 0.05), 0.99))[\"cnt\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"99% of the data is contained below cnt=782. If the model does not perform too well, we might eliminate the most extreme outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's check if numerical features are correlated with one another\nsns.heatmap(data_prep[[\"temp\", \"atemp\", \"windspeed\", \"hum\", \"cnt\"]].corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As one would guess, temperature and feeled temperature are correlated. We will drop the feeled temperature. Windspeed and hum seem correlated, and since windspeed is not well correlated with cnt, we will drop windspeed as well. Let's create our final dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"dropped = [\"windspeed\", \"atemp\", \"workingday\", \"weekday\", \"yr\"]\ndata_final = data_prep.drop(dropped, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only 8 relevant columns remaining!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check autocorrelation of cnt values\nplt.acorr(data_final[\"cnt\"].astype(float), maxlags=12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There's a high auto-correlation for the closest cnt values, this may hurt the linear regression model."},{"metadata":{},"cell_type":"markdown","source":"Back to the cnt distribution, it looks like log-normal, so let's log it to check the normality of the distribution!"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = np.log(data_final[\"cnt\"])\ndf.hist(rwidth=0.9, bins=20, color=\"blue\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"and now it is normally distributed, so let's consider log(cnt) instead of cnt in our dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_final[\"cnt\"] = np.log(data_final[\"cnt\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_final.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now on to the autocorrelation issue"},{"metadata":{"trusted":true},"cell_type":"code","source":"# since cnt is correlated with itself, let's lag the cnt column and consider it as a feature\nt1 = data_final[\"cnt\"].shift(+1).to_frame()\nt1.columns = [\"t-1\"]\nt2 = data_final[\"cnt\"].shift(+2).to_frame()\nt2.columns = [\"t-2\"]\nt3 = data_final[\"cnt\"].shift(+3).to_frame()\nt3.columns = [\"t-3\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lag = pd.concat([data_final, t1, t2, t3], axis=1)\ndata_lag.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop the NaN values\ndata_lag.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The categorical data needs to be transformed into dummy variables. Let's do that."},{"metadata":{"trusted":true},"cell_type":"code","source":"to_be_dummied = [\"season\", \"mnth\", \"hr\", \"holiday\", \"weathersit\"]\ndummy_df = pd.get_dummies(data_lag[to_be_dummied].astype(\"category\"), drop_first=True)\ndummy_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's create ouf data finally pre-processed by concatenating the dummy variables with the numerical features.\ndropped = [\"season\", \"mnth\", \"holiday\", \"weathersit\", \"hr\"]\ndf = pd.concat((data_lag.drop(dropped, axis=1), dummy_df), axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll have 46 features to consider to predict the \"cnt\" value."},{"metadata":{},"cell_type":"markdown","source":"## Train test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(\"cnt\", axis=1)\ny = df[\"cnt\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101) # test size of 25%","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we create the linear regression model\nfrom sklearn.linear_model import LinearRegression\nlr = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's fit it with the training set\nlr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the score on the train set\nlr.score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model has a 0.926 r2 score on the training set. Not bad! Let's now evaluate on the test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score, mean_squared_log_error, mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this is the model predictions\ntest_pred = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(12, 8))\nbins = None\nsns.distplot(test_pred, ax=ax, color=\"blue\", label=\"predictions\", bins=bins)\nsns.distplot(y_test, ax=ax, color=\"red\", label=\"true\", bins=bins)\nax.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The test results seem pretty on point. Let's check that with some scores."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"r2 score: {r2_score(y_test, test_pred):.2f}\")\nprint(f\"RMSE: {np.sqrt(mean_squared_error(y_test, test_pred)):.2f}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 0.93 r2 score"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}