{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pickle\nimport tensorflow as tf\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing import text, sequence\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nprint(tf.__version__)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(filename)","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/hate-speech-and-offensive-language-dataset/labeled_data.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nRow, nCol = df.shape\nprint('There are {} rows and {} columns'.format(nRow, nCol))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c=df['class']\ndf.rename(columns={'tweet' : 'text',\n                   'class' : 'category'}, \n                    inplace=True)\na=df['text']\nb=df['category'].map({0: 'hate_speech', 1: 'offensive_language',2: 'neither'})\n\ndf= pd.concat([a,b,c], axis=1)\ndf.rename(columns={'class' : 'label'}, \n                    inplace=True)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Grouping data by label\ndf['category'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hate, ofensive, neither = np.bincount(df['label'])\ntotal = hate + ofensive + neither\nprint('Examples:\\n    Total: {}\\n    hate: {} ({:.2f}% of total)\\n'.format(\n    total, hate, 100 * hate / total))\nprint('Examples:\\n    Total: {}\\n    Ofensive: {} ({:.2f}% of total)\\n'.format(\n    total, ofensive, 100 * ofensive / total))\nprint('Examples:\\n    Total: {}\\n    Neither: {} ({:.2f}% of total)\\n'.format(\n    total, neither, 100 * neither / total))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_, X_test, y_train_, y_test = train_test_split(\n    df.index.values,\n    df.label.values,\n    test_size=0.10,\n    random_state=42,\n    stratify=df.label.values,    \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(\n    df.loc[X_train_].index.values,\n    df.loc[X_train_].label.values,\n    test_size=0.10,\n    random_state=42,\n    stratify=df.loc[X_train_].label.values,  \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['data_type'] = ['not_set']*df.shape[0]\ndf.loc[X_train, 'data_type'] = 'train'\ndf.loc[X_val, 'data_type'] = 'val'\ndf.loc[X_test, 'data_type'] = 'test'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby(['category', 'label', 'data_type']).count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df.loc[df[\"data_type\"]==\"train\"]\ndf_val = df.loc[df[\"data_type\"]==\"val\"]\ndf_test = df.loc[df[\"data_type\"]==\"test\"]\n\ndf_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_plus_val = pd.concat([df_train,df_val], axis=0)\ndf_train_plus_val.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = df_train_plus_val.text.values\ny = df_train_plus_val.label.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_features = 20000\nmax_text_length = 512","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_tokenizer = text.Tokenizer(max_features)\nx_tokenizer.fit_on_texts(list(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_tokenized = x_tokenizer.texts_to_sequences(x)\nx_train_val= sequence.pad_sequences(x_tokenized, maxlen=max_text_length)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test_tokenized = x_tokenizer.texts_to_sequences(df_test.text.values)\nx_test = sequence.pad_sequences(x_test_tokenized,maxlen=max_text_length)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dim =100\nembeddings_index = dict()\nf = open('/kaggle/input/glove6b100dtxt/glove.6B.100d.txt')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:],dtype='float32')\n    embeddings_index[word]= coefs\nf.close()\nprint(f'Found {len(embeddings_index)} word vectors')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix= np.zeros((max_features,embedding_dim))\nfor word, index in x_tokenizer.word_index.items():\n    if index>max_features-1:\n        break\n    else:\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[index]= embedding_vector","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_plus_val =  tf.keras.utils.to_categorical(y, num_classes=3)\ny_test =  tf.keras.utils.to_categorical(df_test.label, num_classes=3)\ny_train_plus_val","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building 1 D CNN Model","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(max_features,\n                    embedding_dim,\n                    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n                    trainable=False))\n\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv1D(64,2,padding='valid',activation='relu'))\nmodel.add(MaxPooling1D())\nmodel.add(Conv1D(64,2,padding='valid',activation='relu'))\nmodel.add(MaxPooling1D())\n\nmodel.add(Conv1D(32,2,padding='valid',activation='relu'))\nmodel.add(MaxPooling1D())\nmodel.add(Conv1D(32,2,padding='valid',activation='relu'))\nmodel.add(GlobalMaxPooling1D())\n\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(3, activation='softmax'))\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train_val, y_train_plus_val, batch_size= 64, validation_split=0.2, epochs=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot loss\nplt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='validation')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training loss vs. Epochs')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot accuracy\nplt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='validation')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Training accuracy vs. Epochs')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(x_test,y_test, batch_size = 64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(x_test)\ny_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.array( [ np.argmax (y) for y in y_pred ] )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_labels = df_test.label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_test_labels, y_pred)\nfig = sns.heatmap(cm, annot=True, fmt=\"d\")\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"Actual Label\")\nplt.show(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('hate_davidson_dataset_1dcnn_glove.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}