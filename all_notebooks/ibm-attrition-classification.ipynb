{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for columns in df.columns:\n    print(columns,\"=\",df[columns].nunique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a=df.drop(columns=['StandardHours','EmployeeCount','Over18','EmployeeNumber'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"object_col = []\nfor column in a.columns:\n    if a[column].dtype == object and len(a[column].unique()) <= 30:\n        object_col.append(column)\n        print(f\"{column} : {a[column].unique()}\")\n        print(a[column].value_counts())\n        print(\"====================================\")\nobject_col.remove('JobRole' )\nobject_col.remove('EducationField' )  \nprint(object_col)\n        \n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nlabel = LabelEncoder()\na[\"Attrition\"] = label.fit_transform(a.Attrition)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cont_col = []\nfor column in a.columns:\n    if a[column].dtypes != object and a[column].nunique() > 30:\n        print(f\"{column} : Minimum: {a[column].min()}, Maximum: {a[column].max()}\")\n        cont_col.append(column)\n        print(\"====================================\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))\nfor i, column in enumerate(cont_col, 1):\n\n    plt.subplot(2, 4, i)\n    \n    sns.kdeplot(data = a[a['Attrition'] == 0], x = column, shade = True,  alpha = 1, color = '#512b58',Label='Attrition = NO' )\n    sns.kdeplot(data = a[a['Attrition'] == 1], x = column, shade = True,  alpha = 0.8, color = '#fe346e',Label='Attrition = YES')\n    plt.legend()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disc_col = []\nfor column in a.columns:\n    if a[column].dtypes != object and a[column].nunique() < 30:\n        print(f\"{column} : {a[column].unique()}\")\n        disc_col.append(column)\n        print(\"====================================\")\ndisc_col.remove('Attrition')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 20))\n\nfor i, column in enumerate(disc_col, 1):\n    plt.subplot(4, 4, i)\n    a[a[\"Attrition\"] == 0][column].hist(bins=35, color='blue', label='Attrition = NO', alpha=0.6)\n    a[a[\"Attrition\"] == 1][column].hist(bins=35, color='red', label='Attrition = YES', alpha=0.6)\n    plt.legend()\n    plt.grid(False)\n    plt.xlabel(column)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure(figsize=(20, 25))\nfor i, column in enumerate(object_col , 1):\n    plt.subplot(5, 4, i)\n  \n    a[a[\"Attrition\"] == 0][column].hist(bins=5,color='orange', label='Attrition = NO', alpha=0.6)\n    a[a[\"Attrition\"] == 1][column].hist(bins=5, color='red', label='Attrition = YES', alpha=0.6)\n    plt.legend()\n    plt.grid(False)\n    plt.xlabel(column)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    plt.figure(figsize=(20,5 ))\n    a[a[\"Attrition\"] == 0][\"JobRole\"].hist(bins=33,color='blue', label='Attrition = NO', alpha=0.6)\n    a[a[\"Attrition\"] == 1][\"JobRole\"].hist(bins=33, color='darkred', label='Attrition = YES', alpha=0.6)\n    plt.legend()\n    plt.grid(False)\n    plt.xlabel(\"JobRole\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    plt.figure(figsize=(10,5 ))\n    a[a[\"Attrition\"] == 0][\"EducationField\"].hist(bins=33,color='blue', label='Attrition = NO', alpha=0.6)\n    a[a[\"Attrition\"] == 1][\"EducationField\"].hist(bins=33, color='darkred', label='Attrition = YES', alpha=0.6)\n    plt.legend()\n    plt.grid(False)\n    plt.xlabel(\"EducationField\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col = a.corr().nlargest(20, \"Attrition\").Attrition.index\nplt.figure(figsize=(15, 15))\nsns.heatmap(df[col].corr(), annot=True, cmap=\"RdYlGn\", annot_kws={\"size\":10})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy_col = [column for column in a.drop('Attrition', axis=1).columns if a[column].nunique() < 20]\ndata = pd.get_dummies(a, columns=dummy_col, drop_first=True, dtype='uint8')\ndata.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = data.drop('Attrition', axis=1)\ny = data.Attrition\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state= 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler \nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, classification_report, roc_curve, plot_roc_curve, auc, precision_recall_curve, plot_precision_recall_curve, average_precision_score\nfrom sklearn.model_selection import cross_val_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\nmodels.append(['Logistic Regreesion', LogisticRegression(random_state=0)])\nmodels.append([' DecisionTreeClassifier',  DecisionTreeClassifier(random_state=0)])\nmodels.append(['Random Forest', RandomForestClassifier(random_state=0)])\nlst_1= []\n\nfor m in range(len(models)):\n    lst_2= []\n    model = models[m][1]\n    model.fit(x_train, y_train)\n    y_pred = model.predict(x_test)\n    cm = confusion_matrix(y_test, y_pred)  #Confusion Matrix\n    accuracies = cross_val_score(estimator = model, X = x_train, y = y_train, cv = 10)   #K-Fold Validation\n    roc = roc_auc_score(y_test, y_pred)  #ROC AUC Score\n    precision = precision_score(y_test, y_pred)  #Precision Score\n    recall = recall_score(y_test, y_pred)  #Recall Score\n    f1 = f1_score(y_test, y_pred)  #F1 Score\n   \n    \n    print(models[m][0],':')\n    print(cm)\n    print('Accuracy Score: ',accuracy_score(y_test, y_pred))\n    print('')\n    print(\"K-Fold Validation Mean Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n    print('')\n    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n    print('')\n    print('ROC AUC Score: {:.2f}'.format(roc))\n    print('')\n    print('Precision: {:.2f}'.format(precision))\n    print('')\n    print('Recall: {:.2f}'.format(recall))\n    print('')\n    print('F1: {:.2f}'.format(f1))\n    print('-----------------------------------')\n    print('')\n    lst_2.append(models[m][0])\n    lst_2.append((accuracy_score(y_test, y_pred))*100) \n    lst_2.append(accuracies.mean()*100)\n    lst_2.append(accuracies.std()*100)\n    lst_2.append(roc)\n    lst_2.append(precision)\n    lst_2.append(recall)\n    lst_2.append(f1)\n    lst_1.append(lst_2)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\ngrid_models = [(LogisticRegression(),[{'C':[0.25,0.5,0.75,1],'random_state':[0]}]),(RandomForestClassifier(),[{'n_estimators':[100,150,200],'criterion':['gini','entropy'],'random_state':[0]}])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,j in grid_models:\n    grid = GridSearchCV(estimator=i,param_grid = j, scoring = 'accuracy',cv = 10)\n    grid.fit(x_train, y_train)\n    best_accuracy = grid.best_score_\n    best_param = grid.best_params_\n    print('{}:\\nBest Accuracy : {:.2f}%'.format(i,best_accuracy*100))\n    print('Best Parameters : ',best_param)\n    print('')\n    print('----------------')\n    print('')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}