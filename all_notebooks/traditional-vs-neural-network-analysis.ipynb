{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Time-Series Analysis in Python"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/grocery-sales-forecast-weekend-hackathon/Grocery_Sales_ParticipantsData/Train.csv')\ntest = pd.read_csv('/kaggle/input/grocery-sales-forecast-weekend-hackathon/Grocery_Sales_ParticipantsData/Test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"series = train.GrocerySales.values\ntime = np.arange(692, dtype=\"float32\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_series(time, series, format=\"-\", start=0, end=None):\n    plt.plot(time[start:end], series[start:end], format)\n    plt.xlabel(\"Time\")\n    plt.ylabel(\"Value\")\n    plt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplot_series(time, series)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train-Validation Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"split_time = 600\ntime_train = time[:split_time]\nx_train = series[:split_time]\ntime_valid = time[split_time:]\nx_valid = series[split_time:]\nplt.figure(figsize=(10, 6))\nplot_series(time_train, x_train)\nplt.show()\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Forecasting"},{"metadata":{"trusted":true},"cell_type":"code","source":"naive_forecast = series[split_time - 1:-1]\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, naive_forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid, start=0, end=150)\nplot_series(time_valid, naive_forecast, start=1, end=151)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(keras.metrics.mean_squared_error(x_valid, naive_forecast).numpy())\nprint(keras.metrics.mean_absolute_error(x_valid, naive_forecast).numpy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Moving Average Approach"},{"metadata":{"trusted":true},"cell_type":"code","source":"def moving_average_forecast(series, window_size):\n    forecast = []\n    for time in range(len(series) - window_size):\n        forecast.append(series[time:time + window_size].mean())\n    return np.array(forecast)\n\nmoving_avg = moving_average_forecast(series, 30)[split_time - 30:]\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, moving_avg)\n\nprint(keras.metrics.mean_squared_error(x_valid, moving_avg).numpy())\nprint(keras.metrics.mean_absolute_error(x_valid, moving_avg).numpy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Moving Average with differentiation"},{"metadata":{"trusted":true},"cell_type":"code","source":"diff_series = (series[365:] - series[:-365])\ndiff_time = time[365:]\n\nplt.figure(figsize=(10, 6))\nplot_series(diff_time, diff_series)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff_moving_avg = moving_average_forecast(diff_series, 50)[split_time - 365 - 50:]\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, diff_series[split_time - 365:])\nplot_series(time_valid, diff_moving_avg)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff_moving_avg_plus_past = series[split_time - 365:-365] + diff_moving_avg\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, diff_moving_avg_plus_past)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Moving Average with Smooting and Differentiation"},{"metadata":{"trusted":true},"cell_type":"code","source":"diff_moving_avg_plus_smooth_past = moving_average_forecast(series[split_time - 370:-360], 10) + diff_moving_avg\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, diff_moving_avg_plus_smooth_past)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(keras.metrics.mean_squared_error(x_valid, diff_moving_avg_plus_smooth_past).numpy())\nprint(keras.metrics.mean_absolute_error(x_valid, diff_moving_avg_plus_smooth_past).numpy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neural Network with Multiple Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"window_size = 20\nbatch_size = 32\nshuffle_buffer_size = 1000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n    dataset = tf.data.Dataset.from_tensor_slices(series)\n    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n    dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n    dataset = dataset.batch(batch_size).prefetch(1)\n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\nprint(dataset)\nl0 = tf.keras.layers.Dense(1, input_shape=[window_size])\nmodel = tf.keras.models.Sequential([l0])\n\nmodel.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\nmodel.fit(dataset,epochs=100,verbose=0)\n\nprint(\"Layer weights {}\".format(l0.get_weights()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast = []\n\nfor time in range(len(series) - window_size):\n    forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n\nforecast = forecast[split_time-window_size:]\nresults = np.array(forecast)[:, 0, 0]\n\n\nplt.figure(figsize=(10, 6))\n\nplot_series(time_valid, x_valid)\nplot_series(time_valid, results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.sqrt(keras.metrics.mean_squared_error(x_valid, results).numpy()))\nprint(keras.metrics.mean_absolute_error(x_valid, results).numpy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Deep Neural Network with Adam Optimizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.backend.clear_session()\ndataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(10, input_shape=[window_size], activation=\"relu\"), \n    tf.keras.layers.Dense(10, activation=\"relu\"), \n    tf.keras.layers.Dense(1)\n])\n\nmodel.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\nhistory = model.fit(dataset,epochs=100,verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = history.history['loss']\nepochs = range(len(loss))\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = history.history['loss']\nepochs = range(90, len(loss))\nplot_loss = loss[90:]\nprint(plot_loss)\nplt.plot(epochs, plot_loss, 'b', label='Training Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast = []\nfor time in range(len(series) - window_size):\n    forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n\nforecast = forecast[split_time-window_size:]\nresults = np.array(forecast)[:, 0, 0]\n\n\nplt.figure(figsize=(10, 6))\n\nplot_series(time_valid, x_valid)\nplot_series(time_valid, results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.sqrt(keras.metrics.mean_squared_error(x_valid, results).numpy()))\nprint(keras.metrics.mean_absolute_error(x_valid, results).numpy())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus deep neural network thus provides the best RMSE compared to other approaches"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}