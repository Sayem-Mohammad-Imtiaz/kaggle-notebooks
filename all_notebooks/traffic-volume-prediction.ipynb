{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Traffic Volume Prediction\n\nGive some attributes we have to predict the traffic volume.\n\n**There are 9 attributes which represents the following -**\n\n-    **date_time** - DateTime Hour of the data collected in local CST time\n-    **holiday** - Categorical US National holidays plus regional holiday, Minnesota State Fair\n-    **temp** - Numeric Average temp in kelvin\n-    **rain_1h** - Numeric Amount in mm of rain that occurred in the hour\n-    **snow_1h** - Numeric Amount in mm of snow that occurred in the hour\n-    **clouds_all** - Numeric Percentage of cloud cover\n-    **weather_main** - Categorical Short textual description of the current weather\n-    **weather_description** - Categorical Longer textual description of the current weather\n-    **traffic_volume** - Numeric Hourly I-94 ATR 301 reported westbound traffic volume (Target)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import all required libraries for reading, analysing and visualizing data\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom math import sqrt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/metro-traffic-volume/Metro_Interstate_Traffic_Volume.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Dataset shape: ', train_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe(include = 'all')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"train_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert the date_time column to datetime type\ntrain_df['date_time'] = pd.to_datetime(train_df['date_time'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Time vs Traffic Volume"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['time'] = train_df['date_time'].dt.hour","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (axis1,axis2) = plt.subplots(2, 1, figsize = (20,12))\nsns.countplot(x = 'time', data = train_df, ax = axis1)\nsns.lineplot(x = 'time', y = 'traffic_volume', data = train_df, ax = axis2);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus we can infer that traffic is much higher in morning and noon time and gradually decreases as night progresses."},{"metadata":{},"cell_type":"markdown","source":"### Month vs Traffic Volume"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['month'] = train_df['date_time'].dt.month","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, (axis1,axis2) = plt.subplots(2, 1, figsize = (20,12))\nsns.countplot(x = 'month', data = train_df, ax = axis1)\nsns.lineplot(x = 'month', y = 'traffic_volume', data = train_df, ax = axis2);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus we can see that in the months when its cold, the traffic volume decreases is slightly less."},{"metadata":{},"cell_type":"markdown","source":"### Year vs Traffic Volume"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['year'] = train_df['date_time'].dt.year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (axis1,axis2) = plt.subplots(1, 2, figsize = (20,6))\nsns.countplot(x = 'year', data = train_df, ax = axis1)\nsns.lineplot(x = 'year', y = 'traffic_volume', data = train_df, ax = axis2);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Day vs Traffic Volume"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['day'] = train_df['date_time'].dt.day_name()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (axis1,axis2) = plt.subplots(1, 2, figsize = (20,6))\nsns.countplot(x = 'day', data = train_df, ax = axis1)\nsns.lineplot(x = 'day', y = 'traffic_volume', data = train_df, ax = axis2);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Holiday vs Traffic Volume"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train_df['holiday'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z = lambda x: False if x == 'None' else True\ntrain_df['holiday'] = train_df['holiday'].apply(z)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, (axis1,axis2) = plt.subplots(1, 2, figsize = (20,6))\nsns.countplot(x = 'holiday', data = train_df, ax = axis1)\nsns.barplot(x = 'holiday', y = 'traffic_volume', data = train_df, ax = axis2);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus from the above plots we can see that traffic on holidays is usually less than traffic on non holidays."},{"metadata":{},"cell_type":"markdown","source":"### Temperature vs Traffic Volume"},{"metadata":{"trusted":true},"cell_type":"code","source":"(train_df['temp'] == 0).sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the temperature can't be 0 kelvin therefore these are outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df[train_df['temp'] != 0]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sns.scatterplot(x = 'temp', y = 'traffic_volume', data = train_df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Rain vs Traffic Volume"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"(train_df['rain_1h'] > 100).sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Therefore there is an outlier and we have to remove it."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df[train_df.rain_1h < 100]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"sns.scatterplot(x = 'rain_1h', y = 'traffic_volume', data = train_df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Snow vs Traffic Volume"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x = 'snow_1h', y = 'traffic_volume', data = train_df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clouds vs Traffic Volume"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x = 'clouds_all', y = 'traffic_volume', data = train_df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Short Weather Description vs Traffic Volume"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, (axis1,axis2) = plt.subplots(2, 1, figsize = (16,12))\nsns.countplot(x = 'weather_main', data = train_df, ax = axis1)\nsns.lineplot(x = 'weather_main', y = 'traffic_volume', data = train_df, ax = axis2);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Long Weather Description vs Traffic Volume"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['weather_description'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,6))\nsns.lineplot(x = 'weather_description', y = 'traffic_volume', data = train_df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can see from the values of the column that it contains long description of the weather_main column, so we can drop it."},{"metadata":{},"cell_type":"markdown","source":"### Correlation between features"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nplt.title('Correlation between features')\nsns.heatmap(train_df.corr(), annot = True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see from the above heatmap that features are not coorelated."},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop the unrequired columns\ntrain_df.drop(['date_time', 'weather_description'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert values of day column to numerical format\nencoder = LabelEncoder()\ntrain_df['day'] = encoder.fit_transform(train_df['day'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# subtract 242 from the temp column as there is no temperature below it\ntrain_df['temp'] = train_df['temp'] - 242","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert the values of weather_main column to numerical format\nencoder = LabelEncoder()\ntrain_df['weather_main'] = encoder.fit_transform(train_df['weather_main'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Machine Learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the required modules\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor \nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(X, Y) = (train_df.drop(['traffic_volume'], axis = 1).values, train_df['traffic_volume'].values)\n\n# Scale the values\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n(X_train, X_val, Y_train, Y_val) = train_test_split(X, Y)\nprint(\"X_train shape:\" + str(X_train.shape))\nprint(\"Y_train shape:\" + str(Y_train.shape))\nprint(\"X_val shape:\" + str(X_val.shape))\nprint(\"Y_val shape:\" + str(Y_val.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DataFrame to store the RMSE scores of various algorithms\nresults = pd.DataFrame(columns = ['RMSE'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# helper function to evaluate a model\ndef evaluate_model(regressor, name):\n    # train and test scores\n    train_score = round(regressor.score(X_train, Y_train), 2)\n    val_score = round(regressor.score(X_val, Y_val), 2)\n    # predicted output\n    Y_pred = regressor.predict(X_val)\n\n    print(name + ' Train score: ', train_score)\n    print(name + 'Test score: ', val_score)\n    print('Root Mean Squared error: ', sqrt(mean_squared_error(Y_val, Y_pred)))\n    print('Coefficient of determination: ', r2_score(Y_val, Y_pred))\n    \n    # add the current RMSE to the scores list\n    results.loc[name] = sqrt(mean_squared_error(Y_val, Y_pred))\n    \n    # plot predicted vs true values\n    x_points=np.linspace(0,8e3)\n    plt.figure(figsize=(12,5))\n    plt.plot(x_points, x_points, color='r')\n    plt.scatter(Y_val, Y_pred)\n    plt.xlabel('True Values')\n    plt.ylabel('Predicted Values')\n    plt.title('True Values Vs Predicted Values');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"lireg = LinearRegression()\nlireg.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate the Regressor\nevaluate_model(lireg, 'Linear Regression')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using Decision Tree Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtreg = DecisionTreeRegressor(max_depth = 12)\ndtreg.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate the Regressor\nevaluate_model(dtreg, 'Decision Tree')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using Random Forest Regressor"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# n_estimators - The number of trees in the forest.\n# min_samples_split - The minimum number of samples required to split an internal node\nrfreg = RandomForestRegressor(n_estimators = 50, max_depth = 12, min_samples_split = 5)\nrfreg.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate the Regressor\nevaluate_model(rfreg, 'Random Forest')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using Gradient Boosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"# n_estimators - The number of boosting stages to perform.\n# max_depth - maximum depth of the individual regression estimators.\ngbreg = GradientBoostingRegressor(n_estimators=500, max_depth=10)\ngbreg.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate the Regressor\nevaluate_model(gbreg, 'Gradient Boosting')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using AdaBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"# n_estimators - The number of trees in the forest.\n# learning_rate - Learning rate shrinks the contribution of each classifier by learning_rate.\nadareg = AdaBoostRegressor(base_estimator=dtreg, n_estimators=50, learning_rate=0.01)\nadareg.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate the Regressor\nevaluate_model(adareg, 'Ada Boost')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Comparison between all the above algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus we can see that **Gradient Boosting** provide the least RMSE, therefore we will use it to compute the outputs."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(gbreg.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above plot shows that time and da are the most important features."},{"metadata":{},"cell_type":"markdown","source":"### Neural Networks using Keras"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def nn_model ():\n    model = Sequential()\n    model.add(Dense(128, input_dim=10, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, kernel_initializer='normal'))\n\n    model.compile(loss='mean_squared_error', optimizer='adam')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator = KerasRegressor(build_fn=nn_model, epochs=10, batch_size=5, verbose=0)\nkfold = KFold(n_splits=10)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"estimator.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicted output\nY_pred_nn = estimator.predict(X_val)\n\nprint('Root Mean Squared error: ', sqrt(mean_squared_error(Y_val, Y_pred_nn)))\nprint('Coefficient of determination: ', r2_score(Y_val, Y_pred_nn))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}