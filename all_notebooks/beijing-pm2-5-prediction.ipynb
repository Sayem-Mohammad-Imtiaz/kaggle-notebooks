{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/beijing-pm25-data-data-set/PRSA_data_2010.1.1-2014.12.31.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['pm2.5'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop the rows directly -> mess up the order\n# first 24 rows have pm2.5 value that is NaN -> discard\n# else: forward filling\ndf = df[24:].fillna(method='ffill')\ndf['pm2.5'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n\ndf['time'] = df.apply(lambda x : datetime.datetime(year=x['year'], month=x['month'], day=x['day'], hour=x['hour']), axis=1)\ndf.drop(columns=['year', 'month', 'day', 'hour', 'No'], inplace=True)\ndf = df.set_index('time')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['cbwd'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.join(pd.get_dummies(df['cbwd'])) # one-hot encoding\ndel df['cbwd']\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['pm2.5'][-1000:].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['TEMP'][-1000:].plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Determine Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"seq_len = 5*24 # observe the data for the past 5 days\ndelay = 1*24 # predict the PM2.5 value one day after\n\ndf_ = np.array([df.iloc[i : i + seq_len + delay].values for i in range(len(df) - seq_len - delay)])\ndf_.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.shuffle(df_)\nx = df_[:, :5*24, :]\ny = df_[:, -1, 0]\nx.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split & Normalize the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"split = int(y.shape[0]*0.8)\ntrain_x = x[:split]\ntrain_y = y[:split]\ntest_x = x[split:]\ntest_y = y[split:]\n\nmean = train_x.mean(axis=0)\nstd = train_x.std(axis=0)\ntrain_x = (train_x - mean) / std\ntest_x = (test_x - mean) / std # Use the mean & std of train. Since there's no way for us to know the future.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x.shape, test_x.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Start by Trying a Simple Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.Sequential()\nmodel.add(layers.Flatten(input_shape=(120, 11)))\nmodel.add(layers.Dense(32, activation='relu'))\nmodel.add(layers.Dense(1)) # Regression -> No Need for Activation\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='mse', metrics=['mae'])\nhistory = model.fit(train_x, train_y, batch_size=128, epochs=50, validation_data=(test_x, test_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.epoch, history.history['mae'], c='m')\nplt.plot(history.epoch, history.history['val_mae'], c='c')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build LSTM Model (Single-Layer)\n\n(34924, 120, 11) -> (batch, time for observation, features per observation)"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.Sequential()\nmodel.add(layers.LSTM(32, input_shape=(120, 11)))\nmodel.add(layers.Dense(1))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='mae')\nhistory = model.fit(train_x, train_y, batch_size=128, epochs=150, validation_data=(test_x, test_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.epoch, history.history['loss'], c='m')\nplt.plot(history.epoch, history.history['val_loss'], c='c')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build LSTM Model (Multi-Layer)\nReturn the state info to feed back to the second LSTM layer\n\nUse callbacks to decrease learning rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.Sequential()\nmodel.add(layers.LSTM(32, input_shape=(120, 11), return_sequences=True)) \nmodel.add(layers.LSTM(32, return_sequences=True)) \nmodel.add(layers.LSTM(32)) \nmodel.add(layers.Dense(1))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_reduced = keras.callbacks.ReduceLROnPlateau('val_loss', patience=3, factor=0.5, min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='mae')\nhistory = model.fit(train_x, train_y, batch_size=128, epochs=150, validation_data=(test_x, test_y), callbacks=[lr_reduced])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.epoch, history.history['loss'], c='m')\nplt.plot(history.epoch, history.history['val_loss'], c='c')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation & Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(test_x, test_y, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predict = model.predict(test_x)\ntest_x.shape, test_predict.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predict[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = df[-120:]\ntest_data = (test_data - mean)/std\ntest_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = np.expand_dims(test_data, axis=0)\ntest_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict(test_data) # 2015.1.1 11pm pM2.5","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}