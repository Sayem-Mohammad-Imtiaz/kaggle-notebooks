{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### UNet, resnet34","metadata":{}},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:06:21.05006Z","iopub.execute_input":"2021-06-28T21:06:21.050438Z","iopub.status.idle":"2021-06-28T21:06:28.353729Z","shell.execute_reply.started":"2021-06-28T21:06:21.05035Z","shell.execute_reply":"2021-06-28T21:06:28.352774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install segmentation_models_pytorch","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:07:14.196145Z","iopub.execute_input":"2021-06-28T21:07:14.196467Z","iopub.status.idle":"2021-06-28T21:07:24.209289Z","shell.execute_reply.started":"2021-06-28T21:07:14.196437Z","shell.execute_reply":"2021-06-28T21:07:24.208428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torchsummary import summary\nfrom torchvision import models, transforms, datasets\nfrom torch.utils.data import Dataset, DataLoader\nimport segmentation_models_pytorch as smp\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport os\n\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:07:25.565034Z","iopub.execute_input":"2021-06-28T21:07:25.56538Z","iopub.status.idle":"2021-06-28T21:07:27.596432Z","shell.execute_reply.started":"2021-06-28T21:07:25.565347Z","shell.execute_reply":"2021-06-28T21:07:27.595595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:07:28.227213Z","iopub.execute_input":"2021-06-28T21:07:28.227538Z","iopub.status.idle":"2021-06-28T21:07:28.279797Z","shell.execute_reply.started":"2021-06-28T21:07:28.227506Z","shell.execute_reply":"2021-06-28T21:07:28.27862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/makeup-lips-segmentation-28k-samples/set-lipstick-original/list.csv')\ndata","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:08:03.658688Z","iopub.execute_input":"2021-06-28T21:08:03.659061Z","iopub.status.idle":"2021-06-28T21:08:03.753195Z","shell.execute_reply.started":"2021-06-28T21:08:03.65903Z","shell.execute_reply":"2021-06-28T21:08:03.7525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGES_PATH = '../input/makeup-lips-segmentation-28k-samples/set-lipstick-original/720p/'\nMASKS_PATH = '../input/makeup-lips-segmentation-28k-samples/set-lipstick-original/mask/'","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:09:11.76538Z","iopub.execute_input":"2021-06-28T21:09:11.765702Z","iopub.status.idle":"2021-06-28T21:09:11.770144Z","shell.execute_reply.started":"2021-06-28T21:09:11.765672Z","shell.execute_reply":"2021-06-28T21:09:11.769041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = os.listdir(IMAGES_PATH)\nmask = os.listdir(MASKS_PATH)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:09:12.074767Z","iopub.execute_input":"2021-06-28T21:09:12.075049Z","iopub.status.idle":"2021-06-28T21:09:12.101403Z","shell.execute_reply.started":"2021-06-28T21:09:12.075022Z","shell.execute_reply":"2021-06-28T21:09:12.100745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Нужно удалить лишние файлы, кусок кода взят из ноутбука: Lips Segmentation LinkNet PyTorch","metadata":{}},{"cell_type":"code","source":"imgs_set = set(os.listdir(IMAGES_PATH))\nmasks_set = set(os.listdir(MASKS_PATH))\n\nimgs_set = set(''.join(filter(lambda x: x.isdigit(), i)) for i in imgs_set)\nmasks_set = set(''.join(filter(lambda x: x.isdigit(), i)) for i in masks_set)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:10:46.898648Z","iopub.execute_input":"2021-06-28T21:10:46.899012Z","iopub.status.idle":"2021-06-28T21:10:47.058712Z","shell.execute_reply.started":"2021-06-28T21:10:46.898981Z","shell.execute_reply":"2021-06-28T21:10:47.057823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(imgs_set.difference(masks_set)), len(masks_set.difference(imgs_set))","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:10:47.140188Z","iopub.execute_input":"2021-06-28T21:10:47.140453Z","iopub.status.idle":"2021-06-28T21:10:47.151218Z","shell.execute_reply.started":"2021-06-28T21:10:47.140426Z","shell.execute_reply":"2021-06-28T21:10:47.150486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"not_mask = imgs_set.difference(masks_set)\n\nnot_mask = [f'image{i}.jpg' for i in not_mask]\n\ndata = data.loc[~data['filename'].isin(not_mask)]\ndata.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:10:47.92639Z","iopub.execute_input":"2021-06-28T21:10:47.926713Z","iopub.status.idle":"2021-06-28T21:10:47.940362Z","shell.execute_reply.started":"2021-06-28T21:10:47.926683Z","shell.execute_reply":"2021-06-28T21:10:47.939094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Создадим класс для кастомного датасета:","metadata":{}},{"cell_type":"code","source":"SIZE = 256\nclass Pixel_Perfect_Lips_Segmentation(Dataset):\n    \n    def __init__(self, data, preprocessing=None):\n        self.data = data\n\n        self.data_len = len(self.data.index)\n        \n        self.preprocessing = preprocessing\n    \n    def __getitem__(self, idx):\n        data = self.data.iloc[idx]\n        img_path = os.path.join(IMAGES_PATH, data['filename'])\n        mask_path = os.path.join(MASKS_PATH, data['mask'])\n        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_RGB2BGR)\n        img = cv2.resize(img, (SIZE, SIZE))\n        img = np.array(img).astype('float')\n        \n        mask = cv2.cvtColor(cv2.imread(mask_path), cv2.COLOR_RGB2BGR)\n        mask = cv2.resize(mask, (SIZE, SIZE))\n        mask = np.array(mask).astype('float')\n        mask = torch.as_tensor(mask)\n        \n        if self.preprocessing:\n            img = self.preprocessing(img)\n            img = torch.as_tensor(img)\n            mask = self.preprocessing(mask)\n            mask = torch.as_tensor(mask)\n            \n            \n        else:\n            img = torch.as_tensor(img) / 255.0\n            mask = torch.as_tensor(mask) / 255.0\n       \n        img = img.permute(2,0,1)\n        mask = mask.permute(2,0,1)\n\n        \n        return (img.float(), mask) #s)\n    \n    def __len__(self):\n        return self.data_len","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:11:05.36821Z","iopub.execute_input":"2021-06-28T21:11:05.368542Z","iopub.status.idle":"2021-06-28T21:11:05.38517Z","shell.execute_reply.started":"2021-06-28T21:11:05.368508Z","shell.execute_reply":"2021-06-28T21:11:05.384212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = Pixel_Perfect_Lips_Segmentation(data)\nimg, masks = dataset[777]\nprint(img.shape, masks.shape)\nfig, ax = plt.subplots(1, 2, figsize=(15, 7))\nax[0].imshow(img.permute(1, 2, 0))\nax[1].imshow(masks.permute(1, 2, 0))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:11:25.989336Z","iopub.execute_input":"2021-06-28T21:11:25.989674Z","iopub.status.idle":"2021-06-28T21:11:26.527229Z","shell.execute_reply.started":"2021-06-28T21:11:25.989642Z","shell.execute_reply":"2021-06-28T21:11:26.526405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 80 % в тренировочную выборку, 20 - в тестовую\ntrain, test = train_test_split(data, test_size=0.2, random_state=9)\n\n# Упорядочиваем индексацию\ntrain.reset_index(drop=True, inplace=True)\ntest.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:11:35.788455Z","iopub.execute_input":"2021-06-28T21:11:35.788805Z","iopub.status.idle":"2021-06-28T21:11:35.801985Z","shell.execute_reply.started":"2021-06-28T21:11:35.788772Z","shell.execute_reply":"2021-06-28T21:11:35.801052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:11:42.036817Z","iopub.execute_input":"2021-06-28T21:11:42.037157Z","iopub.status.idle":"2021-06-28T21:11:42.045561Z","shell.execute_reply.started":"2021-06-28T21:11:42.037128Z","shell.execute_reply":"2021-06-28T21:11:42.044601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Оборачиваем каждую выборку в наш кастомный датасет:","metadata":{}},{"cell_type":"code","source":"train_dataset = Pixel_Perfect_Lips_Segmentation(train)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:12:53.97013Z","iopub.execute_input":"2021-06-28T21:12:53.970456Z","iopub.status.idle":"2021-06-28T21:12:53.974826Z","shell.execute_reply.started":"2021-06-28T21:12:53.970424Z","shell.execute_reply":"2021-06-28T21:12:53.973892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = Pixel_Perfect_Lips_Segmentation(test)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:12:54.329251Z","iopub.execute_input":"2021-06-28T21:12:54.329532Z","iopub.status.idle":"2021-06-28T21:12:54.334584Z","shell.execute_reply.started":"2021-06-28T21:12:54.329505Z","shell.execute_reply":"2021-06-28T21:12:54.333501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_loader = DataLoader(\n    train_dataset,\n    batch_size=24,\n    shuffle=True\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:12:54.658526Z","iopub.execute_input":"2021-06-28T21:12:54.658842Z","iopub.status.idle":"2021-06-28T21:12:54.664868Z","shell.execute_reply.started":"2021-06-28T21:12:54.658813Z","shell.execute_reply":"2021-06-28T21:12:54.663892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_loader = DataLoader(\n    test_dataset,\n    batch_size=8,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:12:55.010447Z","iopub.execute_input":"2021-06-28T21:12:55.010824Z","iopub.status.idle":"2021-06-28T21:12:55.016425Z","shell.execute_reply.started":"2021-06-28T21:12:55.010785Z","shell.execute_reply":"2021-06-28T21:12:55.015332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for img, target in train_data_loader:\n    print(img.shape, target.shape)\n    print(img[0].min(), img[0].max())\n    print(target[0].min(), target[0].max())\n    fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n    ax[0].imshow(img[0].permute(1, 2, 0))\n    ax[1].imshow(target[0].permute(1, 2, 0))\n    break","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:12:56.764264Z","iopub.execute_input":"2021-06-28T21:12:56.764593Z","iopub.status.idle":"2021-06-28T21:12:58.302421Z","shell.execute_reply.started":"2021-06-28T21:12:56.764554Z","shell.execute_reply":"2021-06-28T21:12:58.30147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# aux_params_1=dict(\n#     pooling='max',             # one of 'avg', 'max'\n#     dropout=0.5,               # dropout ratio, default is None\n#     activation='sigmoid',      # activation function, default is None\n#     classes=1,                 # define number of output labels\n# )","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:13:10.605119Z","iopub.execute_input":"2021-06-28T21:13:10.605455Z","iopub.status.idle":"2021-06-28T21:13:10.608985Z","shell.execute_reply.started":"2021-06-28T21:13:10.605422Z","shell.execute_reply":"2021-06-28T21:13:10.607887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# создание модели, как праваильно добавить aux? Постоянно ошибка TypeError: only integer tensors of a single element can be converted to an index\nBACKBONE = 'resnet34'\nsegmodel = smp.Unet(BACKBONE, classes=1, activation='sigmoid').to(device) # , aux_params=aux_params_1).to(device)\npreprocess_input = smp.encoders.get_preprocessing_fn(BACKBONE, pretrained='imagenet')","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:13:17.334705Z","iopub.execute_input":"2021-06-28T21:13:17.335073Z","iopub.status.idle":"2021-06-28T21:13:31.529712Z","shell.execute_reply.started":"2021-06-28T21:13:17.335041Z","shell.execute_reply":"2021-06-28T21:13:31.5289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"После препроцессинга resnet34:","metadata":{}},{"cell_type":"code","source":"dataset = Pixel_Perfect_Lips_Segmentation(data, preprocessing=preprocess_input)\nimg, masks = dataset[9]\nprint(img.shape, masks.shape)\nfig, ax = plt.subplots(1, 2, figsize=(15, 7))\nax[0].imshow(img[0])#.permute(1, 2, 0))\nax[1].imshow(masks[0])#.permute(1, 2, 0))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:14:21.156454Z","iopub.execute_input":"2021-06-28T21:14:21.156796Z","iopub.status.idle":"2021-06-28T21:14:21.502881Z","shell.execute_reply.started":"2021-06-28T21:14:21.156763Z","shell.execute_reply":"2021-06-28T21:14:21.501912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for img, target in train_data_loader:\n    print(img.shape, target.shape)\n    print(img[0].min(), img[0].max())\n    print(target[0].min(), target[0].max())\n    break","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:13:40.094633Z","iopub.execute_input":"2021-06-28T21:13:40.094981Z","iopub.status.idle":"2021-06-28T21:13:41.018376Z","shell.execute_reply.started":"2021-06-28T21:13:40.094947Z","shell.execute_reply":"2021-06-28T21:13:41.017523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = smp.utils.losses.DiceLoss()\nmetrics = [smp.utils.metrics.IoU(),]\n\noptimizer = torch.optim.Adam(params=segmodel.parameters(), lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:14:54.646372Z","iopub.execute_input":"2021-06-28T21:14:54.646717Z","iopub.status.idle":"2021-06-28T21:14:54.654816Z","shell.execute_reply.started":"2021-06-28T21:14:54.646685Z","shell.execute_reply":"2021-06-28T21:14:54.653802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# it is a simple loop of iterating over dataloader`s samples\ntrain_epoch = smp.utils.train.TrainEpoch(\n    segmodel, \n    loss=criterion, \n    metrics=metrics, \n    optimizer=optimizer,\n    device=device,\n    verbose=True,\n)\n\nvalid_epoch = smp.utils.train.ValidEpoch(\n    segmodel, \n    loss=criterion, \n    metrics=metrics, \n    device=device,\n    verbose=True,\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-28T21:15:00.607276Z","iopub.execute_input":"2021-06-28T21:15:00.607616Z","iopub.status.idle":"2021-06-28T21:15:00.621856Z","shell.execute_reply.started":"2021-06-28T21:15:00.607583Z","shell.execute_reply":"2021-06-28T21:15:00.62085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model\n\nmax_score = 0\n\nfor i in range(0, 1):\n    print(f'Epoch: {i + 1}')\n    train_logs = train_epoch.run(train_data_loader)\n    valid_logs = valid_epoch.run(test_data_loader)\n    \n    # do something (save model, change lr, etc.)\n    if max_score < valid_logs['iou_score']:\n        max_score = valid_logs['iou_score']\n        torch.save(segmodel, './best_model.pth')\n        print('Model saved!')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_orig(image):\n    image = image.permute(1, 2, 0)\n    image = image.numpy()\n    image = np.clip(image, 0, 1)\n    return image","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, data in enumerate(test_data_loader):\n    images, labels = data\n    images = images.to(device)\n    labels = labels.to(device)\n    segmodel.eval()\n    outputs = segmodel(images)\n    f, axarr = plt.subplots(1,3, figsize=(15, 6))\n\n    for j in range(0, 4):\n        axarr[0].imshow(outputs.squeeze().detach().cpu().numpy()[j,:,:])\n        axarr[0].set_title('Guessed labels')\n        axarr[1].imshow(labels.squeeze().detach().cpu().numpy()[j,:, :].transpose(1,2,0))\n        axarr[1].set_title('Ground truth labels')\n\n        original = get_orig(images[j].cpu())\n        axarr[2].imshow(original)\n        axarr[2].set_title('Original Images')\n        plt.show()\n    if i > 3:\n        break","metadata":{},"execution_count":null,"outputs":[]}]}