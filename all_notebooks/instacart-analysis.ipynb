{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datetime as dt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"trainFileName = '../input/train_trips.csv'\norderFileName = '../input/order_items.csv'\ntestFileName = '../input/test_trips.csv'\n##read raw training data\nrawTrainData = pd.read_csv(trainFileName,parse_dates=['shopping_started_at','shopping_ended_at'])\nrawTestData = pd.read_csv(testFileName,parse_dates=['shopping_started_at'])\n#read order information\norderData = pd.read_csv(orderFileName,index_col = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"642e97c871c5a02a8305eca506093a8be845c2bf"},"cell_type":"code","source":"rawTrainData['shopping_trip_time'] = rawTrainData['shopping_ended_at'] - rawTrainData['shopping_started_at']\nrawTrainData['shopping_trip_time']=pd.to_timedelta(rawTrainData['shopping_trip_time']).dt.total_seconds()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6f48353be4f3e68d3fae93392e70b1b58ff10f1"},"cell_type":"code","source":"# merge train data with order data\nallTrainData = rawTrainData\nallTrainData = allTrainData.merge(orderData,how='left',on='trip_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1bbde281dc9bce56db4ed5c556367538ebe4cfc4"},"cell_type":"code","source":"newTrainData = allTrainData.groupby(['trip_id','store_id','department_name','item_id','fulfillment_model','shopping_started_at']).agg({'quantity':np.sum,'shopping_trip_time':np.mean,'shopper_id':np.mean}).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c19b7e27beb704fff9e5a03a164df856c84f4711"},"cell_type":"code","source":"byShopperIdAverageShoppingTime = newTrainData.groupby(['shopper_id']).agg({'shopping_trip_time':np.mean}).reset_index()\nbyStoreIdAverageShoppingTime = newTrainData.groupby(['store_id']).agg({'shopping_trip_time':np.mean}).reset_index()\nbyTripIdAverageShoppingTime = newTrainData.groupby(['trip_id','store_id','shopper_id','shopping_started_at']).agg({'shopping_trip_time':np.mean,'quantity': np.sum,'department_name': 'nunique'}).reset_index().rename(columns = {'department_name':'num_dept_visited'})\nprint(byTripIdAverageShoppingTime.head(100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"289c8c35806a9ae4d336ad79fee973fa3343ac3b"},"cell_type":"code","source":"#learnings from average shopping time by trip id - the orders data mentions quantity but in some cases the quantity is a \n#fraction. Let us include these fractions in our initial model and then omit them to see if there is an improvement in\n#performance as quantity does not seem to a normalized measure. The fractions might be weight of the product as pounds.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16031f8f45fe5fef152881cbce9ec3ef58665306"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib\nimport matplotlib.dates as mdates","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85b8ab363c6435efc5bdf7148cbd5a0e2fbdb9fc"},"cell_type":"code","source":"p1 = plt.scatter(byShopperIdAverageShoppingTime['shopper_id'], byShopperIdAverageShoppingTime['shopping_trip_time'], 0.4)\nplt.ylabel('average shopping time')\nplt.xlabel('shopper_id')\nplt.title('average shopping time by shopper id')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"020dac02f5e8f4096ce66cbb7859c6984f0d5c89"},"cell_type":"code","source":"p2 = plt.bar(byStoreIdAverageShoppingTime['store_id'], byStoreIdAverageShoppingTime['shopping_trip_time'], 1)\nplt.ylabel('average shopping time')\nplt.xlabel('store_id')\nplt.title('average shopping time by store id')\nplt.show()\n\n#average shopping time in some stores is much lower than in other stores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8888b0154650dd62cc9041b6c8a1c4df3d883a9a"},"cell_type":"code","source":"# does fractional quantities - quantities where weights need to be measured impact shopping time? Intuition says it should\n# let us see if our intuition is correct.\ntempVal = pd.to_numeric(byTripIdAverageShoppingTime['quantity'])\ntempVal_rounds = tempVal.round()\ntempVal_ints = tempVal[tempVal_rounds == tempVal]\ntempVal_floats = tempVal[tempVal_rounds != tempVal]\nfractionalIdx =tempVal_floats.index.values\nfraction_averageShoppingTime = byTripIdAverageShoppingTime.iloc[fractionalIdx]\nnonFraction_averageShoppingTime = byTripIdAverageShoppingTime.iloc[tempVal_ints.index.values]\nbyStore_fraction_averageShoppingTime = fraction_averageShoppingTime.groupby(['store_id']).agg({'shopping_trip_time':np.mean}).reset_index()\nbyStore_non_fraction_averageShoppingTime = nonFraction_averageShoppingTime.groupby(['store_id']).agg({'shopping_trip_time':np.mean}).reset_index()\n\nfig = plt.figure()\nax1 = fig.add_subplot(111)\n\nax1.plot(byStore_fraction_averageShoppingTime['store_id'], byStore_fraction_averageShoppingTime['shopping_trip_time'], c='b', marker=\"s\", label='Fractional Quantity')\nax1.plot(byStore_non_fraction_averageShoppingTime['store_id'],byStore_non_fraction_averageShoppingTime['shopping_trip_time'], c='r', marker=\"o\", label='Non Fractional Quantity')\nplt.legend(loc='lower left');\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afc134fd43fc8b0141ade6eaa609bb536c19cea1"},"cell_type":"code","source":"# from the above plots our intuition that when there are fractional quantities like product weights then the shopping time\n# does increase. the data needs to be cleansed and we can build our models for fractional quantities and non fractional quantities\n# before combining the predicted shopping duration (a weighted average) for the shopping durations.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fadbf5b8ede2d5571abbd880ad6801498437a997"},"cell_type":"code","source":"finalTrainData = newTrainData.groupby(['trip_id','store_id','department_name']).agg({'quantity':np.sum,'shopping_trip_time':np.mean,'shopper_id':np.mean,'item_id':'nunique'}).reset_index()\nfinalTrainData = finalTrainData.rename(columns = {'item_id':'num_item_department'})\ndepartmentDf = finalTrainData[['trip_id','department_name']]\nuniqueDepartments = finalTrainData['department_name'].unique()\nuniqueTripIds = finalTrainData['trip_id'].unique()\npivotTrainData_department = pd.pivot_table(finalTrainData,columns = ['department_name'],values=['quantity'],index='trip_id')\npivotTrainData_department = pivotTrainData_department.fillna(0)\npivotTrainData_numItems = pd.pivot_table(finalTrainData,columns = ['department_name'],values=['num_item_department'],index='trip_id')\npivotTrainData_numItems = pivotTrainData_numItems.fillna(0)\npivotTrainData = pd.concat([pivotTrainData_department,pivotTrainData_numItems],axis = 1)\nflat_pivotData = pd.DataFrame(pivotTrainData.to_records())\nflat_pivotData.columns = [hdr.replace(\"('num_item_department', '\", \"num_item_dept.\").replace(\"')\", \"\") for hdr in flat_pivotData.columns]\nflat_pivotData.columns = [hdr.replace(\"('num_item_department',\", \"num_item_dept.\").replace(\")\", \"\") for hdr in flat_pivotData.columns]\nflat_pivotData.columns = [hdr.replace(\"('quantity', '\", \"quantity.\").replace(\"')\", \"\") for hdr in flat_pivotData.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0683fa1b22b4775874667f7b22435a68669bb72b"},"cell_type":"code","source":"AllTrainData = pd.concat([byTripIdAverageShoppingTime,flat_pivotData],axis = 1)\nAllTrainData = AllTrainData.iloc[:,~AllTrainData.columns.duplicated()]\nAllTrainData['day_of_week'] = AllTrainData['shopping_started_at'].dt.dayofweek\nAllTrainData['date'] = AllTrainData['shopping_started_at'].dt.date\nAllTrainData['hour'] = AllTrainData['shopping_started_at'].dt.hour\ncollapsedTrainData = AllTrainData[['shopper_id','store_id','date','hour','day_of_week','quantity','shopping_trip_time','num_dept_visited']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fad8bfc4975f6dcfb5d18275db2388663fd28a09"},"cell_type":"code","source":"tempDF1 = collapsedTrainData.groupby('hour').agg({'quantity':np.mean,'shopping_trip_time':np.mean}).reset_index()\nfig = plt.figure()\nax1 = fig.add_subplot(111)\nax1.plot(tempDF1['hour'], tempDF1['quantity'], c='b', label='Average Quantity By hour')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00561bd5a6661ccecd3a20e7d145cc4c356fbb91"},"cell_type":"code","source":"fig = plt.figure()\nax1 = fig.add_subplot(111)\nax1.plot(tempDF1['hour'], tempDF1['shopping_trip_time'], c='b', label='Average Time By hour')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa68705dd93f5724c10ed240327ac00219577dff"},"cell_type":"code","source":"tempDF = AllTrainData[['day_of_week','quantity','shopping_trip_time']]\ntempDF1 = tempDF.groupby('day_of_week').agg({'quantity':np.mean,'shopping_trip_time':np.mean}).reset_index()\nfig = plt.figure()\nax1 = fig.add_subplot(111)\nax1.plot(tempDF1['day_of_week'], tempDF1['quantity'], c='b', label='Average Quantity By Day of week')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0bd46bb9c70fa3262a630f1407fbfd4e427d899"},"cell_type":"code","source":"fig = plt.figure()\nax1 = fig.add_subplot(111)\nax1.plot(tempDF1['day_of_week'], tempDF1['shopping_trip_time'], c='b', label='Average shopping_trip_time By day of week')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35a17f3d7118b1d6dfcf177d86b26da88329c5df"},"cell_type":"code","source":"y = AllTrainData['shopping_trip_time'].values\n#X = collapsedTrainData[['shopper_id','store_id','hour','day_of_week','quantity','num_dept_visited']]\nX = AllTrainData.drop(['shopping_trip_time','trip_id','shopping_started_at','date'],axis=1)\nprint(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2924853cf63ea96081c44640b69adae5b88d8e53"},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_val,y_train,y_val = train_test_split(X,y,test_size = 0.25)\nreg = LinearRegression().fit(X_train,y_train)\nprint('The coefficients for this linear fit are: ',reg.coef_) \nprint('The intercept for this linear fit are: ', reg.intercept_) \nprint('The score on test data for least squares regression is: ', reg.score(X_val,y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"103be829f03f44f90f7828f68e0092bd9267d8e5"},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nGBRegressor = GradientBoostingRegressor(learning_rate = 0.3,n_estimators = 2000,max_depth=3,min_samples_split = 5,loss='ls')\nGBRegressor.fit(X_train,y_train)\nprint('The Gradient Boosting score is: ', GBRegressor.score(X_val,y_val))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}