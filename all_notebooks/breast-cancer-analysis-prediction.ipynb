{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Dataset Description**\n\nThe Breast Cancer datasets is available UCI machine learning repository maintained by the University of California, Irvine. The dataset contains 569 samples of malignant and benign tumor cells.\n\nThe first two columns in the dataset store the unique ID numbers of the samples and the corresponding diagnosis (M=malignant, B=benign), respectively. The columns 3-32 contain 30 real-value features that have been computed from digitized images of the cell nuclei, which can be used to build a model to predict whether a tumor is benign or malignant.\n\n* 1= Malignant (Cancerous) - Present (M)\n*  0= Benign (Not Cancerous) -Absent (B)"},{"metadata":{},"cell_type":"markdown","source":"# Load libraries and read the data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn import model_selection\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, roc_auc_score\nfrom pandas.plotting import scatter_matrix\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm\nsns.set_style(\"dark\")\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import datset\ndata = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All features are complete, only 'Unnamed: 32' is completely null, probably an error in the dataset, let's drop the unnecessary data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['Unnamed: 32','id'], axis = 1 , inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.skew()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The skew result show a positive (right) or negative (left) skew. Values closer to zero show less skew. From the graphs, we can see that **radius_mean, perimeter_mean, area_mean, concavity_mean and concave_points_mean** are useful in predicting cancer type due to the distinct grouping between malignant and benign cancer types in these features. We can also see that area_worst and perimeter_worst are also quite useful."},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing Multidimensional Relationships\nplt.style.use('fivethirtyeight')\nsns.set_style(\"white\")\nsns.pairplot(data[[data.columns[0], data.columns[1],data.columns[2],data.columns[3],\n                     data.columns[4], data.columns[5]]], hue = 'diagnosis' , size=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create the correlation matrix heat map\nplt.figure(figsize=(10,6))\nsns.heatmap(data[[data.columns[0], data.columns[1],data.columns[2],data.columns[3],\n                     data.columns[4], data.columns[5]]].corr(),linewidths=.1,cmap=\"YlGnBu\", annot=True)\nplt.yticks(rotation=0);\nplt.suptitle('Correlation Matrix')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"\n\nTransform the 'M' and 'B' values (target variable) to 1 and 0 respectively. Following the encoding of the categorical features, we will continue with the normalization (scalling) of the numerical features. For this we will use the MinMax scalling method."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform the 'yes' and 'no' values (target variable) to 1 and 0 respectively\ndata['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n\n#Scalling\nscaler =MinMaxScaler(feature_range=(0, 1))\nscaled_data =  pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n\n# Split the data to train and test sets\nX = scaled_data.loc[:, scaled_data.columns != 'diagnosis']\ny = scaled_data['diagnosis']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Model Evaluation Metrics\n\nFor model evaluation and To perform a full ROC analysis let's define two functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining model evaluation function\ndef getModelEvaluationMetrics(classifier, model_name: str, x_test: pd.core.frame.DataFrame,\n                              y_test: pd.core.frame.DataFrame, y_predicted, plot_confusion_matrix=False,\n                              figsize=(10, 8)) -> np.ndarray:\n\n    conf_mat = confusion_matrix(y_true=y_test, y_pred=y_predicted)\n    print('Confusion matrix:\\n\\n {0}'.format(conf_mat))\n\n    if plot_confusion_matrix:\n        labels = ['M', 'B']\n        fig = plt.figure(figsize=figsize)\n        ax = fig.add_subplot(111)\n        cax = ax.matshow(conf_mat, cmap=plt.cm.Reds)\n        fig.colorbar(cax)\n        ax.set_xticklabels([''] + labels)\n        ax.set_yticklabels([''] + labels)\n        plt.style.use('fivethirtyeight')\n        sns.set_style(\"white\")\n        plt.xlabel('Predicted')\n        plt.ylabel('Expected')\n        plt.title(f'Confusion Matrix for {model_name}', fontweight='bold')\n        plt.show()\n\n    # Calculating the precision (tp/tp+fp)\n    precision = str(np.round((conf_mat[1][1] / (conf_mat[1][1] +\n                              conf_mat[0][1])) * 100, 2))\n    print('The precision is: {0} %'.format(precision))\n\n    # Calculating the recall (tp/tp+fn)\n    recall = str(np.round((conf_mat[1][1] / (conf_mat[1][1] +\n                           conf_mat[1][0])) * 100, 2))\n    print('The recall is: {0} %'.format(recall))\n\n    return conf_mat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining function for performing a full ROC analysis\ndef createROCAnalysis(classifier, model_name: str, y_test: pd.core.series.Series, pred_probs: np.ndarray,\n                      plot_ROC_Curve=False, figsize=(10, 8)) -> int:\n   \n    if plot_ROC_Curve:\n        plt.figure(figsize=figsize)\n        plt.plot([0, 1], [0, 1], linestyle='--', label='No Skill Classifier')\n        fp_rate, tp_rate, _ = roc_curve(y_test, pred_probs[:, 1])\n        plt.plot(fp_rate, tp_rate, marker='.', label=model_name)\n        plt.style.use('fivethirtyeight')\n        sns.set_style(\"white\")\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title(f'ROC Curve for {model_name}', fontweight='bold')\n        plt.grid(True, alpha=0.1, color='black')\n        plt.legend(loc='lower right')\n        plt.show()\n\n    # Calculate Area Under Curve (AUC) for the Receiver Operating\n    # Characteristics Curve (ROC)\n    auc_score = np.round(roc_auc_score(y_test, pred_probs[:, 1]), 4)\n    print(f'{model_name} - ROC AUC score: {auc_score}')\n\n    return auc_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Breast Cancer Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiate the Random Forest model\n#Pre-tuned Hyperparameter of Random Forest Classifier on this dataset\n\nrf_class = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features=10, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=20, min_samples_split=20,\n            min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=None,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assign the above probabilities to the corresponding class ('no', 'yes')\nrf_class.fit(X_train, y_train)\nrf_y_pred = rf_class.predict(X_test)\n# Evaluate the model by using Recall/Precission:\ngetModelEvaluationMetrics(classifier=rf_class, model_name='Random Forest',x_test=X_test, y_test=y_test,\n                              y_predicted=rf_y_pred, plot_confusion_matrix=True, figsize=(8,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate the model by using ROC Curve:\nrf_pred_probs = rf_class.predict_proba(X_test)\ncreateROCAnalysis(classifier=rf_class, model_name='Random Forest', y_test=y_test, pred_probs=rf_pred_probs,\n                  plot_ROC_Curve=True, figsize=(8,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature decomposition using Principal Component Analysis( PCA)"},{"metadata":{},"cell_type":"markdown","source":"The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance."},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance = {}\nbest_estimator_fi = rf_class.feature_importances_\n\nfor feature, importance in zip(X_train.columns, best_estimator_fi):\n    feature_importance[feature] = importance\n\nimportances = pd.DataFrame.from_dict(feature_importance, orient='index').rename(columns={0: 'Gini Score'})\n\nimportances = importances.sort_values(by='Gini Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot for feature importance\nplt.figure(figsize=(20, 8))\nplt.style.use('fivethirtyeight')\nsns.set_style(\"white\")\nsns.barplot(x=importances.index[0:10],\n            y=importances['Gini Score'].iloc[0:10], palette='muted')\nplt.title(f'Importance for the Top 10 Features (Gini criterion) ',\n          fontweight='bold')\nplt.grid(True, alpha=0.1, color='black')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let’s evaluate the same algorithms with a standardized copy of the dataset. Here, I use sklearn to scale and transform the data such that each attribute has a mean value of zero and a standard deviation of one."},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nX_s = sc.fit_transform(X)\n\npca = PCA(n_components = 10)\nX_pca = pca.fit_transform(X_s)\n\nPCA_df = pd.DataFrame()\n\nPCA_df['PCA_1'] = X_pca[:,0]\nPCA_df['PCA_2'] = X_pca[:,1]\n\nplt.plot(PCA_df['PCA_1'][data.diagnosis == 1],PCA_df['PCA_2'][data.diagnosis == 1],'o', alpha = 0.7, color = 'r')\nplt.plot(PCA_df['PCA_1'][data.diagnosis == 0],PCA_df['PCA_2'][data.diagnosis == 0],'o', alpha = 0.7, color = 'b')\nplt.xlabel('PCA 1')\nplt.ylabel('PCA 2')\nplt.legend(['Malignant','Benign'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\npca = PCA(n_components = 10)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assign the above probabilities to the corresponding class ('no', 'yes')\nrf_class.fit(X_train, y_train)\nrf_y_pred = rf_class.predict(X_test)\n# Evaluate the model by using Recall/Precission:\ngetModelEvaluationMetrics(classifier=rf_class, model_name='Random Forest',x_test=X_test, y_test=y_test,\n                              y_predicted=rf_y_pred, plot_confusion_matrix=True, figsize=(8,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate the model by using ROC Curve:\nrf_pred_probs = rf_class.predict_proba(X_test)\ncreateROCAnalysis(classifier=rf_class, model_name='Random Forest', y_test=y_test, pred_probs=rf_pred_probs,\n                  plot_ROC_Curve=True, figsize=(8,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclution"},{"metadata":{},"cell_type":"markdown","source":"Using PCA I used only 10 components (important) from the dataset, though it contains 30 components!\nHowever, with PCA+RF the model slightly outweigh in recall, precision and ROC AUC score than that of the previous model.\n\n*** Random Forest Model Prediction without PCA**\n1. The precision is: 95.24 %\n1. The recall is: 93.02 %\n1. ROC AUC score: 0.9954\n\n*** Random Forest Model Prediction with PCA**\n\n1. The precision is: 97.62 %\n1. The recall is: 95.35 %\n1. ROC AUC score: 0.9974"},{"metadata":{},"cell_type":"markdown","source":"***If you find this notebook useful, would like to hear from you about it. Any feedbacks or any future tips for support will be highly appreciated.***"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}