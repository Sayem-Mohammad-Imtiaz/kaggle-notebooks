{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Telco Customer Churn\n### Problem Statement : analyze all relevant customer data and develop focused customer retention programs\n\n### Data contains below columns \n1. Customers who left within the last month – the column is called Churn\n2. Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n3. Customer account information – how long they’ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n4. Demographic info about customers – gender, age range, and if they have partners and dependents"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nimport glob\nimport seaborn as sns \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(\"customerID\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pre Processing of data \n"},{"metadata":{},"cell_type":"markdown","source":"## Data Manipulation "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing the  ' ' in Totalcharges to NA values and then converting into float  \ndf['TotalCharges']=df['TotalCharges'].replace(' ',np.nan)\ndf[\"TotalCharges\"] = df[\"TotalCharges\"].astype(float)\n# Changing the senior citizen value to YES or NO \ndf['SeniorCitizen']=df['SeniorCitizen'].replace(1,\"Yes\")\ndf['SeniorCitizen']=df['SeniorCitizen'].replace(0,\"No\")\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#defining the continuoes variable and Categoical variable \ncat_var = []\ndata=df.mean()\ndata.index\ncont_var =df[data.index]\ncont_var\nfor i in df : \n    if i in data:\n        print(i)\n    else: \n        cat_var.append(i)\nprint(cat_var)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=\"No internet service\"\nj=i.split()\nj[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Changing the Vlaue No internet service and No phone service into NO\ncat_yes_no =[\"MultipleLines\",\"OnlineSecurity\",\"OnlineBackup\",\"DeviceProtection\",\"TechSupport\",\"StreamingTV\",\"StreamingMovies\"]\nfor value in cat_yes_no:\n    \n    for i in df[value]:\n        \n        split_val = i.split()\n        \n        if split_val[0] ==\"No\":\n            df[value]=df[value].replace(i,\"No\")\n            \n        \ndf[cat_yes_no].nunique()\n       \n\n  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Memory management"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\" iterate through all the columns of a dataframe and modify the data type\n    to reduce memory usage.        \n\"\"\"\nstart_mem = df.memory_usage().sum() / 1024**2\nprint('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\nfor col in df.columns:\n    col_type = df[col].dtype\n\n    if col_type != object:\n        c_min = df[col].min()\n        c_max = df[col].max()\n        if str(col_type)[:3] == 'int':\n            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                df[col] = df[col].astype(np.int8)\n            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                df[col] = df[col].astype(np.int16)\n            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                df[col] = df[col].astype(np.int32)\n            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                df[col] = df[col].astype(np.int64)  \n        else:\n            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                df[col] = df[col].astype(np.float16)\n            elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                df[col] = df[col].astype(np.float32)\n            else:\n                df[col] = df[col].astype(np.float64)\n    else:\n        df[col] = df[col].astype('category')\n\nend_mem = df.memory_usage().sum() / 1024**2\nprint('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\nprint('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Null Value Treatment"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef null_values(base_dataset):\n    print(base_dataset.isna().sum())\n    ## null value percentage     \n    null_value_table=(base_dataset.isna().sum()/base_dataset.shape[0])*100\n    ## null value percentage beyond threshold drop , else treat the columns \n    \n    retained_columns=null_value_table[null_value_table<30].index\n    # if any variable as null value greater than input(like 30% of the data) value than those variable are consider as drop\n    drop_columns=null_value_table[null_value_table>30].index\n    base_dataset.drop(drop_columns,axis=1,inplace=True)\n    len(base_dataset.isna().sum().index)\n    cont=base_dataset.describe().columns\n    cat=[i for i in base_dataset.columns if i not in base_dataset.describe().columns]\n    for i in cat:\n        base_dataset[i].fillna(base_dataset[i].value_counts().index[0],inplace=True)\n    for i in cont:\n        base_dataset[i].fillna(base_dataset[i].median(),inplace=True)\n    print(base_dataset.isna().sum())\n    return base_dataset,cat,cont\nnull_values(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Outlier Treatment \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df[\"MonthlyCharges\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df[\"TotalCharges\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df[\"tenure\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> From above diagram we can see that there is no Outliers in our data so there is no need to do the Outliers Treatment "},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"1. From the below graph we can say that number of Female and Male users in almost same "},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in cat_var : \n    print((df[i].value_counts()/df.shape[0])*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for j in cat_var:\n    sns.countplot(df[j],hue=df[\"Churn\"])\n    plt.xticks(rotation=45)\n    plt.show()\n   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ananysis from Count plot:\n1. Counts of Male and Female are almost same \n2. Only 16% senior citizen choose to have postpain services \n3. only 30% choose to have dependent connection \n4. 90% of the peoplechoose to  have phone seriveces \n5. Major amount of people are choose to pay using Electronic check \n6. Major people are like to opt for paperless bill \n7. Only around 30 % people choose to have Internet services , Online backup,Streming Movies , Streming TV,Device protection,Tech support\n8. People are tend to choose month to month services compared to other services "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df,hue=\"Churn\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analysis from pairplot\n1. As Total charges  increses, tenure and monthly charges also increases \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"Churn\",y=\"tenure\",data=df,jitter=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in cat_var:\n    sns.boxplot(x=df[i],y=df[\"TotalCharges\"],hue=df[\"Churn\"])\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Applying the model\n\n## Label Encoder \n1. Categorical data which is having more than 3 unique values we will conver them using lable encoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\ndf[cat_var].nunique()\nbin_cols   = df.nunique()[df.nunique() == 2].keys().tolist()\nmulti_col=[]\nfor i in cat_var:\n    if  i not in bin_cols:\n        multi_col.append(i)\nmulti_col\nle=LabelEncoder()\nfor i in bin_cols:\n    df[i]=le.fit_transform(df[i])\ndf.head()\ndf = pd.get_dummies(data=df,columns=multi_col)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nY =pd.DataFrame(df[\"Churn\"])\nX = df.drop(\"Churn\",axis=1)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.25,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape,X_test.shape,Y_test.shape,Y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier,BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nmodel=[RandomForestClassifier,BaggingClassifier,DecisionTreeClassifier]\nfor i in model:\n    classifier = i()\n    classifier.fit(X_train,Y_train)\n    y_pred= classifier.predict(X_test)\n    cm=confusion_matrix(Y_test,y_pred)\n    acc_score = accuracy_score(Y_test,y_pred)\n    print(cm,acc_score)\n\n            \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion: \n1. From the above we can say that Random Forest and Bagging gives us 77% of accuracy and Decision Tree gives us 73% "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"165px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":1}