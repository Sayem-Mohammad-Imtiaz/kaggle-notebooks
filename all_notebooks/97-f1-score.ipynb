{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-26T13:52:50.185023Z","iopub.execute_input":"2021-05-26T13:52:50.185689Z","iopub.status.idle":"2021-05-26T13:52:50.201598Z","shell.execute_reply.started":"2021-05-26T13:52:50.18558Z","shell.execute_reply":"2021-05-26T13:52:50.200296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')\nprint('\\nNumber of rows and columns in the data set: ',df.shape)\nprint('')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:56:34.65777Z","iopub.execute_input":"2021-05-26T13:56:34.658257Z","iopub.status.idle":"2021-05-26T13:56:34.698755Z","shell.execute_reply.started":"2021-05-26T13:56:34.658219Z","shell.execute_reply":"2021-05-26T13:56:34.697293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nimport math as m\nimport os\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:57:15.814039Z","iopub.execute_input":"2021-05-26T13:57:15.814674Z","iopub.status.idle":"2021-05-26T13:57:17.318857Z","shell.execute_reply.started":"2021-05-26T13:57:15.814619Z","shell.execute_reply":"2021-05-26T13:57:17.317236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,4))\nsns.heatmap(df.isnull(),cbar=False,cmap='coolwarm',yticklabels=False)\nplt.title('Finding Missing Value')","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:57:32.734066Z","iopub.execute_input":"2021-05-26T13:57:32.734497Z","iopub.status.idle":"2021-05-26T13:57:33.031965Z","shell.execute_reply.started":"2021-05-26T13:57:32.734463Z","shell.execute_reply":"2021-05-26T13:57:33.030433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:57:56.402609Z","iopub.execute_input":"2021-05-26T13:57:56.403101Z","iopub.status.idle":"2021-05-26T13:57:56.419591Z","shell.execute_reply.started":"2021-05-26T13:57:56.403061Z","shell.execute_reply":"2021-05-26T13:57:56.418221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.info())","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:58:11.510691Z","iopub.execute_input":"2021-05-26T13:58:11.511183Z","iopub.status.idle":"2021-05-26T13:58:11.54202Z","shell.execute_reply.started":"2021-05-26T13:58:11.511141Z","shell.execute_reply":"2021-05-26T13:58:11.540679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:58:27.822915Z","iopub.execute_input":"2021-05-26T13:58:27.823372Z","iopub.status.idle":"2021-05-26T13:58:27.847677Z","shell.execute_reply.started":"2021-05-26T13:58:27.823325Z","shell.execute_reply":"2021-05-26T13:58:27.846752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns; sns.set_theme()\nimport matplotlib.pyplot as plt\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:00:01.172981Z","iopub.execute_input":"2021-05-26T14:00:01.173369Z","iopub.status.idle":"2021-05-26T14:00:01.180534Z","shell.execute_reply.started":"2021-05-26T14:00:01.173338Z","shell.execute_reply":"2021-05-26T14:00:01.17912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df.isna(),yticklabels=False,cbar=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:00:16.266217Z","iopub.execute_input":"2021-05-26T14:00:16.266665Z","iopub.status.idle":"2021-05-26T14:00:16.531282Z","shell.execute_reply.started":"2021-05-26T14:00:16.266623Z","shell.execute_reply":"2021-05-26T14:00:16.530409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:00:33.347101Z","iopub.execute_input":"2021-05-26T14:00:33.347746Z","iopub.status.idle":"2021-05-26T14:00:33.36201Z","shell.execute_reply.started":"2021-05-26T14:00:33.347687Z","shell.execute_reply":"2021-05-26T14:00:33.360743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()\n\ndf[\"bmi\"] = df[\"bmi\"].fillna(value=df[\"bmi\"].mean())\n\ndf=df.drop(['id'],axis=1)\n\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:01:13.527679Z","iopub.execute_input":"2021-05-26T14:01:13.528123Z","iopub.status.idle":"2021-05-26T14:01:13.549188Z","shell.execute_reply.started":"2021-05-26T14:01:13.528089Z","shell.execute_reply":"2021-05-26T14:01:13.54809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (20, 4)\nsns.countplot(df['gender'], palette = 'rainbow')\nplt.title('Gender info', fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:01:48.310502Z","iopub.execute_input":"2021-05-26T14:01:48.310988Z","iopub.status.idle":"2021-05-26T14:01:48.487461Z","shell.execute_reply.started":"2021-05-26T14:01:48.310935Z","shell.execute_reply":"2021-05-26T14:01:48.486417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (20, 4)\nsns.countplot(df['Residence_type'], palette = 'rainbow')\nplt.title('Residence_type info', fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:02:15.099713Z","iopub.execute_input":"2021-05-26T14:02:15.100091Z","iopub.status.idle":"2021-05-26T14:02:15.263609Z","shell.execute_reply.started":"2021-05-26T14:02:15.10006Z","shell.execute_reply":"2021-05-26T14:02:15.262755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:02:49.953266Z","iopub.execute_input":"2021-05-26T14:02:49.954057Z","iopub.status.idle":"2021-05-26T14:02:49.976358Z","shell.execute_reply.started":"2021-05-26T14:02:49.954014Z","shell.execute_reply":"2021-05-26T14:02:49.975144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25,10))\nsns.heatmap(df.corr(),cmap='RdYlGn',annot=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\n#no priority issue will bump here because female ratio is higher so value of 0 is good \n# label_encoder object knows how to understand word labels.\nlabel_encoder = preprocessing.LabelEncoder()\n  \n# Encode labels in column 'gender'.\ndf['gender']= label_encoder.fit_transform(df['gender'])\ndf['ever_married']= label_encoder.fit_transform(df['ever_married'])\ndf['work_type']= label_encoder.fit_transform(df['work_type'])\ndf['Residence_type']= label_encoder.fit_transform(df['Residence_type'])\ndf['smoking_status']= label_encoder.fit_transform(df['smoking_status'])\n  \n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:03:07.841023Z","iopub.execute_input":"2021-05-26T14:03:07.841492Z","iopub.status.idle":"2021-05-26T14:03:07.862164Z","shell.execute_reply.started":"2021-05-26T14:03:07.841421Z","shell.execute_reply":"2021-05-26T14:03:07.860555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:03:17.529892Z","iopub.execute_input":"2021-05-26T14:03:17.530485Z","iopub.status.idle":"2021-05-26T14:03:17.548561Z","shell.execute_reply.started":"2021-05-26T14:03:17.530449Z","shell.execute_reply":"2021-05-26T14:03:17.547294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(25,10))\nsns.heatmap(df.corr(),cmap='RdYlGn',annot=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:04:00.116933Z","iopub.execute_input":"2021-05-26T14:04:00.117322Z","iopub.status.idle":"2021-05-26T14:04:01.040642Z","shell.execute_reply.started":"2021-05-26T14:04:00.117292Z","shell.execute_reply":"2021-05-26T14:04:01.039706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nimport math as m\nimport os\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nX_train,X_test,y_train,y_test =train_test_split(df.drop(['stroke'],axis=1),df.stroke,test_size=0.30,random_state=0)\n\nsvc_model = SVC()\nsvc_model.fit(X_train,y_train)\nsvc_pred = svc_model.predict(X_test)\nsvc_cm = confusion_matrix(y_test,svc_pred)\nsvc_cr = classification_report(y_test,svc_pred)\nsvc_as = accuracy_score(y_test,svc_pred)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:05:04.092603Z","iopub.execute_input":"2021-05-26T14:05:04.093129Z","iopub.status.idle":"2021-05-26T14:05:04.27902Z","shell.execute_reply.started":"2021-05-26T14:05:04.093086Z","shell.execute_reply":"2021-05-26T14:05:04.277374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svc_model = SVC()\nsvc_model.fit(X_train,y_train)\nsvc_pred = svc_model.predict(X_test)\nsvc_cm = confusion_matrix(y_test,svc_pred)\nsvc_cr = classification_report(y_test,svc_pred)\nsvc_as = accuracy_score(y_test,svc_pred)\n\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train,y_train)\nknn_pred = knn.predict(X_test)\nknn_cm = confusion_matrix(y_test,knn_pred)\nknn_cr = classification_report(y_test,knn_pred)\nknn_as = accuracy_score(y_test,knn_pred)\n\ndtc = DecisionTreeClassifier()\ndtc.fit(X_train,y_train)\ndtc_pred = dtc.predict(X_test)\ndtc_cm = confusion_matrix(y_test,dtc_pred)\ndtc_cr = classification_report(y_test,dtc_pred)\ndtc_as = accuracy_score(y_test,dtc_pred)\n\nnbc = GaussianNB()\nnbc.fit(X_train,y_train)\nnbc_pred = nbc.predict(X_test)\nnbc_cm = confusion_matrix(y_test,nbc_pred)\nnbc_cr = classification_report(y_test,nbc_pred)\nnbc_as = accuracy_score(y_test,nbc_pred)\n\nprint(svc_cm)\nprint(svc_cr)\nprint(svc_as)\n\nprint(knn_cm)\nprint(knn_cr)\nprint(knn_as)\n\nprint(dtc_cm)\nprint(dtc_cr)\nprint(dtc_as)\n\nprint(nbc_cm)\nprint(nbc_cr)\nprint(nbc_as)\n\naveraged_preds = (svc_pred + knn_pred + dtc_pred+nbc_pred)//4\nacc = accuracy_score(y_test, averaged_preds)\nprint(svc_as)\nprint(knn_as)\nprint(dtc_as)\nprint(nbc_as)\nprint(acc)\n\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.model_selection import cross_val_score\n\nvoting_clf = VotingClassifier(estimators=[('SVC_hard', svc_model), ('DTC_hard', dtc), ('NBC_hard', nbc),('KNN_hard',knn)], voting='hard')\nvoting_clf.fit(X_train, y_train)\nprediction=voting_clf.predict(X_test)\nprint(confusion_matrix(y_test,prediction))\nprint(classification_report(y_test,prediction))\nprint(accuracy_score(y_test,prediction))\n\nvoting_clf_soft = VotingClassifier(estimators=[('SVC_soft', SVC(probability=True)), ('DTC_soft', dtc), ('NBC_soft', nbc),('KNN_soft',knn)],voting='soft')\nvoting_clf_soft.fit(X_train, y_train)\npredictions=voting_clf_soft.predict(X_test)\nprint(confusion_matrix(y_test,predictions))\nprint(classification_report(y_test,predictions))\nprint(accuracy_score(y_test,predictions))\n\n\narray=[10,20,40,60,80,100]\nfor i in range(0,6):\n  random_forest = RandomForestClassifier(n_estimators=10)\n  random_forest.fit(X_train,y_train)\n  rf_predict=random_forest.predict(X_test)\n  print('Accuracy of Rain Forest when estimate is ',array[i], ' : ',accuracy_score(y_test,rf_predict))\n\narray=[10,20,40,60,80,100]\nfor i in range(0,6):\n  ada_boost = AdaBoostClassifier(n_estimators=array[i], random_state=12)\n  ada_boost.fit(X_train,y_train)\n  ada_predict=ada_boost.predict(X_test)\n  print('Accuracy when estimate is ',array[i], ' : ',accuracy_score(y_test,ada_predict))\n\nkf=KFold(n_splits=5,shuffle=True)\ndata=df.drop(['stroke'],axis=1)\nprint(data)\n\narray = array=[10,20,40,60,80,100]\nfor i in range(0,6):\n  rf = RandomForestClassifier(n_estimators=array[i])\n  rf_accuracy=cross_val_score(rf,data,df.stroke,scoring='accuracy',cv=kf)\n  print('Rain Forest KFold accuracy when estimate is ',array[i],' : ', rf_accuracy.mean()*100)\n\narray=[10,20,40,60,80,100]\nfor i in range(0,6):\n  ada_boost = AdaBoostClassifier(n_estimators=array[i])\n  ada_boost_accuracy=cross_val_score(rf,data,df.stroke,scoring='accuracy',cv=kf)\n  print('Ada Boost KFold accuracy when estimate is ',array[i],' : ', ada_boost_accuracy.mean()*100)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T14:05:40.902665Z","iopub.execute_input":"2021-05-26T14:05:40.903106Z","iopub.status.idle":"2021-05-26T14:06:05.719209Z","shell.execute_reply.started":"2021-05-26T14:05:40.90307Z","shell.execute_reply":"2021-05-26T14:06:05.718312Z"},"trusted":true},"execution_count":null,"outputs":[]}]}