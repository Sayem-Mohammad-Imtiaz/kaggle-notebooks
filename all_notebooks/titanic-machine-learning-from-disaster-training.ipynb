{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport random\nimport os\nimport pandas as pd\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder,MinMaxScaler\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib.pyplot import rcParams\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import OneHotEncoder\nimport numpy as np\n\n%matplotlib inline\nrcParams['figure.figsize'] = 10,8\nsns.set(style='whitegrid', palette='muted',\n        rc={'figure.figsize': (15,10)})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path ='/kaggle/input/titanic-machine-learning-from-disaster/train.csv'\ntest_path ='/kaggle/input/titanic-machine-learning-from-disaster/test.csv'\ndf_train = pd.read_csv(train_path)\ndf_test = pd.read_csv(test_path)\ndf_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessing_dataframe(df, test=False):\n    df_clean = df\n    df_clean['Pclass'] = df_clean['Pclass'].astype('int32')\n    df_clean['Age'] = df_clean['Age'].astype('float32')\n    df_clean['SibSp'] = df_clean['SibSp'].astype('int32')\n    df_clean['Parch'] = df_clean['Parch'].astype('int32')\n    df_clean['Fare'] = df_clean['Fare'].astype('float32')\n    if not test:\n        df_clean['Survived'] = df_clean['Survived'].astype('int32')\n    return df_clean\n\ndf_train = preprocessing_dataframe(df_train, test=False)\ndf_test = preprocessing_dataframe(df_test, test=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df_train.columns:\n    num_nans = np.sum(df_train[col].isna())\n    if num_nans>0:\n        print(col,num_nans)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in df_test.columns:\n    num_nans = np.sum(df_test[col].isna())\n    if num_nans>0:\n        print(col,num_nans)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined = [ df_train, df_test]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pclass","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(5,5))\nsns.countplot(x='Pclass', data=df_train, palette='hls', hue='Survived')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SisSp and Parch","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.subplot(121)\nsns.countplot(x='SibSp', data=df_train, palette='hls', hue='Survived')\nplt.subplot(122)\nsns.countplot(x='Parch', data=df_train, palette='hls', hue='Survived')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for d in combined:\n    d['Family_Size'] = d['SibSp'] + d['Parch']\n    d['has_family'] = (d['Family_Size']>0).astype('int32')\n    \nplt.figure(figsize=(20,5))\nplt.subplot(121)\nsns.countplot(x='Family_Size', data=df_train, palette='hls', hue='Survived')\nplt.subplot(122)\nsns.countplot(x='has_family', data=df_train, palette='hls', hue='Survived')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Age and Fare","metadata":{}},{"cell_type":"code","source":"for d in combined:\n    d['is_Age'] = 1-d['Age'].isna().astype('int32')\n    d['is_Fare'] = 1-d['Fare'].isna().astype('int32')\n    \nfor d in combined:\n    d['Age'].fillna(d['Age'].median(), inplace=True)\n    d['Fare'].fillna(d['Fare'].median(), inplace=True)\n    \nplt.figure(figsize=(15,5))\nplt.subplot(121)\nsns.histplot(df_train[\"Age\"], bins=45, kde=True)\nplt.subplot(122)\nsns.histplot(df_train[\"Fare\"], bins=45, kde=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for d in combined:\n    d[\"Age\"] = np.log1p(d[\"Age\"])\n    d[\"Fare\"] = np.log1p(d[\"Fare\"])\n\nplt.figure(figsize=(15,5))\nplt.subplot(121)\nsns.histplot(df_train[\"Age\"], bins=45, kde=True)\nplt.subplot(122)\nsns.histplot(df_train[\"Fare\"], bins=45, kde=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sex","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(5,5))\nsns.countplot(x='Sex', data=df_train, palette='hls', hue='Survived')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Embarked","metadata":{}},{"cell_type":"code","source":"for d in combined:\n    d.fillna(d['Embarked'].mode(), inplace=True)\n    \nplt.figure(figsize=(5,5))\nsns.countplot(x='Embarked', data=df_train, palette='hls', hue='Survived')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Name","metadata":{}},{"cell_type":"code","source":"for d in combined:\n    d['Title'] = d.Name.apply(lambda x: [t for t in x.split() if '.' in t ][0])\n\nplt.figure(figsize=(20,5))\nsns.countplot(x='Title', data=df_train, palette='hls', hue='Survived')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def replace_list(x, listwords, new_word):\n    for s in listwords:\n        x = x.replace(s, new_word)\n    return x\n\nfor d in combined:\n    d['Title'] = d['Title'].apply(lambda x: replace_list(x, \\\n    ['Lady','Countess','Capt','Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'], \\\n    'Rare'))\n    d['Title'] = d['Title'].apply(lambda x: replace_list(x, ['Mlle'], 'Miss'))\n    d['Title'] = d['Title'].apply(lambda x: replace_list(x, ['Ms'], 'Miss'))\n    d['Title'] = d['Title'].apply(lambda x: replace_list(x, ['Mme'], 'Mrs'))\n    \nplt.figure(figsize=(10,5))\nsns.countplot(x='Title', data=df_train, palette='hls', hue='Survived')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cabin","metadata":{}},{"cell_type":"code","source":"for d in combined:\n    d['Cabin'].fillna('Regular', inplace=True)\n    d[\"Cabin_0\"] = d[\"Cabin\"].apply(lambda x:x[0])\n    \nplt.figure(figsize=(10,5))\nsns.countplot(x='Cabin_0', data=df_train, palette='hls', hue='Survived')\nplt.show()    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for d in combined:\n    d[\"Special_Cabin\"] = d.Cabin_0#.map( {\"A\":1,\"B\":1,\"C\":1,\"D\":1,\"E\":1,\"F\":1,\"G\":1,\"T\":1,\"R\":0} )\n    \nplt.figure(figsize=(10,5))\nsns.countplot(x='Special_Cabin', data=df_train, palette='hls', hue='Survived')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessing_dataframe(df, test=False):\n    df_clean = df\n    df_clean['Pclass'] = df_clean['Pclass'].astype('int32')\n    df_clean['Age'] = df_clean['Age'].astype('float32')\n    df_clean['SibSp'] = df_clean['SibSp'].astype('int32')\n    df_clean['Parch'] = df_clean['Parch'].astype('int32')\n    df_clean['Fare'] = df_clean['Fare'].astype('float32')\n    if not test:\n        df_clean['Survived'] = df_clean['Survived'].astype('int32')\n    return df_clean\n\ndf_train = preprocessing_dataframe(df_train)\ndf_test = preprocessing_dataframe(df_test, test=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_features_columns = ['Pclass','Sex','Age','is_Age','has_family','Fare','is_Fare','Embarked','Special_Cabin','Title']#,'Ticket_type']\nfrom collections import Counter\ndfs=[]\nfor g,df in df_train[x_features_columns].groupby(x_features_columns):\n    sv_values =  df_train.iloc[df.index]['Survived'].values\n    if len(df)>1:\n        df1 = df.iloc[0:1]\n        df1['Survived']=Counter(df_train.iloc[df.index]['Survived'].values).most_common()[0][0]\n        dfs.append(df1)\n    else:\n        df1 = df.iloc[0:1]\n        df1['Survived'] = df_train.iloc[df.index[0]]['Survived']\n        dfs.append(df1)\ndfs=pd.concat(dfs,axis=0)\nprint(len(df_train),'->',len(dfs))\ndf_train=dfs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat2transform={\n    'Pclass':OneHotEncoder(), \n    'Sex':LabelEncoder(), \n    'Age':MinMaxScaler(), \n    'is_Age':LabelEncoder(), \n    'SibSp':MinMaxScaler(),\n    'Parch':MinMaxScaler(),\n    'Family_Size':MinMaxScaler(),\n    'has_family':LabelEncoder(), \n    'Fare':MinMaxScaler(),  \n    'is_Fare':LabelEncoder(), \n    'Embarked':OneHotEncoder(),\n    'Special_Cabin':OneHotEncoder(),\n    'Title':OneHotEncoder(),\n    'Ticket_type':OneHotEncoder(),\n}\n\ndef fit_transformations(df_clean):\n    for col in x_features_columns:\n        t = feat2transform[col]\n        t.fit(df_clean[col].values.reshape([-1,1]))\n\ndef preprocessing_data(df_clean, test=False):\n    \n    data = []\n    for col in x_features_columns:\n        t = feat2transform[col]\n        d = t.transform(df_clean[col].values.reshape([-1,1]))\n        if type(t) is OneHotEncoder:\n            d = d.toarray()\n        if type(t) is LabelEncoder:\n            d = d.reshape([-1,1])\n        data.append(d)\n    \n    data = np.concatenate(data,axis=1)\n    \n    if test:\n        return data\n    \n    target = df_clean['Survived'].values.reshape([-1,1])\n    \n    return data,target\n\nfit_transformations(pd.concat([df_train, df_test]))\ndata,target = preprocessing_data(df_train)\ntest_data = preprocessing_data(df_test, test=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\nfrom sklearn.decomposition import PCA\nimport sys\nfrom sklearn.manifold import TSNE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Aditional Features","metadata":{}},{"cell_type":"code","source":"X = np.concatenate([data, test_data], axis=0)\nprint(X.shape)\npca = PCA(n_components=10)\npca.fit(X)\n\ndata_pca= pca.transform(data)\ntest_pca= pca.transform(test_data)\n\ndata_pca=data_pca#/np.linalg.norm(Y)\ntest_pca=test_pca#/np.linalg.norm(Y)\n\ndata_and_pca=np.concatenate([data, data_pca],axis=1)\ntest_and_pca=np.concatenate([test_data, test_pca],axis=1)\nprint(data_and_pca.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nparam_grid = {\n    'n_estimators': [1000, 2000],\n    'max_features': ['auto', 'sqrt', 'log2'],\n    'max_depth':[5,7,9]\n}\n\ngrid = GridSearchCV(estimator=RandomForestClassifier(), \n                    param_grid=param_grid,\n                    cv=5,\n                    verbose=2,\n                    n_jobs=-1)\ngrid.fit(data_and_pca, target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = grid.best_estimator_.predict(test_and_pca)\ndf_test['Survived']=prediction\nres = df_test[['PassengerId','Survived']]\nres.to_csv('output.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}