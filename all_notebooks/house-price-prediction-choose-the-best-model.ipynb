{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-07T19:06:44.739251Z","iopub.execute_input":"2021-06-07T19:06:44.739564Z","iopub.status.idle":"2021-06-07T19:06:44.748454Z","shell.execute_reply.started":"2021-06-07T19:06:44.739535Z","shell.execute_reply":"2021-06-07T19:06:44.747575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Loading and Understanding the Data**","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/ames-housing-dataset/AmesHousing.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:44.753789Z","iopub.execute_input":"2021-06-07T19:06:44.754043Z","iopub.status.idle":"2021-06-07T19:06:44.792613Z","shell.execute_reply.started":"2021-06-07T19:06:44.754018Z","shell.execute_reply":"2021-06-07T19:06:44.791832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.sort_values(\"Yr Sold\")","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:44.799446Z","iopub.execute_input":"2021-06-07T19:06:44.799703Z","iopub.status.idle":"2021-06-07T19:06:44.805495Z","shell.execute_reply.started":"2021-06-07T19:06:44.799678Z","shell.execute_reply":"2021-06-07T19:06:44.804741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.display.max_columns = None","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:44.839907Z","iopub.execute_input":"2021-06-07T19:06:44.840146Z","iopub.status.idle":"2021-06-07T19:06:44.843869Z","shell.execute_reply.started":"2021-06-07T19:06:44.840122Z","shell.execute_reply":"2021-06-07T19:06:44.843012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:44.86428Z","iopub.execute_input":"2021-06-07T19:06:44.864515Z","iopub.status.idle":"2021-06-07T19:06:44.922214Z","shell.execute_reply.started":"2021-06-07T19:06:44.864492Z","shell.execute_reply":"2021-06-07T19:06:44.921374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Getting Information from Data**","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:44.923538Z","iopub.execute_input":"2021-06-07T19:06:44.924045Z","iopub.status.idle":"2021-06-07T19:06:44.948395Z","shell.execute_reply.started":"2021-06-07T19:06:44.924007Z","shell.execute_reply":"2021-06-07T19:06:44.947779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:44.94953Z","iopub.execute_input":"2021-06-07T19:06:44.949907Z","iopub.status.idle":"2021-06-07T19:06:44.954769Z","shell.execute_reply.started":"2021-06-07T19:06:44.949879Z","shell.execute_reply":"2021-06-07T19:06:44.953984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:44.955934Z","iopub.execute_input":"2021-06-07T19:06:44.956276Z","iopub.status.idle":"2021-06-07T19:06:44.966066Z","shell.execute_reply.started":"2021-06-07T19:06:44.956249Z","shell.execute_reply":"2021-06-07T19:06:44.965099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.select_dtypes(object).columns","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:44.988293Z","iopub.execute_input":"2021-06-07T19:06:44.988582Z","iopub.status.idle":"2021-06-07T19:06:44.996853Z","shell.execute_reply.started":"2021-06-07T19:06:44.988557Z","shell.execute_reply":"2021-06-07T19:06:44.995769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.select_dtypes([np.int64, np.float64]).columns","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.006624Z","iopub.execute_input":"2021-06-07T19:06:45.006906Z","iopub.status.idle":"2021-06-07T19:06:45.013065Z","shell.execute_reply.started":"2021-06-07T19:06:45.00688Z","shell.execute_reply":"2021-06-07T19:06:45.012503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### **Checking Duplicates if Any**","metadata":{}},{"cell_type":"code","source":"data.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.026484Z","iopub.execute_input":"2021-06-07T19:06:45.026736Z","iopub.status.idle":"2021-06-07T19:06:45.052422Z","shell.execute_reply.started":"2021-06-07T19:06:45.026712Z","shell.execute_reply":"2021-06-07T19:06:45.051514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.053891Z","iopub.execute_input":"2021-06-07T19:06:45.054235Z","iopub.status.idle":"2021-06-07T19:06:45.069126Z","shell.execute_reply.started":"2021-06-07T19:06:45.054199Z","shell.execute_reply":"2021-06-07T19:06:45.068123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\n# sns.histplot(data['SalePrice'])\nsns.displot(data['SalePrice'], height=7, aspect=1.7, color='brown')\nplt.title('SalePrice Distribution')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.070439Z","iopub.execute_input":"2021-06-07T19:06:45.070718Z","iopub.status.idle":"2021-06-07T19:06:45.446658Z","shell.execute_reply.started":"2021-06-07T19:06:45.070693Z","shell.execute_reply":"2021-06-07T19:06:45.445762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.447864Z","iopub.execute_input":"2021-06-07T19:06:45.44811Z","iopub.status.idle":"2021-06-07T19:06:45.45387Z","shell.execute_reply.started":"2021-06-07T19:06:45.448084Z","shell.execute_reply":"2021-06-07T19:06:45.453108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Handling Missing Values**","metadata":{}},{"cell_type":"markdown","source":"#### **1 - Dropping Features having Null values greater than 5% of dataset size**","metadata":{}},{"cell_type":"code","source":"null_count = data.isnull().sum()\ndlt = null_count[null_count > data.shape[0]*0.05].index\ndlt","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.455303Z","iopub.execute_input":"2021-06-07T19:06:45.45554Z","iopub.status.idle":"2021-06-07T19:06:45.471362Z","shell.execute_reply.started":"2021-06-07T19:06:45.455517Z","shell.execute_reply":"2021-06-07T19:06:45.470765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop(dlt, axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.472916Z","iopub.execute_input":"2021-06-07T19:06:45.473253Z","iopub.status.idle":"2021-06-07T19:06:45.479842Z","shell.execute_reply.started":"2021-06-07T19:06:45.473218Z","shell.execute_reply":"2021-06-07T19:06:45.479237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **2 - Handling Numerical Features**","metadata":{}},{"cell_type":"markdown","source":"**2.1-Checking Numerical Features with Null Values**","metadata":{}},{"cell_type":"code","source":"num_null = data.select_dtypes([np.int64, np.float64]).isnull().sum()\nmissing_num = num_null[num_null>0].index\nmissing_num","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.480893Z","iopub.execute_input":"2021-06-07T19:06:45.48111Z","iopub.status.idle":"2021-06-07T19:06:45.49343Z","shell.execute_reply.started":"2021-06-07T19:06:45.481089Z","shell.execute_reply":"2021-06-07T19:06:45.492702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2.2-Finding out the Mode for each Feature**","metadata":{}},{"cell_type":"code","source":"fill = data[missing_num].mode().to_dict(orient = \"record\")[0]\nfill","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.494459Z","iopub.execute_input":"2021-06-07T19:06:45.494727Z","iopub.status.idle":"2021-06-07T19:06:45.506506Z","shell.execute_reply.started":"2021-06-07T19:06:45.4947Z","shell.execute_reply":"2021-06-07T19:06:45.505853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2.3-Filling them with Mode**","metadata":{}},{"cell_type":"code","source":"data.fillna(fill, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.507377Z","iopub.execute_input":"2021-06-07T19:06:45.507613Z","iopub.status.idle":"2021-06-07T19:06:45.515346Z","shell.execute_reply.started":"2021-06-07T19:06:45.507591Z","shell.execute_reply":"2021-06-07T19:06:45.514333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **3 - Handling Non-Numerical (Object) Features**","metadata":{}},{"cell_type":"code","source":"obj = data.select_dtypes(object)\nobj.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.518518Z","iopub.execute_input":"2021-06-07T19:06:45.51912Z","iopub.status.idle":"2021-06-07T19:06:45.552235Z","shell.execute_reply.started":"2021-06-07T19:06:45.519076Z","shell.execute_reply":"2021-06-07T19:06:45.55159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Dropping Columns Having Unique Values Greater than 10**","metadata":{}},{"cell_type":"markdown","source":"**Finding out Uniques Values for each column**","metadata":{}},{"cell_type":"code","source":"uniq = obj.apply(lambda col: len(col.unique())).sort_values(ascending = False)\nuniq","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.553954Z","iopub.execute_input":"2021-06-07T19:06:45.554237Z","iopub.status.idle":"2021-06-07T19:06:45.574415Z","shell.execute_reply.started":"2021-06-07T19:06:45.554209Z","shell.execute_reply":"2021-06-07T19:06:45.573465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Removing Columns with Unique Values greater than 10**","metadata":{}},{"cell_type":"code","source":"rmv_uniq = uniq[uniq>10].index\ndata.drop(rmv_uniq, axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.575791Z","iopub.execute_input":"2021-06-07T19:06:45.576127Z","iopub.status.idle":"2021-06-07T19:06:45.582817Z","shell.execute_reply.started":"2021-06-07T19:06:45.576092Z","shell.execute_reply":"2021-06-07T19:06:45.582255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"obj_col = data.select_dtypes(object).columns\nobj_col","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.583559Z","iopub.execute_input":"2021-06-07T19:06:45.583898Z","iopub.status.idle":"2021-06-07T19:06:45.592016Z","shell.execute_reply.started":"2021-06-07T19:06:45.583873Z","shell.execute_reply":"2021-06-07T19:06:45.59124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Data Cleaning**","metadata":{}},{"cell_type":"markdown","source":"- We are more interested in **'Years Before Sale'** and **'Years Since Remodelled**' of a car rather than **'Year Built'**, **'Yr Sold'** or **'Year Remod/Add'**.\n- Because before purchasing we are more concerned about **'how much time has passed after remodelling of car'** or **'how many years the car has passed before it was sold'**. So for that we are transforming into our required form.","metadata":{}},{"cell_type":"code","source":"years_sold = data['Yr Sold'] - data['Year Built']\nyears_sold [years_sold<0]","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.593363Z","iopub.execute_input":"2021-06-07T19:06:45.593898Z","iopub.status.idle":"2021-06-07T19:06:45.605118Z","shell.execute_reply.started":"2021-06-07T19:06:45.593862Z","shell.execute_reply":"2021-06-07T19:06:45.604291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'Year Built' will always be smaller than 'Yr Sold', which means 2180 row has wrong values. So we'll have to drop it.","metadata":{}},{"cell_type":"code","source":"years_rmd = data['Yr Sold'] - data['Year Remod/Add']\nyears_rmd[years_rmd<0]","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.60637Z","iopub.execute_input":"2021-06-07T19:06:45.606676Z","iopub.status.idle":"2021-06-07T19:06:45.612928Z","shell.execute_reply.started":"2021-06-07T19:06:45.606641Z","shell.execute_reply":"2021-06-07T19:06:45.611927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These three rows must be dropped b/c they should not be negative.","metadata":{}},{"cell_type":"code","source":"data.drop([1702, 2180,2181], axis = 0,inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.613921Z","iopub.execute_input":"2021-06-07T19:06:45.61416Z","iopub.status.idle":"2021-06-07T19:06:45.621905Z","shell.execute_reply.started":"2021-06-07T19:06:45.614128Z","shell.execute_reply":"2021-06-07T19:06:45.620993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Saving into New Column**","metadata":{}},{"cell_type":"code","source":"data[\"Years Before Sale\"] = years_sold\ndata[\"Years Since Remod\"] = years_rmd","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.62279Z","iopub.execute_input":"2021-06-07T19:06:45.623035Z","iopub.status.idle":"2021-06-07T19:06:45.633984Z","shell.execute_reply.started":"2021-06-07T19:06:45.623011Z","shell.execute_reply":"2021-06-07T19:06:45.633184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Removing Old Features**","metadata":{}},{"cell_type":"code","source":"data.drop(['Year Built','Year Remod/Add'], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.634857Z","iopub.execute_input":"2021-06-07T19:06:45.635074Z","iopub.status.idle":"2021-06-07T19:06:45.643093Z","shell.execute_reply.started":"2021-06-07T19:06:45.635053Z","shell.execute_reply":"2021-06-07T19:06:45.642316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Removing other Unnecessary Features**","metadata":{}},{"cell_type":"markdown","source":"**'Order' is just representing the row order, we don't need it in our dataset**","metadata":{}},{"cell_type":"code","source":"data.drop([\"Order\"], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.64422Z","iopub.execute_input":"2021-06-07T19:06:45.644831Z","iopub.status.idle":"2021-06-07T19:06:45.652371Z","shell.execute_reply.started":"2021-06-07T19:06:45.644796Z","shell.execute_reply":"2021-06-07T19:06:45.651674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We can also see straight away some leaking feature i.e. we have some columns which are leaking our target values. Which may result in bad prediction because of the seasonality present in them. Since we are looking towards modelling a general price prediction model, so we better drop these features**","metadata":{}},{"cell_type":"code","source":"data_leak = ['Mo Sold', 'Yr Sold', 'Sale Type','Sale Condition']\ndata.drop(data_leak,axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.653377Z","iopub.execute_input":"2021-06-07T19:06:45.653838Z","iopub.status.idle":"2021-06-07T19:06:45.662102Z","shell.execute_reply.started":"2021-06-07T19:06:45.653802Z","shell.execute_reply":"2021-06-07T19:06:45.661456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c = data.corr()\nplt.figure(figsize=(15,10))\n# sns.set(font_scale = 1)\nsns.heatmap(c)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:45.66315Z","iopub.execute_input":"2021-06-07T19:06:45.663498Z","iopub.status.idle":"2021-06-07T19:06:46.407162Z","shell.execute_reply.started":"2021-06-07T19:06:45.663466Z","shell.execute_reply":"2021-06-07T19:06:46.406393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Converting Object Feature into Numerical Form**","metadata":{}},{"cell_type":"code","source":"obj_col = data.select_dtypes(object).columns\nobj_col","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:46.408672Z","iopub.execute_input":"2021-06-07T19:06:46.409037Z","iopub.status.idle":"2021-06-07T19:06:46.41816Z","shell.execute_reply.started":"2021-06-07T19:06:46.408998Z","shell.execute_reply":"2021-06-07T19:06:46.417221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[obj_col] = data[obj_col].astype('category')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:46.419412Z","iopub.execute_input":"2021-06-07T19:06:46.419797Z","iopub.status.idle":"2021-06-07T19:06:46.457426Z","shell.execute_reply.started":"2021-06-07T19:06:46.419763Z","shell.execute_reply":"2021-06-07T19:06:46.456841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in obj_col:\n    data[i] = data[i].cat.codes","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:46.458284Z","iopub.execute_input":"2021-06-07T19:06:46.458667Z","iopub.status.idle":"2021-06-07T19:06:46.477895Z","shell.execute_reply.started":"2021-06-07T19:06:46.458616Z","shell.execute_reply":"2021-06-07T19:06:46.477307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Plotting Correlation wrt to SalePrice (Target Label)**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(4,30))\n\ncor_df = pd.DataFrame({'SalePrice' : data.corr()['SalePrice'].values},\n                     index = data.corr()['SalePrice'].index)\n\nsns.heatmap(cor_df, annot=True, cmap='viridis', annot_kws={\"fontsize\":17})\nsns.set(font_scale = 1.5)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:46.481066Z","iopub.execute_input":"2021-06-07T19:06:46.481481Z","iopub.status.idle":"2021-06-07T19:06:47.771014Z","shell.execute_reply.started":"2021-06-07T19:06:46.481443Z","shell.execute_reply":"2021-06-07T19:06:47.770175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We've decided to take the features having correlation with SalePrice > 0.25**","metadata":{}},{"cell_type":"code","source":"cor = data.corr()[\"SalePrice\"].abs().sort_values(ascending = False)\nretained = cor[cor>0.25].index\nretained","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:47.773253Z","iopub.execute_input":"2021-06-07T19:06:47.773569Z","iopub.status.idle":"2021-06-07T19:06:47.815811Z","shell.execute_reply.started":"2021-06-07T19:06:47.773537Z","shell.execute_reply":"2021-06-07T19:06:47.814911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data[retained]","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:47.817231Z","iopub.execute_input":"2021-06-07T19:06:47.817576Z","iopub.status.idle":"2021-06-07T19:06:47.824103Z","shell.execute_reply.started":"2021-06-07T19:06:47.81754Z","shell.execute_reply":"2021-06-07T19:06:47.823088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Checking Multi-Collinearity**","metadata":{}},{"cell_type":"code","source":"s = c.unstack()\nso = s.sort_values(kind=\"quicksort\")","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:47.825459Z","iopub.execute_input":"2021-06-07T19:06:47.82594Z","iopub.status.idle":"2021-06-07T19:06:47.833585Z","shell.execute_reply.started":"2021-06-07T19:06:47.825903Z","shell.execute_reply":"2021-06-07T19:06:47.832925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Below are the features' pair having correlation greater than 0.78**","metadata":{}},{"cell_type":"code","source":"fin = so[(so > 0.78) & (so < 1)].sort_values(ascending=False)\nfin","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:47.834555Z","iopub.execute_input":"2021-06-07T19:06:47.834957Z","iopub.status.idle":"2021-06-07T19:06:47.847078Z","shell.execute_reply.started":"2021-06-07T19:06:47.834922Z","shell.execute_reply":"2021-06-07T19:06:47.846082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We have to remove any one feature from each pair.**","metadata":{}},{"cell_type":"code","source":"f_l = list(fin.index)\nf_l","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:47.848469Z","iopub.execute_input":"2021-06-07T19:06:47.848973Z","iopub.status.idle":"2021-06-07T19:06:47.858243Z","shell.execute_reply.started":"2021-06-07T19:06:47.848934Z","shell.execute_reply":"2021-06-07T19:06:47.857423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will be deleting the following features from our dataset.","metadata":{}},{"cell_type":"code","source":"lst_del = []\nfor index, value in enumerate(f_l):\n    if index%2 != 0:\n        lst = value[0]\n        lst_del.append(lst)\nlst_del","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:47.859439Z","iopub.execute_input":"2021-06-07T19:06:47.859706Z","iopub.status.idle":"2021-06-07T19:06:47.868313Z","shell.execute_reply.started":"2021-06-07T19:06:47.859682Z","shell.execute_reply":"2021-06-07T19:06:47.867341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop(['Garage Cars', 'TotRms AbvGrd', '1st Flr SF'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:47.869538Z","iopub.execute_input":"2021-06-07T19:06:47.869865Z","iopub.status.idle":"2021-06-07T19:06:47.877848Z","shell.execute_reply.started":"2021-06-07T19:06:47.869841Z","shell.execute_reply":"2021-06-07T19:06:47.876974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Checking Variance**","metadata":{}},{"cell_type":"markdown","source":"**We'll be dropping features where there is no or very little variation, b/c these features are of no use for our model. Therefore we'll be keeping features only with variance greater than 0.01**","metadata":{}},{"cell_type":"code","source":"hetro = data.copy()\nhetro = (hetro-hetro.min())/(hetro.max()- hetro.min())\nvar = hetro.var().sort_values(ascending = False)\nvar","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:47.878863Z","iopub.execute_input":"2021-06-07T19:06:47.879086Z","iopub.status.idle":"2021-06-07T19:06:47.905447Z","shell.execute_reply.started":"2021-06-07T19:06:47.879065Z","shell.execute_reply":"2021-06-07T19:06:47.904714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_col = var[var>0.01].index\nfinal_col","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:47.906516Z","iopub.execute_input":"2021-06-07T19:06:47.906752Z","iopub.status.idle":"2021-06-07T19:06:47.91227Z","shell.execute_reply.started":"2021-06-07T19:06:47.90673Z","shell.execute_reply":"2021-06-07T19:06:47.91141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data[final_col]","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:47.913313Z","iopub.execute_input":"2021-06-07T19:06:47.913808Z","iopub.status.idle":"2021-06-07T19:06:47.924993Z","shell.execute_reply.started":"2021-06-07T19:06:47.913773Z","shell.execute_reply":"2021-06-07T19:06:47.924326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:47.925926Z","iopub.execute_input":"2021-06-07T19:06:47.92636Z","iopub.status.idle":"2021-06-07T19:06:47.948193Z","shell.execute_reply.started":"2021-06-07T19:06:47.926325Z","shell.execute_reply":"2021-06-07T19:06:47.947486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:47.949239Z","iopub.execute_input":"2021-06-07T19:06:47.949563Z","iopub.status.idle":"2021-06-07T19:06:47.954586Z","shell.execute_reply.started":"2021-06-07T19:06:47.949538Z","shell.execute_reply":"2021-06-07T19:06:47.953612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Standardizing the Data (Normalization)**","metadata":{}},{"cell_type":"markdown","source":"**Since we cannot perform standardization to our target label ('SalePrice'). Therefore for the time being we are saving it into a variable, then we'll replace it with the original one**","metadata":{}},{"cell_type":"code","source":"sale_price = data[\"SalePrice\"]","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:47.956122Z","iopub.execute_input":"2021-06-07T19:06:47.956453Z","iopub.status.idle":"2021-06-07T19:06:47.964202Z","shell.execute_reply.started":"2021-06-07T19:06:47.956418Z","shell.execute_reply":"2021-06-07T19:06:47.963186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = (data-data.min())/(data.max()-data.min())","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:47.965725Z","iopub.execute_input":"2021-06-07T19:06:47.966158Z","iopub.status.idle":"2021-06-07T19:06:47.981743Z","shell.execute_reply.started":"2021-06-07T19:06:47.966123Z","shell.execute_reply":"2021-06-07T19:06:47.98106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"SalePrice\"] = sale_price","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:47.98283Z","iopub.execute_input":"2021-06-07T19:06:47.983173Z","iopub.status.idle":"2021-06-07T19:06:47.988048Z","shell.execute_reply.started":"2021-06-07T19:06:47.983137Z","shell.execute_reply":"2021-06-07T19:06:47.987058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:47.989865Z","iopub.execute_input":"2021-06-07T19:06:47.990303Z","iopub.status.idle":"2021-06-07T19:06:48.016771Z","shell.execute_reply.started":"2021-06-07T19:06:47.990264Z","shell.execute_reply":"2021-06-07T19:06:48.01595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Shuffling the DataSet before splitting**","metadata":{}},{"cell_type":"code","source":"data = data.sample(frac=1, random_state=123)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:48.017858Z","iopub.execute_input":"2021-06-07T19:06:48.018106Z","iopub.status.idle":"2021-06-07T19:06:48.04092Z","shell.execute_reply.started":"2021-06-07T19:06:48.018081Z","shell.execute_reply":"2021-06-07T19:06:48.04015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:48.041946Z","iopub.execute_input":"2021-06-07T19:06:48.042179Z","iopub.status.idle":"2021-06-07T19:06:48.046765Z","shell.execute_reply.started":"2021-06-07T19:06:48.042155Z","shell.execute_reply":"2021-06-07T19:06:48.046051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Splitting the Data into 75% and 25%**","metadata":{}},{"cell_type":"code","source":"indx = int(2927*0.75)\n\ntrain = data[:indx]\ntest = data[indx:]","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:48.047792Z","iopub.execute_input":"2021-06-07T19:06:48.048226Z","iopub.status.idle":"2021-06-07T19:06:48.05513Z","shell.execute_reply.started":"2021-06-07T19:06:48.048201Z","shell.execute_reply":"2021-06-07T19:06:48.054408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = train.columns.drop('SalePrice')\ntarget = ['SalePrice']","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:48.056083Z","iopub.execute_input":"2021-06-07T19:06:48.056295Z","iopub.status.idle":"2021-06-07T19:06:48.063772Z","shell.execute_reply.started":"2021-06-07T19:06:48.056275Z","shell.execute_reply":"2021-06-07T19:06:48.063133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Linear Regression**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\n\n\nmodel = LinearRegression()\nmodel.fit(train[features], train[target])\n\nprediction = model.predict(test[features])\n\nmae = mean_absolute_error(test[target], prediction)\n\nprint('Linear Regression')\nprint(f'Mean Absolute Error: {mae}')\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:48.064568Z","iopub.execute_input":"2021-06-07T19:06:48.06498Z","iopub.status.idle":"2021-06-07T19:06:48.086471Z","shell.execute_reply.started":"2021-06-07T19:06:48.064952Z","shell.execute_reply":"2021-06-07T19:06:48.085169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **K-Fold Validation**","metadata":{}},{"cell_type":"markdown","source":"**Since the size of our dataset is not too big, therefore we should apply k-fold validation method**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\n\nmodel = LinearRegression()\nmaes = []\n\nkf = KFold(5, True, random_state=123)\n\nfor train_index, test_index in kf.split(data):\n    train = data.iloc[train_index]\n    test = data.iloc[test_index]\n    model.fit(train[features], train[target])\n    prediction = model.predict(test[features])\n    mae = mean_absolute_error(prediction, test[target])\n    maes.append(mae)\n\nprint(f'Mean Absolute Error: {np.mean(maes)}')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:48.087677Z","iopub.execute_input":"2021-06-07T19:06:48.089172Z","iopub.status.idle":"2021-06-07T19:06:48.177941Z","shell.execute_reply.started":"2021-06-07T19:06:48.089135Z","shell.execute_reply":"2021-06-07T19:06:48.176924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Model Comparision with Default Parameters**","metadata":{}},{"cell_type":"markdown","source":"**Now we will be comparing different regression models with their default parameters along with k-fold validation.**","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor \nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import KFold\n\nLG = LinearRegression()\nSV = SVR()\nKN = KNeighborsRegressor()\nDT = DecisionTreeRegressor(random_state=123)\nGB = GradientBoostingRegressor(random_state=123)\nRF = RandomForestRegressor(random_state=123)\n\nmodels = [LG, SV, KN, DT, GB, RF,]\nmodel_name = [ 'Linear Regression', 'Support Vector Regression', 'K Nearest Neighbor', \n              'Decision Tree', 'Gradient Boost', 'Random Forest' ]\n\n\nmeans = []\nr2_score_ = []\nkf = KFold(5, True, random_state=123)\n\nfor i in range(len(models)):\n    maes = []\n    r2s = []\n    model = models[i]\n\n    for train_index, test_index in kf.split(data):\n        train = data.iloc[train_index]\n        test = data.iloc[test_index]\n        model.fit(train[features], train[target])\n        prediction = model.predict(test[features])\n        mae = mean_absolute_error(prediction, test[target])\n        r2 = r2_score(test[target], prediction)\n        maes.append(mae)\n        r2s.append(r2)\n        \n    means.append(np.mean(maes))\n    r2_score_.append(np.mean(r2s))\n    \n    \nmod_comp_def = pd.DataFrame({'Models' : model_name, 'Mean Absolute Error' : means,\n                            'R2_Score' : r2_score_}).set_index('Models')\nmod_comp_def","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:48.182893Z","iopub.execute_input":"2021-06-07T19:06:48.183267Z","iopub.status.idle":"2021-06-07T19:06:57.74332Z","shell.execute_reply.started":"2021-06-07T19:06:48.183229Z","shell.execute_reply":"2021-06-07T19:06:57.742428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Hyperparameter Tuning**","metadata":{}},{"cell_type":"markdown","source":"### **- Using GridSearchCV**","metadata":{}},{"cell_type":"markdown","source":"Here we will be using GridSearchCV of SciKit Learn Library to find out the better parameter values for respective models which give us the optimum result.","metadata":{}},{"cell_type":"markdown","source":"Below we are defining various combinations","metadata":{}},{"cell_type":"code","source":"# #LG = LinearRegression\n# RV = \n# KN = K Nearest Neighbor\n# DT = DecisionTree\n# GB = GradientBoost\n# RF = RandomForest\n\nparameter_space_LG = {\n    'fit_intercept' : [True, False] ,\n    'normalize' : [True, False] ,\n    'copy_X' : [True, False] ,\n    'positive' : [True, False]\n}\n\nparameter_space_SV = {\n    \"kernel\": [\"poly\", \"linear\", \"rbf\", \"sigmoid\"],\n        \"degree\": [3, 5],\n        \"coef0\": [0, 3, 7],\n        \"gamma\":[1e-3, 1e-1, 1/train[features].shape[1]],\n        \"C\": [1, 10, 100],\n}\n\nparameter_space_RI = {\n    \"alpha\": [1, 10, 100, 290, 500],\n    \"fit_intercept\": [True, False],\n    \"solver\": ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n    'normalize': [True, False],\n    'copy_X' : [True, False],\n    'max_iter' : [10, 100, 500, 1000]\n}\n\nparameter_space_EN = {\n    'alpha' : [300, 500,1000,1500] ,\n    'l1_ratio' : [0.1, 0.5, 1] ,\n    'fit_intercept' : [True, False] ,\n    'normalize' : [True, False] ,\n    'max_iter' : [10, 100, 500, 1000],\n    'selection' : ['cyclic', 'random'],\n}\n\nparameter_space_KN = {\n    'n_neighbors' : [1,5,10,20,30,40,50],\n    'weights' : ['uniform', 'distance'],\n    'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n    'leaf_size' : [1,2,20,50,200],\n    'p' : [1,2],\n}\n\nparameter_space_DT = {\n    'criterion' : ['mse', 'friedman_mse', 'mae', 'poisson'] ,\n    'splitter' : ['best', 'random'],\n    'max_depth' : [5,10,20,50],\n}\n\nparameter_space_GB = {\n    'loss' : ['ls', 'lad', 'huber', 'quantile'],\n    'learning_rate' : [0.1,0.2, 0.5],\n    'n_estimators' : [180, 200,300],\n    'criterion' : ['friedman_mse', 'mse', 'mae'],\n}\n\nparameter_space_RF = {\n    'n_estimators' : [100,120],\n    'criterion' : ['mse', 'mae'],\n    'max_depth' : [10,15,30],\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:57.744735Z","iopub.execute_input":"2021-06-07T19:06:57.745142Z","iopub.status.idle":"2021-06-07T19:06:57.75583Z","shell.execute_reply.started":"2021-06-07T19:06:57.745106Z","shell.execute_reply":"2021-06-07T19:06:57.754721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### **Applying these combination in our model using GridsearchCV**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n\nLG = LinearRegression()\nSV = SVR()\nKN = KNeighborsRegressor()\nDT = DecisionTreeRegressor(random_state=123)\nGB = GradientBoostingRegressor(random_state=123)\nRF = RandomForestRegressor(random_state=123)\n\nmodels = [LG, SV, KN, DT, GB, RF,]\nmodel_name = [ 'Linear Regression', 'Support Vector Regression', 'K Nearest Neighbor', \n              'Decision Tree', 'Gradient Boost', 'Random Forest' ]\nparameter_space = [parameter_space_LG, parameter_space_SV, parameter_space_KN, \n                  parameter_space_DT, parameter_space_GB, parameter_space_RF]\n\nfor i in range(6):\n    clf = GridSearchCV(models[i],parameter_space[i] , n_jobs=4,\n                   cv=None, scoring=\"neg_mean_absolute_error\")\n\n    clf.fit(train[features], train[target])\n    print(f'{model_name[i]}:')\n    print(\"Best parameters:\")\n    print(clf.best_params_)\n    print('')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:06:57.75708Z","iopub.execute_input":"2021-06-07T19:06:57.757411Z","iopub.status.idle":"2021-06-07T19:43:00.976467Z","shell.execute_reply.started":"2021-06-07T19:06:57.757376Z","shell.execute_reply":"2021-06-07T19:43:00.975463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After performing Grid Search to our parameters combinations, we can conclude that:\n- Linear Regression will have highest accuracy with parameters: {'copy_X': True, 'fit_intercept': True, 'normalize': True, 'positive': False}\n- Support Vector Regression will have its highest accuracy among the given combination with parameters taken as: {'C': 100, 'coef0': 7, 'degree': 5, 'gamma': 0.1, 'kernel': 'poly'}\n- K Nearest Neighbor's optimum parameterss are: {'algorithm': 'ball_tree', 'leaf_size': 200, 'n_neighbors': 10, 'p': 1, 'weights': 'distance'}\n- Decision Tree has following optimum parameter values: {'criterion': 'mae', 'max_depth': 5, 'splitter': 'best'}\n- For Gradient Boost to perform best, the parameters will be: {'criterion': 'mse', 'learning_rate': 0.1, 'loss': 'huber', 'n_estimators': 200}\n- Random Forest will be having its best performance with parameters: {'criterion': 'mae', 'max_depth': 15, 'n_estimators': 100}","metadata":{}},{"cell_type":"code","source":"LG_ = LinearRegression(copy_X=True, fit_intercept=True, normalize=True, positive=False, )\nSV_ = SVR(C=100, coef0=7, degree=5, gamma=0.1, kernel='poly', )\nKN_ = KNeighborsRegressor(algorithm='ball_tree', leaf_size=200,\n                         n_neighbors=10, p=1, weights='distance')\nDT_ = DecisionTreeRegressor(criterion='mae', max_depth=5, splitter='best', random_state=123)\nGB_ = GradientBoostingRegressor(criterion='mse', learning_rate=0.1, \n                                loss='huber', n_estimators=200, random_state=123)\nRF_ = RandomForestRegressor(criterion='mae', max_depth=15, n_estimators=100, random_state=123)\n\nmodels = [LG_, SV_, KN_, DT_, GB_, RF_,]\nmodel_name = [ 'Linear Regression', 'Support Vector Regression', 'K Nearest Neighbor', \n              'Decision Tree', 'Gradient Boost', 'Random Forest' ]\n\n\nmeans = []\nr2_score_ = []\nkf = KFold(5, True, random_state=123)\n\nfor i in range(len(models)):\n    maes = []\n    r2s = []\n    model = models[i]\n\n    for train_index, test_index in kf.split(data):\n        train = data.iloc[train_index]\n        test = data.iloc[test_index]\n        model.fit(train[features], train[target])\n        prediction = model.predict(test[features])\n        mae = mean_absolute_error(prediction, test[target])\n        r2 = r2_score(test[target], prediction)\n        maes.append(mae)\n        r2s.append(r2)\n        \n    means.append(np.mean(maes))\n    r2_score_.append(np.mean(r2s))\n    \n    \nmod_comp = pd.DataFrame({'Models' : model_name, 'Mean Absolute Error' : means,\n                            'R2_Score' : r2_score_}).set_index('Models')\nmod_comp","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:44:08.628929Z","iopub.execute_input":"2021-06-07T19:44:08.62922Z","iopub.status.idle":"2021-06-07T19:45:18.574535Z","shell.execute_reply.started":"2021-06-07T19:44:08.629194Z","shell.execute_reply":"2021-06-07T19:45:18.573663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### **After hyperparameter tuning we can see that:**\n- Performance of each model except Linear Regression has been improved.\n- SVR performance has improved alot.\n- Among all models that we have used in this ML, Gradient Boost has performed the best with minimum MAE and highest r2_Score.","metadata":{}},{"cell_type":"code","source":"# MAES with default parameters\nmod_comp_def","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:45:18.576046Z","iopub.execute_input":"2021-06-07T19:45:18.576399Z","iopub.status.idle":"2021-06-07T19:45:18.585361Z","shell.execute_reply.started":"2021-06-07T19:45:18.576362Z","shell.execute_reply":"2021-06-07T19:45:18.584412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mod_comp = mod_comp.sort_values('Mean Absolute Error')\nmod_comp_def = mod_comp_def.sort_values('Mean Absolute Error')","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:45:18.587382Z","iopub.execute_input":"2021-06-07T19:45:18.587749Z","iopub.status.idle":"2021-06-07T19:45:18.597026Z","shell.execute_reply.started":"2021-06-07T19:45:18.587713Z","shell.execute_reply":"2021-06-07T19:45:18.596432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mod_comp_def","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:45:18.59803Z","iopub.execute_input":"2021-06-07T19:45:18.59839Z","iopub.status.idle":"2021-06-07T19:45:18.611487Z","shell.execute_reply.started":"2021-06-07T19:45:18.598354Z","shell.execute_reply":"2021-06-07T19:45:18.610704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### **Merging Both Results**","metadata":{}},{"cell_type":"code","source":"final = mod_comp.copy()\nfinal['Mean Absolute Error_Before'] = mod_comp_def['Mean Absolute Error']\nfinal['R2_Score_Before'] = mod_comp_def['R2_Score']\nfinal.reset_index(inplace=True)\nfinal","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:45:18.612613Z","iopub.execute_input":"2021-06-07T19:45:18.612953Z","iopub.status.idle":"2021-06-07T19:45:18.630116Z","shell.execute_reply.started":"2021-06-07T19:45:18.612927Z","shell.execute_reply":"2021-06-07T19:45:18.629243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Mean Absolute Error Comparison Before and After Hyperparameter Tuning**","metadata":{}},{"cell_type":"code","source":"sns.set(font_scale=1.5)\nmy_ticks = ['Gradient Boost', 'Random Forest', 'SVR', 'KNN', 'Linear Reg.', 'Decision Tree']\n\nmylegends = ['Mean Absolute Error_After', 'Mean Absolute Error_Before']\nax = final[['Mean Absolute Error', 'Mean Absolute Error_Before']].plot.bar(figsize=(15,9), \n                                                                           color = ['SteelBlue', 'SeaGreen'])\nax = final['Mean Absolute Error'].plot(ls='--', lw=3, marker='o', color='SteelBlue')\nax = final['Mean Absolute Error_Before'].plot(ls='-.', lw=3, marker='o', color='SeaGreen')\nax.set_xticklabels(my_ticks)\nax.legend(title='MAE', labels=mylegends)\n\nplt.xticks(rotation=-30)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:45:18.631162Z","iopub.execute_input":"2021-06-07T19:45:18.631408Z","iopub.status.idle":"2021-06-07T19:45:18.861022Z","shell.execute_reply.started":"2021-06-07T19:45:18.631386Z","shell.execute_reply":"2021-06-07T19:45:18.860178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **r2_Score Comparison Before and After Hyperparmeter Tuning.**","metadata":{}},{"cell_type":"code","source":"sns.set(font_scale=1.5)\nmy_ticks = ['Gradient Boost', 'Random Forest', 'SVR', 'KNN', 'Linear Reg.', 'Decision Tree']\n\nmylegends = ['R2_Score_After', 'R2_Score_Before']\nax = final[['R2_Score', 'R2_Score_Before']].plot.bar(figsize=(15,12), color = ['LightSalmon', 'Teal'])\nax = final['R2_Score'].plot(ls='--', lw=3, marker='o', color = 'DarkSalmon')\nax = final['R2_Score_Before'].plot(ls='-.', lw=3, marker='o', color='Teal')\nax.set_xticklabels(my_ticks)\nax.legend(title='R2_Score', labels=mylegends)\n\nplt.xticks(rotation=-30)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T19:45:18.861994Z","iopub.execute_input":"2021-06-07T19:45:18.862217Z","iopub.status.idle":"2021-06-07T19:45:19.107865Z","shell.execute_reply.started":"2021-06-07T19:45:18.862195Z","shell.execute_reply":"2021-06-07T19:45:19.107224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **As you can see that after parameters' hypertuning Gradient Boost performs best among other regression models, having lowest Mean Absolute Error and Highest r2_Score**","metadata":{}}]}