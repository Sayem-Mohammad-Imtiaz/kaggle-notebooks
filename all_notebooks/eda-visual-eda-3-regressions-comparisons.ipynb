{"cells":[{"metadata":{"_uuid":"ffcb83c3a423a4aca6456f723134981b790dc62b"},"cell_type":"markdown","source":"# Hello, this notebook will have:\n### EDA\n### Visual EDA            \n### Application of Some Good Regression Models with Sklearn\n### Visually and Statisticly Comparisons of the Results\n\n# ---------------------------------------------------------------------------------------------------------------"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt  # data visualization","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"Let's start with the \"column_2C_weka.csv\""},{"metadata":{"trusted":true,"_uuid":"caed8cef7eaec6ee10341c14d75f3b18a7adcc1e"},"cell_type":"code","source":"data_2C = pd.read_csv(\"../input/column_2C_weka.csv\")  # for clearence I will name both of my DataFrames corresponding to original csv files","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abf515cb39676bb732b2e82be82b4df739109692"},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true,"_uuid":"9acd349b9cd7741e4c603a985efd1cecc0afcd0c"},"cell_type":"code","source":"data_2C.info()    # except our classes, whole dataset is float and there is no null value at all.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b04c28b1e11209d826663f0535abe6b6211badc"},"cell_type":"code","source":"data_2C.head(10)   # as we also know from the overview provided by owner of data, there is only 2 classes, Normal and Abnormal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1281ef13c77872b544f99f3d502aa5b2acc17343"},"cell_type":"code","source":"data_2C.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"1cf6abf876fe467c0d7b08bdd6f45bb1a0a93da5"},"cell_type":"code","source":"data_2C.corr()  # there are some highly correlated columns. such as pelvic_incidence and sacral_slope","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a5a07e04ec5db4afbd347110f0faecf2174f3a7"},"cell_type":"markdown","source":"## Visual EDA"},{"metadata":{"trusted":true,"_uuid":"be64fe07586ea7cc5d542fbad8089dc043d3cc08"},"cell_type":"code","source":"import seaborn as sns   # for making better plots easily\nsns.pairplot(data_2C,hue=\"class\",palette=\"Set2\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4cb1bc1a612894f8bc3043b82d579765f7a2fc74"},"cell_type":"markdown","source":"We can see that \"Normal\" people's values are very near. On the other hand \"Abnormal\" values are literally messy and quite separated. \n\nA simple Boxplot would show it even clearly."},{"metadata":{"trusted":true,"_uuid":"7de211a5fb60320e3e34d671ae1e8c7047c67938"},"cell_type":"code","source":"data_2C.boxplot(figsize=(20,16),by=\"class\",grid=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eab1cafff2337972385a1b0cc03a62ae95f36258"},"cell_type":"markdown","source":"Plots above again showed us that \"Abnormal\"  data values (left side on plots from our view) has wider range and noisy.\n\nAn another goal of this Notebook is using regression models on the data, so I need to find some correlated values to use these models. \nWe already saw some correlated columns on EDA phase but let's create visual representation too."},{"metadata":{"trusted":true,"_uuid":"b9cee3d6ccd77ca4df680fc5095b3be35ab42303"},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.heatmap(data_2C.corr(),vmax=1,vmin=-1,linewidths=0.4,annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e7e98d220225bdecc1cceb60a907dffa1467c345"},"cell_type":"markdown","source":" I decided to do my regrressions on pelvic_incidence and sacral_slope becasue they are most correlated columns by far"},{"metadata":{"_uuid":"82d49136e49f363b67c8af62da6b10d6fc5b492c"},"cell_type":"markdown","source":"## Regression Models"},{"metadata":{"trusted":true,"_uuid":"1070275c10915440a1fe6f2c371c7450de214d92"},"cell_type":"code","source":"# first I will work on our x and y values for model\n\nx_train = data_2C.pelvic_incidence.values.reshape(-1,1)   # shape is crucial for sklearn models since they don't work well with \"(n,)\" style shapes.\ny_train = data_2C.sacral_slope.values.reshape(-1,1)\n\nx_test = np.arange(min(x_train),max(x_train)).reshape(-1,1)   # to predict each possible value between lowest and highest x values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a7bce77d159c4ed9a9dc036a13734a1eccdac3f"},"cell_type":"markdown","source":"Let's see how it looks for regression."},{"metadata":{"trusted":true,"_uuid":"1ce2aa0471f916a31f65d597eb8bfc056acb0953"},"cell_type":"code","source":"plt.clf()\nplt.figure(figsize=(10,6))\nplt.scatter(x_train,y_train,c=\"orange\")\nplt.xlabel(\"pelvic incidence\")\nplt.ylabel(\"sacral slope\")\nplt.show()   # it's very sutiable especially for regression.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89dead8382c974c3abd6d2bcfac12e1aa9f62f54"},"cell_type":"markdown","source":"I will use 3 different Regression models for my data then evaluate them\n\n### Model #1: Linear Regression"},{"metadata":{"trusted":true,"_uuid":"437312840d6a2daa1f38b010157d4df6177cfa97"},"cell_type":"code","source":"# importing the model\nfrom sklearn.linear_model import LinearRegression\n# declaring the model\nlr_model = LinearRegression()\n# training the model\nlr_model.fit(x_train,y_train)\n\n# predicting for all x_test (for graph) values (sequential) and storing in lr_y_head\nlr_y_head = lr_model.predict(x_test)\n\n# predicting real x values for score evaluation\nlr_y_head_real = lr_model.predict(x_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6bdd804e6e333eaed3625e79e7b485f74d064d4d"},"cell_type":"markdown","source":"### Model #2: Decision Tree Regression"},{"metadata":{"trusted":true,"_uuid":"0a523a932a57221f665ccf71ff39e8d9884ceddd"},"cell_type":"code","source":"# importing the model\nfrom sklearn.tree import DecisionTreeRegressor\n# declaring the model\ndtr_model = DecisionTreeRegressor()\n# training the model\ndtr_model.fit(x_train,y_train)\n\n# predicting for all x_test values and storing in dtr_y_head\ndtr_y_head = dtr_model.predict(x_test)\n\n# predicting for all x_test (for graph) values (sequential) and storing in dtr_y_head\ndtr_y_head_real = dtr_model.predict(x_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ce9b0a1c644c65bba70f43435bae97c05502e27"},"cell_type":"markdown","source":"### Model #3: RandomForest Regression"},{"metadata":{"trusted":true,"_uuid":"bccab0593a993ea5832b342bb2a6ef430a5379e1"},"cell_type":"code","source":"# importing the model\nfrom sklearn.ensemble import RandomForestRegressor\n# declaring the model and setting amount of trees to the 128\nrf_model = RandomForestRegressor(n_estimators=128,random_state=42)\n# training the model\nrf_model.fit(x_train,y_train)\n\n# predicting for all x_test values and storing in rf_y_head\nrf_y_head = rf_model.predict(x_test)\n\n# predicting for all x_test (for graph) values (sequential) and storing in rf_y_head\nrf_y_head_real = rf_model.predict(x_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b06dfeabf57f4d4bd0428b21db10535e3400f9c1"},"cell_type":"markdown","source":"Since I predicted with all 3 different models, I can visualize them and see how they worked"},{"metadata":{"trusted":true,"_uuid":"5786f9a21650f3ba6c466e64c5b125f037696cde"},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.scatter(x_train,y_train,c=\"gray\")\nplt.xlabel(\"pelvic incidence\")\nplt.ylabel(\"sacral slope\")\nplt.plot(x_test,lr_y_head,c=\"red\",label=\"Linear Regression\",linewidth=4)\nplt.plot(x_test,rf_y_head,c=\"green\",label=\"RandomForest Regression\",linewidth=4)\nplt.plot(x_test,dtr_y_head,c=\"blue\",label=\"DecisionTree Regression\",linewidth=4)\nplt.legend()\nplt.suptitle(\"COMPARISON OF THE REGRESSION MODELS\",fontsize=20)\nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"796850d50b19025efa9614f570f0247ba165bc37"},"cell_type":"markdown","source":"As seen above, they all worked well on their style. But what about the score?"},{"metadata":{"trusted":true,"_uuid":"0eafc0e9a862d9903ccb7561a90ebf4eeb8d3df6"},"cell_type":"code","source":"from sklearn.metrics import r2_score\n\nprint(\"score of linear regressor:\",          r2_score(y_train,lr_y_head_real))\nprint(\"score of decisiontree regressor:\",    r2_score(y_train,dtr_y_head_real))\nprint(\"score of randomforest regressor:\",    r2_score(y_train,rf_y_head_real))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e70a3352ce30ababc9cf302127f1c0189c261f54"},"cell_type":"code","source":"algorithms = (\"Linear Regression\",\"Random Forest Regression\",\"Decision Tree Regression\")\nscores = (r2_score(y_train,lr_y_head_real), r2_score(y_train,dtr_y_head_real), r2_score(y_train,rf_y_head_real))\ny_pos = np.arange(1,4)\ncolors = (\"red\",\"green\",\"blue\")\n\nplt.figure(figsize=(24,12))\nplt.xticks(y_pos,algorithms,fontsize=18)\nplt.yticks(np.arange(0.00, 1.01, step=0.1))\nplt.bar(y_pos,scores,color=colors)\nplt.grid()\nplt.suptitle(\"Bar Chart Comparison of Models\",fontsize=24)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9a824258a822f29e971141c65240b26149e1cfb5"},"cell_type":"markdown","source":"# Conclusion:\nBoth graphs and scores shows that, with simple regressions we can easily make good predictions on this data."},{"metadata":{"trusted":true,"_uuid":"7ddf06d2b6c985b8f75c94143566fe1747fceb37"},"cell_type":"code","source":"# Your Votes and Comments does matter to me. Please share your ideas or advices.       Regards,efe.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52e322146ad6867356eaeecbb2f465898336e509"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}