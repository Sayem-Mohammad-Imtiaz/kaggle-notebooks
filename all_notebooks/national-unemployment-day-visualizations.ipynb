{"cells":[{"metadata":{},"cell_type":"markdown","source":"# National Unemployment Day : Visualizations\n\n## Let's have a look on data and try to create visualizations from it."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import re\nimport json\nimport itertools\nimport collections\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \nfrom wordcloud import WordCloud, ImageColorGenerator\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create \"stop_words\" list so that we can ignore it when creating WordCloud."},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words = set(stopwords.words('english')) \ncustom_stopwords = [\"https\", \"co\", \"he\", \"i\", \"you\", \"we\", \"l\", \"u\"]\n\nwith open(\"../input/wordcloud-hindi-font/Hindi_StopWords.txt\",encoding='utf-8') as f:\n    hindi_stopword= f.read().strip('\\ufeff')\nhindi_stopword = hindi_stopword.split(\", \")\nhindi_stopword = [i.strip(\"'\") for i in hindi_stopword]\n\nfor sw in (hindi_stopword + custom_stopwords):\n    stop_words.add(sw)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/national-unemployment-day/NUD_tweets.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fill NaN cells with NONE.\nBecause in the columns \"user_location\" and \"hashtags\", we can not fill any other value."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.fillna(\"NONE\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Have a look on data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Defining global variables"},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"with open(\"/kaggle/input/wordcloud-hindi-font/city_states_data.json\") as f:\n    CITY_STATE = json.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"HINDI_ENG_LOC = {\n    \"‡§ó‡•ã‡§∞‡§ñ‡§™‡•Å‡§∞\": \"uttar pradesh\",\n    \"‡§ó‡•ã‡§µ‡§æ\": \"goa\",\n    \"‡§¶‡§∞‡§≠‡§Ç‡§ó‡§æ\": \"bihar\",\n    \"‡§†‡§æ‡§£‡•á\": \"maharashtra\",\n    \"‡§∂‡•ã‡§π‡§∞‡§§‡§ó‡§¢\": \"uttar pradesh\",\n    \"‡§∞‡•Ä‡§µ‡§æ\": \"madhya pradesh\",\n    \"‡§π‡§∏‡§®‡§™‡•Å‡§∞\": \"uttar pradesh\",\n    \"‡§õ‡§§‡•ç‡§§‡•Ä‡§∏‡§ó‡•ù\": \"chhattisgarh\",\n    \"‡§™‡§ü‡§®‡§æ\": \"bihar\",\n    \"‡§π‡§Æ‡•Ä‡§∞‡§™‡•Å‡§∞\": \"uttar pradesh\",\n    \"‡§π‡§∏‡•ç‡§§‡§ø‡§®‡§æ‡§™‡•Å‡§∞\": \"uttar pradesh\",\n    \"‡§≠‡•ã‡§™‡§æ‡§≤\": \"madhya pradesh\",\n    \"‡§á‡§ü‡§æ‡§µ‡§æ\": \"uttar pradesh\",\n    \"‡§™‡•ã‡§≤‡§∏‡§∞‡§æ\": \"odisha\",\n    \"‡§≠‡§ü‡§ø‡§Ç‡§°‡§æ\": \"punjab\",\n    \"‡§¨‡§ø‡§π‡§æ‡§∞\": \"bihar\",\n    \"‡§ù‡§æ‡§∞‡§ñ‡§Ç‡§°\": \"jharkhand\",\n    \"‡§¨‡§≤‡§∞‡§æ‡§Æ‡§™‡•Å‡§∞\": \"uttar pradesh\",\n    \"‡§≠‡•Å‡§µ‡§®‡•á‡§∂‡•ç‡§µ‡§∞\": \"odisha\",\n    \"‡§Ü‡§ú‡§º‡§Æ‡§ó‡§¢‡§º\": \"uttar pradesh\",\n    \"‡§Æ‡•Å‡§Ç‡§¨‡§à\": \"maharashtra\",\n    \"‡§Ü‡§Æ‡§ö‡•Ä ‡§Æ‡•Å‡§Ç‡§¨‡§à \": \"maharashtra\",\n    \"‡§∞‡•á‡§µ‡§æ‡§°‡§º‡•Ä\": \"haryana\",\n    \"‡§™‡•ç‡§∞‡§Ø‡§æ‡§ó‡§∞‡§æ‡§ú\": \"uttar pradesh\",\n    \"‡§≤‡§ñ‡§®‡§ä\": \"uttar pradesh\",\n    \"‡§â‡§§‡•ç‡§§‡§∞‡§™‡•ç‡§∞‡§¶‡•á‡§∂\": \"uttar pradesh\",\n    \"‡§â‡§§‡•ç‡§§‡§∞ ‡§™‡•ç‡§∞‡§¶‡•á‡§∂\": \"uttar pradesh\",\n    \"‡§¨‡•ç‡§∞‡§π‡§Æ‡§™‡•Å‡§∞\": \"odisha\",\n    \"‡§ï‡•ã‡§≤‡§ï‡§æ‡§§‡§æ\": \"west bengal\",\n    \"‡§∞‡§æ‡§ú‡§∏‡•ç‡§•‡§æ‡§®\": \"rajasthan\",\n    \"‡§Ö‡§≤‡§µ‡§∞\": \"rajasthan\",\n    \"‡§∞‡§æ‡§ú‡§∏‡•ç‡§•‡§æ‡§®\": \"rajasthan\",\n    \"‡§Ü‡§∏‡§æ‡§Æ\": \"assam\",\n    \"‡§Æ‡§•‡•Å‡§∞‡§æ\": \"uttar pradesh\",\n    \"‡§ß‡§®‡§¨‡§æ‡§¶\": \"jharkhand\",\n    \"‡§Æ‡§ß‡•ç‡§Ø‡§™‡•ç‡§∞‡§¶‡•á‡§∂\": \"madhya pradesh\",\n    \"‡§â‡§§‡•ç‡§§‡§∞ ‡§™‡•ç‡§∞‡§¶‡•á‡§∂\": \"uttar pradesh\",\n    \"‡§â‡§§‡•ç‡§§‡§∞‡§™‡•ç‡§∞‡§¶‡•á‡§∂\": \"uttar pradesh\",\n    \"‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä\": \"delhi\",\n    \"‡§π‡§∞‡§ø‡§Ø‡§æ‡§£‡§æ\": \"haryana\",\n    \"‡§ï‡•ã‡§ú‡§º‡§ø‡§ï‡•ã‡§°\": \"kerala\",\n    \"‡§ú‡§Ø‡§™‡•Å‡§∞\": \"rajasthan\",\n    \"‡§ó‡•Å‡§ú‡§∞‡§æ‡§§\": \"gujarat\",\n    \"‡§Ü‡§∏‡§®‡§∏‡•ã‡§≤\": \"west bengal\",\n    \"‡§´‡§º‡§∞‡•Ä‡§¶‡§æ‡§¨‡§æ‡§¶\": \"haryana\",\n    \"‡§®‡•à‡§®‡•Ä‡§§‡§æ‡§≤\": \"uttarakhand\",\n    \"‡§Æ‡•à‡§Ç‡§ó‡§≤‡•ã‡§∞\": \"karnataka\",\n    \"‡§õ‡§ø‡§Ç‡§¶‡§µ‡§æ‡§°‡§º‡§æ\": \"madhya pradesh\",\n    \"‡§ó‡§æ‡§ú‡§º‡§ø‡§Ø‡§æ‡§¨‡§æ‡§¶\": \"uttar pradesh\",\n    \"‡§®‡•ã‡§è‡§°‡§æ\": \"uttar pradesh\",\n    \"‡§Æ‡§π‡§æ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞\": \"maharashtra\",\n    \"jambughoda\": \"gujarat\",\n    \"canada\": \"canada\",\n    \"nelamanagala\": \"karnataka\",\n    \"u.p\": \"uttar pradesh\",\n    \"ghaziyabad\": \"uttar pradesh\",\n    \"ùêëùêÄùêâùêÄùêíùêìùêáùêÄùêç\": \"rajasthan\"\n}\n\nCUSTOM_INDIA_LOC = {\n    \"‡§π‡§ø‡§Ç‡§¶‡•Å‡§∏‡•ç‡§§‡§æ‡§®\": \"india\",\n    \"‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§∏‡•ç‡§§‡§æ‡§®‡•Ä\": \"india\",\n    \"‡§á‡§Ç‡§°‡§ø‡§Ø‡§æ\": \"india\",\n    \"‡§≠‡§æ‡§∞‡§§\": \"india\",\n    \"bharat\": \"india\",\n    \"hindu-stan\": \"india\",\n    \"hindustan\": \"india\",\n    \"india\": \"india\"\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"ALL_STATES = [\"Andhra Pradesh\",\"Arunachal Pradesh \",\"Assam\",\"Bihar\",\"Chhattisgarh\",\"Goa\",\"Gujarat\",\"Haryana\",\"Himachal Pradesh\",\"Jammu and Kashmir\",\"Jharkhand\",\"Karnataka\",\"Kerala\",\"Madhya Pradesh\",\"Maharashtra\",\"Manipur\",\"Meghalaya\",\"Mizoram\",\"Nagaland\",\"Odisha\",\"Punjab\",\"Rajasthan\",\"Sikkim\",\"Tamil Nadu\",\"Telangana\",\"Tripura\",\"Uttar Pradesh\",\"Uttarakhand\",\"West Bengal\",\"Andaman and Nicobar Islands\",\"Chandigarh\",\"Dadra and Nagar Haveli\",\"Daman and Diu\",\"Lakshadweep\",\"Delhi\",\"Puducherry\"]\nALL_STATES = [each_string.lower() for each_string in ALL_STATES]\nALL_STATES.sort()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Download BJP Image for masking WorldCloud"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import requests\nresponse = requests.get(\"https://upload.wikimedia.org/wikipedia/en/thumb/1/1e/Bharatiya_Janata_Party_logo.svg/1200px-Bharatiya_Janata_Party_logo.svg.png\")\nfile = open(\"bjp.png\", \"wb\")\nfile.write(response.content)\nfile.close()\n\nMAP = np.array(Image.open('./bjp.png'))\nImage.open('./bjp.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def only_str(line):\n    return line.apply(lambda x : re.findall(r'([0-9a-zA-Z]+)',x))\n\ndef is_eng(line):\n    return line == line.encode(\"unicode-escape\").decode()\n\ndef simple_text(line):\n    line = line.lower()\n    line = line.replace('‚Äú', \"\").replace('‚Äù', \"\").replace('‚Ä¶', \"\").replace('_', \"\").replace(\"co\", \"\")\n    return line","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def create_list(df, column):\n    temp = df.copy()\n    temp[column] = temp[column].apply(lambda x: word_tokenize(x))\n    temp[column] = temp[column].apply(lambda x: [w for w in x if w not in stop_words])\n    temp[column] = temp[column].apply(lambda x: ' '.join(x))\n    t = temp[column].apply(lambda x: word_tokenize(x)).apply(lambda x: ' '.join(x)).tolist()\n    return t\n\n\ndef create_word_cloud(df, column): \n    t = \" \".join(create_list(df, column))\n    wordcloud = WordCloud(font_path=\"../input/wordcloud-hindi-font/Nirmala.ttf\", \n                          background_color='white', max_words=800, width=800, height=400).generate(t)\n    plt.figure( figsize=(20,10) )\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n\n\ndef bjp_word_cloud(df, column):\n    long_text = ' '.join(eng_data[column].tolist())\n    # Generate a word cloud image\n    mask = np.array(Image.open(\"./bjp.png\"))\n    wordcloud_usa = WordCloud(font_path=\"../input/wordcloud-hindi-font/Nirmala.ttf\",\n                              stopwords=stop_words, background_color=\"white\", mode=\"RGBA\", \n                              max_words=800, mask=mask, width=1000, height=1000).generate(long_text)\n\n    # create coloring from image\n    image_colors = ImageColorGenerator(mask)\n    plt.figure(figsize=[10,10])\n    plt.imshow(wordcloud_usa.recolor(color_func=image_colors), interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.savefig('bjp_word_cloud.png')\n    plt.show()\n\n\ndef word_count_graph(df, column, num):\n    temp = pd.DataFrame()\n    temp[column] = only_str(df[column]).apply(lambda x: ' '.join(x))\n    all_words = word_tokenize(\" \".join(create_list(temp, column)))\n    word_counts = collections.Counter(all_words)\n    word_counts_data = pd.DataFrame(word_counts.most_common(num),columns=['words', 'count'])\n    \n    fig, ax = plt.subplots(figsize=(10, 10))\n    # Plot horizontal bar graph\n    word_counts_data.sort_values(by='count').plot.barh(x='words', y='count', ax=ax)\n\n    ax.set_title(\"Most Common Words\")\n    plt.show()\n\n\ndef word_count_to_df(df, column):\n    filtered = pd.DataFrame()\n    filtered[column] = only_str(df[column]).apply(lambda x: ' '.join(x))\n    filtered_list = create_list(filtered,column)\n    return pd.DataFrame({column:word_tokenize(\" \".join(filtered_list))})\n\ndef create_sns_graph(df, column, num):\n    count  = df[column].value_counts()\n    count = count[:num,]\n    plt.figure(figsize=(16,9))\n    sns.barplot(count.index, count.values, alpha=1)\n    # plt.title('Tweets vs User Location')\n    plt.ylabel('Number of Occurrences', fontsize=12)\n    # plt.xlabel('State', fontsize=12)\n    plt.xticks(rotation=90)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"def replace_text1(x):\n    if \"NONE\" in x:\n        return \"NONE\"\n    for state in ALL_STATES:\n        if state in x.lower():\n            return state\n    return x.lower()\n\ndef replace_text(x, func_type):\n    if \"NONE\" in x:\n        return \"NONE\"\n    x = x.lower()\n    if func_type == \"city_state\":\n        for cs in CITY_STATE.keys():\n            if cs.lower() in x:\n                return CITY_STATE[cs].lower()\n    \n    if func_type == \"all_state\":\n        for state in ALL_STATES:\n            if state in x.lower():\n                return state\n\n    if func_type == \"hindi_eng\":\n        for he in HINDI_ENG_LOC.keys():\n            if he.lower() in x:\n                return HINDI_ENG_LOC[he]\n    \n    if func_type == \"india\":\n        for ci in CUSTOM_INDIA_LOC.keys():\n            if ci.lower() in x:\n                return CUSTOM_INDIA_LOC[ci]\n    \n    return x\n\ndef replace_spec(x, spec, change):\n    if \"NONE\" in x:\n        return \"NONE\"\n    if spec.lower() in x.lower():\n        return change.lower()\n    else:\n        return x.lower()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Get number of tweets from different states\n\n## 1.1 Cleaning and try to get all the location to states. \n### But remember, it also contains non-english words and text which doesn't belongs to any city or state."},{"metadata":{},"cell_type":"markdown","source":"## 1.2 Normalize user_location column\nInitially, the unique values in \"user_location\" column are 1830."},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_loc = data.user_location\nunique_loc.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"unique_loc = unique_loc.apply(replace_text, args=(\"hindi_eng\",))\nunique_loc.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"unique_loc = unique_loc.apply(replace_text, args=(\"city_state\",))\nunique_loc.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"unique_loc = unique_loc.apply(replace_text, args=(\"all_state\",))\nunique_loc.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"unique_loc = unique_loc.apply(replace_text, args=(\"india\",))\nunique_loc.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### From ***1830*** to ***488***, user_location column have 488 unique values now."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.user_location = unique_loc\n# data.user_location.nunique()  # 488","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.3 Let's check total number of tweets from different states"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.user_location.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.4 See it on PIE Chart"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# create a dictionary of classes and their totals\nd = data.user_location.value_counts().loc[lambda x : x>50] .to_dict()  # counts greater than 5\n\nfig = plt.figure(figsize = (18, 6))\nax = fig.add_subplot()\n\n# plot the data using matplotlib\nax.pie(d.values(), # pass the values from our dictionary\n       labels = d.keys(), # pass the labels from our dictonary\n       autopct = '%1.1f%%', # specify the format to be plotted\n       textprops = {'fontsize': 10, 'color' : \"white\"} # change the font size and the color of the numbers inside the pie\n      )\n\n# set the title\nax.set_title(\"Twitter Users\")\n\n# set the legend and add a title to the legend\nax.legend(loc = \"upper left\", bbox_to_anchor = (1, 0, 0.5, 1), fontsize = 10, title = \"User's Location\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_count_graph(data, \"user_location\", 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Verified <-> Non-Verified user"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.user_verified.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.1 See it on PIE Chart"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# create a dictionary of classes and their totals\nd = data.user_verified.value_counts().to_dict()\n\nfig = plt.figure(figsize = (18, 6))\nax = fig.add_subplot()\n\n# plot the data using matplotlib\nax.pie(d.values(), # pass the values from our dictionary\n       labels = d.keys(), # pass the labels from our dictonary\n       autopct = '%1.1f%%', # specify the format to be plotted\n       textprops = {'fontsize': 10, 'color' : \"white\"} # change the font size and the color of the numbers inside the pie\n      )\n\n# set the title\nax.set_title(\"Twitter Users\")\n\n# set the legend and add a title to the legend\nax.legend(loc = \"upper left\", bbox_to_anchor = (1, 0, 0.5, 1), fontsize = 10, title = \"Verified Twitter User\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Let's check \"hashtags\" column"},{"metadata":{},"cell_type":"markdown","source":"## 3.1 Sperate hashtags column according to the data it contains\n### 3.1.1 Creating different Dataframes on the basis of \"hashtags\" column."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"text\"] = data[\"text\"].apply(simple_text)\neng_data = data[data[\"hashtags\"].apply(is_eng) == True]\neng_data = eng_data[eng_data[\"hashtags\"] != \"NONE\"]\nnon_eng_data = data[data[\"hashtags\"].apply(is_eng) == False]\nnon_eng_data = non_eng_data[non_eng_data[\"hashtags\"] != \"NONE\"]\nno_hashtag = data[data[\"hashtags\"]==\"NONE\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.1.2 Check number of records in each dataframes created and it should be equal to total records in original dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(eng_data.shape)\nprint(no_hashtag.shape)\nprint(non_eng_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"eng_data = eng_data.reset_index(drop=True)\nno_hashtag = no_hashtag.reset_index(drop=True)\nnon_eng_data = non_eng_data.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Bar-Graph Visualizations\n## 4.1 Create bar graph for most frequent words in \"text\" column of whole dataset."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"word_df = word_count_to_df(data, \"text\")\ncreate_sns_graph(word_df, \"text\", 30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.2 Create bar graph for most frequent words in \"text\" column in \"english\" hashtags."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"word_df = word_count_to_df(eng_data, \"text\")\ncreate_sns_graph(word_df, \"text\", 30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.3 Create bar graph for most frequent words in \"text\" column in \"non_english\" hashtags."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"word_df = word_count_to_df(non_eng_data, \"text\")\ncreate_sns_graph(word_df, \"text\", 30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.4 Create bar graph for most frequent words in \"text\" column in \"NONE\" hashtags."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"word_df = word_count_to_df(no_hashtag, \"text\")\ncreate_sns_graph(word_df, \"text\", 30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. WordCloud visualizations\n## 5.1. Create WordCloud for most frequent words in \"text\" column of whole dataset. #BJP"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"bjp_word_cloud(data, \"text\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.2 Create WordCloud for most frequent words in \"text\" column of whole dataset."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"create_word_cloud(data, \"text\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.3 Create WordCloud for most frequent words in \"text\" column for \"english\" hashtags."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"create_word_cloud(eng_data, \"text\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.4 Create WordCloud for most frequent words in \"text\" column for \"non_english\" hashtags."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"create_word_cloud(non_eng_data, \"text\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.5 Create WordCloud for most frequent words in \"text\" column which have no hashtags."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"create_word_cloud(no_hashtag, \"text\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}