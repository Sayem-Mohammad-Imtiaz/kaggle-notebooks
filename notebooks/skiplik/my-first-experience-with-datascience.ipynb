{"cells":[{"metadata":{"_uuid":"bc05346ba5ffe6d9bfaa8e5a5d4d47a773e662b3"},"cell_type":"markdown","source":"# Preamble\nThis is my first data science project. I learned a lot due to this project, whether it's in python or in the area of data science. The biggest part in such projects is the data preparation and cleansing. As well as in every other data science project, I spend a lot of time here until I came  to the most fun part, the model building and prediction. I tried and errored different approaches during the data preparation, read about better ways and worse ways to do it. I sometimes used the long way to get a better understanding of how the data has to be prepared instead of using the short and faster approach. \nThe main goal of this project is to show some ways of data preparation as well as  predict the delay of a flight based on his input features. Therefore I needed to prepare and create data, which will be handled in the first chapter ***“Data Analysis and Preprocessing”***. There I will give an overview of the data structure and the data condition as well. The next chapter then, will contain the ***“Feature and Label Selection”*** were especially the features will be determined by different feature selections approaches. According to the goal of predicting the delay, the target of this essay is the *flight delay at arrival*. To determine the target I use the Random Forest Regression approach. The amount of 5 million flights is quite a lot for the computation time, therefore I will slice smaller size datasets and use them for prediction.\n\nI would be very pleased for any feedback on this project and the coding ways. ***So feel free to leave some comments***. It's my first project and it can only get better. I am looking forward to your feedback and a upvote if liked it. <br>\n***Thanks a lot.***\n<br>\n<br>\nCheers,<br>\nRobin\n\n___"},{"metadata":{"_uuid":"7385acb24f0e77fb79cb8a8e43b4bec4a73cd307","_cell_guid":"2cc382a8-b0e0-4db2-b3c7-5cfe7ba90ade"},"cell_type":"markdown","source":"# Imports\n## Library Imports and Helpers"},{"metadata":{"_uuid":"9f2337d327b8b9457899d79719e465da8117a0ca","_cell_guid":"51a7ec73-d36e-4165-ac67-087f3a78149d","trusted":true},"cell_type":"code","source":"# Imports \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib as mpl\nimport matplotlib.gridspec as gridspec\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nfrom mpl_toolkits.basemap import Basemap\n\n\nimport seaborn as sns\n\n#maschine learning libraries\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix \n\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.svm import SVC\n\nimport datetime\nimport time\nfrom time import strftime, gmtime","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62dc9902cc92a950c93841547c3c76e25a1ca61d","_cell_guid":"5b7fb6ef-61ff-4794-95a7-42743c0f0f95"},"cell_type":"markdown","source":"## CSV-File Import"},{"metadata":{"_uuid":"f134c7c8eddad806b336abae986311179410680b","_cell_guid":"425f28df-8e02-4928-b280-34050a60b6db","trusted":true},"cell_type":"code","source":"df_flights = pd.read_csv('../input/flights.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4fe699506eb906fbf90f6e9ed66e5ae027f13d83","_cell_guid":"546fe8f4-ee1c-4868-91cd-5c6940a69824"},"cell_type":"markdown","source":"# Data Analysis and Preprocessing\nThe following is the first overview of all attributes:"},{"metadata":{"_uuid":"15a3a305c30bdebee44df534d00677dc8de12d0c","_cell_guid":"79aabdf4-bf84-4ad1-97ba-b39f34e107f5","trusted":true},"cell_type":"code","source":"df_flights.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78bb6d34323139c6f7e6dce5962870141e8308a7"},"cell_type":"markdown","source":"The first thing I noticed is the missing date for each record. It is separated into the attribute **YEAR**, **MONTH** and **DAY**. I could create a full date out of these values right now, but in further processing, a datetime object or a string object could lead to more problems. Right now we have got clean numerical values which can be integrated in any prediction model without problems:"},{"metadata":{"trusted":true,"_uuid":"62d4a61eb046dfa450e70b971b2a355e4bfb3988"},"cell_type":"code","source":"df_flights.loc[:,('YEAR','MONTH','DAY')].dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ecbf04a25c9034e941377e365e0067df95e7b5a9"},"cell_type":"code","source":"df_flights.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25005d306b36817c5136161b8c074817648f9ea2","scrolled":true},"cell_type":"code","source":"df_flights.head(15)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"debd00bc8b43116ac70da23cad80571d9c6b58fd"},"cell_type":"markdown","source":"## Overview\n\nLets get an overview. We have a **CANCELLATION_REASON**, that has not so much value in comparison to the other attribute. Another anomaly is found in the attributes **AIR_SYSTEM_DELAY**, **SECURITY_DELAY**, **AIRLINE_DELAY**, **LATE_AIRCRAFT_DELAY** and **WEATHER_DELAY**. These attributes have only one-fifth of what the other attributes have. \n\nThere are a lot of time values whether it is a time value or just a minute value but there are all stored as a numerical value:\n    - SCHEDULED_DEPARTURE\n    - DEPARTURE_TIME\n    - DEPARTURE_DELAY\n    - TAXI_OUT\n    - WHEELS_OFF\n    - SCHEDULED_TIME\n    - ELAPSED_TIME\n    - AIR_TIME\n    - WHEELS_ON\n    - TAXI_IN\n    - SCHEDULED_ARRIVAL\n    - ARRIVAL_TIME\n    - ARRIVAL_DELAY\n    - AIR_SYSTEM_DELAY\n    - SECURITY_DELAY\n    - AIRLINE_DELAY\n    - LATE_AIRCRAFT_DELAY\n\n\nThis list can also be divided into two types of time vales. The one that is actually real-time values and the one that is only minute values:\n\n***Time of Day Values:***\n    - ARRIVAL_TIME\n    - DEPARTURE_TIME\n    - SCHEDULED_DEPARTURE\n    - WHEELS_ON\n    - WHEELS_OFF\n    - SCHEDULED_ARRIVAL\n        \n        \n***Minute Values:***\n    - DEPARTURE_DELAY\n    - TAXI_IN \n    - TAXI_OUT\n    - SCHEDULED_TIME\n    - ELAPSE_TIME\n    - AIR_TIME\n    - ARRIVAL_DELAY\n    - AIR_SYSTEM_DELAY\n    - SECURITY_DELAY\n    - AIRLINE_DELAY\n    - LATE_AIRCRAFT_DELAY\n\nIt now becomes clear that the actual delay is missing. The delay them self will be the focus on this work according to predict a delayed flight. Later more. \n\nDespite the time values there are some none time values:\n\n- **AIRLINE** - consists out of two letter airline shortcuts corresponding to the data out of the airline.csv.\n\n- **FLIGHT_NUMBER** - A code for an airline service to identify a flight from a departure a destination.\n\n- **TAIL_NUMBER** - The common unique flight number of the flight.\n\n- **ORIGIN_AIRPORT**  and **DESTINATION_AIRPORT** include the three letter IATA-Codes for the Airports.\n\n\n### Delay Times\nThe flight delays have already been calculated in the field **ARRIVAL_DELAY**. It is the difference out of **ARRIVAL_TIME** and **SCHEDULED_ARRIVAL**. Therefore the **ARRIVAL_DELAY** is negative when the flight arrives in (scheduled) time and positive when it is delayed.\n\n"},{"metadata":{"_uuid":"8d8b6827ee7a47fee476795d9b14a4f13e2b2b35"},"cell_type":"markdown","source":"## Analyzing Datatypes\nFirst of all, I will take a look at our dataset and analyze our datatypes. "},{"metadata":{"trusted":true,"_uuid":"803b0878fc72fd72309c8fd9f4aba127c22ee0db","scrolled":false},"cell_type":"code","source":"df_flights.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0abd2e80c73bae620eede46eaae1925a7b517849"},"cell_type":"markdown","source":"We already knew we have two different time values, the ***time of day*** and the ***minute*** values. Especially the ***time of day*** values that are shown below are most frequently stored in a float64 where the first two digits represent the hour and the last two the minutes:\n\n    - SCHEDULED_DEPARTURE\n    - DEPARTURE_TIME\n    - DEPARTURE_DELAY\n    - TAXI_OUT\n    - WHEELS_OFF\n    - SCHEDULED_TIME\n    - ELAPSED_TIME\n    - AIR_TIME\n    - WHEELS_ON\n    - TAXI_IN\n    - SCHEDULED_ARRIVAL\n    - ARRIVAL_TIME\n    - ARRIVAL_DELAY\n    - AIR_SYSTEM_DELAY\n    - SECURITY_DELAY\n    - AIRLINE_DELAY\n    - LATE_AIRCRAFT_DELAY\n    \nThere is a need to convert them all to datetime. In addition, it seems to be helpful to write/use a function for this conversion. (Thanks to  <a href=\"https://www.kaggle.com/fabiendaniel\">fabiendaniel</a> and her great tutorial <a href=\"https://www.kaggle.com/fabiendaniel/predicting-flight-delays-tutorial\">here</a> ):\n"},{"metadata":{"trusted":true,"_uuid":"1bdcb83cf125cf9a8aab66acd5b1512141eb0396"},"cell_type":"code","source":"# converting input time value to datetime.\ndef conv_time(time_val):\n    if pd.isnull(time_val):\n        return np.nan\n    else:\n            # replace 24:00 o'clock with 00:00 o'clock:\n        if time_val == 2400: time_val = 0\n            # creating a 4 digit value out of input value:\n        time_val = \"{0:04d}\".format(int(time_val))\n            # creating a time datatype out of input value: \n        time_formatted = datetime.time(int(time_val[0:2]), int(time_val[2:4]))\n    return time_formatted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efe96e51ffb239d0ecae443374753a3798e3a6ec"},"cell_type":"code","source":"### # convert ARRIVAL_TIME to datetime time format and write it back into df field ARRIVAL_TIME:\ndf_flights['ARRIVAL_TIME'] = df_flights['ARRIVAL_TIME'].apply(conv_time)\ndf_flights['DEPARTURE_TIME'] = df_flights['DEPARTURE_TIME'].apply(conv_time)\ndf_flights['SCHEDULED_DEPARTURE'] = df_flights['SCHEDULED_DEPARTURE'].apply(conv_time)\ndf_flights['WHEELS_OFF'] = df_flights['WHEELS_OFF'].apply(conv_time)\ndf_flights['WHEELS_ON'] = df_flights['WHEELS_ON'].apply(conv_time)\ndf_flights['SCHEDULED_ARRIVAL'] = df_flights['SCHEDULED_ARRIVAL'].apply(conv_time)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41df4353b96bad6cf7cb729c84009e80db4d9819"},"cell_type":"markdown","source":"The required data has now the correct format and can already be viewed:"},{"metadata":{"trusted":true,"_uuid":"5c2fddd264f6fa3eca1b4d1c6c877e9aea1500c5"},"cell_type":"code","source":"df_flights[['YEAR','MONTH','DAY','SCHEDULED_DEPARTURE','DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n       'WHEELS_OFF', 'SCHEDULED_TIME', 'ELAPSED_TIME', 'AIR_TIME','WHEELS_ON', 'TAXI_IN', 'SCHEDULED_ARRIVAL'\n            ,'ARRIVAL_TIME','ARRIVAL_DELAY','AIR_SYSTEM_DELAY','SECURITY_DELAY','AIRLINE_DELAY','LATE_AIRCRAFT_DELAY']].dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7fcae34164a09241ea471aebceb62999af16dfb4"},"cell_type":"markdown","source":"## Handling the Null Values\nAfter I converted the necessary time values to a DateTime datatype, I need to check our data according to its integrity. Null values or missing data are often occurring data states that need to be handled.\n\nIn addition to several other methods, I will focus on two or three methods in this notebook to deal with null value data or missing data.\n\nOne option is to delete the corresponding rows.\n\nAnother case of handling missing or null value data is to reconstruct the missing data according to information from other columns. Imagine there is a start and an end time and only the duration is missing. You could calculate the missing values simply by the difference between end time and start time. Accordingly, you do not have to delete the data column but you can continue to use the information contained in it.\n\nOne of the best ways to handle missing or null value data is the imputation. The imputation will fill the missing gaps with some numbers that are based on existing data columns. The numbers are not as accurate as the real data but fits the needs for the most prediction models and lead to a better resolution of the model. If you need some additional information about that method, read <a href=\"https://www.kaggle.com/dansbecker/handling-missing-values\">this</a> notebook by DanB."},{"metadata":{"trusted":true,"_uuid":"a838397b0d782910bb3c4da13d479ffdc86bbdbf"},"cell_type":"code","source":"#-------------------------------------------------------------\n# null value analysing function.\n# gives some infos on columns types and number of null values:\ndef nullAnalysis(df):\n    tab_info=pd.DataFrame(df.dtypes).T.rename(index={0:'column type'})\n\n    tab_info=tab_info.append(pd.DataFrame(df.isnull().sum()).T.rename(index={0:'null values (nb)'}))\n    tab_info=tab_info.append(pd.DataFrame(df.isnull().sum()/df.shape[0]*100)\n                         .T.rename(index={0:'null values (%)'}))\n    return tab_info","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ebd86675c005db3614f98f64421f3845a2572cd"},"cell_type":"code","source":"nullAnalysis(df_flights)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a53d24577966befe25b6f061a45f81c960df1486"},"cell_type":"markdown","source":"### Reconstruct Data Manually\nOur null analysis above shows the following features with a lot of null values:\n    - CANCELLATION_REASON\n    - AIR_SYSTEM_DELAY\n    - SECURITY_DELAY\n    - AIRLINE_DELAY\n    - LATE_AIRCRAFT_DELAY\n    - WEATHER_DELAY\n    \nIn this case here, I try to determine or \"calculate\" the data by deriving the situation. Look at the values that are mostly empty according to the coherent afford of an airline to not be the reason for a delay. Therefore the missing data (or Not-a-Number data) is not based on a bad data quality, it is more the fact that it didn't happen any action by these delay features. You can prove it by looking at a tuple of one of that features when there is at least one feature triggered, all the other features are **\"initialized\"** with **\"0.0\"**:"},{"metadata":{"trusted":true,"_uuid":"2b526e6c9279d8943661b5e6712e686067c65430"},"cell_type":"code","source":"# show selected columns where AIRLINE_DELAY isnot null\ndf_flights.loc[df_flights['AIRLINE_DELAY'].notnull(), ['AIRLINE_DELAY','AIR_SYSTEM_DELAY','SECURITY_DELAY','AIRLINE_DELAY','LATE_AIRCRAFT_DELAY','WEATHER_DELAY']].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c923389b0ed55c020d5a946ce3038fa67be29c5"},"cell_type":"markdown","source":"So it's ok to transform the NAN-data to the value ***\"0.0\"*** because there was no impact on the flight by these data that causes a delay:"},{"metadata":{"trusted":true,"_uuid":"d9c5d76eeb02224586f79588d0c6700dba45db13"},"cell_type":"code","source":"df_flights['AIRLINE_DELAY'] = df_flights['AIRLINE_DELAY'].fillna(0)\ndf_flights['AIR_SYSTEM_DELAY'] = df_flights['AIR_SYSTEM_DELAY'].fillna(0)\ndf_flights['SECURITY_DELAY'] = df_flights['SECURITY_DELAY'].fillna(0)\ndf_flights['LATE_AIRCRAFT_DELAY'] = df_flights['LATE_AIRCRAFT_DELAY'].fillna(0)\ndf_flights['WEATHER_DELAY'] = df_flights['WEATHER_DELAY'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81da7ffa8afc768a2defa076cac019b46bf40caa"},"cell_type":"code","source":"nullAnalysis(df_flights)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9cec412eefdcc59f045fd88c88955f2cadbc265f"},"cell_type":"markdown","source":"Null values have now decreased significantly. There are only a few attributes left. Particular striking, however, is the **CANCELLATION_REASON** that hits the high mark with around 98% null values. We need to take a closer look at the cancellation data."},{"metadata":{"_uuid":"7deba76f2845b9e05fc064ddcfb157b2756fc60b"},"cell_type":"markdown","source":"### Dealing with Null Values in Categorical Data"},{"metadata":{"trusted":true,"_uuid":"364216cd45c77b67feb083e9e39e62d4331db5fe"},"cell_type":"code","source":"df_flights.loc[df_flights['CANCELLATION_REASON'].notnull(),['CANCELLATION_REASON']].head(15)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5781fbeb9852173ecefc30d50b1065c1a225970"},"cell_type":"markdown","source":"The reason for cancellation of flights splits into the following occurrences:\n- A - Airline/Carrier\n- B - Weather\n- C - National Air System\n- D - Security\n\n... and has the following ration:"},{"metadata":{"trusted":true,"_uuid":"8943528416f12268504fa24599234171c625c8fa"},"cell_type":"code","source":"# group by CANCELLATION_REASON to see the ration\ndf_flights['CANCELLATION_REASON'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e8c5a5cf8ad6d2838086f941717774a414d0174"},"cell_type":"markdown","source":"As you can see the main reason for cancelation is **B** the weather. It is well known that the weather is often the cause of delays and cancelations. In the case of this attribute, we look at the weather as a cancelation reason, not a delay reason. Now there is the following question: If we want to predict delay times from departure flights, is it necessary to include flight cancellation reasons in our calculation? Don't we want to focus only on not canceled flights, on flights with a departure and a (late) arrival time?\nThe answer is: No, we want them all! We don't want to lose data for our prediction. Every information, in this case, is important. For example cancellation reason \"Weather\" for a canceled flight. The flight themselves did not take place, that's right, but what about the consequences of the canceled flights? All the passengers need to get to their destinations, therefore they will be booked on the next flight or moreover the canceled flight will start in another timeshift and will probably block another's plains flight slot. That all leads to a knock-on effect on other flights. \n\n#### \"Manuell\" Conversion of categories to numeric values\nMost models don't work pretty good with categorical values. They need to be converted into numeric values to use a prediction model. There is a way to convert all categorical data into numeric values, its called **One-Hot Encoding**. This approach will line in all categorical values in separate columns, creates a new column and matches every occurrence of the categorical value with 1 or 0 for non-occurrences. You should take a deeper look into it  \n\nAnother approach that is similar to the **One-Hot encoding** approach is included in the Pandas library and is called ***get_dummies()***. This function converts categorical values into dummy/indicator values as well. In this case, all null value data are also converted and filled with ***0*** values. Nevertheless, in this case and according to the small amount of four categorical values, I will convert the **CANCELLATION_REASON** manually. The final result will be the following:\n- NaN = 0\n- A = 1\n- B = 2\n- C = 3\n- D = 4\n"},{"metadata":{"trusted":true,"_uuid":"7034afbf51f308f11612888387f0cee1f8d59227"},"cell_type":"code","source":"# -------------------------------------\n# converting categoric value to numeric\ndf_flights.loc[df_flights['CANCELLATION_REASON'] == 'A', 'CANCELLATION_REASON'] = 1\ndf_flights.loc[df_flights['CANCELLATION_REASON'] == 'B', 'CANCELLATION_REASON'] = 2\ndf_flights.loc[df_flights['CANCELLATION_REASON'] == 'C', 'CANCELLATION_REASON'] = 3\ndf_flights.loc[df_flights['CANCELLATION_REASON'] == 'D', 'CANCELLATION_REASON'] = 4\n\n# -----------------------------------\n# converting NaN data to numeric zero\ndf_flights['CANCELLATION_REASON'] = df_flights['CANCELLATION_REASON'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"628beabb432529bfddabd51fd751a46e3359b514"},"cell_type":"code","source":"# check null values\nnullAnalysis(df_flights)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"997a2213240b5022127e72c8e8cd7bdab67f5b6a"},"cell_type":"markdown","source":"### Null Values in Different Types of Time Values\n\nDue to the null values in the different time values (see evaluation above) I need to get a closer view of these null values.\n\nIn contrast to the other time values (**AIRLINE_DELAY, AIR_SYSTEM_DELAY, SECURITY_DELAY, AIRLINE_DELAY, LATE_AIRCRAFT_DELAY, WEATHER_DELAY**), the remaining time values are the partly measured times and the partly calculated times. I already talked about that separation and now dig deeper into it:\n\n**Measured Times:**\n- SCHEDULED_TIME\n- TAXI_IN\n- WHEELS_ON\n\n\n**Calculated Times:**\n- ELAPSED_TIME\n- AIR_TIME\n- ARRIVAL_TIME\n\nThe time units that are listed under ***Measured Times*** are time units that have been determined by the airline. They are not calculated, they are values that have been measured or scheduled. The situation is different with the ***Calculated Times***. There we have formulas for calculating the values which are composed as follows:\n\n* **ELAPSED_TIME** = TAXI_OUT + AIR_TIME + TAXI_IN\n\n* **AIR_TIME** = WHEELS_ON - WHEELS_OFF \n\n* **ARRIVAL_TIME** =  WHEELS_ON + TAXI_IN\n\nGood to know how to calculate this values, bad is the fact that the values to calculate these times are also NaN - data. That is probably the reason for its initial NaN - data value. I have no choice but to declare the data as outliers."},{"metadata":{"trusted":true,"_uuid":"9df618acd698d17582bc886de70f69bfc49dbc2b"},"cell_type":"code","source":"# drop the last 1% of missing data rows.\ndf_flights = df_flights.dropna(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2cc59609ff14c47182eb2ff55ac36a5d6e8f9052"},"cell_type":"markdown","source":"### Analyzing Distribution after Cleansing, Conversion and Preprocessing"},{"metadata":{"trusted":true,"_uuid":"bc6551c6a76baadc7ffba9617d38ca143db80d02","scrolled":false},"cell_type":"code","source":"\ndf_times = df_flights[\n[\n    'SCHEDULED_DEPARTURE',\n    'DEPARTURE_TIME',\n    'DEPARTURE_DELAY',\n    'TAXI_OUT',\n    'WHEELS_OFF',\n    'SCHEDULED_TIME',\n    'ELAPSED_TIME',\n    'AIR_TIME',\n    'DISTANCE',\n    'WHEELS_ON',\n    'TAXI_IN',\n    'SCHEDULED_ARRIVAL',\n    'ARRIVAL_TIME',\n    'ARRIVAL_DELAY',\n    'DIVERTED',\n    'CANCELLED',\n    'CANCELLATION_REASON',\n    'AIR_SYSTEM_DELAY',\n    'SECURITY_DELAY',\n    'AIRLINE_DELAY',\n    'LATE_AIRCRAFT_DELAY',\n    'WEATHER_DELAY'\n]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2769b71db6046869b0c31f9b13bcc6cbdd3db95"},"cell_type":"code","source":"pd.set_option('float_format', '{:f}'.format)\n\ndf_times.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8fe466de1540ab9ed91b40db6e1aeccccd33bc02"},"cell_type":"markdown","source":"I have cleaned up the data and assigned the correct data types. Now it is time to select our label and moreover our features to predict the label."},{"metadata":{"_uuid":"05c464383cc8be0582d05410893b6f5d8e162695"},"cell_type":"markdown","source":"# Feature and Label Selection\nFor our prediction, I now need to identify the features that are most likely to impact on the flight delays.\n\nFirst I want to include the airports and try to figure out whether there is an impact on the delay regarding the departure airport or not. For this, I will include the airports from another file in this evaluation. With the included information about the location of the airport, I could identify regions on the map that support a delay.\n\nFirst, I will include the airlines in the evaluation to get a distribution of the delays per airline. Later I will add the airports and their location data to the evaluation to get a closer view of the map and some location-based delays."},{"metadata":{"_uuid":"1ea0147ec72e5b823749f7f84e4efd1870f33568"},"cell_type":"markdown","source":"## Merging the Airline Codes (IATA-Codes)\nI am going to merge the IATA-Airline codes from the other .csv-file. "},{"metadata":{"trusted":true,"_uuid":"20b59801c4e59f0ee096429508a00617490f4725"},"cell_type":"code","source":"df_airlines = pd.read_csv('../input/airlines.csv')\ndf_airlines","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11fccaecfdbfaa99b55afb36e8b1b98639451ad0"},"cell_type":"markdown","source":"Above are the values out of the csv-file. Now I am going to check out the distribution in the flight dataset and join them with the other data."},{"metadata":{"trusted":true,"_uuid":"459d414dd14d422722df16d6cf59d21103088a62"},"cell_type":"code","source":"df_flights['AIRLINE'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86493e3ecd6ed480458b8d78fe1ab5a2f813db15"},"cell_type":"markdown","source":"***Southwest Airline (WN)*** is the airline with the most entries in this evaluation. By contrast, ***Virgin America (VX)*** is the one with the lowest. I I will join them to the other data to get a closer view into it."},{"metadata":{"trusted":true,"_uuid":"d684460f121d56dc41fa44d0e03bc2b0fcb886db"},"cell_type":"code","source":"# joining airlines\ndf_flights = df_flights.merge(df_airlines, left_on='AIRLINE', right_on='IATA_CODE', how='inner')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"scrolled":true,"_uuid":"0079f7abb9b2b11ac604114b70bee8dca3cd1a63"},"cell_type":"code","source":"# dropping old column and rename new one\ndf_flights = df_flights.drop(['AIRLINE_x','IATA_CODE'], axis=1)\ndf_flights = df_flights.rename(columns={\"AIRLINE_y\":\"AIRLINE\"})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a3f3c7d3f2a9abcfc0b997fbfb98628574899e05"},"cell_type":"markdown","source":"### Analyzing the Delays by Airline\nGetting an overview of delays by airlines companies."},{"metadata":{"trusted":true,"_uuid":"73dd952373c8af975859e19f89888936a747ab4f"},"cell_type":"code","source":"sns.set(style=\"whitegrid\")\n\n# initialize the figure\nfig_dim = (16,14)\nf, ax = plt.subplots(figsize=fig_dim)\nsns.despine(bottom=True, left=True)\n\n# Show each observation with a scatterplot\nsns.stripplot(x=\"ARRIVAL_DELAY\", y=\"AIRLINE\",\n              data=df_flights, dodge=True, jitter=True\n            )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41857bc3e56e9ae4c4cb3fb5d564deff88a72017"},"cell_type":"markdown","source":"The distribution above shows the airlines in comparison to their **ARRIVAL_DELAYs**. It clearly shows that ***American Airlines*** has a wide spread of delays. By contrast, the airline with the most entries is ***Southwest Airlines*** and their delays look pretty low compared to the ***American Airlines*** delays. I will elaborate on this in the following:"},{"metadata":{"trusted":true,"_uuid":"7d2e21098c97b3f17d70f656d3ca50e9ff2df11f"},"cell_type":"code","source":"# Group by airline and sum up / count the values\ndf_flights_grouped_sum = df_flights.groupby('AIRLINE', as_index= False)['ARRIVAL_DELAY'].agg('sum').rename(columns={\"ARRIVAL_DELAY\":\"ARRIVAL_DELAY_SUM\"})\ndf_flights_grouped_cnt = df_flights.groupby('AIRLINE', as_index= False)['ARRIVAL_DELAY'].agg('count').rename(columns={\"ARRIVAL_DELAY\":\"ARRIVAL_DELAY_CNT\"})\n\n# Merge the two groups together\ndf_flights_grouped_delay = df_flights_grouped_sum.merge(df_flights_grouped_cnt, left_on='AIRLINE', right_on='AIRLINE', how='inner')\n# Calculate the average delay per airline\ndf_flights_grouped_delay.loc[:,'AVG_DELAY_AIRLINE'] = df_flights_grouped_delay['ARRIVAL_DELAY_SUM'] / df_flights_grouped_delay['ARRIVAL_DELAY_CNT']\n\ndf_flights_grouped_delay.sort_values('ARRIVAL_DELAY_SUM', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fdbb49cb08953b2e7b4ee4d37886f77e22a46706"},"cell_type":"markdown","source":"In conclusion, ***Southwest Airlines*** has a lot of mostly smaller delays which are in total the high mark of delays in this evaluation. On the other side and with a hint on our distribution chart above, ***American Airlines*** has a lot of huge delays in single flights which effects the total delay of the airline. They are in the upper thirds of the delays but their mean delay per airline is one of the lowest of all airlines."},{"metadata":{"_uuid":"f130964242d2f1472bcb064cc6f9f3ffe289bf71"},"cell_type":"markdown","source":"## Feature Correlation\n\nSo let us look at the correlation between each of the features ( and the label as well). This might be the first step into a closer feature selection. The main goal is to identify the features that affect the **ARRIVAL_DELAY** in a positive or negative way."},{"metadata":{"trusted":true,"_uuid":"9884df2acd8158b49ca4cc58b36b9e1400656a97","scrolled":false},"cell_type":"code","source":"# Dataframe correlation\ndel_corr = df_flights.corr()\n\n# Draw the figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Draw the heatmap\nsns.heatmap(del_corr)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6026e023fbb3004d78c910247f778d47feea6ad"},"cell_type":"markdown","source":"### Results from Correlation Matrix\nI am dividing the different correlations into two parts,  the **positive correlations** (higher than *0.6* ) and the **less positive correlations** (less than *0.6* but higher than *0.2*). The results are listed in the list below:\n\n#### Positive correlations between:\n* DEPARTURE_DELAY and\n    * ARRIVAL_DELAY\n    * LATE_AIRCRAFT_DELAY\n    * AIRLINE_DELAY\n* ARRIVAL_DELAY and\n    * DEPARTURE_DELAY\n    * LATE_AIRCRAFT_DELAY\n    * AIRLINE_DELAY\n\n#### Less positive correlations between:\n* ARRIVAL_DELAY and\n    * AIR_SYSTEM_DELAY\n    * WEATHER_DELAY\n* DEPARTURE_DELAY and\n    * AIR_SYSTEM_DELAY\n    * WEATHER_DELAY\n* TAXI_OUT and\n    * AIR_SYSTEM_DELAY\n    * ELAPSED_TIME\n\n#### This leads to the following factors of influence:\nI will list the different correlations here to see which features have the most counted influence on different other features.\n\n<table class=\"table\">\n  <thead>\n    <tr>\n    <th scope=\"col\">Positive Value</th>\n    <th scope=\"col\">Count</th>\n    <th scope=\"col\">Type</th>\n    </tr>\n  </thead>\n  <tr>\n    <td scope=\"row\">++</td>\n    <td scope=\"row\">2</td>\n    <td scope=\"row\">LATE_AIRCRAFT_DELAY</td>             \n  </tr>\n  <tr>\n    <td>++</td>\n    <td>2</td>\n    <td>AIRLINE_DELAY</td>             \n  </tr>\n  <tr>\n    <td>++</td>\n    <td>1</td>\n    <td>ARRIVAL_DELAY</td>             \n  </tr>\n <tr>\n    <td>+-</td>\n    <td>3</td>\n    <td>AIR_SYSTEM_DELAY</td>             \n  </tr>\n  <tr>\n    <td>+-</td>\n    <td>2</td>\n    <td>WEATHER_DELAY</td>             \n  </tr>\n   <tr>\n    <td>+-</td>\n    <td>1</td>\n    <td>ELAPSED_TIME</td>             \n  </tr>\n</table>\n\nThese could be the main features (except the **ARRIVAL_DELAY** itself) that influence partly or entirely the flight delays. This needs to be measured by a feature selection method."},{"metadata":{"_kg_hide-output":false,"_uuid":"4ee140bd2e873dd8d38c50d4703e586c73e3a7d7"},"cell_type":"markdown","source":"## Feature Selection with Machine Learning Algorithms\nIn following, I want to proof the above written down feature correlation count with a machine learning algorithms. Do they really correlate as good as I think with the **ARRIVAL_DELAY**? I will classify the data into delayed and not delayed data and define a label (DELAYED) for that in the dataframe. Afterward I will show the feature importance for the given attributes.\n\nIn the beginning, I need to reduce computation time by reducing the data on January 2015. Otherwise, this whole prediction will execute too long."},{"metadata":{"trusted":true,"_uuid":"63bc81dd8ca08a6eef87f76a085d777287fcb114"},"cell_type":"code","source":"# Only using data from January\ndf_flights_jan = df_flights.loc[(df_flights.loc[:,'YEAR'] == 2015 ) & (df_flights.loc[:,'MONTH'] == 1 )]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"caa1174763dba8bed14fd225a8a960c1740da0fe","scrolled":true},"cell_type":"code","source":"df_flights_jan.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6e5a868519757f170480dea373731e7d06c597e","scrolled":true},"cell_type":"code","source":"# Marking the delayed flights\ndf_flights_jan['DELAYED'] = df_flights_jan.loc[:,'ARRIVAL_DELAY'].values > 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b91d7ecc4a4d95e67080e4fa1bd308afa2b1bfc9","scrolled":true},"cell_type":"code","source":"# Label definition\ny = df_flights_jan.DELAYED\n\n# Choosing the predictors\nfeature_list_s = [\n    'LATE_AIRCRAFT_DELAY'\n    ,'AIRLINE_DELAY'\n    ,'AIR_SYSTEM_DELAY'\n    ,'WEATHER_DELAY'\n    ,'ELAPSED_TIME']\n\n# New dataframe based on a small feature list\nX_small = df_flights_jan[feature_list_s]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08b0f595adf7aebaf600d94ed908e21394eddb22"},"cell_type":"code","source":"# RandomForestClassifier with 10 trees and fitted on the small feature set \nclf = RandomForestClassifier(n_estimators = 10, random_state=32) \nclf.fit(X_small, y)\n\n# Extracting feature importance for each feature\ni=0\ndf_feature_small = pd.DataFrame(columns=['FEATURE','IMPORTANCE'])\nfor val in (clf.feature_importances_):\n    df_feature_small.loc[i] = [feature_list_s[i],val]\n    i = i + 1\n    \n\ndf_feature_small.sort_values('IMPORTANCE', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a33edc0c0a3e2dace84c46a3abe122525b0da852"},"cell_type":"markdown","source":"A ittle bit has changed. Now the **AIR_SYSTEM__DELAY** has got the most influences on a flight that has been delayed. This feature had a less positive correlation in our correlation resume above. All the other features have remained in the same order of importance as we have found out. Let us try a wider range with the same model. And please keep in mind that we use a classification here. We have classified the data into delayed and not delayed data and want to find out now which of these features effects a delay of a flight the most. There could be and there probably will be different features for a flight that arrives just in time, but this will be part of a later section where we try to determine the actual arrival at an airport."},{"metadata":{"trusted":true,"_uuid":"ee48271d932b8972955d82d0f71d789a01421f97"},"cell_type":"code","source":"# choosing the predictors\nfeature_list = [\n    'YEAR'\n    ,'MONTH'\n    ,'DAY'\n    ,'AIRLINE'\n    ,'LATE_AIRCRAFT_DELAY'\n    ,'AIRLINE_DELAY'\n    ,'AIR_SYSTEM_DELAY'\n    ,'WEATHER_DELAY'\n    ,'ELAPSED_TIME'\n    ,'DEPARTURE_DELAY'\n    ,'SCHEDULED_TIME'\n    ,'AIR_TIME'\n    ,'DISTANCE'\n    ,'TAXI_IN'\n    ,'TAXI_OUT'\n    ,'DAY_OF_WEEK'\n    ,'SECURITY_DELAY'\n]\n\nX = df_flights_jan[feature_list]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c20b211f0e563ca211e816c709eaff195c1533a6"},"cell_type":"markdown","source":"Here I need to convert the **AIRLINE** feature into a numeric value, the feature themselves is not important for our features determination but I probably want to show the airline in a later approach."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"20b580397ffde4dbb686ab818e79e7925db3034e"},"cell_type":"code","source":"# Label encoding of AIRLINE and write this back to df\nfrom sklearn.preprocessing import LabelEncoder\nlabelenc = LabelEncoder()\n\n# Converting \"category\" airline to integer values\nX.iloc[:,feature_list.index('AIRLINE')] = labelenc.fit_transform(X.iloc[:,feature_list.index('AIRLINE')])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75f2f81df548f28659ee123b1edac0036907189a"},"cell_type":"markdown","source":"In case we need the old values back, we will use the *.inverse_transform()* function:"},{"metadata":{"trusted":true,"_uuid":"396cbe79e02fc3bdfbcda28f1fc259e85927b8d0"},"cell_type":"code","source":"# Convert my encoded categories back\nlabelenc.inverse_transform(X.iloc[:, feature_list.index('AIRLINE')])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b0778ceb1938d8430c70f3999f7c7f66cce5bdb"},"cell_type":"markdown","source":"Now the feature importance will be shown:"},{"metadata":{"trusted":true,"_uuid":"57aff0b772eaa73fcf3fd7b6de406339e9937634","_kg_hide-output":true},"cell_type":"code","source":"# Fit the new features and the label (based on feature_list)\nclf = RandomForestClassifier(n_estimators=10, random_state=32) \nclf.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21109d04b614c2607ac9fb2387430ffc2c3e9b8f","scrolled":true},"cell_type":"code","source":"i=0\ndf_feature_selection = pd.DataFrame(columns=['FEATURE','IMPORTANCE'])\nfor val in (clf.feature_importances_):\n    df_feature_selection.loc[i] = [feature_list[i],val]\n    i = i + 1\n    \n\ndf_feature_selection.sort_values('IMPORTANCE', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81b3ee51aaaa763a20c26caea8d83828062ebb8e"},"cell_type":"markdown","source":"This looks quite different than our first approach. Ok the **AIR_SYSTEM_DELAY** still stays nearly at the top, but **LATE_AIRCRAFT_DELAY**, **AIRLINE_DELAY**, **WEATHER_DELAY** and **ELAPSED_TIME** moved down some positions. The **ELAPSED_TIME** remains in the top five but our other features have got a different importance given by the other features and remember the **ELAPSED_TIME** was the worst feature of our first calculation and now stays at the top five.\n\n\n### Summary\nWe have now analyzed several features and compared them due to a classification model. We came to the conclusion that with a limited view of the features, the causes of delays of a flight can be completely different. The more important it is to use high quality of data and a differentiated set of features for a prediction.\n\nThis feature importance will help us in later progress if we need to prune decision trees from the random forest to maximize our prediction accuracy in the random forest.\n\nIn the next chapter, I will start building the main prediction model for predicting the actual arrival delay themselves."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b7df808d1e0503e3cffb1210e8146c7449db182c"},"cell_type":"markdown","source":"# Data Prediction\n## Preparing the Prediction\n\n"},{"metadata":{"_uuid":"8647c3abfd45ba3e35024a67e2db3540b02d63e8"},"cell_type":"markdown","source":"### Building the Model First\nI am building the model first. Here I am choosing 100 trees for the model to not overexert the computation time in later purpose."},{"metadata":{"trusted":true,"_uuid":"2dcbba5ebf5041ee006bd0985d0196d57f893743"},"cell_type":"code","source":"# RandomForest with 100 trees\nforest_model = RandomForestRegressor(n_estimators = 100, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7142ebfb6859efca0a193beb4360d2401437002"},"cell_type":"markdown","source":"\n### Choosing the Prediction Target\nThis time I choose the ARRIVAL_DELAY as the target and change the model to the Random Forest Regressor (seen above) to predict the exact minutes delayed or arrived in time."},{"metadata":{"trusted":true,"_uuid":"a30aac5d8167fe009ac236ed2938d290af6e5c44"},"cell_type":"code","source":"y = df_flights_jan.ARRIVAL_DELAY\ny = np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8bd8411a2387a1c77beec2cc08b2919ad68bd2f2"},"cell_type":"markdown","source":"### Choosing the Predictors \nTo predict our prediction target (ARRIVAL_DELAY), we need some features. I will select the same features as in the chapter before."},{"metadata":{"trusted":true,"_uuid":"dfaa90cc9e68fc8d35e07e12a70dd1fc8eb39c26"},"cell_type":"code","source":"X = np.array(X)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"172416e4a73664de75856fb8d9e00744659696a0"},"cell_type":"markdown","source":"## Separating into Test and Train Datasets\nIt is necessary to separate the data into train and test dataset."},{"metadata":{"trusted":true,"_uuid":"5d488b3781cbc54214a70cfdee72bab28b4aaf42"},"cell_type":"code","source":"# split data into training and validation data, for both predictors and target\n# The split is based on a random number generator. Supplying a numeric value to\n# the random_state argument guarantees we get the same split every time we\n# run this script.\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, test_size = 0.35, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05a6ecf77c4ab22f4aa29ca5d4fdc327657b322c"},"cell_type":"markdown","source":"### The Shape of  Train- and Testdata"},{"metadata":{"trusted":true,"_uuid":"186935135f03926a3dabf142fba96af899f47e7d"},"cell_type":"code","source":"print('Training Features Shape:', train_X.shape)\nprint('Training Labels Shape:', train_y.shape)\nprint('Testing Features Shape:', val_X.shape)\nprint('Testing Labels Shape:', val_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0baaf1a8c29950db521dcb84bc691264aeab17bf"},"cell_type":"markdown","source":"## Model Training and Prediction\n"},{"metadata":{"_uuid":"892354140d93cfdec238aad372d0472ca16eb0b8"},"cell_type":"markdown","source":"### Establish Baseline"},{"metadata":{"trusted":true,"_uuid":"b18ab1ba2e6a259396b10de73a95c9da7f1c8f18"},"cell_type":"code","source":"# Average arrival delay for our dataset\nbaseline_preds = df_flights_jan['ARRIVAL_DELAY'].agg('sum') / df_flights_jan['ARRIVAL_DELAY'].agg('count') \n\n# Baseline error by average arrival delay \nbaseline_errors = abs(baseline_preds - val_y)\nprint('Average baseline error: ', round(np.mean(baseline_errors),2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"421b4908f033d2a29a15f1cae24b4e811ce3fdb1"},"cell_type":"markdown","source":"This is our average baseline error of 22.16 minutes of delays we want to beat with our regression model. "},{"metadata":{"_uuid":"6c7727c57e8afb8517dbaf30cb2a7c545203040f"},"cell_type":"markdown","source":"### Train Model"},{"metadata":{"trusted":true,"_uuid":"fd97e9b60d64a2bf4599131efdb8df9b08149d98"},"cell_type":"code","source":"# Fit the model\nforest_model.fit(train_X, train_y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8302e8f1d9098dbda6d381c50755a9072e3f476c"},"cell_type":"markdown","source":"### Predict and Validate the Result"},{"metadata":{"trusted":true,"_uuid":"574d24182dc7b239ee379730aa3f7c21da297707"},"cell_type":"code","source":"# Predict the target based on testdata \nflightdelay_pred= forest_model.predict(val_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8e0fd6037550391182dda25679695ff9aa6432a"},"cell_type":"code","source":"#Calculate the absolute errors\nerrors = abs(flightdelay_pred - val_y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86a7818054c893d7aa6e483cfe009ebf51caf769"},"cell_type":"markdown","source":"#### Return the Absolute Error"},{"metadata":{"trusted":true,"_uuid":"fef076878d2d84810142e4ab2c63d8804fa01aa2"},"cell_type":"code","source":"print('Mean Absolute Error: ', round(np.mean(errors),3), 'minutes.')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4485802701f1515919032ea501248c9f9e4a346"},"cell_type":"markdown","source":"This looks quite after overfitting. The mean absolute error is pretty small which means the model predicts the arrival delay nearly accurate or over accurate. I will validate and visualize the model in the next chapter."},{"metadata":{"_uuid":"b08c34e614582587930c8087e8f46bd55eadd6b7"},"cell_type":"markdown","source":"# Validate and Visualize the Model\nIn this chapter, I will validate and visualize the prediction model. The previous mentioned mean absolute error of 0.857 minute seems to be a quite good prediction of the arrival delay. The predictions are on average around 0.857 minutes away from the real value. This is a really exact prediction. It is mandatory to check the model whether it is an overfitted one or not.\n\nThe previously shown feature importance of the model looks like this:"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"e6e50d96b05c2a5b98a699171580c147a1fb0f7c"},"cell_type":"code","source":"# Determine the feature importance of our model\ni=0\ndf_model_features = pd.DataFrame(columns=['FEATURE','IMPORTANCE'])\nfor val in (forest_model.feature_importances_):\n    df_model_features.loc[i] = [feature_list[i],val]\n    i = i + 1\n    \n# Print the determined feature importance\ndf_model_features.sort_values('IMPORTANCE', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7cce8994f07451eddc3b2460d966203d796ca1ef"},"cell_type":"markdown","source":"Nearly 85% of the feature importance is based by the **DEPARTURE_DELAY** feature which is a lot. The next eight features not even have individually more than 10% of importance, they are all lower.  **AIR_SYSTEM_DELAY**, **SCHEDULED_TIME** and **ELAPSED_TIME** have at least values that are greater than 1.0%. The remaining features all having an importance that is lower 1.0%. \n\nI will take a closer look into the single features in the next section."},{"metadata":{"_uuid":"32c8901fe4021d1f17144de7344c2e7c816c99e6"},"cell_type":"markdown","source":"## Visualize the Linear Regression between Features and Target\nNext, I will visualize the linear regression on the first six features that I mainly used to fit model and predict the target. Based on that I will show the determination of coefficiency per feature.  This will give an overview of how good the single features are able to predict the target. Right after that, I will calculate the models r-squared."},{"metadata":{"trusted":true,"_uuid":"cd9ca1455af997a5adcf01cc626e615d34215f4a","_kg_hide-input":true},"cell_type":"code","source":"from statistics import *\n\n# Calculate the solpe and intercept\ndef best_fit_slope_and_intercept(xs,ys):\n    m = ( ((mean(xs) * mean(ys)) - mean(xs*ys)) /\n          ((mean(xs) * mean(xs)) - mean(xs*xs)) )\n    b = mean(ys) - m*mean(xs)\n    return m, b\n\n# Calculate the regression line\ndef regression_line(m, feature, b):\n        regression_line = [(m*x) + b for x in feature]\n        return regression_line\n\n# Draw six grid scatter plot and calculate all necessary functions\ndef draw_sixgrid_scatterplot(feature1, feature2, feature3, feature4, feature5, feature6, target):\n    fig = plt.figure(1, figsize=(16,15))\n    gs=gridspec.GridSpec(3,3)\n    \n    # Axis for the grid\n    ax1=fig.add_subplot(gs[0,0])\n    ax2=fig.add_subplot(gs[0,1])\n    ax3=fig.add_subplot(gs[0,2])\n    ax4=fig.add_subplot(gs[1,0])\n    ax5=fig.add_subplot(gs[1,1])\n    ax6=fig.add_subplot(gs[1,2])\n    \n    # Drawing dots based on feature and target\n    ax1.scatter(feature1, target, color = 'g')\n    ax2.scatter(feature2, target, color = 'c')\n    ax3.scatter(feature3, target, color = 'y')\n    ax4.scatter(feature4, target, color = 'k')\n    ax5.scatter(feature5, target, color = 'grey')\n    ax6.scatter(feature6, target, color = 'm')\n    \n    # Get best fit for slope and intercept\n    m1,b1 = best_fit_slope_and_intercept(feature1, target)\n    m2,b2 = best_fit_slope_and_intercept(feature2, target)\n    m3,b3 = best_fit_slope_and_intercept(feature3, target)\n    m4,b4 = best_fit_slope_and_intercept(feature4, target)\n    m5,b5 = best_fit_slope_and_intercept(feature5, target)\n    m6,b6 = best_fit_slope_and_intercept(feature6, target)\n\n    # Build regression lines\n    regression_line1 = regression_line(m1, feature1, b1)\n    regression_line2 = regression_line(m2, feature2, b2)\n    regression_line3 = regression_line(m3, feature3, b3)\n    regression_line4 = regression_line(m4, feature4, b4)\n    regression_line5 = regression_line(m5, feature5, b5)\n    regression_line6 = regression_line(m6, feature6, b6)\n            \n    # Plotting regression lines\n    ax1.plot(feature1,regression_line1)\n    ax2.plot(feature2,regression_line2)\n    ax3.plot(feature3,regression_line3)\n    ax4.plot(feature4,regression_line4)\n    ax5.plot(feature5,regression_line5)\n    ax6.plot(feature6,regression_line6)\n    \n    # Naming the axis\n    ax1.set_xlabel(feature1.name)\n    ax1.set_ylabel(target.name)\n    ax2.set_xlabel(feature2.name)    \n    ax2.set_ylabel(target.name)\n    ax3.set_xlabel(feature3.name)\n    ax3.set_ylabel(target.name)\n    ax4.set_xlabel(feature4.name)\n    ax4.set_ylabel(target.name)\n    ax5.set_xlabel(feature5.name)\n    ax5.set_ylabel(target.name)\n    ax6.set_xlabel(feature6.name)\n    ax6.set_ylabel(target.name)\n    \n    # Give the labels space\n    plt.tight_layout()\n    plt.show()\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ddbf23976e30bb919cc05ad49988f09f106d130"},"cell_type":"code","source":"# Determine the squared error\ndef squared_error_reg(ys_orig, ys_line):\n    return sum((ys_line-ys_orig)**2)\n\n# Calculating r-squared\ndef coefficient_of_determination(ys_orig, ys_line):\n    y_mean:line = [mean(ys_orig) for y in ys_orig]\n    squared_error_regr = squared_error_reg(ys_orig, ys_line)\n    squared_error_y_mean = squared_error(ys_orig, y_mean_line)\n    return 1 - (squared_error_regr / squared_error_y_mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b206b3d5f6439030bf2fedea07c2672fe252e34c"},"cell_type":"code","source":"# Draw the grid scatters\ndraw_sixgrid_scatterplot(df_flights_jan['DEPARTURE_DELAY'], df_flights_jan['AIR_SYSTEM_DELAY'], df_flights_jan['SCHEDULED_TIME'],\n                         df_flights_jan['ELAPSED_TIME'], df_flights_jan['TAXI_OUT'], df_flights_jan['AIRLINE_DELAY'], df_flights_jan['ARRIVAL_DELAY'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea6f2b961e327ec43feeecc83ccb3dabeef044fa"},"cell_type":"markdown","source":"\nHere we see the linear regression lines for the features \n* DEPARTURE_DELAY\n* AIR_SYSTEM_DELAY\n* SCHEDULED_TIME\n* ELAPSED_TIME \n* TAXI_OUT\n* AIRLINE_DELAY\n\nThese are the six main features that affect the decision trees the most. As I mentioned before, the **DEPARTURE_DELAY** is the most important features with 85% of importance. This is clearly visible in the first chart where you can see the linear correlation and the good fitting regression line between the target **ARRIVAL_DELAY** and the feature **DEPARTURE_DELAY**. When the departure delay raises, the arrival delay will rise, in most cases,  as well. The straight line fits the scattering pretty good. \n\nHowever, this looks a bit different for the feature **AIR_SYSTEM_DELAY**. The scattering spreads a little bit wider and raises the **ARRIVAL_DELAY** right at the beginning of the feature impact. The linear regression line probably fits the correlation good. It is not as good as the previous combination out of **DEPARTURE_DELAY** and **ARRIVAL_DELAY** but it still fits a good regression line.\n\nAccording to the third important feature, the **SCHEDULED_TIME**, this all looks way different. Here is a big and wide scattering where the regression line hits the ground. The line follows straight the x-axis and there is no increase in curve running visibly. This means the **SCHEDULED_TIME** has no impact on the **ARRIVAL_DELAY**. This seems obvious, what kind of effect could have a scheduled arrival time on an arrival delay. Nearly nothing. The only thing that could matter in this topic would be a flight restriction for certain times where airplanes are not allowed to land on that airport. But this kind of flight route would not be planned by an airline company. \n\nThe same way looks the feature **ELAPSED_TIME**. The scattering and the regression line looks almost the same as for the **SCHEDULED_TIME** which is based on the fact that it comes to the same cause here.\n\nThe next feature, the **TAXI_OUT** makes the regression line raise a bit but the scattering looks even wide as before. This features acts nearly the same as the **DEPARTURE_DELAY**. It affects the **DEPARTURE_TIME** by the calculation out of **WHEEL_OFF** **-** **TAXI_OUT** which is used to determine the **DEPARTURE_DELAY** afterward.\n\nThe last feature in the feature importance checks it the **AIRLINE_DELAY**. Here we have again a feature that has an active impact on the **ARRIVAL_DELAY**.  The scattering spreads a little bit wider and raises the **ARRIVAL_DELAY** right at the beginning of a feature impact, which leads to this slope of the regression line. The slope looks nearly the same as in the **DEPARTURE_DELAY** chart. But the interesting fact is, according to the prediction model this feature does not have any high impact on the **ARRIVAL_DELAY**. Moreover, this feature is on the sixth position due to the prediction model's importance check and it does not even have a feature importance that is higher than 0.01 . In return, according to this regression line, the **AIRLINE_DELAY** must effects the **ARRIVAL_DELAY** in one way or the other.\n\nThe question here is, why does the prediction model does not uses the **AIRLINE_DELAY** in its prediction more highly valued. Does this here looks like a need to intervene in the model to make it use the **AIRLINE_DELAY** in a higher importance rank? I will go deeper in that specific feature in the upcoming chapter."},{"metadata":{"_uuid":"05f886871755f8523f5eeeda06b9cc02347e32a8"},"cell_type":"markdown","source":"## Visual Tree\nIn the following approach, I will visualize one of the decision trees from the model above. For a better visibility, I will only show the first six splits in the tree to show the six most important features. In contrast to the conventional presentation of decision trees, I will show this tree in a rotated form from left to right (not top-down) to get it full size on this page. This will give you a better legibility. I chose six to hopefully find the features from the feature importance discovery and especially the **AIRLINE_DELAY** out of the previous chapter."},{"metadata":{"trusted":true,"_uuid":"e9f65063539dc5cc23682f3e4a8ff7a9a67025f0","scrolled":false},"cell_type":"code","source":"# The original forest model\nmodel = forest_model\n\n# Extract single tree\nestimator = model.estimators_[1]\n\nfrom sklearn.tree import export_graphviz\n# Export as dot file\nexport_graphviz(estimator, out_file='tree.dot', \n                max_depth=6,\n                rotate = True,\n                feature_names = feature_list,\n               # class_names = ,\n                rounded = True, proportion = False, \n                precision = 2, filled = True)\n\n# Convert to png using system command (requires Graphviz)\nfrom subprocess import call\ncall(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=3000'])\n\n# Display in jupyter notebook\nfrom IPython.display import Image\nImage(filename = 'tree.png')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9afd2eeb36df41a735a01abfbdbae2a29459543"},"cell_type":"markdown","source":"The split depth shows several features which are used more often for split decisions. One of them is of course, the **DEPARTURE_DELAY**. There are several more which will be discussed in the following comparison between the *Feature Importance by Arrival Delay* where there was tried to determine the minutes of arrival delay (prediction model with the decision tree above) and the *Features Importance by Delayed Flights* where the data was classified into delayed or not delayed flight (previous features selection). \n\n##### Feature Importance by Arrival Delay (minute based)\nThe above-shown decision tree shows the following features in his split, which is based on its feature importance determination:"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"23bc329709f46dcffc0129effcca21d45ad17529"},"cell_type":"code","source":"i=0\ndf_model_s_features = pd.DataFrame(columns=['FEATURE','IMPORTANCE'])\nfor val in (forest_model.feature_importances_):\n    df_model_s_features.loc[i] = [feature_list[i],val]\n    i = i + 1\n    \n\ndf_model_s_features.sort_values('IMPORTANCE', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af062aa912224a1ee37ac672f7f75137dcc6c494"},"cell_type":"markdown","source":"##### Feature Importance by Delayed Flights (True or False)\nThis here is ones again our previous feature importance analysis based on delayed flights with the main five features for comparison:"},{"metadata":{"trusted":true,"_uuid":"da995abfebebe045e492db9874291803ef8ada2c","_kg_hide-input":true,"scrolled":true},"cell_type":"code","source":"df_feature_selection.sort_values('IMPORTANCE', ascending=False).head(6) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8539846afc316ce4b6319e2cb597791b1bdf53e5"},"cell_type":"markdown","source":"If we compare the two feature importance tables, the first one (*Feature Importance by Arrival Delay* - based on the decision tree above) and the second one (*Feature Importance by Delayed Flights*), we clearly recognize that all of the used features by the decision tree (first table), are included in the second table. The second table represents the discovered features from the first indication where we tried to determine the important features of the model. They are all used by the decision tree in a slightly different order, except the **AIR_TIME**. The **AIR_TIME** does not appear in the first six split decisions,  therefore the **AIRLINE_DELAY** has taken place. \n\nOur previous taken feature importance identification (second table) only shows the influencer on a flight that has already been delayed, not in which case the flight has arrived after schedule as shown in the feature importance of the decision tree's split (first table).\nAs you can see the most important feature for the regression model is with around 0.85 importance still the **DEPARTURE_DELAY**.  You can see there are a lot of splits based on the **DEPARTURE_DELAY** in the visualized tree. This could be as well an explanation for that low mean absolute error of around 1.0 minute.\n\nThe **DEPARTURE_DELAY** seems to be the main features for predicting the right **ARRIVAL_DELAY** at all. Let's take a closer look into it before we go further on with the validation:"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"96d0271f441d57f77d095088343605f03bbdf6e8"},"cell_type":"code","source":"# Count of DEPARTURE_DELAYs that are not zero and could influence our prediction.\nprint(\"DEPARTURE_DELAY count: \")\nprint(df_flights_jan[df_flights_jan['DEPARTURE_DELAY'] != 0]['DEPARTURE_DELAY'].count())\nprint(\"-------------------------------\")\nprint(\"All datarow count:\")\nprint((df_flights_jan)['DEPARTURE_DELAY'].count())\nprint(\"-------------------------------\")\nprint(\"-------------------------------\")\nprint(\"Percentag of DEPARTURE_DELAY that is not zero:\")\nprint(df_flights_jan[df_flights_jan['DEPARTURE_DELAY'] != 0]['DEPARTURE_DELAY'].count() / df_flights_jan['DEPARTURE_DELAY'].count())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"72a3c3ab5cef26413867446c4a6199bc5cac6bfb"},"cell_type":"markdown","source":"Nearly 95% of the values from **DEPARTURE_DELAY** are set with a value that is not zero. The nearly 100% fulfillment and the effects from the **DEPARTURE_DELAY** on the  **ARRIVAL_DELAY** leads to that feature importance for the built model. So it seems to be not unusual to have such an accuracy in that case.\nStill, this seems too accurate, we are talking here about a minute difference to the real arrival delay of a flight. There is a need to check the accuracy of the model in a much better way.\n\nIn the next chapter, I will analyze the coefficient of determination to get a better overview of how good the model fits the dataset."},{"metadata":{"_uuid":"28965aff01e59cdb0f56f6c1c713937cd6ce5c30"},"cell_type":"markdown","source":"## The Coefficient of Determination -  The Model Fitness\nIn this chapter, I will calculate the coefficient of determination or \"*R-squared*\" for the model. It will show how good the inputs fit the output of the model, or how good the model represents the underlying data. That means if the regressions of our features have an R-squared close to 1, it means that the independent variables (the features) are well-suited to predict the dependent variable (our target, the **ARRIVAL_DELAY**). \n\nI will now calculate the R-squared for the built model based on the training and test dataset:"},{"metadata":{"trusted":true,"_uuid":"845f9f3f8e479349b73645fb277dbdca9f16e968"},"cell_type":"code","source":"print(\"----------------- TRAINING ------------------------\")\nprint(\"r-squared score: \",forest_model.score(train_X, train_y))\nprint(\"------------------- TEST --------------------------\")\nprint(\"r-squared score: \", forest_model.score(val_X, val_y))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a20076293a73331d99650afcc9910da0d14259d5"},"cell_type":"markdown","source":"This here seems to be as well pretty accurate. The training dataset is a known dataset by the model why the test dataset is used as well here. As we know due to the previous analysis, the model is highly based on the **DEPARTURE_DELAY** feature. All the model's decision is based on what the **DEPARTURE_DELAY** does, which afterward leads to that accuracy.\n\nI will test the model with another new dataset and calculate the necessary key figures."},{"metadata":{"_uuid":"d61b84a8f52eaa7b2084d64aec6465bff2bce615"},"cell_type":"markdown","source":"### Test with Unknown Data Again\nI will use data from February now, to test the model against total new, unknown data. After all the necessary model preparations I will print out the Mean Absolute Error as well as the r-squared score of the new test data."},{"metadata":{"trusted":true,"_uuid":"a85413f5847ff39a6e74aa2ed55a9718128adc55"},"cell_type":"code","source":"df_flights_feb = df_flights.loc[(df_flights.loc[:,'YEAR'] == 2015 ) & (df_flights.loc[:,'MONTH'] == 2 )]\n\n# We only need them as test sets, no split in train and test(val) needed\nX2 = df_flights_feb[feature_list]\ny2 = df_flights_feb.ARRIVAL_DELAY","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"804a54c41c92af7b3afca50add38390594ff5594"},"cell_type":"code","source":"# Converting \"category\" airline to integer values\nX2.iloc[:,feature_list.index('AIRLINE')] = labelenc.fit_transform(X2.iloc[:,feature_list.index('AIRLINE')])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cfcf6702d2255aab3f3f37224585e2b896de69f"},"cell_type":"code","source":"# Filling the features and the target again\nX2 = np.array(X2)\ny2 = np.array(y2)\n\n# Predict the new data based on the old model (forest_model)\nflightdelay_pred_feb = forest_model.predict(X2)\n\n#Calculate the absolute errors\nerrors_feb = abs(flightdelay_pred_feb - y2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da34ebf522e253a1a2ae21662539958cd1dd521d"},"cell_type":"code","source":"# Mean Absolute Error im comparison\nprint('Mean Absolute Error January: ', round(np.mean(errors),3), 'minutes.')\nprint('---------------------------------------------------------------')\nprint('Mean Absolute Error February: ', round(np.mean(errors_feb),3), 'minutes.')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3005cc9aa6a7166e93664fc3780a0551c39419b9"},"cell_type":"markdown","source":"The difference between the two datasets (January and February) is not that big, it's even very small. The model even fits on total new data. What about the R-squared calculation?"},{"metadata":{"trusted":true,"_uuid":"c81e662d242a05690225ebee25b00b34d222311d"},"cell_type":"code","source":"print(\"r-squared score January: \",forest_model.score(val_X, val_y))\nprint(\"------------------- TEST --------------------------\")\nprint(\"r-squared score February: \", forest_model.score(X2, y2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"626f217d0256b6298915ec2f072285b022c9f1ca"},"cell_type":"markdown","source":"On the one hand side, the model seems to be good at new data on the other hand's side, the model seems to learned the data by hart. I can see that the data from February probably does not have much difference to the data from January, but a comparison with data from a summer month with different circumstances would not give an accurate comparison because we did not train the model with data from all over the year.\n\nI would have need to use data from all over the year to train the model and afterward test it with a different month from different seasons. This could be a task for a new version of this notebook, but right now this here \"fits the needs\". \n\nAs I already mentioned, the mean absolute error, as well as the r-squared equation both look that the model would not fit that well, because they seem too accurate. The model is highly based on the **DEPARTURE_DELAY** feature and makes its decisions by that. If there is a flight that has been delayed but not according to the **DEPARTURE_DELAY**, the model would probably don't give a prediction that has that accuracy. \n\nI will test this in the following. "},{"metadata":{"_uuid":"d04517054cea5ee03690b2116200caf605348286"},"cell_type":"markdown","source":"## Model Check without DEPARTURE_DELAY Impact\nFor this test, I will search for a special flight that is not delayed by the **DEPARTURE_DELAY** and is at least a delayed flight of 60 minutes (**ARRIVAL_DELAY** > 60)."},{"metadata":{"trusted":true,"_uuid":"ff127531313df4967d510176515e4e6a0fe5d82c"},"cell_type":"code","source":"# Searching for a flight that fits our needs\ndf_flights_feb[(df_flights_feb.loc[:,'DEPARTURE_DELAY'] < 0) & (df_flights_feb.loc[:,'ARRIVAL_DELAY'] > 60)].head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63247ea41e5136ced5196807de0678c219b0d2d4"},"cell_type":"markdown","source":"The delayed flight with the index number *19777* seems to be a good one. It has the following properties:"},{"metadata":{"trusted":true,"_uuid":"67358f4b54216b98e2c1b5bbbac7836510fc7a4f"},"cell_type":"code","source":"# Look into the flight with indexnumber 19777\ndf_flights_feb.loc[19777]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d415d5c0b123f5c4ee34078f670feb2022fb8fa4"},"cell_type":"markdown","source":"We clearly see that the **DEPARTURE_DELAY** is not the reason for the delay this time, moreover the airplane departed early than scheduled. So let's use this flight for the model check. Preparations in the following step:"},{"metadata":{"trusted":true,"_uuid":"6245e188272b5c2d8289a50a1b71276972b1702c"},"cell_type":"code","source":"# Setting up a new dataframe for February and converting the AIRLINE feature again\nX3 = df_flights_feb.loc[:,feature_list]\nX3.iloc[:,feature_list.index('AIRLINE')] = labelenc.fit_transform(X3.iloc[:,feature_list.index('AIRLINE')])\n\n# Retrieving the flight with index 19777 (delayed flight without departure delay).\nX3 = X3.loc[19777]\n# Setting the target for our flight index 19777\ny3 = df_flights_feb.loc[19777]['ARRIVAL_DELAY']\n\n# Converting to array for the model use\nX3 = np.array(X3)\ny3 = np.array(y3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae6f21f6a1055880f2a1dd571e6cde06c89f7472"},"cell_type":"markdown","source":"### Flight Delay Prediction without DEPARTURE_DELAY\nNext step will be the prediction and the validation of the result. Therefore I will use the already trained model and give them the information from the special flight above."},{"metadata":{"trusted":true,"_uuid":"88833eef0168ccccf112f3fbbbfb58bcc5756565"},"cell_type":"code","source":"# Printing the important stuff\nflight_pred_s = forest_model.predict([X3])\nprint(\"Predicted Delay of the Flight (Minutes): \", flight_pred_s)\nprint(\"-------------------------------------------------\")\nprint(\"Original Delay of the Flight (Minutes):  \", y3)\nprint(\"_________________________________________________\")\nprint(\"_________________________________________________\")\nprint(\"Difference (Minutes)                   : \", flight_pred_s - y3)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3dcf45594a6dd4ebc67297b079e9a2f10258d089"},"cell_type":"markdown","source":"### Conclusion\nThe gap between the predicted and the original delay is 8.49 minutes. Here we can see how the model behavior changes according to the missing main feature impact (the **DEPARTURE_DELAY**). The original delay is much lower than the mean absolute error of 0.857 minutes from the previous calculations. The conjecture about the risk of one high rated feature has confirmed. Nevertheless, this difference is in a range that has not be bad at all. It seems this model has a good accuracy to predict the flight delay. \n\nSome kind of pruning for the **DEPARTURE_DELAY** would definitely improve the model more. I will keep that in mind for a later version of this model, this notebook, right now I'm happy with the result of the model and will leave it as it is. \n\n<br>\n\nThanks for review. **If you like it, give it a upvote** and don't forget your **feedback** down below!<br>\nI am looking forward to.\n\nCheers,\n\nRobin\n"},{"metadata":{"trusted":true,"_uuid":"a37b89202c14578df3c351281e67055e8b2b554f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}