{"cells":[{"metadata":{},"cell_type":"markdown","source":"Reading classics [Deep Learning Models](https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/autoencoder/ae-basic.ipynb)\n\n## Code Modules, Functions, & Classes\n\n[Google Colaboratory Variant](https://colab.research.google.com/drive/1kydV6_IC0BtHwpijx4oVjEab_Z39RpCQ)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np,pandas as pd,pylab as pl\nimport h5py,torch\nfrom torchvision.datasets import MNIST as tmnist\nfrom torchvision import transforms,utils\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nimport torch.nn.functional as tnnf\nimport torch.nn as tnn\nimport tensorflow.image as timage\ndev=torch.device(\"cuda:0\" \\\nif torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class TData(tds):\n    def __init__(self,x,y):   \n        self.x=torch.tensor(x,dtype=torch.float32)\n        self.y=torch.tensor(y,dtype=torch.int32)\n    def __getitem__(self,index):\n        img,lbl=self.x[index],self.y[index]\n        return img,lbl\n    def __len__(self):\n        return self.y.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_examples(data_loader,img_size):\n    for images,labels in data_loader:  \n        print('Image dimensions: %s'%str(images.shape))\n        print('Label dimensions: %s'%str(labels.shape))\n        n=np.random.randint(1,50)\n        fig=pl.figure(figsize=(10,4))\n        for i in range(n,n+5):\n            ax=fig.add_subplot(1,5,i-n+1,\\\n            xticks=[],yticks=[],title=labels[i].item())\n            ax.imshow((images[i]).reshape(img_size,img_size),\n                      cmap=pl.cm.bone)\n        break\ndef display_results(num_images):\n    num_images=int(num_images)\n    fig,axes=pl.subplots(nrows=2,ncols=num_images, \n                         sharex=True,sharey=True,\n                         figsize=(10,4))\n    original_images=features[:num_images]\n    decoded_images=decoded[:num_images]\n    for i in range(num_images):\n        for ax,img in zip(axes,[original_images,\n                                decoded_images]):\n            curr_img=img[i].detach().to(torch.device('cpu'))\n            ax[i].imshow(curr_img.view((img_size,img_size)),\n                         cmap='bone')\n    pl.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"random_seed=12; batch_size=128; img_size=32\ntrans=transforms\\\n.Compose([transforms.Resize((img_size,img_size)),\n          transforms.ToTensor()])\ntrain=tmnist(root='data',train=True,\n             download=True,transform=trans)\ntest=tmnist(root='data',train=False, \n            transform=trans)\ntrain_loader=tdl(dataset=train,shuffle=True, \n                 batch_size=batch_size)\ntest_loader=tdl(dataset=test,shuffle=False, \n                batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_examples(test_loader,img_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpath='../input/classification-of-handwritten-letters/'\nf='LetterColorImages_123.h5'\nf=h5py.File(fpath+f,'r')\nkeys=list(f.keys()); print(keys)\nx=1-np.array(f[keys[1]],dtype='float32')/255\nx=timage.resize(x,[img_size,img_size])\nx=(np.dot(x.numpy(),[.299,.587,.114]))\\\n.reshape(-1,1,img_size,img_size)\ny=np.array(f[keys[2]],dtype='int32')-1\nN=y.shape[0]; n=int(.2*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(23).shuffle(shuffle_ids)\nx,y=x[shuffle_ids],y[shuffle_ids]\nx_test,x_train=x[:n],x[n:]\ny_test,y_train=y[:n],y[n:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_seed=23; batch_size2=128\ntrain2=TData(x_train,y_train)\ntest2=TData(x_test,y_test)\ntrain_loader2=tdl(dataset=train2,shuffle=True,\n                  batch_size=batch_size2)\ntest_loader2=tdl(dataset=test2,shuffle=True,\n                 batch_size=batch_size2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_examples(test_loader2,img_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Autoencoder\ncompresses 32x32-pixel images into (hidden1)-pixel vectors & restores the original images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class AE(tnn.Module):\n    def __init__(self,num_features,hidden1):\n        super(AE,self).__init__()\n        # encoder\n        self.linear1=tnn.Linear(num_features,hidden1)\n        self.linear1.weight.detach().normal_(0.,.1)\n        self.linear1.bias.detach().zero_()\n        # decoder\n        self.linear2=tnn.Linear(hidden1,num_features)\n        self.linear2.weight.detach().normal_(0.,.1)\n        self.linear2.bias.detach().zero_()\n    def forward(self,x):        \n        # encoder\n        encoded=self.linear1(x)\n        encoded=tnnf.leaky_relu(encoded)     \n        # decoder\n        logits=self.linear2(encoded)\n        decoded=torch.sigmoid(logits)\n        return decoded","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(random_seed)\nlearning_rate=.0005; hidden1=32\nmodel=AE(num_features=img_size**2,hidden1=hidden1)\nmodel=model.to(dev)\noptimizer=torch.optim.Adam(model.parameters(),\n                           lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"epochs=10\nfor epoch in range(epochs):\n    for batch_ids,(features,targets) in enumerate(train_loader):\n        features=features.view(-1,img_size**2).to(dev)\n        decoded=model(features)\n        cost=tnnf.binary_cross_entropy(decoded,features)\n        optimizer.zero_grad()      \n        cost.backward(); optimizer.step()\n        if not batch_ids%200:\n            print ('Epoch: %03d/%03d | Batch: %03d/%03d | Cost: %.4f' \n                   %(epoch+1,epochs,batch_ids,\n                     len(train_loader),cost))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"display_results(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Autoencoder 2\ncompresses 32x32-pixel images with convolutional layers & restores the original images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class AE2(tnn.Module):\n    def __init__(self):        \n        super(AE2,self).__init__()\n        # encoder\n        self.conv1=tnn.Conv2d(in_channels=1,out_channels=4,\n                              kernel_size=(3,3),stride=(1,1),\n                              padding=1)\n        self.pool1=tnn.MaxPool2d(kernel_size=(2,2),\n                                 stride=(2,2),padding=0)                                       \n        self.conv2=tnn.Conv2d(in_channels=4,out_channels=16,\n                              kernel_size=(3,3),stride=(1,1),\n                              padding=1)                                         \n        self.pool2=tnn.MaxPool2d(kernel_size=(2,2),\n                                 stride=(2,2),padding=0)\n        # decoder\n        self.conv3=tnn.Conv2d(in_channels=16,out_channels=4,\n                              kernel_size=(3,3),stride=(1,1),\n                              padding=1)\n        self.conv4=tnn.Conv2d(in_channels=4,out_channels=1,\n                              kernel_size=(3,3),stride=(1,1),\n                              padding=1)       \n    def forward(self,x):        \n        # encoder\n        x=self.conv1(x); x=tnnf.leaky_relu(x)\n        x=self.pool1(x)\n        x=self.conv2(x); x=tnnf.leaky_relu(x)\n        x=self.pool2(x)        \n        # decoder\n        x=tnnf.interpolate(x,scale_factor=2,mode='nearest')\n        x=self.conv3(x)\n        x=tnnf.leaky_relu(x)\n        x=tnnf.interpolate(x,scale_factor=2,mode='nearest')\n        x=self.conv4(x)\n        logits=tnnf.leaky_relu(x)\n        probs=torch.sigmoid(logits)\n        return logits,probs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(random_seed)\nlearning_rate=.05\nmodel=AE2()\nmodel=model.to(dev)\noptimizer2=torch.optim.Adam(model.parameters(),\n                            lr=learning_rate) ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"epochs=100\nfor epoch in range(epochs):\n    for batch_ids,(features,targets) in enumerate(train_loader2):\n        features=features.to(dev)\n        logits,decoded=model(features)\n        cost=tnnf.binary_cross_entropy_with_logits(logits,features)\n        optimizer2.zero_grad()      \n        cost.backward(); optimizer2.step()\n        if not batch_ids%100:\n            print ('Epoch: %03d/%03d | Batch: %03d/%03d | Cost: %.4f' \n                   %(epoch+1,epochs,batch_ids,\n                     len(train_loader2),cost))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_results(5)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}