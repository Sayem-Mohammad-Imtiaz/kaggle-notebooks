{"cells":[{"metadata":{},"cell_type":"markdown","source":"Reading classics [Deep Learning Models](https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/cnn/cnn-allconv.ipynb)\n\n## Code Modules & Functions","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np,pandas as pd,pylab as pl\nimport h5py,torch\nfrom torchvision.datasets import MNIST as tmnist\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nimport torch.nn.functional as tnnf\nfrom IPython.core.magic import register_line_magic\ndev=torch.device(\"cuda:0\" if torch.cuda.is_available() \n                 else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class TData(tds):\n    def __init__(self,X,y):   \n        self.X=torch.tensor(X,dtype=torch.float32)\n        self.y=torch.tensor(y,dtype=torch.int32)\n    def __getitem__(self,index):\n        train_img,train_lbl=self.X[index],self.y[index]\n        return train_img,train_lbl\n    def __len__(self):\n        return self.y.shape[0]\ndef model_acc(model,data_loader):\n    correct_preds,num_examples=0,0    \n    for features,targets in data_loader:\n        features=features.to(dev)\n        targets=targets.to(dev)\n        logits,probs=model(features)\n        _,pred_labels=torch.max(probs,1)\n        num_examples+=targets.size(0)\n        correct_preds+=(pred_labels==targets).sum()        \n    return correct_preds.float()/num_examples*100","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"@register_line_magic\ndef train_run(epochs):\n    epochs=int(epochs)\n    for epoch in range(epochs):\n        for batch_ids,(features,targets) in enumerate(train_loader):        \n            features=features.to(dev)\n            targets=targets.to(dev)\n            logits,probs=model(features)\n            cost=tnnf.cross_entropy(logits,targets)\n            optimizer.zero_grad(); cost.backward()\n            optimizer.step()\n            if not batch_ids%300:\n                print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids, \n                         len(train)//batch_size,cost))           \n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d/%03d train accuracy: %.2f%%'%\\\n                  (epoch+1,epochs,model_acc(model,train_loader)))\n@register_line_magic\ndef print_acc(t):\n    if t=='test':\n        print('Test accuracy: %.4f%%'%\\\n        (model_acc(model,test_loader)))\n    if t=='train':\n        print('Train accuracy: %.4f%%'%\\\n        (model_acc(model,train_loader)))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"@register_line_magic\ndef train_run2(epochs):\n    epochs=int(epochs)\n    for epoch in range(epochs):\n        for batch_ids,(features,targets) in enumerate(train_loader2):        \n            features=features.to(dev)\n            targets=targets.to(dev)\n            logits,probs=model(features)\n            cost=tnnf.cross_entropy(logits,targets.long())\n            optimizer2.zero_grad(); cost.backward()\n            optimizer2.step()\n            if not batch_ids%100:\n                print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids, \n                         len(train2)//batch_size2,cost))           \n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d/%03d train accuracy: %.2f%%'%\\\n                  (epoch+1,epochs,model_acc(model,train_loader2)))\n@register_line_magic\ndef print_acc2(t):\n    if t=='test':\n        print('Test accuracy: %.4f%%'%\\\n        (model_acc(model,test_loader2)))\n    if t=='train':\n        print('Train accuracy: %.4f%%'%\\\n        (model_acc(model,train_loader2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"random_seed=23; batch_size=128\ntrain=tmnist(root='data',train=True,download=True,\n            transform=transforms.ToTensor())\ntest=tmnist(root='data',train=False, \n            transform=transforms.ToTensor())\ntrain_loader=tdl(dataset=train,shuffle=True, \n                 batch_size=batch_size)\ntest_loader=tdl(dataset=test,shuffle=False, \n                batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for images,labels in train_loader:  \n    print('Image dimensions: %s'%str(images.shape))\n    print('Label dimensions: %s'%str(labels.shape))\n    n=np.random.randint(1,50)\n    fig=pl.figure(figsize=(11,4))\n    for i in range(n,n+5):\n        ax=fig.add_subplot(1,5,i-n+1,\\\n        xticks=[],yticks=[],title=labels[i])\n        ax.imshow((images[i]).reshape(28,28),\n                  cmap=pl.cm.bone)\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpath='../input/classification-of-handwritten-letters/'\nf='LetterColorImages_123.h5'\nf=h5py.File(fpath+f,'r')\nkeys=list(f.keys()); print(keys)\nx=np.array(f[keys[1]],dtype='float32')/255\nx=(np.dot(x,[.299,.587,.114])).reshape(-1,1,32,32)\ny=np.array(f[keys[2]],dtype='int32')-1\nN=len(y); n=int(.2*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(23).shuffle(shuffle_ids)\nx,y=x[shuffle_ids],y[shuffle_ids]\nx_test,x_train=x[:n],x[n:]\ny_test,y_train=y[:n],y[n:]\nx_train.shape,y_train.shape\nfig=pl.figure(figsize=(11,4))\nn=np.random.randint(1,50)\nfor i in range(n,n+5):\n    ax=fig.add_subplot(1,5,i-n+1,\\\n    xticks=[],yticks=[],title=y_test[i])\n    ax.imshow((x_test[i].reshape(32,32)),\n              cmap=pl.cm.bone)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_seed=1; batch_size2=128\ntrain2=TData(x_train,y_train)\ntest2=TData(x_test,y_test)\ntrain_loader2=tdl(dataset=train2,batch_size=batch_size2,shuffle=True)\ntest_loader2=tdl(dataset=test2,batch_size=batch_size2,shuffle=False)\nfor images,labels in train_loader2:  \n    print('Image dimensions: %s'%str(images.shape))\n    print('Label dimensions: %s'%str(labels.shape))\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## All CNN\n#### calculate same padding:\n#### (w - k + 2 * p) / s + 1 = o => p = (s * (o - 1) - w + k) / 2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class FCNN(torch.nn.Module):\n    def __init__(self,num_classes):\n        super(FCNN,self).__init__()      \n        self.num_classes=num_classes\n        # 28x28x1 => 28x28x4; (1*(28-1)-28+3)/2=1\n        self.conv1=torch.nn\\\n        .Conv2d(in_channels=1,out_channels=4,\n                kernel_size=(3,3),stride=(1,1),padding=1)\n        # 28x28x4 => 14x14x4\n        self.conv2=torch.nn\\\n        .Conv2d(in_channels=4,out_channels=4,\n                kernel_size=(3,3),stride=(2,2),padding=1)                             \n        # 14x14x4 => 14x14x8; (1*(14-1)-14+3)/2=1\n        self.conv3=torch.nn\\\n        .Conv2d(in_channels=4,out_channels=8,\n                kernel_size=(3,3),stride=(1,1),padding=1)               \n        # 14x14x8 => 7x7x8                             \n        self.conv4=torch.nn\\\n        .Conv2d(in_channels=8,out_channels=8,\n                kernel_size=(3,3),stride=(2,2),padding=1)             \n        # 7x7x8 => 7x7x16; (1*(7-1)-7+3)/2=1                            \n        self.conv5=torch.nn\\\n        .Conv2d(in_channels=8,out_channels=16,\n                kernel_size=(3,3),stride=(1,1),padding=1)        \n        # 7x7x16 => 4x4x16                             \n        self.conv6=torch.nn\\\n        .Conv2d(in_channels=16,out_channels=16,\n                kernel_size=(3,3),stride=(2,2),padding=1)             \n        # 4x4x16 => 4x4xnum_classes; (1*(7-1)-7+3)/2=1                          \n        self.conv7=torch.nn\\\n        .Conv2d(in_channels=16,out_channels=self.num_classes,\n                kernel_size=(3,3),stride=(1,1),padding=1)           \n    def forward(self,x):\n        y=tnnf.relu(self.conv1(x))\n        y=tnnf.relu(self.conv2(y))\n        y=tnnf.relu(self.conv3(y))\n        y=tnnf.relu(self.conv4(y))\n        y=tnnf.relu(self.conv5(y))\n        y=tnnf.relu(self.conv6(y))\n        y=tnnf.relu(self.conv7(y))        \n        logits=tnnf.adaptive_avg_pool2d(y,1)\n        logits.squeeze_(-1) # drop width\n        logits.squeeze_(-1) # drop height\n        probs=torch.softmax(logits,dim=1)\n        return logits,probs\ntorch.manual_seed(random_seed)\nnum_classes=10; learning_rate=.001\nmodel=FCNN(num_classes=num_classes)\nmodel=model.to(dev)\noptimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"%train_run 30","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%print_acc train\n%print_acc test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class FCNN2(torch.nn.Module):\n    def __init__(self,num_classes):\n        super(FCNN2,self).__init__()      \n        self.num_classes=num_classes\n        # 32x32x1 => 32x32x16; (1*(32-1)-32+3)/2=1\n        self.conv1=torch.nn\\\n        .Conv2d(in_channels=1,out_channels=16,\n                kernel_size=(3,3),stride=(1,1),padding=1)\n        # 32x32x16 => 16x16x16\n        self.conv2=torch.nn\\\n        .Conv2d(in_channels=16,out_channels=16,\n                kernel_size=(3,3),stride=(2,2),padding=1)                             \n        # 16x16x16 => 16x16x32; (1*(16-1)-16+3)/2=1\n        self.conv3=torch.nn\\\n        .Conv2d(in_channels=16,out_channels=32,\n                kernel_size=(3,3),stride=(1,1),padding=1)               \n        # 16x16x32 => 8x8x32                            \n        self.conv4=torch.nn\\\n        .Conv2d(in_channels=32,out_channels=32,\n                kernel_size=(3,3),stride=(2,2),padding=1)             \n        # 8x8x32 => 8x8x64; (1*(8-1)-8+3)/2=1                            \n        self.conv5=torch.nn\\\n        .Conv2d(in_channels=32,out_channels=64,\n                kernel_size=(3,3),stride=(1,1),padding=1)                                     \n        self.conv6=torch.nn\\\n        .Conv2d(in_channels=64,out_channels=64,\n                kernel_size=(3,3),stride=(2,2),padding=1)                                       \n        self.conv7=torch.nn\\\n        .Conv2d(in_channels=64,out_channels=self.num_classes,\n                kernel_size=(3,3),stride=(1,1),padding=1)\n    def forward(self,x):\n        y=tnnf.relu(self.conv1(x))\n        y=tnnf.relu(self.conv2(y))\n        y=tnnf.relu(self.conv3(y))\n        y=tnnf.relu(self.conv4(y))\n        y=tnnf.relu(self.conv5(y))\n        y=tnnf.relu(self.conv6(y))\n        y=tnnf.relu(self.conv7(y))        \n        logits=tnnf.adaptive_avg_pool2d(y,1)\n        logits.squeeze_(-1) # drop width\n        logits.squeeze_(-1) # drop height\n        probs=torch.softmax(logits,dim=1)\n        return logits,probs\ntorch.manual_seed(random_seed)\nnum_classes=33; learning_rate=.002\nmodel=FCNN2(num_classes=num_classes)\nmodel=model.to(dev)\noptimizer2=torch.optim.Adam(model.parameters(),lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"%train_run2 150","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%print_acc2 train\n%print_acc2 test","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}