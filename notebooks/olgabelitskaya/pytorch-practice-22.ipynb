{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from IPython.display import display,HTML\ndef dhtml(str):\n    display(HTML(\"\"\"<style>\n    @import 'https://fonts.googleapis.com/css?family=Smokum&effect=3d';      \n    </style><h1 class='font-effect-3d' \n    style='font-family:Smokum; color:#ff5511; font-size:35px;'>\n    %s</h1>\"\"\"%str))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Google Colaboratory Version](https://colab.research.google.com/drive/1PxqVoIvUkv-bYDMTGtCNYNji3-ObqNWz)","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Code Modules, Functions, & Classes')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np,pandas as pd,pylab as pl\nimport h5py,torch,time,copy,urllib,zipfile\nfrom torchvision.datasets import CIFAR10 as tcifar10\nfrom torchvision import transforms,utils,models\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nfrom torch.utils.data.dataset import Subset\nimport torch.nn.functional as tnnf\nimport torch.nn as tnn\nimport tensorflow.image as timage\nfrom IPython.core.magic import register_line_magic\ndev=torch.device(\"cuda:0\" \\\nif torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TData(tds):\n    def __init__(self,x,y):   \n        self.x=torch.tensor(x,dtype=torch.float32)\n        self.y=torch.tensor(y,dtype=torch.int32)\n    def __getitem__(self,index):\n        img,lbl=self.x[index],self.y[index]\n        return img,lbl\n    def __len__(self):\n        return self.y.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"@register_line_magic\ndef display_examples(d):\n    if d=='1': loaders=dataloaders\n    if d=='2': loaders=dataloaders2\n    for images,labels in loaders['valid']:  \n        print('Image dimensions: %s'%str(images.shape))\n        print('Label dimensions: %s'%str(labels.shape))\n        n=np.random.randint(1,50)\n        images=np.transpose(images,(0,2,3,1))/2.+.5\n        fig=pl.figure(figsize=(10,4))\n        for i in range(n,n+5):\n            ax=fig.add_subplot(1,5,i-n+1,\\\n            xticks=[],yticks=[],title=labels[i].item())\n            ax.imshow((images[i]).reshape(img_size,img_size,3))\n        break","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def model_acc(model,data_loader):\n    correct_preds,num_examples=0,0    \n    for features,targets in data_loader:\n        features=features.to(dev)\n        targets=targets.to(dev).long()\n        logits=model(features)\n        _,pred_labels=torch.max(logits,1)\n        num_examples+=targets.size(0)\n        correct_preds+=(pred_labels==targets).sum()        \n    return correct_preds.float()/num_examples*100\ndef epoch_loss(model,data_loader):\n    model.eval()\n    curr_loss,num_examples=0.,0\n    with torch.no_grad():\n        for features,targets in data_loader:\n            features=features.to(dev)\n            targets=targets.to(dev).long()\n            logits=model(features)\n            loss=tnnf.cross_entropy(logits,targets,\n                                    reduction='sum')\n            num_examples+=targets.size(0)\n            curr_loss+=loss\n        return curr_loss/num_examples","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Data')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"img_size=64\nclasses=('plane','car','bird','cat','deer',\n          'dog','frog','horse','ship','truck')\nrandom_seed=12; batch_size=128\ntrain_ids=torch.arange(0,44000)\nvalid_ids=torch.arange(44000,50000)\ntr0=(.5,.5,.5)\ntrans=transforms\\\n.Compose([transforms.Resize((img_size,img_size)),\n          transforms.ToTensor(),\n          transforms.Normalize(tr0,tr0)])\ntrain_valid=tcifar10(root='data',train=True,\n                     download=True,\n                     transform=trans)\ntrain=Subset(train_valid,train_ids)\nvalid=Subset(train_valid,valid_ids)\ntest=tcifar10(root='data',train=False, \n              transform=trans)\ndataloaders={'train':tdl(dataset=train,shuffle=True, \n                         batch_size=batch_size), \n             'valid':tdl(dataset=valid,shuffle=True, \n                         batch_size=batch_size),\n             'test':tdl(dataset=test,shuffle=True, \n                        batch_size=batch_size)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%display_examples 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpath='https://olgabelitskaya.github.io/' # from my website \nzf='LetterColorImages_123.h5.zip'\ninput_file=urllib.request.urlopen(fpath+zf)\noutput_file=open(zf,'wb'); \noutput_file.write(input_file.read())\noutput_file.close(); input_file.close()\nzipf=zipfile.ZipFile(zf,'r')\nzipf.extractall(''); zipf.close()\nf=h5py.File(zf[:-4],'r')\nkeys=list(f.keys()); print(keys)\nx=np.array(f[keys[1]],dtype='float32')\nx=timage.resize(x,[img_size,img_size])/255\nx=2*np.transpose(x.numpy(),(0,3,1,2))-1\nprint(x.mean(),x.std())\ny=np.array(f[keys[2]],dtype='int32')-1\nN=len(y); n=int(.1*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(23).shuffle(shuffle_ids)\nx,y=x[shuffle_ids],y[shuffle_ids]\nx_test,x_valid,x_train=x[:n],x[n:2*n],x[2*n:]\ny_test,y_valid,y_train=y[:n],y[n:2*n],y[2*n:]\nrandom_seed=23\ntrain2=TData(x_train,y_train)\nvalid2=TData(x_valid,y_valid)\ntest2=TData(x_test,y_test)\ndataloaders2={'train':tdl(dataset=train2,shuffle=True, \n                          batch_size=batch_size), \n              'valid':tdl(dataset=valid2,shuffle=True, \n                          batch_size=batch_size),\n              'test':tdl(dataset=test2,shuffle=True, \n                         batch_size=batch_size)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%display_examples 2","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('VGG16')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"model=models.vgg16(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad=False\nmodel.classifier[3].requires_grad=True\nmodel","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Training')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@register_line_magic\ndef train_run(pars):\n    [epochs,n]=pars.split()\n    epochs=int(epochs); n=int(n)\n    if n==1: loaders=dataloaders\n    if n==2: loaders=dataloaders2\n    for epoch in range(epochs):\n        model.train()\n        for batch_ids,(features,targets) \\\n        in enumerate(loaders['train']):        \n            features=features.to(dev)\n            targets=targets.to(dev).long()\n            logits=model(features)\n            cost=tnnf.cross_entropy(logits,targets)\n            optimizer.zero_grad(); cost.backward()\n            optimizer.step()\n            if not batch_ids%100:\n                print ('Epoch: %03d/%03d | Batch: %03d/%03d | Cost: %.4f' \n                       %(epoch+1,epochs,batch_ids,\n                         len(loaders['train']),cost))\n        model.eval()\n        with torch.set_grad_enabled(False):\n            print('Epoch: %03d/%03d'%(epoch+1,epochs))\n            print('train acc/loss: %.2f%%/%.2f valid acc/loss: %.2f%%/%.2f'%\\\n                  (model_acc(model,loaders['train']),\n                   epoch_loss(model,loaders['train']),\n                   model_acc(model,loaders['valid']),\n                   epoch_loss(model,loaders['valid'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes=10\nmodel.classifier[6]=tnn.Sequential(\n    tnn.Linear(4096,512),tnn.ReLU(),\n    tnn.Dropout(.5),tnn.Linear(512,num_classes))\nmodel=model.to(dev)\noptimizer=torch.optim.Adam(model.parameters())","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"%train_run 15 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model=models.vgg16(pretrained=True)\n#for param in model.parameters():\n#    param.requires_grad=False#model.classifier[3].requires_grad=True\n#num_classes=33\n#model.classifier[6]=tnn.Sequential(\n#    tnn.Linear(4096,256),tnn.ReLU(),\n#    tnn.Dropout(.5),tnn.Linear(256,num_classes))\n#model=model.to(dev)\n#optimizer=torch.optim.Adam(model.parameters())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%train_run 3 2","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}