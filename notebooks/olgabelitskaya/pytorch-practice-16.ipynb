{"cells":[{"metadata":{},"cell_type":"markdown","source":"Reading classics [Deep Learning Models](https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/autoencoder/ae-conv-var.ipynb)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from IPython.display import display,HTML\ndef dhtml(str):\n    display(HTML(\"\"\"<style>\n    @import 'https://fonts.googleapis.com/css?family=Ewert&effect=3d';      \n    </style><h1 class='font-effect-3d' \n    style='font-family:Ewert; color:#ff6633;'>\n    %s</h1>\"\"\"%str))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"dhtml('Code Modules, Functions, & Classes')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np,pandas as pd,pylab as pl\nimport h5py,torch\nfrom torchvision.datasets import MNIST as tmnist\nfrom torchvision import transforms,utils\nfrom torch.utils.data import DataLoader as tdl\nfrom torch.utils.data import Dataset as tds\nimport torch.nn.functional as tnnf\nimport torch.nn as tnn\nimport tensorflow.image as timage\nfrom IPython.core.magic import register_line_magic\ndev=torch.device(\"cuda:0\" \\\nif torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TData(tds):\n    def __init__(self,x,y):   \n        self.x=torch.tensor(x,dtype=torch.float32)\n        self.y=torch.tensor(y,dtype=torch.int32)\n    def __getitem__(self,index):\n        img,lbl=self.x[index],self.y[index]\n        return img,lbl\n    def __len__(self):\n        return self.y.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"@register_line_magic\ndef display_examples(n):\n    if n=='1': data_loader=train_loader\n    if n=='2': data_loader=train_loader2\n    for images,labels in data_loader:  \n        print('Image dimensions: %s'%str(images.shape))\n        print('Label dimensions: %s'%str(labels.shape))\n        n=np.random.randint(1,50)\n        fig=pl.figure(figsize=(10,4))\n        for i in range(n,n+5):\n            ax=fig.add_subplot(1,5,i-n+1,\\\n            xticks=[],yticks=[],title=labels[i].item())\n            ax.imshow((images[i]).reshape(img_size,img_size),\n                      cmap=pl.cm.bone)\n        break","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Data')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"random_seed=12; batch_size=128; img_size=28\ntrans=transforms\\\n.Compose([transforms.Resize((img_size,img_size)),\n          transforms.ToTensor()])\ntrain=tmnist(root='data',train=True,\n             download=True,transform=trans)\ntest=tmnist(root='data',train=False, \n            transform=trans)\ntrain_loader=tdl(dataset=train,shuffle=True, \n                 batch_size=batch_size)\ntest_loader=tdl(dataset=test,shuffle=False, \n                batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%display_examples 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpath='../input/classification-of-handwritten-letters/'\nf='LetterColorImages_123.h5'\nf=h5py.File(fpath+f,'r')\nkeys=list(f.keys()); print(keys)\nx=1-np.array(f[keys[1]],dtype='float32')/255\nx=timage.resize(x,[img_size,img_size])\nx=(np.dot(x.numpy(),[.299,.587,.114]))\\\n.reshape(-1,1,img_size,img_size)\ny=np.array(f[keys[2]],dtype='int32')-1\nN=y.shape[0]; n=int(.2*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(23).shuffle(shuffle_ids)\nx,y=x[shuffle_ids],y[shuffle_ids]\nx_test,x_train=x[:n],x[n:]\ny_test,y_train=y[:n],y[n:]\nrandom_seed=23; batch_size2=128\ntrain2=TData(x_train,y_train)\ntest2=TData(x_test,y_test)\ntrain_loader2=tdl(dataset=train2,shuffle=True,\n                  batch_size=batch_size2)\ntest_loader2=tdl(dataset=test2,shuffle=False,\n                 batch_size=batch_size2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%display_examples 2","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Convolutional Variational <br/>Autoencoder')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ConvVarAE(tnn.Module):\n    def __init__(self,num_features,num_latent):\n        super(ConvVarAE,self).__init__()\n        # encoder\n        self.conv_en1=tnn\\\n        .Conv2d(in_channels=1,out_channels=16,\n                kernel_size=(6,6),stride=(2,2),\n                padding=0)\n        self.conv_en2=tnn\\\n        .Conv2d(in_channels=16,out_channels=32,\n                kernel_size=(4,4),stride=(2,2),\n                padding=0)                        \n        self.conv_en3=tnn\\\n        .Conv2d(in_channels=32,out_channels=64,\n                kernel_size=(2,2),stride=(2,2),\n                padding=0)                           \n        self.z_mean=tnn.Linear(64*2*2,num_latent)\n        self.z_log_var=tnn.Linear(64*2*2,num_latent)\n        # decoder\n        self.linear_de1=tnn.Linear(num_latent,64*2*2)             \n        self.deconv_de1=tnn\\\n        .ConvTranspose2d(in_channels=64,out_channels=32,\n                         kernel_size=(2,2),stride=(2,2),\n                         padding=0)                         \n        self.deconv_de2=tnn\\\n        .ConvTranspose2d(in_channels=32,out_channels=16,\n                         kernel_size=(4,4),stride=(3,3),\n                         padding=1)       \n        self.deconv_de3=tnn\\\n        .ConvTranspose2d(in_channels=16,out_channels=1,\n                         kernel_size=(6,6),stride=(3,3),\n                         padding=4)\n    def reparameterize(self,z_mu,z_log_var):\n        eps=torch.randn(z_mu.size(0),z_mu.size(1)).to(dev)\n        return z_mu+eps*torch.exp(z_log_var/2.)       \n    def encoder(self,features):\n        x=self.conv_en1(features); x=tnnf.leaky_relu(x)       \n        x=self.conv_en2(x); x=tnnf.leaky_relu(x)\n        x=self.conv_en3(x); x=tnnf.leaky_relu(x)      \n        z_mean=self.z_mean(x.view(-1,64*2*2))\n        z_log_var=self.z_log_var(x.view(-1,64*2*2))\n        encoded=self.reparameterize(z_mean,z_log_var)  \n        return z_mean,z_log_var,encoded  \n    def decoder(self,encoded):\n        x=self.linear_de1(encoded)\n        x=x.view(-1,64,2,2)     \n        x=self.deconv_de1(x); x=tnnf.leaky_relu(x)       \n        x=self.deconv_de2(x); x=tnnf.leaky_relu(x)      \n        x=self.deconv_de3(x); x=tnnf.leaky_relu(x)\n        decoded=torch.sigmoid(x)\n        return decoded\n    def forward(self,features):\n        z_mean,z_log_var,encoded=self.encoder(features)\n        decoded=self.decoder(encoded)\n        return z_mean,z_log_var,encoded,decoded","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Training')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(random_seed)\nlearning_rate=.005; num_latent=15\nmodel=ConvVarAE(num_features=img_size**2,\n                num_latent=num_latent)\nmodel=model.to(dev)\noptimizer=torch.optim.Adam(model.parameters(),\n                           lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"epochs=30\nfor epoch in range(epochs):\n    for batch_ids,(features,targets) in enumerate(train_loader):\n        features=features.to(dev)\n        z_mean,z_log_var,encoded,decoded=model(features)\n        kl_divergence=(.5*(z_mean**2+torch.exp(z_log_var)-\n                           z_log_var-1)).sum()\n        pixelwise_bce=tnnf\\\n        .binary_cross_entropy(decoded,features,reduction='sum')\n        cost=kl_divergence+pixelwise_bce\n        optimizer.zero_grad()\n        cost.backward(); optimizer.step()\n        if not batch_ids%100:\n            print ('Epoch: %03d/%03d | Batch: %03d/%03d | Cost: %.4f' \n                   %(epoch+1,epochs,batch_ids, \n                     len(train_loader),cost))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Reconstruction')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_images=5\nfig,axes=pl.subplots(nrows=2,ncols=num_images, \n                     sharex=True,sharey=True,\n                     figsize=(10,4))\noriginal_images=features[:num_images]\ndecoded_images=decoded[:num_images]\nfor i in range(num_images):\n    for ax,img in zip(axes,[original_images,\n                            decoded_images]):\n        ax[i].imshow(img[i].detach().to(torch.device('cpu'))\\\n                     .reshape((img_size,img_size)),cmap='bone')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Generating')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_images=10\nlatent_features=\\\ntorch.randn(num_images,num_latent).to(dev)\ngenerated_images=model.decoder(latent_features)\ndecoded_images=generated_images[:num_images]\nfig,axes=pl.subplots(nrows=2,ncols=num_images//2,\n                     figsize=(10,4),sharey=True)\nfor ax,img in zip(axes.reshape(num_images),decoded_images):\n    ax.imshow(img.detach().to(torch.device('cpu'))\\\n              .reshape((img_size,img_size)),cmap='bone')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Convolutional Conditional <br/>Variational Autoencoder')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ch1,ch2,ch3=16,48,144\ndef to_onehot(labels,num_classes,device):\n    labels_ohe=torch.zeros(labels.size()[0],\n                           num_classes).to(device)\n    labels_ohe.scatter_(1,labels.view(-1,1),1)\n    return labels_ohe\nclass CondVarAE(tnn.Module):\n    def __init__(self,num_features,num_latent,num_classes):\n        super(CondVarAE,self).__init__()\n        self.num_classes=num_classes\n        # ENCODER\n        self.conv_en1=tnn\\\n        .Conv2d(in_channels=1+self.num_classes,\n                out_channels=ch1,kernel_size=(6,6),\n                stride=(2,2),padding=0)\n        self.conv_en2=tnn\\\n        .Conv2d(in_channels=ch1,out_channels=ch2,\n                kernel_size=(4,4),stride=(2,2),\n                padding=0)                        \n        self.conv_en3=tnn\\\n        .Conv2d(in_channels=ch2,out_channels=ch3,\n                kernel_size=(2,2),stride=(2,2),\n                padding=0)                     \n        self.z_mean=tnn.Linear(ch3*2*2,num_latent)\n        self.z_log_var=tnn.Linear(ch3*2*2,num_latent)\n        # DECODER\n        self.linear_de1=tnn\\\n        .Linear(num_latent+self.num_classes,ch3*2*2)\n        self.deconv_de1=tnn\\\n        .ConvTranspose2d(in_channels=ch3,out_channels=ch2,\n                         kernel_size=(2,2),stride=(2,2),\n                         padding=0)                              \n        self.deconv_de2=tnn\\\n        .ConvTranspose2d(in_channels=ch2,out_channels=ch1,\n                         kernel_size=(4,4),stride=(3,3),\n                         padding=1)\n        \n        self.deconv_de3=tnn\\\n        .ConvTranspose2d(in_channels=ch1,out_channels=1,\n                         kernel_size=(6,6),stride=(3,3),\n                         padding=4)        \n    def reparameterize(self, z_mu, z_log_var):\n        eps=torch.randn(z_mu.size(0),z_mu.size(1)).to(dev)\n        return z_mu+eps*torch.exp(z_log_var/2.)    \n    def encoder(self,features,targets):\n        onehot_targets=\\\n        to_onehot(targets,self.num_classes,dev)\n        onehot_targets=\\\n        onehot_targets.view(-1,self.num_classes,1,1)        \n        ones=torch.ones(features.size()[0], self.num_classes,\n                        features.size()[2],features.size()[3], \n                        dtype=features.dtype).to(dev)\n        ones=ones*onehot_targets\n        x=torch.cat((features,ones),dim=1)        \n        x=self.conv_en1(x); x=tnnf.leaky_relu(x)      \n        x=self.conv_en2(x); x=tnnf.leaky_relu(x)\n        x=self.conv_en3(x); x=tnnf.leaky_relu(x)     \n        z_mean=self.z_mean(x.view(-1,ch3*2*2))\n        z_log_var=self.z_log_var(x.view(-1,ch3*2*2))\n        encoded=self.reparameterize(z_mean,z_log_var)\n        return z_mean,z_log_var,encoded  \n    def decoder(self,encoded,targets):\n        onehot_targets=\\\n        to_onehot(targets,self.num_classes,dev)\n        encoded=torch.cat((encoded,onehot_targets),dim=1)        \n        x=self.linear_de1(encoded)\n        x=x.view(-1,ch3,2,2)  \n        x=self.deconv_de1(x); x=tnnf.leaky_relu(x)      \n        x=self.deconv_de2(x); x=tnnf.leaky_relu(x)\n        x=self.deconv_de3(x); x=tnnf.leaky_relu(x)\n        decoded=torch.sigmoid(x)\n        return decoded\n    def forward(self,features,targets):      \n        z_mean,z_log_var,encoded=self.encoder(features,targets)\n        decoded=self.decoder(encoded,targets)     \n        return z_mean,z_log_var,encoded,decoded","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Training 2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(random_seed)\nlearning_rate=.0015; num_latent=121; num_classes=33\nmodel=CondVarAE(num_features=img_size**2,\n                num_latent=num_latent,\n                num_classes=num_classes)\nmodel=model.to(dev)\noptimizer=torch.optim.Adam(model.parameters(),\n                           lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"epochs=200\nfor epoch in range(epochs):\n    for batch_ids,(features,targets) in enumerate(train_loader2):\n        features=features.to(dev)\n        targets=targets.to(dev)\n        z_mean,z_log_var,encoded,decoded=model(features,targets.long())\n        kl_divergence=(.5*(z_mean**2+torch.exp(z_log_var)-\n                           z_log_var-1)).sum()\n        pixelwise_bce=tnnf\\\n        .binary_cross_entropy(decoded,features,reduction='sum')\n        cost=kl_divergence+pixelwise_bce\n        optimizer.zero_grad()\n        cost.backward(); optimizer.step()\n        if not batch_ids%50:\n            print ('Epoch: %03d/%03d | Batch: %03d/%03d | Cost: %.4f' \n                   %(epoch+1,epochs,batch_ids, \n                     len(train_loader2),cost))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Reconstruction 2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_images=5\nfig,axes=pl.subplots(nrows=2,ncols=num_images, \n                     sharex=True,sharey=True,\n                     figsize=(10,4))\noriginal_images=features[:num_images]\ndecoded_images=decoded[:num_images]\nfor i in range(num_images):\n    for ax,img in zip(axes,[original_images,\n                            decoded_images]):\n        ax[i].imshow(img[i].detach().to(torch.device('cpu'))\\\n                     .reshape((img_size,img_size)),cmap='bone')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dhtml('Generating 2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@register_line_magic\ndef display_gen(l):\n    l=int(l); num_images=5\n    labels=torch.tensor([l]*num_images).to(dev)\n    latent_features=\\\n    torch.randn(num_images,num_latent).to(dev)\n    generated_images=model.decoder(latent_features,labels)\n    decoded_images=generated_images[:num_images]\n    fig,axes=pl.subplots(nrows=1,ncols=num_images,\n                         figsize=(10,2),sharey=True)\n    for ax,img in zip(axes,decoded_images):\n        ax.imshow(img.detach().to(torch.device('cpu'))\\\n                  .reshape((img_size,img_size)),cmap='bone')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%display_gen 0\n%display_gen 1\n%display_gen 2\n%display_gen 3\n%display_gen 4","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}