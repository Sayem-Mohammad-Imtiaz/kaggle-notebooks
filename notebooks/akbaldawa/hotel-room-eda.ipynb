{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"hotel = pd.read_csv('/kaggle/input/hotel-booking-demand/hotel_bookings.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(hotel.shape)\nprint(hotel.info())\nprint(hotel.head().T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking outliers at 25%,50%,75%,90%,95% and 99%\nhotel.describe(percentiles=[.25,.5,.75,.90,.95,.99]).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets drop these rows as there are no actual bookings made and it may not be of much use for Analysis\n\nhotel.drop(hotel[((hotel['children'] == 0) & \n                  (hotel['babies']   == 0) & \n                  (hotel['adults']   == 0))].index,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Detecting Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom collections import Counter \n# Outlier detection\n\ndef detect_outliers(df,n,features):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than n outliers according\n    to the Tukey method.\n    \"\"\"\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in features:\n        print(col)\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        #print(outlier_step)\n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n        # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)\n    #return outlier_indices\n    multiple_outliers = list(k for k, v in outlier_indices.items() if v > n )\n    #multiple_outliers = list(outlier_indices)\n    return multiple_outliers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Removing outliers from the Numerical columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_num = hotel.dtypes[hotel.dtypes != 'object']\nhotel_num = hotel_num.index.to_list()\n\nDate_Drop = {'is_canceled','company'}\nhotel_num = [ele for ele in hotel_num if ele not in Date_Drop]\nhotel_num\n\n#hot_num = hotel[hotel_num].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Outliers_to_drop = detect_outliers(hotel,2,hotel_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in hot_num.columns:\n#     hot_num.boxplot(column=i)\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_num.remove('arrival_date_year') \nhotel_num.remove('arrival_date_week_number')\nhotel_num.remove('arrival_date_day_of_month') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Outliers_to_drop = detect_outliers(hotel,[\"lead_time\",\n#  \"stays_in_weekend_nights\"])\n# #  'stays_in_week_nights',\n#  'adults',\n#  'children',\n#  'babies',\n#  'is_repeated_guest',\n#  'previous_cancellations',\n#  'previous_bookings_not_canceled',\n#  'booking_changes',\n#  'agent',\n#  'days_in_waiting_list',\n#  'adr',\n#  'required_car_parking_spaces',\n#  'total_of_special_requests'])\nlen(Outliers_to_drop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop outliers\nhotel = hotel.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## The country columns missing values can be replaced with unknown\n## Agent missing can be replaced by 0 as these booking are not doe via an agent\n## missing value for company could be replaced \n## Looking at the number of adults, may be there are no children accompanying them,we will replace the missing values with 0\n\n## Looking at the unique values of the company and agents columns gives, they do not seem to be numerical data,these seem to be different codes for the gent or company\n## masked while the data set was released for maintaining data provancy  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## There are 4 columns with missing values\n\n# country                               488\n# agent                               16192\n# company                            109588\n# Children                                4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel.company = hotel.company.fillna(0)\nhotel.agent   = hotel.agent.fillna(0)\nhotel.children = hotel.children.fillna(0)\nhotel.country = hotel.country.fillna('unknown')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_clean = hotel.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel.describe(percentiles=[.25,.5,.75,.90,.95,.99]).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Dummy Variables for all the Categorical Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel['hotel'] = hotel['hotel'].map({'Resort Hotel': 0, 'City Hotel': 1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a dummy variable for the variable 'meal' and dropping the first one.\ncont = pd.get_dummies(hotel['meal'],prefix='meal',drop_first=True)\n#Adding the results to the master dataframe\nhotel = pd.concat([hotel,cont],axis=1)\n\n# Creating a dummy variable for the variable 'market_segment' and dropping the first one.\ncont = pd.get_dummies(hotel['market_segment'],prefix='market_segment',drop_first=True)\n#Adding the results to the master dataframe\nhotel = pd.concat([hotel,cont],axis=1)\n\n# Creating a dummy variable for the variable 'distribution_channel' and dropping the first one.\ncont = pd.get_dummies(hotel['distribution_channel'],prefix='distribution_channel',drop_first=True)\n#Adding the results to the master dataframe\nhotel = pd.concat([hotel,cont],axis=1)\n\n# Creating a dummy variable for the variable 'reserved_room_type' and dropping the first one.\ncont = pd.get_dummies(hotel['reserved_room_type'],prefix='reserved_room_type',drop_first=True)\n#Adding the results to the master dataframe\nhotel = pd.concat([hotel,cont],axis=1)\n\n# Creating a dummy variable for the variable 'assigned_room_type' and dropping the first one.\ncont = pd.get_dummies(hotel['assigned_room_type'],prefix='assigned_room_type',drop_first=True)\n#Adding the results to the master dataframe\nhotel = pd.concat([hotel,cont],axis=1)\n\n# Creating a dummy variable for the variable 'deposit_type' and dropping the first one.\ncont = pd.get_dummies(hotel['deposit_type'],prefix='deposit_type',drop_first=True)\n#Adding the results to the master dataframe\nhotel = pd.concat([hotel,cont],axis=1)\n\n# Creating a dummy variable for the variable 'customer_type' and dropping the first one.\ncont = pd.get_dummies(hotel['customer_type'],prefix='customer_type',drop_first=True)\n#Adding the results to the master dataframe\nhotel = pd.concat([hotel,cont],axis=1)\n\n# Creating a dummy variable for the variable 'reservation_status' and dropping the first one.\ncont = pd.get_dummies(hotel['reservation_status'],prefix='reservation_status',drop_first=True)\n#Adding the results to the master dataframe\nhotel = pd.concat([hotel,cont],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel = hotel.drop(['meal',\n 'country',\n 'market_segment',\n 'distribution_channel',\n 'reserved_room_type',\n 'assigned_room_type',\n 'deposit_type',\n 'customer_type',\n 'reservation_status'],1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Standardizing the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalising continuous features\ndf = hotel[hotel_num]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalized_df=(df-df.mean())/df.std()\n# hotel = hotel.drop(hotel_num, 1)\n# hotel = pd.concat([hotel,normalized_df],axis=1)\nhotel.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n\nhotel['reserve_year'] = pd.DatetimeIndex(hotel['reservation_status_date']).year\nhotel['reserve_month'] = pd.DatetimeIndex(hotel['reservation_status_date']).month\nhotel['reserve_day'] = pd.DatetimeIndex(hotel['reservation_status_date']).day\n\n\nhotel['arrival_date_month'] = pd.to_datetime(hotel['arrival_date_month'], format='%B').dt.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel = hotel.drop('reservation_status_date',axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the data into Test and Train\n\nx = hotel.drop('is_canceled',axis = 1)\ny = hotel['is_canceled']\n\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Machine learning tools.\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.svm import LinearSVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\nmodels.append(SVC())\nmodels.append(LinearSVC())\nmodels.append(Perceptron())\nmodels.append(GaussianNB())\nmodels.append(SGDClassifier())\nmodels.append(LogisticRegression())\nmodels.append(KNeighborsClassifier())\nmodels.append(RandomForestClassifier())\nmodels.append(DecisionTreeClassifier())\nmodels.append(GradientBoostingClassifier())\n\naccuracy_list = []\nfor model in models:\n    model.fit(x_train, y_train)\n    y_pred = model.predict(x_test)\n    accuracy = (accuracy_score(y_pred, y_test, normalize=True)*100)\n    accuracy_list.append(accuracy)\n\n\nmodel_name_list = [\"SVM\",\"Linear SVC\",\"Perceptron\",\"Gaussian NB\",\"SGD Classifier\",\"Logistic Regression\",\n                   \"K-Neighbors Classifier\",\"Random Forest Classifier\",\"Decision Tree\",\"Gradient Boosting\"]\n\nbest_model = pd.DataFrame({\"Model\": model_name_list, \"Score\": accuracy_list})\nbest_model.sort_values(by=\"Score\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DT = DecisionTreeClassifier()\nDT.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now we will deep dive into the dataset using various techniques"},{"metadata":{},"cell_type":"markdown","source":"## We will use the clean data we created in the earlier build"},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_clean = hotel.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_clean[hotel_clean['lead_time'] == 0].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pred = GB.predict(test_data)\n# predictions = pd.DataFrame({ \"PassengerId\" : passenger_id, \"Survived\": pred })","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extracting all the Categorical Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"Cat_Var = hotel_clean.dtypes[hotel.dtypes == 'object']\nCat_Var = Cat_Var.index.to_list()\n\nDate_Drop = {'reservation_status_date'}\nCat_Var = [ele for ele in Cat_Var if ele not in Date_Drop]\nCat_Var","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cnt_plot(a):\n    col = hotel[a]\n    plt.figure(figsize = (16,10))\n    sns.countplot(col,order = col.value_counts().index)\n    title = 'Category wise count of' + ' ' + a\n    plt.title(title)\n    #sns.countplot(col.value_counts())\n    #plt.xticks(rotation= 90)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in Cat_Var:\n    cnt_plot(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot for Numerical Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"def num_plot(x):\n    fea = hotel[x]\n    plt.figure(figsize = (16,10))\n    sns.distplot(a = fea,kde = False)\n    #title = 'Category wise count of' + ' ' + a\n    #plt.title(title)\n    #sns.countplot(col.value_counts())\n    #plt.xticks(rotation= 90)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"for i in hot_num.columns:\n    num_plot(i)"},{"metadata":{},"cell_type":"markdown","source":"## The country plot isn't vary clear,lets group some of them based on the counts"},{"metadata":{"trusted":true},"cell_type":"code","source":"s = hotel_clean['country'].value_counts()\n\nhotel_clean['country'] = np.where(hotel_clean['country'].isin(s.index[s == 1]),'EQ1' , hotel_clean['country'])\nhotel_clean['country'] = np.where(hotel_clean['country'].isin(s.index[s > 1] & s.index[s <= 10]),'LT10' , hotel_clean['country'])\nhotel_clean['country'] = np.where(hotel_clean['country'].isin(s.index[s > 10] & s.index[s <= 49]),'LT50' , hotel_clean['country'])\nhotel_clean['country'] = np.where(hotel_clean['country'].isin(s.index[s > 49] & s.index[s <= 99]),'LT100' , hotel_clean['country'])\nhotel_clean['country'] = np.where(hotel_clean['country'].isin(s.index[s > 99] & s.index[s <= 499]),'LT500' , hotel_clean['country'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Bins for Lead Time"},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = [0,1,8,29,85,169,366,737]\n#labels = [0-8\",\"20-29\",\"30-39\",\"40-49\",\"50+\"]\n\nlabels = [\"0\",\"1-7\",\"8-28\",\"29-84\",\"85-168\",\"169-365\",\"366-737\"]\nhotel_clean[\"LeadtGroup\"] = pd.cut(hotel_clean[\"lead_time\"],bins, labels = labels, include_lowest = True)\n\nleadt_mapping = {\"0\": 0,\"1-7\": 1,\"8-28\":2,\"29-84\":3,\"85-168\":4,\"169-365\":5,\"366-737\":6}\nhotel_clean[\"LeadtGroup\"] = hotel_clean[\"LeadtGroup\"].map(leadt_mapping)\n#data.drop(\"age\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_clean[\"LeadtGroup\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_clean.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_clean['Members'] = hotel_clean['adults'] + hotel_clean['children'] + hotel_clean['babies']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_clean.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Offline TA/TO May refer to Through Agent/Through Operator\n## There are 2 extra type of room in the assigned Room Type as compared to the reserved Room Type/This will need further Analysis\n## It will be interesting to compare  distribution_channel and market_segment, there may be some correlation\n## There are very few bookingd for room C,H,P,I ,we can combine them to a separate category\n## There are many countries from where less than 10 bookings are being done,These can be grouped together under a single category","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extract Arrival Date"},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_clean['arrival_month'] = pd.to_datetime(hotel_clean['arrival_date_month'], format='%B').dt.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arrival_time_df = hotel_clean[['arrival_date_year','arrival_month','arrival_date_day_of_month']].copy()\narrival_time_df.columns = [\"year\", \"month\", \"day\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arrival_time_df[\"month\"] = arrival_time_df.month.map(\"{:02}\".format)\narrival_time_df[\"day\"] = arrival_time_df.day.map(\"{:02}\".format)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_clean['arrival_date'] = pd.to_datetime(arrival_time_df[['year','month','day']])\nhotel_clean['arrival_date'] = pd.to_datetime(hotel_clean['arrival_date']).dt.date","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extract Cost per member Per Night"},{"metadata":{},"cell_type":"markdown","source":"## Lets Explore the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_clean['cost_per_member_night'] = hotel_clean['adr']/(hotel_clean['adults'] + hotel_clean['children'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculate Average cost per Hotel Type Per Night"},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_clean.groupby('hotel')['cost_per_member_night'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_clean.groupby('arrival_date_month')['cost_per_member_night'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# order the hotel dataset by month:\nordered_months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \n          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\nhotel_clean[\"arrival_date_month\"] = pd.Categorical(hotel_clean[\"arrival_date_month\"], categories=ordered_months, ordered=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lin_plot(a):\n    plt.figure(figsize = (16,10))\n    sns.lineplot(x = a, y ='cost_per_member_night' ,hue = 'hotel',data = hotel_clean)\n    plt.title('Cost per night Vs ' + a)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_cols = ['arrival_date_month','arrival_date_year','meal']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in lin_cols:\n    lin_plot(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Revenue Generation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def lin_plot(a):\n    plt.figure(figsize = (16,10))\n    sns.lineplot(x = a, y ='cost_per_member_night' ,hue = 'hotel',data = hotel_clean)\n    plt.title('Cost per night Vs ' + a)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cntry_adr = pd.DataFrame(hotel_clean.groupby('country')['adr'].sum())\ndf_cntry_adr.reset_index(inplace = True)\ndf_cntry_cnt = pd.DataFrame(hotel_clean['country'].value_counts())\ndf_cntry_cnt.reset_index(inplace = True)\ndf_cntry_cnt = df_cntry_cnt.rename(columns = {'country': 'Tot Bookings','index' : 'country'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cntry_data = pd.merge(df_cntry_adr,df_cntry_cnt, on='country')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cntry_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create combo chart\n\nfig, ax1 = plt.subplots(figsize=(10,6))\nax1 = sns.lineplot(x = 'country', y = 'adr',data = df_cntry_data,color = 'Green' )\nplt.xticks(rotation = 90)\nplt.title('Country wise Total Bookings/Adr')\nax2 = ax1.twinx()\nax2 = sns.lineplot(x = 'country', y = 'Tot Bookings', data = df_cntry_data, color = 'Yellow')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_clean.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize = (15,15))\nvalues = hotel_clean.groupby('market_segment')['adr'].sum().values\n#colors = ['b', 'g', 'r', 'c', 'm', 'y', 'w', 'f']\nlabels = hotel_clean.groupby('market_segment')['adr'].sum().index\n#explode = (0.2, 0, 0, 0, 0, 0,0,0)\nplt.pie(values, labels= values,autopct='%1.1f%%',counterclock=False, shadow=True)\nplt.title('Market Segment Wise Revenue')\nplt.legend(labels,loc=2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_clean.groupby('market_segment')['adr'].sum().values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_clean.groupby('distribution_channel')['adr'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_clean.groupby('country')['adr'].sum()\nhotel_clean['country'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_clean.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fact_plot(row):\n    plt.figure(figsize = (16,10))\n    #g = sns.catplot(x=row,y=\"is_canceled\",data=hotel,kind=\"bar\")\n    sns.countplot(x=row,data=hotel,hue='is_canceled',palette='pastel')\n    #g = g.set_ylabels(\"Canceled Status\")\n    #g = plt.xticks(rotation= 90)\n    title = 'Plot of ' + row + ' Vs' + \" is_canceled\"\n    plt.title(title)\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in Cat_Var:\n    fact_plot(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets plot Correlation plot for the DataFrame:\ncorrmap = hotel.corr()\nplt.subplots(figsize = (16,10))\nsns.heatmap(corrmap,annot= True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Cat_df = hotel[['hotel',\n 'meal',\n 'country',\n 'market_segment',\n 'distribution_channel',\n 'reserved_room_type',\n 'assigned_room_type',\n 'deposit_type',\n 'customer_type',\n 'reservation_status']].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in Cat_df:\n    print(Cat_df[col].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel['hotel'] = hotel['hotel'].map({'Resort Hotel': 0, 'City Hotel': 1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a dummy variable for the variable 'meal' and dropping the first one.\ncont = pd.get_dummies(hotel['meal'],prefix='meal',drop_first=True)\n#Adding the results to the master dataframe\nhotel = pd.concat([hotel,cont],axis=1)\n\n# Creating a dummy variable for the variable 'market_segment' and dropping the first one.\ncont = pd.get_dummies(hotel['market_segment'],prefix='market_segment',drop_first=True)\n#Adding the results to the master dataframe\nhotel = pd.concat([hotel,cont],axis=1)\n\n# Creating a dummy variable for the variable 'distribution_channel' and dropping the first one.\ncont = pd.get_dummies(hotel['distribution_channel'],prefix='distribution_channel',drop_first=True)\n#Adding the results to the master dataframe\nhotel = pd.concat([hotel,cont],axis=1)\n\n# Creating a dummy variable for the variable 'reserved_room_type' and dropping the first one.\ncont = pd.get_dummies(hotel['reserved_room_type'],prefix='reserved_room_type',drop_first=True)\n#Adding the results to the master dataframe\nhotel = pd.concat([hotel,cont],axis=1)\n\n# Creating a dummy variable for the variable 'assigned_room_type' and dropping the first one.\ncont = pd.get_dummies(hotel['assigned_room_type'],prefix='assigned_room_type',drop_first=True)\n#Adding the results to the master dataframe\nhotel = pd.concat([hotel,cont],axis=1)\n\n# Creating a dummy variable for the variable 'deposit_type' and dropping the first one.\ncont = pd.get_dummies(hotel['deposit_type'],prefix='deposit_type',drop_first=True)\n#Adding the results to the master dataframe\nhotel = pd.concat([hotel,cont],axis=1)\n\n# Creating a dummy variable for the variable 'customer_type' and dropping the first one.\ncont = pd.get_dummies(hotel['customer_type'],prefix='customer_type',drop_first=True)\n#Adding the results to the master dataframe\nhotel = pd.concat([hotel,cont],axis=1)\n\n# Creating a dummy variable for the variable 'reservation_status' and dropping the first one.\ncont = pd.get_dummies(hotel['reservation_status'],prefix='reservation_status',drop_first=True)\n#Adding the results to the master dataframe\nhotel = pd.concat([hotel,cont],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel = hotel.drop(['meal',\n 'country',\n 'market_segment',\n 'distribution_channel',\n 'reserved_room_type',\n 'assigned_room_type',\n 'deposit_type',\n 'customer_type',\n 'reservation_status'],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for cat in Cat_df:\n#     Cat_df[cat]=Cat_df[cat].astype('category')\n\n# from sklearn.preprocessing import OneHotEncoder\n\n# one_hot = OneHotEncoder()\n# one_hot.fit(Cat_df)\n# cat_enc = pd.DataFrame((one_hot.transform(Cat_df)).toarray())\n# #df[cat] = le.fit_transform(df[cat].astype(str))\n\n# print('the number of rows in train is {} and columns is {}'.format(cat_enc.shape[0],cat_enc.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets plot Correlation plot again for the modified DataFrame:\ncorr = hotel.corr()\ncorrmap = np.triu(corr)\n\nfig, ax = plt.subplots(figsize = (60,60))\n\nsns.heatmap(hotel.corr(),annot= True,square = True,cmap= 'coolwarm', linewidths=3, linecolor='black')\nax.set_xticklabels(corr.columns, fontsize=30)\nax.set_yticklabels(corr.columns, fontsize=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Assigned vs Reserved have correlation for E,F,G,H categories\n#is_cancelled has correlation only with Reservation status check out and deposit type non-refund\n#customer type Transient and Transient type have correaltion\n#distrubtion channel direct vs market segment direct,market segment direct vs market segment TA/TD\n#distrubtion channel direct vs distrubtion channel TA/TD, distrubtion channel TA/TD\n#hotel vs Agent\n#distribution channel undefined vs market segment undefined","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel['reservation_status_date'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n\nhotel['reserve_year'] = pd.DatetimeIndex(hotel['reservation_status_date']).year\nhotel['reserve_month'] = pd.DatetimeIndex(hotel['reservation_status_date']).month\nhotel['reserve_day'] = pd.DatetimeIndex(hotel['reservation_status_date']).day","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel['arrival_date_month'].unique()\nhotel['arrival_date_month'] = pd.to_datetime(hotel['arrival_date_month'], format='%B').dt.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel = hotel.drop('reservation_status_date',axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the data into Test and Train\n\nx = hotel.drop('is_canceled',axis = 1)\ny = hotel['is_canceled']\n\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross validate model with Kfold stratified cross val\nkfold = StratifiedKFold(n_splits=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Modeling step Test differents algorithms \nrandom_state = 2\nclassifiers = []\nclassifiers.append(SVC(random_state=random_state))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(ExtraTreesClassifier(random_state=random_state))\nclassifiers.append(GradientBoostingClassifier(random_state=random_state))\nclassifiers.append(MLPClassifier(random_state=random_state))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LogisticRegression(random_state = random_state))\nclassifiers.append(LinearDiscriminantAnalysis())\n\ncv_results = []\nfor classifier in classifiers :\n    cv_results.append(cross_val_score(classifier, x_train, y = y_train, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n\ncv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n\ncv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\"LogisticRegression\",\"LinearDiscriminantAnalysis\"]})\n\ng = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### META MODELING  WITH ADABOOST, RF, EXTRATREES and GRADIENTBOOSTING\n\n# Adaboost\nDTC = DecisionTreeClassifier()\n\nadaDTC = AdaBoostClassifier(DTC, random_state=7)\n\nada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n              \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n              \"n_estimators\" :[1,2],\n              \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\n\ngsadaDTC = GridSearchCV(adaDTC,param_grid = ada_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsadaDTC.fit(x_train,y_train)\n\nada_best = gsadaDTC.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gsadaDTC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ExtraTrees \nExtC = ExtraTreesClassifier()\n\n\n## Search grid for optimal parameters\nex_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\n\n\ngsExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsExtC.fit(x_train,y_train)\n\nExtC_best = gsExtC.best_estimator_\n\n# Best score\ngsExtC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RFC Parameters tunning \nRFC = RandomForestClassifier()\n\n\n## Search grid for optimal parameters\nrf_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\n\n\ngsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsRFC.fit(x_train,y_train)\n\nRFC_best = gsRFC.best_estimator_\n\n# Best score\ngsRFC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gradient boosting tunning\n\nGBC = GradientBoostingClassifier()\ngb_param_grid = {'loss' : [\"deviance\"],\n              'n_estimators' : [100,200,300],\n              'learning_rate': [0.1, 0.05, 0.01],\n              'max_depth': [4, 8],\n              'min_samples_leaf': [100,150],\n              'max_features': [0.3, 0.1] \n              }\n\ngsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsGBC.fit(x_train,y_train)\n\nGBC_best = gsGBC.best_estimator_\n\n# Best score\ngsGBC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"Generate a simple plot of the test and training learning curve\"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt\n\ng = plot_learning_curve(gsRFC.best_estimator_,\"RF learning curves\",x_train,y_train,cv=kfold)\ng = plot_learning_curve(gsExtC.best_estimator_,\"ExtraTrees learning curves\",x_train,y_train,cv=kfold)\ng = plot_learning_curve(gsadaDTC.best_estimator_,\"AdaBoost learning curves\",x_train,y_train,cv=kfold)\ng = plot_learning_curve(gsGBC.best_estimator_,\"GradientBoosting learning curves\",x_train,y_train,cv=kfold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nrows = ncols = 2\nfig, axes = plt.subplots(nrows = nrows, ncols = ncols, sharex=\"all\", figsize=(15,15))\n\nnames_classifiers = [(\"AdaBoosting\", ada_best),(\"ExtraTrees\",ExtC_best),(\"RandomForest\",RFC_best),(\"GradientBoosting\",GBC_best)]\n\nnclassifier = 0\nfor row in range(nrows):\n    for col in range(ncols):\n        name = names_classifiers[nclassifier][0]\n        classifier = names_classifiers[nclassifier][1]\n        indices = np.argsort(classifier.feature_importances_)[::-1][:40]\n        g = sns.barplot(y=x_train.columns[indices][:40],x = classifier.feature_importances_[indices][:40] , orient='h',ax=axes[row][col])\n        g.set_xlabel(\"Relative importance\",fontsize=12)\n        g.set_ylabel(\"Features\",fontsize=12)\n        g.tick_params(labelsize=9)\n        g.set_title(name + \" feature importance\")\n        nclassifier += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}