{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import all necessary library..\nimport numpy as np # for array calculations\nimport pandas as pd # for dataframe manipulations\n\n# for visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# for not write again and again to show the graph\n%matplotlib inline\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load dataframe\ndf = pd.read_csv('/kaggle/input/goodreadsbooks/books.csv',error_bad_lines= False)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Descriptive Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# difffernt features..\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Features Description:\n\n* bookID\n    Contains the unique ID for each book/series\n* title\n    contains the titles of the books\n* authors\n    contains the author of the particular book\n* average_rating \n    the average rating of the books, as decided by the users\n* ISBN ISBN(10) \n    number, tells the information about a book - such as edition and publisher\n* ISBN 13 \n    The new format for ISBN, implemented in 2007. 13 digits\n* language_code \n    Tells the language for the books\n* Num_pages \n    Contains the number of pages for the book\n* Ratings_count \n    Contains the number of ratings given for the book\n* text_reviews_count \n    Has the count of reviews left by users"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check null values..\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### there is no nan values in any of its attribute. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# about dataframe \ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  numerical summary of dataframe \ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization"},{"metadata":{},"cell_type":"markdown","source":"### Top 15 Rated Books"},{"metadata":{"trusted":true},"cell_type":"code","source":"top_fifteen = df[df['ratings_count'] > 1000000]\ntop_fifteen.sort_values(by='average_rating', ascending=False)\ntop_fifteen.head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you seen above there are top 15 rated books . We saw that the maximum rating in our dataframe was 5.0 but we dont see any books in the above result with 5.0 rating. This is because we filtered these books on the basis of the number of ratings. We made sure that all the books that we have in the above results have a decent amount of rating. There can be books in the data that can have only 1 or 2 ratings can be rated 5.0. We want to avoid such books hence this sort of filtering. \n\n### Let's go ahead and visualize this outcome in form of a graph.\n\n\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn-whitegrid')\nplt.figure(figsize=(10, 10))\n\ndata = top_fifteen.sort_values(by='average_rating', ascending=False).head(15)\ngr = sns.barplot(x=\"average_rating\", y=\"title\", data=data, palette=\"CMRmap_r\")\n\nfor i in gr.patches:\n    gr.text(i.get_width() + .05, i.get_y() + 0.5, str(i.get_width()), fontsize = 10, color = 'k')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Top 15 authors present in our data"},{"metadata":{"trusted":true},"cell_type":"code","source":"top_15_authors = df.groupby('authors')['title'].count().reset_index().sort_values('title', ascending=False).head(15).set_index('authors')\ntop_15_authors.head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's go ahead and take a look at some top 15 authors present in our data. We will rank them according to the number of books they have written provided these books are present in the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(15,10))\nax = sns.barplot(top_15_authors['title'], top_15_authors.index, palette='CMRmap_r')\n\nax.set_title(\"Top 10 authors with most books\")\nax.set_xlabel(\"Total number of books\")\ntotals = []\nfor i in ax.patches:\n    totals.append(i.get_width())\ntotal = sum(totals)\nfor i in ax.patches:\n    ax.text(i.get_width()+.2, i.get_y()+.2,str(round(i.get_width())), fontsize=15,color='black')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to our graphs, Stephen king and P.G. Wodehouse have the most number of books in the data. Both the authors have 40 books in our data set followed by Rumiko Takahashi and Orson scott Card."},{"metadata":{},"cell_type":"markdown","source":"## Relationship between avrage rating and rating count"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.relplot(data=df,\n                 x=\"ratings_count\",\n                 y=\"average_rating\",\n                 color = '#95a3c3',\n                 sizes=(400, 600), \n                 height=7, \n                 marker='o')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ### Language Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 7))\nax = sns.countplot(x=df.language_code, data=df)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x()-0.05, p.get_height()+100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see here most of the books are the language of english.. so,in the features selection section we colud remove non english rows. in the dataframe for accuracy."},{"metadata":{},"cell_type":"markdown","source":"### Top 15 publisher"},{"metadata":{"trusted":true},"cell_type":"code","source":"top_15_publisher = df.groupby('publisher')['title'].count().reset_index().sort_values('title', ascending=False).head(15).set_index('publisher')\ntop_15_publisher.head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To get more about the publisher using visualizations"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(15,10))\nax = sns.barplot(top_15_publisher['title'], top_15_publisher.index, palette='CMRmap_r')\n\nax.set_title(\"Top 15 publisher with most books\")\nax.set_xlabel(\"Total number of books\")\ntotals = []\nfor i in ax.patches:\n    totals.append(i.get_width())\ntotal = sum(totals)\nfor i in ax.patches:\n    ax.text(i.get_width()+.2, i.get_y()+.2,str(round(i.get_width())), fontsize=15,color='black')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distribution of average_rating"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.average_rating = df.average_rating.astype(float)\nfig, ax = plt.subplots(figsize=[15,10])\nsns.distplot(df['average_rating'],ax=ax)\nax.set_title('Average rating distribution for all books',fontsize=20)\nax.set_xlabel('Average rating',fontsize=13)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"it almost follow gussian distributions curve. so, it is very good for model training."},{"metadata":{},"cell_type":"markdown","source":"After comparing the average rating with the different columns, we can go ahead with using the language and the Rating counts for our recommender system. Rest other colummns weren't making much sense and using them might not help us in a big way so we can omit them"},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### 1. Imputation"},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 0.7\n#Dropping columns with missing value rate higher than threshold\ndf = df[df.columns[df.isnull().mean() < threshold]]\n\n#Dropping rows with missing value rate higher than threshold\ndf = df.loc[df.isnull().mean(axis=1) < threshold]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.Handling Outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation between the features\ncorrmat = df.corr() \n  \nf, ax = plt.subplots(figsize =(9, 8)) \nsns.heatmap(corrmat, ax = ax, cmap =\"YlGnBu\", linewidths = 0.1) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"here you can see that text_reviews_count is highly correlated with ratings_count . so, you can you either of these features."},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 =df.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will now create a new column called 'rating_between'. We will divide our average rating column into various categories such as rating between 0 and 1, 1 and 2 and so on. This will work as one of the features that we will feed to our model so that it can make better predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.loc[ (df2['average_rating'] >= 0) & (df2['average_rating'] <= 1), 'rating_between'] = \"between 0 and 1\"\ndf2.loc[ (df2['average_rating'] > 1) & (df2['average_rating'] <= 2), 'rating_between'] = \"between 1 and 2\"\ndf2.loc[ (df2['average_rating'] > 2) & (df2['average_rating'] <= 3), 'rating_between'] = \"between 2 and 3\"\ndf2.loc[ (df2['average_rating'] > 3) & (df2['average_rating'] <= 4), 'rating_between'] = \"between 3 and 4\"\ndf2.loc[ (df2['average_rating'] > 4) & (df2['average_rating'] <= 5), 'rating_between'] = \"between 4 and 5\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rating_df = pd.get_dummies(df2['rating_between'])\nrating_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l_code_df = pd.get_dummies(df2['language_code'])\nl_code_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## now we combine these two in the dataframe \n\n\nfeatures = pd.concat([l_code_df, rating_df, df2['average_rating'], df2['ratings_count']], axis=1)\nfeatures.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have our features ready, we will now use the Min-Max scaler to scale these values down. It will help in reducing the bias for some of the books that have too many features. It will basically find the median for all and equalize it,"},{"metadata":{},"cell_type":"markdown","source":"## Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import necessary pakages for k-nearest-neighbour\n\nfrom sklearn.cluster import KMeans\nfrom sklearn import neighbors\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_max_scaler = MinMaxScaler()\nfeatures = min_max_scaler.fit_transform(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = neighbors.NearestNeighbors(n_neighbors=6, algorithm='ball_tree')\nmodel.fit(features)\ndist, idlist = model.kneighbors(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def book_recommendation_engine(book_name):\n    book_list_name = []\n    book_id = df2[df2['title'] == book_name].index\n    book_id = book_id[0]\n#     print('book_id', book_id)\n    for newid in idlist[book_id]:\n#         print(newid)\n        book_list_name.append(df2.loc[newid].title)\n#         print(new_data.loc[newid].title)\n    return book_list_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"book_list_name = book_recommendation_engine('Little Women')\nbook_list_name","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Working well\n\n              with the help of such a wonderfull notebook\n             1. https://www.kaggle.com/aayushmishra1512ll\n              \n             2. https://www.kaggle.com/snanilim\n             \n              Krish naik sir.. thanks all of you!!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}