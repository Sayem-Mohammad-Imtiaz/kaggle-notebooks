{"cells":[{"metadata":{},"cell_type":"markdown","source":"This dataset is attempted by a group of 4 authors"},{"metadata":{},"cell_type":"markdown","source":"# ABOUT THE DATASETS"},{"metadata":{},"cell_type":"markdown","source":"    The given dataset is of the Protugese Bank. The Bank conducted a Marketing Campaign on their customers to   encourage them to subscribe the Bank's Fixed Deposit Service."},{"metadata":{},"cell_type":"markdown","source":"# AIM OF THE PROJECT"},{"metadata":{},"cell_type":"markdown","source":"     i) To improve the current marketing campaign by using the dataset.\n     \n    ii) To predict if the client of a bank will subscribe (yes/no) to a term deposit (variable y), by building a  various classification ML model and suggesting which would be the best model suited for the bank.\n"},{"metadata":{},"cell_type":"markdown","source":"# DATA COLLECTION (IMPORTING NECESSARY LIBRARIES)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/bank-marketing-dataset/bank.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EXPLORATORY DATA ANALYSIS / VISUALIZATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"#LIST OF COLUMNS\n\nlist(df.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE COLUMNS:\n       \n       CUSTOMER ATTRIBUTES:\n   ----------------------------------------------------------------------------------------------\n   \n    01. age       : Age of the customer. \n    02. job       : Type of Job the customer is in.\n    03. marital   : Marital Status of the customer.\n    04. education : Education Level of the customer.\n    05. default   : Did the customer defaulted any loan repayment.\n    06. balance   : Customer Balance Amount with the bank.\n    07. housing   : Do the customer has housing loan?\n    08. loan      : Do the customer has personal loan?\n    \n        CAMPAIGN ATTRIBUTES:\n    ----------------------------------------------------------------------------------------------\n    \n    09. contact   : Mode of communication made with the customer.\n    10. day       : Last contacted day of the month made with the customer.\n    11. month     : Last contacted month of the year made with the customer.\n    12. duration  : Last contact duration in seconds made with the customer.\n    13. campaign  : Number of contacts performed during this campaign and for this customer.\n    14. deposit   : Has the customer subscribed to the Fixed Deposit.\n    \n        ABOUT PREVIOUS CONTACTS/CAMPAIGN:\n    ----------------------------------------------------------------------------------------------\n     \n    15. pdays     : Number of days that passed by after the customer was last contacted from a previous campaign\n    16. previous  : Number of contacts performed before this campaign and for this customer.\n    17. poutcome  : Outcome of the previous marketing campaign.\n    \n    \n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"# SHAPE OF THE DATASET\n\nTotal_Col = len(df.axes[1])\nTotal_Rows = len(df.axes[0])\n\nprint(\"Total Number of Rows = {} and Total Number of Columns = {}\".format(Total_Rows,Total_Col))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CHECKING DATA TYPES OF THE COLUMNS\n\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LIST OF UNIQUE VALUES OF COLUMNS WHERE DATATYPE IS AN OBJECT\n\ndf_new = df.select_dtypes(include = 'object')\nfor i in df_new:\n    print(\"Column Name: \",i)\n    print(list(df_new[i].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    FEW IMPORTANT POINTS FROM THE ABOVE DESCRIBE TABLE:\n    --------------------------\n    MEAN (AGE) =  41.23\n    MAX  (AGE) =  95.00\n    MIN  (AGE) =  18.00\n    --------------------------\n    MEAN (BALANCE) =  1528.53\n    MAX  (BALANCE) = 81204.00\n    MIN  (BALANCE) = -6847.00\n    ---------------------------\n    \n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf.hist()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# COMPARING ALL FEATURES AGAINST DEPOSIT"},{"metadata":{},"cell_type":"markdown","source":"Since 'deposit' column is our response variable, we will now comapare its values with all other feature variables. Further the values in the 'deposit' columns will be looked into as 'yes' and 'no'. "},{"metadata":{},"cell_type":"markdown","source":"___"},{"metadata":{"trusted":true},"cell_type":"code","source":"# NUMBER OF DEPOSITS\nplt.figure(figsize=(11,5))\n\ndf['deposit'].value_counts().plot.pie(explode=[0,0.05],autopct='%1.2f%%')\nshadow=True\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPOSIT VALUE COUNTS\ndf_deposit=pd.DataFrame({'YES':[5289],'NO':[5873]})\ndf_deposit\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPOSIT GRAPH REPRESENTATION\n\nsns.barplot(data=df_deposit)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE GRAPH:\n    \n    From the above graph we can well establish that 'yes' and 'no' values are relatively close, therefore accuracy of a model will help us determine the outcome of the marketing campaign. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# AGE FREQUENCY GRAPH REPRESENTATION\n\nplt.hist(x='age', data=df, bins = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE GRAPH:\n    \n    As you can see from the above Histograph the majority of frequency lies in between 25 and 40 years."},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPOSIT VS AGE\n\ndf_age = pd.DataFrame()\ndf_age['age_y'] = (df[df['deposit'] == 'yes'][['deposit','age']].describe())['age']\ndf_age['age_n'] = (df[df['deposit'] == 'no'][['deposit','age']].describe())['age']\n\ndf_age.drop(['count','std', '25%', '50%', '75%']).plot.bar()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n    \n    Customers with higher age group are more inclined towards a term deposit"},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPOSIT VS JOB\npd.crosstab(df['job'],df['deposit']).style.background_gradient(cmap='winter')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.countplot(x=df['job'],hue=df['deposit'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n    \n    Customers with management profile and students are more inclined towards a term deposit.\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPOSIT VS MARITAL\n\npd.crosstab(df['marital'],df['deposit']).style.background_gradient(cmap='spring')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=df['marital'],hue=df['deposit'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n    \n    Married customers are less inclined towards a term deposit.\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPOSIT VS EDUCATION\n\npd.crosstab(df['education'],df['deposit']).style.background_gradient(cmap='autumn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=df['education'],hue=df['deposit'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n    \n    Customers with tertiary education background are more inclined towards a term deposit.\n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPOSIT VS LOAN DEFAULT\n\n\npd.crosstab(df['default'],df['deposit']).style.background_gradient(cmap='cool')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=df['default'],hue=df['deposit'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n    \n    Defaulter customers are more reluctant towards a term deposit. \n    "},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPOSIT VS BALANCE\n\ndf_bal = pd.DataFrame()\ndf_bal['bal_y'] = (df[df['deposit'] == 'yes'][['deposit','balance']].describe())['balance']\ndf_bal['bal_n'] = (df[df['deposit'] == 'no'][['deposit','balance']].describe())['balance']\n\ndf_bal.drop(['count','std', '25%', '50%', '75%']).plot.bar()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n\n    Customers with greater bank balance are more inclined towards a term deposit."},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPOSIT VS HOUSING LOAN\n\npd.crosstab(df['housing'],df['deposit']).style.background_gradient(cmap='Wistia')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=df['housing'],hue=df['deposit'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n\n    Customers with no Housing loan are more inclined towards a term deposit."},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPOSIT VS PERSONAL LOAN\n\npd.crosstab(df['loan'],df['deposit']).style.background_gradient(cmap='bwr')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=df['loan'],hue=df['deposit'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n\n    Customers with no personal loan are more inclined towards a term deposit."},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPOSIT VS CONTACT\n\npd.crosstab(df['contact'],df['deposit']).style.background_gradient(cmap='seismic')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=df['contact'],hue=df['deposit'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n\n    Customers who were approached via 'cellular' are more inclined towards a term deposit."},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPOSIT VS DAY\n\n\n\ndf_day = pd.DataFrame()\ndf_day['day_y'] = (df[df['deposit'] == 'yes'][['deposit','day']].describe())['day']\ndf_day['day_n'] = (df[df['deposit'] == 'no'][['deposit','day']].describe())['day']\n\ndf_day.drop(['count','std', '25%', '50%', '75%']).plot.bar()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n\n    Customers are more reluctant towards a term deposit in the beginning of the month."},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPOSIT VS MONTH\n\npd.crosstab(df['month'],df['deposit']).style.background_gradient(cmap='PRGn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=df['month'],hue=df['deposit'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n\n    Customers are more reluctant towards a term deposit during the summer seasons (May to August)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPOSIT VS DURATION\n\n\n\ndf_dur = pd.DataFrame()\ndf_dur['day_y'] = (df[df['deposit'] == 'yes'][['deposit','duration']].describe())['duration']\ndf_dur['day_n'] = (df[df['deposit'] == 'no'][['deposit','duration']].describe())['duration']\n\ndf_dur.drop(['count','std', '25%', '50%', '75%']).plot.bar()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n\n    Chances of successfully locking a customer for a term deposit substantially increase with higher duration of conversation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPOSIT VS CAMPAIGN\n\n\n\ndf_camp = pd.DataFrame()\ndf_camp['day_y'] = (df[df['deposit'] == 'yes'][['deposit','campaign']].describe())['campaign']\ndf_camp['day_n'] = (df[df['deposit'] == 'no'][['deposit','campaign']].describe())['campaign']\n\ndf_camp.drop(['count','std', '25%', '50%', '75%']).plot.bar()\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n\n    Chances of successfully locking a customer for a term deposit decreases with more number of contacts."},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPOSIT VS PDAYS \n\nsns.barplot(y=df['pdays'],x=df['deposit'])\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n\n    More the number of days that passed by after the customer was last contacted from a previous campaign, the customer is inclined towards term deposit"},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPOSIT VS PREVIOUS\n\nsns.barplot(y=df['previous'],x=df['deposit'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n    \n    Lesser the number of contacts performed before this campaign and for this customer,  the customer is inclined towards term deposit"},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEPOSIT VS POUTCOME\n\ndf['poutcome']=df['poutcome'].replace(['other'], ['unknown'])\npd.crosstab(df['poutcome'],df['deposit']).style.background_gradient(cmap='PuOr')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['poutcome'].value_counts().plot.pie(explode=[0,0,0.2],autopct='%1.1f%%')\nplt.show()\nsns.countplot(x=df['poutcome'],hue=df['deposit'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n\n    Previous Campaign was 9.6% successful."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=df,hue='deposit')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# CORRELATION BETWEEN THE ATTRIBUTES \nplt.figure(figsize=(11,9))\n\nsns.heatmap(df.corr(),square=True,annot=True,cmap='twilight_shifted')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n    \n    As we can clearly observe that features are not much correlated. Therefore we will continue with all           the features"},{"metadata":{},"cell_type":"markdown","source":"# ---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*"},{"metadata":{},"cell_type":"markdown","source":"# DATA WRANGLING"},{"metadata":{"trusted":true},"cell_type":"code","source":"# FINDING DUPLICATE ROWS \ndf.duplicated().sum()\n\nprint(\"Number of duplicated rows {}\".format(df.duplicated().sum()))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FINDING NULL VALUES \ndf.isnull().sum()\n\nprint(\"Number of null values in the columns:\\n\\n {}\".format(df.isnull().sum()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ANALYZING THE NUMERICAL ATTRIBUTES FOR OUTLIERS"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new = df.select_dtypes(include = 'int64')\nfor i in df_new:\n    print(\"Column Name: \",i)\n    #print(list(df_new[i].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(y=df['age'],x=df['deposit'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(y=df['balance'],x=df['deposit'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(y=df['day'],x=df['deposit'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(y=df['duration'],x=df['deposit'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(y=df['campaign'],x=df['deposit'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(y=df['pdays'],x=df['deposit'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(y=df['previous'],x=df['deposit'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n    \n    Based on the above shown BoxPlots we can clearly see that except 'day' feature all other features have some anomalies, so we will investigate these attributes further.\n    \n    "},{"metadata":{},"cell_type":"markdown","source":"# FURTHER INVESTIGATION..."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['age','balance','day','duration','campaign','pdays','previous']].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANTION OF THE ABOVE\n    \n    OUTLIERS are defined as 1.5xQ3 value (75%). \n   \n    From the above we can clearly figure out that we have outliers in all the attributes except 'day'.\n    As max values are > 1.5xQ3 (1.5 * 75%). \n    \n    But these outliers are within an acceptable range, {Age can be 95(max), Balance can be 81204(max) or   -6847(min)}, therefore we will continue with this dataset as it is. \n    \n    We can also observe that in the column 'pdays' has -1(min) value, which seems unlikely. We will further continue with our investigation."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['pdays'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(8324 / 11162)*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n    \n    As 'pdays' has value of -1 more then 74% of this column. Therefore we recommend to drop this column.\n    We will continue with the rest of the columns for building the ML Models     "},{"metadata":{"trusted":true},"cell_type":"code","source":"# DROPPING PDAYS COLUMN\n\ndf.drop('pdays', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# VERIFYING UPDATES\nlist(df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new = df.select_dtypes(include = 'object')\nfor i in df_new:\n    print(\"Column Name: \",i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CONVERTING CATEGORICAL FEATURES INTO DUMMY VARIABLES\n\nwork = pd.get_dummies(df['job'],prefix='work')\nwork\n\n# 1 -> Belongs to the category ,  0 -> Does not belong to the category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DROPPING WORK_ADMIN COLUMN\n\nwork = work.drop('work_admin.', axis=1)\nwork.head()\n\n# 1 -> Belongs to the category ,  0 -> Does not belong to the category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CONVERTING CATEGORICAL FEATURES INTO DUMMY VARIABLES\n\nmarital_status = pd.get_dummies(df['marital'],prefix='marital_status')\n\n# DROPPING marital_status_divorced COLUMN\n\nmarital_status = marital_status.drop('marital_status_divorced', axis=1)\nmarital_status.head()\n\n# 1 -> Belongs to the category ,  0 -> Does not belong to the category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CONVERTING CATEGORICAL FEATURES INTO DUMMY VARIABLES\n\nqualification = pd.get_dummies(df['education'],prefix='quali')\n\n# DROPPING quali_primary COLUMN\n\nqualification = qualification.drop('quali_primary', axis=1)\nqualification.head()\n\n# 1 -> Belongs to the category ,  0 -> Does not belong to the category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CONVERTING CATEGORICAL FEATURES INTO DUMMY VARIABLES\n\ndefaulter = pd.get_dummies(df['default'],prefix='defaulter')\n\n# DROPPING quali_primary COLUMN\n\ndefaulter = defaulter.drop('defaulter_yes', axis=1)\ndefaulter.head()\n\n# 1 -> Belongs to the category ,  0 -> Does not belong to the category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CONVERTING CATEGORICAL FEATURES INTO DUMMY VARIABLES\n\nhloan = pd.get_dummies(df['housing'],prefix='hloan')\n\n# DROPPING quali_primary COLUMN\n\nhloan = hloan.drop('hloan_yes', axis=1)\nhloan.head()\n\n# 1 -> Belongs to the category ,  0 -> Does not belong to the category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CONVERTING CATEGORICAL FEATURES INTO DUMMY VARIABLES\n\nploan = pd.get_dummies(df['loan'],prefix='ploan')\n\n# DROPPING quali_primary COLUMN\n\nploan = ploan.drop('ploan_yes', axis=1)\nploan.head()\n\n# 1 -> Belongs to the category ,  0 -> Does not belong to the category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CONVERTING CATEGORICAL FEATURES INTO DUMMY VARIABLES\n\ncontacted = pd.get_dummies(df['contact'],prefix='contacted')\n\n# DROPPING quali_primary COLUMN\n\ncontacted = contacted.drop('contacted_cellular', axis=1)\ncontacted.head()\n\n# 1 -> Belongs to the category ,  0 -> Does not belong to the category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CONVERTING CATEGORICAL FEATURES INTO DUMMY VARIABLES\n\nmon = pd.get_dummies(df['month'],prefix='mon')\n\n# DROPPING quali_primary COLUMN\n\nmon = mon.drop('mon_nov', axis=1)\nmon.head()\n\n# 1 -> Belongs to the category ,  0 -> Does not belong to the category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CONVERTING CATEGORICAL FEATURES INTO DUMMY VARIABLES\n\npout = pd.get_dummies(df['poutcome'],prefix='pout')\n\n# DROPPING quali_primary COLUMN\n\npout = pout.drop('pout_failure', axis=1)\npout.head()\n\n\n# 1 -> Belongs to the category ,  0 -> Does not belong to the category","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#CONVERTING CATEGORICAL FEATURES INTO DUMMY VARIABLES\n\ndepo = pd.get_dummies(df['deposit'],prefix='depo')\n\n# DROPPING quali_primary COLUMN\n\ndepo = depo.drop('depo_yes', axis=1)\ndepo.head(50)\n\n# 1 -> Belongs to the category ,  0 -> Does not belong to the category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CONCATENATE ALL THE NEWLY CREATED COLUMNS TO THE MAIN DATAFRAME\n\ndf = pd.concat([df,work,marital_status,qualification,defaulter,hloan,ploan,contacted,mon,pout,depo], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# VERIFYING UPDATES\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DROPPING ALL THE IRRELEVANT COLUMNS\n\ndf_1 = df.drop(['job','marital','education','default','housing','loan','contact','month','poutcome','deposit'],axis=1)\n\n# VERIFYING UPDATES\n\ndf_1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n    \n    df_1 is our final dataset which we will further use to build relevant ML Models."},{"metadata":{},"cell_type":"markdown","source":"# ---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*"},{"metadata":{},"cell_type":"markdown","source":"# PREDICTIVE MODELLING"},{"metadata":{},"cell_type":"markdown","source":"# LOGISTIC REGRESSION USING SCIKIT LEARN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# SPLITTING THE DATASET INTO TEST-TRAIN\n\nfrom sklearn.model_selection import train_test_split\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df_1.drop(\"depo_no\", axis=1), df_1[\"depo_no\"], train_size = 0.8,\\\n                                                    random_state=101)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FITTING LOGISTIC REGRESSION MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logit = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logit.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MAKING PREDICTIONS\n\npredictions = logit.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CALCULATING ACCURACY\n\nlogit.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CALCULATING ERROR RATE\n\n(1-logit.score(X_test, y_test))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CALCULATING ACCURACY"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CALCULATE NUMBER OF CORRECTLY CLASSIFIED OBSERVATIONS\n\naccuracy_score(y_test, predictions, normalize=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CALCULATE NUMBER OF INCORRECTLY CLASSIFIED OBSERVATIONS\n\nlen(y_test) - accuracy_score(y_test, predictions, normalize=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CALCULATE PREDICTORS COEFFICIENT VALUES\n\nlogit.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CALCULATING LOG LOSS\n\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_encoded = y_test.map(lambda x: 1 if x == 1 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_encoded = np.where(predictions==1,1,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.log_loss(y_test_encoded, predictions_encoded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_encoded[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL EVALUATION USING CONFUSION MATRIX"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_mat = confusion_matrix(y_test, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_mat = confusion_matrix(y_test_encoded, predictions_encoded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_df = pd.DataFrame(confusion_mat, index=['Refused Term Deposit','Accepted Term Deposit'], columns=['Predicted Refusal','Predicted Acceptance'])\nconfusion_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# VISUALIZATION OF CONFUSION MATRIX\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_=sns.heatmap(confusion_df, cmap='coolwarm', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CONFUSION MATRIX EVALUATION METRIC\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, predictions))\nprint(\"Precision:\",metrics.precision_score(y_test, predictions))\nprint(\"Recall:\",metrics.recall_score(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CALCULATE F1 SCORE\n\nmetrics.f1_score(y_test,predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CALCULATE ROC CURVE\n\nfrom sklearn.metrics import roc_curve, roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs = logit.predict_proba(X_test)[::,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc = roc_auc_score(y_test_encoded, probs)\nprint(auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fpr, tpr, threshold = roc_curve(y_test_encoded, probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(11,9))\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CALCULATING THE OPTIMAL THRESHOLD PROBABILITY FROM ROC CURVE\n\n\noptimal_idx = np.argmax(tpr - fpr)\noptimal_threshold = threshold[optimal_idx]\nprint(\"Optimal Threshold: \",optimal_threshold)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# UPDATING THE MODEL BASED ON OPTIMAL THRESHOLD PROBABILITY"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_predictions = np.where(probs>optimal_threshold, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_confusion_mat = metrics.confusion_matrix(y_test_encoded, new_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_LR = pd.DataFrame(new_confusion_mat, index=['Refused Term Deposit','Accepted Term Deposit'], columns=['Predicted Refusal','Predicted Acceptance'])\nconfusion_LR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# UPDATED VISUALIZATION OF CONFUSION MATRIX\n\n\n_=sns.heatmap(confusion_LR, cmap='coolwarm', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CALCULATE THE UPDATED ACCURACY SCORE & LOG LOSS METRICS \n\nACS_LR =accuracy_score(y_test, new_predictions)\nprint(\"Accuracy Score for LR: \", ACS_LR)\n\n# CALCULATING UPDATED LOG LOSS\n\nLL_LR = metrics.log_loss(y_test, new_predictions)\nprint(\"Log Loss for LR: \", LL_LR)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*"},{"metadata":{},"cell_type":"markdown","source":"# GRIDSEARCHCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = [{\"max_depth\":[3,4,5,None], \"max_features\":[2,3,4,5,None]}]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs = GridSearchCV(estimator=DecisionTreeClassifier(random_state=101),\\\n                 param_grid = param_grid,\\\n                 cv=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs.cv_results_['params']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PRINT BEST HYPERPARAMETERS COMBINATION\n\ngs.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs.cv_results_['rank_test_score']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_predictions = gs.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CONFUSION MATRIX BASED ON GRIDSEARCHCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_mat_gs = confusion_matrix(y_test, gs_predictions)\nconfusion_GS = pd.DataFrame(confusion_mat_gs, index=['Refused Term Deposit','Accepted Term Deposit'], columns=['Predicted Refusal','Predicted Acceptance'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_GS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_=sns.heatmap(confusion_GS, cmap=\"winter\", annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ACS_GS=accuracy_score(y_test,gs_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"GRIDSEARCHCV ACCURACY SCORE :\",ACS_GS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    EXPLANATION OF THE ABOVE\n    \n    Using GRIDSEARCHCV, we will take the best hyperparameter values of \n    \n    max_depth    = 3\n    max_features = None\n    \n    Now we will build Decision Tree using above mentioned Hyperparamter values"},{"metadata":{},"cell_type":"markdown","source":"# ---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*"},{"metadata":{},"cell_type":"markdown","source":"# DECISION TREE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# SPLITTING THE DATASET INTO TRAIN-TEST\n\nfrom sklearn.model_selection import train_test_split\nX=df_1.drop(['depo_no'],axis=1)\ny=df_1['depo_no']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn.model_selection as model_selection\n\nX_train,X_test,y_train,y_test = model_selection.train_test_split(X,y,test_size=0.2,random_state=101)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# FEATURE SCALING\n\n"},{"metadata":{},"cell_type":"markdown","source":"    Feature Scaling: We know our dataset is not yet a scaled value. Therefore, it would be beneficial to scale our data  To do so, we will use Scikit-Learn’s StandardScaler class:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()  \nX_train = sc.fit_transform(X_train)  \nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decision_tree = DecisionTreeClassifier(max_depth=5, max_features=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decision_tree.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_predictions = decision_tree.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CHECKING TOP 5 PREDICTIONS & ACTUAL VALUES \n\ndt_predictions[:7]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test[:7]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# EVALUATING PREDICTION ACCURACY\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ACS_DT =accuracy_score(y_test, dt_predictions)\nprint(\"Decision Tree Accuracy Score : \", ACS_DT)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FINDING FEATURE IMPORTANCE\n\npd.Series(decision_tree.feature_importances_, index=X.columns).sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CONFUSION MATRIX BASED ON DECISION TREE"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decision_tree_confusion_mat = confusion_matrix(y_test, dt_predictions)\nconfusion_DT = pd.DataFrame(decision_tree_confusion_mat, index=['Refused Term Deposit','Accepted Term Deposit'], columns=['Predicted Refusal','Predicted Acceptance'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_DT","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_=sns.heatmap(confusion_DT, cmap=\"winter\", annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# VISUALIZE THE DECISION TREE OUTUT THROUGH GRAPHVIZ\n\nfrom sklearn.tree import export_graphviz\nimport graphviz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dot_data = export_graphviz(decision_tree, filled=True, rounded=True, feature_names=X.columns, out_file=None)\ngraphviz.Source(dot_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*"},{"metadata":{},"cell_type":"markdown","source":"# RANDOM FOREST CLASSIFIER"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model = RandomForestClassifier(n_estimators=500, n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_predictions = rf_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ACS_RF=accuracy_score(y_test, rf_predictions)\nprint(\"RANDOM FOREST ACCURACY SCORE : \",ACS_RF)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CONFUSION MATRIX BASED ON RANDOM FOREST"},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_mat_rf = confusion_matrix(y_test, rf_predictions)\nconfusion_RF = pd.DataFrame(confusion_mat_rf, index=['Refused Term Deposit','Accepted Term Deposit'], columns=['Predicted Refusal','Predicted Acceptance'])\nconfusion_RF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_=sns.heatmap(confusion_RF, cmap=\"winter\", annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_list_RF = []\nfor Class, score in zip(X.columns, rf_model.feature_importances_):\n    feature_list_RF.append((score, Class))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(feature_list_RF, reverse=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*"},{"metadata":{},"cell_type":"markdown","source":"# ADABOOST ENSEMBLING MODE"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import accuracy_score\nimport sklearn.metrics as metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = DecisionTreeClassifier(criterion='gini', max_depth=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ada_boost_model = AdaBoostClassifier(base_estimator=model, learning_rate=1.0, n_estimators=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boostmodel=ada_boost_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ada_boost_predictions=boostmodel.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ACS_ADB=accuracy_score(y_test,ada_boost_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"ADABOOST ACCURACY SCORE : \",ACS_ADB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_list_ADB = []\nfor Class, score in zip(X.columns, ada_boost_model.feature_importances_):\n    feature_list_ADB.append((score, Class))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(feature_list_ADB, reverse=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CONFUSION MATRIX BASED ON ADABOOST"},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_mat_ada_boost = confusion_matrix(y_test, ada_boost_predictions)\nconfusion_ADB = pd.DataFrame(confusion_mat_ada_boost, index=['Refused Term Deposit','Accepted Term Deposit'], columns=['Predicted Refusal','Predicted Acceptance'])\nconfusion_ADB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_=sns.heatmap(confusion_ADB, cmap=\"winter\", annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*"},{"metadata":{},"cell_type":"markdown","source":"# VOTING CLASSFIER"},{"metadata":{"trusted":true},"cell_type":"code","source":"# IMPORTING NECESSARY LIBRARIES\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"v_log_model = LogisticRegression()\nv_gs_model = GridSearchCV(estimator=DecisionTreeClassifier(random_state=101), param_grid = param_grid, cv=10)\nv_dtree_model = DecisionTreeClassifier()\nv_rf_model = RandomForestClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble = VotingClassifier(estimators=[('V_LR', v_log_model), ('V_GS',v_gs_model),('V_DT', v_dtree_model),('V_RF', v_rf_model)], voting='hard')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for model in (v_log_model, v_gs_model, v_dtree_model, v_rf_model, ensemble):\n    model.fit(X_train, y_train)\n    v_predictions = model.predict(X_test)\n    print(model.__class__.__name__, accuracy_score(y_test, v_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ACS_V=accuracy_score(y_test, v_predictions)\nprint(ACS_V)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CONFUSION MATRIX BASED ON VOTING CLASSIFIER"},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_mat_V= confusion_matrix(y_test, v_predictions)\nconfusion_V = pd.DataFrame(confusion_mat_V, index=['Refused Term Deposit','Accepted Term Deposit'], columns=['Predicted Refusal','Predicted Acceptance'])\nconfusion_V","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_=sns.heatmap(confusion_V, cmap=\"winter\", annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*"},{"metadata":{},"cell_type":"markdown","source":"# COMPARISON OF ML MODEL BASED CONFUSION MATRIX"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('LR',confusion_LR,\"\\n\")   # Logistic Regression\nprint('GS',confusion_GS,\"\\n\")   # GridSearchCV\nprint('DT',confusion_DT,\"\\n\")   # Decision Tree\nprint('RF',confusion_RF,\"\\n\")   # Random Forest\nprint('ADB',confusion_ADB,\"\\n\") # Ada Boost\nprint('VC',confusion_V,\"\\n\")    # Voting Classifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on Confusion Matrix we can conclude that the Random Forest model was the best model as it is having the least number of misclassified observations from test set.\n\nOnly 308 observation were misclassified.\n"},{"metadata":{},"cell_type":"markdown","source":"# COMPARISON OF ML MODEL BASED ACCURACY SCORE VALUES"},{"metadata":{"trusted":true},"cell_type":"code","source":"ACS_FINAL= pd.DataFrame(columns=['Model_Name', 'Accuracy_Score'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ACS_FINAL['Accuracy_Score']=[ACS_LR, ACS_GS, ACS_DT, ACS_RF, ACS_ADB, ACS_V]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ACS_FINAL['Model_Name']=['LogisticRegression', 'GridSearchCV', 'Decision_Tree', 'RandomForest', 'Ada Boost', \\\n                         'Voting CLassifier']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def highlight_max(s):\n    is_max = s == s.max()\n    return ['background-color: yellow' if v else '' for v in is_max]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ACS_FINAL[['Model_Name', 'Accuracy_Score']].sort_values('Accuracy_Score', ascending=False)\\\n.style.apply(highlight_max, subset=['Accuracy_Score'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on acs values we can conclude that the Random Forest model was the best model as it is having the best accuracy score value of 0.8620689655172413"},{"metadata":{},"cell_type":"markdown","source":"# ---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*"},{"metadata":{},"cell_type":"markdown","source":"# CONCLUSION 1: ML MODEL SELECTION"},{"metadata":{},"cell_type":"markdown","source":"We are selecting our final ML model based on the Accuracy_Score values. As seen above in our case the Random Forest model has the best Accuracy_Score value of 0.8629646215853113. Therefore, going forward to determine our Business Solution we will use Random Forest as our final ML model."},{"metadata":{},"cell_type":"markdown","source":"In order to make any actionable recommendations, we must look upon the feature importances based on our selected model i.e. Random Forest model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# RECALLING THE FEATURE IMPORTANCE LIST\n\nsorted(feature_list_RF, reverse=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PLOTTING FEATURES IMPORTANCES\n\nplt.figure(figsize=(21,5))\n\nFI_RF = pd.DataFrame(sorted(zip(X.columns, rf_model.feature_importances_), \\\n                            key=lambda x: x[1], reverse= True), columns = [\"Features\", \"Score\"])\n\nindex = np.arange(len(FI_RF))\nplt.bar(index, FI_RF['Score'], color = '#6a0dad')\nplt.xticks(index, FI_RF['Features'], rotation=90)\nplt.title('Feature Importances (Random Forest)')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see from the above shown barplot representing the feature importances. It is evident that the top 4 most important features are:\n\n    1) Duration  : Last contact duration in seconds made with the customer.\n    2) Balance   : Customer Balance Amount with the bank.\n    3) Age       : Age of the customer.\n    4) Day       : Last contacted day of the week \n    "},{"metadata":{},"cell_type":"markdown","source":"# CONCLUSION 2: BUSINESS SOLUTION"},{"metadata":{},"cell_type":"markdown","source":"Based on above mentioned features we can conclude the following:\n\n    1) The amount of time spent with the customer is important. Too much or too little could be a reason for refusal. \n    2) Customers with higher account balance are more acceptable to opt for a term deposit.\n    3) Older customers are more acceptable to opt for a term deposit.\n    4) The day of the week a customer is approached is also significant.\n    "},{"metadata":{},"cell_type":"markdown","source":"Now let's try to be more specific with our suggestions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# CREATING A COPY OF THE CLEANED DATA (DF_1)\n\ndf_2 = df_1.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Q1) The duration of time a customer should be contacted for?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# CREATING A NEW COLUMN (CONTACT_DURATION)\n\ndf_2['contact_duration'] = pd.qcut(df_2['duration'], q=10, labels=False, duplicates = 'drop')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#GROUPING THE 'CONTACT_DURATION' AND FINDING AVERAGE CONTACT DURATION\nmean_contact_duration = df_2.groupby(['contact_duration'])['depo_no'].mean()\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# PLOTTING THE MEAN % SUBSCRIPTION VS CONTACT DURATION\nplt.figure(figsize=(21,9))\nplt.plot(mean_contact_duration.index, mean_contact_duration.values)\nplt.title('Mean % subscription depending on Contact Duration')\nplt.xlabel('Contact Duration Bin')\nplt.ylabel('% subscription')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2[df_2['contact_duration'] == 4]['duration'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2[df_2['contact_duration'] == 6]['duration'].min()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A1) From the above graph we can say that the average duration of time (in seconds) a customer should be contacted for must lie between 255 to 324 seconds(4-6 mins). Hence the campaign should have a sales pitch which does not exceed these limits."},{"metadata":{},"cell_type":"markdown","source":"Q2) The account balance of a customer who should be contacted?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# CREATING A NEW COLUMN (CUST_BAL)\n\n\ndf_2['cust_bal'] = pd.qcut(df_2['balance'], q=50, labels=False, duplicates = 'drop')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#GROUPING THE 'CUST_BAL' AND FINDING AVERAGE CUSTOMER BALANCE\n\nmean_cust_bal = df_2.groupby(['cust_bal'])['depo_no'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PLOTTING THE MEAN % SUBSCRIPTION VS AVERAGE CUSTOMER BALANCE\nplt.figure(figsize=(21,9))\nplt.plot(mean_cust_bal.index, mean_cust_bal.values)\nplt.title('Mean % subscription depending on Average Customer Balance')\nplt.xlabel('Average Customer Balance Bin')\nplt.ylabel('% subscription')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2[df_2['cust_bal'] == 28]['balance'].max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A2) From the above graph we can say that the customers having account balance of $935 & above should be the primary focus of the marketing campaign. These customers are more likely to go for a term deposit."},{"metadata":{},"cell_type":"markdown","source":"Q3) The age range of a customer who should be contacted?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# CREATING A NEW COLUMN (CUST_AGE)\n\n\ndf_2['cust_age'] = pd.qcut(df_2['age'], q=10, labels=False, duplicates = 'drop')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#GROUPING THE 'CUST_BAL' AND FINDING AVERAGE CUSTOMER BALANCE\n\nmean_cust_age = df_2.groupby(['cust_age'])['depo_no'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PLOTTING THE MEAN % SUBSCRIPTION VS AVERAGE CUSTOMER BALANCE\nplt.figure(figsize=(21,9))\nplt.plot(mean_cust_age.index, mean_cust_age.values)\nplt.title('Mean % subscription depending on Average Customer Age')\nplt.xlabel('Average Customer Age Bin')\nplt.ylabel('% subscription')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2[df_2['cust_age'] == 1]['age'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2[df_2['cust_age'] == 8]['age'].min()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A3) From the above graph we can say that the average age of a customer to be approached for should be less than 31 or higher than 53. These customers are more likely to go for a term deposit. \n\nThe marketing campaign should avoid focusing on age groups between 31 & 53."},{"metadata":{},"cell_type":"markdown","source":"Q4) The day of the month a customer should be approached?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# CREATING A NEW COLUMN (APPROACH DAY)\n\n\ndf_2['app_day'] = pd.qcut(df_2['day'], q=4, labels=False, duplicates = 'drop')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#GROUPING THE 'CUST_BAL' AND FINDING AVERAGE CUSTOMER BALANCE\n\nmean_app_day = df_2.groupby(['app_day'])['depo_no'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PLOTTING THE MEAN % SUBSCRIPTION VS AVERAGE CUSTOMER BALANCE\nplt.figure(figsize=(21,9))\nplt.plot(mean_app_day.index, mean_app_day.values)\nplt.title('Mean % subscription depending on Approach Day of the Month')\nplt.xlabel('Approach Day of the Month Bin')\nplt.ylabel('% subscription')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2[df_2['app_day'] == 0]['day'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2[df_2['app_day'] == 3]['day'].min()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A4) From the above graph we can say that if the customer is approached, before the 8th of the month or after the 23rd of the month, the likelyhood for a term deposit are high.\n\nThe marketing campaign should avoid focusing between 9th & 22nd of the month.\n"},{"metadata":{},"cell_type":"markdown","source":"# ---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*---*"},{"metadata":{},"cell_type":"markdown","source":"#  FINAL SUMMARY"},{"metadata":{},"cell_type":"markdown","source":"Key outcomes of the analysis are the recommendations for future marketing campaigns:\n\n  \n    1) Sales pitch of the campaign should be 4mins to 6 mins long.\n    2) Customers having account balance north of $935 should be focus group.\n    3) Customers having age groups between 31 & 53 should'nt be the focus group.\n    4) Customers are more willing to invest either before 8th or after 23rd of the month."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}