{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport matplotlib\nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data= pd.read_csv('../input/bengaluru-house-price-data/Bengaluru_House_Data.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Shape of dataset\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('area_type')['area_type'].agg('count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2 = data.drop(['area_type','availability','society','balcony'],axis='columns')\ndata2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of rows where every particular column's value is null\ndata2.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop null value\ndata3 = data2.dropna()\ndata3.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Size column unique values \ndata3['size'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keep only numbers of bedrooms in size column\ndata3['bhk'] = data3['size'].apply(lambda x : int(x.split(' ')[0]))\ndata3['bhk'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total sqft values \ndata3['total_sqft'].unique() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# some total sqft values are range '1133-1384'\n# first find float values\ndef is_float(x):\n    try:\n        float(x)\n    except:\n        return False\n    return True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data3[~data3['total_sqft'].apply(is_float)]['total_sqft'].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_sqft_to_num(x):\n    tokens = x.split('-')\n    if len(tokens) == 2:\n        return (float(tokens[0])+float(tokens[1]))/2 \n    try:\n        return float(x)\n    except:\n        return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data4 = data3.copy()\ndata4['total_sqft'] = data4['total_sqft'].apply(convert_sqft_to_num)\ndata4['total_sqft'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data5 = data4.copy()\ndata5['price_per_sqft'] = data5['price']*100000/data5['total_sqft']\ndata5.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of Location\nlen(data5.location.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reduce dimension\n# remove spaces before and after the location\ndata5.location = data5.location.apply(lambda x: x.strip())\n# how many point exists for every location\nlocation_stats = data5.groupby('location')['location'].agg('count').sort_values(ascending=False)\nlocation_stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# locations with less than 10 datapoints\nlen(location_stats[location_stats<=10])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# there are 1052 location with less than 10 datapoints (1052 out of 1293)\nlocation_stats_less_than_10 = location_stats[location_stats<=10]\nlocation_stats_less_than_10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert location with less than 10 datapoints to 'other'\ndata5.location = data5.location.apply(lambda x: 'other' if x in location_stats_less_than_10 else x)\nlen(data5.location.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data5.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Outliers detection : we admit that area of a given room is >= 300sqft\ndata5[data5.total_sqft/data5.bhk <300].head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove houses with room's areas <300 sqft\ndata6 = data5[~(data5.total_sqft/data5.bhk <300)]\ndata6.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data6.price_per_sqft.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# min 267 max 176470 let's remove extreme values based on standard deviation\n# we  filter all datapoints that stand beyone 1 std\n# Since the price depends on the location we filter with std of price_per_sqft per location\ndef remove_pps_outliers(df):\n    df_out = pd.DataFrame()\n    for key, subdf in df.groupby('location'):\n        m = np.mean(subdf.price_per_sqft)\n        st = np.std(subdf.price_per_sqft)\n        reduced_df = subdf[(subdf.price_per_sqft>m-st)&(subdf.price_per_sqft<=m+st)]\n        df_out = pd.concat([df_out,reduced_df], ignore_index=True)\n    return df_out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data7 = remove_pps_outliers(data6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We notice that in some location house with 2 rooms are more expensive than ones with 3 rooms\ndef plot_scatter_chart(df, location):\n    bhk2 = df[(df.location == location) & (df.bhk==2)]\n    bhk3 = df[(df.location == location) & (df.bhk==3)]\n    matplotlib.rcParams['figure.figsize'] = (15,20)\n    plt.scatter(bhk2.total_sqft,bhk2.price, color= 'blue',label='2 BHK', s=50)\n    plt.scatter(bhk3.total_sqft, bhk3.price, color='green', label='3 BHK', s=50)\n    plt.xlabel('Total square feet area')\n    plt.ylabel('Price')\n    plt.title(location)\n    plt.legend()\n    \nplot_scatter_chart(data7, \"Rajaji Nagar\")\n# same with 'Hebbal' location","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for a given location we will build a dictionary of stats per bhk, \n# we then remove those 2 BHK apartement whose price per sqft is more than mean of price per sqft of 1 BHK apartement\ndef remove_bhk_outliers(df):\n    exclude_indices = np.array([])\n    for location, location_df in df.groupby('location'):\n        bhk_stats = {}\n        for bhk, bhk_df in location_df.groupby('bhk'):\n            bhk_stats[bhk] = {\n                'mean' : np.mean(bhk_df.price_per_sqft),\n                'std'  : np.std(bhk_df.price_per_sqft),\n                'count' : bhk_df.shape[0]\n            }\n        for bhk, bhk_df in location_df.groupby('bhk'):\n            stats = bhk_stats.get(bhk-1)\n            if stats and stats['count']>5:\n                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n                \n    return df.drop(exclude_indices, axis= \"index\")\n    \n    \ndata8 = remove_bhk_outliers(data7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_scatter_chart(data8, \"Rajaji Nagar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Historgram of price_per_sqft\nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)\nplt.hist(data8.price_per_sqft, rwidth=0.8)\nplt.xlabel = 'price_per_sqft'\nplt.ylabel = 'count'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the majority of the data belongs to the range [0, 10000]roupies_per_sqft <br>\nwe notice from the historgram a normal distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of bathrooms Outliers\ndata8.bath.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# datapoints with more than 10 bathrooms\ndata8[data8.bath>=10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# historgram of bathrooms\nplt.hist(data8.bath, rwidth=0.8)\nplt.xlabel = 'Number of bathrooms'\nplt.ylabel = 'count'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The majority of the apartement has only 2 bathrooms","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Outliers = apartements that have more bathrooms than bhk+2\ndata9 = data8[data8.bath<data8.bhk+2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data10 = data9.drop(['size', 'price_per_sqft'], axis='columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# turn location into dummies variable\ndummies = pd.get_dummies(data10.location)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data11 = pd.concat([data10.drop('location', axis ='columns'), dummies.drop('other', axis = 'columns')], axis = 'columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data11.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dependent variables\nX = data11.drop('price', axis ='columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Independent variable\ny = data11.price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split to train and test data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test , y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train linear regression model\nfrom sklearn.linear_model import LinearRegression\nlr_clf = LinearRegression()\nlr_clf.fit(X_train, y_train)\n\n# Model performance\nlr_clf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross validation\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_score\n\ncv = ShuffleSplit(n_splits= 5, test_size=0.2, random_state=0)\ncross_val_score(LinearRegression(), X, y, cv= cv) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run our model on different regressors : Lasso and Decision Tree\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.tree import DecisionTreeRegressor\n\ndef find_best_model_using_gridsearchcv(X,y):\n    algos = {\n        'linear_regression': {\n            'model' : LinearRegression(),\n            'params': {\n                'normalize':[True, False]\n            }\n        },\n        'lasso':{\n            'model': Lasso(),\n            'params':{\n                'alpha':[1,2],\n                'selection': ['random', 'cyclic']\n            }\n        },\n        'decision_tree':{\n            'model': DecisionTreeRegressor(),\n            'params':{\n                'criterion': ['mse','friedman_mse'],\n                'splitter' : ['best', 'random']\n            }\n        }\n    }\n    scores = []\n    cv = ShuffleSplit(n_splits= 5, test_size=0.2, random_state=0)\n    for algo_name, config in algos.items():\n        #print(config['params'])\n        gs = GridSearchCV(config['model'], config['params'],cv=cv, return_train_score = False)\n        gs.fit(X,y)\n        scores.append({\n            'model': algo_name,\n            'best_score': gs.best_score_,\n            'best_params': gs.best_params_,\n        })\n    return pd.DataFrame(scores, columns= ['model', 'best_score', 'best_params'])\n    \nfind_best_model_using_gridsearchcv(X,y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Linear regression model gives as the best score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_price(location, sqft, bath, bhk):\n    loc_index = np.where(X.columns == location)[0][0]\n    \n    x = np.zeros(len(X.columns))\n    x[0] = sqft\n    x[1] = bath\n    x[2] = bhk\n    if loc_index >= 0 :\n        x[loc_index] = 1\n      \n    return lr_clf.predict([x])[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_price('1st Phase JP Nagar',1000,2,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}