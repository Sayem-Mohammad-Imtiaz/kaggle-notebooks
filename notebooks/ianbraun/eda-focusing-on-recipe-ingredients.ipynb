{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction\nThis notebook is an exploration of the Food.com dataset that focuses primarily on looking at variables that are specific to particular ingredients, such as the frequency with which they are included in recipes in the dataset, and their usage in submitted recipes over time. This notebook also creates a model for predicting probabilities that a given recipe includes a particular ingredient, given the name chosen for that recipe.\n\n   \n## Table of Contents\n- [Reading in and merging the data](#1)\n- [Looking at data related to ingredients](#2)\n    - [Ingredient frequency](#2.1)\n    - [Ingredient-specific review scores](#2.2)\n    - [Ingredient usage over time](#2.3)\n- [Naive Bayes Model](#3)\n    - [Getting recipe name tokens](#3.1)\n    - [Estimating probabilities](#3.2)\n    - [Trying out the model](#3.3)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from collections import defaultdict\nfrom plotnine import *\nimport plotnine\nimport numpy as np\nimport pandas as pd\nimport ast\nimport os\nimport math\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading in and merging the data <a name=\"1\"></a>\nRead in the files from the dataset that we want to look at."},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_recipes = pd.read_csv(\"/kaggle/input/food-com-recipes-and-user-interactions/RAW_recipes.csv\")\nraw_interactions = pd.read_csv(\"/kaggle/input/food-com-recipes-and-user-interactions/RAW_interactions.csv\")\npp_recipes = pd.read_csv(\"/kaggle/input/food-com-recipes-and-user-interactions/PP_recipes.csv\")\npp_users = pd.read_csv(\"/kaggle/input/food-com-recipes-and-user-interactions/PP_users.csv\")\ningr_map = pd.read_pickle(\"/kaggle/input/food-com-recipes-and-user-interactions/ingr_map.pkl\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's create a merged version of the recipes data (where rows refer to a unique recipe) that has both the raw and preprocessed data, and just the columns we care about. Let's also rename the ID column to specifically state that it is referring to a recipe ID, which will be useful when merging data between dataframes."},{"metadata":{"trusted":true},"cell_type":"code","source":"recipes = pp_recipes.merge(right=raw_recipes, left_on=\"id\", right_on=\"id\")\nrecipes = recipes[[\"id\", \"name\", \"submitted\", \"ingredient_ids\", \"ingredients\", \"n_ingredients\"]]\nrecipes = recipes.rename({\"id\":\"recipe_id\"}, axis=\"columns\")\nrecipes.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That look's good, let's move on the interactions data."},{"metadata":{"trusted":true},"cell_type":"code","source":"interactions = raw_interactions[[\"user_id\", \"recipe_id\", \"rating\", \"review\"]]\ninteractions.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That looks good too, let's move on to the ingredients. For the ingredients dataframe, let's again rename the columns to make a clear distinction between ID types before merging any data. The original file has raw strings from which the ingredients were parsed out and preprocessed. Let's just look at the preprocessed strings and get rid of duplicate rows, so that a single row in this dataframe now refers to a unique ingredient in the dataset. That way we can add on to this dataframe with new variables that have values specific to a particular ingredient, like its frequency in the dataset, or the average review score for recipes that include it."},{"metadata":{"trusted":true},"cell_type":"code","source":"ingr_df = ingr_map.copy(deep=True)\ningr_df = ingr_df.rename({\"id\":\"ingr_id\",\"replaced\":\"ingr_name\"}, axis=\"columns\")\ningr_df = ingr_df[[\"ingr_id\", \"ingr_name\"]]\ningr_df = ingr_df.drop_duplicates(ignore_index=True)\ningr_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Looking at data related to ingredients <a name=\"2\"></a>\n### Looking at the frequency of specific ingredients <a name=\"2.1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"In order to define other variables with respect to particular ingredients, let's create a version of the recipes dataframe that is exploded with respect to the column that has the list of ingredient IDs. This will form a dataframe where each row refers to a specific ingredient present in a specific recipe. Note that in order to do this, we need to convert the contents of the ingredient IDs field to be actual lists rather than strings representing lists. "},{"metadata":{"trusted":true},"cell_type":"code","source":"recipes_exploded = recipes.copy(deep=True)\nrecipes_exploded[\"ingredient_ids\"] = recipes_exploded['ingredient_ids'].apply(lambda x : ast.literal_eval(x))\nrecipes_exploded = recipes_exploded.explode(column=\"ingredient_ids\", ignore_index=True)\nrecipes_exploded.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Because ingredient IDs are now in their own column, we can now group by ingredient and check the quantity of recipes that each belongs to, and add this to the ingredients dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"ingr_df[\"num_recipes\"] = ingr_df[\"ingr_id\"].map(dict(recipes_exploded.groupby(\"ingredient_ids\")[\"recipe_id\"].size()))\ningr_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's get the total number of recipes in the dataset so that these counts can be represented as frequencies."},{"metadata":{"trusted":true},"cell_type":"code","source":"total_number_of_recipes = recipes[\"recipe_id\"].unique().size\ningr_df[\"frequency\"] = ingr_df[\"num_recipes\"]/total_number_of_recipes\ningr_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some of the ingredients in this dataframe are not actually used in any of the recipes that are included in the dataset, so let's get rid of those."},{"metadata":{"trusted":true},"cell_type":"code","source":"ingr_df = ingr_df.dropna()\ningr_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Getting scores specific to individual ingredients <a name=\"2.2\"></a>"},{"metadata":{},"cell_type":"markdown","source":"We also might want to know if there is a relationship between particular ingredients and review scores. Scores are attributed to recipes not ingredients, so we need to merge the ingredient lists from the recipes dataframe with the interactions dataframe, so that we can then explode that dataframe with respect to the ingredients list."},{"metadata":{"trusted":true},"cell_type":"code","source":"interactions_exploded = interactions.copy(deep=True)\ninteractions_exploded = interactions_exploded.merge(how=\"left\", right=recipes[[\"recipe_id\",\"ingredient_ids\"]], left_on=\"recipe_id\", right_on=\"recipe_id\")\ninteractions_exploded = interactions_exploded.dropna()\ninteractions_exploded[\"ingredient_ids\"] = interactions_exploded['ingredient_ids'].apply(lambda x : ast.literal_eval(x))\ninteractions_exploded = interactions_exploded.explode(column=\"ingredient_ids\", ignore_index=True)\ninteractions_exploded.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can use those relationships to add mean rating for each recipe that includes a given ingredient and the total number of reviews that were created for all recipes including a given ingredient to the ingredients dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"ingr_df[\"mean_rating\"] = ingr_df[\"ingr_id\"].map(dict(interactions_exploded.groupby(\"ingredient_ids\")[\"rating\"].mean()))\ningr_df[\"num_ratings\"] = ingr_df[\"ingr_id\"].map(dict(interactions_exploded.groupby(\"ingredient_ids\")[\"rating\"].size()))\ningr_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotnine.options.dpi = 100\nplotnine.options.figure_size=(6,4)\n(ggplot(ingr_df)\n + geom_point(aes(x=\"frequency\", y=\"mean_rating\"), color=\"black\", show_legend=False)\n + theme_bw()\n + ylab(\"Mean Rating\")\n + xlab(\"Frequency\")\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For ingredients that are used more frequently, the mean rating for all recipes that they are in tends to be closer and closer to the mean for all recipe ratings in the dataset, as expected. The inclusion of less frequently does not necessarily seem to impact the average review score for recipes that include it. As another way to visualize this, let's consider that 'rare' ingredients are ones mentioned 5 or fewer times in the dataset, then bin recipes based on how many 'rare' ingredients they include, then look at the average score distributions for all recipes in each bin."},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 5\nrare_ingredients = ingr_df.loc[ingr_df[\"num_recipes\"] <= threshold, \"ingr_id\"].values\nrecipes_exploded[\"rare_ingr\"] = recipes_exploded[\"ingredient_ids\"].map(lambda x: x in rare_ingredients)\nrecipes_exploded.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recipes[\"num_rare_ingr\"] = recipes[\"recipe_id\"].map(dict(recipes_exploded.groupby(\"recipe_id\")[\"rare_ingr\"].sum()))\nrecipes.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recipes[\"mean_rating\"] = recipes[\"recipe_id\"].map(dict(interactions.groupby(\"recipe_id\")[\"rating\"].mean()))\n\nplotnine.options.dpi = 100\nplotnine.options.figure_size=(6,4)\n(ggplot(recipes)\n + geom_boxplot(aes(x=\"num_rare_ingr\", y=\"mean_rating\", group=\"num_rare_ingr\"), show_legend=False)\n + theme_bw()\n + ylab(\"Mean Rating\")\n + xlab(\"Number of Rare Ingredients\")\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We should also look at the number of recipes in each category (in each boxplot)."},{"metadata":{"trusted":true},"cell_type":"code","source":"recipes.groupby(\"num_rare_ingr\").size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Looking at ingredient inclusion over time <a name=\"2.3\"></a>\nAnother aspect of this dataset at the ingredient level is how the inclusion of specific ingredients in submitted recipes changes over time. These trends might have something to do with changing popularity of specific foods or recipes, or prices or availability of particular ingredients. Drawing conclusions would require in depth knowledge of the submitted recipes were sampled from all recipes submitted during these periods, and when the recipes are accessed is also relevant rather than just when the recipes were submitted, but this section provides a simple example of getting started with this type of analysis.\n\nLet's get started by making a histogram of recipes based no the year they were submitted."},{"metadata":{"trusted":true},"cell_type":"code","source":"recipes[\"submitted\"]\nrecipes[\"year\"] = recipes[\"submitted\"].map(lambda x: x.split(\"-\")[0])\nrecipes = recipes.sort_values(by=\"year\")\n\nplotnine.options.dpi = 100\nplotnine.options.figure_size=(6,4)\n(ggplot(recipes)\n + geom_histogram(aes(x=\"year\"), color=\"darkgray\", show_legend=False)\n + theme_bw()\n + ylab(\"Count\")\n + xlab(\"Year\")\n + theme(axis_text_x=element_text(rotation=65, hjust=1))\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most well-represented portion of the data is from 2002 to 2009, so lets limit the dataset to those years when looking at trends in ingredient usage."},{"metadata":{"trusted":true},"cell_type":"code","source":"recipes_subset = recipes_exploded.copy(deep=True)\nrecipes_subset[\"year\"] = recipes_subset[\"submitted\"].map(lambda x: x.split(\"-\")[0]).astype(int)\nrecipes_subset[\"year\"] = recipes_subset[\"year\"].astype(int)\nrecipes_subset = recipes_subset[(recipes_subset[\"year\"]>=2002) & (recipes_subset[\"year\"]<=2009)]\nrecipes_subset.reset_index(inplace=True)\nrecipes_subset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We're using the version of the recipes dataframe here that has been exploded with respect to the list of ingredients in each recipe. This way, we can now group by individual years and find the number of recipes that use each individual ingredient."},{"metadata":{"trusted":true},"cell_type":"code","source":"by_year_df = pd.DataFrame(recipes_subset.groupby(\"year\")[\"ingredient_ids\"].value_counts())\nby_year_df.columns = [\"num_recipes\"]\nby_year_df.reset_index(inplace=True)\nyear_to_num_recipes = dict(recipes_subset.groupby(\"year\").size())\nby_year_df[\"fraction_using\"] =  by_year_df[[\"year\",\"num_recipes\"]].apply(lambda row: row[\"num_recipes\"]/year_to_num_recipes[row[\"year\"]], axis=1)\nby_year_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have a dataframe with the number of recipes that use each ingredient in a given year, as well as the fraction of recipes submitted during that year that use this ingredient. Let's merge this with our existing ingredients dataframe so so that we have access to the other columns like ingredient names."},{"metadata":{"trusted":true},"cell_type":"code","source":"by_year_df = by_year_df.merge(right=ingr_df[[\"ingr_name\",\"ingr_id\"]], how=\"left\", left_on=\"ingredient_ids\", right_on=\"ingr_id\")\nby_year_df = by_year_df[[\"ingr_name\", \"ingr_id\", \"year\", \"num_recipes\", \"fraction_using\"]]\nby_year_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can start looking at trends for individual ingredients within this period. As an example, let's look at trends for different types of cooking oils. We can start by subsetting the ingredients dataframe for ingredients that contain the word 'oil' and then sorting by frequency to find some cooking oils that are well-represented in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"cooking_oils_df = ingr_df.iloc[list(ingr_df[\"ingr_name\"].apply(lambda x: (\"oil\" in x.split())))].sort_values(by=\"frequency\", ascending=False, ignore_index=True).head(10)\ncooking_oils_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cooking_oil_names = list(cooking_oils_df[\"ingr_name\"].values)\ncooking_oil_names_of_interest = cooking_oil_names[:]\ncooking_oil_names_of_interest.remove(\"oil\")\ncooking_oil_names_of_interest.remove(\"cooking oil\")\nprint(cooking_oil_names_of_interest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_data = by_year_df[by_year_df[\"ingr_name\"].isin(cooking_oil_names_of_interest)]\n\nplotnine.options.dpi = 100\nplotnine.options.figure_size=(8,4)\n(ggplot(plot_data)\n + geom_point(aes(x=\"year\", y=\"fraction_using\"), color=\"darkgray\", show_legend=False)\n + facet_wrap(\"ingr_name\", ncol=4, scales=\"fixed\")\n + theme_bw()\n + theme(subplots_adjust={'wspace': 0.1})\n + ylab(\"Fraction Using\")\n + xlab(\"Year\")\n + theme(axis_text_x=element_text(rotation=45, hjust=1))\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like the fraction of recipes that use many of these types of oils are relatively consisent across this time period, with the exception of olive oil, which looks to be increasing during this time. Could this be because more recipes are using olive oil that were previously using other kinds of oil? Another way to get a clearer look at this question would be to plot the fractions of recipes using any kind of ingredient containing the word oil that use each type, so we can see how the proportions are changing over time."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Subset the dataset again to include oils, this time including all of them but replacing them with 'other' if they aren't in our list of commonly used ones.\nby_year_df_subsets = by_year_df.iloc[list(by_year_df[\"ingr_name\"].apply(lambda x: (\"oil\" in x.split())))]\nby_year_df_subsets[\"ingr_name\"] = by_year_df_subsets[\"ingr_name\"].map(lambda x: {name:name for name in cooking_oil_names}.get(x, \"other\"))\ncooking_oil_names.append(\"other\")\nby_year_df_subsets.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is necessary to make sure the order of the sections in a given bar is the way we want it and consistent with the legend.\ncategory_order = cooking_oil_names\nby_year_df_subsets['ingr_name'] = pd.Categorical(by_year_df_subsets['ingr_name'], categories=category_order, ordered=True)\n\n# Get a color palette and create a mapping between each ingredient that needs to be in the plot and a color palette.\nfrom palettable.mycarta import Cube1_11\npal = Cube1_11.hex_colors\ncolor_mapping = dict(zip(cooking_oil_names, pal[:len(cooking_oil_names)]))\n\n# Make the plot.\n(ggplot(data=by_year_df_subsets)\n    + aes(y='fraction_using', x='year', fill=\"ingr_name\")\n    + scale_x_continuous(breaks=np.arange(2002,2010))\n    + theme_bw()\n    + geom_bar(position=\"fill\", stat=\"identity\")\n    + ylab(\"Proportion\")\n    + xlab(\"Year\")\n    + scale_fill_manual(name=\"Cooking Oil\", values=color_mapping, limits=cooking_oil_names)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ingredient Prediction with a Naive Bayes Model <a name=\"3\"></a>\n\nThe names of recipes in the dataset, although messy, have relationships with the ingredients that are likely to be in the recipe. These relationships might be explicitly indicated by the name, such as 'apple pie' containing apples, or less directly, such as 'apple pie' containing flour. We can use a Naive Bayes model to predict the probabilty that a recipe includes a given ingredient given the words that are present in the recipe's name.\n\n### Tokenizing the recipe names <a name=\"3.1\"></a>"},{"metadata":{},"cell_type":"markdown","source":"Let's look at the names that were provided for the recipes."},{"metadata":{"trusted":true},"cell_type":"code","source":"recipes_exploded_wrt_name_tokens = recipes.copy(deep=True)\nrecipes_exploded_wrt_name_tokens[\"name_tokens\"] = recipes_exploded_wrt_name_tokens[\"name\"].map(lambda x: x.split())\nrecipes_exploded_wrt_name_tokens = recipes_exploded_wrt_name_tokens.explode(column=\"name_tokens\", ignore_index=True)\nrecipes_exploded_wrt_name_tokens = recipes_exploded_wrt_name_tokens[[\"recipe_id\", \"name_tokens\", \"ingredient_ids\"]]\nrecipes_exploded_wrt_name_tokens.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Each row now refers to a specific name token in a specific recipe, with its list of ingredients. Let's explode with respect to the ingredient IDs again."},{"metadata":{"trusted":true},"cell_type":"code","source":"recipes_exploded_wrt_name_tokens[\"ingredient_ids\"] = recipes_exploded_wrt_name_tokens['ingredient_ids'].apply(lambda x : ast.literal_eval(x))\nrecipes_exploded_wrt_name_tokens = recipes_exploded_wrt_name_tokens.explode(column=\"ingredient_ids\", ignore_index=True)\nrecipes_exploded_wrt_name_tokens.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Estimating the probabilities <a name=\"3.2\"></a>\nNow that we have this dataframe, we can easily extract the counts of ingredient tokens being in recipes with specific name tokens."},{"metadata":{"trusted":true},"cell_type":"code","source":"ingredient_id_to_prob = dict(zip(ingr_df[\"ingr_id\"].values, ingr_df[\"frequency\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"name_token_and_ingredient_id_to_counts = dict(recipes_exploded_wrt_name_tokens.groupby(\"name_tokens\")[\"ingredient_ids\"].value_counts())\nname_token_to_count = dict(recipes_exploded_wrt_name_tokens.groupby(\"name_tokens\").size())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"name_token_and_ingredient_id_to_prob = lambda name_token,ingr_id: (name_token_and_ingredient_id_to_counts.get((name_token,ingr_id), 0)+1)/name_token_to_count[name_token]\nname_token_and_ingredient_id_to_prob(\"beef\", 1685)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's create another labmda that lets us pass in an ingrediet ID and list of name tokens and get back to probability for that ingredient given those name tokens."},{"metadata":{"trusted":true},"cell_type":"code","source":"ingr_prob = lambda ingr_id,name_tokens: math.log(ingredient_id_to_prob[ingr_id]) + np.sum([math.log(name_token_and_ingredient_id_to_prob(name_token,ingr_id)) for name_token in name_tokens])\ningr_prob(2200, [\"beef\", \"chicken\", \"soy\", \"rice\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's create another lambda that lets us pass in a list of tokens and get back a mapping between ingredient IDs and scores obtained using the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"ingr_probs = lambda name_tokens: {ingr_id:ingr_prob(ingr_id,name_tokens) for ingr_id in ingr_df[\"ingr_id\"].values}\n#ingr_probs([\"beef\", \"chicken\", \"soy\", \"rice\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Trying out the model <a name=\"3.3\"></a>\nLet's compose some potential recipe names out of individual tokens, and pass them to the model to see what the most likely ingredients for that name are."},{"metadata":{"trusted":true},"cell_type":"code","source":"recipe_name_tokens = [\"stir\", \"fry\"]\nresults = pd.DataFrame(zip(*ingr_probs(recipe_name_tokens).items())).transpose()\nresults.columns = [\"ingr_id\", \"score\"]\nresults = ingr_df.merge(results, on=\"ingr_id\")\nresults = results.sort_values(by=\"score\", ascending=False, ignore_index=True)\nresults.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recipe_name_tokens = [\"beef\", \"burrito\"]\nresults = pd.DataFrame(zip(*ingr_probs(recipe_name_tokens).items())).transpose()\nresults.columns = [\"ingr_id\", \"score\"]\nresults = ingr_df.merge(results, on=\"ingr_id\")\nresults = results.sort_values(by=\"score\", ascending=False, ignore_index=True)\nresults.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recipe_name_tokens = [\"apple\", \"pie\"]\nresults = pd.DataFrame(zip(*ingr_probs(recipe_name_tokens).items())).transpose()\nresults.columns = [\"ingr_id\", \"score\"]\nresults = ingr_df.merge(results, on=\"ingr_id\")\nresults = results.sort_values(by=\"score\", ascending=False, ignore_index=True)\nresults.head(20)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}