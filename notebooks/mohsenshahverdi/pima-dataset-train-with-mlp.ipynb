{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport theano\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom theano import tensor\nfrom sklearn.model_selection import train_test_split\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nseed = 7\n# fix random seed for reproducibility\nnp.random.seed(seed)\n# load pima indians dataset\ndataset = pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")\n# split into input (X) and output (Y) variables\nX = dataset.iloc[:,0:8].values\nY = dataset.iloc[:,8].values\n\n# split into 67% for train and 33% for test\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=seed)\n\n# create model\nmodel = Sequential()\nmodel.add(Dense(32, input_dim=8, activation='relu'))\nmodel.add(Dense(24, activation='relu'))\nmodel.add(Dense(12, activation='relu'))\nmodel.add(Dense(6,  activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Fit the model\nhistory = model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=400, batch_size=40)\n\n# evaluate the model\nscores = model.evaluate(X, Y)\nprint(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}