{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Dataset for worldwide distribution of COVID-19 cases\n\nThis notebook downloads the dataset for worldwide geographic distribution of COVID-19 cases from European Centre for Disease Prevention and Control Agency, and converts it into a Pandas dataframe.\n\nI considered makign a dataset of this, but since the data is updated daily, it seems rather pointless. Instead, this notebook illustrates how to download the current version of the dataset during execution, convert it into a Pandas dataframe, and perform some analysis of it.\n\nThe dataset could further be combined with other country or COVID-19 related data. Here I combine it with a dataset about countries and continents to map the data across continents.\n\nThe dataset is described here:\nhttps://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get the Dataset"},{"metadata":{},"cell_type":"markdown","source":"## Download the file"},{"metadata":{"trusted":true},"cell_type":"code","source":"import requests\n\nURL = \"https://opendata.ecdc.europa.eu/covid19/casedistribution/csv\"\nr = requests.get(url = URL) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read the data into dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"from io import StringIO\n\ncsv_io = StringIO(r.text)\ndf = pd.read_csv(csv_io)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above download and dataframe convert would be what you really need to use the dataset, but let's see what it looks like."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert date string column to Pandas datetime for processing."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"dateRep\"] = pd.to_datetime(df['dateRep'], format='%d/%m/%Y')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Look at Data"},{"metadata":{},"cell_type":"markdown","source":"What countries does it have?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"countriesAndTerritories\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Take 3 Nordic Countries and Compare"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_norway = df[df[\"countriesAndTerritories\"] == \"Norway\"].sort_values(by=\"dateRep\")[[\"dateRep\", \"cases\", \"deaths\"]]\ndf_sweden = df[df[\"countriesAndTerritories\"] == \"Sweden\"].sort_values(by=\"dateRep\")[[\"dateRep\", \"cases\", \"deaths\"]]\ndf_finland = df[df[\"countriesAndTerritories\"] == \"Finland\"].sort_values(by=\"dateRep\")[[\"dateRep\", \"cases\", \"deaths\"]]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_norway.set_index('dateRep', inplace=True)\ndf_sweden.set_index('dateRep', inplace=True)\ndf_finland.set_index('dateRep', inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Function to plot cases and cumulative cases side-by-side:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.dates as mdates\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef dual_plot(col_name, df, type_name):\n    plt.rcParams.update({'font.size': 22})\n    plt.figure(figsize=(20,12))\n\n    ax = plt.subplot(2, 2, 1)\n    plt.xticks(rotation=45) #have to set rotate here before labels created\n    locator = mdates.DayLocator(interval=15)\n    ax.xaxis.set_major_locator(locator)\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m'))\n    plt.plot(df.index, df[col_name], 'c-')\n    plt.title(f'{type_name}s per Day')\n    plt.ylabel(f'{type_name}s')\n    plt.xlabel('Date')\n\n    ax = plt.subplot(2, 2, 2)\n    plt.xticks(rotation=45) #have to set rotate here before labels created\n    locator = mdates.DayLocator(interval=15)\n    ax.xaxis.set_major_locator(locator)\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m'))\n    plt.plot(df.index, df[col_name].cumsum(), 'r-')\n    plt.xlabel('Date')\n    plt.ylabel(f'{type_name}s')\n    plt.title(f'{type_name}s, cumulative')\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dual_plot(\"cases\", df_norway, \"Case\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dual_plot(\"cases\", df_sweden, \"Case\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dual_plot(\"cases\", df_finland, \"Case\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Combine with Another Kaggle Dataset (Continents)"},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/input/country-to-continent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_countries = pd.read_csv(\"/kaggle/input/country-to-continent/countryContinent.csv\", encoding=\"iso-8859-1\")\ndf_countries.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you compare the two datasets, you see the continent dataset is missing Kosovo, which is in the EU daily dataset. So just add it:"},{"metadata":{"trusted":true},"cell_type":"code","source":"set(df[\"countryterritoryCode\"]) - set(df_countries[\"code_3\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_countries.append({\"country\": \"Kosovo\", \"code_2\": \"XK\", \"code_3\": \"XKX\", \"continent\": \"Europe\", \"sub_region\": \"Southern Europe\", \"region_code\": 150, \"sub_region_code\": 39}, ignore_index=True)\npass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[\"countryterritoryCode\"] == \"XKX\"].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Merge the daily dataset now with the continent dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_m = pd.merge(df, df_countries, left_on='countryterritoryCode', right_on='code_3')\ndf_m.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Cumulative Counts per Continent"},{"metadata":{},"cell_type":"markdown","source":"Here I create cumulative counts for different continents. Someone can probably write some fancy groupby one-liners, I decided to do it the simple way.."},{"metadata":{"trusted":true},"cell_type":"code","source":"continents = df_m[\"continent\"].unique()\ncontinents","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_sorted_cumulative = pd.DataFrame()\n#for country in countries:\n#    df_country = df_m[df_m[\"country\"] == country].sort_values(by=\"dateRep\")[[\"country\", \"continent\", \"sub_region\", \"dateRep\", \"cases\", \"deaths\"]]\n#    df_country[\"cum_cases\"] = df_country[\"cases\"].cumsum()\n#    df_country[\"cum_deaths\"] = df_country[\"deaths\"].cumsum()\n#    df_sorted_cumulative = pd.concat([df_sorted_cumulative, df_country], axis=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_sorted_cumulative.head(100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First create cumulative counts per country, sorted so each continent has its countries in single sequence. To make it easier to merge continent-level cumulative stats back if later desired.."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sorted_cumulative = pd.DataFrame()\nfor continent in continents:\n    continent_countries = df_m[df_m[\"continent\"] == continent][\"country\"].unique()\n    for country in continent_countries:\n        df_country = df_m[df_m[\"country\"] == country].sort_values(by=\"dateRep\")[[\"country\", \"continent\", \"sub_region\", \"dateRep\", \"cases\", \"deaths\"]]\n        df_country[\"cum_cases\"] = df_country[\"cases\"].cumsum()\n        df_country[\"cum_deaths\"] = df_country[\"deaths\"].cumsum()\n        df_sorted_cumulative = pd.concat([df_sorted_cumulative, df_country], axis=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sorted_cumulative.head(100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Global Statistics"},{"metadata":{},"cell_type":"markdown","source":"Use the above per country data per day to calculate statistics worldwide:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_total_cumulative = df_sorted_cumulative.groupby(\"dateRep\").sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_total_cumulative.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you compare the above final row to the [daily WHO statistics](https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports), it should be about the same."},{"metadata":{},"cell_type":"markdown","source":"## Create Dataframes for Continents"},{"metadata":{},"cell_type":"markdown","source":"Now calculate cumulative sums per continent from the country datas:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sorted_cumulative_continent = pd.DataFrame()\nfor continent in continents:\n    df_continent = df_sorted_cumulative[df_sorted_cumulative[\"continent\"] == continent]\n    df_continent = df_continent.sort_values(by=\"dateRep\")\n    df_continent[\"cum_cases\"] = df_continent[\"cases\"].cumsum()\n    df_continent[\"cum_deaths\"] = df_continent[\"deaths\"].cumsum()\n    df_sorted_cumulative_continent = pd.concat([df_sorted_cumulative_continent, df_continent], axis=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sorted_cumulative_continent.tail(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So just need to take the last item per day from the above dataframe to get the cumulative per continent."},{"metadata":{},"cell_type":"markdown","source":"For example, what does Asia look like?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sorted_cumulative_continent[df_sorted_cumulative_continent[\"continent\"] == \"Asia\"].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"continents","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are only 5 continents listed, so I just take each separately:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_asia = df_sorted_cumulative_continent[df_sorted_cumulative_continent[\"continent\"] == \"Asia\"].groupby(\"dateRep\").max()\ndf_africa = df_sorted_cumulative_continent[df_sorted_cumulative_continent[\"continent\"] == \"Africa\"].groupby(\"dateRep\").max()\ndf_europe = df_sorted_cumulative_continent[df_sorted_cumulative_continent[\"continent\"] == \"Europe\"].groupby(\"dateRep\").max()\ndf_americas = df_sorted_cumulative_continent[df_sorted_cumulative_continent[\"continent\"] == \"Americas\"].groupby(\"dateRep\").max()\ndf_oceania = df_sorted_cumulative_continent[df_sorted_cumulative_continent[\"continent\"] == \"Oceania\"].groupby(\"dateRep\").max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You could further split these according to the sub-area in the continents dataset, let's see about that later.."},{"metadata":{},"cell_type":"markdown","source":"# Cases and Deaths by Continent / Globally"},{"metadata":{},"cell_type":"markdown","source":"## Global"},{"metadata":{"trusted":true},"cell_type":"code","source":"dual_plot(\"cases\", df_total_cumulative, \"Case\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dual_plot(\"deaths\", df_total_cumulative, \"Death\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Europe"},{"metadata":{"trusted":true},"cell_type":"code","source":"dual_plot(\"cases\", df_europe, \"Case\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dual_plot(\"deaths\", df_europe, \"Death\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Americas"},{"metadata":{},"cell_type":"markdown","source":"This would be quite useful to split to North- and South-America at least but lets see.."},{"metadata":{"trusted":true},"cell_type":"code","source":"dual_plot(\"cases\", df_americas, \"Case\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dual_plot(\"deaths\", df_americas, \"Death\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Africa"},{"metadata":{"trusted":true},"cell_type":"code","source":"dual_plot(\"cases\", df_africa, \"Case\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dual_plot(\"deaths\", df_africa, \"Death\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Oceania"},{"metadata":{"trusted":true},"cell_type":"code","source":"dual_plot(\"cases\", df_oceania, \"Case\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dual_plot(\"deaths\", df_oceania, \"Death\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Possibly deeper splits\ndf_countries[\"sub_region\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To be continued.. but you get the idea on using such dataset already.. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}