{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Comparing fake and real news classifiers","metadata":{"id":"GIvHiS3POSCV"}},{"cell_type":"markdown","source":"This Notebook explores if and to what extent a Neural Network could perform better than a Logistic Regression classifier. It is build upon the \"Fake and real news dataset\" available in Kaggle [here](https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset).\n\nThe dataset consists of 2 files - one holding real news, and the other - fake ones. The general purpose of the classifier is to determine if an article is fake news or not. The work below compares success metrics achived with a Logistic Regression Classifier and with a Neural Network. The former follows the steps and reproduces the results of \"News_Classifier_98%\", published at this [link](https://www.kaggle.com/shawnbalu/news-classifier-98). \n\nAll main stages are organised in separate chapters.","metadata":{}},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"# Import main libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nimport csv\nimport io\nimport re\nfrom IPython.display import Image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import text processing libraries \nimport nltk\nfrom nltk.corpus import stopwords\nimport string\nfrom string import punctuation","metadata":{"id":"7Hz4RfATKSxd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# download \"stopwords\"\nnltk.download('stopwords')","metadata":{"id":"Rs8xTLefpv3J","outputId":"2acf2706-7e79-47e7-b3f4-0342ce74f922","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import scikit learn modules\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix","metadata":{"id":"0HrWrkNyxaC_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import TensorFlow modules\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, Dense, Bidirectional, LSTM\n\nfrom tensorflow.keras import backend as K","metadata":{"id":"M2NhXoKGlON4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Load datasets and insert \"label\" column","metadata":{}},{"cell_type":"markdown","source":"True news are loaded and stored in a variable. A brief check shows that there is not a feature suggesting that the text concerns a real story. Therefore, a new column \"label\" is added with values of \"1\", indicating true news.","metadata":{}},{"cell_type":"code","source":"true_news = pd.read_csv(\"../input/fake-and-real-news-dataset/True.csv\")","metadata":{"id":"WpIFtyIIPqtJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_news","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_news.insert(0,\"label\", 1)","metadata":{"id":"URmvK4YtP0hM","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_news.head()","metadata":{"id":"1LOVVPhmP7GO","outputId":"345daa00-2df5-499d-d686-68c7b48d5d67","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Similarly, fake news are stored in another variable. The same operations were performed over this dataset, too.","metadata":{}},{"cell_type":"code","source":"fake_news = pd.read_csv(\"../input/fake-and-real-news-dataset/Fake.csv\")","metadata":{"id":"FIs0BfMFOcgR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fake_news","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fake_news.insert(0, \"label\", 0)","metadata":{"id":"jqsNjz5VPCgO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fake_news.head()","metadata":{"id":"FDq3ILmoPh7R","outputId":"a04163bb-d3d7-4942-b8a9-d0901d2ca1a0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 21417 entries in the \"true\" dataset, and 23481 samples in the false stories. Both dataframes are concatenated to form a single table.","metadata":{}},{"cell_type":"code","source":"true_and_fake = pd.concat([true_news, fake_news])","metadata":{"id":"9nnVNx5HQOdr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_and_fake.shape","metadata":{"id":"Vqd9lUqUQOhO","outputId":"54bc78a2-4f62-43de-b10c-1df65d66b149","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Prepare and preprocess data","metadata":{}},{"cell_type":"markdown","source":"Now, the new table has 44898 rows and 5 columns. To avoid possible distortions, duplicated news are removed.","metadata":{}},{"cell_type":"code","source":"true_and_fake.drop_duplicates(inplace = True)","metadata":{"id":"Dc0_c5bsIrw6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A brief check shows that around 200 entries were duplicated.","metadata":{}},{"cell_type":"code","source":"true_and_fake.shape","metadata":{"id":"hJXvfwitIxxf","outputId":"6eee6390-6f97-4372-eab0-c21d13cd79d3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modelling both with \"Scikit Learn\" classifier and with Neural Network requires splitting data into training, validation and testing sets. Now, true and fake news  are ordered one afther the other. If this dataset is being split, training part will not get equal or similar false stories since most will fall into the validation and testing sets. Therefore, the code line below shuffles all samples and stores the new values in a new variable.","metadata":{}},{"cell_type":"code","source":"true_and_fake_dataset = true_and_fake.sample(frac = 1).reset_index(drop = True)","metadata":{"id":"1PE6wL8HQ9yh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check if shuffled worked.","metadata":{}},{"cell_type":"code","source":"true_and_fake_dataset.head()","metadata":{"id":"xxaKQtUpTT6K","outputId":"f384454d-9f31-4a5e-e191-f85b8267e666","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\"Title\", \"subject\", and \"date\" columns won't be used for classification. It would be entirely based on the words in the \"text\" field. Therefore, the three features are removed.","metadata":{}},{"cell_type":"code","source":"true_and_fake_dataset = true_and_fake_dataset.drop([\"title\", \"subject\", \"date\"], axis = 1)","metadata":{"id":"dkrljCnHTYSB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_and_fake_dataset.head()","metadata":{"id":"kE8rVCQLJB6r","outputId":"f51e4e3f-9455-4c8b-92d5-5d3258485b52","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is more convenient to have labels on the rightmost of the table. To that end, \"label\" and \"text\" switch places.","metadata":{}},{"cell_type":"code","source":"true_and_fake_dataset = true_and_fake_dataset[[\"text\", \"label\"]]","metadata":{"id":"zjB7omY0J4G3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_and_fake_dataset.head()","metadata":{"id":"WGLs1nHLJ68C","outputId":"937bb0f8-029c-4f2a-bc2b-30e16a5b5b93","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Also, to avoid confusing models, all words are turned into lowercase.","metadata":{}},{"cell_type":"code","source":"true_and_fake_dataset[\"text\"] = true_and_fake_dataset[\"text\"].str.lower()","metadata":{"id":"ZDxh3y_fnJF1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_and_fake_dataset","metadata":{"id":"MUDMhXdgnQyD","outputId":"9815c67d-7a31-461c-8e7b-1775ee042b77","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Usually, texts contain a lot of stopwords. The latter are words which do not add much meaning to a sentence. For example, \"the\", \"he\", \"have\", etc. Thus, they can safely be ignored without sacrificing the meaning of the sentence. Such words are captured in `nltk`'s \"corpus\" module. The function below, when applied, will remove all stopwords from true and fake news.","metadata":{}},{"cell_type":"code","source":"def remove_stopwords(input_text):\n    \"\"\"\n    Function: Removes stopwords from text\n    \n    Arguments: text\n    \n    Returns: text without stopwords\n    \"\"\"\n    words = input_text.split()\n    clean_words = [word for word in words if word not in stopwords.words(\"english\")]\n    clean_words = \" \".join(clean_words)\n    return clean_words","metadata":{"id":"avSSiEqfKZoj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In addition, texts should be clean from digits, special characters, links, and other symbols which do not hold meaningful information if detached from words. Therefore, these will be removed after applying the function below.","metadata":{}},{"cell_type":"code","source":"def custom_preprocessor(text):\n    \"\"\"\n    Function: Make text lowercase, remove text in square brackets, remove links, remove special\n              characters and remove words containing numbers\n    \n    Arguments: text\n    \n    Returns: text without special characters, links, and numbers.\n    \"\"\"\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub(\"\\\\W\",\" \",text) # removes special characters\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n\n    return text","metadata":{"id":"09_nj0nDKZxp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First, text is being cleaned from special characters, links and numbers; stopwords are removed thereafter.","metadata":{}},{"cell_type":"code","source":"true_and_fake_dataset[\"text\"] = true_and_fake_dataset[\"text\"].apply(custom_preprocessor)","metadata":{"id":"FNAKselUMgj9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_and_fake_dataset[\"text\"] = true_and_fake_dataset[\"text\"].apply(remove_stopwords)","metadata":{"id":"e3fmFVDGNAhd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code line below checks if text have been cleaned.","metadata":{}},{"cell_type":"code","source":"true_and_fake_dataset.head()","metadata":{"id":"1HCytEgUVX3l","outputId":"cd73ae2f-46b2-4abe-d22f-f90468ac8972","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Removing stopwords takes **more than half an hour**. In order to avoid repeating this operation, the final dataset is **exported as a \"csv\"** file **and is loaded again** (see below).","metadata":{}},{"cell_type":"code","source":"true_and_fake_dataset.to_csv(\"true_fake_news.csv\", index = False) ","metadata":{"id":"HD86U24xQ6Jp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Classification of fake and true news with Scikit Learn","metadata":{"id":"xVEPAqdWT7dV"}},{"cell_type":"markdown","source":"The exported file is loaded now and its values are used for classification.","metadata":{}},{"cell_type":"code","source":"true_and_fake_dataset = pd.read_csv(\"../input/true-fake-news/true_fake_news.csv\")","metadata":{"id":"6tfXp2Cdw4ME","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_and_fake_dataset.head()","metadata":{"id":"MYTVrV80xA2H","outputId":"1677aeb4-00ac-4003-c47a-4f806b6c9fb9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset was successfully loaded. It is important to check of there are any missing values in it.","metadata":{}},{"cell_type":"code","source":"true_and_fake_dataset.isna().any()","metadata":{"id":"kNxrv_njx4An","outputId":"dacefa33-72eb-45e6-f404-fc8bca7fbf19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems some cells became empty after removing stopwords and other specific characters, links and numbers. Those are dropped off from the DataFrame.","metadata":{}},{"cell_type":"code","source":"true_and_fake_dataset.dropna(inplace = True)","metadata":{"id":"fcf79jYhx-LN","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, the dataset could be split into training and testing sets. In the original Notebook, the author didn't used \"stratify\" split. Here, this option is applied. Test size and random state are left as they are.","metadata":{}},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(true_and_fake_dataset[\"text\"],\n                              true_and_fake_dataset[\"label\"], test_size = 0.25,\n                              stratify = true_and_fake_dataset[\"label\"],\n                              random_state = 100)","metadata":{"id":"vVzyyobLT_Iv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is important to check if resulting datasets are in the proper shape. The code line below confirms that.","metadata":{}},{"cell_type":"code","source":"x_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{"id":"8VbhFqdnVCty","outputId":"32cb98a6-9844-4e28-ae74-5f51f150db3d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The next step is to vectorize all words. This is performed with Scikit Learn's `TfidfVectorizer()`, which is a common algorithm for transforming text into a meaningful representation of numbers, used to fit machine algorithm for prediction.","metadata":{}},{"cell_type":"code","source":"vector = TfidfVectorizer()","metadata":{"id":"kbMQ7U0OT_L4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_vect = vector.fit_transform(x_train)","metadata":{"id":"iGFbOOP-T_Ov","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vectorized data are stored as 33042 entries (rows) and 94854 columns (unique words).","metadata":{}},{"cell_type":"code","source":"x_train_vect.shape","metadata":{"id":"dxPXMYBYT_Rb","outputId":"d4c818dd-180c-442c-d684-959830acfff7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are fed to the `LogisticRegression()` by applying `fit()`, along with respective labels.","metadata":{}},{"cell_type":"code","source":"lg = LogisticRegression().fit(x_train_vect, y_train)","metadata":{"id":"aBcPwjjPT_Ui","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predicted classes are computed by calling `predict` with testing texts.","metadata":{}},{"cell_type":"code","source":"y_pred = lg.predict(vector.transform(x_test))","metadata":{"id":"Jni9nm3gVKU3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y_pred)","metadata":{"id":"lDcgINtyVKYk","outputId":"5096cdcc-839d-486a-ded6-2c7a96b66386","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The most common classification metrics for evaluating a model's performance, is \"accuracy\" and \"f1_score\". The former shows the proportion of true results among the total number of cases examined. \"f1_score\", on the other hand, is the weighted average of \"precision\" and \"recall\" (other popular classification metrics). Thus, \"f1_score\" takes both false positives and false negatives into account.","metadata":{}},{"cell_type":"code","source":"print(f\"Accuracy score is: {accuracy_score(y_test, y_pred)*100}%\")","metadata":{"id":"RPS4hMpzIcow","outputId":"7df7d353-5ab7-4a9a-8925-8b20b4771e4e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"f1 score is {f1_score(y_test, y_pred)*100}%\")","metadata":{"id":"OKuOGKwfHnoV","outputId":"0d7f2584-83e2-422f-d8f5-e9a484547db4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Both \"accuracy\" and \"f1_score\" are pretty high: over 98%. Classification report shows how accurate and precise the algorithm is for each class. It is displayed below.","metadata":{}},{"cell_type":"code","source":"print(classification_report(y_test, y_pred))","metadata":{"id":"K6EcBHJNJFVF","outputId":"f1b08435-fc9b-4321-c759-a8b548ed2daa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The figures above confirm that both fake and real news are properly classified. Less than 1% of each type was misclassified, as shown on the confusion matrix below. Only 74 articles were wrongly declared \"fake\" instead of \"true\" (False Positive, type I error). On the other hand, barely 66 publications were not properly classified as \"fake\" (False Negative, type II error).","metadata":{}},{"cell_type":"code","source":"sns.heatmap(confusion_matrix(y_test, y_pred),\n            annot = True,\n            fmt = \".0f\",\n            cmap = \"coolwarm\",\n            linewidths = 2, \n            linecolor = \"white\",\n            xticklabels = lg.classes_,\n            yticklabels = lg.classes_)\nplt.show()","metadata":{"id":"SKBsv-PVJoYX","outputId":"012cdfbf-6bce-40b8-9cbc-33a0c55ed7ec","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In conclusion, the Logistic Regression Classifier was trained to (almost) perfectly distinguish fake from real news. It is interesting to see if a Neural Network could perform better.","metadata":{}},{"cell_type":"markdown","source":"## 4. Classification of fake and true news with a Neural Network","metadata":{"id":"xHZ4OJpT85yR"}},{"cell_type":"markdown","source":"### 4.1. Preprocessing data","metadata":{}},{"cell_type":"markdown","source":"Although Neural Networks are much more powerful, it might be hard to beat a Scikit Learn model having 98%-99% accuracy and f1_score. Nonetheless, it's worth to try it.\n\nThe first thing to do is to define values of relevant hyper-parameters. In this case, these are vocabulary size, i.e. the number of words used in training, embedding dimension (the dense representation of words and their relative meanings), maximum length of sentences, truncation and padding type, and how out of vocabulary words will be marked.\n\nIt is a common practice to begin with 10000 words. `TfidfVectorizer()` above however, found 94854 words. Therefore, the example below uses not 10000 but 20000 words. Embedding dimension for such not so complex tasks is usually set to 16 or 32. 300 words in a sentence is a kind of compromise - using less words might lead to loss of information, whereas more words (e.g. 400) - lots of \"white space\" at the end of shorter articles. Truncation type shows where to remove values from sequences larger than the maximum length, either at the beginning or at the end of the sequence. In this case, longer sequences will be truncated after the 300-th element. Padding indicates where to add \"white space\" (or 0s) when the text is shorter than the maximum lenght. Out of vocabulary words will be denoted as \"OOV\".","metadata":{}},{"cell_type":"code","source":"# Set values for hyper-parameters\nvocabulary_size = 20000\nembedding_dim = 32\nmax_length = 300\ntrunc_type = \"post\"\npadding_type = \"post\"\noov_tokens = \"<OOV>\"","metadata":{"id":"sKoVifGPQ6NR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the previous example, the dataset was split only into training and testing set. The Neural Network, however, is trained and tested with training, validation, and testing sets. These are created with the function below. Logistic Regression preserved more data for testing and used less for training. It is a better idea, however, to have more (and diverse) training samples (thus the model will be able to learn more and to adjust weights accordingly) and to evaluate performance on smaller sets. Therefore, the formula below takes 1000 samples from each label for validation and testing sets; the remaining are left for training.","metadata":{}},{"cell_type":"code","source":"#Stratified split\ntrain_data = []\nval_data = []\ntest_data = []\n\nfor label, data in true_and_fake_dataset.groupby(\"label\"):\n    shuffled_data = data.sample(len(data))\n    val_in_group = shuffled_data.iloc[:1000]\n    test_in_group = shuffled_data.iloc[1000:2000]\n    train_in_group = shuffled_data.iloc[2000:]\n    \n    train_data.append(train_in_group)\n    val_data.append(val_in_group)\n    test_data.append(test_in_group)","metadata":{"id":"mlnmOdGRVKjM","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All three sets are merged and shuffled (once again) by applying the function below.","metadata":{}},{"cell_type":"code","source":"def merge_and_shuffle(datasets):\n    result = pd.concat(datasets)\n    return result.sample(len(result))","metadata":{"id":"OjBi7b4A9lv-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = merge_and_shuffle(train_data)\nval_data = merge_and_shuffle(val_data)\ntest_data = merge_and_shuffle(test_data)","metadata":{"id":"DD6q7M6A9lzp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Datasets' shape is checked below. 40056 training samples, 2000 for validation, and 2000 for testing. All have two features - text and labels.","metadata":{"id":"6Hx3RzI49l4c"}},{"cell_type":"code","source":"train_data.shape, val_data.shape, test_data.shape","metadata":{"id":"WGll_7d899lp","outputId":"81d82fe6-f174-408c-d52f-ab6254057b83","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Neural Networks work with NumPy arrays and tensors. For this reason, the three datasets (which are lists now) are converted into NumPy arrays.","metadata":{}},{"cell_type":"code","source":"train_text = train_data[\"text\"].to_numpy()\nvalidation_text = val_data[\"text\"].to_numpy()\ntesting_text = test_data[\"text\"].to_numpy()","metadata":{"id":"72MO1pa6-HWP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, sentences (values in \"text\" column) can be tokenized, i.e. replacing each word with a number. This is performed by TensorFlow's `Tokenizer()` function, which expects (at least) the number of words to return (in this case 20000, as defined earlier), and how to denote out of vocabulary words. After initializing, the tokenizer is applied only on the training set. It is assumed the training data are sufficient for predicting fake or real news in validation and testing sets.","metadata":{}},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words=vocabulary_size, oov_token=oov_tokens)","metadata":{"id":"uVzF2KT5bNUB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.fit_on_texts(train_text)","metadata":{"id":"VLrTYXZhbP4f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Applying `word_index` over the tokenizer returns the numbers against each word in vocabulary. Out of vocabulary words are denoted as \"1\", \"trump\" as \"2\", \"president\" as 4, etc. Only the first 10 tokenized words (out of 20000) are displayed below.","metadata":{}},{"cell_type":"code","source":"word_index = tokenizer.word_index","metadata":{"id":"HEX4IkYWlyLX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print first 10 tokenized words (key, value pairs)\niterator = iter(word_index.items())\nfor i in range(10):\n    print(next(iterator))","metadata":{"id":"XCansJG2l6P0","outputId":"a6c398de-db0a-4b10-9a63-7d65d19265e9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The next step is to turn text into sequence of numbers. This is performed with `texts_to_sequences()` method, which accepts training data.","metadata":{}},{"cell_type":"code","source":"train_sequences = tokenizer.texts_to_sequences(train_text)","metadata":{"id":"7lnHknxGmNCd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The first text line is displayed below. It has around 200 words but the Neural Network will expect 300. Therefore, its length is expanded by applying `pad_sequences()`. This function expects the sequences, their maximum lenght, padding and truncating type.","metadata":{}},{"cell_type":"code","source":"np.array(train_sequences[0])","metadata":{"id":"AJ3ecPsp_XbJ","outputId":"bcea5243-0858-40bb-de58-2e4d6f05b13d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_padded = pad_sequences(train_sequences, maxlen = max_length, padding = padding_type, truncating = trunc_type)","metadata":{"id":"n30gfke0mm6-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The cell below shows how the same text looks like after padding. The first numbers are the same as above but 0s are added at the end, until the 300th element.","metadata":{}},{"cell_type":"code","source":"train_padded[0]","metadata":{"id":"xVdWA2BfnEh5","outputId":"72a6ab2d-5792-46e1-d0e4-09761ddeb1fe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The same operations are applied to all text lines in the list. Length of second and sixth texts before and after padding is printed below.","metadata":{}},{"cell_type":"code","source":"print(len(train_sequences[1]))\nprint(len(train_padded[1]))","metadata":{"id":"6RYhUHYInQR6","outputId":"a55e117d-276b-402f-fb60-b9377334363b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_sequences[5]))\nprint(len(train_padded[5]))","metadata":{"id":"iBtjTF4PnU5s","outputId":"c344494c-561b-43b0-9708-4553f810ed72","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To illustrate how padding and \"texts_to_sequences\" work, the code lines below convert sequences to text by reversing word_index.","metadata":{}},{"cell_type":"code","source":"reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_sentence(text):\n    return \" \".join([reverse_word_index.get(i, \"?\") for i in text])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's take the last example - the sixth line in the training set. It has 551 numbers and the remaining are truncated. Decoded sentence is shown first, followed by the original one. ","metadata":{}},{"cell_type":"code","source":"print(decode_sentence(train_padded[5]))\nprint(train_text[5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Validation and testing texts undergo the same preprocessing.","metadata":{}},{"cell_type":"code","source":"validation_sequences = tokenizer.texts_to_sequences(validation_text)","metadata":{"id":"EnMppIwdnXxx","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_padded = pad_sequences(validation_sequences, maxlen = max_length, padding = padding_type, truncating = trunc_type)","metadata":{"id":"1jWmSuQBnjQH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(validation_sequences))\nprint(validation_padded.shape)","metadata":{"id":"bcVlaqGon04L","outputId":"d4db7f44-9f1a-40a3-f336-116a261446c0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_sequences = tokenizer.texts_to_sequences(testing_text)","metadata":{"id":"XR-dwKoo5IA4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_padded = pad_sequences(testing_sequences, maxlen = max_length, padding = padding_type, truncating = trunc_type)","metadata":{"id":"lfPd_Fo8_px0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(testing_sequences))\nprint(testing_padded.shape)","metadata":{"id":"KNvjMnNT_p7S","outputId":"b5295201-8b8f-4bba-886e-723669ef4e3e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Labels should also be preprocessed. They are extracted and turned into NumPy arrays.","metadata":{"id":"e3JqnuunoDSD"}},{"cell_type":"code","source":"train_labels = train_data[\"label\"].to_numpy()\nvalidation_labels = val_data[\"label\"].to_numpy()\ntesting_labels = test_data[\"label\"].to_numpy()","metadata":{"id":"olnL6PJN_6Uo","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.2. Building and training the Neural Network","metadata":{"id":"YeMTmbKnpHqX"}},{"cell_type":"markdown","source":"To avoid clutter from existing models and layers (when model is being fune-tuned several times), especially when memory is limited, `clear_session()` resets all prior state generated by Keras.","metadata":{}},{"cell_type":"code","source":"tf.keras.backend.clear_session()","metadata":{"id":"Pz10Jtb0yTyp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model (classifier) is a simple Neural Network with an Embedding layer, two LSTM layers (one of which Bidirectional to carry information from previous state), and two Dense layers. The last layer returns the output. Its activation is \"sigmoid\" since the task is a binary classification, i.e. there are only two possible outcomes - either an article is fake, or not. Therefore, the layer needs only one neuron. Weights of the previous Dense layer are computed by applying \"relu\" activation, which means only positive activities are returned. Several tests and trials showed that two LSTM layers with 24 and 16 neurons, respectively, return very good results. The Embedding layer expects dataset's shape, namely vocabulary size, embedding dimension, and maximum lenght of sequences.","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n        Embedding(vocabulary_size, embedding_dim, input_length = max_length),\n        Bidirectional(LSTM(24, return_sequences = True)),\n        LSTM(16),\n        Dense(16, activation = \"relu\"),\n        Dense(1, activation = \"sigmoid\")\n])","metadata":{"id":"LPDKJHvtMSKi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model has 655 393 trainable parameters, most of which in the Embedding layer.","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"id":"BjEYu76Ap_PN","outputId":"01ab6300-28f1-467d-c62d-a9f3078b3fbc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"TensorFlow, in contrast to Scikit Learn, does not maintain as a \"ready to use\" `f1_score` or other classification metrics save \"accuracy\". To compare both models, however, the Neural Network should be able to compute them. Thus, the functions below (which compute \"precision\", \"recall\", and \"f1_score\") are passed to the \"metrics\" element of `compile` method. The code is taken from [StackExchange](https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model).","metadata":{}},{"cell_type":"code","source":"def recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall","metadata":{"id":"mdbkanO4bvLI","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision","metadata":{"id":"fMmk7AaccV2_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","metadata":{"id":"3pRL7BPnc2nr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model is compiled by passing the appropriate loss function (\"binary crossentropy\" in this case), an optimizer (i.e. the formula for computing gradient descent and for updating layer weights), and metrics for evaluating model's performance.","metadata":{}},{"cell_type":"code","source":"model.compile(loss = \"binary_crossentropy\",\n              optimizer = \"adam\",\n              metrics = [\"accuracy\", f1_m, precision_m, recall_m])","metadata":{"id":"ZfBew37QqBCX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tests and trials showed that the model converges for around 10 epohcs (i.e. 10 forward and backward propagation of gradient descent).","metadata":{}},{"cell_type":"code","source":"num_epochs = 10","metadata":{"id":"2tEZ2aKeqOJe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training a Neural Network means applying `fit()` method over the model, passing training and validation data, and stating (at least) the number of epochs. The example below reached 99-100% both on \"accuracy\" and \"f1_score\", as well as on \"precision\" and \"recall\" on both datasets.","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_padded, train_labels,\n                    epochs = num_epochs,\n                    validation_data = (validation_padded, validation_labels))","metadata":{"id":"ENZ_3hxbqTc8","outputId":"3c39c59a-78cb-44a0-ae19-011f649aedf4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_graphs(history, string):\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string, 'val_'+string])\n    plt.show()","metadata":{"id":"9J1FUXRoqfDx","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The plots below show how the model converged for 10 epochs.","metadata":{}},{"cell_type":"code","source":"plot_graphs(history, \"loss\")\nplot_graphs(history, \"accuracy\")\nplot_graphs(history, \"f1_m\")\nplot_graphs(history, \"precision_m\")\nplot_graphs(history, \"recall_m\")","metadata":{"id":"a6j85vrnrMBk","outputId":"162ff69d-9027-4101-ee81-9eb4f18d43d2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.3 Model exploring and evaluation","metadata":{}},{"cell_type":"markdown","source":"It would be interesting to see how weights were updated after training (weights' values have normal distribution when model is initialized). To demonstrate this, weights of the Embedding layer are extracted and stored in a variable.","metadata":{}},{"cell_type":"code","source":"e = model.layers[0]\nweights = e.get_weights()[0]","metadata":{"id":"DPrLH9KNtWan","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights","metadata":{"id":"nDINdPmDtco5","outputId":"34cf3185-07b5-4180-91e3-73dd2be56b82","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Weights matrix has 20000 rows (as the number of words in vocabulary) and 32 \"features\" (as the number of embedding dimensions).","metadata":{}},{"cell_type":"code","source":"print(weights.shape)","metadata":{"id":"ojOST-cdtkme","outputId":"2cc24aaa-2f29-4058-f05c-5c900810d621","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The plot below shows how all these 640 000 weights are distributed. Most have (as expected) values very close to 0. Those having higher value are more important, i.e. for deciding if an article is fake or not.","metadata":{}},{"cell_type":"code","source":"# Display distribution of weights in Embedding layer\nplt.hist(weights.ravel())\nplt.xlabel(\"weights of Embedding layer\")\nplt.ylabel(\"count\")\nplt.title(\"Distribution of weights in Embedding after training\")\nplt.show()","metadata":{"id":"F5gMvhAdYYgW","outputId":"daffdcb2-1b57-4f30-db74-561c31410d38","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To compare a Neural Network's performance with that of a Logistic Regression Classifier, the former is evaluated on the testing data. Returned values for \"accuracy\", \"f1_score\", and \"recall\" are 99.9+%, and recall is 100% - higher than those achived by the \"Scikit Learn\" model. This means that the Neural Network is expected to be impeccable in distinguishing true from fake news.","metadata":{}},{"cell_type":"code","source":"loss, accuracy, f1_score, precision, recall = model.evaluate(testing_padded, testing_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Model accuracy is {accuracy * 100}%\")\nprint(f\"Model f1 score is {f1_score * 100}%\")\nprint(f\"Model precision is {precision * 100}%\")\nprint(f\"Model recall is {recall * 100}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Confusion matrix is not computed since it will show only lesser number of misclassified articles. Instead, a screenshot of how words are clustered are shown below. The code lines below (taken from DeepLearning.AI training on NLP) extract vectors and metadata, which are fed into TensorFlow's projector. ","metadata":{}},{"cell_type":"code","source":"out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\nout_m = io.open('meta.tsv', 'w', encoding='utf-8')\nfor word_num in range(1, vocabulary_size):\n    word = reverse_word_index[word_num]\n    embeddings = weights[word_num]\n    out_m.write(word + \"\\n\")\n    out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\nout_v.close()\nout_m.close()","metadata":{"id":"4356KdG0toCD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    from google.colab import files\nexcept ImportError:\n    pass\nelse:\n    files.download('vecs.tsv')\n    files.download('meta.tsv')","metadata":{"id":"6skk2nLltxIt","outputId":"d5e374d7-0360-41dc-8d9b-cf56eddcb230","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n","metadata":{"id":"-2YyNfLQaT9B","outputId":"cb374277-f198-49f3-de0e-a1fa31064f65"}},{"cell_type":"markdown","source":"The screenshots show how the words are clustered within an imaginary shpere. \"trump\" and \"trump\"-linked words (second image) tend to be grouped around one of the poles, whereas \"really\" and similar words are more dispersed, without being explicitly assigned to one of two article types.","metadata":{}},{"cell_type":"code","source":"Image(\"../input/projector-images/01.jpg\")","metadata":{"id":"0eowXRIhDzlk","outputId":"93a0f451-fbfe-4a67-b64b-3dae60b3764b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image(\"../input/projector-images/02.jpg\")","metadata":{"id":"xwfiGwunbv7o","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image(\"../input/projector-images/03.jpg\")","metadata":{"id":"mwnsuTIbbv_v","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In conclusion, it could be said that a Neural Network can better (or perfectly) recognise fake from true news, compared to a top-performing Logistic Regressor.","metadata":{}}]}