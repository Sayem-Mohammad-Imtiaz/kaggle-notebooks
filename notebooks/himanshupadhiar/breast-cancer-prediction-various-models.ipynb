{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-13T05:56:05.444471Z","iopub.execute_input":"2021-06-13T05:56:05.445023Z","iopub.status.idle":"2021-06-13T05:56:05.465191Z","shell.execute_reply.started":"2021-06-13T05:56:05.444912Z","shell.execute_reply":"2021-06-13T05:56:05.463701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This work is in progress.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.offline as pyo\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\n\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot, download_plotlyjs\n","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:05.467051Z","iopub.execute_input":"2021-06-13T05:56:05.467397Z","iopub.status.idle":"2021-06-13T05:56:09.144774Z","shell.execute_reply.started":"2021-06-13T05:56:05.467363Z","shell.execute_reply":"2021-06-13T05:56:09.143482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function defined to check medata of a dataframe\ndef master_dataframe(dataframe):\n    df_metadata = pd.DataFrame({'Datatype': dataframe.dtypes,\n                                \"Null Values\": dataframe.isna().sum(),  \n                                \"Null %\": round(dataframe.isna().sum()/len(dataframe)*100, 2),\n                                \"No: Of Unique Values\": dataframe.nunique()})\n    \n    df_describe = dataframe.describe(include='all').T\n    \n    df_metadata = df_metadata.join(df_describe)  \n\n    return df_metadata","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.146773Z","iopub.execute_input":"2021-06-13T05:56:09.147087Z","iopub.status.idle":"2021-06-13T05:56:09.153539Z","shell.execute_reply.started":"2021-06-13T05:56:09.147055Z","shell.execute_reply":"2021-06-13T05:56:09.152459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import data\nraw_data = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.155317Z","iopub.execute_input":"2021-06-13T05:56:09.155766Z","iopub.status.idle":"2021-06-13T05:56:09.188956Z","shell.execute_reply.started":"2021-06-13T05:56:09.155732Z","shell.execute_reply":"2021-06-13T05:56:09.187841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check metadata by using the function master_dataframe()\nmaster_dataframe(raw_data)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.191168Z","iopub.execute_input":"2021-06-13T05:56:09.191525Z","iopub.status.idle":"2021-06-13T05:56:09.358492Z","shell.execute_reply.started":"2021-06-13T05:56:09.19149Z","shell.execute_reply":"2021-06-13T05:56:09.357451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_data['Unnamed: 32'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.361327Z","iopub.execute_input":"2021-06-13T05:56:09.36177Z","iopub.status.idle":"2021-06-13T05:56:09.369051Z","shell.execute_reply.started":"2021-06-13T05:56:09.361734Z","shell.execute_reply":"2021-06-13T05:56:09.367129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping the ID & Unnamed 32 field.\ndata_col_drop = raw_data.copy()\ndata_col_drop.drop(columns = ['id', 'Unnamed: 32'], axis = 1, inplace = True)\ndata_col_drop.columns","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.370604Z","iopub.execute_input":"2021-06-13T05:56:09.371106Z","iopub.status.idle":"2021-06-13T05:56:09.385663Z","shell.execute_reply.started":"2021-06-13T05:56:09.371074Z","shell.execute_reply":"2021-06-13T05:56:09.384449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the unique value of our target variable diagnosis.\ndata_col_drop['diagnosis'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.388961Z","iopub.execute_input":"2021-06-13T05:56:09.389408Z","iopub.status.idle":"2021-06-13T05:56:09.404219Z","shell.execute_reply.started":"2021-06-13T05:56:09.389371Z","shell.execute_reply":"2021-06-13T05:56:09.402901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Segregating the dependent and independent variables.\nX = data_col_drop.iloc[:, 1:].values\ny = data_col_drop.iloc[:, 0].values","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.40658Z","iopub.execute_input":"2021-06-13T05:56:09.40693Z","iopub.status.idle":"2021-06-13T05:56:09.417997Z","shell.execute_reply.started":"2021-06-13T05:56:09.406896Z","shell.execute_reply":"2021-06-13T05:56:09.416849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.419327Z","iopub.execute_input":"2021-06-13T05:56:09.419637Z","iopub.status.idle":"2021-06-13T05:56:09.432036Z","shell.execute_reply.started":"2021-06-13T05:56:09.419608Z","shell.execute_reply":"2021-06-13T05:56:09.431059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.433068Z","iopub.execute_input":"2021-06-13T05:56:09.433475Z","iopub.status.idle":"2021-06-13T05:56:09.447051Z","shell.execute_reply.started":"2021-06-13T05:56:09.433445Z","shell.execute_reply":"2021-06-13T05:56:09.445994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets encode the dependent variable i.e. diagnosis using LabelEncoder as it is a nominal categorical data(unordered).\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)\nprint(y)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.448699Z","iopub.execute_input":"2021-06-13T05:56:09.449083Z","iopub.status.idle":"2021-06-13T05:56:09.590762Z","shell.execute_reply.started":"2021-06-13T05:56:09.449004Z","shell.execute_reply":"2021-06-13T05:56:09.589776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's split out dataset into train and test data before we create our model.\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\nprint('Shape of X_train', X_train.shape)\nprint('Shape of X_test', X_test.shape)\nprint('Shape of y_train', y_train.shape)\nprint('Shape of y_test', y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.59217Z","iopub.execute_input":"2021-06-13T05:56:09.592487Z","iopub.status.idle":"2021-06-13T05:56:09.664911Z","shell.execute_reply.started":"2021-06-13T05:56:09.592458Z","shell.execute_reply":"2021-06-13T05:56:09.663839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets apply feature scaling to our train and test independent variables as they appear to be in different scale.\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.666508Z","iopub.execute_input":"2021-06-13T05:56:09.666933Z","iopub.status.idle":"2021-06-13T05:56:09.674281Z","shell.execute_reply.started":"2021-06-13T05:56:09.666887Z","shell.execute_reply":"2021-06-13T05:56:09.673258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.675549Z","iopub.execute_input":"2021-06-13T05:56:09.675863Z","iopub.status.idle":"2021-06-13T05:56:09.686688Z","shell.execute_reply.started":"2021-06-13T05:56:09.675834Z","shell.execute_reply":"2021-06-13T05:56:09.685392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.687981Z","iopub.execute_input":"2021-06-13T05:56:09.688408Z","iopub.status.idle":"2021-06-13T05:56:09.695529Z","shell.execute_reply.started":"2021-06-13T05:56:09.688375Z","shell.execute_reply":"2021-06-13T05:56:09.694753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{}},{"cell_type":"code","source":"# Lets create our Logistic Regression model by using sklearn library\nfrom sklearn.linear_model import LogisticRegression\nlog_classifier = LogisticRegression(random_state = 0)\nlog_classifier.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.696489Z","iopub.execute_input":"2021-06-13T05:56:09.696875Z","iopub.status.idle":"2021-06-13T05:56:09.834375Z","shell.execute_reply.started":"2021-06-13T05:56:09.696845Z","shell.execute_reply":"2021-06-13T05:56:09.833268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets make the prediction using the model.\ny_pred = log_classifier.predict(X_test)\nprint(y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.839387Z","iopub.execute_input":"2021-06-13T05:56:09.842125Z","iopub.status.idle":"2021-06-13T05:56:09.855887Z","shell.execute_reply.started":"2021-06-13T05:56:09.842062Z","shell.execute_reply":"2021-06-13T05:56:09.854419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets measure the accuracy of the model using the confusion matrix and accruacy score.\nfrom sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\n\ncorr_pred = cm[0, 0] + cm[1, 1]\ntotal = cm.sum()\ncorr_pred_per = round(corr_pred/total*100, 2)\nprint('Percentage of correct predictions: ', corr_pred_per)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.861487Z","iopub.execute_input":"2021-06-13T05:56:09.864123Z","iopub.status.idle":"2021-06-13T05:56:09.883366Z","shell.execute_reply.started":"2021-06-13T05:56:09.864062Z","shell.execute_reply":"2021-06-13T05:56:09.881827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets check the confusion matrix\nprint(cm)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.888538Z","iopub.execute_input":"2021-06-13T05:56:09.891242Z","iopub.status.idle":"2021-06-13T05:56:09.902856Z","shell.execute_reply.started":"2021-06-13T05:56:09.891179Z","shell.execute_reply":"2021-06-13T05:56:09.9014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets check the accuracy using the accuracy_score from sklearn.\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy of the model: ', round((accuracy*100), 2))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.909533Z","iopub.execute_input":"2021-06-13T05:56:09.912861Z","iopub.status.idle":"2021-06-13T05:56:09.926137Z","shell.execute_reply.started":"2021-06-13T05:56:09.912796Z","shell.execute_reply":"2021-06-13T05:56:09.924677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets transform the encoded predicted variable back to it's original form for better understanding.\ny_pred_d_enco = le.inverse_transform(y_pred)\ny_test_d_enco = le.inverse_transform(y_test)\n\n# Also lets store them in a dataframe and check them parallely\ncomparison = pd.DataFrame()\ncomparison['Actual Values'] = y_test_d_enco\ncomparison['Predicted Values'] = y_pred_d_enco","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.930371Z","iopub.execute_input":"2021-06-13T05:56:09.933491Z","iopub.status.idle":"2021-06-13T05:56:09.94513Z","shell.execute_reply.started":"2021-06-13T05:56:09.933429Z","shell.execute_reply":"2021-06-13T05:56:09.943635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets check all the data in the dataframe we just created.\npd.set_option('display.max_rows', 200)\ncomparison\n\n# Good to see most of them match.","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.950411Z","iopub.execute_input":"2021-06-13T05:56:09.951018Z","iopub.status.idle":"2021-06-13T05:56:09.97798Z","shell.execute_reply.started":"2021-06-13T05:56:09.950965Z","shell.execute_reply":"2021-06-13T05:56:09.976871Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# K Nearest Neighbors Classifier","metadata":{}},{"cell_type":"code","source":"# Creating the model\nfrom sklearn.neighbors import KNeighborsClassifier\nknn_classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nknn_classifier.fit(X_train, y_train)\n\n# Predicting the outcome.\ny_pred_knn = knn_classifier.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:09.979945Z","iopub.execute_input":"2021-06-13T05:56:09.980618Z","iopub.status.idle":"2021-06-13T05:56:10.07718Z","shell.execute_reply.started":"2021-06-13T05:56:09.980571Z","shell.execute_reply":"2021-06-13T05:56:10.076341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets measure the accuracy of the model using the confusion matrix.\ncm = confusion_matrix(y_test, y_pred_knn)\n\ncorr_pred = cm[0, 0] + cm[1, 1]\ntotal = cm.sum()\ncorr_pred_per_knn = round(corr_pred/total*100, 2)\nprint('Percentage of correct predictions: ', corr_pred_per_knn)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:10.07905Z","iopub.execute_input":"2021-06-13T05:56:10.081022Z","iopub.status.idle":"2021-06-13T05:56:10.095643Z","shell.execute_reply.started":"2021-06-13T05:56:10.080973Z","shell.execute_reply":"2021-06-13T05:56:10.094133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets check the accuracy using the accuracy_score from sklearn.\naccuracy = accuracy_score(y_test, y_pred_knn)\nprint('Accuracy of the model: ', round((accuracy*100), 2))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:10.098589Z","iopub.execute_input":"2021-06-13T05:56:10.099903Z","iopub.status.idle":"2021-06-13T05:56:10.111915Z","shell.execute_reply.started":"2021-06-13T05:56:10.099332Z","shell.execute_reply":"2021-06-13T05:56:10.110737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Support Vector Machine","metadata":{}},{"cell_type":"code","source":"# Lets create a SVM classification model.\nfrom sklearn.svm import SVC\nsvc_classifier = SVC(kernel = 'linear')\nsvc_classifier.fit(X_train, y_train)\n\n# Predicting the outcome.\ny_pred_svm = svc_classifier.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:10.113489Z","iopub.execute_input":"2021-06-13T05:56:10.119034Z","iopub.status.idle":"2021-06-13T05:56:10.134234Z","shell.execute_reply.started":"2021-06-13T05:56:10.118966Z","shell.execute_reply":"2021-06-13T05:56:10.132946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets measure the accuracy of the model using the confusion matrix.\ncm = confusion_matrix(y_test, y_pred_svm)\n\ncorr_pred = cm[0, 0] + cm[1, 1]\ntotal = cm.sum()\ncorr_pred_per_svm = round(corr_pred/total*100, 2)\nprint('Percentage of correct predictions: ', corr_pred_per_svm)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:10.139608Z","iopub.execute_input":"2021-06-13T05:56:10.142389Z","iopub.status.idle":"2021-06-13T05:56:10.157369Z","shell.execute_reply.started":"2021-06-13T05:56:10.142314Z","shell.execute_reply":"2021-06-13T05:56:10.156085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets check the accuracy using the accuracy_score from sklearn.\naccuracy = accuracy_score(y_test, y_pred_svm)\nprint('Accuracy of the model: ', round((accuracy*100), 2))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:10.163392Z","iopub.execute_input":"2021-06-13T05:56:10.166226Z","iopub.status.idle":"2021-06-13T05:56:10.181244Z","shell.execute_reply.started":"2021-06-13T05:56:10.166151Z","shell.execute_reply":"2021-06-13T05:56:10.180001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Kernel SVM","metadata":{}},{"cell_type":"code","source":"k_svm_classifier = SVC(kernel = 'rbf')\nk_svm_classifier.fit(X_train, y_train)\n\n# Predicting the outcome.\ny_pred_k_svm = k_svm_classifier.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:10.186703Z","iopub.execute_input":"2021-06-13T05:56:10.187049Z","iopub.status.idle":"2021-06-13T05:56:10.20053Z","shell.execute_reply.started":"2021-06-13T05:56:10.187019Z","shell.execute_reply":"2021-06-13T05:56:10.199549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets measure the accuracy of the model using the confusion matrix.\ncm = confusion_matrix(y_test, y_pred_k_svm)\n\ncorr_pred = cm[0, 0] + cm[1, 1]\ntotal = cm.sum()\ncorr_pred_per_k_svm = round(corr_pred/total*100, 2)\nprint('Percentage of correct predictions: ', corr_pred_per_k_svm)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:10.202072Z","iopub.execute_input":"2021-06-13T05:56:10.202526Z","iopub.status.idle":"2021-06-13T05:56:10.210686Z","shell.execute_reply.started":"2021-06-13T05:56:10.202492Z","shell.execute_reply":"2021-06-13T05:56:10.209652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets check the accuracy using the accuracy_score from sklearn.\naccuracy = accuracy_score(y_test, y_pred_k_svm)\nprint('Accuracy of the model: ', round((accuracy*100), 2))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:56:10.212015Z","iopub.execute_input":"2021-06-13T05:56:10.212336Z","iopub.status.idle":"2021-06-13T05:56:10.22513Z","shell.execute_reply.started":"2021-06-13T05:56:10.212268Z","shell.execute_reply":"2021-06-13T05:56:10.224129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Naive Bayes","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb_classifier = GaussianNB()\nnb_classifier.fit(X_train, y_train)\n\n# Predicting the outcome.\ny_pred_nb = nb_classifier.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T05:59:27.573156Z","iopub.execute_input":"2021-06-13T05:59:27.573632Z","iopub.status.idle":"2021-06-13T05:59:27.581584Z","shell.execute_reply.started":"2021-06-13T05:59:27.573589Z","shell.execute_reply":"2021-06-13T05:59:27.580457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets measure the accuracy of the model using the confusion matrix.\ncm = confusion_matrix(y_test, y_pred_nb)\n\ncorr_pred = cm[0, 0] + cm[1, 1]\ntotal = cm.sum()\ncorr_pred_per_nb = round(corr_pred/total*100, 2)\nprint('Percentage of correct predictions: ', corr_pred_per_nb)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T06:00:00.610124Z","iopub.execute_input":"2021-06-13T06:00:00.610738Z","iopub.status.idle":"2021-06-13T06:00:00.618569Z","shell.execute_reply.started":"2021-06-13T06:00:00.610698Z","shell.execute_reply":"2021-06-13T06:00:00.617497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets check the accuracy using the accuracy_score from sklearn.\naccuracy = accuracy_score(y_test, y_pred_nb)\nprint('Accuracy of the model: ', round((accuracy*100), 2))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T06:00:30.46736Z","iopub.execute_input":"2021-06-13T06:00:30.46777Z","iopub.status.idle":"2021-06-13T06:00:30.474706Z","shell.execute_reply.started":"2021-06-13T06:00:30.467736Z","shell.execute_reply":"2021-06-13T06:00:30.473819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree Clssifier","metadata":{"execution":{"iopub.status.busy":"2021-06-13T06:20:40.622612Z","iopub.execute_input":"2021-06-13T06:20:40.623018Z","iopub.status.idle":"2021-06-13T06:20:40.626913Z","shell.execute_reply.started":"2021-06-13T06:20:40.622981Z","shell.execute_reply":"2021-06-13T06:20:40.625765Z"}}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt_classifier = DecisionTreeClassifier(criterion = 'entropy')\ndt_classifier.fit(X_train, y_train)\n\n# Predicting the outcome.\ny_pred_dt = dt_classifier.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T06:25:06.884983Z","iopub.execute_input":"2021-06-13T06:25:06.885439Z","iopub.status.idle":"2021-06-13T06:25:06.902696Z","shell.execute_reply.started":"2021-06-13T06:25:06.885397Z","shell.execute_reply":"2021-06-13T06:25:06.90118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets measure the accuracy of the model using the confusion matrix.\ncm = confusion_matrix(y_test, y_pred_dt)\n\ncorr_pred = cm[0, 0] + cm[1, 1]\ntotal = cm.sum()\ncorr_pred_per_dt = round(corr_pred/total*100, 2)\nprint('Percentage of correct predictions: ', corr_pred_per_dt)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T06:25:10.16235Z","iopub.execute_input":"2021-06-13T06:25:10.162789Z","iopub.status.idle":"2021-06-13T06:25:10.172352Z","shell.execute_reply.started":"2021-06-13T06:25:10.162748Z","shell.execute_reply":"2021-06-13T06:25:10.17075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets check the accuracy using the accuracy_score from sklearn.\naccuracy = accuracy_score(y_test, y_pred_dt)\nprint('Accuracy of the model: ', round((accuracy*100), 2))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T06:25:13.916054Z","iopub.execute_input":"2021-06-13T06:25:13.916448Z","iopub.status.idle":"2021-06-13T06:25:13.924387Z","shell.execute_reply.started":"2021-06-13T06:25:13.916413Z","shell.execute_reply":"2021-06-13T06:25:13.92305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest Classfier","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf_classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy')\nrf_classifier.fit(X_train, y_train)\n\n# Predicting the outcome.\ny_pred_rf = rf_classifier.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T06:38:12.895652Z","iopub.execute_input":"2021-06-13T06:38:12.896086Z","iopub.status.idle":"2021-06-13T06:38:13.197923Z","shell.execute_reply.started":"2021-06-13T06:38:12.896046Z","shell.execute_reply":"2021-06-13T06:38:13.196831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets measure the accuracy of the model using the confusion matrix.\ncm = confusion_matrix(y_test, y_pred_rf)\n\ncorr_pred = cm[0, 0] + cm[1, 1]\ntotal = cm.sum()\ncorr_pred_per_rf = round(corr_pred/total*100, 2)\nprint('Percentage of correct predictions: ', corr_pred_per_rf)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T06:38:15.452233Z","iopub.execute_input":"2021-06-13T06:38:15.452604Z","iopub.status.idle":"2021-06-13T06:38:15.460673Z","shell.execute_reply.started":"2021-06-13T06:38:15.452571Z","shell.execute_reply":"2021-06-13T06:38:15.459723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets check the accuracy using the accuracy_score from sklearn.\naccuracy = accuracy_score(y_test, y_pred_rf)\nprint('Accuracy of the model: ', round((accuracy*100), 2))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T06:38:21.928352Z","iopub.execute_input":"2021-06-13T06:38:21.928919Z","iopub.status.idle":"2021-06-13T06:38:21.934887Z","shell.execute_reply.started":"2021-06-13T06:38:21.928869Z","shell.execute_reply":"2021-06-13T06:38:21.933831Z"},"trusted":true},"execution_count":null,"outputs":[]}]}