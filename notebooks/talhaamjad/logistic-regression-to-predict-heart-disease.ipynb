{"cells":[{"metadata":{},"cell_type":"markdown","source":"**  LOGISTIC REGRESSION TO  PREDICT HEART DISEASE.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":" **Introduction**\n \nWorld Health Organization has estimated 12 million deaths occur worldwide, every year due to Heart diseases. Half the deaths in the United States and other developed countries are due to cardio vascular diseases. The early prognosis of cardiovascular diseases can aid in making decisions on lifestyle changes in high risk patients and in turn reduce the complications. This research intends to pinpoint the most relevant/risk factors of heart disease as well as predict the overall risk using logistic regression.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"** # Supress Warnings**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**import libraries**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport scipy.stats as st\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.mlab as mlab\n\n#Importing the dataset and dropping the unwanted columns \nheart_df=pd.read_csv(\"../input/framingham.csv\")\nheart_df.drop(['education'],axis=1,inplace=True)\nheart_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Preparation\nSource:\nThe dataset is publically available on the Kaggle website, and it is from an ongoing ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. The classification goal is to predict whether the patient has 10-year risk of future coronary heart disease (CHD).The dataset provides the patients’ information. It includes over 4,000 records and 15 attributes","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Renaming the column name\nheart_df.rename(columns={'male':'Sex_male'},inplace=True)\n\nheart_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the missing values \nheart_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploratory Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Counting the missing values and dropping them\ncount=0\nfor i in heart_df.isnull().sum(axis=1):\n    if i>0:\n        count=count+1\nprint('Total number of rows with missing values is ', count)\nprint('since it is only',round((count/len(heart_df.index))*100), 'percent of the entire dataset the rows with missing values are excluded.')\n\nheart_df.dropna(axis=0,inplace=True)\n\nheart_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**again checking null values**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"heart_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding a constant\nfrom statsmodels.tools import add_constant as add_constant\nheart_df_constant = add_constant(heart_df)\nheart_df_constant.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Logistic Regression**\n\nLogistic regression is a type of regression analysis in statistics used for prediction of outcome of a categorical dependent variable from a set of predictor or independent variables. In logistic regression the dependent variable is always binary. Logistic regression is mainly used to for prediction and also calculating the probability of success.\n\n**Chi-square Test**\n\n● A Chi-square Test (also written 𝜒2) is used to determine the probability of an observed frequency of events given an expected frequency\n\n**Chi-square Test**\n\n● The chi-square formula considers the sum of square distances between observed values O and expected values E, divided by each expected value:\n𝜒2 = ((𝑂 − 𝐸)e2)/E","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nst.chisqprob = lambda chisq, df: st.chi2.sf(chisq, df)\ncols=heart_df_constant.columns[:-1]\nmodel=sm.Logit(heart_df.TenYearCHD,heart_df_constant[cols])\nresult=model.fit()\nresult.summary()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**#Feature Selection: Backward elemination (P-value approach)\n#Takes in the dataframe, the dependent variable and a list of column names, \n#runs the regression repeatedly eleminating feature with the highest\n#P-value above alpha one at a time and returns the regression summary \n#with all p-values below alpha\n**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef back_feature_elem (data_frame,dep_var,col_list):\n    while len(col_list)>0 :\n        model=sm.Logit(dep_var,data_frame[col_list])\n        result=model.fit(disp=0)\n        largest_pvalue=round(result.pvalues,3).nlargest(1)\n        if largest_pvalue[0]<(0.05):\n            return result\n            break\n        else:\n            col_list=col_list.drop(largest_pvalue.index)\n\nresult=back_feature_elem(heart_df_constant,heart_df.TenYearCHD,cols)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Interpreting the results: Odds Ratio, Confidence Intervals and Pvalues\n\nparams = np.exp(result.params)\nconf = np.exp(result.conf_int())\nconf['OR'] = params\npvalue=round(result.pvalues,3)\nconf['pvalue']=pvalue\nconf.columns = ['CI 95%(2.5%)', 'CI 95%(97.5%)', 'Odds Ratio','pvalue']\nprint ((conf))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**#Splitting data to train and test split**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport sklearn\nnew_features=heart_df[['age','Sex_male','cigsPerDay','totChol','sysBP','glucose','TenYearCHD']]\nx=new_features.iloc[:,:-1]\ny=new_features.iloc[:,-1]\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20,random_state=5)\n\nfrom sklearn.linear_model import LogisticRegression\nlogreg=LogisticRegression()\nlogreg.fit(x_train,y_train)\ny_pred=logreg.predict(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**#Confusion matrix**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn import metrics\nconfusion_matrix = metrics.confusion_matrix(y_test,y_pred)\nprint(confusion_matrix)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**#Model accuracy**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsklearn.metrics.accuracy_score(y_test,y_pred)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}