{"cells":[{"metadata":{},"cell_type":"markdown","source":"# I. Introduction\nNowadays, companies are increasingly aware of the importance of subscription services, and the churn rate is a critical indicator to track the health of a subscription-based company. To be more precise, the company can take measures in advance by predicting the customer churn rate to retain customers consistently. Therefore, this project goal is to make a churn prediction so that Telco can optimize products and services proactively."},{"metadata":{},"cell_type":"markdown","source":"# II. Data Description\nThe raw data contains 7043 rows (customers) and 21 columns (features).\n* customer ID: Customer ID\n* gender: Whether the customer is a male or a female\n* SeniorCitizen: Whether the customer is a senior citizen or not (1, 0)\n* Partner: Whether the customer has a partner or not (Yes, No)\n* Dependents: Whether the customer has dependents or not (Yes, No)\n* tenure: Number of months the customer has stayed with the company\n* PhoneService: Whether the customer has a phone service or not (Yes, No)\n* MultipleLines: Whether the customer has multiple lines or not (Yes, No, No phone service)\n* InternetService: Customer’s internet service provider (DSL, Fiber optic, No)\n* OnlineSecurity: Whether the customer has online security or not (Yes, No, No internet service)\n* OnlineBackup: Whether the customer has online backup or not (Yes, No, No internet service)\n* DeviceProtection: Whether the customer has device protection or not (Yes, No, No internet service)\n* TechSupport: Whether the customer has tech support or not (Yes, No, No internet service)\n* StreamingTV: Whether the customer has streaming TV or not (Yes, No, No internet service)\n* StreamingMovies: Whether the customer has streaming movies or not (Yes, No, No internet service)\n* Contract: The contract term of the customer (Month-to-month, One year, Two year)\n* PaperlessBilling: Whether the customer has paperless billing or not (Yes, No)\n* PaymentMethod: The customer’s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))\n* MonthlyCharges: The amount charged to the customer monthly\n* TotalCharges: The total amount charged to the customer\n* Churn: Whether the customer churned or not (Yes or No)"},{"metadata":{},"cell_type":"markdown","source":"# III. Data Collection"},{"metadata":{},"cell_type":"markdown","source":" ### 1. Importing Modules"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# data preprocessing\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n\n# plot\nimport seaborn as sns \nsns.set_style('whitegrid') \n\nimport matplotlib.pyplot as plt \nplt.style.use('seaborn-white')\nfrom mpl_toolkits.mplot3d import Axes3D \n!pip install chart-studio\nimport chart_studio.plotly as py\nfrom plotly import __version__\n\nimport graphviz","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Loading Dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# loading dataset\ndf = pd.read_csv(\"../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. About the Data\nThis dataset has 7,043 samples and 21 attributes(2 integer, 1 float, and 18 objects)\n* Target Feature: Churn\n* Numeric Features: Tenure, MonthlyCharges, and TotalCharges\n* Categorical Features: CustomerID, Gender, SeniorCitizen, Partner, Dependents, PhoneService, MulitpleLines, InternetService, OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV, StreamingMovies, Contract, PaperlessBilling, PaymentMethod"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* From the summary table below, we may infer that the feature TotalCharges has some **missing values**."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Data Reshaping\n* Rename the features 'tenure' and 'gender'\n* Convert the feature 'TotalCharges' to numerical data type\n* Converting the feature 'SeniorCitizen' to object data type"},{"metadata":{"trusted":true},"cell_type":"code","source":"# renaming 'tenure' and 'gender'\ndf = df.rename(columns={'tenure': 'Tenure', 'gender': 'Gender'})\n\n# converting 'TotalCharges' to numerical data type\ndf['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce', downcast='float')\n\n# converting 'SeniorCitizen' to object data type\ndf['SeniorCitizen'] = df['SeniorCitizen'].astype(np.object)\n\n# check\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# IV. Exploratory Data Analysis(EDA)"},{"metadata":{},"cell_type":"markdown","source":"### 1. Target Variable\n(1) Churn: Customer churn rate of Telco from this dataset is 27%, implying this is an ****imbalanced dataset****."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pie chart of churn\nchurn_rate = df.Churn.value_counts() / len(df.Churn)\nlabels = 'Non-Churn', 'Churn'\n\nfig, ax = plt.subplots()\nax.pie(churn_rate, labels=labels, autopct='%.f%%')  \nax.set_title('Churn vs Non Churn', fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Numeric Features\n(1) Tenure: Customer with less tenure is more likely to churn.\n\n(2) Monthly Charges: Customer with low monthly charges is less likely to churn; however, the churn trend between churn customers and non-churn customers gets similar as monthly charges go up.\n\n(3) Total Charges: The distribution is similar for both churn customers and non-churn customers, implying that the feature Monthly Charges may not be a good predictor."},{"metadata":{"trusted":true},"cell_type":"code","source":"# numerical features grouped by churn\nfor col in ['Tenure', 'MonthlyCharges', 'TotalCharges']:\n    fig = plt.figure(figsize=(8,5))\n    sns.distplot(df[df.Churn == 'No'][col],\n                 bins=10,\n                 color='orange',\n                 label='Non-Churn',\n                 kde=True)\n    sns.distplot(df[df.Churn == 'Yes'][col],\n                 bins=10,\n                 color='blue',\n                 label='Churn',\n                 kde=True)\n    plt.legend(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(4) Outliers: The box plots show there is **no outliers** in this data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"# check outliers\nfor col in ['Tenure', 'MonthlyCharges', 'TotalCharges']:\n    fig = plt.figure(figsize=(8,3))\n    sns.boxplot(df[col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(4) Skewness: The density plots show they are **not normal distributions**."},{"metadata":{"trusted":true},"cell_type":"code","source":"# distribution\nfor col in ['Tenure', 'MonthlyCharges', 'TotalCharges']:\n    fig = plt.figure(figsize=(8,3))\n    sns.kdeplot(df[col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(6) Correlation: The correlation matrix plot shows that these numeric features have a positive relationship."},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation between numerical features\nplt.figure(figsize=(10, 8))\nfeature_corr = df.corr()\nsns.heatmap(feature_corr, annot=True, cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Categorical Features\n\n(1) Gender: The churn rate is similar between male and female, indicating **Gender may not be a good predictor**.\n\n(2) Senior Citizen: Customer who is senior citizen is more likely to churn.\n\n(2) Partner: Customer who does not have partner is more likely to churn.\n\n(3) Dependents: Customer who does have dependents is more likely to churn."},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['Gender', 'SeniorCitizen', 'Partner', 'Dependents']:\n    plt.figure(figsize=(8,5))\n    sns.countplot(x=col, hue='Churn', data=df, palette=\"tab10\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(4) Phone Service: PhoneService is a **redundant feature** since we can get the same information from teh feature Multiple Lines. So, we could drop this column.\n\n(5) Multiple Lines: Customer who has multiple lines is slightly more likely to churn."},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['PhoneService', 'MultipleLines']:\n    plt.figure(figsize=(8,5))\n    sns.countplot(x=col, hue='Churn', data=df, palette=\"tab10\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(6) Internet Service: If customer's Internet service provider is Fiber optic, then he/she is more likely to churn.\n\n(7) Online Security: Customer who does not have online security is more likely to churn.\n\n(8) Online Backup: Customer who does not have online backup is more likely to churn.\n\n(9) Device Protection: Customer who does not have device protection is more likely to churn.\n\n(10) Tech Support: Customer who does not have tech support is more likely to churn.\n\n(11) Streaming TV / Streaming Movies: Streaming TV and Streaming Movies have no big effect on churn rate; however, if customer does not have internet service, then he/she is less likely to churn."},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n            'TechSupport','StreamingTV', 'StreamingMovies']:\n    plt.figure(figsize=(8,5))\n    sns.countplot(x=col, hue='Churn', data=df, palette=\"tab10\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(12) Paper less Billing: Customer who has paperless billing is more likely to churn.\n\n(13) Payment Method: Customer who uses electronic check to pay bills is more likely to churn than those who using other payment methods.\n\n(14) Contract: The churn rate goes down as the length of contract increases."},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['PaperlessBilling', 'PaymentMethod', 'Contract',]:\n    plt.figure(figsize=(8,5))\n    sns.countplot(x=col, hue='Churn', data=df, palette=\"tab10\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# V. Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"### 1. Removing Duplicates\nThere is no repeated value in this data set."},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize duplicates\nsum(df.duplicated('customerID'))\n#df2 = df.drop_duplicates('customerID')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Droping Unnecessary Columns\n\nRemove the useless feature customerID."},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove customerID and PhoneService\ndf2 = df.drop(['customerID'], axis = 1)\ndf2.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Categorical Data Encoding\n\nEncode categorical variables, we use One-Hot Encoding for nominal variables and Label Encoding for ordinal variables.\n\n* One-Hot Encoding: Gender, Partner, Dependents, MultipleLines, InternetService, OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV, StreamingMovies, PaperlessBilling, PaymentMethod, Churn\n\n* Label Encoding: Contract"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dummy Variables(One-Hot Encoding)\nGender = pd.get_dummies(df2['Gender'], prefix='Genger', drop_first=True)\nPartner = pd.get_dummies(df2['Partner'], prefix='Partner', drop_first=True)\nDependents = pd.get_dummies(df2['Dependents'], prefix='Dependents', drop_first=True)\nMultipleLines = pd.get_dummies(df2['MultipleLines'], prefix='MultipleLines', drop_first=True)\nInternetService = pd.get_dummies(df2['InternetService'], prefix='InternetService', drop_first=True)\nOnlineSecurity = pd.get_dummies(df2['OnlineSecurity'], prefix='OnlineSecurity', drop_first=True)\nOnlineBackup = pd.get_dummies(df2['OnlineBackup'], prefix='OnlineBackup', drop_first=True)\nDeviceProtection = pd.get_dummies(df2['DeviceProtection'], prefix='DeviceProtection', drop_first=True)\nTechSupport = pd.get_dummies(df2['TechSupport'], prefix='TechSupport', drop_first=True)\nStreamingTV = pd.get_dummies(df2['StreamingTV'], prefix='StreamingTV', drop_first=True)\nStreamingMovies = pd.get_dummies(df2['StreamingMovies'], prefix='StreamingMovies', drop_first=True)\nPaperlessBilling = pd.get_dummies(df2['PaperlessBilling'], prefix='PaperlessBilling', drop_first=True)\nPaymentMethod = pd.get_dummies(df2['PaymentMethod'], prefix='PaymentMethod', drop_first=True)\nChurn = pd.get_dummies(df2['Churn'], prefix='Churn', drop_first=True)\nPaymentMethod = pd.get_dummies(df2['PhoneService'], prefix='PhoneService', drop_first=True)\n\n\ndf3 = pd.concat([df2, Gender, Partner, Dependents, MultipleLines, InternetService, \n                 OnlineSecurity, OnlineBackup, DeviceProtection, TechSupport, StreamingTV, \n                 StreamingMovies, PaperlessBilling, PaymentMethod, Churn], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Label Encoding\nfrom sklearn import preprocessing\nlabel_encoder = preprocessing.LabelEncoder()\ndf3['Contract']= label_encoder.fit_transform(df3['Contract']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop original columns\nlist = ['Gender', 'Partner', 'Dependents', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling', \n'PaymentMethod', 'Churn', 'Contract', 'PhoneService']\ndf3.drop(df3[list], axis=1, inplace=True)\ndf3.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Splitting the Data into Training Set(70%) and Test Set(30%)\nWe split the data in 70:30 ratio so that 70% of the data will be used for training the model while 30% will be used for testing the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# train test split\nfrom sklearn.model_selection import train_test_split # split dataset\nX_train, X_test, y_train, y_test = train_test_split(df3.drop('Churn_Yes',axis=1),df3['Churn_Yes'],test_size=0.3,random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check\nfor i in [X_train, X_test, y_train, y_test]:\n    i.index = range(i.shape[0]) \n    print(i.index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. Identifying Missing Values\n\nFor training set, the feature TotalCharges has **null/missing values**, so we can impute the missing values and replace them with average."},{"metadata":{"trusted":true},"cell_type":"code","source":"#summarize missing values - X_train\nX_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill missing value w/ mean \nX_train['TotalCharges'].fillna(value=X_train['TotalCharges'].mean(), inplace=True)\n# check missing values\nX_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#summarize missing values - y_train\ny_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#summarize missing values - X_test\nX_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill missing value w/ mean \nX_test['TotalCharges'].fillna(value=X_test['TotalCharges'].mean(), inplace=True)\n# check missing values\nX_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#summarize missing values - y_test\ny_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6. Identifying Outliers\n\nThe training data set does not have outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"# check outliers\nfor col in ['Tenure', 'MonthlyCharges', 'TotalCharges']:\n    fig = plt.figure(figsize=(8,3))\n    sns.boxplot(X_train[col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 7. Feature Scaling - Standardization / Normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Standardization\nstandard_scaler = preprocessing.StandardScaler().fit(X_train)\nX_train_standard = standard_scaler.transform(X_train)\nX_test_standard = standard_scaler.transform(X_test)\n\n#from sklearn.preprocessing import StandardScaler\n#scaler_s = StandardScaler() \n#data_standard_scaled = scaler_s.fit_transform(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalization\nminmax_scaler = preprocessing.MinMaxScaler().fit(X_train)\nX_train_minmax = minmax_scaler.transform(X_train)\nX_test_minmax = minmax_scaler.transform(X_test)\n\n#from sklearn.preprocessing import MinMaxScaler\n#scaler_m = MinMaxScaler() \n#data_normal_scaled = scaler_m.fit_transform(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VI. Model Building & Evaluation"},{"metadata":{},"cell_type":"markdown","source":"## 1. Logistic Regression "},{"metadata":{},"cell_type":"markdown","source":"Since this is an imbalanced dataset, we decide to use weighted logistic regression."},{"metadata":{"trusted":true},"cell_type":"code","source":"# training \nfrom sklearn.linear_model import LogisticRegression\nlm = LogisticRegression(random_state=0, max_iter=1000, solver='lbfgs', class_weight='balanced')\nlm.fit(X_train_standard, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting\ny_pred = lm.predict(X_test_standard)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluation\nfrom sklearn.metrics import classification_report \nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# performance matrix\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score ,recall_score, roc_auc_score\naccuracy = round(accuracy_score(y_test, y_pred),2)\nf1_score = round(f1_score(y_test, y_pred),2)\nprecision = round(precision_score(y_test, y_pred),2)\nrecall = round(recall_score(y_test, y_pred),2)\ny_prob_scores_test = lm.predict_proba(X_test_standard)[:,1]\nauc_score = round(roc_auc_score(y_test, y_prob_scores_test),2)\n\n#logis\nfrom astropy.table import Table\ndict1 = [{'accuracy': accuracy, 'f1_score': f1_score, 'precision': precision, 'recall': recall, 'auc_score': auc_score}]\nlogis_matrix = Table(rows=dict1)\nprint(logis_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# roc plot\nfrom sklearn.metrics import plot_roc_curve\nfig,ax = plt.subplots(figsize=(7,7))\nplot_roc_curve(lm, X_test_standard, y_test, ax = ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. K Nearest Neighbors "},{"metadata":{},"cell_type":"markdown","source":"#### Data Transformation: Normalization (Min-Max Scalar) "},{"metadata":{"trusted":true},"cell_type":"code","source":"# training and predicting\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train_minmax,y_train)\ny_pred = knn.predict(X_test_minmax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluation\nfrom sklearn.metrics import classification_report \nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# performance matrix\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score ,recall_score, roc_auc_score\naccuracy = round(accuracy_score(y_test, y_pred),2)\nf1_score = round(f1_score(y_test, y_pred),2)\nprecision = round(precision_score(y_test, y_pred),2)\nrecall = round(recall_score(y_test, y_pred),2)\ny_prob_scores_test = knn.predict_proba(X_test_minmax)[:,1]\nauc_score = round(roc_auc_score(y_test, y_prob_scores_test),2)\n\n# knn\nfrom astropy.table import Table\ndict2 = [{'accuracy': accuracy, 'f1_score': f1_score, 'precision': precision, 'recall': recall, 'auc_score': auc_score}]\nknn_matrix = Table(rows=dict2)\nprint(knn_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# roc plot\nfrom sklearn.metrics import plot_roc_curve\nfig,ax = plt.subplots(figsize=(7,7))\nplot_roc_curve(knn, X_test_minmax, y_test, ax = ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"# training and predicting\nfrom sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier(random_state=0, max_depth=5)\nclf.fit(X_train,y_train)\ny_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluation\nfrom sklearn.metrics import classification_report \nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# performance matrix\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score ,recall_score, roc_auc_score\naccuracy = round(accuracy_score(y_test, y_pred),2)\nf1_score = round(f1_score(y_test, y_pred),2)\nprecision = round(precision_score(y_test, y_pred),2)\nrecall = round(recall_score(y_test, y_pred),2)\ny_prob_scores_test = clf.predict_proba(X_test)[:,1]\nauc_score = round(roc_auc_score(y_test, y_prob_scores_test),2)\n\n# knn\nfrom astropy.table import Table\ndict3 = [{'accuracy': accuracy, 'f1_score': f1_score, 'precision': precision, 'recall': recall, 'auc_score': auc_score}]\ntree_matrix = Table(rows=dict3)\nprint(tree_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# roc plot\nfrom sklearn.metrics import plot_roc_curve\nfig,ax = plt.subplots(figsize=(7,7))\nplot_roc_curve(clf, X_test, y_test, ax = ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\nfrom sklearn.tree import export_graphviz\ndot_data = tree.export_graphviz(clf, out_file=None, \n                                feature_names=X_train.columns,\n                                class_names='Churn_Yes',\n                                filled=True,\n                                max_depth=3)\n\ngraph = graphviz.Source(dot_data, format=\"png\") \n\ngraph","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = clf.feature_importances_\nweights = pd.Series(importances,index=X_train.columns.values)\nweights.sort_values()[-10:].plot(kind = 'barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"# training and predicting\nfrom sklearn.ensemble import RandomForestClassifier\nforest = RandomForestClassifier()\nforest.fit(X_train, y_train)\ny_pred = forest.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluation\nfrom sklearn.metrics import classification_report \nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# performance matrix\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score ,recall_score, roc_auc_score\naccuracy = round(accuracy_score(y_test, y_pred),2)\nf1_score = round(f1_score(y_test, y_pred),2)\nprecision = round(precision_score(y_test, y_pred),2)\nrecall = round(recall_score(y_test, y_pred),2)\ny_prob_scores_test = forest.predict_proba(X_test)[:,1]\nauc_score = round(roc_auc_score(y_test, y_prob_scores_test),2)\n\n# knn\nfrom astropy.table import Table\ndict4 = [{'accuracy': accuracy, 'f1_score': f1_score, 'precision': precision, 'recall': recall, 'auc_score': auc_score}]\nforest_matrix = Table(rows=dict4)\nprint(tree_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# roc plot\nfrom sklearn.metrics import plot_roc_curve\nfig,ax = plt.subplots(figsize=(7,7))\nplot_roc_curve(forest, X_test, y_test, ax = ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = forest.feature_importances_\nweights = pd.Series(importances,index=X_train.columns.values)\nweights.sort_values()[-10:].plot(kind = 'barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VII. Conclusion"},{"metadata":{},"cell_type":"markdown","source":"Based on the performance metrics below, the best model is Logistic Regression with F1-score of 62% and auc score of 0.84."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('logistic regression')\nprint(logis_matrix)\nprint('knn')\nprint(knn_matrix)\nprint('decision tree')\nprint(tree_matrix)\nprint('random forest')\nprint(forest_matrix)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}