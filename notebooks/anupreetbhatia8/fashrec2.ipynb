{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom keras.applications import vgg16\nfrom keras.preprocessing.image import load_img,img_to_array\nfrom keras.models import Model\nfrom keras.applications.imagenet_utils import preprocess_input\n\n\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport pandas as pd\nimport numpy as np # linear algebra\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd /kaggle/input/fashion-product-images-dataset/fashion-dataset/fashion-dataset/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sdf=pd.read_csv('styles.csv',error_bad_lines=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sdf['articleType']=sdf['articleType'].str.lower()\nsdf['id']=sdf['id'].astype(str)\nsdf=sdf[sdf['articleType'].str.find('shirt')==True]\nsdf=sdf.reset_index()\nsdf.drop(columns=['index'],inplace=True)\nsdf.dropna(subset=['season'],inplace=True)\nsdf['season'].unique()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(sdf['id'][0])\nimage_list=list(sdf['id'])\nimgs_path = \"/kaggle/input/fashion-product-images-dataset/fashion-dataset/fashion-dataset/images/\"\nimgs_model_width, imgs_model_height = 224, 224\nnb_closest_images = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files=[]\nfor x in image_list:\n  files.append(imgs_path+x+\".jpg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files=files[0:3000]\ntop_images=pd.DataFrame(files[-200:],columns=['image_id'])\n# top_images.to_csv('top_images.csv',index=False)\nprint(len(files))\nprint(len(top_images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"original = load_img(files[9], target_size=(imgs_model_width, imgs_model_height))\nplt.imshow(original)\nplt.show()\nprint(\"Image loaded successfully!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the model\nvgg_model = vgg16.VGG16(weights='imagenet')\n\n# remove the last layers in order to get features instead of predictions\nfeat_extractor = Model(inputs=vgg_model.input, outputs=vgg_model.get_layer(\"fc2\").output)\n\n# print the layers of the CNN\nfeat_extractor.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numpy_image = img_to_array(original)\n# convert the image / images into batch format\n# expand_dims will add an extra dimension to the data at a particular axis\n# we want the input matrix to the network to be of the form (batchsize, height, width, channels)\n# thus we add the extra dimension to the axis 0.\nimage_batch = np.expand_dims(numpy_image, axis=0)\nprint('Image Batch size', image_batch.shape)\n\n# prepare the image for the VGG model\nprocessed_image = preprocess_input(image_batch.copy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_features = feat_extractor.predict(processed_image)\n\nprint(\"Features successfully extracted for one image!\")\nprint(\"Number of image features:\",img_features.size)\nimg_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importedImages = []\n\nfor f in files:\n    filename = f\n    original = load_img(filename, target_size=(224, 224))\n    numpy_image = img_to_array(original)\n    image_batch = np.expand_dims(numpy_image, axis=0)\n    \n    importedImages.append(image_batch)\n    \nimages = np.vstack(importedImages)\n\nprocessed_imgs = preprocess_input(images.copy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_images.to_csv('/kaggle/working/top_images.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd /kaggle/input/fashion-product-images-dataset/fashion-dataset/fashion-dataset/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs_features = feat_extractor.predict(processed_imgs)\n\nprint(\"features successfully extracted!\")\nimgs_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cosSimilarities = cosine_similarity(imgs_features)\n\n# store the results into a pandas dataframe\n\ncos_similarities_df = pd.DataFrame(cosSimilarities, columns=files, index=files)\ncos_similarities_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cos_similarities_df.to_csv(\"/kaggle/working/cos_similarity.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd /kaggle/input/fashion-product-images-dataset/fashion-dataset/fashion-dataset/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to retrieve the most similar products for a given one\ndef retrieve_most_similar_products(given_img):\n\n    print(\"-----------------------------------------------------------------------\")\n    print(\"original product:\")\n\n    original = load_img(given_img, target_size=(imgs_model_width, imgs_model_height))\n    plt.imshow(original)\n    plt.show()\n\n    print(\"-----------------------------------------------------------------------\")\n    print(\"most similar products:\")\n\n    closest_imgs = cos_similarities_df[given_img].sort_values(ascending=False)[1:nb_closest_images+1].index\n    closest_imgs_scores = cos_similarities_df[given_img].sort_values(ascending=False)[1:nb_closest_images+1]\n\n    for i in range(0,len(closest_imgs)):\n        original = load_img(closest_imgs[i], target_size=(imgs_model_width, imgs_model_height))\n        plt.imshow(original)\n        plt.show()\n        print(\"similarity score : \",closest_imgs_scores[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"retrieve_most_similar_products(top_images['image_id'][16])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"retrieve_most_similar_products(top_images['image_id'][81])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"retrieve_most_similar_products(top_images['image_id'][47])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"retrieve_most_similar_products(top_images['image_id'][60])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"retrieve_most_similar_products(top_images['image_id'][168])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"retrieve_most_similar_products(top_images['image_id'][77])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}