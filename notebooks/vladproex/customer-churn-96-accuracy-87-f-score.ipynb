{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Kaggle Datasets - Predict credit card customer churn. "},{"metadata":{},"cell_type":"markdown","source":"### https://www.kaggle.com/sakshigoyal7/credit-card-customers"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Load the data, split training and test sets. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/credit-card-customers/BankChurners.csv')\n#remove last two cols\ndf = df.iloc[:, :-2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encode target variable. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['target'] = (df['Attrition_Flag'] == 'Attrited Customer').astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classes on target variable are imbalanced. We will use stratified sampling. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df.drop(['Attrition_Flag', 'target'], axis=1)\ny = df['target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Make sure we have the same proportion of positives and negatives in training and testing. "},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.value_counts() / len(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.value_counts() / len(y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ok, the test set and the training set have the same proportion of positive examples. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_positives_prop(series):\n    return sum(series == 'Attrited Customer') / len(series)\n\ndiff = get_positives_prop(y_train) - get_positives_prop(y_test)\nassert abs(diff) < 0.001","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Exploratory Data Analysis with Pandas Profiling. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_eda = pd.concat((X_train, y_train), axis=1)\ndf_eda.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas_profiling\nimport os.path\n\nprofile = df_eda.profile_report()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profile","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Data processing. "},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinals = {\n    'Education_Level': ['Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate'],\n    'Income_Category': ['Less than $40K', '$40K - $60K', '$60K - $80K', '$80K - $120K', '$120K +'],\n    'Card_Category': ['Blue', 'Silver', 'Gold', 'Platinum']\n}\n\ndef encode_ordinals(df, ordinals):\n    sel = df.copy()\n    for var, values in ordinals.items():\n        sel[var] = sel[var].apply(lambda x: values.index(x) + 1\n                                  if x is not np.nan else x)\n    return sel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split our variables\n\ncat_vars = ['Gender', 'Marital_Status']\n\nord_vars = ['Education_Level', 'Income_Category', 'Card_Category']\n\nquant_vars = ['Customer_Age', 'Dependent_count', 'Months_on_book', 'Total_Relationship_Count',\n             'Months_Inactive_12_mon', 'Contacts_Count_12_mon', 'Credit_Limit',\n             'Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1',\n             'Total_Trans_Amt', 'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make sure we haven't missed any variable\n[col for col in X_train.columns\nif col not in cat_vars + ord_vars + quant_vars]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_pipeline(X):\n    \n    #identify NaNs\n    X = X.replace('Unknown', np.nan)\n    \n    #recode ordinals \n    X = encode_ordinals(X, ordinals)\n    \n    #select vars\n    X_cat = X[cat_vars]\n    X_ord = X[ord_vars]\n    X_quant = X[quant_vars]\n    \n    #fill NaNs\n    from sklearn.impute import SimpleImputer\n    \n    cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n    ord_imputer = SimpleImputer(strategy=\"median\")\n    quant_imputer = SimpleImputer(strategy=\"median\")\n    \n    X_cat = cat_imputer.fit_transform(X_cat)\n    X_ord = ord_imputer.fit_transform(X_ord)\n    X_quant = quant_imputer.fit_transform(X_quant)\n    \n    #encode categorical vars\n    from sklearn.preprocessing import OneHotEncoder\n    one_hot_encoder = OneHotEncoder()\n    X_cat = one_hot_encoder.fit_transform(X_cat).toarray()\n    \n    params = [cat_imputer, ord_imputer, quant_imputer, one_hot_encoder]\n    X_prep = np.concatenate([X_cat, X_ord, X_quant], axis=1)\n    \n    return X_prep, params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_pipeline(X, params):\n    \n    cat_imputer, ord_imputer, quant_imputer, one_hot_encoder = params\n    \n    #identify NaNs\n    X = X.replace('Unknown', np.nan)\n    \n    #recode ordinals \n    X = encode_ordinals(X, ordinals)\n    \n    #select vars\n    X_cat = X[cat_vars]\n    X_ord = X[ord_vars]\n    X_quant = X[quant_vars]\n    \n    #fill NaNs\n    X_cat = cat_imputer.transform(X_cat)\n    X_ord = ord_imputer.transform(X_ord)\n    X_quant = quant_imputer.transform(X_quant)\n    \n    #encode categorical vars\n    X_cat = one_hot_encoder.transform(X_cat).toarray()\n    X_prep = np.concatenate([X_cat, X_ord, X_quant], axis=1)\n    \n    return X_prep","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build a model. "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"X_train_prep, params = train_pipeline(X_train)\nX_test_prep = test_pipeline(X_test, params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_prep.shape, X_test_prep.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.metrics import make_scorer\n\nscorer = make_scorer(f1_score)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nparams = {\n    'min_samples_leaf': [1, 2, 4, 6, 8, 10, 12],\n    'n_estimators': [120, 130, 140, 150, 160, 170]\n}\n\nrfc = RandomForestClassifier(random_state=42)\n\nrfc_grid = GridSearchCV(rfc, \n                        params,\n                        scoring=scorer,)\n\nrfc_grid.fit(X_train_prep, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(**rfc_grid.best_params_, random_state=42)\nrfc.fit(X_train_prep, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(rfc, X_train_prep, y_train, cv=5, verbose=2, scoring=scorer)\nprint(scores)\nprint(scores.mean(), scores.std())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Final accuracy and F1 score. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ny_test_pred = rfc.predict(X_test_prep)\naccuracy_score(y_test_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = rfc.predict(X_test_prep)\nf1_score(y_test_pred, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature importances. "},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's get the index of every feature in our decision trees\n#our categorical features are one hot encoded, so our model sees them as multiple features\n\nfeatures ={'Gender': [0, 1],\n           'Marital_Status': [2, 3, 4]\n          }\n\nstart = 5 \n\nfor feat in ord_vars + quant_vars:\n    features[feat] = [start]\n    start += 1\n    \nprint(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we sum the importances of the one hot encoded features\n\nfeat_importances = [(feature, sum([rfc.feature_importances_[index] \n                  for index in indexes]))\n                    for feature, indexes in features.items()]\n\nfeat_importances = sorted(feat_importances, key=lambda x: x[1], reverse=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn-whitegrid')\n\nfeatures, importances = zip(*feat_importances)\n\ny_pos = np.arange(len(features))\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\nax.barh(y_pos, importances, align='center')\nax.set_yticks(y_pos)\nax.set_yticklabels(features)\nax.invert_yaxis()  # labels read top-to-bottom\nax.set_xlabel('Importance')\nax.set_title('Feature Importances')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}