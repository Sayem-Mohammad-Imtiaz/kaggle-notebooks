{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Метрические методы классификации**"},{"metadata":{},"cell_type":"markdown","source":"*1 Методы ближайших соседей\n\nВ этой части работы вы:\n\n• научитесь готовить данные к построению модели (предобработка, или препро-\nцессинг данных);\n\n• познакомитесь с методами ближайших соседей для задач классификации и\nрегрессии, реализованными в библиотеке scikit-learn ;\n• научитесь оценивать качество модели с помощью отложенной выборки.*"},{"metadata":{},"cell_type":"markdown","source":"Указания к выполнению\n1. Подключитесь к одному из наборов данных на Kaggle. Разберитесь в том, как устроен ваш датасет и какова постановка задачи."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(rc={'figure.figsize':(10, 8)});","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":" df = pd.read_csv('../input/bank-marketing-dataset/bank.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Это классический набор данных маркетингового банка, изначально загруженный в репозиторий машинного обучения UCI. Набор данных дает нам информацию о маркетинговой кампании финансового учреждения, которую нам нужно будет проанализировать, чтобы найти способы поиска будущих стратегий для улучшения будущих маркетинговых компаний для банка."},{"metadata":{},"cell_type":"markdown","source":"Целевая переменная deposit-принимает значения да или нет.\n\nЗадача классификации: выяснить, что клиент возьмет депозит."},{"metadata":{},"cell_type":"markdown","source":"2. Извлеките целевой признак (target). Какая из задач обучения с учителем рассматривается – классификация или регрессия?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['deposit']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Имеем конечное количество \"yes\" и \"no\". отсюда следует, что из задач обучения с учителем рассматривается – классификация."},{"metadata":{},"cell_type":"markdown","source":"3. Каково распределение значений target-переменной? Постройте подходящую визуализацию. Прокомментируйте результат."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['deposit'].value_counts().plot(kind = 'bar', color = 'green')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Классы почти сбалансированы, так как количество \"no\"совсем немного превышает\"yes\"."},{"metadata":{},"cell_type":"markdown","source":"4. Проведите необходимую предобработку данных (preprocessing). Для построения моделей с помощью метрических методов все признаки должны быть закодированы числами. Полезными будут следующие методы библиотеки Pandas:\n\n• map() –– для перекодировки категориальной переменной числовыми метками;\n\n• get_dummies() –– для создания нескольких бинарных признаков на основе категориального.\nТакже может потребоваться масштабирование данных (scaling). Воспользуйтесь\nклассом StandardScaler библиотеки Scikit-learn."},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('/kaggle/input/bank-marketing-dataset/bank.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf1 = pd.get_dummies(df, columns=['deposit','job', 'education', 'marital', 'contact', 'poutcome', 'month', 'loan', 'housing', 'default'])\ndf1['deposit']=df['deposit'].map({'no':0,'yes':1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df1.drop(['deposit'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5. Разбейте набор данных на обучающую и валидационную (тестовую) выборки с помощью метода train_test_split ."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Создание X, y\n# X --- вся таблица без таргета\n# y --- таргет (целевая переменная)\nX=df1.drop('deposit', axis=1)\ny =df1['deposit']\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"6. Обучите алгоритм классификации kNeighborsClassifier или регрессии KNeighborsRegressor . Оцените качество каждой модели на валидационной выборке с помощью\n• accuracy_score для классификации;\n• mean_squared_error для регрессии.\nСравните результаты и сделайте выводы."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier(n_neighbors=5)\nneigh.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neigh.score(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neigh.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.neighbors import KNeighborsRegressor\n# neigh = KNeighborsRegressor(n_neighbors=5)\n# neigh.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# neigh.score(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = neigh.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nneigh.score(X_valid, y_valid) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Качество модели:', accuracy_score(y_pred, y_valid)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Мы получаем практически идентичный результат, следственно это является  лучшим результатом."},{"metadata":{},"cell_type":"markdown","source":"2 Настройка оптимального числа ближайших соседей в методе kNN"},{"metadata":{},"cell_type":"markdown","source":"В данной части работы вы научитесь настраивать параметр n_neighbors алгоритма kNN с помощью перекрёстной проверки (кросс-валидации)."},{"metadata":{},"cell_type":"markdown","source":"Указания к выполнению\n\n1. Создайте генератор разбиений, который перемешивает выборку перед созданием блоков ( shuffle=True ). Число блоков n_splits равно 5. Задайте также параметр random_state для воспроизводимости результатов. \nНапример: kf = KFold(n_splits=5, shuffle=True, random_state=42)\n\nНайдите показатель качества модели kNN на кросс-валидации. Подумайте, приемлемо ли использование вашей меры (метрики) качества в данной задаче? При необходимости пересчитайте качество с помощью другой метрики из списка."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42) # n_splits играет роль K\nscores = cross_val_score(neigh, X, y, cv=kf, scoring='accuracy')\nprint('Массив значений метрики:', scores)\nprint('Средняя метрика на кросс-валидации:', np.mean(scores))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Осуществите кросс-валидацию модели при числе соседей k ∈ [1;50]. Используйте GridSearchCV . При каком k качество получилось наилучшим? Чему равна эта оценка качества? Постройте график значений метрики в зависимости от k\n( matplotlib.pyplot.plot() )."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nneigh_params={'n_neighbors': np.arange(1, 50)} \nneigh_grid = GridSearchCV(neigh, neigh_params, cv=kf, scoring='accuracy') # кросс-валидация по 5 блокам\nneigh_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Смотрим лучшие значения параметров\nprint(neigh_grid.best_params_)\n\n# Лучшая модель\nprint(neigh_grid.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(neigh_grid.cv_results_).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nresults_df = pd.DataFrame(neigh_grid.cv_results_)\nplt.plot(results_df['param_n_neighbors'], results_df['mean_test_score'])\n\n# Подписываем оси и график\nplt.xlabel('Number of neighbors')\nplt.ylabel('Test accuracy')\nplt.title('Validation curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3 Выбор метрики в методе kNN\n\nГлавным параметром любого метрического алгоритма является функция расстояния (метрика), используемая для измерения сходства между объектами. Можно использовать стандартный вариант (например, евклидову метрику), но гораздо более\n\nэффективным вариантом является подбор метрики под конкретную задачу. Один из подходов –– использование той же евклидовой метрики, но с весами: каждой координате ставится в соответствие определенный коэффициент; чем он больше, тем выше вклад признака в итоговое расстояние. Веса настраиваются с целью оптимизации качества на отложенной выборке.\nДругой одход, о котором и пойдет речь в данной части работы –– выбор метрики из некоторого класса метрик. Мы возьмем за основу метрику Минковского\n\nПараметром метрики Минковского является число p, которое мы и будем настраивать."},{"metadata":{"trusted":true},"cell_type":"code","source":"p_params = {\"p\": np.linspace(1,10,200)}\nneigh = KNeighborsClassifier(n_neighbors=5, weights = \"distance\", n_jobs = -1)\ncv = GridSearchCV(neigh, p_params, cv = kf, scoring=\"f1\", verbose = 100)\ncv.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(neigh_grid.cv_results_).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neigh_grid.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neigh_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4 Другие метрические методы\n\nПоэкспериментируйте с другими метрическими методами для задач регрессии и клас-\nсификации, представленными в библиотеке Scikit-learn:\n\n• RadiusNeighborsClassifier ;\n• RadiusNeighborsRegressor ;\n• NearestCentroid ."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import RadiusNeighborsRegressor\nneigh = RadiusNeighborsRegressor(radius=1.0)\nneigh.fit(X, y)\nneigh.fit(X_train, y_train)\nneigh.score(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import NearestCentroid\nclf = NearestCentroid()\nclf.fit(X, y)\nclf.fit(X_train, y_train)\nclf.score(X_valid, y_valid)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}