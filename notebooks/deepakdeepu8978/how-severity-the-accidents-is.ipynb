{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns \nimport matplotlib.pyplot as plt \npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 999\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/us-accidents/US_Accidents_May19.csv')\ntrain_df.shape\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.Source.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"states = train_df.State.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_by_state=[]\nfor i in train_df.State.unique():\n    count_by_state.append(train_df[train_df['State']==i].count()['ID'])\n\nfig,ax = plt.subplots(figsize=(16,10))\nsns.barplot(states,count_by_state)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"this says that California this with high accidents\n\n\nlets go for EDA \n\ncheck for missing values "},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df = train_df.isnull().sum(axis=0).reset_index()\nmissing_df.columns = ['column_name','missing_count']\nmissing_df = missing_df.ix[missing_df['missing_count']>0]\nmissing_df = missing_df.sort_values(by='missing_count')\n\nind = np.arange(missing_df.shape[0])\nwidth = 0.5\nfig,ax = plt.subplots(figsize=(12,18))\nrects = ax.barh(ind,missing_df.missing_count.values,color='blue')\nax.set_yticks(ind)\nax.set_yticklabels(missing_df.column_name.values, rotation='horizontal')\nax.set_xlabel(\"Count of missing values\")\nax.set_title(\"Number of missing values in each column\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"here some data pages with lat and lng"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=train_df.Start_Lat.values,y=train_df.Start_Lng.values,height=10)\nplt.ylabel('Start_Lat', fontsize=12)\nplt.xlabel('Start_Lng', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x=train_df.End_Lat.values,y=train_df.End_Lng.values,height=10)\nplt.ylabel('End_Lat', fontsize=12)\nplt.xlabel('End_Lng', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets check for the top5  Weather Condition for accidents"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax=plt.subplots(figsize=(16,7))\ntrain_df['Weather_Condition'].value_counts().sort_values(ascending=False).head(5).plot.bar(width=0.5,edgecolor='k',align='center',linewidth=2)\nplt.xlabel('Weather_Condition',fontsize=20)\nplt.ylabel('Number of Accidents',fontsize=20)\nax.tick_params(labelsize=20)\nplt.title('5 Top Weather Condition for accidents',fontsize=25)\nplt.grid()\nplt.ioff()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets sapater the datasets based on dtype so that we can make good analysis "},{"metadata":{"trusted":true},"cell_type":"code","source":"dtype_df = train_df.dtypes.reset_index()\ndtype_df.columns = [\"Count\", \"Column Type\"]\ndtype_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtype_df.groupby(\"Column Type\").aggregate('count').reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"get the ratio and the columns with more missing values above 80%"},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_df = train_df.isnull().sum(axis=0).reset_index()\nmissing_df.columns = ['columns_name','missing_count']\nmissing_df['missing_ratio'] = missing_df['missing_count'] /train_df.shape[0]\nmissing_df.loc[missing_df['missing_ratio']>0.777]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missin = missing_df.loc[missing_df['missing_count']>250000]\nremovelist = missin['columns_name'].tolist()\nremovelist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we move on making some changes ... "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Start_Time'] = pd.to_datetime(train_df['Start_Time'], errors='coerce')\ntrain_df['End_Time'] = pd.to_datetime(train_df['End_Time'], errors='coerce')\n\n# Extract year, month, day, hour and weekday\ntrain_df['Year']=train_df['Start_Time'].dt.year\ntrain_df['Month']=train_df['Start_Time'].dt.strftime('%b')\ntrain_df['Day']=train_df['Start_Time'].dt.day\ntrain_df['Hour']=train_df['Start_Time'].dt.hour\ntrain_df['Weekday']=train_df['Start_Time'].dt.strftime('%a')\n\n# Extract the amount of time in the unit of minutes for each accident, round to the nearest integer\ntd='Time_Duration(min)'\ntrain_df[td]=round((train_df['End_Time']-train_df['Start_Time'])/np.timedelta64(1,'m'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neg_outliers=train_df[td]<=0\n\n# Set outliers to NAN\ntrain_df[neg_outliers] = np.nan\n\n# Drop rows with negative td\ntrain_df.dropna(subset=[td],axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_lst=['Source','TMC','Severity','Start_Lng','Start_Lat','Distance(mi)','Side','City','County','State','Timezone','Temperature(F)','Humidity(%)','Pressure(in)', 'Visibility(mi)', 'Wind_Direction','Weather_Condition','Amenity','Bump','Crossing','Give_Way','Junction','No_Exit','Railway','Roundabout','Station','Stop','Traffic_Calming','Traffic_Signal','Turning_Loop','Sunrise_Sunset','Hour','Weekday', 'Time_Duration(min)']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train_df[feature_lst].copy()\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since there are so many variables, let us first take the 'float' variables alone and then get the correlation with the target variable to see how they are related."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_cols = [col for col in df.columns if col not in ['Severity'] if df[col].dtype=='float64']\n\nlabels = []\nvalues = []\nfor col in x_cols:\n    labels.append(col)\n    values.append(np.corrcoef(df[col].values, df.Severity.values)[0,1])\ncorr_df = pd.DataFrame({'col_labels':labels, 'corr_values':values})\ncorr_df = corr_df.sort_values(by='corr_values')\n\nind = np.arange(len(labels))\nwidth = 0.9\nfig, ax = plt.subplots(figsize=(12,40))\nrects = ax.barh(ind, np.array(corr_df.corr_values.values), color='y')\nax.set_yticks(ind)\nax.set_yticklabels(corr_df.col_labels.values, rotation='horizontal')\nax.set_xlabel(\"Correlation coefficient\")\nax.set_title(\"Correlation coefficient of the variables\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The correlation of the target variable with the given set of variables are low overall.\n\nthere are some variable with no correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_zero_columns = ['Turning_Loop','Visibility(mi)','Pressure(in)','Humidity(%)','Temperature(F)','TMC']\nfor col in corr_zero_columns:\n    print(col,len(df[col].unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"get highly correlated columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_df_sel = corr_df.loc[(corr_df['corr_values']>0.05) | (corr_df['corr_values'] < -0.05)]\ncorr_df_sel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_df_ = corr_df_sel.col_labels.tolist()\n\ntem_df = df[corr_df_]\n\ncorrmat = tem_df.corr(method='spearman')\nfig,ax= plt.subplots(figsize=(8,8))\n\nsns.heatmap(corrmat,vmax=1,square = True)\nplt.title('corr map',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets once check for all the vriables "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.gcf()\nfig.set_size_inches(20,20)\nfig=sns.heatmap(df.corr(),annot=True,linewidths=1,linecolor='k',square=True,mask=False, vmin=-1, vmax=1,cbar_kws={\"orientation\": \"vertical\"},cbar=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,10)) \nfig_dims = (3, 2)\n\n\nplt.subplot2grid(fig_dims, (0, 0))\ndf['Amenity'].value_counts().plot(kind='bar', \n                                     title='Amenity')\nplt.subplot2grid(fig_dims, (0, 1))\ndf['Crossing'].value_counts().plot(kind='bar', \n                                     title='Crossing')\nplt.subplot2grid(fig_dims, (1, 0))\ndf['Junction'].value_counts().plot(kind='bar', \n                                     title='Junction')\nplt.subplot2grid(fig_dims, (1, 1))\ndf['Junction'].value_counts().plot(kind='bar', \n                                     title='Junction')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Severity of the accident oue target "},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax=plt.subplots(1,2,figsize=(18,8))\ndf['Severity'].value_counts().plot.pie(explode=[0,0.1,0.1,0.1,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Percentage Severity Distribution')\nax[0].set_ylabel('Count')\nsns.countplot('Severity',data=df,ax=ax[1],order=df['Severity'].value_counts().index)\nax[1].set_title('Count of Severity')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.boxplot(x=\"Severity\", y=\"Wind_Chill(F)\", data=train_df)\nplt.ylabel('Wind_Chill(F)', fontsize=12)\nplt.xlabel('Severity', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.violinplot(x='Severity', y='Amenity', data=train_df)\nplt.xlabel('Severity', fontsize=12)\nplt.ylabel('Amenity', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(12,8))\nsns.violinplot(x='Severity', y='Wind_Chill(F)', data=train_df)\nplt.xlabel('Severity', fontsize=12)\nplt.ylabel('Wind_Chill(F)', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.violinplot(x='Severity', y='Crossing', data=train_df)\nplt.xlabel('Severity', fontsize=12)\nplt.ylabel('Crossing', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.violinplot(x='Severity', y='Junction', data=train_df)\nplt.xlabel('Severity', fontsize=12)\nplt.ylabel('Junction', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.violinplot(x='Severity', y='Traffic_Signal', data=train_df)\nplt.xlabel('Severity', fontsize=12)\nplt.ylabel('Traffic_Signal', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ohhh ..... i think we have to check for the importance of the feature ... we will go with that ...."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(subset=df.columns[df.isnull().mean()!=0], how='any', axis=0, inplace=True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_y = df['Severity'].values\nx_cols = [col for col in df.columns if col not in ['Severity'] if df[col].dtype=='float64']\ntrain_col= df[x_cols]\n\nfearture_name = train_col.columns.values \n\nfrom sklearn import ensemble \n\nmodel = ensemble.ExtraTreesRegressor(n_estimators=25, max_depth=30, max_features=0.3, n_jobs=-1, random_state=0)\nmodel.fit(train_col,train_y)\n\n#plot imp \nimportance = model.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in model.estimators_],axis=0)\nindices = np.argsort(importance)[::-1][:20]\n\nplt.figure(figsize=(12,12))\nplt.title(\"Feature importances\")\nplt.bar(range(len(indices)), importance[indices], color=\"r\", yerr=std[indices], align=\"center\")\nplt.xticks(range(len(indices)), fearture_name[indices], rotation='vertical')\nplt.xlim([-1, len(indices)])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"seems like Start_lng . Traffic_signals , start,lat ,TMC are more important Feature and followed by ..\n\nlets check with XGBoost also for Feature_importance_"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb \n\nxgb_prames = {\n    'eta': 0.05,\n    'max_depth': 8,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'silent': 1,\n    'seed' : 0\n}\n\ndtrain = xgb.DMatrix(train_col,train_y,feature_names=train_col.columns.values)\n\nmodel = xgb.train(dict(xgb_prames, silent=0), dtrain, num_boost_round=50)\n\n\nfig, ax = plt.subplots(figsize=(12,18))\nxgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"this gives the same includes Distance(mi)"},{"metadata":{},"cell_type":"markdown","source":"to be contunued...soon \n\n**pleace upvote if you like that makes me motive... :)**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}