{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Lets start working with the LOAN dataset.**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# lets import the required libraries\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport warnings \nwarnings.filterwarnings(\"ignore\") # never prints matching warning.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we see that the data  is having 614 rows and 13 columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()  # for the detailed information about each column.\n# We can aslo identify if we have missing values.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Credit_History'] = df['Credit_History'].astype('O')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# describe categorical data (\"object\")\n\ndf.describe(include='O')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets drop the 'Loan_ID' attribute as it doesn't make any impact. \ndf.drop('Loan_ID', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To check if there's any duplicate rows.\ndf.duplicated().any()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6)) #This creates a figure object, which has a width of 8 inches and 6 inches in height.\nsns.countplot(df['Loan_Status']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    Lets check if the ratio of 'Y' to 'N' is equal."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The percentage of Y class : %.2f' % (df['Loan_Status'].value_counts()[0] / len(df)))\nprint('The percentage of N class : %.2f' % (df['Loan_Status'].value_counts()[1] / len(df)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Credit History\n\ngrid = sns.FacetGrid(df, col = 'Loan_Status', size = 3.2, aspect = 1.6)\ngrid.map(sns.countplot, 'Credit_History');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**From the above chart we realize that people with credit history = 1 gets loan easily. **"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Gender\n\ngrid  = sns.FacetGrid(df, col = 'Loan_Status', size = 3.2, aspect  = 1.6)\ngrid.map(sns.countplot, 'Gender');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above chart we realize that if the person is mail then the possibility of getting the loan is high."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Married\ngrid = sns.FacetGrid(df , col = 'Loan_Status', size = 3.2, aspect = 1.6)\ngrid.map(sns.countplot, 'Married');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above chart we realize that more of people who were not married were given the loan."},{"metadata":{"trusted":true},"cell_type":"code","source":"#dependent\ngrid = sns.FacetGrid(df, col = 'Loan_Status', size=3.2, aspect= 1.6)\ngrid.map(sns.countplot, 'Dependents');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from the above chart we can say the applicants with one dependant has more"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Education\ngrid = sns.FacetGrid(df, col = 'Loan_Status', size=3.2, aspect= 1.6)\ngrid.map(sns.countplot, 'Education');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above chart we can notice that the graduates have a better chance of getting a job."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Self_Employed\ngrid = sns.FacetGrid(df, col = 'Loan_Status', size=3.2, aspect= 1.6)\ngrid.map(sns.countplot, 'Self_Employed');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above chart we can realize that poeple who are **not self employed** have recieved loan."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Property_Area\ngrid = sns.FacetGrid(df, col = 'Loan_Status', size=3.2, aspect= 1.6)\ngrid.map(sns.countplot, 'Property_Area');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. From the above chart we can notice that the semi urban area have higher chance of getting the loan."},{"metadata":{"trusted":true},"cell_type":"code","source":"#applicant income\n\nplt.scatter(df['ApplicantIncome'], df['Loan_Status']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above chart we see we can't find any particular pattern."},{"metadata":{},"cell_type":"markdown","source":"**Now lets move on to the NUMERICAL VARIABLES.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('Loan_Status').median()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above data we can see that the loan has been approved if the **Co-applicant's income** is really high."},{"metadata":{},"cell_type":"markdown","source":"**NOW its time to handle all the MISSING VALUES in out data.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now let's start separating categorical and numerical data.\n\ncat_data = []\nnum_data = []\n\nfor i, c in enumerate(df.dtypes) :\n    if c == object:\n        cat_data.append(df.iloc[:, i])\n    else: \n        num_data.append(df.iloc[:, i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_data = pd.DataFrame(cat_data).transpose()\nnum_data = pd.DataFrame(num_data).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for categorical data\n\ncat_data = cat_data.apply(lambda x:x.fillna(x.value_counts().index[0]))\n\ncat_data.isnull().sum().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_data.fillna(method='bfill', inplace=True)\n\nnum_data.isnull().sum().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder \nle = LabelEncoder()\ncat_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transform the target column.\ntarget_values = {'Y': 0 , 'N' : 1}\n\ntarget = cat_data['Loan_Status']\ncat_data.drop('Loan_Status', axis=1, inplace=True)\n\ntarget = target.map(target_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LETS transform all other columns.\nfor i in cat_data:\n    cat_data[i] = le.fit_transform(cat_data[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([cat_data, num_data, target], axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TRAINING THE DATA**"},{"metadata":{},"cell_type":"markdown","source":"lets use StratifiedShuffleSplit"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.concat([cat_data,num_data], axis= 1)\ny = target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\nsss = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n\nfor train, test in sss.split(X, y):\n    X_train, X_test = X.iloc[train], X.iloc[test]\n    y_train, y_test = y.iloc[train], y.iloc[test]\n    \nprint('X_train shape ', X_train.shape)\nprint('y_train shape', y_train.shape)\nprint('X_test shape ', X_test.shape)\nprint('y_test shape', y_test.shape)\n\n# almost same ratio\nprint('\\nratio of target in y_train :',y_train.value_counts().values/ len(y_train))\nprint('ratio of target in y_test :',y_test.value_counts().values/ len(y_test))\nprint('ratio of target in original_data :',df['Loan_Status'].value_counts().values/ len(df))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we can use 4 different algorithms.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\n\nmodels = {\n    'LogisticRegression: ' : LogisticRegression(random_state=42), \n    'KNeighborsClassifier :' : KNeighborsClassifier(),\n    'SVC:' : SVC(random_state=42),\n    'DecisionTreeClassifier: ': DecisionTreeClassifier(max_depth=1,random_state=42)\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loss\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score, log_loss, accuracy_score\n\ndef loss(y_true, y_pred, retu=False):\n    pre = precision_score(y_true, y_pred)\n    rec = recall_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n    loss = log_loss(y_true, y_pred)\n    acc = accuracy_score(y_true, y_pred)\n    \n    if retu:\n        return pre, rec, f1, loss, acc\n    else:\n        print('  pre: %.3f\\n  rec: %.3f\\n  f1: %.3f\\n  loss: %.3f\\n  acc: %.3f' % (pre, rec, f1, loss, acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef train_eval_train(models, X, y):\n    for name, model in models.items():\n        print(name,':')\n        model.fit(X, y)\n        loss(y, model.predict(X))\n        print('-'*30)\n        \ntrain_eval_train(models, X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"here we see the logistic regression has the maximum score."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cross_validation\n\nfrom sklearn.model_selection import StratifiedKFold\nskf= StratifiedKFold(n_splits=10, random_state=42, shuffle = True)\n\ndef train_eval_cross(models, X , y, folds):\n    X = pd.DataFrame(X)\n    y = pd.DataFrame(y)\n    idx = ['pre', 'rec', 'f1', 'loss', 'acc'] \n    \n    for name, model in models.items():\n        ls = []\n        print(name, ':')\n        \n        for train, test in folds.split(X, y):\n            model.fit(X.iloc[train], y.iloc[train])\n            y_pred = model.predict(X.iloc[test])\n            ls.append(loss(y.iloc[test], y_pred, retu= True))\n        print(pd.DataFrame(np.array(ls).mean(axis =0),index = idx)[0])\n        print('-'*30)\n        \ntrain_eval_cross(models, X_train, y_train, skf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see that DecisionTreeClassifier is giving us more accuracy than logistic regression."},{"metadata":{},"cell_type":"markdown","source":"#lets do Feature engineering. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data_corr = pd.concat([X_train, y_train], axis=1)\ncorr = data_corr.corr()\nplt.figure(figsize=(10,7))\nsns.heatmap(corr, annot=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train['new_col'] = X_train['CoapplicantIncome'] / X_train['ApplicantIncome']  \nX_train['new_col_2'] = X_train['LoanAmount'] * X_train['Loan_Amount_Term'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_corr = pd.concat([X_train, y_train], axis=1)\ncorr = data_corr.corr()\nplt.figure(figsize=(10,7))\nsns.heatmap(corr, annot=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop(['CoapplicantIncome', 'ApplicantIncome', 'Loan_Amount_Term', 'LoanAmount'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_eval_cross(models, X_train, y_train, skf)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#as we can see the decision tree is still doing great :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(X_train.shape[1]):\n    print(X_train.iloc[:,i].value_counts(), end='\\n------------------------------------------------\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import norm\n\nfig, ax = plt.subplots(1,2,figsize=(20,5))\n\nsns.distplot(X_train['new_col_2'], ax=ax[0], fit=norm)\nax[0].set_title('new_col_2 before log')\n\nX_train['new_col_2'] = np.log(X_train['new_col_2'])  # here we take the log of all these values.\n\nsns.distplot(X_train['new_col_2'], ax=ax[1], fit=norm)\nax[1].set_title('new_col_2 after log');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_eval_cross(models, X_train, y_train, skf)\n# taking log has drastically improved our model.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('before:')\nprint(X_train['new_col'].value_counts())\n\nX_train['new_col'] = [x if x==0 else 1 for x in X_train['new_col']]\nprint('-'*50)\nprint('\\nafter:')\nprint(X_train['new_col'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_eval_cross(models, X_train, y_train, skf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(X_train.shape[1]):\n    print(X_train.iloc[:,i].value_counts(), end='\\n------------------------------------------------\\n')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(X_train['new_col_2']);\nplt.title('new_col_2 outliers', fontsize=15);\nplt.xlabel('');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold= 0.1\n\nnew_col_2_out = X_train['new_col_2']\nq25, q75 = np.percentile(new_col_2_out, 25), np.percentile(new_col_2_out, 75) # Q25, Q75\nprint('Quartile 25: {} , Quartile 75: {}'.format(q25, q75))\n\niqr = q75 - q25\nprint('iqr: {}'.format(iqr))\n\ncut = iqr * threshold\nlower, upper = q25 - cut, q75 + cut\nprint('Cut Off: {}'.format(cut))\nprint('Lower: {}'.format(lower))\nprint('Upper: {}'.format(upper))\n\noutliers = [x for x in new_col_2_out if x < lower or x > upper]\nprint('Nubers of Outliers: {}'.format(len(outliers)))\nprint('outliers:{}'.format(outliers))\n\ndata_outliers = pd.concat([X_train, y_train], axis=1)\nprint('\\nlen X_train before dropping the outliers', len(data_outliers))\ndata_outliers = data_outliers.drop(data_outliers[(data_outliers['new_col_2'] > upper) | (data_outliers['new_col_2'] < lower)].index)\n\nprint('len X_train before dropping the outliers', len(data_outliers))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = data_outliers.drop('Loan_Status', axis=1)\ny_train = data_outliers['Loan_Status']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(X_train['new_col_2']);\nplt.title('new_col_2 without outliers', fontsize=15);\nplt.xlabel('');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_eval_cross(models, X_train, y_train, skf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets select the final features required."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets check the correlation.\ndata_corr = pd.concat([X_train, y_train], axis=1)\ncorr = data_corr.corr()\nplt.figure(figsize=(10,7))\nsns.heatmap(corr, annot=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop(['Self_Employed'], axis=1, inplace=True)\n\ntrain_eval_cross(models, X_train, y_train, skf)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop(['Dependents', 'new_col_2', 'Education', 'Gender', 'Property_Area','Married', 'new_col'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_corr = pd.concat([X_train, y_train], axis=1)\ncorr = data_corr.corr()\nplt.figure(figsize=(10,7))\nsns.heatmap(corr, annot=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# lets test our model on the test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_test1 = pd.read_csv('test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_new = X_test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = []\n\nX_test_new['new_col'] = X_test_new['CoapplicantIncome'] / X_test_new['ApplicantIncome']  \nX_test_new['new_col_2'] = X_test_new['LoanAmount'] * X_test_new['Loan_Amount_Term']\nX_test_new.drop(['CoapplicantIncome', 'ApplicantIncome', 'Loan_Amount_Term', 'LoanAmount'], axis=1, inplace=True)\n\nX_test_new['new_col_2'] = np.log(X_test_new['new_col_2'])\n\nX_test_new['new_col'] = [x if x==0 else 1 for x in X_test_new['new_col']]\n\nX_test_new.drop(['Self_Employed'], axis=1, inplace=True)\n\n# drop all the features Except for Credit_History\n#X_test_new.drop(['Self_Employed','Dependents', 'new_col_2', 'Education', 'Gender', 'Property_Area','Married', 'new_col'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name,model in models.items():\n    print(name, end=':\\n')\n    loss(y_test, model.predict(X_test_new))\n    print('-'*40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#So we can see that the logistic and decision tree performs well with the given data. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}