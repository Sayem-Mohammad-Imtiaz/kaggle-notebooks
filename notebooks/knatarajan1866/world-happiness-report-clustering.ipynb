{"cells":[{"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# -*- coding: utf-8 -*-\n## 1.0 Call libraries\nimport time                   # To time processes\nimport warnings               # To suppress warnings\n\nimport numpy as np            # Data manipulation\nimport pandas as pd           # Dataframe manipulatio \nimport matplotlib.pyplot as plt                   # For graphics\n\nfrom sklearn import cluster, mixture, metrics, datasets              # For clustering\nfrom sklearn.preprocessing import StandardScaler  # For scaling dataset\nfrom itertools import cycle, islice\nimport os                     # For os related operations\nimport sys                    # For data size\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n%matplotlib inline\n# Define function for Reading Data \ndef Happyreport():\n    X = pd.read_csv(\"../input/2017.csv\", header = 0)\n    return X\n\ndef data_preprocessing(data):\n    df = StandardScaler().fit_transform(data)\n    df =pd.DataFrame(df, columns = X.columns)\n    return df\n\ndef kmeans_clustering(nclusters, dataset ):\n    km = cluster.KMeans(init = 'k-means++', n_clusters =n_clusters )\n    km_result = km.fit_predict(df)\n    return km_result, km\n    \ndef mbkmeans_clustering(n_clusters, dataset):\n    mbk = cluster.MiniBatchKMeans(init='k-means++', n_clusters=n_clusters, batch_size=100,\n                      n_init=10, max_no_improvement=10, verbose=0)\n    mbk_result = mbk.fit_predict(dataset)\n    return mbk_result, mbk\n\ndef AffinityPropagation_clustering(damping, preference, data):\n    af = cluster.AffinityPropagation(preference=preference, damping=damping).fit(df)\n    ap_result = af.predict(df)\n    return ap_result, af\n\ndef MeanShift_clustering(quantile, n_samples, dataset):\n    bandwidth = cluster.estimate_bandwidth(df, quantile, n_samples)\n    ms = cluster.MeanShift(bandwidth=bandwidth)\n    ms_result = ms.fit_predict(df)\n    return ms_result, ms\n\ndef Spectral_clustering(n_clusters):\n    spectral = cluster.SpectralClustering(n_clusters=n_clusters)\n    sp_result= spectral.fit_predict(df)\n    return sp_result, spectral\n\ndef Agglomerative_Clustering(n_clusters, dataset, linkage):\n    for index, metric in enumerate([\"cosine\", \"euclidean\", \"cityblock\"]):\n        if metric == 'cosine':\n            cos_model = cluster.AgglomerativeClustering(n_clusters=n_clusters,\n                                    linkage=\"average\", affinity=metric)\n            cos_result = cos_model.fit_predict(dataset)\n        if metric == 'euclidean':\n            ec_model = cluster.AgglomerativeClustering(n_clusters=n_clusters,\n                                    linkage=\"average\", affinity=metric)\n            ec_result = ec_model.fit_predict(dataset)\n        if metric == 'cityblock' :\n            cb_model = cluster.AgglomerativeClustering(n_clusters=n_clusters,\n                                                       linkage=\"average\", affinity=metric)\n            cb_result = cb_model.fit_predict(dataset)\n    return cos_model, cos_result, ec_model, ec_result, cb_model, cb_result\n\ndef DBSCAN(dataset, eps):\n    dbscan = cluster.DBSCAN(eps=eps)\n    db_result= dbscan.fit_predict(X)\n    return dbscan, db_result\n\ndef Birch(dataset, n_clusters):\n    birch = cluster.Birch(n_clusters=n_clusters)\n    birch_result = birch.fit_predict(X)\n    return birch, birch_result\n\ndef GMM(dataset, n_clusters, covariance_type ):\n    gmm = mixture.GaussianMixture( n_components=n_clusters, covariance_type='full')\n    gmm.fit(X)\n    gmm_result = gmm.predict(X)\n    return gmm_result, gmm\n\n#  Read Data \nX = Happyreport()\nY = Happyreport()\n## Remove first 2 columns from the dataset\nX = X.iloc[:, 2: ]      # Ignore Country and Happiness_Rank columns\n\n## Data Preprocessing\ndf = data_preprocessing(X)\ndf_cpy = df.copy()\ndf = pd.DataFrame(df)\n\n### Define Parameters\nn_clusters = 2       \npreference=-200\ndamping = 0.9\nquantile=0.2\nn_samples=155\nlinkage=\"average\"\neps = 0.3\ncovariance_type='full'\n\n#### KMeans Clustering\nkm_result, km = kmeans_clustering(n_clusters, df) \ndf_cpy['Kmeans'] = pd.DataFrame(km_result)\n\n\n#### Mini Batch K-Means\nmbk_result, mbk = mbkmeans_clustering(n_clusters, df)\ndf_cpy['MBKmeans'] = pd.DataFrame(mbk_result )\n\n# Compute Affinity Propagation\nap_result, af = AffinityPropagation_clustering(damping, preference, df)\ndf_cpy['Affinity Propagation'] = pd.DataFrame(ap_result )\n\n### Meanshift\nms_result, ms = MeanShift_clustering(quantile, n_samples, df)\ndf_cpy['Meanshift'] = pd.DataFrame(ms_result)\n\n## Spectral clustering\nsp_result ,spectral = Spectral_clustering(n_clusters) \ndf_cpy['Spectral'] = pd.DataFrame(sp_result)\n\n## Agglomerative Clustering\ncos_model, cos_result, ec_model, ec_result, cb_model, cb_result = Agglomerative_Clustering(n_clusters, df,linkage)\ndf_cpy['Agglomerative Cosine'] = pd.DataFrame(cos_result)\ndf_cpy['Agglomerative  Euclidean'] = pd.DataFrame(ec_result)\ndf_cpy['Agglomerative Cityblock'] = pd.DataFrame(cb_result)\n\n## DBSCAN\ndbscan, db_result = DBSCAN(df, eps)\ndf_cpy['DBScan'] = pd.DataFrame(db_result)\n\n## Birch\nbirch, birch_result = Birch(df, n_clusters)\ndf_cpy['Birch'] = pd.DataFrame(birch_result)\n\n## Gaussian Mixture modeling\ngmm_result, gmm = GMM(df, n_clusters, covariance_type )\ndf_cpy['GMM'] = pd.DataFrame(gmm_result)\n\n\nclustering_algorithms = (\n         ('KMeans', km_result),\n         ('MiniBatchKMeans', mbk_result),\n         ('AffinityPropagation', ap_result),\n         ('MeanShift', ms_result),\n         ('SpectralClustering', sp_result),\n         ('Agglo Cosine', cos_result),\n         ('Agglo Euclidean', ec_result),\n         ('Agglo Cityblock', cb_result),##\n        ('DBSCAN', db_result),\n        ('Birch', birch_result),\n        ('GMM', gmm_result)\n   )\n\n\nfig,ax = plt.subplots(4,3, figsize=(5,5)) \ni = 0\nj=0\nfor name, algorithm in clustering_algorithms:\n    ax[i,j].scatter(df.iloc[:, 4], df.iloc[:, 5],  c=algorithm)\n    ax[i,j].set_title(name)\n    j=j+1\n    if( j % 3 == 0) :\n       j= 0\n       i=i+1\nplt.subplots_adjust(bottom=-0.5, top=1.5)\nplt.show()\n\ndata = dict(type = 'choropleth', \n           locations = Y['Country'],\n           locationmode = 'country names',\n           z = df_cpy['Kmeans'], \n           text = Y['Country'],\n           colorbar = {'title':'Cluster Group'})\nlayout = dict(title = 'K-Means Clustering Visualization', \n             geo = dict(showframe = False, \n                       projection = {'type': 'Mercator'}))\nchoromap3 = go.Figure(data = [data], layout=layout)\niplot(choromap3)\n\n\n\n    \n","outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_uuid":"b493f5f5d1b8ef92d18a118e7f76c2fe93d43f99","_cell_guid":"e63f6669-3ff1-41ae-855f-04c47227fc13"}}],"nbformat":4,"nbformat_minor":1,"metadata":{"language_info":{"nbconvert_exporter":"python","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py","version":"3.6.4","mimetype":"text/x-python","pygments_lexer":"ipython3"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}}}