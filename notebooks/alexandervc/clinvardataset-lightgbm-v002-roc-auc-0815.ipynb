{"cells":[{"metadata":{},"cell_type":"markdown","source":"Lightgbm model - roc_auc 0.815 , feature importance visualization \n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style(style='whitegrid')\nsns.set(font_scale=1.5);\nimport re\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/clinvar-conflicting/clinvar_conflicting.csv', dtype={0: object, 38: str, 40: object})\nprint(df.columns)\nprint(df.shape)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CLASS is target variable \n\nThe CLASS distribution is skewed a bit to the 0 class, meaning there are fewer variants with conflicting submissions.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(x=\"CLASS\", data=df)\nax.set(xlabel='CLASS', ylabel='Number of Variants');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('CLASS',axis = 1)\ny = df['CLASS']\ncategorical_features = [col for c, col in enumerate(X.columns) \\\n                        if not ( np.issubdtype(X.dtypes[c], np.number )  )  ]\n\nlen(categorical_features), X.shape, y.shape, y.mean() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in categorical_features:\n    X[f] = X[f].astype('category')\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state = 0, stratify = y  )\nprint(X_train.shape, X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# technical things: transform data into internal lightgbm format\ntrain_data = lgb.Dataset(X_train, label=y_train , categorical_feature=categorical_features)\ntest_data = lgb.Dataset(X_test, label=y_test, categorical_feature=categorical_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create lightgbm model builder.\n# I found params by tuning 'num_leaves': 500, 'learning_rate': 0.0015, \n\nparameters = {\n    'application': 'binary',\n    'objective': 'binary',\n    'metric': 'auc',\n    'is_unbalance': 'true',\n    'boosting': 'gbdt',\n    'num_leaves': 500,\n    'feature_fraction': 0.5,\n    'bagging_fraction': 0.5,\n    'bagging_freq': 20,\n    'learning_rate': 0.0015,\n    'verbose': 0\n}\n\nmodel = lgb.train(parameters,\n                       train_data,\n                       valid_sets=test_data,\n                       num_boost_round=5000,\n                       early_stopping_rounds=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = model.predict(X_test)\nprint('Test roc_auc_score = ', roc_auc_score(y_test, p ))    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ax = plt.figure(figsize = (20,5))\nfig, ax = plt.subplots(figsize=(20, 15))\nlgb.plot_importance(model,ax.axes,  height = 1.6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(index = X.columns, data = model.feature_importance() , name = 'Importance').sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}