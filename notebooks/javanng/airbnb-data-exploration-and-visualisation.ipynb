{"cells":[{"metadata":{},"cell_type":"markdown","source":"# DATA EXPLORATION AND VISUALISATION OF AIRBNB DATASET"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Content\n* Importing required libraries\n* Reading of Data\n* Dealing with Null and Empty values\n* Dealing with Outliers\n* Data Exploration and Visualisation of Numerical features\n* Data Exploration and Visualisation of Categorical features\n* Combined Exploration and Visualisation of all features"},{"metadata":{},"cell_type":"markdown","source":"# IMPORTING LIBRARIES"},{"metadata":{},"cell_type":"markdown","source":"These are the libraries commonly required for a data science / kaggle beginner project."},{"metadata":{"trusted":true},"cell_type":"code","source":"#data wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n#data visualisation\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport re\nimport unicodedata\nimport nltk\nfrom wordcloud import WordCloud,STOPWORDS\n\n#machine learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# READ DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/us-airbnb-open-data/AB_US_2020.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the head and tail of the dataset, I could learn a few things :\n* identified the categorical and numerical features\n* feature [neighbourhood] contains some as words and some as postal codes. This would require some standardisation later if we use it\n* feature [host_name] may not be very useful on its own. However, we can feature engineer it to link it to the gender of the host name for better analysis. \n* feature [neighbourhood_group] seems to contain alot of missing data."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DEALING WITH NULL EMPTY VALUES"},{"metadata":{},"cell_type":"markdown","source":"There are missing values for features [name], [host_name], [neighbourhood_group], [last_review] and [reviews_per_month]. I deleted [neighbourhood_group] because almost 50% of the data is missing. \n\n*improvement that can be made: display missing values as a percentage of the feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2 = data.drop(['neighbourhood_group'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also check for the number of unique data points for each feature. This could be useful when we decide to encode categorical data later. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.select_dtypes('object').apply(pd.Series.nunique, axis = 0) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.select_dtypes('int').apply(pd.Series.nunique, axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data2.select_dtypes('float').apply(pd.Series.nunique, axis = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DEALING WITH OUTLIERS"},{"metadata":{},"cell_type":"markdown","source":"In dealing with numerical outliers, I plotted a density distribution for all numerical features to obtain a big picture of the data. With the distribution, it is much easier to catch the outliers. Features [price], [number of reviews], [reviews per month], [minimum nights] seem to contain outliers. It is ridiculous for prices to go anywhere close to $25000 or that you must stay a minimum of 100000 nights. \n\nThe outliers are removed following the interquartile price range. "},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical = data2.select_dtypes(include = ('int', 'float')).columns\nnumerical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,20))\n\nfor i, feature in enumerate(numerical):\n    plt.subplot(4,3,i+1)\n    sns.kdeplot(data2[feature])\n    plt.title('Distribution of %s' %feature)\n    plt.xlabel('%s' % feature); plt.ylabel('Density')\n    plt.tight_layout()\n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lower_bound = .25\nupper_bound = .75\niqr = data2[data2['price'].between(data2['price'].quantile(lower_bound), data2['price'].quantile(upper_bound), inclusive=True)]\niqr = iqr[iqr['number_of_reviews'] > 0]\niqr = iqr[iqr['calculated_host_listings_count'] < 10]\niqr = iqr[iqr['number_of_reviews'] < 400]\niqr = iqr[iqr['minimum_nights'] < 10]\niqr = iqr[iqr['reviews_per_month'] < 5]\n\n\n#referenced code from Thomas Konstantin's notebook","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iqr.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_iqr = iqr.select_dtypes(include = ('int', 'float')).columns\n\nplt.figure(figsize=(20,20))\n\nfor i, feature in enumerate(numerical_iqr):\n    plt.subplot(4,3,i+1)\n    sns.kdeplot(iqr[feature], bw = 0.2)\n    plt.title('Distribution of %s' %feature)\n    plt.xlabel('%s' % feature); plt.ylabel('Density')\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the distribution above, we can also draw a few observations\n* there is a large density of latitude and longititude at 42 and -70 respectively. A simple google search will tell you that this refers to New York. This possibly means that most listings are from NY. We will look into this later. \n* Most listings are priced in whole such as $100, $150 and $200 per night.\n* Most listings requires 1-2 nights minimally. \n* Most hosts have only one listing\n* There is a large number of listings in city 14 which is in New York. This correlates with what we learnt from the distributions in latitude and longititude which also points to New York. "},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data = iqr.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EXPLORATION OF NUMERICAL FEATURES\n"},{"metadata":{},"cell_type":"markdown","source":" ****The Target Feature : Price****"},{"metadata":{},"cell_type":"markdown","source":"In datsets like these, the end goal is usually to predict price. We examine the distribution of the price of each listing. A describe function to get the gist of the distribution is a good start. It seems that the outliers are indeed out of our way. "},{"metadata":{"trusted":true},"cell_type":"code","source":"cleaned_data['price'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(cleaned_data['price'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(cleaned_data['price'])\n#compare this with a .plot(kind='kde'), this sns plot is better as more could be seen. you can only see a single peak in the latter.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can look at the correlation between price and other numerical features. \n\nI define significance as more than 50%. \nPositive correlations of significance: Minimum_nights. The larger the number of minimum night, the higher the price.\nNegative correlations of significance: lattitude and Reviews per month. The lower the lattitude the higher the price. The lower the review count the higher the price.\n\nSome of the correlation seems strange isn't it?\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations = cleaned_data.corr()['price'].sort_values()\ncorrelations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.scatter(x = cleaned_data['latitude'],y = cleaned_data['price'], s=0.01)\nplt.ylabel('price', fontsize=13)\nplt.xlabel('lattitude', fontsize=13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Minimum Nights**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(cleaned_data['minimum_nights'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.scatter(x = cleaned_data['minimum_nights'], y = cleaned_data['price'], s=0.01)\nplt.ylabel('price', fontsize=13)\nplt.xlabel('minimum_nights', fontsize=13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.scatter(x = cleaned_data['reviews_per_month'],y = cleaned_data['price'], s=0.01)\nplt.ylabel('price', fontsize=13)\nplt.xlabel('reviews_per_month', fontsize=13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EXPLORATION OF CATEGORICAL DATA"},{"metadata":{},"cell_type":"markdown","source":"To deal with the categorical features, we need to do some encoding. The categorical features that may require encodings are neighbourhood, room types and cities. There are 1450 unique neighbourhood, 4 room types, 28 unique cities. \n\n* label encoding or one-hot encoding? Generally, for feature with more than 2 categories, we will use one-hot encoding. However, i would do label encoding in this project as it is easier to deal with and I am not ready to get into dimensionality reduction in this project. We should note that with label encoding with more than 2 categories, there will be arbitrary ordering and may asisgn different weights to each category, \n* 1450 neighbourhood is too much to encode. And also, I do not know how to clean this feature up. \n* For room types and cities, I carried on with encoding. "},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\n\nle.fit(cleaned_data['room_type'])\nle_room_type_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\nprint(le_room_type_mapping)\ncleaned_data['room_type'] = le.transform(cleaned_data['room_type'])\n\nle.fit(cleaned_data['city'])\nle_city_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\nprint(le_city_mapping)\ndata2['city'] = le.transform(data2['city'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Room Types**"},{"metadata":{},"cell_type":"markdown","source":"Most listings are entire home/apt or private rooms."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize= (10,10))\ncleaned_data.room_type.value_counts().plot.pie(autopct=\"%.1f%%\", title = 'distribution of room types')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.scatter(x = cleaned_data['room_type'], y = cleaned_data['price'], s=0.01)\nplt.ylabel('price', fontsize=13)\nplt.xlabel('room_type', fontsize=13)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cities Listed**"},{"metadata":{},"cell_type":"markdown","source":"As expected, most listings are from New York City followed by Los Angeles then Hawaii. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nax = sns.countplot(y=cleaned_data['city'],order=cleaned_data['city'].value_counts().index,palette='rocket')\nax.set_yticklabels(ax.get_yticklabels(),fontsize=11,fontweight='bold')\nax.set_title('Distribution Of Different Cities In Our Data',fontsize=16,fontweight='bold')\nax.set_xlabel('Count',fontsize=14,fontweight='bold')\nplt.show()\n\n#referenced code from Thomas Konstantin's notebook","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Number of Reviews per City**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nbox_plot = sns.barplot(x='number_of_reviews', y='city', \n                 data=cleaned_data, \n                 palette=\"rocket\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Length of Description of Listings**"},{"metadata":{},"cell_type":"markdown","source":"* There is a large variance in word length. While there is a median of 6 words, there are listings with more than 40 words. However, most listings are kept to less than 10 words. There are probably outliers but I do not think it is necessary to remove them. "},{"metadata":{"trusted":true},"cell_type":"code","source":"word_length = cleaned_data['name'].apply(lambda x : len(str(x).split()))\nword_length.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,5))\nsns.kdeplot(word_length, shade=True, color='r').set_title('Distribution of word length in name')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Most Used Words in Listings**"},{"metadata":{},"cell_type":"markdown","source":"Through a wordcloud and a barplot, we can find out the popular words used in the listings. \nMost popular words seen from word cloud : Cosy, home, apartment, beautiful, downtown, studio, heart, beach, charming, modern. \nMost poular words seen from barplot : private, bedroom, apartment, home, studio, cosy, room, beach, house, spacious, modern, downtown, park. \n\nIt seems like most listings are trying to portray an apartment that is filled with warmth. \n\nImprovements that can be made: Add words like 'apartment', 'private', 'bedroom' into stopwords. "},{"metadata":{"trusted":true},"cell_type":"code","source":"x = cleaned_data['name'].astype(str)\nlistToStr = ' '.join([str(elem) for elem in x if elem not in STOPWORDS]).lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,20))\nwordcloud = WordCloud(width=800,height=600,min_font_size=10).generate(listToStr)\nplt.imshow(wordcloud)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = re.sub(\"[^a-zA-Z_]\", ' ', listToStr) #removes everything other than letters\ntext = re.sub(r'\\b\\w{1,3}\\b', '', text) #remove words less than 3 chars","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words_df = pd.DataFrame(text.split(), columns = ['words'])\nplt.figure(figsize = (20,20))\nsns.countplot(y= words_df['words'],order=words_df['words'].value_counts().iloc[:50].index,palette='rocket')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ALL FEATURES"},{"metadata":{},"cell_type":"markdown","source":"Looking at a heatmap that draws correlations across all numerical and encoded categorical features, we can attempt to draw more observations. Something that pops up to me is the correlation between id and number of reviews. Apparently there are more reviews for ids that are listed first. Is this a way that the listings are sorted on Airbnb? Or maybe the listings are older thus have more reviews?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,5))\nsns.heatmap(cleaned_data.corr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le_city_mapping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"city_grouped = cleaned_data.groupby(['city'], as_index = False)\ncity_grouped2 = city_grouped[('city','price','room_type', 'number_of_reviews')].mean()\ncity_grouped2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prices in each City**"},{"metadata":{},"cell_type":"markdown","source":"Looking at the box plot, you could see that most cities are priced at around $120. Listings in pacific grove seems to have a wide variance. A few listings are really expensive."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nbox_plot = sns.boxplot(x='price', y='city', \n                 data=cleaned_data, \n                 palette=\"rocket\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nbox_plot = sns.barplot(x='number_of_reviews', y='city', \n                 data=cleaned_data, \n                 palette=\"rocket\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}