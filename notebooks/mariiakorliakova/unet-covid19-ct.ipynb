{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport nibabel as nib\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/covid19-ct-scans/metadata.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_nii(filepath):\n    '''\n    Reads .nii file and returns pixel array\n    '''\n    ct_scan = nib.load(filepath)\n    array   = ct_scan.get_fdata()\n    array   = np.rot90(np.array(array))\n    return(array)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read sample\nk = 19\nsample_ct   = read_nii(data.loc[k,'ct_scan'])\nsample_lung = read_nii(data.loc[k,'lung_mask'])\nsample_infe = read_nii(data.loc[k,'infection_mask'])\nsample_all  = read_nii(data.loc[k,'lung_and_infection_mask'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_all.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n =sample_all.shape[2] % 2\nn = 40\n\nfig = plt.figure(figsize = (18,15))\nplt.subplot(1,4,1)\nplt.imshow(sample_ct[..., n], cmap = 'bone')\nplt.title('Original Image')\n\nplt.subplot(1,4,2)\nplt.imshow(sample_ct[..., n], cmap = 'bone')\nplt.imshow(sample_lung[..., n],alpha = 0.5, cmap = 'nipy_spectral')\nplt.title('Lung Mask')\n\nplt.subplot(1,4,3)\nplt.imshow(sample_ct[..., n], cmap = 'bone')\nplt.imshow(sample_infe[..., n], alpha = 0.5, cmap = 'nipy_spectral')\nplt.title('Infection Mask')\n\nplt.subplot(1,4,4)\nplt.imshow(sample_ct[..., n], cmap = 'bone')\nplt.imshow(sample_all[..., n], alpha = 0.5, cmap = 'nipy_spectral')\nplt.title('Lung and Infection Mask')\n\nplt.show()\n\n\nfig = plt.figure(figsize = (18,15))\nplt.subplot(1,4,1)\nplt.imshow(sample_ct[..., n], cmap = 'bone')\nplt.title('Original Image')\n\nplt.subplot(1,4,2)\n\nplt.imshow(sample_lung[..., n])\nplt.title('Lung Mask')\n\nplt.subplot(1,4,3)\n\nplt.imshow(sample_infe[..., n])\nplt.title('Infection Mask')\n\nplt.subplot(1,4,4)\nplt.imshow(sample_all[..., n])\nplt.title('Lung and Infection Mask')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im_size = sample_ct[:,:,1].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Region of interest\n\n\n- get area with same label\n- set min-max coordinate"},{"metadata":{"trusted":true},"cell_type":"code","source":"dd = sample_all[:,:,:].sum(axis=2)\nplt.imshow(dd/sample_all.shape[2])\nplt.show()\n\nd_size_interes = np.where(dd > 0)\nprint(np.min(d_size_interes,axis=1),np.max(d_size_interes,axis=1))\nprint(len(d_size_interes),d_size_interes[0].shape,d_size_interes[1].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"[np.min(d_size_interes,axis=1),np.max(d_size_interes,axis=1)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get class label"},{"metadata":{"trusted":true},"cell_type":"code","source":"set(sample_all[:,:,n].reshape((im_size[0]*im_size[1])).tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 0 - background\n* 1 - left\n* 2 - right\n* 3 - infect"},{"metadata":{"trusted":true},"cell_type":"code","source":"set(sample_infe[:,:,n].reshape((im_size[0]*im_size[1])).tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 0 - background\n* 1 - infect"},{"metadata":{},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import math","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.utils import Sequence\n\nclass DataSequence(Sequence):\n    \"\"\"\n    Keras Sequence object to train a model on a list of csv files\n    data, - csv - data with file name information\n    batch_size=1, - batch size\n    out_chanel = 2, - chanel number\n    w_size = 256 - window size, if w_size = 1, full size\n    in_chanel - number of uf input image on sample\n    \n    \"\"\"\n    def __init__(self, data, batch_size=1, out_chanel = 1, in_chanel = 1, w_size = 256, mode='train'):\n        \"\"\"\n        df = dataframe with 4 columns: the labels and a list of filenames\n        \"\"\"\n        \n        self.bsz = batch_size\n        self.mode = mode\n        self.ind = np.arange(batch_size)\n        \n        # Take labels and a list of image locations in memory\n        self.data = data\n        self.x1 = 0\n        self.x2 = w_size\n        self.y1 = 0\n        self.y2 = w_size\n        self.w = w_size\n        self.chanel = out_chanel\n        self.seqenc = in_chanel // 2\n        \n\n    def __len__(self):\n        return int(math.ceil((self.data.shape[0]) ))\n\n    def on_epoch_end(self):\n        #print('epoch end:')\n        self.indexes = range(self.data.shape[0])\n        if self.mode == 'train':\n            # Shuffles indexes after each epoch if in training mode\n            self.indexes = np.random.choice(self.indexes, size=len(self.indexes))\n            #print('gen end:')\n            \n\n    def get_batch_labels(self, idx):\n        # Fetch a batch of labels\n        #idx * self.bsz: (idx + 1) * self.bsz\n        #print(idx)\n        imag = read_nii(data.loc[idx,'lung_and_infection_mask'])\n        batch =[]\n        #print(imag.shape)\n        if self.w >1:\n            # RoI\n            d_size_interes = np.where(imag.sum(axis=2) > 0)\n            # choice corner on new select RoI\n            xy_min = np.min(d_size_interes,axis=1)\n            xy_max = np.max(d_size_interes,axis=1)\n            # randon corner\n            conertb = np.random.choce(np.arange(2), size=1)\n            conerrl = np.random.choce(np.arange(2), size=1)\n            self.x1 = xy_min[1]+(xy_max[1]-xy_min[1]-self.w)*conerrl\n            self.x2 = self.w + self.x1\n            self.y1 = xy_min[0]+(xy_max[0]-xy_min[0]-self.w)*conertb\n            self.y2 = self.w + self.y1\n        else:\n            self.x1 = 0 # full size\n            self.x2 = imag.shape[1]\n            self.y1 = 0\n            self.y2 = imag.shape[0]\n            \n        # chanel on label\n        for i in range(imag.shape[2]):\n            \n            imag4 = np.zeros((imag.shape[0],imag.shape[1],self.chanel))\n            #print(imag4.shape,imag.shape)\n            if self.chanel == 1:\n                imag4[:,:,0] = imag[:,:,i]==3 # only infect\n            if self.chanel == 3:\n                imag4[:,:,0] = imag[:,:,i]==0 # all classes\n                imag4[:,:,1] = imag[:,:,i]==1 \n                imag4[:,:,1] = imag[:,:,i]==2 \n                imag4[:,:,2] = imag[:,:,i]==3               \n            if self.chanel == 2:\n                imag4[:,:,0] = imag[:,:,i]==1 # infect + lung\n                imag4[:,:,0] = imag[:,:,i]==2 \n                imag4[:,:,1] = imag[:,:,i]==3\n            # batch RoI\n            batch.append(imag4[self.y1:self.y2,self.x1:self.x2,:])\n        self.ind = np.random.choice(np.arange(1,len(batch)-1), size=self.bsz )\n        #print(type(self.ind))\n        # sampling labels to batch\n        self.segment = np.array(batch)[self.ind].astype(float)    \n        return self.segment\n\n    def get_batch_features(self, idx):\n        # Fetch a batch of inputs\n        imag = read_nii(data.loc[idx,'ct_scan'])\n        imag = imag.transpose([2,0,1])\n        imag = imag / np.max(imag)\n        # RoI on image + sampling\n        imag =imag.reshape(imag.shape[0],imag.shape[1],imag.shape[2],1)\n        return imag[self.ind,self.y1:self.y2,self.x1:self.x2,:]\n\n    def __getitem__(self, idx):\n        \n        batch_y = self.get_batch_labels(idx)\n        batch_x = self.get_batch_features(idx)\n        return batch_x, batch_y\n    \n    \n  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"test my generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_seq = DataSequence(data.iloc[:-2,:],50)\ndata_seq_test = DataSequence(data.iloc[-2:,:],10)\nfor i in range(2):\n    x,y = data_seq[i]\n    print(i,':',x.shape,y.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 2\nfig = plt.figure(figsize = (15,5))\nplt.subplot(1,3,1)\nplt.imshow(x[n,:,:,0])\nplt.subplot(1,3,2)\nplt.imshow(y[n,:,:,0])\nplt.subplot(1,3,3)\nplt.imshow(x[n,:,:,0], cmap = 'bone')\nplt.imshow(y[n,:,:,0], alpha = 0.5, cmap = 'nipy_spectral')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.max(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Buil UNet model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport skimage.color\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing import image\nimport tensorflow as tf\nfrom keras import backend as K\nfrom PIL import Image\nimport tensorflow\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n\n#\nfrom tensorflow.keras.layers import Conv2D, Conv2DTranspose\nfrom tensorflow.keras.layers import MaxPooling2D, GlobalMaxPool2D\nfrom tensorflow.keras.layers  import concatenate, add\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.framework import ops\n\nfrom tensorflow.python.keras.utils import losses_utils\n\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import math_ops","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred):\n    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.)\n\n\ndef focal(y_true, y_pred):\n    alpha = 1\n    gamma = 2\n    \n    num = y_true.shape\n    print(y_true,y_pred)\n\n    \n    y_pred = ops.convert_to_tensor_v2_with_dispatch(y_pred)\n    y_true = math_ops.cast(y_true, y_pred.dtype)\n    BCE_loss = tensorflow.keras.losses.CategoricalCrossentropy()\n\n    return K.mean((y_pred - 1)** gamma * alpha * BCE_loss( y_true, y_pred), axis=-1)\n   \n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mm = VGG16(input_shape=(256,256,3), include_top=False, weights=\"imagenet\")\nmm.summary()\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(mm.layers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Gray2VGGInput( tensorflow.keras.layers.Layer ) :\n    \"\"\"Custom conversion layer\n    \"\"\"\n    def build( self, x ) :\n        self.image_mean = K.variable(value=np.array([103.939, 116.779, 123.68]).reshape([1,1,1,3]).astype('float32'), \n                                     dtype='float32', \n                                     name='imageNet_mean' )\n        self.built = True\n        return\n    def call( self, x ) :\n        rgb_x = K.concatenate( [x,x,x], axis=-1 )\n        #norm_x = rgb_x - self.image_mean\n        return rgb_x\n    def compute_output_shape( self, input_shape ) :\n        return input_shape[:3] + (3,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unet_pre_train(use_pretrain = True, num_classes = 13, input_shape= (200, 200, 3),level = 3,neuron = 16, lr=0.0001,b1 = 0.9, b2=0.9999):  \n    img_input = Input(shape = input_shape)\n    if use_pretrain :\n        # грузим   VGG16\n        x_in  = Gray2VGGInput( name='gray_to_rgb_norm')( img_input )\n        model_vgg16_3 = VGG16(input_tensor = x_in, input_shape = (input_shape[0],input_shape[1],3),include_top=False, weights=\"imagenet\")\n\n            \n            \n        \n        #y = pre_trained_model(x_in) \n        \n        # замораживаем все слои\n        for layer in model_vgg16_3.layers:\n            layer.trainable = False\n            \n        print('x_in: ',model_vgg16_3.layers)\n        \n        #y_bloc = [y]\n        \n        \n         \n        #print(x_in)\n        #y = pre_trained_model.layers[0](x_in )\n        #print(y)\n        # фиксируем скипы для переноса из VGG16 (надо еще проверять)\n        #blocks_ = [ pre_trained_model.layers[2].output]\n        blocks_ =[ model_vgg16_3.layers[2].output]\n        for i in range(level):\n            #blocks_.append( pre_trained_model.layers[5+i*4].output)\n            blocks_.append( model_vgg16_3.layers[5+i*4].output)\n        #block_3_out = pre_trained_model.layers[6].output\n        #block_2_out = pre_trained_model.layers[3].output\n        \n        #  фиксируем вход сети\n        \n        \n        \n        # фиксируем последний рабочий слой для своего потока  \n        #x = pre_trained_model.layers[level*4+1].output\n        x =  model_vgg16_3.layers[1+level*4].output\n        #x = y_bloc[level*4+2]\n        #print('y:',y_bloc)\n        print('x:',x)\n        \n    else:\n        #x = Conv2D(3, (3, 3), padding='same')(img_input )\n        #pre_trained_model.layers[0].input = x                                      \n        #x = pre_trained_model.layers[0].output\n        x1 = img_input\n        print(x1)\n    \n        blocks_ = []\n        i = 0\n        for i in range(level):\n            x2 = Conv2D(neuron*(i+1), (3, 3), padding='same')(x1)\n            \n            x2 = BatchNormalization()(x2)\n            x2 = Activation('relu')(x2)\n\n            x2 = Conv2D(neuron*(i+1), (1, 1), padding='same')(x2)\n            x2 = BatchNormalization()(x2)\n            x2 = Activation('relu')(x2) \n            \n            x3 = Conv2D(neuron*(i+1), (1, 1), padding='same')(x1)\n            \n            x3 = BatchNormalization()(x3)\n            x3 = Activation('relu')(x3)\n\n            x3 = Conv2D(neuron*(i+1), (3, 3), padding='same')(x3)\n            x3 = BatchNormalization()(x3)\n            x3 = Activation('relu')(x3)\n            \n            x4 = Conv2D(neuron*(i+1), (5, 5), padding='same')(x1)\n            \n            x4 = BatchNormalization()(x4)\n            x4 = Activation('relu')(x4)\n\n            \n            x = concatenate([x2,x3,x4,x1], axis = 3 )\n        \n            blocks4 = x\n            \n            blocks_.append(x)\n            \n    \n            # down i\n            x = MaxPooling2D(padding='same')(x)\n            x1 = x\n            print('i: ',i,x)\n    \n     \n    print('x up:',x)\n    x = Conv2D(neuron*(level+1), (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Conv2D(neuron*(level+1), (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    \n    # задаем список скипов\n    print(blocks_)\n    print(x)\n\n    for i in range(level-1,0,-1):\n      # UP i\n      print(i,'x up:',x)\n      x = Conv2DTranspose(neuron*i, (2, 2), strides=(2, 2), padding='same')(x)\n      x = BatchNormalization()(x)\n      x = Activation('relu')(x)\n        \n      x = concatenate([x, blocks_[i]] ) # добавили перенос из понижаюшего плеча \n      x = Conv2D(neuron*i, (3, 3), padding='same')(x)\n      x = BatchNormalization()(x)\n      x = Activation('relu')(x)\n\n      x = Conv2D(neuron*i, (3, 3), padding='same')(x)\n      x = BatchNormalization()(x)\n      x = Activation('relu')(x)\n\n\n    print(x)\n    x = Conv2DTranspose(neuron*i, (2, 2), strides=(2, 2), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    print(-1+i,'x up:',x)    \n    x = concatenate([x, blocks_[0]] ) # добавили перенос из понижаюшего плеча \n    # последний слой сверток для классификации\n    x = Conv2D(neuron, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    if num_classes>1:\n      x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x)\n      # собираем модель \n      print('model:',img_input,x)  \n      model = Model(img_input, x)\n      model.compile(optimizer=Adam(),\n                    loss= 'categorical_crossentropy',#focal, #'\n                    metrics=[dice_coef])\n    else:\n      x = Conv2D(num_classes, (3, 3), activation='sigmoid', padding='same')(x)\n      # собираем модель\n      print('model:',img_input,x) \n      model = Model(img_input, x)\n      model.compile(optimizer=Adam(learning_rate=lr, beta_1=b1, beta_2=b2),\n                    loss = 'mse',\n                    metrics=[dice_coef])\n\n    model.summary()\n    # вернем модель\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"K.clear_session()\nim_size=x[0,:,:,:].shape\nmodel= unet_pre_train(use_pretrain = False,num_classes = 1, input_shape= (im_size[0], im_size[1], im_size[2]), level = 4,neuron = 16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model,'model1.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"es = EarlyStopping(monitor = ['val_loss'], patience = 3)\nmodch = ModelCheckpoint(monitor='val_loss',mode='min',save_best_only=True,save_weights_only=True,verbose=1,filepath='model.{epoch:02d}-{val_loss:.2f}.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.load_weights('./model.hdf5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history1 = model.fit_generator(data_seq, epochs=500, verbose=1,validation_data = data_seq_test) # , callbacks =[es,modch]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('model.h5')\n\nmodel.save_weights('model.HDF5')\nmodel.save_weights('model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first = False #reset history . If I want long history first = False ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if first:\n    history = history1\nelse:\n    history.history['dice_coef'] = history.history['dice_coef']+history1.history['dice_coef']\n    history.history['val_dice_coef'] = history.history['val_dice_coef']+history1.history['val_dice_coef']\n    history.history['loss'] = history.history['loss']+history1.history['loss']\n    history.history['val_loss'] = history.history['val_loss']+history1.history['val_loss']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['dice_coef'])\nplt.plot(history.history['val_dice_coef'])\nplt.title('dice vs Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('dice')\nplt.legend(['Train', 'Val'], loc = 'upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Loss vs Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Val'], loc = 'upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"predicted masks"},{"metadata":{"trusted":true},"cell_type":"code","source":"X,Y = data_seq[0]\nXt,Yt = data_seq_test[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictedt = model.predict(Xt)\nn = 0\nchanel = 0\nfig = plt.figure(figsize = (18,15))\n\nplt.subplot(1,3,1)\nplt.imshow(Xt[n][...,0], cmap = 'bone')\nplt.title('original lung')\n\nplt.subplot(1,3,2)\n#plt.imshow(Xt[n][...,0], cmap = 'bone')\nplt.imshow(Yt[n][...,chanel],alpha = 0.9, cmap = \"nipy_spectral\")\nplt.title('original infection mask')\n\nplt.subplot(1,3,3)\n#plt.imshow(Xt[n][...,0], cmap = 'bone')\nplt.imshow((predictedt[n,:,:,chanel]>predictedt[n,:,:,chanel].mean()*5.0).astype(float),alpha = 0.9,cmap = \"nipy_spectral\")\nplt.title('predicted infection mask')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"откалибруем ответ по тренировочному набору\n\nпросто по несмкольким примерам подбираю порог (можно и получше сдедать) - predicted[n,:,:,chanel]>predicted[n,:,:,chanel].mean()*5.0"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted = model.predict(X)\nn = 10\nchanel = 0\nfig = plt.figure(figsize = (18,15))\n\nplt.subplot(1,3,1)\nplt.imshow(X[n][...,0], cmap = 'bone')\nplt.title('original lung')\n\nplt.subplot(1,3,2)\n#plt.imshow(X[n][...,0], cmap = 'bone')\nplt.imshow(Y[n][...,chanel],alpha = 0.9, cmap = \"nipy_spectral\")\nplt.title('original infection mask')\n\nplt.subplot(1,3,3)\n#plt.imshow(X[n][...,0], cmap = 'bone')\nplt.imshow((predicted[n,:,:,chanel]>predicted[n,:,:,chanel].mean()*5.).astype(float),alpha = 0.9,cmap = \"nipy_spectral\")\nplt.title('predicted infection mask')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Полный размер"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read sample - генератор больших картинок\ndata_seq_test_big_size = DataSequence(data.iloc[-2:,:],20,w_size = 1)\nfor i in range(2):\n    x,y = data_seq_test_big_size[i]\n    print(i,':',x.shape,y.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Создаю модель для полного размера объектовЖ\n\n- строим размер изображения по объекту из генератора (512х512)\n- Создаем сеть UNet+inception для картинки 512х512\n- грузим в нее веса маленькой сети model\n- запускаем визуализацию ответов\n- результат не без огрех, но пойдет"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create big model\n\n\n\nim_size=x[0,:,:,:].shape\nmodel_big_size= unet_pre_train(use_pretrain = False,num_classes = 1, input_shape= (im_size[0], im_size[1], im_size[2]), level = 4,neuron = 16)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loaw weight from model\nmodel_big_size.load_weights('model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test\nXtb,Ytb = data_seq_test_big_size[0]\npredictedtb = model_big_size.predict(Xtb)\nfor i in range(10):\n    n = i\n    chanel = 0\n    fig = plt.figure(figsize = (18,15))\n\n    plt.subplot(1,3,1)\n    plt.imshow(Xtb[n][...,0], cmap = 'bone')\n    plt.title('original lung')\n\n    plt.subplot(1,3,2)\n    #plt.imshow(X[n][...,0], cmap = 'bone')\n    plt.imshow(Ytb[n][...,chanel],alpha = 0.9, cmap = \"nipy_spectral\")\n    plt.title('original infection mask')\n\n    plt.subplot(1,3,3)\n    #plt.imshow(X[n][...,0], cmap = 'bone')\n    plt.imshow((predictedtb[n,:,:,chanel]>predictedtb[n,:,:,chanel].mean()*5.).astype(float),alpha = 0.9,cmap = \"nipy_spectral\")\n    plt.title('predicted infection mask')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_big_size.evaluate_generator(data_seq_test_big_size,verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Пока не очень - нужно учить"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}