{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport os","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Little modification for Hyundai data\n\nHyundai dataset contains a column which includes pound sign before the 'tax' column. So we have to take care of it before concatenating the datasets. We haven't included the two uncleaned versions of some models.","metadata":{}},{"cell_type":"code","source":"df_hyundi = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/hyundi.csv')\ndf_hyundi.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_hyundi = df_hyundi.rename(columns={'tax(Â£)': 'tax'})\ndf_hyundi.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This will get the names of the files in the dataset's folder\nfiles = [file for file in os.listdir('/kaggle/input/used-car-dataset-ford-and-mercedes/')]\nfull_data = pd.DataFrame()\n\nfor file in files:\n    if file in ['hyundi.csv', 'unclean focus.csv', 'unclean cclass.csv']:\n        continue\n    df = pd.read_csv('/kaggle/input/used-car-dataset-ford-and-mercedes/'+file)\n    full_data = pd.concat([full_data, df])\n\nfull_data = pd.concat([full_data, df_hyundi])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.matrix(full_data);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As seen from the missingno matrix, all the missing values are on the same rows. Let's find out which models have missing values and try to find why they are missing.","metadata":{}},{"cell_type":"code","source":"full_data.loc[np.isnan(full_data.tax), 'model'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We had a car with production year 2060, so we are replacing it with the mean year value.\nfull_data.loc[full_data.year > 2020, 'year'] = 2017","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_data.describe()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Only Focus and C Class models have missing values. Now we have to find out if all of the C Class (and Focus) models have missing values or only a part of them are missing. There are some spaces in the the model names of 'model' column. We're going to strip those spaces in order to use them for conditional subsetting.","metadata":{}},{"cell_type":"code","source":"full_data.model = full_data.model.str.strip()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(full_data[full_data.model == 'C Class']), len(full_data[full_data.model == 'Focus']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_no = full_data[full_data['mpg'].isnull()]['model'].value_counts()\nmissing_no.plot.barh()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A great part of these two models are missing. Let's fill them with random values drawn one standard deviation range around the mean.","metadata":{}},{"cell_type":"code","source":"cols = ['tax', 'mpg']\n\nfor col in cols:\n    mean_val = full_data[col].mean()\n    std_val = full_data[col].std()\n    nan_count = full_data[col].isnull().sum()\n    rand_values = np.random.randint(mean_val-std_val, mean_val+std_val, size=nan_count)\n    \n    col_copy = full_data[col].copy()\n    col_copy[np.isnan(col_copy)] = rand_values\n    full_data[col] = col_copy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(full_data.corr(), annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- People who want to buy a new car have to pay higher tax compared to older cars.\n- Engine size and year highly affects the price of a car.\n- Higher mileage means lower price.\n- Correlation between mileage and year is highly negatively correlated.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(2,2, figsize=(15,10))\nsns.histplot(full_data.price, kde=True, ax=ax[0,0])\nsns.countplot(x='transmission', data=full_data, hue='fuelType', ax=ax[0,1])\nsns.lineplot(x='year', y='price', data=full_data[full_data.year > 1995], ci=None, ax=ax[1,0])\nsns.scatterplot(x='mileage', y='price', data=full_data[full_data.year > 1995], ax=ax[1,1]);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Price column has positive skewness, meaning most of the cars are lower than 50000. As expected, lower mileage means higher price. 0 mileage cars are the most expensive ones.","metadata":{}},{"cell_type":"code","source":"transmission_share = pd.crosstab(full_data.transmission, full_data.fuelType).apply(lambda x: round(x/x.sum() * 100, 2), axis=1)\ntransmission_share['Total'] = full_data.transmission.value_counts()\ntransmission_share['Total perc.'] = round(transmission_share['Total'] / transmission_share['Total'].sum() * 100, 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transmission_share","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Manual cars are dominating the market. More than half of the used cars are manual cars and the majority of them use petrol as fuel. But is there any significant price difference between them?","metadata":{}},{"cell_type":"code","source":"full_data.groupby('transmission')['price'].mean().sort_values().plot.barh();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_data.groupby('transmission')['price'].median().sort_values().plot.barh();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_data['mpg'].plot.hist(bins=50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see that most of the mpg values are under 100 and an mpg value higher than 100 is unrealistic, no car can drive 160 km with only 3.55 liters. Let's divide mpg values which are higher than 100 by 6.","metadata":{}},{"cell_type":"code","source":"def get_real_mpg(value):\n    if value > 100:\n        return round(value / 6, 1)\n    else:\n        return value\n    \n\nfull_data['mpg'] = full_data['mpg'].apply(get_real_mpg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_data['mpg'].plot.hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's encode 'transmission', and 'fuelType' columns and drop the model column, as it's not helpful for us. It'd be a great idea to encode the models into brands, like 'A1', 'A3' etc. into Audi and so on. But we haven't done it here. Because I wanted to concatenate all datasets into one and it would've taken a little time to encode the models into brands. ","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nfull_data.drop('model', axis=1, inplace=True)\n\nle=LabelEncoder()\n\nfor col in full_data.columns.to_numpy():\n    if full_data[col].dtypes=='object':\n        full_data[col]=le.fit_transform(full_data[col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_data = full_data.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's split the data into train, validation and test sets. After that we will scale the dataset","metadata":{}},{"cell_type":"code","source":"train, val, test = np.split(full_data.sample(frac=1), [int(.6*len(full_data)), int(.8*len(full_data))])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train), len(val), len(test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before scaling the dataset, we should split them into X and y.","metadata":{}},{"cell_type":"code","source":"X_train = train.drop('price', axis=1)\ny_train = train['price']\n\nX_val = val.drop('price', axis=1)\ny_val = val['price']\n\nX_test = test.drop('price', axis=1)\ny_test = test['price']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nscaledX_train = sc.fit_transform(X_train)\nscaledX_val = sc.transform(X_val)\nscaledX_test = sc.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We've done everything for fitting a model. Now let's try some models.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error\n\nrfr_reg = RandomForestRegressor(min_samples_leaf = 0.01)\nen_reg = ElasticNet(alpha=0.1, l1_ratio=0.5)\ndtr_reg = DecisionTreeRegressor()\n\nfor regressor in (rfr_reg, en_reg, dtr_reg):\n    regressor.fit(scaledX_train, y_train)\n    y_pred = regressor.predict(scaledX_val)\n    print(regressor.__class__.__name__, np.sqrt(mean_squared_error(y_val, y_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seems like Random Forest and Decision Tree models are better than the ElasticNet. So let's tune them!","metadata":{}},{"cell_type":"code","source":"param_grid_rfr = [{'n_estimators': [3,10,30], 'max_features': [2,4,6]},\n                  {'bootstrap': [False], 'n_estimators': [3,10], 'max_features': [2,3,4]}]\nparam_grid_dtr = {'max_features': [2,4,6], 'min_samples_split': [0.1, 0.01]}\n\nfrom sklearn.model_selection import GridSearchCV\n\ngrid_search_rfr = GridSearchCV(rfr_reg, param_grid_rfr, cv=3, scoring='neg_mean_squared_error')\ngrid_search_dtr = GridSearchCV(dtr_reg, param_grid_dtr, cv=3, scoring='neg_mean_squared_error')\n\n#Since tree based models need no scaling, we will use the unscaled versions\ngrid_search_rfr.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_search_dtr.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_rfr_model = grid_search_rfr.best_estimator_\nbest_dtr_model = grid_search_dtr.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model in (best_rfr_model, best_dtr_model):\n    y_val_pred = model.predict(X_val)\n    print(np.sqrt(mean_squared_error(y_val, y_val_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Random Forest model got better, but the Decision tree model's score has worsened. Let's try a new, untuned Decision Tree model and the tuned Random Forest model to predict the test set.","metadata":{}},{"cell_type":"code","source":"dtr_reg_new = DecisionTreeRegressor()\ndtr_reg_new.fit(X_train, y_train)\n\nfor model in (best_rfr_model, dtr_reg_new):\n    y_test_pred = model.predict(X_test)\n    print(np.sqrt(mean_squared_error(y_test, y_test_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"They are not so bad, they achieved similar scores with the validation set. So our model isn't overfitting. Let's try another metric called r-squared and finish our analysis.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import r2_score\n\nfor model in (best_rfr_model, dtr_reg_new):\n    y_test_pred = model.predict(X_test)\n    print(r2_score(y_test, y_test_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Maximum possible value is 1. Our data could be improved by adding a brand column and encoding it into labels (0,1,2...) and some work could be done on correlation problems, like the correlation between the age and mileage columns. We could also spend some time on other columns, like mpg and tax. If you like, you may try and improve the data from this notebook. See you!","metadata":{}}]}