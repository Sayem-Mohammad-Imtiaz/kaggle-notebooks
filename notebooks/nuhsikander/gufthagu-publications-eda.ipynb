{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\n\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport os\nimport seaborn as sns\n\nfrom fuzzywuzzy import process, fuzz\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\npd.set_option('mode.chained_assignment',None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load & View Data Properties"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/gufhtugu-publications-dataset-challenge/GP Orders - 4.csv',encoding='utf-8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cleaning up the Values for Further Analysis\n#### Not sure, if that '??' was actually in Urdu Script"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.columns = dataset.columns.str.replace(' ', '_')\ndataset['Book_Name'] = dataset['Book_Name'].str.replace('?','')\ndataset['Book_Name'] = dataset['Book_Name'].str.replace(' ','')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets see from which Area we've got most orders"},{"metadata":{"trusted":true},"cell_type":"code","source":"city_wise_orders = dataset.groupby('City_(Billing)')['Order_Number'].nunique().sort_values(ascending=False).head(5)\nprint(city_wise_orders.index)\ncity_wise_orders_top_5 = dataset[dataset['City_(Billing)'].isin(city_wise_orders.index)]\ncity_wise_orders_top_5 = city_wise_orders_top_5[['Order_Number','City_(Billing)']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Picking the top 5 Cities"},{"metadata":{"trusted":true},"cell_type":"code","source":"orders_top_5 = dataset[dataset['City_(Billing)'].isin(city_wise_orders.index)]\nplt.figure(figsize=(10,7))\nsns.countplot(y=\"Order_Status\", data=orders_top_5,order = orders_top_5['Order_Status'].value_counts().index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.countplot(y=\"City_(Billing)\", data=city_wise_orders_top_5,order = city_wise_orders_top_5['City_(Billing)'].value_counts().index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `City_(Billing)` column is not clean, The top counts are not accurate becuase we've got a lot of typos and full adresses instead of Cities. Lets have a quick peek if that's true."},{"metadata":{"trusted":true},"cell_type":"code","source":"process.extract('Lahore', dataset['City_(Billing)'].unique(), scorer=fuzz.token_sort_ratio)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So there are a lot of LAHOREs here :). I'll not be cleaning them but this can be achieved via `fuzzywuzzy`"},{"metadata":{},"cell_type":"markdown","source":"### Lets dive into Karachi and slice the data further;"},{"metadata":{"trusted":true},"cell_type":"code","source":"karachi_orders = dataset[dataset['City_(Billing)'].isin(['Karachi'])]\nprint(karachi_orders.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"karachi_orders.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"karachi_orders['Order_Date']= pd.to_datetime(karachi_orders['Order_Date'])\nprint(karachi_orders.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"karachi_orders['Order_Date'].min(), karachi_orders['Order_Date'].max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We've data from Oct 2019, till Jan 2021.\n\nLets create the Day, Month and Year Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"karachi_orders['year'] = pd.DatetimeIndex(karachi_orders['Order_Date']).year\nkarachi_orders['month'] = pd.DatetimeIndex(karachi_orders['Order_Date']).month\nkarachi_orders['day'] = pd.DatetimeIndex(karachi_orders['Order_Date']).dayofweek","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,3))\nsns.countplot(y=\"year\", data=karachi_orders,order = karachi_orders['year'].value_counts().index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It makes sense, We've got only 2 months data for 2019, and bearly a Month's data for 2021.\n\nLets take only **2020's** data"},{"metadata":{"trusted":true},"cell_type":"code","source":"karachi_orders_2020 = karachi_orders[karachi_orders['year'].isin(['2020'])]\nplt.figure(figsize=(15,7))\nsns.countplot(y=\"month\", data=karachi_orders_2020,order = karachi_orders_2020['month'].value_counts().index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Intersting, Seems the case where people are setting there New year's target :). Major orders are from **November** and **December**."},{"metadata":{},"cell_type":"markdown","source":"### Trend of top Cities - Month Wise "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\ncity_wise_data_top_5 = dataset[dataset['City_(Billing)'].isin(city_wise_orders.index)]\ncity_wise_data_top_5['Order_Date']= pd.to_datetime(city_wise_data_top_5['Order_Date'])\ncity_wise_data_top_5['month'] = pd.DatetimeIndex(city_wise_data_top_5['Order_Date']).month\ncity_wise_data_top_5['year'] = pd.DatetimeIndex(city_wise_data_top_5['Order_Date']).year\ncity_wise_data_top_5 = city_wise_data_top_5[city_wise_data_top_5['year'].isin(['2020'])]\ncity_wise_data_top_5_agg = city_wise_data_top_5.groupby(['City_(Billing)','month'])['Order_Number'].count().reset_index().rename(columns={'Order_Number':'order_count'})\nsns.lineplot(data=city_wise_data_top_5_agg, x=\"month\", y=\"order_count\", hue=\"City_(Billing)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not sure why, but top cities seems to follow a pattern (Like the spikes in 5th and 8th Month). Probably its becuase of some campaign or discounts on Gufthagu. "},{"metadata":{},"cell_type":"markdown","source":"### Lets see a day wise breakup now"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nsns.countplot(y=\"day\", data=karachi_orders_2020,order = karachi_orders_2020['day'].value_counts().index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I should have encoded these to Names but FYI; Monday is denoted by 0 and ends on Sunday which is denoted by 6\n\nSo major order are placed on **Saturdays**."},{"metadata":{},"cell_type":"markdown","source":"### Lets see which book was famous in Karachi"},{"metadata":{"trusted":true},"cell_type":"code","source":"# karachi_orders_2020['Book_Name'].value_counts()\nkarachi_orders_2020_top_books = karachi_orders_2020.groupby('Book_Name')['Order_Number'].nunique().sort_values(ascending=False).head(5)\nprint(karachi_orders_2020_top_books)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(karachi_orders_2020.shape[0])\nkarachi_orders_2020['Book_Name'] = karachi_orders_2020['Book_Name'].replace('', np.nan)\nkarachi_orders_2020.dropna(inplace=True)\nprint(karachi_orders_2020.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"karachi_orders_2020_top_books = karachi_orders_2020.groupby('Book_Name')['Order_Number'].nunique().sort_values(ascending=False).head(5)\nkarachi_orders_2020_top_books = dataset[dataset['Book_Name'].isin(karachi_orders_2020_top_books.index)]\nplt.figure(figsize=(15,7))\nsns.countplot(y=\"Book_Name\", data=karachi_orders_2020_top_books,order = karachi_orders_2020_top_books['Book_Name'].value_counts().index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shout Out to Zeeshan ul Hassan on getting the top position for his Book in Karachi.\n\nI feel honored coding this notebook in Python :D - Because it was pretty hot in 2020\n\nNot to forget we've not Cleansed the Book names yet *(Not sure if there are any typos in Book Names)*. If so, the ranking will surely differ after we sort out the Nomenclature"},{"metadata":{},"cell_type":"markdown","source":"## Lets build a wordclould of all Ordered Booknames - English"},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\ncomment_words = [' ','?']\nstopwords = set(STOPWORDS) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/gufhtugu-publications-dataset-challenge/GP Orders - 2.csv',encoding='unicode_escape')\ndataset.columns = dataset.columns.str.replace(' ', '_')\nbook_words = []\nfor i in dataset.Book_Name: \n    i = str(i) \n    separate = i.split()\n    for j in range(len(separate)): \n        separate[j] = separate[j].lower() \n    book_words+=(separate)\nword_str = ' '.join([str(elem) for elem in book_words])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wordcloud = WordCloud(width = 1600, height = 800, background_color ='white', stopwords = stopwords, min_font_size = 10).generate(word_str)                      \nplt.figure(figsize = (15, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0) \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note**: The wordcloud is plotted on old CSV. I wasn't able to spend some time on setting it up for Urdu Characters as well.\nLeaving it for someone to take up :)"},{"metadata":{},"cell_type":"markdown","source":"Product Managment, Python, AI and Blockchain seems prominent.\n\nIt would be interesting to see bigrams plotted not just individual words to get more context."},{"metadata":{},"cell_type":"markdown","source":"## Now lets check only the Books that were returned"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/gufhtugu-publications-dataset-challenge/GP Orders - 4.csv',encoding='utf-8')\ndataset.columns = dataset.columns.str.replace(' ', '_')\ndataset_returned = dataset[dataset['Order_Status'].isin(['Returned'])]\ndataset_returned_top_5 = dataset_returned[dataset_returned['City_(Billing)'].isin(city_wise_orders.index)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_returned_top_5.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Returned by City amoung top Cities"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"City_(Billing)\", data=dataset_returned_top_5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_one_hot = pd.get_dummies(dataset, columns = ['Order_Status'])\ndataset_one_hot.head()\ndataset_one_hot['Order_Date']= pd.to_datetime(dataset_one_hot['Order_Date'])\ndataset_one_hot['year'] = pd.DatetimeIndex(dataset_one_hot['Order_Date']).year\ndataset_one_hot['month'] = pd.DatetimeIndex(dataset_one_hot['Order_Date']).month\ndataset_one_hot['day'] = pd.DatetimeIndex(dataset_one_hot['Order_Date']).dayofweek\ndataset_one_hot = dataset_one_hot[dataset_one_hot['year'].isin(['2020'])]\ncorr_cols = ['month','day','Order_Status_Canceled','Order_Status_Returned','Order_Status_Completed']\ncorr = dataset_one_hot[corr_cols].corr()\nsns.heatmap(corr,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Seems like Returns are likely to increase as we move ahead in a Year - Slight Correlation with Month-IDs. \n\n#### Don’t mix it with Causation, it might be a trend that doesn’t make any sense."},{"metadata":{},"cell_type":"markdown","source":"Lets quickly vertify if thats happening"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_t5 = dataset_one_hot[dataset_one_hot['City_(Billing)'].isin(city_wise_orders.index)]\ndataset_t5 = dataset_t5.groupby(['month','City_(Billing)']).sum()[[\"Order_Status_Returned\", \"Order_Status_Completed\",\"Order_Status_Canceled\"]].reset_index()\nsns.scatterplot(data=dataset_t5, x=\"month\", y=\"Order_Status_Returned\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can see that returns are in an increasing patterns as we move though the timeline (2020-Months)"},{"metadata":{},"cell_type":"markdown","source":"# Things that I'll try to do;\n\n* Try Fuzzy match on Cities to get an accurate picture\n* Try to predict the orders for next month\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}