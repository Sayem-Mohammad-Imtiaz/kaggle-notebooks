{"cells":[{"metadata":{},"cell_type":"markdown","source":"# פרוייקט למידה חישובית"},{"metadata":{},"cell_type":"markdown","source":"## Introduction\n\n* Context\nIt is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n\n* Content\nThe dataset can be downloaded from here: https://www.kaggle.com/mlg-ulb/creditcardfraud.\nThe datasets contains transactions made by credit cards in September 2013 by european cardholders.\nThis dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n\nIt contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, … V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."},{"metadata":{},"cell_type":"markdown","source":"### Prerequisites\nInstall imblearn and upgrade sklearn to 0.19.0"},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install imblearn\n#!pip install --upgrade sklearn","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2017-04-09T22:20:27.179264Z","start_time":"2017-04-09T22:20:27.1701+00:00"},"trusted":true},"cell_type":"code","source":"import os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Import data `creditcard.csv`. "},{"metadata":{"ExecuteTime":{"end_time":"2017-04-09T22:20:28.243815Z","start_time":"2017-04-09T22:20:27.572024+00:00"},"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndata = pd.read_csv('../input/creditcardfraud/creditcard.csv', sep=',')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2017-04-09T22:20:28.265947Z","start_time":"2017-04-09T22:20:28.245694+00:00"},"trusted":true},"cell_type":"code","source":"data.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The prediction should definitely not include time, that in this case is just like an id field.\n* Normal amount column\n* Change name from 'class' to 'fraud', as boolean."},{"metadata":{"ExecuteTime":{"end_time":"2017-04-09T22:20:28.468823Z","start_time":"2017-04-09T22:20:28.458898+00:00"},"trusted":true},"cell_type":"code","source":"data.drop(['Time'], axis=1, inplace=True)\ndata.rename(columns={'Class': 'Fraud'}, inplace=True)\ndata['Fraud'] = data['Fraud'].astype(np.bool)\n\nmean_amount = data['Amount'].mean()\nstd_amount = data['Amount'].std()\ndata['Amount'] = (data['Amount'] - mean_amount) / std_amount\n\ndata.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_amount, std_amount","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Examine the data types."},{"metadata":{"ExecuteTime":{"end_time":"2017-04-09T22:20:29.42802Z","start_time":"2017-04-09T22:20:29.37055+00:00"},"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"data[['Fraud']].dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check correlation\nIf there is a very high correlation between two features, keeping both of them is not a good idea most of the time not to cause overfitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sn\nsn.heatmap(data.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check count of each fraud"},{"metadata":{"ExecuteTime":{"end_time":"2017-04-09T22:20:30.831794Z","start_time":"2017-04-09T22:20:30.81628+00:00"},"trusted":true},"cell_type":"code","source":"data.Fraud.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2017-04-09T22:20:32.0191Z","start_time":"2017-04-09T22:20:32.008509+00:00"},"trusted":true},"cell_type":"code","source":"data.Fraud.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndata[\"Fraud\"].value_counts().plot(kind = 'pie',explode=[0, 0.1],figsize=(6, 6),autopct='%1.1f%%',shadow=True)\nplt.title(\"Fraudulent and Non-Fraudulent Distribution\",fontsize=20)\nplt.legend([\"Genuine\",\"Fraud\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# split data"},{"metadata":{"ExecuteTime":{"end_time":"2017-04-09T22:20:34.008973Z","start_time":"2017-04-09T22:20:33.561995+00:00"},"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\nfeature_cols = [x for x in data.columns if x != 'Fraud']\n\n# Split the data into two parts with 1500 points in the test data\n# This creates a generator\nstrat_shuff_split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n\n# Get the index values from the generator\ntrain_idx, test_idx = next(strat_shuff_split.split(data[feature_cols], data['Fraud']))\n\n# Create the data sets\nX_train = data.loc[train_idx, feature_cols]\ny_train = data.loc[train_idx, 'Fraud']\n\nX_test = data.loc[test_idx, feature_cols]\ny_test = data.loc[test_idx, 'Fraud']","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2017-04-09T22:20:34.042556Z","start_time":"2017-04-09T22:20:34.035557+00:00"},"scrolled":true,"trusted":true},"cell_type":"code","source":"y_train.value_counts(normalize=False), y_train.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2017-04-09T22:20:36.968198Z","start_time":"2017-04-09T22:20:36.960274+00:00"},"trusted":true},"cell_type":"code","source":"y_test.value_counts(normalize=False), y_test.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score\nfrom sklearn.metrics import f1_score, roc_auc_score\n\ndef scores(y_train, y_train_pred, y_test, y_test_pred):\n    score_df = pd.DataFrame({\n        'set': ['Train', 'Test'], \n        'accuracy': [accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred)],\n        'precision': [precision_score(y_train, y_train_pred), precision_score(y_test, y_test_pred)],\n        'recall': [recall_score(y_train, y_train_pred), recall_score(y_test, y_test_pred)],\n        'f1': [f1_score(y_train, y_train_pred), f1_score(y_test, y_test_pred)],\n        'auc': [roc_auc_score(y_train, y_train_pred), roc_auc_score(y_test, y_test_pred)]\n    })\n    score_df.set_index('set')\n    print(score_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_scores = []\n\ndef add_test_scores(name, y_test, y_test_pred):\n    test_scores.append({\n        'name': name, \n        'accuracy': accuracy_score(y_test, y_test_pred),\n        'precision': precision_score(y_test, y_test_pred),\n        'recall': recall_score(y_test, y_test_pred),\n        'f1': f1_score(y_test, y_test_pred),\n        'auc': roc_auc_score(y_test, y_test_pred)\n    })","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PCA - prepare data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA().fit(X_train)\nprint(pca.explained_variance_ratio_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_components = 10\nprint(sum(list(pca.explained_variance_ratio_[0:n_components])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first 10 most important pca components hold about 2/3 of the data"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=n_components).fit(X_train)\nX_train_pca = pca.fit_transform(X_train)\nX_test_pca = pca.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(max_iter=1000).fit(X_train, y_train)\ny_train_pred = clf.predict(X_train)\ny_test_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_test_scores('Logistic Regression', y_test, y_test_pred)\nscores(y_train, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression on PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_pca = LogisticRegression().fit(X_train_pca, y_train)\ny_train_pca_pred = clf_pca.predict(X_train_pca)\ny_test_pca_pred = clf_pca.predict(X_test_pca)\n\nadd_test_scores('Logistic Regression PCA', y_test, y_test_pca_pred)\nscores(y_train, y_train_pca_pred, y_test, y_test_pca_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import svm model\nfrom sklearn.svm import SVC\n\n#Create a svm Classifier\nsvm_linear = SVC(kernel='linear') # Linear Kernel\n\n#Train the model using the training sets\nsvm_linear.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predict the response for test dataset\ny_train_pred = svm_linear.predict(X_train)\ny_test_pred = svm_linear.predict(X_test)\n\nadd_test_scores('SVM Linear', y_test, y_test_pred)\nscores(y_train, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM with polynom kernel"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvclassifier = SVC(kernel='poly', degree=8)\nsvclassifier = svclassifier.fit(X_train, y_train)\ny_test_pred = svclassifier.predict(X_test)\ny_train_pred = svclassifier.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"add_test_scores('SVM poly', y_test, y_test_pred)\nscores(y_train, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_rbg_pca = SVC(kernel='rbf', )\nsvm_rbg_pca.fit(X_train_pca, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = svm_rbg_pca.predict(X_train_pca)\ny_test_pred = svm_rbg_pca.predict(X_test_pca)\n\nadd_test_scores('SVM RBF - PCA', y_test, y_test_pred)\nscores(y_train, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Don't run! very slow!"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.model_selection import GridSearchCV\n\n#param_grid = { 'C': [c for c in range(1, 11)] }\n\n#GR = GridSearchCV(SVC(kernel='linear'),\n#                  param_grid=param_grid,\n#                  scoring='f1',\n#                  n_jobs=-1)\n\n#GR = GR.fit(X_train_pca, y_train)\n#GR.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The result is:\nSVC(C=1, kernel='linear')"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"svm_linear_pca = SVC(kernel='linear', C=1)\nsvm_linear_pca.fit(X_train_pca, y_train)\ny_train_pred = svm_linear_pca.predict(X_train_pca)\ny_test_pred = svm_linear_pca.predict(X_test_pca)\n\nadd_test_scores('SVM Linear - PCA', y_test, y_test_pred)\nscores(y_train, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Decision tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\ndt = DecisionTreeClassifier()\ndt = dt.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of nodes and the maximum actual depth."},{"metadata":{"trusted":true},"cell_type":"code","source":"dt.tree_.node_count, dt.tree_.max_depth","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = dt.predict(X_train)\ny_test_pred = dt.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_test_scores('Decision tree', y_test, y_test_pred)\nscores(y_train, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Grid search on decision tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {'max_depth':range(1, dt.tree_.max_depth+1, 2),\n              'max_features': range(1, len(dt.feature_importances_)+1)}\n\nGR = GridSearchCV(DecisionTreeClassifier(random_state=42),\n                  param_grid=param_grid,\n                  scoring='f1',\n                  n_jobs=-1)\n\nGR = GR.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of nodes and the maximum depth of the tree."},{"metadata":{"trusted":true},"cell_type":"code","source":"GR.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GR.best_estimator_.tree_.node_count, GR.best_estimator_.tree_.max_depth","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = GR.predict(X_train)\ny_test_pred = GR.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_test_scores('Decision tree grid search', y_test, y_test_pred)\nscores(y_train, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The tree fit without cross validation."},{"metadata":{"trusted":true},"cell_type":"code","source":"from io import StringIO\nfrom IPython.display import Image, display\n\nfrom sklearn.tree import export_graphviz\n\ntry:\n    import pydotplus\n    pydotplus_installed = True\n    \nexcept:\n    print('PyDotPlus must be installed to execute the remainder of the cells associated with this question.')\n    print('Please see the instructions for this question for details.')\n    pydotplus_installed = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if pydotplus_installed:\n    \n    # Create an output destination for the file\n    dot_data = StringIO()\n\n    export_graphviz(dt, out_file=dot_data, filled=True)\n    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n    print(graph)\n    # View the tree image\n    filename = 'fraud_tree.png'\n    graph.write_png(filename)\n    img = Image(filename=filename)\n    display(img)\n    \nelse:\n    print('This cell not executed because PyDotPlus could not be loaded.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The tree fit with cross validation."},{"metadata":{"trusted":true},"cell_type":"code","source":"if pydotplus_installed:\n    \n    # Create an output destination for the file\n    dot_data = StringIO()\n\n    export_graphviz(GR.best_estimator_, out_file=dot_data, filled=True)\n    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n\n    # View the tree image\n    filename = 'fraud_tree_prune.png'\n    graph.write_png(filename)\n    img = Image(filename=filename) \n    display(img)\n    \nelse:\n    print('This cell not executed because PyDotPlus could not be loaded.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KNN"},{"metadata":{},"cell_type":"markdown","source":"### Grid Search for ideal n_neighbors - Don't run! bery slow!"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#param_grid = { 'n_neighbors': [n for n in range(1, 10, 2)] }\n\n#GR = GridSearchCV(KNeighborsClassifier(),\n#                 param_grid=param_grid,\n#                 scoring='f1',\n#                 n_jobs=-1)\n\n#GR_knn = GR.fit(X_train, y_train)\n#GR_knn.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The result is:\nKNeighborsClassifier(n_neighbors=3)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = KNeighborsClassifier(n_neighbors=3)\nclassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Also very slow, unfortunately..."},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_train_pred = classifier.predict(X_train)\n#y_test_pred = classifier.predict(X_test)\n#scores(y_train, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`    set  accuracy  precision    recall        f1       auc\n0  Train  0.999649   0.969178  0.822674  0.889937  0.911315\n1   Test  0.999473   0.918699  0.763514  0.833948  0.881698`"},{"metadata":{"trusted":true},"cell_type":"code","source":"# so will update the scores manually\ntest_scores.append({\n        'name': 'KNN', \n        'accuracy': 0.999473,\n        'precision': 0.918699,\n        'recall': 0.763514,\n        'f1': 0.833948,\n        'auc': 0.881698\n    })","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### GridSearch for KNN on PCA gives same results - n_neighbors=3"},{"metadata":{"trusted":true},"cell_type":"code","source":"#param_grid = { 'n_neighbors': [n for n in range(1, 10, 2)] }\n\n#GR = GridSearchCV(KNeighborsClassifier(),\n#                 param_grid=param_grid,\n#                 scoring='f1',\n#                 n_jobs=-1)\n\n#GR_knn_pca = GR.fit(X_train_pca, y_train)\n#GR_knn_pca.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### And it is lighter to run, but worse f1 results:"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = KNeighborsClassifier(n_neighbors=3)\nclassifier.fit(X_train_pca, y_train)\ny_train_pred = classifier.predict(X_train_pca)\ny_test_pred = classifier.predict(X_test_pca)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_test_scores('KNN - PCA', y_test, y_test_pred)\nscores(y_train, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Balanced Data - Over Sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn import over_sampling as os_smote\nos_sm = os_smote.SMOTE(random_state=42, n_jobs=-1, sampling_strategy=0.1)\nX_train_os, y_train_os = os_sm.fit_resample(X_train, y_train)\ny_train_os.value_counts(), y_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_os = PCA().fit(X_train_os)\nprint(pca_os.explained_variance_ratio_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_components = 10\nprint(sum(list(pca_os.explained_variance_ratio_[0:n_components])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_os = PCA(n_components=n_components).fit(X_train_os)\nX_train_os_pca = pca_os.fit_transform(X_train_os)\nX_test_pca = pca_os.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logisitc Regression on Over Sampling Balanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclf_os = LogisticRegression(max_iter=1000).fit(X_train_os, y_train_os)\ny_train_pred = clf_os.predict(X_train_os)\ny_test_pred = clf_os.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_test_scores('Logistic Regression on Over Sampling Balanced Data', y_test, y_test_pred)\nscores(y_train_os, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_pca = LogisticRegression().fit(X_train_os_pca, y_train_os)\ny_train_pred = clf_pca.predict(X_train_os_pca)\ny_test_pred = clf_pca.predict(X_test_pca)\n\nadd_test_scores('Logistic Regression on Over Sampling Balanced Data PCA', y_test, y_test_pred)\nscores(y_train_os, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gradient Boosting on Over Sampling Balanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\nparam_grid = { \n    'learning_rate': [0.1], #[0.01, 0.05, 0.1, 0.15, 0.2],\n    'n_estimators': [200], #range(100, 400, 50),\n    'max_features': [5] # [1, 5, 10]\n}\n\nGR = GridSearchCV(GradientBoostingClassifier(subsample=0.5, random_state=42),\n                 param_grid=param_grid,\n                 scoring='f1',\n                 n_jobs=-1)\n\nGR_boosting = GR.fit(X_train_os, y_train_os)\nGR_boosting.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = GR_boosting.predict(X_train_os)\ny_test_pred = GR_boosting.predict(X_test)\n\nadd_test_scores('Boosting - Over Sampling', y_test, y_test_pred)\nscores(y_train_os, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gradient Boosting on Over Sampling Balanced Data PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\nparam_grid = { \n    'learning_rate': [0.1], #[0.01, 0.05, 0.1, 0.15, 0.2],\n    'n_estimators': [200], #range(100, 400, 50),\n    'max_features': [5] #[1, 5, 10]\n}\n\nGR = GridSearchCV(GradientBoostingClassifier(subsample=0.5, random_state=42),\n                 param_grid=param_grid,\n                 scoring='f1',\n                 n_jobs=-1)\n\nGR_boosting = GR.fit(X_train_os_pca, y_train_os)\nGR_boosting.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = GR_boosting.predict(X_train_os_pca)\ny_test_pred = GR_boosting.predict(X_test_pca)\n\nadd_test_scores('Boosting - Over Sampling PCA', y_test, y_test_pred)\nscores(y_train_os, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SVM on Balanced Data - too heavy to compute.\n### Trying with under sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\nus = RandomUnderSampler(sampling_strategy=0.1)\nX_train_us, y_train_us = us.fit_resample(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_us.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression Under Sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_os = LogisticRegression(max_iter=1000).fit(X_train_us, y_train_us)\ny_train_pred = clf_os.predict(X_train_us)\ny_test_pred = clf_os.predict(X_test)\n\nadd_test_scores('Linear Regression - Under Sampling', y_test, y_test_pred)\nscores(y_train_us, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM Kernel Polynom"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm_linear = SVC(kernel='poly', degree=1, C=0.01)\nsvm_linear.fit(X_train_us, y_train_us)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = svm_linear.predict(X_train_us)\ny_test_pred = svm_linear.predict(X_test)\n\nadd_test_scores('SVM Poly - Under Sampling', y_test, y_test_pred)\nscores(y_train_us, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM Kernel RBF"},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_rbg = SVC(kernel='rbf', C=0.01)\nsvm_rbg.fit(X_train_us, y_train_us)\n\ny_train_pred = svm_rbg.predict(X_train_us)\ny_test_pred = svm_rbg.predict(X_test)\n\nadd_test_scores('SVM RGB - Under Sampling', y_test, y_test_pred)\nscores(y_train_us, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KNN Under Sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = { 'n_neighbors': [n for n in range(1, 11)] }\n\nGR = GridSearchCV(KNeighborsClassifier(),\n                 param_grid=param_grid,\n                 scoring='f1',\n                 n_jobs=-1)\n\nGR_knn = GR.fit(X_train_us, y_train_us)\nGR_knn.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = GR_knn.predict(X_train_us)\ny_test_pred = GR_knn.predict(X_test)\n\nadd_test_scores('KNN - Under Sampling', y_test, y_test_pred)\nscores(y_train_us, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gradient Descents Under Sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\nparam_grid = { \n    'learning_rate': [0.05], #[0.01, 0.05, 0.1, 0.15, 0.2],\n    'n_estimators': [300], #range(100, 400, 50),\n    'max_features': [1] #[1, 5, 10]\n}\n\nGR = GridSearchCV(GradientBoostingClassifier(random_state=42),\n                 param_grid=param_grid,\n                 scoring='f1',\n                 n_jobs=-1)\n\nGR_boosting = GR.fit(X_train_us, y_train_us)\nGR_boosting.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = GR_boosting.predict(X_train_us)\ny_test_pred = GR_boosting.predict(X_test)\n\nadd_test_scores('Boosting - Under Sampling', y_test, y_test_pred)\nscores(y_train_us, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Boosting - Under Sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nEC = ExtraTreesClassifier(n_estimators=100, max_features=1)\nEC = EC.fit(X_train_us, y_train_us)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = EC.predict(X_train_us)\ny_test_pred = EC.predict(X_test)\n\nadd_test_scores('Bagging - Under Sampling', y_test, y_test_pred)\nscores(y_train_us, y_train_pred, y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Show all the results, sorted by F1 field"},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.DataFrame(test_scores).sort_values(by='f1', ascending=False, ignore_index=True)\nresults","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}