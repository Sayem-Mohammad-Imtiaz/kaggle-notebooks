{"cells":[{"metadata":{},"cell_type":"markdown","source":"Welcome, \n\nThe aim of this project is try to make various classifications and identifications from a visual. Keras Conv2D Layers and 500 images will be use for each training models. You can get better results  by changing image sizes and model variations.  "},{"metadata":{},"cell_type":"markdown","source":"**Introduction:**\n\n\n1. Import necessary libraries \n2. Get info from dataset\n3. Create list for each future (true or false)\n4. Define function, reshape images to prepare training\n5. Make models for each list\n6. Train model\n7. Make prediction \n8. Display result"},{"metadata":{},"cell_type":"markdown","source":"Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport keras\nimport matplotlib.pyplot as plt\nfrom cv2 import cv2 \nfrom PIL import Image\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get data info using pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/celeba-dataset/list_attr_celeba.csv', encoding='utf-8')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create list for classify features. This list will use in models for prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"male_list = df[(df['Male'] == 1)]['image_id'].head(500).values.tolist()\nfemale_list = df[(df['Male'] == -1)]['image_id'].head(500).values.tolist()\n\nglasses_list = df[(df['Eyeglasses'] == 1)]['image_id'].head(500).values.tolist()\nno_glasses_list = df[(df['Eyeglasses'] == -1)]['image_id'].head(500).values.tolist()\n\nsmile_list = df[(df['Smiling'] == 1)]['image_id'].head(500).values.tolist()\nnotsmile_list = df[(df['Smiling'] == -1)]['image_id'].head(500).values.tolist()\n\nmakeup_list = df[(df['Heavy_Makeup'] == 1)]['image_id'].head(500).values.tolist()\nnomakeup_list = df[(df['Heavy_Makeup'] == -1)]['image_id'].head(500).values.tolist()\n\nbald_list = df[(df['Bald'] == 1)]['image_id'].head(500).values.tolist()\nnotbald_list = df[(df['Bald'] == -1)]['image_id'].head(500).values.tolist()\n\nyoung_list = df[(df['Young'] == 1)]['image_id'].head(500).values.tolist()\nnotyoung_list = df[(df['Young'] == -1)]['image_id'].head(500).values.tolist()\n\nwearhat_list = df[(df['Wearing_Hat'] == 1)]['image_id'].head(500).values.tolist()\nnotwearhat_list = df[(df['Wearing_Hat'] == -1)]['image_id'].head(500).values.tolist()\n\nmustache_list = df[(df['Mustache'] == 1)]['image_id'].head(500).values.tolist()\nnomustache_list = df[(df['Mustache'] == -1)]['image_id'].head(500).values.tolist()\n\ngoatee_list = df[(df['Goatee'] == 1)]['image_id'].head(500).values.tolist()\nnogoatee_list = df[(df['Goatee'] == -1)]['image_id'].head(500).values.tolist()\n\nchubby_list = df[(df['Chubby'] == 1)]['image_id'].head(500).values.tolist()\nnotchubby_list = df[(df['Chubby'] == -1)]['image_id'].head(500).values.tolist()\n\nwavyhair_list = df[(df['Wavy_Hair'] == 1)]['image_id'].head(500).values.tolist()\nnowavyhair_list = df[(df['Wavy_Hair'] == -1)]['image_id'].head(500).values.tolist()\n\nattractive_list = df[(df['Attractive'] == 1)]['image_id'].head(500).values.tolist()\nnotattractive_list = df[(df['Attractive'] == -1)]['image_id'].head(500).values.tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining some functions for multiprediction. Two type of variable here, yes or no. Such as male or female.. In function reading necessary images and converting to numpy arrays."},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width = 48\nimg_height = 48\n\ndef multimodels(model_name,x_list,y_list):\n    data=[]\n    img_pth = '../input/celeba-dataset/img_align_celeba/img_align_celeba/'\n    labels=[]\n    \n    for val_x in x_list:\n        imag=cv2.imread(img_pth+val_x)\n        img_from_ar = Image.fromarray(imag, 'RGB')\n        resized_image = img_from_ar.resize((img_width, img_height))\n        data.append(np.array(resized_image))\n        labels.append(0)\n    for val_y in y_list:\n        imag=cv2.imread(img_pth+val_y)\n        img_from_ar = Image.fromarray(imag, 'RGB')\n        resized_image = img_from_ar.resize((img_width, img_height))\n        data.append(np.array(resized_image))\n        labels.append(1)\n        \n        \n    model_type=np.array(data)\n    labels=np.array(labels)\n        \n    #optionally save np arrays for future use\n    np.save(model_name+'.npy',model_type)\n    np.save(model_name+'_labels.npy',labels)\n    model_type=np.load(model_name+'.npy')\n    labels=np.load(model_name+'_labels.npy')\n        \n    s=np.arange(model_type.shape[0])\n    np.random.shuffle(s)\n    model_type=model_type[s]\n    labels=labels[s]\n        \n    num_classes=len(np.unique(labels))\n    data_length=len(model_type)\n        \n    #Train test split\n    (x_train,x_test)=model_type[(int)(0.1*data_length):],model_type[:(int)(0.1*data_length)]\n    x_train = x_train.astype('float32')/255\n    x_test = x_test.astype('float32')/255\n        \n    (y_train,y_test)=labels[(int)(0.1*data_length):],labels[:(int)(0.1*data_length)]\n    y_train=keras.utils.to_categorical(y_train,num_classes)\n    y_test=keras.utils.to_categorical(y_test,num_classes)\n        \n    # And Creating the model \n    #linear and sigmoid activation may output better result..\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(img_width, img_height,3)))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation='softmax'))\n    model.summary()\n        \n    #Fitting and compiling the model and adding the early stop to avoid overfitting\n    model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adamax(), metrics=['accuracy'])\n    early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n    history = model.fit(x_train,y_train,batch_size=50, epochs=90,verbose=1, validation_split=0.33, callbacks=[early_stop])\n    score =  model.evaluate(x_test, y_test, verbose=1)\n        \n    rslt = ('Test accuracy:', score[1])\n    rslt\n        \n    #save model for future use to predict new images\n    model.save(model_name+'_model.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Definition is done in function, now lets train datas for models"},{"metadata":{"trusted":true},"cell_type":"code","source":"multimodels(\"gender\",male_list,female_list)\nmultimodels(\"glasses\", glasses_list, no_glasses_list)\nmultimodels(\"smiles\", smile_list, notsmile_list)\nmultimodels(\"makeup\", makeup_list, nomakeup_list)\nmultimodels(\"bald\", bald_list, notbald_list)\nmultimodels(\"young\", young_list, notyoung_list)\nmultimodels(\"wearhat\", wearhat_list, notwearhat_list)\nmultimodels(\"mustache\", mustache_list, nomustache_list)\nmultimodels(\"goatee\", goatee_list, nogoatee_list)\nmultimodels(\"chubby\", chubby_list, notchubby_list)\nmultimodels(\"wavyhair\", wavyhair_list, nowavyhair_list)\nmultimodels(\"attractive\", attractive_list, notattractive_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Models created and saved. Now import libraries for prediction side "},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nimport os\nimport keras\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\nfrom cv2 import cv2\nimport webbrowser","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Select image to predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_dir = '../input/celeba-dataset/img_align_celeba/img_align_celeba/'\nimg_width = 48\nimg_height = 48\nresults = []\naccuracies = []\nmodel_img = \"000001.jpg\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define new function for prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_model(model_name, model_path, image, val_1, val_2):\n    \n    model = keras.models.load_model(model_path)\n    model.summary()\n    def convert_to_array(img):\n        im = cv2.imread(img)\n        img = Image.fromarray(im, 'RGB')\n        image = img.resize((img_width,img_height))\n        return np.array(image)\n    def get_model_type_name(label):\n        \n        if label==0:\n            results.append(val_1)\n            return val_1\n        if label==1:\n            results.append(val_2)\n            return val_2\n    \n    def predict_model_type(file):\n        print(\"Predicting .................................\")\n        ar=convert_to_array(file)\n        ar=ar/255\n        a=[]\n        a.append(ar)\n        a=np.array(a)\n        score=model.predict(a,verbose=1)\n        #print(score)\n        label_index=np.argmax(score)\n        #print(label_index)\n        acc=np.max(score)\n        model_type=get_model_type_name(label_index)\n        #print(model_type)\n        print(\"The predicted model  \"+model_type+\" with accuracy =    \"+str(acc))\n        accuracies.append(str(acc))\n    predict_model_type(image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicting images using saved models"},{"metadata":{"trusted":true},"cell_type":"code","source":"im_path = img_dir+model_img\npredict_model(\"gender\",\"./gender_model.h5\",img_dir+model_img,\"is a male\", \"is a female\")\npredict_model(\"glasses\",\"./glasses_model.h5\",img_dir+model_img,\"has glasses\", \"has no glasses\")\npredict_model(\"smiles\",\"./smiles_model.h5\",img_dir+model_img,\"is smiling\", \"is not smiling\")\npredict_model(\"makeup\",\"./makeup_model.h5\",img_dir+model_img,\"has heavy makeup\", \"has not heavy makeup\")\npredict_model(\"bald\",\"./bald_model.h5\",img_dir+model_img,\"is bald\", \"is not bald\")\npredict_model(\"young\",\"./young_model.h5\",img_dir+model_img,\"is young\", \"is not young\")\npredict_model(\"wearhat\",\"./wearhat_model.h5\",img_dir+model_img,\"is wearing a hat\", \"is not wearing a hat\")\npredict_model(\"mustache\",\"./mustache_model.h5\",img_dir+model_img,\"has mustache\", \"has not mustache\")\npredict_model(\"goatee\",\"./goatee_model.h5\",img_dir+model_img,\"is goatee\", \"has not goatee\")\npredict_model(\"chubby\",\"./chubby_model.h5\",img_dir+model_img,\"is chubby\", \"is not chubby\")\npredict_model(\"wavyhair\",\"./wavyhair_model.h5\",img_dir+model_img,\"has wavyhair\", \"has not wavyhair\")\npredict_model(\"attractive\",\"./attractive_model.h5\",img_dir+model_img,\"is attractive\", \"is not attractive\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualize output with html codes"},{"metadata":{"trusted":true},"cell_type":"code","source":"html = '''\n    <div style=\"overflow: auto;  border: 2px solid #FFF8D8;\n        padding: 2px; width: 300px;\" >\n        \n        <div style=\"padding: 10px 0px 0px 10px; overflow: auto;\">           \n            <h4 style=\"margin-left: 50px; margin-top: 2px;\">{}{}</h4>\n            <h4 style=\"margin-left: 50px; margin-top: 2px;\">{}{}</h4>\n            <h4 style=\"margin-left: 50px; margin-top: 2px;\">{}{}</h4>\n            <h4 style=\"margin-left: 50px; margin-top: 2px;\">{}{}</h4>\n            <h4 style=\"margin-left: 50px; margin-top: 2px;\">{}{}</h4>\n            <h4 style=\"margin-left: 50px; margin-top: 2px;\">{}{}</h4>\n            <h4 style=\"margin-left: 50px; margin-top: 2px;\">{}{}</h4>\n            <h4 style=\"margin-left: 50px; margin-top: 2px;\">{}{}</h4>\n            <h4 style=\"margin-left: 50px; margin-top: 2px;\">{}{}</h4>\n            <h4 style=\"margin-left: 50px; margin-top: 2px;\">{}{}</h4>\n            <h4 style=\"margin-left: 50px; margin-top: 2px;\">{}{}</h4>\n\t    <h4 style=\"margin-left: 50px; margin-top: 2px;\">{}{}</h4>\n            \n        </div>\n    </div>\n    '''.format(\"gender= \"+results[0],\", acc: \"+accuracies[0][:4],\n                \"glasses= \"+results[1],\",  acc : \"+accuracies[1][:4],\n                \"smiling= \"+results[2], \",  acc : \"+accuracies[2][:4], \n                \"makeup= \"+results[3], \",  acc: \"+accuracies[3][:4],\n                \"bald= \"+results[4], \",  acc: \"+accuracies[4][:4],\n                \"young= \"+results[5], \",  acc: \"+accuracies[5][:4],\n                \"wearhat= \"+results[6], \",  acc: \"+accuracies[6][:4],\n                \"mustache= \"+results[7], \",  acc: \"+accuracies[7][:4],\n                \"goatee= \"+results[8], \",  acc: \"+accuracies[8][:4],\n                \"chubby= \"+results[9], \",  acc: \"+accuracies[9][:4],\n\t        \"wavyhair= \"+results[10], \",  acc: \"+accuracies[10][:4],\n                \"attractive= \"+results[11], \",  acc: \"+accuracies[11][:4] )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Display image and prediction.."},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML, Image\nimport IPython.display\nim_path = img_dir+model_img\ndisplay(HTML(html))\nImage(filename=im_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thanks"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}