{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport math\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom itertools import compress","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_movies = '../input/movies-on-netflix-prime-video-hulu-and-disney/MoviesOnStreamingPlatforms_updated.csv'\npath_series = '../input/tv-shows-on-netflix-prime-video-hulu-and-disney/tv_shows.csv'\npath_movies_ott = '../input/movies-on-ott-platforms/MoviesOnStreamingPlatforms_updated.csv'\npath_series_ott = '../input/tv-shows-on-ott-platforms/TV_Shows.csv'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Comparing with the New Datasets","metadata":{}},{"cell_type":"code","source":"df_movies = pd.read_csv(path_movies, index_col='Title')\ndf_movies.drop(['ID','Unnamed: 0'], axis=1, inplace=True)\ndf_series = pd.read_csv(path_series, index_col='Title')\ndf_series.drop(['Unnamed: 0'], axis=1, inplace=True)\ndf_series.rename(columns={'type': 'Type'}, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_movies.columns)\nprint(df_series.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_movies_ott = pd.read_csv(path_movies_ott, index_col='Title')\ndf_movies_ott.drop('ID', axis=1, inplace=True)\ndf_movies_ott.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_movies_ott.isnull().sum() - df_movies.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_movies.index.symmetric_difference(df_movies_ott.index).to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_movies_ott.loc['01:54',:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_series_ott = pd.read_csv(path_series_ott, index_col='Title')\ndf_series_ott.drop(['Unnamed: 0'], axis=1, inplace=True)\ndf_series_ott.rename(columns={'type': 'Type'}, inplace=True)\ndf_series_ott.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_series_ott.isnull().sum() - df_series.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_series.index.symmetric_difference(df_series_ott.index).to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion:\n* Both Series datasets are missing the 'Directors', 'Genres', 'Country', 'Language', and 'Runtime' columns.\n* Both Movie datasets have the same missing values.\n* The original Series dataset has one less missing value.\n* The new Movie OTT dataset has some extra movies.\n* Both Series datasets have the same series.\n\n**Therefore we combine the original Series dataset with the new Movies OTT dataset.**","metadata":{}},{"cell_type":"markdown","source":"# Combining the First Dataset with Series Dataset","metadata":{}},{"cell_type":"code","source":"df_combined = pd.concat([df_movies_ott, df_series])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The \"Type\" variable indicates whether it's a movie or a series.\n* 0: movie\n* 1: series","metadata":{}},{"cell_type":"code","source":"df_combined.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_combined = df_combined[~df_combined.index.duplicated()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_combined.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_combined.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cleaning the Combined Dataset","metadata":{}},{"cell_type":"code","source":"df_combined[\"Rotten Tomatoes\"] = df_combined[\"Rotten Tomatoes\"].str.rstrip(\"%\").astype(\"float\")\ndf_combined[\"Age\"].replace({\"all\":\"1+\"},inplace=True)\ndf_combined[\"Age\"] = df_combined[\"Age\"].str.replace(\"+\",\"\", regex=False).astype(\"float\")\n\nclean_type = lambda row: 'movie' if row['Type'] == 0 else 'series'\ndf_combined['Type'] = df_combined.apply(clean_type, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_combined.to_csv('./movies_and_series_clean.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Filling the Nulls","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install git+https://github.com/alberanid/imdbpy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imdb import IMDb\nfrom tqdm.notebook import tqdm\n\nimport logging\nlogger = logging.getLogger()\nlogger.setLevel(logging.CRITICAL)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_combined = '../input/streaming-services-nulls-filled/movies_and_series_clean.csv'\ndf_combined = pd.read_csv(path_combined, index_col='Title').drop('Rotten Tomatoes', axis=1)\ndf_nulls = df_combined[df_combined.isnull().any(axis=1)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_nulls.loc[:,'Age'] = np.where(pd.isna(df_nulls['Age']), df_nulls['Age'], df_nulls['Age'].astype(str))\ndf_nulls1 = df_nulls.iloc[:3800,:]\ndf_nulls2 = df_nulls.iloc[3800:7600,:]\ndf_nulls3 = df_nulls.iloc[7600:11400,:]\ndf_nulls4 = df_nulls.iloc[11400:15000,:]\ndf_nulls5 = df_nulls.iloc[15000:15262,:]\nprint(df_nulls1.shape[0] + df_nulls2.shape[0] + df_nulls3.shape[0] + df_nulls4.shape[0] + df_nulls5.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fill_na(df):\n    ia = IMDb()\n    for index, row in tqdm(df.iterrows()):\n        movie_id = ia.search_movie(index + f\" ({row['Year']})\")\n        if not movie_id:\n            movie_id = ia.search_movie(index)\n        if movie_id:\n            movie_id = movie_id[0].getID()\n            movie = ia.get_movie(movie_id)\n            if pd.isna(row['Age']):\n                try:\n                    df.at[index,'Age'] = movie.get('certificates')[0].rsplit(':')[-1]\n                except (KeyError,TypeError):\n                    pass\n            if pd.isna(row['IMDb']):\n                try:\n                    df.at[index,'IMDb'] = movie['rating']\n                except (KeyError,TypeError):\n                    pass\n            if pd.isna(row['Directors']):\n                try:\n                    df.at[index,'Directors'] = ','.join(director['name'] for director in movie['director'])\n                except (KeyError,TypeError):\n                    pass\n            if pd.isna(row['Genres']):\n                try:\n                    df.at[index,'Genres'] = movie['genres']\n                except (KeyError,TypeError):\n                    pass\n            if pd.isna(row['Country']):\n                try:\n                    df.at[index,'Country'] = ','.join(country for country in movie['countries'])\n                except (KeyError,TypeError):\n                    pass\n            if pd.isna(row['Language']):\n                try:\n                    df.at[index,'Language'] = ','.join(language for language in movie['languages'])\n                except (KeyError,TypeError):\n                    pass\n            if pd.isna(row['Runtime']):\n                try:\n                    df.at[index,'Runtime'] = float(movie['runtimes'][0])\n                except (KeyError,TypeError):\n                    pass\n\n#fill_na(df_nulls5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cleaning after Filling the Nulls","metadata":{}},{"cell_type":"code","source":"old_shape = df_combined.shape\nold_nulls = df_combined.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!head -n 1 \"../input/streaming-services-nulls-filled/nulls_filled1.csv\" > merged.csv\n!tail -q -n +2 \"../input/streaming-services-nulls-filled/nulls_filled1.csv\" >> merged.csv\n!tail -q -n +2 \"../input/streaming-services-nulls-filled/nulls_filled2.csv\" >> merged.csv\n!tail -q -n +2 \"../input/streaming-services-nulls-filled/nulls_filled3.csv\" >> merged.csv\n!tail -q -n +2 \"../input/streaming-services-nulls-filled/nulls_filled4.csv\" >> merged.csv\n!tail -q -n +2 \"../input/streaming-services-nulls-filled/nulls_filled5.csv\" >> merged.csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_nulls = pd.read_csv('./merged.csv', index_col='Title')\n!rm ./merged.csv\ndf_combined.update(df_nulls)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n\nhas_number = lambda x: any(char.isdigit() for char in str(x))\n\ndef safe_float_convert(x):\n    try:\n        float(x)\n        return True\n    except ValueError:\n        return False\n    except TypeError:\n        return False\n\nremove_parenthesis = lambda x: np.nan if str(x)[0] == '(' and str(x)[-1] == ')' else x\n\nextract_num = lambda x: float(''.join(re.findall(r'\\d+', str(x)))) if len(re.findall(r'\\d+', str(x))) == 1 else x\n\nage_map = {'PG': 1.0,\n           'TV-PG': 1.0,\n           'M': 15.0,\n           'U': 1.0,\n           'G': 1.0,\n           'A': 18.0,\n           'Atp': 1.0,\n           'TV-MA':17.0,\n           'UA': 12.0,\n           'R': 17.0,\n           'S':18.0,\n           'Tous publics': 1.0,\n           'Tous Public': 1.0,\n           'All': 1.0,\n           'AL': 1.0,\n           'TV-G': 1.0,\n           'T': 1.0,\n           'TV-Y': 2.0,\n           'L': 1.0,\n           'Livre': 1.0,\n           'IIB': 1.0,\n           'IIA': 1.0,\n           'Btl': 1.0,\n           'Tous publics avec avertissement': 1.0,\n           'BPjM Restricted': 18.0,\n           'Banned': 18.0,\n           'Passed': 1.0,\n           'Approved': 1.0,\n           'C': 18.0,\n           'MA': 17.0,\n           'B': 1.0,\n           'X': 18.0,\n           'E': 1.0,\n           'KT/EA': 1.0,\n           'SU': 1.0,\n           'GP': 1.0,\n           'I': 1.0,\n           'NRC': 12.0,\n           'TE': 1.0,\n           'KNT/ENA': 16.0,\n           'U/A': 1.0,\n           'K': 1.0,\n           'II': 18.0,\n           'TP': 1.0,\n           'K-16/13': 16.0,\n           'SOA': np.nan,\n           'nan': np.nan,\n           'Not Rated': np.nan,\n           'Unrated': np.nan,\n           '(January 10, 2011)': np.nan\n          }\n\n\nmask_safefloat = df_combined['Age'].map(safe_float_convert)\nmask_hasnumber = df_combined['Age'].map(has_number)\n\ndf_combined.loc[~mask_hasnumber, 'Age'] = df_combined.loc[~mask_hasnumber, 'Age'].apply(remove_parenthesis)\ndf_combined.replace(age_map, inplace=True)\ndf_combined.loc[~mask_safefloat, 'Age'] = df_combined.loc[~mask_safefloat, 'Age'].apply(extract_num)\ndf_combined['Age'] = df_combined['Age'].astype(float)\ndf_combined['Age'].replace({1996.0:np.nan, 2145.0:np.nan, 0.0:1.0}, inplace=True)\n\ndf_combined['Age'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"old_nulls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_combined.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_combined.to_csv('streaming_final.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploring the Combined Dataset","metadata":{}},{"cell_type":"code","source":"path_final = '../input/streaming-services-nulls-filled/streaming_final.csv'\ndf = pd.read_csv(path_final, index_col='Title')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Oldest and Newest Movie","metadata":{}},{"cell_type":"code","source":"print(df['Year'].min())\nprint(df['Year'].max())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of Series vs Movies","metadata":{}},{"cell_type":"code","source":"def label_function(val):\n    return f'{val / 100 * len(df):.0f}\\n{val:.0f}%'\n\nplt.figure(figsize=(12,5))\ndf.groupby('Type').size().plot(kind='pie', autopct=label_function,\n                                textprops={'fontsize': 16, 'fontweight':'bold'})\nplt.ylabel('Movies Vs. Series')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def col_2_str(data: pd.DataFrame, col_name: str, sep=',', collocations=False) -> str:\n    text = ''\n    col = data.dropna(subset=[col_name])[col_name].to_list()\n    for elem in col:\n        if collocations:\n            elem = elem.replace(' ', '_')\n        text += elem.replace(sep, ' ')\n        text+= ' '\n    return text\n\nwc_color = lambda *args,**kwargs: 'black'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"genres_text = col_2_str(df, 'Genres').replace('-', '')\nwc = WordCloud(collocations=False, background_color='white', color_func=wc_color).generate(genres_text)\nplt.figure(figsize=(14,8));\nplt.imshow(wc, interpolation='bilinear');\nplt.axis(\"off\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most Common Spoken Languages","metadata":{}},{"cell_type":"code","source":"lang_text = col_2_str(df, 'Language')\nwc = WordCloud(collocations=False, background_color='white', color_func=wc_color).generate(lang_text)\nplt.figure(figsize=(14,8));\nplt.imshow(wc, interpolation='bilinear');\nplt.axis(\"off\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most Common Directors","metadata":{}},{"cell_type":"code","source":"dir_text = col_2_str(df, 'Directors', collocations=True)\ndir_text = dir_text.split()\ndir_text = [director.replace('_', ' ') for director in dir_text]\ndir_freq = Counter(dir_text)\n\nwc = WordCloud(collocations=False, background_color='white').generate_from_frequencies(dir_freq)\nplt.figure(figsize=(14,8));\nplt.imshow(wc, interpolation='bilinear');\nplt.axis(\"off\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of Productions per Country","metadata":{}},{"cell_type":"code","source":"country_text = col_2_str(df, 'Country', collocations=True)\ncountry_text = country_text.split()\ncountry_text = [country.replace('_', ' ') for country in country_text]\ncountry_freq = Counter(country_text)\n\ncountry_freq = pd.DataFrame.from_dict(country_freq, orient='index').reset_index().rename(columns={'index':'country', 0:'count'})\ncountry_freq.head(20)\n\nfig = px.choropleth(data_frame=country_freq,\n                    locations='country', locationmode='country names',\n                    color='count', color_continuous_scale='algae')\n\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}