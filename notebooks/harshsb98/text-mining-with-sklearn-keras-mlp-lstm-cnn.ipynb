{"cells":[{"metadata":{"_cell_guid":"556e7862-c59b-a1e7-c8d2-91bcd7dc5b8c"},"cell_type":"markdown","source":"Aim: Predict Rating from Review using basic and deep models"},{"metadata":{"_cell_guid":"4d6a2d9e-f548-ceaf-9226-97d0ef00023c","trusted":true},"cell_type":"code","source":"import re\nimport nltk\n\nimport pandas as pd\nimport numpy as np\n\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nenglish_stemmer=nltk.stem.SnowballStemmer('english')\n\nfrom sklearn.feature_selection.univariate_selection import SelectKBest, chi2, f_classif\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import SGDClassifier, SGDRegressor\n\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport random\nimport itertools\n\nimport sys\nimport os\nimport argparse\nfrom sklearn.pipeline import Pipeline\nfrom scipy.sparse import csr_matrix\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport six\nfrom abc import ABCMeta\nfrom scipy import sparse\nfrom scipy.sparse import issparse\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.utils import check_X_y, check_array\nfrom sklearn.utils.extmath import safe_sparse_dot\nfrom sklearn.preprocessing import normalize, binarize, LabelBinarizer\nfrom sklearn.svm import LinearSVC\n\nfrom keras.preprocessing import sequence\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Lambda\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.recurrent import LSTM, SimpleRNN, GRU\nfrom keras.preprocessing.text import Tokenizer\nfrom collections import defaultdict\nfrom keras.layers.convolutional import Convolution1D\nfrom keras import backend as K\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\n%matplotlib inline\nplt.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3764b93f-8c69-a9c2-d40a-70f164032661","trusted":false},"cell_type":"code","source":"#https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"daf69378-7811-49c3-1b1c-b28aad12ad91"},"cell_type":"markdown","source":"## Preprocessing Function"},{"metadata":{"_cell_guid":"2688fc8f-ca7b-9bd7-bc6e-8ea18ebdb957"},"cell_type":"markdown","source":"Here is the process :\n* Remove the non Letters\n* Convert everything to lower case\n* Remove stop words\n* Stem the words"},{"metadata":{"_cell_guid":"68c37e32-789d-1ecf-d88f-679cd79fe461","trusted":true},"cell_type":"code","source":"def review_to_wordlist( review, remove_stopwords=True):\n    # Function to convert a document to a sequence of words,\n    # optionally removing stop words.  Returns a list of words.\n    #\n    # 1. Remove HTML\n    review_text = BeautifulSoup(review).get_text()\n\n    #\n    # 2. Remove non-letters\n    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n    #\n    # 3. Convert words to lower case and split them\n    words = review_text.lower().split()\n    #\n    # 4. Optionally remove stop words (True by default)\n    if remove_stopwords:\n        stops = set(stopwords.words(\"english\"))\n        words = [w for w in words if not w in stops]\n\n    b=[]\n    stemmer = english_stemmer #PorterStemmer()\n    for word in words:\n        b.append(stemmer.stem(word))\n\n    # 5. Return a list of words\n    return(b)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a43527ec-5612-afeb-ffdd-3b823b676e72"},"cell_type":"markdown","source":"## Import Datas"},{"metadata":{"_cell_guid":"51e77b0c-7cd7-6ba0-53e7-c126d6ea2d6f"},"cell_type":"markdown","source":"We import only 20000 lines of our total data in order to run the notebook faster"},{"metadata":{"_cell_guid":"a741e1fc-0191-c6f4-f476-52d494d17698","trusted":false},"cell_type":"code","source":"data_file = '../input/Amazon_Unlocked_Mobile.csv'\n\nn = 413000  \ns = 20000 \nskip = sorted(random.sample(range(1,n),n-s))\n\n\ndata = pd.read_csv( data_file, delimiter = \",\", skiprows = skip)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5984c90f-8e97-8279-9cef-ee7735c75025","trusted":false},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cd77f712-e27a-a5c3-2892-bd8b1c2a3106","trusted":false},"cell_type":"code","source":"data = data[data['Reviews'].isnull()==False]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a4b9503f-8820-40f2-31e3-a016d155bc2b","trusted":false},"cell_type":"code","source":"train, test = train_test_split(data, test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d263bb83-4cf3-4f86-d30d-38902e140f30"},"cell_type":"markdown","source":"## Labels Exploration"},{"metadata":{"_cell_guid":"075d9e7c-236b-e7bf-d374-971404c9bd18","trusted":false},"cell_type":"code","source":"sns.countplot(data['Rating'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ba1cbbaf-2581-18c9-71bd-244c82d504b3"},"cell_type":"markdown","source":"Much More 5 than others ratings"},{"metadata":{"_cell_guid":"de5cb5a7-d4cd-9854-d479-4d1bb5ab7e71"},"cell_type":"markdown","source":"### Apply Preprocessing"},{"metadata":{"_cell_guid":"0d7df42d-fc16-a8d0-2ac9-36ef7eca2a97","trusted":false},"cell_type":"code","source":"clean_train_reviews = []\nfor review in train['Reviews']:\n    clean_train_reviews.append( \" \".join(review_to_wordlist(review)))\n    \nclean_test_reviews = []\nfor review in test['Reviews']:\n    clean_test_reviews.append( \" \".join(review_to_wordlist(review)))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"615da5fd-a050-83f4-41c7-179d2e6d9af6"},"cell_type":"markdown","source":"## TFidf transformation"},{"metadata":{"_cell_guid":"8b8b704d-3214-9422-13fd-275128b1155f"},"cell_type":"markdown","source":"### TFidf"},{"metadata":{"_cell_guid":"b6ed9c5d-ebd9-0a56-aeeb-3cab6ec2568a"},"cell_type":"markdown","source":"We will use tfidf transformation with ngrams between 1 and 4."},{"metadata":{"_cell_guid":"ec98d8dc-f48e-4c28-15d1-d37a7e84a1cc","trusted":false},"cell_type":"code","source":"vectorizer = TfidfVectorizer( min_df=2, max_df=0.95, max_features = 200000, ngram_range = ( 1, 4 ),\n                              sublinear_tf = True )\n\nvectorizer = vectorizer.fit(clean_train_reviews)\ntrain_features = vectorizer.transform(clean_train_reviews)\n\ntest_features = vectorizer.transform(clean_test_reviews)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b4cebdfe-17c7-ffb7-969b-8048424a885a"},"cell_type":"markdown","source":"### Select Best Features"},{"metadata":{"_cell_guid":"a68058f9-c22e-70b1-8936-70229e52a513"},"cell_type":"markdown","source":"We only select the best features for our prediction"},{"metadata":{"_cell_guid":"0db6ebf3-7d61-17a0-a6d1-562c50166506","trusted":false},"cell_type":"code","source":"fselect = SelectKBest(chi2 , k=10000)\ntrain_features = fselect.fit_transform(train_features, train[\"Rating\"])\ntest_features = fselect.transform(test_features)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"99ab74c0-2e18-6326-8533-c24a0d932968","trusted":false},"cell_type":"code","source":"batch_size = 32\nnb_classes = 5","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"65baef9c-1531-33bf-be3d-0dc1984b26ed","trusted":false},"cell_type":"code","source":"vectorizer = TfidfVectorizer( min_df=2, max_df=0.95, max_features = 1000, ngram_range = ( 1, 3 ),\n                              sublinear_tf = True )\n\nvectorizer = vectorizer.fit(clean_train_reviews)\ntrain_features = vectorizer.transform(clean_train_reviews)\n\ntest_features = vectorizer.transform(clean_test_reviews)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"18670f42-9924-c06a-af8a-ee09ce2d8950","trusted":false},"cell_type":"code","source":"X_train = train_features.toarray()\nX_test = test_features.toarray()\n\nprint('X_train shape:', X_train.shape)\nprint('X_test shape:', X_test.shape)\ny_train = np.array(train['Rating']-1)\ny_test = np.array(test['Rating']-1)\n\nY_train = np_utils.to_categorical(y_train, nb_classes)\nY_test = np_utils.to_categorical(y_test, nb_classes)\n\n\n# pre-processing: divide by max and substract mean\nscale = np.max(X_train)\nX_train /= scale\nX_test /= scale\n\nmean = np.mean(X_train)\nX_train -= mean\nX_test -= mean\n\ninput_dim = X_train.shape[1]\n\n# Here's a Deep Dumb MLP (DDMLP)\nmodel = Sequential()\nmodel.add(Dense(256, input_dim=input_dim))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(nb_classes))\nmodel.add(Activation('softmax'))\n\n# we'll use categorical xent for the loss, and RMSprop as the optimizer\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\nprint(\"Training...\")\nmodel.fit(X_train, Y_train, nb_epoch=5, batch_size=16, validation_split=0.1, show_accuracy=True)\n\nprint(\"Generating test predictions...\")\npreds = model.predict_classes(X_test, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"20a7e1d9-4b7a-f03c-82a6-5974504ba15d","trusted":false},"cell_type":"code","source":"print('prediction 6 accuracy: ', accuracy_score(test['Rating'], preds+1))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6711f545-9784-2e77-4a7a-58af16519096"},"cell_type":"markdown","source":"### LSTM"},{"metadata":{"_cell_guid":"09ec7a73-b091-92e3-a24f-77a28c18dd31","trusted":false},"cell_type":"code","source":"max_features = 20000\nEMBEDDING_DIM = 100\nVALIDATION_SPLIT = 0.2\nmaxlen = 80\nbatch_size = 32\nnb_classes = 5","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f28a2622-6859-41e9-f98d-aec9098962e2","trusted":false},"cell_type":"code","source":"# vectorize the text samples into a 2D integer tensor\ntokenizer = Tokenizer(nb_words=max_features)\ntokenizer.fit_on_texts(train['Reviews'])\nsequences_train = tokenizer.texts_to_sequences(train['Reviews'])\nsequences_test = tokenizer.texts_to_sequences(test['Reviews'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c9405324-f068-a1b2-fc63-dd98a4d3a82f","trusted":false},"cell_type":"code","source":"print('Pad sequences (samples x time)')\nX_train = sequence.pad_sequences(sequences_train, maxlen=maxlen)\nX_test = sequence.pad_sequences(sequences_test, maxlen=maxlen)\n\nY_train = np_utils.to_categorical(y_train, nb_classes)\nY_test = np_utils.to_categorical(y_test, nb_classes)\n\n\nprint('X_train shape:', X_train.shape)\nprint('X_test shape:', X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"36d3d256-4fa8-5664-a716-61e7af263220","trusted":false},"cell_type":"code","source":"print('Build model...')\nmodel = Sequential()\nmodel.add(Embedding(max_features, 128, dropout=0.2))\nmodel.add(LSTM(128, dropout_W=0.2, dropout_U=0.2)) \nmodel.add(Dense(nb_classes))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nprint('Train...')\nmodel.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=1,\n          validation_data=(X_test, Y_test))\nscore, acc = model.evaluate(X_test, Y_test,\n                            batch_size=batch_size)\nprint('Test score:', score)\nprint('Test accuracy:', acc)\n\n\nprint(\"Generating test predictions...\")\npreds = model.predict_classes(X_test, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a5d0507c-d01c-11e3-70b0-ae5a790bea26","trusted":false},"cell_type":"code","source":"print('prediction 7 accuracy: ', accuracy_score(test['Rating'], preds+1))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"aa310c6a-414d-3781-90a5-6cb83e4da82a"},"cell_type":"markdown","source":"### CNN"},{"metadata":{"_cell_guid":"b8f524ba-611f-67b9-5973-e1d3d7b3ee08","trusted":false},"cell_type":"code","source":"print('Build model...')\nmodel = Sequential()\nmodel.add(Embedding(max_features, 128, dropout=0.2))\n# we add a Convolution1D, which will learn nb_filter\n# word group filters of size filter_length:\nmodel.add(Convolution1D(nb_filter=nb_filter,\n                        filter_length=filter_length,\n                        border_mode='valid',\n                        activation='relu',\n                        subsample_length=1))\n\ndef max_1d(X):\n    return K.max(X, axis=1)\n\nmodel.add(Lambda(max_1d, output_shape=(nb_filter,)))\nmodel.add(Dense(hidden_dims)) \nmodel.add(Dropout(0.2)) \nmodel.add(Activation('relu'))\nmodel.add(Dense(nb_classes))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"109858be-7b08-d3b6-4930-d4db0f124d7d","trusted":false},"cell_type":"code","source":"print('Train...')\nmodel.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=1,\n          validation_data=(X_test, Y_test))\nscore, acc = model.evaluate(X_test, Y_test,\n                            batch_size=batch_size)\nprint('Test score:', score)\nprint('Test accuracy:', acc)\n\n\nprint(\"Generating test predictions...\")\npreds = model.predict_classes(X_test, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3d0bc468-cef3-bb40-adbb-846490cc273d","trusted":false},"cell_type":"code","source":"print('prediction 8 accuracy: ', accuracy_score(test['Rating'], preds+1))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cedd0e04-c7ce-b276-6ce2-724752c8d5cf","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":1}