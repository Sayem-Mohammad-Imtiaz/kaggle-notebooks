{"cells":[{"metadata":{"_uuid":"7c6b815cc90354b1666aff2f9d45e0cb224a8841"},"cell_type":"markdown","source":" ## 1. Importing the required libraries "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud # to Visualize our dataset in the WordCloud  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28681d494f81fe8917e24401b93b298b9ef3c4da","collapsed":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/spam.csv\", encoding = 'ISO-8859-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3826b0714f08b8da19765ecf20c32c2b8fe02e6e"},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28ad9a95951b318091769b3e76a019e89d1961b8"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d67dec70fe3df447fd8e6c33870cb5a5d4c9115"},"cell_type":"markdown","source":"## 2. Data Pre-processing"},{"metadata":{"trusted":true,"_uuid":"7b3045a6b1c74b6a79af16618590bd8cee02bd54","collapsed":true},"cell_type":"code","source":"#Removing the NaN variables\ndata = data.drop([\"Unnamed: 2\",\"Unnamed: 3\",\"Unnamed: 4\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38e853e5b3676a421891fe14beaad0292965f969"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb13cdf0944bf2252f18eb1a0946fc28e76825fb"},"cell_type":"code","source":"# Re-naming the columns for our convenience \ndata.columns = [\"labels\", \"data\"]\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bfa84bd054c750e588c3d1a082a3e800b54fa41"},"cell_type":"code","source":"#Converting the labels to the binary format \ndata[\"b_labels\"] = data[\"labels\"].map({'ham': 0, 'spam':1})\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d515da2e3b874ef223eba3fd3711d6d70b4d30b","collapsed":true},"cell_type":"code","source":"Y = data[\"b_labels\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91f22485f28657013bb99316da83f4094d66eb07","collapsed":true},"cell_type":"code","source":"#Fitting CV to convert the text data to vectors\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.model_selection import train_test_split\n\ncv = CountVectorizer(decode_error = 'ignore')\nX = cv.fit_transform(data[\"data\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5b79c2eab6e35a0612fc0ba5ea7e1b798fd8cc8"},"cell_type":"markdown","source":"## 3. Splitting the data into train and test datasets"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a926e09278fded4de3741aa12f1c4d61a790ce24"},"cell_type":"code","source":"Xtrain, Xtest, Ytrain , Ytest = train_test_split(X,Y, test_size = 0.33)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ebb50bc6a9e4e8ae0a42c1a6cfd4f7d5e29f63d"},"cell_type":"markdown","source":" ## 4. Building the model, training it and printing the scores"},{"metadata":{"trusted":true,"_uuid":"52d0ffc02bffa08af72e2d6fd60a7bdcf9756c81"},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n#fitting the model\nmodel = MultinomialNB()\nmodel.fit(Xtrain, Ytrain)\n#Printing the scores\nprint(\"train score:\", model.score(Xtrain, Ytrain))\nprint(\"test score:\", model.score(Xtest, Ytest))\n\n#Predicting Xtest\nYpred = model.predict(Xtest)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dbcaef922962dcf0cf2e4dcbd39b70fd06aa3f37"},"cell_type":"markdown","source":" #### We can also try fitting Tf-Idf Vectorizor to the Data"},{"metadata":{"trusted":true,"_uuid":"614b27abc85abde42eade0264141babb2abc6c19","collapsed":true},"cell_type":"code","source":"\"\"\"tfidf = TfidfVectorizer(decode_error = \"ignore\")\nXt = tfidf.fit_transform(data['data'])\n\nXt_train, Xt_test, Y_train , Y_test = train_test_split(X,Y, test_size = 0.33)\nmodel.fit(Xt_train, Ytrain)\nprint(\"train score:\", model.score(Xt_train, Ytrain))\nprint(\"test score:\", model.score(Xt_test, Ytest))\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"097c42f2c37b458b202b7f0c6a89eb9c63658ada"},"cell_type":"markdown","source":"## 5. Visualizng the data with Word Cloud"},{"metadata":{"trusted":true,"_uuid":"02a6abc716e1b9bc52c91262b7f689eae6000266","collapsed":true},"cell_type":"code","source":"def visualize(label):\n    words = ''\n    for msg in data[data['labels']== label]['data']:\n        msg = msg.lower()\n        words += msg + ' '\n    wordcloud = WordCloud(width = 600, height = 400).generate(words)\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n    \nvisualize('spam')\nvisualize('ham')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a804fd39ace21135fc98dcfe9f22bcd050647543"},"cell_type":"markdown","source":"## 6. Implementing confusion matrix to predict the test data."},{"metadata":{"trusted":true,"_uuid":"0721a1fec0d93725442f6ac84155aae216b425fa"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(Ypred,Ytest)\nprint(cm)\naccuracy = (cm[0][0]+cm[1][1])/(cm[0][1]+cm[0][0]+cm[1][1]+cm[1][0])\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51bc1bb0b8b4800ab6169be986cc2d51d6bc4c1d"},"cell_type":"markdown","source":"## 7. Figuring out where our model is getting wrong. \n#### It should not show a lot as our accuracy is around 98%"},{"metadata":{"trusted":true,"_uuid":"597bb743cfa8787904d4b0e7d72fc1c57946a554"},"cell_type":"code","source":"data['predictions'] = model.predict(X)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ca51002db7258ca10d42e691bb3d3b32dc672ef"},"cell_type":"code","source":"#Figuring out where we are predicitng not spam in the place of spam\nsneaky_spam = data[(data['predictions'] == 0) & (data['b_labels'] == 1)][\"data\"]\nfor msg in sneaky_spam:\n    print(msg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a5c88752ceae121b38228a914f49a9f1b15bd0d"},"cell_type":"code","source":"#Figuring out where we are predicitng spam in the place of not spam\nsneaky_not_spam = data[(data['predictions'] == 1) & (data['b_labels'] == 0)][\"data\"]\nfor msg in sneaky_not_spam:\n    print(msg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"83250efb87a6ba375900dbfe5acf7555db874dd3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}