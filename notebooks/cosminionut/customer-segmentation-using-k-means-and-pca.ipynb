{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.read_csv('../input/customer-segmentation-tutorial-in-python/Mall_Customers.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.describe(include = 'all')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x = 'Gender', kind = 'count', data=dataset, height = 6, aspect = 1)\nplt.title('Gender Distribution', size = 20)\nplt.xlabel(\"\")\nplt.ylabel(\"\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['Age'].plot(kind='hist', figsize = (10, 6))\nplt.title('Age Distribution', size = 20)\nplt.xlabel('Age', size = 15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['Annual Income (k$)'].plot(kind='hist', figsize = (10, 6))\nplt.title('Income Distribution', size = 20)\nplt.xlabel('Annual Income (k$)', size = 15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['Spending Score (1-100)'].plot(kind='hist', figsize = (10, 6))\nplt.title('Spending Score Distribution', size = 20)\nplt.xlabel('Spending Score (1-100)', size = 15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x = 'Gender', y = 'Spending Score (1-100)', data = dataset, \n            kind = 'bar', height = 6, aspect = 1)\nplt.title('Gender vs. Spending Score', size = 20)\nplt.xlabel('')\nplt.ylabel('Avg. Spending Score', size = 15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(rc={'figure.figsize':(10,6)})\nsns.scatterplot(x = 'Age', y = 'Spending Score (1-100)', data=dataset)\nplt.title('Age vs. Spending Score', size = 20)\nplt.xlabel('Age', size = 15)\nplt.ylabel('Spending Score (1-100)', size = 15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(rc={'figure.figsize':(10,6)})\nsns.scatterplot(x = 'Annual Income (k$)', y = 'Spending Score (1-100)', data=dataset)\nplt.title('Annual Income (k$) vs. Spending Score', size = 20)\nplt.xlabel('Annual Income (k$)', size = 15)\nplt.ylabel('Spending Score (1-100)', size = 15)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###### By looking at the last two graphs we can see that there are differences in spending scores based on age and anual income ","metadata":{}},{"cell_type":"markdown","source":"## Clustering ","metadata":{}},{"cell_type":"code","source":"# Get rid of the ID column \n\nX = dataset.iloc[:,1:]\n\n# Peform Feature Scaling\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX.iloc[:,1:] = sc.fit_transform(X.iloc[:,1:])\n\n# Recode the Gender column\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X[:5])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### K-Means Clusering","metadata":{}},{"cell_type":"markdown","source":"#### In order to find the optimal number of clusters I will use the elbow method","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++')\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###### It seems that the optimal number of clusters is 6","metadata":{}},{"cell_type":"code","source":"kmeans = KMeans(n_clusters = 6, init = 'k-means++')\ny_kmeans = kmeans.fit_predict(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kmeans_dataset = dataset.copy()\nkmeans_dataset['Clusters'] = y_kmeans","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kmeans_dataset.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### PCA","metadata":{}},{"cell_type":"code","source":"# Get rid of the ID column \n\nX = dataset.iloc[:,1:-1]\ny = dataset.iloc[:,-1]\n\n# Peform Feature Scaling\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX.iloc[:,1:] = sc.fit_transform(X.iloc[:,1:])\n\n# Recode the Gender column\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components = 1)\nX = pca.fit_transform(X)\nprint(X[:5])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca_dataframe = pd.DataFrame({'Spending_Score':y, 'PCA_Var':X[:,0]})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca_dataframe.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pca_dataframe.iloc[:].values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 11):\n    kmeans_pca = KMeans(n_clusters = i, init = 'k-means++')\n    kmeans_pca.fit(X)\n    wcss.append(kmeans_pca.inertia_)\nplt.plot(range(1, 11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kmeans_pca = KMeans(n_clusters = 3, init = 'k-means++')\ny_kmeans_pca = kmeans_pca.fit_predict(X)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca_dataframe['Cluster'] = y_kmeans_pca","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(rc={'figure.figsize':(10,6)})\nsns.scatterplot(x = 'PCA_Var', y = 'Spending_Score', hue = 'Cluster', data=pca_dataframe, palette = \"deep\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###### We can see that after applying PCA the number of clusters reduced to only 3, and it looks like there is a clear difference between the three regarding their spending score, but probably the model won't be able to discriminate well between the customers based on the dimension resulted from applying PCA","metadata":{}}]}