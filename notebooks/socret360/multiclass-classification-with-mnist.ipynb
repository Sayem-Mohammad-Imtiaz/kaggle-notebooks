{"cells":[{"metadata":{},"cell_type":"markdown","source":"# GLOBAL VARIABLES"},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH_DATASET = \"/kaggle/input/mnist-in-csv/\"\nTRAINING_DATASET = \"mnist_train.csv\"\nTESTING_DATASET = \"mnist_test.csv\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# IMPORT DATA"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\n\ndef load_dataset(filename, path_dataset=PATH_DATASET):\n    print(\"LOADED: \" + filename)\n    return pd.read_csv(os.path.join(path_dataset, filename))\n    \ntrain = load_dataset(TRAINING_DATASET)\ntest = load_dataset(TESTING_DATASET)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EXPLORING DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> As you can see, both the training set and testing are loaded as panda DataFrame with the first columns as the labels (y) of each row. In total there are 785 columns including the labels column. Therefore, in order to create a training set, and testing set, we need to drop the labels for both train.csv and test.csv."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, y_train, x_test, y_test = train.drop(['label'], axis=1), train.label, test.drop(['label'], axis=1), test.label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MODEL TRAINING"},{"metadata":{},"cell_type":"markdown","source":"> One method that can be used to classify multiclass dataset is the K Nearest Neighbors algorithm."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_clf = KNeighborsClassifier(weights=\"distance\", n_neighbors=3)\nknn_clf.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> The parameters used to construct the KNeighborsClassifiers might not be the combinations that yeilds the highest accuracy. To that end, we still need to find the best parameters that will yield highest accuracy. Hence, one possible way is to use Grid Search."},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import GridSearchCV\n# from sklearn.neighbors import KNeighborsClassifier\n\n# param_grid = [{\"weights\": [\"uniform\", \"distance\"], \"n_neighbors\": [3, 4, 5]}]\n\n# knn_clf = KNeighborsClassifier()\n# grid_search = GridSearchCV(knn_clf, param_grid, cv=2, verbose=3)\n# grid_search.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# MAKING PREDICTIONS"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred = knn_clf.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ACCURACY TESTING"},{"metadata":{},"cell_type":"markdown","source":"> In classification problems, accuracy testing algorithms includes the follow:\n- simple accuracy\n- precision\n- recall\n- f1-score\n- roc (auc)"},{"metadata":{},"cell_type":"markdown","source":"### SIMPLE ACCURACY\nsimple accuracy = (tp + tn) / (tp + tn + fp + fn)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PRECISION\nprecision = (tp) / (tp + fp)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score\n\nprecision_score(y_test, y_test_pred, average=\"micro\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RECALL\nrecall = (tp) / (tp + fn)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import recall_score\n\nrecall_score(y_test, y_test_pred, average=\"micro\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### F1 SCORE\nf1 = 2 * (precision * recall) / (precision + recall)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nf1_score(y_test, y_test_pred, average=\"micro\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}