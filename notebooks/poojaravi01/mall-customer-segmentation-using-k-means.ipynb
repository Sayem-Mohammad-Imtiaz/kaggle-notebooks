{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Unsupervised learning with K-Means for mall customer data segmentation.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Unsupervised learning refers to the machine learning algorithm that infers from data that is not labelled. It learns or studies the patterns in the data on it's own. K-means is a popular unsupervised learning algorithm that separates n observations into k clusters in which each observation belongs to the cluster with the nearest mean. Firstly, import all necessary modules.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import silhouette_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/customer-segmentation-tutorial-in-python/Mall_Customers.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets look at some basic details the dataset can tell us like the dimensions and count/mean etc of the various features in the dataset. Also lets rename the 2 columns with long names into ones we can easily access.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.rename(columns={'Spending Score (1-100)':'SpendingScore','Annual Income (k$)':'AnnualIncome'},inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Plot some basic graphs with the help of matplotlib library and seaborn. \nThe countplot gives us an idea of how many examples are present in a given group in categorical data and here it is gender.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data=df,x='Gender',palette='Set2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets look at the distplot(histogram) which gives the range of the different features;age, income and the spending score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nplt.subplot(3,3,1)\nsns.distplot(df['Age'])\nplt.subplot(3,3,2)\nsns.distplot(df['AnnualIncome'],color='red')\nplt.subplot(3,3,3)\nsns.distplot(df['SpendingScore'],color='green')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, a heatmap shows the two-dimensional graphical representation of data where the individual values that are contained in a matrix are represented as colors and the relation between each of them is shown in the matrix. It helps us analyze the relationship between different features in our dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.iloc[:,1:5].corr(),annot=True,linewidths=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The simple lineplot is created between 2 variables, with respect to gender.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.lineplot(x='AnnualIncome',y='SpendingScore',hue='Gender',data=df,ci=False,style='Gender',markers=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.lineplot(x='Age',y='SpendingScore',hue='Gender',data=df,ci=False,style='Gender',markers=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A boxplot can also be used to visualize distributions.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nx=0\nfor i in ['AnnualIncome','SpendingScore']:\n    x=x+1\n    plt.subplot(2,2,x)\n    sns.boxplot(data=df,x=i,y='Gender',palette='Set'+str(x))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next few steps are to check if all the values in the dataset are non-null and contain proper numerical values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lenc=LabelEncoder()\ndf['Gender']=lenc.fit_transform(df['Gender'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('CustomerID',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# K-Means","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First, lets check the elbow curve for different number of clusters using a forloop to append the values of inertia of the K-means algorithm into a list and plotting them for a range of 1-10 clusters.\nK-Means algorithm clusters data by trying to separate samples in n groups of equal variance, minimizing a criterion known as the inertia or within-cluster sum-of-squares. Inertia tells us how far away the points within a cluster are.\nThe value of inertia decreases as the number of clusters increase. \nThe elbow point is the point in the graph when we notice a bend in the curve.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cluster=list()\nfor i in range(1,11):\n    kmns=KMeans(n_clusters=i)\n    kmns.fit(df)\n    cluster.append(kmns.inertia_)\nplt.figure(figsize=(10,7))\nsns.lineplot(x=list(range(1,11)),y=cluster)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We notice 2 potential elbow points or \"bends\" i.e. one at approximately 3 and another at around 5. Thus we run K-means at both those points to form the requires clusters which we'll visualize eventually.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 3 clusters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"n=3\nkmeans3=KMeans(n_clusters=n,n_init=10,max_iter=500)\nkmeans3.fit(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['clusters']=kmeans3.labels_\nkmeans3.cluster_centers_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The silhouette score is calculated using the mean intra-cluster distance and the mean nearest-cluster distance for each sample.The values of this score range from -1 to 1. Values almost equal to 0 indicate overlapping clusters. Values closer to 1 indicate the best possible clustering while negative values generally indicate that a sample has been assigned to the wrong cluster.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(silhouette_score(df.iloc[:,0:4],kmeans3.labels_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the plot below, we can clearly notice 3 clusters distinguished by color. Thus K-means has performed its job and assigned proper clusters to the data points.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.scatterplot(df['AnnualIncome'], df['SpendingScore'], hue=df['clusters'], palette='Set1',style=df['Gender'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5 clusters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"n=5\nkmeans5=KMeans(n_clusters=n,n_init=10,max_iter=500)\nkmeans5.fit(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['clusters']=kmeans5.labels_\nkmeans5.cluster_centers_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(silhouette_score(df.iloc[:,0:4],kmeans5.labels_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see and improvement in the silhouette score. Thus, plotting the clusters, we can distinguish the 5 groups.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.scatterplot(df['AnnualIncome'], df['SpendingScore'], hue=df['clusters'], palette='Set1',style=df['Gender'])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}