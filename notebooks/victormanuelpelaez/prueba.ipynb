{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# The data comes both as CSV files and a SQLite database\n\nimport sqlite3\nimport pandas as pd\nimport numpy as np\nimport collections\nimport matplotlib.pyplot as plt # Visualization \nimport seaborn as sns"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"sql_conn = sqlite3.connect('../input/database.sqlite') \n# MetadataTo - Email TO field (from the FOIA metadata)\n# MetadataFrom - Email FROM field (from the FOIA metadata)\n# ExtractedBodyText - Attempt to only pull out the text in the body that the email sender wrote (extracted from the PDF)\n\ndata = sql_conn.execute('SELECT MetadataTo, MetadataFrom, ExtractedBodyText FROM Emails')\n\n# data is a <class 'sqlite3.Cursor'> doc: https://docs.python.org/3/library/sqlite3.html\n\n# ----------------------\n# Show first messages \nshowfirst = 8\nl =0\nSenders = []\nfor email in data:\n    if l<showfirst:\n        print(email)\n        Senders.append(email[1].lower())\n        l+=1\n    else:\n        break    \nprint('\\n',Senders)        "},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"[sender for sender in Senders if sender!=''] "},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"df_aliases = pd.read_csv('../input/Aliases.csv',index_col=0)\ndf_emails = pd.read_csv('../input/Emails.csv',index_col=0)\ndf_email_receivers = pd.read_csv('../input/EmailReceivers.csv', index_col=0)\ndf_persons = pd.read_csv('../input/Persons.csv', index_col=0)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"df_persons.head(5)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"top = df_email_receivers.PersonId.value_counts().head(n=10).to_frame()\ntop.columns = ['Emails received']\ntop = pd.concat([top, df_persons.loc[top.index]], axis=1)\ntop.plot(x='Name', kind='barh', figsize=(12, 8), grid=True, color='green')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Data cleaning\ndf_persons['Name'] = df_persons['Name'].str.lower()\ndf_emails = df_emails.dropna(how='all').copy()\nprint(len(df_emails))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"person_id = df_persons[df_persons.Name.str.contains('hillary')].index.values # identificadores de hillary\nperson_id"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"person_id = df_persons[df_persons.Name.str.contains('hillary')].index.values # identificadores de hillary\ndf_emails = df_emails[(df_emails['SenderPersonId']==person_id[0])]\nprint(u'Hillarys emails:', len(df_emails))\n\n\ndf_emails['MetadataDateSent'] = pd.to_datetime(df_emails['MetadataDateSent'])\ndf_emails = df_emails.set_index('MetadataDateSent')\ndf_emails['dayofweek'] = df_emails.index.dayofweek"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"sns.set_style('white')\nt_labels = ['Mon', 'Tues', 'Wed', 'Thur', 'Fri', 'Sat', 'Sun']\nax = sns.barplot(x=np.arange(0,7), y=df_emails.groupby('dayofweek').SenderPersonId.count(),\\\n                 label=t_labels, palette=\"RdBu\")\nsns.despine(offset=10)\nax.set_xticklabels(t_labels)\nax.set_ylabel('Message Count')\nax.set_title('Hillary\\'s Sent Emails')"},{"cell_type":"markdown","metadata":{},"source":"### Pregunta"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"df_emails.MetadataTo.value_counts().head(n=10)"},{"cell_type":"markdown","metadata":{},"source":"### Machine learning with scikit_learn "},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn import metrics\nfrom sklearn.cluster import KMeans\nfrom scipy.spatial.distance import cdist"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"import re\ndef cleanEmailText(text):\n    \n    text = re.sub(r\"-\", \" \", text) # Replace hypens with spaces   \n    text = re.sub(r\"\\d+/\\d+/\\d+\", \"\", text)# Removes dates\n    text = re.sub(r\"[0-2]?[0-9]:[0-6][0-9]\", \"\", text)  # Removes times\n    text = re.sub(r\"[\\w]+@[\\.\\w]+\", \"\", text)# Removes email addresses\n    text = re.sub(r\"/[a-zA-Z]*[:\\/\\/]*[A-Za-z0-9\\-_]+\\.+[A-Za-z0-9\\.\\/%&=\\?\\-_]+/i\", \"\", text) # Removes web addresses\n    clndoc = ''\n    for eachLetter in text:\n        if eachLetter.isalpha() or eachLetter == ' ':\n            clndoc += eachLetter\n        \n    text = ' '.join(clndoc.split()) # Remove any bad characters\n    \n    return text"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#np.random.seed(13)\n#data = df_emails['RawText']\nvectorizer = TfidfVectorizer(max_df=0.6, max_features=500,stop_words='english', use_idf=True)\nX = vectorizer.fit_transform(data)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#vectorizer.get_feature_names()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"svd = TruncatedSVD(100)\nlsa = make_pipeline(svd, Normalizer(copy=False))\nX = lsa.fit_transform(X)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"x_vect = np.arange(3,100,5)\ny_vect = np.zeros(x_vect.shape)\nfor i, cl in enumerate(x_vect):\n    km = KMeans(n_clusters=cl, init='k-means++', max_iter=100, n_init=1,\n                verbose=0)\n    km.fit(X)\n    dist = np.min(cdist(X,km.cluster_centers_,'euclidean'),axis=1)\n    y_vect[i] = np.sum(dist)/X.shape[0]\n    \nplt.plot(x_vect,y_vect,marker=\"o\")\nplt.ylim([0,1])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"k = 30\nkm = KMeans(n_clusters=k, init='k-means++', max_iter=100, n_init=1,\n                verbose=0)\nkm.fit(X)\n\noriginal_space_centroids = svd.inverse_transform(km.cluster_centers_)\norder_centroids = original_space_centroids.argsort()[:, ::-1]\n\nterms = vectorizer.get_feature_names()\nfor i in range(k):\n    print(\"Cluster %d:\" % i, end='')\n    for ind in order_centroids[i, :10]:\n        print(' %s' % terms[ind], end='')\n    print()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}