{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 align=\"center\">Stroke - EDA and ANN Prediction</h1>","metadata":{}},{"cell_type":"markdown","source":"**The notebook consists of**\n\n1. [Importing libraries](#1)\n2. [Checking for missing data](#2)\n3. [Univariate Analysis](#3)\n    - [Count plot for categorical variables](#4)\n    - [Box plot of age](#5)\n    - [Box plot of avg_glucose_level](#6)\n    - [Box plot of bmi](#7)\n    - [Distribution plot of age](#8)\n    - [Distribution plot of avg_glucose_level](#9)\n    - [Distribution plot of bmi](#10)\n4. [Bivariate Analysis](#11)\n    - [Correlation plot for continuous features](#12)\n    - [Scatter plot for age vs avg_glucose_level with a Stroke hue](#13)\n    - [Scatter plot for avg_glucose_level vs bmi with a Stroke hue](#14)\n    - [Scatter plot for age vs bmi with a Stroke hue](#15)\n    - [Violin plot for continuous features](#16)\n    - [Pairplot of the dataset](#17)\n5. [Data Preprocessing](#18)\n    - [Removing the other from gender](#19)\n    - [Checking the effect of outliers](#20)\n    - [Removing the outliers](#21)\n    - [Re-checking the distributions](#22)\n    - [Handling data imbalance](#23)\n6. [PyTorch Model Development](#24)\n    - [Separate categorical from continuous](#25)\n    - [Categorigy](#26)\n    - [Stacking the columns for embeddings](#27)\n    - [Setting an embedding size](#28)\n    - [Defining the model](#29)\n    - [Defining loss and optimizer](#30)\n    - [Perform train/test split](#31)\n    - [Training the model](#32)\n    - [Plotting the loss function](#33)\n    - [Model Validation](#34)","metadata":{}},{"cell_type":"markdown","source":"# 1. Imports <a id=\"1\"></a>","metadata":{}},{"cell_type":"code","source":"# Data manipulation libraries\nimport numpy as np\nimport pandas as pd\n\n# Visualization libraries\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\n# Avoid Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.shape)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The feature list and the target variable:**\n\n1. id: unique identifier\n2. gender: \"Male\", \"Female\" or \"Other\"\n3. age: age of the patient\n4. hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n5. heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n6. ever_married: \"No\" or \"Yes\"\n7. work_type: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n8. Residence_type: \"Rural\" or \"Urban\"\n9. avg_glucose_level: average glucose level in blood\n10. bmi: body mass index\n11. smoking_status: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n12. stroke: 1 if the patient had a stroke or 0 if not\n\nNote: \"Unknown\" in smoking_status means that the information is unavailable for this patient","metadata":{}},{"cell_type":"markdown","source":"**Dropping the *id* column as it's just an identifier**","metadata":{}},{"cell_type":"code","source":"df.drop(['id'],axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Checking for missing data <a id=\"2\"></a>","metadata":{}},{"cell_type":"code","source":"#count of missing data\nmissing_values_count = df.isna().sum()\n\n#find the percentage of missing data\ntotal_cells = np.product(df.shape)\ntotal_missing = missing_values_count.sum()\npercent_missing = (total_missing / total_cells) * 100\nprint(\"Percentage of missing data from the dataset is : {}%\".format(percent_missing))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plotting a heatmap to check for missing data features**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (12,6))\nsns.heatmap(df.isnull())\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Filling the missing data in *bmi* column with mean**","metadata":{}},{"cell_type":"code","source":"df['bmi'].fillna(df['bmi'].mean(), inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Univariate analysis <a id=\"3\"></a>","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Making different arrays for categorical and continuous features**","metadata":{}},{"cell_type":"code","source":"cat_cols = [\"gender\",\"hypertension\",\"heart_disease\",\"ever_married\",\"work_type\",\"Residence_type\",\"smoking_status\",\"stroke\"]\ncont_cols = [\"age\",\"avg_glucose_level\",\"bmi\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Count Plot of Categorical features <a id=\"4\"></a>","metadata":{}},{"cell_type":"code","source":"fig,axes = plt.subplots(4,2,figsize = (16,16))\nsns.set_style('darkgrid')\nfig.suptitle(\"Count plot for various categorical features\")\n\nsns.countplot(ax=axes[0,0],data=df,x='gender')\nsns.countplot(ax=axes[0,1],data=df,x='hypertension')\nsns.countplot(ax=axes[1,0],data=df,x='heart_disease')\nsns.countplot(ax=axes[1,1],data=df,x='ever_married')\nsns.countplot(ax=axes[2,0],data=df,x='work_type')\nsns.countplot(ax=axes[2,1],data=df,x='Residence_type')\nsns.countplot(ax=axes[3,0],data=df,x='smoking_status')\nsns.countplot(ax=axes[3,1],data=df,x='stroke')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Box Plot of *age* <a id=\"5\"></a>","metadata":{}},{"cell_type":"code","source":"fig = px.box(data_frame = df,\n            x = \"age\",\n            width = 800,\n            height = 300)\nfig.update_layout({\"template\":\"plotly_dark\"})\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Box Plot of *avg_glucose_level* <a id=\"6\"></a>","metadata":{}},{"cell_type":"code","source":"fig = px.box(data_frame = df,\n            x = \"avg_glucose_level\",\n            width = 800,\n            height = 300)\nfig.update_layout({\"template\":\"plotly_dark\"})\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Box Plot of *bmi* <a id=\"7\"></a>","metadata":{}},{"cell_type":"code","source":"fig = px.box(data_frame = df,\n            x = \"bmi\",\n            width = 800,\n            height = 300)\nfig.update_layout({\"template\":\"plotly_dark\"})\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribution Plot of *age* <a id=\"8\"></a>","metadata":{}},{"cell_type":"code","source":"age = list(df['age'].values)\n\nhist_data = [age]\ngroup_labels = ['age']\ncolors = ['Orange']\nfig = ff.create_distplot(hist_data,group_labels,show_hist = True,colors=colors)\nfig.update_layout({\"template\":\"plotly_dark\"})\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribution Plot of *avg_glucose_level* <a id=\"9\"></a>","metadata":{}},{"cell_type":"code","source":"avg_glucose_level = list(df['avg_glucose_level'].values)\nhist_data = [avg_glucose_level]\ngroup_labels = ['avg_glucose_level']\ncolors = ['Orange']\nfig = ff.create_distplot(hist_data,group_labels,show_hist = True,colors=colors)\nfig.update_layout({\"template\":\"plotly_dark\"})\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribution Plot of *bmi* <a id=\"10\"></a>","metadata":{}},{"cell_type":"code","source":"bmi = list(df['bmi'].values)\nhist_data = [bmi]\ngroup_labels = [\"bmi\"]\ncolors = ['Orange']\nfig = ff.create_distplot(hist_data,group_labels,show_hist = True,colors=colors)\nfig.update_layout({\"template\":\"plotly_dark\"})\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Bivariate analysis <a id=\"11\"></a>","metadata":{}},{"cell_type":"markdown","source":"**Just re-writing the arrays again**","metadata":{}},{"cell_type":"code","source":"cat_cols = [\"gender\",\"hypertension\",\"heart_disease\",\"ever_married\",\"work_type\",\"Residence_type\",\"smoking_status\",\"stroke\"]\ncont_cols = [\"age\",\"avg_glucose_level\",\"bmi\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation plot of Continuous features <a id=\"12\"></a>","metadata":{}},{"cell_type":"code","source":"cr = df[cont_cols].corr(method='pearson')\nplt.figure(figsize = (6,6))\nsns.heatmap(cr,cmap=\"coolwarm\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scatter plot for *age vs avg_glucose_level* with a *Stroke* hue <a id=\"13\"></a>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.set_style(\"darkgrid\")\nsns.scatterplot(data = df, x = 'age', y = 'avg_glucose_level', hue='stroke')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scatter plot for *avg_glucose_level vs bmi* with a *Stroke* hue <a id=\"14\"></a>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.set_style(\"darkgrid\")\nsns.scatterplot(data = df, x = 'avg_glucose_level', y = 'bmi', hue='stroke')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scatter plot for *age vs bmi* with a *Stroke* hue <a id=\"15\"></a>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.set_style(\"darkgrid\")\nsns.scatterplot(data = df, x = 'age', y = 'bmi', hue='stroke')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Violin plot for continuous features <a id=\"16\"></a>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.subplot(1,3,1)\nsns.violinplot(x = 'stroke', y = 'age', data = df)\nplt.subplot(1,3,2)\nsns.violinplot(x = 'stroke', y = 'avg_glucose_level', data = df)\nplt.subplot(1,3,3)\nsns.violinplot(x = 'stroke', y = 'bmi', data = df)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scatter-matrix of the dataset <a id=\"17\"></a>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (16,16))\nsns.pairplot(df,hue='stroke')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Data preprocessing <a id=\"18\"></a>","metadata":{}},{"cell_type":"markdown","source":"**Conclusions from EDA**\n\n- Gender feature has some very less number of *Other* gender so it can be removed.\n- There are a lot of outliers in *avg_glucose_level* and *bmi*\n- The outliers make the distribution curve of both the features highly skewed towards right\n- Either the outliers can be removed or the distribution curve can be made less-skewed by mapping the values with a log but both cases will lead to loss of the number of datapoints with *Stroke = 1*\n- *avg_glucose_level* increases with *age* and similarly leads to more chances of stroke\n- The stroke class is highly imbalanced which has to be taken of","metadata":{}},{"cell_type":"markdown","source":"### Removing the other from *gender* <a id=\"19\"></a>","metadata":{}},{"cell_type":"code","source":"df[\"gender\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(df[df['gender'] == 'Other'].index, inplace = True)\ndf[\"gender\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking the effect of outliers on the reduction of dataset <a id=\"20\"></a>","metadata":{}},{"cell_type":"code","source":"print(\"The number of people who don't have stroke : \", df['stroke'].value_counts()[0])\nprint(\"The number of people who don't have stroke : \", df['stroke'].value_counts()[1])\ncond1 = df['avg_glucose_level'] > 170\ncond2 = df['stroke'] == 1\nprint(\"The number of outliers in avg_glucose_level with stroke = 1 are : \", df[cond1 & cond2].shape)\ncond3 = df['bmi'] > 47\ncond4 = df['stroke'] == 1\nprint(\"The number of outliers in bmi with stroke = 1 are : \", df[cond3 & cond4].shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There are 83 outliers in the *avg_glucose_level* which have a *stroke=1* which comprises of a large quantity of data. Removing them will lead to loss of data. I'll rather remove the outliers in *bmi* because the number of outliers with stroke are just 3 which won't effect the dataset much.**\n\n### Removing the outliers in *bmi* <a id=\"21\"></a>","metadata":{}},{"cell_type":"code","source":"print(\"The shape before removing the BMI outliers : \",df.shape)\ndf.drop(df[df['bmi'] > 47].index, inplace = True)\nprint(\"The shape after removing the BMI outliers : \",df.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking the distribution of *bmi* again which should have been made less skewed now <a id=\"22\"></a>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (14,5))\nsns.distplot(x=df['bmi'],color='red')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling data imbalance <a id=\"23\"></a>\n\n**Now since the stroke is highly imbalanced, the 2 ways to deal with it are :**\n- **the majority class can either be undersampled using Tomek Links**\n- **the minority class can be oversampled using SMOTE**\n\n**I'll be using SMOTE for this. For using SMOTE, all the cateogrial variables must be converted into int. I'll be Label Encoding all of them because later I'll make a *PyTorch* model using *Embeddings*, and that's why I won't be One-Hot-Encoding them.**","metadata":{}},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label Encoding the categorical variables\nfrom sklearn.preprocessing import LabelEncoder\nobject_cols = [\"gender\",\"ever_married\",\"work_type\",\"Residence_type\",\"smoking_status\"]\nlabel_encoder = LabelEncoder()\nfor col in object_cols:\n    label_encoder.fit(df[col])\n    df[col] = label_encoder.transform(df[col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using SMOTE\nfrom imblearn.over_sampling import SMOTE\nsampler = SMOTE(random_state = 42)\nX = df.drop(['stroke'],axis=1)\ny = df[['stroke']]\nX,y= sampler.fit_resample(X,y['stroke'].values.ravel())\ny = pd.DataFrame({'stroke':y})\nsns.countplot(data = y, x = 'stroke', y= None)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**It's quite clear that the data has been completely balanced.**","metadata":{}},{"cell_type":"code","source":"# Joining back dataset\ndf = pd.concat([X,y],axis = 1)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shuffling the dataset before model development\ndf = df.sample(frac = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. PyTorch Model Development <a id=\"24\"></a>","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Seperate categorical from continuous <a id=\"25\"></a>","metadata":{}},{"cell_type":"code","source":"cat_cols = [\"gender\",\"hypertension\",\"heart_disease\",\"ever_married\",\"work_type\",\"Residence_type\",\"smoking_status\"]\ncont_cols = [\"age\",\"avg_glucose_level\",\"bmi\"]\ny_col = [\"stroke\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Categorify <a id=\"26\"></a>","metadata":{}},{"cell_type":"code","source":"for cat in cat_cols:\n    df[cat] = df[cat].astype('category')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stacking the columns for the embeddings <a id=\"27\"></a>","metadata":{}},{"cell_type":"code","source":"# stacking the categorical columns\ncats = np.stack([df[col].cat.codes.values for col in cat_cols], 1)\ncats[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# converting the stack into tensor\ncats = torch.tensor(cats, dtype = torch.int64)\ncats[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# stacking the continuous columns & converting to tensor\nconts = np.stack([df[col].values for col in cont_cols], 1)\nconts = torch.tensor(conts, dtype=torch.float)\nconts[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# converting target variable to tensor and flattening since CrossEntropyLoss expects a 1-d tensor\ny = torch.tensor(df[y_col].values).flatten()\ny[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cats.shape)\nprint(conts.shape)\nprint(y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Setting an embedding size <a id=\"28\"></a>","metadata":{}},{"cell_type":"code","source":"cat_szs = [len(df[col].cat.categories) for col in cat_cols]\nemb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs]\nemb_szs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Defining the tabular model <a id=\"29\"></a>","metadata":{}},{"cell_type":"code","source":"class TabularModel(nn.Module):\n\n    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n        super().__init__()\n        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n        self.emb_drop = nn.Dropout(p)\n        self.bn_cont = nn.BatchNorm1d(n_cont)\n        \n        layerlist = []\n        n_emb = sum((nf for ni,nf in emb_szs))\n        n_in = n_emb + n_cont\n        \n        for i in layers:\n            layerlist.append(nn.Linear(n_in,i)) \n            layerlist.append(nn.ReLU(inplace=True))\n            layerlist.append(nn.BatchNorm1d(i))\n            layerlist.append(nn.Dropout(p))\n            n_in = i\n        layerlist.append(nn.Linear(layers[-1],out_sz))\n            \n        self.layers = nn.Sequential(*layerlist)\n    \n    def forward(self, x_cat, x_cont):\n        embeddings = []\n        for i,e in enumerate(self.embeds):\n            embeddings.append(e(x_cat[:,i]))\n        x = torch.cat(embeddings, 1)\n        x = self.emb_drop(x)\n        \n        x_cont = self.bn_cont(x_cont)\n        x = torch.cat([x, x_cont], 1)\n        x = self.layers(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42)\nmodel = TabularModel(emb_szs, conts.shape[1], 2, [400,200,100], p=0.2)\nmodel","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Defining loss function and optimizer <a id=\"30\"></a>","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Performing train/test split <a id=\"31\"></a>","metadata":{}},{"cell_type":"code","source":"batch_size = 9000\ntest_size = 492\n\ncat_train = cats[:batch_size-test_size]\ncat_test = cats[batch_size-test_size:batch_size]\ncon_train = conts[:batch_size-test_size]\ncon_test = conts[batch_size-test_size:batch_size]\ny_train = y[:batch_size-test_size]\ny_test = y[batch_size-test_size:batch_size]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(cat_train))\nprint(len(cat_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training the model <a id=\"32\"></a>","metadata":{}},{"cell_type":"code","source":"import time\nstart_time = time.time()\n\nepochs = 320\nlosses = []\n\nfor i in range(epochs):\n    i+=1\n    y_pred = model(cat_train, con_train)\n    loss = criterion(y_pred, y_train)\n    losses.append(loss)\n    \n    if i%25 == 1:\n        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\nprint(f'epoch: {i:3}  loss: {loss.item():10.8f}') \nprint(f'\\nDuration: {time.time() - start_time:.0f} seconds') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the loss function <a id=\"33\"></a>","metadata":{}},{"cell_type":"code","source":"plt.plot(range(epochs), losses)\nplt.ylabel('Cross Entropy Loss')\nplt.xlabel('epoch');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Validation <a id=\"34\"></a>","metadata":{}},{"cell_type":"code","source":"# TO EVALUATE THE ENTIRE TEST SET\nwith torch.no_grad():\n    y_val = model(cat_test, con_test)\n    loss = criterion(y_val, y_test)\nprint(f'CE Loss: {loss:.8f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows = 200\ncorrect = 0\ngroundTruth = []\npredictedValues = []\nprint(f'{\"MODEL OUTPUT\":26} ARGMAX  Y_TEST')\nfor i in range(rows):\n    print(f'{str(y_val[i]):26} {y_val[i].argmax():^7}{y_test[i]:^7}')\n    predictedValues.append(y_val[i].argmax().item())\n    groundTruth.append(y_test[i])\n    if y_val[i].argmax().item() == y_test[i]:\n        correct += 1\nprint(f'\\n{correct} out of {rows} = {100*correct/rows:.2f}% correct')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nprint(\"The F1-score is :\", f1_score(groundTruth, predictedValues))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**This is the F1-score for the first 200 values of the testing set.**","metadata":{}},{"cell_type":"markdown","source":"### If you like the notebook, consider giving an upvote.\nCheck out my other notebooks\n\n1. https://www.kaggle.com/namanmanchanda/heart-attack-eda-prediction-90-accuracy\n2. https://www.kaggle.com/namanmanchanda/asl-detection-99-accuracy\n3. https://www.kaggle.com/namanmanchanda/pytorch-101\n4. https://www.kaggle.com/namanmanchanda/pima-indian-diabetes-eda-and-prediction\n5. https://www.kaggle.com/namanmanchanda/rnn-in-pytorch","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}