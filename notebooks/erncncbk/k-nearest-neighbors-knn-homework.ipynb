{"cells":[{"metadata":{"_uuid":"f1e323c00bff953eacf4314850378d79f8deed79"},"cell_type":"markdown","source":"# Introduction\n\nThis kernel we will use sklearn for KNN algorithm\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/column_2C_weka.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bd66cd38f2ddfea8254d6a1ab3e541f121b688d"},"cell_type":"code","source":"# Do it first df.info() because we dont know is there any NaN value or length of data\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63f302f1f9e682cf0f5eb4c47e70a57cb46f1098"},"cell_type":"code","source":"# to know about features an target variable\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"727bca897a7e0b9db3ca4a9f31cd8101430b0d84"},"cell_type":"markdown","source":"##  K-NEAREST NEIGHBORS (KNN)\n* x = features \n* y = target variables(normal,abnormal)\n"},{"metadata":{"trusted":true,"_uuid":"fa8796a58dd14c3a13b52f7d2bccddaa42f224c6"},"cell_type":"code","source":"x = df.loc[:,df.columns != 'class']\n#x  = df.drop(['class'],axis =1 )\n\ny = df.loc[:,df.columns == 'class']\n\n#x = pd.DataFrame(df.iloc[:,:-1].values)\n#y = pd.DataFrame(df.iloc[:,6].values)\n\nNormal = df.loc[df['class'] == 'Normal']\nAbnormal = df.loc[df['class'] == 'Abnormal']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b92a1271adfc997e61cd530e86535cf2a0e475c6"},"cell_type":"code","source":"# Scatter Plot\nplt.scatter(Normal.pelvic_radius,Normal.pelvic_incidence,color='r',label=\"Normal\",alpha=0.3)\nplt.scatter(Abnormal.pelvic_radius,Abnormal.pelvic_incidence,color='g',label=\"Abnormal\",alpha=0.3)\nplt.xlabel(\"pelvic_radius\")\nplt.ylabel(\"pelvic_incidence\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aefb2ca6866ba4404896787cc250059eef2cd59a"},"cell_type":"markdown","source":"### Categorical Data\n"},{"metadata":{"trusted":true,"_uuid":"7b2ace16de99c9830d81690d84466dd4c381b970"},"cell_type":"code","source":"#from sklearn.preprocessing import LabelEncoder\n#labelencoder_y=LabelEncoder()\n#y=pd.DataFrame(labelencoder_y.fit_transform(y).reshape(-1,1))\n\n# Categorical Data without sklearn liblary\n\ndf['class'] = [ 1 if each == \"Normal\" else 0 for each in df['class']]\ny = df['class'].values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6669cefd2d007775da22c5f47125b3053f3700e1"},"cell_type":"markdown","source":"###  Normalization\n\n"},{"metadata":{"trusted":true,"_uuid":"5311261f08895c3f853bf14a7255886330f1be8f"},"cell_type":"code","source":"x = ((x-np.min(x)) / ( np.max(x)-np.min(x)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36b11e674073b8a16208dd0b2cbabfaeab65d353"},"cell_type":"markdown","source":"### Train Test Split"},{"metadata":{"trusted":true,"_uuid":"a77deb94bcb95d5cc128111557dde65a0b1aaa5d"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01d9b787c9e2950b0ce5df2f6d0aecba56b264fa"},"cell_type":"markdown","source":"### KNN Model"},{"metadata":{"trusted":true,"_uuid":"1528b934cbf4b0c447930c6ac10cdcfad6e7b9aa"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn= KNeighborsClassifier()\nknn.fit(x,y)\nprediction = knn.predict(x_test)\n\nprint(\"{} nn score : {}\".format(3,knn.score(x_test,y_test)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8985a9948c6ba4d3af2648484c35501456422274"},"cell_type":"markdown","source":"### Model complexity\n"},{"metadata":{"trusted":true,"_uuid":"1b6b6b9bde740576aaa7df0c2d39bf3d8096075f"},"cell_type":"code","source":"neig = np.arange(1, 25)\ntrain_accuracy = []\ntest_accuracy = []\n# Loop over different values of k\nfor i, k in enumerate(neig):\n    # k from 1 to 25(exclude)\n    knn = KNeighborsClassifier(n_neighbors=k)\n    # Fit with knn\n    knn.fit(x_train,y_train)\n    #train accuracy\n    train_accuracy.append(knn.score(x_train, y_train))\n    # test accuracy\n    test_accuracy.append(knn.score(x_test, y_test))\n\n# Plot\nplt.figure(figsize=[13,8])\nplt.plot(neig, test_accuracy, label = 'Testing Accuracy')\nplt.plot(neig, train_accuracy, label = 'Training Accuracy')\nplt.legend()\nplt.title('Value VS Accuracy')\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Accuracy')\nplt.xticks(neig)\nplt.savefig('graph.png')\nplt.show()\nprint(\"Best accuracy is {} with K = {}\".format(np.max(test_accuracy),1+test_accuracy.index(np.max(test_accuracy)))) ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}