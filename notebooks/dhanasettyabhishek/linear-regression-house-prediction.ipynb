{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Importing Libraries**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importing Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/housesalesprediction/kc_house_data.csv\")\nprint(\"Dimensions:\",data.shape)\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 3) Data cleaning, checking for null values and finding out the datatype of each column ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def checkNull(data):\n    return data.isnull().any()\ndef checkDatatype(data):\n    return data.dtypes\nprint(checkNull(data))\nprint(\"=================\")\nprint(checkDatatype(data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Coverting date datatype from object to datetime\ndata['date'] =  pd.to_datetime(data['date'], format='%Y%m%dT000000')\n# Pariwise plot for features such as squarefeet, price, and the number of bedrooms to see how the features are distributed\nsns.pairplot(data[['sqft_lot','sqft_above','price','sqft_living','bedrooms']], hue='bedrooms')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Finding the correlation between features, using heatmap\nfeatureCorr = data.corr()\nfig, ax = plt.subplots(figsize=(12,12))\nsns.heatmap(featureCorr, xticklabels=featureCorr.columns, yticklabels=featureCorr.columns, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From the above heatmap we can say that the columns id and date are not corelated to the decision, hence eliminating id and date column from the dataset.\nnew_data = data.drop(['id', 'date'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### 4) Building a linear regression model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# In the model features are 'X' and the class/varaible we are predicting is 'y'\ny = new_data.price.values\ndata_without_price = new_data.drop(['price'], axis=1)\nX = data_without_price.values\nfeatures = data_without_price.columns\nprint(features,\"\\n\", X,\"\\n\", y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Spliting the dataset into training and testing.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=9)\n\n# Linear Regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Predicting the price for the test dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = model.predict(X_test)\ny_predict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Using backward elimination, we are only selecting the variables which are highly relavent to the determining the price of the house","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Backward Elimination we eliminate the features based on p-Value\n\nimport statsmodels.api as sm\n\ndef backwardElimation(data, threshold):\n    zeros = np.zeros(data.shape).astype(int)\n    no_of_features = len(data[0])\n    for i in range(no_of_features):\n        model = sm.OLS(y, data).fit()\n        max_value = max(model.pvalues).astype(float)\n        adjR = model.rsquared_adj.astype(float)\n        if max_value > threshold:\n            for j in range(no_of_features-i):\n                if model.pvalues[j].astype(float) == max_value:\n                    zeros[:, j] = data[:, j]\n                    data = np.delete(data, j, 1)\n                    new_model = sm.OLS(y, data).fit()\n                    new_adjR = new_model.rsquared_adj.astype(float)\n                    if adjR >= new_adjR:\n                        new_data = np.hstack((data, zeros[:, [0, j]]))\n                        new_data = np.delete(new_data, j, 1)\n                        print(model.summary())\n                        return new_data\n                    else:\n                        continue\n    model.summary()\n    return data\n\nthreshold = 0.05\nbackwardElimation(data_without_price.values, threshold)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross validation score between 'Living area square feet and price of the house'\nscore_train = model.score(X_train, y_train)\nscore_test = model.score(X_test, y_test)\nprint(\"Training score:\", score_train)\nprint(\"Testing score:\", score_test)\n# Cross validation\ncrossValidation = cross_val_score(model, data[['sqft_living']], data[['price']], cv=5).mean()\nprint(\"Crossvalidation score between the living are square feet and price is:\",crossValidation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the model based on the training dataset of square feet. \nsqft_living_train = X_train[:, 2]\nsqft_living_test = X_test[:, 2]\nbedrooms_train = X_train[:, 0]\nbedrooms_test = X_test[:, 0]\nsqft_living_model = LinearRegression()\nsqft_living_model.fit(sqft_living_train.reshape(-1, 1), y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Regression plot\nplt.scatter(sqft_living_test,y_test,label=\"Price Data\", alpha=.3)\nplt.plot(sqft_living_test,sqft_living_model.predict(sqft_living_test.reshape(-1, 1)),color=\"red\",label=\"Predicted Regression Line\")\nplt.xlabel(\"Living room square feet\")\nplt.ylabel(\"Price\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparing price with respect to number of bedrooms\ncrossValidation = cross_val_score(model, data[['bedrooms']], data[['price']], cv=5).mean()\nprint(\"Crossvalidation score between the living are square feet and price is:\",crossValidation)\nfig, ax = plt.subplots(figsize=(12, 8))\n# sns.despine(left=True, bottom=True)\nsns.boxplot(x=data['bedrooms'],y=data['price'], ax=ax)\nax.yaxis.tick_left()\nax.set(xlabel='Bedrooms', ylabel='Price');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Heatmap of King County, with respective house prices.\nfrom mpl_toolkits.mplot3d import Axes3D\nimport folium\nfrom folium.plugins import HeatMap\n\nmax_price=data.loc[data['price'].idxmax()]\n\ndef generateBaseMap(default_location=[max_price['lat'], max_price['long']]):\n    base_map = folium.Map(location=default_location, control_scale=True)\n    return base_map\n\ndata['count'] = 1\nbasemap = generateBaseMap()\ns=folium.FeatureGroup(name='icon').add_to(basemap)\nfolium.Marker([max_price['lat'], max_price['long']],popup='Highest Price:'+str(max_price['price']),\n              icon=folium.Icon(color='red')).add_to(s)\nHeatMap(data=data[['lat','long', 'count']].groupby(['lat','long']).sum().reset_index().values.tolist(),\n        radius=8,name='Heat Map').add_to(basemap)\nfolium.LayerControl(collapsed=False).add_to(basemap)\nbasemap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We are able to predict the price based on a input dataset\ninput_data = float(input(\"Enter your desired square feet\"))\ntest_data = np.array([input_data]).reshape(-1, 1)\nresult = sqft_living_model.predict(test_data)\nprint(f'The price of a house for {test_data[0][0]} square feet in Kings County, USA is: ${ round(result[0], 2) }')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}