{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### Importing libraries","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom keras import optimizers\nfrom keras.models import Sequential, Model \nfrom keras.utils import np_utils\nfrom keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, BatchNormalization, Input\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras import backend as K\nfrom keras.utils import plot_model\n\nimport cv2    \n\nfrom sklearn.metrics import f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_folder = '../input/celeba-dataset/img_align_celeba/img_align_celeba/'\ntrain_samples = 10000\nvalidation_samples = 2500\ntest_samples = 1000\nbatch_size  = 16\nepochs = 10\nheight = 218 \nwidth = 178","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if K.image_data_format() == 'channel_first':\n    input_shape = (3, height, width)\nelse:\n    input_shape = (height, width, 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Exploratory Data Analysis\nReading attribute CSV file.","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/celeba-dataset/list_attr_celeba.csv', index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Male'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"1\" represents positive while \"-1\" represents negative","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10, 10))\nsns.countplot(y = 'Male', data =df)\nplt.title('Countplot of Male and Female')\nplt.xlabel('Count of persons')\nplt.ylabel('Male VS Female')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see there are more number of female gender as compared to male gender so we need to ballance the dataset.\n\nNow let's display some random images from dataset with few attributes to understand the values of attribute and corresponding image clearly.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (30, 15))\nplt.subplot(2,5,1)\nimage = cv2.imread(image_folder + '000004.jpg')\nplt.imshow(image, aspect=\"auto\")\nattr = df.loc['000004.jpg'.split('/')[-1]][['Oval_Face','Male','Pointy_Nose']]\nplt.title(str(attr), fontsize = 20)\n\nplt.subplot(2,5,2)\nimage = cv2.imread(image_folder + '000017.jpg')\nplt.imshow(image, aspect=\"auto\")\nattr = df.loc['000017.jpg'.split('/')[-1]][['Oval_Face','Male','Pointy_Nose']]\nplt.title(str(attr), fontsize = 20)\n\nplt.subplot(2,5,3)\nimage = cv2.imread(image_folder + '000014.jpg')\nplt.imshow(image, aspect=\"auto\")\nattr = df.loc['000014.jpg'.split('/')[-1]][['Oval_Face','Male','Pointy_Nose']]\nplt.title(str(attr), fontsize = 20)\n\nplt.subplot(2,5,4)\nimage = cv2.imread(image_folder + '000225.jpg')\nplt.imshow(image, aspect=\"auto\")\nattr = df.loc['000225.jpg'.split('/')[-1]][['Oval_Face','Male','Pointy_Nose']]\nplt.title(str(attr), fontsize = 20)\n\nplt.subplot(2,5,5)\nimage = cv2.imread(image_folder + '005287.jpg')\nplt.imshow(image, aspect=\"auto\")\nattr = df.loc['005287.jpg'.split('/')[-1]][['Oval_Face','Male','Pointy_Nose']]\nplt.title(str(attr), fontsize = 20)\n\nplt.subplot(2,5,6)\nimage = cv2.imread(image_folder + '000150.jpg')\nplt.imshow(image, aspect=\"auto\")\nattr = df.loc['000004.jpg'.split('/')[-1]][['Oval_Face','Male','Pointy_Nose']]\nplt.title(str(attr), fontsize = 20)\n\nplt.subplot(2,5,7)\nimage = cv2.imread(image_folder + '000999.jpg')\nplt.imshow(image, aspect=\"auto\")\nattr = df.loc['000017.jpg'.split('/')[-1]][['Oval_Face','Male','Pointy_Nose']]\nplt.title(str(attr), fontsize = 20)\n\nplt.subplot(2,5,8)\nimage = cv2.imread(image_folder + '001014.jpg')\nplt.imshow(image, aspect=\"auto\")\nattr = df.loc['000014.jpg'.split('/')[-1]][['Oval_Face','Male','Pointy_Nose']]\nplt.title(str(attr), fontsize = 20)\n\nplt.subplot(2,5,9)\nimage = cv2.imread(image_folder + '052225.jpg')\nplt.imshow(image, aspect=\"auto\")\nattr = df.loc['000225.jpg'.split('/')[-1]][['Oval_Face','Male','Pointy_Nose']]\nplt.title(str(attr), fontsize = 20)\n\nplt.subplot(2,5,10)\nimage = cv2.imread(image_folder + '065877.jpg')\nplt.imshow(image, aspect=\"auto\")\nattr = df.loc['005287.jpg'.split('/')[-1]][['Oval_Face','Male','Pointy_Nose']]\nplt.title(str(attr), fontsize = 20)\n\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The recommended partitioning of images into training, validation, testing of the data set is:\n\n1. 1-162770 images for training\n2. 162771-182637 images for validation\n3. 182638-202599 images for testing\n\nAs the size of the dataset is very huge we will take only subset of it for our experiment as follows:\n\n1. 10000 images for training\n2. 5000 images for validation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading partition file data\ndf_partition_data = pd.read_csv('../input/celeba-dataset/list_eval_partition.csv')\ndf_partition_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_partition_data['partition'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 0 indicates training set\n* 1 indicates validation set\n* 2 indicates testing set\n\nNow let's join the partition dataframe(df_partition_data) with our target attribute from actual dataframe(df).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_partition_data.set_index('image_id', inplace=True)\ndf = df_partition_data.join(df['Male'], how='inner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_image(file_name):\n    img = load_img(file_name)\n    X = img_to_array(img)/255.\n    X = X.reshape((1,) + X.shape)\n\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_df(partition, attribute, nsamples):\n    new_df = df[(df['partition'] == partition) & (df[attribute] == 1)].sample(int(nsamples/2))\n    new_df = pd.concat([new_df, df[(df['partition'] == partition) & (df[attribute] == -1)].sample(int(nsamples/2))])\n    \n    # Preprocessing image and setting the target attribute in the appropriate fromat for test and validation data\n    if partition!=2:\n        X = np.array([load_image(image_folder + file_name) for file_name in new_df.index])\n        X = X.reshape(X.shape[0], 218, 178, 3)\n        y = np_utils.to_categorical(new_df[attribute],2)\n    else:\n        X = []\n        y = []\n\n        for index, target in new_df.iterrows():\n            img = cv2.imread(image_folder + index)\n            img = cv2.resize(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), (width, height)).astype(np.float32) / 255.0\n            img = np.expand_dims(img, axis =0)\n            X.append(img)\n            y.append(target[attribute])\n        \n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting train dataframe\nX_train, y_train = generate_df(0, 'Male', train_samples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preparing train data with data augmentation\ndatagen_train =  ImageDataGenerator(\n  rotation_range=30,\n  width_shift_range=0.2,\n  height_shift_range=0.2,\n  shear_range=0.2,\n  zoom_range=0.2,\n  horizontal_flip=True\n)\n\ndatagen_train.fit(X_train)\n\ndatagen_train = datagen_train.flow(\nX_train, y_train,\nbatch_size=batch_size,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting validation dataframe\nX_val, y_val = generate_df(1, 'Male', validation_samples)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preparing train data with data augmentation\ndatagen_val =  ImageDataGenerator(\n  rotation_range=30,\n  width_shift_range=0.2,\n  height_shift_range=0.2,\n  shear_range=0.2,\n  zoom_range=0.2,\n  horizontal_flip=True\n)\n\ndatagen_val.fit(X_val)\n\ndatagen_val = datagen_val.flow(\nX_val, y_val,\nbatch_size=batch_size,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Defining the model architecture","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\n#first convolutional layer\nmodel.add(Conv2D(32, (3,3), input_shape = input_shape, padding ='same'))\nmodel.add(Activation('relu'))\n\n#second convolutional layer\nmodel.add(Conv2D(64, (3,3), activation = 'relu', padding ='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\n#third convolutional layer\nmodel.add(Conv2D(64, (3,3), activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(rate = 0.5))\n\n#fourth convolutional layer\nmodel.add(Conv2D(64, (3,3), activation = 'relu',padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(rate = 0.5))\n\n#flatten\nmodel.add(Flatten())\n\n#first dense layer\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(rate = 0.5))\n\n#second dense layer\nmodel.add(Dense(32))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(rate = 0.5))\n\n#output layer\nmodel.add(Dense(2))\nmodel.add(Activation('softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#compiling the model\nmodel.compile(optimizer =Adam(lr = 0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpointer = ModelCheckpoint(filepath='model.h5', \n                               verbose=1, \n                               save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(datagen_train,\n                    validation_data = (X_val, y_val),\n                    steps_per_epoch= train_samples/batch_size,\n                    epochs= epochs,\n                    callbacks=[checkpointer],\n                    verbose=1\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history.history.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nplt.figure(figsize = (8, 8))\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (8, 8))\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load the best model\nmodel = load_model('model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gender_prediction(filename):   \n    im = cv2.imread(filename)\n    im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (178, 218)).astype(np.float32) / 255.0\n    im = np.expand_dims(im, axis =0)\n    \n    # prediction\n    result = model.predict(im)\n    prediction = np.argmax(result)\n    \n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#select random images of the test partition\ndf_test = df[(df['partition'] == 2)].sample(5)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = image_folder +df_test.index[0]\nimage = cv2.imread(filename)\nimage = cv2.resize(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), (178, 218)).astype(np.float32) / 255.0\nimage = np.expand_dims(image, axis =0)\n    \n# prediction\nresult = model.predict(image)\nprediction = np.argmax(result)\n#print(result)\nif prediction == 1:\n    print(\"Predicted Label: Male\")\n\nelse:\n    print(\"Predicted Label: Female\")\n\n\nimage = cv2.imread(filename)\nplt.imshow(image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = image_folder +df_test.index[1]\nimage = cv2.imread(filename)\nimage = cv2.resize(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), (178, 218)).astype(np.float32) / 255.0\nimage = np.expand_dims(image, axis =0)\n    \n# prediction\nresult = model.predict(image)\nprediction = np.argmax(result)\nif prediction == 1:\n    print(\"Predicted Label: Male\")\n\nelse:\n    print(\"Predicted Label: Female\")\n\n\nimage = cv2.imread(filename)\nplt.imshow(image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = image_folder +df_test.index[2]\nimage = cv2.imread(filename)\nimage = cv2.resize(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), (178, 218)).astype(np.float32) / 255.0\nimage = np.expand_dims(image, axis =0)\n    \n# prediction\nresult = model.predict(image)\nprediction = np.argmax(result)\nif prediction == 1:\n    print(\"Predicted Label: Male\")\n\nelse:\n    print(\"Predicted Label: Female\")\n\n\nimage = cv2.imread(filename)\nplt.imshow(image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}