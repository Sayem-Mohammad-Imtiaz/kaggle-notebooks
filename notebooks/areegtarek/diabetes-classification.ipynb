{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Importing Libraries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Importing The Dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset= pd.read_csv('../input/diabetes/diabetes.csv')\nX=dataset.iloc[:,:-1].values\ny=dataset.iloc[:,-1].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Exploratory Data Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PLOTS for Visualization and Insights"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.hist(figsize = (20,20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0 - pink color scatter indicates No Diabetes\n# 1 - blue color scatter indicates Has Diabetes\nplt.rcParams['figure.figsize'] = (40, 41)\nplt.style.use('dark_background')\n\nsns.pairplot(dataset, hue = 'Outcome', palette = 'husl')\nplt.title('Pair plot for the data', fontsize = 40)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **It is better to replace zeros with nan since after that counting them would be easier and zeros need to be replaced with suitable values**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_copy = dataset.copy(deep = True)\ndataset_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = dataset_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\n\n## showing the count of Nans\nprint(dataset_copy.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Aiming to impute nan values for the columns in accordance with their distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_copy['Glucose'].fillna(dataset_copy['Glucose'].mean(), inplace = True)\ndataset_copy['BloodPressure'].fillna(dataset_copy['BloodPressure'].mean(), inplace = True)\ndataset_copy['SkinThickness'].fillna(dataset_copy['SkinThickness'].median(), inplace = True)\ndataset_copy['Insulin'].fillna(dataset_copy['Insulin'].median(), inplace = True)\ndataset_copy['BMI'].fillna(dataset_copy['BMI'].median(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Plotting after Nan removal**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_copy.hist(figsize = (20,20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0 - pink color scatter indicates No Diabetes\n# 1 - blue color scatter indicates Has Diabetes\nplt.rcParams['figure.figsize'] = (40, 41)\nplt.style.use('dark_background')\n\nsns.pairplot(dataset_copy, hue = 'Outcome', palette = 'husl')\nplt.title('Pair plot for the data', fontsize = 40)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Heatmap for unclean data"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))  \np=sns.heatmap(dataset.corr(), annot=True,cmap ='RdYlGn') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Heatmap for clean data"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))  \np=sns.heatmap(dataset_copy.corr(), annot=True,cmap ='RdYlGn') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Feature Scaling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX= sc.fit_transform(dataset_copy.drop([\"Outcome\"],axis = 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Splitting Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1/3,random_state=42, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Train The Model**"},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclassifier=LogisticRegression(random_state=0,C=1.0,max_iter=200)\nclassifier.fit(X_train,y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n#calculate the details Logistic Regression\nprint('train_score classifier',classifier.score(X_train,y_train))\nprint('test_score classifier',classifier.score(X_test,y_test))\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\nprint(cm)\n\n# drawing confusion matrix\nsns.heatmap(cm,center=True)\nplt.show(10,10)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvcmodel = SVC(kernel='rbf',degree=3)\nsvcmodel.fit(X_train,y_train)\n\n# Predicting the Test set results SVM\ny_pred = svcmodel.predict(X_test)\n\n#calculate the details SVM\nprint('train_score svcmodel', svcmodel.score(X_train,y_train))\nprint('test_score svcmodel',svcmodel.score(X_test,y_test))\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\nprint(cm)\n\n# drawing confusion matrix\nsns.heatmap(cm,center=True)\nplt.show(10,10)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n\nmlp_model = MLPClassifier(hidden_layer_sizes=100 ,activation='relu',alpha=0.01,epsilon=1E-08)\nmlp_model.fit(X_train,y_train)\n\n# Predicting the Test set results NNClassifier Model\ny_pred = mlp_model.predict(X_test)\n\n#calculate the details NNClassifier Model\nprint('train_score mlp_model', mlp_model.score(X_train,y_train))\nprint('test_score mlp_model',mlp_model.score(X_test,y_test))\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\nprint(cm)\n\n# drawing confusion matrix\nsns.heatmap(cm,center=True)\nplt.show(10,10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nKnnclassifier_model = KNeighborsClassifier(n_neighbors=11)\nKnnclassifier_model.fit(X_train,y_train)\n\n# Predicting the Test set results KNeighborsClassifier\ny_pred = Knnclassifier_model.predict(X_test)\n\n#calculate the details KNeighborsClassifier\nprint('train_score Knnclassifier_model', Knnclassifier_model.score(X_train,y_train))\nprint('test_score Knnclassifier_model',Knnclassifier_model.score(X_test,y_test))\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\nprint(cm)\n\n# drawing confusion matrix\nsns.heatmap(cm,center=True)\nplt.show(10,10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree Classification "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nDT_model=DecisionTreeClassifier(criterion='entropy')\nDT_model.fit(X_train,y_train)\n\n# Predicting the Test set results DecisionTreeClassifier Model\ny_pred = DT_model.predict(X_test)\n\n#calculate the details DecisionTreeClassifier Model\nprint('train_score DT_model', DT_model.score(X_train,y_train))\nprint('test_score DT_model',DT_model.score(X_test,y_test))\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\nprint(cm)\n\n# drawing confusion matrix\nsns.heatmap(cm,center=True)\nplt.show(10,10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngussian_model = GaussianNB(priors=None, var_smoothing=1e-09)\ngussian_model.fit(X_train,y_train)\n\n# Predicting the Test set results Naive Bayes\ny_pred = gussian_model.predict(X_test)\n\n#calculate the details Naive Bayes\nprint('train_score gussian_model', gussian_model.score(X_train,y_train))\nprint('test_score gussian_model',gussian_model.score(X_test,y_test))\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\nprint(cm)\n\n# drawing confusion matrix\nsns.heatmap(cm,center=True)\nplt.show(10,10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrfc= RandomForestClassifier(criterion='gini',n_estimators=200,max_depth=3)\nrfc.fit(X_train,y_train)\n\n# Predicting the Test set results RandomForestClassifier Model\ny_pred = rfc.predict(X_test)\n\n#calculate the details RandomForestClassifier Model\nprint('train_score rfc', rfc.score(X_train,y_train))\nprint('test_score rfc',rfc.score(X_test,y_test))\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\nprint(cm)\n\n# drawing confusion matrix\nsns.heatmap(cm,center=True)\nplt.show(10,10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **bar chart with labels For Models**"},{"metadata":{"trusted":true},"cell_type":"code","source":"r=[[classifier.score(X_train,y_train),svcmodel.score(X_train,y_train),Knnclassifier_model.score(X_train,y_train),gussian_model.score(X_train,y_train)\n   ,DT_model.score(X_train,y_train),mlp_model.score(X_train,y_train),rfc.score(X_train,y_train)],\n   [classifier.score(X_test,y_test),svcmodel.score(X_test,y_test),Knnclassifier_model.score(X_test,y_test),gussian_model.score(X_test,y_test)\n    ,DT_model.score(X_test,y_test),mlp_model.score(X_test,y_test),rfc.score(X_test,y_test)]]\n\n\nX = np.arange(7)\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nplt.style.use('seaborn-notebook')\nax.bar(X+ 0.00,r[0], color = 'blue', width = 0.30,label = 'train score')\nax.bar(X+ 0.40, r[1], color = 'red', width = 0.30,label = 'test score')\nfor i,m in list(zip(X,r[0])):\n  plt.text(x = i ,y = m,s = m)\nfor i,m in list(zip(X,r[1])):\n  plt.text(x = i + 0.45 ,y = m,s = m)\nax.set_xlabel('Models')\nax.set_ylabel('score')\nax.set_xticklabels(('','classifier', 'SVC', 'KNN', 'Gussian', 'DT','MLP','RFC'))\nplt.legend()\nplt.show(10,10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}