{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom wordcloud import WordCloud\nimport math","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# preprocessing data","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv(\"/kaggle/input/reddit-wallstreetsbets-posts/reddit_wsb.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"title_raw = []\nscore = []\n\nfor i in range(len(dataset)):\n    title_raw.append(dataset[\"title\"][i])\n    score.append(int(dataset[\"score\"][i]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = tf.keras.preprocessing.text.Tokenizer()\ntokenizer.fit_on_texts(title_raw)\ntitle = tokenizer.texts_to_sequences(title_raw)\n\nprint(len(tokenizer.word_index))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# distribution of upvotes","metadata":{}},{"cell_type":"code","source":"scores = {\"0\":0, \"1-10\":0, \"11-100\":0, \"101-1000\":0, \"1001-10000\":0, \"10001-100000\":0, \"100001->\":0}\n\nfor i in score:\n    if i < 1:\n        scores[\"0\"] += 1\n    elif i < 11:\n        scores[\"1-10\"] += 1\n    elif i < 101:\n        scores[\"11-100\"] += 1\n    elif i < 1001:\n        scores[\"101-1000\"] += 1\n    elif i < 10001:\n        scores[\"1001-10000\"] += 1\n    elif i < 100001:\n        scores[\"10001-100000\"] += 1\n    else:\n        scores[\"100001->\"] += 1\n\nfig = plt.figure(figsize=(9, 3))\nax = fig.add_axes([0,0,1,1])\nscore_label = [\"0\", \"1-10\", \"11-100\", \"101-1000\", \"1001-10000\", \"10001-100000\", \"100001->\"]\nvalue = [scores[\"0\"], scores[\"1-10\"], scores[\"11-100\"], scores[\"101-1000\"], scores[\"1001-10000\"], scores[\"10001-100000\"], scores[\"100001->\"]]\nax.bar(score_label,value)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_cloud(wordcloud):\n    plt.figure(figsize=(40, 30))\n    plt.imshow(wordcloud) \n    plt.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# most common words overall","metadata":{}},{"cell_type":"code","source":"total_posts=0\n\nfor i in value:\n    total_posts+=i\n\noverallfreqs={}\n    \nfor word, index in tokenizer.word_index.items():\n      overallfreqs[word] = 0\n    \nfor i in title:\n    for j in i:\n        for word, index in tokenizer.word_index.items():\n          if j == index:\n            overallfreqs[word] += 1\n            break\n    \n    \nfor word, index in tokenizer.word_index.items():\n      overallfreqs[word] /= total_posts\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(overallfreqs)\n\nplot_cloud(wordcloud)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# most relatively common words up to 10 upvotes","metadata":{}},{"cell_type":"code","source":"total_posts=scores[\"0\"] + scores[\"1-10\"]\n\nfreqto10 = {}\n\nfor word, index in tokenizer.word_index.items():\n      freqto10[word] = 0\n    \nfor i in range(len(title)):\n    if score[i] < 11:\n        for j in title[i]:\n            for word, index in tokenizer.word_index.items():\n              if j == index:\n                freqto10[word] += 1\n                break    \n    \nfor word, index in tokenizer.word_index.items():\n      freqto10[word] /= total_posts\n        \nfor word, index in tokenizer.word_index.items():\n    if freqto10[word] != 0 and overallfreqs[word] != 0:\n        freqto10[word] /= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(freqto10)\n\nplot_cloud(wordcloud)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# most relatively common words 11 to 1000 upvotes","metadata":{}},{"cell_type":"code","source":"total_posts=scores[\"11-100\"] + scores[\"101-1000\"]\n\nfreq11to1000 = {}\n\nfor word, index in tokenizer.word_index.items():\n      freq11to1000[word] = 0\n    \nfor i in range(len(title)):\n    if score[i] > 10 or score[i] < 1001:\n        for j in title[i]:\n            for word, index in tokenizer.word_index.items():\n              if j == index:\n                freq11to1000[word] += 1\n                break    \n    \nfor word, index in tokenizer.word_index.items():\n      freq11to1000[word] /= total_posts\n        \nfor word, index in tokenizer.word_index.items():\n    if freq11to1000[word] != 0 and overallfreqs[word] != 0:\n        freq11to1000[word] /= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(freq11to1000)\n\nplot_cloud(wordcloud)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# most relatively common words 1001 to 100000 upvotes","metadata":{}},{"cell_type":"code","source":"total_posts=scores[\"1001-10000\"] + scores[\"10001-100000\"]\n\nfreq1001to100000 = {}\n\nfor word, index in tokenizer.word_index.items():\n      freq1001to100000[word] = 0\n    \nfor i in range(len(title)):\n    if score[i] > 1000 or score[i] < 100001:\n        for j in title[i]:\n            for word, index in tokenizer.word_index.items():\n              if j == index:\n                freq1001to100000[word] += 1\n                break    \n    \nfor word, index in tokenizer.word_index.items():\n      freq1001to100000[word] /= total_posts\n        \nfor word, index in tokenizer.word_index.items():\n    if freq1001to100000[word] != 0 and overallfreqs[word] != 0:\n        freq1001to100000[word] /= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(freq1001to100000)\n\nplot_cloud(wordcloud)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# most relatively common words 100001 and up upvotes","metadata":{}},{"cell_type":"code","source":"total_posts=scores[\"100001->\"]\n\nfreqover100001 = {}\n\nfor word, index in tokenizer.word_index.items():\n      freqover100001[word] = 0\n    \nfor i in range(len(title)):\n    if score[i] > 100001:\n        for j in title[i]:\n            for word, index in tokenizer.word_index.items():\n              if j == index:\n                freqover100001[word] += 1\n                break    \n    \nfor word, index in tokenizer.word_index.items():\n      freqover100001[word] /= total_posts\n        \nfor word, index in tokenizer.word_index.items():\n    if freqover100001[word] != 0 and overallfreqs[word] != 0:\n        freqover100001[word] /= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(freqover100001)\n\nplot_cloud(wordcloud)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I think this shows that some words are very common in post titles of various popularities. As well as this the words overall are very different from the distributions over the wider english language","metadata":{}},{"cell_type":"markdown","source":"I will try to take on any suggestions... I hope you enjoyed. Please consider voting this notebook while you enjoy those chicken tendies","metadata":{}}]}