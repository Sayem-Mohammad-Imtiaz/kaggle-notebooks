{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data.dataset import Dataset\n\nclass CellDataset(Dataset):\n    def __init__(self, data_dir, csv_file, transform=None):\n        super().__init__()\n\n        self.data_dir = data_dir\n        self.df = csv_file\n        self.transforms = transform           \n        self.cell_types = self.df[['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18']].values\n        self.img_ids = self.df['image_id'].values\n        self.cell_ids = self.df['cell_id'].values\n\n    def __len__(self):\n        # return len(self.img_ids)\n        return 100\n\n    def get_image(self, index):\n\n        image_id = self.img_ids[index]\n        cell_id = self.cell_ids[index]\n        \n        img_path = os.path.join(self.data_dir, 'cells', image_id + '_' + str(cell_id) + '.jpg')\n        \n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = self.transforms(image=img)\n        img = img['image']\n\n        return img\n\n    def __getitem__(self, index):\n        x = self.get_image(index)\n        y = self.cell_types[index]\n        y = torch.from_numpy(y).float()\n        return x, y\n\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install iterative-stratification","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport timm\n\nclass Net(nn.Module):\n    def __init__(self, name = 'resnet34', num_classes=19):\n        super(Net, self).__init__()\n        self.model = timm.create_model(name, pretrained=False, num_classes=num_classes)\n\n    def forward(self, x):\n        out = self.model(x)\n\n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Params:\n    def __init__(self):\n        self.epochs = 2\n        self.batch_size = 32 \n        self.lr = 2e-3 \n        self.n_workers = 24\n        self.data_dir = '../input/hpa-cell-tiles-sample-balanced-dataset'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = Params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pytorch_lightning as pl\nfrom torch.utils.data import DataLoader\nimport torch\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.loggers import CSVLogger\nfrom pytorch_lightning.utilities.seed import seed_everything\nfrom argparse import ArgumentParser\nfrom pytorch_lightning.callbacks import Callback\nfrom tqdm import tqdm\nfrom pytorch_lightning.callbacks.progress import ProgressBar\n# from base_model import Net\n# from dataset import CellDataset\nfrom pytorch_lightning.callbacks import LearningRateMonitor\nfrom pytorch_lightning.metrics import Accuracy\nfrom pytorch_lightning.metrics import Recall\nfrom pytorch_lightning.loggers import WandbLogger\nimport os\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport torchvision.transforms as transforms\nimport pandas as pd\nimport numpy as np\n\ntrain_transforms = A.Compose([\n    A.Rotate(),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.Resize(width=224, height=224),\n    A.Normalize(),\n    ToTensorV2(),\n])\n\nvalid_transforms = A.Compose([\n    A.Resize(width=224, height=224),\n    A.Normalize(),\n    ToTensorV2,\n])\n\n\ndf = pd.read_csv('../input/hpa-cell-tiles-sample-balanced-dataset/cell_df.csv')\nlabels = [str(i) for i in range(19)]\nfor x in labels: df[x] = df['image_labels'].apply(lambda r: int(x in r.split('|')))\n\ndfs = df.sample(frac=1, random_state=42)\ndfs = dfs.reset_index(drop=True)\nlen(dfs)\n\nunique_counts = {}\nfor lbl in labels:\n    unique_counts[lbl] = len(dfs[dfs.image_labels == lbl])\n\nfull_counts = {}\nfor lbl in labels:\n    count = 0\n    for row_label in dfs['image_labels']:\n        if lbl in row_label.split('|'): count += 1\n    full_counts[lbl] = count\n    \ncounts = list(zip(full_counts.keys(), full_counts.values(), unique_counts.values()))\ncounts = np.array(sorted(counts, key=lambda x:-x[1]))\ncounts = pd.DataFrame(counts, columns=['label', 'full_count', 'unique_count'])\ncounts.set_index('label').T\n\n\nnfold = 10\n#seed = 42\n\ny = dfs[labels].values\nX = dfs[['image_id', 'cell_id']].values\n\ndfs['fold'] = np.nan\n\nmskf = MultilabelStratifiedKFold(n_splits=nfold, shuffle=False)\nfor i, (_, test_index) in enumerate(mskf.split(X, y)):\n    dfs.iloc[test_index, -1] = i\n    \ndfs['fold'] = dfs['fold'].astype('int')\n\n\ndfs['is_valid'] = False\ndfs['is_valid'][dfs['fold'] == 0] = True\n\ntrain_df = dfs[dfs['is_valid'] == False]\nvalid_df = dfs[dfs['is_valid'] == True]\nprint(len(train_df))\nprint(len(valid_df))\n# def collate_fn(batch):\n#     batch = list(filter(lambda x: x is not None, batch))\n#     return torch.utils.data.dataloader.default_collate(batch)\n\n\nclass HPALit(pl.LightningModule):\n\n    def __init__(self):\n        super().__init__()\n        \n        \n        self.lr = params.lr\n        self.model = Net()\n        self.criterion = torch.nn.BCEWithLogitsLoss()\n        self.train_dataset = CellDataset(data_dir=params.data_dir,\n                                        csv_file=train_df, transform=train_transforms)\n        self.val_dataset = CellDataset(data_dir=params.data_dir,\n                                        csv_file=valid_df, transform=valid_transforms)\n        self.train_accuracy = Accuracy(subset_accuracy=True)\n        self.val_accuracy = Accuracy(subset_accuracy=True)\n        self.train_recall = Recall()\n        self.val_recall = Recall()\n\n    def train_dataloader(self):\n        return DataLoader(self.train_dataset,\n                        #   collate_fn = collate_fn,\n                          batch_size=params.batch_size,\n                          shuffle=True,\n                          num_workers=params.n_workers,\n                          pin_memory=True,\n                          #drop_last=True\n                          )\n\n    def val_dataloader(self):\n        return DataLoader(self.val_dataset,\n                        #   collate_fn = collate_fn,\n                          batch_size=params.batch_size,\n                          shuffle=False,\n                          num_workers=params.n_workers,\n                          pin_memory=True,\n                          #drop_last=True\n                          )\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5, eps=1e-6)\n        lr_scheduler = {'scheduler': scheduler, 'interval': 'epoch', 'monitor': 'valid_loss_epoch'}\n\n        return [optimizer], [lr_scheduler]\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        pred = self.model(x)\n\n        train_loss = self.criterion(pred, y)\n        self.train_accuracy(torch.sigmoid(pred), y.type(torch.int))\n        self.train_recall(torch.sigmoid(pred), y.type(torch.int))\n\n        # self.log('train_acc_step', self.train_accuracy)\n        # self.log('train_loss_step', train_loss)\n        # self.log('train_recall_step', self.train_recall)\n        \n        return {'loss': train_loss}\n\n    def training_epoch_end(self, outputs):\n        train_loss_epoch = torch.stack([x['loss'] for x in outputs]).mean()\n        self.log('train_loss_epoch', train_loss_epoch)\n        self.log('train_acc_epoch', self.train_accuracy.compute())\n        self.log('train_recall_epoch', self.train_recall.compute())\n        self.train_accuracy.reset()\n        self.train_recall.reset()\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        pred = self.model(x)\n\n        val_loss = self.criterion(pred, y)\n        self.val_accuracy(torch.sigmoid(pred), y.type(torch.int))\n        self.val_recall(torch.sigmoid(pred), y.type(torch.int))\n        \n        # self.log('valid_recall_step', self.val_recall)\n        # self.log('valid_loss_step', val_loss)\n        # self.log('valid_acc_step', self.val_accuracy)\n        return {'valid_loss': val_loss}\n\n\n    def validation_epoch_end(self, outputs):\n        val_loss_epoch = torch.stack([x['valid_loss'] for x in outputs]).mean()\n        self.log('valid_loss_epoch', val_loss_epoch)\n        self.log('valid_acc_epoch', self.val_accuracy.compute())\n        self.log('valid_recall_epoch', self.val_recall.compute())\n        self.val_accuracy.reset()\n        self.val_recall.reset()\n\n\n\nclass MyPrintingCallback(Callback):\n\n    def on_validation_epoch_end(self, trainer, pl_module):\n        # print(trainer.callback_metrics)\n        print('\\n')\n        print('Train Loss: {:.3f}'.format(trainer.callback_metrics['train_loss_epoch'].item()))\n        print('Val Loss: {:.3f}'.format(trainer.callback_metrics['valid_loss_epoch'].item()))\n        print('Train Accuracy: {:.3f}'.format(trainer.callback_metrics['train_acc_epoch'].item()))\n        print('Val Accuracy: {:.3f}'.format(trainer.callback_metrics['valid_acc_epoch'].item()))\n        print('Train Recall: {:.3f}'.format(trainer.callback_metrics['train_recall_epoch'].item()))\n        print('Val Recall: {:.3f}'.format(trainer.callback_metrics['valid_recall_epoch'].item()))\n\n\nclass LitProgressBar(ProgressBar):\n\n    def init_validation_tqdm(self):\n        bar = tqdm(\n            disable=True,\n        )\n        return bar","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint(\n    dirpath='logs/resnet34-224',\n    filename='{epoch}-{valid_loss_epoch:.3f}',\n    save_top_k=-1,\n    verbose=False,\n)\nprinter = MyPrintingCallback()\nlogger = CSVLogger(save_dir=\"logs/resnet34-224\", name=\"text_logs\")\nwandb_logger = WandbLogger(name='resnet34-224', project='polish-pipeline')\nbar = LitProgressBar()\nlr_monitor = LearningRateMonitor(logging_interval='step')\nmodel = HPALit()\ntrainer = pl.Trainer(\n    progress_bar_refresh_rate=1,\n    max_epochs=params.epochs,\n    callbacks=[checkpoint, printer, bar, lr_monitor],\n    gradient_clip_val=1,\n    logger=[logger],# wandb_logger],\n    gpus=1,\n    # accelerator='ddp',\n    num_sanity_val_steps=0,\n    #auto_lr_find=True,\n)\n#trainer.tune(model)\ntrainer.fit(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}