{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Department\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count1=0\ncount2=0\ncount3=0\ncount4=0\ncount5=0\ncount6=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data.index:\n    if(data[\"Department\"][i]=='Sales' and data['Attrition'][i]=='Yes'):\n        count1=count1+1;\n    if(data[\"Department\"][i]=='Sales' and data['Attrition'][i]=='No'):\n        count2=count2+1;\n    if(data[\"Department\"][i]=='Research & Development' and data['Attrition'][i]=='Yes'):\n        count3=count3+1;\n    if(data[\"Department\"][i]=='Research & Development' and data['Attrition'][i]=='No'):\n        count4=count4+1;\n    if(data[\"Department\"][i]=='Human Resources' and data['Attrition'][i]=='Yes'):\n        count5=count5+1;\n    if(data[\"Department\"][i]=='Human Resources' and data['Attrition'][i]=='No'):\n        count6=count6+1;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(count1)\nprint(count2)\nprint(count3)\nprint(count4)\nprint(count5)\nprint(count6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nx=0\nx_=('Sales','Research and development','Human Resources')\nax = plt.subplot(111)\nax.bar(x-0.2, count1, width=0.2, color='g', align='center',label='yes')\nax.bar(x, count2, width=0.2, color='r', align='center',label='no')\nax.bar(x+0.4, count3, width=0.2, color='g', align='center')\nax.bar(x+0.6, count4, width=0.2, color='r', align='center')\nax.bar(x+1.0, count5, width=0.2, color='g', align='center')\nax.bar(x+1.2, count6, width=0.2, color='r', align='center')\nplt.xticks([-0.1,0.5,1.1],('Sales','R&D','Human Resources'))\nplt.xlabel(\"Department\")\nplt.legend();\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"BusinessTravel\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count1=0\ncount2=0\ncount3=0\ncount4=0\ncount5=0\ncount6=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data.index:\n    if(data[\"BusinessTravel\"][i]=='Travel_Rarely' and data['Attrition'][i]=='Yes'):\n        count1=count1+1;\n    if(data[\"BusinessTravel\"][i]=='Travel_Rarely' and data['Attrition'][i]=='No'):\n        count2=count2+1;\n    if(data[\"BusinessTravel\"][i]=='Travel_Frequently' and data['Attrition'][i]=='Yes'):\n        count3=count3+1;\n    if(data[\"BusinessTravel\"][i]=='Travel_Frequently' and data['Attrition'][i]=='No'):\n        count4=count4+1;\n    if(data[\"BusinessTravel\"][i]=='Non-Travel' and data['Attrition'][i]=='Yes'):\n        count5=count5+1;\n    if(data[\"BusinessTravel\"][i]=='Non-Travel' and data['Attrition'][i]=='No'):\n        count6=count6+1;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(count1)\nprint(count2)\nprint(count3)\nprint(count4)\nprint(count5)\nprint(count6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=0\nx_=('Travel_Rarely','Travel_Frequently','Non-Travel')\nax = plt.subplot(111)\nax.bar(x-0.2, count1, width=0.2, color='y', align='center',label='yes')\nax.bar(x, count2, width=0.2, color='c', align='center',label='no')\nax.bar(x+0.4, count3, width=0.2, color='y', align='center')\nax.bar(x+0.6, count4, width=0.2, color='c', align='center')\nax.bar(x+1.0, count5, width=0.2, color='y', align='center')\nax.bar(x+1.2, count6, width=0.2, color='c', align='center')\nplt.xticks([-0.1,0.5,1.1],('Travel_Rarely','Travel_Frequently','Non-Travel'))\nplt.xlabel(\"BusinessTravel\")\nplt.legend();\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install wordcloud","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\nfrom os import path\nfrom wordcloud import WordCloud\n\n# get data directory (using getcwd() is needed to support running example in generated IPython notebook)\nd = path.dirname(__file__) if \"__file__\" in locals() else os.getcwd()\n\n# Read the whole text.\ntext = open(path.join(r\"/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv\")).read()\n\n# Generate a word cloud image\nwordcloud = WordCloud().generate(text)\n\n# Display the generated image:\n# the matplotlib way:\nimport matplotlib.pyplot as plt\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lower max_font_size\nwordcloud = WordCloud(max_font_size=40).generate(text)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\n\n# The pil way (if you don't have matplotlib)\n# image = wordcloud.to_image()\n# image.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Label Encoding the data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ndata['BusinessTravel']=le.fit_transform(data['BusinessTravel'])\ndata['Department']=le.fit_transform(data['Department'])\ndata['Gender']=le.fit_transform(data['Gender'])\ndata['MaritalStatus']=le.fit_transform(data['MaritalStatus'])\ndata['OverTime']=le.fit_transform(data['OverTime'])\ndata['Attrition']=le.fit_transform(data['Attrition'])\ndata['PerformanceRating']=le.fit_transform(data['PerformanceRating'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=data.iloc[:,[0,2,4,5,10,11,16,17,18,22,23,24,25,28,31,33]].values\n#0:age 1:Businesstravel 2:Department 3:Distance from home 4:EnvironmentSatisfaction 5:Gender 6:JobSatisfaction \n#7:MaritalStatus  8:MonthlyIncome 9:OverTime 10:PercentSalaryHike 11:PerformanceRating 12:RelationshipSatisfaction\n#13:TotalWorkingYears 14:YearsAtCompany 15:YearsSinceLastPromotion \ny=data.iloc[:,1:2].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **OneHot Encoding**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.preprocessing import OneHotEncoder\none=OneHotEncoder()\nz=one.fit_transform(x[:,1:2]).toarray()#2 more columns\nt=one.fit_transform(x[:,2:3]).toarray()#2 more columns\nr=one.fit_transform(x[:,4:5]).toarray()#3 more columns\ns=one.fit_transform(x[:,6:7]).toarray()#3 more columns\nm=one.fit_transform(x[:,7:8]).toarray()#2 more columns\nq=one.fit_transform(x[:,12:13]).toarray()#3 more columns\nx=np.delete(x,[1,2,4,6,7,12],axis=1)\nx=np.concatenate((q,m,s,r,t,z,x),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape#(16+2+2+3+3+2+3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split#then we divided the data into train set and test set so that we can send it for further processing\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=23)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we scaled the data so that we can avoid outliers and we classify the data accurately\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nx_train=sc.fit_transform(x_train)\nx_test=sc.fit_transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Decision Tree Classifier**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndtc=DecisionTreeClassifier(random_state=23,criterion='entropy')\ndtc.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtcpred=dtc.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtcpred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ndtcacc=accuracy_score(y_test,dtcpred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtcacc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,dtcpred)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn.metrics as metrics\nfpr,tpr,threshold=metrics.roc_curve(y_test,dtcpred)\nroc_auc=metrics.auc(fpr,tpr)#false positive rate fpr and true positive rate tpr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}