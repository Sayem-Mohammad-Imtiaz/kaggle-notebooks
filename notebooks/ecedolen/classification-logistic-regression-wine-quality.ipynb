{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <font color=\"red\"> <div align=\"center\"> CLASSIFICATION PROJECT  \n    \n## <div align=\"center\"> WINE QUALITY\n"},{"metadata":{},"cell_type":"markdown","source":"## Contents\n1.  Introduction\n2.  The Aim of Analysis\n3.  General Information of the Data\n4.  Data Exploration\n5.  Checking for NULL Values \n6.  Filling of the Row Data \n7.  General Looking at Wine Quality Classes\n     * 7. 1 Creating 2 Bins Model of Two Types of Wine Quality Classes\n8.  Overview about Outliers \n     * 8.1    Winsorization\n9.  LOGISTIC REGRESSION CLASSIFIER\n     * 9.1    Creating Train / Test Groups with 2 Bins Model \n     * 9.1.a  LogisticRegression\n     * 9.1.b  Performance Measurements\n     * 9.2    Creating Train / Test Groups with 3 Bins Model\n     * 9.2.a  LogisticRegression\n     * 9.2.b  Performance Measurements\n10.  Imbalanced Data\n     * 10.1   Resampling Imbalance Data\n     * 10.2   Cross Validation\n     * 10.3   K-Fold Cross Validation\n     * 10.4   Cross_val_score & Cross_validate \n11. Hyperparameter Tuning\n     * 11.1   Grid Search\n     * 11.2   RandomizedSearchCV"},{"metadata":{},"cell_type":"markdown","source":"# <div align=\"center\">  **1. Introduction**"},{"metadata":{},"cell_type":"markdown","source":"### <font color=\"gray\">The dataset was downloaded from the UCI Machine Learning Repository.\n\n### <font color=\"gray\">The two datasets are related to red and white variants of the Portuguese \"Vinho Verde\" wine"},{"metadata":{},"cell_type":"markdown","source":"# <div align=\"center\"> **2. The Aim of Analysis**"},{"metadata":{},"cell_type":"markdown","source":"### <font color=\"gray\"> This study aims to search for the elements which effects WINE QUALITY by using multiclass  decision classification methods such as Support Vector Machines, K-NN, Logistic Regression, Softmax, Confusion Matrix, Accuracy, Precision, Specificity, F1 Score, ROC/AUC, Logarithmic Loss, Cross Validation, K-Fold Cross Validation, Grid Search, SMOTE "},{"metadata":{},"cell_type":"markdown","source":"# <div align=\"center\">  **3. General Information of the Data**"},{"metadata":{},"cell_type":"markdown","source":"\n### <font color=\"black\">Type:<font color=\"gray\"> Two types of wines such as red wine and white wine.\n    \n### <font color=\"black\">Fixed acidity:<font color=\"gray\"> Fixed acids include tartaric, malic, citric, and succinic acids which are found in grapes (except succinic)\n\n### <font color=\"gray\">Acids are one of the fundamental properties of wine and contribute greatly to the taste of the wine, Acidity in food and drink tastes tart and zesty. Tasting acidity is also sometimes confused with alcohol. Wines with higher acidity feel lighter-bodied because they come across as “spritzy”. Reducing acids significantly might lead to wines tasting flat. If you prefer a wine that is richer and rounder, you enjoy slightly less acidity.\n\n### <font color=\"black\">Volatile acidity:<font color=\"gray\"> These acids are to be distilled out from the wine before completing the production process. It is primarily constituted of acetic acid though other acids like lactic, formic and butyric acids might also be present. Excess of volatile acids are undesirable and lead to unpleasant flavour.\n\n### <font color=\"black\">Citric acid:<font color=\"gray\"> This is one of the fixed acids which gives a wine its freshness. Usually most of it is consumed during the fermentation process and sometimes it is added separately to give the wine more freshness.\n\n### <font color=\"black\">Residual sugar: <font color=\"gray\">This typically refers to the natural sugar from grapes which remains after the fermentation process stops, or is stopped.\n\n### <font color=\"black\">Chlorides: <font color=\"gray\">Chloride concentration in the wine is influenced by terroir and its highest levels are found in wines coming from countries where irrigation is carried out using salty water or in areas with brackish terrains.\n\n### <font color=\"black\">Free sulfur dioxide:<font color=\"gray\"> This is the part of the sulphur dioxide that when added to a wine is said to be free after the remaining part binds. Winemakers will always try to get the highest proportion of free sulphur to bind. They are also known as sulfites and too much of it is undesirable and gives a pungent odour.\n\n### <font color=\"black\">Total sulfur dioxide:<font color=\"gray\"> This is the sum total of the bound and the free sulfur dioxide. This is mainly added to kill harmful bacteria and preserve quality and freshness. There are usually legal limits for sulfur levels in wines and excess of it can even kill good yeast and give out undesirable odour.\n\n### <font color=\"black\">Density: <font color=\"gray\">This can be represented as a comparison of the weight of a specific volume of wine to an equivalent volume of water. It is generally used as a measure of the conversion of sugar to alcohol. \n\n### <font color=\"black\">pH: <font color=\"gray\"> Also known as the potential of hydrogen, this is a numeric scale to specify the acidity or basicity the wine. Fixed acidity contributes the most towards the pH of wines. You might know, solutions with a pH less than 7 are acidic, while solutions with a pH greater than 7 are basic. With a pH of 7, pure water is neutral. Most wines have a pH between 2.9 and 3.9 and are therefore acidic.\n\n### <font color=\"black\">Sulphates: <font color=\"gray\">These are mineral salts containing sulfur. Sulphates are to wine as gluten is to food. They are a regular part of the winemaking around the world and are considered essential. They are connected to the fermentation process and affects the wine aroma and flavour. \n\n### <font color=\"black\">Alcohol: <font color=\"gray\"> It's usually measured in % vol or alcohol by volume (ABV).\n\n### <font color=\"black\">Quality:<font color=\"gray\"> Wine experts graded the wine quality between 0 (very bad) and 10 (very excellent). The eventual quality score is the median of at least three evaluations made by the same wine experts.\n"},{"metadata":{},"cell_type":"markdown","source":"# <div align=\"center\"> **4. Data Exploration**"},{"metadata":{},"cell_type":"markdown","source":"### 0. Importing Packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ***Getting Data***"},{"metadata":{"trusted":true},"cell_type":"code","source":"from subprocess import check_output\n\nprint(check_output([\"ls\", \"../input/wine-quality\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/wine-quality/winequalityN.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ***About data***"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ***Switching Column Names into a suitable format***"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"print(*df.columns, sep='\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns = ('type', 'fixed_acidity', 'volatile_acidity', 'citric_acid',\n       'residual_sugar', 'chlorides', 'free_sulfur_dioxide',\n       'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol',\n       'quality')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ***First 5 rows***"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div align=\"center\"> **5. Checking for NULL Values**"},{"metadata":{},"cell_type":"markdown","source":"#### ***Looking NAN values with heatmap***"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ***Checking for NULL Values***"},{"metadata":{"trusted":true},"cell_type":"code","source":"Sum = df.isnull().sum()\nPercentage = ( df.isnull().sum()/df.isnull().count())\n\npd.concat([Sum,Percentage], axis =1, keys= ['Sum', 'Percentage'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def null_cell(df): \n    total_missing_values = df.isnull().sum() \n    missing_values_per = df.isnull().sum()/df.isnull().count() \n    null_values = pd.concat([total_missing_values, missing_values_per], axis=1, keys=['total_null', 'total_null_perc']) \n    null_values = null_values.sort_values('total_null', ascending=False) \n    return null_values[null_values['total_null'] > 0] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div align=\"center\"> **6. Filling of the Row Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fill_list = (null_cell(df)).index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mean = df.copy()\n\nfor col in fill_list:\n    df_mean.loc[:, col].fillna(df_mean.loc[:, col].mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df_mean.isnull(),yticklabels=False,cbar=False,cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = df_mean.corr()\ncorr_list = corr_matrix.quality.abs().sort_values(ascending=False).index[0:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(11,9))\ndropSelf = np.zeros_like(corr_matrix)\ndropSelf[np.triu_indices_from(dropSelf)] = True\n\nsns.heatmap(corr_matrix, cmap=sns.diverging_palette(220, 10, as_cmap=True), annot=True, fmt=\".2f\", mask=dropSelf)\n\nsns.set(font_scale=1.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wine quality has the highest correlation with alcohol. Other relation degrees are very low with each other,such as citric acid,free_sulfur_dioxide, sulphates and pH.\nQuality also has a low negative correlation with density,volatile acidity, chlorides, total_sulfur_dioxide and residual_sugar. "},{"metadata":{},"cell_type":"markdown","source":" #### ***Distribution  of Variables***"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import norm ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,22))\n\nfor i in range(1,13):\n    plt.subplot(5,4,i)\n    sns.distplot(df_mean[df_mean.columns[i]], fit=norm)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div align=\"center\"> **7. General Looking at Wine Quality Classes"},{"metadata":{},"cell_type":"markdown","source":"## <font color=\"darkblue\"> 7. 1 Creating 2 Bins Model of Two Types of Wine Quality Classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bins= df_mean.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = [0,5,10]\n\n\nlabels = [0, 1] # 'low'=0, 'high'=1\ndf_bins['quality_range']= pd.cut(x=df_bins['quality'], bins=bins, labels=labels)\n\nprint(df_bins[['quality_range','quality']].head(5))\n\ndf_bins = df_bins.drop('quality', axis=1) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Quality in  Different Wine Types"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,5))\n\nsns.countplot(x = 'type', hue = 'quality_range', data = df_bins)\nplt.show()\n# 'low'=0, 'high'=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see on the chart, Low quality red wine has the highest numerical value in data set as well as low quality white wine. \nHigh quality white and red wines have little place in data. "},{"metadata":{},"cell_type":"markdown","source":"## Quality & Alcohol Relation "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,7))\nsns.scatterplot(x='quality_range', \n                y='alcohol', \n                hue='type',\n                data=df_bins);\nplt.xlabel('Quality',size=15)\nplt.ylabel('Alcohol', size =15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Red and White wines has similar results on the chart. High quality wines are mostly red wines and have more alcohol level."},{"metadata":{},"cell_type":"markdown","source":"## Quality & Volatile Acidity by Types"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 8))\nf.suptitle('Wine Types by Quality & Acidity', fontsize=14)\n\nsns.violinplot(x='quality_range', y='volatile_acidity', hue='type', data=df_bins, split=True, inner='quart', linewidth=1.3,\n               palette={'red': 'red', 'white': 'white'}, ax=ax1)\nax1.set_xlabel(\"Wine Quality Class \",size = 15,alpha=0.8)\nax1.set_ylabel(\"Wine Fixed Acidity\",size = 15,alpha=0.8)\n\nsns.violinplot(x='quality_range', y='alcohol', hue='type', data=df_bins, split=True, inner='quart', linewidth=1.3,\n               palette={'red': 'darkred', 'white': 'white'}, ax=ax2)\nax2.set_xlabel(\"Wine Quality Class\",size = 15,alpha=0.8)\nax2.set_ylabel(\"Wine Fixed Alcohol\",size = 15,alpha=0.8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fixed acidity level is low in both wine classes, especially in white wine while red wine has more in low quality class up to 1.70.  Fixed alcohol level is again high in red wine class comparing white wine in low quality. High quality class has the highest fixed alcohol level in booth wine classes. "},{"metadata":{},"cell_type":"markdown","source":"## Chlorides Level in Quality Classes "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize= (6,4))\n\nlow_quality = df_bins [df_bins['quality_range']== 0]['chlorides']\nhigh_quality   = df_bins [df_bins['quality_range']== 1][ 'chlorides']\nax = sns.kdeplot(data= low_quality, label= 'low_quality', shade=True, color=None)\nax = sns.kdeplot(data= high_quality,label= 'high_quality',shade=True, color= \"r\")\n\nplt.title(\"Chloride Level in Wine Classes\")\nplt.xlim(0.0,0.3)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Chloride Level is a bit higher in red wine in contrats with white wine. "},{"metadata":{},"cell_type":"markdown","source":"## Fixed Acidity & Volatile Acidity & Citric Acid Density in Quality Classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, (ax1, ax2, ax3) = plt.subplots(3, figsize = (10,10))\n\nf.suptitle('Wine Quality - Acidity Levels', fontsize=14)\n\n\nfixed_acidity_low_quality    = df_bins [df_bins['quality_range']== 0]['fixed_acidity']\nfixed_acidity_high_quality   = df_bins [df_bins['quality_range']== 1]['fixed_acidity']\n\n\nvolatile_acidity_low_quality = df_bins [df_bins['quality_range']== 0]['volatile_acidity']\nvolatile_acidity_high_quality= df_bins [df_bins['quality_range']== 1]['volatile_acidity']\n\ncitric_acid_low_quality      = df_bins [df_bins['quality_range']== 0]['citric_acid']\ncitric_acid_high_quality     = df_bins [df_bins['quality_range']== 1]['citric_acid']\n\n\nsns.kdeplot(data=fixed_acidity_low_quality, label=\"low_quality\", shade=True,ax=ax1)\nsns.kdeplot(data=fixed_acidity_high_quality, label=\"high_quality\", shade=True, ax=ax1)\nax1.set_xlabel(\"fixed_acidity\",size = 15,alpha=0.8)\nax1.set_ylabel(\"Wine Quality\",size = 15,alpha=0.8)\n\n\nsns.kdeplot(data=volatile_acidity_low_quality, label=\"low_quality\", shade=True,ax=ax2)\nsns.kdeplot(data=volatile_acidity_high_quality, label=\"high_quality\", shade=True, ax=ax2)\nax2.set_xlabel(\"volatile_acidity\",size = 15,alpha=0.8)\nax2.set_ylabel(\"Wine Quality\",size = 15,alpha=0.8)\n\n\nsns.kdeplot(data=citric_acid_low_quality, label=\"low_quality\", shade=True,ax=ax3)\nsns.kdeplot(data=citric_acid_high_quality, label=\"high_quality\", shade=True, ax=ax3)\nax3.set_xlabel(\"citric_acid\",size = 15,alpha=0.8)\nax3.set_ylabel(\"Wine Quality\",size = 15,alpha=0.8)\n\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Residual Sugar Levels by Wine Quality Classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,5))\n\nresidual_sugar_low   = df_bins [df_bins['quality_range']== 0]['residual_sugar']\nresidual_sugar_high  = df_bins [df_bins['quality_range']== 1]['residual_sugar'] \nax = sns.kdeplot(data= residual_sugar_low, label= 'low quality', shade=True)\nax = sns.kdeplot(data= residual_sugar_high,   label= 'high quality',   shade=True)\n\nplt.title(\"Distributions of Residual Sugar by Wine Qualities\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sulfur Dioxide Distribution in Wine Quality Classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.scatterplot(x='total_sulfur_dioxide', y='free_sulfur_dioxide', hue='quality_range',data=df_bins);\nplt.xlabel('total_sulfur_dioxide',size=15)\nplt.ylabel('free_sulfur_dioxide', size =15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are some extreme values in low quality wine class. Total sulfur dioxide level is getting higher in some low quality wine class while general disturubution is standing up to 100 level of free sulfur dioxide.   "},{"metadata":{},"cell_type":"markdown","source":"## pH Level in Wine Quality"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,7))\n\npH_low_quality  = df_bins [df_bins['quality_range']== 0]['pH']\npH_high_quality = df_bins [df_bins['quality_range']== 1][ 'pH']\nax = sns.kdeplot(data= pH_low_quality, label= 'low_quality', shade=True) \nax = sns.kdeplot(data= pH_high_quality,label= 'high_quality',   shade=True)\n\nplt.title(\"pH Levels in Low/High Quality Wines\")\nplt.xlabel('pH')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Density by Wine Quality Classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,5))\n\ndensity_low_quality  = df_bins [df_bins['quality_range']== 0]['density']\ndensity_high_quality = df_bins [df_bins['quality_range']== 1][ 'density']\nax = sns.kdeplot(data= density_low_quality, label= 'low_quality', shade=True) \nax = sns.kdeplot(data= density_high_quality,label= 'high_quality', shade=True)\n\nplt.title(\"Density Levels in Low/High Quality of Wines\")\nplt.xlabel('density')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sulphate Values in Wine Quality Classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,5))\n\nsulphates_low_quality    = df_mean [df_bins['quality_range']== 0]['sulphates']\nsulphates_high_quality   = df_mean [df_bins['quality_range']== 1][ 'sulphates']\nax = sns.kdeplot(data= sulphates_low_quality, label= 'low_quality',  shade=True) \nax = sns.kdeplot(data= sulphates_high_quality,label= 'high_quality', shade=True)\n\nplt.title(\"Sulphates Levels in Low/High Quality of Wines\")\nplt.xlabel('sulphates')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is more low quality wine in between 0.4 and 0.6 levels of sulphate levels. Both quality classes have similar values."},{"metadata":{},"cell_type":"markdown","source":"# <div align=\"center\">**8.  Overview about Outliers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"outliers_by_12_variables = ['fixed_acidity', 'volatile_acidity', 'citric_acid',\n                            'residual_sugar', 'chlorides', 'free_sulfur_dioxide',\n                            'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol'] \nplt.figure(figsize=(22,20))\n\nfor i in range(0,11):\n    plt.subplot(5, 4, i+1)\n    plt.boxplot(df_bins[outliers_by_12_variables[i]])\n    plt.title(outliers_by_12_variables[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color=\"darkblue\"> 8.1 Winsorization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def winsor(x, multiplier=3): \n    upper= x.median() + x.std()*multiplier\n    for limit in np.arange(0.001, 0.20, 0.001):\n        if np.max(winsorize(x,(0,limit))) < upper:\n            return limit\n    return None ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats.mstats import winsorize\n\nkolon_isimleri = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide',\n                                  'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n\nfor i in range(1,len(kolon_isimleri)):\n\n    df_bins[kolon_isimleri[i]] = winsorize(df_bins[kolon_isimleri[i]], (0, winsor(df_bins[kolon_isimleri[i]])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div align=\"center\">**9. LOGISTIC REGRESSION CLASSIFIER**"},{"metadata":{},"cell_type":"markdown","source":"## <font color=\"darkblue\"> 9.1 Creating Train / Test Groups with 2 Bins Model "},{"metadata":{},"cell_type":"markdown","source":"In order to have all variables in numeric data, I mapped wine types as following by using the previous data frame 'df_bins':"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bins.type = df_bins.type.map({'white':0, 'red':1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_bins[['type', 'alcohol', 'density', 'volatile_acidity', 'chlorides',\n       'citric_acid', 'fixed_acidity', 'free_sulfur_dioxide',\n       'total_sulfur_dioxide', 'sulphates', 'residual_sugar', 'pH']] \ny = df_bins.quality_range\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=40)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color=\"darkblue\"> 9.1.a  LogisticRegression"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(random_state=40)\nlr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_accuracy = lr.score(X_train, y_train)\ntest_accuracy = lr.score(X_test, y_test)\nprint('One-vs-rest', '-'*35, \n      'Accuracy in Train Group   : {:.2f}'.format(train_accuracy), \n      'Accuracy in Test  Group   : {:.2f}'.format(test_accuracy), sep='\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Confusion Matrix in Chart"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix as cm\n\npredictions = lr.predict(X_test)\nscore = round(accuracy_score(y_test, predictions), 3)\ncm1 = cm(y_test, predictions)\nsns.heatmap(cm1, annot=True, fmt=\".0f\")\nplt.xlabel('Predicted Values')\nplt.ylabel('Actual Values')\nplt.title('Accuracy Score: {0}'.format(score), size = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test  = lr.predict(X_test)\npred_train = lr.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Confusion Matrix in array format"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix \n\n\ncm = confusion_matrix(y_test,pred_test)\ncm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color=\"darkblue\"> 9.1.b   Performance Measurements"},{"metadata":{"trusted":true},"cell_type":"code","source":"quality_pred = LogisticRegression(random_state=40)\nquality_pred.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix_train = confusion_matrix(y_train,pred_train)\nconfusion_matrix_test = confusion_matrix(y_test,pred_test)\n\nprint('Confusion Matrix Train Data', '--'*20, confusion_matrix_train, sep='\\n')\nprint('Confusion Matrix Test Data', '--'*20, confusion_matrix_test, sep='\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TN = confusion_matrix_test[0][0]\nTP = confusion_matrix_test[1][1]\nFP = confusion_matrix_test[0][1]\nFN = confusion_matrix_test[1][0]\n\nprint(\"(Total) True Negative       :\", TN)\nprint(\"(Total) True Positive       :\", TP)\nprint(\"(Total) Negative Positive   :\", FP)\nprint(\"(Total) Negative Negative   :\", FN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FP+FN ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is better to check FP and FN values for another deep study to focus on false predictions for a better target of accurancy and results.  \nA new data set can be created with predictions, X_test and y_test data, than we can check for prediction value of this seperate data set. "},{"metadata":{},"cell_type":"markdown","source":"### <font color='dark pink'> Accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nprint(\"Accuracy Score of Our Model     : \",  quality_pred.score(X_test, y_test))\n#print(\"Accuracy Score of Our Model     : \",  accuracy_score(y_test, pred_test)) # same ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color='dark pink'> Error Rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"Error_Rate = 1- (accuracy_score(y_test, pred_test))  \nError_Rate","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color='dark pink'> Precision: Out of all the predicted positive instances, how many were predicted correctly = TP / (TP + FP) ) \n"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score\n\nprint(\"precision_score()         : \",  precision_score(y_test, pred_test, average='micro'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color='dark pink'> Recall ( Out of all the positive classes, how many instances were identified correctly = TP / (TP + FN)) "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import recall_score\n\nprint(\"recall_score()            : \",  recall_score(y_test, pred_test, average='micro'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color='dark pink'> Specificity :(TN)/(TN + FP)) "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\" Specificity Score   : \",  (TN)/(TN + FP)) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color='dark pink'> F1-Score: From Precision and Recall, F-Measure is computed and used as metrics sometimes. F – Measure is nothing but the harmonic mean of Precision and Recall =(2 * Recall * Precision) / (Recall + Precision) )"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nprecision_s = precision_score(y_test, pred_test,average='micro')\nrecall_s    = recall_score(y_test, pred_test, average='micro')\n\n\nprint(\"F1_score     : \",  2*((precision_s*recall_s)/(precision_s + recall_s)))\n#print(\"F1_score     : \",  f1_score(y_test, pred_test,average='micro')) #By formula","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, precision_recall_fscore_support\n\nprint(classification_report(y_test,pred_test))\n\nprint(\"f1_score        : {:.2f}\".format(f1_score(y_test, pred_test, average='micro')))\nprint(\"recall_score    : {:.2f}\".format(recall_score(y_test, pred_test, average='micro')))\nprint(\"precision_score : {:.2f}\".format(precision_score(y_test, pred_test, average='micro')))\n\nprint('\\n')\nmetrics =  precision_recall_fscore_support(y_test, pred_test)\nprint(\"Precision       :\" , metrics[0]) \n#print(\"Recall          :\" , metrics[1]) \nprint(\"F1 Score        :\" , metrics[2]) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color='dark pink'> ROC/AUC(Area Under Curve)"},{"metadata":{"trusted":true},"cell_type":"code","source":"probs = quality_pred.predict_proba(X_test)[:,1]  #Predict probabilities for the test data\n\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\nfpr, tpr, thresholds  = roc_curve(y_test, probs) #Get the ROC Curve\n\n\nimport matplotlib.pyplot as plt\n\n\nplt.figure(figsize=(8,5))\n# Plot ROC curve\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate = 1 - Specificity Score')\nplt.ylabel('True Positive Rate  = Recall Score')\nplt.title('ROC Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('AUC Değeri : ', roc_auc_score(y_test.values, probs))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color='dark pink'>PRECISION RECALL CURVE \n(The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n\nThe recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\nprecision, recall, _ = precision_recall_curve(y_test, pred_test)\n\nplt.plot(recall, precision)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color='dark pink'> Log Loss (calculating the difference between ground truth and predicted score for every observation and average those errors over all observations. )"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import log_loss\n\nprint(\"Log-Loss)    : \" , log_loss(y_test.values, probs))\nprint(\"Error Rate   : \" , 1- accuracy_score(y_test.values, pred_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## General Looking at Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"C_values = [0.001,0.01,0.1,1,10,100, 1000]\naccuracy_df = pd.DataFrame(columns = ['C_values','Accuracy'])\n\naccuracy_values = pd.DataFrame(columns=['C Value', 'Accuracy Train', 'Accuracy Test'])\n\nfor c in C_values:\n    \n    # Apply logistic regression model to training data\n    lr = LogisticRegression(penalty = 'l2', C = c, random_state = 0)\n    lr.fit(X_train,y_train)\n    accuracy_values = accuracy_values.append({'C Value': c,\n                                                    'Accuracy Train' : lr.score(X_train, y_train),\n                                                    'Accuracy Test': lr.score(X_test, y_test)\n                                                    }, ignore_index=True)\ndisplay(accuracy_values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <font color=\"darkblue\">9.2 Creating 3 Bins Models by a large Margin"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mean.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bins3= df_mean.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bins3.type = df_bins3.type.map({'white':0, 'red':1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = [0,4,7,10]\n\nlabels = [0,1,2] # 'low'=0,'average'=1, 'high'=2\n\ndf_bins3['quality_range']= pd.cut(x=df_bins3['quality'], bins=bins, labels=labels)\n\n#df_bins3.type = df_bins3.type.map({'white':0, 'red':1})\n\nprint(df_bins3[['quality_range','quality']].head(5))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_bins3[['type', 'alcohol', 'density', 'volatile_acidity', 'chlorides',\n       'citric_acid', 'fixed_acidity', 'free_sulfur_dioxide',\n       'total_sulfur_dioxide', 'sulphates', 'residual_sugar', 'pH']]\ny = df_bins3.quality_range\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=40)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color=\"darkblue\">9.2.a  LogisticRegression"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr    = LogisticRegression(random_state=40)\nlr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_accuracy = lr.score(X_train, y_train)\ntest_accuracy = lr.score(X_test, y_test)\nprint('One-vs-rest', '-'*35, \n      'Accuracy Score of Train Model : {:.2f}'.format(train_accuracy), \n      'Accuracy Score of Test  Model : {:.2f}'.format(test_accuracy), sep='\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix as cm\n\npredictions = lr.predict(X_test)\nscore = round(accuracy_score(y_test, predictions), 3)\ncm1 = cm(y_test, predictions)\nsns.heatmap(cm1, annot=True, fmt=\".0f\")\nplt.xlabel('Predicted Values')\nplt.ylabel('Actual Values')\nplt.title('Accuracy Score: {0}'.format(score), size = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = lr.predict(X_test)\ny_pred[y_pred == 2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test,y_pred)\ncm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color=\"darkblue\">9.2.b   Performance Measurements"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"quality_pred = LogisticRegression(random_state=40)\nquality_pred.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_train = lr.predict(X_train)\npred_test  = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix_train = confusion_matrix(y_train,pred_train)\nconfusion_matrix_test = confusion_matrix(y_test,pred_test)\n\nprint('Confusion Matrix Train Data', '--'*20, confusion_matrix_train, sep='\\n')\nprint('Confusion Matrix Test  Data ', '--'*20, confusion_matrix_test, sep='\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TN = confusion_matrix_test[0][0]\n#TP = confusion_matrix_test[1][1]\n#FP = confusion_matrix_test[0][1]\n#FN = confusion_matrix_test[1][0]\n\nprint(\"(Total) True Negative       :\", TN)\nprint(\"(Total) True Positive       :\", TP)\nprint(\"(Total) Negative Positive   :\", FP)\nprint(\"(Total) Negative Negative   :\", FN)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color='dark pink'> Accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nprint(\"Accuracy Score of Test Model : \",  quality_pred.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color='dark pink'> Error Rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"Error_Rate = 1 - (accuracy_score(y_test, pred_test))\nError_Rate","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color='dark pink'> Hassasiyet (Precision)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score\n\nprint(\"precision_score        : \",  precision_score(y_test, pred_test, average='micro'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color='dark pink'>  Duyarlılık (Recall/Sensitivity)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import recall_score\n\nprint(\"recall_score        : \",  recall_score(y_test, pred_test, average='micro'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color='dark pink'>  F1 (F1 Score)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nprecision_s = precision_score(y_test, pred_test,average='micro')\nrecall_s    = recall_score(y_test, pred_test, average='micro')\n\n\nprint(\"F1_score     : \",  2*((precision_s*recall_s)/(precision_s + recall_s)))# by mathematical formula\nprint(\"f1_score()   : \",  f1_score(y_test, pred_test,average='micro'))  #By formula","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, precision_recall_fscore_support\n\nprint(classification_report(y_test,pred_test) )\n\nprint(\"f1_score()         : {:.2f}\".format(f1_score(y_test, pred_test, average='micro')))\nprint(\"recall_score()     : {:.2f}\".format(recall_score(y_test, pred_test, average='micro')))\nprint(\"precision_score()  : {:.2f}\".format(precision_score(y_test, pred_test, average='micro')))\n\nprint('\\n')\nmetrikler =  precision_recall_fscore_support(y_test, pred_test)\nprint(\"Precision   :\" , metrics[0]) \nprint(\"Recall      :\" , metrics[1]) \nprint(\"F1 Score    :\" , metrics[2]) \n\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    y_pred = lb.transform(y_pred)\n    return roc_auc_score(y_test, y_pred, average=average)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('AUC Değeri : ', multiclass_roc_auc_score(y_test.values, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color='dark pink'> ROC/AUC(Area Under Curve)"},{"metadata":{"trusted":true},"cell_type":"code","source":"probs = quality_pred.predict_proba(X_test)[:,1]\n\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\nfpr, tpr, thresholds  = roc_curve(y_test, probs, pos_label=1)\n\n\n# Plot ROC curve\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color='dark pink'> PRECISION RECALL CURVE"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\nprecision, recall, _ = precision_recall_curve(y_test, probs, pos_label=1)\n\nplt.plot(precision, recall)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### General Looking at Results "},{"metadata":{"trusted":true},"cell_type":"code","source":"C_values = [0.001,0.01,0.1,1,10,100, 1000]\naccuracy_df = pd.DataFrame(columns = ['C_values','Accuracy'])\n\naccuracy_values = pd.DataFrame(columns=['C Value', 'Accuracy Train', 'Accuracy Test'])\n\nfor c in C_values: \n    \n    # Apply logistic regression model to training data\n    lr = LogisticRegression(penalty = 'l2', C = c, random_state = 0)\n    lr.fit(X_train,y_train)\n    accuracy_values = accuracy_values.append({'C Value': c,\n                                                    'Accuracy Train' : lr.score(X_train, y_train),\n                                                    'Accuracy Test': lr.score(X_test, y_test)\n                                                    }, ignore_index=True)\ndisplay(accuracy_values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div align=\"center\">  **10. Imbalanced Data**"},{"metadata":{},"cell_type":"markdown","source":"In order to see the differency between logistic regression model, I also would like to check resampling imblance data. In previous steps, I added bins in low and high ranges on quality variable, this section will show the results by using resampling method.  "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_mean_imb = df_mean.copy() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = [0,4,10] \n\n\nlabels = [0, 1] # 'low'=0, 'high'=1 \ndf_mean_imb['quality_range']= pd.cut(x=df_mean_imb['quality'], bins=bins, labels=labels) \n\nprint(df_mean_imb[['quality_range','quality']].head(5)) \n\ndf_mean_imb = df_mean_imb.drop('quality', axis=1) #","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df_mean_imb.quality_range)\n #'low'=0, 'high'=1\n    \nprint(\"Low Quality  0   : %{:.2f}\".format(sum(df_mean_imb.quality_range)/len(df_mean_imb.quality_range)*100))\nprint(\"High Quality 1   : %{:.2f}\".format((len(df_mean_imb.quality_range)-sum(df_mean_imb.quality_range))/len(df_mean_imb.quality_range)*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When splitting data in two parts starting from four, it gives an imbalanced data. "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"balance = (df_mean_imb.quality_range.value_counts()[1]/df_mean_imb.quality_range.shape[0])*100\nprint('Data Quality Percentage:\\n', balance,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color=\"darkblue\">10.1 Resampling Imbalance Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import resample \nfrom imblearn.over_sampling import SMOTE \nsmote = SMOTE() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_mean_imb.type = df_mean_imb.type.map({'white':0, 'red':1}) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X =  df_mean_imb.drop(['quality_range'], axis=1) \ny =  df_mean_imb.quality_range \n\nX_sm, y_sm =smote.fit_resample(X,y) \n\nprint(X.shape, y.shape) \nprint(X_sm.shape, y_sm.shape) \nsns.countplot(y_sm) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(X, y): \n    X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.20, random_state=40, stratify = y) \n    logreg_model = LogisticRegression() \n    logreg_model.fit(X_train, y_train) \n\n    pred_train = logreg_model.predict(X_train) \n    pred_test = logreg_model.predict(X_test) \n    confusion_matrix_train = confusion_matrix(y_train, pred_train) \n    confusion_matrix_test = confusion_matrix(y_test, pred_test) \n    print(\"Accuracy of Test Model : \",  logreg_model.score(X_test, y_test)) \n    print(\"Train Data Set\") \n    print(classification_report(y_train,pred_train) ) \n    print(\"Test Data Set \") \n    print(classification_report(y_test,pred_test) ) \n    return  None ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_model(X_sm,y_sm) \nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color=\"darkblue\">10.2 Cross Validation with 2  Bins Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bins.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_bins.drop(['quality_range'], axis=1)\ny = df_bins.quality_range\ny = np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('fivethirtyeight')\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)\nprint(\"Number of Rows in    Training dataset :  {} \".format(len(X_train)))\nprint(\"Number of Targets in Training dataset :  {} \".format(len(y_train)))\nprint(\"Number of Rows in    Test dataset :  {} \".format(len(X_test)))\nprint(\"Number of Targets in Test dataset :  {} \".format(len(y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y_test)\nplt.ylim((0,1000))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,9))\ny_list = [y, y_train, y_test]\ntitles = ['All Data','Train Data', 'Test Data']\n\nfor i in range(1,4):\n    plt.subplot(1,3,i)\n    sns.countplot(y_list[i-1])\n    plt.title(titles[i-1])\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Tüm veri kümesi '0' yüzdesi : %{:.0f} \".format(len(y[y==0])/len(y)*100))\nprint(\"Test verisi '0' yüzdesi     : %{:.0f} \".format(len(y_test[y_test==0])/len(y_test)*100))\nprint(\"Eğitim verisi '0' yüzdesi   : %{:.0f} \".format(len(y_train[y_train==0])/len(y_train)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\ntahmin_eğitim = model.predict(X_train)\ntahmin_test = model.predict(X_test)\nmodel.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We splitted y values equally and trained our model.However, in order to see X values distribution we need following Cross Validation Measurement."},{"metadata":{},"cell_type":"markdown","source":"##  <font color=\"darkblue\">10.3 K-Fold Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold \nkf = KFold(n_splits=5, shuffle=True, random_state=40) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.loc[[3,5]] \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parcalar = kf.split(X)\nfor num, (train_index, test_index) in enumerate(parcalar): \n    print(\"{}.Training Set Size : {}\".format(num+1,len(train_index)))  \n    print(\"{}.Test Set Size     : {}\".format(num+1,len(test_index))) \n    print('-'*26)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error \n\nmodel2 = LogisticRegression()\npieces = kf.split(X)\naccuracy_list = []\n\nfor i, (egitim_indeks, test_indeks) in enumerate(pieces):\n    \n    X_train, y_train = X.loc[train_index], y[train_index]\n    X_test, y_test = X.loc[test_indeks], y[test_indeks]\n    \n    model2.fit(X_train, y_train)\n    tahmin = model2.predict(X_test)\n    accuracy_value = model2.score(X_test, y_test)  \n    \n    accuracy_list.append(accuracy_value)\n    \n    print(\"{}.Accuracy Value of Pieces: {:.3f}\".format(i+1, accuracy_value))\n    print(\"-\"*30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Avarage Accuracy Value : {:.2f}\".format(np.mean(accuracy_list)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We splited our function in 5 pieces and trained them with Kfold method. In the following section, Cross Validate and Cross Validation Score tools will do everything itself.  "},{"metadata":{},"cell_type":"markdown","source":"##  <font color=\"darkblue\">10.4   Cross Validation Score & Cross Validate"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_validate, cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lrm = LogisticRegression()\ncv = cross_validate(estimator=lrm,\n                     X=X,\n                     y=y,\n                     cv=10,return_train_score=True\n                    )\nprint('Test Scores            : ', cv['test_score'], sep = '\\n')\nprint(\"-\"*50)\nprint('Train Scores           : ', cv['train_score'], sep = '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean of Test Set  : ', cv['test_score'].mean())\nprint('Mean of Train Set : ', cv['train_score'].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The average accuracy score is calculated from 10 different accuracy scores from the model.\n\nWe still have similiar accuracy scores (.96-.97) by different methods applied previously. "},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = cross_validate(estimator=lrm, \n                     X=X,\n                     y=y,\n                     cv=10,return_train_score=True,\n                     scoring = ['accuracy', 'r2', 'precision']\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Test Set Accuracy   Mean      : {:.2f}'.format(cv['test_accuracy'].mean()))\nprint('Test Set R Square   Mean      : {:.2f}'.format(cv['test_r2'].mean()))\nprint('Test Set Precision  Mean      : {:.2f}'.format(cv['test_precision'].mean()))\nprint('Train Set Accuracy  Mean      : {:.2f}'.format(cv['train_accuracy'].mean()))\nprint('Train Set R Square  Mean      : {:.2f}'.format(cv['train_r2'].mean()))\nprint('Train Set Precision Mean      : {:.2f}'.format(cv['train_precision'].mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = cross_val_score(estimator=lrm,\n                     X=X,\n                     y=y,\n                     cv=10                    \n                    )\nprint('Model Scores           : ', cv, sep = '\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"cross_val_score and cross_validate functions used only test set. In order to have model predictions we can also check cross_val_predict  function."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_predict ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = cross_val_predict(estimator=lrm, X=X, y=y, cv=10)\nprint(y_pred[0:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div align=\"center\">  **11. Hyperparameter Tuning**"},{"metadata":{},"cell_type":"markdown","source":"Apart from using appropriate function for our model, using the suitable parameter is also an important detail to have accurate predictions. I will use Grid Search and Random Search for this aim. "},{"metadata":{},"cell_type":"markdown","source":"In order to have suitable parametres I used get_params() function. "},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"logreg = LogisticRegression()\nprint(logreg.get_params())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  <font color=\"darkblue\">11.1 Grid Search"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\"C\": [10 ** x for x in range (-5, 5, 1)],\n                \"penalty\": ['l1', 'l2']\n                }","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n\ngrid_cv = GridSearchCV(estimator=logreg,\n                       param_grid = parameters,\n                       cv = 10\n                      )\ngrid_cv.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The Best Parametre : \", grid_cv.best_params_)\nprint(\"The Best Score     : \", grid_cv.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = grid_cv.cv_results_\ndf = pd.DataFrame(results)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[['param_penalty','param_C', 'mean_test_score']]\ndf = df.sort_values(by='mean_test_score', ascending = False)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The most successful 10 parametres on a chart.\nplt.style.use('fivethirtyeight')\n\nplt.figure(figsize=(12,12))\n\nsns.scatterplot(x = 'param_C', y = 'mean_test_score', hue = 'param_penalty', data = df[0:10], s=150)\n\nplt.xscale('symlog')\n#plt.ylim((0.9,1))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  <font color=\"darkblue\">11.2 RandomizedSearchCV"},{"metadata":{},"cell_type":"markdown","source":"While we checked all combinations of our parameters with Grid Search method, we can also use this function with desired number of conbinations of parameters. "},{"metadata":{"trusted":true},"cell_type":"code","source":"parametres = {\"C\": [10 ** x for x in range (-5, 5, 1)],\n                \"penalty\": ['l1', 'l2']\n                }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will make 10 combination with 'n_iter' parameter."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nrs_cv = RandomizedSearchCV(estimator=logreg,\n                           param_distributions = parametres,\n                           cv = 10,\n                           n_iter = 10,\n                           random_state = 111,\n                           scoring = 'precision'\n                      )\nrs_cv.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The Best Parametres        : \", rs_cv.best_params_)\nprint(\"All Precisions Values      : \", rs_cv.cv_results_['mean_test_score'])\nprint(\"The Best Precision Value   : \", rs_cv.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_rs = rs_cv.cv_results_\ndf_rs = pd.DataFrame(results_rs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_rs = rs_cv.cv_results_\ndf_rs = pd.DataFrame(results_rs)\ndf_rs = df_rs[['param_penalty','param_C', 'mean_test_score']]\ndf_rs = df_rs.sort_values(by='mean_test_score', ascending = False)\ndf_rs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(12,12))\nsns.scatterplot(x = 'param_C', y = 'mean_test_score', hue = 'param_penalty', data = df_rs, s=200)\nplt.xscale('symlog')\nplt.ylim((0.0,1))\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nIn the beginning of this study, I checked general characteristic of the data set. Data has some NULL values. Even though, dropping missing values is still an option due to low percentage of missing values in data, I preferred to filled them by the mean of data. \n\nData set shows that red wine is very reach in wine quality with a high correlation with alcohol. \n\nI also looked at quality levels in each variable by using suitable charts for a general understanding.  \n\nFollowing sections, I searched for 2 different types of models with different bins. Behind this study I created many models for a better accuracy and recall scores. This study only shows the best model with good scores and predictions.\n\nThe first model was included 2 bins with all variables in a quality range of 0-5,5-10. This model gives %0.74 accuracy score on train and test samples. \n\ndf_bins3 data frame was split in 3 different bins to check accuracy levels. First bin was between 0-5,5-6,6-10 range. This model gives score of %0.58.  \n\nOn the other hand, when bins are arranged by following 0-4,4-7,7-10; score reached 0.93%. I continued with this model for the further steps on other performance measurements. \n\nA general note: These results for imbalance data, thus I would like to see scores after balancing data set. Due to this reason, and to check the difference between logistic regression model, I resampled imbalance data. In previous steps, I added bins in low and high ranges on quality variable, this section will show the results by using resampling method.\nHowever, having very high scores and a negative R square show that data set needs another approach at the end. For further studies, more suitable data set can be chosen. \n\nA Quick Note for Resampling Data: Splitting data in 2 parts from 0 to 5 gives a balance distribution. However, when we split data  from 0 to 4 in the first bin, I got an imbalance data. \nAfter resampling our data, I needed to switch y values in array format to have Cross Validation scores. \n\nGenerally, our measurements and model scores worked well to show the aim of the study. This study can be completed in a shorter way as well without repeating similar functions; however, this study also aims to use different methods to have accurate scores from variable sources. \n\nI focused on classification methods on this study. However, I agree that other algorithms can be more successful such as Random forest and Boosting algorithms give better results. I will use these methods in my next kernel.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}