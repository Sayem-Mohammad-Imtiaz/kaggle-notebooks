{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport sys\nsys.path.append(\"../input/timm-pytorch-image-models/pytorch-image-models-master/\")\nimport timm\nimport cv2\nimport torchvision\nimport torchvision.transforms as transforms\n\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)\nbest_acc = 0  # best test accuracy\nstart_epoch = 0  # start from epoch 0 or last checkpoint epoch\nend_epoch = 100\nbz = 128\nlr = 0.0001\nprint(\"Init done!\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-22T11:31:11.27224Z","iopub.execute_input":"2021-05-22T11:31:11.272561Z","iopub.status.idle":"2021-05-22T11:31:14.190131Z","shell.execute_reply.started":"2021-05-22T11:31:11.272488Z","shell.execute_reply":"2021-05-22T11:31:14.188836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport time\nimport math\n\nimport torch.nn as nn\nimport torch.nn.init as init\n\n\ndef get_mean_and_std(dataset):\n    '''Compute the mean and std value of dataset.'''\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n    mean = torch.zeros(3)\n    std = torch.zeros(3)\n    print('==> Computing mean and std..')\n    for inputs, targets in dataloader:\n        for i in range(3):\n            mean[i] += inputs[:,i,:,:].mean()\n            std[i] += inputs[:,i,:,:].std()\n    mean.div_(len(dataset))\n    std.div_(len(dataset))\n    return mean, std\n\ndef init_params(net):\n    '''Init layer parameters.'''\n    for m in net.modules():\n        if isinstance(m, nn.Conv2d):\n            init.kaiming_normal(m.weight, mode='fan_out')\n            if m.bias:\n                init.constant(m.bias, 0)\n        elif isinstance(m, nn.BatchNorm2d):\n            init.constant(m.weight, 1)\n            init.constant(m.bias, 0)\n        elif isinstance(m, nn.Linear):\n            init.normal(m.weight, std=1e-3)\n            if m.bias:\n                init.constant(m.bias, 0)\n\n\n# _, term_width = os.popen('stty size', 'r').read().split()\nterm_width = 80 \n\nTOTAL_BAR_LENGTH = 65.\nlast_time = time.time()\nbegin_time = last_time\ndef progress_bar(current, total, msg=None):\n    global last_time, begin_time\n    if current == 0:\n        begin_time = time.time()  # Reset for new bar.\n\n    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n\n    sys.stdout.write(' [')\n    for i in range(cur_len):\n        sys.stdout.write('=')\n    sys.stdout.write('>')\n    for i in range(rest_len):\n        sys.stdout.write('.')\n    sys.stdout.write(']')\n\n    cur_time = time.time()\n    step_time = cur_time - last_time\n    last_time = cur_time\n    tot_time = cur_time - begin_time\n\n    L = []\n    L.append('  Step: %s' % format_time(step_time))\n    L.append(' | Tot: %s' % format_time(tot_time))\n    if msg:\n        L.append(' | ' + msg)\n\n    msg = ''.join(L)\n    sys.stdout.write(msg)\n    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n        sys.stdout.write(' ')\n\n    # Go back to the center of the bar.\n    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n        sys.stdout.write('\\b')\n    sys.stdout.write(' %d/%d ' % (current+1, total))\n\n    if current < total-1:\n        sys.stdout.write('\\r')\n    else:\n        sys.stdout.write('\\n')\n    sys.stdout.flush()\n\ndef format_time(seconds):\n    days = int(seconds / 3600/24)\n    seconds = seconds - days*3600*24\n    hours = int(seconds / 3600)\n    seconds = seconds - hours*3600\n    minutes = int(seconds / 60)\n    seconds = seconds - minutes*60\n    secondsf = int(seconds)\n    seconds = seconds - secondsf\n    millis = int(seconds*1000)\n\n    f = ''\n    i = 1\n    if days > 0:\n        f += str(days) + 'D'\n        i += 1\n    if hours > 0 and i <= 2:\n        f += str(hours) + 'h'\n        i += 1\n    if minutes > 0 and i <= 2:\n        f += str(minutes) + 'm'\n        i += 1\n    if secondsf > 0 and i <= 2:\n        f += str(secondsf) + 's'\n        i += 1\n    if millis > 0 and i <= 2:\n        f += str(millis) + 'ms'\n        i += 1\n    if f == '':\n        f = '0ms'\n    return f\nprint(\"Utils done!\")","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:31:14.191792Z","iopub.execute_input":"2021-05-22T11:31:14.192135Z","iopub.status.idle":"2021-05-22T11:31:14.214536Z","shell.execute_reply.started":"2021-05-22T11:31:14.1921Z","shell.execute_reply":"2021-05-22T11:31:14.213596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data ","metadata":{}},{"cell_type":"code","source":"transform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntrainset = torchvision.datasets.CIFAR10(\n    root='./data', train=True, download=True, transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(\n    trainset, batch_size= bz, shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(\n    root='./data', train=False, download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(\n    testset, batch_size= bz, shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer',\n           'dog', 'frog', 'horse', 'ship', 'truck')\nNUM_CLASSES = 10\nprint(\"Data done!\")","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:31:14.216731Z","iopub.execute_input":"2021-05-22T11:31:14.217447Z","iopub.status.idle":"2021-05-22T11:31:17.182194Z","shell.execute_reply.started":"2021-05-22T11:31:14.217407Z","shell.execute_reply":"2021-05-22T11:31:17.178694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"print('==> Building model..')\nimport torch.backends.cudnn as cudnn\nnet = timm.create_model(\"tf_efficientnet_b8\", pretrained = True, num_classes = NUM_CLASSES)\nprint(net)\n\nnet = net.to(device)\nif device == 'cuda':\n    net = torch.nn.DataParallel(net)\n    cudnn.benchmark = True\n\nprint('==> Building model Done')\n","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:31:17.184954Z","iopub.status.idle":"2021-05-22T11:31:17.187102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr= lr,\n                      momentum=0.99, weight_decay=5e-4)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max= end_epoch)\nprint(\"Model done!\")","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:31:17.1905Z","iopub.status.idle":"2021-05-22T11:31:17.192631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train and test","metadata":{}},{"cell_type":"code","source":"def train(epoch):\n    print('\\nEpoch: %d' % epoch)\n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n    for batch_idx, (inputs, targets) in enumerate(trainloader):\n        inputs, targets = inputs.to(device), targets.to(device)\n        optimizer.zero_grad()\n        outputs = net(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\n\ndef test(epoch):\n    global best_acc\n    net.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for batch_idx, (inputs, targets) in enumerate(testloader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = net(inputs)\n            loss = criterion(outputs, targets)\n\n            test_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n   \n                \n            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n    # Save checkpoint.\n    acc = 100.*correct/total\n    if acc > best_acc:\n        print('Saving..')\n        state = {\n            'net': net.state_dict(),\n            'acc': acc,\n            'epoch': epoch,\n        }\n#         if not os.path.isdir('checkpoint'):\n#             os.mkdir('checkpoint')\n        torch.save(state,'./ckpt-best.pth')\n        best_acc = acc\n    return 'Epoch%d, Test Loss: %.3f | Acc: %.3f\\n'% (epoch, test_loss,100.*correct/total)\n\nprint(\"Train and test done!\")","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:31:17.195989Z","iopub.status.idle":"2021-05-22T11:31:17.198104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Main","metadata":{}},{"cell_type":"code","source":"print(\"START MAIN!\")\nwith open(\"./test_efficientnet_b8_lr1e-4_SGD_cifer10_info.txt\",\"w\") as f:\n    for epoch in range(start_epoch, end_epoch):\n\n        train(epoch)\n        info = test(epoch)\n        f.write(info)\n        scheduler.step()\n    f.close()","metadata":{"execution":{"iopub.status.busy":"2021-05-22T11:31:17.201276Z","iopub.status.idle":"2021-05-22T11:31:17.202017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}