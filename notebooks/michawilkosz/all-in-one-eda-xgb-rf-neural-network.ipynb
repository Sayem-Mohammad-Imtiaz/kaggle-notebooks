{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport warnings\n\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nsns.set_style(\"whitegrid\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <p style=\"text-align:center;\">What causes heart problemsðŸ’”? </p>\n#  <p style=\"text-align:center;\"> Analysis and comprehensive classification </p>"},{"metadata":{},"cell_type":"markdown","source":"<center><img src=\"https://img.webmd.com/dtmcms/live/webmd/consumer_assets/site_images/article_thumbnails/slideshows/did_you_know_this_could_lead_to_heart_disease_slideshow/650x350_did_you_know_this_could_lead_to_heart_disease_slideshow.jpg\"></center>"},{"metadata":{},"cell_type":"markdown","source":"One of the key applications of machine learning methods is certainly health problems. The heaviest element in the application of black box models by scientists is to explain what affected the result. Since human life is the most important thing in medicine, data scientists must face up to the challenge and be able to answer the fundamental question - **why**?\n\nThe presented data includes numerous qualitative and quantitative features that will allow us to build the machine learning model. However as I mentioned, we work with human data, so the key element in building the model is to understand what really causes heart diseases. Starting with an extensive exploratory data analysing, I will try to answer some heart disease questions. Then the data will be cleaned and inserted into machine learning models .\n\n### Thus, this kernel is more focused for learning purposes and exploration. Please feel free to give advice, recommendations/ better approaches or whatsover on the code below."},{"metadata":{},"cell_type":"markdown","source":"## If you find this kernel helpful, any **<font color='orange'>UPVOTES</font>** would be very much appreciated."},{"metadata":{},"cell_type":"markdown","source":"# Data overview"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Info"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.float','{:.2f}'.format)\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Columns description:\n\n* age - age in years \n* sex - (1 = male; 0 = female) \n* cp - chest pain type \n* trestbps - resting blood pressure (in mm Hg on admission to the hospital) \n* chol - serum cholestoral in mg/dl \n* fbs - (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false) \n* restecg - resting electrocardiographic results \n* thalach - maximum heart rate achieved \n* exang - exercise induced angina (1 = yes; 0 = no) \n* oldpeak - ST depression induced by exercise relative to rest \n* slope - the slope of the peak exercise ST segment \n* ca - number of major vessels (0-3) colored by flourosopy \n* thal - 3 = normal; 6 = fixed defect; 7 = reversable defect \n* target - have disease or not (1=yes, 0=no)"},{"metadata":{},"cell_type":"markdown","source":"## Target\n\n* 1 - (YES) have heart disease\n* 0 - (NO) have not heart disease"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disease = len(data[data['target'] == 1])\nno_disease = len(data[data['target']== 0])\n\nplt.figure(figsize=(12,6))\n\nlabels = 'Have heart disease','Have not heart disease'\nsizes = [disease,no_disease]\nexplode = (0.1, 0) \nplt.pie(sizes, explode=explode, labels=labels, colors=['orangered','skyblue'],\nautopct='%1.2f%%', shadow=True, startangle=90, textprops={'fontsize': 12})\nplt.axis('equal')\nplt.title('Percentage of target', size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great! Dataset is free from NaN values. "},{"metadata":{},"cell_type":"markdown","source":"# 1.Exploratory Data Analysis (EDA)"},{"metadata":{},"cell_type":"markdown","source":"## Categorical values\nApart from target, some of features contianed in the dataset are categorical. Let's discover them."},{"metadata":{"trusted":true},"cell_type":"code","source":"qualitative = []\nquantitative = []\nfor feature in data.columns:\n    if len(data[feature].unique()) <= 8:\n        qualitative.append(feature)\n    else:\n        quantitative.append(feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qualitative","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qualitative","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Corellation Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"top = 15\ncorr = data.corr()\ntop15 = corr.nlargest(top, 'target')['target'].index\ncorr_top15 = data[top15].corr()\nf,ax = plt.subplots(figsize=(10,10))\nsns.heatmap(corr_top15, square=True, ax=ax, annot=True, cmap='coolwarm', fmt='.2f', annot_kws={'size':12})\nplt.title('Top correlated features of dataset', size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Age visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(16,4))\n\nax1 = fig.add_subplot(121)\nsns.boxplot(y = data['age'], ax=ax1, color='orangered')\ndescribe = data['age'].describe().to_frame().round(2)\n\nax2 = fig.add_subplot(122)\nax2.axis('off')\nfont_size = 16\nbbox = [0, 0, 1, 1]\ntable = ax2.table(cellText = describe.values, rowLabels = describe.index, bbox=bbox, colLabels=describe.columns)\ntable.set_fontsize(font_size)\nfig.suptitle('Distribution of age', fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion\n* Based on boxplot we can see that data most often include people of age between 47-61 becouse, these ages lying between I and III percentile (IQR)."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.countplot(data['age'], hue=data['sex'], palette=['skyblue','orangered'], saturation=0.8)\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.title('Gender count', fontsize=16)\nplt.legend(loc='upper right', fontsize=16, labels=['Female', 'Male'])\nplt.text(30, 11,'Total male: {:.2f}%'. \n         format(((data['sex'].value_counts()[1])/(len(data)))*100), fontsize=16)\nplt.text(30, 10.5,'Total female: {:.2f}%'. \n         format(((data['sex'].value_counts()[0])/(len(data)))*100), fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion\n* The data examined included mainly men, at the age mentioned. "},{"metadata":{},"cell_type":"markdown","source":"## Target gender count"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,4))\nlabels = ['female','male']\nsns.countplot(data['sex'], hue=data['target'], palette=['skyblue','orangered'], saturation=0.8)\nplt.xlabel('Sex')\nplt.ylabel('Count')\nplt.title('Target count in genders', fontsize=16)\nplt.legend(loc='upper right', fontsize=16, labels=['No disease', 'Disease'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion\n* In the data under study, men more often had heart problems."},{"metadata":{},"cell_type":"markdown","source":"## Sex, age vs target"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\npalette=['skyblue','orangered']\ns1=sns.boxenplot(x=data.sex, y=data.age, hue=data.target, palette=palette, linewidth=3)\nhandles = s1.get_legend_handles_labels()[0]\ns1.legend(handles, ['No disease', 'Disease'])\ns1.set_title(\"Sex, age, target boxenplot\",fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Conclusion\n* On average, men start having heart problems at an earlier age than women."},{"metadata":{},"cell_type":"markdown","source":"## Key categorical features vs heart disease\nBased on corrplot I took three most corellating qualitative features with target."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(figsize=(24,6))\npalette = ['skyblue','orangered']\n\nplt.subplot(131)\nx1=sns.countplot(x=data.cp,hue=data.target,palette=palette,linewidth=3)\nx1.set_title('Chest pain type vs heart disease',size=16)\nx1.legend(loc='upper right', fontsize=12, labels=['No disease', 'Disease'])\n\nplt.subplot(132)\nx2=sns.countplot(x=data.thal,hue=data.target,palette=palette,linewidth=3)\nx2.set_title('Thalassaemia vs heart disease',size=16)\nx2.legend(loc='upper left', fontsize=12, labels=['No disease', 'Disease'])\n\nplt.subplot(133)\nx3=sns.countplot(x=data.slope,hue=data.target,palette=palette,linewidth=3)\nx3.set_title('Slope of the peak exercise ST segment vs heart disease',size=16)\nx3.legend(loc='upper left', fontsize=12, labels=['No disease', 'Disease'])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusions\n* Second type of chest pain most often accompanies heart problems.\n* Second thalassaemia type(fixed defect) most often accompanies heart problems.\n* Second slope  most often accompanies heart problems."},{"metadata":{},"cell_type":"markdown","source":"## Key quantitative features vs heart disease\nBased on corrplot I took three most corellating quantitative features with target."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(figsize=(24,6))\npalette = ['darkblue','darkred']\n\nplt.subplot(1, 3, 1)\ndata['bin_thalach']=pd.cut(data.thalach, bins=[80,100,125,150,175,200])\np1=sns.countplot(x=data.bin_thalach,hue=data.target,palette=palette,linewidth=3)\np1.set_title(\"Thalach vs heart disease\",size=16)\np1.legend(loc='upper left', fontsize=12, labels=['No disease', 'Disease'])\n\n\n\nplt.subplot(1, 3, 2)\ndata['bin_chol']=pd.cut(data.chol, bins=[100,150,200,250,300,350,400])\np2=sns.countplot(x=data.bin_chol,hue=data.target,palette=palette,linewidth=3)\np2.set_title(\"Cholesterol vs heart disease\",size=16)\np2.legend(loc='upper left', fontsize=12, labels=['No disease', 'Disease'])\n\n\n\nplt.subplot(1, 3, 3)\ndata['bin_trestbps']=pd.cut(data.trestbps, bins=[80,100,120,140,160,180,200])\np3=sns.countplot(x=data.bin_trestbps,hue=data.target,palette=palette,linewidth=3)\np3.set_title(\"Trestbps vs heart disease\",size=16)\np3.legend(loc='upper left', fontsize=12, labels=['No disease', 'Disease'])\n\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusions\n* The most frequent heart rate(thalach) suggesting heart disease is 175.\n* Cholesterol levels suggestive of heart disease are most likely to be 250.\n* The most frequent resting blood pressure, which is associated with heart disease, is 140."},{"metadata":{},"cell_type":"markdown","source":"## Oldpeak and Slope\nAccording to the high correlation score between oldpeak and slope, it is worth taking a closer look at this dependence."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(figsize=(24,6))\n\nplt.subplot(121)\nold_bins = [0,1,2,3,4,5,6]\ndata['oldpeak_bin']=pd.cut(data.oldpeak, bins=old_bins)\no1=sns.countplot(x=data.oldpeak_bin,hue='target',data=data, palette='bright')\no1.legend(loc='upper right', fontsize=12, labels=['No disease', 'Disease'])\n\n\nplt.subplot(122)\no2 = sns.pointplot(x='slope',y='oldpeak',data=data,hue='target',palette='bright')\nhandles = o2.get_legend_handles_labels()[0]\no2.legend(handles, ['No disease', 'Disease'])\n\nplt.suptitle('Oldpeak, slope vs target', size = 22)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusions\n* With the value of oldpeak increases the rate of heart disease decreases\n* With increases of value of slope, heart disease people have lower oldpeak"},{"metadata":{},"cell_type":"markdown","source":"## Age and thalach"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(24,6))\nz1=sns.pointplot(x=data.age, y=data.thalach, hue=data.target, palette='bright', linewidth=3)\nplt.title('Age, thalach vs target',size=22)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusions\n* As the age increases, the thalach slightly decreases\n* In almost every age, for disease samples thalach feature has a higher value."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping columns used only to plots.\ndata.drop(['bin_chol','bin_thalach','bin_trestbps','oldpeak_bin'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2.Outliers\nTo detect outliers I will use the IQR method on quantitative features."},{"metadata":{"trusted":true},"cell_type":"code","source":"data[quantitative].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def iqr(df, column):\n  Q1 = np.percentile(df[column], 25)\n  Q3 = np.percentile(df[column], 75)\n  IQR = Q3 - Q1\n  outlier_step = 1.5 * IQR\n  outliers_index = df[(df[column] < Q1 - outlier_step) | (df[column] > Q3 + outlier_step)].index\n  return outliers_index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outliers in trestbps"},{"metadata":{"trusted":true},"cell_type":"code","source":"outliers_index = iqr(data,'trestbps')\ndata.drop(outliers_index, inplace=True)\ndata.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outliers in cholesterol"},{"metadata":{"trusted":true},"cell_type":"code","source":"outliers_index = iqr(data,'chol')\ndata.drop(outliers_index, inplace=True)\ndata.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outliers in thalach"},{"metadata":{"trusted":true},"cell_type":"code","source":"outliers_index = iqr(data,'thalach')\ndata.drop(outliers_index, inplace=True)\ndata.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outliers in oldpeak"},{"metadata":{"trusted":true},"cell_type":"code","source":"outliers_index = iqr(data,'oldpeak')\ndata.drop(outliers_index, inplace=True)\ndata.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3.Data preparation"},{"metadata":{},"cell_type":"markdown","source":"### Split data into features and target"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data['target']\nX = data.drop('target',axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encode categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"qualitative.remove('target')\nX = pd.get_dummies(X, columns = qualitative)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Features scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"X[quantitative] = StandardScaler().fit_transform(X[quantitative])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4.Models"},{"metadata":{},"cell_type":"markdown","source":"# K-Nearest Neighbor Algorithm\nimplemented with GridSearchCV for hyperparameter tunning."},{"metadata":{},"cell_type":"markdown","source":"### Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nknn = KNeighborsClassifier()\n\nparams = {'n_neighbors':list(range(1,20)),\n    'p':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n    'leaf_size':list(range(1,20)),\n    'weights':['uniform', 'distance']}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_param = GridSearchCV(knn, params, cv=5, n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_param.fit(X_train, y_train)\n#Best params selected by GridSearchCV\nknn_param.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = knn_param.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_acc_train = knn_param.score(X_train, y_train)*100\nknn_acc_test = knn_param.score(X_test, y_test)*100\n\nprint(\"Train Accuracy {:.2f}%\".format(knn_acc_train))\nprint(\"Test Accuracy {:.2f}%\".format(knn_acc_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Report"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix = confusion_matrix(y_test,predict)\nclass_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\nsns.heatmap(pd.DataFrame(confusion_matrix), annot = True, cmap = 'Blues',\n           fmt = 'g')\n\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for K-NN')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC Curve for K-Nearest Neighbor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score,roc_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_probabilities = knn_param.predict_proba(X_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"false_positive_rate_knn,true_positive_rate_knn,threshold_knn = roc_curve(y_test,y_probabilities)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting ROC Curve\nplt.figure(figsize=(10,6))\nplt.title('ROC for K-NN')\nplt.plot(false_positive_rate_knn, true_positive_rate_knn, linewidth=5, color='red')\nplt.plot([0,1],ls='--',linewidth=5)\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.text(0.2,0.6,'AUC: {:.2f}'.format(roc_auc_score(y_test,y_probabilities)),size= 16)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression\nimplemented with GridSearchCV for hyperparameter tunning."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlog = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'penalty':['l1','l2'],\n         'C':[0.01,0.1,1,10,100],\n         'class_weight':['balanced',None]}\n\nlog_param = GridSearchCV(log,param_grid=params,cv=10, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_param.fit(X_train,y_train)\n#Best params selected by GridSearchCV\nlog_param.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = log_param.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_acc_train = log_param.score(X_train, y_train)*100\nlog_acc_test = log_param.score(X_test, y_test)*100\n\nprint(\"Train Accuracy {:.2f}%\".format(log_acc_train))\nprint(\"Test Accuracy {:.2f}%\".format(log_acc_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix = confusion_matrix(y_test,predict)\nclass_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\nsns.heatmap(pd.DataFrame(confusion_matrix), annot = True, cmap = 'Blues',\n           fmt = 'g')\n\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for Logistic Regression')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC Curve for Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_probabilities = log_param.predict_proba(X_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"false_positive_rate_log,true_positive_rate_log,threshold_log = roc_curve(y_test,y_probabilities)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting ROC Curve\nplt.figure(figsize=(10,6))\nplt.title('ROC for Logistic Regression')\nplt.plot(false_positive_rate_log, true_positive_rate_log, linewidth=5, color='red')\nplt.plot([0,1],ls='--',linewidth=5)\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.text(0.2,0.6,'AUC: {:.2f}'.format(roc_auc_score(y_test,y_probabilities)),size= 16)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Supported Vector Classifier\nimplemented with GridSearchCV for hyperparameter tunning."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm_clf = SVC(probability=True, kernel='rbf', gamma=0.1, C=1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\"C\":(0.1, 0.5, 1, 2, 5, 10, 20), \n          \"gamma\":(0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 1), \n          \"kernel\":('linear', 'poly', 'rbf')}\n\nsvm_param = GridSearchCV(svm_clf, params, n_jobs=-1, cv=5, verbose=1, scoring=\"accuracy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_param.fit(X_train, y_train)\n#Best params selected by GridSearchCV\nsvm_param.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = svm_param.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_acc_train = svm_param.score(X_train, y_train)*100\nsvc_acc_test = svm_param.score(X_test, y_test)*100\n\nprint(\"Train Accuracy {:.2f}%\".format(svc_acc_train))\nprint(\"Test Accuracy {:.2f}%\".format(svc_acc_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix = confusion_matrix(y_test,predict)\nclass_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\nsns.heatmap(pd.DataFrame(confusion_matrix), annot = True, cmap = 'Blues',\n           fmt = 'g')\n\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for Supported Vector Classifier')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC Curve for Supported Vector Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_probabilities = svm_param.predict_proba(X_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"false_positive_rate_svc,true_positive_rate_svc,threshold_svc = roc_curve(y_test,y_probabilities)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting ROC Curve\nplt.figure(figsize=(10,6))\nplt.title('ROC for Supported Vector Classifier')\nplt.plot(false_positive_rate_svc, true_positive_rate_svc, linewidth=5, color='red')\nplt.plot([0,1],ls='--',linewidth=5)\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.text(0.2,0.6,'AUC: {:.2f}'.format(roc_auc_score(y_test,y_probabilities)),size= 16)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree Classifier\nimplemented with GridSearchCV for hyperparameter tunning."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ntree_clf = DecisionTreeClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\"criterion\":(\"gini\", \"entropy\"), \n          \"splitter\":(\"best\", \"random\"), \n          \"max_depth\":(list(range(1, 20))), \n          \"min_samples_split\":[2, 3, 4], \n          \"min_samples_leaf\":list(range(1, 20))}\n\ntree_param = GridSearchCV(tree_clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=3, iid=True)\ntree_param.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params = tree_param.best_params_\n#Best params selected by GridSearchCV\nbest_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_param = DecisionTreeClassifier(**best_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_param.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = tree_param.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_acc_train = tree_param.score(X_train, y_train)*100\ntree_acc_test = tree_param.score(X_test, y_test)*100\n\nprint(\"Train Accuracy {:.2f}%\".format(tree_acc_train))\nprint(\"Test Accuracy {:.2f}%\".format(tree_acc_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix = confusion_matrix(y_test,predict)\nclass_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\nsns.heatmap(pd.DataFrame(confusion_matrix), annot = True, cmap = 'Blues',\n           fmt = 'g')\n\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for Decision Tree')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC Curve for Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_probabilities = tree_param.predict_proba(X_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"false_positive_rate_tree, true_positive_rate_tree, threshold_tree = roc_curve(y_test,y_probabilities)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting ROC Curve\nplt.figure(figsize=(10,6))\nplt.title('Revceiver Operating Characterstic')\nplt.plot(false_positive_rate_tree, true_positive_rate_tree, linewidth=5, color='red')\nplt.plot([0,1],ls='--',linewidth=5)\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.text(0.2,0.6,'AUC: {:.2f}'.format(roc_auc_score(y_test,y_probabilities)),size= 16)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  XGBoost Classifier\nimplemented with GridSearchCV for hyperparameter tunning."},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost.sklearn import XGBClassifier  \n\nxgb = XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_estimators = [100, 500, 900, 1100, 1500]\nmax_depth = [2, 3, 5, 10, 15]\nbooster = ['gbtree', 'gblinear']\nbase_score = [0.25, 0.5, 0.75, 0.99]\nlearning_rate = [0.05, 0.1, 0.15, 0.20]\nmin_child_weight = [1, 2, 3, 4]\n\nparams = {'n_estimators': n_estimators, 'max_depth': max_depth,\n    'learning_rate' : learning_rate, 'min_child_weight' : min_child_weight, \n    'booster' : booster, 'base_score' : base_score}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_cv = GridSearchCV(xgb, params, cv=5, scoring = 'accuracy',n_jobs =-1, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_cv.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params = xgb_cv.best_params_\n#Best params selected by GridSearchCV\nbest_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier(**best_params, silent=1)\nxgb.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = xgb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_acc_train = xgb.score(X_train, y_train)*100\nxgb_acc_test = xgb.score(X_test, y_test)*100\n\nprint(\"Train Accuracy {:.2f}%\".format(xgb_acc_train))\nprint(\"Test Accuracy {:.2f}%\".format(xgb_acc_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix = confusion_matrix(y_test,predict)\nclass_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\nsns.heatmap(pd.DataFrame(confusion_matrix), annot = True, cmap = 'Blues',\n           fmt = 'g')\n\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for XGB Classifier')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### ROC Curve for XGB Classifier\n\ny_probabilities = xgb.predict_proba(X_test)[:,1]\n\nfalse_positive_rate_xgb, true_positive_rate_xgb, threshold_xgb = roc_curve(y_test,y_probabilities)\n\n#Plotting ROC Curve\nplt.figure(figsize=(10,6))\nplt.title('ROC for XGB Classifier')\nplt.plot(false_positive_rate_xgb, true_positive_rate_xgb, linewidth=5, color='red')\nplt.plot([0,1],ls='--',linewidth=5)\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.text(0.2,0.6,'AUC: {:.2f}'.format(roc_auc_score(y_test,y_probabilities)),size= 16)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, regularizers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.Sequential([\n        layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n        layers.Dropout(0.4),\n        layers.Dense(16, activation='relu',kernel_regularizer=regularizers.l2(0.001)),\n        layers.Dense(1,activation='sigmoid')\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer='adam',metrics='accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Fit model on training data\")\nhistory = model.fit(X_train, y_train, batch_size=30, epochs=100, validation_split = 0.2, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,6))\n\nax1.plot(history.history['accuracy'])\nax1.plot(history.history['val_accuracy'])\nax1.set_title('Model Accuracy')\nax1.set_ylabel('Accuracy')\nax1.set_xlabel('Epoch')\nax1.legend(['Train', 'Test'])\n\nax2.plot(history.history['loss'])\nax2.plot(history.history['val_loss'])\nax2.set_title('Model Loss')\nax2.set_ylabel('loss')\nax2.set_xlabel('epoch')\nax2.legend(['train', 'test'])\nplt.suptitle(\"Model Accuracy & Loss\",fontsize=16)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_test = model.predict_classes(X_test)\npredict_train = model.predict_classes(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nn_acc_train = accuracy_score(y_train, predict_train)*100\nnn_acc_test = accuracy_score(y_test, predict_test)*100\n\nprint(\"Train Accuracy {:.2f}%\".format(nn_acc_train))\nprint(\"Test Accuracy {:.2f}%\".format(nn_acc_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix = confusion_matrix(y_test,predict_test)\nclass_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\nsns.heatmap(pd.DataFrame(confusion_matrix), annot = True, cmap = 'Blues',\n           fmt = 'g')\n\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for Neural Network')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### ROC Curve for Neural Network\n\ny_probabilities = model.predict_proba(X_test)\n\nfalse_positive_rate_nn, true_positive_rate_nn, threshold_nn = roc_curve(y_test,y_probabilities)\n\n#Plotting ROC Curve\nplt.figure(figsize=(10,6))\nplt.title('ROC for Neural Network')\nplt.plot(false_positive_rate_nn, true_positive_rate_nn, linewidth=5, color='red')\nplt.plot([0,1],ls='--',linewidth=5)\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.text(0.2,0.6,'AUC: {:.2f}'.format(roc_auc_score(y_test,y_probabilities)),size= 16)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Summary"},{"metadata":{},"cell_type":"markdown","source":"## ROC Curves for all models"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,10))\nplt.title('ROC Curves')\nplt.plot(false_positive_rate_knn,true_positive_rate_knn,label='K-NN')\nplt.plot(false_positive_rate_log,true_positive_rate_log,label='Logistic Regression')\nplt.plot(false_positive_rate_svc,true_positive_rate_svc,label='Supported Vector Classifier')\nplt.plot(false_positive_rate_tree, true_positive_rate_tree,label='Decision Tree Classifier')\nplt.plot(false_positive_rate_xgb, true_positive_rate_xgb,label='XGB Classifier')\nplt.plot(false_positive_rate_nn, true_positive_rate_nn,label='Neural Network Classifier')\nplt.plot([0,1],ls='--')\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.ylabel('True positive rate')\nplt.xlabel('False positive rate')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = pd.DataFrame(data=[[\"K-NN\", knn_acc_train, knn_acc_test],\n                            [\"Logistic Regression\", log_acc_train, log_acc_test],\n                            [\"Supported Vector Classifier\", svc_acc_train, svc_acc_test],\n                            [\"Decision Tree Classifier\", tree_acc_train, tree_acc_test],\n                            [\"XGB Classifier\", xgb_acc_train, xgb_acc_test],\n                            [\"Neural Network Classifier\", nn_acc_train, nn_acc_test]], \n                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\nscores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <p style=\"text-align:center;\">**<font color='orange'>Suggestions</font>** are welcome </p>"},{"metadata":{},"cell_type":"markdown","source":"# <p style=\"text-align:center;\"> **<font color='orange'>Feel free</font>** to ask below </p>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}