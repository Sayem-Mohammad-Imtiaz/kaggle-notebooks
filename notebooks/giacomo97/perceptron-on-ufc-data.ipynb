{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Analizing Data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/ufcdata/preprocessed_data.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"List of all feature available in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in data.columns: \n    print(col) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing\nSklearn implementation of the decision tree algoritmh doesn't support discrete values, but only binary or real values, so we need to encode each label into a numerical value"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn.preprocessing import label_binarize\n\nle = preprocessing.LabelEncoder()\nfor i in range(0,len(data.columns)):\n    data.iloc[:,i] = le.fit_transform(data.iloc[:,i])\ndata.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dividing into training data and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"nrows=len(data.index)\npercentage=round((nrows*90)/100)\ndata=data.sample(frac=1, random_state=69)\ntrainingData=data.iloc[:percentage,:]\ntestData=data.iloc[percentage:,:]\n\nprint(\"Number of training data examples \"+str(len(trainingData.index)))\nprint(\"Number of test examples \"+str(len(testData.index)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x=trainingData[[\"B_wins\", \"B_losses\",\"B_draw\", \"R_wins\", \"R_losses\",\"R_draw\"]]\n#train_x=trainingData[trainingData.columns.difference(['b'])]\ntrain_y=trainingData[\"Winner\"]\n\ntest_x=testData[[\"B_wins\", \"B_losses\",\"B_draw\", \"R_wins\", \"R_losses\",\"R_draw\"]]\n#test_x=testData[testData.columns.difference(['b'])]\ntest_y=testData[\"Winner\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y.head","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating the perceptron algorithm"},{"metadata":{},"cell_type":"markdown","source":"AbstractPerceptron class which contains all the attributes and operations common to each type of perceptron"},{"metadata":{"trusted":true},"cell_type":"code","source":"class AbstractPerceptron :\n    weights=np.array([])\n    learningRate=1\n    def __init__(self, learningRate):\n        self.learningRate=learningRate\n        \n    def predict(self,x):\n        xtemp=np.append(1,x)\n        return self.weights.dot(xtemp)\n\n    def getWeights(self):\n        return self.weights","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most basic perceptron version without any kind of activation function"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Perceptron(AbstractPerceptron):\n    def train(self,x,y):\n        nFeatures=x.shape[1]\n        nExamples=x.shape[0]\n        onesColumn=np.ones([nExamples,1],dtype=int)\n        xtemp=np.append(onesColumn,x,axis=1)\n        np.random.seed(69)\n        self.weights=np.random.rand(nFeatures+1)\n        for i in range(0,nExamples):\n            output=self.predict(x[i][:])\n            adjustment=(self.learningRate*(y[i]-output))*xtemp[i][:]\n            self.weights=(self.weights+adjustment)\n    pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Extention of the base perceptron which uses the sign function as activation function"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SignPerceptron(Perceptron):\n    def  predict(self,x):\n        predictions=super().predict(x)\n        return np.sign(predictions)\n    pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Extention of the base perceptron that uses the sigmoid function as activation function"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SigmoidPerceptron(Perceptron):\n    def  predict(self,x):\n        predictions=super().predict(x)\n        sigmoid=lambda x : 1/(np.exp(x*-1)+1)\n        return sigmoid(predictions)\n    pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gradient descent version of the perceptron"},{"metadata":{"trusted":true},"cell_type":"code","source":"class GradientDescentPerceptron(AbstractPerceptron):\n    def train(self,x,y):\n        nFeatures=x.shape[1]\n        nExamples=x.shape[0]\n        onesColumn=np.ones([nExamples,1],dtype=int)\n        xtemp=np.append(onesColumn,x,axis=1)\n        np.random.seed(69)\n        self.weights=np.random.uniform(-0.5,0.5,nFeatures+1)\n        deltas=np.zeros(len(self.weights))\n        for i in range(0,nExamples):\n            output=self.predict(x[i][:])\n            for j in range(0,len(deltas)):\n                deltas[j]=deltas[j]+(self.learningRate*(y[i]-output))*xtemp[i][j]\n        self.weights=(self.weights+deltas)\n    pass","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gradient descent version of the perceptron with a sigmoid function as activation function"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SigmoidGradientDescentPerceptron(AbstractPerceptron):  \n    def train(self,x,y):\n        sigmoid=lambda x : 1/(np.exp(x*-1)+1)\n        nFeatures=x.shape[1]\n        nExamples=x.shape[0]\n        onesColumn=np.ones([nExamples,1],dtype=int)\n        xtemp=np.append(onesColumn,x,axis=1)\n        np.random.seed(69)\n        self.weights=np.random.uniform(-1*10^-10,-1*10^-10,nFeatures+1)\n        deltas=np.zeros(len(self.weights))\n        for i in range(0,nExamples):\n            output=self.predict(x[i][:])\n            for j in range(0,len(deltas)):\n                deltas[j]=deltas[j]+self.learningRate*(y[i]-output)*sigmoid(y[i])*(1-sigmoid(y[i]))*xtemp[i][j]\n            self.weights=(self.weights+deltas)\n    def predict(self,x):\n        prediction=super().predict(x)\n        sigmoid=lambda x : 1/(np.exp(x*-1)+1)\n        return sigmoid(prediction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the perceptron"},{"metadata":{},"cell_type":"markdown","source":"Analizziamo prima la versione che ha come funzione di attivazione la funzione segno"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nperceptron=SignPerceptron(1)\nperceptron.train(train_x.to_numpy(),train_y.to_numpy())\n\nnExamples=test_x.shape[0]\npredictions=np.empty([nExamples,1])\nfor i in range(0,nExamples):\n    predictions[i]=perceptron.predict(test_x.iloc[i][:])\n\nprint(\"The accuracy score of the prediction on the test data is\",accuracy_score(test_y, predictions))\n\nnExamples=train_x.shape[0]\npredictions=np.empty([nExamples,1])\nfor i in range(0,nExamples):\n    predictions[i]=perceptron.predict(train_x.iloc[i][:])\nprint(\"The accuracy score of the prediction on the train data is\",accuracy_score(train_y, predictions))\n\nprint()\n\nprint(\"The calculated weights are \")\nprint(perceptron.getWeights())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analizziamo ora la versione alternativa in cui utilizziamo come funzione di attivazione la funzione sigmoide"},{"metadata":{"trusted":true},"cell_type":"code","source":"perceptron=SigmoidPerceptron(1)\nperceptron.train(train_x.to_numpy(),train_y.to_numpy())\n\nnExamples=test_x.shape[0]\npredictions=np.empty([nExamples,1])\nfor i in range(0,nExamples):\n    predictions[i]=perceptron.predict(test_x.iloc[i][:])\nprint(\"The accuracy score of the prediction on the test data is\",accuracy_score(test_y, predictions.round()))\n\nnExamples=train_x.shape[0]\npredictions=np.empty([nExamples,1])\nfor i in range(0,nExamples):\n    predictions[i]=perceptron.predict(train_x.iloc[i][:])\nprint(\"The accuracy score of the prediction on the train data is\",accuracy_score(train_y, predictions.round()))\n\nprint()\n\nprint(\"The calculated weights are \")\nprint(perceptron.getWeights())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analizziamo la versione sigmoide gradient descent"},{"metadata":{"trusted":true},"cell_type":"code","source":"perceptron=SigmoidGradientDescentPerceptron(1)\nperceptron.train(train_x.to_numpy(),train_y.to_numpy())\n\nnExamples=test_x.shape[0]\npredictions=np.empty([nExamples,1])\nfor i in range(0,nExamples):\n    predictions[i]=perceptron.predict(test_x.iloc[i][:])\nprint(\"The accuracy score of the prediction on the test data is\",accuracy_score(test_y, predictions.round()))\n\nnExamples=train_x.shape[0]\npredictions=np.empty([nExamples,1])\nfor i in range(0,nExamples):\n    predictions[i]=perceptron.predict(train_x.iloc[i][:])\nprint(\"The accuracy score of the prediction on the train data is\",accuracy_score(train_y, predictions.round()))\n\nprint()\n\nprint(\"The calculated weights are \")\nprint(perceptron.getWeights())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Comparing results with the sklearn implementation of the perceptron"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Perceptron\nperceptron = Perceptron(alpha=1)\n\nperceptron.fit(train_x, train_y)\n\npredictions=perceptron.predict(test_x)\nprint(\"The accuracy score of the prediction on the test data is\",accuracy_score(test_y, predictions.round()))\n\npredictions=perceptron.predict(train_x)\nprint(\"The accuracy score of the prediction on the train data is\",accuracy_score(train_y, predictions.round()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Come si può notare l'accuracy ottenuta è piuttosto bassa ciononostante ritengo che sia piuttosto normale ottenere tali risultati con un singolo perceptron. Per aspirare a risultati migliori sarebbe necessario implementare un'apposita rete neurale multistrato."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}