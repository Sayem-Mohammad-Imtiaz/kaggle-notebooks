{"cells":[{"metadata":{"_uuid":"2b59ffaa692a3b66c35a6021af387d75ade4f5dd"},"cell_type":"markdown","source":"# E Commerce Reviews "},{"metadata":{"_uuid":"b52a9869fbd6c79af50258ed003d7330d7c7dc40"},"cell_type":"markdown","source":"### Inspiration:\n[Tutorials on Bag of words](https://www.kaggle.com/rochachan/bag-of-words-meets-bags-of-popcorn)\n\n[Abhishek's Kernel on NLP](https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle)\n\n[Jeremy Howard's kernel on Naive Bayes](https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline)\n\n[sban's advanced kernel on LSTM](https://www.kaggle.com/shivamb/beginners-guide-to-text-generation-using-lstms)\n\nMany more kernels dealing with NLP."},{"metadata":{"_uuid":"8959219d9b7da08b51d6a554edffcb4f52b48f89"},"cell_type":"markdown","source":"### Objective:"},{"metadata":{"_uuid":"025ff000d9293f692ecf5cfb864c4e9c099a2ca7"},"cell_type":"markdown","source":"This is my first extensive kernel dealing with an text classification problem.Therefore I have tried my hands on whatever i have learnt so far on NLP.I try to do a data analysis and visualisation before creating a simple naive bayes model to predict review scores using the reviews.Thanks for reading through.Also check out my other kernel on [whiskey classification using reviews](https://www.kaggle.com/gsdeepakkumar/classy-whisky-approach-through-nlp)"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"fa7fcba9fb1b36c67b0caedceb17987edf1a001e"},"cell_type":"code","source":"\n\n# Loading the required libraries \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport warnings\nimport itertools\nwarnings.filterwarnings('ignore')\nreview =pd.read_csv(\"../input/Womens Clothing E-Commerce Reviews.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"4f7a553445d69bd34d3ba6e23ef890ae1f4dc82d"},"cell_type":"code","source":"review.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"3e3f15858930eb1b7e59f2b8bab18d02c784d266"},"cell_type":"code","source":"text = review[['Review Text','Rating']]\ntext.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"ff717ae0004cf4e331957d0d2e3aad84c9046674"},"cell_type":"code","source":"text['Review Text'][0]\ntext[text['Review Text']==\"\"]=np.NaN\ntext['Review Text'].fillna(\"No Review\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"bf8f95a51cc130f06c48c7c4e5594b224ebd2b3b"},"cell_type":"code","source":"# Split into train and test data:\nsplit = np.random.randn(len(text)) <0.8\ntrain = text[split]\ntest = text[~split]\nprint(\"Total rows in train:\",len(train),\"and test:\",len(test))\nytrain=train['Rating']\nytest=test['Rating']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"32667a95f86a1a7a855930935a0dfb58b5ad5f16"},"cell_type":"markdown","source":"### Examine the length of the comments:\n"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"3c1f1b1c6d5ca0ba455eed90d3fa8b506f2e2604"},"cell_type":"code","source":"lens=train['Review Text'].str.len()\nprint(\"Mean Length:\",lens.mean(),\"Standard Deviation\",lens.std(),\"Maximum Length\",lens.max())\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"7b7877e1d3e42ba63811901204a26bba54997d4c"},"cell_type":"code","source":"lens.hist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4ee70d0fabb5a43b2ea66aeda6383a2a88d2b08"},"cell_type":"markdown","source":"We find that the length of the text varies.Let us see how the length is distributed for every rating ."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"eb74942756532c6e37ac4182777fbd8e2de0b86a"},"cell_type":"code","source":"plt.figure(figsize=(8,8))\ntext['Length']=lens\nfx=sns.boxplot(x='Rating',y='Length',data=text)\nplt.title(\"Distribution of length with respect to rating\")\nplt.xlabel(\"Rating\")\nplt.ylabel(\"Length\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ba9595f23b6c8f036fd05238f6d458d0b090b32"},"cell_type":"markdown","source":"There seems to be a slight difference in the length of the reviews for different rating."},{"metadata":{"_uuid":"a17641953a63caa9d2422aa9545f932c76112cf0"},"cell_type":"markdown","source":"We will now convert the text files into numerical vectors through **Bag of words** model.For this , first we will clean the reviews - remove stopwords as a baseline model.We can also look at removing punctuations,numbers."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"7bdbb9e2c51eeb9893bd91864cd7f50ffa3faad2"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import log_loss,confusion_matrix,classification_report, accuracy_score\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import RegexpTokenizer\nimport re\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"814bded0cb1f14b3cb9a4249c8b1d7e124fd814b"},"cell_type":"code","source":"count_vect = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 3), stop_words = 'english',max_features=5000)\ncount_vect.fit(list(train['Review Text'].values.astype('U'))+list(test['Review Text'].values.astype('U')))\nxtrain=count_vect.transform(train['Review Text'].values.astype('U'))\nxtest=count_vect.transform(test['Review Text'].values.astype('U'))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"616b49d05693dea6e0dcb77a039c7c9cf179484c"},"cell_type":"markdown","source":"Now we train naive bayes model on the data and look at the log loss value."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"c25154fbf6ca2c0e13d8785f76181b203b403948"},"cell_type":"code","source":"## Applying naive bayes:\n\nmodel = MultinomialNB()\nmodel.fit(xtrain, ytrain)\npredictions = model.predict(xtest)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fcaa29b66159fef4d3dbd35afb828ffac12415ab"},"cell_type":"markdown","source":"### Metrics:"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"de91cb36809a1d28de2d78b879ea965bdf540611"},"cell_type":"code","source":"### Lets check the accuracy score.\nprint(accuracy_score(ytest, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"303582099f4b528052b3f4c790e9ec769ec517bd"},"cell_type":"code","source":"conf_matrix=confusion_matrix(ytest,predictions)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed6400ad6328e6254039f99a2943f468144a1b1d"},"cell_type":"markdown","source":"The model has an accuracy of 62 %."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"3c6d4947a18dae903df1ff030b774726d61b894f"},"cell_type":"code","source":"### Print confusion matrix:\ndef plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    print(cm)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\nplt.figure(figsize=(8,8))\nplot_confusion_matrix(conf_matrix, classes=['1', '2','3','4','5'],\n                      title='Confusion matrix')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9bfb726e05e3b28c2866c59036eeeb4b7c39cd17"},"cell_type":"markdown","source":"**Thanks for reading my kernel.**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.0"}},"nbformat":4,"nbformat_minor":1}