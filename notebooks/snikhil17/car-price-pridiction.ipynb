{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id=\"table-of-contents\"></a>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\"><u>Content in this Notebook</u>\n\n<p style=\"font-family:cursive;font-size:17px; color:white\" >Notebook is a part of FREE ML course by Glexey Grigorev.\n<a style=\"font-family:cursive;font-size:17px; color: yellow\" href=\"https://datatalks.club/courses/2021-winter-ml-zoomcamp.html\" target=\"_blank\"> <u>Link for the Course</u></a></p>\n    \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#1\"> 1. Introduction </a></li>     \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#2\"> 2. Impoting Libraries </a></li> \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15;\" href = \"#3\"> 3. Loading and Reading Data </a></li> \n<li  style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#4\"> 4. Cleaning Strings in Column and Values</a></li> <ul>\n<li style = \"line-height: 0.7\" ><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#4.1\"> 4.1 Making List of Categorical Columns</a></li>\n    <li style = \"line-height: 0.7\" ><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#4.2\">4.2  Cleaning Categorical Data in our data set</a></li>\n    </ul>\n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#5\"> 5. Exploratory Data Analysis </a></li>     \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#6\"> 6. Missing Values </a></li>\n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#7\"> 7. Validation Framework: Creating Train Validation and Test Split Manually</a></li>        \n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#8\">8. Linear Regression</a></li>\n<li style = \"line-height: 0.7\"><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#9\">9. Linear Regression Vector Form</a></li>\n<ul>\n<li style = \"line-height: 0.7\" ><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#9.1\"> 9.1 Generalized Linear Regression</a></li>\n    <li style = \"line-height: 0.7\" ><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#9\">9.2 Linear Regression with Multiple Variables</a></li></ul>\n        <li style = \"line-height: 0.7\" ><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#10\">10. Training Linear Regression - Normal Equation</a></li>\n<li style = \"line-height: 0.7\" ><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#11\">11. Car Price Baseline Model</a></li>\n<li style = \"line-height: 0.7\" ><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#12\">12. Root Mean Squared Error (RMSE)</a></li>\n<li style = \"line-height: 0.7\" ><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#13\">13. Validating the Model using RMSE</a></li>\n<li style = \"line-height: 0.7\" ><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#14\">14. Feature Engineering</a></li>\n    \n<li style = \"line-height: 0.7\" ><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#15\">15. Categorical Variables</a></li>\n<li style = \"line-height: 0.7\" ><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#16\">16. Regularization</a></li>\n<li style = \"line-height: 0.7\" ><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#17\">17. Tuning the Model</a></li>\n    <li style = \"line-height: 0.7\" ><a style=\"font-family:cursive;font-size:17px; color:#ecfe15\" href = \"#18\">18. Using the model</a></li>\n\n    \n    \n    \n    \n    \n</div>\n","metadata":{}},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"1\"></a>\n\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\">1. Introduction\n   \n<p style=\"font-family:cursive;font-size:17px;color:white\">Cars dataset with features including make, model, year, engine, and other properties of the car used to predict its price.</p>\n<p style=\"font-family:cursive;font-size:17px;color:white\">Scraped from Edmunds and Twitter.</p>\n<p style=\"font-family:cursive;font-size:17px;color:white\"> Effects of features on the price</p>\n<ul style=\"font-family:cursive;font-size:17px;color:white\">\n<li> Predict the price of Cars using different Variables </li>\n    </ul>\n</div>\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"2\"></a>\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\">2. Importing Libraries</div>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rcParams['figure.figsize'] = (16, 8)\nplt.style.use('fivethirtyeight')","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:44.464575Z","iopub.execute_input":"2021-09-17T08:05:44.464886Z","iopub.status.idle":"2021-09-17T08:05:45.631332Z","shell.execute_reply.started":"2021-09-17T08:05:44.464857Z","shell.execute_reply":"2021-09-17T08:05:45.630261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"3\"></a>\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\">3. Loading and Reading Data </div>\n\n","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/cardataset/data.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:45.63266Z","iopub.execute_input":"2021-09-17T08:05:45.632894Z","iopub.status.idle":"2021-09-17T08:05:45.728189Z","shell.execute_reply.started":"2021-09-17T08:05:45.632868Z","shell.execute_reply":"2021-09-17T08:05:45.727289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"4\"></a>\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\">4. Data Cleaning: Cleaning Strings in Column and values</div>","metadata":{}},{"cell_type":"code","source":"df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:45.729521Z","iopub.execute_input":"2021-09-17T08:05:45.729785Z","iopub.status.idle":"2021-09-17T08:05:45.7546Z","shell.execute_reply.started":"2021-09-17T08:05:45.729753Z","shell.execute_reply":"2021-09-17T08:05:45.753814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"4.1\"></a>\n<div style=\"background:#59a1c6;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:black\">4.1 Making List of Categorical Columns </div>","metadata":{}},{"cell_type":"code","source":"\"\"\"\nMaking List of Categorical Columns\n\"\"\"\n\n\"\"\" \nMethod shown in mlzoomcamp \n\"\"\"\nstrings = list(df.dtypes[df.dtypes == 'object'].index)\nstrings\n\n\n# Other methods \n# list(df.select_dtypes(include = 'O').columns)\n# [col for col in df.columns if df[col].dtype == 'object']","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:45.756835Z","iopub.execute_input":"2021-09-17T08:05:45.757682Z","iopub.status.idle":"2021-09-17T08:05:45.770164Z","shell.execute_reply.started":"2021-09-17T08:05:45.757629Z","shell.execute_reply":"2021-09-17T08:05:45.769491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"4.2\"></a>\n<div style=\"background:#59a1c6;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:black\">4.2 <u>Cleaning Categorical Data in our data set</u> </div>","metadata":{}},{"cell_type":"code","source":"\"\"\"\nCleaning Categorical Data in our data set\n\"\"\"\nfor col in strings:\n    df[col] = df[col].str.lower().str.replace(\" \", \"_\")\n    \ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:45.771576Z","iopub.execute_input":"2021-09-17T08:05:45.77186Z","iopub.status.idle":"2021-09-17T08:05:45.931491Z","shell.execute_reply.started":"2021-09-17T08:05:45.771827Z","shell.execute_reply":"2021-09-17T08:05:45.930564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"5\"></a>\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\">5. Exploratory Data Analysis</div>","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background:#59a1c6;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:black\">Unique values and their numbers </div>","metadata":{}},{"cell_type":"code","source":"for col in df.columns:\n    print(col)\n    print(df[col].unique()[:5])\n    print(df[col].nunique())\n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:45.932676Z","iopub.execute_input":"2021-09-17T08:05:45.932953Z","iopub.status.idle":"2021-09-17T08:05:45.988863Z","shell.execute_reply.started":"2021-09-17T08:05:45.932923Z","shell.execute_reply":"2021-09-17T08:05:45.987954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n\n<div style=\"background:#59a1c6;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:black\">Distribution of price</div>","metadata":{}},{"cell_type":"code","source":"sns.histplot(df['msrp'], bins = 50);","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:45.989985Z","iopub.execute_input":"2021-09-17T08:05:45.990233Z","iopub.status.idle":"2021-09-17T08:05:46.443189Z","shell.execute_reply.started":"2021-09-17T08:05:45.990204Z","shell.execute_reply":"2021-09-17T08:05:46.441865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<div style=\"background:#59a1c6;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:black\">Distribution of price with msrp less than 100000 </div>","metadata":{}},{"cell_type":"code","source":"sns.histplot(df['msrp'][df['msrp'] < 100000], bins = 50);","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:46.445609Z","iopub.execute_input":"2021-09-17T08:05:46.446004Z","iopub.status.idle":"2021-09-17T08:05:46.937402Z","shell.execute_reply.started":"2021-09-17T08:05:46.445959Z","shell.execute_reply":"2021-09-17T08:05:46.935855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<div style=\"background:#59a1c6;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:black\">Log(msrp +1)</div>","metadata":{}},{"cell_type":"code","source":"\"\"\"\nApplying log to 'msrp' column\n\"\"\"\nprice_logs = np.log1p(df['msrp'])\nsns.histplot(price_logs, bins = 50);","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:46.939381Z","iopub.execute_input":"2021-09-17T08:05:46.939747Z","iopub.status.idle":"2021-09-17T08:05:47.400321Z","shell.execute_reply.started":"2021-09-17T08:05:46.939696Z","shell.execute_reply":"2021-09-17T08:05:47.398817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"6\"></a>\n<a id=\"6\"></a><div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\">6. Missing Values</div>","metadata":{}},{"cell_type":"code","source":"print(df.isnull().sum())\ndf.isnull().sum().plot(kind = 'bar')","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:47.404663Z","iopub.execute_input":"2021-09-17T08:05:47.404972Z","iopub.status.idle":"2021-09-17T08:05:47.992317Z","shell.execute_reply.started":"2021-09-17T08:05:47.404942Z","shell.execute_reply":"2021-09-17T08:05:47.991464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"7\"></a>\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\">7. Validation Framework: Creating Train Validation and Test Split Manually</div>\n","metadata":{}},{"cell_type":"code","source":"\"\"\"\nCreating length/number of values of train, validation and test set\n\"\"\"\nn  = len(df)    \n\nn_val = int(n * 0.2)  # Creating Validation Set\nn_test = int(n * 0.2) # Creating test set\nn_train = n - n_val - n_test\n\n\"\"\"\nSetting up for randomizing the values\n\"\"\"\nidx = np.arange(n)\nnp.random.seed(2)\nnp.random.shuffle(idx)\n\n\n\"\"\"\nCreating data set for Train Valid and Test set.\nAlso to randomize the index to avoid bias.\n\"\"\"\n\ndf_train = df.iloc[idx[:n_train]]\ndf_val = df.iloc[idx[n_train:n_train+n_val]]\ndf_test = df.iloc[idx[n_train+n_val:]]\n\n\n\"\"\"\nDropping the indexes from all the datasets as they are of no use now.\n\"\"\"\n\ndf_train = df_train.reset_index(drop = True)\ndf_val = df_val.reset_index(drop = True)\ndf_test = df_test.reset_index(drop = True)\n\n\n\"\"\"\nMaking dependent variables with LOG transformation for all the datasets.\n\"\"\"\n\ny_train = np.log1p(df_train['msrp'].values)\ny_val = np.log1p(df_val['msrp'].values)\ny_test = np.log1p(df_test['msrp'].values)\n\n\"\"\"\nDeleting target / dependent variables from training, validation and test sets\n\"\"\"\ndel df_train['msrp']\ndel df_val['msrp']\ndel df_test['msrp']\n\n\"\"\"\nFinally Checking the Length of Datasets created\n\"\"\"\nlen(df_train), len(df_val), len(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:47.993583Z","iopub.execute_input":"2021-09-17T08:05:47.99382Z","iopub.status.idle":"2021-09-17T08:05:48.030809Z","shell.execute_reply.started":"2021-09-17T08:05:47.993793Z","shell.execute_reply":"2021-09-17T08:05:48.02977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"8\"></a>\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\">8. Linear Regression</div>","metadata":{}},{"cell_type":"markdown","source":"### **General Regression:** $\\large  g(X) \\approx y$\n\n### **Liner Regression for predicting price for only 1 car**  $\\Large g(x_i) \\approx y_i$\n### $\\large x_i = (x_{i1}, x_{i2}, ..... , x_{in})$ \n### $\\large y_i = g(x_{i1}, x_{i2}, ..... , x_{in})$ \n### **where $\\large x_i$ is a row in our dataset and $\\large y_i$ is the prediction we get from function** $\\large g(x_i)$\n\n### **In the following implementation we took:**\n### $\\large x_i$ **= [453, 11, 86]**\n\n### Now the formula says:\n### $\\large {g(x_i) = w_0 + w_1x_{i1} + w_2x_{i2} +w_3x_{i3}}$\n### Therefore we implement this formula $\\large g(x_i) = w_0 + \\sum_{k=0}^{n-1}w_jx_{ij}$\n### $w_0$ :  is the biased term i.e. Price of a car when we don't know anything about the car\n\n","metadata":{}},{"cell_type":"code","source":"\"\"\"\nTaking values of 3 variables for a specific row (10): engine_hp, city_mpg, popularity\nDeclaring Biased Term and Weights for each features\n\"\"\"\nxi = [453, 11, 86] \n\n\nw0 = 0\n\n\"\"\"\nDeclaring Weights for each features\n\"\"\"\nw =  [1, 1, 1]\n\n\"\"\"\nCreating Linear Regression Function\n\"\"\"\ndef linear_regression(xi):\n    n =len(xi)                # Number of features used\n    \n    pred = w0                 # Initial / Base prediction\n    \n    for j in range(n):\n        pred += w[j]*xi[j]     # Formula = w0 +sigma[0:n-1]{w[j]*xi[j]}\n    \n    return pred\n\n\"\"\"\nCalling linear_regression function on xi\n\"\"\"\nlinear_regression(xi)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:48.03291Z","iopub.execute_input":"2021-09-17T08:05:48.033266Z","iopub.status.idle":"2021-09-17T08:05:48.046003Z","shell.execute_reply.started":"2021-09-17T08:05:48.033218Z","shell.execute_reply":"2021-09-17T08:05:48.044695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nChanging the bias terms and checking the prediction\n\"\"\"\n\n\"\"\"Biased Term :\"\"\"\nw0 = 7.17\n\n\"\"\"#Declaring Weights for each features\"\"\"\nw =  [0.01, 0.04, 0.002]\n\n\"\"\"\nCalling linear_regression function again on xi\n\"\"\"\nlinear_regression(xi)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:48.048404Z","iopub.execute_input":"2021-09-17T08:05:48.048741Z","iopub.status.idle":"2021-09-17T08:05:48.066618Z","shell.execute_reply.started":"2021-09-17T08:05:48.048707Z","shell.execute_reply":"2021-09-17T08:05:48.065773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nUsing exponent to undo the logrithm which we did initially\nAlso recall we did log(1 + msrp). Therefore we will need subtract 1.\n\"\"\"\nprint(\"predicted prices: \", np.expm1(12.312))","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:48.068132Z","iopub.execute_input":"2021-09-17T08:05:48.068935Z","iopub.status.idle":"2021-09-17T08:05:48.086525Z","shell.execute_reply.started":"2021-09-17T08:05:48.068896Z","shell.execute_reply":"2021-09-17T08:05:48.085507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"9\"></a>\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\">9. Linear Regression Vector Form</div>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"9.1\"></a>\n<div style=\"background:#59a1c6;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:black\">9.1 Generalized Linear Regression</div>","metadata":{}},{"cell_type":"code","source":"\"\"\"\nDefining a function for dot product\n\"\"\"\ndef dot(xi,w):\n    n = len(xi)\n    \n    res = 0.0\n    \n    for j in range(n):\n        res += xi[j]*w[j]\n    return res\n\n\"\"\"\nImprovising linear_regression\n\"\"\"\ndef linear_regression(xi):\n    return w0 + dot(xi,w)\n\n\"\"\"\nMore Improvising : using W.T Xi = Xi W.T = w0 + dot product as done before\nWe add weight of 1 to bias term and add 1 to xis also.\n\"\"\"\nw_new = [w0] + w\ndef linear_regression(xi):\n    xi = [1] + xi\n    return dot(xi,w_new)\n\n\n\"\"\"\nchecking the function again\n\"\"\"\nlinear_regression(xi)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:48.087766Z","iopub.execute_input":"2021-09-17T08:05:48.088674Z","iopub.status.idle":"2021-09-17T08:05:48.105268Z","shell.execute_reply.started":"2021-09-17T08:05:48.08862Z","shell.execute_reply":"2021-09-17T08:05:48.104623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"9.2\"></a>\n<div style=\"background:#59a1c6;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:black\">9.2 Linear Regression with Multiple Variables</div>","metadata":{}},{"cell_type":"code","source":"\"\"\"\nMaking final model with multiple vectors.\n\"\"\"\n\n\"\"\"Biased Term :\"\"\"\nw0 = 7.17\n\n\"\"\"#Declaring Weights for each features\"\"\"\nw =  [0.01, 0.04, 0.002]\n\n\"\"\"We add weight of 1 to bias term\"\"\"\nw_new = [w0] + w\n\n\"\"\"Making Variables\"\"\"\nx1 = [1, 148, 24, 1385]\nx2 = [1, 132, 25, 2031]\nx10 = [1, 453, 11, 86]\n\n\"\"\"Making X: independent variables array\"\"\"\nX= [x1, x2, x10]\nX = np.array(X)\n\n\"\"\"\nLinear Regression with multiple vectors\n\"\"\"\ndef linear_regression(X):\n    return X.dot(w_new)\n\n\"\"\"\nPredicting Values\n\"\"\"\nlinear_regression(X)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:48.106907Z","iopub.execute_input":"2021-09-17T08:05:48.107153Z","iopub.status.idle":"2021-09-17T08:05:48.124552Z","shell.execute_reply.started":"2021-09-17T08:05:48.107126Z","shell.execute_reply":"2021-09-17T08:05:48.123543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"10\"></a>\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\">10. Training Linear Regression - Normal Equationraining Linear Regression - Normal Equation</div>","metadata":{}},{"cell_type":"code","source":"\"\"\"Making Variables\"\"\"\nX = [\n    [148, 24, 1385],\n    [132, 25, 2031],\n    [453, 11, 86],\n    [158, 24, 185],\n    [172, 25, 201],\n    [413, 11, 86],\n    [38, 54, 185],\n    [142, 25, 431],\n    [453, 31, 86]\n]\n \n\"\"\"Making X: independent variables array\"\"\"\nX = np.array(X)\n\n# \"\"\"\n# Including a biased term\n# \"\"\"\n# ones = np.ones(X.shape[0])\n# X = np.column_stack([ones, X])\n# X\n\n\"\"\"Declaring Target Variable\"\"\"\ny = [10000, 20000, 15000, 20050, 10000, 20000, 15000, 25000, 120]\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:48.125757Z","iopub.execute_input":"2021-09-17T08:05:48.12599Z","iopub.status.idle":"2021-09-17T08:05:48.138202Z","shell.execute_reply.started":"2021-09-17T08:05:48.125964Z","shell.execute_reply":"2021-09-17T08:05:48.137548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nGram Matrix\n\"\"\"\nXTX = X.T.dot(X)\n\n\"\"\"inverse of Gram Matrix\"\"\"\nXTX_inv = np.linalg.inv(XTX)\n\n\"\"\"\nNot exactly identity matrix but the numbers here are very small. Hence can be treated as 0s and 1s\n\"\"\"\n# XTX.dot(XTX_inv).round(1)\nXTX.dot(XTX_inv)\n\n\"\"\" Model\"\"\"\nw_full = XTX_inv.dot(X.T).dot(y)\n\n\n\"\"\"\nCreating Coefficients\n\"\"\"\nw0 = w_full[0]\nw = w_full[1:]\n\n\"\"\"\nprinting Coefficient\n\"\"\"\nw0, w","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:48.139238Z","iopub.execute_input":"2021-09-17T08:05:48.139948Z","iopub.status.idle":"2021-09-17T08:05:48.158873Z","shell.execute_reply.started":"2021-09-17T08:05:48.139911Z","shell.execute_reply":"2021-09-17T08:05:48.157823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Creating a function for Training Linear Regression Model\"\"\"\ndef train_linear_regression(X,y):\n    \"\"\"\n    Including a biased term\n    \"\"\"\n    ones = np.ones(X.shape[0])\n    X = np.column_stack([ones, X])\n    \n    \"\"\"\n    Gram Matrix\n    \"\"\"\n    XTX = X.T.dot(X)\n    \n    \"\"\"inverse of Gram Matrix\"\"\"\n    XTX_inv = np.linalg.inv(XTX)\n    w_full = XTX_inv.dot(X.T).dot(y)\n    \n    return w_full[0], w_full[1:]   \n\n\n\"\"\"Training the Model\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:48.160642Z","iopub.execute_input":"2021-09-17T08:05:48.16179Z","iopub.status.idle":"2021-09-17T08:05:48.177019Z","shell.execute_reply.started":"2021-09-17T08:05:48.161724Z","shell.execute_reply":"2021-09-17T08:05:48.176079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"11\"></a>\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\">11. Car Price Baseline Model</div>","metadata":{}},{"cell_type":"code","source":"\"\"\"\nWe need only numerical columns\n\"\"\"\ndf_train.dtypes\n\n\"\"\"\nCreating subset of only Numerical Columns\n\"\"\"\nbase = ['engine_hp','engine_cylinders','highway_mpg', 'city_mpg', 'popularity']\n\n\"\"\"\nCreating subset of Dataframe to be used as X.\n\"\"\"\nX_train = df_train[base].values\n\n\"\"\" Training model will throw error b'coz of missing values\"\"\"\ntrain_linear_regression(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:48.178753Z","iopub.execute_input":"2021-09-17T08:05:48.179784Z","iopub.status.idle":"2021-09-17T08:05:48.208678Z","shell.execute_reply.started":"2021-09-17T08:05:48.179732Z","shell.execute_reply":"2021-09-17T08:05:48.207697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nchecking missing values in our subset\n\"\"\"\ndf_train[base].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:48.210051Z","iopub.execute_input":"2021-09-17T08:05:48.210847Z","iopub.status.idle":"2021-09-17T08:05:48.225655Z","shell.execute_reply.started":"2021-09-17T08:05:48.210728Z","shell.execute_reply":"2021-09-17T08:05:48.224376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Imputing Missing values with 0 \"\"\"\nX_train = df_train[base].fillna(0).values","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:48.227389Z","iopub.execute_input":"2021-09-17T08:05:48.228283Z","iopub.status.idle":"2021-09-17T08:05:48.236183Z","shell.execute_reply.started":"2021-09-17T08:05:48.228237Z","shell.execute_reply":"2021-09-17T08:05:48.234966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Building and Training the model \"\"\"\nw0, w = train_linear_regression(X_train,y_train)\n\n\"\"\" Prediction\"\"\"\ny_pred =  w0 + X_train.dot(w)\n\n\"\"\"Visualizing the Predictions\"\"\"\nsns.histplot(y_pred, color = 'red', alpha = 0.5, bins = 50)\nsns.histplot(y_train, color = 'blue', alpha = 0.5, bins = 50);","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:48.238316Z","iopub.execute_input":"2021-09-17T08:05:48.238925Z","iopub.status.idle":"2021-09-17T08:05:48.950102Z","shell.execute_reply.started":"2021-09-17T08:05:48.238872Z","shell.execute_reply":"2021-09-17T08:05:48.949078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"12\"></a>\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\">12. Root Mean Squared Error (RMSE)</div>","metadata":{}},{"cell_type":"code","source":"def rmse(y,y_pred):\n    error  = y- y_pred\n    squared_error = error ** 2\n    mse = squared_error.mean()\n    return np.sqrt(mse)  ","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:48.951932Z","iopub.execute_input":"2021-09-17T08:05:48.952407Z","iopub.status.idle":"2021-09-17T08:05:48.956916Z","shell.execute_reply.started":"2021-09-17T08:05:48.952373Z","shell.execute_reply":"2021-09-17T08:05:48.955939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse(y_train,y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:48.958831Z","iopub.execute_input":"2021-09-17T08:05:48.9594Z","iopub.status.idle":"2021-09-17T08:05:48.975993Z","shell.execute_reply.started":"2021-09-17T08:05:48.959257Z","shell.execute_reply":"2021-09-17T08:05:48.974716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"13\"></a>\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\">13. Validating the Model using RMSE</div>","metadata":{}},{"cell_type":"code","source":"\"\"\"\nCreating subset of only Numerical Columns\n\"\"\"\nbase = ['engine_hp','engine_cylinders','highway_mpg', 'city_mpg', 'popularity']\n\ndef prepare_X(df):\n    df_num = df[base]\n    df_num = df_num.fillna(0)\n    X = df_num.values\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:48.977934Z","iopub.execute_input":"2021-09-17T08:05:48.978258Z","iopub.status.idle":"2021-09-17T08:05:48.987147Z","shell.execute_reply.started":"2021-09-17T08:05:48.978223Z","shell.execute_reply":"2021-09-17T08:05:48.986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = prepare_X(df_train)                            # Preparing Training set\n\n\"\"\"Building and Training the model on training set\"\"\"\nw0,w = w0, w = train_linear_regression(X_train,y_train)  # Building the model on Train set\n\n\"\"\"Prediction the values of Validation Set\"\"\"\nX_val = prepare_X(df_val)                                 # Preparing Validation Set\ny_pred = w0 + X_val.dot(w)                                # Prediction on Validation Set\n\n\"\"\"Evaluation on Validation set\"\"\"\nrmse(y_val, y_pred)                                       # Calculating RMSE for Validation Set ","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:48.989149Z","iopub.execute_input":"2021-09-17T08:05:48.989608Z","iopub.status.idle":"2021-09-17T08:05:49.018486Z","shell.execute_reply.started":"2021-09-17T08:05:48.989558Z","shell.execute_reply":"2021-09-17T08:05:49.016799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"14\"></a>\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\">14. Feature Engineering</div>","metadata":{}},{"cell_type":"code","source":"\"\"\"\nModifying prepare_S function to include Feature engineering step\n\"\"\"\ndef prepare_X(df):\n    df = df.copy()\n    df['age'] = max(df['year']) - df['year']\n    features = base + ['age']\n    df_num = df[features]\n    df_num = df_num.fillna(0)\n    X = df_num.values\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:49.024585Z","iopub.execute_input":"2021-09-17T08:05:49.025049Z","iopub.status.idle":"2021-09-17T08:05:49.033948Z","shell.execute_reply.started":"2021-09-17T08:05:49.024971Z","shell.execute_reply":"2021-09-17T08:05:49.032612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = prepare_X(df_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:49.036276Z","iopub.execute_input":"2021-09-17T08:05:49.036978Z","iopub.status.idle":"2021-09-17T08:05:49.058142Z","shell.execute_reply.started":"2021-09-17T08:05:49.036914Z","shell.execute_reply":"2021-09-17T08:05:49.056857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = prepare_X(df_train)                            # Preparing Training set\n\n\"\"\"Building and Training the model on training set\"\"\"\nw0,w = w0, w = train_linear_regression(X_train,y_train)  # Building the model on Train set\n\n\"\"\"Prediction the values of Validation Set\"\"\"\nX_val = prepare_X(df_val)                                 # Preparing Validation Set\ny_pred = w0 + X_val.dot(w)                                # Prediction on Validation Set\n\n\"\"\"Evaluation on Validation set\"\"\"\nrmse(y_val, y_pred)                                       # Calculating RMSE for Validation Set ","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:49.060354Z","iopub.execute_input":"2021-09-17T08:05:49.061048Z","iopub.status.idle":"2021-09-17T08:05:49.092608Z","shell.execute_reply.started":"2021-09-17T08:05:49.060923Z","shell.execute_reply":"2021-09-17T08:05:49.091067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\"\"\"Visualizing the Predictions\"\"\"\nsns.histplot(y_pred, color = 'red', alpha = 0.5, bins = 50)\nsns.histplot(y_val, color = 'blue', alpha = 0.5, bins = 50);","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:49.094596Z","iopub.execute_input":"2021-09-17T08:05:49.095192Z","iopub.status.idle":"2021-09-17T08:05:49.673307Z","shell.execute_reply.started":"2021-09-17T08:05:49.095138Z","shell.execute_reply":"2021-09-17T08:05:49.672351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"15\"></a>\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\">15. Categorical Variables</div>","metadata":{}},{"cell_type":"code","source":"\"\"\"Top 5 makers\"\"\"\nmakes = list(df['make'].value_counts().head().index)\nmakes","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:49.674835Z","iopub.execute_input":"2021-09-17T08:05:49.675223Z","iopub.status.idle":"2021-09-17T08:05:49.690292Z","shell.execute_reply.started":"2021-09-17T08:05:49.675176Z","shell.execute_reply":"2021-09-17T08:05:49.688922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nModifying prepare_S function for Creating new columns for number of doors\nMaking columns for top 5 makes of the cars\n\"\"\"\ndef prepare_X(df):\n    df = df.copy()\n    features = base.copy()\n     \n    df['age'] = max(df['year']) - df['year']    \n    features.append('age')\n    \n    \"\"\"Making Variables for number of Doors\"\"\"\n    for v in [2,3,4]:\n        df['num_doors_%s' %v] = (df['number_of_doors'] == v).astype('int') \n        features.append('num_doors_%s' %v)\n      \n    \"\"\"Making variables for top 5 makes\"\"\"\n    for m in makes:\n        df['make_%s' %m] = (df['make'] == m).astype('int') \n        features.append('make_%s' %m)\n        \n    df_num = df[features]\n    df_num = df_num.fillna(0)\n    X = df_num.values\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:49.691551Z","iopub.execute_input":"2021-09-17T08:05:49.691798Z","iopub.status.idle":"2021-09-17T08:05:49.702259Z","shell.execute_reply.started":"2021-09-17T08:05:49.69177Z","shell.execute_reply":"2021-09-17T08:05:49.700906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Preparing Training set\"\"\"\nX_train = prepare_X(df_train)                            # Preparing Training set\n\n\"\"\"Building and Training the model on training set\"\"\"\nw0,w = train_linear_regression(X_train,y_train)  # Building the model on Train set\n\n\"\"\"Prediction the values of Validation Set\"\"\"\nX_val = prepare_X(df_val)                                 # Preparing Validation Set\ny_pred = w0 + X_val.dot(w)                                # Prediction on Validation Set\n\n\"\"\"Evaluation on Validation set\"\"\"\nrmse(y_val, y_pred)                                       # Calculating RMSE for Validation Set ","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:49.70371Z","iopub.execute_input":"2021-09-17T08:05:49.703962Z","iopub.status.idle":"2021-09-17T08:05:49.777819Z","shell.execute_reply.started":"2021-09-17T08:05:49.703934Z","shell.execute_reply":"2021-09-17T08:05:49.776643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_variables = ['make','engine_fuel_type', 'transmission_type' , 'driven_wheels', 'market_category', \n'vehicle_size', 'vehicle_style' ]           ","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:49.77967Z","iopub.execute_input":"2021-09-17T08:05:49.780089Z","iopub.status.idle":"2021-09-17T08:05:49.786898Z","shell.execute_reply.started":"2021-09-17T08:05:49.780042Z","shell.execute_reply":"2021-09-17T08:05:49.785777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categories = {}\n\nfor c in categorical_variables:\n    categories[c] = list(df[c].value_counts().head().index)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:49.789661Z","iopub.execute_input":"2021-09-17T08:05:49.790584Z","iopub.status.idle":"2021-09-17T08:05:49.842589Z","shell.execute_reply.started":"2021-09-17T08:05:49.79052Z","shell.execute_reply":"2021-09-17T08:05:49.841542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categories.items()","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:49.844624Z","iopub.execute_input":"2021-09-17T08:05:49.845476Z","iopub.status.idle":"2021-09-17T08:05:49.853826Z","shell.execute_reply.started":"2021-09-17T08:05:49.845406Z","shell.execute_reply":"2021-09-17T08:05:49.852606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nModifying to include categorical variables \n\"\"\"\ndef prepare_X(df):\n    df = df.copy()\n    features = base.copy()\n     \n    df['age'] = max(df['year']) - df['year']    \n    features.append('age')\n    \n    \"\"\"Making Variables for number of Doors\"\"\"\n    for v in [2,3,4]:\n        df['num_doors_%s' %v] = (df['number_of_doors'] == v).astype('int') \n        features.append('num_doors_%s' %v)\n        \n    \"\"\"Making Variables for Categorical variables\"\"\"\n    for c,values in categories.items():\n        for v in values:\n            df[\"%s_%s\" %(c,v)] = (df[c] == v).astype('int') \n            features.append(\"%s_%s\" %(c,v))\n        \n    df_num = df[features]\n    df_num = df_num.fillna(0)\n    X = df_num.values\n    return X","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:49.856127Z","iopub.execute_input":"2021-09-17T08:05:49.856916Z","iopub.status.idle":"2021-09-17T08:05:49.870846Z","shell.execute_reply.started":"2021-09-17T08:05:49.856865Z","shell.execute_reply":"2021-09-17T08:05:49.869855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Preparing Training set\"\"\"\nX_train = prepare_X(df_train)                            # Preparing Training set\n\n\"\"\"Building and Training the model on training set\"\"\"\nw0,w = train_linear_regression(X_train,y_train)  # Building the model on Train set\n\n\"\"\"Prediction the values of Validation Set\"\"\"\nX_val = prepare_X(df_val)                                 # Preparing Validation Set\ny_pred = w0 + X_val.dot(w)                                # Prediction on Validation Set\n\n\"\"\"Evaluation on Validation set\"\"\"\nrmse(y_val, y_pred)                                       # Calculating RMSE for Validation Set ","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:49.873351Z","iopub.execute_input":"2021-09-17T08:05:49.87415Z","iopub.status.idle":"2021-09-17T08:05:50.09987Z","shell.execute_reply.started":"2021-09-17T08:05:49.874096Z","shell.execute_reply":"2021-09-17T08:05:50.098154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"16\"></a>\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\">16. Regularization</div>","metadata":{}},{"cell_type":"code","source":"def train_linear_regression_reg(X, y, r=0.001):\n    ones = np.ones(X.shape[0])\n    X = np.column_stack([ones, X])\n    \n    XTX = X.T.dot(X)\n    \"\"\"Adding Regularization term to the diagonals\"\"\"\n    XTX = XTX + r * np.eye(XTX.shape[0])\n    \n    XTX_inv = np.linalg.inv(XTX)\n    w_full = XTX_inv.dot(X.T).dot(y)\n    \n    return w_full[0], w_full[1:]","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:50.101189Z","iopub.execute_input":"2021-09-17T08:05:50.101761Z","iopub.status.idle":"2021-09-17T08:05:50.110827Z","shell.execute_reply.started":"2021-09-17T08:05:50.101711Z","shell.execute_reply":"2021-09-17T08:05:50.109895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Preparing X, Building, predicting and Evaluating model\"\"\"\nX_train = prepare_X(df_train)\nw0, w = train_linear_regression_reg(X_train, y_train, r=0.01)\n\nX_val = prepare_X(df_val)\ny_pred = w0 + X_val.dot(w)\nrmse(y_val, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:17:13.946218Z","iopub.execute_input":"2021-09-17T08:17:13.946968Z","iopub.status.idle":"2021-09-17T08:17:14.123117Z","shell.execute_reply.started":"2021-09-17T08:17:13.94693Z","shell.execute_reply":"2021-09-17T08:17:14.122072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"17\"></a>\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\">17. Tuning the Model</div>","metadata":{}},{"cell_type":"code","source":"\"\"\"\nTraining the model for different values of r: regularization term\n\"\"\"\nfor r in [0.0, 0.00001, 0.0001, 0.001, 0.1, 1, 10]:\n    X_train = prepare_X(df_train)\n    w0, w = train_linear_regression_reg(X_train, y_train, r=r)\n\n    X_val = prepare_X(df_val)\n    y_pred = w0 + X_val.dot(w)\n    score = rmse(y_val, y_pred)\n    \n    print(r, w0, score)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:50.381398Z","iopub.execute_input":"2021-09-17T08:05:50.381904Z","iopub.status.idle":"2021-09-17T08:05:52.062695Z","shell.execute_reply.started":"2021-09-17T08:05:50.381849Z","shell.execute_reply":"2021-09-17T08:05:52.061763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nSelecting the best r for training our model \n\"\"\"\nr = 0.001\nX_train = prepare_X(df_train)\nw0, w = train_linear_regression_reg(X_train, y_train, r=r)\n\nX_val = prepare_X(df_val)\ny_pred = w0 + X_val.dot(w)\nscore = rmse(y_val, y_pred)\nscore","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:05:58.509514Z","iopub.execute_input":"2021-09-17T08:05:58.509792Z","iopub.status.idle":"2021-09-17T08:05:58.723739Z","shell.execute_reply.started":"2021-09-17T08:05:58.509764Z","shell.execute_reply":"2021-09-17T08:05:58.722467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[back to top](#table-of-contents)\n<a id=\"18\"></a>\n<div style=\"background:#2b6684;color:white; font-family:'Goudy Old Style';padding:0.5em;border-radius:0.2em;font-size:30px;color:white\">18. Using the model</div>","metadata":{}},{"cell_type":"code","source":"\"\"\"Concatnating the datasets: train and valid\"\"\"\ndf_full_train = pd.concat([df_train, df_val])","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:13:58.963093Z","iopub.execute_input":"2021-09-17T08:13:58.963356Z","iopub.status.idle":"2021-09-17T08:13:58.976288Z","shell.execute_reply.started":"2021-09-17T08:13:58.963329Z","shell.execute_reply":"2021-09-17T08:13:58.97537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Full Train dataset with index dropped. As they are of no use.\"\"\"\ndf_full_train = df_full_train.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:14:07.031792Z","iopub.execute_input":"2021-09-17T08:14:07.032062Z","iopub.status.idle":"2021-09-17T08:14:07.042294Z","shell.execute_reply.started":"2021-09-17T08:14:07.032034Z","shell.execute_reply":"2021-09-17T08:14:07.041653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Creating X and y\"\"\"\nX_full_train = prepare_X(df_full_train)\ny_full_train = np.concatenate([y_train, y_val])","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:14:52.485332Z","iopub.execute_input":"2021-09-17T08:14:52.485659Z","iopub.status.idle":"2021-09-17T08:14:52.595071Z","shell.execute_reply.started":"2021-09-17T08:14:52.48562Z","shell.execute_reply":"2021-09-17T08:14:52.593966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Building model\"\"\"\nw0, w = train_linear_regression_reg(X_full_train, y_full_train, r=0.001)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:14:52.813661Z","iopub.execute_input":"2021-09-17T08:14:52.813938Z","iopub.status.idle":"2021-09-17T08:14:52.829974Z","shell.execute_reply.started":"2021-09-17T08:14:52.813911Z","shell.execute_reply":"2021-09-17T08:14:52.828966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Preparing X, Predicting and Evaluating model\"\"\"\nX_test = prepare_X(df_test)\ny_pred = w0 + X_test.dot(w)\nscore = rmse(y_test, y_pred)\nscore","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:15:11.047395Z","iopub.execute_input":"2021-09-17T08:15:11.047713Z","iopub.status.idle":"2021-09-17T08:15:11.108352Z","shell.execute_reply.started":"2021-09-17T08:15:11.047682Z","shell.execute_reply":"2021-09-17T08:15:11.107093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Checking our model on random car selected\"\"\"\ncar = df_test.iloc[20].to_dict()\ncar","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:15:13.610507Z","iopub.execute_input":"2021-09-17T08:15:13.611467Z","iopub.status.idle":"2021-09-17T08:15:13.618699Z","shell.execute_reply.started":"2021-09-17T08:15:13.611399Z","shell.execute_reply":"2021-09-17T08:15:13.61781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Making dataset out of given dictionary\"\"\"\ndf_small = pd.DataFrame([car])\ndf_small","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:15:31.30541Z","iopub.execute_input":"2021-09-17T08:15:31.306309Z","iopub.status.idle":"2021-09-17T08:15:31.323867Z","shell.execute_reply.started":"2021-09-17T08:15:31.306245Z","shell.execute_reply":"2021-09-17T08:15:31.323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Creating X\"\"\"\nX_small = prepare_X(df_small)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:15:38.741182Z","iopub.execute_input":"2021-09-17T08:15:38.741523Z","iopub.status.idle":"2021-09-17T08:15:38.781639Z","shell.execute_reply.started":"2021-09-17T08:15:38.741489Z","shell.execute_reply":"2021-09-17T08:15:38.780672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Predicting y\"\"\"\ny_pred = w0 + X_small.dot(w)\ny_pred = y_pred[0]\ny_pred","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:15:50.230294Z","iopub.execute_input":"2021-09-17T08:15:50.230605Z","iopub.status.idle":"2021-09-17T08:15:50.237404Z","shell.execute_reply.started":"2021-09-17T08:15:50.230577Z","shell.execute_reply":"2021-09-17T08:15:50.236542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Undoing Log by using exp\"\"\"\nnp.expm1(y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:15:57.871665Z","iopub.execute_input":"2021-09-17T08:15:57.871946Z","iopub.status.idle":"2021-09-17T08:15:57.878496Z","shell.execute_reply.started":"2021-09-17T08:15:57.8719Z","shell.execute_reply":"2021-09-17T08:15:57.877479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"Checking what was the real value of that car.\"\"\"\nnp.expm1(y_test[20])","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:16:05.850733Z","iopub.execute_input":"2021-09-17T08:16:05.851405Z","iopub.status.idle":"2021-09-17T08:16:05.856779Z","shell.execute_reply.started":"2021-09-17T08:16:05.851369Z","shell.execute_reply":"2021-09-17T08:16:05.856201Z"},"trusted":true},"execution_count":null,"outputs":[]}]}