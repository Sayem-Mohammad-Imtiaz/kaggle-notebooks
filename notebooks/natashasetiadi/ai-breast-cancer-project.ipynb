{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# here we will import the libraries used for machine learning\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL\nimport matplotlib.pyplot as plt # this is used for the plot the graph \nimport seaborn as sns # used for plot interactive graph. I like it most for plot\n%matplotlib inline\nfrom sklearn.linear_model import LogisticRegression # to apply the Logistic regression\nfrom sklearn.model_selection import train_test_split # to split the data into two parts\n# from sklearn.cross_validation import KFold # use for cross validation\nfrom sklearn.model_selection import GridSearchCV# for tuning parameter\nfrom sklearn.ensemble import RandomForestClassifier # for random forest classifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import svm # for Support Vector Machine\nfrom sklearn import metrics # for the check the error and accuracy of the model\n# Any results you write to the current directory are saved as output.\n# dont worry about the error if its not working then insteda of model_selection we can use cross_validation","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Import Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/breast-cancer-wisconsin-data/data.csv\", header=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.head(2))\n#data.head(2) = first two items in dataset\n#data.tail(2) = last two items in dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(\"Unnamed: 32\", axis=1, inplace=True)\ndata.drop(\"id\", axis=1, inplace=True)\n#gets rid of unnecessary data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_mean = list(data.columns[1:11])\nfeatures_se = list(data.columns[11:20])\nfeatures_worst=list(data.columns[21:31])\n#in the dataset with 32 types of data, we are saying the mean is from data column 2-11 and so on \nprint(features_mean)\nprint(\"----\")\nprint(features_se)\nprint(\"----\")\nprint(features_worst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B':0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(data['diagnosis'], label=\"Count\")\n#see number of malignant (0) and benign tumors (1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = data[features_mean].corr()\n#takes features and creates correlations between the data\nplt.figure(figsize=(14,14))\nsns.heatmap(corr, cbar=True, square = True, annot=True,fmt='.2f', annot_kws={'size': 15},\n            xticklabels = features_mean, yticklabels=features_mean,\n            cmap = 'coolwarm')\n#look up and research above, called Seabourne method?\n#red: more correlated, blue= less correlated\n#the features are features that have a high correlation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_var = ['texture_mean', 'perimeter_mean', 'smoothness_mean','compactness_mean', 'symmetry_mean']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = train_test_split(data, test_size = 0.3)\n#train_test_split returns splittinglist, length=2 * len(arrays) List containing train-test split of inputs.\n\n#first parameter: array of data, second parameter: test_size, a float between 0 and 1 that represents the proportion of the dataset to include in the test split\n#If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. \n#If train_size is also None, it will be set to 0.25. \n\nprint(train.shape)\nprint(test.shape)\nprint(\"adf\",train)\nprint(\"zcv\", test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X = train[prediction_var]\ntrain_Y = train.diagnosis\ntest_X = test[prediction_var]\ntest_Y = test.diagnosis\n\nprint(\"adf\",train_X)\nprint(\"ggg\", train_Y)\nprint(\"zcv\", test_X)\nprint(\"lll\",test_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest Classifier\nmodel = RandomForestClassifier(n_estimators = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_X, train_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(test_X)\nprint(prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.accuracy_score(prediction, test_Y)\n#how accurate our prediction was","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Support Vector Machine\nmodel = svm.SVC()\nmodel.fit(train_X, train_Y)\nprediction = model.predict(test_X)\nprint(prediction)\nmetrics.accuracy_score(prediction, test_Y)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Worst Features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_var = features_worst\ntrain_X = train[prediction_var]\ntrain_Y = train.diagnosis\ntest_X = test[prediction_var]\ntest_Y = test.diagnosis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest Classifier\nmodel = RandomForestClassifier(n_estimators = 100)\nmodel.fit(train_X, train_Y)\nprediction = model.predict(test_X)\nprint(prediction)\nmetrics.accuracy_score(prediction, test_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Support Vector Machine\nmodel = svm.SVC()\nmodel.fit(train_X, train_Y)\nprediction = model.predict(test_X)\nprint(prediction)\nmetrics.accuracy_score(prediction, test_Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Select worse features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_var = ['concave points_worst', 'radius_worst', 'area_worst', 'perimeter_worst', 'concavity_worst']\ntrain_X = train[prediction_var]\ntrain_Y = train.diagnosis\ntest_X = test[prediction_var]\ntest_Y = test.diagnosis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Random Forest Classifier\nmodel = RandomForestClassifier(n_estimators = 100)\nmodel.fit(train_X, train_Y)\nprediction = model.predict(test_X)\nprint(prediction)\nmetrics.accuracy_score(prediction, test_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Support Vector Machine\nmodel = svm.SVC()\nmodel.fit(train_X, train_Y)\nprediction = model.predict(test_X)\nprint(prediction)\nmetrics.accuracy_score(prediction, test_Y)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}