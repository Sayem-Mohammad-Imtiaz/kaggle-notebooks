{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction\n\nIn this notebook, we will be looking at one of the most important steps in building a machine learning model - **Feature Selection**. How we select our features from the dataset will determine how accurate the model will be when trained and being tested.\n\nWe will use some statistical tests like Chi-square to select features which will only improve our model.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.feature_selection import chi2, SelectKBest\nfrom sklearn.ensemble import RandomForestClassifier\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-21T12:10:12.915385Z","iopub.execute_input":"2021-08-21T12:10:12.915749Z","iopub.status.idle":"2021-08-21T12:10:12.921277Z","shell.execute_reply.started":"2021-08-21T12:10:12.91572Z","shell.execute_reply":"2021-08-21T12:10:12.920027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load and Prepare the Dataset","metadata":{}},{"cell_type":"code","source":"# Load the data\n\ndata = pd.read_csv('../input/mobile-price-classification/train.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-21T11:54:43.22909Z","iopub.execute_input":"2021-08-21T11:54:43.229528Z","iopub.status.idle":"2021-08-21T11:54:43.295825Z","shell.execute_reply.started":"2021-08-21T11:54:43.229493Z","shell.execute_reply":"2021-08-21T11:54:43.294755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into features and target variables\n\nX = data.iloc[:, :-1]\ny = data.iloc[:, -1]","metadata":{"execution":{"iopub.status.busy":"2021-08-21T11:56:50.107741Z","iopub.execute_input":"2021-08-21T11:56:50.108188Z","iopub.status.idle":"2021-08-21T11:56:50.114291Z","shell.execute_reply.started":"2021-08-21T11:56:50.108139Z","shell.execute_reply":"2021-08-21T11:56:50.113294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compare and Select N-best features using SelectKBest","metadata":{}},{"cell_type":"code","source":"# Call the constructor to select 10 best features according to their Chi-square tests against the target variable\nbest_features = SelectKBest(score_func=chi2, k = 10)\n\nfit = best_features.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:01:41.555376Z","iopub.execute_input":"2021-08-21T12:01:41.555722Z","iopub.status.idle":"2021-08-21T12:01:41.565546Z","shell.execute_reply.started":"2021-08-21T12:01:41.555694Z","shell.execute_reply":"2021-08-21T12:01:41.564358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chi_scores = pd.DataFrame(fit.scores_)\ncolumns = pd.DataFrame(X.columns)\n\nfeatureScores = pd.concat([columns, chi_scores], axis = 1)\nfeatureScores.columns = ['Feature', 'Score']\n\nfeatureScores.sort_values(by = 'Score', ascending = False)","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:05:17.008143Z","iopub.execute_input":"2021-08-21T12:05:17.008654Z","iopub.status.idle":"2021-08-21T12:05:17.02463Z","shell.execute_reply.started":"2021-08-21T12:05:17.008624Z","shell.execute_reply":"2021-08-21T12:05:17.023782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see from the above DataFrame and from our own experience, the RAM for a smartphone is the most significant feature to determine its price range. Also, some really good indicators are: dimensions of the phone, battery power, and its internal memory.","metadata":{}},{"cell_type":"markdown","source":"## Feature Importance\n\nAnother techinque which we will be using is the feature importance. Here, we will be using a tree-based model to assign an importance to each of the feature in the dataset.","metadata":{}},{"cell_type":"code","source":"# Initialize a RandomForestClassifier model and fit our dataset\nmodel = RandomForestClassifier()\nmodel.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:10:58.69619Z","iopub.execute_input":"2021-08-21T12:10:58.696538Z","iopub.status.idle":"2021-08-21T12:10:59.211415Z","shell.execute_reply.started":"2021-08-21T12:10:58.69651Z","shell.execute_reply":"2021-08-21T12:10:59.210278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# From this model, we get importance scores for each feature\nmodel.feature_importances_","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:11:30.254834Z","iopub.execute_input":"2021-08-21T12:11:30.255524Z","iopub.status.idle":"2021-08-21T12:11:30.273323Z","shell.execute_reply.started":"2021-08-21T12:11:30.255485Z","shell.execute_reply":"2021-08-21T12:11:30.272053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featureImp = pd.DataFrame(model.feature_importances_, index = X.columns, columns = ['Importance'])\nfeatureImp = featureImp.sort_values(by = 'Importance', ascending = False)\nfeatureImp","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:14:57.20046Z","iopub.execute_input":"2021-08-21T12:14:57.200823Z","iopub.status.idle":"2021-08-21T12:14:57.230275Z","shell.execute_reply.started":"2021-08-21T12:14:57.200793Z","shell.execute_reply":"2021-08-21T12:14:57.228888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again, we get similar result from the model also. RAM is the most important feature for determining the price range of any mobile.","metadata":{}},{"cell_type":"code","source":"# Let's plot the importance score for the features\nplt.figure(figsize = (10, 5))\nplt.xticks(rotation = 90)\nplt.bar(featureImp.index, featureImp['Importance'])","metadata":{"execution":{"iopub.status.busy":"2021-08-21T12:16:26.077103Z","iopub.execute_input":"2021-08-21T12:16:26.077557Z","iopub.status.idle":"2021-08-21T12:16:26.376587Z","shell.execute_reply.started":"2021-08-21T12:16:26.07752Z","shell.execute_reply":"2021-08-21T12:16:26.375072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above plot, we can see that after a fwe features, there isn't much importance left and we can select the first 4-5 features and our model will be sufficiently accurate.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}