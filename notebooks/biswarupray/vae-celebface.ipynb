{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom collections import Counter\nimport glob\nimport pickle\nimport tensorflow\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Lambda, Dense, Dropout, Activation, Flatten, Input, Reshape\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, UpSampling2D\nfrom mpl_toolkits.axes_grid1 import AxesGrid\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.losses import mse, binary_crossentropy\nfrom tensorflow.keras.optimizers import SGD, Adam\nimport random\nfrom random import shuffle\nimport skimage\nimport random\nfrom skimage.io import imread\n\ntrain = True\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading the images of the dataset with their attributes"},{"metadata":{"trusted":true},"cell_type":"code","source":"pic_size = 64\ndef load_data_set(df, n):\n    pics, labels = [], []\n    i = 0\n    for pic in df['image_id']:\n        if i > n:\n            break\n        else:\n            i+=1\n        pic_url = \"../input/celeba-dataset/img_align_celeba/img_align_celeba/\"+pic\n        temp = cv2.imread(pic_url)\n        temp = cv2.resize(temp, (pic_size,pic_size)).astype('float32') / 255.\n        pics.append(temp)\n        labels.append(df[df['image_id'] == pic].values)\n    X = np.array(pics)\n    y = np.array(labels)\n    y = y.reshape(y.shape[0], y.shape[2])\n    print(\"Data set\", X.shape, y.shape)\n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\n\nattr = pd.read_csv(\"../input/celeba-dataset/list_attr_celeba.csv\")\nattr.head()\nfeature_dict = {k:v for v,k in enumerate(attr.columns)}\nn = 10000\nX, y = load_data_set(attr, n)\n\nprint(feature_dict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Displaying 3 random images with their attributes from the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_sample_image(nb=3, df=attr, verbose=True):\n    f, ax = plt.subplots(1, nb, figsize=(10,5))\n    for i in range(nb):\n        idx = random.randint(0, df.shape[0]-1)\n        img_id = df.loc[idx].image_id\n        img_uri = '../input/celeba-dataset/img_align_celeba/img_align_celeba/' + img_id\n        img = skimage.io.imread(img_uri)  \n        if verbose:\n            label = img_id\n            for col in df.columns:\n                if df.loc[idx][col]==1:\n                    label = label + '\\n' + col  \n            if nb > 1:\n                ax[i].imshow(img)\n                ax[i].set_title(label)\n            else:\n                ax.imshow(img) \n                ax.set_title(label)\n        \n    return img, list(df.loc[idx][1:df.shape[1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_img, sample_img_meta = show_sample_image()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating batches of the large dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to create batches of the large dataset\ndef sampling(args):\n    \"\"\"Reparameterization function by sampling from an isotropic unit Gaussian.\n    # Arguments:\n        args (tensor): mean and log of variance of Q(z|X)\n    # Returns:\n        z (tensor): sampled latent vector\n    \"\"\"\n\n    z_mean, z_log_var = args\n    batch = K.shape(z_mean)[0]\n    dim = K.int_shape(z_mean)[1]\n    # by default, random_normal has mean=0 and std=1.0\n    epsilon = K.random_normal(shape=(batch, dim))\n    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building the VAE"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_VAE(input_shape):\n    #CREATING THE VAE NETWORK\n    image_size = input_shape[1]\n    original_dim = image_size * image_size\n    inputs = Input(shape=input_shape)\n    print(inputs.shape)\n    x = Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n    print(x.shape)\n    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    x = AveragePooling2D(pool_size=(2, 2))(x)\n    print(x.shape)\n    x = Dropout(0.2)(x)\n    \n    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    x = AveragePooling2D(pool_size=(2, 2))(x)\n    print(x.shape)\n    x = Dropout(0.2)(x)\n    \n    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    x = AveragePooling2D(pool_size=(2, 2))(x)\n    print(x.shape)\n    x = Dropout(0.2)(x)\n    \n    x = Flatten()(x)\n    print(x.shape)\n    x = Dense(pic_size, activation='relu')(x)\n    print(x.shape)\n    \n    latent_dim = 20\n    \n    latent_mean = Dense(latent_dim)(x)\n    print(latent_mean.shape)\n    latent_log_variance = Dense(latent_dim)(x)\n    print(latent_log_variance.shape)\n    \n    latent_sample = Lambda(sampling)([latent_mean, latent_log_variance])\n    print(latent_sample.shape)\n    \n    #BUILDING THE ENCODER\n    encoder = Model(inputs, [latent_mean, latent_log_variance, latent_sample])\n    \n    latent_inputs = Input(shape=(latent_dim,))\n    print(latent_inputs.shape)\n    x = Dense(8*8*pic_size, activation='relu')(latent_inputs)\n    print(x.shape)\n    x = Reshape((8,8,pic_size))(x)\n    print(x.shape)\n    x = UpSampling2D((2, 2))(x)\n    print(x.shape)\n    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    \n    x = UpSampling2D((2, 2))(x)\n    print(x.shape)\n    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    \n    x = UpSampling2D((2, 2))(x)\n    print(x.shape)\n    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n    print(x.shape)\n   \n    # Outputs for the encoder by a sigmoid activation function\n    outputs = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n    print(outputs.shape)\n    \n    #BUILDING THE DECODER\n    decoder = Model(latent_inputs, outputs)\n    \n    # The outputs of the decoder are taken as the inputs of the encoder\n    outputs = decoder(encoder(inputs)[2])\n    vae = Model(inputs, outputs)\n    \n    # The losses of the VAE model is taken as the sum of the (binary cross entropy *dimensions) and the kl divergence loss\n    reconstruction_loss = binary_crossentropy(inputs, outputs) * original_dim\n    reconstruction_loss = K.mean(reconstruction_loss)\n    print(reconstruction_loss)\n    \n    kl_loss = 1 + latent_log_variance - K.square(latent_mean) - K.exp(latent_log_variance)\n    kl_loss = K.sum(kl_loss, axis=-1)\n    kl_loss *= -0.5\n    print(kl_loss)\n    vae_loss = K.mean(reconstruction_loss + kl_loss)\n    print(vae_loss)\n    vae.add_loss(vae_loss)\n    return vae, encoder, decoder","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating the vae model with Adam Optimizer for accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"vae, encoder, decoder = create_VAE(input_shape=(pic_size,pic_size,3))\nvae.compile(optimizer='adam', metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"if train:\n    epochs = 100\n    for i in range(0,epochs):\n        print(i)\n        vae.fit(X, batch_size=32, epochs=1, verbose = 0)\n        vae.save_weights(\"CELEBVAE.tf\")\n        encoder.save_weights(\"CELEBVAEE.tf\")\n        decoder.save_weights(\"CELEBVAED.tf\")\n    vae.fit(X, batch_size=32, epochs=1, verbose = 1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Displaying an image with its vae generated image"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\nimage_test = X[6]\nimage_reconstruction = vae.predict(np.expand_dims(image_test, axis = 0))[0]\n\nz = np.array(encoder.predict(X)[2])\n\npca = PCA(n_components=20).fit(z)\nz_pca = pca.transform(z)\nz_female = z_pca[y[:,feature_dict['Male']] == -1]\nz_avg_female_pca = np.mean(z_female, axis = 0)\nX_avg_female = decoder.predict(np.expand_dims(pca.inverse_transform(z_avg_female_pca), axis = 0))[0]\n\nz_male = z_pca[y[:,feature_dict['Male']] == 1]\nz_avg_male_pca = np.mean(z_male, axis = 0)\nX_avg_male = decoder.predict(np.expand_dims(pca.inverse_transform(z_avg_male_pca), axis = 0))[0]\n\nz_glasses = z_pca[y[:,feature_dict['Eyeglasses']] == 1]\nz_avg_glasses_pca = np.mean(z_glasses, axis = 0)\nX_avg_glasses = decoder.predict(np.expand_dims(pca.inverse_transform(z_avg_glasses_pca), axis = 0))[0]\n\nz_not_glasses = z_pca[y[:,feature_dict['Eyeglasses']] == -1]\nz_avg_not_glasses_pca = np.mean(z_not_glasses, axis = 0)\n\nz_reconstruction_w_glasses_pca = z_pca[6] + z_avg_glasses_pca - z_avg_not_glasses_pca\nX_reconstruction_w_glasses = decoder.predict(np.expand_dims(pca.inverse_transform(z_reconstruction_w_glasses_pca), axis = 0))[0]\n\nz_reconstruction_not_man_pca = z_pca[6] - z_avg_male_pca\nX_reconstruction_not_man_pca = decoder.predict(np.expand_dims(pca.inverse_transform(z_reconstruction_not_man_pca), axis = 0))[0]\n\nz_reconstruction_woman_pca = z_reconstruction_not_man_pca + z_avg_female_pca\nX_reconstruction_woman_pca = decoder.predict(np.expand_dims(pca.inverse_transform(z_reconstruction_woman_pca), axis = 0))[0]\n\nfig  = plt.figure(figsize=(20,20))\n\nplt.subplot(2,4,1)\nplt.imshow(cv2.cvtColor(image_test, cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,2)\nplt.imshow(cv2.cvtColor(image_reconstruction, cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,3)\nplt.imshow(cv2.cvtColor(X_avg_female, cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,4)\nplt.imshow(cv2.cvtColor(X_avg_male, cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,5)\nplt.imshow(cv2.cvtColor(X_avg_glasses, cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,6)\nplt.imshow(cv2.cvtColor(X_reconstruction_w_glasses, cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,7)\nplt.imshow(cv2.cvtColor(X_reconstruction_not_man_pca, cv2.COLOR_BGR2RGB))\nplt.subplot(2,4,8)\nplt.imshow(cv2.cvtColor(X_reconstruction_woman_pca, cv2.COLOR_BGR2RGB))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vae.save_weights(\"CELEBVAE.tf\")\nencoder.save_weights(\"CELEBVAEE.tf\")\ndecoder.save_weights(\"CELEBVAED.tf\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}