{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Trump Tweet Ananlysis\n## Table of content\n* 1.Reading csv\n* 2.Preprocessing\n    * 2.1 Extracting the year,month,dates,hour,minute,second from date coloumn\n    * 2.2 Removing tag names from tweets\n    * 2.3 preprocessing of tweet text\n* 3.Most active hour on twitter\n* 4. Number of tweet \n* 5.Average number of tweet in a day\n* 6.Most retweeted tweet\n* 7.Most Like tweets\n* 8.Most liked tweet durning Presidential year\n* 9.Most retweeted tweet durning presidential year\n* 10.Word priority\n  * 10.1 Business year\n  * 10.2 compain year\n  * 10.3 presidential year"},{"metadata":{},"cell_type":"markdown","source":"### 1. Reading csv"},{"metadata":{"colab":{},"colab_type":"code","id":"UfQcn_s9rc28","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n#ignore warning messages\nimport warnings\nwarnings.filterwarnings('ignore')\nimport plotly\nplotly.offline.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom wordcloud import WordCloud\ndf= pd.read_csv(\"../input/trump-tweets/trumptweets.csv\")","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":632},"colab_type":"code","id":"VA_95iUmsEpR","outputId":"0307eeb2-54d1-4bae-8e73-7d774d83f23a","trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"JTmkl08uwGP3","trusted":true},"cell_type":"code","source":"df.drop(['id','link'],axis=1,inplace=True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"#### 2.1 Extracting the year,month,dates,hour,minute,second from date coloumn"},{"metadata":{"colab":{},"colab_type":"code","id":"p4iHYcpQCgOD","trusted":true},"cell_type":"code","source":"year=[]\nmonth=[]\ndate=[]\nhour=[]\nminute=[]\nsecond=[]\nfor x in df['date']:\n    year.append(int(x.split(\"-\")[0]))\n    month.append(int(x.split(\"-\")[1]))\n    date.append(int(x.split(\"-\")[2].split(\" \")[0]))\n    hour.append(int(x.split(\"-\")[2].split(\" \")[1].split(\":\")[0]))\n    minute.append(int(x.split(\"-\")[2].split(\" \")[1].split(\":\")[1]))\n    second.append(int(x.split(\"-\")[2].split(\" \")[1].split(\":\")[2]))\n\ndf['year']=year\ndf['month']=month\ndf['dates']=date\ndf['hour']=hour\ndf['minute']=minute\ndf['second']=second\ndf.drop(['date'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.2. Removing tag names from tweets"},{"metadata":{"colab":{},"colab_type":"code","id":"w2rO7EptHkaE","trusted":true},"cell_type":"code","source":"import re\ncontent=[]\nfor tweet in df[\"content\"]:\n    content.append(re.sub('\\@\\S+','',tweet))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2.3 preprocessing of tweet text\n* remove url"},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading stop words from nltk library\nimport nltk\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\ndef preprocessing(total_text, index, column):\n    if type(total_text) is not int:\n        string = \"\"\n        #Removing link\n        url_pattern = r'((http|ftp|https):\\/\\/)?[\\w\\-_]+(\\.[\\w\\-_]+)+([\\w\\-\\.,@?^=%&amp;:/~\\+#]*[\\w\\-\\@?^=%&amp;/~\\+#])?'\n        total_text = re.sub(url_pattern, ' ', total_text)\n        # replace every special char with space\n        #total_text = re.sub('[^a-zA-Z0-9\\n]', ' ', total_text)\n        # replace multiple spaces with single space\n        total_text = re.sub('\\s+',' ', total_text)\n        #total_text=total_text.replace('realdonaldtrump','').replace('donald','').replace('trump','')\n        # converting all the chars into lower-case.\n        total_text = total_text.lower()\n        \n        for word in total_text.split():\n        # if the word is a not a stop word then retain that word from the data\n            if not word in stop_words:\n                word=(word)\n                string += word + \" \"\n        \n        df[column][index] = string\n\nfor index, row in df.iterrows():\n    if type(row['content']) is str:\n        preprocessing(row['content'], index, 'content')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### 3. Most active hour on twitter"},{"metadata":{"trusted":true},"cell_type":"code","source":"Category=df['hour'].value_counts().sort_index()\ndata = [go.Pie(\n        labels = Category.index,\n        values = Category.values,\n        hoverinfo = 'label+value',\n)]\nplotly.offline.iplot(data, filename='active_category')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Number of tweet "},{"metadata":{"trusted":true},"cell_type":"code","source":"year_country = df['year'].value_counts().reset_index(name='counts')\n\nfig = px.bar(year_country, x='index', y='counts',\n             hover_data=['index', 'counts'], color='counts',\n             labels={'label':'year v/s number'}, height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.Average number of tweet in a day per year"},{"metadata":{"trusted":true},"cell_type":"code","source":"Category=(df['year'].value_counts()/365).sort_index()\nCategory\n\nfrom plotly.subplots import make_subplots\ntrace1=go.Scatter(x=Category.index,y=Category.values,mode='lines+markers',name='average tweet in a day')\ndata=[trace1]\nlayout = go.Layout(title=\"\", height=500,width=900, legend=dict(x=0.1, y=1.1))\nfig = go.Figure(data,layout=layout)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6.Most retweeted tweet"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.iloc[df['retweets'].idxmax()]['content'])\nprint(df.iloc[df['retweets'].idxmax()]['year'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 7.Most Like tweets "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.iloc[df['favorites'].idxmax()]['content'])\nprint(df.iloc[df['favorites'].idxmax()]['year'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8.Most tag names from tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nimport re\nmention_df=df.dropna(subset=[\"mentions\"])\nmentions=[]\nfor x in mention_df[\"mentions\"]:\n    x=x.replace(\"@\",\"\")\n    #x=re.sub(r'[\\s]+',' ',)\n    if not x.strip()==\"\":\n        mentions.append(x)\n\nTop_ten_mentions=Counter(mentions).most_common(10)\n\nname=[]\nnumber=[]\nfor x in Top_ten_mentions:\n    name.append(x[0])\n    number.append(x[1])\n\nfig = go.Figure(data=[go.Bar(x=name, y=number)])\n\nfig.update_traces(marker_color='rgb(158,202,225)', marker_line_color='rgb(8,48,107)',\n                  marker_line_width=1.5, opacity=0.6)\nfig.update_layout(title_text='Number v/s name mentions')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 9.Most liked tweet durning Presidential year"},{"metadata":{"trusted":true},"cell_type":"code","source":"president_date=president_year=df[((df['year']>=2017) &(df['month']>1))]\nprint(df.iloc[president_date['favorites'].idxmax()]['content'])\nprint(df.iloc[president_date['favorites'].idxmax()]['year'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 10.Most retweeted tweet durning presidential year"},{"metadata":{"trusted":true},"cell_type":"code","source":"president_date=president_year=df[((df['year']>=2017) &(df['month']>1))]\nprint(df.iloc[president_date['retweets'].idxmax()]['content'])\nprint(df.iloc[president_date['retweets'].idxmax()]['year'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 11.Word priority"},{"metadata":{},"cell_type":"markdown","source":"#### 11.1 Durning Business Year"},{"metadata":{"trusted":true},"cell_type":"code","source":"business_year=df[((df['year']<=2017))]\nfrom sklearn.feature_extraction.text import CountVectorizer\nvec = CountVectorizer().fit(business_year['content'])\nbag_of_words = vec.transform(business_year['content'])\nsum_words = bag_of_words.sum(axis=0) \nwords_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\nwords_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\nimport squarify\n\ny =dict(words_freq[:30])\n\nfig = plt.figure(figsize=(15, 15))\nsquarify.plot(sizes = y.values(), label = y.keys(), color=sns.color_palette(\"RdGy\", n_colors=20),\n             linewidth=4, text_kwargs={'fontsize':14, 'fontweight' : 'bold'})\nplt.title('Top 30 words', position=(0.5, 1.0+0.03), fontsize = 20, fontweight='bold')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 11.2 Durning election campaign"},{"metadata":{"colab":{},"colab_type":"code","id":"ctFxj1I9GybH","trusted":true},"cell_type":"code","source":"compain_year=df[(df['year'] == 2016) & (df['month'] >5) | (df['year'] == 2017) &(df['month']==1)]\nfrom sklearn.feature_extraction.text import CountVectorizer\nvec = CountVectorizer().fit(compain_year['content'])\nbag_of_words = vec.transform(compain_year['content'])\nsum_words = bag_of_words.sum(axis=0) \nwords_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\nwords_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\nimport squarify\n\ny =dict(words_freq[:30])\n\nfig = plt.figure(figsize=(15, 15))\nsquarify.plot(sizes = y.values(), label = y.keys(), color=sns.color_palette(\"RdGy\", n_colors=20),\n             linewidth=4, text_kwargs={'fontsize':14, 'fontweight' : 'bold'})\nplt.title('Top 30 words', position=(0.5, 1.0+0.03), fontsize = 20, fontweight='bold')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 11.3 Durning presidentail year"},{"metadata":{"trusted":true},"cell_type":"code","source":"president_year=df[((df['year']>=2017) &(df['month']>1))]\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nvec = CountVectorizer().fit(president_year['content'])\nbag_of_words = vec.transform(president_year['content'])\nsum_words = bag_of_words.sum(axis=0) \nwords_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\nwords_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\nimport squarify\n\ny =dict(words_freq[:30])\n\nfig = plt.figure(figsize=(15, 15))\nsquarify.plot(sizes = y.values(), label = y.keys(), color=sns.color_palette(\"RdGy\", n_colors=20),\n             linewidth=4, text_kwargs={'fontsize':14, 'fontweight' : 'bold'})\nplt.title('Top 30 words', position=(0.5, 1.0+0.03), fontsize = 20, fontweight='bold')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"trump tweet.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}