{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Libraries ","metadata":{}},{"cell_type":"code","source":"#import module\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nimport warnings\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/students-performance-in-exams/StudentsPerformance.csv\")\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"mean_scores\"] = (data[\"math score\"] + data[\"reading score\"] + data[\"writing score\"]) / 3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There is no missing value so I want to look statistical information with describe()\ndata.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe().T\n# data is distributed as normally but,\n# math score has 0 point cause math is harder than other all the time.\n# when I look the data, I can see min exam_score is 27.\n# Values of mean and 50% is so close.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.corr()\n# I want to look before I do get_dummies","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# I did that to see histogram plot and distribution of exam_scores\n\ndef histogramPlot(variable):\n    variable.plot(kind = \"hist\", density = True, bins = 15)\n    variable.plot(kind = \"kde\");\n\nif __name__=='__main__':\n    histogramPlot(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def groupbyFunc(data, feature):\n    # The function that you can use to analyze the mean of the features you have given and their situation in the data.\n    values = data[feature].value_counts()\n    feature_analysis = data.groupby(feature).mean()\n    return values,feature_analysis    \n    \n    \n# Firstly\ngroupbyFunc(data, \"parental level of education\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### I can say: when parents of the student were graduated the master degree and bachelor degree, students are better at lessons","metadata":{}},{"cell_type":"code","source":"# Secondly\ngroupbyFunc(data, \"race/ethnicity\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lastly\ngroupbyFunc(data, \"gender\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I have to drop values of outlier scores to take a better rmse value.\nsns.boxplot( y = data[\"math score\"])\nplt.show()\n\nsns.boxplot(y = data[\"reading score\"] )\nplt.show()\n\n\nsns.boxplot(y = data[\"writing score\"])\nplt.show()\n\nsns.boxplot(y = data[\"mean_scores\"])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def drop_outliers(df,column_name,lower,upper):\n    drop_outliers = df[column_name].between(df[column_name].quantile(lower), df[column_name].quantile(upper))\n    \n    print(str(df[column_name][drop_outliers].size) + \"/\" + str(df[column_name].size) + \" data points remain.\") \n\n    index_names = df[~drop_outliers].index\n    return df.drop(index_names)\n\n\nnew_data = drop_outliers(data,\"mean_scores\",0.05,0.95) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"data:\",data.shape)\nprint(\"new_data:\", new_data.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"math_score = new_data[\"math score\"]\nreading_score = new_data[\"reading score\"]\nwriting_score = new_data[\"writing score\"]\nmean_score = new_data[\"mean_scores\"]\nX_features = new_data.drop([\"math score\",\"reading score\",\"writing score\",\"mean_scores\"],axis = 'columns')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get Dummy Function\n","metadata":{}},{"cell_type":"code","source":"X_features.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_features_encoded = X_features.apply(lambda x: x.astype('category')) \n\nX_features_encoded = pd.get_dummies(X_features_encoded,drop_first= True)\nX_features_encoded.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Test","metadata":{}},{"cell_type":"code","source":"target = mean_score\nX_train, X_val, y_train, y_val = train_test_split(X_features_encoded, \n                                                      target, \n                                                      test_size=0.4, \n                                                      shuffle = True, \n                                                      random_state=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"code","source":"# true ---> real     predicted---> predict\ndef calculateModel(real, predict):\n    rmse = np.sqrt(mean_squared_error(real, predict))\n    r2 = r2_score(real, predict)\n    print(\"rmse:\",rmse)\n    print(\"r2 score:\",r2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RMSE","metadata":{}},{"cell_type":"code","source":"## Random Forest and Linear Model that I tried to calculate model\nprint(\"Random Forest Regressor\")\nprint(\"------------\")\nrf = RandomForestRegressor(random_state=0).fit(X_train, y_train)\nrf_pred = rf.predict(X_train)\nprint(\"Train set of RF\")\ncalculateModel(y_train,rf_pred)\n\nprint(\"------------\")\nprint(\"Test set of RF\")\nrf_pred_val= rf.predict(X_val)\ncalculateModel(y_val,rf_pred_val)\n\nprint(\"------------\")\n\n\nprint(\"Linear Regression\")\nprint(\"------------\")\nlr = LinearRegression(normalize=True).fit(X_train, y_train)\nlr_pred = lr.predict(X_train)\nprint(\"Train set of LR\")\ncalculateModel(y_train,lr_pred)\n\nprint(\"------------\")\nprint(\"Test set of LR\")\nlr_pred_val= lr.predict(X_val)\ncalculateModel(y_val,lr_pred_val)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}