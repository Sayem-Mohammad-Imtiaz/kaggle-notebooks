{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Will it rain or won't it rain? I gotta know so I know how to dress!!**"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option(\"display.max_columns\",100)\npd.set_option(\"display.max_rows\",120)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nparams={\"figure.facecolor\":(0.0,0.0,0.0,0),\n        \"axes.facecolor\":(1.0,1.0,1.0,1),\n        \"savefig.facecolor\":(0.0,0.0,0.0,0)}\nplt.rcParams.update(params)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report,roc_auc_score,roc_curve,confusion_matrix\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/weather-dataset-rattle-package/weatherAUS.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check our data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 142193 readings and 23 columns, of which *RainTomorrow* is our target variable. We also have a mixture of numerical and categorical variables, and some missing values (which we shall tackle when we split the data into the training and testing sets).\n\nFirst let's see view our target variable ***RainTomorrow***:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"RainTomorrow\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df[\"RainTomorrow\"],palette=[\"lightcoral\",\"skyblue\"])\nplt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"RainTomorrow\"]=df[\"RainTomorrow\"].apply(lambda x:0 if x==\"No\" else 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's go through and check the values for each feature. We will start with the numerical features:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().drop([\"RainTomorrow\"],axis=1).T","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"for column in df.select_dtypes(exclude=\"object\").drop([\"RainTomorrow\"],axis=1).columns:\n    print(column,\":\",df[column].isnull().sum(),\"missing values.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Quite a number of missing values, which we will impute after we split the data.\n\nFor numerical features, it is important to remove any outliers to improve model's performance."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axes=plt.subplots(1,2,figsize=(12,5))\n\ndf[df.select_dtypes(exclude=\"object\").columns.drop([\"Pressure9am\",\"Pressure3pm\",\"RainTomorrow\"])].plot(kind=\"box\",color=\"#AE9CCD\",ax=axes[0])\naxes[0].set_xticklabels(axes[0].get_xticklabels(),rotation=90)\naxes[0].set_ylabel(\"Measurement\")\n\ndf[[\"Pressure9am\",\"Pressure3pm\"]].plot(kind=\"box\",color=\"#AE9CCD\",ax=axes[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above boxplots, we have quite a number of outliers outside 1.5 times the interquartile range. But because there are no real bounds for weather data, i.e. due to extreme weather events, we will not be removing all of these outliers. If we do we will be creating a perfect dataset that won't properly reflect real world weather. Instead let's just further examine the outliers of the outliers in *Rainfall*, *Evaporation* and *WindSpeed9am*:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axes=plt.subplots(1,3,figsize=(15,4))\n\nsns.distplot(df[\"Rainfall\"],bins=12,color=\"lightskyblue\",ax=axes[0])\nsns.distplot(df[\"Evaporation\"],bins=12,color=\"lightcoral\",ax=axes[1])\nsns.distplot(df[\"WindSpeed9am\"],bins=12,color=\"lightgreen\",ax=axes[2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although it is possible to achieve these amounts of rainfall, evaporation and wind speed - for example in a storm or heatwave event - we remove them from the dataset so the model doesn't think these extreme weather events are common."},{"metadata":{"trusted":true},"cell_type":"code","source":"droppers=df.loc[(df[\"Rainfall\"]>300)|(df[\"Evaporation\"]>100)|(df[\"WindSpeed9am\"]>100)]\ndf.drop(droppers.index,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"We have dropped {num1} rows, so now instead of the initial 142193 readings, we have {num2}.\".format(num1=142193-df.shape[0],num2=df.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's continue with the categorical features:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.select_dtypes(include=\"object\").describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For categorical features, it is important to check the actual categories and change the format into numbers. Remember we will only impute the missing data after we split the data."},{"metadata":{},"cell_type":"markdown","source":"***Date***"},{"metadata":{},"cell_type":"markdown","source":"- There are 3436 unique values in the format of YYYY-MM-DD. Instead of using the *categoricals* function, we will just split up the date format into year, month and day but we only use the month data as rain is seasonal and not yearly/daily."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"{num} missing values.\".format(num=df[\"Date\"].isnull().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Date\"]=pd.to_datetime(df[\"Date\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Month\"]=df[\"Date\"].dt.month","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Now we can drop the *Date* column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop([\"Date\"],axis=1,inplace=True)\ndf.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Location***"},{"metadata":{},"cell_type":"markdown","source":"- We will not be dropping *Location* because rain is regional."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"{num} missing values.\".format(num=df[\"Location\"].isnull().sum()))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df[\"Location\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We will convert these categories into numbers when we impute the missing values after we split the data."},{"metadata":{},"cell_type":"markdown","source":"***WindGustDir***"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"{num} missing values.\".format(num=df[\"WindGustDir\"].isnull().sum()))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df[\"WindGustDir\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We will convert these categories into numbers when we impute the missing values after we split the data."},{"metadata":{},"cell_type":"markdown","source":"***WindDir9am***"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"{num} missing values.\".format(num=df[\"WindDir9am\"].isnull().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"WindDir9am\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We will convert these categories into numbers when we impute the missing values after we split the data."},{"metadata":{},"cell_type":"markdown","source":"***WindDir3pm***"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"{num} missing values.\".format(num=df[\"WindDir3pm\"].isnull().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"WindDir3pm\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We will convert these categories into numbers when we impute the missing values after we split the data."},{"metadata":{},"cell_type":"markdown","source":"***RainToday***"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"{num} missing values.\".format(num=df[\"RainToday\"].isnull().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"RainToday\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We will also convert these text data into numbers but just using a simple if statement:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"RainToday\"]=df[\"RainToday\"].apply(lambda x:0 if x==\"No\" else 1)\ndf.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So this is what our data looks like now:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before we tackle the missing values or scale the data, we must first split the data into the training and testing sets to ensure we do not cause any data leakage."},{"metadata":{"trusted":true},"cell_type":"code","source":"x=df.drop([\"RainTomorrow\"],axis=1)\ny=df[\"RainTomorrow\"]\n\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=7)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Training set shape:\",x_train.shape)\nprint(\"Testing set shape:\",x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To replace the missing values, we will compute a fill value for the numerical and categorical features based on the training set and then apply them to the testing set."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"x_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Missing values in numerical features will be filled with the median. We could in fact use the mean or a set constant instead, but because of the range and the number of outliers in the data we will use the median."},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in [x_train,x_test]:\n    for col in df.select_dtypes(exclude=\"object\").columns:\n        col_median=x_train[col].median()\n        df[col].fillna(col_median,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Missing values in categorical features will be filled with the mode."},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in [x_train,x_test]:\n    for col in df.select_dtypes(\"object\").columns:\n        col_mode=x_train[col].mode()[0]\n        df[col].fillna(col_mode,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Up until now the categorical features are still in text format. We will have to convert them into a format the model will be able to use as input (i.e. numbers). We shall do so by converting the text into numbers using pd.get_dummies, concatenating the dummies to the dataframe, and then dropping the original text column:"},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in x_train.select_dtypes(\"object\").columns:\n    x_train=pd.concat([x_train,pd.get_dummies(x_train[col],drop_first=True)],axis=1)\n    x_train.drop([col],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in x_test.select_dtypes(\"object\").columns:\n    x_test=pd.concat([x_test,pd.get_dummies(x_test[col],drop_first=True)],axis=1)\n    x_test.drop([col],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since each feature has it's own range of values, we will scale the data (again, only based on the training set and then applied to the testing set):"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler=StandardScaler()\n\nx_train=pd.DataFrame(scaler.fit_transform(x_train),columns=x_train.columns)\nx_test=pd.DataFrame(scaler.transform(x_test),columns=x_test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"But before we fit our model, perhaps we should reduce the number of features selected:"},{"metadata":{"trusted":true},"cell_type":"code","source":"model=LogisticRegression(random_state=7)\n\nmin_features_to_select=1\nrfecv=RFECV(estimator=model,step=1,cv=5,scoring=\"accuracy\",min_features_to_select=min_features_to_select)\nrfecv.fit(x_train,y_train)\n\nprint(\"Optimal number of features : %d\" % rfecv.n_features_)\n\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.plot(range(min_features_to_select,\n               len(rfecv.grid_scores_)+min_features_to_select),\n         rfecv.grid_scores_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfetable=pd.DataFrame({\"Feature\":x_train.columns,\"Support\":rfecv.support_,\"Ranking\":rfecv.ranking_,}).sort_values(by=\"Ranking\",ascending=False)\nrfetable","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Recurssive feature elimination suggests we can remove some columns to the optimal amount of 101."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=x_train.drop([\"Rainfall\",\"SSE\",\"SSW\",\"NNE\",\"ESE\",\"W\",\"Williamtown\",\"PearceRAAF\",\"ENE\",\"SE\"],axis=1)\nx_test=x_test.drop([\"Rainfall\",\"SSE\",\"SSW\",\"NNE\",\"ESE\",\"W\",\"Williamtown\",\"PearceRAAF\",\"ENE\",\"SE\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have removed some features, we can finally fit our model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters=[{\"penalty\":[\"l1\",\"l2\",\"elasticnet\"]},\n            {\"C\":[0.1,1,10,100]},\n            {\"class_weight\":[\"balanced\",None]},\n            {\"solver\":[\"newton-cg\",\"lbfgs\",\"liblinear\",\"sag\",\"saga\"]},\n            {\"multi_class\":[\"auto\",\"ovr\",\"multinomial\"]}]\n\ngrid=GridSearchCV(estimator=model,param_grid=parameters,refit=True,cv=5,verbose=1)\n\ngrid.fit(x_train,y_train)\n\ny_predict=grid.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we can evaluate our model using a classifcation report, ROC AUC score, ROC curve  and a confusion matrix:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def cm(predictions):\n    cm_matrix=pd.DataFrame(data=confusion_matrix(y_test,predictions),columns=[\"No Rain\",\"Rain\"],index=[\"No Rain\",\"Rain\"])\n    sns.heatmap(cm_matrix,annot=True,square=True,fmt=\"d\",cmap=\"Purples\",linecolor=\"w\",linewidth=2)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.yticks(va=\"center\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,y_predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_score=model.predict_proba(x_test)[:,1]\n\nprint(\"roc_auc_score: \",roc_auc_score(y_test,y_score))\n\nfalse_positive_rate,true_positive_rate,threshold=roc_curve(y_test,y_score)\nplt.plot(false_positive_rate,true_positive_rate)\nplt.plot([0,1],ls=\"--\")\nplt.plot([0,0],[1,0],c=\".7\")\nplt.plot([1,1],c=\".7\")\nplt.title(\"Receiver Operating Characteristic\")\nplt.ylabel(\"True Positive Rate\")\nplt.xlabel(\"False Positive Rate\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm(y_predict)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Training set score: {num:.4f}.\".format(num=model.score(x_train,y_train)))\nprint(\"Testing set score: {num:.4f}.\".format(num=model.score(x_test,y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our model didn't do so bad with an accuracy score of 0.84 and a ROC AUC score of 0.86! This means our model was able to correctly predict 83% of the instances. It was however better at predicting class 0 (i.e. no rain) than class 1 (i.e. rain) with the higher precision and recall, and the model also predicted a lot more false negatives (i.e. predicted that it would not rain when it actually will) than false positives (i.e. predicted that it would rain when it actually will not). Thankfully after all that work the training and testing scores are very similar so there is no obvious indication of any over/underfitting hence our model will fair well with new data."},{"metadata":{},"cell_type":"markdown","source":"**Now should I bring my umbrella or sunglasses..**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}