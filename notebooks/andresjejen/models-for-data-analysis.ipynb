{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Why are low quality diamonds more expensive?\n## 66 Days of Data with Ken Jee\n\n\nToday I was wondering if the objective of a data science project is to build a predictive model. So I take back my \"R for Data Science\" book and read again the modeling chapter, and this time I found new insights about. A model can be used for data processing like a filter that you can train to make your data more understandable. I hope you can read it and reproduce the diamonds example. Here my Python version...\n\n**Author:** Andres Jejen   \n**Bibliography**: [model building](https://r4ds.had.co.nz/model-building.html)\n\n### Loading Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np    # linear algebra\nimport pandas as pd   # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns # graphication library\nimport matplotlib.pyplot as plt\n\n#Modeling libreries\nfrom sklearn import linear_model\nsns.set_style(\"whitegrid\") # setting style","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading Data\n\nDiamonds dataset contains information about ~54K diamonds, includind the ``price``, ``carat (weight)``, ``cut``, ``clarity``, ``depth``, ``x,y,x dimensions`` and so on.   \nAfter the Exploatory Data Analysis we found son counter intuitive facts. For Example, apparently the median price of diamonds is higher for lower quality cuts, colors, and clarity.   \nIs that true or can we explain this phenomenon with the data. First at all lets take a look."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"diamonds = pd.read_csv('/kaggle/input/diamonds/diamonds.csv')\n\norder = {\n    \"cut\": [\"Fair\",\"Good\", \"Very Good\", \"Premium\", \"Ideal\"],\n    \"clarity\": [\"I1\", \"SI2\", \"SI1\", \"VS2\", \"VS1\", \"VVS2\", \"VVS1\", \"IF\"],\n    \"color\": [\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\"]\n}\n\ndiamonds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def EDA(data=diamonds ,target_feature=\"price\"):\n    for feature in [\"cut\",\"clarity\",\"color\"]:\n        plt.figure(figsize=(14,7))\n        sns.boxplot(data=data,x = feature, y=target_feature, order=order[feature])\n        print(f\"Median analysis by {feature}\")\n        print(data[[feature,target_feature]].groupby(feature).median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EDA()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can find that the median value is higher for the lost quality diamonds.\n\n- In ``cut`` category, ``Fair`` is the worst but this have in median the higher price.   \n- In ``color`` category, ``J`` is the worst color but this have in median the higher price.   \n- In ``clarity`` category, ``I1`` and ``SI2`` are the worst but they have in median the higher price.   \n\n> I would like a challenge In this case, Why are we using the median instead of the mean?, **please comment below**.\n\nLets take another insight, What if we compare the carat (weight) feature vs price?."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,7))\nsns.scatterplot(data=diamonds, x=\"carat\", y=\"price\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems like a exponential growing, and we observe that most of the data are from carat lower than 2.5.   \nLet's make a couple of tweas to the dataset in order to make it easier to work with.   \n\n1. Focus on diamonds smaller than 2.5 carats.\n2. Log transform carat and price in order to avoid the exponential relationshit between."},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds_filtered = diamonds.query(\"carat < 2.5\") \ndiamonds_filtered[\"log_price\"] = np.log2(diamonds_filtered[\"price\"])\ndiamonds_filtered[\"log_carat\"] = np.log2(diamonds_filtered[\"carat\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,7))\nsns.scatterplot(data=diamonds_filtered, x=\"log_carat\", y=\"log_price\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we found a possible linear relationship, now let create a linear model and evaluate the result."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = diamonds_filtered.loc[:, \"log_carat\"].values.reshape(-1, 1)  # values converts it into a numpy array\nY = diamonds_filtered.loc[:, \"log_price\"].values.reshape(-1, 1)  # -1 means that calculate the dimension of rows, but have 1 column\n\nlinear_regressor = linear_model.LinearRegression()  # create object for the class\nlinear_regressor.fit(X, Y)  # perform linear regression\nscore = linear_regressor.score(X,Y)\n\nprint(f\"R^2 of the linear regression {score}\")\n\ndiamonds_filtered[\"log_predicted_price\"] = linear_regressor.predict(X)  # make predictions\ndiamonds_filtered[\"predicted_price\"] = diamonds_filtered[\"log_predicted_price\"].apply(lambda x: 2**x)\n\nplt.figure(figsize=(14,7))\nfig, ax = plt.subplots()\nsns.scatterplot(diamonds_filtered[\"log_carat\"],diamonds_filtered[\"log_price\"], ax=ax)\nsns.scatterplot(diamonds_filtered[\"log_carat\"],diamonds_filtered[\"log_predicted_price\"], ax=ax)\n\nplt.figure(figsize=(14,7))\nfig, ax = plt.subplots()\nsns.scatterplot(diamonds_filtered[\"carat\"],diamonds_filtered[\"price\"], ax=ax)\nsns.scatterplot(diamonds_filtered[\"carat\"],diamonds_filtered[\"predicted_price\"], ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see the residuals, remember that a linear regression can be evaluated if the sparse of the residuals is uniform."},{"metadata":{"trusted":true},"cell_type":"code","source":"diamonds_filtered[\"model_log_residuals\"] = diamonds_filtered[\"log_price\"]-diamonds_filtered[\"log_predicted_price\"]\nplt.figure(figsize=(14,7))\nsns.scatterplot(data=diamonds_filtered, x=\"log_carat\", y=\"model_log_residuals\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Final part\nNow just try the Explortory Data analysis, in this case we use the residuals instead of the price.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"EDA(diamonds_filtered,\"model_log_residuals\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# > The counterintuitive part is because the poorest quality diamonds tend to be the largest, possibly used for tunneling or drilling for oil. Using the linear regression model we found a way to overcome this effect and be able to explain the phenomenon, now it is possible to create more sophisticated models that can lead to a possible model that predicts the price of a diamond."},{"metadata":{},"cell_type":"markdown","source":"## TAKEAWAYS\n\nthe modeling process is not only the final task of a data science project, they are also usefull to performs some twaks over the data, in order to extraxt insights or clean it. This Example is takem from \"R for data science\" Book, I just translate it to Python and add some personal comments.\nPlease let me know your thoughts below."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}