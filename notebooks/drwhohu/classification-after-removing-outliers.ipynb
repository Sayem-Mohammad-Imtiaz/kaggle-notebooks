{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"9a6e175c-2406-8303-5a92-3f6f5468ea2d"},"source":"My first code (https://www.kaggle.com/drwhohu/d/uciml/glass/predict-glass-types-using-svm) for classification is not very good. There must be two reasons for that. \n\n1. Not enough data for all types, especially Type 6.\n2. The outliers will mess up in the classification.\n\nTo test my conjecture, I decided to remove the outliers from the original set and try the classification again to see whether it will make it better.  "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0adac5fd-2695-3e6b-ed29-b2a7c91a4e74"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\nglassdata = pd.read_csv('../input/glass.csv') \n\nglassdata.describe()\n# Notice that in the description, it has 1-7 types, but the dataset does not have Type 4"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a8f538d7-2b5c-f9d8-96c6-7edbaafd8f5b"},"outputs":[],"source":"# Let's count the number of glasses in each group\n\npd.value_counts(glassdata['Type'].values.ravel()) \n\n\n# It is clear that type 6 has very few data. \n# That's why it is hard to predict glasses in that type."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9a5317a6-26d6-7551-d349-87a342d43fd2"},"outputs":[],"source":"# According to http://www.mathwords.com/o/outlier.htm, we can calulate the outliers. \n# The formula tells us that any number that outside the range [Q1 - 1.5*IQR, Q2 + 1.5*IQR] will be outliers\n\n# For examples, for Na, \n# IQR = Q3 - Q1 = 13.825000 - 12.907500 = 0.9175\n# Q1 - 1.5*IQR = 12.907500 - 1.5*0.9175 = 11.53125 \n# Q3 + 1.5*IQR = 13.825000 + 1.5*0.9175 = 15.20125\n\n# Therefore any number that's outside [11.53125, 15.20125] will be an outlier. \n# Since the maximum number for Na is 17.380000, there exists at least one outlier. \n\n# Before we remove the outliers, let's first check the box plot for each feature. \n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfeature_names = glassdata.columns\nfor i in range(len(feature_names)-1):\n    figure = plt.figure()\n    ax = sns.boxplot(x='Type', y=feature_names[i], data=glassdata)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fdb97a69-debe-0f3f-5a88-64c5acedfd31"},"outputs":[],"source":"# The diamond shaped dots outside the boxplot indicates the outliers \n# There are some extreme cases in K, Ba and Fe. \n# That why it is necessary to rule out the outliers \n\ndf = glassdata.copy(deep=True) # Make a copy of original data, just in case\n\n# Create new dataframe for each type\n\ntypes = df['Type'].unique()\nd = {type: df[df['Type'] == type] for type in types}\n\nd[1]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19677871-24ee-caa9-f6a3-ce48ebe0fd73"},"outputs":[],"source":"# Set the quantile\n\nlow = .25\nhigh = .75\n\nbounds = {}\nfor type in types:\n    filt_df = d[type].loc[:, d[type].columns != 'Type'] # Remove 'Type' Column\n    quant_df = filt_df.quantile([low, high])\n    IQR = quant_df.iloc[1,:]-  quant_df.iloc[0,:]\n    quant_df.iloc[0,:] = quant_df.iloc[0,:] - 1.5*IQR\n    quant_df.iloc[1,:] = quant_df.iloc[1,:] + 1.5*IQR\n    bounds[type] = quant_df\n    \nbounds[1]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d0d9c5ec-0ceb-c55f-98a2-d654f375e21d"},"outputs":[],"source":"# Define our new dataset by removing the outliers \n\nfilt_df = d[1].loc[:, d[1].columns != 'Type'] # Remove 'Type' Column\nfilt_df = filt_df.apply(lambda x: x[(x>bounds[1].loc[low,x.name]) & (x < bounds[1].loc[high,x.name])], axis=0)\nfilt_df = pd.concat([filt_df,d[1].loc[:,'Type']], axis=1)\n\nfilt_df"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"23e62d88-18d5-45c6-327b-72387c450959"},"outputs":[],"source":"# Let's remove the outliers from the dataset \ndf_new = {}\n\nfor type in types:\n    filt_df = d[type].loc[:, d[type].columns != 'Type'] # Remove 'Type' Column\n    filt_df = filt_df.apply(lambda x: x[(x>bounds[type].loc[low,x.name]) & (x < bounds[type].loc[high,x.name])], axis=0)\n    df_new[type] = pd.concat([filt_df,d[type].loc[:,'Type']], axis=1)\n\n\nglassdata_new = result = pd.concat(df_new)\nglassdata_new"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"784e170b-7f1e-44d7-8524-926ea21138c1"},"outputs":[],"source":"# Now we have our glass data that has all outliers removed\n# Check out the boxplot again\n\nfor i in range(len(feature_names)-1):\n    figure = plt.figure()\n    ax = sns.boxplot(x='Type', y=feature_names[i], data=glassdata_new)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2eeaf4ed-b819-7689-43f2-8916a1d0bd52"},"outputs":[],"source":"# Now let's look at the average of the glass_newdata\n\ntypes = np.unique(train['Type'])\n\nfor i in range(len(types)):\n    fig = plt.figure()\n    average = glassdata_new[[glassdata_new.columns[i], \"Type\"]].groupby(['Type'],as_index=False).mean()\n    sns.barplot(x = 'Type', y = glassdata_new.columns[i], data= average)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5efaf18a-1626-1d8c-c1c5-9efe2c57814a"},"outputs":[],"source":"# There is some great information. \n# 1. Type 7 vanished in Mg \n# 2. Type 6 vanished in K\n\n# This two important messages can help us classify Type 6 and 7! \n# We do not need to worry about the small data for these two types. \n\n# Check the original data \n\nglassdata[glassdata['Type'] == 6]\n\n# Like what we expected all K are 0. That the character for 6. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43a0e866-d4b6-dfdb-e34e-77ede56d7aab"},"outputs":[],"source":"glassdata[glassdata['Type'] == 7]\n\n# There are few has nonzero Mg in Type 7, but most of them has 0. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"384a3223-61f4-39bb-b7f3-73cca2e4dad5"},"outputs":[],"source":"# Now let's plot type 6 and 7 using Mg and K\n\n\nx_6 = glassdata[glassdata['Type']==6]['K']\ny_6 = glassdata[glassdata['Type']==6]['Mg']\nplt.scatter(x_6,y_6, color = 'red', label = \"Type 6\")\n\nx_7 = glassdata[glassdata['Type']==7]['K']\ny_7 = glassdata[glassdata['Type']==7]['Mg']\nplt.scatter(x_7,y_7, color = 'blue', label = \"Type 7\")\n\nplt.legend()\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d937ca79-f3b3-e53b-00d7-484ca94ef010"},"outputs":[],"source":"# From the picture above, it is easy to see, except for one outlier in Type 6 (right top corner)\n# The rest are fairly easy to distinguish between 6 and 7. \n\n# Let's just use Mg and K for SVM\n\n# Now let's separate the data in to training and test data\n\nalpha = 0.7 # training data ratio\n\n# Splitting glassdata to training and test data\ntrain = pd.DataFrame()\ntest = pd.DataFrame()\nfor i in range(len(types)):\n    tempt = glassdata_new[glassdata_new.Type == types[i]]\n    train = train.append(tempt[0:int(alpha*len(tempt))])\n    test = test.append(tempt[int(alpha*len(tempt)): len(tempt)])\n    # test.append(tempt[int(alpha*len(tempt)): len(tempt)])\n\n# Check whether the dimension match\nprint (train.shape, test.shape, glassdata.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c4f6c7a8-14ce-8066-bbc1-66479e62e815"},"outputs":[],"source":"fig = plt.figure()\nax = fig.add_subplot(111)\n\nfor type in types:\n    x = glassdata_new[glassdata_new['Type'] == type]['Mg']\n    y = glassdata_new[glassdata_new['Type'] == type]['K']\n    ax.scatter(x,y,label = \"Type\" + str(type))\n\nplt.legend()\nplt.show()\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5c56e599-e3d3-f94f-a308-cac49f43ec95"},"outputs":[],"source":"\n# Calculate the distance between test points and the centers \n\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}