{"cells":[{"metadata":{},"cell_type":"markdown","source":"该笔记本可在 Kaggle 环境下成功运行，本地环境暂未测试。\n\n模型实现参考了如下教程：\n\nhttps://github.com/bentrevett/pytorch-sentiment-analysis/","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%%capture\n\nimport os\nimport time\nimport string\n\nimport numpy as np\nimport pandas as pd\n\n# PyTorch 相关\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchtext.vocab import Vectors\nfrom torchtext import data\n\n# 安装特定版本库\n!pip install -v pytorch-ignite==0.4rc.0.post1\n!pip install --upgrade scikit-learn\n\n# Ignite 相关\nfrom ignite.engine import Events, Engine\nfrom ignite.metrics import Precision, Recall, Accuracy, Loss\nfrom ignite.handlers import ModelCheckpoint\nfrom ignite.contrib.metrics import RocCurve, ROC_AUC\nfrom ignite.contrib.handlers.tqdm_logger import ProgressBar\n\nfrom sklearn.metrics import RocCurveDisplay","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input data files are available in the \"/kaggle/input\" directory.\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 准备数据\n\n对于词嵌入层以及数据集的预处理，我们使用 `torchtext` 包来进行处理。`torchtext` 包提供了从 csv 数据集文件直接构建 PyTorch 所需数据集格式的相关函数。\n\n同时，`torchtext` 还提供 `build_vocab` 函数，加载词向量文件（word2vec 或 GloVe），同时根据数据集中存在的词语，去除掉预训练向量中多余的词汇，以提高内存利用效率。","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"EMBEDDING_FILE = '/kaggle/input/imdb-word2vec/word2vec.txt'\n# EMBEDDING_FILE = '/kaggle/input/glove6b100dtxt/glove.6B.100d.txt'\n\ndef load_file(file_path, device, embedding_file):\n\n    TEXT = data.Field(sequential=True, lower=True, include_lengths=True)\n    LABEL = data.Field(sequential=False, use_vocab=False)\n    \n    datafields = [('clean_text', TEXT), ('label', LABEL)]\n    # Step two construction our dataset.\n    train, valid, test = data.TabularDataset.splits(path=file_path,\n                                                    train=\"Train_clean.csv\", validation=\"Valid_clean.csv\",\n                                                    test=\"Test_clean.csv\", format=\"csv\",\n                                                    skip_header=True, fields=datafields)\n    # because of input dir is read-only we must change the cache path.\n    cache = ('/kaggle/working/.vector_cache')\n    if not os.path.exists(cache):\n        os.mkdir(cache)\n    # using the pretrained word embedding.\n    vector = Vectors(name=embedding_file, cache=cache)\n    TEXT.build_vocab(train, vectors=vector, max_size=25000, unk_init=torch.Tensor.normal_)\n    train_iter, valid_iter, test_iter = data.BucketIterator.splits((train, valid, test), device=device, batch_size=64, \n                                                             sort_key=lambda x:len(x.clean_text), sort_within_batch=True)\n    \n    return TEXT, LABEL, train_iter, valid_iter, test_iter\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\nTEXT, LABEL, train_iter, valid_iter, test_iter = load_file('/kaggle/input/cleaned-imdb-data', \n                                                          device, EMBEDDING_FILE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEXT.vocab","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 建立模型\n\n分别实现 RNN 模型及 LSTM 模型。 (RNN 有梯度消失的问题) \n\n我们使用 PyTorch 框架提供的 API 来构建模型。\n\nPyTorch 的 nn 模块提供了神经网络中常见的网络层，如 `nn.Embedding` 和 `nn.RNN`，以及 `nn.Linear`等。我们按照前一节设计的网络结构，在一个继承 `nn.Module` 的类中定义相关层的实例，并在 `forward` 函数中定义网络的前向传播即可。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class SentimentModelRNN(nn.Module):\n    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n        super().__init__()\n        self.embedding = nn.Embedding(input_dim, embedding_dim)\n        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n        \n    def forward(self, text, text_lengths):\n\n        embedded = self.embedding(text)\n        \n        output, hidden = self.rnn(embedded)\n\n        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n        \n        return self.fc(hidden.squeeze(0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SentimentModelLSTM(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n        super().__init__()\n        \n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n        \n        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n        \n        if bidirectional:\n            self.fc = nn.Linear(hidden_dim * 2, output_dim)\n        else:\n            self.fc = nn.Linear(hidden_dim, output_dim)\n        \n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, text, text_lengths):\n        \n        embedded = self.dropout(self.embedding(text))\n        \n        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n        \n        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n        \n        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n        \n        hidden = self.dropout(torch.cat([hidden[-2,:,:], hidden[-1,:,:]], dim=1)).squeeze()    \n\n        return self.fc(hidden)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 网络参数\n\n设置 RNN 和 LSTM 的高阶参数如下。（二者共有一些参数）\n\n参数的选取上，由于我们的词向量均为 100 维，所以嵌入层维度也为 100 维；同时，我们选取隐藏层维度为 256 维，输出层维度为 1 维（二分类任务）。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_DIM = len(TEXT.vocab)\nEMBEDDING_DIM = 100\nHIDDEN_DIM = 256\nOUTPUT_DIM = 1\nN_LAYERS = 2\nBIDIRECTIONAL = True\nDROPOUT = 0.5\nPAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n\nmodel_rnn = SentimentModelRNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\nmodel_lstm = SentimentModelLSTM(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"统计模型参数数量：","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint('model_rnn', count_parameters(model_rnn))\nprint('model_lstm', count_parameters(model_lstm))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"导入嵌入层数据：","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pretrained_embeddings = TEXT.vocab.vectors\n\nprint(pretrained_embeddings.shape)\n\nmodel_rnn.embedding.weight.data.copy_(pretrained_embeddings)\nmodel_lstm.embedding.weight.data.copy_(pretrained_embeddings)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 训练模型\n\n使用 Adam 训练算法，使用交叉熵损失函数（BinaryCrossEntropy）。\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer_rnn = optim.Adam(model_rnn.parameters())\noptimizer_lstm = optim.Adam(model_lstm.parameters())\n\nloss_rnn = nn.BCEWithLogitsLoss()\nloss_lstm = nn.BCEWithLogitsLoss()\n\nmodel_rnn = model_rnn.to(device)\nmodel_lstm = model_lstm.to(device)\n\nloss_rnn = loss_rnn.to(device)\nloss_lstm = loss_lstm.to(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"对于训练过程，在手动编写网络前向、后向传播的前提下，我们利用了 PyTorch 提供的 ignite 包。这个包从高层面提供了对训练过程监控的能力，我们可以根据不同的事件（每个 epoch、每个 iteration 等）在 ignite engine 分别注册事件处理函数。这样，我们可以把训练代码与验证代码分开，同时获得灵活的监控验证功能。\n\nIgnite Engine 接受一个两参数的回调函数，这个函数会在每个 batch 调用，是我们的训练过程。为了在不同的模型中复用代码，我们使用 Python 的高阶函数（闭包）功能来动态创建这个回调：","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_trainer_callback(model, optimizer, loss_fn):\n    def train(engine, batch):\n        model.train()\n        \n        text, text_lengths = batch.clean_text\n        \n        predictions = model(text, text_lengths).squeeze(1)\n        \n        loss = loss_fn(predictions, batch.label.float())\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    return train\n\ndef get_evaluator_callback(model):\n    def evaluate(engine, batch):\n        model.eval()\n        with torch.no_grad():\n            text, text_lengths = batch.clean_text\n            \n            predictions = model(text, text_lengths).squeeze(1)\n            \n            y_pred =torch.sigmoid(predictions)\n            y = batch.label.float()\n\n            return y_pred, y\n\n    return evaluate","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"我们通过 `ignite.Engine`创建训练器。然后，我们为其添加几个事件：\n\n- ProgressBar，用来图形化显示训练进度；\n- ModelCheckpoint，用来保存模型文件；\n- log_training_results，log_validation_results，用来自动在每个 epoch 后进行评估。\n\n同时，我们也挂载了几个监控指标：\n\n```python\naccuracy = Accuracy(output_transform=output_transform)\nprecision = Precision(output_transform=output_transform, average=False)\nrecall = Recall(output_transform=output_transform, average=False)\nF1 = (precision * recall * 2 / (precision + recall)).mean()\nroc_curve = RocCurve()\nroc_auc = ROC_AUC()\n```","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def output_transform(output):\n    y_pred = torch.round(output[0])\n    y = output[1]\n    return y_pred, y\n\ndef create_trainer_evaluator(model, optimizer, loss_fn, model_name):\n    trainer = Engine(get_trainer_callback(model, optimizer, loss_fn))\n    \n    evaluator = Engine(get_evaluator_callback(model))\n\n    pbar = ProgressBar(persist=True)\n    pbar.attach(trainer)\n    \n    saver = ModelCheckpoint('./', 'checkpoint', n_saved=2, require_empty=False)\n    \n    trainer.add_event_handler(Events.EPOCH_COMPLETED, saver, {model_name: model})\n    \n    @trainer.on(Events.EPOCH_COMPLETED)\n    def log_training_results(engine):\n        evaluator.run(train_iter)\n        metrics = evaluator.state.metrics\n        print(\"Training Results - Epoch: {}  Avg accuracy: {:.2f}\"\n              .format(engine.state.epoch, metrics['accuracy']))\n\n\n    @trainer.on(Events.EPOCH_COMPLETED)\n    def log_validation_results(engine):\n        evaluator.run(valid_iter)\n        metrics = evaluator.state.metrics\n        print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f}\"\n              .format(engine.state.epoch, metrics['accuracy']))\n        \n    accuracy = Accuracy(output_transform=output_transform)\n    precision = Precision(output_transform=output_transform, average=False)\n    recall = Recall(output_transform=output_transform, average=False)\n    F1 = (precision * recall * 2 / (precision + recall)).mean()\n    roc_curve = RocCurve()\n    roc_auc = ROC_AUC()\n\n    accuracy.attach(evaluator, \"accuracy\")\n    precision.attach(evaluator, \"precision\")\n    recall.attach(evaluator, \"recall\")\n    F1.attach(evaluator, \"F1\")\n    roc_curve.attach(evaluator, \"roc_curve\")\n    roc_auc.attach(evaluator, \"roc_auc\")\n\n    return trainer, evaluator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"创建训练器实例，并训练 5 个 epoch：","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"trainer_rnn, evaluator_rnn = create_trainer_evaluator(model_rnn, optimizer_rnn, loss_rnn, 'model_rnn')\ntrainer_rnn.run(train_iter, max_epochs=5)\ntorch.save(model_rnn.state_dict(), 'model_rnn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainer_lstm, evaluator_lstm = create_trainer_evaluator(model_lstm, optimizer_lstm, loss_lstm, 'model_lstm')\ntrainer_lstm.run(train_iter, max_epochs=5)\ntorch.save(model_lstm.state_dict(), 'model_lstm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 模型评估\n\n用 Sklearn 中的 `RocCurveDisplay` 绘制 ROC 曲线：","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_plot_scores(model, evaluator, name):\n    evaluator.run(test_iter)\n    \n    metrics = evaluator.state.metrics\n\n    for key, value in metrics.items():\n        if key != 'roc_curve':\n            print('{}: {:.3f}'.format(key, value))\n\n    fpr, tpr, _ = metrics['roc_curve']\n\n    roc_auc = metrics['roc_auc']\n\n    viz = RocCurveDisplay(\n        fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=name\n    )\n\n    viz.plot(name=name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_rnn.load_state_dict(torch.load('model_rnn'))\nprint_plot_scores(model_rnn, evaluator_rnn, 'rnn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_lstm.load_state_dict(torch.load('model_lstm'))\nprint_plot_scores(model_lstm, evaluator_lstm, 'lstm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 用户输入测试","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_sentiment(model, sentence):\n    model.eval()\n    tokenizer = lambda x: str(x).translate(str.maketrans('', '', string.punctuation)).strip().split()\n    tokenized = [tok for tok in tokenizer(sentence)]\n    print(tokenized)\n    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n    length = [len(indexed)]\n    tensor = torch.LongTensor(indexed).to(device)\n    tensor = tensor.unsqueeze(1)\n    length_tensor = torch.LongTensor(length).to(device)\n    prediction = torch.sigmoid(model(tensor, length_tensor))\n    return prediction.item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_sentiment(model_lstm, \"i love it\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_sentiment(model_lstm, \"This movie sucks\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}