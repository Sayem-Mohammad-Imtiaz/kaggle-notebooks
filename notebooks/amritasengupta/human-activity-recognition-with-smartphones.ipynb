{"cells":[{"metadata":{},"cell_type":"markdown","source":"### CONTEXT\n"},{"metadata":{},"cell_type":"markdown","source":"GOT THE DATASET FROM KAGGLE: https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones\n\n\"The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKINGUPSTAIRS, WALKINGDOWNSTAIRS, SITTING, STANDING, LAYING).\"\n\n__IMPLEMENTED SUPERVISED MACHINE LEARNING ALGORITHMS FOR CLASSIFICATION__"},{"metadata":{},"cell_type":"markdown","source":"### IMPORTING REQUIRED LIBRARIES"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom sklearn.model_selection import cross_val_score\n\n# To remove the scientific notation from numpy arrays\nnp.set_printoptions(suppress=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### READING THE DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"df= pd.read_csv(\"../input/human-activity-recognition-with-smartphones/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EXPLORATORY DATA ANALYSIS"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= df.drop_duplicates()\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__No duplicate rows were found.__"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()[df.isnull().sum()>0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__The data has no missing values in the form of NaN.__"},{"metadata":{"trusted":true},"cell_type":"code","source":"X= df.drop(columns=['Activity'])\nX=X.values\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=3)\n\n# fitting the data\npca_fit=pca.fit(X)\n\n# calculating the principal components\nreduced_X = pca_fit.transform(X)\n#561 Columns present in X are now represented by 3-Principal components present in reduced_X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Since there are 561 predictors, we are using PCA to reduce the number of predictors which will help us in visualization.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2= pd.DataFrame(reduced_X, columns=['PC1','PC2','PC3'])\ndf2['activity']=df['Activity']\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VIZUALIZING THE DISTRIBUTION OF THE COLUMNS"},{"metadata":{},"cell_type":"markdown","source":"_Since PC1, PC2, PC3 is continuous in nature, we will use histogram to visualize it._\n\n_For Activity, we will use bar chart because it is categorical in nature._"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.hist(['PC1','PC2','PC3'],figsize=(20,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_None of them has extreme skewness and represent a fair distribution._"},{"metadata":{"trusted":true},"cell_type":"code","source":"def bar_graph(data,predictor):\n    grouped=data.groupby(predictor)\n    chart=grouped.size().plot.bar(rot=0, title='Bar Chart showing the total frequency of different '+str(predictor), figsize=(15,4))\n    chart.set_xlabel(predictor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_graph(df2,'activity')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.activity.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__The distribution of the classes is fairly balanced.__\n_____________________________________________________________________________________________________________________________"},{"metadata":{},"cell_type":"markdown","source":"### VIZUALIZING THE RELATIONSHIP BETWEEN THE PREDICTORS AND THE TARGET VARIABLE "},{"metadata":{},"cell_type":"markdown","source":"_Using boxplot to see the relationship between categorical target variable and continuous predictors._"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.boxplot(column=['PC1'], by='activity', figsize=(15,10),grid=False, layout=(2,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.boxplot(column=['PC2'], by='activity', figsize=(15,5),grid=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.boxplot(column=['PC3'], by='activity', figsize=(15,5),grid=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__The mean value of different activities is varying for all the 3 boxplots. This implies that the predictors are correlated with the target variable.__"},{"metadata":{},"cell_type":"markdown","source":"### STATISTICAL TEST FOR CORRELATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"def anova_test(data,target,predictor):\n    data1=data.groupby(target)[predictor].apply(list)\n    from scipy.stats import f_oneway\n    AnovaResults = f_oneway(*data1)\n    if AnovaResults[1]<0.05:\n        print(str(predictor)+' is related with the target variable : ', AnovaResults[1])\n    else:\n        print(str(predictor)+' is NOT related with the target variable : ', AnovaResults[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anova_test(df2,'activity','PC1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anova_test(df2,'activity','PC2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anova_test(df2,'activity','PC3')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__We used ANOVA test to check whether the predictors are correlated with the target variable.__"},{"metadata":{},"cell_type":"markdown","source":"### TREATING THE CATEGORICAL VARIABLE"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.activity.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"activity_mapping = {'STANDING': 1,\n                'SITTING': 2,\n                'LAYING': 3,\n              'WALKING': 4,\n               'WALKING_DOWNSTAIRS': 5,\n               'WALKING_UPSTAIRS':6\n              }\n# encoding the Ordinal variable cut\ndf['Activity'] = df['Activity'].map(activity_mapping)\n\n# Checking the encoded columns\ndf['Activity'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__USING PCA WE SAW THAT THE PREDICTORS ARE RELATED TO THE TARGET VARIABLE. HOWEVER WE WILL NOT USE THE PCA COLUMNS FOR MODELLING PURPOSE BECAUSE IT CAN REDUCE THE ACCURACY.__"},{"metadata":{},"cell_type":"markdown","source":"### SPLITTING THE DATASET INTO TRAINING AND TESTING"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TargetVariable='Activity'\ndf2=df.drop(columns=['Activity','subject'])\npredictor = df2.columns\nx=df[predictor].values\ny =df[TargetVariable].values\n\nfrom sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nx=scaler.fit_transform(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### APPLYING DIFFERENT ALGORITHMS"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MODEL"},{"metadata":{},"cell_type":"markdown","source":"_LOGISTIC REGRESSION_"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LogisticRegression(C=1)\n\n# Creating the model on Training Data\nLOG=clf.fit(x_train,y_train)\nprediction=LOG.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_K-NEAREST CLASSIFIER_"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = KNeighborsClassifier(n_neighbors=3)\n\n# Creating the model on Training Data\nKNN=clf.fit(x_train,y_train)\nprediction=KNN.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_DECISION TREE CLASSIFIER_"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier(max_depth=3,criterion='entropy')\n\n# Creating the model on Training Data\nDTree=clf.fit(x_train,y_train)\nprediction=DTree.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(DTree.feature_importances_, index=predictor)\nfeature_importances.nlargest(10).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_RANDOM FOREST CLASSIFIER_"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(max_depth=4, n_estimators=600,criterion='entropy')\n\n# Creating the model on Training Data\nRF=clf.fit(x_train,y_train)\nprediction=RF.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(RF.feature_importances_, index=predictor)\nfeature_importances.nlargest(10).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_SUPPORT VECTOR MACHINE_"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = SVC(C=100, gamma=0.001, kernel='rbf')\n\n# Creating the model on Training Data\nSVM=clf.fit(x_train,y_train)\nprediction=SVM.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SAMPLING TECHNIQUES: SMOTE, OVERSAMPLING, UNDERSAMPLING"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nsmk=SMOTE(random_state=42)\nx_smote,y_smote=smk.fit_sample(x_train,y_train)\nprint('Resampled dataset shape %s' % Counter(y_smote))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\nros= RandomOverSampler(random_state=42)\nx_over,y_over= ros.fit_resample(x_train,y_train)\nprint('Resampled dataset shape %s' % Counter(y_over))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\nrus= RandomUnderSampler(random_state=42)\nx_under,y_under= rus.fit_resample(x_train,y_train)\nprint('Resampled dataset shape %s' % Counter(y_under))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_LOGISTIC REGRESSION AFTER SAMPLING_"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LogisticRegression(C=1)\n\n# Creating the model on Training Data\nLOG=clf.fit(x_smote,y_smote)\nprediction=LOG.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LogisticRegression(C=1)\n\n# Creating the model on Training Data\nLOG=clf.fit(x_over,y_over)\nprediction=LOG.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LogisticRegression(C=1)\n\n# Creating the model on Training Data\nLOG=clf.fit(x_under,y_under)\nprediction=LOG.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_K NEAREST CLASSIFIERS AFTER SAMPLING_"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = KNeighborsClassifier(n_neighbors=3)\n\n# Creating the model on Training Data\nKNN=clf.fit(x_smote,y_smote)\nprediction=KNN.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = KNeighborsClassifier(n_neighbors=3)\n\n# Creating the model on Training Data\nKNN=clf.fit(x_over,y_over)\nprediction=KNN.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = KNeighborsClassifier(n_neighbors=3)\n\n# Creating the model on Training Data\nKNN=clf.fit(x_under,y_under)\nprediction=KNN.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_DECISION TREE AFTER SAMPLING_"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier(max_depth=3,criterion='entropy')\n\n# Creating the model on Training Data\nDTree=clf.fit(x_smote,y_smote)\nprediction=DTree.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(DTree.feature_importances_, index=predictor)\nfeature_importances.nlargest(10).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier(max_depth=3,criterion='entropy')\n\n# Creating the model on Training Data\nDTree=clf.fit(x_over,y_over)\nprediction=DTree.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(DTree.feature_importances_, index=predictor)\nfeature_importances.nlargest(10).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier(max_depth=3,criterion='entropy')\n\n# Creating the model on Training Data\nDTree=clf.fit(x_under,y_under)\nprediction=DTree.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(DTree.feature_importances_, index=predictor)\nfeature_importances.nlargest(10).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_RANDOM FOREST CLASSIFIER AFTER SAMPLING_"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(max_depth=4, n_estimators=600,criterion='entropy')\n\n# Creating the model on Training Data\nRF=clf.fit(x_smote,y_smote)\nprediction=RF.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(RF.feature_importances_, index=predictor)\nfeature_importances.nlargest(10).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(max_depth=4, n_estimators=600,criterion='entropy')\n\n# Creating the model on Training Data\nRF=clf.fit(x_over,y_over)\nprediction=RF.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(RF.feature_importances_, index=predictor)\nfeature_importances.nlargest(10).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(max_depth=4, n_estimators=600,criterion='entropy')\n\n# Creating the model on Training Data\nRF=clf.fit(x_under,y_under)\nprediction=RF.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(RF.feature_importances_, index=predictor)\nfeature_importances.nlargest(10).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"_SUPPORT VECTOR CLASSIFIER AFTER SAMPLING_"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = SVC(C=100, gamma=0.001, kernel='rbf')\n\n# Creating the model on Training Data\nSVM_smote=clf.fit(x_smote,y_smote)\nprediction=SVM_smote.predict(x_test)\n\n# Measuring accuracy on Testing Datam\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = SVC(C=100, gamma=0.001, kernel='rbf')\n\n# Creating the model on Training Data\nSVM_over=clf.fit(x_over,y_over)\nprediction=SVM_over.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = SVC(C=100, gamma=0.001, kernel='rbf')\n\n# Creating the model on Training Data\nSVM_under =clf.fit(x_under,y_under)\nprediction=SVM_under.predict(x_test)\n\n# Measuring accuracy on Testing Data\nfrom sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__THE BEST MODEL IS SUPPORT VECTOR CLASSIFIER WITHOUT ANY SAMPLING TECHNIQUE.__\n\n_Accuracy: 99%_\n\n_Error proportion: 0.013_"},{"metadata":{},"cell_type":"markdown","source":"### K-FOLD CROSS VALIDATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_values= cross_val_score(SVM_under, x, y, cv=10, scoring='f1_weighted')\nprint(accuracy_values)\nprint('Final Average Accuracy of the Model:',accuracy_values.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DEPLOYMENT OF THE MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_svm= SVM.fit(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test= pd.read_csv('../input/human-activity-recognition-with-smartphones/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop(columns=['subject'],inplace=True)\ntest=test.drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()[df.isnull().sum()>0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"activity_mapping = {'STANDING': 1,\n                'SITTING': 2,\n                'LAYING': 3,\n              'WALKING': 4,\n               'WALKING_DOWNSTAIRS': 5,\n               'WALKING_UPSTAIRS':6\n              }\n# encoding the Ordinal variable cut\ntest['Activity'] = test['Activity'].map(activity_mapping)\n\n# Checking the encoded columns\ntest['Activity'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TargetVariable='Activity'\ntest2= test.drop(columns=['Activity'])\npredictor = test2.columns\nx_test= test[predictor].values\ny_test = test[TargetVariable].values\n\nfrom sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nx=scaler.fit_transform(x_test)\n\nprediction= final_svm.predict(x)\ntest['Activity_Predictions']=prediction\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint(metrics.classification_report(y_test, prediction))\nprint(metrics.confusion_matrix(y_test, prediction))\n\n# Printing the Overall Accuracy of the model\nF1_Score=metrics.classification_report(y_test, prediction).split()[-2]\nprint('Accuracy of the model:', F1_Score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### ACCURACY OF TRAIN SET : 99%\n\n#### ACCURACY OF TEST SET : 100%\n\n_MODEL: SUPPORT VECTOR CLASSIFIER AFTER UNDERSAMPLING (Because it has the highest accuracy and lowest error percentage)_\n\n_STANDARDIZED the TRAIN SET_\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}