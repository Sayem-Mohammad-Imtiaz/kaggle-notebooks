{"cells":[{"metadata":{},"cell_type":"markdown","source":"***Loading the dataset from specified location ***"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\ndata=pd.read_csv('../input/diamonds/diamonds.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After loading the data , We will first look at the data to get an understanding . "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Description of the variables**\n\n***Independent Variable **\n    1. carat - Weight of the diamond \n    2. cut - Quality of the diamond . It is categorical column which contains 5 different categories of the diamond . \n    3. color - Categorical column representing the color of the diamond . It is categorised into 7 types . \n    4. clarity - Refers to the visual appearance of internal characteristics of a diamond called inclusions and blemishes.It has 8    different categories .\n    5. Depth - Height of the diamond. the depth of diamond is represent in precentage. \n    6. Table - Represents the flat surface on the top of the diamond. \n    7. x - length in mm \n    8. y - width in mm \n    9. z - depth in mm \n\n*** Dependent Variable **\n    1. Price - Represents the price of the diamond.     "},{"metadata":{},"cell_type":"markdown","source":"Now that we have gained knowledge about what each variable represents , lets do few basic checks in the data . \n\n* First lets check if there are any unwanted columns to be removed \n* Next lets check for null values present in the data . "},{"metadata":{},"cell_type":"markdown","source":"From the data we can seen that Unnamed:0 column is not required as it is an index column . Therefore we will remove the column from the data.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop('Unnamed: 0',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Super!! We do not have any null values . If are null values present then we should have either deleted the rows or replace them mean/median ."},{"metadata":{},"cell_type":"markdown","source":"Now lets get the summary statistics of the data (count, min,max,mean,std etc ). \n\nThe summary is shown only for numerical variables. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow !! . Now we got to know the stats of the variables . You check and everything seems fine and proceed further.                                 \nStop !!                                                                                                                                  \nIf you clearly notice the min values for columns x,y and z are 0 which is impratical."},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for columns with 0 \ndata.loc[(data['x']==0)|(data['y']==0)|(data['z']==0)]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there are 20 rows containing zero in either x,y or z . Since this is impratical we will exclude from the data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#deleting values having zero \ndata=data[(data[['x','y','z']]!=0).all(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn import metrics\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nX=data.drop('price',axis=1)\ny=data['price']\n   \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.countplot(x='cut',data=X,order=X['cut'].value_counts().index)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.countplot(x='color',data=X,order=X['color'].value_counts().index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.countplot(x='clarity',data=X,order=X['clarity'].value_counts().index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"object_col=[col for col in X.columns if X[col].dtype==\"object\"]\noh_encoder=pd.get_dummies(X[object_col])\n\nnum_X_train=X.drop(object_col,axis=1)\nscale=MinMaxScaler()\nscale_X_train=pd.DataFrame(scale.fit_transform(num_X_train),index=num_X_train.index,columns=['carat','depth','table','x','y','z'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diamond_data=pd.concat([scale_X_train,oh_encoder],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking correlation \nplt.figure(figsize=(20,20))  # on this line I just set the size of figure to 12 by 10.\np=sns.heatmap(diamond_data.corr(), annot=True,cmap='RdYlGn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(diamond_data,y,test_size=0.2,random_state=42)\n\n#linear Regression \nlnr_model=LinearRegression()\nlnr_model.fit(X_train,y_train)\ny_pred=lnr_model.predict(X_test)\n\n\nprint(\"Accuracy :- \"+ str(lnr_model.score(X_test,y_test)*100) +' %')\nprint(\"R Squared :- \"+ str(metrics.r2_score(y_test,y_pred)))\nprint(\"Mean Absolute Error :- {}\".format(mean_absolute_error(y_test,y_pred)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decision tree\nregressor = DecisionTreeRegressor(random_state = 0)  \n\nregressor.fit(X_train, y_train)\n\ny_pred_dt=regressor.predict(X_test)\n\n\nprint(\"Accuracy :- \" + str(regressor.score(X_test,y_test)*100) +' %')\nprint(\"R Squared :- \" + str(metrics.r2_score(y_test,y_pred_dt)))\nprint(\"Mean absolute error :- {}\".format(mean_absolute_error(y_test,y_pred_dt)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#random forest with default parameters \nrf=RandomForestRegressor(random_state=42)\nrf.fit(X_train,y_train)\nrfy_pred=rf.predict(X_test)\nmetrics.r2_score(y_test,rfy_pred)\n\nprint(\"Accuracy :- \"+ str(rf.score(X_test,y_test)*100) +' %')\nprint(\"R Squared :- \"+ str(metrics.r2_score(y_test,rfy_pred)))\nprint(\"Mean Absolute Error :- {}\".format(mean_absolute_error(y_test,rfy_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#random forest with estimators\n\nrf = RandomForestRegressor(n_estimators=100,random_state = 42)\n\nrf.fit(X_train,y_train)\n\ny_pred_rf=rf.predict(X_test)\n\nprint(\"Accuracy :- \"+ str(rf.score(X_test,y_test)*100) +' %')\nprint(\"R Squared :- \"+ str(metrics.r2_score(y_test,y_pred_rf)))\nprint(\"Mean Absolute Error :- {}\".format(mean_absolute_error(y_test,y_pred_rf)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Stay Tuned !! Will improve the results by tuning the parameters of Random forest ,Decision Tree and XG Boost .\n\n**Thank You :) **"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}