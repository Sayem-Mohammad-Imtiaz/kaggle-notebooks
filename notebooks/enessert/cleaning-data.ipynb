{"cells":[{"metadata":{"_uuid":"6df43a370f4e8c95b63d9c40a3fcc61ed6d0347f"},"cell_type":"markdown","source":"**Content:**\n1. [Cleaning Data](#1)\n    1. [Diagnose data for cleaning](#2)\n    1. [Exploratory data analysis](#3)\n    1. [Visual exploratory data analysis](#4)\n    1. [Tidy data](#5)\n    1. [Pivoting data](#6)\n    1. [Concatenating data](#7)\n    1. [Data types](#8)\n    1. [Missing data and testing with assert](#9)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01e2945c17e0519616eca235ea42397695634655"},"cell_type":"markdown","source":"<a id=\"1\"></a> <br>\n# 1.CLEANING DATA"},{"metadata":{"_uuid":"fba31021bb1f8ec89244ee61bfa78544b1b9c9ea"},"cell_type":"markdown","source":"<a id=\"2\"></a> <br>\n### DIAGNOSE DATA for CLEANING\nWe need to diagnose and clean data before exploring.\n<br>Unclean data:\n* Column name inconsistency like upper-lower case letter or space between words\n* missing data\n* different language\n\n<br> We will use head, tail, columns, shape and info methods to diagnose data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data =pd.read_csv('../input/Pokemon.csv')     # data read","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8938aaff3c104c4a7219762fbf37afbd994c08b6"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"9f5e931b4251ceb7427c93b1124528a8d17a18a2"},"cell_type":"code","source":"data.info()     #data's information","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b641d5eacf2792949d729fe4544a277088124115"},"cell_type":"markdown","source":"\n"},{"metadata":{"trusted":true,"_uuid":"dd3495b9ad6dbea04fc31ddcca4cb46e1572c3cb"},"cell_type":"code","source":"data.head()  # first 5 rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87bed3945f73743c4969ee243d061d830d032c2d"},"cell_type":"code","source":"data.tail()  # last 5 rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ecc7b101f4365e188092b34fbe28cd29667b022"},"cell_type":"code","source":"data.columns # give me column names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29adcc03f5271d3d695f81476fd659bf968794bb"},"cell_type":"code","source":"data.shape  ## shape gives number of rows and columns in a tuble","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d7a19196b434ba4833398f6ddb1e35bc7d82817"},"cell_type":"markdown","source":"<a id=\"3\"></a> <br>\n### EXPLORATORY DATA ANALYSIS\nvalue_counts(): Frequency counts\n<br>outliers: the value that is considerably higher or lower from rest of the data\n* Lets say value at 75% is Q3 and value at 25% is Q1. \n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n<br>We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\n<br> What is quantile?\n\n* 1,3,4,5,8,9,10,12,13,17,18,21,23\n* The median is the number that is in **middle** of the sequence. In this case it would be 10.\n\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 10, which is 4.\n* The upper quartile, you find the median between the median and the largest number i.e. between 10 and 23, which will be 17 according to the question above."},{"metadata":{"trusted":true,"_uuid":"2521e1d1490333c869e0876f27e785b0c69c4621"},"cell_type":"code","source":"# frequency of pokemon types\nprint(data['Type 2'].value_counts(dropna = False))   # if there are nan values that also be counted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a5845bfb242a58781de50e691074b4577e39c59"},"cell_type":"code","source":"# For example max Speed is 180 or min attack is 5\ndata.describe() # ignore null entries","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d5098687b7a1a3819333ebc85c8d68e2707e3e4"},"cell_type":"markdown","source":"<a id=\"4\"></a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n* Box plots: A data set shows five summaries. At least minimum, first quarter, median, third quarter and maximum."},{"metadata":{"trusted":true,"_uuid":"79fca1e407c656f584b4495e742cb04e8eb9ae45"},"cell_type":"code","source":"# For example: compare defense of pokemons that are legendary  or not\n# Black line at top is max\n# Blue line at top is 75%\n# Green line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\n# -------------------------------------------\n# boxplot parameters\n# column : Column name or list of names, or vector.\n# by : Column in the DataFrame to pandas.DataFrame.groupby(). \n# ax : The matplotlib axes to be used by boxplot.\n# fontsize : Tick label font size in points or as a string (e.g., large).\n# grid : Setting this to True will show the grid.\n# figsize : The size of the figure to create in matplotlib.\n\ndata.boxplot(column='Defense',by = 'Legendary',fontsize = 'large', figsize = (8,8) )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"161d8523550a752d2c9bfca4a67d246301c9b29d"},"cell_type":"markdown","source":"<a id=\"5\"></a> <br>\n### TIDY DATA\nWe tidy data with melt().\nDescribing melt is confusing. Therefore lets make example to understand it."},{"metadata":{"trusted":true,"_uuid":"f2d87abcf8ac02dd8e9bd1a29a169be4a3052faf"},"cell_type":"code","source":"# Merge data\nnew_data = data.head()  # I only take 5 rows into new data\nnew_data   #show new_data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d4fa1d4c15b2b7c7e9294d51a246e3681c22ebd"},"cell_type":"code","source":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=new_data,id_vars ='Name' , value_vars =['HP','Speed'])\nmelted     # show melted","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e831fb16cfc90f6aa48ae7b23d5aff02ca203ed"},"cell_type":"markdown","source":"<a id=\"6\"></a> <br>\n### PIVOTING DATA\nReverse of melting."},{"metadata":{"trusted":true,"_uuid":"fbe774602d4993f7e425f3878acc048a7c0ba2b6"},"cell_type":"code","source":"# Lets reverse\nmelted.pivot(index ='Name' , columns ='variable', values = 'value' )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a5e6d05582bb143b2eaa192b8b600923c2f8621"},"cell_type":"markdown","source":"<a id=\"7\"></a> <br>\n### CONCATENATING DATA\nWe can concatenate two dataframe "},{"metadata":{"trusted":true,"_uuid":"5936b19bf985b5e806f0f2f83991e074106ec260"},"cell_type":"code","source":"# Create 2 dataframe\ndata1 = data.head()\ndata2 = data.tail()\nconc_data_row = pd.concat([data1,data2],axis=0, ignore_index=True ) # axis=0 dataframes in row \nconc_data_row   # show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48f5686f40d56aacfe941d68a8757c72e119a7ef"},"cell_type":"code","source":"# Create 2 dataframe\ndata1 = data['HP'].head()\ndata2 = data['Speed'].head()\nconc_data_col = pd.concat([data1,data2],axis=1 )  \nconc_data_col   # show","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c677edc280b06e09399599d85662c0428cf735e"},"cell_type":"markdown","source":"<a id=\"8\"></a> <br>\n### DATA TYPES\nData types: object(string),boolean,  integer, float and categorical.\n<br> We can make conversion data types like from str to categorical or from int to float\n<br> Why is category important: \n* make dataframe smaller in memory \n* can be utilized for anlaysis especially for sklear(we will learn later)"},{"metadata":{"trusted":true,"_uuid":"113806aab3febbc3362c855bb35a7d46069d7fa6"},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3ca6079d70b29bc8acc653b2e6a25557744f80a"},"cell_type":"code","source":"# convert object(str) -----> categorical\n# convert int ------> float\ndata['Type 1'] =data['Type 1'].astype('category')\ndata['Defense'] =data['Defense'].astype('float')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8153a8a503c3dbcba6f183975fb1bcc7a8264f9"},"cell_type":"code","source":"# Type 2 changed from object to category\n# Speed changed from int to float\ndata.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6d82f790635e723263b96926e6ee341f87d64db"},"cell_type":"markdown","source":"<a id=\"9\"></a> <br>\n### MISSING DATA and TESTING WITH ASSERT\nIf we encounter with missing data, what we can do:\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean\n<br>Assert statement: check that you can turn on or turn off when you are done with your testing of the program"},{"metadata":{"trusted":true,"_uuid":"ee5e2b695894bba522e3b9102601645712d85d02"},"cell_type":"code","source":"#Type 2 has 414 non-null object so it has 386 null object\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0aff3f53fd0e690ba40a678f03a909fbceccfb6c"},"cell_type":"code","source":"#Lets chech Type 2\ndata[\"Type 2\"].value_counts(dropna =False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"263449ec2f300ed0bcf00907042a8c503843ced3"},"cell_type":"code","source":"#Lets drop nan values (delete)\ndata1 = data   # also we will use data to fill missing value so I assign it to data1 variable\ndata1['Type 2'].dropna(inplace = True) # inplace = True means we do not assign it to new variable. Changes automatically assigned to data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"209467e79a6ae39bd5e3b41a238c02dc083efa09"},"cell_type":"code","source":"# Assert statement:\nassert 1==1   # return nothing because it is true","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04b486477388b7f8601cd08a494893495094678c"},"cell_type":"code","source":"# False so give me error\n#assert 1==2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9ef0115b8e8187eaa095d4c83ebe9fb84e741db"},"cell_type":"code","source":"assert data['Type 2'].notnull().all()  # returns nothing because we drop nan values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9f9baf000fa6724c2811eb6aef3ac0a3acac25d"},"cell_type":"code","source":"data[\"Type 2\"].fillna('empty',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a28b5867361f6544e0e2059ce409429b1f1f963"},"cell_type":"code","source":"assert data['Type 2'].notnull().all()  # returns nothing because we do not have nan values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0facf12f10cd3d63ae6797c0d05d82a05fba4038"},"cell_type":"markdown","source":"What we learned at the end of this chapter:\n* Diagnose data for cleaning\n* Exploratory data analysis\n* Visual exploratory data analysis\n* Tidy data\n* Pivoting data\n* Concatenating data\n* Data types\n* Missing data and testing with assert"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}