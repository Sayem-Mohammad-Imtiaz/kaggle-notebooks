{"cells":[{"metadata":{"_uuid":"226475edbd8ad060157024c1e2d96713867b0376"},"cell_type":"markdown","source":"1. [Pandas Basics](#1)\n    1. [Review of pandas](#2)\n    1. [Building data frames from scratch](#3)\n    1. [Visual exploratory data analysis](#4)\n    1. [Statistical explatory data analysis](#5)\n    1. [Indexing pandas time series](#6)\n    1. [Resampling pandas time series](#7)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data =pd.read_csv('../input/tmdb_5000_movies.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8c8c61b10332cbf8cc345f48009c4609c8f6048"},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6bd7d171d087728c7e971891f4d0a2e2946156f1"},"cell_type":"markdown","source":"<a id=\"1\"></a> <br>\n#  PANDAS BASICS "},{"metadata":{"trusted":true,"_uuid":"e09670571a061fd722116d6e099d587601c68b49"},"cell_type":"markdown","source":"<a id=\"2\"></a> <br>\n### REVİEW of PANDAS\n\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy"},{"metadata":{"trusted":true,"_uuid":"456dee91bac9e08557c5947df5de56ad41bbff88"},"cell_type":"markdown","source":"<a id=\"3\"></a> <br>\n### BUILDING DATA FRAMES FROM SCRATCH\n* We can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries\n    * zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column"},{"metadata":{"trusted":true,"_uuid":"51ae6a0376bb3a2a9c8ebc2fb7e92b3de334b578"},"cell_type":"code","source":"# data frames from dictionary\ncountry = [\"Turkey\",\"USA\"]\npopulation =[\"10000\",\"15000\"]\nlist_label= [\"country\",\"population\"]\nlist_col =[country,population]\nzipped =list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf\n             \n             ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09d30827bfcb548c499a71ff3dd97edf3b614249"},"cell_type":"code","source":"# Add column \ndf[\"capital\"] =[\"ankara\",\"miami\"]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4823f450f50142e1157679f0e3a6ae20388bf00"},"cell_type":"code","source":"#Broadcasting\ndf[\"income\"]=0 #Broadcasting entire column\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fec26c5c3b5f8b528b000f360525140abfdd3166"},"cell_type":"markdown","source":"<a id=\"4\"></a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n\n* Plot\n* Subplot\n* Histogram:\n    * bins: number of bins\n    * range(tuble): min and max values of bins\n    * normed(boolean): normalize or not\n    * cumulative(boolean): compute cumulative distribution"},{"metadata":{"trusted":true,"_uuid":"ec96531b6fe7b8df50d6481940ce76996891d66e"},"cell_type":"code","source":"# Plotting all data\nnew_data =data.loc[:,[\"runtime\",\"popularity\"]]\nnew_data.plot()\n# it is confusing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a594ed84647e57128ef47bbb0054b06abd20b269"},"cell_type":"code","source":"#subplots\nnew_data.plot(subplots=True)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d67ce305c244e21c82290ae4eaa0ccc785f26cac"},"cell_type":"code","source":"# scatter plot\nnew_data.plot(kind=\"scatter\",x=\"runtime\",y=\"popularity\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b622fa401b8a75a8fe4e282965fd1f67060219b6"},"cell_type":"code","source":"#histogram plot\nnew_data.plot(kind=\"hist\",y=\"popularity\",bins=40,range =(0,250),normed=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fbec5f5d6e7d4da1867f8ca462fbf3c3450515d1"},"cell_type":"code","source":"# histogram subplot with non-cumulative and cumulative\nfig,axes =plt.subplots(nrows=2,ncols=1)\nnew_data.plot(kind=\"hist\",y=\"popularity\",bins =50,range =(0,250),normed=True,ax=axes[0])\nnew_data.plot(kind=\"hist\",y=\"popularity\",bins =50,range =(0,250),normed=True,ax=axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd027b9d2ae097648cb56a56c1ab470618eeb30b"},"cell_type":"markdown","source":"<a id=\"5\"></a> <br>\n### STATISTICAL EXPLORATORY DATA ANALYSIS\nI already explained it at previous parts. However lets look at one more time.\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry"},{"metadata":{"trusted":true,"_uuid":"3ab184bc8b9107d2c4aaabf715eb114b193e0389"},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1d302a0ee1880623591ef6037b9afaa4c0fb97e"},"cell_type":"markdown","source":"<a id=\"6\"></a> <br>\n### INDEXING PANDAS TIME SERIES\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format"},{"metadata":{"trusted":true,"_uuid":"795b09ca9f5e24099c14a739d9ed1245e836e2ae"},"cell_type":"code","source":"time_list = [\"2001-05-07\",\"2001-04-11\"]\nprint(type(time_list[1])) # As you can see date is string\n# however we want it to be datetime object\ndatetime_object=pd.to_datetime(time_list)\nprint(type(datetime_object))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcb9ce357d8f3bf29a57a36fa340143001da99e1"},"cell_type":"code","source":"# In order to practice lets take head of tmdb_500 data and add it a time list\ndata1 =data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object =pd.to_datetime(date_list)\ndata1[\"date\"] =datetime_object\n# lets make date as index\ndata1 =data1.set_index(\"date\")\ndata1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db774e2f81fdeed941d6c2ecb1d614bd5baff210"},"cell_type":"code","source":"# Now we can select according to our date index\nprint(data1.loc[\"1993-03-16\"])\nprint(data1.loc[\"1992-02-10\":\"1993-03-16\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e725888af9d794b060b7bc59a98e348b7c8ca4a"},"cell_type":"markdown","source":"<a id=\"7\"></a> <br>\n### RESAMPLING PANDAS TIME SERIES\n* Resampling: statistical method over different time intervals\n    * Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like ‘linear’, ‘time’ or index’ \n    * https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.interpolate.html\n"},{"metadata":{"trusted":true,"_uuid":"d423b0f4bdadb83de3ddc98bf868a538ef238d2d"},"cell_type":"code","source":"# We will use data1 that we create at previous part\ndata1.resample(\"A\").mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ae2f846c5d4f296fa4d66947ef5ec1d9e7a3818"},"cell_type":"code","source":"# Lets resample with month\ndata1.resample(\"M\").mean()\n# As you can see there are a lot of nan because data1 does not include all months","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0755dc53cf59380bd5535321a64f2d44849bb76"},"cell_type":"code","source":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata1.resample(\"m\").first().interpolate(\"linear\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcb64c303d914a43c928337dba786ea2610d0772"},"cell_type":"code","source":"# Or we can interpolate with mean()\ndata1.resample(\"m\").mean().interpolate(\"linear\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc1eebb60f7a8b704aef1421ef83267258926eeb"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}