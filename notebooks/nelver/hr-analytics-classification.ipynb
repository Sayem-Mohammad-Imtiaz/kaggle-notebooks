{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook we will only be working with `aug_train.csv`. The ultimate goal is to try to accurately predict whether particular candidate will be looking for a new job."},{"metadata":{},"cell_type":"markdown","source":"Importing relevant libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nimport tensorflow as tf\nimport math\nfrom scipy import special,stats #comb, factorial\nfrom keras import backend as K\nfrom scipy.stats import uniform\nfrom matplotlib import pyplot as plt\nfrom sklearn import tree\nfrom scipy import sparse,stats\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest,chi2\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler,LabelEncoder, OneHotEncoder\nfrom sklearn.metrics import classification_report, roc_auc_score, recall_score, make_scorer, plot_confusion_matrix, confusion_matrix, accuracy_score,f1_score\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hr-analytics-job-change-of-data-scientists/aug_train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(f'Shape of the dataset: {df.shape}')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that we will mostly be dealing with categorical features. Furhermore, it seems that there are quite a lot of nulls. Let's see where the nulls are:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's have a closer look at the columns with nulls:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ser = df.isnull().sum()\nser = ser[ser > 0]\ncolumns = ser.index.values\ndf[columns]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that all features with nulls are categorical. For each column, we will replace all `NaN` values with `Unknown`. But first let's verify that neither of the columns with nulls contain unique value `Unknown` (if some column already has value `Unknown`, then it clearly wouldn't make sense to replace `NaN` values with it)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"val = 'Unknown'\ntaken = False\nfor col in columns:\n    if val in df[col].unique():\n        taken = True\nif taken:\n    print(\"value `Unknown` is already taken\")\nelse: print('There is no column that contains unique value `Unknown`')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since no columns contains value `Unknown`, we will replace all nulls in the columns with it."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ser = df.isnull().sum()\nser = ser[ser > 0]\ncolumns = ser.index.values\n\nfor col in columns:\n    df[col].fillna(value='Unknown',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check whether we have nulls now:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No, we don't"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first observation suggests that `enrollee_id` will not be of much use."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df['enrollee_id'].astype(str).describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Indeed, every single value in the column is unique. We will remove the column."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df.drop(['enrollee_id'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's have a look at the distribution of our label, namely `target`:"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df['target'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that the label is pretty disbalanced."},{"metadata":{},"cell_type":"markdown","source":"Our dataset contains only two numeric features, namely `city_development_index` and `training_hours`. Let's check the statistics summary and the distribution."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cont_feat = ['city_development_index', 'training_hours']\nround(df[cont_feat].describe(),2)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cont_features = ['city_development_index', 'training_hours']\nWIDTH = 10\nLENGTH = 6\n\nrows = math.ceil(len(cont_features)/3)\nfig, ax = plt.subplots(1,2,figsize=(WIDTH,LENGTH))\nax = ax.flatten()\nfor i,feature in enumerate(cont_features):\n    ax[i].hist(df[feature],alpha=0.6)\n    ax[i].set_title(f'Distribution of a feature `{feature}`')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cont_features = ['city_development_index', 'training_hours']\ncat_variable = 'target'\nWIDTH = 10\nLENGTH = 6\n\nrows = math.ceil(len(cont_features)/3)\nfig, ax = plt.subplots(1,2,figsize=(WIDTH,LENGTH))\nax = ax.flatten()\nfor i,feature in enumerate(cont_features):\n    sns.boxplot(x=cat_variable, y=feature, data=df,ax=ax[i])\n    ax[i].set_title(f'Cond. dist. of feature `{feature}`')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that while `training_hours` doesn't seem to be doing good job at discerning those who will move to a new job, but `city_development_index` does give us some insights: the smaller the `city_development_index` (generally speaking), the more likely it is that he will be looking for a new job."},{"metadata":{},"cell_type":"markdown","source":"Now let's check the bivariate conditional distribution"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\ncont_features = ['city_development_index', 'training_hours']\nsns.scatterplot(data=df, x=cont_features[0], y=cont_features[1], hue='target',alpha=0.6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Besides what we have already mentioned (i.e., smaller `city_development_index` implies higher chance of a candidate looking for a new job), there doesn't seem to be any significant pattern."},{"metadata":{},"cell_type":"markdown","source":"Now let's have a look at the categorical features:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cat_features = ['city', 'gender', 'relevent_experience',\n       'enrolled_university', 'education_level', 'major_discipline',\n       'experience', 'company_size', 'company_type', 'last_new_job',]\n\ncount = np.array([df[feature].unique().size for feature in cat_features])\n\nto_sort = np.argsort(count)[::-1]\ncat_features = np.array(cat_features)[to_sort]\ncount = count[to_sort]\n\nplt.figure(figsize=(11,6))\ngraph = sns.barplot(cat_features,count)\nfor p in graph.patches:\n    graph.annotate(p.get_height(), (p.get_x()+0.4, p.get_height()),\n                   ha='center', va='bottom',\n                   color= 'black')\n\n\nplt.title(\"Number of unique values per each feature\")\nplt.xticks(rotation=45)\nplt.ylabel('Count')\nplt.xlabel('Feature')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For each feature (besides `city`), let's visualize the distribution (conditional on `target`)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cat_features = ['city', 'gender', 'relevent_experience',\n       'enrolled_university', 'education_level', 'major_discipline',\n       'experience', 'company_size', 'company_type', 'last_new_job',]\n\nplt.figure(figsize=(10,30))\nfor feature in cat_features[1:]:\n    dataframe = df\n    feature_1 = feature # FEATURE\n    feature_2 = 'target' # LABEL\n    to_sort = True # `True` would be useful if label is binary\n\n\n\n    cs = pd.crosstab(dataframe[feature_1],\n                     dataframe[feature_2],\n                     normalize='index')\n    if to_sort == True:\n        cs.sort_values(by=[cs.columns[0]],inplace=True)\n    cs.plot.bar(stacked=True,figsize=(10,6))\n    plt.xlabel(feature)\n    plt.xticks(rotation=45)\n    plt.title(f'Conditional distributions of `{feature_2}`')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Couple of observations can be made here: \n1. Gender doesn’t seem to be a good predictor of people who want to switch jobs.\n2. If one didn’t have a previous relevant experience, one is more likely to look for a new job.\n3.  Those who signed up for a full time course are more likely to look for a new job (especially when we compare with the candidates who didn’t sign up for any course)\n4. Those with little or no working experience (i.e., working experience less than 1 year) are the most likely to look for a new job (roughly 50% probability). Furthermore, based on the graph, we see that the experience is (roughly) negatively correlated with the proportion of people who look for a new job, in other words: the more experience you have, the less likely it is that you will be looking for a new job.\n5.  The number of previous jobs is negatively correlated with the probability of looking for a new job (as the last graph suggests): the more jobs you have had previously, the less likely it is that you will be looking for a new job."},{"metadata":{},"cell_type":"markdown","source":"# Feature preprocessing"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Preprosessing cat. features"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cat_features = ['city', 'gender', 'relevent_experience',\n       'enrolled_university', 'education_level', 'major_discipline',\n       'experience', 'company_size', 'company_type', 'last_new_job',]\n\n\ncat_feat_df = df[cat_features].copy()\ncat_feat_df = OneHotEncoder().fit_transform(cat_feat_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Concatenating matrices containing cat. and cont. features."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cont_feat = ['city_development_index','training_hours']\ncont_feat_df = df[cont_feat].copy()\ncont_feat_df = sparse.csr_matrix(cont_feat_df.values)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"X,y = sparse.hstack((cat_feat_df,cont_feat_df)), df['target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split our dataset into training and test sets."},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=11)\n\n\nsc = StandardScaler()\n\nleft = X_train[:,:-2]\nright = sparse.csr_matrix(sc.fit_transform(X_train[:,-2:].todense()))\nX_train = sparse.hstack((left,right)).tocsr()\n\n\nleft = X_test[:,:-2]\nright = sparse.csr_matrix(sc.transform(X_test[:,-2:].todense()))\nX_test = sparse.hstack((left,right)).tocsr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate models\n\nSince we deal with the imbalanced target variable (i.e., there are way more entries with label $0$ than with label $1$), we would expect our models to incorrectly predict a lot of entries with label $1$. Hence the metric that we will be closely looking at is f1 score (where positive label is $1$)"},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"log_random_state = None\nlog_clf = LogisticRegression(random_state=log_random_state,max_iter=500).fit(X_train, y_train)\nprint(classification_report(y_true=y_test, y_pred=log_clf.predict(X_test)))\nplot_confusion_matrix(log_clf, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected, we see that the model misclassifies a lot of people who chose to look for a new job (i.e., entries where the value in the `target` is $1$)"},{"metadata":{},"cell_type":"markdown","source":"# KNN (25 neighbors)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"knn_clf = KNeighborsClassifier(n_neighbors=25).fit(X_train,y_train)\nprint(classification_report(y_true=y_test, y_pred=knn_clf.predict(X_test)))\nplot_confusion_matrix(knn_clf, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest\nWhere the hyperparameters are:\n1. `max_depth` = 20\n2. `n_estimators` = 700\n3. `bootstrap` = False"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"rf_clf = RandomForestClassifier(bootstrap=False, \n                                max_depth=20, \n                                n_estimators=700,\n                                random_state=13).fit(X_train, y_train)\n\nprint(classification_report(y_true=y_test, y_pred=rf_clf.predict(X_test)))\nplot_confusion_matrix(rf_clf, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM: Default hyperparameters"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"svm_clf = SVC(gamma=0.0870736086175949).fit(X_train,y_train)\nprint(classification_report(y_true=y_test, y_pred=svm_clf.predict(X_test)))\nplot_confusion_matrix(svm_clf, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that even without any hyperparameter tuning, SVM performs way better than the previous models (mainly signified by the fact that SVM gives us the highest `f1 score` (where $1$ is positive label))\nIn a separate notebook, I have tested different sets of hyperparameters. After trying dozens of combinations, I haven't found any set that would give us better f1 score (positive label: 1) than the default set (by the \"default\" set of hyperparameters, I mean $C=1$, gamma $=$ 'scale' $\\approx  0.087$, and kernel $=$ 'rbf')"},{"metadata":{},"cell_type":"markdown","source":"# XGBoost\n\nAfter using grid search (in a separate notebook), the optimal (i.e., those that maximize f1-score (where positive label is $1$)) hyperparameters found are:\n\n1. `max_depth` = 7\n\n2. `eta` = 0.047895\n\n3. `ojbective` = 'binary:hinge'\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import xgboost as xgb\n\ndtrain = xgb.DMatrix(X_train,label=y_train)\nparam = {'max_depth': 7, \n         'eta': 0.047895, 'objective': \n         'binary:hinge'}\nbst = xgb.train(params=param,dtrain=dtrain, num_boost_round=30)\n\n\ndtest = xgb.DMatrix(X_test)\nprint(classification_report(y_true=y_test,y_pred=bst.predict(dtest)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that while precision for label $1$ drops by roughly $3\\%$, the recall increases significantly, thus giving us the best f1-score (0.62) out of all models used."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}