{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndata = pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv', index_col='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['stroke']==1].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt \n\ndef plot_bar_graph(column):\n    ax = sns.countplot(x=column,data=data[data['stroke'] == 1])\n    total_1 =float(len(data[data['stroke'] == 1]))\n    plt.title(column + '/ Suffered stroke')\n    plt.xlabel(column)\n\n    for p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_height()/total_1)\n        x = p.get_x() + p.get_width()\n        y = p.get_height()\n        ax.annotate(percentage, (x, y),ha='right')\n    plt.show()\n\n    ax = sns.countplot(x=column,data=data[data['stroke'] == 0])\n    total_1 =float(len(data[data['stroke'] == 0]))\n    plt.title(column + \" / Didnt suffer stroke\")\n    plt.xlabel(column)\n\n    for p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_height()/total_1)\n        x = p.get_x() + p.get_width()\n        y = p.get_height()\n        ax.annotate(percentage, (x, y),ha='right')\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_bar_graph(column):\n    ax = sns.countplot(x=column,data=data[data['stroke'] == 1])\n    total_1 =float(len(data[data['stroke'] == 1]))\n    plt.title(column + ' / Suffered stroke')\n    plt.xlabel(column)\n\n    for p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_height()/total_1)\n        x = p.get_x() + p.get_width()\n        y = p.get_height()\n        ax.annotate(percentage, (x, y),ha='right')\n    plt.show()\n\n    ax = sns.countplot(x=column,data=data[data['stroke'] == 0])\n    total_1 =float(len(data[data['stroke'] == 0]))\n    plt.title(column + \" / Didnt suffer stroke\")\n    plt.xlabel(column)\n\n    for p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_height()/total_1)\n        x = p.get_x() + p.get_width()\n        y = p.get_height()\n        ax.annotate(percentage, (x, y),ha='right')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_line_graph(column):\n    plt.figure(figsize=(12, 6))\n    plt.title(column + ' /Suffered stroke')\n    sns.histplot(data[data['stroke'] == 1][column], kde=True)\n    plt.figure(figsize=(12, 6))\n    plt.title(column + ' / Didnt suffer Stroke')\n    sns.histplot(data[data['stroke'] == 0][column], kde=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('gender')['stroke'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('hypertension')['stroke'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('heart_disease')['stroke'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('ever_married')['stroke'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('work_type')['stroke'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('Residence_type')['stroke'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('smoking_status')['stroke'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['stroke'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.loc[(data['stroke'] == 1) & (data['gender'] == 'Male')]['gender']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['gender'] == 'Male']['stroke']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_pie2(column, value_1, value_2):\n    race_score = data[data[column] == value_1]['stroke']\n    values = race_score.value_counts()\n    labels = values.keys()\n    bar,ax = plt.subplots(figsize=(8,8))\n    plt.pie(x = values, labels = labels , autopct='%.2f%%',pctdistance=0.8)\n    plt.title(column + ' ' + str(value_1) + ' stroke', fontsize=20)\n    race_score = data[data[column] == value_2]['stroke']\n    values = race_score.value_counts()\n    labels = values.keys()\n    bar,ax = plt.subplots(figsize=(8,8))\n    plt.pie(x = values, labels = labels , autopct='%.2f%%',pctdistance=0.8)\n    plt.title(column + ' ' + str(value_2) + ' stroke', fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pie2('gender', 'Male', 'Female')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pie2('ever_married', 'Yes', 'No')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pie2('hypertension', 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pie2('heart_disease', 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['stroke']==1].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['stroke']==1].groupby('heart_disease')['stroke'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['stroke']==1].groupby('hypertension')['stroke'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('heart_disease')['stroke'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('hypertension')['stroke'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.stroke.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.hypertension.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['heart_disease'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_pie(column):\n    race_score = data[data['stroke'] == 1][column]\n    values = race_score.value_counts()\n    labels = values.keys()\n    bar,ax = plt.subplots(figsize=(8,8))\n    plt.pie(x = values, labels = labels , autopct='%.2f%%',pctdistance=0.8)\n    plt.title(column + ' / Suffered stroke', fontsize=20)\n    race_score = data[data['stroke'] == 0][column]\n    values = race_score.value_counts()\n    labels = values.keys()\n    bar,ax = plt.subplots(figsize=(8,8))\n    plt.pie(x = values, labels = labels , autopct='%.2f%%',pctdistance=0.8)\n    plt.title(column + ' / Didnt suffer stroke', fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.arange(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('gender')['stroke'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = 2\nstroke = (data.loc[(data['stroke'] == 1) & (data['gender'] == 'Male')]['gender'].count(), data.loc[(data['stroke'] == 1) & (data['gender'] == 'Female')]['gender'].count())\nno_stroke = (data.loc[(data['stroke'] == 0) & (data['gender'] == 'Male')]['gender'].count(), data.loc[(data['stroke'] == 0) & (data['gender'] == 'Female')]['gender'].count())\n\nind = np.arange(N) # the x locations for the groups\nwidth = 0.8\nfig = plt.figure()\nax = fig.add_axes([0,0,2,1])\nax.bar(ind, stroke, width, color='r')\nax.bar(ind, no_stroke, width,bottom=stroke, color='b')\nax.set_ylabel('Scores')\nax.set_title('Scores by group and gender')\nax.set_xticks(ind, ('Stroke', 'No Stroke'))\nax.set_yticks(np.arange(0, 3000, 100))\nax.legend(labels=['Stroke', 'No Stroke'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = 2\nstroke = (data.loc[(data['stroke'] == 1) & (data['hypertension'] == 1)]['hypertension'].count(), data.loc[(data['stroke'] == 1) & (data['hypertension'] == 0)]['hypertension'].count())\nno_stroke = (data.loc[(data['stroke'] == 0) & (data['hypertension'] == 1)]['hypertension'].count(), data.loc[(data['stroke'] == 0) & (data['hypertension'] == 0)]['hypertension'].count())\n\nind = np.arange(N) # the x locations for the groups\nwidth = 0.5\nfig = plt.figure()\nax = fig.add_axes([0,0,1,1])\nax.bar(ind, stroke, width, color='r')\nax.bar(ind, no_stroke, width,bottom=stroke, color='b')\nax.set_ylabel('Scores')\nax.set_title('Scores by group and hypertension')\nax.set_xticks(ind, ('Stroke', 'No Stroke'))\nax.set_yticks(np.arange(0, 5000, 500))\nax.legend(labels=['Stroke', 'No Stroke'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['gender'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar_graph('gender')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_line_graph('age')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar_graph('hypertension')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar_graph('heart_disease')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar_graph('ever_married')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar_graph('work_type')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar_graph('Residence_type')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_line_graph('avg_glucose_level')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_line_graph('bmi')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bar_graph('smoking_status')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_pie(column):\n    race_score = data[data['stroke'] == 1][column]\n    values = race_score.value_counts()\n    labels = values.keys()\n    bar,ax = plt.subplots(figsize=(8,8))\n    plt.pie(x = values, labels = labels , autopct='%.2f%%',pctdistance=0.8)\n    plt.title(column + ' / Suffered stroke', fontsize=20)\n    race_score = data[data['stroke'] == 0][column]\n    values = race_score.value_counts()\n    labels = values.keys()\n    bar,ax = plt.subplots(figsize=(8,8))\n    plt.pie(x = values, labels = labels , autopct='%.2f%%',pctdistance=0.8)\n    plt.title(column + ' / Didnt suffer stroke', fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pie('smoking_status')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pie('work_type')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=\"gender\",y=\"bmi\",data=data,palette=\"Set1\")\nplt.title(\"Distribution of bmi\")\nplt.xlabel(\"gender\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=data, x=\"age\", y=\"bmi\", hue='stroke')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=\"hypertension\",y=\"bmi\",data=data,palette=\"Set1\")\nplt.title(\"Distribution of bmi\")\nplt.xlabel(\"hypertension\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=\"heart_disease\",y=\"bmi\",data=data,palette=\"Set1\")\nplt.title(\"Distribution of bmi\")\nplt.xlabel(\"heart_disease\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=\"ever_married\",y=\"bmi\",data=data,palette=\"Set1\")\nplt.title(\"Distribution of bmi\")\nplt.xlabel(\"ever_married\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=\"work_type\",y=\"bmi\",data=data,palette=\"Set1\")\nplt.title(\"Distribution of bmi\")\nplt.xlabel(\"work_type\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=\"Residence_type\",y=\"bmi\",data=data,palette=\"Set1\")\nplt.title(\"Distribution of bmi\")\nplt.xlabel(\"Residence_type\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(data=data, x=\"avg_glucose_level\", y=\"bmi\", hue='stroke')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=\"smoking_status\",y=\"bmi\",data=data,palette=\"Set1\")\nplt.title(\"Distribution of bmi\")\nplt.xlabel(\"smoking_status\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = [ 0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85]\nlabels = [ 'Zero', 'Cinco', 'Diez', 'Quince', 'Veint', 'VeintC', 'Treint', 'TreintC', 'Cuar', 'CuarC', 'Cinc', 'CincC'\n         , 'Ses', 'SesC', 'Set', 'SetC', 'Och']\ndata['AgeGroup'] = pd.cut(data[\"age\"], bins, labels = labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\n#data.groupby(['hypertension','ever_married','work_type', 'AgeGroup'])['bmi'].agg(lambda x: stats.mode(x)[0][0])\ndata['bmi'] = data.groupby(['hypertension','ever_married','work_type', 'AgeGroup'])['bmi'].transform(lambda x: x.fillna(stats.mode(x)[0][0]))\ndata['bmi'] = data.groupby(['AgeGroup'])['bmi'].transform(lambda x: x.fillna(stats.mode(x)[0][0]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop('AgeGroup', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\ncolumns = ['gender','ever_married','work_type','Residence_type','smoking_status']\noh_encoder = OneHotEncoder(drop='first', sparse=False)\noh_encoded = pd.DataFrame(oh_encoder.fit_transform(data[columns]))\noh_encoded.index = data.index\nnum_data = data.drop(columns, axis=1)\nconcatenated = pd.concat([num_data, oh_encoded], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"concatenated","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"concatenated.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nnorm_cols = ['avg_glucose_level','bmi']\n# Min-max normalization\nconcatenated[norm_cols] = MinMaxScaler().fit_transform(concatenated[norm_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"concatenated","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = concatenated.drop(['stroke'], axis=1)\nY = concatenated.stroke\n\nx_train, x_val, y_train, y_val = train_test_split(X, Y, test_size = 0.22, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n%pylab\n%matplotlib inline\nfrom sklearn.linear_model import LogisticRegression\n\n\ndef calculateIV(data, features, target):\n    result = pd.DataFrame(index = ['IV'], columns = features)\n    result = result.fillna(0)\n    var_target = array(data[target])\n    \n    for cat in features:\n        var_values = array(data[cat])\n        var_levels = unique(var_values)\n\n        mat_values = numpy.zeros(shape=(len(var_levels),2))\n        \n        for i in range(len(var_target)):\n            for j in range(len(var_levels)):\n                if var_levels[j] == var_values[i]:\n                    pos = j\n                    break\n\n            # Estimación del número valores en cada nivel\n            if var_target[i]:\n                mat_values[pos][0] += 1\n            else:\n                mat_values[pos][1] += 1\n\n            # Obtención del IV\n            IV = 0\n            for j in range(len(var_levels)):\n                if mat_values[j][0] > 0 and mat_values[j][1] > 0:\n                    rt = mat_values[j][0] / (mat_values[j][0] + mat_values[j][1])\n                    rf = mat_values[j][1] / (mat_values[j][0] + mat_values[j][1])\n                    IV += (rt - rf) * np.log(rt / rf)\n                    \n        # Se agrega el IV al listado\n        result[cat] = IV\n        \n    return result\n\ncalculateIV(concatenated, concatenated.columns, 'stroke')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\ndef calculateVIF(data):\n    features = list(data.columns)\n    num_features = len(features)\n    \n    model = LinearRegression()\n    \n    result = pd.DataFrame(index = ['VIF'], columns = features)\n    result = result.fillna(0)\n    \n    for ite in range(num_features):\n        x_features = features[:]\n        y_featue = features[ite]\n        x_features.remove(y_featue)\n        \n        x = data[x_features]\n        y = data[y_featue]\n        \n        model.fit(data[x_features], data[y_featue])\n        \n        result[y_featue] = 1/(1 - model.score(data[x_features], data[y_featue]))\n    \n    return result\n\ndef selectDataUsingVIF(data, max_VIF = 5):\n    result = data.copy(deep = True)\n    \n    VIF = calculateVIF(result)\n    \n    while VIF.values.max() > max_VIF:\n        col_max = np.where(VIF == VIF.as_matrix().max())[1][0]\n        features = list(result.columns)\n        features.remove(features[col_max])\n        result = result[features]\n        \n        VIF = calculateVIF(result)\n        \n    return result\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calculateVIF(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selectDataUsingVIF(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_WoE(data, var, target):\n    crosstab = pd.crosstab(data[target], data[var])\n    \n    print(\"Obteniendo el Woe para la variable\", var, \":\")\n    \n    for col in crosstab.columns:\n        if crosstab[col][1] == 0:\n            print(\"  El WoE para\", col, \"[\", sum(crosstab[col]), \"] es infinito\")\n        else:\n            print(\"  El WoE para\", col, \"[\", sum(crosstab[col]), \"] es\", np.log(float(crosstab[col][0]) / float(crosstab[col][1])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"concatenated.age","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_WoE(concatenated, 'age', 'stroke')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_regression \nfrom sklearn.feature_selection import chi2 \n\nvar_sk = SelectKBest(f_regression, k = 5)\nx_sk = var_sk.fit_transform(X, Y)\n\nprint(\"Variables finales \", x_sk.shape[1])\n\nprint(\"Listado de variables \", np.asarray(list(X))[var_sk.get_support()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectPercentile\nfrom sklearn.feature_selection import f_regression \n\nvar_sp = SelectPercentile(f_regression, percentile = 50)\nx_sp = var_sp.fit_transform(X, Y)\n\nprint(\"Variables finales \", x_sp.shape[1])\n\nprint(\"Listado de variables \", np.asarray(list(X))[var_sp.get_support()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\n# Modelo para realizar los ajustes\nmodel = LinearRegression()\n\n# Variable para almecena los índices de la lista de atributos usados\nfeature_order =  []\nfeature_error = []\n\n# Iteración sobre todas las variables\nfor i in range(len(X.columns)):\n    idx_try = [val for val in range(len(X.columns)) if val not in feature_order]\n    iter_error = []\n\n    for i_try in idx_try:\n        useRow = feature_order[:]\n        useRow.append(i_try)\n\n        use = X[X.columns[useRow]]\n\n        model.fit(use, Y)\n        rmsError = numpy.linalg.norm((Y - model.predict(use)), 2)/sqrt(len(Y))\n        iter_error.append(rmsError)\n\n    pos_best = numpy.argmin(iter_error)\n    feature_order.append(idx_try[pos_best])\n    feature_error.append(iter_error[pos_best])\n\nfor i in range(len(X.columns)):\n    print(\"En el paso\", i, \"se ha insertado la variable\", \n        features[feature_order[i]], \"con un error\", feature_error[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold\n\nvar_th = VarianceThreshold(threshold = 0.60)\nx_var = var_th.fit_transform(X)\n\nprint(\"Variables originales \", X.shape[1])\nprint(\"Variables finales \", x_var.shape[1])\n\nprint(\"Listado de variables \", np.asarray(list(X))[var_th.get_support()])\nprint(var_th.get_support())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.svm import SVC\nfrom xgboost import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, train_test_split\nimport sklearn.svm as svm\nimport xgboost as xgb\n\nmodels = {\n    'SVM':{'model':svm.SVC(gamma='auto',C=5,kernel='rbf'),'params': {'C': [1,5,10]}},\n    'xgboost':{'model':xgb.XGBClassifier(),'params': {'max_depth':[4,6,8],'gamma': [0.5, 1, 2, 5]}}\n}\n#Hyperparameters tuning using GridSearchCV\nscores = []\n\nfor model_name, mp in models.items():\n    clf =  GridSearchCV(mp['model'],mp['params'] ,cv= 2, return_train_score=False)\n    clf.fit(X, Y)\n    scores.append({\n        'model': model_name,\n        'best_score': clf.best_score_,\n        'best_params': clf.best_params_\n    })\n    \ndf_model = pd.DataFrame(scores,columns=['model','best_score','best_params'])\ndf_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import plot_importance\nfrom sklearn.metrics import classification_report,accuracy_score\nimport xgboost as xgb\nmodel = xgb.XGBClassifier(gamma=5,max_depth=4)\nmodel.fit(x_train,y_train)\nypred = model.predict(x_val)\nprint(classification_report(y_val,ypred))\nprint(\"Xgboost model accuracy - \", accuracy_score(y_val,ypred)*100)\n#Plotting features importance\nplt.rcParams[\"figure.figsize\"] = (10, 7)\nplot_importance(model)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvc = SVC()\nsvc.fit(x_train, y_train)\ny_pred = svc.predict(x_val)\nacc_svc = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_svc,'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\nlgbm = lgb.LGBMClassifier(objective='binary', num_leaves=10, learning_rate=0.05, \n                      max_depth=1, n_estimators=50, boosting_type='goss') # You can play with hyperparameters, pay special attention to num_leaves, max_depth and n_estimators.\nlgbm.fit(x_train, y_train)\ny_pred = lgbm.predict(x_val)\nacc_svc = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_svc,'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_val)\nacc_logreg = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_logreg,'%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['age','hypertension','heart_disease','avg_glucose_level',2,5,6,8]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ncols = ['age','hypertension','heart_disease','avg_glucose_level',2,5,6,8]\nX = concatenated[cols]\nY = concatenated.stroke\n\nx2_train, x2_val, y2_train, y2_val = train_test_split(X, Y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y2_val.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y2_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y2_pred.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import mean_absolute_error\n\nlogreg = LogisticRegression()\nlogreg.fit(x2_train, y2_train)\ny2_pred = logreg.predict(x2_val)\nprint(round(accuracy_score(y2_pred, y2_val) * 100, 2),'%')\nprint(mean_absolute_error(y2_pred, y2_val))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}