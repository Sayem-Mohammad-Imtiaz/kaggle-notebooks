{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PANDAS TO READ CSV FILE NUMPY FOR ANY USE CASE"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = \"/kaggle/input/twitter-sentiment-analysis-hatred-speech/train.csv\"\ntrain_data = pd.read_csv(train_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DROPING AXIS\nThe id coloumn is no use to me so i am going to drop it."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_data.drop('id',axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets Know the size of our training"},{"metadata":{"trusted":true},"cell_type":"code","source":"size = train_data.shape[0]\nprint(size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.countplot(train_data['label'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LIBRARIES FOR PREPROCESSING TEXT"},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nimport re\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PREPRAING CORPUS OUT OF THE TEXT\nI created a function corpus_tweets to create a corpus of sentences containing lametized words . \n<br> Creating the function would ease the work further .\n<br> The corpus will exactly have the tweets converted into list of tweets where the words are lametized. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_corpus(tweets):\n  corpus_tweets = []\n  size = tweets.shape[0]\n  ps = PorterStemmer()\n  for i in range(0,size):\n    tweet = re.sub(pattern='[^a-zA-Z]',repl=' ', string=tweets['tweet'][i])\n\n    tweet = re.sub(pattern='user' , repl='' , string = tweet)\n\n    tweet = tweet.lower()\n\n    words = tweet.split()\n\n    words = [ps.stem(word) for word in words if not word in stopwords.words('english')]\n\n    tweet = ' '.join(words)\n\n    corpus_tweets.append(tweet)\n  return corpus_tweets\n\ncorpus_tweets_train = prepare_corpus(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus_tweets_train[0:2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### TFIDF Vectorizer\nIts is required to convert the corpus into meanigful sum of numbers . \n<br>TFIDF vectorizer performs well text preprocessing than count vectorizer . "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(max_features=7000)\nX_tfidf = tfidf.fit_transform(corpus_tweets_train).toarray()\ny_ifidf = train_data['label'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tfidf[0:2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SPLITTING THE DATA FOR TRAIN AND TEST\nUsing the train test split X and y are splitted to 80:20 ratio . "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndef split_train_test(X,y):\n  X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.20)\n  return X_train , X_test , y_train , y_test\n\nX_train_idf , X_test_idf , y_train_idf , y_test_idf = split_train_test(X_tfidf, y_ifidf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ACCURACY AND CLASSIFICATION REPORT FUNCTION"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\ndef accuracy_check(model,data,label):\n  y_pred = model.predict(data)\n  print(classification_report(label , y_pred)) \n  accuracy = accuracy_score(label , y_pred)\n  return accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nnb_idf = MultinomialNB()\nnb_idf.fit(X_train_idf , y_train_idf)\nnb_idf_accuracy = accuracy_check(nb_idf , X_test_idf , y_test_idf)\nprint(nb_idf_accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MODEL PERFORMANCE\nThe accuracy hit is nearly 96% on the test data . \n<br> For the final model the complete data could be provided . "},{"metadata":{},"cell_type":"markdown","source":"#### A FUNCTION TO KNOW APPROPRIATE VALUE OF ALPHA(Hyperparameter)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def optimization_idf(X_train_idf , X_test_idf , y_train_idf , y_test_idf):\n  best_accuracy = 0.0\n  alpha_val = 0.0\n  for i in np.arange(0.1,1.1,0.1):\n    temp_classifier = MultinomialNB(alpha=i)\n    temp_classifier.fit(X_train_idf, y_train_idf)\n    temp_y_pred = temp_classifier.predict(X_test_idf)\n    score = accuracy_score(y_test_idf, temp_y_pred)\n    print(\"Accuracy score for alpha={} is: {}%\".format(round(i,1), round(score*100,2)))\n    if score>best_accuracy:\n      best_accuracy = score\n      alpha_val = i\n  print('The best accuracy is {}% with alpha value as {}'.format(round(best_accuracy*100, 2), round(alpha_val,1)))\n  return alpha_val\n\noptimal_value_idf = optimization_idf(X_train_idf , X_test_idf , y_train_idf , y_test_idf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ml_model_final = MultinomialNB(alpha = 0.1)\nml_model_final.fit(X_tfidf , y_ifidf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### MAKING PREDICTIONS FOR THE TEST DATA"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_path = \"/kaggle/input/twitter-sentiment-analysis-hatred-speech/test.csv\"\ntest_data = pd.read_csv(test_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br>The smae function use to convert into corpus . \n<br>The tfidf defined previously used for transformation . "},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus_test = prepare_corpus(test_data)\nvectors = tfidf.transform(corpus_test).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answer = ml_model_final.predict(vectors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = test_data\nsubmission.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['Predicted Labels'] = answer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### FINAL CHECKS"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ones = [ans for ans in answer if ans==1]\nlen(ones)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.countplot(submission['Predicted Labels'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv' , index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### HIT A UPVOTE IF YOU LIKED OR IT HELPED YOU . \nMy Special thanks to Krish Naik Sir for his youtube tutorials and His NLP playlist for awesome content ."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}