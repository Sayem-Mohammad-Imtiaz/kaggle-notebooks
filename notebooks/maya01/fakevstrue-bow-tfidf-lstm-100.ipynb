{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB,GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.model_selection import cross_val_score,cross_val_predict\nfrom sklearn.metrics import confusion_matrix,precision_score,recall_score,f1_score,precision_recall_curve,roc_auc_score,roc_curve\nimport gensim\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Embedding,LSTM,Dropout\nfrom keras.callbacks import ReduceLROnPlateau\nimport tensorflow as tf\nfrom keras.preprocessing import text, sequence\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![fake_news](https://media-assets-02.thedrum.com/cache/images/thedrum-prod/s3-news-tmp-140656-fake_news--default--1280.jpg)","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path = '/kaggle/input/fake-and-real-news-dataset/'\nfake = pd.read_csv(path+'Fake.csv')\ntrue = pd.read_csv(path+'True.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Shape ->',fake.shape)\nprint('Description ->',fake.describe())\nprint('Checking null values .. . ',fake.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.countplot(x='subject',data=fake)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true.title.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Shape ->',true.shape)\nprint('Description ->',true.describe())\nprint('Checking null values .. . ',true.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.countplot(x='subject',data=true)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true['category'] = 1\nfake['category'] = 0\ndf = pd.concat([true,fake])\nprint('Shape ->',df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df.category)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.countplot(df.subject)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Combining Features ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['combined_text'] = df['text'] + ' ' + df['title'] + ' ' +df['subject']\ndel df['title']\ndel df['text']\ndel df['subject']\ndel df['date']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom collections import Counter\nnltk.download('stopwords')\nnltk.download('wordnet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STOPWORDS = set(stopwords.words('english'))\npunctuations = string.punctuation\nSTOPWORDS.update(punctuations)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_word_cloud(data,title=None):\n    word_cloud = WordCloud(\n        background_color = 'white',\n        max_words =1000,\n        width=1600,\n        height=800,\n        stopwords=STOPWORDS,\n        max_font_size = 40, \n        scale = 3,\n        random_state = 42 ).generate(data)\n    fig = plt.figure(1, figsize = (20, 20))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize = 20)\n        fig.subplots_adjust(top = 2.3)\n\n    plt.imshow(word_cloud)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(STOPWORDS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    text = text.lower()\n    text = \" \".join([word for word in text.split() if word not in STOPWORDS])\n    text = re.sub(r'https?://\\S+|www\\.\\S+',r'',text)\n    text = re.sub('[\\d]',r'',text)\n    text = re.sub('[()]',r'',text)\n    text = re.sub(r'(<.*?>)',r'',text)\n    text = re.sub(r'[^(A-Za-z)]',r' ',text)\n    text = re.sub(r'\\s+',r' ',text)\n  \n    return text  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['text'] = df['combined_text'].apply(lambda x : clean_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[:30]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_word_cloud(\" \".join(df[df.category == 1].text),'True Words')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_word_cloud(\" \".join(df[df.category == 0].text),'Fake Words')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Word Distribution between True and Fake Words","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_len = df[df.category == 0].text.str.len()\ntrue_len = df[df.category == 1].text.str.len()\n\nplt.hist(fake_len, bins=20, label=\"fake_length\")\nplt.hist(true_len, bins=20, label=\"true_length\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Ploting Most comman True and Fake words in dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_word_token = word_tokenize(\" \".join(df[df.category == 0].text))\ntrue_word_token = word_tokenize(\" \".join(df[df.category == 1].text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_20_fake = Counter(fake_word_token).most_common(20)\nfreq_20_true = Counter(true_word_token).most_common(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_most_comman_words(data,label):\n    most_comman_dict = {}\n    palette=''\n    for x in data:\n        tup = x\n        most_comman_dict[tup[0]] = tup[1]\n    d = pd.DataFrame({label: list(most_comman_dict.keys()),\n                  'Count': list(most_comman_dict.values())})\n    if label=='fake words':\n        palette='plasma_r'\n    else:\n        palette='rocket'\n    plt.figure(figsize=(12, 8))\n    ax = sns.barplot(data=d, x= \"Count\", y = label,palette=palette)\n    ax.set(ylabel = label)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_most_comman_words(freq_20_fake,'fake words')\nplot_most_comman_words(freq_20_true,'true words')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Splitting into Train-Test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.text\ny = df.category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"BOW","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"vect = CountVectorizer()\nX_train = vect.fit_transform(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bow_clf = MultinomialNB()\nhistory = bow_clf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history.score(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_score = cross_val_score(bow_clf,X_train,y_train,cv=10,scoring='accuracy')\nprint(val_score.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = cross_val_predict(bow_clf,X_train, y_train, cv=10)\ny_train_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bow_train_cm = confusion_matrix(y_train,y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cm_scores(cm):\n    TN = cm[0][0]\n    FP = cm[0][1]\n    FN = cm[1][0]\n    TP = cm[1][1]\n    precision = TP/(TP+FP)\n    recall = TP/(TP+FN)\n    f1_scre = 2*((precision*recall)/(precision+recall))\n    return TN,FP,FN,TP,precision,recall,f1_scre","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TN,FP,FN,TP,precision,recall,f1_score = cm_scores(bow_train_cm)\nprint('Precision : ',precision)\nprint('Recall : ',recall)\nprint('F1 Score:',f1_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precisions,recalls,thresholds = precision_recall_curve(y_train,y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_precision_vs_recall(precisions,recalls):\n    plt.plot(recalls,precisions,'g-',linewidth=2)\n    plt.grid(True)\n    plt.ylabel('Precision')\n    plt.xlabel('Recall')\n\nplt.figure(figsize=(12, 10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_precision_recall_vs_threshold(precisions,recalls,thresholds):\n    plt.figure(figsize=(8, 4))\n    plt.plot(thresholds,precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n    plt.plot(thresholds,recalls[:-1], \"g--\", label=\"Recall\", linewidth=2)\n    plt.legend(loc=\"center right\", fontsize=16) \n    plt.xlabel(\"Threshold\", fontsize=16)        \n    plt.grid(True)                              ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_roc_curve(FPR,TPR,label):\n    plt.plot(FPR,TPR,'b--',linewidth=2,label=label)\n    plt.grid(True)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlabel('False Positive Rate (FPR)')\n    plt.ylabel('True Positive Rate (TPR)')\n    plt.legend(loc='best')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recalls[np.argmax(precisions >= 0.90)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_precision_vs_recall(precisions,recalls)\nplt.plot([0.9636, 0.9636], [0., 0.9], \"r:\")\nplt.plot([0.0, 0.9636], [0.9, 0.9], \"r:\")\nplt.plot([0.9636], [0.9], \"ro\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_precision_recall_vs_threshold(precisions,recalls,thresholds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FPR,TPR,thresholds = roc_curve(y_train,y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(FPR,TPR,'MultinomialNB')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score = roc_auc_score(y_train,y_train_pred)\nprint('roc_auc_score -- >',roc_auc_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = vect.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = history.predict(X_test)\nprint(predictions[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bow_cm_test = confusion_matrix(y_test,predictions)\nTN,FP,FN,TP,precision,recall,f1_score = cm_scores(bow_cm_test)\nprint('Precision : ',precision)\nprint('Recall : ',recall)\nprint('F1 Score:',f1_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TF-IDF","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\nX_train = tfidf.fit_transform(x_train.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_clf = MultinomialNB()\nhistory = tfidf_clf.fit(X_train,y_train)\nprint('Model Score: ',history.score(X_train,y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_clf = RandomForestClassifier(n_estimators=500, random_state=42).fit(X_train, y_train)\nprint('Model Score: ',rf_clf.score(X_train,y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_score = cross_val_score(tfidf_clf,X_train,y_train,cv=5,scoring='accuracy')\nprint(val_score.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time\nrf_val_score = cross_val_score(rf_clf,X_train,y_train,cv=5,scoring='accuracy')\nprint(rf_val_score.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = cross_val_predict(tfidf_clf,X_train, y_train, cv=5)\ny_train_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_y_train_pred = cross_val_predict(rf_clf,X_train, y_train, cv=5)\nrf_y_train_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_train_cm = confusion_matrix(y_train,y_train_pred)\nrf_tfidf_train_cm = confusion_matrix(y_train,rf_y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TN,FP,FN,TP,precision,recall,f1_score = cm_scores(tfidf_train_cm)\nprint('Precision : ',precision)\nprint('Recall : ',recall)\nprint('F1 Score:',f1_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_TN,rf_FP,rf_FN,rf_TP,rf_precision,rf_recall,rf_f1_score = cm_scores(rf_tfidf_train_cm)\nprint('Precision : ',rf_precision)\nprint('Recall : ',rf_recall)\nprint('F1 Score:',rf_f1_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precisions,recalls,thresholds = precision_recall_curve(y_train,y_train_pred)\nrf_precisions,rf_recalls,rf_thresholds = precision_recall_curve(y_train,rf_y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recalls[np.argmax(precisions >= 0.90)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_precision_vs_recall(precisions,recalls)\nplt.plot([0.9336, 0.9336], [0., 0.9], \"r:\")\nplt.plot([0.0, 0.9336], [0.9, 0.9], \"r:\")\nplt.plot([0.9336], [0.9], \"ro\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_precision_recall_vs_threshold(precisions,recalls,thresholds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FPR,TPR,thresholds = roc_curve(y_train,y_train_pred)\nrf_FPR,rf_TPR,rf_thresholds = roc_curve(y_train,rf_y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nplt.plot(rf_FPR,rf_TPR,\"g:\", linewidth=2,label='Random Forest')\nplt.grid(True)\nplt.legend(loc='best')\nplot_roc_curve(FPR,TPR,'MultinomialNB')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred[:4]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = tfidf.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = history.predict(X_test)\nrf_predictions =rf_clf.predict(X_test)\nprint(rf_predictions[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_cm_test = confusion_matrix(y_test,predictions)\nTN,FP,FN,TP,precision,recall,f1_score = cm_scores(tfidf_cm_test)\nprint('Precision : ',precision)\nprint('Recall : ',recall)\nprint('F1 Score:',f1_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_tfidf_cm_test = confusion_matrix(y_test,rf_predictions)\nrf_TN,rf_FP,rf_FN,rf_TP,rf_precision,rf_recall,rf_f1_score = cm_scores(rf_tfidf_cm_test)\nprint('Precision : ',rf_precision)\nprint('Recall : ',rf_recall)\nprint('F1 Score:',rf_f1_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Word Embeddings","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"*Glove","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"max_features=1000\nmaxlen = 300","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GLOVE_MODEL = '../input/glove-twitter/glove.twitter.27B.100d.txt'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_coefs(word, *arr): \n    return word, np.asarray(arr, dtype='float32')\nembeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(GLOVE_MODEL))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(embeddings_index.get(\"leaders\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = text.Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(x_train)\ntokenized_train = tokenizer.texts_to_sequences(x_train)\nX_train = sequence.pad_sequences(tokenized_train, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenized_test = tokenizer.texts_to_sequences(x_test)\nX_test = sequence.pad_sequences(tokenized_test, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_embs = np.stack(embeddings_index.values())\nemb_mean,emb_std = all_embs.mean(), all_embs.std()\nembed_size = all_embs.shape[1]\n\nword_index = tokenizer.word_index\nnb_words = min(max_features, len(word_index))\n#change below line if computing normal stats is too slow\nembedding_matrix = embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\nfor word, i in word_index.items():\n    if i >= max_features: continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None: embedding_matrix[i] = embedding_vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(embedding_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 256\nepochs = 5\nembed_size = 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ReduceLROnPlateau -> *Reduces learning rate when a metric has stopped improving.*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining Neural Network\nmodel = Sequential()\n#Non-trainable embeddidng layer\nmodel.add(Embedding(max_features, output_dim=embed_size, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n#LSTM \nmodel.add(LSTM(units=128 , return_sequences = True , recurrent_dropout = 0.25 , dropout = 0.25))\nmodel.add(LSTM(units=64 , recurrent_dropout = 0.1 , dropout = 0.1))\nmodel.add(Dense(units = 32 , activation = 'relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer=keras.optimizers.Adam(lr = 0.01), loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train, y_train, batch_size = batch_size , validation_data = (X_test,y_test) , epochs = epochs , callbacks = [learning_rate_reduction])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict_classes(X_test)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = [i for i in range(5)]\nfig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nfig.set_size_inches(20,10)\n\nax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\nax[0].plot(epochs , val_acc , 'ro-' , label = 'Testing Accuracy')\nax[0].set_title('Training & Testing Accuracy')\nax[0].legend()\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"Accuracy\")\n\nax[1].plot(epochs , train_loss , 'go-' , label = 'Training Loss')\nax[1].plot(epochs , val_loss , 'ro-' , label = 'Testing Loss')\nax[1].set_title('Training & Testing Loss')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"Loss\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm= confusion_matrix(y_test,y_pred)\nplt.figure(figsize = (10,10))\nsns.heatmap(cm,cmap= \"Reds\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='' , xticklabels = ['Fake','Not Fake'] , yticklabels = ['Fake','Not Fake'])\nplt.xlabel(\"Actual\")\nplt.ylabel(\"Predicted\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TN,FP,FN,TP,precision,recall,f1_score = cm_scores(cm)\nprint('Precision : ',precision)\nprint('Recall : ',recall)\nprint('F1 Score:',f1_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precisions,recalls,thresholds = precision_recall_curve(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thrs = recalls[np.argmax(precisions >= 0.90)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_precision_vs_recall(precisions,recalls)\nplt.plot([thrs, thrs], [0., 1.0], \"r:\")\nplt.plot([0.0, thrs], [1.0, 1.0], \"r:\")\nplt.plot([thrs], [1.0], \"ro\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FPR,TPR,thresholds = roc_curve(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc_curve(FPR,TPR,'LSTM with Glove Emb')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Please Upvote if you find this kernel useful.Thankyou :)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}