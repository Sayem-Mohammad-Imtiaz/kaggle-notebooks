{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hands-on implementation for various recommender systems.\n\n![img](https://images.unsplash.com/photo-1601944179066-29786cb9d32a?ixid=MnwxMjA3fDB8MHxzZWFyY2h8MTN8fG5ldGZsaXh8ZW58MHwwfDB8fA%3D%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=500&q=60)\n\nInspired by : https://github.com/alanchn31/recommender-system\n\n**What kind of data do we need to implement the recommendation system?**\n\nFor our target variable\n1. Explicit rating - A rating given by a user to an item on a scale (could be score 1 to 5, or 1 to 10).\n2. Implicit rating - A measurement to indicate the user preference indirectly. It could be a view, click, like, how long they read, how much they bought, etc.\n\nFor other features\n1. Content feature - Genre, Type, Number of subscriber, Age, Published channel, etc.\n\nHere we use `Anime-recommendations-database` as an input data for our tutorial.\n\n## Let's see what we have in our data source.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\npd.set_option('display.max_columns',None)\nimport seaborn as sns\nfrom collections import defaultdict\nfrom tqdm.notebook import tqdm\nimport gc\n\ndef basic_summary(df):\n    \n    '''\n    Report the basic information about the input dataframe\n    \n    Args:\n    df -> pd.DataFrame\n    \n    Returns:\n    None\n    '''\n    \n    print(f\"Samples : {df.shape[0]:,} \\nColumns : {df.shape[1]} : {list(df.columns.values)}\")\n    print(\"\\nHeads\")\n    display(df.head(3))\n    print(\"\\nData types\")\n    display(pd.DataFrame(df.dtypes, columns=['dtypes']).transpose())\n    print(\"\\nNull values\")\n    display(pd.concat([df.isna().sum(),df.isna().mean() * 100],axis=1).rename({0:'count',1:'pct'},axis=1).transpose())\n    print(\"\\nBasic statistics\")\n    display(df.describe().transpose())\n      \n\nif __name__ == \"__main__\":\n    \n    BASE_PATH = '/kaggle/input/anime-recommendations-database/'\n    ANIME_DTYPES = {'anime_id': str, 'name': str, 'genre': str, 'type': str, 'episodes': str, 'rating': float, 'members': int}\n    RATING_DTYPES = {'user_id': str, 'anime_id': str, 'rating': int}\n    ANIME_PATH = os.path.join(BASE_PATH, 'anime.csv')\n    RATING_PATH = os.path.join(BASE_PATH, 'rating.csv')\n\n    anime = pd.read_csv(ANIME_PATH, dtype = ANIME_DTYPES)\n    rating = pd.read_csv(RATING_PATH,  dtype = RATING_DTYPES)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T10:59:46.979081Z","iopub.execute_input":"2021-09-05T10:59:46.979491Z","iopub.status.idle":"2021-09-05T10:59:50.250556Z","shell.execute_reply.started":"2021-09-05T10:59:46.979452Z","shell.execute_reply":"2021-09-05T10:59:50.249476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Basic summary","metadata":{}},{"cell_type":"markdown","source":"## Anime\n\n- The `anime` dataframe contains the data related to the anime. \n\n### Metadata\n\n- anime_id - myanimelist.net's unique id identifying an anime.\n- name - full name of anime.\n- genre - comma separated list of genres for this anime.\n- type - movie, TV, OVA, etc.\n- episodes - how many episodes in this show. (1 if movie).\n- rating - average rating out of 10 for this anime.\n- members - number of community members that are in this anime's \"group\".","metadata":{}},{"cell_type":"code","source":"basic_summary(anime)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T10:59:50.252002Z","iopub.execute_input":"2021-09-05T10:59:50.252266Z","iopub.status.idle":"2021-09-05T10:59:50.350779Z","shell.execute_reply.started":"2021-09-05T10:59:50.25224Z","shell.execute_reply":"2021-09-05T10:59:50.34979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Rating\n\n- The `rating` dataframe contains raw data of how each user rate each anime.\n- The rating score is in range [0,10]\n\n### Metadata\n\n- user_id - non identifiable randomly generated user id.\n- anime_id - the anime that this user has rated.\n- rating - rating out of 10 this user has assigned (-1 if the user watched it but didn't assign a rating).","metadata":{}},{"cell_type":"code","source":"basic_summary(rating)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T10:59:50.353033Z","iopub.execute_input":"2021-09-05T10:59:50.353448Z","iopub.status.idle":"2021-09-05T10:59:51.887391Z","shell.execute_reply.started":"2021-09-05T10:59:50.353396Z","shell.execute_reply":"2021-09-05T10:59:51.886567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Popular based recommendation\n\n![img](https://images.unsplash.com/photo-1583258292688-d0213dc5a3a8?ixid=MnwxMjA3fDB8MHxzZWFyY2h8NXx8bWFya2V0fGVufDB8fDB8fA%3D%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=500&q=60)\n\n**Introduction**\n\nFor any machine learning problems, we need a **baseline model or method** to use as a reference whether our approach is good or not. \n\nOur machine learning prediction or sophsticated analysis should, at least, beat those baseline performance.\n\nFor recommendation system, we can make a simple baseline score with **popular item recommendation**\n\n**To define the popularity of the item**\n\nRegarding the IMDB syetem, there have a metrics called `weighted rating system` that is used to score the rating of each movie.\n\nHere is the formular \n```\n(WR) = (v ÷ (v+m)) × R + (m ÷ (v+m)) × C \n```\nwhere:\n- R = average rating for the movie. (rating)\n- v = number of votes for the movie. (members)\n- m = minimum votes required to be listed in the Top 250 (defined by > percentile 80 of total votes)\n- C = the average rating across the whole dataset.\n\n**Drawback**\n- It's not personalized. All the users will get the same exact list of popularity based recommendation.\n\n**Actions**\n\n- For new users, if we don't have any information about them we can provide the list based on ranking the `vote_count` or `weighted_rating` as a best guess.\n- In real world, this is the result when you see the section \"Popular on Netflix\"\n\n**Reference**\n- https://help.imdb.com/article/imdb/track-movies-tv/ratings-faq/G67Y87TFYYP6TWAV?ref_=helpms_helpart_inline#","metadata":{}},{"cell_type":"code","source":"def weighted_rating(v,m,R,C):\n    '''\n    Calculate the weighted rating\n    \n    Args:\n    v -> average rating for each anime (float)\n    m -> minimum votes required to be classified as popular (float)\n    R -> average rating for the anime (pd.Series)\n    C -> average rating for the whole dataset (pd.Series)\n    \n    Returns:\n    pd.Series\n    '''\n    return ( (v / (v + m)) * R) + ( (m / (v + m)) * C )\n\ndef assign_popular_based_score(rating):\n    '''\n    Assigned popular based score based on the IMDB weighted average.\n    \n    Args:\n    rating -> pd.DataFrame contains ['anime_id', 'rating'] for each user.\n    \n    Returns\n    popular_anime -> pd.DataFrame contains anime name and IMDB weighted score.\n    '''\n    \n    # pre processing\n    filter_rating = rating[rating['rating'] != -1]\n    vote_count = filter_rating.groupby('anime_id',as_index=False).agg({'user_id':'count', 'rating':'mean'})\n    vote_count.columns = ['anime_id','vote_count', 'avg_rating']\n    \n    # calcuate input parameters\n    C = np.mean(vote_count['avg_rating'])\n    m = np.percentile(vote_count['vote_count'], 70)\n    vote_count = vote_count[vote_count['vote_count'] >= m]\n    R = vote_count['avg_rating']\n    v = vote_count['vote_count']\n    vote_count['weighted_rating'] = weighted_rating(v,m,R,C)\n    \n    # post processing\n    vote_count = vote_count.merge(anime[['anime_id','name']],on=['anime_id'],how='left')\n    vote_count = vote_count.drop('anime_id', axis=1)\n    popular_anime = vote_count.loc[:,['name', 'vote_count', 'avg_rating', 'weighted_rating']]\n    \n    return popular_anime","metadata":{"execution":{"iopub.status.busy":"2021-09-05T10:59:51.888774Z","iopub.execute_input":"2021-09-05T10:59:51.889043Z","iopub.status.idle":"2021-09-05T10:59:51.897135Z","shell.execute_reply.started":"2021-09-05T10:59:51.889017Z","shell.execute_reply":"2021-09-05T10:59:51.896152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"popular_anime = assign_popular_based_score(rating)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T10:59:51.898638Z","iopub.execute_input":"2021-09-05T10:59:51.899029Z","iopub.status.idle":"2021-09-05T10:59:53.160813Z","shell.execute_reply.started":"2021-09-05T10:59:51.898986Z","shell.execute_reply":"2021-09-05T10:59:53.159653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Popularity based on the number of votes count","metadata":{}},{"cell_type":"code","source":"sns.barplot(data = popular_anime.sort_values('vote_count',ascending=False).head(10),\n            x = 'vote_count', y = 'name', palette='mako');\nsns.despine()","metadata":{"execution":{"iopub.status.busy":"2021-09-05T10:59:53.16198Z","iopub.execute_input":"2021-09-05T10:59:53.162232Z","iopub.status.idle":"2021-09-05T10:59:53.408339Z","shell.execute_reply.started":"2021-09-05T10:59:53.162207Z","shell.execute_reply":"2021-09-05T10:59:53.407202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Popularity based on the weighted score","metadata":{}},{"cell_type":"code","source":"sns.barplot(data = popular_anime.sort_values('weighted_rating',ascending=False).head(10),\n            x = 'weighted_rating', y = 'name', palette = 'mako');\nsns.despine()","metadata":{"execution":{"iopub.status.busy":"2021-09-05T10:59:53.409545Z","iopub.execute_input":"2021-09-05T10:59:53.40983Z","iopub.status.idle":"2021-09-05T10:59:53.612594Z","shell.execute_reply.started":"2021-09-05T10:59:53.409802Z","shell.execute_reply":"2021-09-05T10:59:53.611647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Content-based recommendation\n\n**Introduction**\n\nFor example, if a person has liked the movie “Inception”, then this algorithm will recommend movies that fall under the same genre.\n\nHere we create a better way of recommendation by introducing other features of the content into our engine. \n\nIt's an improvement compared to the popularity based recommendation we mentioned earlier. \n\nNow, the customer who read, watch, or like any kinds of specific products will get a recommendation based on the product they interacted in the past.\n\n![img](https://i.ibb.co/S5GWr1r/Content-recommendation.png)\n\n> Consider the example of Netflix. They save all the information related to each user in a vector form. This vector contains the past behavior of the user, i.e. the movies liked/disliked by the user and the ratings given by them. This vector is known as the profile vector. All the information related to movies is stored in another vector called the item vector. Item vector contains the details of each movie, like genre, cast, director, etc. The content-based filtering algorithm finds **the cosine of the angle between the profile vector and item vector**, i.e. cosine similarity.\n\n\n\n**drawback**\n- A major drawback of this algorithm is that it is limited to recommending items that are of the same type. \n- It will **never recommend products which the user has not bought or liked** in the past. So if a user has watched or liked only action movies in the past, the system will recommend only action movies.\n\n**reference**\n- [Content based recommender system](https://towardsdatascience.com/content-based-recommender-systems-28a1dbd858f5)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T15:32:46.087743Z","iopub.execute_input":"2021-08-24T15:32:46.088211Z","iopub.status.idle":"2021-08-24T15:32:46.109399Z","shell.execute_reply.started":"2021-08-24T15:32:46.088113Z","shell.execute_reply":"2021-08-24T15:32:46.107827Z"}}},{"cell_type":"code","source":"def top_k_similar_anime(anime_id, top_k, corr_mat, map_name):\n    \n    # sort correlation value ascendingly and select top_k csr_anime_id\n    top_anime = corr_mat[anime_id,:].argsort()[-top_k:][::-1] \n    \n    # convert csr_anime_id to anime name\n    top_anime = [map_name[e] for e in top_anime] \n\n    return top_anime","metadata":{"execution":{"iopub.status.busy":"2021-09-05T10:59:53.613819Z","iopub.execute_input":"2021-09-05T10:59:53.614156Z","iopub.status.idle":"2021-09-05T10:59:53.620397Z","shell.execute_reply.started":"2021-09-05T10:59:53.614123Z","shell.execute_reply":"2021-09-05T10:59:53.619626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract the genre\ngenre = anime['genre'].str.split(\",\", expand=True)\n\n# get all possible genre\nall_genre = set()\nfor c in genre.columns:\n    distinct_genre = genre[c].str.lower().str.strip().unique()\n    all_genre.update(distinct_genre)\n\nall_genre.remove(None)\nall_genre.remove(np.nan)\nprint(f\"The number of possible genre is : {len(all_genre)}\")\n\n# create item-genre matrix\nitem_genre_mat = anime[['name','genre']].copy()\nitem_genre_mat['genre'] = item_genre_mat['genre'].str.lower().str.strip()\nfor genre in tqdm(all_genre):\n    item_genre_mat[genre] = np.where(item_genre_mat['genre'].str.contains(genre), 1, 0)\n    \nitem_genre_mat = item_genre_mat.drop(['genre'], axis=1)\nitem_genre_mat = item_genre_mat.set_index('name')\n\n# compute similarity matix\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nind2name = {ind:name for ind,name in enumerate(item_genre_mat.index)}\nname2ind = {v:k for k,v in ind2name.items()}\ncosine_mat = cosine_similarity(item_genre_mat)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T10:59:53.623049Z","iopub.execute_input":"2021-09-05T10:59:53.623655Z","iopub.status.idle":"2021-09-05T10:59:55.523379Z","shell.execute_reply.started":"2021-09-05T10:59:53.623609Z","shell.execute_reply":"2021-09-05T10:59:55.522344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similar_anime = top_k_similar_anime(name2ind['Naruto'],\n                                    top_k = 10,\n                                    corr_mat = cosine_mat,\n                                    map_name = ind2name)\n\nanime.loc[anime['name'].isin(similar_anime), ['name','genre']]","metadata":{"execution":{"iopub.status.busy":"2021-09-05T10:59:55.524882Z","iopub.execute_input":"2021-09-05T10:59:55.525159Z","iopub.status.idle":"2021-09-05T10:59:55.537523Z","shell.execute_reply.started":"2021-09-05T10:59:55.525132Z","shell.execute_reply":"2021-09-05T10:59:55.536907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similar_anime = top_k_similar_anime(name2ind['Death Note'],\n                                    top_k = 10,\n                                    corr_mat = cosine_mat,\n                                    map_name = ind2name)\n\nanime.loc[anime['name'].isin(similar_anime), ['name','genre']]","metadata":{"execution":{"iopub.status.busy":"2021-09-05T10:59:55.538414Z","iopub.execute_input":"2021-09-05T10:59:55.538761Z","iopub.status.idle":"2021-09-05T10:59:55.559173Z","shell.execute_reply.started":"2021-09-05T10:59:55.538734Z","shell.execute_reply":"2021-09-05T10:59:55.558473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del cosine_mat\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-05T10:59:55.560149Z","iopub.execute_input":"2021-09-05T10:59:55.560556Z","iopub.status.idle":"2021-09-05T10:59:55.683055Z","shell.execute_reply.started":"2021-09-05T10:59:55.560526Z","shell.execute_reply":"2021-09-05T10:59:55.682422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Collaborative filtering\n\n**Introduction**\n\n> The collaborative filtering algorithm uses **“User Behavior”** for recommending items. This is one of the most commonly used algorithms in the industry as it is not dependent on any additional information. There are different types of collaborating filtering techniques. [comprehensive-guide-recommendation-engine-python](https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-recommendation-engine-python/)[1]\n\nThere are 2 types of memory based collaborative filtering \n\n![img](https://predictivehacks.com/wp-content/uploads/2020/06/recommenders_systems.png) <br>\n1. User based - The user-similarity matrix will consist of some distance metric that measures the similarity between any two pairs of users.\n> This algorithm is useful when the number of users is less. Its **not effective when there are a large number of users** as it will take a lot of time to compute the similarity between all user pairs. This leads us to item-item collaborative filtering, which is effective when the number of users is more than the items being recommended. [1]\n2. Item based - Likewise, the item-similarity matrix will measure the similarity between any two pairs of items.\n\n**drawback**\n- What will happen if a new user or a new item is added in the dataset? It is called a **Cold Start**. There can be two types of cold start.\n    1. Visitor - Since there is no history of that user, the system does not know the preferences of that user\n        - These can be determined by what has been **popular recently overall or regionally**.\n    2. Product - More the interaction a product receives, the easier it is for our model to recommend that product to the right user.\n        - We can make use of **Content based filtering** to solve this problem. \n\n**References**\n- [comprehensive-guide-recommendation-engine-python](https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-recommendation-engine-python/)\n- [intro-to-collaborative-filtering](https://www.ethanrosenthal.com/2015/11/02/intro-to-collaborative-filtering/)\n- [intro-to-recommender-system-collaborative-filtering](https://towardsdatascience.com/intro-to-recommender-system-collaborative-filtering-64a238194a26)","metadata":{}},{"cell_type":"code","source":"# replace the rating -1 with 0 (convert from watched it but didn't rate the anime into they didn't like it)\ncollab_rating = rating.copy()\ncollab_rating['rating'] = collab_rating['rating'].replace(-1, 0)\n\nn_users = collab_rating['user_id'].nunique()\nn_animes = collab_rating['anime_id'].nunique()\nprint(f\"Unique users : {n_users:,} \\nUnique anime : {n_animes:,}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-05T10:59:55.684041Z","iopub.execute_input":"2021-09-05T10:59:55.684477Z","iopub.status.idle":"2021-09-05T10:59:57.791608Z","shell.execute_reply.started":"2021-09-05T10:59:55.684441Z","shell.execute_reply":"2021-09-05T10:59:57.790511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create ordered user_id, and anime_id\nmap_user_id = {v:int(i) for i,v in enumerate(sorted(collab_rating['user_id'].unique()))}\nmap_anime_id = {v:int(i) for i,v in enumerate(sorted(collab_rating['anime_id'].unique()))}\n\ncollab_rating['csr_user_id'] = collab_rating['user_id'].map(map_user_id)\ncollab_rating['csr_anime_id'] = collab_rating['anime_id'].map(map_anime_id)\ncollab_rating = collab_rating.merge(anime[['anime_id', 'name']], on='anime_id', how='left')\n\n# create another mapping from the anime name to the new defined indexes\nmap_csr_anime_id_to_name = {ind:name for ind, name in zip(collab_rating['csr_anime_id'], collab_rating['name'])}\nmap_name_to_csr_anime_id = {name:ind for ind, name in map_csr_anime_id_to_name.items()}","metadata":{"execution":{"iopub.status.busy":"2021-09-05T10:59:57.79278Z","iopub.execute_input":"2021-09-05T10:59:57.793058Z","iopub.status.idle":"2021-09-05T11:00:04.365396Z","shell.execute_reply.started":"2021-09-05T10:59:57.793032Z","shell.execute_reply":"2021-09-05T11:00:04.364425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.sparse import csr_matrix\nfrom tqdm.notebook import tqdm\n\nrow = collab_rating['csr_user_id']\ncol = collab_rating['csr_anime_id']\ndata = collab_rating['rating']\n\nmat = csr_matrix((data, (row, col)), shape=(n_users, n_animes))\nmat.eliminate_zeros()\n\nsparsity = float(len(mat.nonzero()[0]))\nsparsity /= (mat.shape[0] * mat.shape[1])\nsparsity *= 100\n\nprint(f'Sparsity: {sparsity:4.2f}%. This means that {sparsity:4.2f}% of the user-item ratings have a value.')","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:00:04.3666Z","iopub.execute_input":"2021-09-05T11:00:04.366873Z","iopub.status.idle":"2021-09-05T11:00:04.977597Z","shell.execute_reply.started":"2021-09-05T11:00:04.366846Z","shell.execute_reply":"2021-09-05T11:00:04.97675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_test_split(mat, test_size = 0.2):\n    \n    train = mat.copy()\n    \n    test_row = []\n    test_col = []\n    test_data = []\n    \n    for user in tqdm(range(mat.shape[0])):\n        \n        # extract the csr_anime_id that has a rating > 0\n        user_ratings = mat[user, :].nonzero()[1] \n        \n        # random test label based on each user_ratings size.\n        test_ratings = np.random.choice(user_ratings,\n                                        size = int(test_size * len(user_ratings)), \n                                        replace = False)\n        \n        # because the changing of the csr_matrix is expensive, we store the data and create new csr_matrix instead.\n        test_row.extend([user] * len(test_ratings))\n        test_col.extend(list(test_ratings))\n        test_data.extend(list(train[user, test_ratings].toarray()[0]))\n        \n        train[user, test_ratings] = 0\n    \n    test = csr_matrix((test_data, (test_row, test_col)), shape=(mat.shape[0], mat.shape[1]))\n    test.eliminate_zeros()\n    \n    return train, test","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:00:04.978763Z","iopub.execute_input":"2021-09-05T11:00:04.979216Z","iopub.status.idle":"2021-09-05T11:00:04.986214Z","shell.execute_reply.started":"2021-09-05T11:00:04.979183Z","shell.execute_reply":"2021-09-05T11:00:04.985351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, test = train_test_split(mat)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:00:04.987407Z","iopub.execute_input":"2021-09-05T11:00:04.987666Z","iopub.status.idle":"2021-09-05T11:00:48.284432Z","shell.execute_reply.started":"2021-09-05T11:00:04.987641Z","shell.execute_reply":"2021-09-05T11:00:48.283158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.1 Memory based approache\n\n**Introduction**\n\n> The key difference of memory-based approach from the model-based techniques is that we are **not learning any parameter** using gradient descent (or any other optimization algorithm). The closest user or items are calculated only by using **Cosine similarity** or **Pearson correlation coefficients**, which are only based on arithmetic operations. [various-implementations-of-collaborative-filtering](https://towardsdatascience.com/various-implementations-of-collaborative-filtering-100385c6dfe0) \n\n> Memory-based methods use user rating historical data to compute the similarity between users or items. The idea behind these methods is to define a similarity measure between users or items, and find the most similar to recommend unseen items. [Building a memory based collaborative filtering recommender](https://towardsdatascience.com/how-does-collaborative-filtering-work-da56ea94e331)\n\n**Implementatiuon**\n- Due to the size of user-item matrix. It's impossible to compute the user_features with `n_users x n_users` shape or the anime_features with `n_animes x n_animes` shape with the current running instance.\n- Therefore, we drop the number of row for demostrating purpose.\n- Also, another way is to create the matrix with the lower dimension with the deterministic approach such as 'TruncatedSVD'\n\n**User-based**\n- We find the group of similar users (the group size is arbitarily) based on the `pearson correlation`, `cosine similarity`, or `KNN Neareast neighbour`.\n- We average the rating of each item based on the group of similar users\n- Rank the item based on the averate rating descendently, and recommend the target user with the movie that they never rated it before ranking from the highest `top_k` average rating.\n\n**Item-based**\n\n- We find the group of similar item based on the `pearson correlation`, `cosine similarity`, or `KNN Neareast neighbour`\n- Select up to the `top_k` most similar item to recommend. \n- Just to note that the item is **not similar in term of the content** (like the content-based recommendation) but it's **similar in term of the explicit rating from the user behavior** (the similarity between each item from the user-item matrix)\n\n**Drawback**\n- It's not scalable due to the sprasity of the data.\n- We needs to construct the similarity matrix everytime the new user comes. (Hard to maintain, and operationalize)\n\n**Actions**\n- The list result can be showed in the front-end application like \"Made for you\" -> Provide the list of recommended animes.\n- The list result can be showed in the front-end application like \"Because you like Naruto\" -> Provided the list of recommended animes.\n\n**Reference**\n- [various-implementations-of-collaborative-filtering](https://towardsdatascience.com/various-implementations-of-collaborative-filtering-100385c6dfe0)\n- [Building a memory based collaborative filtering recommender](https://towardsdatascience.com/how-does-collaborative-filtering-work-da56ea94e331)","metadata":{}},{"cell_type":"markdown","source":"## Compute similarity\n\n- When we try to compute the similarity with the whole matrix (75K x 11K) shape. We doesn't have enough memory to store the whole matrix.\n- So, for this purpose of illustration, we will undersampling the data set by 90%.","metadata":{}},{"cell_type":"code","source":"# we need to reduce the size of user-item matrix so that we can compute the similarity based on the raw value.\n\ndef under_sampling(mat, ratio):\n    \n    sample_inds = np.random.choice(mat.shape[0],\n                    size = int(ratio * mat.shape[0]), \n                    replace = False)\n    \n    return train[sample_inds,:]","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:00:48.286109Z","iopub.execute_input":"2021-09-05T11:00:48.286477Z","iopub.status.idle":"2021-09-05T11:00:48.291208Z","shell.execute_reply.started":"2021-09-05T11:00:48.286441Z","shell.execute_reply":"2021-09-05T11:00:48.290313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pearson correlation","metadata":{}},{"cell_type":"code","source":"epsilon = 1e-9\nsmall_train = under_sampling(train, ratio = .1).toarray() + epsilon\nitem_corr_mat = np.corrcoef(small_train.T)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:00:48.292195Z","iopub.execute_input":"2021-09-05T11:00:48.292475Z","iopub.status.idle":"2021-09-05T11:01:04.011255Z","shell.execute_reply.started":"2021-09-05T11:00:48.292445Z","shell.execute_reply":"2021-09-05T11:01:04.010234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similar_anime = top_k_similar_anime(map_name_to_csr_anime_id['Naruto'],\n                                    top_k = 10,\n                                    corr_mat = item_corr_mat,\n                                    map_name = map_csr_anime_id_to_name)\n\nanime.loc[anime['name'].isin(similar_anime), ['name','genre']]","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:01:04.012438Z","iopub.execute_input":"2021-09-05T11:01:04.012685Z","iopub.status.idle":"2021-09-05T11:01:04.027276Z","shell.execute_reply.started":"2021-09-05T11:01:04.01266Z","shell.execute_reply":"2021-09-05T11:01:04.026234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similar_anime = top_k_similar_anime(map_name_to_csr_anime_id['Death Note'],\n                                    top_k = 10,\n                                    corr_mat = item_corr_mat,\n                                    map_name = map_csr_anime_id_to_name)\n\nanime.loc[anime['name'].isin(similar_anime), ['name','genre']]","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:01:04.028949Z","iopub.execute_input":"2021-09-05T11:01:04.029468Z","iopub.status.idle":"2021-09-05T11:01:04.05038Z","shell.execute_reply.started":"2021-09-05T11:01:04.029422Z","shell.execute_reply":"2021-09-05T11:01:04.049514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Summary**\n\n- You can see that with this size of data and the limitation of the resouce computation. This approach is hard to scale up in the real world.\n- It leads to the problem that we can't leverage the pattern inside our data. ","metadata":{}},{"cell_type":"code","source":"del small_train, item_corr_mat\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:01:04.051389Z","iopub.execute_input":"2021-09-05T11:01:04.051654Z","iopub.status.idle":"2021-09-05T11:01:04.173719Z","shell.execute_reply.started":"2021-09-05T11:01:04.051629Z","shell.execute_reply":"2021-09-05T11:01:04.172939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Model-based approach\n\n**Introduction**\n\n> Model-based CF uses machine learning algorithms to predict users’ rating of unrated items. There are many model-based CF algorithms, the most commonly used are matrix factorization models such as to applying a SVD to reconstruct the rating matrix, latent Dirichlet allocation or Markov decision process based models. [Building a memory based collaborative filtering recommender](https://towardsdatascience.com/how-does-collaborative-filtering-work-da56ea94e331)\n\n\n**Type**\n\n> 1. Matrix Factorization based\n    - TruncatedSVD\n    - Funk Matrix Factorization (SVD-like algorithm) (Surprise) <br>\n    >  Note that, in Funk MF **no singular value decomposition is applied**, it is a SVD-like machine learning model. [Wiki/Matrix_factorization](https://en.wikipedia.org/wiki/Matrix_factorization_(recommender_systems))\n    - Probabilistic Matrix Factorization (fastai)\n    - Non negative Matrix Factorization (Surprise)\n2. Deep learning based\n    - Embedding (fastai)\n    \n**Implementation**\n\n**Item-based**\n\n- We can extract the `user_features` and `anime_features` based on the matrix factorization technique. The purpose is to get the underlying latent matrix generated the user-item interaction matrix.\n- After that, We select the `anime_features` for example. We calculate the `pearson correlation`, `cosine similarity`, or `KNN Neareast neighbour` between each item and check up for the `top_k` most similar item to recommend. \n- Just to note that the item is **not similar in term of the content** (like the content-based recommendation) and **not similar in term of the explicit user behavior** (like the memory-based CF recommendation), but in term of **latent factors** (underlying factors that we can't interpret explicitly) based on the matrix decomposition.\n\n**User-based**\n- We can extract the `user_features` and `anime_features` based on the matrix factorization technique. The purpose is to get the underlying latent matrix generated the user-item interaction matrix.\n- We find the group of similar users (the group size is arbitarily) based on the `pearson correlation`, `cosine similarity`, or `KNN Neareast neighbour`.\n- We average the rating of each item based on the group of similar users\n- Rank the item based on the averate rating descendently, and recommend the target user with the movie that they never rated it before ranking from the highest top-k average rating.\n\n**References**\n- [Building a memory based collaborative filtering recommender](https://towardsdatascience.com/how-does-collaborative-filtering-work-da56ea94e331)\n- [Wiki/Matrix_factorization](https://en.wikipedia.org/wiki/Matrix_factorization_(recommender_systems))","metadata":{}},{"cell_type":"markdown","source":"\n\n## 3.1.1 Matrix factorization - TruncatedSVD (sklearn)\n\n### TruncatedSVD\n\n![img](https://www.researchgate.net/profile/Jun-Xu-67/publication/321344494/figure/fig1/AS:702109309751298@1544407312766/Diagram-of-matrix-factorization.png)\n\n> Truncated SVD shares similarity with PCA while SVD is produced from the data matrix and the factorization of PCA is generated from the covariance matrix. Unlike regular SVDs, truncated SVD produces a factorization where the number of columns can be specified for a number of truncation. [recommender-system-singular-value-decomposition-svd-truncated-svd](https://towardsdatascience.com/recommender-system-singular-value-decomposition-svd-truncated-svd-97096338f361)\n\n**Reference**\n- [recommender-system-singular-value-decomposition-svd-truncated-svd](https://towardsdatascience.com/recommender-system-singular-value-decomposition-svd-truncated-svd-97096338f361)","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD\n\nepsilon = 1e-9\nn_latent_factors = 10\n\nanime_svd = TruncatedSVD(n_components = n_latent_factors)\nanime_features = anime_svd.fit_transform(train.transpose()) + epsilon\n\nuser_svd = TruncatedSVD(n_components = n_latent_factors)\nuser_features = user_svd.fit_transform(train) + epsilon\n\nprint(f\"anime_features shape : {anime_features.shape}\\nuser_feature shape : {user_features.shape}\")","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:01:04.174836Z","iopub.execute_input":"2021-09-05T11:01:04.175229Z","iopub.status.idle":"2021-09-05T11:01:07.760278Z","shell.execute_reply.started":"2021-09-05T11:01:04.175195Z","shell.execute_reply":"2021-09-05T11:01:07.758993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Item-based Collaborative filtering","metadata":{"execution":{"iopub.status.busy":"2021-08-24T16:54:52.249185Z","iopub.execute_input":"2021-08-24T16:54:52.249536Z","iopub.status.idle":"2021-08-24T16:54:52.254241Z","shell.execute_reply.started":"2021-08-24T16:54:52.249508Z","shell.execute_reply":"2021-08-24T16:54:52.252964Z"}}},{"cell_type":"markdown","source":"### Pearson correlation","metadata":{}},{"cell_type":"code","source":"corr_mat = np.corrcoef(anime_features)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:01:07.761812Z","iopub.execute_input":"2021-09-05T11:01:07.7625Z","iopub.status.idle":"2021-09-05T11:01:09.310206Z","shell.execute_reply.started":"2021-09-05T11:01:07.76245Z","shell.execute_reply":"2021-09-05T11:01:09.309222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similar_anime = top_k_similar_anime(map_name_to_csr_anime_id['Naruto'],\n                                    top_k = 10,\n                                    corr_mat = corr_mat,\n                                    map_name = map_csr_anime_id_to_name)\n\nanime.loc[anime['name'].isin(similar_anime), ['name','genre']]","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:01:09.311501Z","iopub.execute_input":"2021-09-05T11:01:09.311788Z","iopub.status.idle":"2021-09-05T11:01:09.327348Z","shell.execute_reply.started":"2021-09-05T11:01:09.311758Z","shell.execute_reply":"2021-09-05T11:01:09.326417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similar_anime = top_k_similar_anime(map_name_to_csr_anime_id['Death Note'],\n                                    top_k = 10,\n                                    corr_mat = corr_mat,\n                                    map_name = map_csr_anime_id_to_name)\n\nanime.loc[anime['name'].isin(similar_anime), ['name','genre']]","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:01:09.328629Z","iopub.execute_input":"2021-09-05T11:01:09.328913Z","iopub.status.idle":"2021-09-05T11:01:09.343979Z","shell.execute_reply.started":"2021-09-05T11:01:09.328884Z","shell.execute_reply":"2021-09-05T11:01:09.343094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cosine similarity","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\ncosine_mat = cosine_similarity(anime_features)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:01:09.346882Z","iopub.execute_input":"2021-09-05T11:01:09.347156Z","iopub.status.idle":"2021-09-05T11:01:10.255966Z","shell.execute_reply.started":"2021-09-05T11:01:09.347131Z","shell.execute_reply":"2021-09-05T11:01:10.254985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similar_anime = top_k_similar_anime(map_name_to_csr_anime_id['Naruto'],\n                                    top_k = 10,\n                                    corr_mat = cosine_mat,\n                                    map_name = map_csr_anime_id_to_name)\n\nanime.loc[anime['name'].isin(similar_anime), ['name','genre']]","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:01:10.257836Z","iopub.execute_input":"2021-09-05T11:01:10.258254Z","iopub.status.idle":"2021-09-05T11:01:10.274451Z","shell.execute_reply.started":"2021-09-05T11:01:10.258208Z","shell.execute_reply":"2021-09-05T11:01:10.273306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similar_anime = top_k_similar_anime(map_name_to_csr_anime_id['Death Note'],\n                                    top_k = 10,\n                                    corr_mat = cosine_mat,\n                                    map_name = map_csr_anime_id_to_name)\n\nanime.loc[anime['name'].isin(similar_anime), ['name','genre']]","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:01:10.276119Z","iopub.execute_input":"2021-09-05T11:01:10.276569Z","iopub.status.idle":"2021-09-05T11:01:10.292251Z","shell.execute_reply.started":"2021-09-05T11:01:10.276526Z","shell.execute_reply":"2021-09-05T11:01:10.290988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Summary**\n\nWith this method, you can see that we can compute the similarity based on the specific number of latent factor.\n- Now, the recommendation would be based on some latent factors that we cannot explain directly.\n- But in mathematically speaking, it will be the top latent factor that minimize the loss between the Actual rating and Reconstructed rating.\n- You can see that now we reduce the size of matrix compared to the one in memory-based approach. however, it's still not good enough approach because eventually when the user, or item size growing with the time.<br> Soon it will reach the limitation of computation resouce as well.","metadata":{}},{"cell_type":"code","source":"del user_features, anime_features\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:01:10.295409Z","iopub.execute_input":"2021-09-05T11:01:10.295706Z","iopub.status.idle":"2021-09-05T11:01:10.411232Z","shell.execute_reply.started":"2021-09-05T11:01:10.295677Z","shell.execute_reply":"2021-09-05T11:01:10.410428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.1.2 Matrix factorization - Funk MF (SVD-like algorithm in surprise)","metadata":{}},{"cell_type":"code","source":"from surprise import SVD, accuracy\nfrom surprise import Dataset, Reader\nfrom surprise.model_selection import cross_validate\nfrom surprise.model_selection.split import train_test_split\n\ndef pred2dict(predictions, top_k=None):\n    \n    rec_dict = defaultdict(list)\n    for user_id, anime_id, actual_rating, pred_rating, _ in tqdm(predictions):\n        rec_dict[user_id].append((anime_id, pred_rating))        \n        \n    return rec_dict\n\ndef get_top_k_recommendation(rec_dict, user_id, top_k, animeid2name):\n    \n    pred_ratings = rec_dict[user_id]\n    pred_ratings = sorted(pred_ratings, key=lambda x: x[1], reverse=True) # sort descendingly by pred_rating\n    pred_ratings = pred_ratings[:top_k]\n    recs = [animeid2name[e[0]] for e in pred_ratings]\n    \n    return recs\n\nreader = Reader(rating_scale=(1,10))\ndata = Dataset.load_from_df(collab_rating[['user_id','anime_id','rating']], reader)\ntrain, test = train_test_split(data, test_size=.2, random_state=42)\n\nalgo = SVD(random_state = 42)\nalgo.fit(train)\npred = algo.test(test)\naccuracy.rmse(pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:01:10.41254Z","iopub.execute_input":"2021-09-05T11:01:10.412971Z","iopub.status.idle":"2021-09-05T11:08:37.740105Z","shell.execute_reply.started":"2021-09-05T11:01:10.412925Z","shell.execute_reply":"2021-09-05T11:08:37.73897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction - Funk MF (SVD-like algorithm in surprise)","metadata":{}},{"cell_type":"code","source":"animeid2name = {ind:name for ind,name in zip(collab_rating['anime_id'], collab_rating['name'])}\n\nrec_dict = pred2dict(pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:08:37.741917Z","iopub.execute_input":"2021-09-05T11:08:37.742353Z","iopub.status.idle":"2021-09-05T11:08:44.185729Z","shell.execute_reply.started":"2021-09-05T11:08:37.742306Z","shell.execute_reply":"2021-09-05T11:08:44.184937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Item-based recommendation","metadata":{}},{"cell_type":"code","source":"corr_mat = np.corrcoef(algo.qi)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:08:44.186892Z","iopub.execute_input":"2021-09-05T11:08:44.187342Z","iopub.status.idle":"2021-09-05T11:08:45.502969Z","shell.execute_reply.started":"2021-09-05T11:08:44.187309Z","shell.execute_reply":"2021-09-05T11:08:45.501913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similar_anime = top_k_similar_anime(map_name_to_csr_anime_id['Naruto'],\n                                    top_k = 10,\n                                    corr_mat = corr_mat,\n                                    map_name = map_csr_anime_id_to_name)\n\nanime.loc[anime['name'].isin(similar_anime), ['name','genre']]","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:08:45.504654Z","iopub.execute_input":"2021-09-05T11:08:45.505071Z","iopub.status.idle":"2021-09-05T11:08:45.5227Z","shell.execute_reply.started":"2021-09-05T11:08:45.505025Z","shell.execute_reply":"2021-09-05T11:08:45.521724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"similar_anime = top_k_similar_anime(map_name_to_csr_anime_id['Death Note'],\n                                    top_k = 10,\n                                    corr_mat = corr_mat,\n                                    map_name = map_csr_anime_id_to_name)\n\nanime.loc[anime['name'].isin(similar_anime), ['name','genre']]","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:11:16.244435Z","iopub.execute_input":"2021-09-05T11:11:16.24508Z","iopub.status.idle":"2021-09-05T11:11:16.278758Z","shell.execute_reply.started":"2021-09-05T11:11:16.245026Z","shell.execute_reply":"2021-09-05T11:11:16.277705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### User-based recommendation","metadata":{}},{"cell_type":"code","source":"# Example rating of user#3\ncollab_rating[ (collab_rating['user_id'] == '3') & (collab_rating['rating'] > 0)]\\\n.sort_values('rating',ascending=False)\\\n.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:08:45.542887Z","iopub.execute_input":"2021-09-05T11:08:45.543296Z","iopub.status.idle":"2021-09-05T11:08:46.021408Z","shell.execute_reply.started":"2021-09-05T11:08:45.543254Z","shell.execute_reply":"2021-09-05T11:08:46.020311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Recommendation for user#3\nrecs = get_top_k_recommendation(rec_dict, '3', 10, animeid2name)\nanime.loc[anime['name'].isin(recs), ['name','genre']]","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:10:10.876542Z","iopub.execute_input":"2021-09-05T11:10:10.877268Z","iopub.status.idle":"2021-09-05T11:10:10.894722Z","shell.execute_reply.started":"2021-09-05T11:10:10.877217Z","shell.execute_reply":"2021-09-05T11:10:10.89387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Summary**\n\n- Here we use the Funk MF algorithms to create the latent factors matrix, and now we can build both the user-based, item-based recommendation.\n- We also randomly split out some users from the train set into the test set for the validation purpose.","metadata":{}},{"cell_type":"code","source":"del corr_mat\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-05T11:08:46.038581Z","iopub.execute_input":"2021-09-05T11:08:46.038924Z","iopub.status.idle":"2021-09-05T11:08:48.301688Z","shell.execute_reply.started":"2021-09-05T11:08:46.038892Z","shell.execute_reply":"2021-09-05T11:08:48.300456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# What to do next?\n\n- Hybrid MF\n- Deep learning MF\n- Evaluation","metadata":{}}]}