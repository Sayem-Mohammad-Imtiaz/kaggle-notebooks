{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tnrange\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.model_selection import train_test_split\nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom keras.callbacks import ModelCheckpoint\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.utils import plot_model,to_categorical\nfrom keras.layers import Conv2D,Dense,Flatten,BatchNormalization,Add,Activation,Dropout,\\\n            GlobalAveragePooling2D,MaxPooling2D,AveragePooling2D\nfrom keras.engine.input_layer import Input\nfrom keras.initializers import glorot_uniform\nfrom keras.regularizers import l2\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/celeba-dataset/list_attr_celeba.csv\",usecols=['image_id','Male','Young'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"../input/celeba-dataset/img_align_celeba/img_align_celeba/\"\n# images = os.listdir(\"../input/celeba-dataset/img_align_celeba/img_align_celeba/\")\n# images = images[:5000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_image_to_array(image_dir):\n    try:\n        image = cv2.imread(image_dir)\n        if image is not None : \n            return cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n        else :\n            return np.array([])\n    except Exception as e:\n        print(f\"Error : {e}\")\n        return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_list = []\nlabel1 = []\nlabel2 = []\nimages = list(df.values)\nfor i in tnrange(10000):\n    image_list.append(convert_image_to_array(path+str(images[i][0])))\n    if images[i][1]==-1:\n        label1.append(0)\n    else:\n        label1.append(1)  \n        \n    if images[i][2]==-1:\n        label2.append(0)\n    else:\n        label2.append(1)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = image_list[:8000]\nx_test = image_list[8000:]\n\ny_train1 = label1[:8000]\ny_test1 = label1[8000:]\n\ny_train2 = label2[:8000]\ny_test2 = label2[8000:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(\"[INFO] Spliting data to train, test\")\n# # x_train, x_test, y_train, y_test = train_test_split(image_list, labels, test_size=0.2, random_state = 42) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train1 = to_categorical(y_train1)\ny_test1 = to_categorical(y_test1)\n\ny_train2 = to_categorical(y_train2)\ny_test2 = to_categorical(y_test2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = np.array(x_train)\nx_test = np.array(x_test)\ny_train1 = np.array(y_train1)\ny_test1 = np.array(y_test1)\ny_train2 = np.array(y_train2)\ny_test2 = np.array(y_test2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputShape = (218, 178, 3)\ninputs = Input(shape=inputShape)\nx = inputs\nx = Conv2D(32,(3,3),padding='SAME',kernel_initializer='random_uniform',input_shape=inputShape,activation='relu')(x)\nx = BatchNormalization(axis=-1)(x)\n# model.add(Activation('relu'))\nx = MaxPooling2D((2,2))(x)\nx = Conv2D(32,(3,3),padding='SAME',kernel_initializer='random_uniform',activation='relu')(x)\nx = BatchNormalization(axis=-1)(x)\n# model.add(Activation('relu'))\n\nx = Conv2D(64,(3,3),padding='SAME',kernel_initializer='random_uniform',activation='relu')(x)\nx = BatchNormalization(axis=-1)(x)\n# model.add(Activation('relu'))\nx = MaxPooling2D((2,2))(x)\nx = Conv2D(64,(3,3),padding='SAME',kernel_initializer='random_uniform',activation='relu')(x)\nx = BatchNormalization(axis=-1)(x)\n# model.add(Activation('relu'))\n\nx = Conv2D(128,(3,3),padding='SAME',kernel_initializer='random_uniform',activation='relu')(x)\nx = BatchNormalization(axis=-1)(x)\n# model.add(Activation('relu'))\nx = MaxPooling2D((2,2))(x)\nx = Conv2D(128,(3,3),padding='SAME',kernel_initializer='random_uniform',activation='relu')(x)\nx = BatchNormalization(axis=-1)(x)\n# model.add(Activation('relu'))\n\nx = Conv2D(192,(5,5),padding='SAME',kernel_initializer='random_uniform',activation='relu')(x)\nx = BatchNormalization(axis=-1)(x)\n# model.add(Activation('relu'))\nx = MaxPooling2D((2,2))(x)\nx = Conv2D(192,(5,5),padding='SAME',kernel_initializer='random_uniform',activation='relu')(x)\nx = BatchNormalization(axis=-1)(x)\n# model.add(Activation('relu'))\n\nx = Conv2D(256,(3,3),padding='SAME',kernel_initializer='random_uniform',activation='relu')(x)\nx = BatchNormalization(axis=-1)(x)\n# model.add(Activation('relu'))\nx = MaxPooling2D((3,3))(x)\nx = Conv2D(256,(3,3),padding='SAME',kernel_initializer='random_uniform',activation='relu')(x)\nx = BatchNormalization(axis=-1)(x)\n# model.add(Activation('relu'))\n\nout1 = Flatten()(x)\nout1 = Dense(512)(out1)\nout1 = BatchNormalization()(out1)\nout1 = Activation('relu')(out1)\nout1 = Dropout(0.3)(out1)\nout1 = Dense(2)(out1)\nout1 = Activation('softmax')(out1)\n\nout2 = Flatten()(x)\nout2 = Dense(512)(out2)\nout2 = BatchNormalization()(out2)\nout2 = Activation('relu')(out2)\nout2 = Dropout(0.3)(out2)\nout2 = Dense(2)(out2)\nout2 = Activation('softmax')(out2)\n\nmodel = Model(inputs,[out1,out2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# aug = ImageDataGenerator(\n#     rotation_range=25, width_shift_range=0.1,\n#     height_shift_range=0.1, shear_range=0.2, \n#     zoom_range=0.2, \n#     fill_mode=\"nearest\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history = model.fit_generator(\n#     aug.flow(x_train, y_train, batch_size=64),\n#     validation_data=(x_test, y_test),\n#     steps_per_epoch=len(x_train) // 64,\n#     epochs=20, verbose=1\n#     )\nmodel.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\nbest_model = ModelCheckpoint('cnn_weights.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nh = model.fit(x_train,[y_train1,y_train2],validation_data=(x_test,[y_test1,y_test2]),epochs=15,callbacks=[best_model])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inc_model = InceptionV3(weights='../input/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                   include_top = False,\n                   input_shape=(218,178,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = inc_model.output\n# x = GlobalAveragePooling2D()(x)\nx = Flatten()(x)\nx = Dense(2048, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation=\"relu\")(x)\npredictions = Dense(2, activation=\"softmax\")(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = Model(inc_model.input,predictions)\nbest_model = ModelCheckpoint('inc_weights.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in model1.layers[:311]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.fit(x_train,y_train1,epochs=20,validation_data=(x_test,y_test1),batch_size=32,callbacks=[best_model])\n\n# history = model.fit_generator(\n#     aug.flow(x_train, y_train, batch_size=64),\n#     validation_data=(x_test, y_test),\n#     steps_per_epoch=len(x_train) // 64,\n#     epochs=20, verbose=1\n#     )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nmodel_json = model1.to_json()\nwith open(\"model_inc.json\", \"w\") as json_file:\n    json_file.write(model_json)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}