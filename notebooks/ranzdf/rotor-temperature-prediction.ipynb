{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objs as go\nimport matplotlib.pyplot as plt\nimport sklearn\nimport seaborn as sns\n# ^^^ pyforest auto-imports - don't write above this line\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/electric-motor-temperature/pmsm_temperature_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Process"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"####  Data is anonymized and looks like scaled by some factor"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_model = data.drop(columns='profile_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 12))\nfor i,j in enumerate(data.columns[:-1]):\n    plt.subplot(3, 4, i+1)\n    \n    skew_ = np.round(data[j].skew(), 2)\n    sns.distplot(data[j], label = 'skewness = '+str(skew_))\n    \n    plt.vlines(data[j].mean(), ymin = 0, ymax =1, color = 'r')\n    plt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Our tagret(pm) looks like normally distributed.\n* Most of the attributes looks like multi-model, this may be due to profile_id.\n* Most of the attributes have skewness less than 0.5 expect ambient temp, coolant, i_d\n    > i_d(current through d axis) : this may directly related to the current through field windings but the motor used in testing is PM(permanent magnet motor) so field flux is constant but i_d may depend on voltage and load, which inturn depend on speed.\n    \n    > ambient temp and coolant temp, this may directly depend on testing scenario.\n* Stator_tooth and Stator_winding distributions looks like similar"},{"metadata":{"trusted":true},"cell_type":"code","source":"counts_ = data['profile_id'].value_counts()\n\nfig = px.bar(x = counts_.index,y = counts_.values , template = 'plotly_dark', labels = {'x':'Profile_id', 'y': 'Counts'}, range_x = (0,82))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Is profile_id is a random number or they cut some data of some profile Id's till 40 and afterwards it is continous"},{"metadata":{},"cell_type":"markdown","source":"### ***Profile Id*** does not make sense while to use in a model, bcoz each test case is given a profile id and we don't know which parameters are varying, and in actual situation we don't determine the profile_id(but still we can, assuming as classfication problem(profile_id) first and later regression(pm)).\n#### But still we can check the attribute changes in every profile id"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data['profile_id'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25, 40))\nfor i,j in enumerate(data['profile_id'].unique()):\n    data_ = data[data['profile_id'] == j]\n    \n    plt.subplot(11,5, i + 1)\n    sns.distplot(data_['pm'],label = 'profile_id = '+str(j))\n    plt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> I thought the distribution of pm is slightly normal, but for each test case it is a multi-modal distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25, 50))\nfor i,j in enumerate(data['profile_id'].unique()):\n    data_ = data[data['profile_id'] == j]\n    \n    plt.subplot(11,5, i + 1)\n    sns.distplot(data_['ambient'], hist = False, label = 'ambient')\n    sns.distplot(data_['coolant'], hist = False, label = 'coolant')\n    plt.title('profile_id = '+str(j))\n    plt.legend()\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> The temp of coolant can increase if increase in heat from motor(some cases might be continous working, critical tests,high eddy currents) and also increase in ambinet temp around the motor.\n\n> As the data is anonymized, We can hypothesis that if density of ambient is greater than zero is more, then likely the density of coolant greater than zero is more.\nBut only few cases follow the hypothesis."},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(25, 55))\nfor i,j in enumerate(data['profile_id'].unique()):\n    data_ = data[data['profile_id'] == j]\n    \n    plt.subplot(11,5, i + 1)\n    sns.distplot(data_['motor_speed'], hist = False, label = 'motor_speed')\n    sns.distplot(data_['torque'], hist = False, label = 'torque')\n    plt.title('profile_id = '+str(j))\n    plt.legend()\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Torque and Speed are inversly proportional.\n\n> But the density plotly are slightly overlapping, which shouldn't be the case, This may be because of the axis are normalized  \n\n> The test cases from 46 to 59 follow some type of pattern and remaining won't."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25, 59))\nfor i,j in enumerate(data['profile_id'].unique()):\n    data_ = data[data['profile_id'] == j]\n    \n    plt.subplot(11,5, i + 1)\n    sns.distplot(data_['stator_winding'], hist = False, label = 's_winding')\n    sns.distplot(data_['stator_yoke'], hist = False, label = 's_yoke')\n    sns.distplot(data_['stator_tooth'], hist = False, label = 's_tooth')\n    plt.title('profile_id = '+str(j))\n    plt.legend()\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We can clearly observe that Stator winding and Stator tooth are more overlapping in most of the cases than yoke. This is obivous because the winding sits in tooth. \n\n> We may have multi-colinearity if we use both winding and tooth. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### lets Check attributes w.r.t pm in different test cases."},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()['pm']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(data,x = 'stator_yoke' ,y='pm',template='plotly_dark')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25, 40))\nfor i,j in enumerate(data['profile_id'].unique()):\n    data_ = data[data['profile_id'] == j]\n    \n    plt.subplot(11,5, i + 1)\n    plt.xticks([-2.5,-1.5,0,1.5,2.5])\n    plt.yticks([-3,-2,-1,0,1,2,3])\n    sns.regplot(x = data_['stator_yoke'] ,y=data_['pm'],label = 'profile_id = '+str(j))\n    plt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> By looking at the above graphs we can clearly say the test cases are very distinct, Some of them are strongly positive co-related and some moderately and some are neutral(52,59)."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(data,x = 'stator_tooth' ,y='pm',template='plotly_dark')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25, 40))\nfor i,j in enumerate(data['profile_id'].unique()):\n    data_ = data[data['profile_id'] == j]\n    \n    plt.subplot(11,5, i + 1)\n    plt.xticks([-2.5,-1.5,0,1.5,2.5])\n    plt.yticks([-3,-2,-1,0,1,2,3])\n    sns.regplot(x = data_['stator_tooth'] ,y=data_['pm'],label = 'profile_id = '+str(j))\n    plt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(data,x = 'ambient' ,y='pm',template='plotly_dark')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25, 40))\nfor i,j in enumerate(data['profile_id'].unique()):\n    data_ = data[data['profile_id'] == j]\n    \n    plt.subplot(11,5, i + 1)\n    plt.yticks([-3,-2,-1,0,1,2,3])\n    plt.xticks([-10,-5,0,2.5,5])\n    sns.regplot(x = data_['ambient'] ,y=data_['pm'], label = 'profile_id = '+str(j))\n    plt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> from above graphs we can observe that ambient temp is also a factor of testing parameters, bcoz in some test cases they are postively co-related and in some test cases they are negatively co-related."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(data,x = 'coolant' ,y='pm',template='plotly_dark')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(25, 40))\nfor i,j in enumerate(data['profile_id'].unique()):\n    data_ = data[data['profile_id'] == j]\n    \n    plt.subplot(11,5, i + 1)\n    plt.yticks([-3,-2,-1,0,1,2,3])\n    plt.xticks([-2,-1,0,1,2,3])\n    sns.regplot(x = data_['coolant'] ,y=data_['pm'], label = 'profile_id = '+str(j))\n    plt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We can find some pattern in pm temp and coolant temp in most of the test cases.\n\n> some of the interseting test cases to dig deeper are 51,53,62,69,78"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature-Selection"},{"metadata":{},"cell_type":"markdown","source":"> If we isolate some test_cases(profile_id) we may get better results while predicting pm, but for now lets consider all test cases."},{"metadata":{"trusted":true},"cell_type":"code","source":"X,Y = data.drop(columns = 'pm'), data['pm']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()['pm'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_cols = ['stator_tooth','stator_winding','stator_yoke','ambient']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_regression,f_regression,f_oneway","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fs = SelectKBest(score_func=f_regression, k='all')\nfs.fit(X, Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(x =X.columns, y = fs.scores_, template = 'plotly_dark')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15,8)","execution_count":null,"outputs":[]},{"metadata":{"id":"0Eb4xoNi_fsZ","trusted":true},"cell_type":"code","source":"def check_mutlicolinearity(data_x):\n    corr = data_x.corr()\n    corr = pd.DataFrame(np.tril(corr, k=-1),      # gets Lower triangular matrix\n                        columns=data_x.columns,\n                        index=data_x.columns)  \n\n    corr = corr.replace(0.000000, np.NAN)\n    count_of_total_correlation_values = corr.count().sum()\n\n    for i in [0.5, 0.6, 0.7, 0.8, 0.9]:\n        data_corr = corr[abs(corr) > i]\n        count_greater_than_thresh = data_corr.count().sum()\n        print(f'Percent Values Greater than {i} co-relation : {count_greater_than_thresh/count_of_total_correlation_values}')\n    return corr\n\ndef plot_corr(threshold, corr):\n    data_corr = corr[abs(corr) > threshold]\n    sns.heatmap(data_corr, annot=True, cmap=\"YlGnBu\", center=0)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = check_mutlicolinearity(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_corr(0.7, corr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> As torque directly depends on current through quadratic axis."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()['pm']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import bartlett","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"H0 : variance_1 = variance_2\n\nH1 : variance_1 != variance_2"},{"metadata":{},"cell_type":"markdown","source":"pvalue is less than 0.05. So we reject the null hypothesis and can say that variance of attribute_1 is not equal to the variance of attribute_2"},{"metadata":{},"cell_type":"markdown","source":"pvalue is higher than 0.05. So we fail to reject the null hypothesis and can say that we do not have enough evidence to reject the null hypothesis.                      \nSo we ***do not have enough evidence*** to prove that variance of attribute_1 is not equal to the variance of attribute_2."},{"metadata":{"trusted":true},"cell_type":"code","source":"bartlett(data['i_q'],data['torque'])  # Can remove one feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bartlett(data['stator_winding'],data['stator_tooth'])  # Can remove one feature , drop stator_tooth","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bartlett(data['stator_yoke'],data['stator_tooth'])  # Can remove one feature, drop stator_tooth","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bartlett(data['stator_yoke'],data['coolant'])  # Can remove one feature, but lets keep both","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bartlett(data['torque'],data['u_d'])  # Can remove one feature, drop torque","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bartlett(data['i_d'],data['motor_speed'])  # keep both","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bartlett(data['u_d'],data['motor_speed'])  # keep both","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling "},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import BaggingRegressor,AdaBoostRegressor,GradientBoostingRegressor,RandomForestRegressor,VotingRegressor\nfrom sklearn.model_selection import cross_val_score,GridSearchCV,KFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nfrom statsmodels.api import add_constant","execution_count":null,"outputs":[]},{"metadata":{"id":"Oce_pmf_n_kX","trusted":true},"cell_type":"code","source":"X_new_c=sm.add_constant(X)\n\nmodel2=sm.OLS(Y,X_new_c).fit()\nmodel2.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Durbin-watson statistic is less than 2, so there is negative auto correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_selected = X.drop(columns = ['profile_id','torque'])\nX_new=sm.add_constant(X_selected)\n\nmodel=sm.OLS(Y,X_new).fit()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_error = mean_squared_error(Y, model.predict(X_new))\ntrain_error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While using the ols to test on whole trained data in a ***range of -3 to +3***, we are getting ***mse = 0.225***"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"mmtlK0yDftJt","trusted":true,"collapsed":true},"cell_type":"code","source":"# GB_bias=[]\n# GB_ve=[]\n# for n in np.arange(90,100):\n#     GB=GradientBoostingRegressor(n_estimators=n,random_state=0)\n#     scores=cross_val_score(GB,X_selected,Y,cv=2,scoring='neg_mean_squared_error', n_jobs = -1)\n#     rmse=np.sqrt(np.abs(scores))\n#     GB_bias.append(np.mean(rmse))\n#     GB_ve.append((np.std(rmse,ddof=1)))\n\n# # x_axis=np.arange(len(GB_bias))\n# # plt.plot(x_axis,GB_bias)\n\n# np.argmin(GB_bias)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"mmtlK0yDftJt","trusted":true,"collapsed":true},"cell_type":"code","source":"# bias=[]\n# ve=[]\n# LR=LinearRegression()\n\n# for n in np.arange(20,60):\n#     mod=AdaBoostRegressor(base_estimator=LR,n_estimators=n,random_state=0)\n#     scores=cross_val_score(mod,X_selected,Y,cv=3,scoring='neg_mean_squared_error', n_jobs = -1)\n#     bias.append(np.mean(rmse))\n#     ve.append((np.std(rmse,ddof=1)))\n\n# # x_axis=np.arange(len(bias))\n# # plt.plot(x_axis,bias)\n\n# np.argmin(bias)","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":997,"status":"ok","timestamp":1591062538189,"user":{"displayName":"Mahesh Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAxRvO4nLPhI4SJLaIoUVmhr8lm1tddyCLyKOj=s64","userId":"06788086636039591358"},"user_tz":-330},"id":"zuAXDszas_WG","outputId":"e9e75aa5-2463-422d-f811-d75169eaae08","trusted":false},"cell_type":"code","source":"# bias=[]\n# ve=[]\n# for n in np.arange(10,60):\n#     mod=AdaBoostRegressor(n_estimators=n,random_state=0)\n#     scores=cross_val_score(mod,X_selected,Y,cv=3,scoring='neg_mean_squared_error', n_jobs = -1)\n#     bias.append(np.mean(rmse))\n#     ve.append((np.std(rmse,ddof=1)))\n\n# # x_axis=np.arange(len(bias))\n# # plt.plot(x_axis,bias)\n\n# np.argmin(bias)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"vUWwlMjleBpq","trusted":true},"cell_type":"code","source":"LR=LinearRegression()\nLR_AB=AdaBoostRegressor(base_estimator=LR,n_estimators = 100 ,random_state=0)\nDT_AB=AdaBoostRegressor(n_estimators = 50 ,random_state=0)\nLR_GB=GradientBoostingRegressor(n_estimators = 100, random_state=0)\nRF=RandomForestRegressor(criterion='mse',random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"id":"MsOXxC8rQr1w","trusted":true},"cell_type":"code","source":"models = []\nmodels.append(('LinearRegression', LR))\nmodels.append(('Adaboost',LR_AB))\nmodels.append(('DT_boost',DT_AB))\nmodels.append(('GBoost',LR_GB))\nmodels.append(('RF',RF))","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":1884,"status":"ok","timestamp":1591701987539,"user":{"displayName":"Mahesh Anand","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiAxRvO4nLPhI4SJLaIoUVmhr8lm1tddyCLyKOj=s64","userId":"06788086636039591358"},"user_tz":-330},"id":"AIjRN_8gQkEF","outputId":"a865e3ed-d22d-4e37-e989-634586c79020","trusted":true},"cell_type":"code","source":"# evaluate each model in turn\nresults = []\nnames = []\nfor name, model in models:\n    kfold = KFold(shuffle=True,n_splits=3,random_state=0)\n    cv_results = cross_val_score(model, X_selected, Y,cv=kfold, scoring='neg_mean_squared_error', n_jobs = -1)\n    results.append(np.sqrt(np.abs(cv_results)))\n    names.append(name)\n    \n    print(\"%s: %f (%f)\" % (name, np.mean(np.sqrt(np.abs(cv_results))),np.std(np.sqrt(np.abs(cv_results)),ddof=1)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import neighbors\nknn=neighbors.KNeighborsRegressor()\n\nparam_grid={\n    'n_neighbors':np.arange(1,5),\n    'weights':['uniform', 'distance']}\n\nkfold= KFold(n_splits=3,shuffle=True,random_state=1)\nmodel= GridSearchCV(estimator=knn,\n                        param_grid=param_grid,\n                        scoring='neg_mean_squared_error',\n                        cv=kfold,\n                        refit=True,\n                        verbose=5,\n                        n_jobs=-1)\n                        \nmodel.fit(X_selected,Y)\n\nprint('Best Scorer{}'.format(model.best_score_))\nprint()\nprint('Best Parameters{}'.format(model.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = pd.DataFrame(model.cv_results_)\nres.sort_values('rank_test_score').head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}