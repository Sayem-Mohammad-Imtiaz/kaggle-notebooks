{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### *We're going to use only that 1 dataset, so don't take into account others imported*"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_sum=pd.read_csv('/kaggle/input/corona-virus-report/country_wise_latest.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Look through info to check that data is clean or dirty and what columns consist of objects**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sum.info()\ndf_sum.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Use labelEncoder to transform objects into int."},{"metadata":{"trusted":true},"cell_type":"code","source":"s = (df_sum.dtypes == 'object')\nobject_cols = list(s[s].index)\nprint(object_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Make copy to avoid changing original data \nlabeled_data= df_sum.copy()\n\n\n# Apply label encoder to each column with categorical data\nlabel_encoder = LabelEncoder()\n\nfor col in object_cols:\n    labeled_data[col] = label_encoder.fit_transform(df_sum[col])\n    \nprint(labeled_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We don't have any missing values, so we can skip technics of dealing with NA like Simple Imputer\n### But we need to check for outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(10,4))\nplt.xlim(labeled_data.Confirmed.min(), labeled_data.Confirmed.max()*1.1)\nsns.boxplot(x=labeled_data.Confirmed )\n\nplt.figure(figsize=(10,4))\nplt.xlim(labeled_data.Deaths.min(), labeled_data.Deaths.max()*1.1)\nsns.boxplot(x=labeled_data.Deaths )\n\nplt.figure(figsize=(10,4))\nplt.xlim(labeled_data. Recovered.min(), labeled_data. Recovered.max()*1.1)\nsns.boxplot(x=labeled_data. Recovered)\n\n\nplt.figure(figsize=(10,4))\nplt.xlim(labeled_data.Active.min(), labeled_data.Active.max()*1.1)\nsns.boxplot(x=labeled_data.Active)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(labeled_data.Confirmed[labeled_data.Confirmed>2000000].count())\nprint(labeled_data.Deaths[labeled_data.Deaths>80000].count())\nprint(labeled_data.Recovered[labeled_data.Recovered>750000].count())\nprint(labeled_data.Active[labeled_data.Active>1000000].count())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get rid of outliers"},{"metadata":{},"cell_type":"markdown","source":"### Experiments have shown that with outliers models better fit data, so we just comment this part"},{"metadata":{"trusted":true},"cell_type":"code","source":"#labeled_data=labeled_data[labeled_data.Confirmed<700000]\n#labeled_data=labeled_data[labeled_data.Deaths<80000]\n#labeled_data=labeled_data[labeled_data.Recovered<500000]\n#labeled_data=labeled_data[labeled_data.Active<150000]\n#labeled_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.figure(figsize=(10,4))\n#plt.xlim(labeled_data.Confirmed.min(), labeled_data.Confirmed.max()*1.1)\n#sns.boxplot(x=labeled_data.Confirmed )\n\n#plt.figure(figsize=(10,4))\n#plt.xlim(labeled_data.Deaths.min(), labeled_data.Deaths.max()*1.1)\n#sns.boxplot(x=labeled_data.Deaths )\n\n#plt.figure(figsize=(10,4))\n#plt.xlim(labeled_data. Recovered.min(), labeled_data. Recovered.max()*1.1)\n#sns.boxplot(x=labeled_data. Recovered)\n\n\n#plt.figure(figsize=(10,4))\n#plt.xlim(labeled_data.Active.min(), labeled_data.Active.max()*1.1)\n#sns.boxplot(x=labeled_data.Active)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"labeled_data = labeled_data.drop(columns=['Deaths / 100 Recovered'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nlabeled_data = scaler.fit_transform(labeled_data)\n\nprint(labeled_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labeled_data=pd.DataFrame(labeled_data)\nlabeled_data.columns = ['Country/Region',  'Confirmed',  'Deaths',  'Recovered',  'Active',  'New cases', 'New deaths',  'New recovered',  'Deaths / 100 Cases',  'Recovered / 100 Cases', 'Confirmed last week',  '1 week change', '1 week % increase','WHO Region']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Here we can start modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Select predictors\ncols_to_use = ['Country/Region', 'Confirmed', 'Recovered' , 'Active' , 'New cases', 'New deaths'  ,'New recovered' , 'Confirmed last week' , 'Recovered / 100 Cases','Deaths / 100 Cases','1 week change','1 week % increase','WHO Region']\n\nX = labeled_data[cols_to_use]\n\n# Select target\ny = labeled_data.Deaths\n\n# Separate data into training and validation sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle= True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### GridSearch for XGBRegressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model validation.\nfrom sklearn.model_selection import GridSearchCV\n\nfrom xgboost import XGBRegressor\n\nparam_grid = {\n    \"learning_rate\": [0.01, 0.025, 0.05],\n    \"max_depth\":[5,8],\n    \"criterion\": [\"explained_variance\"],\n    \"subsample\":[0.5, 0.8, 0.85],\n    \"n_estimators\":[500,1000]\n}\n\ngridsearch = GridSearchCV(XGBRegressor(), param_grid=param_grid, cv=5,\n                         scoring='explained_variance',n_jobs=-1).fit(X_train, y_train,\n             early_stopping_rounds=15, \n             eval_set=[(X_test, y_test)], \n             verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(gridsearch.score(X_train, y_train))\nprint(gridsearch.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import explained_variance_score\n\npredictions = gridsearch.predict(X_test)\n\nprint(\"Mean Absolute Error: \" + str(mean_absolute_error(y_test, predictions)))\n\nexplained_variance_score=explained_variance_score(y_test, predictions)\nprint('Explained_variance_score: '+ str(explained_variance_score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\n    \"max_depth\": [3, 5, 7, 9, 11, 13],\n}\n\nmodel_desicion_tree = DecisionTreeRegressor()\n\nmodel_desicion_tree = GridSearchCV(\n    model_desicion_tree, \n    parameters, \n    cv=5,\n    scoring='explained_variance',\n)\n\nmodel_desicion_tree.fit(X_train, y_train)\n\nprint(f'Best parameters {model_desicion_tree.best_params_}')\nprint(f'Mean cross-validated accuracy score of the best_estimator: {model_desicion_tree.best_score_:.3f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {\n    \"n_estimators\": [5, 10, 15, 20, 25], \n    \"max_depth\": [3, 5, 7, 9, 11, 13],\n}\n\nmodel_random_forest = RandomForestRegressor()\n\nmodel_random_forest = GridSearchCV(\n    model_random_forest, \n    parameters, \n    cv=5,\n    scoring='explained_variance',\n)\n\nmodel_random_forest.fit(X_train, y_train)\n\nprint(f'Best parameters {model_random_forest.best_params_}')\nprint(f'Mean cross-validated accuracy score of the best_estimator: {model_random_forest.best_score_:.3f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBRegressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model = XGBRegressor(n_estimators=500, learning_rate=0.01, max_depth=8,subsample=0.5 )\nmy_model.fit(X_train, y_train, \n             early_stopping_rounds=10, \n             eval_set=[(X_test, y_test)], \n             verbose=False)\n\npredictions = my_model.predict(X_test)\nprint(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_test)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's look at the graph of the average cross-validation test scores for each model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nkfold = 10 #validation subsamples\nresult_val = {} #list for results of validation\n\nscores = model_selection.cross_val_score(model_desicion_tree, X, y, cv = kfold)\nresult_val['Desicion Tree'] = scores.mean()\nscores = model_selection.cross_val_score(model_random_forest, X, y, cv = kfold)\nresult_val['Random Forest'] = scores.mean()\nscores = model_selection.cross_val_score(my_model, X, y, cv = kfold)\nresult_val['XGBRegressor'] = scores.mean()\nscores = model_selection.cross_val_score(gridsearch,X, y, cv = kfold)\nresult_val['Gridsearch'] = scores.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame.from_dict(data = result_val, orient='index').plot(kind='bar', legend=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gridsearch for XGB has shown the best result around 70%"},{"metadata":{},"cell_type":"markdown","source":"### Vizualization is important and pretty"},{"metadata":{},"cell_type":"markdown","source":"### Plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = plt.figure(figsize=(15, 15))\nplt.matshow(X.corr(), fignum=f.number)\nplt.xticks(range(X.shape[1]), X.columns, fontsize=14, rotation=45)\nplt.yticks(range(X.shape[1]), X.columns, fontsize=14)\ncb = plt.colorbar();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import plot_importance\n\ndef plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1,1,figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)\n\nplot_features(my_model, (10,14))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize = (10, 10), dpi = 80)\n# plot the data using seaborn\nax = sns.boxplot(x = \"WHO Region\", y = \"Deaths\", data = df_sum)\n\n\n# ----------------------------------------------------------------------------------------------------\n# prettify the plot\n\n# change the font of the x and y ticks (numbers on the axis)\nax.tick_params(axis = 'x', labelrotation = 90, labelsize = 12)\nax.tick_params(axis = 'y', labelsize = 12)\n\n# set and x and y label\nax.set_xlabel(\"WHO Region\", fontsize = 14)\nax.set_ylabel(\"Deaths\", fontsize = 14)\n\n# set a title\nax.set_title(\"Boxplot\", fontsize = 14);\nax.margins(y=0.05)\nax.set_ylim([-1,60000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8), dpi= 80)\nsns.pairplot(X, kind=\"scatter\", plot_kws=dict(s=80, edgecolor=\"white\", linewidth=2.5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import squarify \n\n# Prepare Data\ndf = df_sum.groupby('WHO Region').size().reset_index(name='counts')\nlabels = df.apply(lambda x: str(x[0]) + \"\\n (\" + str(x[1]) + \")\", axis=1)\nsizes = df['counts'].values.tolist()\ncolors = [plt.cm.Spectral(i/float(len(labels))) for i in range(len(labels))]\n\n# Draw Plot\nplt.figure(figsize=(12,8), dpi= 80)\nsquarify.plot(sizes=sizes, label=labels, color=colors, alpha=.8)\n\n# Decorate\nplt.title('WHO Region')\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}