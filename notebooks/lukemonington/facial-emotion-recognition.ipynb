{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data can be found here: https://www.kaggle.com/ashishpatel26/facial-expression-recognitionferchallenge\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport tensorflow as tf\n\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.losses import CategoricalCrossentropy\n\ndf = pd.read_csv('../input/facial-expression-recognitionferchallenge/fer2013/fer2013/fer2013.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = []\nfor i in range(df.shape[0]):\n    # the pixels column is a string of space-separated numbers, convert this to a list where each entry is separated by a space\n    image = df['pixels'][i].split()\n    # convert from strings to floats, alter to be in range 0-1 instead of 0-255\n    image = [float(i)/255 for i in image]\n    # reshape to be 48 x 48\n    image = np.reshape(image, (48, 48))\n    # expand dims to have channels, so the array is shape 48x48x1\n    image = np.expand_dims(image, axis=2)\n    images.append(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = np.stack(images, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert targets to series\ntargets = df['emotion']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_to_hr = {0:'anger', 1:'disgust', 2:'fear', 3:'happiness', 4: 'sadness', 5: 'surprise', 6: 'neutral'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,10))\nfor i in range(10):\n    fig.add_subplot(5, 5, i+1)\n    plt.imshow(images[i], cmap='gray')\n    label = label_to_hr[targets[i]]\n    plt.title(label)\n    plt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n(X_train, X_valid, y_train, y_valid) = train_test_split(images, targets, test_size=0.2, random_state=999)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nlb = preprocessing.LabelBinarizer()\nlb.fit(y_valid)\n\ny_train_bin = lb.transform(y_train)\ny_valid_bin = lb.transform(y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lb.classes_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    rotation_range = 20,\n    horizontal_flip = True\n)\n\nvalid_datagen = ImageDataGenerator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size=10\n\ntrain_generator = train_datagen.flow(X_train, y_train_bin, batch_size=batch_size)\nvalid_generator = valid_datagen.flow(X_valid, y_valid_bin, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_network():\n    input_layer = Input(shape=(48, 48, 1))\n    x = Conv2D(filters=32,\n               kernel_size=(3, 3),\n               padding='same',\n               strides=(1, 1))(input_layer)\n    x = ReLU()(x)\n    x = Dropout(rate=0.5)(x)\n\n    x = Flatten()(x)\n    x = Dense(units=7)(x)\n    output = Softmax()(x)\n\n    model = Model(inputs=input_layer, outputs=output)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_network()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 50\nmodel.compile(loss=CategoricalCrossentropy(from_logits=True), optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for iteration in train_generator:\n    print(iteration)\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', \n                                              min_delta=0, \n                                              patience=5, \n                                              verbose=0,\n                                              mode='auto', \n                                              baseline=None, \n                                              restore_best_weights=False\n                                             )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 50\nhistory = model.fit(train_generator, validation_data=valid_generator, epochs=epochs, callbacks=[early_stop])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50V2\n\nn_layers = 150\nimg_shape = (48, 48, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model  = ResNet50V2(input_shape=img_shape, include_top=False, weights='imagenet')\nhead_model = base_model\nfor layers in base_model.layers[:n_layers]:\n    layers.trainable = False\nhead_model = head_model.output\nhead_model = tf.keras.layers.GlobalMaxPooling2D()(head_model)\nhead_model = tf.keras.layers.Flatten(name=\"Flatten\")(head_model)\nhead_model = tf.keras.layers.Dense(1024, activation='relu')(head_model)\nhead_model = tf.keras.layers.Dropout(0.2)(head_model)\nprediction_layer = tf.keras.layers.Dense(7, activation='softmax')(head_model)\nmodel = tf.keras.Model(inputs=base_model.input, outputs=prediction_layer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}