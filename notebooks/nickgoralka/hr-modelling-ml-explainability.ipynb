{"cells":[{"metadata":{},"cell_type":"markdown","source":"# HR Data Analysis: Intro\n\nThe situation set up by the data set is that a company which is active in the Big Data and Data Analysis space is offer in courses to some of its employees. The company is offer paid training to their employees. Fortunately, many employees have signed up for these paid job trainings. However, they have been running into the situation where upon finishing a course they end up switching companies. The company would like to know whether or a candidate is going to jump ship after finishing the course. The provide dataset encapsulates a number of measured factors such as the number of the training being offered, the education level of the candidate, the developement index of the city for which the company is located, ext ... The data was collected with idea that it could posible to predict whether or not a person is going to leave the company right after completing the paid training.\n\n\nThe comprehensive goal of this brief investagation is produce a predictive model which can accurately decern whether or not a candidate is going to jump ship. Moreover, it is the goal of this investation to create human understandible insights. If these decisions were to be integrated into a real company, it is best not to have a \"black box\" solution. "},{"metadata":{},"cell_type":"markdown","source":"![Image of Yaktocat](https://img.etimg.com/thumb/width-640,height-480,imgsize-126438,resizemode-1,msid-70712251/wealth/earn/should-you-change-your-job-heres-how-to-find-out/jon-change-4.jpg)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport plotly.express as px\nimport plotly.graph_objects as go\n\n\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.tree import export_graphviz\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.metrics import plot_confusion_matrix\n\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.pipeline import Pipeline as Pipeline_im\n\n\nfrom IPython.display import Image\n\nfrom subprocess import call\n\nimport matplotlib.pyplot as plt\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing the Data\n\nUpon importing the data we can descernably make a couple of observations\n - Data Points are missing \n - The dataset is inbalanced\n     - Mainly in that most of the sampled participants are Men is STEM majors\n - Most features are catagorical and some are of high cardinality\n \n \n This will be taken into consideration upon building our pipeline"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/hr-analytics-job-change-of-data-scientists/aug_train.csv')\nprint('DataSet Info')\nprint('=' * 60)\nprint(train.info())\nprint('=' * 60)\nprint('=' * 60)\nprint('=' * 60)\n\nprint('DataSet Stats')\nprint('=' * 60)\nprint(train.describe())\n\nprint('=' * 60)\nprint('=' * 60)\nprint('=' * 60)\n\n\nprint('Missing Values')\nprint('=' * 60)\nprint(train.isna().sum())\n\n\n\ntrain.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/hr-analytics-job-change-of-data-scientists/aug_train.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain.gender.unique()\nmale = train[(train['gender'] == 'Male') & (train['target'] == 0)]\nfemale = train[(train['gender'] == 'Female')  & (train['target'] == 0)]\nother = train[(train['gender'] == 'Other')  & (train['target'] == 0)]\n\n\nfig = go.Figure()\nfig.add_trace(go.Histogram(x=male['training_hours'],\n             name=\"Male\"))\nfig.add_trace(go.Histogram(x=female['training_hours'],\n             name=\"Female\"))\nfig.add_trace(go.Histogram(x=other['training_hours'],\n             name=\"Other\"))\n\n\n\n# Overlay both histograms\nfig.update_layout(barmode='overlay',\n                 xaxis_title_text='Number of Training Hours',\n                 yaxis_title_text='Count',\n                 title_text='Distibution of Candidatas Not Looking For Company Change')\n# Reduce opacity to see both histograms\nfig.update_traces(opacity=0.5)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"male = train[(train['gender'] == 'Male') & (train['target'] == 1)]\nfemale = train[(train['gender'] == 'Female')  & (train['target'] == 1)]\nother = train[(train['gender'] == 'Other')  & (train['target'] == 1)]\n\nfig = go.Figure()\nfig.add_trace(go.Histogram(x=male['training_hours'],\n             name=\"Male\"))\nfig.add_trace(go.Histogram(x=female['training_hours'],\n             name=\"Female\"))\nfig.add_trace(go.Histogram(x=other['training_hours'],\n             name=\"Other\"))\n\n\n# Overlay both histograms\nfig.update_layout(barmode='overlay',\n                 xaxis_title_text='Number of Training Hours',\n                 yaxis_title_text='Count',\n                 title_text='Distibution of Candidatas Looking For Company Change')\n# Reduce opacity to see both histograms\nfig.update_traces(opacity=0.75)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['major_discipline'].unique()\n\ndf = train['major_discipline'].value_counts()\n\n\nfig = px.pie(df, values=df, names=df.index,\n            title='Employees by Major')\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box Plot Comparing\ntrain = train.replace(np.nan, 'Unknown', regex=True)\ntrain['city_development_index'].unique()\nfig = px.box(train, x='target',y=\"city_development_index\", \n             color='gender',\n             )\nfig.update_layout(\n            xaxis_title_text='Looking For New Job')\nfig.show()\n\ntrain['city_development_index'].unique()\nfig = px.box(train, x='target',y=\"city_development_index\", \n             color='education_level',\n             notched=True)\nfig.update_layout(\n            xaxis_title_text='Looking For New Job')\nfig.show()\n\n# Box Plot Comparing\ntrain = train.replace(np.nan, 'Unknown', regex=True)\n\n# analysze how company size affects the likelyhood that they are getting the training\ndf = train['company_size']\nfig = px.box(train, x='target',y=\"training_hours\", \n             color='education_level',\n             notched=True)\nfig.update_layout(\n            xaxis_title_text='Looking For New Job')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train[(train['target'] == 0)]\ndf = train['relevent_experience'].value_counts()\n\nfig = px.pie(df, values=df, names=df.index,\n            title='Not Looking For New Job')\n\nfig.show()\n\ndf = train[(train['target'] == 1)]\ndf = train['relevent_experience'].value_counts()\n\nfig = px.pie(df, values=df, names=df.index,\n            title='Looking For New Job')\n\n\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA - Key Takeaways\n\nAs we can see gender plays list to no roll at all to whether a person is a flight risk or not. The distributions for gender across both groups who chose to stay and to those who chose to leave look nearly identical. Another key takeaway is the degree to which our data is imbalanced. Seventy two percent of candidates have relevent experience, eighty nine percent of of candidates have STEM backgrounds, and the overwhelming majority of candidates are male. Therefore, it should be necissary that we take into account this imbalance when defining our pipeline. \n\nIt should also be noted that across both gender and education levels we see that the city's level of developement plays a significant role in determining whether the participant leaves or not. This makes sense as a person living in a city with a low developement index logically is going to be more likely to look elsewhere for another opportunity, Additionally, it is the reason why top companies such as google locate their offices in growing cities with high levels of developement. "},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning and Model Definition\n\n    - Define Pipeline,\n        - Impute Missing Values or Drop the Columns\n        - One Hot Encode the Low Cardinality Categorical Data\n        - Utilize SMOTE to deal with imbalance (Synthetic Minority Oversampling Technique)\n        - Utilize Cross Validation to evaluate our model to get a better sense of our accuracy\n\nResources: \\ \n[Cross Validation](https://www.kaggle.com/alexisbcook/cross-validation) \\ \n[SMOTE - Over Sampling](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)\n\n "},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/hr-analytics-job-change-of-data-scientists/aug_train.csv')\ntest = pd.read_csv('../input/hr-analytics-job-change-of-data-scientists/aug_test.csv')\ntrain.isna().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperate input data from the target data\ny = train['target']\nX_full = train.drop('target', axis=1)\nX_train_full = X_full.drop('enrollee_id', axis=1)\n\ny_test_full = train['target']\nX_test_full = train.drop('target', axis=1)\nX_enrollee_id = X_test_full['enrollee_id']\nX_test_full = X_test_full.drop('enrollee_id', axis=1)\n\n\n\n\n\n\n\n\n# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\ncategorical_cols_low = [cname for cname in X_train_full.columns if\n                    X_train_full[cname].nunique() < 10 and \n                    X_train_full[cname].dtype == \"object\"]\n\ncategorical_cols_high = [cname for cname in X_train_full.columns if\n                    X_train_full[cname].nunique() > 10 and \n                    X_train_full[cname].dtype == \"object\"]\n\n# Select numerical columns\nnumerical_cols = [cname for cname in X_train_full.columns if \n                X_train_full[cname].dtype in ['int64', 'float64']]\n\n# # Keep selected columns only\nmy_cols = categorical_cols_low + numerical_cols \n\nX_test = X_test_full[my_cols].copy()\n\nX = X_full[my_cols].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Columns to Include: {my_cols}')\nprint(f'Columns Getting Excluded {categorical_cols_high}')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both 'city' and 'experience can be reasoned to be redundant in 'relevent_expericence' and 'city_developement_index', so I'm alright with loosing that bit of information."},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_model(model=DecisionTreeClassifier, max_depth=None):\n    # Preprocessing for numerical data\n    numerical_transformer = SimpleImputer(strategy='constant')\n\n    # Preprocessing for categorical data\n    categorical_transformer = Pipeline(steps=[\n        ('imputer', SimpleImputer(strategy='most_frequent')),\n        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n    ])\n\n    # Bundle preprocessing for numerical and categorical data\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numerical_transformer, numerical_cols),\n            ('cat', categorical_transformer, categorical_cols_low)\n        ])\n\n\n\n    if max_depth:\n    # Define model\n        model = Pipeline_im([('passthrough', SMOTE()),\n           ('model',model(max_depth=max_depth))])\n    else:\n        model = Pipeline_im([('passthrough', SMOTE()),\n           ('model',model())])\n\n    # Bundle preprocessing and modeling code in a pipeline\n    clf = Pipeline(steps=[('preprocessor', preprocessor),  \n                          ('model', model)\n                         ])\n\n    # Cross Validate the training data\n    auc = cross_val_score(clf, X, y,\n                              cv=5,\n                              scoring='roc_auc')\n   \n    # Preprocessing of training data, actually fit a model \n    clf.fit(X, y)\n    \n    avg_auc = auc.mean()\n    std_auc = auc.std()\n    \n    print('ROC//AUC Score w/ Cross Validation:', avg_auc)\n    print('AUC Score Standard Deviation: ', std_auc)\n\n    return avg_auc, std_auc, clf\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_DT_limitted, std_auc_DT, clf_DT_limtted = make_model(DecisionTreeClassifier, max_depth=4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract the onehot encoded features out of the Pipeline\nfeature_names = clf_DT_limtted.named_steps['preprocessor'].transformers_[1][1]\\\n   .named_steps['onehot'].get_feature_names(categorical_cols_low)\nfeature_names = numerical_cols + list(feature_names) \n\n\n\n# Export a Visual Representation of the tree\nexport_graphviz(clf_DT_limtted['model']['model'], out_file='tree.dot', \n                feature_names = feature_names,\n                class_names = ['stay', 'leave'],\n                rounded = True, proportion = False, \n                precision = 2, filled = True)\n\n\ncall(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\nImage(filename = 'tree.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_ADA, std_ADA, clf_ADA = make_model(AdaBoostClassifier)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nauc_XGB, std_XGB, clf_XGB = make_model(GradientBoostingClassifier, 4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_KNN, std_KNN, clf_KNN = make_model(KNeighborsClassifier)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = plt.gca()\nada_disp = plot_roc_curve(clf_ADA, X_test, y_test_full, ax=ax, alpha=0.8, name='AdaBoostClassifier')\nXGB_disp = plot_roc_curve(clf_XGB, X_test, y_test_full,  ax=ax, alpha=0.8, name='GradientBoostingClassifier')\nKNN_disp = plot_roc_curve(clf_KNN, X_test, y_test_full,  ax=ax, alpha=0.8, name='KNeighborsClassifier')\nDT_disp =  plot_roc_curve(clf_DT_limtted, X_test, y_test_full,  ax=ax, alpha=0.8, name='DecisionTree')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disp = plot_confusion_matrix(clf_KNN, X_test, y_test_full)\ndisp.ax_.set_title('KNeighborsClassifier')\n\ndisp1 = plot_confusion_matrix(clf_XGB, X_test, y_test_full)\ndisp1.ax_.set_title('XGBoostClassifier')\n\ndisp2 = plot_confusion_matrix(clf_DT_limtted, X_test, y_test_full)\ndisp2.ax_.set_title('Decision Tree')\n\ndisp3 = plot_confusion_matrix(clf_ADA, X_test, y_test_full)\ndisp3.ax_.set_title('AdaBoostClassifier')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Permutation Importance \nresults = permutation_importance(clf_XGB, X_test, y_test_full,\n                                n_repeats = 30,\n                                random_state=69)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df = pd.DataFrame(results.importances_mean)\nresults_df['Features'] = my_cols\nresults_df = results_df.rename(columns={0 : 'Average Importance'})\n\nfig = px.bar(results_df, x='Features', y='Average Importance')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion - Key Take Aways\n\nSince we are getting varying results with our models which at best are imperfectly accurate, one has to question to validity of productionalizing this model into an actual HR department in a company. Analyzing the ROC curve which visualizes True Positivity Rate vs False Positive Rate for every threshold we can give the classifier. True Positivity Rate is that rate of truly positive results that our model predicts over the numeber of actual positive. False Positivity Rate is the number of False Positives detected over the actual number of negatives in the dataset. Our classifiers can be tuned based on a threshold so that it is less likely to either yeild false positives or false negatives, however there is a trade off. The ROC (Reciever Operator Characteristic) Curve demostrates this tradeoff. If we make some broad estimates with interpretting our results, we can see that in the best of conditions if we want to truly identify 80% of true fight risks, we would be falsely acusing 50% of our candidates. Impementing any threshold (any point on the curve) might lead to demotivating effects of the employees and consiquently make them more likely to leave your company. Thus it is my opinion that a productionalized model should not be used over traditional HR resources.\n\nUtilizing our model as a tool to extract insight, we see as was noting in the exploratory data analysis portion of the notebook city developement is by and large the most prodominant determinant. This confirms what we already know. This makes sense as a person living in a city with a low developement index logically is going to be more likely to look elsewhere for another opportunity, Additionally, it is the reason why top companies such as google locate their offices in growing cities with high levels of developement. From the visualized tree we see that if a person lives in a low developement city, they are less likely to leave if they are working in a larger company.\n\nAnother important note is that gender play absolutely no role in determining whether or not a candidate is a flight risk. Unfortunately, sexism and bias are prevelent in our society and historically a person might get overlooked for a training based on their gender. Our finding go beyond the moral arguement, to find this empirically nonsensical. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}