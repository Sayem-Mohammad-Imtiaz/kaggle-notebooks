{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv('/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv')\ndata.head(13)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n = data.isna().sum()\nn = n.reset_index()\nn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n['%'] = n[0]*100/len(data)\nn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['RainToday'] = data['RainToday'].replace(\"No\",0).replace(\"Yes\",1)\ndata['RainToday'].head(13)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['RainTomorrow'] = data['RainTomorrow'].replace(\"No\",0).replace(\"Yes\",1)\ndata['RainTomorrow'].head(13)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"> The below plot shows that our output data is biased for category 0 i.e. No. Upsampling should be done to make it equal","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nsns.histplot(data,x=\"RainTomorrow\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Dropping the rows which have output variable as NAN**","metadata":{}},{"cell_type":"code","source":"data = data.dropna(subset=[\"RainTomorrow\"],axis=0)\ndata.shape\ndata.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"objects_data = data.select_dtypes(include=\"object\")\nobjects_data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"objects_data.nunique()\n# objects_data = objects_data.fillna(objects_data.mode()[0]) \n# objects_data.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"objects_data.Location.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Imputation**","metadata":{}},{"cell_type":"code","source":"data = data.iloc[:,1:]\ndata.head(40)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Filling the NAN Values with mean and mode\n#Mean if values are regressive and mode if values are categorical or discrete\ndata = data.fillna(data.mean())\n# for col in data.columns:\n#     data[col] = data[col].fillna(data[col].mean())\n# data.isna().sum()\ndata.head(13)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['WindGustDir'] = data['WindGustDir'].fillna(data['WindGustDir'].mode()[0])\ndata['WindDir9am'] = data['WindDir9am'].fillna(data['WindDir9am'].mode()[0])\ndata['WindDir3pm'] = data['WindDir3pm'].fillna(data['WindDir3pm'].mode()[0])\ndata['WindDir3pm'].isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Encoding**","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\nlabel_encoder = preprocessing.LabelEncoder()\ndata['Location'] = label_encoder.fit_transform(data['Location'])\ndata['WindGustDir'] = label_encoder.fit_transform(data['WindGustDir'])\ndata['WindDir9am'] = label_encoder.fit_transform(data['WindDir9am'])\ndata['WindDir3pm'] = label_encoder.fit_transform(data['WindDir3pm'])\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Balance the Data using SMOTE**","metadata":{}},{"cell_type":"code","source":"y = data.iloc[:,-1]\ny.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.iloc[:,:-1]\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\noversample = SMOTE()\ndata, y = oversample.fit_resample(data, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\nc = Counter(y)\nc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Correlation","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ncorr = data.corr()\nplt.figure(figsize=(20, 20))\nsns.heatmap(corr, annot=True,fmt = '.1f');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**If we look at the above heatmap it is evident that:**\n\n* Temp9am Temp3pm are highly correlated with MinTemp and MaxTemp\n* Humidity9am and humidity3pm are highly correlated\n","metadata":{}},{"cell_type":"code","source":"cols = ['Temp9am','Temp3pm','Humidity9am']\ndata = data.drop(['Temp9am','Temp3pm','Humidity9am'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Training**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(penalty = 'elasticnet',solver='saga', random_state=0,l1_ratio=0.4)\nclf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = clf.predict(X_test)\ny_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5],\n        'learning_rate':[0.01, 0.03, 0.05],\n        'n_estimators': [100,300,600,700]\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#XGBoost\n \nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nimport xgboost as xgb\nxgb_model= xgb.XGBClassifier()\nxgb_model.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_search = RandomizedSearchCV(xgb_model, param_distributions=params, n_iter=5, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train,y_train), verbose=3, random_state=42 )\n\n# Uncomment the below line when you run the model\nrandom_search.fit(X_train,y_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_search.cv_results_\nrandom_search.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_random_pred = random_search.predict(X_test)\nxgb_random_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_pred = xgb_model.predict(X_test)\nxgb_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Accuracy & Error Metrics**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.metrics import accuracy_score, classification_report\nprecision, recall, fscore, support = score(y_test,y_pred,average='weighted')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_pred,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lg = {\n    'precision':precision,\n    'recall':recall,\n    'fscore':fscore,\n    'support':support\n}\nlg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_precision, xgb_recall, xgb_fscore, xgb_support = score(y_test,xgb_pred,average='weighted')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(xgb_pred,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_= {\n    'precision':xgb_precision,\n    'recall':xgb_recall,\n    'fscore':xgb_fscore,\n    'support':xgb_support\n}\nxgb_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rs_precision, rs_recall, rs_fscore, rs_support = score(y_test,xgb_random_pred,average='weighted')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(xgb_random_pred,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rs_= {\n    'precision':rs_precision,\n    'recall':rs_recall,\n    'fscore':rs_fscore,\n    'support':rs_support\n}\nrs_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}