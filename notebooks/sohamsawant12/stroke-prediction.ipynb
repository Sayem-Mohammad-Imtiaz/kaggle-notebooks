{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.bmi.replace(to_replace=np.nan, value=df.bmi.mean(), inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf['bmi_cat'] = pd.cut(df['bmi'], bins = [0, 19, 25,30,10000], labels = ['Underweight', 'Ideal', 'Overweight', 'Obesity'])\ndf['age_cat'] = pd.cut(df['age'], bins = [0,13,18, 45,60,200], labels = ['Children', 'Teens', 'Adults','Mid Adults','Elderly'])\ndf['glucose_cat'] = pd.cut(df['avg_glucose_level'], bins = [0,90,160,230,500], labels = ['Low', 'Normal', 'High', 'Very High'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns=['bmi','id'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.kdeplot(data = df[df['stroke'] == 0], x = 'age', shade = True,  alpha = 0.8, color = 'blue',Label='NOSTROKE')\nsns.kdeplot(data = df[df['stroke'] == 1], x = 'age', shade = True,  alpha = 0.8, color = 'red',Label='STROKE')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.kdeplot(data = df[df['stroke'] == 0], x = 'avg_glucose_level', shade = True,  alpha = 1, color = '#512b58',Label='NOSTROKE' )\nsns.kdeplot(data = df[df['stroke'] == 1], x = 'avg_glucose_level', shade = True,  alpha = 0.8, color = '#fe346e',Label='STROKE')\nplt.legend()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.kdeplot(data = df[df['stroke'] == 0], x = 'bmi', shade = True,  alpha = 1, color = '#512b58',Label='NOSTROKE' )\nsns.kdeplot(data = df[df['stroke'] == 1], x = 'bmi', shade = True,  alpha = 0.8, color = '#fe346e',Label='STROKE')\nplt.legend()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"healthy_gen = df[df['stroke'] == 0].gender.value_counts()\nstroke_gen = df[df['stroke'] == 1].gender.value_counts()\nplt.bar( healthy_gen.index , height = healthy_gen.values, width = 0.5, color = 'blue')\nplt.bar( np.arange(len(stroke_gen.index)), height = stroke_gen.values, width = 0.5, color= 'red')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"healthy_gen = df[df['stroke'] == 0].work_type.value_counts()\nstroke_gen = df[df['stroke'] == 1].work_type.value_counts()\nplt.bar( healthy_gen.index , height = healthy_gen.values, width = 0.5, color = 'blue')\nplt.bar( np.arange(len(stroke_gen.index)), height = stroke_gen.values, width = 0.5, color= 'red')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"healthy_gen = df[df['stroke'] == 0].Residence_type.value_counts()\nstroke_gen = df[df['stroke'] == 1].Residence_type.value_counts()\nplt.bar( healthy_gen.index , height = healthy_gen.values, width = 0.5, color = 'blue')\nplt.bar( np.arange(len(stroke_gen.index)), height = stroke_gen.values, width = 0.5, color= 'red')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"healthy_gen = df[df['stroke'] == 0].smoking_status.value_counts()\n\nstroke_gen = df[df['stroke'] == 1].smoking_status.value_counts()\nplt.bar( healthy_gen.index , height = healthy_gen.values, width = 0.5, color = 'blue')\nplt.bar( np.arange(len(stroke_gen.index)), height = stroke_gen.values, width = 0.5, color= 'red')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"healthy_gen = df[df['stroke'] == 0].hypertension.value_counts()\n\nstroke_gen = df[df['stroke'] == 1].hypertension.value_counts()\nplt.bar( ['YES','NO'] , height = healthy_gen.values, width = 0.5, color = 'blue')\nplt.bar( np.arange(len(stroke_gen.index)), height = stroke_gen.values, width = 0.5, color= 'red')\nplt.xlabel('HYPERTENSION')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"healthy_gen = df[df['stroke'] == 0].heart_disease.value_counts()\n\nstroke_gen = df[df['stroke'] == 1].heart_disease.value_counts()\nplt.bar( ['YES','NO'] , height = healthy_gen.values, width = 0.5, color = 'blue')\nplt.bar( np.arange(len(stroke_gen.index)), height = stroke_gen.values, width = 0.5, color= 'red')\nplt.xlabel('HEARTDISEASE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"healthy_gen = df[df['stroke'] == 0].ever_married.value_counts()\n\nstroke_gen = df[df['stroke'] == 1].ever_married.value_counts()\nplt.bar( ['YES','NO'] , height = healthy_gen.values, width = 0.5, color = 'blue')\nplt.bar( np.arange(len(stroke_gen.index)), height = stroke_gen.values, width = 0.5, color= 'red')\nplt.xlabel('MARRITIALRISK')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()\na=df.drop(columns=['id','bmi_cat','age_cat','glucose_cat'])\na.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = a.iloc[ :,0:-1].values\ny = a.iloc[:, -1].values\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers= [('encoder', OneHotEncoder(), [0,5,9])], remainder= 'passthrough')\nx = np.array(ct.fit_transform(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nx[:, 15] = le.fit_transform(x[:, 15])\nx[:, 16] = le.fit_transform(x[:, 16])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.shape\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state= 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler \nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\nsm = SMOTE(random_state=2)\nx_train_res, y_train_res = sm.fit_resample(x_train, y_train.ravel())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, classification_report, roc_curve, plot_roc_curve, auc, precision_recall_curve, plot_precision_recall_curve, average_precision_score\nfrom sklearn.model_selection import cross_val_score\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\nmodels.append(['Logistic Regreesion', LogisticRegression(random_state=0)])\n\nmodels.append(['KNeighbors', KNeighborsClassifier()])\n\n\nmodels.append(['Random Forest', RandomForestClassifier(random_state=0)])\n\nlst_1= []\n\nfor m in range(len(models)):\n    lst_2= []\n    model = models[m][1]\n    model.fit(x_train_res, y_train_res)\n    y_pred = model.predict(x_test)\n    cm = confusion_matrix(y_test, y_pred)  #Confusion Matrix\n    accuracies = cross_val_score(estimator = model, X = x_train_res, y = y_train_res, cv = 10)   #K-Fold Validation\n    roc = roc_auc_score(y_test, y_pred)  #ROC AUC Score\n    precision = precision_score(y_test, y_pred)  #Precision Score\n    recall = recall_score(y_test, y_pred)  #Recall Score\n    f1 = f1_score(y_test, y_pred)  #F1 Score\n    print(models[m][0],':')\n    print(cm)\n    print('Accuracy Score: ',accuracy_score(y_test, y_pred))\n    print('')\n    print(\"K-Fold Validation Mean Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n    print('')\n    print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n    print('')\n    print('ROC AUC Score: {:.2f}'.format(roc))\n    print('')\n    print('Precision: {:.2f}'.format(precision))\n    print('')\n    print('Recall: {:.2f}'.format(recall))\n    print('')\n    print('F1: {:.2f}'.format(f1))\n    print('-----------------------------------')\n    print('')\n    lst_2.append(models[m][0])\n    lst_2.append((accuracy_score(y_test, y_pred))*100) \n    lst_2.append(accuracies.mean()*100)\n    lst_2.append(accuracies.std()*100)\n    lst_2.append(roc)\n    lst_2.append(precision)\n    lst_2.append(recall)\n    lst_2.append(f1)\n    lst_1.append(lst_2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.model_selection import GridSearchCV\ngrid_models = [(LogisticRegression(),[{'C':[0.25,0.5,0.75,1],'random_state':[0]}]), \n               (KNeighborsClassifier(),[{'n_neighbors':[5,7,8,10], 'metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski']}]), \n                (RandomForestClassifier(),[{'n_estimators':[100,150,200],'criterion':['gini','entropy'],'random_state':[0]}])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,j in grid_models:\n    grid = GridSearchCV(estimator=i,param_grid = j, scoring = 'accuracy',cv = 10)\n    grid.fit(x_train_res, y_train_res)\n    best_accuracy = grid.best_score_\n    best_param = grid.best_params_\n    print('{}:\\nBest Accuracy : {:.2f}%'.format(i,best_accuracy*100))\n    print('Best Parameters : ',best_param)\n    print('')\n    print('----------------')\n    print('')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}