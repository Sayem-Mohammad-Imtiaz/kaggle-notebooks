{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-04T12:49:19.622241Z","iopub.execute_input":"2021-08-04T12:49:19.622766Z","iopub.status.idle":"2021-08-04T12:49:19.633758Z","shell.execute_reply.started":"2021-08-04T12:49:19.622719Z","shell.execute_reply":"2021-08-04T12:49:19.632713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt # for data visualization and using histogram\nimport seaborn as sns # for data visualization\n%matplotlib inline \nfrom sklearn import metrics # measure classification performance\nfrom sklearn.model_selection import train_test_split # estimate machine learning performance\nfrom sklearn.neighbors import KNeighborsClassifier # to implement learning by k nearest neighbors","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:49:19.635496Z","iopub.execute_input":"2021-08-04T12:49:19.636014Z","iopub.status.idle":"2021-08-04T12:49:19.64531Z","shell.execute_reply.started":"2021-08-04T12:49:19.635984Z","shell.execute_reply":"2021-08-04T12:49:19.644093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diab_data = pd.read_csv(\"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\")\ndiab_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:49:19.647329Z","iopub.execute_input":"2021-08-04T12:49:19.647663Z","iopub.status.idle":"2021-08-04T12:49:19.677802Z","shell.execute_reply.started":"2021-08-04T12:49:19.647633Z","shell.execute_reply":"2021-08-04T12:49:19.676649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diab_data.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:49:19.679823Z","iopub.execute_input":"2021-08-04T12:49:19.680248Z","iopub.status.idle":"2021-08-04T12:49:19.694959Z","shell.execute_reply.started":"2021-08-04T12:49:19.680203Z","shell.execute_reply":"2021-08-04T12:49:19.693675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diab_data.isnull().sum() # to check null values","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:49:19.696742Z","iopub.execute_input":"2021-08-04T12:49:19.697115Z","iopub.status.idle":"2021-08-04T12:49:19.706077Z","shell.execute_reply.started":"2021-08-04T12:49:19.697083Z","shell.execute_reply":"2021-08-04T12:49:19.704961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diab_corr = diab_data.corr() # to check correlation\nsns.heatmap(diab_corr, annot = True)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:49:19.707712Z","iopub.execute_input":"2021-08-04T12:49:19.70833Z","iopub.status.idle":"2021-08-04T12:49:20.49551Z","shell.execute_reply.started":"2021-08-04T12:49:19.708282Z","shell.execute_reply":"2021-08-04T12:49:20.494431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = diab_data.drop(['Outcome'], axis = 1) # Split the dataset into train and test set\ny = diab_data['Outcome']\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:49:20.496934Z","iopub.execute_input":"2021-08-04T12:49:20.497249Z","iopub.status.idle":"2021-08-04T12:49:20.507563Z","shell.execute_reply.started":"2021-08-04T12:49:20.497219Z","shell.execute_reply":"2021-08-04T12:49:20.506666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(diab_data, hue = 'Outcome') # to plot pair plot","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:49:20.509843Z","iopub.execute_input":"2021-08-04T12:49:20.510137Z","iopub.status.idle":"2021-08-04T12:49:42.728943Z","shell.execute_reply.started":"2021-08-04T12:49:20.510102Z","shell.execute_reply":"2021-08-04T12:49:42.727805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As the pair plot is non-linear, we use KNeighbors Classifier","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:49:42.730806Z","iopub.execute_input":"2021-08-04T12:49:42.731184Z","iopub.status.idle":"2021-08-04T12:49:42.735484Z","shell.execute_reply.started":"2021-08-04T12:49:42.731147Z","shell.execute_reply":"2021-08-04T12:49:42.734335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diab_model = KNeighborsClassifier(n_neighbors = 12).fit(x_train, y_train) # Apply Model\ny_pred = diab_model.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:49:42.736928Z","iopub.execute_input":"2021-08-04T12:49:42.737383Z","iopub.status.idle":"2021-08-04T12:49:42.771211Z","shell.execute_reply.started":"2021-08-04T12:49:42.737345Z","shell.execute_reply":"2021-08-04T12:49:42.770225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The accuracy of the model at k = 12 is', metrics.accuracy_score(y_test,y_pred), ' = ', metrics.accuracy_score(y_test,y_pred)*100, '%.')","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:49:42.772325Z","iopub.execute_input":"2021-08-04T12:49:42.772841Z","iopub.status.idle":"2021-08-04T12:49:42.780423Z","shell.execute_reply.started":"2021-08-04T12:49:42.772805Z","shell.execute_reply":"2021-08-04T12:49:42.779203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To check best K value\n\nerror_rate = []\nfor i in range(1, 50):\n    diab_knn = KNeighborsClassifier(n_neighbors = i)\n    diab_knn.fit(x_train, y_train)\n    pred_i = diab_knn.predict(x_test)\n    error_rate.append(np.mean(pred_i != y_test))\n\nplt.figure(figsize = (15, 9))\nplt.plot(range(1, 50), error_rate, color = 'green', linestyle = '-.', marker = 'o', markerfacecolor = 'red', markersize = 15)\nplt.title('Error Rate V/s K Value:')\nplt.xlabel('K') \nplt.ylabel('Error Rate')\nprint('Minimum error = ', min(error_rate), ' at K = ', error_rate.index(min(error_rate)))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:49:42.782071Z","iopub.execute_input":"2021-08-04T12:49:42.783385Z","iopub.status.idle":"2021-08-04T12:49:43.783379Z","shell.execute_reply.started":"2021-08-04T12:49:42.783339Z","shell.execute_reply":"2021-08-04T12:49:43.782255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The maximum accuracy = ', 1 - min(error_rate), ' = ', (1 - min(error_rate))*100, '%')","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:49:43.784689Z","iopub.execute_input":"2021-08-04T12:49:43.78499Z","iopub.status.idle":"2021-08-04T12:49:43.791558Z","shell.execute_reply.started":"2021-08-04T12:49:43.784953Z","shell.execute_reply":"2021-08-04T12:49:43.790406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion**","metadata":{}},{"cell_type":"markdown","source":"While predicting chance of diabetes, if we choose  K Nearest Neighbors method, the accuracy of the model is 74.026%.\nThe maximum accuracy obtained (taking upto K = 50) is 75.325% at K = 48.","metadata":{}}]}