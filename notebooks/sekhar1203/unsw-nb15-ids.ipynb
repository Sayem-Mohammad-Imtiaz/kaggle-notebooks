{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom numpy import array\nimport time\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as s\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/unsw-nb15/UNSW_NB15_training-set.csv')\ndf2 = pd.read_csv('/kaggle/input/unsw-nb15/UNSW_NB15_testing-set.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/unsw-nb15/UNSW_NB15_training-set.csv')\ndf.drop(columns='attack_cat', inplace = True )\nAttack= df[df['label'] == 1]\nNonAttack = df[df['label'] == 0]\nclasses = pd.value_counts(df['label'], sort = True)\noutput=df['label']\ndf=df.iloc[:,:-1]\n\nlabels = ['NonAttacks','Attack']\nclasses.plot(kind = 'pie', rot=0)\nplt.title(\"Transaction class distribution\")\nplt.xticks(range(2), labels)\nplt.xlabel(\"Class\")\nplt.ylabel(\"Frequency\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One Hot Encoding\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport numpy as np\nfrom numpy import array\n\nle_service = LabelEncoder()\nle_proto = LabelEncoder()\nle_state= LabelEncoder()\ndf['service_encoded'] = le_service.fit_transform(df.service)\ndf['proto_encoded'] = le_proto.fit_transform(df.proto)\ndf['state_encoded'] = le_state.fit_transform(df.state)\n\n\nservice_ = OneHotEncoder()\nproto_ = OneHotEncoder()\nstate_ = OneHotEncoder()\nX = service_.fit_transform(df.service_encoded.values.reshape(-1,1)).toarray()\nXm = proto_.fit_transform(df.proto_encoded.values.reshape(-1,1)).toarray()\nXmm = state_.fit_transform(df.state_encoded.values.reshape(-1,1)).toarray()\ndfOneHot = pd.DataFrame(X, columns = [\"service_\"+str(int(i)) for i in range(X.shape[1])])\ndf = pd.concat([df, dfOneHot], axis=1)\ndfOneHot = pd.DataFrame(Xm, columns = [\"proto_\"+str(int(i)) for i in range(Xm.shape[1])])\ndf = pd.concat([df, dfOneHot], axis=1)\ndfOneHot = pd.DataFrame(Xmm, columns = [\"state_\"+str(int(i)) for i in range(Xmm.shape[1])])\ndf = pd.concat([df, dfOneHot], axis=1)\n\ndf.drop(columns=['proto','service','state'], inplace = True )\ndf.shape\ndf2.drop(columns='attack_cat', inplace = True )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Selection\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nbestfeatuers=SelectKBest(score_func=chi2,k=100)\ninp=df.iloc[:,0:198]\nfit=bestfeatuers.fit(inp,output)\ndfscores=pd.DataFrame(fit.scores_)\ndfcol=pd.DataFrame(inp.columns)\nfeaturescore=pd.concat([dfcol,dfscores],axis=1)\nfeaturescore.columns=['feature','score']\nk=featurescore['feature']\nt=featurescore.nlargest(100,'score')\nli=list(t['feature'])\nprint(\"Top 100 features:\")\nprint(\"\\n\")\nfor x in li:\n    print(x,end=\" , \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=df[li]\ny_train=output\nx_test=df2[li]\ny_test = df2['label']\nval=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decision tree\nstart = time.time()\nfrom sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier(random_state=0)\nclf.fit(x_train, y_train)\npreds = clf.predict(x_test)\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n\nprint (\"Train Accuracy :: \", accuracy_score(y_train, clf.predict(x_train)))\nprint (\"Test Accuracy  :: \", accuracy_score(y_test, preds))\nval=[]\ndec_tree_f=accuracy_score(y_test, preds)\nval.append(dec_tree_f)\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, preds))\nend = time.time()\nprint(end - start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RandomForest\nfrom sklearn.ensemble import RandomForestClassifier\nstart = time.time()\n\nclf = RandomForestClassifier(n_estimators = 2,random_state=30)\nclf.fit(x_train, y_train)\npreds = clf.predict(x_test)\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n\nprint (\"Train Accuracy :: \", accuracy_score(y_train, clf.predict(x_train)))\nprint (\"Test Accuracy  :: \", accuracy_score(y_test, preds))\nrandom_for_f=accuracy_score(y_test, preds)\nval.append(random_for_f)\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, preds))\nend = time.time()\nprint(end - start)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#NaiveBayes\nfrom sklearn.naive_bayes import GaussianNB\n\n# create Gaussian Naive Bayes model object and train it with the data\nn = GaussianNB()\n\nn.fit(x_train, y_train)\npreds = n.predict(x_test)\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n\nprint (\"Train Accuracy :: \", accuracy_score(y_train, n.predict(x_train)))\nprint (\"Test Accuracy  :: \", accuracy_score(y_test, preds))\ngnb=accuracy_score(y_test, preds)\nval.append(gnb)\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, preds))\nend = time.time()\nprint(end - start)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Accuracy Graph\nalg=[\"Decision Tree\",\"Random Forest\",\"Gaussian NB \"] \nfor i in range(len(alg)):\n    print(\"The accuracy acheived using \",alg[i],\" is: \",(val[i])*100,\"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s.set(rc={'figure.figsize':(8,8)})\nplt.xlabel(\"algorithm\")\nplt.ylabel(\"accuracy\")\ns.barplot(alg,val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Project of other Candidate **"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler, Normalizer\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport time\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if 'csv' in filename:\n            print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Introduction\n* [The UNSW-NB15 dataset description](https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-NB15-Datasets/)\n* [Feature visualization and preprocessing](https://www.kaggle.com/khairulislam/unsw-nb15-eda)\n* [Feature importance using RandomForest classifier](https://www.kaggle.com/khairulislam/unsw-nb15-feature-importance)\n* [Performance with other classifiers](https://www.kaggle.com/khairulislam/unsw-nb15-anomaly-detection)"},{"metadata":{},"cell_type":"markdown","source":"# Utils"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def input_train_test():\n    root = '../input/unsw-nb15/'\n    train = pd.read_csv(root+'UNSW_NB15_training-set.csv')\n    test = pd.read_csv(root+'UNSW_NB15_testing-set.csv')\n    \n    if train.shape[0] == 82332:\n        print(\"Train and test sets are reversed here. Fixing them.\")\n        train, test = test, train\n    drop_columns = ['attack_cat', 'id']\n    for df in [train, test]:\n        for col in drop_columns:\n            if col in df.columns:\n                print('Dropping '+col)\n                df.drop([col], axis=1, inplace=True)\n    return train, test\n\ndef get_cat_columns(train):\n    categorical = []\n    for col in train.columns:\n        if train[col].dtype == 'object':\n            categorical.append(col)\n    return categorical\n    \ndef label_encode(train, test):\n    for col in get_cat_columns(train):\n        le = LabelEncoder()\n        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n        train[col] = le.transform(list(train[col].astype(str).values))\n        test[col] = le.transform(list(test[col].astype(str).values))\n    return train, test\n\ndef feature_process(df):\n    df.loc[~df['state'].isin(['FIN', 'INT', 'CON', 'REQ', 'RST']), 'state'] = 'others'\n    df.loc[~df['service'].isin(['-', 'dns', 'http', 'smtp', 'ftp-data', 'ftp', 'ssh', 'pop3']), 'service'] = 'others'\n    df.loc[df['proto'].isin(['igmp', 'icmp', 'rtp']), 'proto'] = 'igmp_icmp_rtp'\n    df.loc[~df['proto'].isin(['tcp', 'udp', 'arp', 'ospf', 'igmp_icmp_rtp']), 'proto'] = 'others'\n    return df\n\ndef get_train_test(train, test, feature_engineer=True, label_encoding=False, scaler=None):\n    x_train, y_train = train.drop(['label'], axis=1), train['label']\n    x_test, y_test = test.drop(['label'], axis=1), test['label']\n    \n    x_train, x_test = feature_process(x_train), feature_process(x_test)\n    if scaler is not None:\n        categorical_columns = get_cat_columns(x_train)\n        non_categorical_columns = [x for x in x_train.columns if x not in categorical_columns]\n        x_train[non_categorical_columns] = scaler.fit_transform(x_train[non_categorical_columns])\n        x_test[non_categorical_columns] = scaler.transform(x_test[non_categorical_columns])\n    \n    if label_encoding:\n        x_train, x_test = label_encode(x_train, x_test)\n        features = x_train.columns\n    else:\n        x_train = pd.get_dummies(x_train)\n        x_test = pd.get_dummies(x_test)\n        print(\"Column mismatch {0}, {1}\".format(set(x_train.columns)- set(x_test.columns),  set(x_test.columns)- set(x_train.columns)))\n        features = list(set(x_train.columns) & set(x_test.columns))\n    print(f\"Number of features {len(features)}\")\n    x_train = x_train[features]\n    x_test = x_test[features]\n\n    return x_train, y_train, x_test, y_test\n\ndef run_lgb(x, y, tr_idx, val_idx, param, num_round=100):\n    lgb_train = lgb.Dataset(x.iloc[tr_idx], y.iloc[tr_idx])\n    x_val, y_val = x.iloc[val_idx], y.iloc[val_idx]\n    validation = lgb.Dataset(x_val, y_val)\n    clf = lgb.train(param, lgb_train, num_round, valid_sets=[validation], early_stopping_rounds=50, verbose_eval=200, feval=lgb_f1_score)\n    return clf\n\ndef false_alarm_rate(y_true, y_pred):\n    CM = metrics.confusion_matrix(y_true, y_pred)\n    TN, FN, TP, FP = CM[0][0], CM[1][0], CM[1][1], CM[0][1]\n    return (FP+FN)/(TP+TN+FP+FN)\n\ndef results(y_test, y_prob):\n    threshold = 0.5\n    y_pred = np.where(y_prob >= threshold, 1, 0)\n    \n    acc = metrics.accuracy_score(y_test, y_pred)\n    pre = metrics.precision_score(y_test, y_pred)\n    rec = metrics.recall_score(y_test, y_pred) # it is also called detection rate or true positive rate\n    f1 = metrics.f1_score(y_test, y_pred)\n    print(f\"Acc {acc}, Precision {pre}, Recall {rec}, F1-score {f1}\")\n    \n    CM = metrics.confusion_matrix(y_test, y_pred)\n    TN, FN, TP, FP = CM[0][0], CM[1][0], CM[1][1], CM[0][1]\n    # false positive rate\n    FPR = FP/(FP+TN)\n    # false alarm rate \n    FAR = (FP+FN)/(TP+TN+FP+FN)\n    AUC = metrics.roc_auc_score(y_test, y_prob)\n    \n    print(\"FPR {0}, FAR {1}, AUC {2}\".format(FPR, FAR, AUC))\n    # print(metrics.classification_report(y_test, y_pred))\n    \ndef test_run(x_train, y_train, x_test, y_test, param, num_round=2000):\n    start = time.clock()\n    \n    lgb_train = lgb.Dataset(x_train, y_train)\n    lgb_validation = lgb.Dataset(x_test, y_test)\n    clf = lgb.train(param, lgb_train, num_round, valid_sets=[lgb_validation], early_stopping_rounds=50, verbose_eval=200, feval=lgb_f1_score)\n    # clf = lgb.train(param, lgb_train, 2000, valid_sets=[lgb_validation], early_stopping_rounds=50, verbose_eval=200)\n    y_prob = clf.predict(x_test, num_iteration=clf.best_iteration)\n    \n    print()\n    results(y_test, y_prob)\n    print(\"Time spent {0}\".format(time.clock() - start))\n    return y_prob\n    \ndef cross_validation(X, Y, param, kf, num_round=2000):\n    start = time.clock()\n    y_probs = []\n    y_vals = []\n\n    # for tr_idx, val_idx in tqdm(kf.split(X, Y), total=folds):\n    for tr_idx, val_idx in kf.split(X, Y):\n        clf = run_lgb(X, Y, tr_idx, val_idx, param, num_round)\n        x_val, y_val = X.iloc[val_idx], Y.iloc[val_idx]\n        y_prob = clf.predict(x_val, num_iteration=clf.best_iteration)\n        \n        y_probs.extend(y_prob)\n        y_vals.extend(y_val)\n\n    print()\n    results(y_vals, np.asarray(y_probs))\n    print(\"Time spent {0}\".format(time.clock() - start))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train, test = input_train_test()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train data"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nimport lightgbm as lgb\nfrom tqdm import tqdm_notebook as tqdm\n\ndef lgb_accuracy(preds, data):\n    y_true = data.get_label()\n    y_pred = np.round(preds)\n    return 'acc', metrics.accuracy_score(y_true, y_pred), True\n\ndef lgb_f1_score(preds, data):\n    y_true = data.get_label()\n    y_pred = np.round(preds) # scikits f1 doesn't like probabilities\n    return 'f1', metrics.f1_score(y_true, y_pred), True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = 10\nseed = 1\nnum_round = 2000\nkf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n\nstart = time.clock() \ndrop_columns = ['is_sm_ips_ports', 'dwin', 'is_ftp_login', 'trans_depth', 'dttl', 'ct_ftp_cmd']\nfor df in [train, test]:\n    df.drop(drop_columns, axis=1, inplace=True)\nx_train, y_train, x_test, y_test = get_train_test(train, test, feature_engineer=True, label_encoding=False, scaler=StandardScaler())\nprint(\"Time spent in total preprocessing {0} s\".format(time.clock() - start))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {\n    'objective': 'binary', \n    'learning_rate': 0.1, \n    \"boost_from_average\":True,\n    \"metric\": 'binary_logloss' # 'auc'\n}\nstart = time.clock()\n# test_run( x_train, y_train, x_train, y_train, param)\nclf = lgb.train(param, lgb.Dataset(x_train, y_train), 2000, valid_sets=[lgb.Dataset(x_train, y_train)], early_stopping_rounds=50, verbose_eval=200)\ny_prob = clf.predict(x_train, num_iteration=clf.best_iteration)\nprint()\nresults(y_train, y_prob)\nprint(\"Time spent {0}\".format(time.clock() - start))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_prob = clf.predict(x_test, num_iteration=clf.best_iteration)\nprint()\nresults(y_test, y_prob)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ten-fold cross validation"},{"metadata":{},"cell_type":"markdown","source":"After dropping irrelevant columns, feature engineering and applying oneHotEncoding. We found among different scaling StandardScaler is performing the best.\n\n|Preprocess| Param | Accuracy |F1-score |\n|:---:|:---:|:---:|:---:|:---:|:---:|\n|RobustScaler|learning rate 0.05|96.11| 97.16|\n||learning rate 0.1|95.19| 97.22|\n||learning rate 0.3|95.73| 96.88|\n|StandardScaler |learning rate 0.05|96.08| 97.14 |\n||learning rate 0.1| 96.20 | 97.23|\n||learning rate 0.3| 95.71 | 96.87|\n|MinMaxScaler |learning rate 0.05|96.08| 97.14\n| |learning rate 0.1|96.20|97.22 "},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"param = {\n    'objective': 'binary', \n    'learning_rate': 0.1, \n    \"boost_from_average\":True,\n    \"metric\": 'binary_logloss' # 'auc'\n}\ncross_validation(x_train, y_train, param, kf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Five-fold cross validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\ncross_validation(x_train, y_train, param, kf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {\n    'objective': 'binary', \n    'learning_rate': 0.1, \n    \"boost_from_average\":True,\n    \"metric\": 'binary_logloss' # 'auc'\n}\ny_prob = test_run(x_test, y_test, x_test, y_test, param)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Validate on test data\nHere the model trained on test data is being validated using test data."},{"metadata":{},"cell_type":"markdown","source":"|Param|Accuracy|F1-score|\n|:---:|:---:|:---:|:---:|\n|learning_rate 0.1 | 87.74 | 89.87\n|learning_rate 0.05 | 87.60 | 89.77\n|learning_rate 0.1, is_unbalance True | 91.87 | 92.9\n|learning_rate 0.05, is_unbalance True | 91.95 | 92.96"},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"param = {\n    'objective': 'binary',\n    'learning_rate': 0.05, \n    'boost_from_average':True,\n    'is_unbalance':True,\n    \"metric\": 'binary_logloss' # 'auc'\n}\ny_prob = test_run(x_train, y_train, x_test, y_test, param)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = np.where(y_prob >= 0.5, 1, 0)\nprint(metrics.confusion_matrix(y_test, y_pred))\n\ntarget_names = ['Normal', 'Anomaly']\ncm = metrics.confusion_matrix(y_test, y_pred)\n# Normalize\ncmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\nplt.rc('font', size=20) \nfig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=target_names, yticklabels=target_names)\n\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\n \nplt.show(block=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ten-fold cross validation"},{"metadata":{},"cell_type":"markdown","source":"|Param|Accuracy| F1-score|\n|:---:|:---:|:---:|\n|learning_rate 0.05| 98.07 | 98.24\n|learning_rate 0.1| 98.18 | 98.34\n|learning_rate 0.3| 98.08 | 98.25\n|learning_rate 0.1, feature_fraction 0.5 | 98.14 | 98.30\n|learning_rate 0.05, feature_fraction 0.5| 98.04 | 98.21\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {\n    'objective': 'binary',\n    'learning_rate': 0.1, \n    \"boost_from_average\":True,\n    # 'is_unbalance':True,\n    # \"feature_fraction\":0.5,\n    \"metric\": 'binary_logloss' # 'auc'\n}\nkf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\ncross_validation(x_test, y_test, param, kf, num_round=2000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Five-fold cross validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\ncross_validation(x_test, y_test, param, kf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Combined data\nHere we combined both train and test set. Then evaluated their ten-fold cross validation performance."},{"metadata":{"trusted":true},"cell_type":"code","source":"total = pd.concat([train, test], axis=0)\nX, Y = total.drop(['label'], axis=1), total['label']\ncategorical_columns = get_cat_columns(X)\nnon_categorical_columns = [col for col in X.columns if col not in categorical_columns]\nX = feature_process(X)\nX[non_categorical_columns] = StandardScaler().fit_transform(X[non_categorical_columns])\nX = pd.get_dummies(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"| Param | Accuracy | F1-score\n|:---:|:---:|:---:|\n|learning rate 0.05 | 95.11 | 96.15\n|learning rate 0.01 | 93.69 | 95.07\n|learning rate 0.1 | 95.09 | 96.07\n|learning rate 0.1, is_unbalance True | 95.16 | 96.19\n|learning rate 0.1, bagging_fraction 0.8 | 95.14 | 96.17\n|learning rate 0.1, feature_fraction 0.5 | 95.20 | 96.22\n|learning rate 0.1, feature_fraction 0.5, bagging_fraction 0.8 | 95.05 | 96.11"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"param = {\n    'objective': 'binary',\n    'learning_rate': 0.1, \n    \"boost_from_average\":True,\n    # 'is_unbalance':True,\n    # \"bagging_fraction\":0.8,\n    \"feature_fraction\":0.5,\n    # \"bagging_freq\":1,\n    \"metric\": 'binary_logloss' # 'auc'\n}\ncross_validation(X, Y, param, kf, num_round=2000)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}