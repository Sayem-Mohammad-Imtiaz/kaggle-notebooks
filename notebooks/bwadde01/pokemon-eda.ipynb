{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"pokemon_stats = pd.read_csv('/kaggle/input/pokemon/Pokemon.csv')\npokemon_images = pd.read_csv('/kaggle/input/pokemon-images-and-types/pokemon.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pokemon_stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From examination, it appears that there are some pokemon in the stats dataset that are not in the images dataset (e.g. VenusaurMega)\npokemon_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pokemon_stats['lower_names'] = pokemon_stats['Name'].apply(lambda x: x.lower())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge the images and the stats together so we can extract images where possible\npokemon_full = pokemon_stats.merge(pokemon_images,how='left',left_on='lower_names',right_on='Name')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pokemon_full","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# here are all of the pokemon missing from the images set based on our join - looks like there are some that would have matches if we reformat the names to match\npokemon_full[pokemon_full['Name_y'].isna()]['Name_x'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# in the meantime, let's filter out the megas to see how many remain -- here are all the unavailable pokemon\npokemon_missing = pd.DataFrame(pokemon_full[pokemon_full['Name_y'].isna() & ['mega' not in name for name in pokemon_full['lower_names'].tolist()]])\npokemon_full[pokemon_full['Name_y'].isna() & ['mega' not in name for name in pokemon_full['lower_names'].tolist()]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's re-format these pokemon based on the observed naming convention being used in the files\n# pokemon with more than one form make up the vast majority of this population; we can use regular expresisons to highlight these and update them to the \n# naming convention being used in the images dataset\npokemon_missing['reformatted_name'] = [\"\".join(re.split('([A-Z])',eg)[1:3]).lower()+'-'+\"\".join(re.split('([A-Z])',eg)[3:5]).lower()[:-1] if len(re.findall('[A-Z]',eg))>2 else eg for eg in pokemon_full[pokemon_full['Name_y'].isna() & ['mega' not in name for name in pokemon_full['lower_names'].tolist()]]['Name_x'].tolist()]\npokemon_missing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# here are the matches we were able to get from reformatting... looks like some of the alternate forms are not present in the images dataset, so we will leave those\n# for now, but a few other ones which did not get picked up we will have to look at more closely\npokemon_missing.merge(pokemon_images,how='left',left_on='reformatted_name',right_on='Name')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Below are the pokemon which require manual updating to be joined with the images dataset\n# Nidoran♀ -> 'nidoran-m'\n# Nidoran♂ -> 'nidoran-f'\n# Farfetch'd -> 'farfetchd'\n# Mr. Mime -> 'mr-mime'\n# Mime Jr. -> 'mime-jr'\n# Basculin? -> 'basculin-red-striped'\n# Flabébé -> 'flabebe'\n# MeowsticMale -> 'meowstick-male'\n# Zygarde50% Forme -> 'zygarde-50'\n# HoopaHoopa Confined -> 'hoopa-confined'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for some of the names, we go in and manually update them in the missing df to have them align with the images df\npokemon_missing['manual_name']=pokemon_missing['Name_x'].map({'Nidoran♀':'nidoran-m','Nidoran♂':'nidoran-f','Farfetch\\'d':'farfetchd','Mr. Mime':'mr-mime','Mime Jr.':'mime-jr','Basculin':'basculin-red-striped','Flabébé':'flabebe','MeowsticMale':'meowstick-male','Zygarde50% Forme':'zygarde-50','HoopaHoopa Confined':'hoopa-confined'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# as you can see, the manual name has been added\npokemon_missing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# here, we add the manual name and reformatted name together to optimize the matching between this set and the pokemon images dataset (through matching with the full view on name)\npokemon_missing['final_name'] = [y if y is not np.nan else x  for x,y in zip(pokemon_missing['reformatted_name'].tolist(),pokemon_missing['manual_name'].tolist())]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pokemon_missing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pokemon_full = pokemon_full.merge(pokemon_missing,how='left',left_on='Name_x',right_on ='Name_x')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# same process as for the missing pokemon; \npokemon_full['master_name'] = [y if y is not np.nan else x  for x,y in zip(pokemon_full['lower_names_x'].tolist(),pokemon_full['final_name'].tolist())]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add the pokemon image path to the full df\npokemon_full['image'] = pokemon_full['master_name'].apply(lambda x: f\"/kaggle/input/pokemon-images-and-types/images/images/{x}.png\" if x in pokemon_images['Name'].tolist() else \"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rename the columns back to the original values to clean things up\npokemon_full = pokemon_full[['#_x','Name_x','Type1_x','Type2_x','Total_x','HP_x','Attack_x','Defense_x','Sp. Atk_x','Sp. Def_x','Speed_x','Generation_x','Legendary_x','master_name','image']]\npokemon_full.columns = ['#','Name','Type 1','Type 2','Total','HP','Attack','Defense','Sp. Atk','Sp. Def','Speed','Generation','Legendary']+['master_name','image']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filter out the pokemon which were not found in the images dataset\npokemon_full = pd.DataFrame(pokemon_full[pokemon_full['image']!=''])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pokemon_full","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image \npil_img = Image(filename=pokemon_full['image'].iloc[383])\ndisplay(pil_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's try to visualize the data, first by reducing its dimension to 2D\nfrom sklearn.decomposition import PCA\n\ndim_reducer = PCA()\n\ndim_reducer.fit(pokemon_full[['HP','Attack','Defense','Sp. Atk','Sp. Def','Speed']].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the first two principal components have an explained variance ratio of 43.6% and 18.9% respectively\ndim_reducer.explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now let's take the principal components and see what information they hold\n\nresult = dim_reducer.transform(pokemon_full[['HP','Attack','Defense','Sp. Atk','Sp. Def','Speed']].values)\npokemon_full['pca-one'] = result[:,0]\npokemon_full['pca-two'] = result[:,1]\npokemon_full['pca-three'] = result[:,2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now let's visualize the pokemon based on their first two principal components\nfrom PIL import Image\nplt.figure(figsize=(32,20))\nplt.xlim([-110,125])\nplt.ylim([-110,150])\n\nsns.scatterplot(\n    x='pca-one', y='pca-two',\n    data=pokemon_full,\n    palette='bright',\n    legend=\"full\",\n    alpha=0.3,\n    zorder=0\n)\n\nfor index,row in pokemon_full.iterrows():\n    plt.imshow(Image.open(row.image).resize((50,50)),zorder=5,extent=(row['pca-one']-10,row['pca-one']+10,row['pca-two']-10,row['pca-two']+10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lookin also at the other groupings, we can see that those pokemon classified as legendary score much higher in the first principal component but possess\n# similar variation in the second\n\nplt.figure(figsize=(16,10))\nsns.scatterplot(\n    x='pca-one', y='pca-two',\n    hue='Legendary',\n    data=pokemon_full,\n    palette='bright',\n    legend=\"full\",\n    alpha=0.3,\n    zorder=0\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# as one might expect, there is significant diversity in the quality of pokemon across typings\n\nplt.figure(figsize=(16,10))\nsns.scatterplot(\n    x='pca-one', y='pca-two',\n    hue='Type 1',\n    data=pokemon_full,\n    palette='bright',\n    legend=\"full\",\n    alpha=0.3\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# as one might expect, there is significant diversity in the quality of pokemon across the generations in which they were released\nplt.figure(figsize=(16,10))\nsns.scatterplot(\n    x='pca-one', y='pca-two',\n    hue='Generation',\n    data=pokemon_full,\n    palette='bright',\n    legend=\"full\",\n    alpha=0.3\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# commonly, people have general archetypes that they use to classify pokemon, but this is not so formal.\n# In this section, we try clustering to be able to identify typical groupings people use (bulky, glass cannon, pseudo-legendary, etc.)\nfrom sklearn.cluster import KMeans\n\nclustering = KMeans(n_clusters=6).fit(pokemon_full[['HP','Attack','Defense','Sp. Atk','Sp. Def','Speed']].values) # tuned for number of clusters; 6 appeared best","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#update the pokemon full view witht the clustering labels\npokemon_full['Cluster'] = clustering.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using the hue from the new Cluster column, let's see the groupings it produced\n\nplt.figure(figsize=(16,10))\nsns.scatterplot(\n    x='pca-one', y='pca-two',\n    hue='Cluster',\n    data=pokemon_full,\n    palette='bright',\n    legend=\"full\"\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It appears that the clustering has carried over relatively smoothly from 6 dimensions to 2 dimensions -- particularly, the red, orange, and blue pokemon are relatively well-separated from the other classes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# grabbed list of all final evolutions from this site: https://bulbapedia.bulbagarden.net/wiki/List_of_fully_evolved_Pok%C3%A9mon_by_base_stats\n# to be used to reduce noise in the visual and evaluate pokemon for their competitive usability (assuming people would not use earlier stages of a pokemon)\nfully_evolved = pd.read_csv(r\"/kaggle/input/pokemon-fully-evolved/fully_evolved.csv\")\n# remove duplicates in serial number from the fully evolved file\nfully_evolved.drop_duplicates(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now let's overlay the images of the pokemon to dive deeper into the clusters\nfrom matplotlib.patches import Ellipse\n\n\nplt.figure(figsize=(15,30))\nsns.scatterplot(\n    x='pca-one', y='pca-two',\n    hue='Cluster',\n    data=pokemon_full,\n    palette='bright',\n    legend=\"full\"\n)\n\nplt.xlim([-110,125])\nplt.ylim([-110,150])\n\nfor index,row in pokemon_full[[pokemon in fully_evolved['#'].tolist() for pokemon in pokemon_full['#'].tolist()]].iterrows():\n    plt.imshow(Image.open(row.image).resize((50,50)),zorder=5,extent=(row['pca-one']-10,row['pca-one']+10,row['pca-two']-10,row['pca-two']+10))\n\ncentroids = clustering.cluster_centers_\nfor enum,color in zip(enumerate(centroids),['blue','orange','green','red','purple','brown']):\n    ind = enum[0]\n    i = enum[1]\n    data_for_class = pokemon_full[pokemon_full['Cluster']==ind][['pca-one','pca-two']]\n    \n    # compute average in 2d space and diameter of class\n    max_horiz_dist=np.max(data_for_class['pca-one'].values)-np.min(data_for_class['pca-one'].values)\n    max_vert_dist=np.max(data_for_class['pca-two'].values)-np.min(data_for_class['pca-two'].values)\n    avg_2d = [data_for_class['pca-one'].mean(),data_for_class['pca-two'].mean()]\n    \n    plt.gca().add_artist(Ellipse(avg_2d,max_horiz_dist,max_vert_dist, fill=False,zorder=10,color=color,linewidth=3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusions:\nFrom visual inspection, it appears that the clusters roughly correspond to the following:\n1. Cluster 0 (blue): the \"Glass cannons\" being those pokemon with high attack but low defense\n2. Cluster 1 (orange): the pre-evolutions and \"gimmicky\" pokemon that are overall weak \n3. Cluster 2 (green): mostly average pokemon, with significant overlap with Cluster 4 and 5\n4. Cluster 3 (red): the \"ubers\" -- legendaries with high overall stats, regular pokemon with relatively high stats (would likely see these in competitions)\n5. Cluster 4 (purple): the \"decent\" pokemon--these are average with respect to both principal components and have pretty average stats\n6. Cluster 5 (brown): the \"bulky\" pokemon--these have high defense but tend to have average attack; these can take a few hits","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}