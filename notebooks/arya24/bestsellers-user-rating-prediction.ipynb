{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Importing required libraries\n\nfrom sklearn.model_selection import train_test_split                \nfrom sklearn.tree import DecisionTreeClassifier                     \nfrom sklearn.metrics import accuracy_score                          \nfrom sklearn.metrics import classification_report                   \nfrom sklearn import tree    \nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.neighbors import KNeighborsClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport math\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom wordcloud import WordCloud , ImageColorGenerator\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The points discussed :\n1. Total number of unique books\n2. Total number of unique authors\n3. Percentage of Fictional and non-fictional books\n4. Variations in books with respect to year\n5. Distribution of books :\n    1. wrt Price\n    2. wrt Reviews\n    3. wrt User Rating\n6. First 10 Books with the Most Reviews\n7. First 10 Books with the Highest user ratings\n8. First 10 Authors with the Highest reviews\n9. First 10 Authors with the Highest user ratings\n10. Linear Regression Model\n11. Calculation of errors (MAE,R2 score)\n12. Decision Tree Classifier for Genre Prediction\n13. Decision Tree Classifier for User Rating Prediction"},{"metadata":{},"cell_type":"markdown","source":"# **1. Import Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import data\ndf = pd.read_csv('../input/amazon-top-50-bestselling-books-2009-2019/bestsellers with categories.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#exploring data\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Books = df.Name.nunique()  #number of unique book names\nBooks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Authors = df.Author.nunique()  #number of unique authors\nAuthors ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **2. Data Interpretation**\n*Checking Statistics, Null values if any, Total no of rows and columns*"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check null values if any\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#statistics\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#no of rows and columns\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **3. Data Cleaning : Label Encoding**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#label encoding of 4 columns\nfrom sklearn.preprocessing import LabelEncoder\n\ndf1 = df.copy(deep = True)\nGenre = LabelEncoder()\ndf1['Genre'] = Genre.fit_transform(df['Genre'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ndf2 = df1.copy(deep = True)\nAuthor = LabelEncoder()\ndf2['Author'] = Author.fit_transform(df1['Author'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ndf3 = df2.copy(deep = True)\nName = LabelEncoder()\ndf3['Name'] = Name.fit_transform(df2['Name'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ndf4 = df3.copy(deep = True)\nName = LabelEncoder()\ndf4['User Rating'] = Name.fit_transform(df3['User Rating'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **4. Data Visualization**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check correlation and plot heatmap \ncorr1 = df4.corr()\nplt.figure(figsize = (12,8))\nsns.heatmap(corr1,annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Genre wise classification\npie_df = df.Genre.value_counts().reset_index()\npie_df.columns = ['Genre', 'count']\nfig = px.pie(pie_df, values='count', names='Genre', title='Genre',\n             color_discrete_sequence=['blue', 'light green'])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#variations wrt year \nsns.countplot('Year', data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import seaborn as sns\n#sns.set_theme(style=\"darkgrid\")\n#p = sns.load_dataset(\"df\")\n#ax = sns.countplot(x=\"Price\", data=p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#how much it costs?\nsns.distplot(df[\"Price\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#What are people's reviews\nsns.distplot(df[\"Reviews\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#How people rate the book\nsns.distplot(df[\"User Rating\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new1 = df.drop_duplicates(subset=['Name'])\n\nhighest_reviews = df_new1[['Name','Reviews']].groupby('Name').sum().sort_values('Reviews', ascending=False)\n\nhighest_reviews.iloc[:10].plot(kind='barh', color=['skyblue', 'blue'])\nplt.gcf().set_size_inches(8, 5)\nplt.title('10 Books with the Most Reviews')\nplt.gca().invert_yaxis()\nplt.xlabel('Number of Reviews')\n_ = plt.ylabel('Book')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new1 = df.drop_duplicates(subset=['Name'])\n\n#books with the highest number of reviews\nhighest_rating = df_new1[['Name','User Rating']].groupby('Name').sum().sort_values('User Rating', ascending=False)\n\nhighest_rating.iloc[:10].plot(kind='barh',color=['skyblue', 'blue'])\nplt.gcf().set_size_inches(8,5)\nplt.title('First 10 Books with the Highest ratings')\nplt.gca().invert_yaxis()\nplt.xlabel('Ratings')\n_ = plt.ylabel('Book')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new2 = df.drop_duplicates(subset=['Author'])\n\n#authors with the highest number of reviews\nhighest_rating_auth = df_new2[['Author','Reviews']].groupby('Author').sum().sort_values('Reviews', ascending=False)\n\nhighest_rating_auth.iloc[:10].plot(kind='barh',color=['lightgreen', 'blue'])\nplt.gcf().set_size_inches(8,5)\nplt.title('First 10 Authors with the Highest reviews')\nplt.gca().invert_yaxis()\nplt.xlabel('Reviews')\n_ = plt.ylabel('Author Name')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_new = df.drop_duplicates(subset=['Author'])\n\n#authors with the highest number of reviews\nhighest_rating_auth = df_new[['Author','User Rating']].groupby('Author').sum().sort_values('User Rating', ascending=False)\n\nhighest_rating_auth.iloc[:10].plot(kind='barh',color=['lightgreen', 'blue'])\nplt.gcf().set_size_inches(8,5)\nplt.title('First 10 Authors with the Highest rating books')\nplt.gca().invert_yaxis()\nplt.xlabel('User Rating')\n_ = plt.ylabel('Author Name')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **5. Data Modelling **"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dependent variables\nX = np.array(df4[['Name', 'Author', 'Reviews', 'Price', 'Year', 'Genre']]) \n\n#Independent variables\ny = np.array(df4[\"User Rating\"])  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 100)                                    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Regression Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Linear Regression\nfrom sklearn import linear_model\nreg = linear_model.LinearRegression()\n\nreg.fit(X_train, y_train)\ny_1 = reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MAE: \" + str(mean_absolute_error(y_test, y_1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"R2_score: \" + str(r2_score(y_test, y_1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision Tree : To predict Genre**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X1 = np.array(df4[['Name', 'Author','Reviews', 'Price', 'Year', 'User Rating']])\ny1 = np.array(df4[['Genre']])\nfrom sklearn import tree\n\ntree1 = tree.DecisionTreeClassifier(max_depth=4)\ntree1 = tree1.fit(X1, y1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.30, random_state = 1)                                    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree1.score(X1, y1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y1_predicted = tree1.predict(X1_test)\ny1_predicted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision Tree : To predict User Rating**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X2 = np.array(df4[['Name', 'Author','Reviews', 'Price', 'Year', 'Genre']])\ny2 = np.array(df4[['User Rating']])\nfrom sklearn import tree\n\ntree2 = tree.DecisionTreeClassifier(max_depth=4)\ntree2 = tree2.fit(X2, y2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.30, random_state = 100)                                    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree2.score(X2, y2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y2_predicted = tree2.predict(X2_test)\ny2_predicted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# **Conclusion**\n\n1. Total unique Books : 351.\n2. Total unique Authors : 248.\n3. Average User Rating : 4.6.\n4. Average Price : 13.10.\n5. Min rating : 3.3 | Max rating : 4.9.\n6. Maximum books were in 2019 whereas minimum were in 2009.\n7. 56.4 % books are Non Fictional while 43.6 are fictional.\n8. Decision tree classifier works enough good for Genre prediction whereas it is not that accurate for User rating prediction.\n9. Linear Regression model works good in User Rating prediction."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}