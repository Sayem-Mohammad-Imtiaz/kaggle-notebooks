{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# # A rapid analysis of salaries in San Fransisco \n# #### This data contains the names, job title, and compensation for San Francisco city employees on an annual basis from 2011 to 2014.\n# \n# ## Questions to be answered are:\n# ###1. In what professions are the internal pay gaps the largest and how did it change over time?\n# ###2. \n#SF salaries analysis\n\n#Jonatan H. Bergqvist\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport nltk as nl\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import HashingVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n\n# Any results you write to the current directory are saved as output.\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# ### Let's explore the features!\n\nsalaries = pd.read_csv('../input/Salaries.csv')\nsalaries.info()"},{"cell_type":"markdown","metadata":{},"source":"###Now let's do some basic pre-processing"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"salaries = salaries.drop(['Notes', 'Agency', 'Status', 'Id'], axis=1);\n#Remove unimportant columns (empty or all rows containing the same information or uninteresting)\nsalaries = salaries[salaries['JobTitle']!='Not provided']\nsalaries.JobTitle = salaries.JobTitle.str.lower()\nsalaries = salaries[salaries['TotalPay']>0.00]\n#Clean up JobTitles and TotalPay columns\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Let's look at the different professions and try to classify them into departments\n#Split into different years not to get duplicate persons\nsal2011 = salaries[salaries['Year']==2011]\nsal2012 = salaries[salaries['Year']==2012]\nsal2013 = salaries[salaries['Year']==2013]\nsal2014 = salaries[salaries['Year']==2014]\n\njobTitlesByYear = pd.DataFrame({'2011': sal2011.JobTitle.value_counts(),\n                            '2012': sal2012.JobTitle.value_counts(),\n                            '2013': sal2013.JobTitle.value_counts(),\n                            '2014': sal2014.JobTitle.value_counts(),})\njobTitlesByYear.describe()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"jobTitlesByYear.sort_values(\"2011\",axis=0, ascending=False)[:30].plot(kind='bar')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"\njobnames=salaries['JobTitle']\nfrom nltk.tokenize import RegexpTokenizer\ntokenizer = RegexpTokenizer(r'\\w+')\nwordsinjobs=\"\"\nfor word in jobnames:\n    wordsinjobs=wordsinjobs+word\ntokens=tokenizer.tokenize(wordsinjobs)\nvectorizer=CountVectorizer(tokens)\ndtm=vectorizer.fit_transform(salaries['JobTitle'])\n\njobwords = salaries.JobTitle.str.split(r'[ -]',expand=True)\n#jobwords"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"jobnamesByYear=pd.DataFrame([sal2011['JobTitle'], sal2012['JobTitle'], sal2013['JobTitle'], sal2014['JobTitle']], index=[2011, 2012,2013,2014])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"jobnamesByYear = jobnamesByYear.T"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"jobnamesByYear"},{"cell_type":"markdown","metadata":{},"source":"###It looks like there are many titles that are common, \"transit operator\" being the most common one. \n\n### Now we want to classify each job title according into a department, but without having to do it manually. \n### Let's use some unsupervised classification!"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"#Feature extraction\nCvect=CountVectorizer(max_df=0.95, min_df=2, max_features=30,\n                                stop_words='english');\nX = Cvect.fit_transform(salaries.JobTitle)\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"def professional_features(listOfWords):\n    if ('department' in listOfWords):\n        return listOfWords[listOfWords.index('department')-1]\n    elif \n        \n    "},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"    \njobwords \n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"    \njobwords"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"'iii' in jobwords"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}