{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nplt.style.use(\"seaborn-whitegrid\")       \nimport pandas_profiling as pp \n\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/diabetes/diabetes.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization"},{"metadata":{},"cell_type":"markdown","source":"* You can use PandasProfile in order to analysis data.\n"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"import pandas_profiling as pp \nprofile_df = pp.ProfileReport(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profile_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* You can use visualization tools(such as seaborn, matmatplotlib) in order to analysis data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.hist(figsize=(10, 10), bins=50, xlabelsize=5, ylabelsize=5);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"Outcome\",data=df, kind=\"count\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.plot(kind=\"density\", layout=(6,5),subplots=True,sharex=False, sharey=False, figsize=(15,15));\nplt.tight_layout() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df, kind = \"reg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_corr = df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df_corr, linewidths = 1);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df_corr, kind = \"reg\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As can be seen in heatmap and pairplot, there is no specific correlation between both data and result."},{"metadata":{},"cell_type":"markdown","source":"# Model Selection"},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop([\"Outcome\"], axis = 1)\ny = df[\"Outcome\"]\n\n#or \n#X = df[:,0:8]\n#y = df[:, 8]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size = 0.30, \n                                                    random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlog = LogisticRegression(solver = \"liblinear\")\nlog_model = log.fit(X_train,y_train)\nlog_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = log_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nconfusion_matrix(y_test, y_pred)\nprint(classification_report(y_test, y_pred))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_test, log_model.predict(X_test))\ncross_val_score(log_model, X_test, y_test, cv = 10).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logit_roc_auc = roc_auc_score(y_test, log_model.predict(X_test))\n\nfpr, tpr, thresholds = roc_curve(y_test, log_model.predict_proba(X_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive ')\nplt.ylabel('True Positive ')\nplt.title('ROC')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\n\nnb = GaussianNB()\nnb_model = nb.fit(X_train, y_train)\nnb_model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = nb_model.predict(X_test)\naccuracy_score(y_test, y_pred)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_val_score(nb_model, X_test, y_test, cv = 10).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn_model = knn.fit(X_train, y_train)\nknn_model\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = knn_model.predict(X_test)\naccuracy_score(y_test, y_pred)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_params = {\"n_neighbors\": np.arange(1,20)}\nknn = KNeighborsClassifier()\nknn_cv = GridSearchCV(knn, knn_params, cv=10)\nknn_cv.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best KNN score:\" + str(knn_cv.best_score_))\nprint(\"Best KNN parameter: \" + str(knn_cv.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(1)\nknn_tuned = knn.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = knn_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {'Accuracy in KNN before GridSearchCV ': [0.77], 'Accuracy in KNN After GridSearchCV': [0.95]}\nknn_data = pd.DataFrame(data=d)\nknn_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM - Support Vector Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\n\nsvm_model = SVC(kernel = \"linear\").fit(X_train, y_train)\n\ny_pred = svm_model.predict(X_test)\naccuracy_score(y_test, y_pred)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_params = {\"C\": np.arange(1,10)}\n\nsvc = SVC(kernel = \"linear\")\n\nsvc_cv_model = GridSearchCV(svc,svc_params, \n                            cv = 10, \n                            n_jobs = -1, \n                            verbose = 2 )\nsvc_cv_model.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best Params: \" + str(svc_cv_model.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_tuned = SVC(kernel = \"linear\", C = 2).fit(X_train, y_train)\n\ny_pred = svc_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, y_pred)\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {'Accuracy in SVM before GridSearchCV ': [0.7983], 'Accuracy in SVM After GridSearchCV': [0.7933]}\nsvm_data = pd.DataFrame(data=d)\nsvm_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forests"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf_model = RandomForestClassifier().fit(X_train, y_train)\ny_pred = rf_model.predict(X_test)\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_params = {\"max_depth\": [2,5,8],\n            \"max_features\": [2,5,8],\n            \"n_estimators\": [10,500,1000],\n            \"min_samples_split\": [2,5,10]}\n\nrf_model = RandomForestClassifier()\n\nrf_cv_model = GridSearchCV(rf_model, \n                           rf_params, \n                           cv = 10, \n                           n_jobs = -1, \n                           verbose = 2) \n\nrf_cv_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best Params: \" + str(rf_cv_model.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_tuned = RandomForestClassifier(max_depth = 8, \n                                  max_features = 8, \n                                  min_samples_split = 2,\n                                  n_estimators = 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_tuned.fit(X_train, y_train)\ny_pred = rf_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, y_pred)\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Importance = pd.DataFrame({\"Importance\": rf_tuned.feature_importances_*100},\n                         index = X_train.columns)\n\nImportance.sort_values(by = \"Importance\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"r\");\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {'Accuracy in RF before GridSearchCV ': [0.97], 'Accuracy in RF After GridSearchCV': [0.92]}\nrf_data = pd.DataFrame(data=d)\nrf_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbm_model = GradientBoostingClassifier().fit(X_train, y_train)\n\ny_pred = gbm_model.predict(X_test)\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm_params = {\"learning_rate\" : [0.001, 0.01, 0.1, 0.05],\n             \"n_estimators\": [100,500,100],\n             \"max_depth\": [3,5,10],\n             \"min_samples_split\": [2,5,10]}\n\ngbm = GradientBoostingClassifier()\n\ngbm_cv = GridSearchCV(gbm, gbm_params, cv = 10, n_jobs = -1, verbose = 2)\ngbm_cv.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best Params: \" + str(gbm_cv.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm = GradientBoostingClassifier(learning_rate = 0.1, \n                                 max_depth = 10,\n                                min_samples_split = 2,\n                                n_estimators = 100)\n\ngbm_tuned =  gbm.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = gbm_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, y_pred)\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Importance = pd.DataFrame({\"Importance\": gbm_tuned.feature_importances_*100},\n                         index = X_train.columns)\n\nImportance.sort_values(by = \"Importance\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"r\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = {'Accuracy in GBM before GridSearchCV ': [0.87], 'Accuracy in GBM After GridSearchCV': [0.95]}\ngbm_data = pd.DataFrame(data=d)\ngbm_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [\n    knn_tuned,\n    log_model,\n    svc_tuned,\n    nb_model,\n    rf_tuned,\n    gbm_tuned,\n    \n]\n\n\nfor model in models:\n    name = model.__class__.__name__\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    print(\"-\"*28)\n    print(name + \":\" )\n    print(\"Accuracy: {:.4%}\".format(accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = []\n\nresults = pd.DataFrame(columns= [\"Models\",\"Accuracy\"])\n\nfor model in models:\n    name = model.__class__.__name__\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)    \n    result = pd.DataFrame([[name, accuracy*100]], columns= [\"Models\",\"Accuracy\"])\n    results = results.append(result)\n    \n    \nsns.barplot(x= 'Accuracy', y = 'Models', data=results, color=\"r\")\nplt.xlabel('Accuracy %')\nplt.title('accuracy rate of models'); ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Suggestions\n\n* There is a high difference between the outcome data.( 0: 1316 , 1 : 684). This can affect model results. You use *from sklearn.utils import class_weight* in order to avoid unbalanced distribution.\n  \n* There are too many zeros in the database.Especially in values such as insulin, glucose, BMI.If your values are zero, you are probably dead.:) So, you find zeros in this values and drop its. After doing this, you can model it again.\n\n* You can apply a standardscaler to the data before modeling.\n\n* You can examine how all these changes affect the results."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"Outcome\",data=df, kind=\"count\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Outcome\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Insulin\"].value_counts() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"BMI\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}