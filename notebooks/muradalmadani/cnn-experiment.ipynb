{"cells":[{"metadata":{"_uuid":"dfa397fd-dd46-4a5d-8c18-78382f0ce1bb","_cell_guid":"fdf9c456-6b48-466c-af5d-e47293fa006a","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"299dba54-bc59-457d-89a8-bed834eb6170","_cell_guid":"7faf0f24-4cdd-4215-9670-ebc78e4d6842","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import validation_curve\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"574448f7-837a-42de-91a0-d2e83f5f386a","_cell_guid":"b7331a14-3236-474b-927b-eebcea74b86a","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/mnist-in-csv/mnist_train.csv\") #reading the csv files using pandas\ntest_data = pd.read_csv(\"../input/mnist-in-csv/mnist_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56576815-3a4e-40b3-9ef9-1d196cd753e1","_cell_guid":"76ec390e-b6b3-4059-838e-1fbe51132863","trusted":true},"cell_type":"code","source":"## Separating the X and Y variable\ny = train_data['label'].values.astype('int32')\n## Dropping the variable 'label' from X variable\nX = train_data.drop(columns = 'label').values.astype('float32')\n## Printing the size of data\nprint(\"X:\", X.shape)\n     # X: (60000, 784)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e86e737-e5f4-491f-bb04-c92d0f1e5b2f","_cell_guid":"b36cd28c-0e75-4afc-a836-119d32f89d5f","trusted":true},"cell_type":"code","source":"## Normalization\nX = X/255.0\n# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n# canal = 1 => For gray scale\nX = X.reshape(-1,28,28,1)\nprint(\"X:\", X.shape)\n     # X: (60000, 784)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"84477e06-1a16-4f97-851f-c2b4e8c47847","_cell_guid":"7c55bd96-eb20-42aa-bb58-bfaba4e98415","trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\ny_cat = to_categorical(y)\n# train test split\nX_train, X_val, y_train, y_val = train_test_split(X, y_cat, test_size = 0.2, train_size = 0.8, random_state = 10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a7da04b-e8f8-4d99-b49c-a065ab1a89b0","_cell_guid":"a9812194-4a6a-4f14-b85d-06d4a8d62dcb","trusted":true},"cell_type":"code","source":"X_train.shape, X_val.shape, y_train.shape, y_val.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7905690-eab7-4162-b855-cae804efe190","_cell_guid":"5124b004-7c9c-45a3-95cc-aa3870a465e5","trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\nfeaturewise_center=False, # set input mean to 0 over the dataset\nsamplewise_center=False, # set each sample mean to 0\nfeaturewise_std_normalization=False, # divide inputs by std of the dataset\nsamplewise_std_normalization=False, # divide each input by its std\nzca_whitening = False, # apply ZCA whitening\nrotation_range = 10, # randomly rotate images in the range (degrees, 0 to 180)\nzoom_range = 0.1, # Randomly zoom image\nwidth_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\nheight_shift_range=0.1, # randomly shift images vertically (fraction of total height)\nhorizontal_flip = False, vertical_flip = False) # randomly flip images\n#datagen.fit(X_train)\nbatch_size = 64\ntrain_gen = datagen.flow(X_train, y_train, batch_size=batch_size)\nval_gen = datagen.flow(X_val, y_val, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a8b1e48-7140-4682-9636-1d3325bfb603","_cell_guid":"b4b9f740-074a-4ad4-953a-3302646d2208","trusted":true},"cell_type":"code","source":"from subprocess import check_output\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers.advanced_activations import LeakyReLU, PReLU","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"206982d0-8343-4d58-95a1-190ea285c4b9","_cell_guid":"71e7af19-0d87-4e68-b84f-51ad0e5e8e73","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Flatten\nmodel=Sequential()\n#model.add(Lambda(standardize,input_shape=(28,28,1)))\nmodel.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\", input_shape=(28,28,1)))\nmodel.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\nmodel.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(512,activation=\"relu\"))\nmodel.add(Dense(10,activation=\"softmax\"))\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d27c21d-d441-4c25-ad17-73e4cc1b7e80","_cell_guid":"50822856-6862-46b3-b1b0-c0691e99f312","trusted":true},"cell_type":"code","source":"epochs = 50\nhistory = model.fit_generator(train_gen,\nepochs = epochs,\nsteps_per_epoch = X_train.shape[0] // batch_size,\nvalidation_data = val_gen,\nvalidation_steps = X_val.shape[0] // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7fe942b3-94b2-40eb-8bd8-41b584b66ca5","_cell_guid":"380e1166-597a-490e-b382-f4317e1f091c","trusted":true},"cell_type":"code","source":"# Plot the loss and accuracy curves for training and validation\nfig, ax = plt.subplots(2,1, figsize=(18, 10))\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f94679f8-6570-4026-9068-ff64bf62bd5f","_cell_guid":"d8beb017-0d77-4638-a9a3-e609d4272205","trusted":true},"cell_type":"code","source":"y_test = test_data['label'].values.astype('int32')\n## Dropping the variable 'label' from X variable\nX_test = test_data.drop(columns = 'label').values.astype('float32')\nX_test=X_test/255\nX_test = X_test.reshape(-1,28,28,1)\nprint(\"X:\", X_test.shape)\n     # X: (60000, 784)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9a1f13f9-56ff-42cf-a3b7-4143af56fbbd","_cell_guid":"40d29a79-9462-467b-b6d0-b5d0b127bdba","trusted":true},"cell_type":"code","source":"y_test_pred = model.predict_classes(X_test)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"115f3c64-8626-4d0f-a033-f09b3ce6e310","_cell_guid":"8643c03e-3cb1-45ef-8f0a-46b909c15311","trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10, 10)) # Set Figure\nmat = confusion_matrix(y_test, y_test_pred) # Confusion matrix\n# Plot Confusion matrix\nsns.heatmap(mat.T, square=True, annot=True, cbar=False, cmap=plt.cm.Blues)\nplt.xlabel('Predicted Values')\nplt.ylabel('True Values');\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef88f252-8d34-4ab8-a4a7-20a5e017b7cc","_cell_guid":"b119ee37-61e0-4dcf-b031-8ee9b2846e78","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}