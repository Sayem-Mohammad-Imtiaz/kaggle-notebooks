{"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py","name":"python","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.1"}},"nbformat_minor":0,"nbformat":4,"cells":[{"metadata":{"collapsed":false,"_execution_state":"idle","_uuid":"d8c4dadc619cf1f18a498eae5cf6aba77904e4d2"},"source":"Simple Classifier using NLTK and NaiveBayes of NLTK ","execution_count":null,"cell_type":"markdown","outputs":[]},{"metadata":{"_cell_guid":"392af0a5-8448-4bcd-aec7-fcd0387a2d0d","_execution_state":"busy","_uuid":"fc7725b4c583e80cb0987856cf7e1d12f3cc1655","trusted":false},"source":" \n\nimport numpy as np \nimport pandas as pd \nfrom collections import Counter\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize\nimport matplotlib.pyplot as plt\nimport nltk\n\n\ndf = pd.read_csv('../input/spam.csv',encoding='ISO-8859-1')\ndf['v1'] = df['v1'].map(lambda x: 1 if x =='ham' else 0)\ndf['words'] = df['v2'].map(lambda x: word_tokenize(x))\nall_words = []\nfor i in df.words:\n    all_words.extend(i)\nstop_words = set(stopwords.words('english'))\n\nall_words = [word for word in all_words if word not in stop_words]\nall_words = nltk.FreqDist(all_words)\n\nall_words_len = len(all_words)\n\n# Considering the top 30 percent words as features\nword_features = list(all_words)[:int(all_words_len*0.30)] \n\nrecords = list(zip(df.v1, df.words))\n\ndef get_features(sms):\n    words = set(sms)\n    features = {}\n    for i in word_features:\n        features[i] = (i in words)\n    return features\n\n# Prepare data for training\nfeatures_set = [(get_features(sms),category) for category,sms in records]\n\nlen_of_features_set = len(features_set)\n\ntraining_data_size = int(len_of_features_set*0.75)\n\ntraining_set = features_set[:training_data_size]\ntesting_set = features_set[training_data_size: ]\n\nprint('training....')\nclassifier = nltk.NaiveBayesClassifier.train(training_set)\n\nprint('testing.....')\nprint(\"Accuracy: \",nltk.classify.accuracy(classifier, testing_set)*100)\n\n","execution_count":null,"cell_type":"code","outputs":[]}]}