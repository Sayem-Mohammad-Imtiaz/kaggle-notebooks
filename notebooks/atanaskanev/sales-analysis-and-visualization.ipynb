{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# E-commerce Business Sales Analysis and Visualization\n<img src=\"https://drive.google.com/uc?export=view&id=1YeekIMo5PH33ZEV1clEfmU-wDD0PhfZA\" width=\"750\"> ","metadata":{}},{"cell_type":"markdown","source":"<font size=\"5\"> Outline</font>\n\nThis notebook provides a sales analysis for an e-commerce business. The data contains 537,966 sales records and 9 columns, including a product description, quanitity of items sold, unit price, date of sale and country.\n\nThe analysis answers several business questions, among which:\n* What is the overall sales trend?\n* Which is the best selling product in each country?\n* How many new customers are there each month?\n* When do customers make the most purchases?\n\nMost of the data visualizations are done using Plotly express, which allows for a relatively easy implementation of interactive graphs. Seaborn is also used to create heatmaps, matplotlib is used to create subplots and format figures, and conditional formatting (such as background gradients) is applied to several dataframes to highlight values.\n\n\nThe dataset used in the present notebook is the cleaned version of the original online retail business dataset. The notebook containing the cleaning, which I have also published, can be found [<ins>here</ins>](https://www.kaggle.com/atanaskanev/e-commerce-business-data-cleaning).\n\nIn short, the cleaning process included:\n* cleaning erroneous and missing data\n* removing duplicated descriptions for the same stockcodes\n* handling outliers\n\nI have also created an SQL notebook which replicates this analysis and answers the same business questions using PostgreSQL. You can see my SQL notebook on my Github [<ins>here</ins>](https://github.com/atanaskanev/ecommerce_sales_analysis/blob/main/ecommerce_business.ipynb).","metadata":{}},{"cell_type":"markdown","source":"## Table of Contents\nClick on any heading to jump straight to the content\n\n[<font size=\"5\">Importing Libraries and Data</font>](#section-eight)\n\n[<font size=\"5\">Sales Analysis and Visualization</font>](#section-nine)\n* [What are the Sales Figures for Each Country?](#section-ten)\n* [What is the Overall Sales Trend?](#section-eleven)\n* [How Many Customers Purchased Products Each Month?<br> How Many New Customers were There Each Month?](#section-twelve)\n* [What Time During the Day Do Customers Make the Most Purchases?](#section-thirteen)\n* [Which is the Best Selling Product in Each Country?](#section-fourteen)\n* [Which are the Most Successful Products Overall?](#section-fifteen)\n* [Which Customers Contributed the Most to Total Sales?](#section-sixteen)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-eight\"></a>\n# Importing Libraries and Data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt # creating subplots and formating figures\nimport seaborn as sns # visualizations including heatmaps\nimport plotly.express as px # used for interactive visualizations\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot # plot plotly graphs in line in a notebook\ninit_notebook_mode(connected = True)\nimport calendar # used to convert numbers between 1 and 12 to month names\n\nimport warnings        \nwarnings.filterwarnings(\"ignore\") # ignores warnings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing the cleaned dataset\ndata = pd.read_csv(\"../input/online-retail-business-cleaned-dataset/online_retail_cleaned.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cast InvoiceDate as a date type\ndata[\"InvoiceDate\"] = pd.to_datetime(data[\"InvoiceDate\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-nine\"></a>\n# Sales Analysis and Visualization","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-ten\"></a>\n## What are the Sales Figures for Each Country?\nFirst, let's see what percentage of total sales each country accounts for:","metadata":{}},{"cell_type":"code","source":"# calculate total sales by country\ncountry_sales = pd.DataFrame(data.groupby(\"Country\") \\\n[\"ItemTotal\"].sum()).reset_index().rename({\"ItemTotal\":\"TotalSales\"},axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.pie(country_sales,\n             values=\"TotalSales\",\n             names=\"Country\",\n             title=\"Percent of Total Sales by Country\",\n             color_discrete_sequence=px.colors.qualitative.G10\n            )\n# px.colors.qualitative.swatches().show() # see available color palettes\n\nfig.update_traces(\n                  textposition=\"inside\",\n                  textinfo=\"percent+label\"\n                 )\nfig.update_layout(\n                  margin=dict(l=10, r=50, b=10, t=70, pad=0),\n                  titlefont = dict(size = 20)\n                 )\niplot(fig)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that the UK accounts for the vast majority of total sales. \n\nLet's visualize other countries' share of total sales by plotting the sales figure on a map. We will plot this map without the UK sales since it would skew the scale due to its predominant share of sales.","metadata":{}},{"cell_type":"code","source":"# also drop \"Unspecified\" and \"European Community\" since they cannot be mapped\ncountry_sales = country_sales[country_sales[\"Country\"] \\\n.isin([\"Unspecified\", \"European Community\",\"United Kingdom\"]) == False]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rename countries into names which are recognised by plotly\ncountry_sales[\"Country\"] = \\\ncountry_sales[\"Country\"].replace({\"EIRE\": \"Ireland\",\n                                  \"Channel Islands\": \"United Kingdom\",\n                                  \"RSA\": \"South Africa\"})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that the following map is interactive so you can zoom in and out, and can hover on different countries to show sales figures.","metadata":{}},{"cell_type":"code","source":"# https://stackoverflow.com/questions/59812824/plotly-express-plot-not-shown-in-jupyter-notebook\nchoro_data = dict(\n                  type = \"choropleth\",\n                  colorscale = \"Agsunset\",\n                  locations = country_sales[\"Country\"],\n                  locationmode = \"country names\",\n                  z = country_sales[\"TotalSales\"].astype(float).round(0).tolist(),\n                  hovertext = country_sales[\"Country\"],\n                  hovertemplate = \"%{hovertext}: £%{z:,.0f} <extra></extra>\",\n                  # https://stackoverflow.com/questions/59057881/python-plotly-how-to-customize-hover-template-on-with-what-information-to-show\n                  colorbar = {\"title\" : \"Total Sales\", },\n                ) \n\nlayout = dict(\n              title = \"Total Sales By Country Excluding the UK\",\n              titlefont = dict(size = 20),\n              geo = dict(showframe = False, bgcolor = \"#BAEAED\",),\n              margin={\"r\":0,\"t\":50,\"l\":10,\"b\":0}  \n             )\n\nfig = go.Figure(data=choro_data, layout=layout)\n# fig.update_traces(visible = True)\niplot(fig)\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that apart from the UK, Australia and countries in Europe have contributed the most towards total sales.\n\nLet's zoom in on Europe:","metadata":{}},{"cell_type":"code","source":"choro_data = [dict(\n                  type = \"choropleth\",\n                  colorscale = \"Agsunset\",\n                  locations = country_sales[\"Country\"],\n                  locationmode = \"country names\",\n                  z = country_sales[\"TotalSales\"].astype(float).round(0).tolist(),\n                  hovertext = country_sales[\"Country\"],\n                  hovertemplate = \"%{hovertext}: £%{z:,.0f} <extra></extra>\",\n                  # https://stackoverflow.com/questions/59057881/python-plotly-how-to-customize-hover-template-on-with-what-information-to-show\n                  colorbar = {\"title\" : \"Total Sales\", },\n                 ),\n              dict(\n                  type = \"scattergeo\", # add static country labels\n                  locations = country_sales[\"Country\"],\n                  locationmode = \"country names\",\n                  text = country_sales[\"Country\"],\n                  hoverinfo = \"skip\", # do not display static label when hovering over the country\n                  mode = \"text\",\n                  textfont=dict( # format the static country labels\n                                size = 11, # only these 3 properties are allowed\n                                color = \"white\",\n                                family = \"Arial\"\n                               )\n                  ) \n            ]\nlayout = dict(\n              title = \"Total Sales By Country Excluding the UK\",\n              titlefont = dict(size = 20),\n              geo = dict(\n                         showframe = False,\n                         bgcolor = \"#A4E0E4\",\n                         projection = dict(scale = 4.5), # default zoom\n                         center = dict(lat = 47, lon = 5) # default map position\n                         ),\n              margin={\"r\":0,\"t\":50,\"l\":10,\"b\":0}\n             )\n\nfig = go.Figure(data = choro_data, layout = layout)\niplot(fig)\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-eleven\"></a>\n## What is the Overall Sales Trend?","metadata":{}},{"cell_type":"markdown","source":"Check date range:","metadata":{}},{"cell_type":"code","source":"print(\"first date: \", data[\"InvoiceDate\"].min(),\"\\n\", \"last date: \", data[\"InvoiceDate\"].max())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see the data spans between 12 January 2010 and 10 December 2011, which is almost 2 years. \n\nNote that since the data does not cover the whole month of December 2011, sales figures are likely going to be low in this month, since they are about 12 days only. ","metadata":{}},{"cell_type":"code","source":"# create columns extracting the year and month of InvoiceDates\ndata[\"year\"], data[\"month\"] = data[\"InvoiceDate\"].dt.year, data[\"InvoiceDate\"].dt.month","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sales = data.groupby([\"year\",\"month\"])[\"ItemTotal\"].sum() \\\n.reset_index().rename({\"ItemTotal\":\"TotalSales\"},axis=1)\n\nsales","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It turns out we have no data about April 2010 and November 2010, so we add two columns with the averages of the preceding and following months for consistency. The averages were calculated, and instead of using a formula, the actual values are inserted for brevity.","metadata":{}},{"cell_type":"code","source":"# create rows about April 2010 and November 2010 with averages from preceding and following month \n                                                                                                  \nnew_rows = pd.DataFrame({\"year\":[2010,2010],\n                         \"month\": [4,11],\n                         \"TotalSales\": [38123.21,184980.04]},\n                         index = [98,99]) # arbitrary indexes\n\n# insert the row in the sales table\nsales = pd.concat([new_rows, sales]) \\\n.sort_values(by=[\"year\",\"month\"]).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some formatting:","metadata":{}},{"cell_type":"code","source":"# convert numbers into month names\nsales[\"month\"] = sales[\"month\"].apply(lambda x: calendar.month_abbr[x])\n\n# combine month and year\nsales[\"month\"] = sales[\"month\"].astype(str) + \" \" + sales[\"year\"].astype(str)\n\n# drop the redundant year column\nsales = sales.drop(\"year\", axis = 1) \n\nsales = sales[0:23] # drop December 2011 since the data does not cover the whole month","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And we visualize. The graph is interactive so you can zoom in/out and hover over the data to see details.","metadata":{}},{"cell_type":"code","source":"# line chart using plotly expess Scatter\ntrace = go.Scatter(\n                    x = sales[\"month\"],\n                    y = sales[\"TotalSales\"],\n                    mode = \"lines+markers\",\n                    name = \"TotalSales\",\n                    line = dict(width = 4),\n                    marker = dict(\n                                  size = 10,\n                                  color = \"rgba(120, 26, 120, 0.8)\"\n                                 ),\n                    hovertemplate = \" %{x}<br>£%{y:,.0f} <extra></extra>\",\n                  )\nline_data = [trace]\nlayout = dict(\n              title = \"Total Sales by Month\",\n              titlefont = dict(size = 20),\n              margin=dict(l=10, r=50, b=10, t=70, pad=0),\n              xaxis= dict(title= \"Month\",ticklen = 5,zeroline = False),\n              yaxis= dict(title= \"Total Sales\", tickformat = \",.0f\", tickprefix=\"£\")\n             )\nfig = dict(data = line_data, layout = layout)\niplot(fig)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see a clear upward trend with initial sharp increses towards the end of 2010 and the beginning of 2011. Let's investigate whether the number of customers in each month exhibit a similar trend.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-twelve\"></a>\n##  How Many Customers Purchased Products Each Month? <br> How Many New Customers were There Each Month?\nWe saw some records with missing CustomerIDs above, so first we check how many unique Invoices there are and how many of them have a missing CustomerID:","metadata":{}},{"cell_type":"code","source":"# all orders\nlen(data[\"InvoiceNo\"].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# invoices with at least one record with missing CustomerID\nlen(data[data[\"CustomerID\"].isna()][\"InvoiceNo\"].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can also check how many invoices have <ins>all</ins> of their CustomerIDs missing.","metadata":{}},{"cell_type":"code","source":"data.groupby(\"InvoiceNo\").apply(lambda x: all(np.isnan(i) for i in x[\"CustomerID\"])).tolist().count(True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we see, the number is the same, which means that invoices either have missing values for all CustomerIDs, or no CustomerIDs are missing.\n\nSince we do not know how many customers have an NaN value for CustomerID, we drop records with missing CustomerIDs for this analysis.","metadata":{}},{"cell_type":"code","source":"customers = data[data[\"CustomerID\"].notna()].groupby([\"year\", \"month\"]) \\\n.agg({\"CustomerID\": \"unique\"}) \\\n.reset_index().rename({\"CustomerID\": \"unique_customer_ids\"}, axis = 1)\n\n# calculate the number of unique customers and insert it as a column\ncustomers.insert(2,\"unique_customers_this_month\", customers[\"unique_customer_ids\"].str.len())\n\ncustomers.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nNew customers are customers who purchase an item for the first time. In other words, these are customers whose CustomerID appears in the records for the first time at the date of the purchase.\n\nTo find which CustomerIDs appear for the first time, we create a running list which accumulates all unique_customer_ids up to each month. Then we remove duplicates and check the length of the list for each month. In doing so, we get the running total of unique customers.","metadata":{}},{"cell_type":"code","source":"ids = []\n\n# creates a running list of customerids up to each month\nfor index, row in customers.iterrows(): \n    if index == 0:\n        ids.append(row[\"unique_customer_ids\"].tolist())\n        \n    else:   # adds the present ids to the accumulated list of previous ids\n        ids.append(row[\"unique_customer_ids\"].tolist() + ids[index-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_customers = []\nfor i in range(len(ids)):\n    total_customers.append(len(set(ids[i]))) # the set removes duplicates  \n    \n# insert as a column\ncustomers.insert(3, \"total_customers\", total_customers)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add the first difference of totaL_customers\n\ncustomers.insert(3, \"new_customers_this_month\", customers[\"total_customers\"].diff() \\\n.replace({np.nan: 98}).astype(int)) # fill in the first value","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" # drop the long lists of unique customers\ncustomers = customers.drop(\"unique_customer_ids\", axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create rows about April 2010 and November 2010 with averages from preceding and following months\nnew_rows = \\\npd.DataFrame({\"year\":[2010,2010],\n              \"month\": [4,11],\n              \"unique_customers_this_month\": [65,271],\n              \"new_customers_this_month\": [59,163],\n              \"total_customers\": [288,803]}, index = [98,99]) # arbitrary indexes\n\n# insert the row in the customers table\ncustomers = pd.concat([new_rows, customers]) \\\n.sort_values(by=[\"year\",\"month\"]).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some formatting:","metadata":{}},{"cell_type":"code","source":"# convert numbers into month names\ncustomers[\"month\"] = customers[\"month\"].apply(lambda x: calendar.month_abbr[x])\n\n# combine month and year\ncustomers[\"month\"] = customers[\"month\"].astype(str) + \" \" + customers[\"year\"].astype(str)\n\n# drop the redundant year column\ncustomers = customers.drop(\"year\", axis = 1)\n\ncustomers = customers[0:23] # drop December 2011 since the data does not cover the whole month","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And plot:","metadata":{}},{"cell_type":"code","source":"trace1 = go.Scatter(\n                    x = customers[\"month\"],\n                    y = customers[\"unique_customers_this_month\"],\n                    mode = \"lines+markers\",\n                    name = \"Unique Customers This Month\",\n                    line = dict(width = 4),\n                    marker = dict(\n                                  size = 10,\n                                  color = \"#0E79B2\"\n                                 ),\n                    hovertemplate = \"%{x}<br>Unique Customers: %{y} <extra></extra>\",\n                  )\ntrace2 = go.Scatter(\n                    x = customers[\"month\"],\n                    y = customers[\"new_customers_this_month\"],\n                    mode = \"lines+markers\",\n                    name = \"New Customers This Month\",\n                    line = dict(width = 4),\n                    marker = dict(\n                                  size = 10,\n                                  color = \"rgba(242, 225, 39, 1)\"\n                                 ),\n                    hovertemplate = \"%{x}<br>New Customers: %{y} <extra></extra>\",\n                  )\n\nline_data = [trace1, trace2]\n\nlayout = dict(\n              title = \"Customers by Month\",\n              titlefont = dict(size = 20),\n              margin=dict(l=10, r=50, b=10, t=70, pad=0),\n              xaxis= dict(title= \"Month\",ticklen = 5,zeroline = False),\n              yaxis= dict(title= \"Number of Customers\"),\n              legend=dict(\n                          font = dict(size = 12),\n                          yanchor = \"top\",\n                          y=0.98,\n                          x= 0.01\n                         )\n             )\nfig = dict(data = line_data, layout = layout)\niplot(fig)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wee see a significant jump in new customers around December 2010 and January 2011, likely related to the Christmas holidays. We could investigate whether the business has been running marketing campaigns around these times, and which campaigns were the most successful.\n\nWe can see that after the spike of new customers around December/January, the number of customers per month has been increasing steadity. We can see another spike in customers in November 2011, although there is no spike in new customers. This might suggest that customers were satisfied with their Christmas purchases in 2010, and are now coming back to the online store for their Christmas 2011 purchases.\n\nWe do see that the number of new customers has been decreasing slowly over the year. This could once again be related to marketing campaigns and could be investigated.\n\n\nLet's look at the chart with total customers added:","metadata":{}},{"cell_type":"code","source":"trace1 = go.Scatter(\n                    x = customers[\"month\"],\n                    y = customers[\"unique_customers_this_month\"],\n                    mode = \"lines+markers\",\n                    name = \"Unique Customers This Month\",\n                    line = dict(width = 4),\n                    marker = dict(\n                                  size = 10,\n                                  color = \"#0E79B2\"\n                                 ),\n                    hovertemplate = \"%{x}<br>Unique Customers: %{y} <extra></extra>\",\n                  )\ntrace2 = go.Scatter(\n                    x = customers[\"month\"],\n                    y = customers[\"new_customers_this_month\"],\n                    mode = \"lines+markers\",\n                    name = \"New Customers This Month\",\n                    line = dict(width = 4),\n                    marker = dict(\n                                  size = 10,\n                                  color = \"rgba(242, 225, 39, 1)\"\n                                 ),\n                    hovertemplate = \"%{x}<br>New Customers: %{y} <extra></extra>\",\n                  )\ntrace3 = go.Scatter(\n                    x = customers[\"month\"],\n                    y = customers[\"total_customers\"],\n                    mode = \"lines+markers\",\n                    name = \"Total Customers\",\n                    line = dict(width = 4),\n                    marker = dict(\n                                  size = 10,\n                                  color = \"rgba(242, 39, 127, 1)\"\n                                 ),\n                    hovertemplate = \"%{x}<br>Total Customers: %{y} <extra></extra>\",\n                  )\n\nline_data = [trace1, trace2, trace3]\n\nlayout = dict(\n              title = \"Customers by Month\",\n              titlefont = dict(size = 20),\n              margin=dict(l=10, r=50, b=10, t=70, pad=0),\n              xaxis= dict(title= \"Month\",ticklen = 5,zeroline = False),\n              yaxis= dict(title= \"Number of Customers\"),\n              legend=dict(\n                          font = dict(size = 12),\n                          yanchor = \"top\",\n                          y=0.98,\n                          x= 0.01\n                         )\n             )\nfig = dict(data = line_data, layout = layout)\niplot(fig)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We do infact see that the line chart of the number of total customers has a concave shape. In other words, the number of total customers is increasing at a descreasing rate. As commented above, this is directly related to the decreasing number of new customers.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-thirteen\"></a>\n## What Time During the Day Do Customers Make the Most Purchases? \nWe have seen spikes in sales around December 2010, which is likely related to the Christmas holidays. Since the last date of this dataset is December 2011 (which we assume is the present), we expect that the business would be running marketing campaigns for this year's Christmas hodidays as well. Therefore, it would be useful to find out what time of day customers make the most purchases in order to target the marketing campaigns around these times.\n\nTo check this, we can look at what time customers were making the most orders the previous December (i.e. December 2010), as well as the most common hours for purchases during the last 2 months (i.e. October and November 2011). Since we have data about 12 days of December 2011, we include these in the analysis as well.","metadata":{}},{"cell_type":"code","source":"# take data only about December 2010 and October, Novermber and December 2011\nsubset = data[\n              ((data[\"year\"] == 2010) & (data[\"month\"] == 12))\n              |    \n              ((data[\"year\"] == 2011) & (data[\"month\"] == 10))\n              |\n              ((data[\"year\"] == 2011) & (data[\"month\"] == 11))\n              |\n              ((data[\"year\"] == 2011) & (data[\"month\"] == 12))\n              ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract the hour of purchase from InvoiceDate and add it as a column\nsubset[\"hour\"] = subset[\"InvoiceDate\"].astype(str).str[11:13].astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate the total number of orders for each hour of the day in these months\n\nfrequency = subset.groupby([\"year\",\"month\",\"hour\"]) \\\n.agg({\"InvoiceNo\":\"nunique\"}).reset_index() \\\n.rename({\"InvoiceNo\": \"num_orders\"}, axis = 1)\n\nfrequency.head()","metadata":{"cell_style":"center","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We pivot the table, so it is easier to read and easier to plot:","metadata":{}},{"cell_type":"code","source":"pivot = frequency.pivot(index = \"hour\", columns = [\"year\",\"month\"], values = [\"num_orders\"])\n\npivot = pd.DataFrame(pivot.to_records()) # flattens multilevel column headings\n\npivot[\"hour\"] = pivot[\"hour\"].astype(str) + \":00\" # make hours more readable\n\npivot = pivot.set_index(\"hour\")\n\npivot.index.name = \"\" # remove index name for plotting\n\npivot.rename(columns={ # set more readable names\n                      pivot.columns[0]:\"Dec 2010\",\n                      pivot.columns[1]:\"Oct 2011\",\n                      pivot.columns[2]:\"Nov 2011\",\n                      pivot.columns[3]:\"Dec 2011\"\n                      }, inplace = True)\n\npivot","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And we plot a heatmap of these values for each month:","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(4,1, figsize = (9,2.7))\ncbar_ax = fig.add_axes([0.92, .10, .03, .8]) # add custom colorbar\n\nsns.heatmap(pd.DataFrame(pivot[\"Dec 2010\"]).T, ax = axs[0], cbar = False)\nsns.heatmap(pd.DataFrame(pivot[\"Oct 2011\"]).T, ax = axs[1], cbar_ax = cbar_ax, xticklabels=False)\nsns.heatmap(pd.DataFrame(pivot[\"Nov 2011\"]).T, ax = axs[2], cbar = False, xticklabels=False)\nsns.heatmap(pd.DataFrame(pivot[\"Dec 2011\"]).T, ax = axs[3], cbar = False, xticklabels=False)\n\ncbar = axs[1].collections[0].colorbar # set custom colorbar labels\ncbar.set_ticks([30, 190, 350])\ncbar.set_ticklabels([\"low\", \"medium\", \"high\"])\n\naxs[0].xaxis.set_ticks_position(\"top\")\naxs[0].yaxis.set_ticklabels(axs[0].get_yticklabels(), rotation = 0)\naxs[1].yaxis.set_ticklabels(axs[1].get_yticklabels(), rotation = 0)\naxs[2].yaxis.set_ticklabels(axs[2].get_yticklabels(), rotation = 0)\naxs[3].yaxis.set_ticklabels(axs[3].get_yticklabels(), rotation = 0)\n\nfig.suptitle(\"Total Number of Orders for Each Hour of the Day\", y = 1.10)\nplt.show()","metadata":{"scrolled":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Or alternatively, we could have applied background gradients directly to the dataframe:","metadata":{}},{"cell_type":"code","source":"pivot.replace(np.nan,0).style\\\n.background_gradient(cmap=\"rocket\", subset=[\"Dec 2010\"])\\\n.background_gradient(cmap=\"rocket\", subset=[\"Oct 2011\"])\\\n.background_gradient(cmap=\"rocket\", subset=[\"Nov 2011\"])\\\n.background_gradient(cmap=\"rocket\", subset=[\"Dec 2011\"])\\\n.format(\"{:.0f}\")","metadata":{"scrolled":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From these figures, it is clear that the most orders are placed around midday, more specifically at 12:00. Therefore, the marketing team could target their campaigns around these times to maximize conversions.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-fourteen\"></a>\n## Which is the Best Selling Product in Each Country?\nWe are going to investigate which product generated the highest sales in each country, how much sales it generated, and what percent of the country's total sales it generated. We also find which product is the most common best seller.","metadata":{}},{"cell_type":"code","source":"# calculate total sales for each product in each country\nsales_countr_descr = data.groupby([\"Country\", \"Description\"]) \\\n.agg({\"ItemTotal\": \"sum\"}) \\\n.rename({\"ItemTotal\":\"TotalSales\"},axis=1).reset_index()\n\nsales_countr_descr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find the total sales of the best selling product in each country\nmax_sales = pd.DataFrame(sales_countr_descr.groupby(\"Country\") \\\n[\"TotalSales\"].max().reset_index()) \\\n.rename({\"TotalSales\":\"Best_Product_Total_Sales\"},axis=1)\n\nmax_sales.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# join the two tables from above together\njoined_df = sales_countr_descr.merge(max_sales, on = \"Country\", how = \"left\")\njoined_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find the products whose sales equal the highest product sales in each country\n# in other words, find the best selling item in each country\njoined_df = joined_df[joined_df[\"TotalSales\"] == joined_df[\"Best_Product_Total_Sales\"]]\njoined_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop the redundant column\njoined_df = joined_df.drop(\"Best_Product_Total_Sales\", axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we want to find the percentage of total sales these products have generated in each country. To do this we create a table with the countries' total sales and join it to the table above:","metadata":{}},{"cell_type":"code","source":"# total sales in each country\ncountry_sales = pd.DataFrame(data.groupby(\"Country\")[\"ItemTotal\"].sum()) \\\n.reset_index().rename({\"ItemTotal\":\"Country_Total_Sales\"}, axis = 1)\n\ncountry_sales.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"joined_df = joined_df.merge(country_sales, on = \"Country\", how = \"inner\") \\\n.rename({\"Description\":\"Best_Selling_Product\"}, axis = 1)\n\njoined_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And add another column calculating the percentage of total sales which the Best selling items has generated in each country. It is formatted as a percentage with 2 decimal points. A background gradient is applied.","metadata":{}},{"cell_type":"code","source":"joined_df[\"%_of_Country_Sales\"] = (joined_df[\"TotalSales\"] / joined_df[\"Country_Total_Sales\"])\n\njoined_df \\\n.style.background_gradient(cmap=sns.light_palette(\"seagreen\", as_cmap=True), \\\n subset=[\"%_of_Country_Sales\"]) \\\n.format({\"%_of_Country_Sales\":\"{:.2%}\",\n         \"TotalSales\":\"£{:,.0f}\",\n         \"Country_Total_Sales\":\"£{:,.0f}\"})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Which product is the most common best seller? ","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(joined_df[\"Best_Selling_Product\"].value_counts()) \\\n.rename({\"Best_Selling_Product\":\"Best_Selling_Product_in_X_Countries\"},axis=1)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-fifteen\"></a>\n## Which are the Most Successful Products Overall?\nA characteristic we could use to answer this is: which products of relatively high price have sold relatively high quantities. This can be easily visualized with a scatter plot of all products with total quantity sold and average unitprice on the x and y axes.\n\nProducts' markers to the north-east on the scatter plot suggest relatively high quantities sold at a relatively high price.  ","metadata":{}},{"cell_type":"code","source":"# find total quantity sold and average unit price for all products\nproducts = data.groupby(\"Description\") \\\n.agg({\"Quantity\":\"sum\", \"UnitPrice\":\"mean\"}).reset_index()\n\nproducts = products[products[\"Description\"].isin([\"DOTCOM\",\"Manual\",\"Discount\"]) == False] # remove for plotting\n\nproducts","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following scatter plot is interactive, so you can hover over any point to see its details.","metadata":{}},{"cell_type":"code","source":"trace = go.Scatter(\n                    x = products[\"Quantity\"],\n                    y = products[\"UnitPrice\"],\n                    customdata = products[\"Description\"],\n                    hovertemplate = \"%{customdata}<br>Quantity Sold: %{x}<br>UnitPrice: £%{y:.2f}<br><extra></extra>\",\n                    mode = \"markers\",\n                    name = \"Products\",\n                    line = dict(width = 4),\n                    marker = dict(\n                                  size = 10,\n                                  color = \"#1199cf\"\n                                 )\n                    )\n\nscatter_data = [trace]\n\nlayout = dict(\n              title = \"Products\",\n              titlefont = dict(size = 20),\n              margin=dict(l=10, r=50, b=10, t=70, pad=0),\n              xaxis= dict(title= \"Quantity Sold\",ticklen = 5,zeroline = False),\n              yaxis= dict(title= \"Unit Price\")\n             )\nfig = dict(data = scatter_data, layout = layout)\niplot(fig)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above we saw \"REGENCY CAKESTAND 3 TIER\" as the most common best seller (8 countries) and here we see it as a high selling product as well - its marker is visually separated from the other products on the plot. ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-sixteen\"></a>\n## Which Customers Contributed the Most to Total Sales?\nFinally, let's see the customers with highest purchase figures and their corresponding number of orders: ","metadata":{}},{"cell_type":"code","source":"cust_purchases = \\\ndata.groupby(\"CustomerID\") \\\n.agg({\"InvoiceNo\": \"nunique\", \"ItemTotal\": \"sum\"}) \\\n.rename({\"ItemTotal\":\"TotalPurchases\",\"InvoiceNo\":\"Number_of_Orders\"},axis = 1) \\\n.sort_values(by = \"TotalPurchases\", ascending = False)\n\ncust_purchases.head(15) # only first 15","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"How much did each customer contribute to the total sales figure in percentage terms?","metadata":{}},{"cell_type":"code","source":"cust_purchases[\"Percent_of_TotalSales\"] = (cust_purchases[\"TotalPurchases\"]/data[\"ItemTotal\"].sum()).map(\"{:.2%}\".format)\ncust_purchases[\"TotalPurchases\"] = cust_purchases[\"TotalPurchases\"].map(\"£{:,.0f}\".format) # format as currency\n\ncust_purchases.head(15) # first 15 only\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"5\">Thank you for reading my notebook!</font>\n\nI have also created an SQL notebook which replicates this analysis and answers the same business questions using PostgreSQL. You can see my SQL notebook on my Github [<ins>here</ins>](https://github.com/atanaskanev/ecommerce_sales_analysis/blob/main/ecommerce_business.ipynb).\n\nAny comments and suggestions are highly appreciated!","metadata":{}}]}