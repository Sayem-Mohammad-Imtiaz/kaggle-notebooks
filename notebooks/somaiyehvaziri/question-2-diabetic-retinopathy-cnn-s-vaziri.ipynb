{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator\nfrom PIL import Image\nfrom glob import glob\nimport cv2\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense , Dropout, Flatten , Conv2D,MaxPool2D\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_images(path,num_img):\n    array=np.zeros((num_img,224,224,3))\n    i=0\n    for img in os.listdir(path):\n        img_path=path + \"/\" + img\n        img=Image.open(img_path,mode=\"r\")\n        data=np.asarray(img,dtype=\"uint8\")\n        array[i]=data\n        i+=1\n    return array\n#no\nno_dr_path=r\"/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images/No_DR\"\nnum_no_dr=len(glob(\"/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images/No_DR/*\"))\nno_dr_array=read_images(no_dr_path,num_no_dr)\nno_dr_array=no_dr_array.astype(np.uint8)\n#mild\nmild_path=r\"/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images/Mild\"\nnum_mild=len(glob(\"/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images/Mild/*\"))\nmild_array=read_images(mild_path,num_mild)\nmild_array=mild_array.astype(np.uint8)\n#moderate\nmoderate_path=r\"/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images/Moderate\"\nnum_moderate=len(glob(\"/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images/Moderate/*\"))\nmoderate_array=read_images(moderate_path,num_moderate)\nmoderate_array=moderate_array.astype(np.uint8)\n#proliferate\nproliferate_dr_path=r\"/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images/Proliferate_DR\"\nnum_proliferate_dr=len(glob(\"/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images/Proliferate_DR/*\"))\nproliferate_dr_array=read_images(proliferate_dr_path,num_proliferate_dr)\nproliferate_dr_array=proliferate_dr_array.astype(np.uint8)\n#severe\nsevere_path =r\"/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images/Severe\"\nnum_severe=len(glob(\"/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images/Severe/*\"))\nsevere_array=read_images(severe_path,num_severe)\nsevere_array=severe_array.astype(np.uint8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"no_dr_array\",no_dr_array.shape)\nprint(\"mild_array\",mild_array.shape)\nprint(\"moderate_array\",moderate_array.shape)\nprint(\"proliferate_dr_array\",proliferate_dr_array.shape)\nprint(\"severe_array\",severe_array.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(no_dr_array[1])\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"no_dr_array dtype is\",no_dr_array.dtype)\nprint(\"mild_array dtype is\",mild_array.dtype)\nprint(\"moderate_array dtype is\",moderate_array.dtype)\nprint(\"proliferate_dr_array dtype is\",proliferate_dr_array.dtype)\nprint(\"severe_array dtype is\",severe_array.dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"num_no_dr:\",num_no_dr)\nprint(\"num_mild:\",num_mild)\nprint(\"num_moderate:\",num_moderate)\nprint(\"num_proliferate_dr:\",num_proliferate_dr)\nprint(\"num_severe:\",num_severe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zeros=np.zeros(1805)\nones=np.ones(370)\ntwos=np.full(999,2)\nthrees=np.full(295,3)\nfours=np.full(193,4)\ny = np.concatenate((zeros,ones,twos,threes,fours),axis=0)\nprint(\"y shape\",y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def resize_images(img):\n    number_of_image=img.shape[0]\n    new_array=np.zeros((number_of_image,64,64,3))\n    for i in range(number_of_image):\n        new_array[i]=cv2.resize(img[i,:,:,:],(64,64))\n    return new_array\nno_dr_array=resize_images(no_dr_array)\nno_dr_array=no_dr_array.astype(np.uint8)\nmild_array=resize_images(mild_array)\nmild_array=mild_array.astype(np.uint8)\nmoderate_array=resize_images(moderate_array)\nmoderate_array=moderate_array.astype(np.uint8)\nproliferate_dr_array=resize_images(proliferate_dr_array)\nproliferate_dr_array=proliferate_dr_array.astype(np.uint8)\nsevere_array=resize_images(severe_array)\nsevere_array=severe_array.astype(np.uint8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(no_dr_array[1])\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"new no_dr_array shape\",no_dr_array.shape)\nprint(\"new mild_array shape\",mild_array.shape)\nprint(\"new moderate_array shape\",moderate_array.shape)\nprint(\"new proliferate_dr_array shape\",proliferate_dr_array.shape)\nprint(\"new severe_array shape\",severe_array.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"no_dr_array dtype is\",no_dr_array.dtype)\nprint(\"mild_array dtype is\",mild_array.dtype)\nprint(\"moderate_array dtype is\",moderate_array.dtype)\nprint(\"proliferate_dr_array dtype is\",proliferate_dr_array.dtype)\nprint(\"severe_array dtype is\",severe_array.dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = to_categorical(y,5)\nprint(\"new y shape\",y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=np.concatenate((no_dr_array,mild_array,moderate_array,proliferate_dr_array,severe_array),axis=0)\nprint(\"x shape\",x.shape)\nprint(\"x dtype is \",x.dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=x / 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)\nprint(\"x_train shape\",x_train.shape)\nprint(\"x_test shape\",x_test.shape)\nprint(\"y_train shape\",y_train.shape)\nprint(\"y_test shape\",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The main model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters=250,kernel_size=(3,3),activation=\"relu\",padding=\"same\",input_shape=(64,64,3)))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=1))\n\nmodel.add(Conv2D(filters=125,kernel_size=(3,3),activation=\"relu\",padding=\"same\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=1))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(250,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(125,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5,activation=\"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen=ImageDataGenerator(\n                          shear_range=0.3,\n                          horizontal_flip=True,\n                          vertical_flip=True,\n                          zoom_range=0.3,\n                          rotation_range=0.3)\ndatagen.fit(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size=125\nepochs=10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist=model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),\n                        epochs=epochs,validation_data=(x_test,y_test),steps_per_epoch=x_train.shape[0] // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_val_loss_values = hist.history['val_loss']\nmain_val_accuracy_values = hist.history['val_accuracy']\n\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,1)\nplt.plot(hist.history[\"loss\"],label=\"train loss\")\nplt.plot(hist.history[\"val_loss\"],label=\"val loss\")\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,2)\nplt.plot(hist.history[\"accuracy\"],label=\"train accuracy\")\nplt.plot(hist.history[\"val_accuracy\"],label=\"val accuracy\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simlified model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters=250,kernel_size=(3,3),activation=\"relu\",padding=\"same\",input_shape=(64,64,3)))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=1))\n\nmodel.add(Conv2D(filters=125,kernel_size=(3,3),activation=\"relu\",padding=\"same\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=1))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(250,activation=\"relu\"))\nmodel.add(Dropout(0.5))\n#model.add(Dense(125,activation=\"relu\"))\n#model.add(Dropout(0.5))\nmodel.add(Dense(5,activation=\"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\nhist=model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),\n                        epochs=epochs,validation_data=(x_test,y_test),steps_per_epoch=x_train.shape[0] // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s_val_loss_values = hist.history['val_loss']\ns_val_accuracy_values = hist.history['val_accuracy']\n\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,1)\n#plt.plot(hist.history[\"loss\"],label=\"s_train loss\")\nplt.plot(hist.history[\"val_loss\"],label=\"s_val loss\")\nplt.plot(main_val_loss_values, 'g', label='main_Val loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,2)\nplt.plot(hist.history[\"accuracy\"],label=\"s_train accuracy\")\nplt.plot(hist.history[\"val_accuracy\"],label=\"s_val accuracy\")\nplt.plot(main_val_accuracy_values, 'g', label='main_Val accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  corrected model by dropout in conv layers"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters=250,kernel_size=(3,3),activation=\"relu\",padding=\"same\",input_shape=(64,64,3)))\nmodel.add(Dropout(0.5))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=1))\n\n\nmodel.add(Conv2D(filters=125,kernel_size=(3,3),activation=\"relu\",padding=\"same\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=1))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(250,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(125,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5,activation=\"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\nhist=model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),\n                        epochs=epochs,validation_data=(x_test,y_test),steps_per_epoch=x_train.shape[0] // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"D_conv_val_loss_values = hist.history['val_loss']\nD_conv_val_accuracy_values = hist.history['val_accuracy']\n\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,1)\n#plt.plot(hist.history[\"loss\"],label=\"train loss\")\nplt.plot(hist.history[\"val_loss\"],label=\"val loss\")\nplt.plot(main_val_loss_values, 'g', label='main_Val loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,2)\nplt.plot(hist.history[\"accuracy\"],label=\"train accuracy\")\nplt.plot(hist.history[\"val_accuracy\"],label=\"val accuracy\")\nplt.plot(main_val_loss_values, 'g', label='main_Val accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# corrected model by weight regulaizer in dense layers(L1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import regularizers\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=250,kernel_size=(3,3),activation=\"relu\",padding=\"same\",input_shape=(64,64,3)))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=1))\n\n\nmodel.add(Conv2D(filters=125,kernel_size=(3,3),activation=\"relu\",padding=\"same\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=1))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(250,kernel_regularizer=regularizers.l1(0.001),activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(125,kernel_regularizer=regularizers.l1(0.001),activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5,activation=\"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n\nhist=model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),\n                        epochs=epochs,validation_data=(x_test,y_test),steps_per_epoch=x_train.shape[0] // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L1_val_loss_values = hist.history['val_loss']\nL1_val_accuracy_values = hist.history['val_accuracy']\n\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,1)\nplt.plot(hist.history[\"loss\"],label=\"train loss\")\nplt.plot(hist.history[\"val_loss\"],label=\"val loss\")\nplt.plot(main_val_loss_values, 'g', label='main_Val loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,2)\nplt.plot(hist.history[\"accuracy\"],label=\"train accuracy\")\nplt.plot(hist.history[\"val_accuracy\"],label=\"val accuracy\")\nplt.plot(main_val_loss_values, 'g', label='main_Val accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  corrected model by weight regulaizer in dense layers(L2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import regularizers\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=250,kernel_size=(3,3),activation=\"relu\",padding=\"same\",input_shape=(64,64,3)))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=1))\n\n\nmodel.add(Conv2D(filters=125,kernel_size=(3,3),activation=\"relu\",padding=\"same\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=1))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(250,kernel_regularizer=regularizers.l2(0.001),activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(125,kernel_regularizer=regularizers.l2(0.001),activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5,activation=\"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n\nhist=model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),\n                        epochs=epochs,validation_data=(x_test,y_test),steps_per_epoch=x_train.shape[0] // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L2_val_loss_values = hist.history['val_loss']\nL2_val_accuracy_values = hist.history['val_accuracy']\n\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,1)\nplt.plot(hist.history[\"loss\"],label=\"train loss\")\nplt.plot(hist.history[\"val_loss\"],label=\"val loss\")\nplt.plot(main_val_loss_values, 'g', label='main_Val loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,2)\nplt.plot(hist.history[\"accuracy\"],label=\"train accuracy\")\nplt.plot(hist.history[\"val_accuracy\"],label=\"val accuracy\")\nplt.plot(main_val_loss_values, 'g', label='main_Val accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  corrected model by weight regulaizer in dense layers(l1_l2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import regularizers\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=250,kernel_size=(3,3),activation=\"relu\",padding=\"same\",input_shape=(64,64,3)))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=1))\n\n\nmodel.add(Conv2D(filters=125,kernel_size=(3,3),activation=\"relu\",padding=\"same\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=1))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(250,kernel_regularizer=regularizers.l1_l2(l1=0.001,l2=0.001),activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(125,kernel_regularizer=regularizers.l1_l2(l1=0.001,l2=0.001),activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5,activation=\"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n\nhist=model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),\n                        epochs=5,validation_data=(x_test,y_test),steps_per_epoch=x_train.shape[0] // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L1_l2_val_loss_values = hist.history['val_loss']\nL1_L2_val_accuracy_values = hist.history['val_accuracy']\n\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,1)\nplt.plot(hist.history[\"loss\"],label=\"train loss\")\nplt.plot(hist.history[\"val_loss\"],label=\"val loss\")\nplt.plot(main_val_loss_values, 'g', label='main_Val loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,2)\nplt.plot(hist.history[\"accuracy\"],label=\"train accuracy\")\nplt.plot(hist.history[\"val_accuracy\"],label=\"val accuracy\")\nplt.plot(main_val_loss_values, 'g', label='main_Val accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# corrected model by weight regulaizer in conv(l1_l2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import regularizers\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=250,kernel_size=(3,3),activation=\"relu\",padding=\"same\",kernel_regularizer=regularizers.l1_l2(l1=0.001,l2=0.001),input_shape=(64,64,3)))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=1))\n\n\nmodel.add(Conv2D(filters=125,kernel_size=(3,3),activation=\"relu\",padding=\"same\",kernel_regularizer=regularizers.l1_l2(l1=0.001,l2=0.001)))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=1))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(250,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(125,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5,activation=\"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=\"rmsprop\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n\nhist=model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),\n                        epochs=5,validation_data=(x_test,y_test),steps_per_epoch=x_train.shape[0] // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L1_l2_conv_val_loss_values = hist.history['val_loss']\nL1_L2_conv_val_accuracy_values = hist.history['val_accuracy']\n\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,1)\nplt.plot(hist.history[\"loss\"],label=\"train loss\")\nplt.plot(hist.history[\"val_loss\"],label=\"val loss\")\nplt.plot(main_val_loss_values, 'g', label='main_Val loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,2)\nplt.plot(hist.history[\"accuracy\"],label=\"train accuracy\")\nplt.plot(hist.history[\"val_accuracy\"],label=\"val accuracy\")\nplt.plot(main_val_loss_values, 'g', label='main_Val accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Comparsion the methods"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(main_val_loss_values, 'g', label='main_Val loss')\nplt.plot(s_val_loss_values, label='s_Val loss')\nplt.plot(D_conv_val_loss_values, label='D_conv_Val loss')\nplt.plot(L1_val_loss_values, label='L1_Val loss')\nplt.plot(L2_val_loss_values, label='L2_Val loss')\nplt.plot(L1_l2_val_loss_values, label='L1_L2_Val loss')\nplt.plot(L1_l2_conv_val_loss_values, label='L1_l2_conv_Val loss')\nplt.plot(D_conv_val_loss_values, label='D_conv_Val loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(main_val_accuracy_values, 'g', label='main_Val accuracy')\nplt.plot(s_val_accuracy_values, label='s_Val accuracy')\nplt.plot(D_conv_val_accuracy_values, label='D_conv_Val accuracy')\nplt.plot(L1_val_accuracy_values, label='L1_Val accuracy')\nplt.plot(L2_val_accuracy_values, label='L2_Val accuracy')\nplt.plot(L1_L2_val_accuracy_values, label='L1_L2_Val accuracy')\nplt.plot(L1_L2_conv_val_accuracy_values, label='L1_l2_conv_Val accuracy')\nplt.plot(D_conv_val_accuracy_values, label='D_conv_Val accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}