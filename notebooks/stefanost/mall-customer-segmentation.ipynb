{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Mall Customer Segmentation"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/customer-segmentation-tutorial-in-python/Mall_Customers.csv')\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns='CustomerID', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#distribution of categorical binary variable: Gender\nplt.figure(figsize=(12,4));\nplt.subplot(1,2,1);\nsns.countplot(df['Gender']);\nplt.title('gender value_counts');\nplt.subplot(1,2,2);\ndf['Gender'].value_counts().plot(kind='pie',autopct='%.1f%%');\nplt.title('gender proportion');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#one-hot encoding of Gender\ndf['Male']=pd.get_dummies(df['Gender'],drop_first=True)\ndf.drop(columns='Gender',inplace=True)\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The relationship between annual income and spending score seems interesting. Let's explore a little further, by bringing the other variables into the conversation."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='Spending Score (1-100)', y='Annual Income (k$)',\n               data=df, hue='Male');\nplt.legend(loc=[1.1,0.7]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='Spending Score (1-100)', y='Annual Income (k$)',\n               data=df, hue='Age');\nplt.legend(loc=[1.1,0.7]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There doesn't seem to be a strong relationship between Gender and Spending Score, although with Age there does seem to be a degree of negative correlation, with older people tending to spend less. The correlation heatmap below confirms this."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.corr(), annot=True, fmt='1.1f');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clustering\n"},{"metadata":{},"cell_type":"markdown","source":"### K-means"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples\nfrom matplotlib import cm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Clustering According to Annual Income and Spending Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"x=df[['Annual Income (k$)','Spending Score (1-100)']].values\ninertia=[]\n\nfor i in range(1,11):\n    km=KMeans(n_clusters=i,random_state=33)\n    km.fit(x)\n    inertia.append(km.inertia_)\n    \nsns.lineplot(range(1,11),inertia);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With the lineplot above we are using the 'elbow' method to determine the optimal number of clusters. The graph shows how the within-cluster SSE (Sum of Squared Errors) decreases as the number of clusters increases. The point where the line makes an 'elbow' is the optimal number of clusters. In the above case that number is five."},{"metadata":{"trusted":true},"cell_type":"code","source":"km=KMeans(n_clusters=5, random_state=33)\nclusters=km.fit_predict(x)\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(x[:,0], x[:,1], hue =clusters);\nplt.title('Clusters');\nplt.legend(loc=(1.05,0.7));\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(x[:,0], x[:,1], hue =clusters);\nsns.scatterplot(km.cluster_centers_[:,0], km.cluster_centers_[:,1], color='red');\nplt.title('Clusters plus Cluster Centroids');\nplt.legend(loc=(1.05,0.7));\n\n#Graphing Silhouette\n#code from Sebastian Raschka's book 'Python Machine Learning'\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(x,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.title('Silhouette Graph');\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The silhouette graph above(code taken from Sebastian Raschka's book 'Python Machine Learning'), plots a measure of how tightly grouped the samples in the clusters are. The silhouette coefficient takes values between -1 and 1, the closer to 1 the better the clustering. The vertical red line depicts the average coefficient across all samples.\n\nIn the above cease the silhouettes aren't close to zero, and the clustering is considered rather good.\n"},{"metadata":{},"cell_type":"markdown","source":"#### Clustering According to Age and Spending Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"#initializations\nx=df[['Age','Spending Score (1-100)']].values\ninertia=[]\n\n#kmeans with various cluster-numbers\nfor i in range (1,11):\n    km=KMeans(n_clusters=i, random_state=33)\n    km.fit(x)\n    inertia.append(km.inertia_)\n\n#plot inertia\nind=np.arange(1,11)\nsns.lineplot(ind,inertia);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"km=KMeans(n_clusters=4,random_state=33)\nclusters=km.fit_predict(x)\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(x[:,1],x[:,0],hue=clusters);\nplt.title('Clusters');\nplt.legend(loc=(1.05,0.7));\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(x[:,1],x[:,0],hue=clusters);\nsns.scatterplot(km.cluster_centers_[:,1],km.cluster_centers_[:,0], color='red')\nplt.title('Clusters plus Cluster Centers');\nplt.legend(loc=(1.05,0.7));\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(x,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.title('Silhouette Graph');\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clustering using all variables (no standardization of data)"},{"metadata":{"trusted":true},"cell_type":"code","source":"x=df.values\ninertia=[]\n\nfor i in range(1,11):\n    km=KMeans(n_clusters=i,random_state=33)\n    km.fit(x)\n    inertia.append(km.inertia_)\n    \nsns.lineplot(range(1,11),inertia);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"km=KMeans(n_clusters=6,random_state=33)\nclusters=km.fit_predict(x)\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(x,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.title('Silhouette Graph');\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clustering using all variables (standardized data)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nx=sc.fit_transform(df.values)\ninertia=[]\n\nfor i in range(1,11):\n    km=KMeans(n_clusters=i,random_state=33)\n    km.fit(x)\n    inertia.append(km.inertia_)\n    \nsns.lineplot(range(1,11),inertia);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The 'elbow' graph is vague, and although eight seems to be the optimal number of clusters, we will try with six, seven, and eight clusters, and compare the silhouette graphs."},{"metadata":{"trusted":true},"cell_type":"code","source":"#six clusters\nkm=KMeans(n_clusters=6,random_state=33)\nclusters=km.fit_predict(x)\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(x,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#seven clusters\nkm=KMeans(n_clusters=7,random_state=33)\nclusters=km.fit_predict(x)\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(x,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#eight clusters\nkm=KMeans(n_clusters=8,random_state=33)\nclusters=km.fit_predict(x)\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(x,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The silhouette graphs confirm that eight is the best number of clusters, although, as is usually the case with real-world data that have more than two or three dimensions, the results aren't perfect."},{"metadata":{},"cell_type":"markdown","source":"# PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PCA on raw data"},{"metadata":{"trusted":true},"cell_type":"code","source":"pca=PCA(n_components=2)\nx=pca.fit_transform(df.values)\nsns.scatterplot(x[:,0],x[:,1]);\n\nplt.figure()\nsns.scatterplot(x[:,0],x[:,1],hue=df['Spending Score (1-100)']);\nplt.legend(loc=(1.01,0.64));\n\nplt.figure()\nsns.scatterplot(x[:,0],x[:,1],hue=df['Annual Income (k$)']);\nplt.legend(loc=(1.01,0.64));\n\nplt.figure()\nsns.scatterplot(x[:,0],x[:,1],hue=df['Age']);\nplt.legend(loc=(1.01,0.57));\n\nplt.figure()\nsns.scatterplot(x[:,0],x[:,1],hue=df['Male']);\nplt.legend(loc=(1.01,0.64));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#elbow graph to determine optimal n_clusters\ninertia=[]\nfor i in range(1,11):\n    km=KMeans(n_clusters=i,random_state=33)\n    km.fit(x)\n    inertia.append(km.inertia_)\n    \nsns.lineplot(range(1,11),inertia);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"km=KMeans(n_clusters=5, random_state=33)\nclusters=km.fit_predict(x)\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(x[:,0], x[:,1], hue =clusters);\nplt.title('Clusters');\nplt.legend(loc=(1.05,0.7));\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(x[:,0], x[:,1], hue =clusters);\nsns.scatterplot(km.cluster_centers_[:,0], km.cluster_centers_[:,1], color='red')\nplt.title('Clusters plus Cluster Centers');\nplt.legend(loc=(1.05,0.7));\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(x,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.title('Silhouette Graph');\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PCA on standardized data"},{"metadata":{"trusted":true},"cell_type":"code","source":"pca=PCA(n_components=2)\nsc=StandardScaler()\nx=pca.fit_transform(sc.fit_transform(df.values))\nsns.scatterplot(x[:,0],x[:,1]);\n\nplt.figure()\nsns.scatterplot(x[:,0],x[:,1],hue=df['Spending Score (1-100)']);\nplt.legend(loc=(1.01,0.64));\n\nplt.figure()\nsns.scatterplot(x[:,0],x[:,1],hue=df['Annual Income (k$)']);\nplt.legend(loc=(1.01,0.64));\n\nplt.figure()\nsns.scatterplot(x[:,0],x[:,1],hue=df['Age']);\nplt.legend(loc=(1.01,0.57));\n\nplt.figure()\nsns.scatterplot(x[:,0],x[:,1],hue=df['Male']);\nplt.legend(loc=(1.01,0.64));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#elbow graph to determine optimal n_clusters\ninertia=[]\nfor i in range(1,11):\n    km=KMeans(n_clusters=i,random_state=33)\n    km.fit(x)\n    inertia.append(km.inertia_)\n    \nsns.lineplot(range(1,11),inertia);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Which cluster number is best, four or six? Let's try both."},{"metadata":{"trusted":true},"cell_type":"code","source":"km=KMeans(n_clusters=4, random_state=33)\nclusters=km.fit_predict(x)\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(x[:,0], x[:,1], hue =clusters);\nplt.title('Clusters');\nplt.legend(loc=(1.05,0.7));\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(x[:,0], x[:,1], hue =clusters);\nsns.scatterplot(km.cluster_centers_[:,0], km.cluster_centers_[:,1], color='red')\nplt.title('Clusters plus Cluster Centers');\nplt.legend(loc=(1.05,0.7));\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(x,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.title('Silhouette Graph');\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"km=KMeans(n_clusters=6, random_state=33)\nclusters=km.fit_predict(x)\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(x[:,0], x[:,1], hue =clusters);\nplt.title('Clusters');\nplt.legend(loc=(1.05,0.7));\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(x[:,0], x[:,1], hue =clusters);\nsns.scatterplot(km.cluster_centers_[:,0], km.cluster_centers_[:,1], color='red')\nplt.title('Clusters plus Cluster Centers');\nplt.legend(loc=(1.05,0.7));\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(x,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.title('Silhouette Graph');\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clearly four clusters is a better option.\n\nSo, should we keep the clustering on raw PCA data, or standardized PCA data? In theory, we should keep the standardized one, but in practice the raw version seems better, both from visual inspection and from the silhouette figure. (Perhaps it worked that way because the data aren't very complex).\n\nNow let's move on to hierarchical clustering.\n"},{"metadata":{},"cell_type":"markdown","source":"### Hierarchical Clustering (Agglomerative)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import linkage\nfrom sklearn.cluster import AgglomerativeClustering as agglo","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Clustering According to Annual Income and Spending Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"x=df[['Annual Income (k$)','Spending Score (1-100)']].values\ndend=dendrogram(linkage(x, method='ward'))\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ag=agglo(n_clusters=5, affinity='euclidean',linkage='complete')\nclusters=ag.fit_predict(x)\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(x[:,0], x[:,1], hue =clusters);\nplt.title('Clusters');\nplt.legend(loc=(1.05,0.7));\n\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(x,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.title('Silhouette Graph');\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Clustering According to Age and Spending Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"x=df[['Age','Spending Score (1-100)']].values\nden=dendrogram(linkage(x,method='ward'))\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above dendrogram it is unclear whether the otimal number of clusters is three or four. Although four clusters seem to be best, we will try both options."},{"metadata":{"trusted":true},"cell_type":"code","source":"#four clusters\n\nag=agglo(n_clusters=4, affinity='euclidean',linkage='complete')\nclusters=ag.fit_predict(x)\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(x[:,1], x[:,0], hue =clusters);\nplt.title('Clusters');\nplt.legend(loc=(1.05,0.7));\n\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(x,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.title('Silhouette Graph');\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#three clusters\nag=agglo(n_clusters=3, affinity='euclidean',linkage='complete')\nclusters=ag.fit_predict(x)\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(x[:,1], x[:,0], hue =clusters);\nplt.title('Clusters');\nplt.legend(loc=(1.05,0.7));\n\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(x,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.title('Silhouette Graph');\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we see in the silhouette graph, the three-cluster is the worse of the two options, so we stick to four clusters, which was also suggested by the 'elbow' method used in k-means.\n\nNow, as with k-means, we will explore the scenario where we don't want to cluster based on a specific attribute, but want to use them all.\n"},{"metadata":{},"cell_type":"markdown","source":"### Clustering using all variables (standardized data)"},{"metadata":{"trusted":true},"cell_type":"code","source":"x=df.values\nden=dendrogram(linkage(x,method='ward'))\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#the dendrogram suggests six clusters\nag=agglo(n_clusters=6, affinity='euclidean',linkage='complete')\nclusters=ag.fit_predict(x)\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(x,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PCA on raw data"},{"metadata":{"trusted":true},"cell_type":"code","source":"pca=PCA(n_components=2)\nx=pca.fit_transform(df.values)\ndend=dendrogram(linkage(x,method='ward'))\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dendrogram suggests five clusters\nag=agglo(n_clusters=5, linkage='complete')\nclusters=ag.fit_predict(x)\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(x[:,0], x[:,1], hue =clusters);\nplt.title('Clusters');\nplt.legend(loc=(1.05,0.7));\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(x,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.title('Silhouette Graph');\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PCA on standardized data"},{"metadata":{"trusted":true},"cell_type":"code","source":"sc=StandardScaler()\npca=PCA(n_components=2)\nx=pca.fit_transform(sc.fit_transform(df.values))\ndend=dendrogram(linkage(x,method='ward'))\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dendrogram suggests four clusters\nag=agglo(n_clusters=4, linkage='complete')\nclusters=ag.fit_predict(x)\n\nplt.figure(figsize=(7,5));\nsns.scatterplot(x[:,0], x[:,1], hue =clusters);\nplt.title('Clusters');\nplt.legend(loc=(1.05,0.7));\n\n#Graphing Silhouette\nlabels=np.unique(clusters)\nn_clusters=labels.shape[0]\nsils=silhouette_samples(x,clusters,metric='euclidean')\ny_ax_lower, y_ax_upper=0, 0\nyticks=[]\nplt.figure(figsize=(6,5))\nfor i,c in enumerate(labels):\n    cluster_sil=sils[clusters==c]\n    cluster_sil.sort()\n    y_ax_upper +=len(cluster_sil)\n    color=cm.jet(float(i)/n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper),\n            cluster_sil, height=1.0,\n            edgecolor='none', color=color)\n    yticks.append((y_ax_lower+y_ax_upper)/2.)\n    y_ax_lower+=len(cluster_sil)\nsilhouette_avg=np.mean(sils)\nplt.axvline(silhouette_avg,color='red', linestyle='--')\nplt.yticks(yticks,labels+1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\nplt.title('Silhouette Graph');\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Agglomerative clustering yielded some interesting results, but k-means seems better, and for this project is picked as the best option."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}