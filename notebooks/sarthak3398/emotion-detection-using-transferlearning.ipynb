{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install scikit-plot","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\nfrom glob import glob\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom keras.utils import np_utils\nimport scikitplot\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\nfrom keras.models import Model\nfrom keras.layers import Dropout, Dense, Flatten,GlobalMaxPool2D,GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.losses import categorical_crossentropy\nfrom keras.regularizers import l2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.layers import Input\nfrom keras.utils import plot_model\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input/ck48-5-emotions/CK+48')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_PATH = \"../input/ck48-5-emotions/CK+48/\"\ntotal_images = 0\nfor dir in os.listdir(INPUT_PATH):\n    count = len(os.listdir(INPUT_PATH + dir))\n    total_images += count\n    print(f\"{dir} has {count} images\")\n\nprint(f\"total_images : {total_images}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TOP_EMOTIONS = ['anger', 'surprise', 'happy']\n# total_images\n# img_arr = np.empty(shape=(total_images, 48, 48, 1))\n# img_label = np.empty(shape=(total_images))\n# label_to_text = {}\n\n# idx = 0\n# label = 0\n# for dir_ in os.listdir(INPUT_PATH):\n#     if dir_ in  TOP_EMOTIONS:\n#         for f in os.listdir(INPUT_PATH + dir_ + \"/\"):\n#             img_arr[idx] = np.expand_dims(cv2.imread(INPUT_PATH + dir_ + \"/\" + f, 0), axis=2)\n#             img_label[idx] = label\n#             idx += 1\n#         label_to_text[label] = dir_\n#         label += 1\n\n# img_label = np_utils.to_categorical(img_label)\n\n\ne=0\ni=0\nimg_label=[]\nimg_arr=[]\nlabel_to_text = {}\n\nfor dir_ in os.listdir(INPUT_PATH):\n    if dir_ in TOP_EMOTIONS:\n        label_to_text[e] = dir_\n        for f in os.listdir(INPUT_PATH + dir_ + \"/\"):\n            img_arr.append( np.array(cv2.imread(INPUT_PATH + dir_ + \"/\" + f)))\n            img_label.append(e)\n            i+=1\n        print(f\"loaded all {dir_} images to numpy arrays\")  \n        e+=1\n        \nimg_arr,img_label = np.array(img_arr),np.array(img_label)\nprint(img_arr.shape,img_label.shape)\n\nimg_label = np_utils.to_categorical(img_label)\nimg_label.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_arr = img_arr / 255.\n\nX_train, X_test, y_train, y_test = train_test_split(img_arr, img_label,\n                                                    shuffle=True, stratify=img_label,\n                                                    train_size=0.7, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width = X_train.shape[1]\nimg_height = X_train.shape[2]\nimg_depth = X_train.shape[3]\nnum_classes = y_train.shape[1]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model= ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(img_width, img_height, img_depth)))\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model, show_shapes=True, show_layer_names=True, expand_nested=True, dpi=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# x = model.layers[-5].output\n# global_pool = GlobalMaxPool2D(name=\"global_pool\")(x)\n# predictions = Dense(num_classes, activation=\"softmax\")(global_pool)\n\n# model = Model(inputs=model.input, outputs=predictions)\n\n\nx = model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(128, activation='relu')(x) \npredictions = Dense(3, activation='softmax')(x)\nmodel = Model(model.input, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_model(model, show_shapes=True, show_layer_names=True, expand_nested=True, dpi=50, )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in model.layers[:38]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainAug = ImageDataGenerator(\n    rotation_range=30,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\")\n\nvalAug = ImageDataGenerator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainAug.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# valAug.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = EarlyStopping(\n    monitor='val_accuracy',\n    min_delta=0.00008,\n    patience=11,\n    verbose=1,\n    restore_best_weights=True,\n)\n\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_accuracy',\n    min_delta=0.0001,\n    factor=0.25,\n    patience=4,\n    min_lr=1e-7,\n    verbose=1,\n)\n\ncallbacks = [\n    early_stopping,\n    lr_scheduler,\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nepochs = 40\nopt = Adam(lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n        loss='categorical_crossentropy',\n        optimizer=opt,\n        metrics=['accuracy']\n)\n\nhistory = model.fit_generator(\n    trainAug.flow(X_train, y_train, batch_size=batch_size),\n    validation_data=(X_test, y_test),\n    steps_per_epoch=len(X_train) / batch_size,\n    epochs=epochs,\n    callbacks=callbacks,\n    use_multiprocessing=True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set()\nfig = plt.figure(0, (12, 4))\n\nax = plt.subplot(1, 2, 1)\nsns.lineplot(history.epoch, history.history['accuracy'], label='train')\nsns.lineplot(history.epoch, history.history['val_accuracy'], label='valid')\nplt.title('Accuracy')\nplt.tight_layout()\n\nax = plt.subplot(1, 2, 2)\nsns.lineplot(history.epoch, history.history['loss'], label='train')\nsns.lineplot(history.epoch, history.history['val_loss'], label='valid')\nplt.title('Loss')\nplt.tight_layout()\n\n#plt.savefig('epoch_history_resnet7-3-split.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat_test = np.argmax(model.predict(X_test), axis=1)\nytest_ = np.argmax(y_test, axis=1)\n\nscikitplot.metrics.plot_confusion_matrix(ytest_, yhat_test, figsize=(7,7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}