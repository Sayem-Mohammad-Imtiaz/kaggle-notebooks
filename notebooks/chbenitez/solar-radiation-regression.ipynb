{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Predicción de la Radiación Solar"},{"metadata":{},"cell_type":"markdown","source":"Vamos a intentar predecir la radiación solar dependiendo distintos factores como la hora del día, la temperatura, presión, etc..\n\nPueden encontrar este dataset en Kaggle: \n\nhttps://www.kaggle.com/dronio/SolarEnergy\n\nTener una herramienta que prediga la cantidad de radiación solar que habrá, dependiendo diversos factores, nos permitirá ver si es rentable o no invertir en paneles solares para alimentar nuestros aparatos electros hogareños, que cantidad de energía vamos a tener disponible durante el año y distintas ventajas relacionadas con el tema que un especialista en el área podria descubrir."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importamos las librerias\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cargamos los datos\ndf_SolarRad = pd.read_csv(\"../input/SolarEnergy/SolarPrediction.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_SolarRad.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_SolarRad.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocesamiento"},{"metadata":{},"cell_type":"markdown","source":"Vamos a trabajar sobre la columna **Time**, vamos a tomar los horarios y transformarlos en nuevos features (**Morning, Afternoon, Night** y **EarlyMorning**)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cortamos los datos de la columna tomando los primeros 2 valores y transformandolos en enteros\ndf_SolarRad[\"Time\"] = df_SolarRad.Time.str.slice(stop=2).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_SolarRad[\"Time\"].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que los datos se tomaron en distintos horarios.\n\nVamos a realizar la transformación a nuevos features "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creamos la nueva columna y la llenamos con valores Booleanos en caso de que cumpla la condicion\ndf_SolarRad[\"Morning\"] = (df_SolarRad[\"Time\"] >= 6) & (df_SolarRad[\"Time\"] <= 12)\ndf_SolarRad[\"Afternoon\"] = (df_SolarRad[\"Time\"] >= 13) & (df_SolarRad[\"Time\"] <= 19)\ndf_SolarRad[\"Night\"] = (df_SolarRad[\"Time\"] >= 20) & (df_SolarRad[\"Time\"] <= 23)\ndf_SolarRad[\"EarlyMorning\"] = (df_SolarRad[\"Time\"] >= 0) & (df_SolarRad[\"Time\"] <= 5)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Vemos que se crearon correctamente\ndf_SolarRad.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para que esto funcione tenemos que transformar los valores Booleanos a númericos, para esto vamos a utilizar una herramienta muy útil de la librería sklearn: LabelEncoder\n\nEsta herramienta nos permite transformar y etiquetar categorías a variables numéricas. Generalmente se utiliza cuando tenemos un problema de Clasificación sobre nuestra variable objetivo (**y**), pero en este caso nos va a ser útil.\n\nEs recomendable aprender mas sobre esta técnica: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nlab_enc = LabelEncoder()\n#Utilizamos fit_transform ya que entrenamos y aplicamos el cambio sobre el mismo conjunto de datos\ndf_SolarRad['Morning'] = lab_enc.fit_transform(df_SolarRad['Morning'])\ndf_SolarRad['Afternoon'] = lab_enc.fit_transform(df_SolarRad['Afternoon'])\ndf_SolarRad['Night'] = lab_enc.fit_transform(df_SolarRad['Night'])\ndf_SolarRad['EarlyMorning'] = lab_enc.fit_transform(df_SolarRad['EarlyMorning'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_SolarRad[[\"Time\",\"Morning\",\"Afternoon\",\"Night\",\"EarlyMorning\"]].tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que el cambio se aplico correctamente, a la hora 0 tenemos el valor 1 que nos indica que es de madrugada \n\nVamos a hacer lo mismo con las columnas **TimeSunRise** y **TimeSunSet**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_SolarRad[\"TimeSunRise\"] = df_SolarRad.TimeSunRise.str.slice(stop=2).astype(int)\ndf_SolarRad[\"TimeSunSet\"] = df_SolarRad.TimeSunSet.str.slice(stop=2).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_SolarRad[\"TimeSunRise\"].describe()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_SolarRad[\"TimeSunSet\"].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que los datos de estas dos columnas no varían, asique no van a sumar valor aplicarlos al modelo"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Eliminamos las columnas\ndf_SolarRad = df_SolarRad.drop(columns=[\"TimeSunSet\",\"TimeSunRise\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veamos si tenemos **outliers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize=(10,6)) \nplt.title(\"Radiation\") \nsns.boxplot(df_SolarRad[\"Radiation\"]) \n\nplt.figure(2, figsize=(10,6))\nplt.title(\"Temperatura\")\nsns.boxplot(df_SolarRad[\"Temperature\"])\n\nplt.figure(3, figsize=(10,6)) \nplt.title(\"Presion\")\nsns.boxplot(df_SolarRad[\"Pressure\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que son pocos. Podemos quitarlos a medida que entrenamos los modelos y probar como afecta al **score** de nuestro modelo"},{"metadata":{},"cell_type":"markdown","source":"Vamos a visualizar la correlación de los datos con nuestro objetivo **Radiation**, esto nos va a permitir seleccionar que features son mas relevante para utilizarlas con nuestro modelo\n\nVamos a generar un mapa de calor utilizando Seaborn: https://seaborn.pydata.org/generated/seaborn.heatmap.html"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.heatmap(df_SolarRad.corr(),cmap='coolwarm',annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vamos a filtrar el dataset con las columnas que tengan correlación alta o positiva"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_SolarRad[[\"Temperature\",\"Pressure\",\"Morning\",\"Afternoon\"]] #Nuestros features mas relevantes\ny = df_SolarRad[\"Radiation\"] #Separamos nuestro objetivo","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning"},{"metadata":{},"cell_type":"markdown","source":"Vamos a probar distintos modelos de **regresión** a ver como funcionan nuestros modelos. Inicialmente vamos a cargar nuestros modelos con los **hiperparametros** por defecto, después vamos a pasar a la etapa de optimización."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importamos librerias para evaluar nuestros modelos\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Primero vamos a dividir nuestro dataset en 4 partes:\n - X_train: Datos para entrenar el modelos \n - y_train: Nuestro objetivo a predecir que utilizaremos para entrenar el modelo\n - X_test: Conjunto de datos al cual le aplicaremos la predicción\n - y_test: Conjunto de datos objetivo con las que compararemos los resultados de la predicción para ver que tan bien funciona el modelo\n \n**y_pred**: Es el resultado del modelo aplicado al conjunto de X_test que se va a comparar con **y_test** para medir el error del modelo\n\nGeneralmente la divición se hace un 80%(train), 20%(test):\n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Linear Regression"},{"metadata":{},"cell_type":"markdown","source":"Ver hiperparametros del modelo: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nregression_linear = LinearRegression()\n\nregression_linear.fit(X_train, y_train) #Entrenamos el modelo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = regression_linear.predict(X_test) #Aplicamos la prediccion","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Grafiquemos el valor de nuestra **predicción** (y_pred) y los **valores reales** (relación 1:1)"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.scatter(y_test,y_pred) #Valores predichos \nplt.plot(y_test, y_test, 'r') #Nuestro valor real\nplt.xlabel('Valor Real', fontsize = 15)  \nplt.ylabel('Prediccion', fontsize = 15)  \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La linea roja son nuestros valores reales y los puntos azules nuestras predicciones.\nVemos que los puntos siguen el patrón de la linea roja, pero una gran cantidad cae fuera. \n\nVamos a medir el error en nuestras predicciones con el **RMSE**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Aplicamos la raiz cuadrada (np.sqrt) al MSE para obtener el RMSE\nrmse = np.sqrt(mean_squared_error(y_test, y_pred)) \nprint(\"RMSE: \", rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que nuestro **error mínimo** es de **186.3**, esto quiere decir que nuestra predicción esta alejada 186 watts por metro^2 (unidad de medida de la radiación solar), del **valor real**.\n\nVeamos como nos dio el R^2 de nuestro modelo"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"R^2: \", r2_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Es un valor bastante bajo, hay que tener en cuenta que aplicamos el modelo por defecto sin tunear los hiperparametros o realizar algún tipo de optimización.\n\nVamos a probar otros modelos de regresión a ver si esto mejora"},{"metadata":{},"cell_type":"markdown","source":"### Decision Tree Regressor"},{"metadata":{},"cell_type":"markdown","source":"Ver hiperparametros del modelo: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor \n\ntree_reg = DecisionTreeRegressor(random_state =12)\n\ntree_reg.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = tree_reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(\"RMSE: \", rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_test,y_pred)\nplt.plot(y_test, y_test, 'r')\nplt.xlabel('Valor Real', fontsize = 15)  \nplt.ylabel('Prediccion', fontsize = 15)  \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"R^2: \", r2_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que con el modelo de **Decision Tree** bajo nuestro **RMSE** a **158**, y nuestro **score** subió a 75, esto es una buena señal de mejora.\n\nSigamos viendo ejemplos con otros modelos"},{"metadata":{},"cell_type":"markdown","source":"### Random Forest"},{"metadata":{},"cell_type":"markdown","source":"Ver hiperparametros del modelo: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n\nEn este caso ya definimos el hiperparamentro **n_estimators**, el cual es la cantidad de árboles a entrenar dentro de nuestro bosque"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nregression_RF = RandomForestRegressor(n_estimators = 200, random_state =12)\nregression_RF.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = regression_RF.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(\"RMSE: \", rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_test,y_pred)\nplt.plot(y_test, y_test, 'r')\nplt.xlabel('Valor Real', fontsize = 15)  \nplt.ylabel('Prediccion', fontsize = 15)  \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que el RMSE y el R2 no cambiaron"},{"metadata":{},"cell_type":"markdown","source":"# Optimizacion"},{"metadata":{},"cell_type":"markdown","source":"Existen varias técnicas para optimizar nuestros modelos\n- Cross Validation: https://scikit-learn.org/stable/modules/cross_validation.html\n- Randomized Search: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n- Gradient Descent: Es mas utilizado en **Deep Learning**\n- Grid Search: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n\nVamos a utilizar este ultimo"},{"metadata":{},"cell_type":"markdown","source":"### GridSearch"},{"metadata":{},"cell_type":"markdown","source":"Esta técnica se basa en **comparar los hiperparametros** del modelo, cargados en una grilla que nosotros definimos, Grid Search nos va a brindar los mejores parámetros a utilizar"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cargamos la grilla con los hiperparametros a comparar\nparam_grid ={'max_depth': [4, 6, 8, 10, 12], 'max_features': [1, 2, 3, 4]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_reg = DecisionTreeRegressor(random_state=12)\n#Pasamos los parametros a GridSearch \ngrid_search = GridSearchCV(tree_reg, param_grid, cv=5,\n                           scoring='r2', \n                           return_train_score=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Entrenamos\ngrid_search.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Vemos los resultados de GridSearch \nresults = pd.DataFrame(grid_search.cv_results_)\nresults.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"El mejor score es:\", grid_search.best_score_) \nprint(\"Mejores parametros entcontrados:\\n\", grid_search.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vemos que para este conjunto de datos, el mejor score es **75** con la métrica de **R2**\n\nVamos a utilizar el mejor estimador que nos brindo GridSearch"},{"metadata":{"trusted":true},"cell_type":"code","source":"optimised_Tree = grid_search.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tomamos un ejemplo del conjunto de test\ntest_predict= X_test[50:51]\ntest_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Radiacion solar:\",optimised_Tree.predict(test_predict), \"watts por metro^2\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}