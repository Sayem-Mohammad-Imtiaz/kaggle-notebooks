{"cells":[{"metadata":{"_uuid":"94401c405b8ede7d9c135e7c0f7ac613885a4ca2"},"cell_type":"markdown","source":"# Classification Algorithm Comparison\nWhen beginneging in the field of machine learning, sometimes it becmes tough to chose a appropriate algorithm for prediction.\n\nThis kernel will help the beginners to compare various algorithms used for classification.\n\n## What is classification.?\nClassification is the process of predicting the class of given data points. Classes are sometimes called as targets/ labels or categories. Classification predictive modeling is the task of approximating a mapping function (f) from input variables (X) to discrete output variables (y).\nFor example, spam detection in email service providers can be identified as a classification problem. This is s binary classification since there are only 2 classes as spam and not spam. A classifier utilizes some training data to understand how given input variables relate to the class. In this case, known spam and non-spam emails have to be used as the training data. When the classifier is trained accurately, it can be used to detect an unknown email.\nClassification belongs to the category of supervised learning where the targets also provided with the input data. There are many applications in classification in many domains such as in credit approval, medical diagnosis, target marketing etc.\n\nThere are two types of learners in classification as lazy learners and eager learners.\n* Lazy learners :- Lazy learners simply store the training data and wait until a testing data appear. When it does, classification is conducted based on the most related data in the stored training data. Compared to eager learners, lazy learners have less training time but more time in predicting.\nEx. k-nearest neighbor, Case-based reasoning\n* Eager learners :-Eager learners construct a classification model based on the given training data before receiving data for classification. It must be able to commit to a single hypothesis that covers the entire instance space. Due to the model construction, eager learners take a long time for train and less time to predict.\nEx. Decision Tree, Naive Bayes, Artificial Neural Networks\n\n(src- https://towardsdatascience.com/machine-learning-classifiers-a5cc4e1b0623)\n\n**Although the performance of the algorithms will only give a ballpark estimation of how a particular algo performs. Rest it depends on the person on what kind of tweaking do they do to get higher accuracy.**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ndf=pd.read_csv(\"../input/winequality-red.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Getting the consolidated information about the dataset\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9367ac9f33b0620a2a6d6435361f0dc9676be50b"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nsns.set_color_codes(\"pastel\")\n%matplotlib inline\n\nsns.barplot(df.quality,df.alcohol)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"471a9a1ce57c1c1d9b6c03612ff04d909f4b1ce8"},"cell_type":"code","source":"#relation of features with other features\n\nplt.style.use('ggplot')\nfig=plt.figure(figsize=(15,10))\nsns.heatmap(df.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2feb31852f2854f7d05aa969e5c298757b1ad88"},"cell_type":"markdown","source":"* The heatmap shows some interesting relations like the column 'ciric acid' is highly positively correlated to the column fixed acidity.\n* The target column 'quality' is strongly correlated to the alcohol content of the wine(which was to be expexted)\n* The bar plot shows an increase in alcohol content of the wine as the quality increases."},{"metadata":{"trusted":true,"_uuid":"6fd89a68cb9fd2d2aff86036c677899bf57ba73a"},"cell_type":"code","source":"#import various ML algorithms to be used from the library\n\nfrom sklearn.svm import SVC,NuSVC\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB,MultinomialNB\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nclassification_algos_name = [\"SVC\", \"NuSVC\", \"KNeighborsClassifier\", \"GaussianNB\", \"MultinomialNB\", \"SGDClassifier\", \"LogisticRegression\", \"DecisionTreeClassifier\",\n                            \"ExtraTreeClassifier\", \"QuadraticDiscriminantAnalysis\", \"LinearDiscriminantAnalysis\", \"RandomForestClassifier\", \"AdaBoostClassifier\",\n                            \"GradientBoostingClassifier\", \"XGBClassifier\"]\nclassification_algos=[SVC(),\n                      NuSVC(nu=0.285),\n                      KNeighborsClassifier(),\n                      GaussianNB(),\n                      MultinomialNB(),\n                      SGDClassifier(),\n                      LogisticRegression(),\n                      DecisionTreeClassifier(),\n                      ExtraTreeClassifier(),\n                      QuadraticDiscriminantAnalysis(),\n                      LinearDiscriminantAnalysis(),\n                      RandomForestClassifier(),\n                      AdaBoostClassifier(),\n                      GradientBoostingClassifier(),\n                      XGBClassifier()]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e7e84222361e0a858ba28581910575a934ba90dc"},"cell_type":"markdown","source":"# Preprcessing and cleaning of data set\n"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"8ae44f93d2a362ce9406e7de49ed6a7ce8bd8ea4"},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25c7b2db8b6a3ae85a9407fe73321949d0c2f017"},"cell_type":"markdown","source":"Since the data set contains no empty value cleaning not required."},{"metadata":{"trusted":true,"_uuid":"644781d2cbe9e5f1926e9a557a2f2d57658b2acf"},"cell_type":"code","source":"#Converting discreate values of the quality column into categorial values\n\nbins=(2,6.5,8)\ncategory=[\"bad\",\"good\"]\ndf[\"quality\"]=pd.cut(df[\"quality\"],bins=bins, labels=category)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"391cdeb45bc85442918e14d3eb04a01894833933"},"cell_type":"code","source":"le=LabelEncoder()\ndf[\"quality\"]=le.fit_transform(df[\"quality\"])\ndf[\"quality\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dcd9698e8f28e0d210024775da3a9735c23ad56c"},"cell_type":"code","source":"df[\"quality\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e3919ae6c3138e7771b58be62bd011622930fe8"},"cell_type":"code","source":"x_train, y_test, x_train_target, y_test_target = train_test_split(df.drop(\"quality\", axis=1), df[\"quality\"], test_size = 0.25, random_state = 1)\nprint(x_train.shape, \" \",y_test_target.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"896a6246ac96ba0d5e36a74d1bba9fc7a9be5ee8"},"cell_type":"code","source":"accuracy_score_list = []\nfor mod in classification_algos:\n    model = mod\n    model.fit(x_train, x_train_target)\n    pred = model.predict(y_test)\n    accuracy_score_list.append(accuracy_score(y_test_target,pred))\nfor idx,i in enumerate(accuracy_score_list):\n    print(classification_algos_name[idx],\" \",i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7f422b4f9d780030c82258b083305d14b34e359"},"cell_type":"code","source":"from bokeh.io import output_notebook\ndata = pd.DataFrame({\"algorithms\": classification_algos_name, \"accuracy_score\": accuracy_score_list})\ndata['color'] = ['#440154', '#404387', '#29788E', '#22A784', '#79D151', '#FDE724','#30678D','#084594', '#2171b5', '#4292c6', '#6baed6', '#9ecae1', '#c6dbef', '#deebf7', '#f7fbff']\noutput_notebook()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9ddabd37a16c3c2001a29ea421bf3544cbae4ed"},"cell_type":"code","source":"from bokeh.io import show, output_file\nfrom bokeh.models import ColumnDataSource, FactorRange\nfrom bokeh.plotting import figure\nfrom bokeh.palettes import Spectral6\nfrom bokeh.transform import factor_cmap\n\nsource = ColumnDataSource(data=data)\n\np = figure(x_range=data['algorithms'],\n           y_range=(0,1),\n           plot_width = 800,\n           plot_height = 600,\n           title = \"Comparison\",\n           tools=\"hover\",\n           tooltips=\"@algorithms: @accuracy_score\")\np.vbar(x='algorithms', top='accuracy_score',color= 'color',\n       width=0.95, source=source)\n\np.xgrid.grid_line_color = None\np.xaxis.major_label_orientation = 120\noutput_file('comparison.html')\nshow(p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fee3f5fb498294026833957d621700df6f6adc6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a36dc2e65eaccc3d8a57f8c14f3429fac9ebe48f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c7a7f74a5a464150486ea1fd82f447e95c2db9c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}