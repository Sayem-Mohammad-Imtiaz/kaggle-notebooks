{"cells":[{"metadata":{"_uuid":"eb9a09efb38315457357801f54b57ffdc7da553f"},"cell_type":"markdown","source":"In this kernel I am going to do some basic EDA on the data. Also I am going to build a classifer which will predict what features effects customer retention."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('../input/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c02445646f24001f8a37a84f8e62761cf2e37fb"},"cell_type":"markdown","source":"### Exploring Relation between Churn and Fetures\n\nLets take a look at what factors strongly influence Churn ratio"},{"metadata":{"trusted":true,"_uuid":"37c4ca419ce24a0bfaff9a77e77087cebc128d94"},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\nSMALL_SIZE = 15\nMEDIUM_SIZE = 17\nBIGGER_SIZE = 20\n\nplt.rc('font', size=SMALL_SIZE)\nplt.rc('axes', titlesize=SMALL_SIZE)\nplt.rc('axes', labelsize=MEDIUM_SIZE)\nplt.rc('xtick', labelsize=SMALL_SIZE)\nplt.rc('ytick', labelsize=SMALL_SIZE)\nplt.rc('legend', fontsize=SMALL_SIZE)\nplt.rc('figure', titlesize=BIGGER_SIZE)\n\ndf_eda = df.copy()\ncols = df_eda.columns.tolist()\ncols = set(cols) - set(['customerID', 'TotalCharges', 'tenure', 'MonthlyCharges', 'Churn'])\n\nfig, *axes = plt.subplots(nrows=8, ncols=2, figsize=(20,35))\naxes = np.array(axes).ravel()\n\nfor c,i in enumerate(cols):\n    df_eda.groupby(['Churn', i]).size().unstack(level=0).plot(kind='barh', ax=axes[c])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97e94051acc8f7414024f7e7ccf7be6c292016ff"},"cell_type":"markdown","source":"### Preprocessing\n\nNext I am going to do some preprocessing for machine learning models. "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"Y = df['Churn'].map({\"Yes\": 1, \"No\": 0})\ndf = df.drop('Churn', 1);\ndf = df.drop('customerID', 1);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"deedf82e76b1ffd73fdbfdf20ffaa3e3bcc3a1b3"},"cell_type":"code","source":"#Check dtypes of columns\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21b100f7b3d4b13f6ed2834b0ff25e4c872e7998"},"cell_type":"code","source":"#Cast `TotalCharges` to float\ndf['TotalCharges'] = df['TotalCharges'].apply(pd.to_numeric, errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13f44e9bd561cc5b326e45499996b707fe5c6fd7"},"cell_type":"code","source":"#Check NaN values in columns\ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02cf202416f37044f40ba9008213ee0d198f69b4"},"cell_type":"code","source":"#Fill NaN with 0 in `TotalCharges`\ndf['TotalCharges'] = df['TotalCharges'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee4bf3983841b6e83ca0f0c7216213227c9e614c"},"cell_type":"code","source":"c_single = ('Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'gender')\nc_all = ('MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaymentMethod')\n\ndf_categorical = df.join(pd.concat([pd.get_dummies(df[col], prefix=col, drop_first=True) for col in c_single] + [pd.get_dummies(df[col], prefix=col) for col in c_all], axis=1))\ndf_categorical.drop(list(c_single + c_all), inplace=True, axis=1)\ndf_categorical.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b05b77e21098abf353d25a5d39d57521a8f5c6a6"},"cell_type":"markdown","source":"### Churn Prediction\n\nI am going to test three model i.e. *Logistic Regression, Decision Tree and Random Forest* with *ROC AUC* as evaluation metric."},{"metadata":{"trusted":true,"_uuid":"20474ff8830c236141fd3ce9fa2dc3c1eceafc8c"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\nx_train, x_test, y_train, y_test = train_test_split(df_categorical, Y, test_size=0.2, random_state=42)\nclfs = [LogisticRegression(C=0.1, random_state=0), SVC(C=0.01, degree=2, gamma='auto', probability=True, random_state=0), DecisionTreeClassifier(random_state=0, max_depth=5, criterion='entropy'), RandomForestClassifier(max_depth=6, criterion='entropy', n_estimators=10, random_state=0)]\nclf_labels = ['Logistic Regression', 'SVC', 'DecisionTreeClassifier', 'RandomForestClassifier']\nfor clf, label in zip(clfs, clf_labels):\n    score = cross_val_score(estimator=clf, X=x_train, y=y_train, cv=10, scoring='roc_auc')\n    print(\"ROC AUC {} Score Mean: {}, Std: {}\".format(label, round(score.mean(),2), round(score.std(),3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6c50bb914847827d93449a9ce2b39504634ec9b"},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\n\nplt.rc('legend', fontsize=10)\ncolors = ['black', 'orange', 'blue', 'green']\nline_styles = [':', '--', '-.', '-']\n\nfor clf, label, clr, ls in zip(clfs, clf_labels, colors, line_styles):\n    y_pred = clf.fit(x_train, y_train).predict_proba(x_test)[:,1]\n    fpr, tpr, threashold = roc_curve(y_true=y_test, y_score=y_pred)\n    roc_auc = auc(x=fpr, y=tpr)\n    plt.plot(fpr, tpr, color=clr, linestyle=ls, label=\"{} (auc = {})\".format(label, round(roc_auc, 2)))\n\nplt.legend(loc='lower right')\nplt.plot([0,1], [0,1], linestyle='--', color='gray', linewidth=2)\nplt.xlim([-0.1, 1.1])\nplt.ylim([-0.1, 1.1])\nplt.grid()\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa63a376c0d2892aab9106ff93553dfe3451564f"},"cell_type":"markdown","source":"### Confusion Matrix\n\nRandom Forest seems to perform best as compared to others. So I will plot confusion matrix for Random Forest only."},{"metadata":{"trusted":true,"_uuid":"64a2cd387edef996cdcb9bf0fa13c72f166162da"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sn\n\ny_pred = clfs[-1].fit(x_train, y_train).predict(x_test)\n\nax= plt.subplot()\nsn.heatmap(confusion_matrix(y_test, y_pred), annot=True, ax=ax, cmap='Blues', fmt='g')\nax.set_xlabel('Predicted labels');\nax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix');","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}