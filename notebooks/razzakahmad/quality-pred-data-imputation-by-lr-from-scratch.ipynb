{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-06T14:50:01.96625Z","iopub.execute_input":"2021-07-06T14:50:01.966681Z","iopub.status.idle":"2021-07-06T14:50:01.9774Z","shell.execute_reply.started":"2021-07-06T14:50:01.966621Z","shell.execute_reply":"2021-07-06T14:50:01.97602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import optimize\n\ndf=pd.read_csv('/kaggle/input/wine-quality/winequalityN.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:50:12.761358Z","iopub.execute_input":"2021-07-06T14:50:12.761815Z","iopub.status.idle":"2021-07-06T14:50:12.97077Z","shell.execute_reply.started":"2021-07-06T14:50:12.761756Z","shell.execute_reply":"2021-07-06T14:50:12.969884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df.columns:\n    if df[i].dtype== 'O':\n        df[i].replace({'white':1,'red':0},inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:50:16.447769Z","iopub.execute_input":"2021-07-06T14:50:16.448232Z","iopub.status.idle":"2021-07-06T14:50:16.461921Z","shell.execute_reply.started":"2021-07-06T14:50:16.448194Z","shell.execute_reply":"2021-07-06T14:50:16.460192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().any()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:50:18.35253Z","iopub.execute_input":"2021-07-06T14:50:18.353186Z","iopub.status.idle":"2021-07-06T14:50:18.364973Z","shell.execute_reply.started":"2021-07-06T14:50:18.353147Z","shell.execute_reply":"2021-07-06T14:50:18.363977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nNow i will impute the missing values using linear regression, based on correlation between each null column (treated as target column) and all other columns/features. I will be using threshold correlation of (corr>0.25 | corr<-0.25) between target column and other features.  ","metadata":{}},{"cell_type":"code","source":"corr_mat=df.corr()\ncorr_mat","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:50:20.996935Z","iopub.execute_input":"2021-07-06T14:50:20.997577Z","iopub.status.idle":"2021-07-06T14:50:21.032894Z","shell.execute_reply.started":"2021-07-06T14:50:20.997536Z","shell.execute_reply":"2021-07-06T14:50:21.031776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1=df.copy()\ndf_null=df1.loc[:,(df1.isnull().sum()>0)]\nnull_cols=df_null.columns\nnull_cols","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:50:23.937384Z","iopub.execute_input":"2021-07-06T14:50:23.938006Z","iopub.status.idle":"2021-07-06T14:50:23.956441Z","shell.execute_reply.started":"2021-07-06T14:50:23.937948Z","shell.execute_reply":"2021-07-06T14:50:23.955295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**All Functions used for imputation**","metadata":{}},{"cell_type":"code","source":"\ndef normalization(X):\n    mu=np.mean(X,axis=0)\n    sigma=np.std(X,axis=0)\n    X_norm=np.zeros(X.shape)\n    m,n=X.shape\n    i=0\n    while i<n:    \n        X_norm[:,i]=(X[:,i]-np.mean(X[:,i]))/(np.std(X[:,i]))\n        i+=1\n\n    return X_norm,mu,sigma\n\n# LINEAR REGRESSION (FROM SCRATCH)\n\ndef lin_reg_CF(theta,X,y,lambda_):\n    \n    m=X.shape[0]\n    X=np.concatenate([np.ones((m,1)),X],axis=1)\n    J = 0\n    grad = np.zeros(theta.shape)\n\n    h = X.dot(theta)\n    J = (1 / (2*m)) * np.sum(np.square(h - y)) + (lambda_ / (2*m)) * np.sum(np.square(theta[1:]))\n    grad= np.dot((np.dot(X,theta)-y),X)*(1/m)\n    grad[1:] = grad[1:] + (lambda_ / m) * theta[1:]\n    \n    return J,grad\n\ndef prediction(X,theta):\n    X=np.concatenate([np.ones((X.shape[0],1)),X],axis=1)\n    return np.dot(X,theta)\n\ndef preprocessing(cols,df1,target_col):\n\n    df1.dropna(axis=0,inplace=True)\n    new_df=df1.loc[:,cols]\n    y=new_df.loc[:,target_col].to_numpy()\n    X=new_df.iloc[:, new_df.columns!=target_col].to_numpy()\n\n    X_norm,mu,sigma=normalization(X)\n    return X_norm,y,mu,sigma\n\n# This function will impute every null values in the dataset using Linear regression.\ndef Imputation_LR(null_cols,df):\n\n    for i in null_cols:\n        df1=df.copy()\n\n        s=(corr_mat[i]>0.25) | (corr_mat[i]<-0.25)  \n        new_df_cols=df1.columns[s]\n        \n        X, y, mu, sigma= preprocessing(new_df_cols,df1,i)        \n        initial_theta= np.zeros(X.shape[1]+1)\n        \n        # Here scipy's advanced optimization method are utilized. It takes the cost function and other parameters which \n        # must accurately return cost and gradient to do accurate internal update of parameters after each iteration. \n        # It also internally select best value of learning rate (alpha).\n        res= optimize.minimize(lin_reg_CF,initial_theta,(X,y,0),jac=True,method='TNC',)\n        \n        # Preparing to fill null rows of ith (null) column.\n        null_rows_index= df[i].index[df[i].apply(np.isnan)]\n        null_rows_df= df.loc[null_rows_index,new_df_cols]\n        # Dropping the target col or ith col because we have to predict that column (containing NAN values).\n        null_rows_df.drop([i],axis=1,inplace=True)\n\n        # Filling the nan values of other features (if any) by there mean for the prediction of null values.\n        null_rows_df.fillna(np.mean(df),inplace=True)\n        \n        # Normalizing the features null_rows_df by the main Dataframe's (mean and std) for predictions.\n        null_rows_df -= mu\n        null_rows_df /= sigma\n\n        # res.x contains optimal or trained parameters or coefficients of ith LR model.\n        null_values_prediction=prediction(null_rows_df,res.x)\n\n        # Now filling or imputing the missing values, into our main dataframe (df), generated by our ith linear regression model for            ith null column. \n        df.loc[null_rows_index,i]= null_values_prediction          \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:50:26.274331Z","iopub.execute_input":"2021-07-06T14:50:26.274964Z","iopub.status.idle":"2021-07-06T14:50:26.295329Z","shell.execute_reply.started":"2021-07-06T14:50:26.274916Z","shell.execute_reply":"2021-07-06T14:50:26.294297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:50:29.688843Z","iopub.execute_input":"2021-07-06T14:50:29.689434Z","iopub.status.idle":"2021-07-06T14:50:29.702787Z","shell.execute_reply.started":"2021-07-06T14:50:29.68938Z","shell.execute_reply":"2021-07-06T14:50:29.700657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final=Imputation_LR(null_cols,df)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:50:31.84927Z","iopub.execute_input":"2021-07-06T14:50:31.849999Z","iopub.status.idle":"2021-07-06T14:50:32.079812Z","shell.execute_reply.started":"2021-07-06T14:50:31.849941Z","shell.execute_reply":"2021-07-06T14:50:32.078522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:50:34.117558Z","iopub.execute_input":"2021-07-06T14:50:34.118024Z","iopub.status.idle":"2021-07-06T14:50:34.129094Z","shell.execute_reply.started":"2021-07-06T14:50:34.117985Z","shell.execute_reply":"2021-07-06T14:50:34.128001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Linear regression and Ridge Regression**\n\nI will use Ridge Reg (check lin_reg_CF() function for formula) which will help us in seeing model's bias and variance.","metadata":{}},{"cell_type":"code","source":"df2=df.copy()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:50:37.957267Z","iopub.execute_input":"2021-07-06T14:50:37.957896Z","iopub.status.idle":"2021-07-06T14:50:37.962473Z","shell.execute_reply.started":"2021-07-06T14:50:37.957831Z","shell.execute_reply":"2021-07-06T14:50:37.961491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.max()-df2.min()","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:50:39.751668Z","iopub.execute_input":"2021-07-06T14:50:39.752205Z","iopub.status.idle":"2021-07-06T14:50:39.762577Z","shell.execute_reply.started":"2021-07-06T14:50:39.752171Z","shell.execute_reply":"2021-07-06T14:50:39.761752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is the reason why we need to do normalization because it will avoid the biasness of features with comparatively higher values than the features with lower values.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX,y=  df2.iloc[:,:-1].to_numpy(),  df2.iloc[:,-1].to_numpy()\nX_train,x_cv_test,y_train,y_cv_test= train_test_split(X,y,train_size=0.6,random_state=43)\nX_cv, X_test, y_cv, y_test = train_test_split(x_cv_test,y_cv_test,train_size=0.5,random_state=43)\n\nX_train.shape,X_cv.shape,X_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:50:43.957373Z","iopub.execute_input":"2021-07-06T14:50:43.957912Z","iopub.status.idle":"2021-07-06T14:50:44.275833Z","shell.execute_reply.started":"2021-07-06T14:50:43.957877Z","shell.execute_reply":"2021-07-06T14:50:44.275007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NORMALZING THE FEATURES FOR TRAINING SET\nm,n=X_train.shape\nX_train_norm,mu,sigma=normalization(X_train)\n\n# normalizing the features of cross validation set\nX_cv -= mu\nX_cv /= sigma\n\n# Normalizing the features of test set\nX_test -= mu\nX_test /= sigma","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:50:47.953428Z","iopub.execute_input":"2021-07-06T14:50:47.953952Z","iopub.status.idle":"2021-07-06T14:50:47.960799Z","shell.execute_reply.started":"2021-07-06T14:50:47.95392Z","shell.execute_reply":"2021-07-06T14:50:47.959967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the model and computing the cost or MSE on train and CV set after hundred iterations\nm,n= X_train.shape\ninitial_theta=np.zeros(n+1)\nres=optimize.minimize(lin_reg_CF, initial_theta, (X_train_norm,y_train,0), jac=True, method='TNC', options={'maxiters':100})\n\nj_train,_=lin_reg_CF(res.x, X_train_norm, y_train, 0)\nj_cv,_=lin_reg_CF(res.x, X_cv, y_cv, 0)\n\nprint('MSE on train set:',j_train)\nprint('MSE on CV set:',j_cv)\nprint('Optimal parameters or cofficients of our LR model:',res.x)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:50:56.625832Z","iopub.execute_input":"2021-07-06T14:50:56.626395Z","iopub.status.idle":"2021-07-06T14:50:56.684817Z","shell.execute_reply.started":"2021-07-06T14:50:56.626361Z","shell.execute_reply":"2021-07-06T14:50:56.683284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see the MSE on train set is very close to Cv set and both are nearly equal. It can be the case of high bias or vey simple model (less complexity in our hypohesis) or underfitting which we will confirm by varying lambda and try to improve the model performance by varying the regularization parameter to get the better fit state of our model.\n\nNOTE: I will be using ridge linear regression you can check the lin_reg_CF() function for formula.\n\nSince this might be the case of underfitting so we will try to see the variations between j_cv and j_train and we expect to get improvement in accuracy when lambda decreases. If you are familiar with andrew ng's course you would know what it means.","metadata":{}},{"cell_type":"code","source":"def lambda_tuning(X,y,X_cv,y_cv):\n    m,n=X.shape\n#     lambda_=np.linspace(10e-5,1,num=500)\n    lambda_=np.linspace(100,10e5,num=500)\n\n    err_train=np.array([])\n    err_cv=np.array([])\n\n    for i in lambda_:\n        initial_theta=np.zeros(n+1)\n        res=optimize.minimize(lin_reg_CF,initial_theta,(X,y,i),jac=True,method=\"TNC\",options={'maxiters':100})\n        \n        j_train,_=lin_reg_CF(res.x, X, y, lambda_=0)\n        err_train=np.append(err_train,j_train)\n        \n        j_cv,_=lin_reg_CF(res.x, X_cv, y_cv, lambda_=0)\n        err_cv=np.append(err_cv,j_cv)\n    \n    return lambda_,err_train,err_cv","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:51:29.488752Z","iopub.execute_input":"2021-07-06T14:51:29.489209Z","iopub.status.idle":"2021-07-06T14:51:29.498843Z","shell.execute_reply.started":"2021-07-06T14:51:29.489171Z","shell.execute_reply":"2021-07-06T14:51:29.497781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lambda_, error_train, error_val = lambda_tuning(X_train_norm, y_train, X_cv, y_cv)\nplt.figure(figsize=(10,5))\nplt.plot((lambda_), error_train, '-o', (lambda_), error_val, '-o', lw=2)\nplt.legend(['Train', 'Cross Validation'])\nplt.xlabel('lambda')\nplt.ylabel('Error (MSE)')\nplt.grid(True)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:51:11.325343Z","iopub.execute_input":"2021-07-06T14:51:11.325982Z","iopub.status.idle":"2021-07-06T14:51:22.628565Z","shell.execute_reply.started":"2021-07-06T14:51:11.325933Z","shell.execute_reply":"2021-07-06T14:51:22.626188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is the plot of mse vs lambda, it is clear that there is no variation in j_cv and j_train when lambda decreased upto 10e-5. So we may conclude that the lambda parameter has no affect on the errors. Usually the errors are supposed to further decrease but it did not decreased instead are constant. I am not sure what could be the reason but do look (at last cell) at my model's generalization error on test set. I think this could be due to i have initially normalized all features.","metadata":{}},{"cell_type":"markdown","source":"For the sake of completeness, we will now also try to see the variations in errors when lambda is increased which simply means we will be decreasing variance or increasing the bias of our model. In this case we expect to see rise in j_cv and j_train as lambda increases.","metadata":{}},{"cell_type":"code","source":"lambda_, error_train, error_val = lambda_tuning(X_train_norm, y_train, X_cv, y_cv)\nplt.figure(figsize=(10,5))\nplt.plot(lambda_, error_train, '-o', lambda_, error_val, '-o', lw=2)\nplt.legend(['Train', 'Cross Validation'])\nplt.xlabel('lambda')\nplt.ylabel('Error (MSE)')\nplt.grid(True)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:51:45.932101Z","iopub.execute_input":"2021-07-06T14:51:45.932507Z","iopub.status.idle":"2021-07-06T14:51:49.120647Z","shell.execute_reply.started":"2021-07-06T14:51:45.932475Z","shell.execute_reply":"2021-07-06T14:51:49.119864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\nHence we may conclude that our model is working fine and we will now check the mse of our model on test set to generalize this model performance.","metadata":{}},{"cell_type":"code","source":"j_test,_=lin_reg_CF(res.x, X_test, y_test, 0)\nprint('MSE on test set:',j_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-06T14:51:54.274275Z","iopub.execute_input":"2021-07-06T14:51:54.274844Z","iopub.status.idle":"2021-07-06T14:51:54.283939Z","shell.execute_reply.started":"2021-07-06T14:51:54.274793Z","shell.execute_reply":"2021-07-06T14:51:54.282768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can clearly see that the test error is nearly equal to train error hence we can conclude that the model generalizes well on test set.  ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}