{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom scipy import stats\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\nsns.set_palette(\"pastel\")\npd.options.display.float_format = \"{:,.4f}\".format","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1> Reading the Train and Test Dataset </h1>\n\n<p>The test dataset does not contain target variables. It will ultimately be the dataset we predict for submission.\n   The train dataset will be split into a training and validation set using train_test_split. </p>\n\n<h3> What is the validation set used for? </h3>\n    \n<p>It is taken from a part of the training dataset (0.2% in this case). \n   It will be used to tune the parameters of the model and to avoid overfitting. </p>\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/health-insurance-cross-sell-prediction/train.csv')\ntest=pd.read_csv('../input/health-insurance-cross-sell-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## At first glance\n\nCategorical Data: Gender, Driving_License, Region_Code, Previously_Insured, Vehicle_Damage, Policy_Sales_Channel\n\nContinuous Data: Age,Annual_Premium, Vintage\n\nTarget Data: Response\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check if there are any null values\n\nIf there are any...\n1. Fill it up with a null represented value\n2. Remove that row of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"####################\n# Null Data Analysis\n####################\nnullDF=pd.DataFrame()\nnullDF['Train']=train.isnull().sum()\nnullDF['Test']=test.isnull().sum()\nnullDF","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Encoding Categorical Data\n\nML/AI algorithms requires the inputs to be numerical.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby(by=['Vehicle_Age']).count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###########################\n# Encoding Categorical Data\n###########################\n\nfrom sklearn.preprocessing import LabelEncoder\n\nle=LabelEncoder()\ntrain['Gender']=le.fit_transform(train['Gender'])\ntest['Gender']=le.fit_transform(test['Gender'])\nprint(\"Gender Encoding Classes:\", le.classes_)\n\ntrain['Vehicle_Damage']=le.fit_transform(train['Vehicle_Damage'])\ntest['Vehicle_Damage']=le.fit_transform(test['Vehicle_Damage'])\nprint(\"Vehicle Damage Encoding Classes:\", le.classes_)\n\ndef ordered_encoding(lst,x):\n    return lst.index(x)\nlst = ['< 1 Year','1-2 Year','> 2 Years']\ntrain['Vehicle_Age']=train['Vehicle_Age'].apply(lambda x : ordered_encoding(lst,x))\ntest['Vehicle_Age']=test['Vehicle_Age'].apply(lambda x : ordered_encoding(lst,x))\n\ntrain['Region_Code']=train['Region_Code'].apply(lambda x : int(x))\ntest['Region_Code']=test['Region_Code'].apply(lambda x : int(x))\n\ntrain['Policy_Sales_Channel']=train['Policy_Sales_Channel'].apply(lambda x : int(x))\ntest['Policy_Sales_Channel']=test['Policy_Sales_Channel'].apply(lambda x : int(x))\n\ntrain.drop(columns=['id'])\ntest.drop(columns=['id'])\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining our training features and target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train.drop(columns=['id','Response'])\ny=train['Response']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#########################\n# Distribution of Target\n#########################\n\nsns.countplot(y)\ncount_0, count_1 = y.value_counts()\ntotal=count_0+count_1\npercent_0=float(\"{:.2f}\".format(count_0/total))\npercent_1=float(\"{:.2f}\".format(count_1/total))\nprint(\"Not Interested: \",count_0,f\"{percent_0}%\")\nprint(\"Interested:     \",count_1,f\" {percent_1}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Highly Skewed Dataset\nAs seen from the countplot above, we have a dataset that recorded 88% of customers not being interested in Vehicle Insurance.\n\nIf we continue to learn with this dataset, the model will probably overfit and returns a prediction of not interested way more often than it should.\n\nWe will be oversampling with Synthetic Minority Oversampling Technique(SMOTE) and cleaning with Tomek links to produce a balanced dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.combine import SMOTETomek\n\nsmt=SMOTETomek(random_state=42)\n\nX,y=smt.fit_sample(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###################################\n# Distribution of resampled Labels\n###################################\n\nsns.countplot(y)\ncount_0, count_1 = y.value_counts()\ntotal=count_0+count_1\npercent_0=float(\"{:.2f}\".format(count_0/total))\npercent_1=float(\"{:.2f}\".format(count_1/total))\nprint(\"Not Interested: \",count_0,f\"{percent_0}%\")\nprint(\"Interested:     \",count_1,f\" {percent_1}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gender (Categorical)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(X['Gender'],hue=y)\nplt.legend(labels=[\"not interested\",\"interested\"])\n\nfemale,male=X['Gender'].value_counts()\nprint(\"Number of female:\",female)\nprint(\"Number of male:\",male)\n\nplt.show()\n\n#### Gender - Response #####\ngender=X['Gender']\n\n# Form a Contingency Table #\nctb=pd.crosstab(gender, y, normalize=True)\n\n(chi2,p,dof,_)=stats.chi2_contingency([ctb.iloc[0].values,ctb.iloc[1].values])\n\ngender_=['Gender',chi2,p,dof,gender.var()]\n(ctb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution:\nThe number of female and male (by percentage) do not differ by much. \n\n### Observation:\nThe females customers favours being interested while the male customers favours being uninterested.\n"},{"metadata":{},"cell_type":"markdown","source":"## Age (Discrete)"},{"metadata":{"trusted":true},"cell_type":"code","source":"age_interested=(X.loc[y[y==1].index.values])['Age']\nage_notinterested=(X.loc[y[y==0].index.values])['Age']\n\nf, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\nsns.boxplot(X['Age'],ax=ax_box)\nsns.distplot(X['Age'],ax=ax_hist)\nax_box.set(xlabel='')\nax_box.set(title=\"Distribution of customer's age\")\nplt.show()\n\nsns.distplot(age_notinterested, color='salmon')\nsns.distplot(age_interested, color='lightblue')\nplt.title(\"Distribution of customer's age and their interest\")\nplt.legend(labels=[\"not interested\",\"interested\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution:\nThe customers are generally ranging from young to middle age adults. However, the younger adults are predominantly uninterested in the vehicle insurance.\n\n### Analysis:\nIt is very likely that the younger adults have just started working and might not have the sufficient purchasing power to own a vehicle."},{"metadata":{},"cell_type":"markdown","source":"## Driving License (Categorical)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(X['Driving_License'],hue=y)\nplt.legend(labels=[\"not interested\",\"interested\"])\n\ndl=X['Driving_License']\n\ndl1,dl0 = X['Driving_License'].value_counts()\nprint(\"Number of customers that have a driving license:\", dl1)\nprint(\"Number of customers that do not have a driving license:\", dl0)\nprint(\"Variance:\", X['Driving_License'].var())\nplt.show()\n\n# Form a Contingency Table #\nctb=pd.crosstab(dl, y)\n\n(chi2,p,dof,_)=stats.chi2_contingency([ctb.iloc[0].values,ctb.iloc[1].values])\n\ndriving_license=['Driving_License',chi2,p,dof,dl.var()]\n(ctb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution:\nThe dataset contains a heavily skewed amount of customers that have a driving license as compared to customers that do not. The poor spread in data will most likely result in a low variance.\n\n### Action:\nThe variance of this feature (0.0019) is extremely low and therefore will be removed."},{"metadata":{},"cell_type":"markdown","source":"## Region Code (Discrete)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Variance:\", X['Region_Code'].var())\n\nf, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\nsns.boxplot(X['Region_Code'],ax=ax_box)\nsns.distplot(X['Region_Code'],ax=ax_hist)\nax_box.set(xlabel='')\nax_box.set(title=\"Distribution of customer's region code\")\nplt.show()\n\n\nrc_interested=(X.loc[y[y==1].index.values])['Region_Code']\nrc_notinterested=(X.loc[y[y==0].index.values])['Region_Code']\nsns.distplot(rc_notinterested, color='salmon')\nsns.distplot(rc_interested, color='lightblue')\nplt.title(\"Distribution of customer's region code and their interest\")\nplt.legend(labels=[\"not interested\",\"interested\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution\nThe distribution of customers from different regions are fairly consistent except for region code 28 where there is a enormous spike in customer data collected.\n\n### Analysis\nThe spike might be due to a convenient method of collecting data from that region, we can further probe into this hypothesis by looking at the relationship between region code and policy sales channel \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(4,4,figsize=(29,29))\n\ncount=20\n\nfor i in range(4):\n    for j in range(4):\n        df=(X[['Region_Code','Policy_Sales_Channel']][X['Region_Code']==count])\n        if(count==28):\n            ax[i,j].hist(df['Policy_Sales_Channel'],color='black')\n        else:\n            ax[i,j].hist(df['Policy_Sales_Channel'])\n        ax[i,j].title.set_text(\"Region Code: \" + str(count))\n        count+=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Previously Insured (Categorical)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Variance:\",X['Previously_Insured'].var())\n\nsns.countplot(X['Previously_Insured'],hue=y)\nplt.legend(labels=[\"not interested\",\"interested\"])\n\nplt.show()\n\n#### Previously_Insured - Response #####\npi=X['Previously_Insured']\n\n## Categorical - Categorical ##\n# Form a Contingency Table #\nctb=pd.crosstab(pi, y)\n\n(chi2,p,dof,_)=stats.chi2_contingency([ctb.iloc[0].values,ctb.iloc[1].values])\n\npreviosly_insured=['Previously_Insured',chi2,p,dof,pi.var()]\n(ctb)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution:\nThere is a larger amount of customers that were not previously insured, relative to customers that were previously insured. Being insured in this instance refers to having their vehicle insured.\n\n### Observation:\nFor the customers that were not previously insured, they were more likely to be interested in the insurance. Whereas, for the customers that were previously insured, they were predominantly uninterested."},{"metadata":{},"cell_type":"markdown","source":"## Vehicle Age (Categorical)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(X['Vehicle_Age'],hue=y)\nplt.legend(labels=[\"not interested\",\"interested\"])\nplt.show()\n\n#### Vehicle_Age - Response #####\nva=X['Vehicle_Age']\n\n# Form a Contingency Table #\nctb=pd.crosstab(va, y, normalize=True)\n\n(chi2,p,dof,_)=stats.chi2_contingency([ctb.iloc[0].values,ctb.iloc[1].values])\n\nvehicle_age=['Vehicle_Age',chi2,p,dof,va.var()]\n(ctb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution\nThere is an overwhelming amount of customer data collected with a vehicle that is between 1-2 years old. That is followed by customers with a vehicle that is less than a year old and a small amount of customers with a vehicle that is more than 2 years old.\n\n### Analysis\nThe insurance company is assuming that newer car owners will likely be more interested in getting their vehicles covered."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(X['Vehicle_Damage'],hue=y)\nplt.legend(labels=[\"not interested\",\"interested\"])\nplt.show()\n\n#### Vehicle_Damage - Response #####\nvd=X['Vehicle_Damage']\n\n# Form a Contingency Table #\nctb=pd.crosstab(vd, y)\n\n(chi2,p_,dof,_)=stats.chi2_contingency([ctb.iloc[0].values,ctb.iloc[1].values])\nvehicle_damage=['Vehicle_Damage',chi2,p_,dof,vd.var()]\n(ctb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Vehicle Damage (Categorical)\n\n### Analysis\nCustomers with past vehicle damage were more prone to be interested in the vehicle insurance while customers with no past vehicle damage are more likely to be uninterested."},{"metadata":{},"cell_type":"markdown","source":"## Annual Premium (Continuous)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Variance:\", X['Annual_Premium'].var())\n\nf, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\nsns.boxplot(X['Annual_Premium'],ax=ax_box)\nsns.distplot(X['Annual_Premium'],ax=ax_hist)\nax_box.set(xlabel='')\nax_box.set(title=\"Distribution of Annual Preium paid\")\nplt.show()\n\n\nap_interested=(X.loc[y[y==1].index.values])['Annual_Premium']\nap_notinterested=(X.loc[y[y==0].index.values])['Annual_Premium']\n\nsns.distplot(ap_notinterested, color='salmon')\nplt.title(\"Distribution of Annual Premium paid for customers that were interested\")\nplt.show()\nsns.distplot(ap_interested, color='lightblue')\nplt.title(\"Distribution of Annual Premium paid for customers that were not interested\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Policy Sales Channel (Discrete)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Variance:\", X['Policy_Sales_Channel'].var())\n\nf, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\nsns.boxplot(X['Policy_Sales_Channel'],ax=ax_box)\nsns.distplot(X['Policy_Sales_Channel'],ax=ax_hist)\nax_box.set(xlabel='')\nax_box.set(title=\"Distribution of Policy Sales Channel\")\nplt.show()\n\n\npsc_interested=(X.loc[y[y==1].index.values])['Policy_Sales_Channel']\npsc_notinterested=(X.loc[y[y==0].index.values])['Policy_Sales_Channel']\n\nsns.distplot(psc_notinterested, color='salmon')\nplt.title(\"Distribution of Policy Sales Channel for customers that were interested\")\nplt.show()\nsns.distplot(psc_interested, color='lightblue')\nplt.title(\"Distribution of Policy Sales Channel for customers that were not interested\")\nplt.show()\n\nprint(\"Most used channel:\")\nprint((X['Policy_Sales_Channel'].value_counts())[:3])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Analysis\n* The 3 most used policy sales channels are channel 26, 124 and 152.\n* Customers that were predominantly reached through channels 26 and 124 resulted in a disinterest in the insurance.\n* Customers that were predominantly reached through channels 152 resulted in an interest in the insurance"},{"metadata":{},"cell_type":"markdown","source":"## Vintage (Discrete)"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Variance:\", X['Vintage'].var())\n\nf, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\nsns.boxplot(X['Vintage'],ax=ax_box)\nsns.distplot(X['Vintage'],ax=ax_hist)\nax_box.set(xlabel='')\nax_box.set(title=\"Distribution of Policy Sales Channel\")\nplt.show()\n\n\nap_interested=(X.loc[y[y==1].index.values])['Vintage']\nap_notinterested=(X.loc[y[y==0].index.values])['Vintage']\n\nsns.distplot(ap_notinterested, color='salmon')\nplt.title(\"Distribution of Policy Sales Channel for customers that were interested\")\nplt.show()\nsns.distplot(ap_interested, color='lightblue')\nplt.title(\"Distribution of Policy Sales Channel for customers that were not interested\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution\n\nThere is a fairly even distribution of customers with regards to the number of days the customer is associated with the company\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"chi2summary=(gender_,driving_license,previosly_insured,vehicle_age,vehicle_damage)\nchi2DF=pd.DataFrame(chi2summary,columns=['FeatureName','Chi2','p-val','DegreeOfFreedom','Variance'])\nchi2DF","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Categorical Feature Summary\n\n1. Obtain the variance of the feature\n    * Driving_License will be removed as the variance is close to zero\n    \n2. Evaluate strength of relationship between feature and target (alpha=0.05)\n    * Both Gender and Vehicle_Age has a p-val that is >0.05 but not overwhelmingly larger so I will take a look at the feature importance for a reinforced decision to remove or keep the feature\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"etc=ExtraTreesClassifier()\netc.fit(X,y)\nfeat_imp=pd.Series(etc.feature_importances_,\n                  index=X.columns)\nfeat_imp.nlargest(10).plot(kind='barh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Selection\n\n* With the additional information from the ExtraTreeClassifier, we can see that Driving License is useless for the classification and hence will be removed.\n\n* Gender has a low score for feature importance and coupled with a p-val > 0.05 we will be removing this feature as well"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=X.drop(columns=['Driving_License','Gender'])\ntest=test.drop(columns=['id','Driving_License','Gender'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting the dataset\n\nThe train dataset will be split into xtrain,xtest,ytrain,ytest where we fit (xtrain,ytrain) into our models for training and validate using (xtest,ytest).\n\nThe distribution of Response is fairly random so we do not need to shuffle before spliiting"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nxtrain,xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\nfrom sklearn.model_selection import RandomizedSearchCV,GridSearchCV, cross_val_score\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report,roc_auc_score,roc_curve","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Additional Functions\n\n1. Plotting a roc curve since it is a nice visualization tool to evaluate the model\n\n2. A generic function to fit a classifier and extract the evaluation metrics required"},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://stackabuse.com/understanding-roc-curves-with-python/\ndef plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()\n    \n    \ndef build_model(clf):\n    classifier_name=str(clf).split('(')[0]\n\n    clf.fit(xtrain,ytrain)\n    \n    ypred = clf.predict(xtest)\n    \n    accuracy=accuracy_score(ytest,ypred)\n    probs = (clf.predict_proba(xtest))[:,1]\n    auc=roc_auc_score(ytest, probs)\n    kfold=cross_val_score(clf,X,y,cv=10)\n    kfold_acc = kfold.mean()\n\n    cr=(classification_report(ypred,ytest,output_dict=True))\n    cr0=cr['0']\n    cr1=cr['1']\n    cm=confusion_matrix(ypred,ytest)\n    \n    summary=([classifier_name ,cr0['precision'], cr0['recall'], cr0['f1-score'], cr0['support'],cr1['precision'], cr1['recall'], cr1['f1-score'], cr1['support'], cm[0,0], cm[0,1], cm[1,0], cm[1,1], auc, kfold_acc, accuracy])\n\n    fpr, tpr, _ = roc_curve(ytest,probs)\n    plot_roc_curve(fpr, tpr)\n    \n    return clf,summary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hyperparameter Tuning\n\nIt takes quite some time to run the grid/random searches on kaggle,therefore I've done it on Visual Studio Code on my pc to utilize a better cpu."},{"metadata":{"trusted":true},"cell_type":"code","source":"# hp={\n#     'criterion'         : ['gini','entropy'],\n#     'min_samples_split' : [x for x in range(2,25)],\n#     'max_depth'         : [x for x in range(90,100)]\n# }\n\n# dtc_tune=RandomizedSearchCV(estimator=DecisionTreeClassifier(),\n#                            param_distributions = hp, \n#                            scoring='roc_auc',\n#                             cv = 5, \n#                             verbose=1,  \n#                             n_jobs = -1,\n#                            return_train_score=True)\n\n# dtc_tune.fit(X,y)\n\n# dtc_tune.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hp={\n#     'criterion'         : ['entropy','gini'],\n#     'max_features'      : [None, 'sqrt','log2'],\n#     'min_samples_split' : [x for x in range(2,11)]\n# }\n\n# rfc_tune=RandomizedSearchCV(estimator=RandomForestClassifier(),\n#                       param_distributions = hp, \n#                       cv = 5,\n#                       scoring='roc_auc',\n#                       verbose=1,  \n#                       n_jobs = -1,\n#                       return_train_score=True)\n\n# rfc_tune.fit(X,y)\n# rfc_tune.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hp={\n#     'n_estimators' : [x for x in range(50,150,10)],\n#     'learning_rate': [x for x in range(1,10)]\n# }\n\n# abc_tune=RandomizedSearchCV(estimator=XGBClassifier(),\n#                            param_distributions = hp, \n#                            scoring='roc_auc',\n#                            cv = 5,\n#                            verbose=1,\n#                            n_jobs = -1,\n#                            return_train_score=True)\n\n# abc_tune.fit(X,y)\n# abc_tune.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hp={\n#     'n_estimators' : [x for x in range(50,150,10)],\n#     'learning_rate': [x for x in range(1,10)]\n# }\n\n# abc_tune=RandomizedSearchCV(estimator=AdaBoostClassifier(),\n#                            param_distributions = hp, \n#                            scoring='roc_auc',\n#                            cv = 5,\n#                            verbose=1,\n#                            n_jobs = -1,\n#                            return_train_score=True)\n\n# abc_tune.fit(X,y)\n# abc_tune.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtc=DecisionTreeClassifier(criterion='gini',\n                          max_depth=97,\n                          min_samples_split=21)\n\ndtc_model, dtc_summary = build_model(dtc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=130)\n\nrfc_model, rfc_summary = build_model(rfc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBClassifier()\n\nxgb_model, xgb_summary = build_model(xgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abc = AdaBoostClassifier(n_estimators=100)\n\nabc_model, abc_summary = build_model(abc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm=LGBMClassifier()\n\nlgbm_model, lgbm_summary = build_model(lgbm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_summary=[dtc_summary,rfc_summary,xgb_summary,abc_summary,lgbm_summary]\nmodel_summary=pd.DataFrame(model_summary,columns=['ModelName','precision_0','recall_0','f1_score_0','support_0','precision_1','recall_1','f1_score_1','support_1','TP','FP','FN','TN','AUC','cross_val_score','Accuracy']).set_index('ModelName')\nmodel_summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction=rfc.predict(test)\nsubmission=pd.read_csv('../input/health-insurance-cross-sell-prediction/sample_submission.csv')\nsubmission['Response']=prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###################################\n# Distribution of predicted Target\n###################################\n\nsns.countplot(submission['Response'])\ncount_0, count_1 = submission['Response'].value_counts()\ntotal=count_0+count_1\npercent_0=float(\"{:.2f}\".format(count_0/total))\npercent_1=float(\"{:.2f}\".format(count_1/total))\nprint(\"Not Interested: \",count_0,f\"{percent_0}%\")\nprint(\"Interested:     \",count_1,f\" {percent_1}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}