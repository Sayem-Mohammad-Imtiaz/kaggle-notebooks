{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Data Manipulation\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n#Data Visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('seaborn-whitegrid')\n#OS interaction\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv\"\nheartDF = pd.read_csv(path)\nheartDF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check if there are null values\nheartDF.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Applying simple Decision Tree for classification","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier,export_graphviz\nfrom graphviz import render,Source\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\ny = heartDF['DEATH_EVENT']\nX = heartDF.drop(columns=['DEATH_EVENT'])\n\naccuracy_dict = {}\n\nx_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\ndtc = DecisionTreeClassifier(random_state=0)\ndtc.fit(x_train,y_train)\ny_pred = dtc.predict(x_test)\naccuracy = accuracy_score(y_test,y_pred)\naccuracy_dict[\"DecisionTreeClassifier\"] = accuracy\nprint(\"Accuracy:\",accuracy)\ndotfile = open(\"dtc.dot\", 'w')\nexport_graphviz(dtc, out_file = dotfile, feature_names = x_train.columns)\ndotfile.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Decision path for Decision Tree Classifier\")\nrender('dot', 'png', 'dtc.dot')\nSource.from_file(\"dtc.dot\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning\n\n* Check for features with low variance and remove those features\n* There is no need for feature scaling for the bagging and boosting algorithms below","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold\nvarDF = pd.DataFrame(X.var(),columns=['Feature Variance'])\nvarDF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thres = VarianceThreshold(threshold=0.2)\nhigh_var = thres.fit_transform(X)\nprint(\"Columns deleted:\",X.columns[~thres.get_support()])\nx_train = x_train[ X.columns[(thres.get_support())]]\nx_test = x_test[X.columns[(thres.get_support())]]\npd.DataFrame(high_var,columns= X.columns[(thres.get_support())])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bagging\n* With Random Forrest Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(n_estimators=100)\nrfc.fit(x_train,y_train)\ny_pred = rfc.predict(x_test)\naccuracy = accuracy_score(y_test,y_pred)\nprint(\"Accuracy:\",accuracy)\n\naccuracy_dict[\"RandomForestClassifier\"] = accuracy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Boosting\n* With XGBoost and AdaBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgb = XGBClassifier()\nxgb.fit(x_train,y_train)\ny_pred = xgb.predict(x_test)\naccuracy = accuracy_score(y_test,y_pred)\nprint(\"Accuracy:\",accuracy)\n\naccuracy_dict[\"XGBoost Classifier\"] = accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\nabc = AdaBoostClassifier(n_estimators=50)\nabc.fit(x_train,y_train)\ny_pred = abc.predict(x_test)\naccuracy = accuracy_score(y_test,y_pred)\nprint(\"Accuracy:\",accuracy)\n\naccuracy_dict[\"AdaBoost Classifier\"] = accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for k,v in accuracy_dict.items():\n    if(v == max(accuracy_dict.values())):\n        model_chosen = k\n\nif model_chosen == \"DecisionTreeClassifier\":\n    model = dtc\nelif model_chosen == \"RandomForestClassifier\":\n    model = rfc\nelif model_chosen == \"XGBoost Classifier\":\n    model = xgb\nelse:\n    model = ada","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best model for this classification:\", model_chosen)\nprint(\"Accuracy:\",accuracy_dict[model_chosen])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}