{"cells":[{"metadata":{"_uuid":"ce8f87da9f5cd240c05e94030e3a9556d0ca8b5b","_cell_guid":"dbdafe14-224a-43a5-9943-f537e1a80e8d"},"cell_type":"markdown","source":"# Introduction\n\nPreviously I built XG Boost models to predict the main and sub-types of Pokemon from all 7 generations (https://www.kaggle.com/xagor1/pokemon-type-predictions-using-xgb). This was relatively successful, but often stalled at around 70% accuracy per generation, with some much worse. To gain more experience with parameter tuning and feature engineering, I decided to revisit just the 1st Generation, and see if I could improve my results."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_kg_hide-input":true,"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"#Load various packages\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nimport gc\nimport time\nimport numpy as np\nimport pandas as pd\nfrom sklearn.cross_validation import train_test_split\nimport xgboost as xgb\nfrom xgboost import plot_importance\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nimport seaborn as sns\nprint(os.listdir(\"../input\"))\nfrom sklearn.feature_selection import SelectFromModel\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"628921a535d4e9485ece5293951a10eea375b259","_cell_guid":"727b809b-1c60-4c69-8707-53a0c20f75ac"},"cell_type":"markdown","source":"# Loading and Modifying Data\n\nTo start with, I loaded and modified the data as in the previous kernel.\n\nIn contrast to last time, I separated out the numerical and categorical data, and applied one-hot encoding to the latter. This caused the number of features to explode from 24 to 500.\n\nThe original plan was to do feature engineering to improve my overall accuracy. However, thus far all my attempts have actually made the predictions worse, so I have left this aside for now."},{"metadata":{"_uuid":"fc8aa7faac714ab53dbcdbd28cb5b84fb725b405","_kg_hide-input":true,"_cell_guid":"0a6f6d63-d5e2-408b-b8ce-2e615594825d","collapsed":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"#Read data\npath = '../input/'\negg_df=pd.read_csv(path+\"egg-group-data-for-pokemon/pokemon_egg_groups.csv\")\nspecies_df=pd.read_csv(path+\"pokemon-species/pokemon_species.csv\")\nabilities_df=pd.read_csv(path+\"abilities/pokemon_abilities.csv\")\n\n#Split duplicates off & combine back\negg2_df=pd.DataFrame.copy(egg_df)\negg2_df=egg_df.loc[egg_df['species_id'].duplicated(), :]\negg_df.drop_duplicates('species_id',inplace=True)\nmerged = egg_df.merge(egg2_df,on=\"species_id\",how='outer')\nmerged.fillna(0,inplace=True)\n\n#Rename columns to simpler form.\nmerged.rename(index=str,columns={\"egg_group_id_x\":\"egg_group_1\"},inplace=True)\nmerged.rename(index=str,columns={\"egg_group_id_y\":\"egg_group_2\"},inplace=True)\n\n#Drop last 6 columns\nmerged.drop(merged.tail(6).index,inplace=True)\n\n#Rename\nmerged.rename(index=str,columns={\"species_id\":\"pokedex_number\"},inplace=True)\n\n#Make a new smaller dataframe\nspecies_trim_df=pd.DataFrame()\nspecies_trim_df[\"pokedex_number\"]=species_df['id']\nspecies_trim_df[\"color_id\"]=species_df['color_id']\nspecies_trim_df[\"shape_id\"]=species_df['shape_id']\nspecies_trim_df[\"habitat_id\"]=species_df['habitat_id']\nspecies_trim_df.drop(species_trim_df.tail(6).index,inplace=True)\n\n#Trim all below Magearna off\nabilities_df = abilities_df[abilities_df.pokemon_id < 802]\n\n#Make 3 new columns\nabilities_df[\"Ability1\"]=0\nabilities_df[\"Ability2\"]=0\nabilities_df[\"Ability3\"]=0\n\n#Assign values to the 3 columns based on the ability slot (1-3)\nabilities_df[\"Ability1\"] = abilities_df.ability_id.where(abilities_df.slot == 1,0)\nabilities_df[\"Ability2\"] = abilities_df.ability_id.where(abilities_df.slot == 2,0)\nabilities_df[\"Ability3\"] = abilities_df.ability_id.where(abilities_df.slot == 3,0)\n\n#Split duplicates off into new dataframes \n#3 abilities on some means it needs to be split twice\n#I'm sure there's an easier way to do this\nabilities_df2=pd.DataFrame.copy(abilities_df)\nabilities_df2=abilities_df.loc[abilities_df['pokemon_id'].duplicated(), :]\nabilities_df.drop_duplicates('pokemon_id',inplace=True)\nabilities_df3=pd.DataFrame.copy(abilities_df2)\nabilities_df3=abilities_df2.loc[abilities_df2['pokemon_id'].duplicated(), :]\nabilities_df2.drop_duplicates('pokemon_id',inplace=True)\n\n#Drop extra columns\nabilities_df.drop(['ability_id','is_hidden','slot'],axis=1,inplace=True)\nabilities_df2.drop(['ability_id','is_hidden','slot'],axis=1,inplace=True)\nabilities_df3.drop(['ability_id','is_hidden','slot'],axis=1,inplace=True)\n\n#Combine everything back\nabilities_df=abilities_df.set_index('pokemon_id').add(abilities_df2.set_index('pokemon_id'),fill_value=0).reset_index()\nabilities_df=abilities_df.set_index('pokemon_id').add(abilities_df3.set_index('pokemon_id'),fill_value=0).reset_index()\n\n#Rename pokemon_id to pokedex number to allow for merging.\nabilities_df.rename(index=str,columns={\"pokemon_id\":\"pokedex_number\"},inplace=True)\n\n#Read Kaggle data\npath = '../input/'\npokemon_df=pd.read_csv(path+\"pokemon/pokemon.csv\")\n\nName_df=pd.DataFrame()\nName_df[\"name\"]=pokemon_df[\"name\"].copy()\n\n#Fix Minior's capture rate\npokemon_df.capture_rate.iloc[773]=30\n\n#Change the type\npokemon_df['capture_rate']=pokemon_df['capture_rate'].astype(str).astype(int)\n\n#Merge all my data.\npokemon_df=pokemon_df.merge(merged,on=\"pokedex_number\",how='outer')\npokemon_df=pokemon_df.merge(species_trim_df,on=\"pokedex_number\",how='outer')\npokemon_df=pokemon_df.merge(abilities_df,on=\"pokedex_number\",how='outer')\n\n#Remove against columns\npokemon_df.drop(list(pokemon_df.filter(regex = 'against')), axis = 1, inplace = True)\n#Correct the spelling error\npokemon_df.rename(index=str,columns={\"classfication\":\"classification\"},inplace=True)\n\n#Change nan to 'none'\npokemon_df.type2.replace(np.NaN, 'none', inplace=True)\n\n#Drop Pokedex number for now\npokemon_df.drop(\"pokedex_number\",axis=1,inplace=True)\npokemon_df.drop(\"generation\",axis=1,inplace=True)\n\n#First find the NAs.\nindex_height = pokemon_df['height_m'].index[pokemon_df['height_m'].apply(np.isnan)]\nindex_weight = pokemon_df['weight_kg'].index[pokemon_df['weight_kg'].apply(np.isnan)]\nindex_male   = pokemon_df['percentage_male'].index[pokemon_df['percentage_male'].apply(np.isnan)]\n\n#Manually replace the missing heights & weights using the Kanto version etc\npokemon_df.height_m.iloc[18]=0.3\npokemon_df.height_m.iloc[19]=0.7\npokemon_df.height_m.iloc[25]=0.8\npokemon_df.height_m.iloc[26]=0.6\npokemon_df.height_m.iloc[27]=1.0\npokemon_df.height_m.iloc[36]=0.6\npokemon_df.height_m.iloc[37]=1.1\npokemon_df.height_m.iloc[49]=0.2\npokemon_df.height_m.iloc[50]=0.7\npokemon_df.height_m.iloc[51]=0.4\npokemon_df.height_m.iloc[52]=1.0\npokemon_df.height_m.iloc[73]=0.4\npokemon_df.height_m.iloc[74]=1.0\npokemon_df.height_m.iloc[75]=1.4\npokemon_df.height_m.iloc[87]=0.9\npokemon_df.height_m.iloc[88]=1.2\npokemon_df.height_m.iloc[102]=2.0\npokemon_df.height_m.iloc[104]=1.0\npokemon_df.height_m.iloc[719]=0.5\npokemon_df.height_m.iloc[744]=0.8\n\npokemon_df.weight_kg.iloc[18]=3.5\npokemon_df.weight_kg.iloc[19]=18.5\npokemon_df.weight_kg.iloc[25]=30.0\npokemon_df.weight_kg.iloc[26]=12.0\npokemon_df.weight_kg.iloc[27]=29.5\npokemon_df.weight_kg.iloc[36]=9.9\npokemon_df.weight_kg.iloc[37]=19.9\npokemon_df.weight_kg.iloc[49]=0.8\npokemon_df.weight_kg.iloc[50]=33.3\npokemon_df.weight_kg.iloc[51]=4.2\npokemon_df.weight_kg.iloc[52]=32.0\npokemon_df.weight_kg.iloc[73]=20.0\npokemon_df.weight_kg.iloc[74]=105.0\npokemon_df.weight_kg.iloc[75]=300.0\npokemon_df.weight_kg.iloc[87]=30.0\npokemon_df.weight_kg.iloc[88]=30.0\npokemon_df.weight_kg.iloc[102]=120.0\npokemon_df.weight_kg.iloc[104]=45.0\npokemon_df.weight_kg.iloc[719]=9.0\npokemon_df.weight_kg.iloc[744]=25.0\n\n#Create a Genderless column to separate them from the all-female cases.\npokemon_df[\"Genderless\"]=0\npokemon_df[\"Genderless\"].loc[list(index_male)]=1\n\n#Replace all the NANs with zeros in the % male\npokemon_df.percentage_male.replace(np.NaN, 0, inplace=True)\n\n#Check the typings of the pokemon with Alolan forms & fix\n#I'm sure this can be done much more elegantly\npokemon_df.type2.iloc[18]='none'\npokemon_df.type2.iloc[19]='none'\npokemon_df.type2.iloc[25]='none'\npokemon_df.type2.iloc[26]='none'\npokemon_df.type2.iloc[27]='none'\npokemon_df.type2.iloc[36]='none'\npokemon_df.type2.iloc[37]='none'\npokemon_df.type2.iloc[49]='none'\npokemon_df.type2.iloc[50]='none'\npokemon_df.type2.iloc[51]='none'\npokemon_df.type2.iloc[52]='none'\npokemon_df.type2.iloc[87]='none'\npokemon_df.type2.iloc[88]='none'\npokemon_df.type2.iloc[104]='none'\n\n#Lets start with just the numerical data for now.\nnum_features=pokemon_df.select_dtypes(include=np.number)\nnum_features=num_features.columns\n\n#print(\"The Type models will be built using the following features\")\n#print(list(num_features))","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"cdf9fc30c321708275543feb961ff9d1aa605cb0","_kg_hide-input":true,"_cell_guid":"e064784f-eb42-4d0a-a650-97503b5a1710","collapsed":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"numerical_df=pd.DataFrame.copy(pokemon_df[['attack', 'base_egg_steps', 'base_happiness', 'base_total',\n                                           'capture_rate', 'defense', 'experience_growth',\n                                           'height_m', 'hp', 'percentage_male', 'sp_attack', 'sp_defense', 'speed',\n                                           'weight_kg']])\nnumerical_df.to_csv('numerical_features.csv',index=False)\none_hot_df=pd.DataFrame.copy(pokemon_df[[\"Ability1\",\"Ability2\",\"Ability3\",\"egg_group_1\",\"egg_group_2\",\n                                              \"is_legendary\",\"color_id\",\"shape_id\",\"habitat_id\",\"Genderless\"]])\none_hot_df=pd.get_dummies(one_hot_df,prefix=[\"Ability1\",\"Ability2\",\"Ability3\",\"egg_group_1\",\"egg_group_2\",\n                                              \"is_legendary\",\"color_id\",\"shape_id\",\"habitat_id\",\"Genderless\"],\n                       columns=[\"Ability1\",\"Ability2\",\"Ability3\",\"egg_group_1\",\"egg_group_2\",\n                                              \"is_legendary\",\"color_id\",\"shape_id\",\"habitat_id\",\"Genderless\"])\none_hot_df.to_csv('one_hot_features.csv',index=False)\nfeatures=pd.concat([numerical_df,one_hot_df],axis=1)","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"5b42d94863faee6adc30aaa5f2a73aebfa7e4199","_kg_hide-input":true,"_cell_guid":"2ae9ffff-9a92-48d0-bc7b-42540787558f","collapsed":true,"trusted":false},"cell_type":"code","source":"#Do some feature engineering\n#features[\"Total_Offense\"]=features[\"attack\"]+features[\"sp_attack\"]\n#features[\"Total_Defense\"]=features[\"defense\"]+features[\"sp_defense\"]\n#features[\"Total_Physical\"]=features[\"attack\"]+features[\"defense\"]\n#features[\"Total_Special\"]=features[\"sp_attack\"]+features[\"sp_defense\"]\n#features[\"Attack_Difference\"]=abs(features[\"attack\"]-features[\"sp_attack\"])\n#features[\"Defense_Difference\"]=abs(features[\"defense\"]-features[\"sp_defense\"])\n#features[\"Physical_Difference\"]=abs(features[\"attack\"]-features[\"defense\"])\n#features[\"Special_Difference\"]=abs(features[\"sp_attack\"]-features[\"sp_defense\"])\n#features[\"HeightXWeight\"]=features[\"height_m\"]*features[\"weight_kg\"]\n#features[\"BMI\"]=features[\"weight_kg\"]/(features[\"weight_kg\"]**2)\n#features[\"Speed_X_Weight\"]=features[\"speed\"]*features[\"weight_kg\"]\n#features=features.drop(columns=[\"attack\",\"sp_attack\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df42166920f8dd2bd66a1ebde2e53032aeaaccf0","_kg_hide-input":true,"_cell_guid":"f490eecb-52e1-485b-b47f-8d62773adf9f","collapsed":true,"trusted":true},"cell_type":"code","source":"targets=pd.DataFrame()\ntargets2=pd.DataFrame()\ntargets[\"type1\"]=pokemon_df[\"type1\"]\ntargets=np.ravel(targets)\ntargets2[\"type2\"]=pokemon_df[\"type2\"]\ntargets2=np.ravel(targets2)\n\n\n#Split features & targets into each generation.\nGen1_features=features[0:151]\nGen2_features=features[151:251]\nGen3_features=features[251:386]\nGen4_features=features[386:493]\nGen5_features=features[493:649]\nGen6_features=features[649:721]\nGen7_features=features[721:801]\nGen1_targets=targets[0:151]\nGen2_targets=targets[151:251]\nGen3_targets=targets[251:386]\nGen4_targets=targets[386:493]\nGen5_targets=targets[493:649]\nGen6_targets=targets[649:721]\nGen7_targets=targets[721:801]\nGen1_targets=np.ravel(Gen1_targets)\nGen2_targets=np.ravel(Gen2_targets)\nGen3_targets=np.ravel(Gen3_targets)\nGen4_targets=np.ravel(Gen4_targets)\nGen5_targets=np.ravel(Gen5_targets)\nGen6_targets=np.ravel(Gen6_targets)\nGen7_targets=np.ravel(Gen7_targets)\n\n#Recombine 6 of them, in 7 different ways, to make my different training sets\n#Ordering of the features & targets should be the same!\n#But doesn't have to be necessarily in numerical order\nGens_not1_features=pd.concat([Gen2_features,Gen3_features,Gen4_features,Gen5_features,Gen6_features,Gen7_features],axis=0)\nGens_not2_features=pd.concat([Gen1_features,Gen3_features,Gen4_features,Gen5_features,Gen6_features,Gen7_features],axis=0)\nGens_not3_features=pd.concat([Gen2_features,Gen1_features,Gen4_features,Gen5_features,Gen6_features,Gen7_features],axis=0)\nGens_not4_features=pd.concat([Gen2_features,Gen3_features,Gen1_features,Gen5_features,Gen6_features,Gen7_features],axis=0)\nGens_not5_features=pd.concat([Gen2_features,Gen3_features,Gen4_features,Gen1_features,Gen6_features,Gen7_features],axis=0)\nGens_not6_features=pd.concat([Gen2_features,Gen3_features,Gen4_features,Gen5_features,Gen1_features,Gen7_features],axis=0)\nGens_not7_features=pd.concat([Gen2_features,Gen3_features,Gen4_features,Gen5_features,Gen6_features,Gen1_features],axis=0)\nGens_not1_targets=np.concatenate((Gen2_targets,Gen3_targets,Gen4_targets,Gen5_targets,Gen6_targets,Gen7_targets),axis=0)\nGens_not2_targets=np.concatenate((Gen1_targets,Gen3_targets,Gen4_targets,Gen5_targets,Gen6_targets,Gen7_targets),axis=0)\nGens_not3_targets=np.concatenate((Gen2_targets,Gen1_targets,Gen4_targets,Gen5_targets,Gen6_targets,Gen7_targets),axis=0)\nGens_not4_targets=np.concatenate((Gen2_targets,Gen3_targets,Gen1_targets,Gen5_targets,Gen6_targets,Gen7_targets),axis=0)\nGens_not5_targets=np.concatenate((Gen2_targets,Gen3_targets,Gen4_targets,Gen1_targets,Gen6_targets,Gen7_targets),axis=0)\nGens_not6_targets=np.concatenate((Gen2_targets,Gen3_targets,Gen4_targets,Gen5_targets,Gen1_targets,Gen7_targets),axis=0)\nGens_not7_targets=np.concatenate((Gen2_targets,Gen3_targets,Gen4_targets,Gen5_targets,Gen6_targets,Gen1_targets),axis=0)\n\nGen1_targets2=targets2[0:151]\nGen2_targets2=targets2[151:251]\nGen3_targets2=targets2[251:386]\nGen4_targets2=targets2[386:493]\nGen5_targets2=targets2[493:649]\nGen6_targets2=targets2[649:721]\nGen7_targets2=targets2[721:801]\nGen1_targets2=np.ravel(Gen1_targets2)\nGen2_targets2=np.ravel(Gen2_targets2)\nGen3_targets2=np.ravel(Gen3_targets2)\nGen4_targets2=np.ravel(Gen4_targets2)\nGen5_targets2=np.ravel(Gen5_targets2)\nGen6_targets2=np.ravel(Gen6_targets2)\nGen7_targets2=np.ravel(Gen7_targets2)\nGens_not1_targets2=np.concatenate((Gen2_targets2,Gen3_targets2,Gen4_targets2,Gen5_targets2,Gen6_targets2,Gen7_targets2),axis=0)\nGens_not2_targets2=np.concatenate((Gen1_targets2,Gen3_targets2,Gen4_targets2,Gen5_targets2,Gen6_targets2,Gen7_targets2),axis=0)\nGens_not3_targets2=np.concatenate((Gen2_targets2,Gen1_targets2,Gen4_targets2,Gen5_targets2,Gen6_targets2,Gen7_targets2),axis=0)\nGens_not4_targets2=np.concatenate((Gen2_targets2,Gen3_targets2,Gen1_targets2,Gen5_targets2,Gen6_targets2,Gen7_targets2),axis=0)\nGens_not5_targets2=np.concatenate((Gen2_targets2,Gen3_targets2,Gen4_targets2,Gen1_targets2,Gen6_targets2,Gen7_targets2),axis=0)\nGens_not6_targets2=np.concatenate((Gen2_targets2,Gen3_targets2,Gen4_targets2,Gen5_targets2,Gen1_targets2,Gen7_targets2),axis=0)\nGens_not7_targets2=np.concatenate((Gen2_targets2,Gen3_targets2,Gen4_targets2,Gen5_targets2,Gen6_targets2,Gen1_targets2),axis=0)","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"40741ba251e2701b88f351c28f76da04f7d14888","_cell_guid":"984b78a0-aded-4ac4-aa1d-8fa0ca0bab91"},"cell_type":"markdown","source":"# Tuning XGB Parameters\n\nIn the previous kernel, I'd only done minor tuning of the XGB parameters when trying to fit to the full Pokedex. I'd then just assumed this was the best choice for all other situations, which might not actually be true.\n\nIn this kernel, I optimized a range of hyperparameters for both the Type 1 and Type 2 models, to obtain the best Test accuracy. This included tuning:\n\n* max depth and min child weight\n* subsample and col sample by tree\n* gamma\n* reg alpha\n* reg lambda\n* learning rate and n estimators\n\nIn both cases, I was able to improve the accuracy by about 5% compared to the default values.\n\nFor both models, I also explored the effect of adding weightings, but only found improvements for the Type 2 model, which has a major imbalance between None and all other types.\n\nFor type 1, I found that the optimal parameters were:\n\nmax depth = 3, n estimators = 158, learning rate = 0.1, gamma = 0, min child weight = 1, subsample = 0.6, col sample by tree = 0.2, alpha =0 and lambda = 0.9.\n"},{"metadata":{"_uuid":"01d394c3821bd4d08aedc0844af6316571bf5b27","_kg_hide-input":true,"_cell_guid":"2352ee02-b45d-4441-b9ff-7e7e49576a94","collapsed":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"params={\n'max_depth':3,\n'learning_rate':0.1, \n'n_estimators':300, \n'silent':True, \n'booster':'gbtree',\n'n_jobs':1, \n'nthread':4, \n'gamma':0, \n'min_child_weight':1, \n'max_delta_step':0, \n'subsample':0.6, \n'colsample_bytree':0.2, \n'colsample_bylevel':1, \n'reg_alpha':0, \n'reg_lambda':0.9, \n'scale_pos_weight':1, \n'base_score':0.5, \n'random_state':1,\n'missing':None,}","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"b36e24d2e836fd1862190c58e67dfc12e9a328c9","_kg_hide-input":true,"_cell_guid":"3e8c2bbe-181f-43c8-b0cb-f5b9715a345c","collapsed":true,"trusted":false},"cell_type":"code","source":"#Test adding weights wrt water\n#weights = np.zeros(len(Gens_not1_targets))\n#for i in range(len(Gens_not1_targets)):\n#    weights[i]=Counter(Gens_not1_targets)['water']/Counter(Gens_not1_targets)[Gens_not1_targets[i]]\n#weights","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64c4e227e8b846fce15569640cc386b5307b3fdf","_kg_hide-input":true,"_cell_guid":"3462717d-5799-434c-874e-6e82d46df308","_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"#Generation 1 model\nmodel_xgb=xgb.XGBClassifier(**params)\neval_set = [(Gens_not1_features, Gens_not1_targets),(Gen1_features, Gen1_targets)]\nmodel_xgb.fit(Gens_not1_features, Gens_not1_targets,eval_set=eval_set,eval_metric=\"merror\",verbose=False)\ntraining_eval=model_xgb.evals_result()\nmin_error=min(training_eval['validation_1']['merror'])\nprint(\"The minimum error is:\")\nprint(min_error)\ntraining_step=training_eval['validation_1']['merror'].index(min_error)\nprint(\"This occurs at step:\")\nprint(training_step)\nxgb.plot_importance(model_xgb,max_num_features=20)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"8897bde3fd6042baee15b85dcbb7d7b32e0e1102","_kg_hide-input":true,"_cell_guid":"3e3cae6a-2870-4d3e-ad99-b9bcf9379570","trusted":true},"cell_type":"code","source":"#Final model\nparams['n_estimators']=158\nmodel_xgb=xgb.XGBClassifier(**params)\n\nmodel_xgb.fit(Gens_not1_features, Gens_not1_targets)\nGen1_T1_pred = model_xgb.predict(Gen1_features)\n\n# evaluate predictions\ntest_accuracy = accuracy_score(Gen1_targets, Gen1_T1_pred)\nprint(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\nxgb.plot_importance(model_xgb,max_num_features=20)\n# Output a plot of the confusion matrix.\nlabels =list(set(Gen1_targets))\ncm = metrics.confusion_matrix(Gen1_targets, Gen1_T1_pred,labels)\n# Normalize the confusion matrix by row (i.e by the number of samples\n# in each class)\ncm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\nsns.set(font_scale=4)\nplt.figure(figsize=(20,20))\nax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\nax.set_aspect(1)\nax.set_xticklabels(labels)\nax.set_yticklabels(labels)\nplt.xticks(rotation=90)\nplt.yticks(rotation=0)\nplt.title(\"Type 1 Confusion matrix\")\nplt.ylabel(\"True label\")\nplt.xlabel(\"Predicted label\")\nplt.show()\nsns.set(font_scale=0.8)","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"69dc67d659cd012344f7426375a4ff434690588e","_cell_guid":"fc4ca7b8-0be8-4f32-a9d2-888db2e65463"},"cell_type":"markdown","source":"After hyperparameter tuning, I was able to get a 72.19% accuracy for Type 1, which just beats my models from the previous attempt.\n\nAll types have some correct predictions, except for Ice, which is always confused for either Water or Psychic.\n\nBy contrast, Bug, Water and Grass each have 100% accuracy, and Normal performs pretty well too.\n\nMost of the incorrect predictions appear to be from incorrect assignment of Water, Normal, Electric or Psychic type, meaning the model is over-predicted all four of these types.\n\nSince type ordering is somewhat arbitrary, there is the possibility that some of these are correct predictions, but for Type 2, rather than type 1."},{"metadata":{"_uuid":"bb50d101424bd90532adcd2a80f5862e83690313","_kg_hide-input":true,"_cell_guid":"9e3207c2-5da1-4e3e-a3b0-32914ae3fe1a","trusted":true},"cell_type":"code","source":"print(\"Some predictions may match the sub-type, rather than the main type\")\nmismatch_accuracy = accuracy_score(Gen1_targets2, Gen1_T1_pred)\nprint(\"Mismatch Accuracy: %.2f%%\" % (mismatch_accuracy * 100.0))\nprint(\"The Pokemon whose predicted types match their sub-type are:\")\nfor i in range(0,len(Gen1_targets)):\n    if Gen1_T1_pred[i] == Gen1_targets2[i]:\n        print (pokemon_df[\"name\"][i])","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"c3881732dd0de1acdf115c7aaf16be6284cd51ed","_cell_guid":"ebadb2bf-83a4-4d97-ba5e-2f45462ffb49"},"cell_type":"markdown","source":"As it turns out, there are 7 Pokemon which fall into this category.\n\nHowever, this still leaves about a quarter of the Pokemon with incorrect types. \n\nOne possible way to address this is to look closer at the incorrect predictions to see where they went wrong, and come up with ideas for how to fix them. For now, this is a task left to the future."},{"metadata":{"_uuid":"f97d4c9a01d4df50627731b6fdf72d7d968a094e","_cell_guid":"4c9c3b2e-c4dd-416f-82bf-52e451184637","trusted":true},"cell_type":"code","source":"print(\"Pokemon with incorrect types are as follows:\")\nfor i in range(0,len(Gen1_targets)):\n    if Gen1_T1_pred[i] != Gen1_targets[i]:\n        print (pokemon_df[\"name\"][i],Gen1_T1_pred[i])","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"90d3e815d4c674505269d95e16f9087ee453a6e7","_kg_hide-input":true,"_cell_guid":"0348976d-4139-4725-a96a-145883c62e67","collapsed":true,"_kg_hide-output":true,"trusted":false},"cell_type":"code","source":"#selection = SelectFromModel(model_xgb, threshold=1e-15,prefit=True)\n#feature_idx = selection.get_support()\n#feature_name = Gens_not1_features.columns[feature_idx]\n#print(feature_name)\n#print(feature_name.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e6a8f645405cdb79fa606f44925e7bb2adda021","_kg_hide-input":true,"_cell_guid":"8add6a55-990e-446c-b743-2ae7c114a6c8","collapsed":true,"trusted":true},"cell_type":"code","source":"weights = np.zeros(len(Gens_not1_targets2))\nfor i in range(len(Gens_not1_targets2)):\n    weights[i]=Counter(Gens_not1_targets2)['none']/Counter(Gens_not1_targets2)[Gens_not1_targets2[i]]","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"4f90ca24fe2af0c05fa76ae5a23a07eb0a441229","_cell_guid":"82e8e1e3-6054-4599-a59d-24efa8d41b5f"},"cell_type":"markdown","source":"For type 2, I found that the optimal parameters were:\n\nmax depth = 4, n estimators = 242, learning rate = 0.1, gamma = 0.1, min child weight = 3, subsample = 1, col sample by tree = 0.3, alpha =0 and lambda = 1.\n"},{"metadata":{"_uuid":"500a4a2003ac721ce749948310a9a522781380d3","_kg_hide-input":true,"_cell_guid":"e0d0d2cf-ca30-4e4d-9d43-53b80dd74d86","collapsed":true,"trusted":true},"cell_type":"code","source":"#With weights\n#Max depth 4\n#child weight 3\n#gamma 0.1\n#colsample 0.3\n\n#Without weights: child weight=4, lambda=4\n\nparams2={\n'max_depth':4,\n'learning_rate':0.1, \n'n_estimators':300, \n'silent':True, \n'booster':'gbtree',\n'n_jobs':1, \n'nthread':4, \n'gamma':0.1, \n'min_child_weight':3, \n'max_delta_step':0, \n'subsample':1, \n'colsample_bytree':0.3, \n'colsample_bylevel':1, \n'reg_alpha':0, \n'reg_lambda':1, \n'scale_pos_weight':1, \n'base_score':0.5, \n'random_state':1,\n'missing':None,}","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"0865456b8a72cef74e45b579d305a70e1293b691","_kg_hide-input":true,"_cell_guid":"b8a2e4dd-e70a-4af0-96fd-e01de7ee6456","_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"#Type 2 classification\nmodel_xgb2=xgb.XGBClassifier(**params2)\neval_set = [(Gens_not1_features, Gens_not1_targets2),(Gen1_features, Gen1_targets2)]\nmodel_xgb2.fit(Gens_not1_features, Gens_not1_targets2,sample_weight=weights,eval_set=eval_set,eval_metric=\"merror\",verbose=False)\ntraining_eval=model_xgb2.evals_result()\nmin_error=min(training_eval['validation_1']['merror'])\nprint(\"The minimum error is:\")\nprint(min_error)\ntraining_step=training_eval['validation_1']['merror'].index(min_error)\nprint(\"This occurs at step:\")\nprint(training_step)\nxgb.plot_importance(model_xgb2,max_num_features=20)","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"10cbcb7836fa6c59ee177425687002c55440d1b1","_kg_hide-input":true,"_cell_guid":"09e8b880-7456-439e-af0b-c648f27c81e5","trusted":true},"cell_type":"code","source":"#Type 2 final version\nparams2['n_estimators']=242\nmodel_xgb2=xgb.XGBClassifier(**params2)\n\nmodel_xgb2.fit(Gens_not1_features, Gens_not1_targets2,weights)\nGen1_T2_pred = model_xgb2.predict(Gen1_features)\n\n# evaluate predictions\ntest_accuracy = accuracy_score(Gen1_targets2, Gen1_T2_pred)\nprint(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\nxgb.plot_importance(model_xgb2,max_num_features=20)\n# Output a plot of the confusion matrix.\nlabels =list(set(Gen1_targets2))\ncm = metrics.confusion_matrix(Gen1_targets2, Gen1_T2_pred,labels)\n# Normalize the confusion matrix by row (i.e by the number of samples\n# in each class)\ncm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\nsns.set(font_scale=4)\nplt.figure(figsize=(20,20))\nax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\nax.set_aspect(1)\nax.set_xticklabels(labels)\nax.set_yticklabels(labels)\nplt.xticks(rotation=90)\nplt.yticks(rotation=0)\nplt.title(\"Type 2 Confusion matrix\")\nplt.ylabel(\"True label\")\nplt.xlabel(\"Predicted label\")\nplt.show()\nsns.set(font_scale=0.8)","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"dc8d0dae7d07652aef0bc5446befd983225a806b","_cell_guid":"fafa04be-1658-46bf-95da-4564b35553d8"},"cell_type":"markdown","source":"After hyperparameter tuning, I was able to get a 67.55% accuracy for Type 2, which marginally beats my older model.\n\nAs always for Type 2, most types were incorrectly predicted as None, with a few other misclassifcations, as for example Rock, Ground or Poison.\n\nFlying and Rock stand out as particularly good predictions, with most of both correctly identified. Steel, Psychic and Ground all have a reasonable number of correct predictions.\n\nSince type ordering is somewhat arbitrary, there is the possibility that some of these are correct predictions, but for Type 1, rather than type 2."},{"metadata":{"_uuid":"7e9c00f16da37bd3a0905e87cebb6abfb1865054","_kg_hide-input":true,"_cell_guid":"cfd36b61-c727-422d-97d4-c3c24ddcf43d","trusted":true},"cell_type":"code","source":"print(\"Some predictions may match the main type, rather than the sub-type\")\nmismatch_accuracy_T2 = accuracy_score(Gen1_targets, Gen1_T2_pred)\nprint(\"Mismatch Accuracy: %.2f%%\" % (mismatch_accuracy_T2 * 100.0))\nprint(\"The Pokemon whose predicted types match their main type are:\")\nfor i in range(0,len(Gen1_targets2)):\n    if Gen1_T2_pred[i] == Gen1_targets[i]:\n        print (pokemon_df[\"name\"][i])","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"e61a62d56fe707cbbd14a4b7974c1f70b8d1f7e6","_cell_guid":"28406d96-b5c4-4365-9ef7-194d81beb5b0"},"cell_type":"markdown","source":"In this case, 6 Pokemon had the correct type predictions, but in the wrong order. The 4 fossil Pokemon, between Omanyte and Kabutops, have appeared in both sets of mis-ordered predictions. This means that both types were correctly predicted, just in the wrong order.\n\nAs before, it might be instructive to look at the incorrect predictions to try and work out where they went wrong."},{"metadata":{"_uuid":"0e50f3b96a84494cc372a1f5535b7d3501d3349c","_cell_guid":"441aeed8-d33f-4f75-ad86-b26a4e79ce20","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"Pokemon with incorrect sub-types are as follows:\")\nfor i in range(0,len(Gen1_targets2)):\n    if Gen1_T2_pred[i] != Gen1_targets2[i]:\n        print (pokemon_df[\"name\"][i],Gen1_T2_pred[i])","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"6e284b4e9828cd9f0edb079b9f6592fb9b10ca17","_cell_guid":"29d3890d-c343-4a34-9f4c-1b7e25d7541b"},"cell_type":"markdown","source":"In the majority of cases, it is just a matter that None was selected instead of the correct type, suggesting it might be possible to add more information to the model and improve the predictions.\n\nIn other cases, a Pokemon was predicted a type, but it was wrong. A few of these are interesting, given the nature of the incorrect prediciton.\n\nFor example, Charizard is predicted to have Dragon, rather than Flying sub-type. This has been a wish of fans since the beginning, and actually came true for one of the Mega Evolutions.\n\nBeedrill and Venomoth are both predicted to be Flying sub-type, which is understandable, given that they both have wings, however they are both actually poison types.\n\nSome of the other mistakes, like Mewtwo being sub-type Ice, or Gyarados being Ground, are just odd."},{"metadata":{"_uuid":"0e5589753b945c12e1f11d486330f8d9e6546811","_cell_guid":"d0a09a66-43b2-4f2d-be9d-aaa4544368fb"},"cell_type":"markdown","source":"I improved both of my models by incorporating the ordering mismatches. This lead to slight improvements for both models, although by less than the number of mis-ordered Types. This is because the other model may have predicted the same type already, meaning that updating the value made no difference."},{"metadata":{"_uuid":"6e8440ebf1a251802e734fd23f855fac42b924ac","_kg_hide-input":true,"_cell_guid":"4d2e1567-ac80-4162-9f78-bea50c32b4f7","trusted":true},"cell_type":"code","source":"Gen1_T1_pred_v2=Gen1_T1_pred.copy()\nGen1_T2_pred_v2=Gen1_T2_pred.copy()\nfor i in range(0,len(Gen1_targets)):\n    if Gen1_T1_pred[i] == Gen1_targets2[i]:\n        Gen1_T2_pred_v2[i]=Gen1_T1_pred[i]\n        \nfor i in range(0,len(Gen1_targets)):\n    if Gen1_T2_pred[i] == Gen1_targets[i]:\n        Gen1_T1_pred_v2[i]=Gen1_T2_pred[i]\n        \nType1_accuracy = accuracy_score(Gen1_targets, Gen1_T1_pred_v2)\nprint(\"New Type 1 Accuracy: %.2f%%\" % (Type1_accuracy * 100.0))\nType2_accuracy = accuracy_score(Gen1_targets2, Gen1_T2_pred_v2)\nprint(\"New Type 2 Accuracy: %.2f%%\" % (Type2_accuracy * 100.0))","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"f2175b6402e9387c55a07ee8c2b73536df45db91","_cell_guid":"733e4b55-1f86-4d99-aad3-d4cadc59689a"},"cell_type":"markdown","source":"By combining the two models in this way, I was able to raise the accuracy of both to over 70%, and reach new records for both.\n\nSomething interesting to note, is that when I re-used my Type 1 parameters for Type 2, the overall accuracy was worse, but the mismatch percentage was higher. Meaning that I could get a 75% accuracy on Type 1 when both models were combined, but with a lower Type 2 accuracy.\n\nI'd still like to do feature engineering in some way, because I'm sure it must be possible to improve the accuracy further.\n\n"},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true,"_uuid":"cea2817a9721f4e298ceee4d76731f30c6e85580"},"cell_type":"code","source":"XGB_predictions_df=pd.DataFrame()\nXGB_predictions_df[\"Type1\"]=0\nXGB_predictions_df[\"Type1\"]=Gen1_T1_pred_v2\nXGB_predictions_df[\"Type2\"]=0\nXGB_predictions_df[\"Type2\"]=Gen1_T2_pred_v2\nXGB_predictions_df.to_csv(\"XGB_Predictions.csv\",index=False)","execution_count":26,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}