{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom glob import glob\nimport sklearn\nimport tensorflow as tf\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/A_DeviceMotion_data/A_DeviceMotion_data\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Activety types dict:\nActivety_Types = {'dws':1,'jog':2,'sit':3,'std':4,'ups':5,'wlk':6}        \nlistDict = list(Activety_Types.keys())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5df6426d2e5039faba3f0ff27aadfcda50cfb738"},"cell_type":"code","source":"# Data Folders:\nFolders = glob('../input/A_DeviceMotion_data/A_DeviceMotion_data/*_*')\nFolders = [s for s in Folders if \"csv\" not in s]\n\nDf_all_list = []\nExp = 0\n# Segment the data to 400 sampels frames , each one will be a different Expirament\nSegment_Size = 400\n\n# Load All data:\nfor j  in Folders:\n    Csv = glob(j + '/*' )\n\n\n    for i in Csv:\n        df = pd.read_csv(i)\n        # Add Activety label, Subject name and Experiment number\n        df['Activity'] = Activety_Types[j[49:52]]\n        df['Sub_Num'] = i[len(j)+5:-4]\n        df['Exp_num'] = 1\n        ExpNum = np.zeros((df.shape[0])) \n        for i in range(0,df.shape[0]-Segment_Size,Segment_Size):\n            ExpNum[range(i,i+Segment_Size)] = i/Segment_Size +Exp*100 \n        df['Exp_num'] = ExpNum\n        #Df_all = pd.concat([Df_all,df])\n        Df_all_list.append(df)\n        Exp += 1        \n\nDf_all = pd.concat(Df_all_list,axis=0)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b54d048e39cee294c3b2f58158d4404713366532"},"cell_type":"code","source":"# let's see the data\nDf_all.head()\nplt.plot([1,2,3])\n# now create a subplot which represents the top plot of a grid\n# with 2 rows and 1 column. Since this subplot will overlap the\n# first, the plot (and its axes) previously created, will be removed\n#plt.subplot(2,1,1)\n#plt.plot(range(12))\nfor i in range(6):\n    D = Df_all[Df_all['Activity']==i+1]\n    plt.subplot(3,2,i+1)\n    plt.plot(D['userAcceleration.z'][:200])\n    plt.title(listDict[i])\n    plt.ylim([-1, 1])\nplt.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f64ad0401054213d0db26b2b3d053f35bfd8ff8a"},"cell_type":"code","source":"#  Calculate features\ndf_sum = Df_all.groupby('Exp_num', axis=0).mean().reset_index()\ndf_sum.columns = df_sum.columns.str.replace('.','_sum_')\n\ndf_sum_SS = np.power(Df_all.astype(float),2).groupby('Exp_num', axis=0).median().reset_index() \ndf_sum_SS.columns = df_sum_SS.columns.str.replace('.','_sumSS_')\n\ndf_max = Df_all.groupby('Exp_num', axis=0).max().reset_index()\ndf_max.columns = df_max.columns.str.replace('.','_max_')\n\ndf_min = Df_all.groupby('Exp_num', axis=0).min().reset_index()\ndf_min.columns = df_min.columns.str.replace('.','_min_')\n\ndf_skew = Df_all.groupby('Exp_num', axis=0).skew().reset_index()\ndf_skew.columns = df_skew.columns.str.replace('.','_skew_')\n\ndf_std = Df_all.groupby('Exp_num', axis=0).std().reset_index()\ndf_std.columns = df_std.columns.str.replace('.','_std_')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3336e8af7d910f43b3a7a255719a36b9f2c3d3a8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1a8489d4b77fb5a85c7ca3f546dab63b3d82369"},"cell_type":"code","source":"# Concat features and labels vector into one Data Frame:\nDf_Features = pd.concat([ df_max , df_sum[df_sum.columns[2:-2]], \n                         df_min[df_min.columns[2:-2]], df_sum_SS[df_sum_SS.columns[2:-2]], \n                         df_std[df_std.columns[2:-2]], df_skew[df_skew.columns[2:-2]]], axis=1)\n# Features\nDf_Features_1 = Df_Features.drop(['Exp_num','Unnamed: 0','Activity','Sub_Num'],axis=1)\nLabels = Df_Features['Activity']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc2a7190856feddaf6027e39ef87a7735a34a3dd"},"cell_type":"code","source":"# Train test split (this can be done also by user, to makeit a more realistic case)\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(Df_Features_1, Labels, test_size=0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8aedfd7fa536b4549311bc2e29290d616f6ed1d6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5df8fffee95dc7ff0ea0bc8071d33d0ed0d6e479"},"cell_type":"code","source":"# Define placeholders for X and Y\nX_shape = Df_Features_1.shape[1]\nCluss_Num = len(Activety_Types)\nX = tf.placeholder(dtype=tf.float32,shape=[None,X_shape])\ny = tf.placeholder(dtype=tf.float32,shape = [None,Cluss_Num])\nHold_prob = tf.placeholder(tf.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8cc31debd8262805295b36653b719073337be1a3"},"cell_type":"code","source":"# Helper functions for DNN design\ndef Init_Wightes(shape1):\n    W = tf.truncated_normal(shape1,stddev=0.1)\n    return tf.Variable(W)\n\ndef Init_bias(shape1):\n    b =  tf.constant(0.1,shape=shape1)\n    return tf.Variable(b)\n\ndef FC_layer(input1,shape1):\n    \n    W = Init_Wightes(shape1)\n    B = Init_bias([shape1[1]])\n    Wx = tf.matmul(input1,W)\n    Wx_b = tf.add(Wx,B)\n    return tf.nn.relu(Wx_b)\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba6ac1c923530736578afcccc7e61f3084bd82cd"},"cell_type":"code","source":"# Define model parmeters and net design\nH1_size = 54\nH2_size = 24\n\nH1 = FC_layer(X, [X_shape,H1_size])\n#H2 = FC_layer(H1,[H1_size,H2_size])\nH1_drop = tf.nn.dropout(H1,keep_prob=Hold_prob)\ny_pred = FC_layer(H1_drop,[H1_size,len(Activety_Types)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82c0dcd5dd5a0e3cd3adb9c347228e680388f92e"},"cell_type":"code","source":"# Set TensorFlow Error and train function\nErr = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=y_pred))\nOptimaizer = tf.train.AdamOptimizer()\nTrain = Optimaizer.minimize(Err)\nInit = tf.global_variables_initializer()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cc0561ef470b4536640c16aca4205e76d048073"},"cell_type":"code","source":"BatchSize = 64\nlabel_binarizer = sklearn.preprocessing.LabelBinarizer()\nlabel_binarizer.fit(range(Cluss_Num))\n\n# convarte to numpy and devide into batches:\n\nX_train_Np = np.array(X_train,dtype=np.float32)\nY_train_Np = np.array(y_train,dtype=np.float32)\nX_test_Np = np.array(X_test,dtype=np.float32)\nY_test_Np = np.array(y_test,dtype=np.float32)\nY_test_OH  = label_binarizer.transform(Y_test_Np)\nY_test_OH = np.array(Y_test_OH,dtype=np.float32)\nBatches = np.array(range(0,X_train_Np.shape[0]-BatchSize,BatchSize))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52ece1e51a5c7152328772fda2faaafa9e2cd864"},"cell_type":"code","source":"# Run net\nsteps = 5000\n\nwith tf.Session() as sess:\n    \n    sess.run(Init)\n    \n    for i in range(steps):\n        \n        BastchNum = np.mod(i,len(Batches)-1)\n        #print(BastchNum)\n        batch_x = X_train_Np[Batches[BastchNum] : Batches[BastchNum+1] ,:]\n        batch_y = Y_train_Np[Batches[BastchNum] : Batches[BastchNum+1] ]\n        batch_y_OH  = label_binarizer.transform(batch_y)\n        batch_y_OH = np.array(batch_y_OH,dtype=np.float32)\n        sess.run(Train,feed_dict={X:batch_x,y:batch_y_OH,Hold_prob:0.5})\n        \n        # PRINT OUT A MESSAGE EVERY 100 STEPS\n        if i%100 == 0:\n            \n            print('Currently on step {}'.format(i))\n            print('Accuracy is:')\n            # Test the Train Model\n            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y,1))\n\n            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n\n            print(sess.run(acc,feed_dict={X:X_test_Np,y:Y_test_OH,Hold_prob:1.0}))\n            print('\\n')\n            Conf = tf.confusion_matrix(tf.arg_max(y_pred,1),tf.arg_max(y,1))\n            C1 = sess.run(Conf,feed_dict={X:X_test_Np,y:Y_test_OH,Hold_prob:1.0})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f07a371d293d19bdab02a9983515c136d1dd0d95"},"cell_type":"code","source":"# Plot Confusion matrix\ndef plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import itertools\n\n    accuracy = np.trace(cm) / float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()\n    \n    \nConf = tf.confusion_matrix(tf.arg_max(y_pred,1),tf.arg_max(y,1))\nplot_confusion_matrix(C1,target_names=[*Activety_Types])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdaca27a67cc4b9c42147ef03aec99ad6bf26f98"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ee79ea7c063298c4beaa78fceec75467f9e6562"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9f09fc7f01a19e1816a39a4cebe3d45a0d0d828"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}