{"cells":[{"metadata":{},"cell_type":"markdown","source":"> Goal to find out spam or not "},{"metadata":{},"cell_type":"markdown","source":"import "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport string\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport nltk\nfrom nltk.corpus import stopwords\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"load dataset "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/sms-spam-collection-dataset/spam.csv', encoding='latin-1')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"cleaning data "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis= 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"change name of columns for more comfortable using "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.rename(columns={'v1': 'label', 'v2': 'text'}, inplace=True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('label').describe()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"add count column"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['length'] = data['text'].apply(len)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.length.describe()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualition **"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['length'].plot(bins=100, kind='hist') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.hist(column='length', by='label', bins=50, figsize=(15,5))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"add function for drop punctuation marks"},{"metadata":{"trusted":true},"cell_type":"code","source":"def text_process(mess):\n    \n    nopunc = [char for char in mess if char not in string.punctuation]\n\n    nopunc = ''.join(nopunc)\n    \n    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"split set of data for training"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nmsg_train, msg_test, label_train, label_test = \\\ntrain_test_split(data['text'], data['label'], test_size=0.3)\n\nprint(len(msg_train), len(msg_test), len(msg_train) + len(msg_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"size of test 30% of dataset  1672 sms of  5572, for learning  -  3900  of 5572\n"},{"metadata":{},"cell_type":"markdown","source":"Logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = Pipeline([\n    ('bow', CountVectorizer(analyzer=text_process)), \n    ('tfidf', TfidfTransformer()),  \n    ('classifier', LogisticRegression()),  \n])\npipeline.fit(msg_train,label_train)\npredictions=pipeline.predict(msg_test)\nprint(classification_report(predictions,label_test))\nlrscore=accuracy_score(predictions,label_test)\nprint(lrscore)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline1 = Pipeline([\n    ('bow', CountVectorizer(analyzer=text_process)), \n    ('tfidf', TfidfTransformer()), \n    ('classifier', MultinomialNB()), \n])\npipeline1.fit(msg_train,label_train)\npredictions1 = pipeline1.predict(msg_test)\nprint(classification_report(predictions1,label_test))\nnbscore=accuracy_score(predictions1,label_test)\nprint(nbscore)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"result"},{"metadata":{"trusted":true},"cell_type":"code","source":"results=[lrscore,nbscore]\nn=['Logis. regression','Naiva Bayse']\nndf=pd.DataFrame(n)\nrdf=pd.DataFrame(results)\nrdf[1]=n\nprint('Accuracy')\nrdf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Naiva Bayse better match than Logistic regression"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}