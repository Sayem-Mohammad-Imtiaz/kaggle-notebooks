{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Hotel Booking\n\nGoal : Predict the chances of cancelation using data of costumers from multiple hotels.\nThe data is given in a tabular form of 32 columns (20 numerical + 12 objects).\n\nAs a first stage the data was seperated to training/validation/test sets.\nTo get the optimal model I have investigated the features in the training-set, starting with the numerical features that are most correlated with the target. \nI proceded with encoding the categorical features while monitoring the accuracy with a small subset of features to get an initial estimation of the achievable prediction.\n\nModel selection was made by considering three models (Random Forest, Gradient Boosting and Logistic Regression) and evaluating them on the validation set. The effectiveness of dimensionality-reduction (using PCA) and model tuning (using Grid-Search) was assessed as well.\n\nContent:\n1. Import and read the data\n2. Data Analysis\n3. Model"},{"metadata":{},"cell_type":"markdown","source":"# 1. Import and read data:\n* Import libraries\n* Read and explore data : remove unimportant & incomplete data\n* Split into train-val-test"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/hotel-booking-demand/hotel_bookings.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info(), len(data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.abs(data.corr()['is_canceled']).sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(labels = ['country', 'agent', 'company'], axis =1)\ndata.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split the data to train-val-test\ntrain_val, test = train_test_split(data, train_size=0.9, test_size=0.1, random_state=42)\ntrain,val = train_test_split(train_val, train_size = 0.89, test_size=0.11, random_state=42)\nlen(data), len(train), len(val), len(test), len(train)/len(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Data analysis\nIncludes:\n* Data visualization\n* Data cleaning\n* Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"### Features\n\n* is_canceled : Value : indicating if the booking was canceled (1) or not (0)\n* lead_time : Number of days that elapsed between the entering date of the booking into the PMS and the arrival date\n* arrival_date_year : Year of arrival date\n\n* arrival_date_week_number : Week number of year for arrival date\n* arrival_date_day_of_month : Day of arrival date\n* stays_in_weekend_nights : Number of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel\n* stays_in_week_nights : Number of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel\n* adults : Number of adults\n* children : Number of children\n* babies : Number of babies\n\n* country : Country of origin. Categories are represented in the ISO 3155–3:2013 format\n\n* is_repeated_guest : Value indicating if the booking name was from a repeated guest (1) or not (0)\n* previous_cancellations : Number of previous bookings that were cancelled by the customer prior to the current booking\n* previous_bookings_not_canceled : Number of previous bookings not cancelled by the customer prior to the current booking\n\n* booking_changes : Number of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation\n\n* agentID of the travel agency that made the booking\n* companyID of the company/entity that made the booking or responsible for paying the booking. ID is presented instead of designation for anonymity reasons\n* days_in_waiting_list - Number of days the booking was in the waiting list before it was confirmed to the customer\n\n* adr : Average Daily Rate as defined by dividing the sum of all lodging transactions by the total number of staying nights\n* required_car_parking_spaces : Number of car parking spaces required by the customer\n* total_of_special_requests : Number of special requests made by the customer (e.g. twin bed or high floor)\n\n* reservation_status_date : Date at which the last status was set. This variable can be used in conjunction with the ReservationStatus to understand when was the booking canceled or when did the customer checked-out of the hotel"},{"metadata":{},"cell_type":"markdown","source":"## Top Correlated Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check most correlated features\nmost_corr = np.abs(train.corr()['is_canceled']).sort_values(ascending=False)[1:7]\nmost_corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sns.pairplot(train[most_corr.index])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['is_canceled'].value_counts(normalize = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### lead_time \nNumber of days that elapsed between the entering date of the booking into the PMS and the arrival date\nWe will use lead-time as a one-feature-desicion criterion"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['lead_time'].plot(kind='kde')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['lead_time'].quantile(np.arange(0.1,1,0.1))\n#np.arange(0.1,1,0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qlt = pd.qcut(train['lead_time'],10, labels=False)\nqlt_df=pd.concat([qlt, train['is_canceled']], axis=1)\nqlt_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x= 'lead_time', y='is_canceled', data=qlt_df, )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qlt_df['is_canceled'].groupby(qlt_df['lead_time']).value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qlt_df['lead_time'].groupby(qlt_df['is_canceled']).value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qlt_df['lead_time'].groupby(qlt_df['is_canceled']).value_counts(normalize=True)[1].plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preliminary Accuracy Estimation\nwe will create an accuracy dataframe to monitor the quality of prediction at any step"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_prediction = pd.DataFrame(columns = ['Score'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### One-feature-decision"},{"metadata":{"trusted":true},"cell_type":"code","source":"qlt_df['Decision'] = 0\n#cond1  = (qlt_df['lead_time']==(11.0, 26.0]) | (qlt_df['lead_time']==(2.0, 11.0]) | ( qlt_df['lead_time']==(-0.001, 2.0])\nqlt_df.loc[qlt_df['lead_time']>=7, 'Decision'] = 1\nqlt_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qlt_df['Decision'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_score(prediction,validation,name):\n    acc = np.round(accuracy_score(validation,prediction) * 100, 2)\n    print('Accuracy Score : ',acc)\n    df_prediction.loc[name,'Score'] = acc\n    cm_norm = confusion_matrix(prediction,validation)/(confusion_matrix(prediction,validation).sum())\n    return sns.heatmap(cm_norm, cmap='hot', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_score(qlt_df['Decision'],qlt_df['is_canceled'],'Top 1 Numeric Feat')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Intuitvely, the longer the lead-time is the probability of canceltion is growing.\n* for the bottom centile (up to 2 days) the chances for cancelation are 8%\n* for the 8th and 9th centile (137-265 days) the chances for cancelation are ~50%\n* for the upper centile (more than a year) the chances for cancelation are 67%\n* Prediction based solely on lead_time is no better than all-True ~65%"},{"metadata":{},"cell_type":"markdown","source":"#### Top-5 correlated Festures based Decision\nWe will check the accuracy achieved for a minimal number of features without any feature engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_5 = train[most_corr.index.values]\ntrain_5.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_5.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_5 = val[most_corr.index.values]\nval_5.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_5 = train['is_canceled']\ntarget_val_5 = val['is_canceled']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_5 = RandomForestClassifier()\nrf_5.fit(train_5, target_5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf5_pred = rf_5.predict(val_5)\nprint_score(rf5_pred,target_val_5,'Top 5 Numeric Feat')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preliminary accuracy estimations shows that one feature is sufficient to reach an accuracy level of ~70% and five features are can yield a prediction with ~75% accuracy. Involvement of more features by categorical encoding, feature enginnering and hyperparameters optimization should give rise to a better result"},{"metadata":{},"cell_type":"markdown","source":"### total_of_special_requests\nNumber of special requests made by the customer (e.g. twin bed or high floor)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['total_of_special_requests'].value_counts(normalize=True).plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['is_canceled'].groupby(train['total_of_special_requests']).value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='total_of_special_requests', y='is_canceled', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qlt_df['total_of_special_requests']=train['total_of_special_requests']\nqlt_df.pivot_table(index='lead_time', columns='total_of_special_requests', values='is_canceled')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"More special requests reduce the probability of cancelation "},{"metadata":{},"cell_type":"markdown","source":"### required_car_parking_spaces\nThe values of this feature arise several questions: \n* Is car space is actually a type of special request? in the sense that it indicates planning and ingagement\n* Are car spaces correlated with the type of need? for example, in buissness trips or resorts it is more common to travel without a car\n* Is more than one car space imply planning of many members? a fact that may increase the engagement but also the logistic complication"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['required_car_parking_spaces'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['required_car_parking_spaces'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# it is obvious that more than two cars are rare and stated in a different category, \n#therefore we will change the classification of this feature, not enough data for 3 cars or more\ntrain.loc[train['required_car_parking_spaces']>1,'required_car_parking_spaces']=2\nval.loc[val['required_car_parking_spaces']>1,'required_car_parking_spaces']=2\ntest.loc[test['required_car_parking_spaces']>1,'required_car_parking_spaces']=2\ntrain['required_car_parking_spaces'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['is_canceled'].groupby(train['required_car_parking_spaces']).value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x = 'required_car_parking_spaces',y ='is_canceled', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The only cancelations are from people that does not ask for a parking space (who are 93% of the population)\nthe 7% who ask for a parking space do not cancel"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.abs(train.corr()['required_car_parking_spaces']).sort_values(ascending=False)[1:7]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### hotel"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['hotel'].groupby(train['required_car_parking_spaces']).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['required_car_parking_spaces'].groupby(train['hotel']).value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='required_car_parking_spaces', y='hotel', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking if cancelation is correlated to the type of hotel, regardless to parking spaces\ntrain['is_canceled'].groupby(train['hotel']).value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most reservations are without parking space request (94%), request of more than one parking space is rare, more than two is an outlier\n* parking space requests are more common in resorts, however it is not highly correlated\n* the 7% who ask for a parking space do not cancel the booking"},{"metadata":{},"cell_type":"markdown","source":"### booking_changes\nNumber of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['booking_changes'].value_counts(normalize=True).plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['booking_changes'].value_counts(),train['booking_changes'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['booking_changes']>5,'booking_changes']=6\nval.loc[val['booking_changes']>5,'booking_changes']=6\ntest.loc[test['booking_changes']>5,'booking_changes']=6\ntrain['booking_changes'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['is_canceled'].groupby(train['booking_changes']).value_counts(normalize=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='booking_changes',y='is_canceled',data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"looks like there is no significant difference between one change and multiple changes as far as it goes to cancellation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['is_change']=0\ntrain.loc[train['booking_changes']>0,'is_change']=1\ntrain[['is_change','booking_changes']][10:30]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.corr()[['is_change','booking_changes']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.abs(train.corr()['is_change']-train.corr()['booking_changes']).sort_values(ascending=False)[2:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Is_change is not very diffrent from booking_changes, however it is more correlated to cancelation and babies/adults and less correlated to stays_in_week_nights. It is worth while to check the correlation between adults/babies to week nights/weekend nights"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace booking_changes by is_change and apply changes to validation and test sets\nval['is_change']=0\ntest['is_change']=0\nval.loc[val['booking_changes']>0,'is_change']=1\ntest.loc[test['booking_changes']>0,'is_change']=1\n\ntrain = train.drop('booking_changes',axis=1)\nval = val.drop('booking_changes',axis=1)\ntest = test.drop('booking_changes',axis=1)\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.corr()['is_change'].sort_values(ascending=False)[1:7]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.corr()['is_change'].sort_values(ascending=True)[:7]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"changes are slightly correlated to babies/car_space and children and negatively correlated to cancelations and adults\nIt is worth analyzing if changes without children and babies are different from other cancelations"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.pivot_table(index='is_change', columns='babies',values='is_canceled')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Focusing on the population that makes changes, it does not matter if they have babies or not"},{"metadata":{},"cell_type":"markdown","source":"### previous_cancellations\nNumber of previous bookings that were cancelled by the customer prior to the current booking"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['previous_cancellations'].value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['previous_cancellations'].value_counts().sort_index()[2:].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['previous_cancellations'].value_counts().sort_index()[3:].plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prc = train['previous_cancellations']\nsns.barplot(x='previous_cancellations',y='is_canceled',data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is clear that cancelation is varying with previous_cancellations in a non-monotonic manner, it can be categorized into 4 populations: \n* 0 : with ~30% cancelations\n* 1 : with ~90% cancelations! \n* 2 - 11 : with higly varying cancelations of 10%-50%\n* more than 12 : with 100% cancelations\n\nWe can categorize the data accordingly all to a new scale of categories: 0,1,2,3, however the data is too small and the distribtion does not make a lot of sense. It appears that other parameter may be involved.\nWe can engineer the features in a way they will make more sense by checking correlation with other features"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.abs(train.corr()['previous_cancellations']).sort_values(ascending=False)[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['previous_bookings_not_canceled'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will create a new feature of the cancelation percentage\ntotal_canc = train['previous_bookings_not_canceled'] + train['previous_cancellations']\ntrain['previous_cancellation_per'] =  train['previous_cancellations'].div(total_canc)\ntrain['previous_cancellation_per'] = train['previous_cancellation_per'].fillna(0)\ntrain[['previous_cancellations','previous_bookings_not_canceled','previous_cancellation_per']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['previous_cancellation_per'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = [-1,0,0.5,1]\ntrain['previous_cancellation_per'] =  pd.cut(train['previous_cancellation_per'], bins, labels = [0,1,2])\nsns.barplot(x='previous_cancellation_per',y='is_canceled',data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['previous_cancellation_per'] = train['previous_cancellation_per'].astype('int64')\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.abs(train.corr()[['previous_cancellation_per','previous_cancellations']]).sort_values(ascending=False,by='previous_cancellation_per')\ntrain[['previous_cancellation_per','previous_cancellations','previous_bookings_not_canceled','is_canceled']].corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The new feature 'previous_cancellation_per' which was constructed from 'previous_cancellations' and 'previous_bookings_not_canceled' is correlated much better to the target parameter 'is_canceled'. It comes as no surprise as its distribution in relation to cancelation makes more sense. As 'previous_bookings_not_canceled' still hold some information 'previous_cancellations' can only confuse the model, therefore we will use 'previous_cancellation_per' instead."},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_previous_cancelation_per(df):\n    total_canc = df['previous_bookings_not_canceled'] + df['previous_cancellations']\n    df['previous_cancellation_per'] =  df['previous_cancellations'].div(total_canc)\n    df['previous_cancellation_per'] = df['previous_cancellation_per'].fillna(0)\n    bins = [-1,0,0.5,1]\n    df['previous_cancellation_per'] =  pd.cut(df['previous_cancellation_per'], bins, labels = [0,1,2])\n    df['previous_cancellation_per'] = df['previous_cancellation_per'].astype('int64')\n    df = df.drop('previous_cancellations',axis=1)\n    return df\n\nval = add_previous_cancelation_per(val)\ntest = add_previous_cancelation_per(test)\ntrain = train.drop('previous_cancellations',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val['previous_cancellation_per'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### is_repeated_guest"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['is_repeated_guest'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['is_canceled'].groupby(train['is_repeated_guest']).value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='is_repeated_guest',y='is_canceled',data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Repeated guests tend to cancel less"},{"metadata":{},"cell_type":"markdown","source":"## Other Numerical Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_feat = list(train.columns[(train.dtypes.values=='int64')|(train.dtypes.values=='float64')])\nnon_num_feat = list(train.columns[(train.dtypes.values!='int64')&(train.dtypes.values!='float64')])\nnum_feat, non_num_feat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if 'is_canceled' in num_feat:\n    num_feat.remove('is_canceled')\nif 'is_change' in num_feat:\n    num_feat.remove('is_change')\nif 'previous_cancellation_per' in num_feat:\n    num_feat.remove('previous_cancellation_per')\nif 'previous_bookings_not_canceled' in num_feat:\n    num_feat.remove('previous_bookings_not_canceled')\n    \nfor item in list(most_corr.index):\n    if item in num_feat:\n        num_feat.remove(item)\nnum_feat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[num_feat]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The rest of the columns can be classified to three:\n* date (year,weak number,day)\n* stays in week/weekends nights\n* number of guests (adults/children/babies)\n* address"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[num_feat].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Four points of missing values are insignificant, however, as it is the only missing values to fill I will demonstrate data cleaning on them by correlating to another feature"},{"metadata":{},"cell_type":"markdown","source":"### Children"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.abs(train.corr()['children']).sort_values(ascending=False)[1:6]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most correlated feature: adr\n* adr : Average Daily Rate as defined by dividing the sum of all lodging transactions by the total number of staying nights"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['adr'].groupby(train['children']).median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='children', y='adr', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the absence of a better measure and given the fact that the 'adr' is extremely low we will predict children=0 for all na samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['children'].isnull(),'children']=0\ntrain.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## None numerical features\nNone numerical features were not considered when the most correlated features were calculated\\\nThe category encoders that may be used:\n* Simple encoding for ordinal features -> 0,1,2...\n* get_dummies, split a category to binary features\n* Target encoding - mean value of a category in relation to the target, to avoid overfitting we will use Leave-One-Out"},{"metadata":{},"cell_type":"markdown","source":"The features are:\n* hotel : Hotel (H1 = Resort Hotel or H2 = City Hotel)\n* arrival_date_month : Month of arrival date\n* meal : Type of meal booked. Categories are presented in standard hospitality meal packages: Undefined/SC – no meal package; BB – Bed & Breakfast; HB – Half board (breakfast and one other meal – usually dinner); FB – Full board (breakfast, lunch and dinner)\n* market_segment : Market segment designation. In categories, the term “TA” means “Travel Agents” and “TO” means “Tour Operators”\n* distribution_channel: Booking distribution channel. The term “TA” means “Travel Agents” and “TO” means “Tour Operators”\n* reserved_room_type : Code of room type reserved. Code is presented instead of designation for anonymity reasons.\n* assigned_room_type : Code for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g. overbooking) or by customer request. Code is presented instead of designation for anonymity reasons.\n* deposit_type : Indication on if the customer made a deposit to guarantee the booking. This variable can assume three categories: No Deposit – no deposit was made; Non Refund – a deposit was made in the value of the total stay cost; Refundable – a deposit was made with a value under the total cost of stay.\n* customer_type : Type of booking, assuming one of four categories: Contract - when the booking has an allotment or other type of contract associated to it; Group – when the booking is associated to a group; Transient – when the booking is not part of a group or contract, and is not associated to other transient booking; Transient-party – when the booking is transient, but is associated to at least other transient booking\n* reservation_status : Reservation last status, assuming one of three categories: Canceled – booking was canceled by the customer; Check-Out – customer has checked in but already departed; No-Show – customer did not check-in and did inform the hotel of the reason why"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_flag = False\ntrain[non_num_feat].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a dataframe of all the unique categories\ncat_df = pd.DataFrame(index = non_num_feat, columns = ['Unique Values', 'Number of Categories'])\nfor feature in non_num_feat:\n    cat_df.loc[feature,'Unique Values'] = train[feature].unique()\n    cat_df.loc[feature,'Number of Categories'] = len(train[feature].unique())\ncat_df.drop('reservation_status_date', axis=0, inplace=True)\ncat_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['deposit_type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='deposit_type',y='is_canceled', data = train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['reservation_status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='reservation_status', y='is_canceled', data = train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The correlation between the target and the reservation status  is much too high, suggesting that the feature is actually bound to the target, as it will probably cause data leakage we'll later remove it from the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dummies(df,var,prefix=None):\n    dummies = pd.get_dummies(df[var], prefix = prefix)\n    df = pd.concat([df, dummies], axis=1)\n    df = df.drop(var, axis=1)\n    return df\n\ndef set_cat_feat(df):\n\n    #Ordinal/binary parameters   \n    month = {\n        'January':1, 'February':2, 'March':3, 'April':4, 'May':5, 'June':6, 'July':7,\\\n        'August':8, 'September':9, 'October':10, 'November':11, 'December':12}\n    hotel = { 'Resort Hotel' : 0, 'City Hotel' : 1}\n    df['arrival_date_month'] = df['arrival_date_month'].map(month)\n    df['hotel'] = df['hotel'].map(hotel)\n    \n    df['assigned/reserved'] = 0\n    df.loc[df['reserved_room_type']==df['assigned_room_type'],'assigned/reserved']=1\n    df = df.drop('reserved_room_type', axis=1)\n    df = df.drop('assigned_room_type', axis =1)\n    \n    df = df.drop('reservation_status', axis=1)\n    \n    dummy_feat = ['meal','market_segment','distribution_channel','customer_type','deposit_type']\n    dummy_prefix=['meal','MS','DC','CT','DT']\n    \n    # get_dummies for parameters with a few categories, as we face classification problem no need to drop any category\n    for i in range(len(dummy_feat)):\n        df = dummies(df,dummy_feat[i],dummy_prefix[i])\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = train.loc[:,non_num_feat+ ['is_canceled']]\ntemp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply changes in all the datasets\nif cat_flag == False:\n    print('Perform encoding...')\n    train = set_cat_feat(train)\n    val = set_cat_feat(val)\n    test = set_cat_feat(test)\n    cat_flag=True\n\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dates\nreservation_status_date \n* reservation_status : Reservation last status, assuming one of three categories: Canceled – booking was canceled by the customer; Check-Out – customer has checked in but already departed; No-Show – customer did not check-in and did inform the hotel of the reason why"},{"metadata":{"trusted":true},"cell_type":"code","source":"object_list = train.dtypes.index[train.dtypes=='object'].values\nobject_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"object_feat = object_list[0] # reservation_status_date\nminibatch = train.loc[:,[object_feat]]\nminibatch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"minibatch[['res_year','res_month','res_day']] = minibatch[object_feat].str.split('-', expand=True).astype(int)\nminibatch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"minibatch['res_year'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['arrival_date_year' ].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def adjust_dates(df):\n    object_feat = 'reservation_status_date'\n    df[['res_year','res_month','res_day']] = df[object_feat].str.split('-', expand=True).astype(int)\n    df = df.drop(object_feat, axis = 1)\n    years_dict = {2014:1,2015:2,2016:3,2017:4}\n    df['res_year'] = df['res_year'].map(years_dict)\n    df['arrival_date_year'] = df['arrival_date_year'].map(years_dict)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = adjust_dates(train)\nval = adjust_dates(val)\ntest = adjust_dates(test) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Final Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_test = train.columns.values.tolist()\nfor i in train.columns.values:\n    for j in test.columns.values:\n        if i==j:\n            missing_test.remove(i)\nmissing_val = train.columns.values.tolist()\nfor i in train.columns.values:\n    for j in val.columns.values:\n        if i==j:\n            missing_val.remove(i)\nmissing_test, missing_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in missing_val:\n    val[col]=0\nfor col in missing_test:\n    test[col]=0\n\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resort the columns\ntrain = train.reindex(sorted(train.columns), axis=1)\nval = val.reindex(sorted(train.columns), axis=1)\ntest = test.reindex(sorted(train.columns), axis=1)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.abs(train.corr()['is_canceled']).sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_prediction","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best correlation is to \"deposit transfer\" (DT) where NON-refund and No-deposit are the most informative statuses"},{"metadata":{"trusted":true},"cell_type":"code","source":"score_deposit = np.round((np.sum(train['DT_Non Refund']==train['is_canceled'])/len(train))*100,2)\ndf_prediction.loc['Top-1 Cat. Feat','Score']=score_deposit\nscore_deposit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feat_to_remove = train.columns[[\"RS\" in x for x in train.columns]].values\ntrain.columns.shape, val.columns.shape, test.columns.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Upon running the PCA for the first time, set 'n_components' to 'None' and then evaluate the 'explained_variance' variable for choosing the optimal number of n_components. In this case, 100 should be fine."},{"metadata":{},"cell_type":"markdown","source":"# 3. Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_Xy(df,target):\n    X = df.drop(target, axis=1) \n    y = df[target]\n    return X,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train = get_Xy(train,'is_canceled')\nprint('X dim = {}, y dim = {}'.format(X_train.shape, y_train.shape))\nprint(y_train[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test, y_test = get_Xy(test, 'is_canceled')\nX_val, y_val = get_Xy(val, 'is_canceled')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize input matrix\nsc = preprocessing.StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_val = sc.transform(X_val)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape, X_val.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Selection"},{"metadata":{},"cell_type":"markdown","source":"#### Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will start by running Random Forest with default hypreparameters\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_pred = rf.predict(X_val)\nprint_score(rf_pred, y_val, 'Random Forest')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Gradient Boosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"gb = GradientBoostingClassifier()\ngb.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb_pred = gb.predict(X_val)\nprint_score(gb_pred, y_val, 'Gradient Boosting')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"log = LogisticRegression()\nlog.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_pred = log.predict(X_val)\nprint_score(log_pred, y_val, 'Logistic Regression')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Dimensionality Reduction"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components = None)\nXp_train = pca.fit(X_train)\n\ntarget_var = 0.99\nexplained_variance = pca.explained_variance_ratio_\nev_curve = np.cumsum(explained_variance)\nplt.plot(ev_curve)\nplt.plot(np.arange(len(explained_variance)),np.ones(len(explained_variance))*target_var, color='red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_components = np.min(np.where(ev_curve>target_var))\nn_components","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components = n_components)\nXp_train = pca.fit_transform(X_train)\nXp_test = pca.transform(X_test)\nXp_val = pca.transform(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfp = RandomForestClassifier()\nrfp.fit(Xp_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfp_pred = rfp.predict(Xp_val)\nprint_score(rfp_pred, y_val, 'Random Forest (PCA)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_p = LogisticRegression()\nlog_p.fit(Xp_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_p_pred = log_p.predict(Xp_val)\nprint_score(log_p_pred, y_val, 'Logistic Regression (PCA)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At this point PCA doesn't seems very effective, especualy for logistic regression, therfore we'll procede with the original set of features"},{"metadata":{},"cell_type":"markdown","source":"### Model Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model = RandomForestClassifier()\n#Run a gridsearch\nrf_params = {\"max_depth\": [10,20,30,40],\n            \"max_features\": [10,20,35],\n            \"n_estimators\": [10,500,1000],\n            \"min_samples_split\": [2,5,10]}\n            \nrf_val = GridSearchCV(rf_model, \n                           rf_params, \n                           cv = 5, \n                           n_jobs = -1, \n                           verbose = 2) \n\nrf_val.fit(X_val, y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_val.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_tuned = RandomForestClassifier(max_depth = rf_val.best_params_.get('max_depth'), \n                                  max_features = rf_val.best_params_.get('max_features'), \n                                  min_samples_split = rf_val.best_params_.get('min_samples_split'),\n                                  n_estimators = rf_val.best_params_.get('n_estimators'))\n\nrf_tuned.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluation on Test set\nrft_pred = rf_tuned.predict(X_test)\nprint_score(rft_pred,y_test,'Random Forest (tuned)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"C = np.logspace(2, 8, 4)\npenalty = ['l1', 'l2']\nmax_iter = [100, 200, 500]\n#log_params = dict(C=C, penalty=penalty, max_iter=max_iter) \nlog_params = dict(C=C, penalty=['l2'], solver = ['lbfgs'], max_iter = max_iter) \nlog_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_model = LogisticRegression()\n#Run a gridsearch  \n#log_val = GridSearchCV(log_model, log_params, cv=5, verbose=0)\nlog_val = GridSearchCV(log_model, log_params, cv=5, verbose=0)\n\nlog_val.fit(X_val, y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_val.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_val.best_params_.get('C')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_tuned = LogisticRegression(C=log_val.best_params_.get('C'), max_iter=log_val.best_params_.get('max_iter'), solver= 'lbfgs')\n\nlog_tuned.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluation on Test set\nlog_t_pred = log_tuned.predict(X_test)\nprint_score(log_t_pred,y_test,'Logistic Regression (tuned)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluation Summary"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_prediction.plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Importance = pd.DataFrame( {\"Importance\": rf_tuned.feature_importances_*100},\n                         index = train.drop('is_canceled',axis=1).columns)\nImportance.sort_values(by = \"Importance\", axis = 0, ascending = False)[:10].plot(kind =\"barh\", color = \"r\")\n\nplt.xlabel(\"Variable Importance Level\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check the wrongly classified example"},{"metadata":{"trusted":true},"cell_type":"code","source":"wrong = []\nfor i in np.arange(len(y_test)):\n    if y_test.iloc[i]!=log_t_pred[i]:\n        wrong.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_ranked = Importance.sort_values(by = \"Importance\", axis = 0, ascending = True).index.values\n#pd.concat([test[feat_ranked],log_t_pred],axis=1)\ndf_wrong = test[feat_ranked].iloc[wrong]\ndf_wrong['Prediction'] = log_t_pred[wrong]\ndf_wrong['Target'] = test['is_canceled'].iloc[wrong]\ndf_wrong","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusions\nLoistic Regression found to be the best model for cancellation prediction. Hyperparameters tuning of the model provided additional improvement while dimensionality reduction using PCA seemed to be counter-productive.\nThe model was selected using the validation set and training was performed on the training set, the test set wan not used or analyzed until the final estimation which indicated more than 99.99% accuracy. The wrongly classified examples set (7) contains mostly false positive predictions in which all costumers did not have non-refundable deposit status (the most important feature) and the reservation was made on the day of the arrival. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}