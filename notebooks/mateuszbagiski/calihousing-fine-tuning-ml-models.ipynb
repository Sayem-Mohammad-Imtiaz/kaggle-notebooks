{"cells":[{"metadata":{},"cell_type":"markdown","source":"### To do:\n\n* Predictive imputing for total_bedrooms\n* Try more models (SVM?)\n* Ensembles of neural networks with random forests (and maybe something else)\n* Pipelines\n* Fine-tuning: grid-search, random-search\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Basic stuff\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nfrom tqdm import tqdm\n\n# Preprocessing\nfrom sklearn.model_selection import train_test_split as tts\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\n\n\n# Models, metrics etc\nfrom sklearn.linear_model import LinearRegression as LR\nfrom sklearn.tree import DecisionTreeRegressor as DTR\nfrom sklearn.ensemble import RandomForestRegressor as RFR\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.model_selection import cross_val_score as cvs\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers, optimizers, utils, callbacks","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"housing_dir = '../input/california-housing-prices/housing.csv'\n\ndata = pd.read_csv(housing_dir)\n\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the data\ndata = pd.read_csv(housing_dir)\n\n# Separate the numerical part of the data\ndata_num = data.drop('ocean_proximity', axis=1)\n\n# Names of the numerical attributes in the data\nattribs_num = [*data_num.columns.tolist(), 'ocean_distance'] # #####\n\n# Name of the only categorical attribute in the data\nattribs_cat = ['ocean_proximity']\n\n# I initialize an encoder here only to extract the list of labels in the same order in which they will be given later in the pipeline\nencoder = OneHotEncoder()\nencoder.fit(data[attribs_cat])\noh_labels = encoder.categories_[0].tolist()\n\n# Names of the attributes added by FeatExpander\nnew_features = [\n    'rooms_per_household',\n    'bedrooms_per_household',\n    'rooms_per_person',\n    'bedrooms_per_person',\n    'bedrooms_fraction',\n    'people_per_household'\n]\n\n# Names of columns needed for reconversion of the numpy array returned by column_transformer back into a DataFrame\ncolumns_tr = [*attribs_num, *new_features, 'center_distance', *oh_labels]\n\nclass OutlierRemover(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        X = X.copy() # To make sure that we don't change the original DataFrame\n        X_cleaned = X.drop(index = data.query(' `median_house_value` >= 500000 | `housing_median_age` >= 50 ').index.values)\n        return X_cleaned\n\nclass MyImputer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        X = X.copy()\n        X['total_bedrooms'].fillna(value=X['total_bedrooms'].median(), inplace=True)\n        return X\n\n\nclass FeatExpander(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        X = X.copy()\n        X['rooms_per_household'] = X['total_rooms'] / X['households']\n        X['bedrooms_per_household'] = X['total_bedrooms'] / X['households']\n        X['rooms_per_person'] = X['total_rooms'] / X['population']\n        X['bedrooms_per_person'] = X['total_bedrooms'] / X['population']\n        X['bedrooms_fraction'] = X['total_bedrooms'] / X['total_rooms']\n        X['people_per_households'] = X['population'] / X['households']\n        return X\n\n#data_num = data.drop('ocean_proximity', axis=1)\n#attribs_num = [*data_num.columns.tolist(), 'ocean_distance']\n#attribs_cat = ['ocean_proximity']\n#encoder = OneHotEncoder()\n#encoder.fit(data[attribs_cat])\n#oh_labels = encoder.categories_[0].tolist()\n#columns_tr = [*attribs_num, *new_features, 'center_distance', *oh_labels]\n#print(columns_tr)\n        \nclass DFConverter(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        X = X.copy()\n        X_df = pd.DataFrame(X)\n        X_df.columns = columns_tr\n        return X_df\n    \ncenter_NW = [-122.94, 37.04]\ncenter_SE = [-118.915, 33.165]\ndef calculate_center_distance(long_val, lat_val):\n    NW_distance = np.sqrt((center_NW[0]-long_val)**2 + (center_NW[1]-lat_val)**2)\n    SE_distance = np.sqrt((center_SE[0]-long_val)**2 + (center_SE[1]-lat_val)**2)\n    return np.min([NW_distance, SE_distance])\nclass CenterDistanceCalculator(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        X = X.copy()\n        X['center_distance'] = X.apply(lambda x: calculate_center_distance(x['longitude'], x['latitude']), axis=1)\n        return X\n        \ntqdm.pandas()\nland_labels = ['<1H OCEAN', 'INLAND']\ndata_ocean = data.copy().query(' ocean_proximity == \"NEAR OCEAN\" | ocean_proximity == \"NEAR BAY\"').sample(frac=1/20, random_state=42) # skipping island districts, because they will obviously be always very far from the inland ones\ndef calculate_ocean_distance(long_val, lat_val):\n    data_ocean['district_distance'] = data_ocean.apply(lambda x: np.sqrt((long_val-x['longitude'])**2 + (lat_val-x['latitude'])**2), axis=1)\n    return data_ocean['district_distance'].min()\nclass OceanDistanceCalculator(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        X = X.copy()\n        X['ocean_distance'] = X.progress_apply(lambda x: calculate_ocean_distance(x['longitude'], x['latitude']) if x['ocean_proximity'] in land_labels else 0, axis=1)\n        return X\n        \n        \n        \npipeline_num = Pipeline([\n    ('imputer', MyImputer()),\n    ('feat_expander', FeatExpander()),\n    ('center_distance_calculator', CenterDistanceCalculator()),\n    ('scaler', StandardScaler())\n])      \n\ncolumn_transformer = ColumnTransformer([\n    ('num', pipeline_num, attribs_num),\n    ('cat', OneHotEncoder(), attribs_cat)\n])\n\npipeline_full = Pipeline([\n    ('outlier_remover', OutlierRemover()),\n    ('ocean_distance_calculator', OceanDistanceCalculator()),\n    ('column_transformer', column_transformer),\n    ('df_converter', DFConverter()),\n])\n\ndata_tr = pipeline_full.fit_transform(data)\ndata_tr.corr()['median_house_value']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}