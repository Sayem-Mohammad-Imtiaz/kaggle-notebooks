{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n    \nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score \nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\ndef rmse(y_test,y_pred):\n      return np.sqrt(mean_squared_error(y_test,y_pred))\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import preprocessing\nfrom sklearn import utils\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\n#Metrics: I will measure the accuracy of the model with following measures: coefficient of determination R-squared, MSE, MAE\n#Methods: Linear Regression, Random Forest/Decision trees, KNN algorithm, XGBoost  \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Description of the dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/nyc-property-sales/nyc-rolling-sales.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset constist of 22 feaures and 84548 observations. Dataset description:\n* **Borough**: The name of the borough in which the property is located.\n* **Neighborhood**: Department of Finance assessors determine the neighborhood name in the course of valuing properties. \n* **Building Class Category**: to simplify identification of similar properties by broad usage (e.g. One Family Homes)\n* **Tax Class at Present**: Every property in the city is assigned to one of four tax classes (Classes 1, 2, 3, and 4), based on the use of the property.\n* **Block**: A Tax Block is a sub-division of the borough on which real properties are located.\n* **Lot**: A Tax Lot is a subdivision of a Tax Block and represents the property unique location.\n* **Easement**: An easement is a right, such as a right of way, which allows an entity to make limited use of\nanother’s real property.\n* **Building Class at Present**: The Building Classification is used to describe a property’s constructive use. \n* **Address**: The street address of the property as listed on the Sales File.\n* **Apartment number**\n* **Zip Code**: The property’s postal code\n* **Residential Units**: The number of residential units at the listed property.\n* **Commercial Units**: The number of commercial units at the listed property.\n* **Total Units**: The total number of units at the listed property.\n* **Land Square Feet**: The land area of the property listed in square feet.\n* **Gross Square Feet**:  The total area of all the floors of a building as measured from the exterior surfaces of theoutside walls of the building, including the land area and space within any building or structure\non the property. \n* **Year Built**: Year the structure on the property was built.\n* **Tax Class at Time of Sale**:\n* **Building Class at Time of Sale**\n* **Sales Price**: Price paid for the property. Start date: 1 Sept 2016, End date: 31.08.2017\n* **Sale Date**: Date the property sold.\n "},{"metadata":{},"cell_type":"markdown","source":"At first let's remove some features from our dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"del df['EASE-MENT'] #empty column\ndel df['Unnamed: 0'] #iteration column\ndel df['SALE DATE'] #that would be useful for time series\ndel df['ADDRESS'] #too many unique values\ndel df['APARTMENT NUMBER'] #unrelevant, 77% of empty records","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's search for duplicates and drop rows with duplicates"},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(df.duplicated())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop_duplicates(df.columns, keep='last')\nsum(df.duplicated(df.columns))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Type conversion"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-> nominal feature\ndf['NEIGHBORHOOD'] = df['NEIGHBORHOOD'].astype('category')\ndf['BOROUGH'] = df['BOROUGH'].astype('category')\ndf['BUILDING CLASS CATEGORY'] = df['BUILDING CLASS CATEGORY'].astype('category')\ndf['TAX CLASS AT PRESENT'] = df['TAX CLASS AT PRESENT'].astype('category')\ndf['BLOCK'] = df['BLOCK'].astype('category')\ndf['LOT'] = df['LOT'].astype('category')\ndf['BUILDING CLASS AT PRESENT'] = df['BUILDING CLASS AT PRESENT'].astype('category')\ndf['ZIP CODE'] = df['ZIP CODE'].astype('category')\ndf['BUILDING CLASS AT TIME OF SALE'] = df['BUILDING CLASS AT TIME OF SALE'].astype('category')\ndf['TAX CLASS AT TIME OF SALE'] = df['TAX CLASS AT TIME OF SALE'].astype('category')\n#-> numeric\ndf['LAND SQUARE FEET'] = pd.to_numeric(df['LAND SQUARE FEET'], errors='coerce') #By setting errors=’coerce’, you’ll transform the non-numeric values into NaN.\ndf['GROSS SQUARE FEET']= pd.to_numeric(df['GROSS SQUARE FEET'], errors='coerce')\ndf['SALE PRICE'] = pd.to_numeric(df['SALE PRICE'], errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's deal with missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can check percentage of missing data in columns ['LAND SQUARE FEET', 'GROSS SQUARE FEET', 'SALE PRICE']"},{"metadata":{"trusted":true},"cell_type":"code","source":"miss = df.isnull().sum()/len(df) \nmiss=miss[miss>0]\nmiss.sort_values(inplace=True) \nmiss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_data = df.select_dtypes(include=[np.number])\nnumeric_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have missing values in 3 feature columns. We found unexpected 0 values for LAND SQUARE FEET, GROSS SQUARE FEET, YEAR BUILT, SALE PRICE.\n\nGROSS SQUARE FEET might be equal zero if land is sold without any building (we will investige that later).\n> A $\\$0$ sale indicates that there was a transfer of ownership without a cash consideration. \nThere can be a number of reasons for a $\\$0$ sale including transfers of ownership from\nparents to children.\n\nWe could use rows with missing price or zero value (exactly 22,812 samples) to predict the prices as independent project.\nYEAR BULIT can be equal 2017 but value '0' it quite alarming."},{"metadata":{"trusted":true},"cell_type":"code","source":"test2 = df[df['SALE PRICE'].isna() | df['SALE PRICE'] == 0.0]\ndf = df[~df['SALE PRICE'].isna() & df['SALE PRICE'] != 0.0]\ntest2 = test2.drop(columns='SALE PRICE')\ndf.shape ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_data = df.select_dtypes(include=[np.number])\nnumeric_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LAND SQUARE FEET          -        24938 missing values & 8520 zero values\n\nGROSS SQUARE FEET          -       26231 missing values & 8032 zero values"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['LAND SQUARE FEET']=df['LAND SQUARE FEET'].fillna(0)\ndf['GROSS SQUARE FEET']=df['GROSS SQUARE FEET'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We found 1039 samples of properties which are probably unbuilt"},{"metadata":{"trusted":true},"cell_type":"code","source":"sum((df['LAND SQUARE FEET']!=0 )& (df['GROSS SQUARE FEET']==0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will reject 3469 samples with missing (or zero values) in the following columns: LAND SQUARE FEET, GROSS SQUARE FEET, YEAR BUILT. "},{"metadata":{"trusted":true},"cell_type":"code","source":"sum((df['LAND SQUARE FEET']==0 )& (df['GROSS SQUARE FEET']==0) & (df['YEAR BUILT']==0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will save samples which may represent vacant lands (unbulit hence zero value in GROSS SQUARE LAND and YEAR BUILT)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sum((df['LAND SQUARE FEET']!=0 )& (df['GROSS SQUARE FEET']==0) & (df['YEAR BUILT']==0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df[~((df['LAND SQUARE FEET']==0 )& (df['GROSS SQUARE FEET']==0) & (df['YEAR BUILT']==0))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LAND SQUARE FEET shouldn't be empty or equal 0"},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"mean_lqf= df['LAND SQUARE FEET'].mean(skipna=True)\ndf=df.replace({'LAND SQUARE FEET': {0: mean_lqf}})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_data = df.select_dtypes(include=[np.number])\nnumeric_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's investigate samples with YEAR BUILT equals to zero"},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_year_only=df[(df['GROSS SQUARE FEET']!=0) & (df['YEAR BUILT']==0)]\nzero_year_only.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_year= df['YEAR BUILT'].mean(skipna=True)\ndf.loc[ (df['GROSS SQUARE FEET']!=0) & (df['YEAR BUILT']==0) , 'YEAR BUILT'] = mean_year","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We imputed average year into samples where we suspected it was ommitted by mistake. In other cases (see table below) year can be equal to 0 if there are no buildings on property"},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_year =df[(df['YEAR BUILT']==0 )]\nzero_year","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a closer look at RESIDENTIAL UNITS, COMMERCIAL UNITS and\tTOTAL UNITS"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[[\"TOTAL UNITS\", \"SALE PRICE\"]].groupby(['TOTAL UNITS'], as_index=False).count().sort_values(by='SALE PRICE', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Buildings with 1 total unit were mostly sold. We have one extremely large amount of 2261 units but the sample looks legitimate"},{"metadata":{"trusted":true},"cell_type":"code","source":"largest_unit=df[ df['TOTAL UNITS']==2261]\nlargest_unit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_unit=df[ df['TOTAL UNITS']==0]\nzero_unit","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I checked that in 793 rows the sum of residential and commercial units is not equal to total units. It's only 1% of whole dataset so I will leave them as they are."},{"metadata":{"trusted":true},"cell_type":"code","source":"check_units_match=df[df['TOTAL UNITS'] != df['RESIDENTIAL UNITS']+ df['COMMERCIAL UNITS']]\nlen(check_units_match)/len(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_data = df.select_dtypes(include=[np.number])\nnumeric_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Categorical data analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df=df.select_dtypes(exclude=[np.number])\ncat_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the preeding table we can draw conclusions necessary to feature selection. \n* Location is undoubtly is very important factor that will influence the price. There are a lot of unique values of NEIGHBORHOOD, BLOCK, LOT and ZIPCODE which will produce enormous amount of dummie features. Hence we will model the price on the basis of BOROUGH.\n* Building class\n> Every property in the city is assigned to one of four tax classes (Classes 1, 2, 3, and 4),\nbased on the use of the property. \nThe Building Classification is used to describe a property’s constructive use. \n\nAccording to the dataset desciprtion there is a correlation between building class and tax class. In order to reduce dimensionality of the dataset we will reject some of these information."},{"metadata":{},"cell_type":"markdown","source":"# Categorical features - Visual analysis"},{"metadata":{},"cell_type":"markdown","source":"**BOROUGH - a digit code for the borough the property is located in; **\n\nThey are Manhattan (1), Bronx (2), Brooklyn (3), Queens (4), and Staten Island (5).\nMedian of price sales is the highest in Manhattan. The most in-demand borough is Queens."},{"metadata":{"trusted":true},"cell_type":"code","source":"pivot_b1=df.pivot_table(index='BOROUGH', values='SALE PRICE', aggfunc=np.median)\npivot_b1.plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pivot_b2=df.pivot_table(index='BOROUGH', aggfunc='size')\npivot_b2.plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **TAX CLASS**\n\nThere are only 4 classes so column TAX CLASS AT PRESENT with 10 unique values must be unclean. We will use TAX CLASS AT TIME OF SALE for futher analysis and prediction.\nThe meadian of sale price is the higest among 4th tax class buldings, which constitue small part of all sold properties.\n> Class 4: Includes all other properties not included in class 1,2, and 3, such as offices, factories, warehouses, garage buildings, etc. "},{"metadata":{"trusted":true},"cell_type":"code","source":"pivot_t1=df.pivot_table(index='TAX CLASS AT TIME OF SALE', values='SALE PRICE', aggfunc=np.median)\npivot_t1.plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pivot_t2=df.pivot_table(index='TAX CLASS AT TIME OF SALE', aggfunc='size')\npivot_t2.plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **BUILDING CLASS CATEGORY**"},{"metadata":{},"cell_type":"markdown","source":"By plotting histogram I noticed one outlier with respect to SALE PRICE. I would examine this sample in the next part."},{"metadata":{"trusted":true},"cell_type":"code","source":"pivot_bc1=df.pivot_table(index='BUILDING CLASS CATEGORY', values='SALE PRICE', aggfunc=np.median)\npivot_bc1.plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pivot_bc2=df.pivot_table(index='BUILDING CLASS CATEGORY', aggfunc='size')\nresult = pivot_bc2.sort_values(ascending=False)\nresult=result[0:5]\nresult","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Numeric features analysis and visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_data = df.select_dtypes(include=[np.number])\nnumeric_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SALE PRICE - target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"boxplot_s1= df.boxplot(column=['SALE PRICE'], vert=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Samples with particularly high sale price seem all right. "},{"metadata":{"trusted":true},"cell_type":"code","source":"sale_price_outliers_high=df[df['SALE PRICE']>1000000000]\nsale_price_outliers_high","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(df['SALE PRICE'], range=[0, 2000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sale_price_outliers_low=df[df['SALE PRICE']<=1000]\nsale_price_outliers_low.sort_values('SALE PRICE')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= df[df['SALE PRICE'] >1000]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will exclude samples with SALE PRICE smaller then 1000$\\$$. "},{"metadata":{},"cell_type":"markdown","source":"### SQUARE FEET"},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_data = df.select_dtypes(include=[np.number])\nnumeric_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boxplot_s1= df.boxplot(column=['LAND SQUARE FEET'], vert=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(df['LAND SQUARE FEET'], range=[0, 6000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.scatter(df['LAND SQUARE FEET'], df['SALE PRICE'], alpha=0.5)\nplt.xlim(0, 10000)\nplt.ylim(0, 3000000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boxplot_s2= df.boxplot(column=['GROSS SQUARE FEET'], vert=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(df['GROSS SQUARE FEET'], range=[0, 6000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.scatter(df['GROSS SQUARE FEET'], df['SALE PRICE'], alpha=0.5)\nplt.xlim(0, 10000)\nplt.ylim(0, 3000000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RESIDENTIAL AND COMMERCIAL UNITS"},{"metadata":{"trusted":true},"cell_type":"code","source":"units = df[(df['TOTAL UNITS'] <50) & (df['SALE PRICE']<5000000)] \nplt.figure(figsize=(10,6))\nsns.boxplot(x='TOTAL UNITS', y='SALE PRICE', data=units)\nplt.title('Total Units vs Sale Price')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pair-wise correlations"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr(method='pearson')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ONE-HOT ENCODING"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_df=df.select_dtypes(exclude=[np.number])\ncat_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df['NEIGHBORHOOD']\ndel df['BLOCK']\ndel df['LOT']\ndel df['BUILDING CLASS AT PRESENT']\ndel df['ZIP CODE']\ndel df['TAX CLASS AT PRESENT']\ndel df['BUILDING CLASS AT TIME OF SALE']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s1=['BOROUGH', 'BUILDING CLASS CATEGORY', 'TAX CLASS AT TIME OF SALE']\n\none_hot_encoded_training_set = pd.get_dummies(df[s1])\none_hot_encoded_training_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing categorical columns with dummies\ndf2= df.drop(s1,axis=1)\ndf2= pd.concat([df2, one_hot_encoded_training_set] ,axis=1)\ndf2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dataset without outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"df3= df2[(df2['SALE PRICE']<50000000) & (df2['GROSS SQUARE FEET']>0) & (df2['GROSS SQUARE FEET']<10000)]\ndf3.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.1 DECISION TREE / RANDOM FOREST"},{"metadata":{"trusted":true},"cell_type":"code","source":" def lin_regplot(X, y, model): \n        plt.scatter(X, y, c='blue') \n        plt.plot(X, model.predict(X), color='red') \n        return None ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nX = df2[['GROSS SQUARE FEET']].values \ny = df2['SALE PRICE'].values\ntree = DecisionTreeRegressor(max_depth=3)# 3 BYŁO OK\ntree.fit(X, y) \nsort_idx = X.flatten().argsort()\nlin_regplot(X[sort_idx], y[sort_idx], tree) \nplt.xlabel('GROSS SQUARE FEET')\nplt.ylabel('SALE PRICE')\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X= df2.iloc[:, df2.columns!='SALE PRICE'].values\ny = df2['SALE PRICE'].values \n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n\nfrom sklearn.ensemble import RandomForestRegressor\nforest = RandomForestRegressor(n_estimators=25, \n                               criterion='mse',\n                               random_state=1, \n                               n_jobs=-1)\nforest.fit(X_train, y_train)\ny_train_pred = forest.predict(X_train)\ny_test_pred = forest.predict(X_test)\nprint('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))\nprint('RMSE train: %.3f, test: %.3f' % (rmse(y_train, y_train_pred), rmse(y_test, y_test_pred)))\nprint('MAE train: %.3f, test: %.3f' % (mean_absolute_error(y_train, y_train_pred), mean_absolute_error(y_test, y_test_pred)))\nprint('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature importance with random forests"},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_labels = df2.columns[0:]\nimportances = forest.feature_importances_\nindices = np.argsort(importances)[::-1] \nfor f in range(X_train.shape[1]): \n    print(\"%2d) %-*s %f\" % (f + 1, 30, \n                            feat_labels[f],\n                            importances[indices[f]])) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Feature Importances') \nplt.bar(range(X_train.shape[1]), \n        importances[indices], \n        color='lightblue',\n        align='center')\nplt.xticks(range(X_train.shape[1]), \n           feat_labels, rotation=90) \nplt.xlim([-1, X_train.shape[1]]) \nplt.tight_layout() \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_train_pred,  \n            y_train_pred - y_train, \n            c='black', \n            marker='o', \n            s=15, \n            alpha=0.5, \n            label='Training data') \nplt.scatter(y_test_pred, \n            y_test_pred - y_test, \n            c='lightgreen', \n            marker='s', \n            s=15, \n            alpha=0.7, \n            label='Test data') \nplt.xlabel('Predicted values') \nplt.ylabel('Residuals') \nplt.legend(loc='upper left') \n#plt.hlines(y=0, xmin=-10, xmax=50, lw=2, color='red') \nplt.xlim([0, 1000000])\nplt.ylim([-0.1, 0.1]) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.2 DECISION TREE / RANDOM FOREST without outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nX = df3[['GROSS SQUARE FEET']].values \ny = df3['SALE PRICE'].values\ntree = DecisionTreeRegressor(max_depth=3)\ntree.fit(X, y) \nsort_idx = X.flatten().argsort()\nlin_regplot(X[sort_idx], y[sort_idx], tree) \nplt.xlabel('GROSS SQUARE FEET')\nplt.ylabel('SALE PRICE')\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X= df3.iloc[:, df3.columns!='SALE PRICE'].values\ny = df3['SALE PRICE'].values \n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n\nfrom sklearn.ensemble import RandomForestRegressor\nforest = RandomForestRegressor(n_estimators=100, \n                               criterion='mse',\n                               random_state=1, \n                               n_jobs=-1)\nforest.fit(X_train, y_train)\ny_train_pred = forest.predict(X_train)\ny_test_pred = forest.predict(X_test)\nprint('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))\nprint('RMSE train: %.3f, test: %.3f' % (rmse(y_train, y_train_pred), rmse(y_test, y_test_pred)))\nprint('MAE train: %.3f, test: %.3f' % (mean_absolute_error(y_train, y_train_pred), mean_absolute_error(y_test, y_test_pred)))\nprint('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"important_rf=[]\nfeat_labels = df2.columns[0:]\nimportances = forest.feature_importances_\nindices = np.argsort(importances)[::-1] \nfor f in range(X_train.shape[1]): \n    if f < 12: \n        important_rf.append(feat_labels[f])\n    print(\"%2d) %-*s %f\" % (f + 1, 30, \n                            feat_labels[f],\n                            importances[indices[f]])) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.3 RANDOM FOREST WITH SELECTED FEATURES"},{"metadata":{"trusted":true},"cell_type":"code","source":"df4=df2[important_rf]\ndf4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X= df4.iloc[:, df4.columns!='SALE PRICE'].values\ny = df4['SALE PRICE'].values \n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n\nfrom sklearn.ensemble import RandomForestRegressor\nforest = RandomForestRegressor(n_estimators=12, \n                               criterion='mse',\n                               random_state=1, \n                               n_jobs=-1)\nforest.fit(X_train, y_train)\ny_train_pred = forest.predict(X_train)\ny_test_pred = forest.predict(X_test)\nprint('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))\nprint('RMSE train: %.3f, test: %.3f' % (rmse(y_train, y_train_pred), rmse(y_test, y_test_pred)))\nprint('MAE train: %.3f, test: %.3f' % (mean_absolute_error(y_train, y_train_pred), mean_absolute_error(y_test, y_test_pred)))\nprint('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# 2.1 XGBOOST"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nX= df3.iloc[:, df3.columns!='SALE PRICE'].values\ny = df3['SALE PRICE'].values \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123)\nxg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.15,\n                max_depth = 5, alpha = 10, n_estimators = 25)\nxg_reg.fit(X_train,y_train)\n\npreds = xg_reg.predict(X_test)\ny_train_pred = xg_reg.predict(X_train)\ny_test_pred = xg_reg.predict(X_test)\n\nprint('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))\nprint('RMSE train: %.3f, test: %.3f' % (rmse(y_train, y_train_pred), rmse(y_test, y_test_pred)))\nprint('MAE train: %.3f, test: %.3f' % (mean_absolute_error(y_train, y_train_pred), mean_absolute_error(y_test, y_test_pred)))\nprint('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dmatrix = xgb.DMatrix(data=X,label=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\"objective\":\"reg:squarederror\",'colsample_bytree': 0.3,'learning_rate': 0.2,\n                'max_depth': 5, 'alpha': 10}\n\ncv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=5,\n                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print((cv_results[\"test-rmse-mean\"]).tail(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg_reg = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=10)\nxgb.plot_importance(xg_reg)\nplt.rcParams['figure.figsize'] = [15, 15]\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df5=df3[['RESIDENTIAL UNITS', 'TOTAL UNITS', 'LAND SQUARE FEET', 'GROSS SQUARE FEET', 'YEAR BUILT', 'SALE PRICE']]\ndf5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nX= df5.iloc[:, df5.columns!='SALE PRICE'].values\ny = df5['SALE PRICE'].values \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123)\nxg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.15,\n                max_depth = 3, alpha = 10, n_estimators = 10)\nxg_reg.fit(X_train,y_train)\n\npreds = xg_reg.predict(X_test)\ny_train_pred = xg_reg.predict(X_train)\ny_test_pred = xg_reg.predict(X_test)\n\nprint('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))\nprint('RMSE train: %.3f, test: %.3f' % (rmse(y_train, y_train_pred), rmse(y_test, y_test_pred)))\nprint('MAE train: %.3f, test: %.3f' % (mean_absolute_error(y_train, y_train_pred), mean_absolute_error(y_test, y_test_pred)))\nprint('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Before we move to next part we need to prepare our numerical data for KNN and LINEAR REGRESSION"},{"metadata":{},"cell_type":"markdown","source":"## Standarization"},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_data = df.select_dtypes(include=[np.number])\nnumeric_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_std=df2\ndf_std.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(df_std[numeric_data.columns])\nscaled = scaler.transform(df_std[numeric_data.columns])\n\nfor i, col in enumerate(numeric_data.columns):\n       df_std[col] = scaled[:,i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_std","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"X= df_std.iloc[:, df_std.columns!='SALE PRICE'].values\ny = df_std['SALE PRICE'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lab_enc = preprocessing.LabelEncoder()\nencoded = lab_enc.fit_transform(y)\nprint(utils.multiclass.type_of_target(y))\nprint(utils.multiclass.type_of_target(y.astype('int')))\nprint(utils.multiclass.type_of_target(encoded))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier \n\nX_train, X_test, y_train, y_test = train_test_split(X, encoded, test_size=0.20)\nknn = KNeighborsClassifier(n_neighbors=50, p=2, metric='minkowski') \nknn.fit(X_train, y_train)\n\ny_train_pred = knn.predict(X_train)\ny_test_pred = knn.predict(X_test)\n\nprint('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))\nprint('RMSE train: %.3f, test: %.3f' % (rmse(y_train, y_train_pred), rmse(y_test, y_test_pred)))\nprint('MAE train: %.3f, test: %.3f' % (mean_absolute_error(y_train, y_train_pred), mean_absolute_error(y_test, y_test_pred)))\nprint('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error = []\n\n# Calculating error for K values between 1 and 40\nfor i in range(30,50):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    pred_i = knn.predict(X_test)\n    error.append(np.mean(pred_i != y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.plot(range(30,50), error, color='red', linestyle='dashed', marker='o',\n         markerfacecolor='blue', markersize=10)\nplt.title('Error Rate K Value')\nplt.xlabel('K Value')\nplt.ylabel('Mean Error')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SBS algorithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n\n#sfs1 = SFS(knn, \n #          k_features=3, \n  #         forward=True, \n   #        floating=False, \n    #       verbose=2,\n     #      scoring='accuracy',\n      #     cv=0)\n\n#sfs1 = sfs1.fit(X, encoded)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. LINEAR REGRESSION"},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_data = df.select_dtypes(include=[np.number])\nnumeric_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = np.corrcoef(df[numeric_data.columns].values.T) \nsns.set(font_scale=1.5) \nhm = sns.heatmap(cm, \n                cbar=True, \n                annot=True, \n                square=True, \n                fmt='.2f', \n                annot_kws={'size': 15}, \n                yticklabels=numeric_data.columns, \n                xticklabels=numeric_data.columns)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X= df_std.iloc[:, df_std.columns!='SALE PRICE']\ny = df_std['SALE PRICE'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression \nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\n\nlinreg = LinearRegression()\nlinreg.fit(X_train, y_train)\ny_train_pred = linreg.predict(X_train)\ny_test_pred = linreg.predict(X_test)\n\nprint('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))\nprint('RMSE train: %.3f, test: %.3f' % (rmse(y_train, y_train_pred), rmse(y_test, y_test_pred)))\nprint('MAE train: %.3f, test: %.3f' % (mean_absolute_error(y_train, y_train_pred), mean_absolute_error(y_test, y_test_pred)))\nprint('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_train_pred, y_train_pred - y_train, c='blue', marker='o', label='Training data')\nplt.scatter(y_test_pred,  y_test_pred - y_test, c='lightgreen', marker='s', label='Test data') \nplt.xlabel('Predicted values')\nplt.ylabel('Residuals') \nplt.legend(loc='upper left') \nplt.xlim([0,30]) \nplt.ylim([-20,20]) \nplt.hlines(y=0, xmin=0, xmax=30, lw=2, color='red') \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDRegressor\n\nX= df_std.iloc[:, df_std.columns!='SALE PRICE']\ny = df_std['SALE PRICE'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\nclf = SGDRegressor(alpha=0.1, max_iter=20, loss='squared_loss') #penalty='l2')\nclf.fit(X_train, y_train)\n\ny_train_pred = clf.predict(X_train)\ny_test_pred = clf.predict(X_test)\n\nprint('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))\nprint('RMSE train: %.3f, test: %.3f' % (rmse(y_train, y_train_pred), rmse(y_test, y_test_pred)))\nprint('MAE train: %.3f, test: %.3f' % (mean_absolute_error(y_train, y_train_pred), mean_absolute_error(y_test, y_test_pred)))\nprint('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import RANSACRegressor \nransac = RANSACRegressor(LinearRegression(), \n                         max_trials=10, \n                         min_samples=50, \n                         residual_threshold=5.0, \n                         random_state=123)\nransac.fit(X_train, y_train)\ny_train_pred = ransac.predict(X_train)\ny_test_pred = ransac.predict(X_test)\n\nprint('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))\nprint('RMSE train: %.3f, test: %.3f' % (rmse(y_train, y_train_pred), rmse(y_test, y_test_pred)))\nprint('MAE train: %.3f, test: %.3f' % (mean_absolute_error(y_train, y_train_pred), mean_absolute_error(y_test, y_test_pred)))\nprint('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge \nridge = Ridge(alpha=0.00099, max_iter=1000)\nridge.fit(X_train, y_train)\ny_train_pred = ridge.predict(X_train)\ny_test_pred = ridge.predict(X_test)\n\nprint('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))\nprint('RMSE train: %.3f, test: %.3f' % (rmse(y_train, y_train_pred), rmse(y_test, y_test_pred)))\nprint('MAE train: %.3f, test: %.3f' % (mean_absolute_error(y_train, y_train_pred), mean_absolute_error(y_test, y_test_pred)))\nprint('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso\nlasso = Lasso(alpha=0.00099, max_iter=1000)\nlasso.fit(X_train, y_train)\ny_train_pred = lasso.predict(X_train)\ny_test_pred = lasso.predict(X_test)\n\nprint('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))\nprint('RMSE train: %.3f, test: %.3f' % (rmse(y_train, y_train_pred), rmse(y_test, y_test_pred)))\nprint('MAE train: %.3f, test: %.3f' % (mean_absolute_error(y_train, y_train_pred), mean_absolute_error(y_test, y_test_pred)))\nprint('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Last try with few features selected via RANDOM FOREST"},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_data = df.select_dtypes(include=[np.number])\nnumeric_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df4_std=df4.copy()\ndf4_std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(df4_std[numeric_data.columns])\nscaled = scaler.transform(df4_std[numeric_data.columns])\n\nfor i, col in enumerate(numeric_data.columns):\n       df4_std[col] = scaled[:,i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df4_std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X= df4_std.iloc[:, df4_std.columns!='SALE PRICE']\ny = df4_std['SALE PRICE'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ridge = Ridge(alpha=0.00099, max_iter=1000)\nridge.fit(X_train, y_train)\ny_train_pred = ridge.predict(X_train)\ny_test_pred = ridge.predict(X_test)\n\nprint('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred), mean_squared_error(y_test, y_test_pred)))\nprint('RMSE train: %.3f, test: %.3f' % (rmse(y_train, y_train_pred), rmse(y_test, y_test_pred)))\nprint('MAE train: %.3f, test: %.3f' % (mean_absolute_error(y_train, y_train_pred), mean_absolute_error(y_test, y_test_pred)))\nprint('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SUMMARY\n"},{"metadata":{},"cell_type":"markdown","source":"**RANDOM FOREST (n_estimators=12)**\n* MSE train: 32887397752547.805, test: 36782968316167.930\n* RMSE train: 5734753.504, test: 6064896.398\n* MAE train: 606061.501, test: 930501.404\n* R^2 train: 0.802, test: 0.770\n\n**XGBOOST (learning_rate = 0.15,max_depth = 3, alpha = 10, n_estimators = 10)**\n* MSE train: 1868011735798.321, test: 1444052356572.113\n* RMSE train: 1366752.258, test: 1201687.296\n* MAE train: 455641.730, test: 443066.799\n* R^2 train: 0.170, test: 0.166\n\n**KNN (n_neighbors=50, and more probably would work)**\n* MSE train: 4318301.989, test: 4536137.416\n* RMSE train: 2078.052, test: 2129.821\n* MAE train: 1454.516, test: 1509.331\n* R^2 train: 0.131, test: 0.083\n\n**LINEAR REGRESSION (Ridge(alpha=0.00099, max_iter=1000))**\n* MSE train: 2654989.682, test: 2680561.178\n* RMSE train: 1629.414, test: 1637.242\n* MAE train: 1271.535, test: 1281.574\n* R^2 train: 0.466, test: 0.458\n"},{"metadata":{},"cell_type":"markdown","source":"We noted the best performance for RANDOM FOREST model with selected features. The second best is RIDGE REGRESSION for which we tried two models (with 63 features and 12) with similar results. \nWe could avoid overfitting by reducing number of variables or by preparing data in a different way by examining outliers or using tranformations. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}