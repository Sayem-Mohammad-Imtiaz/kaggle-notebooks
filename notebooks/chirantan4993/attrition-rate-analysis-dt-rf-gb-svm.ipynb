{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd # package for high-performance, easy-to-use data \n#structures and data analysis\nimport numpy as np # fundamental package for scientific computing with Python\nimport matplotlib\nimport matplotlib.pyplot as plt # for plotting\nimport seaborn as sns # for making plots with seaborn\nimport missingno as msno #checking missing values\ncolor = sns.color_palette()\nsns.set_style(\"whitegrid\")\nplt.style.use(\"fivethirtyeight\")\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.offline as offline\noffline.init_notebook_mode()\nfrom pylab import rcParams\n\n\nfrom datetime import datetime\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, learning_curve, train_test_split\nfrom sklearn.metrics import precision_score, roc_auc_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score\n\n# import cufflinks and offline mode\nimport cufflinks as cf\ncf.go_offline()\n\n# from sklearn import preprocessing\n# # Supress unnecessary warnings so that presentation looks clean\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()\ndata.describe().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Observations:\n1. The average age of employees at IBM is 39, which means while hiring, they prefer candidates with decent work experience and expect higher level of expertise.\n2. The average salary hike for employees is 15% with maximum being 25%. With decent salary hike in the organisation, employees tend to stay longer at the company and tend to enjoy long-term benefits with job security. This means, IBM rewards it's employees for their performance. This is proporational to employee satisfaction.\n3. However , the average Employee satisfaction stands at 2.7 out of 5.\n4. Most of the employees who get into IBM have worked with 2 or 3 companies in the past.\n5. On an average, an employee has worked at IBM for around 11 years and there seems to be an outlier - wherein an employee has worked for 38 years.\n6. It takes around 2 years for an IBM employee to bag his/her next promotion at the workplace."},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.bar(data, color = 'r', figsize = (10,8))   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reassign target\ndata.Attrition.replace(to_replace = dict(Yes = 1, No = 0), inplace = True)\n# Drop useless feat\ndata = data.drop(columns=['StandardHours', \n                          'EmployeeCount', \n                          'Over18',\n                        ])\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"attrition = data[(data['Attrition'] != 0)]\nno_attrition = data[(data['Attrition'] == 0)]\n\n#COUNT\ntrace = go.Bar(x = (len(attrition), len(no_attrition)), y = ['Yes_attrition', 'No_attrition'], orientation = 'h', opacity = 0.8, marker=dict(\n        color=['gold', 'lightskyblue'],\n        line=dict(color='#000000',width=1.5)))\n\nlayout = dict(title =  'Attrition Count')\n                    \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)\n\n#PERCENTAGE\ntrace = go.Pie(labels = ['No_attrition', 'Yes_attrition'], values = data['Attrition'].value_counts(), \n               textfont=dict(size=15), opacity = 0.8,\n               marker=dict(colors=['lightskyblue','gold'], \n                           line=dict(color='#000000', width=1.5)))\n\n\nlayout = dict(title =  'Attrition Distribution')\n           \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Observations:\n1. In Attribution distribution diagram, it can be seem around 83.9% or 1233 (out of 1470 employees) dont think of leaving the organisation or are not at the risk of losing their employment.\n2. Around 16.1% or 237 (out of 1470 employees) are either thinking of leaving the organisation or are at the risk of losing their employment."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,20))\ncorr = data.corr()\n#Plot figsize\nfig, ax = plt.subplots(figsize=(20,20))\n#Generate Heat Map, allow annotations and place floats in map\nsns.heatmap(corr,  cmap=\"RdYlGn\", annot=True, fmt=\".2f\")\n#Apply xticks\nplt.xticks(range(len(corr.columns)), corr.columns);\n#Apply yticks\nplt.yticks(range(len(corr.columns)), corr.columns)\n#show plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Observations from co-relation matrix:\n1. Age and Total working years seem to have a good correlation of around 68%. \n2. Job level and Monthly income have around 95% co-relation ,which is evident. It also has around 51% correlation with Age, 78% with Total Working years and 53% with years spent in the company.\n3. Percent Salary hike and Performance Rating have around 7&%.\n4. years at the company seem to have a strong 77% co-relation with Years in current role and Years with current manager.\n"},{"metadata":{},"cell_type":"markdown","source":"# let's have a look at numerical and categorical types"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_num=data.select_dtypes(include='number')\ndata_num.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_obj=data.select_dtypes(include='object')\ndata_obj.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualisations "},{"metadata":{},"cell_type":"markdown","source":"# 1. What is the age range of employees at IBM ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(10,10))\nsns.countplot(data.Age)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. What is the relation between Age and monthly income ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='Age',y='MonthlyIncome',data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. What is the relation between performance rating and attrition ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='Attrition',hue='PerformanceRating',data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. What level of education does IBM employees generally have ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(10,8))\nsns.countplot(data.Education)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. With how many companies have the employees worked in the past?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(10,8))\nsns.countplot(data.NumCompaniesWorked)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. How many employees receive what percent salary hike at IBM ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(10,8))\nsns.countplot(data.PercentSalaryHike)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Is business travelling a part of work life at IBM ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(6,8))\nsns.countplot(x='BusinessTravel', data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8. What is the relationship status of IBM employees in general ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(10,8))\nsns.countplot(x='MaritalStatus', data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 50% of employees from each gender are Divorced "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.groupby(['Gender','MaritalStatus'])['MaritalStatus'].count())\nprint(data.groupby('Gender')['Gender'].count())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 9. What are the most active job roles at IBM ?\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nplt.pie(data['JobRole'].value_counts(),labels=data['JobRole'].value_counts().index,autopct='%.2f%%');\nplt.title('Job Role Distribution',fontdict={'fontsize':22});","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 10. Does a particular Gender dominate a Job role ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(10,8))\nfig = plt.gcf()\nfig.set_size_inches(20,14)\nsns.countplot(x='JobRole', hue='Gender',data=data)\nplt.title('Job Role Between Male and Female')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 11. Which education field is commonly noticed amongst IBM employees?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nplt.pie(data['EducationField'].value_counts(),labels=data['EducationField'].value_counts().index,autopct='%.2f%%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 12. Which department has maximum employees employed with them ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(10,8))\nsns.countplot(x='Department', data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 13. Which department witnesses maximum Attrition ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(10,8))\nsns.countplot(x='Department', hue='Attrition',data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 14. Which age range demands what kind of Salary hike ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 9))\nsns.boxplot(x='PercentSalaryHike',y='Age',data=data,palette='winter')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 15. What is the montly income as per the job role ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(font_scale=1)\nsns.boxplot(x='JobRole',y='MonthlyIncome',data=data)\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 16. What is the monthly income as per the Education field ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='EducationField',y='MonthlyIncome',data=data)\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking co-relation of Attrition with other attributes :"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr()['Attrition'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Critical attributes w.r.t Job role"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby(by='JobRole')[\"PercentSalaryHike\",\"YearsAtCompany\",\"TotalWorkingYears\",\"YearsInCurrentRole\",\"WorkLifeBalance\"].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Encoding the categorical columns  "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_obj=data.select_dtypes(include='object')\ndata_obj.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le= LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_col=[]\nfor col in data.columns:\n    if data[col].dtype== object and data[col].nunique()<=50:\n        categorical_col.append(col)\nprint(categorical_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in categorical_col:\n    data[col]=le.fit_transform(data[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X= data.drop('Attrition',axis=1)\ny=data['Attrition']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.metrics import roc_auc_score,roc_curve\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 33)\nprint(\"Train Set Size : \",X_train.shape)\nprint(\"Train Target Set Size : \",y_train.shape)\nprint(\"Test  Set Size : \",X_test.shape)\nprint(\"Test  Target Set Size : \",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree Classifier :"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model= DecisionTreeClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dir(model) #to select which all parameters are important to us","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred= model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NOW, WE WILL BE TUNING THE HYPERPARAMETERS OF DECISION TREE USING RANDOMIZED SEARCH CROSS VALIDATION METHOD FOR IMPROVING THE ACCURACY OF THE MODEL."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params={\"criterion\":(\"gini\", \"entropy\"),\n        \"splitter\":(\"best\", \"random\"), \n        \"max_depth\":(list(range(1, 20))), \n        \"min_samples_split\":[2, 3, 4], \n        \"min_samples_leaf\":list(range(1, 20))}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_randomized= RandomizedSearchCV(model,params,n_iter=100,n_jobs=-1,cv=5,verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_randomized.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_randomized.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n                       max_depth=4, max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=11, min_samples_split=4,\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\n                       random_state=42, splitter='random')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,y_train)\npred=model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classifier :"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(RandomForestClassifier())\nprint(RandomForestRegressor()) #check HP we can tune","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#n_estimators (how many indiviual trees can be built) and max depth(how deep can the tree go ) to consider"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier \nimport pandas as pd\nfrom sklearn.model_selection import GridSearchCV\nimport warnings\nwarnings.filterwarnings('ignore', category=FutureWarning) #to let us that the default value for gridsearch is going to change in future release\nwarnings.filterwarnings('ignore', category=DeprecationWarning) #to let us know tyhe beahviour of gridsearchcv within test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_results(results):\n    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n\n    means = results.cv_results_['mean_test_score']\n    stds = results.cv_results_['std_test_score']\n    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\nparameters = {\n    'n_estimators': [5,50,250], 'max_depth':[2,4,8,16,32,None] #none will let it go as deep as it want\n}\n\ncv = GridSearchCV(rf, parameters, cv=5) #(modelobject, parameter dictionary, how many folds we want cv=5)\ncv.fit(X_train,y_train.values.ravel()) #training lables are stored as vector type, but we need array , hence .ravel()\n\nprint_results(cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf= RandomForestClassifier(n_estimators=50,max_depth=32)\nrf.fit(X_train,y_train)\nrf_pred= rf.predict(X_test)\nprint(classification_report(y_test,rf_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,rf_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Machine "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SVC()# we only select ones that are imp - C and kernel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dir(SVC)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import svm\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = svm.SVC()\nclf.fit(X_train,y_train)\n\nprint('Accuracy of SVC on training set: {:.2f}'.format(clf.score(X_train, y_train) * 100))\n\nprint('Accuracy of SVC on test set: {:.2f}'.format(clf.score(X_test, y_test) * 100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Applying Linear SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X_train, y_train)\naccuracy_lin_train = linear.score(X_train, y_train)\naccuracy_lin_test = linear.score(X_test, y_test)\nprint('Accuracy Linear Kernel on training set:', accuracy_lin_train*100)\nprint('Accuracy Linear Kernel on testing set:', accuracy_lin_test*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Appyling RBF SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"rbf = svm.SVC(kernel='rbf', gamma=0.1, C=0.1, decision_function_shape='ovo').fit(X_train, y_train)\naccuracy_rbf_train = rbf.score(X_train, y_train)\naccuracy_rbf_test = rbf.score(X_test, y_test)\nprint('Accuracy Radial Basis Kernel on training set:', accuracy_rbf_train*100)\nprint('Accuracy Radial Basis Kernel on testing set:', accuracy_rbf_test*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Grid Search "},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']} ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# May take awhile!\ngrid.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_predictions = grid.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,grid_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,grid_predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Henceforth, we will be choosing only a few important attributes and check them on other algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X= data.drop(['Attrition','BusinessTravel','DailyRate','Department','DistanceFromHome','Education','EmployeeNumber','Gender',\n             'HourlyRate','JobInvolvement','JobLevel','JobRole','JobSatisfaction','MaritalStatus',\n             'MonthlyRate','NumCompaniesWorked','OverTime','RelationshipSatisfaction','StockOptionLevel',\n              'TrainingTimesLastYear'],axis=1)\ny=data['Attrition']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.metrics import roc_auc_score,roc_curve\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 101)\nprint(\"Train Set Size : \",X_train.shape)\nprint(\"Train Target Set Size : \",y_train.shape)\nprint(\"Test  Set Size : \",X_test.shape)\nprint(\"Test  Target Set Size : \",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying Scaling Standardiztion to all of the features in order to bring them into common scale .\n# Standardiztion : is preferred when most of the featues are not following gaussian distribution . \n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = pd.DataFrame(sc.fit_transform(X_train))\nX_test  = pd.DataFrame(sc.fit_transform(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(random_state = 42 )\n\n# Setting Parameters for Logistic Regression . \n\nparams = {    # Regularization Params\n             'penalty' : ['l1','l2','elasticnet'],\n              # Lambda Value \n             'C' : [0.01,0.1,1,10,100]\n         }\n\nlog_reg = GridSearchCV(lr,param_grid = params,cv = 10)\nlog_reg.fit(X_train,y_train)\nlog_reg.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make Prediction of test data \ny_pred = log_reg.predict(X_test)\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (6,4)\nclass_names = [1,0]\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(confusion_matrix(y_test,y_pred)), annot = True, cmap = 'BuGn_r',\n           fmt = 'g')\nplt.tight_layout()\nplt.title('Confusion matrix for Logistic Regression  Model', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (10,6)\n\n# Get predicted probabilites from the model\ny_proba = log_reg.predict_proba(X_test)[:,1]\n\n# display auc value for log_reg\nauc_log_reg = roc_auc_score(y_test,y_pred)\nprint(\"roc_auc_score value for log reg is : \",roc_auc_score(y_test,y_pred))\n\n# Create true and false positive rates\nfpr_log_reg,tpr_log_reg,thershold_log_reg_model = roc_curve(y_test,y_proba)\nplt.plot(fpr_log_reg,tpr_log_reg)\nplt.plot([0,1],ls='--')\n#plt.plot([0,0],[1,0],c='.5')\n#plt.plot([1,1],c='.5')\nplt.title('Reciever Operating Characterstic For Logistic Regregression')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier \n\ndt = DecisionTreeClassifier(random_state = 42)\n\n\n# Setting Parameters for DecisionTreeClassifier . \n\nparams = {  \n             'criterion'    : [\"gini\", \"entropy\"],\n             'max_features' : [\"auto\", \"sqrt\", \"log2\"],\n              'min_samples_split' :[i for i in range(4,16)],\n              'min_samples_leaf' : [i for i in range(4,16)]\n         }\n\ndt_clf = GridSearchCV(dt,param_grid = params,cv = 10)\ndt_clf.fit(X_train,y_train)\ndt_clf.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make Prediction of test data \ny_pred = dt_clf.predict(X_test)\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (6,4)\nclass_names = [1,0]\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(confusion_matrix(y_test,y_pred)), annot = True, cmap = 'BuGn_r',\n           fmt = 'g')\nplt.tight_layout()\nplt.title('Confusion matrix for DecisionTreeClassifier   Model', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (10,6)\n\n# Get predicted probabilites from the model\ny_proba = dt_clf.predict_proba(X_test)[:,1]\n\ndt_clf_auc_score = roc_auc_score(y_test,y_pred)\n# display auc value for DecisionTreeClassifier\nprint(\"roc_auc_score value for log reg is : \",roc_auc_score(y_test,y_pred))\n\n# Create true and false positive rates\nfpr_dt_clf,tpr_dt_clf,thershold_dt_clf_model = roc_curve(y_test,y_proba)\nplt.plot(fpr_dt_clf,tpr_dt_clf)\nplt.plot([0,1],ls='--')\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.title('Reciever Operating Characterstic For DecisionTreeClassifier ')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classifier:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf_clf = RandomForestClassifier(n_estimators = 150,min_samples_split = 20,min_samples_leaf = 5,random_state = 42)\nrf_clf.fit(X_train,y_train)\ny_pred = rf_clf.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make Prediction of test data \ny_pred = rf_clf.predict(X_test)\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (6,4)\nclass_names = [1,0]\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(confusion_matrix(y_test,y_pred)), annot = True, cmap = 'BuGn_r',\n           fmt = 'g')\nplt.tight_layout()\nplt.title('Confusion matrix for RandomForestClassifier   Model', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (10,6)\n\n# Get predicted probabilites from the model\ny_proba = dt_clf.predict_proba(X_test)[:,1]\n\nrf_auc_score = roc_auc_score(y_test,y_pred)\n\n# display auc value for RandomForestClassifier\nprint(\"roc_auc_score value for log reg is : \",roc_auc_score(y_test,y_pred))\n\n# Create true and false positive rates\nfpr_rf_clf,tpr_rf_clf,thershold_rf_clf_model = roc_curve(y_test,y_proba)\nplt.plot(fpr_rf_clf,tpr_rf_clf)\nplt.plot([0,1],ls='--')\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.title('Reciever Operating Characterstic For RandomForestClassifier ')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_jobs = -1)\n\n# set params\n\nparams = {\n             \"n_neighbors\" : [i for i in range(15)],\n               'p' : [1,2] ,\n              'leaf_size' : [i for i in range(15)],\n               \n          }\nknn = GridSearchCV(knn,param_grid = params, cv = 5)\nknn.fit(X_train,y_train)\nknn.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make Prediction of test data \ny_pred = knn.predict(X_test)\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (6,4)\nclass_names = [1,0]\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(confusion_matrix(y_test,y_pred)), annot = True, cmap = 'BuGn_r',\n           fmt = 'g')\nplt.tight_layout()\nplt.title('Confusion matrix for KNN Algorithm   Model', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (10,6)\n\n# Get predicted probabilites from the model\ny_proba = knn.predict_proba(X_test)[:,1]\n\nknn_auc_score = roc_auc_score(y_test,y_pred)\n\n\n# display auc value for KNN Algorithm\nprint(\"roc_auc_score value for log reg is : \",roc_auc_score(y_test,y_pred))\n\n# Create true and false positive rates\nfpr_KNN,tpr_KNN,thershold_KNN_model = roc_curve(y_test,y_proba)\nplt.plot(fpr_KNN,tpr_KNN)\nplt.plot([0,1],ls='--')\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.title('Reciever Operating Characterstic For KNN Algorithm ')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.title('Reciever Operating Characterstic Curve')\nplt.plot(fpr_log_reg,tpr_log_reg,label='LogisticRegression')\nplt.plot(fpr_dt_clf,tpr_dt_clf,label='DecisionTreeClassifier')\nplt.plot(fpr_rf_clf,tpr_rf_clf,label='RandomForestClassifier')\nplt.plot(fpr_KNN,tpr_KNN,label='KNearestNeighbors ')\nplt.plot([0,1],ls='--')\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.ylabel('True positive rate')\nplt.xlabel('False positive rate')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Area Under Curve Score values for Different algorithms : \")\nprint(\"LogisticRegression          : \",auc_log_reg)\nprint(\"DecisionTreeClassfier       : \",dt_clf_auc_score)\nprint(\"RandomForest Classifier     : \",rf_auc_score)\nprint(\"KnearestNeighborsClassifier : \",knn_auc_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler=StandardScaler()\nscaled_data=scaler.fit_transform(data.drop('Attrition',axis=1))\nX=scaled_data\ny=data['Attrition']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SVC()# we only select ones that are imp - C and kernel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import svm\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclf = svm.SVC()\nclf.fit(X_train,y_train)\n\nprint('Accuracy of SVC on training set: {:.2f}'.format(clf.score(X_train, y_train) * 100))\n\nprint('Accuracy of SVC on test set: {:.2f}'.format(clf.score(X_test, y_test) * 100))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Grid Search"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm = SVC()\nsvm.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparam_grid = {'C':[0.1,1,10,100], 'gamma':[1,0.1,0.01,0.001]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = GridSearchCV(SVC(), param_grid, refit = True, verbose=3)\ngrid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import svm\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=150)\n\nclf = svm.SVC(C=1,gamma=0.01)\nclf.fit(X_train,y_train)\n\nprint('Accuracy of SVC on training set: {:.2f}'.format(clf.score(X_train, y_train) * 100))\n\nprint('Accuracy of SVC on test set: {:.2f}'.format(clf.score(X_test, y_test) * 100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Grid Search on Linear SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm = SVC(kernel='linear')\nsvm.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparam_grid = {'C':[0.1,1,10,100], 'gamma':[1,0.1,0.01,0.001]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = GridSearchCV(SVC(kernel='linear'), param_grid, refit = True, verbose=3)\ngrid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import svm\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=150)\n\nclf = svm.SVC(kernel='linear',C=1,gamma=0.01)\nclf.fit(X_train,y_train)\n\nprint('Accuracy of SVC on training set: {:.2f}'.format(clf.score(X_train, y_train) * 100))\n\nprint('Accuracy of SVC on test set: {:.2f}'.format(clf.score(X_test, y_test) * 100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Grid Search on rbf SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm = SVC(kernel='rbf')\nsvm.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparam_grid = {'C':[0.1,1,10,100], 'gamma':[1,0.1,0.01,0.001]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = GridSearchCV(SVC(kernel='rbf'), param_grid, refit = True, verbose=3)\ngrid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import svm\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=150)\n\nclf = svm.SVC(kernel='rbf',C=1,gamma=0.01)\nclf.fit(X_train,y_train)\n\nprint('Accuracy of SVC on training set: {:.2f}'.format(clf.score(X_train, y_train) * 100))\n\nprint('Accuracy of SVC on test set: {:.2f}'.format(clf.score(X_test, y_test) * 100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Apply Gram Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import svm\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=150)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = svm.SVC(kernel='precomputed')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gram_train = np.dot(X_train, X_train.T)\nclf.fit(gram_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gram_test = np.dot(X_test, X_train.T)\nclf.predict(gram_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy of SVC on training set: {:.2f}'.format(clf.score(gram_train, y_train) * 100))\nprint('Accuracy of SVC on training set: {:.2f}'.format(clf.score(gram_test, y_test) * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (6,4)\nclass_names = [1,0]\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(confusion_matrix(y_test,y_pred)), annot = True, cmap = 'BuGn_r',\n           fmt = 'g')\nplt.tight_layout()\nplt.title('Confusion matrix for Logistic Regression  Model', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Gradient Boosting Classifier:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(GradientBoostingClassifier())\nprint(GradientBoostingRegressor())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nimport pandas as pd\nfrom sklearn.model_selection import GridSearchCV\n\nimport warnings\nwarnings.filterwarnings('ignore', category=FutureWarning) #to let us that the default value for gridsearch is going to change in future release\nwarnings.filterwarnings('ignore', category=DeprecationWarning) #to let us know tyhe beahviour of gridsearchcv within test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb = GradientBoostingClassifier()\nparameters = {\n    'n_estimators': [5,50,250,500], 'max_depth':[2,4,8,16,32],'learning_rate': [0.01,0.1,1,10,100]\n}\n\n\ncv = GridSearchCV(gb, parameters, cv=5) #(modelobject, parameter dictionary, how many folds we want cv=5)\ncv.fit(X_train,y_train.values.ravel()) #training lables are stored as vector type, but we need array , hence .ravel()\n\nprint_results(cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}