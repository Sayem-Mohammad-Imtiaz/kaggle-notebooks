{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"294bfaa3-8c98-8ca8-251c-003c7140b380"},"source":"Have something you would like to do but can't get started with python? Write a comment in this Kernel and I will try to get you some starter code for working with the desired data. \n\nCurrent sections \n\n - how to add region information to match.csv\n - how to add patch version to match.csv\n - join purchase_log.csv and match.csv\n\n**NOTE** This is a working document so things will be a little messy at times. I will try to regularly tidy things and leave notes as to the status of various sections. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dafad089-c10b-1ebb-3ed3-d425c5a15b30"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"markdown","metadata":{"_cell_guid":"5a7c1513-7312-a19c-5812-b520fe28012e"},"source":"###Add region information to match table\n*This sections is usable* \n\nLeft join using pandas.merge() on cluster, for the tables match.csv, and cluster_region.csv.  \nTake a look at http://pandas.pydata.org/pandas-docs/stable/generated/pandas.merge.html for information on merge.  Additionally the documentation on on this page http://pandas.pydata.org/pandas-docs/stable/merging.html was helpful. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"16a090a6-d05a-8ddc-b5f0-2fe3f49328d5"},"outputs":[],"source":"match = pd.read_csv('../input/match.csv')\ncluster_regions = pd.read_csv('../input/cluster_regions.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2a521e93-f3c0-3b58-821f-9b0f9543674c"},"outputs":[],"source":"match.iloc[:5,8:]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"913a8d2e-4d3d-ac78-2a26-9f0dcbc38d57"},"outputs":[],"source":"cluster_regions.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"76ec1fad-8fbf-d7ef-ac89-d0f7b650eaca"},"outputs":[],"source":"match = pd.merge(match, cluster_regions, how='left',left_on='cluster', right_on='cluster')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"918f7188-b55b-47c4-fa39-fa3501fbb8a1"},"outputs":[],"source":"match.iloc[:5,8:]"},{"cell_type":"markdown","metadata":{"_cell_guid":"2cc1683b-5226-5997-b469-049ef53c20f4"},"source":"###Patch Version\n*requires cleaning up*\n\nShows how to get patch version from start time. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e15d378e-2cd1-1299-a263-b7df0243bbfc"},"outputs":[],"source":"patch_dates = pd.read_csv('../input/patch_dates.csv')\npatch_dates.iloc[:,0] = pd.to_datetime(patch_dates['patch_date'])\npatch_dates.iloc[-5:]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fdee6f27-d23d-92f5-2b16-21611d5acf2b"},"outputs":[],"source":"match.loc[:,'start_time'] = pd.to_datetime(match.loc[:,'start_time'], unit='s')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7a777702-d104-5f75-0c99-e44b1737b46b"},"outputs":[],"source":"match.iloc[:5,:5]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"36bc3cdb-81b1-1e9d-8be1-1086e67b92a5"},"outputs":[],"source":"def get_patch_version(start_time, patch_date):\n    \"\"\"Determine patch version based on date\n    \n       There are faster ways to do this if processing more data, \n       This also fails in edge cases\n    \"\"\"\n    for e,i in enumerate(patch_date['patch_date']):\n        if start_time <= i:\n            return patch_date.iloc[e-1,1]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d8ed046b-2f85-1cd6-c8f8-1085fff4bf6d"},"outputs":[],"source":"match.loc[:,'patch_version'] = match.loc[:,'start_time'].apply(get_patch_version, patch_date=patch_dates)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b6bb0547-a98a-7e02-c2d3-f63a536d643d"},"outputs":[],"source":"match.loc[:,['start_time','patch_version']].head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a892e28-5de8-8762-3906-14fa7b05e8b2"},"outputs":[],"source":"match.loc[:,['start_time','patch_version']].tail()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a0a5640-8506-5a07-f734-a8b33e63a791"},"outputs":[],"source":"test_matches = pd.read_csv('../input/test_labels.csv')\ntest_players = pd.read_csv('../input/test_player.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c4852652-d3c5-89c8-bbd6-1717ff3d32f9"},"outputs":[],"source":"test_matches.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0d56351c-e271-ea23-8661-f2d77ce8df1c"},"outputs":[],"source":"test_players.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"0a2c4168-3122-b209-f391-f1e351fda784"},"source":"From this it becomes apparent that patch version is not available in the test set. I will fix this for the next update of the data. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f5ef5367-cb81-74e3-ae31-d7f9f5326e5f"},"outputs":[],"source":"%xdel test_matches\n%xdel test_players"},{"cell_type":"markdown","metadata":{"_cell_guid":"d6fd6bd6-5144-0782-2bed-fe51ac9455d3"},"source":"### Join purchase log with match\n*Unpolished could use editing* \n\nThis should point in one of the possible directions to join purchase_log, with match. Aggregation of some sort is required. This example finds the time of the first tpscroll purchase"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ce5f1f84-9585-76dd-b9c7-b35261a5865f"},"outputs":[],"source":"purchase_log = pd.read_csv('../input/purchase_log.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"118b6bd0-995d-f3da-1b7c-fa10195c63bc"},"outputs":[],"source":"purchase_log.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0bac0d2d-e3f0-abb6-707b-8e4136f1d95a"},"outputs":[],"source":"purchase_log['player_slot'].value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"68f435a4-c559-6ae1-3113-78127939604f"},"outputs":[],"source":"players_info = pd.read_csv('../input/players.csv',usecols=['match_id','account_id','player_slot'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cadd39d3-fdb4-7680-92de-658b2845d6e9"},"outputs":[],"source":"players_info.head(10)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e1eca01f-bf0d-d199-f905-6bfcd1ef49b9"},"outputs":[],"source":"match.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"dd908c03-9b16-dc91-3e6d-3a83da11c873"},"source":"purchase_log cannot be merged with *players* or *match* immediately."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a9a87d99-b6cd-f90f-9ceb-0184e25a58d0"},"outputs":[],"source":"example_log = purchase_log.query('match_id == 0 and player_slot == 0').copy()\nexample_log"},{"cell_type":"markdown","metadata":{"_cell_guid":"5a796e9d-33d6-838d-c228-cfc6b0147dcb"},"source":"Lets first replace the item_ids with item names to make this a little more intelligible. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bc51d51f-4399-4810-b6ac-459c8ac4407a"},"outputs":[],"source":"item_id_names = pd.read_csv('../input/item_ids.csv')\nitem_id_names.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"db5c071e-46ea-34a7-9609-3d15101bbe8a"},"outputs":[],"source":"# for the above example we can use item_id_names to to replace the item ids. For the full data this would probably \n# cause a memory error as pandas is memory inefficient when replacing. \nexample_log.loc[:, 'item_id'].replace(item_id_names['item_id'].values.tolist(),\n                                      item_id_names['item_name'].values.tolist(), inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bb842faf-7a44-945b-335d-807b5e7a7258"},"outputs":[],"source":"example_log.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f6b29330-1358-2ca1-3821-d741d6716ecb"},"outputs":[],"source":"# now for instance say we were only interested in the time of first tpscroll purchase\nfirst_tp_purch = example_log[example_log['item_id'] == 'tpscroll'].iloc[0,1]\nfirst_tp_purch"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"66964cb7-adcd-9899-68a5-9d5412c092e6"},"outputs":[],"source":"# lets turn this into a function and see if it fails for when there are no tpscroll purchases\n# note I didn't ac\ndef first_tpscroll_purch(log,item_id_names):\n    \"\"\"\n    :param log: all item purchases for a single player during a single match\n    :return: time of first tpscroll purchase\n    \"\"\"\n    log.loc[:, 'item_id'].replace(item_id_names['item_id'].values.tolist(),\n                                  item_id_names['item_name'].values.tolist(), inplace=True)\n    return log[log['item_id'] == 'tpscroll'].iloc[0,1]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"92baa9cd-0268-f42a-aa00-0f648d01b71a"},"outputs":[],"source":"# now use groupby on purchase log, \npurch_group = purchase_log.groupby(['match_id','player_slot'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"077657d7-aa01-9198-c878-7392a17bc8a3"},"outputs":[],"source":"# take a look at a group\nfor group in purch_group:\n    print(group)\n    break"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1e208fa1-200f-efa2-a97d-d52c73a538c2"},"outputs":[],"source":"# note this is unfinished\n\nfirst_purch_arr = np.zeros((100, 3)) # going to start with 100 to see if it breaks anything\nfor e,group in enumerate(purch_group):\n    purch_time = first_tpscroll_purch(group[1].copy(),item_id_names)\n    first_purch_arr[e,2] = purch_time\n    first_purch_arr[e,0] = group[0][0] # match_id\n    first_purch_arr[e,1] = group[0][1] # player_slot\n    if e > 98:\n        break"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6427de95-7fd2-8f75-6678-2f7ba58939fd"},"outputs":[],"source":"first_purch_df = pd.DataFrame(first_purch_arr.astype(int), columns=['match_id','player_slot','tpscroll_first_purch'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"98072f27-8fd5-cbcd-9f07-1102ee23a5e1"},"outputs":[],"source":"first_purch_df"},{"cell_type":"markdown","metadata":{"_cell_guid":"00855870-ae47-d96e-40d3-089b45f3aa0d"},"source":"This can now be merged with *player*"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"12718929-de4d-8da4-0933-cdd8db9940f7"},"outputs":[],"source":"tmp = pd.merge(first_purch_df, players_info, how='left',\n               left_on=['match_id','player_slot'],\n               right_on=['match_id','player_slot'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8b4df3cb-ab05-601a-ae61-fa824cb112e2"},"outputs":[],"source":"# now merge with with match if you want but this is creating redundent info\n# \ntmp2 = pd.merge(tmp, match, how='left',\n               left_on=['match_id'],\n               right_on=['match_id'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"385d1097-08b6-a61b-d45f-cf1959180ed3"},"outputs":[],"source":"tmp"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3b2dd014-ae8a-c95c-ff9c-c0ba8abb4e23"},"outputs":[],"source":"tmp2.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"846b937e-d3ba-a877-d7d6-27a11115e8aa"},"source":"The above can easily cause a memory error if done on larger amount of data, some more aggregation is probably a better idea then merging with *match*"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}