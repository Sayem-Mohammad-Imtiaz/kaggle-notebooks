{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Women's E-Commerce Clothing Reviews \n\nClothing ID: Integer Categorical variable that refers to the specific piece being reviewed.\n\nAge: Positive Integer variable of the reviewers age.\n\nTitle: String variable for the title of the review.\n\nReview Text: String variable for the review body.\n\nRating: Positive Ordinal Integer variable for the product score granted by the customer from 1 Worst, to 5 Best.\n\nRecommended IND: Binary variable stating where the customer recommends the product where 1 is recommended, 0 is not \nrecommended.\n\nPositive Feedback Count: Positive Integer documenting the number of other customers who found this review positive.\n\nDivision Name: Categorical name of the product high level division.\n\nDepartment Name: Categorical name of the product department name.\n\nClass Name: Categorical name of the product class name.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly as py\nimport cufflinks as cf\n\nfrom plotly.offline import iplot\n%matplotlib inline\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"py.offline.init_notebook_mode(connected=True)\ncf.go_offline()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Import","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/womens-ecommerce-clothing-reviews/Womens Clothing E-Commerce Reviews.csv', index_col=0)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(labels=['Title', 'Clothing ID'], axis=1, inplace=True)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dropna(subset=['Review Text', 'Division Name'], inplace=True)\ndf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"' '.join(df['Review Text'].tolist())[:1000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Text Cleaning","metadata":{}},{"cell_type":"code","source":"contractions = { \n\"ain't\": \"am not\",\n\"aren't\": \"are not\",\n\"can't\": \"cannot\",\n\"can't've\": \"cannot have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he will\",\n\"he'll've\": \"he will have\",\n\"he's\": \"he is\",\n\"how'd\": \"how did\",\n\"how'd'y\": \"how do you\",\n\"how'll\": \"how will\",\n\"how's\": \"how does\",\n\"i'd\": \"i would\",\n\"i'd've\": \"i would have\",\n\"i'll\": \"i will\",\n\"i'll've\": \"i will have\",\n\"i'm\": \"i am\",\n\"i've\": \"i have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it would\",\n\"it'd've\": \"it would have\",\n\"it'll\": \"it will\",\n\"it'll've\": \"it will have\",\n\"it's\": \"it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"mightn't've\": \"might not have\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"needn't\": \"need not\",\n\"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\",\n\"oughtn't\": \"ought not\",\n\"oughtn't've\": \"ought not have\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"shan't've\": \"shall not have\",\n\"she'd\": \"she would\",\n\"she'd've\": \"she would have\",\n\"she'll\": \"she will\",\n\"she'll've\": \"she will have\",\n\"she's\": \"she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"so've\": \"so have\",\n\"so's\": \"so is\",\n\"that'd\": \"that would\",\n\"that'd've\": \"that would have\",\n\"that's\": \"that is\",\n\"there'd\": \"there would\",\n\"there'd've\": \"there would have\",\n\"there's\": \"there is\",\n\"they'd\": \"they would\",\n\"they'd've\": \"they would have\",\n\"they'll\": \"they will\",\n\"they'll've\": \"they will have\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"to've\": \"to have\",\n\"wasn't\": \"was not\",\n\" u \": \" you \",\n\" ur \": \" your \",\n\" n \": \" and \"}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cont_to_exp(x):\n    if type(x) is str:\n        x = x.replace('\\\\', '')\n        for key in contractions:\n            value = contractions[key]\n            x = x.replace(key, value)\n        return x\n    else:\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = \"i don't know what date is today, I am 5'8\\\"\" ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cont_to_exp(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf['Review Text'] = df['Review Text'].apply(lambda x: cont_to_exp(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(' '.join(df['Review Text'].tolist())[:1000])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering ","metadata":{}},{"cell_type":"code","source":"from textblob import TextBlob","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['polarity'] = df['Review Text'].apply(lambda x: TextBlob(x).sentiment.polarity)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['review_len'] = df['Review Text'].apply(lambda x: len(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['word_count'] = df['Review Text'].apply(lambda x: len(x.split()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_avg_word_len(x):\n    words = x.split()\n    word_len = 0\n    for word in words:\n        word_len = word_len + len(word)\n    return word_len/len(words)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['avg_word_len'] = df['Review Text'].apply(lambda x: get_avg_word_len(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of Sentiment Polarity ","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['polarity'].iplot(kind = 'hist', colors = 'red', bins = 50,\n                    xTitle = 'Polarity', yTitle = 'Count', title  = 'Sentiment Polarity Distribution')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of Reviews Rating and Reviewers Age","metadata":{}},{"cell_type":"code","source":"df['Rating'].iplot(kind='hist', xTitle='Rating', yTitle='Count',\n                  title='Review Rating Distribution')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Age'].iplot(kind='hist', bins=40, xTitle='Age', yTitle='Count',\n                  title='Reviewers Age Dist', colors='red', linecolor='black')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of Review Text Length and Word Length","metadata":{}},{"cell_type":"code","source":"df['review_len'].iplot(kind='hist', xTitle='Review Len', yTitle='Count',\n                      title='Review Text Len Dist')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['word_count'].iplot(kind = 'hist', xTitle = 'Word Count', yTitle = 'Count',\n                       title = 'Word Count Distribution')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['avg_word_len'].iplot(kind = 'hist', xTitle = 'Avg Word Len', yTitle = 'Count',\n                         title = 'Review Text Avg Word Len Dist')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['word_count'].iplot(kind = 'hist', xTitle = 'Word Count', yTitle = 'Count', \n                       title = 'Word Count Distribution')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of Department, Division, and Class ","metadata":{}},{"cell_type":"code","source":"df.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Department Name'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby('Department Name').count()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Department Name'].value_counts().iplot(kind = 'bar', yTitle = 'Count', xTitle = 'Department',\n                                          title = \"Bar Chart of Department's Name\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Division Name'].value_counts().iplot(kind = 'bar', yTitle = 'Count', xTitle = 'Division',\n                                          title = \"Bar Chart of Division's Name\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Class Name'].value_counts().iplot(kind = 'bar', yTitle = 'Count', xTitle = 'Class',\n                                          title = \"Bar Chart of Class Name\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of Unigram, Bigram and Trigram ","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Unigram","metadata":{}},{"cell_type":"code","source":"def get_top_n_words(x, n):\n    vec = CountVectorizer().fit(x)\n    bow = vec.transform(x)\n    sum_words = bow.sum(axis = 0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n    return words_freq[:n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = get_top_n_words(df['Review Text'], 20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.DataFrame(words, columns=['Unigram', 'Frequency'])\ndf1 = df1.set_index('Unigram')\ndf1.iplot(kind='bar', xTitle = 'Unigram', yTitle = 'Count', title = ' Top 20 unigram words')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bigram \n","metadata":{}},{"cell_type":"code","source":"def get_top_n_words(x, n):\n    vec = CountVectorizer(ngram_range=(2, 2)).fit(x)\n    bow = vec.transform(x)\n    sum_words = bow.sum(axis = 0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n    return words_freq[:n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = get_top_n_words(df['Review Text'], 20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.DataFrame(words, columns = ['Bigram', 'Frequency'])\ndf1 = df1.set_index('Bigram')\ndf1.iplot(kind = 'bar', xTitle = 'Bigram', yTitle = 'Count', title = ' Top 20 Bigram words')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Trigram ","metadata":{}},{"cell_type":"code","source":"def get_top_n_words(x, n):\n    vec = CountVectorizer(ngram_range=(3, 3)).fit(x)\n    bow = vec.transform(x)\n    sum_words = bow.sum(axis = 0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n    return words_freq[:n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = get_top_n_words(df['Review Text'], 20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.DataFrame(words, columns = ['Trigram', 'Frequency'])\ndf1 = df1.set_index('Trigram')\ndf1.iplot(kind = 'bar', xTitle = 'Trigram', yTitle = 'Count', title = ' Top 20 Trigram words')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of Unigram, Bigram and Trigram without STOP WORDS","metadata":{}},{"cell_type":"markdown","source":"### Unigram ","metadata":{}},{"cell_type":"code","source":"def get_top_n_words(x, n):\n    vec = CountVectorizer(ngram_range=(1, 1), stop_words='english').fit(x)\n    bow = vec.transform(x)\n    sum_words = bow.sum(axis = 0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n    return words_freq[:n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = get_top_n_words(df['Review Text'], 20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.DataFrame(words, columns = ['Unigram', 'Frequency'])\ndf1 = df1.set_index('Unigram')\ndf1.iplot(kind = 'bar', xTitle = 'Unigram', yTitle = 'Count', title = ' Top 20 Unigram words')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bigram ","metadata":{}},{"cell_type":"code","source":"def get_top_n_words(x, n):\n    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(x)\n    bow = vec.transform(x)\n    sum_words = bow.sum(axis = 0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n    return words_freq[:n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = get_top_n_words(df['Review Text'], 20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.DataFrame(words, columns = ['Bigram', 'Frequency'])\ndf1 = df1.set_index('Bigram')\ndf1.iplot(kind = 'bar', xTitle = 'Bigram', yTitle = 'Count', title = ' Top 20 Bigram words')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Trigram ","metadata":{}},{"cell_type":"code","source":"def get_top_n_words(x, n):\n    vec = CountVectorizer(ngram_range=(3, 3), stop_words='english').fit(x)\n    bow = vec.transform(x)\n    sum_words = bow.sum(axis = 0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n    return words_freq[:n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = get_top_n_words(df['Review Text'], 20)\nwords","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.DataFrame(words, columns = ['Trigram', 'Frequency'])\ndf1 = df1.set_index('Trigram')\ndf1.iplot(kind = 'bar', xTitle = 'Trigram', yTitle = 'Count', title = ' Top 20 Trigram words')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of Top 20 Parts-of-Speech POS tags ","metadata":{}},{"cell_type":"code","source":"import nltk","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(str(df['Review Text']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"blob = TextBlob(str(df['Review Text']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(nltk.help.upenn_tagset())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pos_df = pd.DataFrame(blob.tags, columns=['words', 'pos'])\npos_df = pos_df['pos'].value_counts()\npos_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pos_df.iplot(kind='bar')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bivariate Analysis ","metadata":{}},{"cell_type":"code","source":"df.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x='Division Name', y='polarity', data=df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x = 'Division Name', y = 'polarity', data = df, kind = 'box')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x = 'Department Name', y = 'polarity', data = df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x = 'Department Name', y = 'polarity', data = df, kind = 'box')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x = 'Division Name', y = 'review_len', data = df, kind = 'box')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.catplot(x = 'Department Name', y = 'review_len', data = df, kind = 'box')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of Sentiment Polarity of Reviews Based on the Recommendation ","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\nimport plotly.graph_objects as go","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x1 = df[df['Recommended IND']==1]['polarity']\nx0 = df[df['Recommended IND']==0]['polarity']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(x1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trace0 = go.Histogram(x = x0, name = 'Not Recommended', opacity = 0.7)\ntrace1 = go.Histogram(x = x1, name = 'Recommended', opacity = 0.7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = [trace0, trace1]\nlayout = go.Layout(barmode = 'overlay', title = 'Distribution of Sentiment Polarity of Reviews Based on the Recommendation')\nfig = go.Figure(data = data, layout = layout)\n\niplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of Ratings Based on the Recommendation ","metadata":{}},{"cell_type":"code","source":"x1 = df[df['Recommended IND']==1]['Rating']\nx0 = df[df['Recommended IND']==0]['Rating']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(x1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trace0 = go.Histogram(x = x0, name = 'Not Recommended', opacity = 0.7)\ntrace1 = go.Histogram(x = x1, name = 'Recommended', opacity = 0.7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = [trace0, trace1]\nlayout = go.Layout(barmode = 'overlay', title = 'Distribution of Reviews Rating Based on the Recommendation')\nfig = go.Figure(data = data, layout = layout)\n\niplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}