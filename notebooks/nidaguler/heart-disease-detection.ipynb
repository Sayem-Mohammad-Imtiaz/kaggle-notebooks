{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hello, everyone! I am new here. "},{"metadata":{},"cell_type":"markdown","source":"<h1>Data Analysis of Heart Disease </h1>"},{"metadata":{},"cell_type":"markdown","source":"<h2>Import Required Modules</h2>"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Read Data</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/heart.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count the number of rows and columns in the daha set\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#count the number of missing values in each columns\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get a count of the number of target(1) or not(0)\ndf.target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualize the count\nsns.countplot(df.target,label=\"count\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a pair plot\nsns.pairplot(df,hue=\"target\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualize the correlation\nplt.figure(figsize=(15,10))\nsns.heatmap(df.corr(), annot=True,fmt=\".0%\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the data set into independent(x) and dependent (y) data sets\nx=df.iloc[:,0:13].values\ny=df.iloc[:,-1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#split the data set into 75% training and 25% testing\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test=train_test_split(x,y,test_size=0.25,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scale the data(feature scaling)\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nx_train=sc.fit_transform(x_train)\nx_test=sc.fit_transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a function for the models\ndef models(x_train,y_train):\n  #Logistic Regression Model\n  from sklearn.linear_model import LogisticRegression\n  log=LogisticRegression(random_state=0)\n  log.fit(x_train,y_train)\n  \n  #Decision Tree\n  from sklearn.tree import DecisionTreeClassifier\n  tree=DecisionTreeClassifier(criterion='entropy',random_state=0)\n  tree.fit(x_train,y_train)\n  \n  #Random Forest Classifier\n  from sklearn.ensemble import RandomForestClassifier\n  forest = RandomForestClassifier(n_estimators=10,criterion=\"entropy\",random_state=0)\n  forest.fit(x_train,y_train)\n\n  #Print the models accuracy on the training data\n  print(\"[0]Logistic Regression Training Accuracy:\",log.score(x_train,y_train))\n  print(\"[1]Decision Tree Classifier Training Accuracy:\",tree.score(x_train,y_train))\n  print(\"[2]Random Forest Classifier Training Accuracy:\",forest.score(x_train,y_train))\n  \n  return log,tree,forest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting all of the models\nmodel = models(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test model accuracy on confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\nfor i in range(len(model)):\n  print(\"Model \", i)\n  cm =confusion_matrix(y_test,model[i].predict(x_test))\n\n  TP=cm[0][0]\n  TN=cm[1][1]\n  FN=cm[1][0]\n  FP=cm[0][1]\n\n  print(cm)\n  print(\"Testing Accuracy = \", (TP+TN) / (TP+TN+FN+FP))\n  print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#show another way to get metrics of the models\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nfor i in range(len(model) ):\n  print(\"Model \",i)\n  print( classification_report(y_test,model[i].predict(x_test)))\n  print( accuracy_score(y_test,model[i].predict(x_test)))\n  print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print the prediction of random forest classifier model\npred=model[2].predict(x_test)\nprint(pred)\nprint()\nprint(y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"References:\n\nhttps://www.kaggle.com/kanncaa1/data-sciencetutorial-for-beginners\n\nhttps://seaborn.pydata.org/tutorial/distributions.html\n\nhttps://www.kaggle.com/kanncaa1/machine-learning-tutorial-for-beginners\n\nhttps://www.youtube.com/watch?v=NSSOyhJBmWY\n\nThank you!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}