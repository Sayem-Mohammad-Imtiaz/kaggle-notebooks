{"cells":[{"metadata":{"_uuid":"8f4ba61032210e7c6c38d1e10b2945d3f7ff5f6d"},"cell_type":"markdown","source":"# Twitter US Airlines Sentiment with ULMFiT"},{"metadata":{"_uuid":"002138cc3d30e60595f6fdd0249b5274f69645d4"},"cell_type":"markdown","source":"## Introduction"},{"metadata":{"_uuid":"db8eaed4bba95cbf0d6e51e4af3fab888dec6867"},"cell_type":"markdown","source":"This notebook implements training the [AWD-LSTM](https://arxiv.org/pdf/1708.02182.pdf) architecure according to [ULMFiT](https://arxiv.org/pdf/1801.06146.pdf) paper on the [Twitter US Airline Sentiment Dataset](https://www.kaggle.com/crowdflower/twitter-airline-sentiment) using fastai library. The aim of the model is to determine sentiments of the tweets."},{"metadata":{},"cell_type":"markdown","source":"First, needed libraries are imported."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sn\n\nfrom fastai.text import *\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We read the file containing tweets into a DataFrame object and have a look at the first few records."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/Tweets.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that our DataFrame contains numerous columns that provide information about the corresponding tweet. In our context of training a language model the most important columns are 'airline_sentiment' and 'text'. Let's check if there're no missing values in them.\nNext we visualise the counts of tweets by sentiment category."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['airline_sentiment', 'text']].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There're no missing values so we can proceed. Let's visualise counts of tweets by sentiment category."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['airline_sentiment'].value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that neutral and positive tweets are underepresented compared to negative ones. We will not balance this dataset and evaluate the perfomance of the model on the test set with the same proportion of sentiments.\n\nNext let's investugate the relationship between tweet length and its sentiment."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['tweet_length'] = df['text'].apply(len)\ndf.groupby(['tweet_length', 'airline_sentiment']).size().unstack().plot(kind='line')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that for negative sentiment distribution is higly skewed towards longer tweets. \n\nWe split our dataset into train and test parts. We don't show the test part to our model until it is trained and use it for evaluation purposes. Then we save them as .csv files for later purporses."},{"metadata":{"trusted":true},"cell_type":"code","source":"rnd_state = 111\ndf_train, df_test = train_test_split(df, test_size=0.15, random_state = rnd_state)\ndf_train[['airline_sentiment', 'text']].to_csv('Tweets_train.csv', index=False, encoding='utf-8')\ndf_test[['airline_sentiment', 'text']].to_csv('Tweets_test.csv', index=False, encoding='utf-8')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we create TextDataBunch objects for language model and classifier and save them so in future iterations we can load them straight away and skip running previous steps. \n\nWe specify 15% our training data for validation purposes so that we can experiment with hypoparameters and adjust them based on perfomance on the validation data."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm = TextLMDataBunch.from_csv('.', 'Tweets_train.csv', valid_pct=0.15)\ndata_clas = TextClasDataBunch.from_csv('.', 'Tweets_train.csv', valid_pct=0.15, vocab=data_lm.train_ds.vocab, bs=32)\ndata_lm.save('data_lm_export.pkl')\ndata_clas.save('data_clas_export.pkl')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load previosly created data for language model and classifier."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_lm = load_data('.', 'data_lm_export.pkl')\ndata_clas = load_data('.', 'data_clas_export.pkl', bs=32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have a look at what our TextDataBunch objects contain. The texts of tweets has gone through automatic tokenization stage that includes but not limited to:\n* Separation according to spaces and punctuation.\n* Transforming text to lower case.\n* Introducing special tokens that encode spicific information, e.g. indication of the beginning of a text.\nAfter that tokens are numericalised meaning substituting words by their values in the vocabulary. The resulting numerical sequences will serve as inputs for the language model.\nWe print an example preprocessed text with the encoding it was transformed to."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Preprocessed text:\", data_lm.x[0])\nprint(\"\\n\")\nprint(\"Corresponding numerical sequence:\", data_lm.x[0].data)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Language model"},{"metadata":{},"cell_type":"markdown","source":"Now we implement our language model. The UlMFit apporach consists of three main steps:\n1. Pretraining the language model. We will download the model pretrained on a large corpus of English text. \n2. Fine-tuning the language model. This is necessary to adjust the language model to the specificities of the dataset we are going to work with.\n3. Using our language model as an ecoder for the classifier which will infer the sentiment of the tweets.\n\nNow we are ready to create the learner for our model. It will come with pretrained [AWD_LSTM](https://arxiv.org/pdf/1708.02182.pdf) architecure which will serve as our laguage model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we explore the space of possible learning rates."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we fit the last layer of our model for 1 epoch using 1 cycle policy. This approach was described to work best in the original paper. We use the learning rate of one order of magnitude lower than the one corresponding to the lowest loss on the previous plot as recommended. We use values for the cyclic momentum and other parameters as they were found to work well in guidelines of fastai course."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(1, 1e-02, moms=(0.8, 0.7))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we unfreeze the whole model and fine-tune it for 10 epochs."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(10,1e-03, moms=(0.8, 0.7))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the last few epochs we see that the accuracy on the validation set stagnates which means that training further will only lead to overfitting.\n\nNext we ask our trained language model to finish a phrase."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.predict(\"My experience was\", n_words=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that our model follows basic rules of grammar. \n\nFinally we save our trained model to use it as an encoder for the classifier."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save_encoder('ft_enc')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Classifier"},{"metadata":{},"cell_type":"markdown","source":"Now it's time to implement the final stage of ULMFit - Classifier. Fot this we create an appropriate learner and import our fine-tuned language model as an encoder."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\nlearn.load_encoder('ft_enc')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again, let's explore different values for the learning rate."},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will train our classifier gradually unfreezing layers from the top. Training all layers straight way may result in loss of information achieved through fine-tuning of language model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(8, 1e-2, moms=(0.8, 0.7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.freeze_to(-2)\nlearn.fit_one_cycle(5, slice(1e-2/(2.6**4),1e-2), moms=(0.8, 0.7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(5, slice(5e-3/(2.6**4),5e-3), moms=(0.8, 0.7))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluating the model"},{"metadata":{},"cell_type":"markdown","source":"Now we will evalute the perfomance. For this let's first read the previously saved test part of our dataset. Then make a prediction of each tweet."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(\"Tweets_test.csv\", encoding=\"utf-8\")\ntest_df['pred_sentiment'] = test_df['text'].apply(lambda row: str(learn.predict(row)[0]))\ntest_df['airline_sentiment'].value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that test set contains same proportion of sentiments as train set.\nFinally we calculate the accuracy on the test set. "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test Accuracy: \", accuracy_score(test_df['airline_sentiment'], test_df['pred_sentiment']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's ivestigate mistakes that has been made by our model using confusion matrix."},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_matrix = confusion_matrix(y_true=test_df['airline_sentiment'].values, y_pred=test_df['pred_sentiment'].values, labels=['negative', 'neutral', 'positive'])\nlabels = ['negative', 'neutral', 'positive']\nsn.heatmap(conf_matrix, annot=True, fmt='g', xticklabels=labels, yticklabels=labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that our model classified significant amount of neutral tweets as negatives which is reasonable because even as humans it sometimes not clear. What is more interesting is to look at positive tweets that were classified as negatives."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_colwidth', -1)\ntest_df.loc[(test_df['airline_sentiment'] == 'positive') & (test_df['pred_sentiment'] == 'negative')].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From here we see that these tweets are indeed confusing as often they are responses to other users' tweets."},{"metadata":{},"cell_type":"markdown","source":"## Coclusion\nIn this notebook we explored the application of ULMFiT strategy for detecting sentiments of tweets and achieved level of accuracy similar to human. Improvement in perfomance might be obtained by tweaking the parameters of the model as well as taking into account additional information such as relation between particular tweets."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}