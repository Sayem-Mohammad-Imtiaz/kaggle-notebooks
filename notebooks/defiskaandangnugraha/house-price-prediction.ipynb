{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Preface"},{"metadata":{},"cell_type":"markdown","source":"In this notebook, it will be briefly discussed the effect of regularization on regression models and examples of how to evaluate regression models. The data used were taken from the Kaggle dataset: https://www.kaggle.com/anmolkumar/house-price-prediction-challenge"},{"metadata":{},"cell_type":"markdown","source":"# Import Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/house-price-prediction-challenge/train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Understanding"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{},"cell_type":"markdown","source":"## Dataset Splitting "},{"metadata":{},"cell_type":"markdown","source":"Performed splitting between features and targets and data used for training with data to be tested."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(columns=['TARGET(PRICE_IN_LACS)','LONGITUDE','LATITUDE','ADDRESS'])\ny = df['TARGET(PRICE_IN_LACS)']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\nX_train.shape,X_test.shape,y_train.shape,y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In general, there is not much feature engineering done where only quick feature selection is carried out and then preprocessing is carried out by adjusting the nature of the feature whether numeric or catatonic. For numeric features, polynomial degrees were adjusted, data transformation was performed using the yeo-johnson method, and scaling with a standard scaler. Meanwhile, for categorical features, encoding is performed."},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, PolynomialFeatures, PowerTransformer, StandardScaler\nfrom sklearn.compose import ColumnTransformer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_pipe = Pipeline([\n    ('poly',PolynomialFeatures(degree=5)),\n    ('transform',PowerTransformer(method='yeo-johnson')),\n    ('scaler',StandardScaler())\n])\n\ncat_pipe = Pipeline([\n    ('encoder',OrdinalEncoder())\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prepro = ColumnTransformer([\n    ('numeric',num_pipe,['SQUARE_FT','BHK_NO.']),\n    ('categoric',cat_pipe,['POSTED_BY','UNDER_CONSTRUCTION','RERA','BHK_OR_RK','READY_TO_MOVE','RESALE'])\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Learning "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, ElasticNet\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To find out how the effect of regularization is, at the training or learning stage it is compared to the Linear Regression model with a 5th order polynomial with the Elastic Net Regression model with the same polynomial order, but there are additional hyperparameters, namely the weight of the penalty which functions to regularize and the ratio of penalty weight between terms l1 and l2 norm."},{"metadata":{},"cell_type":"markdown","source":"### Using Linear Regression (Polynomial) "},{"metadata":{"trusted":true},"cell_type":"code","source":"param_linreg = {\n    'algo__fit_intercept':[True,False],\n}\n\npipe_linreg = Pipeline([\n    ('prep',prepro),\n    ('algo',LinearRegression())\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_linreg = GridSearchCV(pipe_linreg,param_linreg,cv=3,n_jobs=-1,verbose=1)\nmodel_linreg.fit(X_train,y_train)\n\nprint(\"Train data R squared score: \", model_linreg.score(X_train,y_train))\nprint(\"Test data R squared score: \", model_linreg.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The choice of degree polynomial 5 was deliberately made to see how the overfit model was. Based on the R-squared score in the Linear Regression model, it can be seen that the training data has a higher R-squared score than the R-squared score in the test data, the difference is about 0.2. This means that the model is relatively good when studying the training data, but the model's performance is not good when it is applied to the test data, in other words, there is an overfit condition."},{"metadata":{},"cell_type":"markdown","source":"### Using Elastic Net Regression "},{"metadata":{"trusted":true},"cell_type":"code","source":"param_enet = {\n    'algo__fit_intercept':[True,False],\n    'algo__alpha':np.logspace(start=-4,stop=2),\n    'algo__l1_ratio':np.linspace(start=0,stop=1)\n}\n\npipe_enet = Pipeline([\n    ('prep',prepro),\n    ('algo',ElasticNet())\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_enet = RandomizedSearchCV(pipe_enet,param_enet,cv=3,n_iter=100,n_jobs=-1,verbose=1,random_state=42)\nmodel_enet.fit(X_train,y_train)\n\nprint(model_enet.best_params_)\nprint(\"Train data R squared score: \", model_enet.score(X_train,y_train))\nprint(\"Test data R squared score: \", model_enet.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the R-squared score on the Elastic Net Regression model, it can be seen that the scores on the training data are relatively the same as the scores on the test data. This means that the l1 norm and l2 norm terms in the Elastic Net Regression model can reduce the model's tendency to overfitting."},{"metadata":{},"cell_type":"markdown","source":"### Using XGBoost Regressor "},{"metadata":{"trusted":true},"cell_type":"code","source":"param_xgb = {\n    'algo__max_depth':np.arange(1,11),\n    'algo__learning_rate':np.logspace(-2,0),\n    'algo__n_estimators':np.arange(100,200),\n    'algo__gamma':np.arange(1,11),\n    'algo__reg_alpha':np.logspace(-3,1),\n    'algo__reg_lambda':np.logspace(-3,1)\n}\n\npipe_xgb = Pipeline([\n    ('prep',prepro),\n    ('algo',XGBRegressor(n_jobs=-1,random_state=42))\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_xgb = RandomizedSearchCV(pipe_xgb,param_xgb,cv=3,n_iter=100,n_jobs=-1,verbose=1,random_state=42)\nmodel_xgb.fit(X_train,y_train)\n\nprint(model_xgb.best_params_)\nprint(\"Train data R squared score: \", model_xgb.score(X_train,y_train))\nprint(\"Test data R squared score: \", model_xgb.score(X_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we try to improve the performance of the model using the gradient boosting algorithm. By using the XGB Regressor model, a significant increase in the R-squared score is obtained so that this model will later be used to evaluate with other metric scores."},{"metadata":{},"cell_type":"markdown","source":"# Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model_xgb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mae = mean_absolute_error(y_test,y_pred)\nmse = mean_squared_error(y_test,y_pred)\nr2 = r2_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The model performance for testing set\")\nprint(\"--------------------------------------\")\nprint('MAE is {}'.format(mae))\nprint('MSE is {}'.format(mse))\nprint('R2 score is {}'.format(r2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make Trendline\n\ny_test = pd.DataFrame(y_test)\ny_pred = pd.DataFrame(y_pred)\nlm = LinearRegression()\nlm.fit(y_test,y_pred)\ny_trend = lm.predict(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_trend = pd.DataFrame(y_trend)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(15,5))\n\nax1 = plt.subplot(121)\nax1.scatter(y_test,y_pred)\nax1.plot(y_test['TARGET(PRICE_IN_LACS)'],y_trend[0],color='green')\nax1.set_xlabel('Actual')\nax1.set_ylabel('Predicted')\nax1.set_title('Actual vs Predicted')\n\nax2 = plt.subplot(122)\nsns.residplot(y_test,y_pred)\nax2.set_xlabel('Actual')\nax2.set_ylabel('Predicted')\nax2.set_title('Residual Plot')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Actual vs predicted and residual plot visualization are used to check whether the model is relatively good or not. Based on the results obtained, the relative residual plot has shown a symetrical and stationary distribution and the actual vs predicted plot has shown a relatively strong trend. Thus, this visualization also supports the relatively good model produced. However, there are points of prediction that are not quite right and there are still outliers. The model's performance can be further improved by eliminating outliers, feature selection by model, or perhaps doing more in-depth exploratory data analysis."},{"metadata":{},"cell_type":"markdown","source":"# Recap"},{"metadata":{},"cell_type":"markdown","source":"In this notebook it has been shown that the effect of the weight penalty is for the regularization process which reduces the model's tendency to overfit. And it has also been shown that the score metrics for evaluating the regression model used the MAE, MSE, and R-squared metrics. Actual vs predicted visualization and residual plot can be used to better illustrate the model's performance and what are the strategies to improve model performance."}],"metadata":{"kernelspec":{"display_name":"Python [conda env:defiska]","language":"python","name":"conda-env-defiska-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":4}