{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"scrolled":true},"cell_type":"code","source":"# Imports\n#from datetime import datetime\nimport datetime as dt\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math\n#import plotly\nimport plotly.graph_objs as go\nimport plotly.plotly as py\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\n\n'''For ML:'''\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\n\n#plotly.__version__\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# List of Datafiles\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b586a7ac6d48b8762e394c130df3333e0a237a15","_kg_hide-input":true},"cell_type":"code","source":"pitstops = pd.read_csv('../input/pitStops.csv')\nresults = pd.read_csv('../input/results.csv')\nraces = pd.read_csv('../input/races.csv')\ncircuits = pd.read_csv('../input/circuits.csv', encoding='latin1')\ndrivers = pd.read_csv('../input/drivers.csv', encoding='latin1')\n\n#identify yellow flag\nlaptimes = pd.read_csv('../input/lapTimes.csv')\nlaptimes.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6cc94bd70d96e1ec5f13788b3fce4c59cbec8e5"},"cell_type":"code","source":"# Time Behind Leader\nlaptimes.sort_values(by = ['raceId', 'driverId', 'lap'], inplace=True)\n\nlaptimes.head()\n#calculating the \"totalmilli\" and creating apropriate column for it in the df\nlaptimes['totalmilli'] = laptimes.groupby(['raceId', 'driverId'])['milliseconds'].transform(pd.Series.cumsum)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"166c275b6d60c340cc09f4ff44c31bf0f4542cbb"},"cell_type":"code","source":"# Creating the copies to mearge:\nlaptimes_2 = laptimes[['raceId', 'lap', 'position', 'totalmilli']].copy()\nlaptimes_3 = laptimes[['raceId', 'lap', 'position', 'totalmilli']].copy()\n\n# Adding and subtractin \"1\" to each position, so than we can merge the \"correct\" position with the one in front of it:\nlaptimes_2['position'] = laptimes_2['position'] + 1\nlaptimes_2.rename(columns={'position': \"position_plus_1\", 'totalmilli' : 'totalmilli_plus_1'}, inplace=True)\n\nlaptimes_3['position'] = laptimes_3['position'] -1\nlaptimes_3.rename(columns={'position': \"position_min_1\", 'totalmilli' : 'totalmilli_min_1'}, inplace=True)\n\n# Mearging two dataframes:\nmerged = pd.merge(laptimes, laptimes_2, how = 'left', left_on=['raceId', 'lap', 'position'],\n                  right_on=['raceId', 'lap', 'position_plus_1'])\n\n# Mearging two dataframes:\nmerged = pd.merge(merged, laptimes_3, how = 'left', left_on=['raceId', 'lap', 'position'],\n                  right_on=['raceId', 'lap', 'position_min_1'])\n\n# Calculating how far each car behind/in front:\nmerged['to_in_front'] = merged['totalmilli'] - merged['totalmilli_plus_1']\nmerged['to_behind'] = merged['totalmilli_min_1'] - merged['totalmilli']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24b9682a2153133a1ac8c0a2bec226636d4cfe71"},"cell_type":"code","source":"#Checking Results of Time Between\n# 'to_previous' has to be >= 0:\nprint(\"positive:\", merged[merged['to_in_front']>0].shape)\nprint(\"equal zero:\", merged[merged['to_in_front']==0].shape)\nprint('less than zero', merged[merged['to_in_front']<0].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69c15c6c7791c73a15743dcde28a7175398f8788"},"cell_type":"code","source":"# Now we can delete 'position_plus_1' and 'totalmilli_plus_1' columns if needed.\nmerged.drop(['position_plus_1', 'totalmilli_plus_1', 'position_min_1', 'totalmilli_min_1'], axis=1, inplace = True)\n# Puting merged df into laptimes\nlaptimes = merged.copy()\nlaptimes.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f6af688b1bf6ef9f6d4edd9ba7f4875c7062156"},"cell_type":"markdown","source":"\n## Creating parameters:"},{"metadata":{"_uuid":"1e1500dc64682537d5b7d14efca34e2fea8936bc"},"cell_type":"markdown","source":"### DBs descriptions:\n\npitstops: 'raceId', 'driverId', 'stop'(order number), 'lap', 'time'(real time), 'duration',\n       'milliseconds'\n       \nresults: 'resultId', 'raceId', 'driverId', 'constructorId'??, 'number', 'grid',\n       'position'(many NaN), 'positionText'(has letters R, D), 'positionOrder'(only numbers),\n        'points', 'laps', 'time', 'milliseconds'(total time for the race), 'fastestLap' (order number),\n        'rank'?, 'fastestLapTime', 'fastestLapSpeed', 'statusId'??\n        \nraces: 'raceId', 'year', 'round', 'circuitId', 'name', 'date', 'time', 'url' (just name, date, Wiki page\n                                                                             of the race)\n                                                                             \ncircuits: 'circuitId', 'circuitRef', 'name', 'location', 'country', 'lat', 'lng',\n       'alt', 'url'\n       \ndrivers: 'driverId', 'driverRef', 'number', 'code', 'forename', 'surname', 'dob',\n       'nationality', 'url'"},{"metadata":{"_uuid":"25bb0cee960efa45fd5ab719ac6280e2c6d09f10"},"cell_type":"markdown","source":"### Calculating the average (finish) position for each driver:"},{"metadata":{"trusted":true,"_uuid":"82d4c4dfdcf50f373ce5931025cee816d5b0c338"},"cell_type":"code","source":"'''To calculate the average position at the finish we take only races that were finished by the driver'''\navg_position = results[results['milliseconds'].notnull()].groupby(['driverId'])['position'].mean()\navg_position = avg_position.to_frame()\navg_position.columns = ['avg_position']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff0b460002ea36b69b1d331b3dda7e23d6bbd506"},"cell_type":"code","source":"'''Puting avg_position into seperate column in the results df'''\nresults = results.merge(avg_position, left_on='driverId', right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0458cbebc09b1ec4d841f084cecca06d14bb9219"},"cell_type":"markdown","source":"### Calculating relative position at every lap:"},{"metadata":{"trusted":true,"_uuid":"95d1e5402527eb8c22afcf58b7c8531cd4094bc7"},"cell_type":"code","source":"laptimes = laptimes.merge(avg_position, left_on='driverId', right_index=True)\nlaptimes['relative_to_avg'] = laptimes['avg_position'] - laptimes['position']\nlaptimes.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9dee36c3030aae8a39ba504ffadf5bb617fc47ac"},"cell_type":"markdown","source":"'''Notes:'''\n\npitstops_df - only has data for 841-988 raceId\n    pitstops['raceId'].hist()\nlaptimes_df - strange (but the last interval = 841-988 )\n    laptimes['raceId'].hist(bins = 100)\nresults-df - fine\n    results['raceId'].hist(bins = 100)\n    \n'''Starts from the 2nd pitstop'''\nlaptimes[(laptimes['raceId']==908)&(laptimes['driverId']==820)].head()\n\n'''Maybe add avg_ps_duration?'''"},{"metadata":{"_uuid":"1c4bb3ee8895d2c325d5640327e72345948c63c1"},"cell_type":"markdown","source":"### Merging pitstops_df with laptime_df:"},{"metadata":{"trusted":true,"_uuid":"436fc7ff4bba9adaf92f3cab5dc0c71d77ab2e25"},"cell_type":"code","source":"pitstops.rename(columns = {'stop':'ps_order', 'time':'exact_ps_time', 'milliseconds':'ps_duration'}, inplace=True)\n\n'''Take only races for which we have ps data (#841-988) and drop \"duration\" column from pitstops_df'''\nlaptimes = laptimes[laptimes['raceId']>=841].merge(pitstops.drop(['duration'], axis=1),\n                                                    how='left',on =['raceId','driverId','lap'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6b2126eb079247611ef165df6d475ff4fccd96c"},"cell_type":"markdown","source":"### Calculating 'minLaps' and 'flag'"},{"metadata":{"trusted":true,"_uuid":"a63d7a51d16ccec42c52f3a3d6ae4dee1818a57f"},"cell_type":"code","source":"'''Getting the fastest laps times:'''\nminLaps = laptimes.groupby(['raceId', 'lap'])['milliseconds'].min().reset_index()\nminLaps.head()\n\n# '''Getting the fastest laps in races times:'''\nBestLapinRaces = laptimes.groupby(['raceId'])['milliseconds'].min().reset_index()\nBestLapinRaces.head()\n\n# '''Calculating yellowThreshold = fastest lap in race * 1.1'''\nBestLapinRaces['yellowThreshold'] = BestLapinRaces['milliseconds'] * 1.1 \nBestLapinRaces.head()\n\n# '''flag if yellowThreshold > the best lap time'''\nminLaps = minLaps.merge(BestLapinRaces[['raceId','yellowThreshold']], how = 'left', on='raceId')\nminLaps['flag'] = (minLaps['yellowThreshold'] >  minLaps['milliseconds']).astype(int)\nminLaps.drop(['yellowThreshold'], axis=1) #drop yellowThreshold\n              \nminLaps.rename(index=str, columns={\"milliseconds\": \"minLap\"}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2dca30a089fde0e76c89c5aa34de9d4285769d33"},"cell_type":"code","source":"'''Merge laptimes_df with minLaps_df'''\nlaptimes = laptimes.merge(minLaps, how='left', on=['raceId', 'lap'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0c1a333baa5375722f15720e25b36ab9b0eb245"},"cell_type":"markdown","source":"### Calculating previous lap times\nWe take the times in milliseconds for the previous 2 laps. So, we observe the cars from a 3rd lap. Although there are cases, when the drivers did a pit stop at the 1st or 2nd lap, we ignore them."},{"metadata":{"trusted":true,"_uuid":"fa3fc7725939ab86967dbf1f639f44020900ece9"},"cell_type":"code","source":"'''Graph to better understand the number of pit stops that are ignored:'''\nlaptimes[(laptimes['ps_order'].notnull())&(laptimes['lap'] <= 10)]['lap'].hist(bins=10)\nplt.title('Pitstops')\nplt.xlabel('lap')\nvar = plt.ylabel('number of pit stops')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2cc6faf7ef28ae285e1f9af1606d6144c69945cb"},"cell_type":"markdown","source":"### Getting the time for the previous two laps and puting those into seperate columns:"},{"metadata":{"trusted":true,"_uuid":"d3373f0ccaf36f4c64bd4674b5a44aa74a190aa4"},"cell_type":"code","source":"'''Creating df to get time_min_1 and put it into laptimes_df'''\nlap_min_1 = laptimes.groupby(['raceId', 'driverId', 'lap'])['milliseconds'].first().to_frame()\nlap_min_1.reset_index(inplace=True)\nlap_min_1['lap'] = lap_min_1['lap'] + 2 # increased to 2 & 3 prior because entry lap show pit activity - ie slowing\nlap_min_1.rename(columns={\"milliseconds\": \"milli_for_min_1\"}, inplace=True)\n\n'''Creating df to get time_min_2 and put it into laptimes_df'''\nlap_min_2 = laptimes.groupby(['raceId', 'driverId', 'lap'])['milliseconds'].first().to_frame()\nlap_min_2.reset_index(inplace=True)\nlap_min_2['lap'] = lap_min_2['lap'] + 3\nlap_min_2.rename(columns={\"milliseconds\": \"milli_for_min_2\"}, inplace=True)\n\n'''Merging 3 dataframes'''\nlaptimes = laptimes.merge(lap_min_1, how='left', on=['raceId', 'driverId', 'lap'])\nlaptimes = laptimes.merge(lap_min_2, how='left', on=['raceId', 'driverId', 'lap'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6c20e7dafd9d5a018963ccc069be6fd0dd410c4"},"cell_type":"markdown","source":"### Calculating time since last ps\nWe assume that the firs pit stop is done at the start of each race by each driver"},{"metadata":{"trusted":true,"_uuid":"96ffdfb7b1dfa9f57f78479fb77300770dc4797b","scrolled":true},"cell_type":"code","source":"laptimes['since_last_ps'] = np.nan\nfor index, row in laptimes[laptimes['ps_order'].notnull()].iterrows():\n    if row['ps_order'] == 1: # and row['lap'] not in [1,2]:\n        since_last_ps = row['totalmilli']\n    elif row['ps_order'] != 1 and index != 115486: # 115486 because the data issue,see below\n        since_last_ps = row['totalmilli'] - laptimes[(laptimes['ps_order'].notnull())&\n                                                    (laptimes['raceId']==row['raceId'])&\n                                                    (laptimes['driverId']==row['driverId'])&\n                                                    (laptimes['ps_order']==row['ps_order']-1)\n                                                    ]['totalmilli']\n#     print(index, since_last_ps)\n    laptimes.at[index, 'since_last_ps'] = since_last_ps\n\n'''There is some data issue for (raceId, driverId) = (908,820)\nThe time for the 2nd lap is very big'''\n# laptimes[(laptimes['raceId']==908)&(laptimes['driverId']==820)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5fa47da69482874a4c9dc3550b024637ca5e6734"},"cell_type":"code","source":"laptimes['since_last_ps'] = laptimes.apply(lambda x :x['milliseconds'] if math.isnan(x['since_last_ps'])\n                                           else x['milliseconds'] + x['since_last_ps']*-1, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2671b3f832ad1a3ce6e2f33591ff42be67c8b1c4"},"cell_type":"code","source":"# Sorting values\nlaptimes.sort_values(by = ['raceId', 'driverId', 'lap'], inplace=True)\n\n'''Calculating since_last_ps (final)'''\nlaptimes['since_last_ps'] = laptimes.groupby(['raceId', 'driverId'])['since_last_ps'].transform(pd.Series.cumsum)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f81c22c13ef24fbe3111abb51d6bb054d1e59c3a"},"cell_type":"markdown","source":"### Splitting the races into segments (10 laps) and making calculation:"},{"metadata":{"trusted":true,"_uuid":"faddec345a1a7e3efbe187385e62706b349e7dbf"},"cell_type":"code","source":"'''Identifying each lap according to its segment'''\nlaptimes['segment'] = laptimes['lap'].apply(lambda x: (x-1) // 10)\n\n'''Calculating the min lap in each segment'''\nlaptimes['min_Lap_Segm'] = laptimes.groupby(['raceId', 'segment'])['milliseconds'].transform(pd.Series.min)\n\n'''Calculating min lap for (race, driver, segment)'''\nlaptimes['min_Lap_Driv_Segm'] = laptimes.groupby(['raceId', 'driverId', 'segment'])['milliseconds'].transform(pd.Series.min)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45643be5f9b4fdf7b0934188f2ee07ad175d0ece"},"cell_type":"code","source":"'''Function to calculate ps_order: returns a list'''\ndef ps_position_fn(inp_list):\n    ps_order_list = []\n    ps_order = 0\n    \n    for ps in inp_list:\n        if ~np.isnan(ps):\n            ps_order += 1\n        ps_order_list.append(ps_order)\n    return ps_order_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fa2dff31982040e9285c19463418bd5a9e10458"},"cell_type":"code","source":"'''Calculating the fastest lap by driver and race since last pitstop'''\n\ntemp_df = laptimes.groupby(['raceId', 'driverId'])['ps_order'].apply(ps_position_fn).reset_index()\ns = temp_df.apply(lambda x: pd.Series(x['ps_order']),axis=1).stack().reset_index(level=1, drop=True)\nlaptimes['temp_ps_order'] = s.values\n\n'''Creating temp_df'''\ntemp_df = laptimes.groupby(['raceId', 'driverId', 'temp_ps_order'])['milliseconds'].min().reset_index()\ntemp_df['min_Lap_since_ps'] = 1\n\n'''Merging'''\nlaptimes = laptimes.merge(temp_df, how='left', on = ['raceId', 'driverId', 'temp_ps_order', 'milliseconds'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d25787865056c7f9b6d7806f0dce59d320848ea2"},"cell_type":"markdown","source":"### Creating new df and shifting the data for the previous lap to match the pit stop"},{"metadata":{"trusted":true,"_uuid":"b6aa4c72b2df223a92606bba26c296c2ddc99f08"},"cell_type":"code","source":"'''Creating new df and shifting the data for the previous lap to match the pit stop'''\ntemp_df = laptimes.copy()\n\nmin_1_df = temp_df.groupby(['raceId', 'driverId', 'lap'])['position', 'totalmilli', 'to_in_front',\n                                                                    'to_behind', 'minLap', 'flag',\n                                                                  'relative_to_avg', 'since_last_ps'].last()\nmin_1_df.reset_index(inplace=True)\nmin_1_df['lap'] = min_1_df['lap'] + 1\n# min_1_df.rename(columns={\"to_in_front\": \"to_in_front_min_1\",\n#                          'to_behind':'to_behind_min_1'}, inplace=True)\n'''Merging'''\ntemp_df = temp_df.merge(min_1_df, how='left', on=['raceId', 'driverId', 'lap'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15c644f562bf40f75ae1bd9d547022afd23ac8ef"},"cell_type":"markdown","source":"\n# ML:"},{"metadata":{"trusted":true,"_uuid":"41a1fa10fffea502e02468b089b3bf00848b5b97","scrolled":true},"cell_type":"code","source":"'''We do not observe (race, driver, lap) for drivers who are at the position #1, because we do not have\nto_in_front_y data for them.\nAlso we do not observe to_behind_y for some (race, driver, lap).\nTo better understand what data we lose, below are the codes to plot distributions\n(uncommnet some of the lines):'''\n# temp_df[(temp_df['milli_for_min_2'].notnull())\n# #         &(temp_df['to_in_front_y'].isnull())\n# #         &(temp_df['to_behind_y'].isnull())\n#         ]['position_y'].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eef164eeb26fdbb376228bec18d6ed8222810e08"},"cell_type":"markdown","source":"### Making a function to visualize DecisionTree"},{"metadata":{"trusted":true,"_uuid":"bcb251a8a486ef6bb5f82dc0a930644084df3e07"},"cell_type":"code","source":"import graphviz\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\n# A function that gives a visual representation of the decision tree\ndef show_decision_tree(model):\n    dot_data = tree.export_graphviz(ps_tree, out_file=None) \n    graph = graphviz.Source(dot_data) \n#     To save on a PDF file\n#     graph.render(\"iris\")\n    return graph","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3eeab34a4d198d7d38c35fe4bb7cbbc1124943f5"},"cell_type":"code","source":"'''transforming ps_order column into 1 (there was a pit stop) and 0 (there was not a pit stop)'''\ntemp_df['ps_order'] = temp_df['ps_order'].apply(lambda x: 0 if np.isnan(x) else 1)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10c1c4d27981eeaef16a3e21836bc33128fac011"},"cell_type":"markdown","source":"**Could we get some graphs of the colums going into ML?**\n\n"},{"metadata":{"trusted":true,"_uuid":"125e6c778b82fa8ce4f9d55c48f7042cd2dbec5f"},"cell_type":"code","source":"'''getting X and y'''\nX_y = temp_df[['ps_order', 'position_y', 'totalmilli_y', 'to_in_front_y', 'to_behind_y', 'minLap_y',\n               'flag_y', 'relative_to_avg_y', 'milli_for_min_1','milli_for_min_2', 'since_last_ps_y']\n             ].dropna()\nX = X_y[['position_y', 'totalmilli_y', 'to_in_front_y', 'to_behind_y', 'minLap_y',\n               'flag_y', 'relative_to_avg_y', 'milli_for_min_1','milli_for_min_2', 'since_last_ps_y'\n           ]].values\ny = X_y[['ps_order']].values\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"efbf1f1fca8bf8d999452afd6c5a616c5bb59a93"},"cell_type":"markdown","source":"### Visualization of the correlation between parameters:"},{"metadata":{"trusted":true,"_uuid":"9011e7e1f581b73b7e8bbe3c9a24db74de96c787"},"cell_type":"code","source":"'''Visualization of the correlation between parameters:'''\nplt.figure(figsize=(10,10))\nplt.matshow(X_y.corr(), cmap=\"Blues\", fignum = 1)\nplt.colorbar(shrink=0.8)\nplt.xticks(range(len(list(X_y))), list(X_y), rotation=90, size = 15)\nplt.yticks(range(len(list(X_y))), list(X_y), size = 15)\n\nprint('Correlatino matrix:')\nplt.show()\n\n'''If you want to see the representation in numbers:'''\n# try_df.corr()\n\n'''Note:\nWe can also plot the distributions of the variables but I am not sure how informative it will be.'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f61c5453bcc56d39baa6afe819419349e06d061e"},"cell_type":"code","source":"'''Splitting whole sample into train and test:'''\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, \n                                                    train_size=0.8,\n                                                    test_size=0.2,\n                                                    random_state=123,\n                                                    stratify=y)\n'''max-depth = 5'''\nps_tree = DecisionTreeClassifier(max_depth=5, criterion=\"gini\")\nps_tree.fit(train_X, train_y)\n\npred_y = ps_tree.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd71b7468ba42a2086af57d3850594d73a79ea84"},"cell_type":"markdown","source":"### Checking on what is the optimal depth of te Decision Tree Classifier:"},{"metadata":{"trusted":true,"_uuid":"559b8037ec7fcad3a3c976588982e14bbf403640"},"cell_type":"code","source":"'''Checking on what is the optimal depth of te Decision Tree Classifier:'''\naccuracies_train = []\naccuracies_test = []\ndepths = range(1, 35)\n\nfor md in depths:\n    model = DecisionTreeClassifier(max_depth=md)\n    model.fit(train_X, train_y)\n    \n    accuracies_train.append(model.score(train_X, train_y))\n    accuracies_test.append(model.score(test_X, test_y))\n\nplt.plot(depths, accuracies_train, label=\"Train\")\nplt.plot(depths, accuracies_test, label=\"Test\")\nplt.title(\"Performance on train and test data\")\nplt.xlabel(\"Max depth\")\nplt.ylabel(\"Accuracy\")\nplt.ylim([0.85, 1.05])\nplt.xlim([1,35])\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd0dd0dbf1ea1904475d8584a85a845c3f42c81f"},"cell_type":"markdown","source":"The graph above shows that the accuracy of the model dos not increase when we add new parameters. The same trend can be seen on the Correlation matrix above - there almost 0 correlatin between dependend and independend variables."},{"metadata":{"trusted":true,"_uuid":"9af9aa3a25daf525e5c9dde5d392dcae7565ccd2"},"cell_type":"code","source":"# using the score function in each model class\nprint(\"accuracy on the test set\", ps_tree.score(test_X, test_y))\nprint(\"accuracy on the training set\", ps_tree.score(train_X, train_y))\n\n# using single metric functions in the sklearn.metrics package \nprint(\"accuracy on the test set\", accuracy_score(pred_y, test_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47131fe71cb0c9c20e1396a96b4bdaa4b317220c"},"cell_type":"code","source":"'''Visualizing DecisionTree'''\n# show_decision_tree(ps_tree)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0bbf28a34ae90218a7c27d88ab4bb57de757f33"},"cell_type":"code","source":"'''Count number of pist stops (1) and number of laps without pit stops (0)'''\nfrom collections import Counter\ny_list = y.tolist()\ny_list = [item for sublist in y_list for item in sublist]\nCounter(y_list)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"431a82d11431b19104d450aee04a46ed471dd0e8"},"cell_type":"markdown","source":"### Feature_importances"},{"metadata":{"trusted":true,"_uuid":"dca9377b477f38878dc9a886bd0251b4197d1b35"},"cell_type":"code","source":"'''We can check how the feature_importances changes as we change the depth of the tree'''\nmax_depth = 1\n\nps_tree = DecisionTreeClassifier(max_depth=max_depth, criterion=\"gini\")\nps_tree.fit(train_X, train_y)\n\nps_tree.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4644983aec9b3995eb000159a7b65a67098138db"},"cell_type":"markdown","source":"# Second Model:\n### looking at the first half of the race:"},{"metadata":{"_uuid":"39908c777013c601d61a89a4612030591bc7eb67"},"cell_type":"markdown","source":"### Creating parameters:"},{"metadata":{"trusted":true,"_uuid":"1cef47ba0c36df8823e0c2ffe80557b16a3a797b"},"cell_type":"code","source":"'''Indicating the circuitId\ncreating the column that will indicate the circuitId'''\nlaptimes = laptimes.merge(races[['raceId', 'circuitId']], how='left', on='raceId')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f063cff166374f33e45f5e74df71b8acb59f8a8"},"cell_type":"code","source":"'''finding the circuitId with the most finished laps'''\n# temp_df = laptimes.groupby(['circuitId', 'lap'])['raceId'].count().reset_index()\n# temp_df['temp_col'] = temp_df['lap'] * temp_df['raceId']\n# temp_df.sort_values('temp_col', ascending = False).head(2)\n\n# '''So we will take cidrcuitId = 11'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac0e5405cf52f85b5ac2170d2ed71a6b272458e7"},"cell_type":"code","source":"'''finding mid lap for each circuitId'''\nlaptimes = laptimes.merge(results[['raceId', 'driverId', 'position']].rename(columns={\"position\": \"finish_position\"}),\n                            how='left', on=['raceId', 'driverId'])\n\n'''take all the laps which were the part of the \"finish\" races\ndetermine the mid lap for each circle'''\ns_temp = laptimes[(laptimes['finish_position'].notnull())]\ns_temp = s_temp.groupby(['circuitId'])['lap'].apply(lambda x: np.max(x) // 2)\n\n'''taking only the laps forom the first half of the races'''\nfirst_half_df = laptimes[laptimes[['lap','circuitId']].apply(lambda x: x[0] <= s_temp[x[1]], axis=1)]\n\n'''Taking the laps which were the part of the finish races'''\nfirst_half_df = first_half_df[first_half_df['finish_position'].notnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e9e29212d092ca5a44a99b07ffb6f76aa3099bb"},"cell_type":"code","source":"'''Calculating time since last PS (before_prev_ps)'''\nfirst_half_df['before_prev_ps'] = np.nan\nfor index, row in first_half_df[first_half_df['ps_order'].notnull()].iterrows():\n    if row['ps_order'] == 1: # and row['lap'] not in [1,2]:\n        before_prev_ps = row['totalmilli'] - row['ps_duration']\n    elif row['ps_order'] != 1 and index not in [115486, 80831]: # 115486, 80831 because the data issue\n        before_prev_ps = row['totalmilli'] - first_half_df[(first_half_df['ps_order'].notnull())&\n                                                            (first_half_df['raceId']==row['raceId'])&\n                                                            (first_half_df['driverId']==row['driverId'])&\n                                                            (first_half_df['ps_order']==row['ps_order']-1)\n                                                            ]['totalmilli'] - row['ps_duration']\n#     print(index, before_prev_ps)\n    first_half_df.at[index, 'before_prev_ps'] = before_prev_ps\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d0378bf225e4b32e1f6dda624203dbd44bb2b66"},"cell_type":"code","source":"'''Calculating the parameters'''\nf = {'milliseconds':['min'],\n     'ps_order':['count'],\n     'before_prev_ps':['mean', 'min', 'max'],\n     'position':['first', 'last'],\n     'ps_duration':['sum'],\n     'finish_position':['last'],\n     'circuitId': ['last']}\nX_y = first_half_df.groupby(['raceId', 'driverId']).agg(f).reset_index()\nX_y.columns = ['raceId', 'driverId', 'milliseconds_min', 'ps_count', 'before_prev_ps_mean',\n               'before_prev_ps_min', 'before_prev_ps_max','position_first', 'position_last',\n               'ps_duration_sum', 'finish_position', 'circuitId']\n\n'''Calculating avg of the fastest laps in the race'''\nX_y['avg_milliseconds_min'] = X_y.groupby(['raceId'])['milliseconds_min'].transform(pd.Series.mean)\n# X_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da37daebf4206519eb9f816143ae532f2a9a2dd7"},"cell_type":"code","source":"'''Checking the size of our sample'''\nprint('Sample size:', X_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ab4dbb416c5a8b7c616a5cbea612119a92abf5e"},"cell_type":"markdown","source":"# ML:"},{"metadata":{"trusted":true,"_uuid":"94d9366f15b5522e0e83c5a5efb4347bd739271d"},"cell_type":"code","source":"'''Notes:\n1)The sample size is porbably too small for the lightgbm.\n    Accourding to this article (https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc)\n    it can lead to overfitting.\n2) How we sorted the data - we took only the races of the drivers who finished a particular race;\n                          - for each circleId we take the average max number of laps and find the medium lap;\n                          - we took all the laps that are <= medium lap\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"174ab6b8d61030976de3077e1cd25399d3c24b01"},"cell_type":"code","source":"'''Looking at our sample.\nThe sample is relatively small because we have pitstops data only for 841-988 raceId.\nIt would be good to have potstop data for previous races'''\ntry_races = races.copy()\ntry_races['date'] = try_races['date'].apply(lambda x: dt.datetime.strptime(x, '%Y-%m-%d'))\ntry_races['date'].hist(bins = 73)\ntry_races[try_races['raceId'].isin(X_y['raceId'])]['date'].hist(bins = 10)\nprint('Whole sample:', len(try_races['date']))\nprint('The data that we have:', len(try_races[try_races['raceId'].isin(X_y['raceId'])]['date']))\n# X_y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ef9cffad2cb84e89ed269d1c46e9bf60f4797d5"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"3e457201a70ff4b37cea0aa03c15cf5a94864acd"},"cell_type":"markdown","source":"### Visualization of the correlation between parameters:"},{"metadata":{"trusted":true,"_uuid":"2945051ed19c43c7a084161fa1305df5f8472b4a"},"cell_type":"code","source":"'''Visualization of the correlation between parameters:'''\nplt.figure(figsize=(10,10))\nplt.matshow(X_y.corr(), cmap=\"Blues\", fignum = 1)\nplt.colorbar(shrink=0.8)\nplt.xticks(range(len(list(X_y))), list(X_y), rotation=90, size = len(X_y.columns))\nplt.yticks(range(len(list(X_y))), list(X_y), size = len(X_y.columns))\n\nprint('Correlatino matrix:')\nplt.show()\n\n'''If you want to see the representation in numbers:'''\n# try_df.corr()\n\n'''Note:\nThe variable we want to predict is \"finish_position\".\nWe can see that only the \"position_first\" and \"position_last\" have strong correlation with the \"finish_position\"\n'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bfd9a39dab460898806bfb0f38768edfab12528a"},"cell_type":"markdown","source":"## 1) Linear Regression:"},{"metadata":{"_uuid":"2be7265f9ecb34361708ab6fe521d9ab7612ea27"},"cell_type":"markdown","source":"### With statsmodels"},{"metadata":{"trusted":true,"_uuid":"af1e2736d99ed3ae40238a2470aa56db9f825f17"},"cell_type":"code","source":"import statsmodels.formula.api as sm\n\nresult = sm.ols(formula=\"finish_position ~ milliseconds_min + avg_milliseconds_min + ps_count +\\\n + before_prev_ps_mean + before_prev_ps_min + before_prev_ps_max + position_first + position_last +\\\n + ps_duration_sum\", data=X_y).fit()\n\nresult.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ac7bf3c58ee99d6dc048f59a6ec51d5c60c0a1f"},"cell_type":"markdown","source":"### With linearmodels:"},{"metadata":{"trusted":true,"_uuid":"86233d9b50b680bb1290e7a2a71e6458a5ffbe13"},"cell_type":"code","source":"'''Creating additional parameters, which may increase the accuracye of the fixed effects model:'''\nX_y_linearmodels = X_y.copy()\nX_y_linearmodels['milliseconds_dif'] = X_y_linearmodels['milliseconds_min'] - X_y_linearmodels['avg_milliseconds_min']\nX_y_linearmodels['laps_increase'] = X_y_linearmodels['position_last'] - X_y_linearmodels['position_first']\n\n'''Splitting the dataset into the Training set and Test set'''\n\ntrain, test = train_test_split(X_y_linearmodels.dropna(), \n                                train_size=0.8,\n                                test_size=0.2,\n                                random_state=123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7d65157d90d78db628d10433bd1af8ded867fdf"},"cell_type":"code","source":"'''Preparing the dataframes to apply the fixed-effects'''\ncolumns = ['milliseconds_min', 'ps_count',\n           'before_prev_ps_mean', 'before_prev_ps_min', 'before_prev_ps_max',\n           'position_first', 'position_last', 'ps_duration_sum', 'finish_position',\n           'circuitId', 'avg_milliseconds_min', 'milliseconds_dif', 'laps_increase']\n\ntrain = train.groupby(['driverId', 'raceId'])[columns].first()\ntest = test.groupby(['driverId', 'raceId'])[columns].first()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9df78413b96fe03f9db7dfc17823f2dbca1bd6a0"},"cell_type":"code","source":"'''Fitting the model:'''\nfrom linearmodels.panel import PanelOLS\n\n'''\nWe use the fixed effects to controll for the driverId (different drivers have different abilities)\nTo use fixed effects - add \"+ EntityEffects\" in the equation below:\n'''\nequation = 'finish_position ~ 1 + milliseconds_min + avg_milliseconds_min + ps_count +\\\n + before_prev_ps_mean + before_prev_ps_min + before_prev_ps_max + position_first + position_last +\\\n + ps_duration_sum + EntityEffects'\n\nmod = PanelOLS.from_formula(equation, train)\nres = mod.fit(cov_type='clustered', cluster_entity=True)\n# print(res)\n'''To see the results of the model and coefficients (uncommend):'''\nres","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20ee95306d60a74056bdcc49e404d20415458aec"},"cell_type":"code","source":"'''Predicting:'''\ntemp_columns = ['milliseconds_min', 'avg_milliseconds_min', 'ps_count', 'before_prev_ps_mean',\n                'before_prev_ps_min', 'before_prev_ps_max', 'position_first', 'position_last',\n                'ps_duration_sum', 'milliseconds_dif', 'laps_increase']\ntest_pred = res.predict(data= test[temp_columns])\n# test['finish_position']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00f241424b72c2fbba5e38a05d3a7f9fbd24b1e8"},"cell_type":"code","source":"'''Calculating the accuracy:'''\ndifference_array = test_pred['predictions'].values - test['finish_position'].values\n\n'''We assume that the prediction is currect if it within +-0.5 from the actual finish position'''\nround_fun = lambda x: 1 if abs(x) <= 0.5 else 0\nv_func = np.vectorize(round_fun)\n\nround_accuracy_array = v_func(difference_array)\naccuracy_score = dict(Counter(round_accuracy_array))\nprint('Accuracy score:', accuracy_score[1]/len(round_accuracy_array))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8443518068d0490ccf7b3613aed070b6220e5bbc"},"cell_type":"code","source":"'''Notes:\nThe coef colum shows coefficients for each parameter.\nFor example, the coefficient next to the position_last = 0.6677, meaning that if the last position increases\nby 1, the final position increases by 0.667.\nThe t and P>|t| columns indicates the statistical significance of each coefficient.\n\nI would suggest to modify this model and use the fixed-effect to controll for the circuitId. Because\non different tracks drivers may use different pitstop strategy.\n'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0890f1b8739cb97c96d951645f8f19e4a9d529d8"},"cell_type":"markdown","source":"## 2) LightGBM:"},{"metadata":{"trusted":true,"_uuid":"72e1d95a0fd0c3646b570fe01dad398605e46509"},"cell_type":"code","source":"'''Separating the X and y'''\n\nX = X_y[['milliseconds_min', 'avg_milliseconds_min', 'ps_count',\n       'before_prev_ps_mean', 'before_prev_ps_min', 'before_prev_ps_max',\n       'position_first', 'position_last', 'ps_duration_sum']].values\ny = X_y['finish_position'].values\n\n'''Splitting the dataset into the Training set and Test set'''\nx_train, x_test, y_train, y_test = train_test_split(X, y, \n                                                    train_size=0.8,\n                                                    test_size=0.2,\n                                                    random_state=123,\n                                                    stratify=y)\n\n'''Feature Scaling'''\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fff21c0f03844875e6d55220415e01536a66376"},"cell_type":"code","source":"'''I do not think that LightGBM is good to answer our question: the sample size is not big enough,\nthe results are very sensitive to parameters we specify.'''\nimport lightgbm as lgb\nd_train = lgb.Dataset(data = x_train, label=y_train)\nparams = {}\n# params['learning_rate'] = 0.003\nparams['boosting_type'] = 'gbdt'\nparams['objective'] = 'regression'\nparams['metric'] = 'mse' # mean squared error\n# params['sub_feature'] = 0.5\n# params['num_leaves'] = 10\n# params['min_data'] = 50\n# params['max_depth'] = 10\nmodel = lgb.train(params, d_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa1becda5960a4a008892035d9440e9201b0ca00"},"cell_type":"code","source":"lgb.plot_importance(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27749848a947c322da897ba6700cba0b792d4857"},"cell_type":"code","source":"'''this is X:'''\nX_y[['milliseconds_min', 'avg_milliseconds_min', 'ps_count',\n       'before_prev_ps_mean', 'before_prev_ps_min', 'before_prev_ps_max',\n       'position_first', 'position_last', 'ps_duration_sum']].head(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"949f06bd24a78336dbeef65eed6e54b04f1d9662"},"cell_type":"markdown","source":"# END"},{"metadata":{"trusted":true,"_uuid":"0dcb53900856500cf02d7dd2f1e0b583f9d97d04"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}