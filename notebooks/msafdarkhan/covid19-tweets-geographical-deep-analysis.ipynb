{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <center>ðŸŒŽ ANALYSIS OF COVID-19  DATA</center>"},{"metadata":{},"cell_type":"markdown","source":"The section consists of various section of geo analysis of data\n## **Content**\n\n1. [Data and library loading](#1)\n2. [Visualizing and Understading of Data](#2)\n3. [Preprocessing/Data Cleaning](#3)\n4. [Data Viualization](#4)\n    * [Valid Tweets](#5)\n    * [Top 10 Countries with Most Tweets](#6)\n    * [10 Countries with Least Tweets](#7)\n    * [Top 15 Countries with Most Tweets Diffrent Representation](#8)\n    * [Geo-MAP](#9)\n10. [Conclusion](#10)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a> <br>\n# <div class=\"alert alert-block alert-info\">Data and library loading</div>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#importing necessery libraries for future analysis of the dataset\n!pip install calmap\n\nfrom datetime import date\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport geopandas as gpd\nimport geoplot\nfrom geopy import Nominatim\nimport folium\nimport mapclassify\nimport plotly.express as px \nimport plotly.graph_objs as go \nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom folium.plugins import HeatMapWithTime, TimestampedGeoJson\nimport matplotlib.style as style \nstyle.use('fivethirtyeight')\nimport numpy as np; np.random.seed(sum(map(ord, 'calmap')))\nimport pandas as pd\nimport calmap\nfrom shapely.geometry import Polygon\nfrom shapely.geometry import MultiPolygon\n        \n#Now Loading Tweetes Dataset \ncovid_tweets_data = pd.read_csv('../input/covid19-tweets/covid19_tweets.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a> <br>\n# <div class=\"alert alert-block alert-info\">Visualizing and Understading of Data</div>"},{"metadata":{},"cell_type":"markdown","source":"These tweets are collected using Twitter API and a Python script. A query for this high-frequency hashtag (#covid19) is run on a daily basis for a certain time period, to collect a larger number of tweets samples.\n\nContent The tweets have #covid19 hashtag. Collection started on 25/7/2020, with an initial 17k batch and will continue on a daily basis.\n\n* The collection script can be found here: https://github.com/gabrielpreda/covid-19-tweets"},{"metadata":{},"cell_type":"markdown","source":"View Recentrly Imported Dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"covid_tweets_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This Dataset Contains Following Columns and Datatypes"},{"metadata":{},"cell_type":"markdown","source":"1. user_name         **(object)**\n2. user_location     **(object)**\n3. user_description  **(object)**\n4. user_created      **(object)**\n5. user_followers    **(int64)** \n6. user_friends      **(int64)** \n7. user_favourites   **(int64)** \n8. user_verified     **(bool)**  \n9. date              **(object)**\n10. text              **(object)**\n11. hashtags          **(object)**\n12. source            **(object)**\n13. is_retweet        **(bool)**  \n\n> dtypes: bool(2), int64(3), object(8)"},{"metadata":{"trusted":true},"cell_type":"code","source":"nRow, nCol = covid_tweets_data.shape\nprint(f'There are {nRow} rows and {nCol} columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid_tweets_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"covid_tweets_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a> <br>\n# <div class=\"alert alert-block alert-info\">Preprocessing/Data Cleaning</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# World City Dataset\n\ncities = pd.read_csv('../input/world-cities-datasets/worldcities.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Duplicate Location in Tweets Dataset\n\ncovid_tweets_data[\"location\"] = covid_tweets_data[\"user_location\"]\ncovid_tweets_data[\"country\"] = np.NaN\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Removing Mising Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"user_location = covid_tweets_data['location'].fillna(value='').str.split(',')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering(Countries Where Users Tweet)"},{"metadata":{"trusted":true},"cell_type":"code","source":"lat = cities['lat'].fillna(value = '').values.tolist()\nlng = cities['lng'].fillna(value = '').values.tolist()\ncountry = cities['country'].fillna(value = '').values.tolist()\n\n# Getting all alpha 3 codes into  a list\nworld_city_iso3 = []\nfor c in cities['iso3'].str.lower().str.strip().values.tolist():\n    if c not in world_city_iso3:\n        world_city_iso3.append(c)\n        \n# Getting all alpha 2 codes into  a list    \nworld_city_iso2 = []\nfor c in cities['iso2'].str.lower().str.strip().values.tolist():\n    if c not in world_city_iso2:\n        world_city_iso2.append(c)\n        \n# Getting all countries into  a list        \nworld_city_country = []\nfor c in cities['country'].str.lower().str.strip().values.tolist():\n    if c not in world_city_country:\n        world_city_country.append(c)\n\n# Getting all amdin names into  a list\nworld_states = []\nfor c in cities['admin_name'].str.lower().str.strip().tolist():\n    world_states.append(c)\n\n\n# Getting all cities into  a list\nworld_city = cities['city'].fillna(value = '').str.lower().str.strip().values.tolist()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor each_loc in range(len(user_location)):\n    ind = each_loc\n    each_loc = user_location[each_loc]\n    for each in each_loc:\n        each = each.lower().strip()\n        if each in world_city:\n            order = world_city.index(each)\n            covid_tweets_data['country'][ind] = country[order]\n            continue\n        if each in world_states:\n            order= world_states.index(each)\n            covid_tweets_data['country'][ind] = country[order]\n            continue\n        if each in world_city_country:\n            order = world_city_country.index(each)\n            covid_tweets_data['country'][ind] = world_city_country[order]\n            continue\n        if each in world_city_iso2:\n            order = world_city_iso2.index(each)\n            covid_tweets_data['country'][ind] = world_city_country[order]\n            continue\n        if each in world_city_iso3:\n            order = world_city_iso3.index(each)\n            covid_tweets_data['country'][ind] = world_city_country[order]\n            continue\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a> <br>\n# <div class=\"alert alert-block alert-info\">Data visualizations</div>"},{"metadata":{},"cell_type":"markdown","source":"**<a id=\"5\">Valid Tweets</a>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total Number of valid Tweets Available: ',covid_tweets_data['country'].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **<a id=\"6\">Top 10 Countries with Most Tweets</a>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet_per_country = covid_tweets_data['country'].str.lower().dropna()\ntw = tweet_per_country.value_counts().rename_axis('Country').reset_index(name='Tweet Count')\nprint(tw)\nplt.rcParams['figure.figsize'] = (15,10)\nplt.title('Top 10 Countries with Most Tweets',fontsize=15)\nsns.set_palette(\"husl\")\nax = sns.barplot(y=tw['Country'].head(10),x=tw['Tweet Count'].head(10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **<a id=\"7\">10 Countries with Least Tweets</a>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"tweet_per_country = covid_tweets_data['country'].str.lower().dropna()\ntw = tweet_per_country.value_counts().rename_axis('Country').reset_index(name='Tweet Count')\nprint(tw)\nplt.rcParams['figure.figsize'] = (15,10)\nplt.title('10 Countries with Least Tweets',fontsize=15)\nsns.set_palette(\"husl\")\nax = sns.barplot(y=tw['Country'][-9:],x=tw['Tweet Count'][-9:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Min and Max Dates Between The Dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print (covid_tweets_data[\"date\"].min())\nprint (covid_tweets_data[\"date\"].max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **<a id=\"8\">Top 15 Countries with Most Tweets Diffrent Representation</a>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"country_graph_03=px.bar(x='Tweet Count',y='Country',data_frame=tw[:15],color='Country')\ncountry_graph_03.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **<a id=\"9\">Geo-MAP</a>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"geolocator = Nominatim(user_agent=\"covid19-application\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize_Global_Corona_map(df,  zoom):\n    \n    lat_map=30.038557\n    lon_map=31.231781\n    f = folium.Figure(width=1000, height=500)\n    m = folium.Map([lat_map,lon_map], zoom_start=zoom).add_to(f)\n    print(df[\"Country\"])\n    for i in range(0,len(df)):\n        t_country=str(df[\"Country\"][i])\n        location = geolocator.geocode(t_country)\n        popup_text='<i>Location:'+t_country+', Tweets: '+str(df[\"Tweet Count\"][i])+'</i>'\n        folium.Marker(location=[location.latitude,location.longitude],popup=popup_text,icon=folium.Icon(icon_color='white',icon ='virus',prefix='fa')).add_to(m)\n    \n    return m","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_Global_Corona_map(tw, 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion <a id=\"10\"></a>\nThis concludes your Geographical Deep analysis! To go forward from here, click the blue \"Fork Notebook\" button at the top of this kernel. This will create a copy of the code and environment for you to edit. Delete, modify, and add code as you please. Happy Kaggling! For More Follow me or Give me a Star or contact me now at [Safdar Khan](https://www.safdarhan.ml) or [clikc Here to email me](mailto:safdarkhanofficial@gmail.com)."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}