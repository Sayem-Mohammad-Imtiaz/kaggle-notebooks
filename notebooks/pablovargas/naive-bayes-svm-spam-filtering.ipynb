{"nbformat":4,"nbformat_minor":1,"cells":[{"cell_type":"markdown","source":"#  Spam classification with Naive Bayes and Support Vector Machines.","metadata":{"_uuid":"25f02ffdb0d53b9663f351fa0c0f415d2bce15b1","_cell_guid":"f169d7cf-818b-4815-a5be-76265e99d139"}},{"cell_type":"markdown","source":"- Libraries\n- Exploring the Dataset\n- Distribution spam and non-spam plots\n- Text Analytics\n- Feature Engineering\n- Predictive analysis (**Multinomial Naive Bayes and Support Vector Machines**)\n- Conclusion\n","metadata":{"_uuid":"73148e4af546e95aa951ee5cb2c9ee2728eb4401","_cell_guid":"8b0b431e-8d74-4a03-9858-539f067f6604"}},{"cell_type":"markdown","source":"## Libraries","metadata":{"_uuid":"e27ea858875f6d5698fcfb196b32160c8d761697","_cell_guid":"ba30922b-183b-4f2e-ac19-35ebc9dd865a"}},{"outputs":[],"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm\nfrom IPython.display import Image\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline  ","execution_count":null,"metadata":{"_uuid":"5eb96b9e55cca9f7dbc74128cd5933856b39aa51","_cell_guid":"77dbf249-4662-4faf-ae30-654f5f76f5b1","collapsed":true}},{"cell_type":"markdown","source":"## Exploring the Dataset","metadata":{"_uuid":"2a11f84b23cf786579a3beb1074c6e7375456b77","_cell_guid":"ab7471a7-9fda-4dc9-ba8b-6d4f0c1b92e1"}},{"outputs":[],"cell_type":"code","source":"data = pd.read_csv('../input/spam.csv', encoding='latin-1')\ndata.head(n=10)","execution_count":null,"metadata":{"_uuid":"3a9038c1ea6026f8ae89cf052aa71c89bcb940dd","_cell_guid":"e8604809-62b9-47bd-84fa-92063d8ae5b3","scrolled":true}},{"cell_type":"markdown","source":"## Distribution spam/non-spam plots","metadata":{"_uuid":"d71ec916875461c07bdb1f9d53d9b0a7210de035","_cell_guid":"2ed76eea-004a-42a0-a1c9-c45c092bbb4b"}},{"outputs":[],"cell_type":"code","source":"count_Class=pd.value_counts(data[\"v1\"], sort= True)\ncount_Class.plot(kind= 'bar', color= [\"blue\", \"orange\"])\nplt.title('Bar chart')\nplt.show()","execution_count":null,"metadata":{"_uuid":"99a4b831313c23573b7972c65637d01dd497c6fe","_cell_guid":"74f9cf41-4793-4be5-a46e-bdb93067e973","scrolled":true}},{"outputs":[],"cell_type":"code","source":"count_Class.plot(kind = 'pie',  autopct='%1.0f%%')\nplt.title('Pie chart')\nplt.ylabel('')\nplt.show()","execution_count":null,"metadata":{"_uuid":"f233eab105cb93e90ce37f9361616a5be6645751","_cell_guid":"5596df63-7be7-4625-b952-c5508917a630"}},{"cell_type":"markdown","source":"## Text Analytics","metadata":{"_uuid":"9ec51be1879d2987eef26632bc411a3577b42ae8","_cell_guid":"ff53e1a6-a37b-4a31-9b41-c959296156de"}},{"cell_type":"markdown","source":"We want to find the frequencies of words in the spam and non-spam messages. The words of the messages will be model features.<p>\nWe use the function Counter.","metadata":{"_uuid":"b3c395e8534efc8a402df3b6ac1b699b48fa09f3","_cell_guid":"ba58d2e5-63a4-4443-ab05-7810decb5eb7"}},{"outputs":[],"cell_type":"code","source":"count1 = Counter(\" \".join(data[data['v1']=='ham'][\"v2\"]).split()).most_common(20)\ndf1 = pd.DataFrame.from_dict(count1)\ndf1 = df1.rename(columns={0: \"words in non-spam\", 1 : \"count\"})\ncount2 = Counter(\" \".join(data[data['v1']=='spam'][\"v2\"]).split()).most_common(20)\ndf2 = pd.DataFrame.from_dict(count2)\ndf2 = df2.rename(columns={0: \"words in spam\", 1 : \"count_\"})","execution_count":null,"metadata":{"_uuid":"03677f8369b4bb3450ffe8a9cd3de9c0b01e681d","_cell_guid":"8c750858-87e9-498c-86f5-4df7310f9e63","collapsed":true}},{"outputs":[],"cell_type":"code","source":"df1.plot.bar(legend = False)\ny_pos = np.arange(len(df1[\"words in non-spam\"]))\nplt.xticks(y_pos, df1[\"words in non-spam\"])\nplt.title('More frequent words in non-spam messages')\nplt.xlabel('words')\nplt.ylabel('number')\nplt.show()","execution_count":null,"metadata":{"_uuid":"d18e09f35264ea374ffce57eae07c9335439a2ef","_cell_guid":"b8850226-0043-4a37-9e65-a8409efe7026","scrolled":true}},{"outputs":[],"cell_type":"code","source":"df2.plot.bar(legend = False, color = 'orange')\ny_pos = np.arange(len(df2[\"words in spam\"]))\nplt.xticks(y_pos, df2[\"words in spam\"])\nplt.title('More frequent words in spam messages')\nplt.xlabel('words')\nplt.ylabel('number')\nplt.show()","execution_count":null,"metadata":{"_uuid":"bf9b59581db68038824724344fe937e65f5f8661","_cell_guid":"9637faec-7114-4365-aceb-a2d74787a205"}},{"cell_type":"markdown","source":"We can see that the majority of frequent words in both classes are stop words such as 'to', 'a', 'or' and so on. <p>\nWith stop words we refer to the most common words in a lenguage, there is no simgle, universal list of stop words. <p>","metadata":{"_uuid":"c971edae5a8be1bfd0719e777ba92322ad897abe","_cell_guid":"40db40e9-aeb2-487f-9ab7-d6debf26d611"}},{"cell_type":"markdown","source":"## Feature engineering","metadata":{"_uuid":"47d3122a6fe0ed51dbe5775c7549695cce2a8470","_cell_guid":"6887a2a9-6c4c-42f1-92df-fdec4ae3f9f0"}},{"cell_type":"markdown","source":"Text preprocessing, tokenizing and filtering of stopwords are included in a high level component that is able to build a dictionary of features and transform documents to feature vectors.<p>\n**We remove the stop words in order to improve the analytics**","metadata":{"_uuid":"93273550c383144e9ddec84b179475ea7d9cb85c","_cell_guid":"238e6b23-de89-4334-80d9-1662dfc1a211"}},{"outputs":[],"cell_type":"code","source":"f = feature_extraction.text.CountVectorizer(stop_words = 'english')\nX = f.fit_transform(data[\"v2\"])\nnp.shape(X)","execution_count":null,"metadata":{"_uuid":"67b9147f254e720b0641d9a171333942ef529aba","_cell_guid":"653bfeae-e298-44e3-b92c-78c0f747b8ef"}},{"cell_type":"markdown","source":"We have created more than 8400 new features. The new feature $j$ in the row $i$ is equal to 1 if the word $w_{j}$ appears in the text example $i$. It is zero if not.","metadata":{"_uuid":"35e5277996ce60e9e8725e20805b2a0d7d118764","_cell_guid":"205a78b4-b452-4a1a-8912-de897a798097"}},{"cell_type":"markdown","source":"## Predictive Analysis","metadata":{"_uuid":"1f0489faa50638217e4754ff0a8f26e5298752df","_cell_guid":"448eda90-2493-46f0-a588-8e6e73b7e2d3"}},{"cell_type":"markdown","source":"**My goal is to predict if a new sms is spam or non-spam. I assume that is much worse misclassify non-spam than misclassify an spam. (I don't want to have false positives)**\n<p>\nThe reason is because I normally don't check the spam messages.<p> The two possible situations are:<p>\n1. New spam sms in my inbox. (False negative).<p>\nOUTCOME: I delete it.<p>\n2. New non-spam sms in my spam folder (False positive).<p>  OUTCOME: I probably don't read it. <p>\nI prefer the first option!!!","metadata":{"_uuid":"da31f2e8dd19f4ff0a6c1f6dbf29b34a2c28391a","_cell_guid":"e19c8da3-73b0-4ed8-ac08-04e45a4309da"}},{"cell_type":"markdown","source":"First we transform the variable spam/non-spam into binary variable, then we split our data set in training set and test set. ","metadata":{"_uuid":"83edda58f114f466bf6cf6d1a278a1e5af08e651","_cell_guid":"d1e8c9ef-588e-4708-8275-bfafe82c5cd8"}},{"outputs":[],"cell_type":"code","source":"data[\"v1\"]=data[\"v1\"].map({'spam':1,'ham':0})\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, data['v1'], test_size=0.33, random_state=42)\nprint([np.shape(X_train), np.shape(X_test)])","execution_count":null,"metadata":{"_uuid":"ab65abc5fe63168bfea503db8e58e5ab03383a22","_cell_guid":"e5e2bee3-cdad-4ee6-9c59-f3a536195ed7"}},{"cell_type":"markdown","source":"### Multinomial naive bayes classifier","metadata":{"_uuid":"0463069f7287a20571ab90885b85dad8d9a64368","_cell_guid":"76cc3deb-7b7c-4511-ae4e-ef5cd2f7592b"}},{"cell_type":"markdown","source":"We train different bayes models changing the regularization parameter $\\alpha$. <p>\nWe evaluate the accuracy, recall and precision of the model with the test set.","metadata":{"_uuid":"7146dbec1c30fd6f2c39454834281e7b74648f39","_cell_guid":"691fa70e-6aa0-4743-b948-650e90f61e40"}},{"outputs":[],"cell_type":"code","source":"list_alpha = np.arange(1/100000, 20, 0.11)\nscore_train = np.zeros(len(list_alpha))\nscore_test = np.zeros(len(list_alpha))\nrecall_test = np.zeros(len(list_alpha))\nprecision_test= np.zeros(len(list_alpha))\ncount = 0\nfor alpha in list_alpha:\n    bayes = naive_bayes.MultinomialNB(alpha=alpha)\n    bayes.fit(X_train, y_train)\n    score_train[count] = bayes.score(X_train, y_train)\n    score_test[count]= bayes.score(X_test, y_test)\n    recall_test[count] = metrics.recall_score(y_test, bayes.predict(X_test))\n    precision_test[count] = metrics.precision_score(y_test, bayes.predict(X_test))\n    count = count + 1 ","execution_count":null,"metadata":{"_uuid":"4bf729b41f966730729d72d6b61e287ab426bd39","_cell_guid":"e7b5bbc6-23cb-49f8-8ea3-83f71c9f6d97","collapsed":true}},{"cell_type":"markdown","source":"Let's see the first 10 learning models and their metrics!","metadata":{"_uuid":"2c9003728118d2729d284b1712b85f0d2a4df3d5","_cell_guid":"4390a64a-41a8-46a6-b6bb-a204e769a617"}},{"outputs":[],"cell_type":"code","source":"matrix = np.matrix(np.c_[list_alpha, score_train, score_test, recall_test, precision_test])\nmodels = pd.DataFrame(data = matrix, columns = \n             ['alpha', 'Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision'])\nmodels.head(n=10)","execution_count":null,"metadata":{"_uuid":"b38a2e021e3b5898e0883ee95165457af85f954b","_cell_guid":"9bb5c44b-9d9b-4f79-8462-324eb3addcad"}},{"cell_type":"markdown","source":"I select the model with the most test precision","metadata":{"_uuid":"7a3bfc6ad5f9e5d05187c61074b1b47b50516772","_cell_guid":"072aeed4-d578-4917-b32e-ca54380dd5e2"}},{"outputs":[],"cell_type":"code","source":"best_index = models['Test Precision'].idxmax()\nmodels.iloc[best_index, :]","execution_count":null,"metadata":{"_uuid":"4d87a52c2e11585c970314171d943bcb45f596c8","_cell_guid":"6f285b74-00bc-45cd-af8c-ac3c846b92e7"}},{"cell_type":"markdown","source":"**My best model does not produce any false positive, which is our goal.** <p>\nLet's see if there is more than one model with 100% precision !","metadata":{"_uuid":"da73a1525d323708933ea89fbe4e77027c0a50db","_cell_guid":"060f159b-e0d9-4d49-8d1b-108db0683551"}},{"outputs":[],"cell_type":"code","source":"models[models['Test Precision']==1].head(n=5)","execution_count":null,"metadata":{"_uuid":"a493d149424ca65839847ff534cbd7630011bf09","_cell_guid":"258125aa-b60f-448a-ab78-e6bb54871837"}},{"cell_type":"markdown","source":"Between these models with the highest possible precision, we are going to select which has more test accuracy.","metadata":{"_uuid":"8d9107309dfcd3c0b77bb9be6f09ac07d0d860f4","_cell_guid":"8c77ed68-bd03-41cd-9293-f8c7777df06d"}},{"outputs":[],"cell_type":"code","source":"best_index = models[models['Test Precision']==1]['Test Accuracy'].idxmax()\nbayes = naive_bayes.MultinomialNB(alpha=list_alpha[best_index])\nbayes.fit(X_train, y_train)\nmodels.iloc[best_index, :]","execution_count":null,"metadata":{"_uuid":"d74e1e4cebee52716b5bf9e9aa72efa147f43f93","_cell_guid":"1dd94a26-7252-4fcd-ad18-7d755ab20ab7"}},{"cell_type":"markdown","source":"#### Confusion matrix with naive bayes classifier","metadata":{"_uuid":"606304507b731dd866ad9b97daa654a0c32a544a","_cell_guid":"67ca2aef-56b9-4701-9590-387eb64c13a8"}},{"outputs":[],"cell_type":"code","source":"m_confusion_test = metrics.confusion_matrix(y_test, bayes.predict(X_test))\npd.DataFrame(data = m_confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n            index = ['Actual 0', 'Actual 1'])","execution_count":null,"metadata":{"_uuid":"a700b298131b18e8ec21a67959df4a71c1177a54","_cell_guid":"076b7447-5c33-4671-8b25-7000e0c3a28f"}},{"cell_type":"markdown","source":"* #### We misclassify 56 spam messages as non-spam emails whereas we don't misclassify any non-spam message.","metadata":{"_uuid":"a3bedbcaf45f81634407cbce15bcf8c701a4bbdb","_cell_guid":"f941e85f-382a-4da1-86a7-6f7da14f70c0"}},{"cell_type":"markdown","source":"### Support Vector Machine","metadata":{"_uuid":"63efdf82c6e3aeabf14cc906cec456ba6f6a6ac0","_cell_guid":"edfcb798-4f74-4552-8bea-2617804eea56"}},{"cell_type":"markdown","source":"We are going to apply the same reasoning applying the support vector machine model with the gaussian kernel.\n\nWe train different models changing the regularization parameter C. <p>\nWe evaluate the accuracy, recall and precision of the model with the test set.","metadata":{"_uuid":"2d549025a14408ce4cd2df88f02c3468e75b9c45","_cell_guid":"2fc3af32-8b41-402b-b934-7e594eb4c972"}},{"outputs":[],"cell_type":"code","source":"list_C = np.arange(500, 2000, 100) #100000\nscore_train = np.zeros(len(list_C))\nscore_test = np.zeros(len(list_C))\nrecall_test = np.zeros(len(list_C))\nprecision_test= np.zeros(len(list_C))\ncount = 0\nfor C in list_C:\n    svc = svm.SVC(C=C)\n    svc.fit(X_train, y_train)\n    score_train[count] = svc.score(X_train, y_train)\n    score_test[count]= svc.score(X_test, y_test)\n    recall_test[count] = metrics.recall_score(y_test, svc.predict(X_test))\n    precision_test[count] = metrics.precision_score(y_test, svc.predict(X_test))\n    count = count + 1 ","execution_count":null,"metadata":{"_uuid":"1101b49ede4dccec53089e86f3db2969abea67ee","_cell_guid":"f82fc85a-e883-42d1-abbc-c3b3342247dc","collapsed":true}},{"cell_type":"markdown","source":"Let's see the first 10 learning models and their metrics!","metadata":{"_uuid":"4e1c88cc318233afe97fa9e298562c1e6025de1d","_cell_guid":"820fad12-6a0e-4ec6-b16a-e9734d69bf64"}},{"outputs":[],"cell_type":"code","source":"matrix = np.matrix(np.c_[list_C, score_train, score_test, recall_test, precision_test])\nmodels = pd.DataFrame(data = matrix, columns = \n             ['C', 'Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision'])\nmodels.head(n=10)","execution_count":null,"metadata":{"_uuid":"ec36f5defc3f1477cca07c5280818ee4282995d9","_cell_guid":"4da69237-fe8c-40ac-a72a-d33dc7863859"}},{"cell_type":"markdown","source":"I select the model with the most test precision","metadata":{"_uuid":"17a895a4c6a415493afae69ebeff7d172f09b014","_cell_guid":"7d5e554d-e0d8-44b0-9fca-480063caf529"}},{"outputs":[],"cell_type":"code","source":"best_index = models['Test Precision'].idxmax()\nmodels.iloc[best_index, :]","execution_count":null,"metadata":{"_uuid":"45c5f185a965f1b92889e56ce5f12c7acacffdf6","_cell_guid":"d0380748-44f5-4e41-af56-d25230c44479"}},{"cell_type":"markdown","source":"**My best model does not produce any false positive, which is our goal.** <p>\nLet's see if there is more than one model with 100% precision !","metadata":{"_uuid":"a428ab899dc27a65d3ec696ead5a049663c16524","_cell_guid":"166cb5ab-09da-49f4-bbb7-4e43bebd5c8e"}},{"outputs":[],"cell_type":"code","source":"models[models['Test Precision']==1].head(n=5)","execution_count":null,"metadata":{"_uuid":"fe2f070186300fed89e91380437f036e5feabe1d","_cell_guid":"89a59c66-8814-49d0-8f0e-f3b8acee666b"}},{"cell_type":"markdown","source":"Between these models with the highest possible precision, we are going to selct which has more test accuracy.","metadata":{"_uuid":"790cff4e431937d762bbe8db39911bf0d87dc53d","_cell_guid":"08cb6d81-fb1d-4e11-95a6-7922d19d082b"}},{"outputs":[],"cell_type":"code","source":"best_index = models[models['Test Precision']==1]['Test Accuracy'].idxmax()\nsvc = svm.SVC(C=list_C[best_index])\nsvc.fit(X_train, y_train)\nmodels.iloc[best_index, :]","execution_count":null,"metadata":{"_uuid":"d7d6eb9f249d10c19d4b9332c794476973dcf33f","_cell_guid":"49e4103a-3be1-4feb-bec4-d8baa5255a0b"}},{"cell_type":"markdown","source":"#### Confusion matrix with support vector machine classifier.","metadata":{"_uuid":"dd004721e1b6171488e1acf4c2a14235fc7f9700","_cell_guid":"d41fbc97-15f5-4963-9d5f-1452b2efe7ab"}},{"outputs":[],"cell_type":"code","source":"m_confusion_test = metrics.confusion_matrix(y_test, svc.predict(X_test))\npd.DataFrame(data = m_confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n            index = ['Actual 0', 'Actual 1'])","execution_count":null,"metadata":{"_uuid":"77005bd9a0fd6de323ada9206468c0598fa9c476","_cell_guid":"bf03b698-42e2-407f-a3da-dcc4acc36221"}},{"cell_type":"markdown","source":"#### We misclassify 31 spam as non-spam messages whereas we don't misclassify any non-spam message.","metadata":{"_uuid":"5190739594c1136056c12e2539889e38a9827641","_cell_guid":"44c24499-7357-41f3-af6f-2d05f2b988b4"}},{"cell_type":"markdown","source":"## Conclusion","metadata":{"_uuid":"1fb3ac434f7fd2b82cfb11e67cef5f9a369046cf","_cell_guid":"8535b776-3be3-45de-b17f-d2ca39ee3036"}},{"cell_type":"markdown","source":"**The best model I have found is support vector machine with 98.3% accuracy.** <p>\n**It classifies every non-spam message correctly (Model precision)** <p> \n**It classifies the 87.7% of spam messages correctly (Model recall)**<p>","metadata":{"_uuid":"d338aab6355df361ab8445d67e6b76bbcd5770b4","_cell_guid":"4e7d0e4d-52a7-4cba-b5f2-4fe363a8db26"}}],"metadata":{"language_info":{"version":"3.6.1","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py"},"anaconda-cloud":{},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"}}}