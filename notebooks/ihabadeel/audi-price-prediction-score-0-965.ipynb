{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Importing necessary modules\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nsns.set_style('whitegrid')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/used-car-dataset-ford-and-mercedes/audi.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the models to check for feature engineering \n\ndf.model.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating two columns for Series and Series Model\n\ndef Series(model):\n    series = ''\n    for char in model:\n        if char.isalpha():\n            series += char\n    return series\n\ndef Smodel(model):\n    smodel = ''\n    for char in model:\n        if char.isdigit():\n            smodel += char\n    if smodel == '':\n        return 1\n    return int(smodel)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['series'] = df['model'].apply(Series)\ndf['smodel'] = df['model'].apply(Smodel)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding a column as age of the car and drooping the year column\n\ndf['age'] = df['year'].apply(lambda x: 2020-x)\ndf.drop('year', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\n\nsns.countplot(y=df['model'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(18,6))\n\nfig.add_subplot(1,2,1)\nsns.countplot(df['transmission'])\nfig.add_subplot(1,2,2)\nsns.countplot(df['fuelType'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\n\nsns.countplot(df['series'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = df.select_dtypes(exclude=['object'])\n\nfig = plt.figure(figsize=(20,8))\n\nfor col in range(len(num_cols.columns)):\n    fig.add_subplot(2,4,col+1)\n    sns.distplot(num_cols.iloc[:,col], hist=False, rug=True, kde_kws={'bw':0.1}, label='UV')\n    plt.xlabel(num_cols.columns[col])\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20,8))\nplt.title('VS. Price')\n\nfor col in range(len(num_cols.columns)):\n    fig.add_subplot(2,4,col+1)\n    sns.scatterplot(x=num_cols.iloc[:,col], y=df['price'], label='MV')\n    plt.xlabel(num_cols.columns[col])\n    plt.ylabel('Price')\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.heatmap(df.corr(), annot=True, cmap='Blues', linewidth=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping the models columns and one hot encoding the rest\n\ndf.drop('model', axis=1, inplace=True)\n\ndf = pd.get_dummies(df)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing all the necessary modules for ML\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scaling the data\n\nscaler = StandardScaler()\nscaled = scaler.fit_transform(df)\ndf = pd.DataFrame(scaled, columns=df.columns)\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Generating the test and train datasets\n\nX = df.drop('price', axis=1)\ny = df['price']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making a list of Models to test against\n\nmodels = [['Linear Regression',LinearRegression()],\n         ['Decision Tree',DecisionTreeRegressor()],\n         ['Random Forest',RandomForestRegressor(n_estimators=100,n_jobs=-1)],\n         ['XGBoost',XGBRegressor(learning_rate=0.05,n_jobs=-1,n_estimators=1000)]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evaluating the models\n\nfor name, model in models:\n    model.fit(X_train,y_train)\n    predictions = model.predict(X_test)\n    \n    print('{} Score: '.format(name), model.score(X_test,y_test))\n    print('{} MAE: '.format(name), mean_absolute_error(y_test,predictions))\n    print('{} MSE: '.format(name), mean_squared_error(y_test,predictions))\n    print('{} RMSE: '.format(name), np.sqrt(mean_squared_error(y_test,predictions)), end='\\n\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Since XGB gave the best performance, we'll use it for the final predictions\n\nboost = XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=-1)\n\nboost.fit(X_train,y_train,early_stopping_rounds=5, eval_set=[(X_test,y_test)], verbose=False)\npred = boost.predict(X_test)\n\nprint('Boost Score: ', model.score(X_test,y_test))\nprint('Boost MAE: ', mean_absolute_error(y_test,predictions))\nprint('Boost MSE: ', mean_squared_error(y_test,predictions))\nprint('Boost RMSE: ', np.sqrt(mean_squared_error(y_test,predictions)), end='\\n\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scatterplot showing the spread of actual and predicted prices\n\nsns.scatterplot(x=pred, y=y_test)\n\nplt.title('Predicted vs Actual Price')\nplt.xlabel('Predicted Price')\nplt.ylabel('Actual Price')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}