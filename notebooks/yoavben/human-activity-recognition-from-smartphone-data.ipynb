{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Import relevant packges / functions:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data manipulation:\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\n# ML packages:\nfrom sklearn.model_selection import cross_validate, KFold\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score, matthews_corrcoef, make_scorer\nfrom sklearn.model_selection import train_test_split\n\n# Auxilliary:\nimport os\nfrom multiprocessing import cpu_count","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Load raw data:\n<font color=red>Note:</font>make sure the data is in the current working directory, or change `dataset_path` accordingly."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Deinfe integer encoding for the 6 classes:\nactivity_to_code = {'dws': 1, 'ups': 2, 'sit': 3, 'std': 4, 'wlk': 5, 'jog': 6}\ncode_to_activity = {v:k for k,v in activity_to_code.items()}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load all data from all subjects / experiments, as well as their demographic data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_raw_data(data_directory_path):\n    \"\"\"\n    Given a path to the motionsense-dataset directory, loop through the different CSVs and concatenate them \n    to one pandas DataFrame. Join with demographic data, and return the DataFrame.\n    \"\"\"\n    subjects_data_directory_path = os.path.join(dataset_path, \"data_subjects_info.csv\")\n    \n    # Load demographic data of subjects:\n    subject_data = pd.read_csv(subjects_data_directory_path).rename(columns={'code':'subject'}) # rename for clarity\n    subject_data['subject'] = subject_data.subject.astype(str)\n\n    # Load data from sensor:\n    motion_data_directory_path = os.path.join(dataset_path, r\"A_DeviceMotion_data/A_DeviceMotion_data\")\n    dirs = os.listdir(motion_data_directory_path)\n    dfs = []\n    for d in dirs:\n        activity_name, experiment_id = d.split(\"_\")\n        for subject in os.listdir(os.path.join(motion_data_directory_path, d)):\n            filepath = os.path.join(os.path.join(motion_data_directory_path, d), subject)\n            df = pd.read_csv(filepath, index_col=0)\n            df['subject'] = subject.split(\".\")[0].split(\"_\")[1] # keep only the subject's numerical i.d.\n            df['activity'] = activity_to_code[activity_name]\n            df['experiment_id'] = int(experiment_id)\n            df['experiment_step'] =  np.arange(0, len(df)) # assign a numerical step number for every measurement in the experiment\n            dfs.append(df)\n\n    motion_data = pd.concat(dfs)\n    \n    # Join demographic data to final dataframe:\n    final_df = motion_data.merge(subject_data, on=['subject'])\n    \n    return final_df, subject_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_path = r\"../input/motionsense-dataset\" # Assuming here dataset is in cwd.\nraw_df, subject_data = load_raw_data(dataset_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"raw data shape: \", raw_df.shape)\nprint(\"\\nraw data columns:\\n\", raw_df.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. EDA:"},{"metadata":{},"cell_type":"markdown","source":"### Check for missing values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_df.isnull().sum(axis=0)\n# There are no missing values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color=blue>There are no missing values in the data.</font>"},{"metadata":{},"cell_type":"markdown","source":"### Inspect the distribution of the raw data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"MOTION_SENSOR_COLUMNS = ['attitude.roll', 'attitude.pitch', 'attitude.yaw', 'gravity.x', 'gravity.y', 'gravity.z', \n                         'rotationRate.x', 'rotationRate.y', 'rotationRate.z', 'userAcceleration.x', 'userAcceleration.y',\n                        'userAcceleration.z']\nDEMOGRAPHIC_FEATURES = ['weight', 'height', 'age', 'gender']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_df[MOTION_SENSOR_COLUMNS].describe(percentiles=[0.001,0.01,0.25,0.5,0.75,0.95,0.99, 0.999]).round(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color=blue>\nWe can see that some of the feature exhibit some extremely large values (relatively to their distribution) - for \n    example rotationRate.y. This appears to happen in both sides of the distribution (extremely small values & extremely large ones), and thus less likely to be measurements errors.\n</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot histograms of the motion features:\n\nsamp = raw_df.sample(10**5) # plotting a sample, for run-time considerations\nfig, ax = plt.subplots(3, 4, sharex='col', sharey='row', figsize=(10, 8))\n\nm=0\nfor i in range(3):\n    for j in range(4):\n        colname = MOTION_SENSOR_COLUMNS[m]\n        samp[colname].plot(kind='hist', ax=ax[i,j], bins=20, title=colname, density=True, xlim=(-4,4))\n        m += 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color=blue>\nWe observe that most raw features exhibit bell-shaped distributions around 0, while others (like attitute.pitch) are highly skewed</font>"},{"metadata":{},"cell_type":"markdown","source":"### Examine \"demographics\" distibution:"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_df[['weight','height','age']].describe().round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color=blue>No suspicious values such as negative height or impossible age.</font>"},{"metadata":{},"cell_type":"markdown","source":"### Inspect target-class distribution:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot class distribution:\nactiviry_counts = raw_df.activity.apply(lambda x: code_to_activity[x] ).value_counts()\nactiviry_counts.plot(kind='bar', title='Activity Class Distibution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color=blue>classes are not balances, with (walk, sit, stand) ~2X larger than (upstairs, jog, downstairs)</font>"},{"metadata":{},"cell_type":"markdown","source":"# Calculate features as summary statistics over fixed window:\n\nWe'll split consecutive measurements (within subject, within experiment) to windows of a fixed size (for example, a window size of 50 corresponds to 1 second of measurements as the measure frequency is 50htz), and calculate a set of summary statistics for the measurements in the window.\nAdditionaly, we'll add the demographic features (age, weight, etc.) per subject."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_processed_df(window_size, summary_statistics):\n    \"\"\"\n    Group measurements per subject per experiment to windows of requested size, and calculate a set of summary_statistics \n    withing that window \n    window_size: int, size of window.\n    summary_statistics: list, either of string representations of aggregation functions or aggregation function objects\n    \"\"\"\n    grouped_df = raw_df.groupby(['subject', 'experiment_id'])\n    processed_dfs = []\n    for name, group in grouped_df: # iterate over data from consecutive meaurements, per subject per experiment\n        subject, experiment = name\n        nbins = int(len(group) / window_size) # num of bins depends on length of epxeriment\n        bin_edges = pd.cut(group.experiment_step, bins=nbins) \n        activity = group.activity.values[0] # all activites in this df are the same\n        agg_per_bin = group[MOTION_SENSOR_COLUMNS].groupby(bin_edges).agg(summary_statistics)\n\n        # fix colum names:\n        agg_per_bin = agg_per_bin.reset_index()\n        cols = list(agg_per_bin.columns)\n        fixed_cols = [str(c[0])+\"_\"+str(c[1]) for c in cols]\n        agg_per_bin.columns = fixed_cols\n\n        # Add the constant features (constant per sbject and experiment):\n        agg_per_bin['experiment_id'] = experiment\n        agg_per_bin['activity'] = activity # this will be the label\n        agg_per_bin['subject'] = subject\n        agg_per_bin = agg_per_bin.merge(subject_data, on='subject')\n        \n        processed_dfs.append(agg_per_bin)\n    \n    processed_data = pd.concat(processed_dfs)\n    return processed_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll choose the following summary statistics, as they seem like a reasonable approximation for the disribution of a feature within the window. \nI'd expect these values to exibit different mean, std, etc. when a person switches between activities.\nAdditionaly, such measures could vary between different gender/height/weight/age groups, so we keep the demographoc features as well.\n<font color=red>Following cell takes ~1m to run (on a local i7 processor):</font>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"summary_statistics = ['mean', 'median', 'max', 'min', 'std', 'skew']\nprocessed_data = get_processed_df(window_size=100, summary_statistics=summary_statistics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(processed_data.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Examine feature behaviour accross classes:\n\nWe'll look at the difference in distribution of some of the features accross classes\""},{"metadata":{"trusted":true},"cell_type":"code","source":"features_to_plot = [\"attitude.roll_mean\", \"userAcceleration.y_skew\", \"gravity.y_median\"] # arbitrary choice\nfor feature in features_to_plot:\n    processed_data.groupby('activity')[feature].plot(kind='kde',legend=True,\n                                                    title=\"'%s' density per class\" % feature)\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color=blue>It's evident that the features are distributed differently between classes.</font>"},{"metadata":{},"cell_type":"markdown","source":"# Extract feature matrix & labels for model training:"},{"metadata":{},"cell_type":"markdown","source":"create a list of all the features to train on (sensor summary statistics & demographic features):"},{"metadata":{"trusted":true},"cell_type":"code","source":"motion_sensor_features =  [f for f in processed_data.columns if any([x in f for x in MOTION_SENSOR_COLUMNS])]\nfeature_names = motion_sensor_features + DEMOGRAPHIC_FEATURES","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create feature matrix **X** and labels vecotr **y**:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = processed_data[feature_names]\ny = processed_data['activity']\n\nprint(\"feature matrix shape: \",X.shape)\nprint(\"target vector matrix shape: \",y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train and evaluate using k-ofld CV, to estimate MCC (and is standard deviation):"},{"metadata":{},"cell_type":"markdown","source":"We'll choose the xgboost implementation of **gradient boosted trees clasifier**, as a good off-the-shelf classifier with relative robustness to redundant features and fast training time, as well as explainable results. We will also compare it's perofrmance to multiclass **logistic-regression**."},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_clf = XGBClassifier(n_jobs=-1)\nlr = LogisticRegression(n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define a scorrer and a CV splitter:\nThe CV splitter has to explicitly be defined so that we can demand that data be shuffeld before splitting. This is required because (X,y) are sorted by subject/experiment, so unshuffled splits will produce biased estimators."},{"metadata":{"trusted":true},"cell_type":"code","source":"mcc_scorer = make_scorer(matthews_corrcoef) # defining a custom scorer (requried for computing MCC + accuracy in one go)\nkfold_splitter = KFold(n_splits=5, shuffle=True)\nnamed_classifiers = [(xgb_clf, \"xgb_classifier\"), (lr, \"logistic_regression\")]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train & evaluate both classifeirs <font color=red>(will take a few minutes on the full dataset):</font>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_results = {}\nfor model, name in named_classifiers:\n    print(\"fitting %s...\" % name)\n    cv_results[name] = \\\n        cross_validate(model, X, y, \n                        cv=kfold_splitter, scoring={\"mcc\":mcc_scorer, \"accuracy\":\"accuracy\"}, \n                       n_jobs=cpu_count()-1, verbose=3, return_estimator=True) # use all cores but one\n    print(\"Done\")\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Parse and report cv results - keep only the evaluation metrics (cross_validate also reports timing metrics):"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_metrics = {}\nfor model, results in cv_results.items():\n    test_metrics[model] = {}\n    for metric, values in results.items():\n        if \"test\" in metric: # skip timing metrics\n            test_metrics[model].update({\n                metric: np.mean(values),\n                metric + \"_std\": np.std(values)\n            })\ntest_metrics = pd.DataFrame(test_metrics)\n\nprint(test_metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color=blue>We can see that the gradient boosted trees model achieves high MCC and accuracy,\nwith very small standard deviations. logistic_regression doesn't perform as well.</font>\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Inspect feature importances"},{"metadata":{},"cell_type":"markdown","source":"### Extract feature importance from one of the trained xgb_classifiers:"},{"metadata":{"trusted":true},"cell_type":"code","source":"trained_xgb_clf = cv_results[\"xgb_classifier\"][\"estimator\"][0] # 0 is abritrary, the estimator from the 1st fold\n\n# get feature importances:\nfi = pd.DataFrame(zip(X.columns, trained_xgb_clf.feature_importances_), columns=['feature','importance'])\nfi.sort_values(by='importance', ascending=False, inplace=True)\nfi.set_index('feature', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the 20 most important features:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fi.head(20).plot(kind='barh', figsize=(10,10), title=\"Most important features\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color=blue>We can see that all 6 statistics (mean, median, min, max, std, skew) are represented in the top-20 features.</font>"},{"metadata":{},"cell_type":"markdown","source":"### Check how many features (and which ones) were excluded form model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"excluded_features = fi[fi.importance == 0]\nprint(excluded_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font color=blue>Very few features were not used for splits by the model (in my run they were interestingly all \"gravity\" features, but this may slightly change accross runs).</font>"},{"metadata":{},"cell_type":"markdown","source":"# Additional directions:"},{"metadata":{},"cell_type":"markdown","source":"* Experiment with different window sizes. current windows requires 2 seconds of data, which may be a lot for some applications\n* Consider other metrics such as multi-class AUC (I didn't add it here because cross_validate doesn't support it, and I chose to go along woth the parallelized implementation othar than iterating over CV folds)\n* Investigate perfomrance metrics per class and per person in the test set - could be interesting.\n* Deal with anbormal values in the raw data - this requires some more info about their scales (consider some transformation such as log-scale for the features with abnormal values)\n* Conduct meta-parameter optimization, and switch from using the vanilla model.\n* Consider additional models, including RNN architectures (could work on the raw data, or on smaller feature-windows)\n* Use bootstrapping to better estimate the variability of the test metrics\n* Add more summary statistics as features, for example I would try adding more percentiles of each raw feature in the window in order to better convey it's distribution to the model (currently we use only the 0.5 percentile - the median).\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}