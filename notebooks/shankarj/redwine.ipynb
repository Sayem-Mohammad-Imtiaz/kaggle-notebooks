{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nsns.set_style('darkgrid')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12,6))\nsns.countplot(x = 'quality',data = data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['wineClass'] = data['quality'].copy()\nfor index in range(len(data['wineClass'])):\n    if data['wineClass'][index]>=6:data['wineClass'][index] = 'Good'\n    else:data['wineClass'][index] = 'Bad'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12,6))\nsns.countplot(x = 'wineClass',data = data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(data.select_dtypes(include = ['object']).columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y = data['wineClass']\ndata.drop(['wineClass','quality'],axis = 1,inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" fig=plt.figure(figsize=(30, 60)) \ncolumns = 2 \nrows = 6\ncolumn = list(data.columns)\ncol = 0\nfor i in range(1, columns*rows +1): \n    if col==len(column):break\n    fig.add_subplot(rows, columns, i) \n    tab = data[column[col]]\n    plt.hist(tab)\n    plt.xlabel(column[col])\n    col+=1\nplt.show() ","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logistic_reg = LogisticRegression()\nrandom_forest = RandomForestClassifier()\ndecision_tree = DecisionTreeClassifier()\nsvm = SVC()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xtrain,xtest, Ytrain, ytest = train_test_split(data,Y,test_size = 0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def trainer(model):\n    model.fit(Xtrain,Ytrain)\n    return model.score(xtest,ytest)\nmodels = [logistic_reg,random_forest,decision_tree,svm]\nmodel_names =  ['Logistic Regression','Random Forest Classifier','Decision Tree Classifier','Support Vector Machines']\n\ntraining_with_defaults = []\nfor model,model_name in zip(models,model_names):\n    score = trainer(model)\n    training_with_defaults.append('{} : {}'.format(model_name,score))\n    print('{} : {}'.format(model_name,score))\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gridsearch(model,params_grid):\n    grid_search = GridSearchCV(estimator=model,param_grid = params_grid,cv = 3,verbose = 2,n_jobs = 4)\n    grid_search.fit(Xtrain,Ytrain)\n    return grid_search.best_params_\nlogistic_reg_params_grid = {'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n                            'dual':[True,False],\n                            'C':np.arange(11),\n                            'fit_intercept':[True,False]\n                            \n                           }\nrandom_forest_params_grid = {'n_estimators':[20,70,100],\n                            'criterion':['gini','entropy'],\n                             'max_depth':[None,5,10],\n                             'min_samples_split':[2,7],\n                             'min_samples_leaf':[1,2,4]\n                            }\ndecision_tree_params_grid = {'criterion':['gini', 'entropy'],\n                             'splitter' : ['best', 'random'],\n                             'max_depth':[None,5,10,15],\n                             'min_samples_split':[2,7],\n                             'min_samples_leaf':[1,2,4]\n                            }\nsvm_params_grid = {'kernel' : ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']}\nparameter_grids = [logistic_reg_params_grid,random_forest_params_grid,decision_tree_params_grid]\nparam_dict = {}\nfor model,model_name,paramgrid in zip(models,model_names,parameter_grids):\n    if model_name=='Support Vector Machine':break\n    parameters = gridsearch(model,paramgrid)\n    param_dict[model_name] = parameters\nprint(param_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logistic_reg = LogisticRegression(C= 1,dual= False, fit_intercept= True, penalty= 'l2')\nrandom_forest = RandomForestClassifier(criterion= 'entropy', max_depth= None, min_samples_leaf= 1, min_samples_split= 2, n_estimators= 100)\ndecision_tree = DecisionTreeClassifier(criterion= 'entropy', max_depth= 15, min_samples_leaf= 1, min_samples_split= 2, splitter = 'best')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_with_hypers = []\nfor model,model_name in zip(models,model_names):\n    score = trainer(model)\n    training_with_hypers.append('{} : {}'.format(model_name,score))\n#     print('{} : {}'.format(model_name,score))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Defaults : ')\nfor res in training_with_defaults:print(res)\nprint('\\n\\nTuned : ')\nfor res in training_with_hypers:print(res)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}