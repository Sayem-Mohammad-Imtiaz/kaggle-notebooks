{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predicting House Prices\n----------------------------------------------\n\nIn this notebook, I will be creating a model to predict house prices in the King County based on the dataset.","metadata":{}},{"cell_type":"markdown","source":"# Table of Contents\n\n* [Setup](#1)\n* [Exploratory Analysis](#2)\n    - [Summary](#3)\n    - [Finding categorical and continous variables](#4)\n    - [Continous](#5)\n        + [Statistical Significance](#6)\n        + [Conclusion: Continous](#7)\n    - [Categorical](#8)\n        + [Conclusion: Categorical](#9)\n    - [Exploratory Conclusion](#10)\n* [Model Development and Evaluation](#11)\n* [Setup](#12)\n* [Multiple Linear Regression Model](#13)\n    - [Building the model](#14)\n    - [Teseting and evaluating the model](#15)\n* [Polynomial Regression and Normalization](#16)\n    - [Creating a pipeline](#17)\n* [Ridge Regression](#18)\n* [Cross-validation](#19)\n* [Conclusion](#20)\n* [Author](#21)","metadata":{}},{"cell_type":"markdown","source":"Without further ado, let's get started.","metadata":{}},{"cell_type":"markdown","source":"# Setup <a id='1'></a>\n\nImporting the libraries and getting the data.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom scipy import stats\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set(color_codes=True)\npd.set_option('display.max_columns', None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = '../input/housesalesprediction/kc_house_data.csv'\ndf = pd.read_csv(file_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Analysis <a id='2'></a>\n----------------------","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary <a id='3'></a>\n\nNow let's see the columns types in the dataframe. ","metadata":{}},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Summary of the data","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finding categorical and continous variables <a id='4'></a>\n\nWe can see that the columns _floors, waterfront, view, condition,_ and _grade_ have few values and could be seen as categorical. Thus we should use a boxplot to explore the relationship between them.\n\nAs of the rest, a scatterplot would be a good idea.","metadata":{}},{"cell_type":"code","source":"# The columns\ncategorical = ['bedrooms', 'bathrooms', 'floors', 'waterfront', 'view', 'condition', 'grade']\ncontinous = ['sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Continous <a id='5'></a>\n\nLet's explore the relationship of continous variables and price.\n\nWe would be using two methods:\n* The Pearson coefficient\n* Scatter plot","metadata":{}},{"cell_type":"code","source":"# Pearson coefficient\ncontinous_df = df[continous]\ncontinous_df.corrwith(df['price'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column_name in continous:\n    plt.figure(figsize=(10,8))\n    sns.scatterplot(x=column_name, y='price', data=df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the ones that might have correlation with price are _sqft_living, sqft_above, sqft_living15._ _lat,_ and _sqft_basement_ also have moderate correlation too.","metadata":{}},{"cell_type":"markdown","source":"### Statistical Significance <a id='6'></a>\n\nLet's find whether they are statistically significant or not. We would be using p-value for that.","metadata":{}},{"cell_type":"code","source":"pearson_coeff, p_value = stats.pearsonr(df['sqft_living'], df['price'])\nprint(\"sqft_living -- Pearson's Coefficient is: \", pearson_coeff, \" and the p-value is: \", p_value)\n\npearson_coeff, p_value = stats.pearsonr(df['sqft_living15'], df['price'])\nprint(\"sqft_living15 -- Pearson's Coefficient is: \", pearson_coeff, \" and the p-value is: \", p_value)\n\npearson_coeff, p_value = stats.pearsonr(df['sqft_above'], df['price'])\nprint(\"sqft_above -- Pearson's Coefficient is: \", pearson_coeff, \" and the p-value is: \", p_value)\n\npearson_coeff, p_value = stats.pearsonr(df['sqft_basement'], df['price'])\nprint(\"sqft_basement -- Pearson's Coefficient is: \", pearson_coeff, \" and the p-value is: \", p_value)\n\npearson_coeff, p_value = stats.pearsonr(df['lat'], df['price'])\nprint(\"lat -- Pearson's Coefficient is: \", pearson_coeff, \" and the p-value is: \", p_value)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The p-value is extremely low to the point that it seems like 0.\n\nNow, we can confidently say that these variables have correlation with price.","metadata":{}},{"cell_type":"markdown","source":"### Conclusion: Continous <a id='7'></a>","metadata":{}},{"cell_type":"markdown","source":"The features that can predict price are _sqft_living, sqft_living15, sqft_above, sqft_basement and lat_","metadata":{}},{"cell_type":"markdown","source":"## Categorical <a id='8'></a>\n\nLet's figure out the relationship between categorical variables and price. We will first plot them. ","metadata":{}},{"cell_type":"code","source":"# Categorical\nfor column_name in categorical:\n    plt.figure(figsize=(10,8))\n    sns.boxplot(x=column_name, y='price', data=df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems that everything except condition would be a good predictor. ","metadata":{}},{"cell_type":"markdown","source":"### Conclusion: Categorical <a id='9'></a>\n\nWe concluded that the variables of interest are _bedrooms, bathrooms, waterfront, view,_ and _grade_","metadata":{}},{"cell_type":"markdown","source":"## Exploratory Conclusion <a id='10'></a>\n\nThe features that we found that we can use to predict the house price are:\n* sqft_above\n* sqft_living15\n* sqft_living\n* sqft_basement\n* bedrooms\n* bathrooms\n* waterfront\n* floors\n* lat\n* view \n* grade","metadata":{}},{"cell_type":"markdown","source":"# Model Development and Evaluation <a id='11'></a>\n----------------------------------\n\nNow, let's move onto creating a model.\n\nI will be making a linear regression since we are trying to predict a continous variable that has some linear relationship with its 'dependent' variables. ","metadata":{}},{"cell_type":"markdown","source":"# Setup <a id='12'></a>\n\nFirst, we need to get started by importing the libraries, setting some options and importing the data.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nsns.set(color_codes=True)\npd.set_option('display.max_columns', None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Multiple Linear Regression Model <a id='13'></a>","metadata":{}},{"cell_type":"markdown","source":"## Building the model <a id='14'></a>\n\nWe would first be building a MLR model. From the exploratory analysis, we know that the important features are:\n* sqft_above\n* sqft_living15\n* sqft_living\n* sqft_basement\n* bedrooms\n* bathrooms\n* waterfront\n* floors\n* lat\n* view \n* grade\n\nThe first step would be to create X and y. ","metadata":{}},{"cell_type":"code","source":"X = df[['sqft_above', 'sqft_living15', 'sqft_living', 'sqft_basement', 'bedrooms', 'bathrooms', 'waterfront', 'floors', 'lat', 'view' , 'grade']]\ny = df[['price']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, we need to split the data. ","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, let's create the model.","metadata":{}},{"cell_type":"code","source":"lm = LinearRegression()\nlm.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing and evaluating the model <a id='15'></a>","metadata":{}},{"cell_type":"markdown","source":"Let's test the model by getting prediction values and making a distribution plot.","metadata":{}},{"cell_type":"code","source":"yhat_test = lm.predict(X_test)\nyhat_test_df = pd.DataFrame(yhat_test, columns=['predicted_price'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,10))\nax = sns.kdeplot(y_test['price'])\nax = sns.kdeplot(yhat_test_df['predicted_price'], ax=ax)\nax.legend(['y', 'y_hat'], fontsize=13);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That looks a really good estimate. We should also get some numeric values. Let's get the R-squared value.","metadata":{}},{"cell_type":"code","source":"lm.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, there's room for improvement. \n\nIf we take a look at the graphs in the exploratory analysis, we can see them some features (say grade) have a non-linear relationship. So, we need to make a polynomial linear regression model to take those into account properly.\n\nFurthermore, it would be helpfult to normalize the variables, so that few variables might not dominate the model","metadata":{}},{"cell_type":"markdown","source":"# Polynomial Regression and Normalization <a id='16'></a>","metadata":{}},{"cell_type":"markdown","source":"The best way to go at it would be to create a pipeline.\n\nLet's import the modules first.","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating a pipeline <a id='17'></a>","metadata":{}},{"cell_type":"markdown","source":"We will create a pipeline that will first normalize the values (using standard scalar), create polynomial features (with degree of 2) and then use linear model to predict the data. \n\nLet's create the pipeline","metadata":{}},{"cell_type":"code","source":"pipe_info = [('Normalize', StandardScaler()), ('Polynomial Features', PolynomialFeatures(include_bias=False)), ('Linear Model', LinearRegression())]\npipe = Pipeline(pipe_info)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's use the pipeline","metadata":{}},{"cell_type":"code","source":"pipe.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yhat_test_pipe = pipe.predict(X_test)\nyhat_test_pipe_df = pd.DataFrame(yhat_test_pipe, columns=['predicted_price'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's plot it and see what we get.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,10))\nax = sns.kdeplot(y_test['price'])\nax = sns.kdeplot(yhat_test_pipe_df['predicted_price'], ax=ax)\nax.legend(['y', 'y_hat'], fontsize=13);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe.score(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A better score. But there's further room for improvement. \n\nLet's try Ridge Regression because the parameters could be correlated (such as having more bedrooms is likely to imply more bathrooms).","metadata":{}},{"cell_type":"markdown","source":"# Ridge Regression <a id='18'></a>","metadata":{}},{"cell_type":"markdown","source":"We would be creating a pipe to first normalize, polynomial features and then ridge regression. \n\nMandatory Imports:","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import Ridge","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe_info_ridge = [('Normalize', StandardScaler()), ('Polynomial Features', PolynomialFeatures(include_bias=False)), ('Regression', Ridge())]\nridge_pipe = Pipeline(pipe_info_ridge)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For ridge regression, we would be optimizing the hyper-parameter $\\alpha$ by grid search. Let's get the parameters.","metadata":{}},{"cell_type":"code","source":"ridge_pipe.get_params().keys()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, we would be using the `Regression__alpha` parameter then. Let's create the dict with parameters.","metadata":{}},{"cell_type":"code","source":"hyper_params_dict = {'Regression__alpha': [0.0001, 0.001, 0.01, 0.1, 0, 1, 10, 100, 1000, 10000]}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Time to use the grid search","metadata":{}},{"cell_type":"code","source":"grid = GridSearchCV(estimator=ridge_pipe, param_grid=hyper_params_dict, scoring='r2', n_jobs=-1, cv=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's find the best estimator and the param","metadata":{}},{"cell_type":"code","source":"grid.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_ridge = grid.best_estimator_\nbest_ridge","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution plot:","metadata":{}},{"cell_type":"code","source":"yhat_ridge = best_ridge.predict(X_test)\nyhat_ridge_df = pd.DataFrame(yhat_ridge, columns=['predicted_price'])\nplt.figure(figsize=(12,10))\nax = sns.kdeplot(y_test['price'])\nax = sns.kdeplot(yhat_test_pipe_df['predicted_price'], ax=ax)\nax.legend(['y', 'y_hat'], fontsize=13);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, the R-squared score we got.","metadata":{}},{"cell_type":"code","source":"grid.best_score_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross-validation <a id='19'></a>","metadata":{}},{"cell_type":"markdown","source":"Although we did take Cross-validation into account when doing the Grid Search for Regression, let's do a k-fold cross-validation with 5 folds regardless. We would getting the R-squared values.\n\nLet's get started. \n\nMandatory Imports.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_scores = cross_val_score(estimator=best_ridge, X=X, y=y, cv=5)\ncv_scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, we need to get summary of the array.","metadata":{}},{"cell_type":"code","source":"pd.Series(cv_scores).describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That seems like a decent result. ","metadata":{}},{"cell_type":"markdown","source":"# Conclusion <a id='20'></a>\n\nThere we go. A linear regression model to predict houseprices.\n\nThe best model we achieved had a mean cv score of 0.73 and was a Ridge Regression model with $\\alpha$ as 1000.  ","metadata":{}},{"cell_type":"markdown","source":"# Author <a id='21'></a>\nBy Abhinav Garg","metadata":{}}]}