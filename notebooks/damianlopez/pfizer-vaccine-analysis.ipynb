{"cells":[{"metadata":{},"cell_type":"markdown","source":"## How the new Covid-19 vaccine from Pfizer and BioNTech was received by Tweeter Public"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [20,10]\n#%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vaccineTweet_DF = pd.read_csv('/kaggle/input/pfizer-vaccine-tweets/vaccination_tweets.csv')\nvaccineTweet_DF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vaccineTweet_DF.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking null\nvaccineTweet_DF.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# User location and hashtags and descripton NULL values will be replace with unknown and None, and NoDesc respectivetly \nvaccineTweet_DF['user_location'].fillna('Unknown', inplace=True)\nvaccineTweet_DF['hashtags'].fillna('None', inplace=True)\nvaccineTweet_DF['user_description'].fillna('NoDesc', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vaccineTweet_DF.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vaccineTweet_DF.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analazing data with NLP"},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nnltk.download('stopwords')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plan is to analyze text and hashtags columns \nimport string\nstring.punctuation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove punctuation FUNCTION\ndef remove_punctuation(text):\n    for eachPunct in string.punctuation:\n        text = text.replace(eachPunct, '')\n    return text ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vaccineTweet_DF['text'] = vaccineTweet_DF['text'].apply(remove_punctuation)\nvaccineTweet_DF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vaccineTweet_DF.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check some retweets \nvaccineTweet_DF['retweets'].value_counts().plot(kind='bar', title='No of Retweets Twitter Acounts')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vaccineTweet_DF['favorites'].value_counts().plot(kind='bar', color='red',title='No of Favorites Twitter Acounts')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's do some tokenize FUNCTION  \nfrom nltk.tokenize import word_tokenize\ndef tokenize_text(text):\n    text = word_tokenize(text.lower())\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply the tokenize function to the text column\nvaccineTweet_DF['text'] = vaccineTweet_DF['text'].apply(tokenize_text)\nvaccineTweet_DF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install textblob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install langdetect ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from langdetect import detect\nfrom textblob import TextBlob    \nmyword = detect(\"hello\")\nmyword","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# stop words FUNCTION\nfrom nltk.corpus import stopwords\ndef remove_stopwords(text):\n    #global stopwords\n    stop_words = set(stopwords.words('english'))\n    text = [word for word in text if not word in stop_words]\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vaccineTweet_DF['text'] = vaccineTweet_DF['text'].apply(remove_stopwords)\nvaccineTweet_DF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nnltk.download('wordnet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lemmatization FUNCTION\ndef lemmatize_words(text):\n    wn = nltk.WordNetLemmatizer()\n    text = [wn.lemmatize(word) for word in text]\n    return text\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#vaccineTweet_DF['text'] = vaccineTweet_DF.apply(lemmatize_words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import PorterStemmer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stemming \ndef stemming_word(text):\n    porter = PorterStemmer()\n    text = [porter.stem(t) for t in text]\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vaccineTweet_DF['text'].apply(stemming_word)\nvaccineTweet_DF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from textblob import TextBlob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Polarity and Subjectivity\ndef sentiment_analysis(text):\n    analisys = TextBlob(text).sentiment\n    return analisys\n\nvaccineTweet_DF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To String\ndef listToStr(myList):\n    if type(myList) is list:\n        return \";\".join(myList)\n    else:\n        return myList","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vaccineTweet_DF['text'].apply(lambda x: [listToStr(i) for i in x])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vaccineTweet_DF['stringText'] = vaccineTweet_DF['text'].apply(lambda x: x[1:])\nvaccineTweet_DF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vaccineTweet_DF['text'] = vaccineTweet_DF['text'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vaccineTweet_DF['senti_score'] = vaccineTweet_DF['text'].apply(sentiment_analysis)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vaccineTweet_DF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_series = vaccineTweet_DF['senti_score'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#vaccineTweet_DF['senti_score'].value_counts().plot(kind='pie')\nuser_verify_plot = vaccineTweet_DF.groupby('user_verified').hashtags.count()\nuser_verify_plot.plot(kind='pie', title='User Verify Twitter Account')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check top 20 locations (USER)\nuser_location = vaccineTweet_DF['user_location'].value_counts().index[:20]\nuser_location","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y='user_location', data=vaccineTweet_DF, order=user_location, color='cornflowerblue')\nplt.title('Number of USERS per LOCATION', loc='center')\nplt.xlabel('Number of users', weight='bold')\nplt.ylabel('Location', weight='bold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analize Polarity & Subjetivity together\nfig, ax = plt.subplots(figsize=(8,6), sharex=True)\nplt.ylim(0,2)\nvaccineTweet_DF['senti_score'].hist(ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analizing Polarity and Subjetivity separate\nsentiment_series = vaccineTweet_DF['senti_score'].tolist()\ncols = ['Polarity', 'Subjetivity']\nsentimentDF = pd.DataFrame(sentiment_series, columns=cols, index=vaccineTweet_DF.index)\nsentimentDF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove all 0.00 's \nsentimentDF = sentimentDF.loc[(sentimentDF != 0).any(axis=1)].reset_index(drop=True)\nsentimentDF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Polarity Distribution\nplt.hist(sentimentDF['Polarity'], color='darkred', edgecolor='black', density=False, bins= int(30))\nplt.title('Polarity Distribution')\nplt.xlabel('Polarity')\nplt.ylabel('Number of Times')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Subjetivity Distribution\nsns.distplot(sentimentDF['Subjetivity'], hist=True, kde=True, bins=int(30), color='darkred', hist_kws={'edgecolor':\n                                                                                                   'black'}, axlabel='Subjetivity')\nplt.xlabel('Subjetivity')\nplt.ylabel('Number of times')\nplt.title('Subjetivity Distribution')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}