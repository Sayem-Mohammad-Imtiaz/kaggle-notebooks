{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction\n\n* [What are ANNs?](#1)\n* [Types of NNs?](#2)\n* [Is there a difference between NN and ANN?](#3)\n* [In what situation does the algorithm fit best?](#4)\n* [How does ANN work?](#5)\n* [Activation Function](#6)\n* [What happens without activation function?](#7)\n* [How are NNs different from classical models?](#8)\n* [Implementation](#9)\n* [Business Problem and EDA](#10)\n* [Evaluation Metrics](#11)\n* [Evaluation of Multiple Training Instances](#12)\n* [Improving the ANN with dropout layer](#13)\n* [Tuning the ANN](#14)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\ntry:\n    import theano\nexcept:\n    !pip install Theano\nimport theano\nimport keras\nimport tensorflow\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":2,"outputs":[{"output_type":"stream","text":"WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\nUsing TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"['Churn_Modelling.csv']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a>\n# 1. What are ANNs?\n\n#### Artificial neural networks are one of the main tools used in machine learning. As the “neural” part of their name suggests, they are brain-inspired systems which are intended to replicate the way that we humans learn. Neural networks consist of input and output layers, as well as (in most cases) a hidden layer consisting of units that transform the input into something that the output layer can use. ANNs have three layers that are interconnected. The first layer consists of input neurons. Those neurons send data on to the second layer, which in turn sends the output neurons to the third layer. ANNs are considered non-linear statistical data modeling tools where the complex relationships between inputs and outputs are modeled or patterns are found. Note that a neuron can also be referred to as a perceptron.\n\nNote: The way layers would be created, arranged, assigned, number of neurons the layers would hold and other such questions come under architecture designing for neural networks. It is a common thing while starting out to have these queries. Architecture of NNs is an ocean frankly, one can gain knowledge of it only by exploring it, working on different problems optimising for better solutions by trial and error. There are some thumb rules that are known but since the complexity of the mechanism is such there are a very few detailed proofs of why some things work for some problems and some don't."},{"metadata":{},"cell_type":"markdown","source":"![](https://icdn6.digitaltrends.com/image/artificial_neural_network_1-720x720.jpg)"},{"metadata":{},"cell_type":"markdown","source":"#### For a basic idea of how a deep learning neural network learns, imagine a factory line. After the raw materials (the data set) are input, they are then passed down the conveyer belt, with each subsequent stop or layer extracting a different set of high-level features. If the network is intended to recognize an object, the first layer might analyze the brightness of its pixels. The next layer could then identify any edges in the image, based on lines of similar pixels. After this, another layer may recognize textures and shapes, and so on. By the time the fourth or fifth layer is reached, the deep learning net will have created complex feature detectors. It can figure out that certain image elements (such as a pair of eyes, a nose, and a mouth) are commonly found together.\n\n#### Once this is done, the researchers who have trained the network can give labels to the output, and then use backpropagation to correct any mistakes which have been made. After a while, the network can carry out its own classification tasks without needing humans to help every time."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a>\n# 2. Types of Neural Network\n\n#### There are multiple types of neural network, each of which come with their own specific use cases and levels of complexity. The most basic type of neural net is something called a feedforward neural network, in which information travels in only one direction from input to output. A more widely used type of network is the recurrent neural network, in which data can flow in multiple directions. These neural networks possess greater learning abilities and are widely employed for more complex tasks such as learning handwriting or language recognition.\n\n#### There are also convolutional neural networks, Boltzmann machine networks, Hopfield networks, and a variety of others. Picking the right network for your task depends on the data you have to train it with, and the specific application you have in mind. In some cases, it may be desirable to use multiple approaches, such as would be the case with a challenging task like voice recognition."},{"metadata":{},"cell_type":"markdown","source":"![](https://i.stack.imgur.com/LgmYv.png)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a>\n# 3. Is there a difference between NN and ANN?\n#### Neural Network is a broad term that encompases various types of networks which were shown above. Is ANN one of the types? Well to understand this it is important to realise that neural network alone is not an algorithm but a framework which assists the algorithms to work. ANN is the most basic type of implementation of neurals. ANN was the term coined much earlier and nowadays the two terms are interchangeably used.\n"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a>\n# 4. In what situation does the algorithm fit best?\n\n#### ANN is rarely used for predictive modelling. The reason being that Artificial Neural Networks (ANN) usually tries to over-fit the relationship. ANN is generally used in cases where what has happened in past is repeated almost exactly in same way. For example, say we are playing the game of Black Jack against a computer. An intelligent opponent based on ANN would be a very good opponent in this case (assuming they can manage to keep the computation time low). With time ANN will train itself for all possible cases of card flow. And given that we are not shuffling cards with a dealer, ANN will be able to memorize every single call. Hence, it is a kind of machine learning technique which has enormous memory. But it does not work well in case where scoring population is significantly different compared to training sample. For instance, if I plan to target customer for a campaign using their past response by an ANN. I will probably be using a wrong technique as it might have over-fitted the relationship between the response and other predictors."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5\"></a>\n# 5. How does ANN work?\n#### It is truly said that the working of ANN takes its roots from the neural network residing in human brain. ANN operates on something referred to as Hidden State. These hidden states are similar to neurons. Each of these hidden state is a transient form which has a probabilistic behavior. A grid of such hidden state act as a bridge between the input and the output. \n#### We have an input layer which is the data we provide to the ANN. We have the hidden layers, which is where the magic happens. Lastly, we have the output layer, which is where the finished computations of the network are placed for us to use.\n\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"![](http://cdn-images-1.medium.com/max/600/1*f0hA2R652htmc1EaDrgG8g.png)"},{"metadata":{},"cell_type":"markdown","source":"#### Initially the weights of the network can be randomly. When the input in given to the input layer the process moves forward and the hidden layer receives the input combined with the weights. This process goes on till the final layer of output is reached and result is given. When the result is out it is compared to the actual value and a back propagation algorithm comes into play to adjust the weights of the network linkages to better the result. What do the neurons in the layers then do? They are responsible for the learning individually. They consist of activation function that allows the signal to pass or not depending on which activation function is being used and what input came from the previous layer. We'll see activation functions in detail now."},{"metadata":{},"cell_type":"markdown","source":"![](http://www.analyticsvidhya.com/blog/wp-content/uploads/2014/10/flowchart-ANN.png)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6\"></a>\n# 6. Activation Function\n#### Activation functions are really important for a Artificial Neural Network to learn and make sense of something really complicated and Non-linear complex functional mappings between the inputs and response variable.They introduce non-linear properties to our Network.Their main purpose is to convert a input signal of a node in a A-NN to an output signal. That output signal now is used as a input in the next layer in the stack.\n\n#### Specifically in A-NN we do the sum of products of inputs(X) and their corresponding Weights(W) and apply a Activation function f(x) to it to get the output of that layer and feed it as an input to the next layer.\n\n"},{"metadata":{},"cell_type":"markdown","source":"#### Most popular types of Activation functions -\n* Sigmoid or Logistic\n* Tanh — Hyperbolic tangent\n* ReLu -Rectified linear units\n\n**Sigmoid Activation function**: It is a activation function of form f(x) = 1 / 1 + exp(-x) . Its Range is between 0 and 1. It is a S — shaped curve. It is easy to understand and apply but it has major reasons which have made it fall out of popularity -\n\n* Vanishing gradient problem\n* Secondly , its output isn’t zero centered. It makes the gradient updates go too far in different directions. 0 < output < 1, and it makes optimization harder.\n* Sigmoids saturate and kill gradients.\n* Sigmoids have slow convergence.\n\n\n![](http://cdn-images-1.medium.com/max/1600/0*WYB0K0zk1MiIB6xp.png)\n\n\n\n**Hyperbolic Tangent function- Tanh** : It’s mathamatical formula is f(x) = 1 — exp(-2x) / 1 + exp(-2x). Now it’s output is zero centered because its range in between -1 to 1 i.e -1 < output < 1 . Hence optimization is easier in this method hence in practice it is always preferred over Sigmoid function . But still it suffers from Vanishing gradient problem.\n\n\n![](http://cdn-images-1.medium.com/max/1600/0*VHhGS4NwibecRjIa.png)\n\n**ReLu- Rectified Linear units** : It has become very popular in the past couple of years. It was recently proved that it had 6 times improvement in convergence from Tanh function. It’s just R(x) = max(0,x) i.e if x < 0 , R(x) = 0 and if x >= 0 , R(x) = x. Hence as seeing the mathamatical form of this function we can see that it is very simple and efficinent . A lot of times in Machine learning and computer science we notice that most simple and consistent techniques and methods are only preferred and are best. Hence it avoids and rectifies vanishing gradient problem . Almost all deep learning Models use ReLu nowadays.\n\nBut its limitation is that it should only be used within Hidden layers of a Neural Network Model.\n\nHence for output layers we should use a Softmax function for a Classification problem to compute the probabilites for the classes , and for a regression problem it should simply use a linear function.\n\nAnother problem with ReLu is that some gradients can be fragile during training and can die. It can cause a weight update which will makes it never activate on any data point again. Simply saying that ReLu could result in Dead Neurons.\n\nTo fix this problem another modification was introduced called Leaky ReLu to fix the problem of dying neurons. It introduces a small slope to keep the updates alive.\n\nWe then have another variant made form both ReLu and Leaky ReLu called Maxout function .\n\n![](http://cdn-images-1.medium.com/max/1600/0*qtfLu9rmtNullrVC.png)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7\"></a>\n# 7. What happens without activation function?\n#### If we do not apply a Activation function then the output signal would simply be a simple linear function.A linear function is just a polynomial of one degree. Now, a linear equation is easy to solve but they are limited in their complexity and have less power to learn complex functional mappings from data. A Neural Network without Activation function would simply be a Linear regression Model, which has limited power and does not performs good most of the times. We want our Neural Network to not just learn and compute a linear function but something more complicated than that. Also without activation function our Neural network would not be able to learn and model other complicated kinds of data such as images, videos , audio , speech etc. That is why we use Artificial Neural network techniques such as Deep learning to make sense of something complicated ,high dimensional,non-linear -big datasets, where the model has lots and lots of hidden layers in between and has a very complicated architecture which helps us to make sense and extract knowledge form such complicated big datasets."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"8\"></a>\n# 8. How are NNs different from classical models?\n#### To better understand artificial neural computing it is important to know first how a conventional 'serial' computer and it's software process information. A serial computer has a central processor that can address an array of memory locations where data and instructions are stored. Computations are made by the processor reading an instruction as well as any data the instruction requires from memory addresses, the instruction is then executed and the results are saved in a specified memory location as required. In a serial system (and a standard parallel one as well) the computational steps are deterministic, sequential and logical, and the state of a given variable can be tracked from one operation to another.\n\n#### In comparison, ANNs are not sequential or necessarily deterministic. There are no complex central processors, rather there are many simple ones which generally do nothing more than take the weighted sum of their inputs from other processors. ANNs do not execute programed instructions; they respond in parallel (either simulated or actual) to the pattern of inputs presented to it. There are also no separate memory addresses for storing data. Instead, information is contained in the overall activation 'state' of the network. 'Knowledge' is thus represented by the network itself, which is quite literally more than the sum of its individual components."},{"metadata":{},"cell_type":"markdown","source":"<a id='9'></a>\n# 9. Implementation"},{"metadata":{},"cell_type":"markdown","source":"#### A brief about the NN libraries:\n#### Theano is an open source numerical computation library based on numpy syntax. It can run not only on the CPU ( Central Processing Unit) but also the GPU (Graphical Processing Unit). GPU is a processor for graphic purposes somewhat similar to a graphic card. GPU is much more powerful in terms of efficiency etc. because it has more cores and is able to run more floating points calculations per second than the CPU. GPU is highly specialised for heavy, parallel computations which is a requirement in Neural Networks that we are about to see.\n#### How parallel computation comes into play in NNs? When we are forward propagating the different activations of neurons for the activation function or when we back propagate the error. Also calculations can be carried out faster this way. Theano was developed at the University of Montreal.\n\n#### Tensorflow is similar to Theano. It's been developed by Google.\n\n#### However the point to consider is that these two libraries are more towards the research and development side of Neural Networks. If we were to create a model from scratch and make some improvements in it, experiment or something these two would be great but right now we would be using Keras for beginning till we step up. Keras in some way wraps the two libraries for us and provides small and easy to implement modules of code."},{"metadata":{},"cell_type":"markdown","source":"<a id='10'></a>\n# 10. Business Problem and EDA\n\n#### Our Business problem which I have chosen for this tutorial is a classification problem wherein we have a dataset in which there are details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the dataset\nchurn_data = pd.read_csv('../input/Churn_Modelling.csv',index_col='RowNumber')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_data.info()","execution_count":4,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 10000 entries, 1 to 10000\nData columns (total 13 columns):\nCustomerId         10000 non-null int64\nSurname            10000 non-null object\nCreditScore        10000 non-null int64\nGeography          10000 non-null object\nGender             10000 non-null object\nAge                10000 non-null int64\nTenure             10000 non-null int64\nBalance            10000 non-null float64\nNumOfProducts      10000 non-null int64\nHasCrCard          10000 non-null int64\nIsActiveMember     10000 non-null int64\nEstimatedSalary    10000 non-null float64\nExited             10000 non-null int64\ndtypes: float64(2), int64(8), object(3)\nmemory usage: 1.1+ MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_data.describe()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"         CustomerId   CreditScore      ...       EstimatedSalary        Exited\ncount  1.000000e+04  10000.000000      ...          10000.000000  10000.000000\nmean   1.569094e+07    650.528800      ...         100090.239881      0.203700\nstd    7.193619e+04     96.653299      ...          57510.492818      0.402769\nmin    1.556570e+07    350.000000      ...             11.580000      0.000000\n25%    1.562853e+07    584.000000      ...          51002.110000      0.000000\n50%    1.569074e+07    652.000000      ...         100193.915000      0.000000\n75%    1.575323e+07    718.000000      ...         149388.247500      0.000000\nmax    1.581569e+07    850.000000      ...         199992.480000      1.000000\n\n[8 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CustomerId</th>\n      <th>CreditScore</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.000000e+04</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.00000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.569094e+07</td>\n      <td>650.528800</td>\n      <td>38.921800</td>\n      <td>5.012800</td>\n      <td>76485.889288</td>\n      <td>1.530200</td>\n      <td>0.70550</td>\n      <td>0.515100</td>\n      <td>100090.239881</td>\n      <td>0.203700</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>7.193619e+04</td>\n      <td>96.653299</td>\n      <td>10.487806</td>\n      <td>2.892174</td>\n      <td>62397.405202</td>\n      <td>0.581654</td>\n      <td>0.45584</td>\n      <td>0.499797</td>\n      <td>57510.492818</td>\n      <td>0.402769</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.556570e+07</td>\n      <td>350.000000</td>\n      <td>18.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>11.580000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.562853e+07</td>\n      <td>584.000000</td>\n      <td>32.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>51002.110000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.569074e+07</td>\n      <td>652.000000</td>\n      <td>37.000000</td>\n      <td>5.000000</td>\n      <td>97198.540000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>100193.915000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.575323e+07</td>\n      <td>718.000000</td>\n      <td>44.000000</td>\n      <td>7.000000</td>\n      <td>127644.240000</td>\n      <td>2.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>149388.247500</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.581569e+07</td>\n      <td>850.000000</td>\n      <td>92.000000</td>\n      <td>10.000000</td>\n      <td>250898.090000</td>\n      <td>4.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>199992.480000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_data.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"           CustomerId   Surname  ...    EstimatedSalary Exited\nRowNumber                        ...                          \n1            15634602  Hargrave  ...          101348.88      1\n2            15647311      Hill  ...          112542.58      0\n3            15619304      Onio  ...          113931.57      1\n4            15701354      Boni  ...           93826.63      0\n5            15737888  Mitchell  ...           79084.10      0\n\n[5 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CustomerId</th>\n      <th>Surname</th>\n      <th>CreditScore</th>\n      <th>Geography</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n    <tr>\n      <th>RowNumber</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>15634602</td>\n      <td>Hargrave</td>\n      <td>619</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15647311</td>\n      <td>Hill</td>\n      <td>608</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>41</td>\n      <td>1</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15619304</td>\n      <td>Onio</td>\n      <td>502</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>8</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15701354</td>\n      <td>Boni</td>\n      <td>699</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>15737888</td>\n      <td>Mitchell</td>\n      <td>850</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>2</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# some columns are totally unproductive so let's remove them\nchurn_data.drop(['CustomerId','Surname'],axis=1,inplace=True)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_data.head()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"           CreditScore Geography   ...   EstimatedSalary  Exited\nRowNumber                          ...                          \n1                  619    France   ...         101348.88       1\n2                  608     Spain   ...         112542.58       0\n3                  502    France   ...         113931.57       1\n4                  699    France   ...          93826.63       0\n5                  850     Spain   ...          79084.10       0\n\n[5 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CreditScore</th>\n      <th>Geography</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n    <tr>\n      <th>RowNumber</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>619</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>608</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>41</td>\n      <td>1</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>502</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>8</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>699</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>850</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>2</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# some columns have text data so let's one hot encode them\n#  for more on one hot encoding click this link below\n# https://www.kaggle.com/shrutimechlearn/types-of-regression-and-stats-in-depth\nGeography_dummies = pd.get_dummies(prefix='Geo',data=churn_data,columns=['Geography'])","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Geography_dummies.head()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"           CreditScore  Gender    ...      Geo_Germany  Geo_Spain\nRowNumber                         ...                            \n1                  619  Female    ...                0          0\n2                  608  Female    ...                0          1\n3                  502  Female    ...                0          0\n4                  699  Female    ...                0          0\n5                  850  Female    ...                0          1\n\n[5 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CreditScore</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n      <th>Geo_France</th>\n      <th>Geo_Germany</th>\n      <th>Geo_Spain</th>\n    </tr>\n    <tr>\n      <th>RowNumber</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>619</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>608</td>\n      <td>Female</td>\n      <td>41</td>\n      <td>1</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>502</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>8</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>699</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>850</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>2</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Gender_dummies = Geography_dummies.replace(to_replace={'Gender': {'Female': 1,'Male':0}})","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Gender_dummies.head()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"           CreditScore  Gender    ...      Geo_Germany  Geo_Spain\nRowNumber                         ...                            \n1                  619       1    ...                0          0\n2                  608       1    ...                0          1\n3                  502       1    ...                0          0\n4                  699       1    ...                0          0\n5                  850       1    ...                0          1\n\n[5 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CreditScore</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n      <th>Geo_France</th>\n      <th>Geo_Germany</th>\n      <th>Geo_Spain</th>\n    </tr>\n    <tr>\n      <th>RowNumber</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>619</td>\n      <td>1</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>608</td>\n      <td>1</td>\n      <td>41</td>\n      <td>1</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>502</td>\n      <td>1</td>\n      <td>42</td>\n      <td>8</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>699</td>\n      <td>1</td>\n      <td>39</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>850</td>\n      <td>1</td>\n      <td>43</td>\n      <td>2</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_data_encoded = Gender_dummies","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(y=churn_data_encoded.Exited ,data=churn_data_encoded)\nplt.xlabel(\"Count of each Target class\")\nplt.ylabel(\"Target classes\")\nplt.show()","execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYQAAAESCAYAAAD9gqKNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHpxJREFUeJzt3XtUVXXi9/EPV+9XRCW10XGUMDMRknRUEhBSEWg0NcPGW64Rsxx1En95yYz15GSpmViN2cyUT7XMMjUr75q28srIQ2oqZWIiGGAq98v3+aPT+cmkuEXP4Wjv11quBXuzz/6cveV82Hc3Y4wRAOA3z72mAwAAXAOFAACQRCEAAGwoBACAJAoBAGBDIQAAJFEIAAAbCgEAIIlCAADYUAgAAEkUAgDAhkIAAEiiEAAANp41HcCqvLx8VVS45o1ZfXzqKyfnUk3HuCry3Rjy3Rjy3Zjq5nN3d1OTJvWua5pbphAqKozLFoIkl84mke9Gke/GkO/GOCsfu4wAAJIoBACADYUAAJBEIQAAbCgEAIAkCgEAYEMhAAAkUQgAABs3Y4xrX5EBAL9RRcWlql3LS+fOXbzuad3d3eTjU/+6prllrlR+8v+s0Y95+TUdAwCc5v/+/VGnzo9dRgAASRQCAMCGQgAASKIQAAA2FAIAQBKFAACwoRAAAJIoBACADYUAAJBEIQAAbCgEAIAkCgEAYEMhAAAkUQgAABsKAQAgiUIAANhQCAAASRQCAMCGQgAASKIQAAA2FAIAQBKFAACwoRAAAJIoBACADYUAAJBEIQAAbCgEAIAkCgEAYEMhAAAkUQgAABsKAQAgiUIAANhQCAAASRQCAMCGQgAASKIQAAA2FAIAQBKFAACwcVohfPfddxo2bJiioqI0bNgwnTx50lmzBgBY4LRCmDNnjkaMGKHPP/9cI0aM0OzZs501awCABU4phJycHB0+fFjR0dGSpOjoaB0+fFi5ubnOmD0AwAKnFEJmZqZatGghDw8PSZKHh4eaN2+uzMxMZ8weAGABB5UBAJKcVAh+fn7KyspSeXm5JKm8vFzZ2dny8/NzxuwBABY4pRB8fHwUEBCg9evXS5LWr1+vgIAANW3a1BmzBwBY4OmsGT377LNKTExUcnKyGjZsqPnz5ztr1gAAC5xWCO3bt9eqVaucNTsAwHXioDIAQBKFAACwoRAAAJIoBACADYUAAJBEIQAAbCgEAIAki9chHDhwQC1btlSrVq2Uk5OjxYsXy83NTU899RRXGwPAbcLSFsLs2bNljJEkvfDCCzp//rwKCgp4pgEA3EYsbSGcPXtWrVu3Vnl5uXbu3KktW7bI29tbvXv3dnQ+AICTWCqEOnXqKDc3V8ePH1e7du1Uv359lZSUqKyszNH5AABOYqkQHnnkEQ0dOlTFxcWaOnWqJOnQoUNq27atI7MBAJzIUiFMnDhR4eHh8vT01B/+8AdJUtOmTfXcc885NBwAwHksn3basWNHFRQUaPPmzZKk1q1bq0OHDg4LBgBwLktbCOnp6UpISFBpaany8vKUkpKi3bt365NPPtFLL73k6IwAACewtIUwZ84cjRs3Tlu3bpWn588dEhISon379jk0HADAeSwVwjfffKMhQ4ZIktzc3CRJ9erVU2FhoeOSAQCcylIh+Pn56ejRo5WGpaWlqU2bNg4JBQBwPkvHECZNmqTx48crPj5epaWl+uc//6m3335bM2fOdHQ+AICTWCqEfv36ydfXV++//766dOmio0eP6sUXX1S3bt0cnQ8A4CSWCkGSunbtqq5duzoyCwCgBlk6hvDOO+/YjyGkpaUpKipK/fv3V2pqqkPDAQCcx1IhvPnmm/Lz85MkLViwQIMHD1Z8fLySkpIcGg4A4DyWdhn99NNPatSokfLz83X48GEtX75cHh4eWrhwoaPzAQCcxFIhtGjRQmlpaTp+/Li6desmT09PXbp0SR4eHo7OBwBwEkuFMHXqVI0dO1aenp5KTk6WJO3cuVOdO3d2aDgAgPNYKoSIiAhFRERUGta3b1/17dvXIaEAAM5n6aDyyZMnlZubK0kqLCzU66+/rrffflvu7pZvlgoAcHGWPtEnT56svLw8SdKLL76o7du3a9euXZo7d65DwwEAnMfSLqPTp0+rffv2Msbo888/19q1a1WrVi1FRkY6Oh8AwEksFYKXl5cKCgp04sQJNW/eXD4+PiovL1dRUZGj8wEAnMRSITz44IMaM2aM8vPzNXjwYEnSkSNH1KpVK4eGAwA4j6VCmDVrlrZt2yZPT0+FhoZKksrLy/X00087NBwAwHksFYK7u7vCw8MrDbv33nsdEggAUDMsFUJFRYVWrVqlvXv36vz58zLG2MetWLHCYeEAAM5j6bTT+fPna8WKFfL399fBgwd1//33KyMjQ/fcc4+j8wEAnMRSIXz66adavny5xo8fL3d3d40fP17JyclKSUlxdD4AgJNYKoTCwkL785Nr166toqIidejQQWlpaQ4NBwBwHkvHENq1a6e0tDR17txZnTp10muvvaYGDRrI19fX0fnsXpkR57R5AYArKCouVe1aXk6bn5u5/AjxVRw8eFCenp7q0qWL0tPTNXPmTOXn52vGjBnq0aOHM3IqJ+eSKiquGbVG+Po20LlzF2s6xlWR78aQ78aQ78ZUN5+7u5t8fOpf1zSWthC6detm/7p9+/Z69913ry8ZAMDlXbUQDh48aOkFLi8LAMCt66qF8OSTT1p6gV27dt20MACAmnPVQuCDHgB+Wyyddnr8+HFlZWVVGpaVlaUTJ044JBQAwPksFcLUqVNVWFhYaVhhYaGmTp3qkFAAAOezVAinT59W27ZtKw1r27atMjIyHJEJAFADLBVCixYtdPTo0UrDjh496tQL0wAAjmXpOoT4+HglJCRowoQJat26tTIyMvTGG29o9OjRjs4HAHASS4Xw6KOPql69elq9erUyMzPl5+enSZMmKTY21tH5AABOYqkQJCkuLk5xcdxPCABuV5aOIQAAbn8UAgBAEoUAALCxVAhbtmy54vBt27bd1DAAgJpjqRD+9re/XXH49OnTb2oYAEDNqfIso1/uX2SMUXZ2ti5/lk5GRoa8vJz3JB8AgGNVWQihoaFyc3OTJPXp06fSuIYNG1q+RTYAwPVVWQipqakyxig+Pl4rV66sNM7b29uhwQAAzlVlIfzyob9q1SpJUm5urs6ePatOnTo5Ptl/ud5ngzqbr2+Dmo5QpSaNvJX3U0lNxwDgwixdqZydna1p06bp4MGD8vLyUkpKijZu3Kgvv/xSzz77rIMj/uz/vTZdJRdynDKv21HQ08slUQgArs7SWUazZ89WUFCQUlJS5On5c4eEhIRo586dDg0HAHAeS1sIKSkpWrp0qTw8POwHmRs1aqQLFy44NBwAwHksbSE0adJEP/zwQ6Vh3333nVq2bOmQUAAA57NUCKNGjdKECRO0fv16lZeXa9OmTZoyZQrPQwCA24ilXUbDhw9Xw4YN9d5776lJkyb697//rXHjxmngwIGOzgcAcBLLz0MYMGCABgwY4MgsAIAaZKkQ1q1bd8Xh3t7eatmype6++2772UcAgFuTpU/xd955R19//bUaNmyoFi1aKCsrSxcuXFDHjh115swZ1a1bV6+++mqNXLAGALg5LBXCvffeq379+mns2LFyc3OTMUYrVqxQdna2nn76aS1ZskTz5s3Tu+++6+i8AAAHsXSW0Zo1azR69Gj7NQhubm4aNWqUPvroI3l4eGjChAk6fvy4Q4MCABzL8nUIu3btqjRs9+7daty4sSSptLRUHh4eNz8dAMBpLO0ymjFjhiZPnqwuXbrIz89PmZmZSk1N1csvvyxJOnjwoIYNG+bQoAAAx7JUCA888IA2btyobdu2KTs7W4GBgVqwYIF8fX0l/fyshP9+XgIA4NZyzUIoLy/XoEGDtGbNGg0dOtQZmQAANeCaxxA8PDxUWlqqkhJunQwAtzNLB5XHjBmjadOm6dChQ8rKyqr0DwBwe7B0DGHu3LmSpO3bt1ca7ubmpiNHjtz0UAAA57NUCKmpqY7OAQCoYZYK4ZdnKwMAbl+WCqGiokKrVq3S3r17df78eRlj7ONWrFjhsHAAAOexdFB5/vz5WrFihfz9/XXw4EHdf//9ysjI0D333OPofAAAJ7FUCJ9++qmWL1+u8ePHy93dXePHj1dycrJSUlIcnQ8A4CSWCqGwsFBt2rSRJNWuXVtFRUXq0KGD0tLSHBoOAOA8lo4htGvXTmlpaercubM6deqk1157TQ0aNLDfugIAcOuztIWQmJhoP5CcmJioPXv2aO3atfbrEwAAt74qtxDWr1+v6OhodevWzT6sffv2PAgHAG5DVW4hzJ4921k5AAA1rMpCuPx6AwDA7a3KXUYVFRX66quvqiyGHj163PRQAADnq7IQSkpK9Mwzz1y1ENzc3LRlyxaHBAMAOFeVhVCnTh0+8AHgN8LSaacAgNsfB5UBAJKuUQjcqwgAfjvYZQQAkEQhAABsKAQAgCQKAQBg45RCmD9/vsLCwuTv769jx445Y5YAgOvklEIIDw/XypUr1apVK2fMDgBQDZYekHOjgoODnTEbAMAN4BgCAEAShQAAsKEQAACSKAQAgI1TCuH5559Xnz59dPbsWY0ePVoDBw50xmwBANfBKWcZzZw5UzNnznTGrAAA1cQuIwCAJAoBAGBDIQAAJFEIAAAbCgEAIIlCAADYUAgAAEkUAgDAhkIAAEiiEAAANhQCAEAShQAAsKEQAACSKAQAgA2FAACQRCEAAGwoBACAJAoBAGBDIQAAJFEIAAAbCgEAIIlCAADYUAgAAEkUAgDAhkIAAEiiEAAANhQCAEAShQAAsKEQAACSKAQAgA2FAACQRCEAAGwoBACAJAoBAGBDIQAAJFEIAAAbCgEAIIlCAADYeNZ0AKvu+cv8mo5wSysrKa7pCABc3C1TCDk5l1RRYWo6xhX5+jbQuXMXazrGVfn6NlDeTyU1HQOAi2OXEQBAEoUAALChEAAAkigEAIANhQAAkEQhAABsKAQAgCQKAQBgc8tcmObu7lbTEapEvhtDvhtDvhtzO+arzjRuxhjXvPwXAOBU7DICAEiiEAAANhQCAEAShQAAsKEQAACSKAQAgA2FAACQRCEAAGwoBACAJBcvhO+++07Dhg1TVFSUhg0bppMnTzp8nvPnz1dYWJj8/f117NgxS1mqO6468vLy9PjjjysqKkqDBg3SE088odzcXEnSf/7zH8XExCgqKkpjxoxRTk6OfbrqjquOhIQExcTEKC4uTiNGjNCRI0ckuc4ylKRXX3210jp2lWUnSWFhYXrwwQcVGxur2NhYffHFFy6Vsbi4WHPmzFFkZKQGDRqkWbNmSXKN9Xv69Gn7couNjVVYWJi6d+/uMvkkadu2bYqLi1NsbKxiYmK0ceNG18lnXNjIkSPNmjVrjDHGrFmzxowcOdLh89y3b585c+aM6du3r/nmm28sZanuuOrIy8szX331lf37F154wcyYMcOUl5ebiIgIs2/fPmOMMUuXLjWJiYnGGFPtcdV14cIF+9ebNm0ycXFxxhjXWYZpaWlm7Nix9nXsSsvOGPOr/3s3ksMRGefNm2eSkpJMRUWFMcaYc+fOGWNcZ/1e7vnnnzdz5851mXwVFRUmODjYvn6PHDliunbtasrLy10in8sWwo8//miCgoJMWVmZMcaYsrIyExQUZHJycpwy/8t/KavKUt1xN8tnn31m/vznP5tDhw6ZgQMH2ofn5OSYrl27GmNMtcfdDB999JF56KGHXGYZFhcXm6FDh5qMjAz7Ona1ZXelQnCVjJcuXTJBQUHm0qVLlYa7yvq9XHFxsQkJCTFpaWkuk6+iosJ0797d7N+/3xhjzN69e01kZKTL5HPZu51mZmaqRYsW8vDwkCR5eHioefPmyszMVNOmTV0mizGmWuNuxnuoqKjQu+++q7CwMGVmZuqOO+6wj2vatKkqKip0/vz5ao9r3LhxtbM988wz2r17t4wxWr58ucssw8WLFysmJkatW7e2D3O1ZSdJ06ZNkzFGQUFBmjJlistkzMjIUOPGjfXqq69qz549qlevnp566inVrl3bJdbv5bZu3aoWLVro7rvvVlpamkvkc3Nz06JFi5SQkKC6desqPz9fb7zxhsv8frj0MQRUbd68eapbt67i4+NrOsqvJCUlafv27frrX/+qv//97zUdR5KUkpKitLQ0jRgxoqajVGnlypVau3atVq9eLWOMnnvuuZqOZFdeXq6MjAx16tRJH374oaZNm6ZJkyapoKCgpqP9yurVqzV48OCajlFJWVmZXn/9dSUnJ2vbtm1atmyZJk+e7DLLz2ULwc/PT1lZWSovL5f083/E7Oxs+fn5uVSW6o67UfPnz9f333+vRYsWyd3dXX5+fjpz5ox9fG5urtzd3dW4ceNqj7sZ4uLitGfPHrVs2bLGl+G+ffuUnp6u8PBwhYWF6ezZsxo7dqy+//57l1p2v7w3b29vjRgxQgcPHnSZ9evn5ydPT09FR0dLku699141adJEtWvXrvH1e7msrCzt27dPgwYNsud2hXxHjhxRdna2goKCJElBQUGqU6eOatWq5RL5XLYQfHx8FBAQoPXr10uS1q9fr4CAAKfvLrpWluqOuxEvv/yy0tLStHTpUnl7e0uSOnfurKKiIu3fv1+S9N577+nBBx+8oXHVkZ+fr8zMTPv3W7duVaNGjVxiGY4fP167du3S1q1btXXrVrVs2VJvvvmmxo0b5xLLTpIKCgp08eJFSZIxRhs2bFBAQIDLrN+mTZsqJCREu3fvlvTzGS45OTlq27Ztja/fy3300UcKDQ1VkyZNJLnO73DLli119uxZffvtt5Kk9PR05eTk6He/+51L5HPZg8rGGHPixAkzZMgQExkZaYYMGWLS09MdPs958+aZ3r17m4CAANOzZ08zYMCAa2ap7rjqOHbsmOnYsaOJjIw0MTExJiYmxiQkJBhjjDlw4ICJjo42/fr1M6NGjbKf/XEj467XuXPnzMMPP2yio6NNTEyMGTlypElLSzPGuM4y/MXlB29dYdkZY8ypU6dMbGysiY6ONgMGDDCTJk0yWVlZLpcxPj7eREdHm7i4OLN9+3ZjjGut38jISLNjx45Kw1wl38cff2yio6PNoEGDzKBBg8ymTZtcJh9PTAMASHLhXUYAAOeiEAAAkigEAIANhQAAkEQhAABsKATcsjZt2qTQ0FAFBgbq8OHDTplnYmKiFi5c6JR5uYr09HR16tSppmPACSgEaN26dfrTn/6kwMBA9erVS+PGjbNfyORI/v7++v7776s9/fz58zVr1iylpKS43AfW/v37FRgYqMDAQHXt2lX+/v727wMDAytdPewMO3fuVL9+/Zw6T9x6XPbmdnCOt956S2+88Ybmzp2rXr16ycvLS1988YW2bNmi4ODgmo5XpTNnzqhDhw41HeOKgoODlZKSIunne/SHh4dr37598vSs3q9cWVlZtacFrGIL4Tfs4sWLeuWVVzR79mxFRkaqbt268vLyUlhYmKZPny5JKikpUVJSknr16qVevXopKSlJJSUlkqQPP/xQjzzySKXXvPyv/sTERM2dO1fjx49XYGCgHn74YZ06dUqS9Oijj0qSYmNjFRgYqA0bNvwqX0VFhZKTk9W3b1/16NFDTz/9tC5evKiSkhIFBgaqvLxcsbGxioiIuOL7S09P1+jRo9W9e3dFRUVVmsf27dsVFxenbt26KTQ0VEuWLKk07f79+zV8+HAFBwcrNDRUH374oX3chQsXrviertcvt5EIDAxUv3799MEHH9jH/fIX/dKlS9WzZ089++yzkqTk5GT17NlTffr00fvvvy9/f3+dPXtWklRUVKSkpCSFhobqj3/8o+bNm6eSkhLl5eXpiSeeUEZGhn0LJS8v71d5CgoK9Pzzzys0NFRBQUGKj49XWVnZdeU+d+6cxo4dq+DgYIWEhOixxx6zj1u6dKl69eqlbt26qX///k7ZCsV1qvY1zrjl7dixwwQEBJjS0tKr/syiRYvMww8/bH788UeTk5Njhg0bZhYuXGiMMWb16tVm+PDhlX6+Y8eO5uTJk8YYY6ZPn266d+9uDh06ZEpLS82UKVPM5MmTr/izV7Jq1SoTERFhTp06ZS5dumQmTpxopk2bZmn6/Px806dPH/PBBx+Y0tJS8/XXX5vu3bub48ePG2OM+eqrr8zRo0dNeXm5OXLkiOnRo4f9FgKnT582Xbt2NevWrTMlJSUmNzfXHD582NJ7upKMjAzTsWPHXy3nzZs3m1OnTpmKigqze/duc88995hjx44ZY/533SxatMgUFxebwsJCs2nTJtO7d2+Tnp5u8vPzzZNPPmk6duxoMjMzjTHGzJ4920yaNMn89NNP5sKFC2bMmDFmyZIl9teLiIioMueMGTPM6NGjTXZ2tikrKzP79u0zZWVl5sSJEyYgIMBS7qSkJDNv3jxTWlpqiouLzd69e40xPz8IJiwszJw7d85UVFSYU6dOmVOnTlWZB87HFsJv2Pnz59WkSZMqd0WsW7dOEydOlI+Pj5o2baqJEydq7dq1lucRERGhLl26yNPTUzExMfbHaVqxbt06jRo1Sm3atFG9evU0ZcoUbdiw4Yp/tf637du3q1WrVho8eLA8PT3VqVMnRUVF6bPPPpMkhYSEyN/fX+7u7rrrrrs0cOBA7d27V9LPNwjr2bOnoqOj5eXlpSZNmiggIOCmvKfLhYeHq02bNnJzc1PPnj1133336cCBA/bx3t7eSkhIkLe3t2rXrq1PP/1UQ4cO1e9//3vVrVtXEydOtP9sWVmZVq9erWeeeUYNGzZUgwYN9Pjjj+uTTz6xlKW0tFQff/yxZs6cKV9fX3l4eCg4ONh+n32ruT09PZWdna3MzEx5e3vrvvvuk/TzffqLi4t14sQJlZeXq02bNmrTpk21lhsch52Sv2GNGzdWXl5elfuns7OzKz1g5Y477lB2drbleTRr1sz+de3ata/rvu/Z2dlq1aqV/ftWrVqprKxMOTk5atGiRZXT/vDDD0pNTa10HKS8vFwxMTGSpEOHDmnBggU6fvy4SktLVVJSYr8LaGZmpu68806HvKfLbdmyRcuWLdOpU6dUUVGhoqKiSnmbNWsmLy8v+/fZ2dnq0aOH/fvLb3GcnZ2t0tJSDRw40D7MGGP5uMO5c+dUVlZW5fu2knvChAlavHixHnvsMXl6emrEiBEaPXq0OnTooKlTp2rRokX69ttv1bt3b82YMaPSskTNYwvhNywwMFDe3t7avHnzVX+mefPmlc6IyczMVPPmzSVJderUUVFRkX3cuXPnbmq+5s2b64cffrB/f+bMGXl6esrHx+ea0/r5+em+++7T/v377f9SUlI0d+5cSdLUqVMVHh6uHTt26MCBAxo+fLiM7T6Pfn5+1T4uYFVBQYGeeuopJSQk6Msvv9T+/fsVEhJizyD9/HSty/n6+tqPF0iqdJtxX19feXp6atOmTfb3e+DAAe3Zs+eKr/Xffpn+Wu/7WrkbNGigmTNnatu2bVqyZImWLVtm33p46KGH9N5772nz5s0qKSnRokWLLCwpOBOF8BvWoEEDPfnkk3ruuee0efNmFRYWqrS0VDt27LA/5WzgwIFatmyZcnNzlZubq6VLl9ofOnLXXXfp+PHjOnLkiIqLi391YPZamjVrpoyMjKuOj46O1r/+9S9lZGQoPz9fCxcuVP/+/S391fvAAw/o5MmTWrNmjUpLS1VaWqrU1FSlp6dL+vm5DY0aNVKtWrWUmppqv5+8JA0aNEhffvmlffdUXl5etXcLXU1RUZHKysrk4+Mjd3d3bdmyxb7L6mr69++vDz74QCdPnlRBQYGWLVtmH+fl5aXBgwcrKSlJubm5MsYoMzPT/tyCZs2aKScnR/n5+Vd8bS8vL8XGxiopKUk//vijysvLtX//fvuDV6zm3rJlizIyMmSMUf369eXu7i53d3edOHFCe/fuVUlJiWrXrq1atWrJ3Z2PH1fDGvmNGzNmjBITE5WcnKwePXrogQce0MqVK+1n7iQkJKhz586KiYlRTEyM7r77biUkJEiS2rVrp4kTJ2rUqFGKjIy0PwXKqieeeEKJiYkKDg6+4llGgwcPVkxMjOLj4xUeHi5vb2/NmjXL0mvXr19fb775pjZs2KDevXurV69eWrBggf0MqTlz5uiVV15RYGCgli5dqv79+9unveOOO/SPf/xDb731lrp37664uDgdPXr0ut7btTRt2lTTp0/XX/7yF4WEhGjz5s0KDQ2tcpp+/fppyJAheuSRRxQVFWXfTfPLQ5L+53/+R82bN9eQIUMUFBSkcePG2c/4uuuuuxQWFqawsDAFBwfr/Pnzv3r9mTNn6s4771RcXJxCQkK0ePHiSlssVnKnp6frscceU7du3RQfH68xY8YoMDBQRUVFeuGFFxQSEqJevXrZtzTgWngeAnCLOnz4sIYNG6bU1NRr7hICrGALAbiFbNy4USUlJcrNzdVLL72kiIgIygA3DVsIwC1k5MiR+vrrr+Xl5aWQkBDNmTPH0kF2wAoKAQAgiV1GAAAbCgEAIIlCAADYUAgAAEkUAgDAhkIAAEiS/j+pj4qopj6MAAAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_data_encoded.hist(figsize=(15,12),bins = 15)\nplt.title(\"Features Distribution\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\np=sns.heatmap(churn_data_encoded.corr(), annot=True,cmap='RdYlGn',center=0) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(nrows = 4, ncols=3, figsize=(30,30))\nrow = 0\ncol = 0\nfor i in range(len(churn_data_encoded.columns) -1):\n    if col > 2:\n        row += 1\n        col = 0\n    axes = ax[row,col]\n    sns.boxplot(x = churn_data_encoded['Exited'], y = churn_data_encoded[churn_data_encoded.columns[i]],ax = axes)\n    col += 1\nplt.tight_layout()\n# plt.title(\"Individual Features by Class\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = churn_data_encoded.drop(['Exited'],axis=1)\ny = churn_data_encoded.Exited","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head(10)","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"           CreditScore  Gender    ...      Geo_Germany  Geo_Spain\nRowNumber                         ...                            \n1                  619       1    ...                0          0\n2                  608       1    ...                0          1\n3                  502       1    ...                0          0\n4                  699       1    ...                0          0\n5                  850       1    ...                0          1\n6                  645       0    ...                0          1\n7                  822       0    ...                0          0\n8                  376       1    ...                1          0\n9                  501       0    ...                0          0\n10                 684       0    ...                0          0\n\n[10 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CreditScore</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Geo_France</th>\n      <th>Geo_Germany</th>\n      <th>Geo_Spain</th>\n    </tr>\n    <tr>\n      <th>RowNumber</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>619</td>\n      <td>1</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>608</td>\n      <td>1</td>\n      <td>41</td>\n      <td>1</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>502</td>\n      <td>1</td>\n      <td>42</td>\n      <td>8</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>699</td>\n      <td>1</td>\n      <td>39</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>850</td>\n      <td>1</td>\n      <td>43</td>\n      <td>2</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>645</td>\n      <td>0</td>\n      <td>44</td>\n      <td>8</td>\n      <td>113755.78</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>149756.71</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>822</td>\n      <td>0</td>\n      <td>50</td>\n      <td>7</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10062.80</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>376</td>\n      <td>1</td>\n      <td>29</td>\n      <td>4</td>\n      <td>115046.74</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>119346.88</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>501</td>\n      <td>0</td>\n      <td>44</td>\n      <td>4</td>\n      <td>142051.07</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>74940.50</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>684</td>\n      <td>0</td>\n      <td>27</td>\n      <td>2</td>\n      <td>134603.88</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>71725.73</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 0)\n","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Scaling because yes we don't want one independent variable dominating the other and it makes computations easy\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":18,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/opt/conda/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n  return self.fit(X, **fit_params).transform(X)\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n  \"\"\"\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sequential model to initialise our ann and dense module to build the layers\nfrom keras.models import Sequential\nfrom keras.layers import Dense","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = Sequential()\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n\n# Adding the second hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n\n# Compiling the ANN | means applying SGD on the whole ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nclassifier.fit(X_train, y_train, batch_size = 10, epochs = 100,verbose = 0)\n\nscore, acc = classifier.evaluate(X_train, y_train,\n                            batch_size=10)\nprint('Train score:', score)\nprint('Train accuracy:', acc)\n# Part 3 - Making predictions and evaluating the model\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)\n\nprint('*'*20)\nscore, acc = classifier.evaluate(X_test, y_test,\n                            batch_size=10)\nprint('Test score:', score)\nprint('Test accuracy:', acc)\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='11'></a>\n# 11. Evaluation Metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"p = sns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import classification_report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\ny_pred_proba = classifier.predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='ANN')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('ROC curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Area under ROC curve\nfrom sklearn.metrics import roc_auc_score\nroc_auc_score(y_test,y_pred_proba)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='12'></a>\n# 12. Evaluation of Multiple Training Instances"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Part 4 - Evaluating, Improving and Tuning the ANN\n\n# Evaluating the ANN\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential\nfrom keras.layers import Dense\ndef build_classifier():\n    classifier = Sequential()\n    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return classifier\nclassifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 100,verbose=0)\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\nmean = accuracies.mean()\nvariance = accuracies.std()","execution_count":21,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-59ac02c5ead2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean accuracy score of 10 different models using Kfold cross validation: {}'.format(mean))\nprint('Standard Deviation of accuracy score of 10 different models using Kfold cross validation: {}'.format(variance))","execution_count":22,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'mean' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-fe80157fb2b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean accuracy score of 10 different models using Kfold cross validation: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Standard Deviation of accuracy score of 10 different models using Kfold cross validation: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"]}]},{"metadata":{},"cell_type":"markdown","source":"#### Deviation is very low so I'd say that it is unlikely to be an overfitted model. With different training sets it got the mean with all training results is still very close to the above model."},{"metadata":{},"cell_type":"markdown","source":"<a id='13'></a>\n# 13. Improving ANN with Dropout layer"},{"metadata":{},"cell_type":"markdown","source":"#### Dropout Regularization is used to reduce overfitting if needed.\n\n#### p is the fraction of input units to drop. If suppose there are ten neurons from a layer and p is 0.1 then one of the neurons would be disabled and its output would not be sent to the further layer.\n#### It is advisable to start with p 0.1 and move to higher values when in case the overfitting problem persists. Also going over 0.5 is not advisable generally because it may cause underfitting as most of the neurons are disabled.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Improving the ANN\nfrom keras.layers import Dropout\nclassifier = Sequential()\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\nclassifier.add(Dropout(rate = 0.1))\n\n# Adding the second hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\nclassifier.add(Dropout(rate = 0.1))\n\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nclassifier.fit(X_train, y_train, batch_size = 10, epochs = 100,verbose = 0)\n\n# Part 3 - Making predictions and evaluating the model\n\nscore, acc = classifier.evaluate(X_train, y_train,\n                            batch_size=10)\nprint('Train score:', score)\nprint('Train accuracy:', acc)\n# Part 3 - Making predictions and evaluating the model\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)\n\nprint('*'*20)\nscore, acc = classifier.evaluate(X_test, y_test,\n                            batch_size=10)\nprint('Test score:', score)\nprint('Test accuracy:', acc)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = sns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import classification_report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\ny_pred_proba = classifier.predict_proba(X_test)\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr,tpr, label='ANN')\nplt.xlabel('fpr')\nplt.ylabel('tpr')\nplt.title('ROC curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Area under ROC curve\nfrom sklearn.metrics import roc_auc_score\nroc_auc_score(y_test,y_pred_proba)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='14'></a>\n# 14. Tuning the ANN"},{"metadata":{},"cell_type":"markdown","source":"#### Let's test 2 values of the batch size and we're gonna try 25 and 32. So why 25 and 32? Well, that's based on my experience and that's also common practice to take powers of 2. Well, you can try other values of the batch size as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Tuning the ANN\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom keras.models import Sequential\nfrom keras.layers import Dense\ndef build_classifier(optimizer):\n    classifier = Sequential()\n    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return classifier\nclassifier = KerasClassifier(build_fn = build_classifier)\nparameters = {'batch_size': [25, 32],\n              'epochs': [100, 200],\n              'optimizer': ['adam', 'rmsprop']}\ngrid_search = GridSearchCV(estimator = classifier,\n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           cv = 10)\ngrid_search = grid_search.fit(X_train, y_train,verbose = 0)\nbest_parameters = grid_search.best_params_\nbest_accuracy = grid_search.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Best Parameters after tuning: {}'.format(best_parameters))\nprint('Best Accuracy after tuning: {}'.format(best_accuracy))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Big Thanks to\n* https://www.techopedia.com/definition/5967/artificial-neural-network-ann\n* https://www.digitaltrends.com/cool-tech/what-is-an-artificial-neural-network/\n* https://www.analyticsvidhya.com/blog/2014/10/ann-work-simplified/\n* https://www.analyticsvidhya.com/blog/2014/10/introduction-neural-network-simplified/\n* https://medium.com/technology-invention-and-more/everything-you-need-to-know-about-artificial-neural-networks-57fac18245a1\n* http://pages.cs.wisc.edu/~bolo/shipyard/neural/local.html\n* https://towardsdatascience.com/activation-functions-and-its-types-which-is-better-a9a5310cc8f"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}