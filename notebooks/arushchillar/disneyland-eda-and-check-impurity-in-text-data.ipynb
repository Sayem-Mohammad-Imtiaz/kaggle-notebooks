{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd # dataframe manipulation\nimport numpy as np # linear algebra\n#------------------data viz-----------------------\nimport matplotlib.pyplot as plt \nimport matplotlib.gridspec as gridspec \n%matplotlib inline\nimport seaborn as sns \nimport plotly.express as px # \nimport plotly.graph_objects as go # \nfrom statsmodels.graphics.gofplots import qqplot \n#_________________________________________________\nimport re # text data\nimport string","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets look at the data...","metadata":{}},{"cell_type":"code","source":"file_path = '../input/disneyland-reviews/DisneylandReviews.csv'\ndf = pd.read_csv(file_path, encoding = 'ISO-8859-1')","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## First five rows","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Last five rows","metadata":{}},{"cell_type":"markdown","source":"- Although, there were no missing values initially, but, after looking as the last five rows of the dataset, the `Year_month` column consists of missing values passed as string. Therefore, reading the file again and specifying the na_values as `missing` ","metadata":{}},{"cell_type":"code","source":"df.tail()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reading data again and specifying na_values as 'missing'","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(file_path, encoding = 'ISO-8859-1', na_values = 'missing')\ndf.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`Year_month` column consists of 6 percent missing values. These value are not dropped since the goal is to analyse the reviews. Removing these missing dates will result in loss of data.","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()/len(df)*100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Duplicate Reviews","metadata":{}},{"cell_type":"markdown","source":"The `Review_ID` column consits of dupicate id's","metadata":{}},{"cell_type":"code","source":"df.Review_ID.value_counts().head(21)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Further analysing the dupicate id indicate that they also contain the same information in other columns too.","metadata":{}},{"cell_type":"code","source":"df[df.Review_ID == 166787525]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.Review_ID == 129231609]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Droping duplicate records and keeping first","metadata":{}},{"cell_type":"code","source":"df.drop_duplicates(subset='Review_ID', inplace=True, keep='first')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"## Number of reviews for the three Disneyland branches\nDisneyland Califoria has the highest percentage of reviews (approx. 46%).","metadata":{}},{"cell_type":"code","source":"branch_count = df.Branch.value_counts()\nbranch_col = ['navy', 'crimson', 'forestgreen']\n# remove extra characters from branch name\nbranch_name = [branch[11:] for branch in branch_count.index] \n\nwith plt.style.context('fivethirtyeight'):\n    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n    plt.subplots_adjust(wspace=0.3)\n    # plot 1\n    ax[0].bar(branch_name, \n              branch_count.values, \n              color=branch_col)\n    for x , y, col in zip(branch_name, \n                     branch_count.values, branch_col):\n        ax[0].text(x, y/2, y, \n                   ha='center',color='white', \n                   bbox=dict(facecolor=col, edgecolor='white', boxstyle='circle'))\n    ax[0].set_ylabel('Number of Reviews')\n    # plot 2\n    ax[1].pie(x=branch_count.values, \n              #labels=branch_name,\n              colors=branch_col,  \n              autopct='%1.1f%%', textprops=dict(color='white'))\n    ax[1].legend(labels=branch_name, loc='upper right', fontsize=\"xx-small\")\n    plt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Peak time to visit Disneyland\nThe peak time is computed by counting the reviews/visits in all the quaters for a repective disneyland branch. `Note` only data from 2014 - 2019 was included in this analysis, to analyse the current trend.","metadata":{}},{"cell_type":"code","source":"no_missing = df.dropna().reset_index() # drop missing dates\nno_missing['Year'] = no_missing['Year_Month'].apply(lambda x: int(re.split('-', x)[0]))\nno_missing['Month'] = no_missing['Year_Month'].apply(lambda x: int(re.split('-', x)[1]))\n# computes quater using month number\nno_missing['Quater'] = no_missing['Month'].apply(lambda x: (x-1)//3+1) ","metadata":{"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Therefore, Quater 3 is the most busiest period to visit Disneyland for all the Disneyland branches.","metadata":{}},{"cell_type":"code","source":"# plot\nbranch_col = ['navy', 'crimson', 'forestgreen']\nwith plt.style.context('ggplot'):\n    fig, ax = plt.subplots(1, 3, figsize=(12, 5), sharey=True)\n    plt.subplots_adjust(top=0.8)\n    for i, (branch, col) in enumerate(zip(no_missing.Branch.unique(), branch_col)):\n        counts = no_missing[(no_missing.Branch == branch)|(no_missing.Year>=2014)]['Quater'].value_counts()\n        x = counts.index\n        y = counts.values\n        ax[i].bar(x, y, color=col, label=branch)\n        for q, val in zip(x, y):\n            ax[i].text(q, val/2, val, ha='center', \n                       color='white', \n                       bbox=dict(facecolor=col, edgecolor='white', boxstyle=\"circle\"))\n        ax[i].set_xlabel('Quater')\n        ax[0].set_ylabel('Number of visits')\n        ax[i].set_title(branch.upper()[11:], color=col)\n    fig.suptitle('Peak time to visit Disneyland (from 2014-2019 data)', fontsize=15, fontweight='semibold')\n    fig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure()\nfor i, (branch, col) in enumerate(zip(no_missing.Branch.unique(), branch_col)):\n    counts = no_missing[(no_missing.Branch == branch)|(no_missing.Year>=2014)]['Quater'].value_counts()\n    x = counts.index\n    y = counts.values\n    fig.add_trace(go.Bar(x=x, y=y, name=branch[11:], marker_color=col, text=y))\nfig.update_traces(textposition='inside')\nfig.update_layout(barmode='group', xaxis_tickangle=-45, template='ggplot2')\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Major Groups visiting Disneyland branches","metadata":{}},{"cell_type":"code","source":"with plt.style.context('seaborn'):\n    fig, ax = plt.subplots(1, 3, figsize=(12, 5))\n    plt.subplots_adjust(top=0.8, wspace=0.3)\n    for i, (branch, col) in enumerate(zip(df.Branch.unique(), branch_col)):\n        # count the reviews for a particular disneyland branch\n        loc_count = df[df.Branch == branch]['Reviewer_Location'].value_counts()[:5]\n        # plot\n        x = loc_count.index\n        y = loc_count.values\n        ax[i].bar(x, y, color=col)\n        ax[0].set_ylabel('Number of visits')\n        ax[i].set_title(branch.upper()[11:], color=col)\n        ax[i].tick_params(axis='x', rotation=90)\n        for c, val in zip(x, y):\n            ax[i].text(c, val*1.01, val, ha='center', color='white',\n                       bbox=dict(facecolor=col, \n                                 edgecolor='white', \n                                 boxstyle=\"circle\", pad=0.5))\n    fig.suptitle('Major groups visiting disneyland branches', \n                     fontsize=15, fontweight='semibold')\n    fig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of Ratings","metadata":{}},{"cell_type":"code","source":"rating_count = df.Rating.value_counts()\nwith plt.style.context('ggplot'):\n    plt.figure(figsize=(8, 6))\n    plt.bar(rating_count.index, rating_count.values, color='teal')\n    for r, val in zip(rating_count.index, rating_count.values):\n        plt.text(r, val, \n                 str(round(val/sum(rating_count.values)*100, 2))+'%', \n                 ha='center', color='white', \n                 bbox=dict(facecolor='dimgrey', edgecolor='white', boxstyle=\"round\"))\n    plt.xlabel('Ratings')\n    plt.ylabel('Number of reviewers')\n    plt.yticks(np.arange(0, 30001, 5000))","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"markers = ['o', '*', 'D']\nwith plt.style.context('bmh'):\n    plt.figure(figsize=(10, 8))\n    for branch, m, col in zip(df.Branch.unique(), markers, branch_col):\n        counts = df[df.Branch == branch]['Rating'].value_counts()\n        x = counts.index\n        y = counts.values\n        plt.plot(x, y, marker=m, markersize=9, color=col, label=branch)\n        plt.xticks(np.arange(1, 6))\n        plt.xlabel('Ratings')\n        plt.ylabel('Number of reviews')\n    plt.title('Distribution of Ratings across disneyland branches')\n    plt.legend()\n    plt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"branch_ratings = df.groupby('Branch').agg({'Rating': 'mean'}).unstack()['Rating']\nplt.figure(figsize=(6, 5))\nplt.barh([branch[11:] for branch in branch_ratings.index], \n         branch_ratings.values, \n         color=['forestgreen', 'navy', 'crimson'])\nfor val, p in zip(branch_ratings.values, [branch[11:] for branch in branch_ratings.index]):\n    plt.text(val/2, p, round(val, 2), color='white', ha='center', \n            bbox=dict(boxstyle='round4', facecolor='black'))\nplt.xlabel('Average rating')\nplt.xticks(np.arange(0, 6))\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Additional Features","metadata":{}},{"cell_type":"markdown","source":"### Length of Review\nIt is the length of a review minus the spaces","metadata":{}},{"cell_type":"code","source":"df['review_len'] = df.Review_Text.apply(lambda x: len(x) - x.count(' '))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def univariate_dist(data, col, color=None, theme='ggplot', figsize=(12, 10), hist_bins='auto'):\n    \"\"\"\n    This functions plots the univariate distribution - histogram, boxplot and qqplot, \n    for a pandas dataframe \n    \"\"\"\n    with plt.style.context(theme):\n        fig = plt.figure(figsize=figsize)\n        plt.subplots_adjust(wspace=0.5, hspace=0.4)\n        spec = gridspec.GridSpec(2, 3, figure=fig)\n        ax1 = fig.add_subplot(spec[0, :-1]) # first axis\n        ax1.set_title('Histogram', color='crimson')\n        ax2 = fig.add_subplot(spec[1, :-1]) # second axis\n        ax2.set_title('QQ Plot', color='crimson')\n        ax3 = fig.add_subplot(spec[:, -1:]) # third axis\n        ax3.set_title('Boxplot', color='crimson')\n        sns.histplot(data=data, x=col, ax=ax1, color=color, kde=True, bins=hist_bins)\n        qqplot(data[col], fit=True, line='45', ax=ax2, color=color)\n        sns.boxplot(y=data[col], ax=ax3, color=color)\n        plt.suptitle(col.upper())\n        return fig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"univariate_dist(df, 'review_len', 'goldenrod')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Punctuations Percentage","metadata":{}},{"cell_type":"code","source":"punctuations = string.punctuation # list of punctuations\n# percentage of punctuations\ndef count_punc(text):\n    \"\"\"This function counts the number of punctuations in a text\"\"\"\n    count = sum(1 for char in text if char in punctuations)\n    return round(count/(len(text) - text.count(\" \"))*100, 3)\n\n# apply function\ndf['punc%'] = df['Review_Text'].apply(lambda x: count_punc(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"univariate_dist(df, 'punc%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Word Count","metadata":{}},{"cell_type":"code","source":"df.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['word_count'] = df['Review_Text'].apply(lambda x: len(x.split(' ')))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"univariate_dist(df, 'word_count')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check Impurity","metadata":{}},{"cell_type":"markdown","source":"It is quit obvious that the relationship between the review length an the word count would be linear. But the plot below indicates some impurity in the dataset. There are some data points with a small review length but a extremly large word count. Further analysis needs to be conducted.","metadata":{}},{"cell_type":"code","source":"with plt.style.context('ggplot'):\n    plt.figure(figsize=(12, 8))\n    sns.scatterplot(data=df, x='review_len', y='word_count')\n    plt.text(188, 1330, 'Bad Data')\n    plt.text(521, 5600, 'Bad Data')\n    plt.text(168, 793, 'Bad Data')\n    plt.text(145, 1175, 'Bad Data')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Function to check impurity\n- The below function searches for all the characters defined in RE_SUSPICIOUS","metadata":{}},{"cell_type":"code","source":"RE_SUSPICIOUS = re.compile(r'[&#<>{}\\[\\]\\\\]')\ndef impurity(text, min_len=10):\n    \"\"\"returns the share of suspicious characters in a text\"\"\"\n    if text == None or len(text) < min_len:\n        return 0\n    else:\n        return len(RE_SUSPICIOUS.findall(text))/len(text)*100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['impurity'] = df['Review_Text'].apply(impurity)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- After applying the function to the dataframe, the dataframe is sorted with respect to the percecntage of impurity in decending order.\n- It can be observed that there is maximum 3% impurity in the data. ","metadata":{}},{"cell_type":"code","source":"df.sort_values(by='impurity', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}