{"cells":[{"metadata":{},"cell_type":"markdown","source":"Depois: criar uma coluna de doentes (que é DOENTES = Confirmados - Mortos - Recuperação). \nSelecionar BRAZIL e fazer análises de séries temporais. \nUsar modelo ARMA, ARIMA, SARIMA."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport matplotlib.pylab as plt\n%matplotlib inline\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 15, 6\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Carregando a base.\n\ndf = pd.read_csv('/kaggle/input/novel-corona-virus-2019-dataset/covid_19_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verificando o carregamento da base.\n\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Conferindo amostra dos dados.\n\ndf.sample(5).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Inspecionando tipos de variáveis do dataset.\n\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importar Datetime para ajustar formato de variaveis\n\nfrom datetime import datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ajustando o tipo da variável ObservationDate para DateTime.\n\ndf['ObservationDate'] = pd.to_datetime(df['ObservationDate'],infer_datetime_format=True)\ndf.sample().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Conferindo tipo alterado.\n\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Acrescentar nova coluna 'Sick' que representará a quantidade de doentes.\n#Calculo de Sick = Confirmed - Deaths - Recovered\n\ndf['Sick'] = df['Confirmed'] - df['Deaths'] - df['Recovered']\ndf.sample(40).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecionar os dados que serão utilizados para a análise.\n#Apenas dados sobre o país Brasil.\n\nnewdf = df[df['Country/Region'].str.contains('Brazil')]\nnewdf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fazendo corte no dataset, separando apenas as colunas que serão utilizadas.\n\ndata = newdf[['ObservationDate', 'Sick']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Conferidndo tipos de variáveis utilizadas para criar a série temporal.\n\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Setando a coluna ObservationDate como index.\n\ndata.set_index('ObservationDate',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tranformando o dataset em série temporal.\n\nts = data['Sick']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotando a série temporal.\n\nplt.plot(ts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Definindo funções.\n#Plotagens de Rolling Statistics e resultados dos testes de Dickey-Fulle.\n\nfrom statsmodels.tsa.stattools import adfuller\ndef test_stationarity(ts):\n    \n    #Determing rolling statistics\n    rolmean = pd.Series(ts).rolling(window=7).mean()\n    rolstd = pd.Series(ts).rolling(window=7).std()\n\n    #Plot rolling statistics:\n    orig = plt.plot(ts, color='blue',label='Original')\n    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Desvio Padrão')\n    plt.show(block=False)\n    \n    #Perform Dickey-Fuller test:\n    print ('Resultados do Teste de Dickey-Fuller:')\n    dftest = adfuller(ts, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Estatística de teste','p-valor','Defasagem usada','Número de observações usadas'])\n    for key,value in dftest[4].items():\n        dfoutput['Valor crítico (%s)'%key] = value\n    print (dfoutput)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Teste de estacionariedade.\n\ntest_stationarity(ts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Realizando transformação em logaritmo.\n\nts_log = np.log(ts)\nplt.plot(ts_log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropando valores Na\n\nts_log.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropando valores \"não válidos\".\n\nts_log.drop(ts_log.index[[0]],inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#determinando estatísticas de rolagem.\n\nmoving_avg = ts_log.rolling(window=7).mean()  \nplt.plot(ts_log)\nplt.plot(moving_avg, color='red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Mostrando valores que não possuem média.\n\nts_log_moving_avg_diff = ts_log - moving_avg\nts_log_moving_avg_diff.head(7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Usando valores NaN para testar a estacionaridade.\n\nts_log_moving_avg_diff.dropna(inplace=True)\ntest_stationarity(ts_log_moving_avg_diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Atribuindo pesos utilizando a média ponderada exponencial.\n\nexpwighted_avg = ts_log.ewm(halflife=12).mean()\nplt.plot(ts_log)\nplt.plot(expwighted_avg, color='red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tentando obter estacionariedade.\n\nts_log_ewma_diff = ts_log - expwighted_avg \ntest_stationarity(ts_log_ewma_diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Testando método da diferenciação de primeira ordem para obter estacionariedade.\n\nts_log_diff = ts_log - ts_log.shift()\nplt.plot(ts_log_diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando a diferenciação por meio de gráficos.\n\nts_log_diff.dropna(inplace=True)\ntest_stationarity(ts_log_diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Modelando a tendência e sazonalidade pela método de decomposição.\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose\ndecomposition = seasonal_decompose(ts_log) \ntrend = decomposition.trend \nseasonal = decomposition.seasonal \nresidual = decomposition.resid \nplt.subplot(411) \nplt.plot(ts_log, label='Original') \nplt.legend(loc='best') \nplt.subplot(412) \nplt.plot(trend, label='Trend') \nplt.legend(loc='best') \nplt.subplot(413) \nplt.plot(seasonal,label='Seasonality') \nplt.legend(loc='best') \nplt.subplot(414) \nplt.plot(residual, label='Residuals') \nplt.legend(loc='best') \nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verificando a estacionaridade dos resíduos.\n\nts_log_decompose = residual \nts_log_decompose.dropna(inplace=True) \ntest_stationarity(ts_log_decompose)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotando ACF e PACF.\n\nfrom statsmodels.tsa.stattools import acf, pacf\n\n#Função de autocorrelação (ACF): É uma medida da correlação entre o TS com uma versão desfasada de si mesmo.\n\nlag_acf = acf(ts_log_diff, nlags=10)\n\n#Função de autocorrelação parcial (FACP): Esta mede a correlação entre o TS com uma versão desfasada de si mesmo, \n#mas depois de eliminar as variações já explicadas pelas comparações intervenientes.\n\nlag_pacf = pacf(ts_log_diff, nlags=10, method='ols')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotando ACF: \nplt.subplot(121) \nplt.plot(lag_acf)\nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')\nplt.axhline(y=1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')\nplt.title('Autocorrelation Function')\n\n#Plotando PACF: \nplt.subplot(122)\nplt.plot(lag_pacf)\nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray')\nplt.axhline(y=1.96/np.sqrt(len(ts_log_diff)),linestyle='--',color='gray') \nplt.title('Partial Autocorrelation Function') \nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importando modelo ARIMA\n\nfrom statsmodels.tsa.arima_model import ARIMA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Utilizando modelo AR.\n\nmodel = ARIMA(ts_log, order=(2, 1, 0))  \nresults_AR = model.fit(disp=-1)  \nplt.plot(ts_log_diff)\nplt.plot(results_AR.fittedvalues, color='red')\nplt.title('RSS: %.4f'% sum((results_AR.fittedvalues-ts_log_diff)**2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Utilizando modelo MA.\n\nmodel = ARIMA(ts_log, order=(0, 1, 2))  \nresults_MA = model.fit(disp=-1)  \nplt.plot(ts_log_diff)\nplt.plot(results_MA.fittedvalues, color='red')\nplt.title('RSS: %.4f'% sum((results_MA.fittedvalues-ts_log_diff)**2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Utilizando modelo combinado ARIMA.\n\nmodel = ARIMA(ts_log, order=(2, 1, 2)) \nresults_ARIMA = model.fit(disp=-1) \nplt.plot(ts_log_diff) \nplt.plot(results_ARIMA.fittedvalues, color='red') \nplt.title('RSS: %.4f'% sum((results_ARIMA.fittedvalues-ts_log_diff)**2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Armazenando resultados previstos\n\npredictions_ARIMA_diff = pd.Series(results_ARIMA.fittedvalues, copy=True) \nprint (predictions_ARIMA_diff.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convertendo a diferenciação de escala logarítmica utilizando a soma cumulativa.\n\npredictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum() \nprint (predictions_ARIMA_diff_cumsum.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Criando uma série com os números base e adicionando as diferenças a eles\n\npredictions_ARIMA_log = pd.Series(ts_log.ix[0], index=ts_log.index)\npredictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum,fill_value=0)\nprint (predictions_ARIMA_log.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tomando o expoente e comparando com a série original.\n\npredictions_ARIMA = np.exp(predictions_ARIMA_log) \nplt.plot(ts) \nplt.plot(predictions_ARIMA) \nplt.title('RMSE: %.4f'% np.sqrt(sum((predictions_ARIMA-ts)**2)/len(ts)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}