{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Setup\n\nAs always, read the data file and look at the data to determine whether or not it needs to be cleaned up before doing any predictions. The SEED is for the random_state parameter in RandomForesClassifier.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport timeit\n\nstart_time_total = timeit.default_timer()\n\nSEED = 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"lol_data = pd.read_csv('../input/league-of-legends-diamond-ranked-games-10-min/high_diamond_ranked_10min.csv', index_col='gameId')\nlol_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lol_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"My theory is that the gold and experience differences will be the most important features in determining whether blue wins or not. But, when the gold and experience differences are almost negligible, other features start becoming important in predicting which team will win.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=\"blueWins\", y=\"blueGoldDiff\", data=lol_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=\"blueWins\", y=\"blueExperienceDiff\", data=lol_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like there are no categorical features so we can proceed with training the model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y = lol_data.blueWins\nX = lol_data.drop(columns='blueWins')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomForestClassifier will be the model used to predict whether or not blue wins. Without any data manipulation the accuracy is:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=SEED)\nrf_model = RandomForestClassifier(random_state=SEED)\nrf_model.fit(train_X, train_y)\npred = rf_model.predict(val_X)\nbaseline_score = accuracy_score(val_y, pred)\nprint('Accuracy: %.2f%%' %(baseline_score*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above accuracy will be the baseline and will be referred to as comparison in later predictions. To improve the score, start with a heatmap showing all the correlations. The features that have extremely high correlation should be dropped:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"r = lol_data.drop('blueWins', axis=1).corr()\nplt.figure(figsize=(20, 12))\nsns.heatmap(r, annot=True, fmt='.2f', center= 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"redundant_data = ['redFirstBlood', 'redKills', 'redDeaths', 'redGoldDiff', 'redExperienceDiff', 'redGoldPerMin', 'redCSPerMin', 'blueGoldPerMin', 'blueCSPerMin']\nclean_data = lol_data.drop(redundant_data, axis=1)\n\nr = clean_data.drop('blueWins', axis=1).corr()\nplt.figure(figsize=(20, 12))\nsns.heatmap(r, annot=True, fmt='.2f', center= 0);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There should no longer be any 1s or -1s unless it's on the diagonal. Then, the accuracy of the cleaned data vs the baseline accuracy:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_clean = clean_data.blueWins\nX_clean = clean_data.drop(columns='blueWins')\ntrain_X, val_X, train_y, val_y = train_test_split(X_clean, y_clean, random_state=SEED)\nrf_model = RandomForestClassifier(random_state=SEED)\nrf_model.fit(train_X, train_y)\npred = rf_model.predict(val_X)\nscore = accuracy_score(val_y, pred)\nprint('Accuracy: %.2f%% vs baseline accuracy: %.2f%%' %(score*100, baseline_score*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Choosing the features","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Permutation importance\n\nThe most important features, according to permutation importance, determining whether or not blue wins are:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\nfrom sklearn.svm import SVC\nfrom sklearn.feature_selection import SelectFromModel\n\nstart_time = timeit.default_timer()\nperm = PermutationImportance(rf_model).fit(val_X, val_y)\nelapsed = timeit.default_timer() - start_time\nprint('Elapsed time: %s s' %elapsed)\neli5.show_weights(perm, feature_names=val_X.columns.tolist(), top=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SHAP values\n\nSeparate the rows where blue wins and the ones where blue loses:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = clean_data[clean_data.blueWins==0]\nwon = clean_data[clean_data.blueWins==1]\nloss = loss.drop(columns='blueWins')\nwon = won.drop(columns='blueWins')\nloss.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"won.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a helper function that shows the SHAP value plot for a specific row:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap\n\ndef shap_row(df, model, row_to_show=0):\n    data_for_prediction = df.iloc[row_to_show]\n    data_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n    model.predict_proba(data_for_prediction_array)\n    explainer = shap.TreeExplainer(model)\n    shap_values = explainer.shap_values(data_for_prediction)\n    shap.initjs()\n    return shap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For a losing team, let's look at the SHAP values that determined why they lost:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot = shap_row(loss, rf_model, 1)\nplot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And for a winning team:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot = shap_row(won, rf_model, 1)\nplot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What features become important when the gold difference and experience difference are both small?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_small_diff = loss[(abs(loss.blueGoldDiff)<500) & (abs(loss.blueExperienceDiff)<500)]\nloss_small_diff.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below shows the SHAP values of the first row from the table above. In general, when the gold/experience differences are small, the total gold and total experience both become an important feature determining the outcome of the game.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot = shap_row(loss_small_diff, rf_model, 0)\nplot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This took a few minutes (~3 mins) to run on my PC because there were almost 10k rows and a lot of features but it shows which features push the outcome towards a loss or a win:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = timeit.default_timer()\n\nexplainer = shap.TreeExplainer(rf_model)\nshap_values_all = explainer.shap_values(val_X)\nshap.summary_plot(shap_values_all[0], val_X)\n\nelapsed = timeit.default_timer() - start_time\nprint('Elapsed time: %s s' %elapsed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SelectKBest with RandomForestClassifier","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"A few helper functions to help out in the next section. Click to unhide:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest, f_classif\n\ndef k_features(model, train_X, val_X, train_y, val_y, k=1):\n    selector = SelectKBest(f_classif, k=k)\n    X_new = selector.fit_transform(train_X, train_y)\n    selected_features = pd.DataFrame(selector.inverse_transform(X_new), \n                                     index=train_X.index, \n                                     columns=train_X.columns)\n    selected_cols = selected_features.columns[selected_features.var() != 0]\n\n    kbest_X = train_X[selected_cols]\n    kval_X = val_X[selected_cols]\n\n    model.fit(kbest_X, train_y)\n    pred = model.predict(kval_X)\n    score = accuracy_score(val_y, pred)\n    return score\n\ndef plot_results(results):\n    plt.plot(list(results.keys()), list(results.values()))\n    plt.xlabel('# of features')\n    plt.ylabel('Score (accuracy)')\n    plt.show()\n    \ndef scores(results):\n    key_min = min(results.keys(), key=(lambda k: results[k]))\n    key_max = max(results.keys(), key=(lambda k: results[k]))\n    \n    print('Highest score at %d features of %.2f%%' %(key_max, results[key_max]*100))\n    print('Lowest score at %d features of %.2f%%' %(key_min, results[key_min]*100))\n    return key_max","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using **SelectKBest** to help pick out the best features with ANOVA F-value for classification:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = timeit.default_timer()\nresults_rf = {}\n\nrf_model = RandomForestClassifier(random_state=SEED)\n\nfor i in range(1, len(train_X.columns)): # len(train_X.columns)\n    score = k_features(rf_model, train_X, val_X, train_y, val_y, i)\n#     print('Accuracy: %.2f%% %s' %(score*100, selected_cols.tolist()))\n    results_rf[i] = score\n    \nplot_results(results_rf)\nelapsed = timeit.default_timer() - start_time\nprint('Elapsed time: %.2f s' %elapsed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best and worst accuracy scores are shown below as well as the number of features used in the model. This is again compared with the baseline accuracy score.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"k_num = scores(results_rf)\nselector = SelectKBest(f_classif, k=k_num)\nX_new = selector.fit_transform(train_X, train_y)\nselected_features = pd.DataFrame(selector.inverse_transform(X_new), \n                                 index=train_X.index, \n                                 columns=train_X.columns)\nselected_cols = selected_features.columns[selected_features.var() != 0]\n\nkbest_X = train_X[selected_cols]\nkval_X = val_X[selected_cols]\n\nrf_model.fit(kbest_X, train_y)\npred = rf_model.predict(kval_X)\nscore = accuracy_score(val_y, pred)\nprint('\\nAccuracy: %.2f%% vs the baseline score %.2f%% \\n\\nBest Features using RandomForestClassifier: %s' %(score*100, baseline_score*100, selected_cols.tolist()))\nnot_selected = selected_features.columns[selected_features.var() == 0]\nprint('\\nFeatures not selected in RandomForestClassifier: %s' %not_selected.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SelectKBest with XGBoost","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Will XGBoost give better accuracy? For XGBoost, without selecting the k best features, the accuracy is:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgb_model = XGBClassifier()\nxgb_model.fit(train_X, train_y)\npred = xgb_model.predict(val_X)\nscore = accuracy_score(val_y, pred)\nprint('Accuracy: %.2f%% vs the baseline score of %.2f%%' %(score*100, baseline_score*100))\n\nperm = PermutationImportance(xgb_model).fit(val_X, val_y)\neli5.show_weights(perm, feature_names=val_X.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = timeit.default_timer()\nresults_xgb = {}\n\nfor i in range(1, len(train_X.columns)): # len(train_X.columns)\n    score = k_features(xgb_model, train_X, val_X, train_y, val_y, i)\n#     print('Accuracy: %.2f%% %s' %(score*100, selected_cols.tolist()))\n    results_xgb[i] = score\n\n# print(results_xgb)\nplot_results(results_xgb)\nelapsed = timeit.default_timer() - start_time\nprint('Elapsed time: %.2f s' %elapsed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After running SelectKBest from 1 to the total number of features, XGBoost was faster and had better accuracy with less features. While RandomForestModel was slower and had better accuracy with more features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"k_num = scores(results_xgb)\nselector = SelectKBest(f_classif, k=k_num)\nX_new = selector.fit_transform(train_X, train_y)\nselected_features = pd.DataFrame(selector.inverse_transform(X_new), \n                                 index=train_X.index, \n                                 columns=train_X.columns)\nselected_cols = selected_features.columns[selected_features.var() != 0]\n\nkbest_X = train_X[selected_cols]\nkval_X = val_X[selected_cols]\n\nxgb_model.fit(kbest_X, train_y)\npred = xgb_model.predict(kval_X)\nscore = accuracy_score(val_y, pred)\nprint('\\nAccuracy: %.2f%% vs the baseline score %.2f%% \\n\\nBest features using XGBoost: %s' %(score*100, baseline_score*100, selected_cols.tolist()))\nnot_selected = selected_features.columns[selected_features.var() == 0]\nprint('\\nFeatures not selected in XGBClassifier: %s' %not_selected.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Taking it one step further\n\nRed and blue's total gold and total experience are basically red and blue's gold and experience differences subtracted from each other. Thus, they can be removed. Looking at the difference in each team's jungle minions killed, assists and kills, etc. could be useful. Starting at the original data set then removing and adding features that were used in calculating differences:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Helper function\ndef make_diffs(df):\n    df['killDiff'] = df['blueKills'] - df['redKills']\n    df['assistDiff'] = df['blueAssists'] - df['redAssists']\n    df['avgLevelDiff'] = df['blueAvgLevel'] - df['redAvgLevel']\n    df['eliteMonstersDiff'] = df['blueEliteMonsters'] - df['redEliteMonsters']\n    df['towersDiff'] = df['blueTowersDestroyed'] - df['redTowersDestroyed']\n    df['wardsPlacedDiff'] = df['blueWardsPlaced'] - df['redWardsPlaced']\n    df['wardsDestroyedDiff'] = df['blueWardsDestroyed'] - df['redWardsDestroyed']\n    df['minionsDiff'] = df['blueTotalMinionsKilled'] - df['redTotalMinionsKilled']\n    df['jungleMinionsDiff'] = df['blueTotalJungleMinionsKilled'] - df['redTotalJungleMinionsKilled']\n    df.head()\n    return df\n\nclean_data = lol_data.copy()\ny = clean_data.blueWins\n# clean_data.columns\nclean_data = clean_data.drop(columns='blueWins', axis=1)\nclean_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create all the possible differences, minus the difference in number of dragons and heralds which gets combined as the different between elite monsters, all the columns are:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_data = make_diffs(clean_data)\nprint(clean_data.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then, looking at the correlation between the columns listed above and removing blueTotalGold and redTotalGold since they're what make up blueGoldDiff, as well as those that perfectly correlate with each other:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"r = clean_data.corr()\nplt.figure(figsize=(20, 12))\nsns.heatmap(r, annot=True, fmt='.2f', center= 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations = ['redFirstBlood', 'redKills', 'redDeaths', 'blueCSPerMin', 'blueGoldPerMin', 'blueTotalGold', \n                'redGoldDiff', 'redExperienceDiff', 'redTotalGold', 'redCSPerMin', 'redGoldPerMin', \n                'blueTotalExperience', 'redTotalExperience']\n\nother_data = ['blueWardsPlaced', 'blueWardsDestroyed', 'blueKills', 'blueDeaths', 'blueAssists', \n              'blueEliteMonsters', 'blueDragons', 'blueHeralds', 'blueTowersDestroyed', \n              'blueAvgLevel', 'blueTotalMinionsKilled', 'blueTotalJungleMinionsKilled', \n              'redWardsPlaced', 'redWardsDestroyed', 'redAssists', 'redEliteMonsters', \n              'redDragons', 'redHeralds', 'redTowersDestroyed', 'redAvgLevel', \n              'redTotalMinionsKilled', 'redTotalJungleMinionsKilled']\nteam_diff = clean_data.drop(correlations, axis=1)\nteam_diff.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The correlations after the perfectly correlated columns were removed:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"r = team_diff.corr()\nplt.figure(figsize=(20, 12))\nsns.heatmap(r, annot=True, fmt='.2f', center= 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X, val_X, train_y, val_y = train_test_split(team_diff, y, random_state=SEED)\ndiff_model = RandomForestClassifier(random_state=SEED)\ndiff_model.fit(train_X, train_y)\npred = diff_model.predict(val_X)\nscore = accuracy_score(val_y, pred)\nprint('Accuracy: %.2f%% vs the baseline score %.2f%%' %(score*100, baseline_score*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Permutation importance for reduced dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"perm = PermutationImportance(diff_model).fit(val_X, val_y)\neli5.show_weights(perm, feature_names=val_X.columns.tolist(), top=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Choosing the features that Permutation Importance thinks are the best (this will change depending on the seed):","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sel = SelectFromModel(perm, threshold=0.02, prefit=True)\nX_trans = sel.transform(val_X)\nX_trans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pi_features = team_diff.filter(['blueGoldDiff', 'killDiff', 'blueExperienceDiff', 'jungleMinionsDiff', \n                                'redTotalMinionsKilled', 'redEliteMonsters', 'redTotalJungleMinionsKilled', \n                                'blueDeaths', 'blueDragons'], axis=1)\ntpi_X, vpi_X, tpi_y, vpi_y = train_test_split(pi_features, y, random_state=SEED)\npi_model = RandomForestClassifier(random_state=SEED)\npi_model.fit(tpi_X, tpi_y)\npred = pi_model.predict(vpi_X)\nscore = accuracy_score(vpi_y, pred)\nprint('Accuracy: %.2f%% vs the baseline score %.2f%%' %(score*100, baseline_score*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SHAP values for reduced dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = timeit.default_timer()\n\nexplainer = shap.TreeExplainer(diff_model)\nshap_values_all = explainer.shap_values(val_X)\nshap.summary_plot(shap_values_all[0], val_X)\n\nelapsed = timeit.default_timer() - start_time\nprint('Elapsed time: %s s' %elapsed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SelectKBest for reduced dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = timeit.default_timer()\nresults_rf = {}\n\nfor i in range(1, len(train_X.columns)): # len(train_X.columns)\n    score = k_features(diff_model, train_X, val_X, train_y, val_y, i)\n#     print('Accuracy: %.2f%% %s' %(score*100, selected_cols.tolist()))\n    results_rf[i] = score\n    \nplot_results(results_rf)\nelapsed = timeit.default_timer() - start_time\nprint('Elapsed time: %.2f s' %elapsed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k_num = scores(results_rf)\nselector = SelectKBest(f_classif, k=k_num)\nX_new = selector.fit_transform(train_X, train_y)\nselected_features = pd.DataFrame(selector.inverse_transform(X_new), \n                                 index=train_X.index, \n                                 columns=train_X.columns)\nselected_cols = selected_features.columns[selected_features.var() != 0]\n\nkbest_X = train_X[selected_cols]\nkval_X = val_X[selected_cols]\n\ndiff_model.fit(kbest_X, train_y)\npred = diff_model.predict(kval_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = accuracy_score(val_y, pred)\nprint('Accuracy: %.2f%% vs a baseline score of %.2f%%\\n\\nBest Features using RandomForestClassifier: %s' %(score*100, baseline_score*100, selected_cols.tolist()))\nnot_selected = selected_features.columns[selected_features.var() == 0]\nprint('\\nFeatures not selected in RandomForestClassifier: %s' %not_selected.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"end_time_total = timeit.default_timer() - start_time_total\nprint('Elapsed time: %.2f s' %end_time_total)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}