{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing necessary libraries","metadata":{"id":"ICSkXc7hOjA1"}},{"cell_type":"code","source":"import sys, os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter(action='ignore')\nimport seaborn as sns\nimport pandas as pd\nfrom datetime import datetime\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, SimpleRNN, LSTM, Activation, Dropout,RNN\nimport math\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nplotsize = (12,5)","metadata":{"id":"HFHURjBZETVA","execution":{"iopub.status.busy":"2021-08-27T04:56:27.550852Z","iopub.execute_input":"2021-08-27T04:56:27.551391Z","iopub.status.idle":"2021-08-27T04:56:34.074636Z","shell.execute_reply.started":"2021-08-27T04:56:27.551312Z","shell.execute_reply":"2021-08-27T04:56:34.073589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading CSV file having Covid-19 records in India","metadata":{"id":"dsprvTRHOy1d"}},{"cell_type":"code","source":"base  = pd.read_csv(\"../input/covid19-in-india/covid_19_india.csv\")","metadata":{"id":"rXn0IBhuETVD","execution":{"iopub.status.busy":"2021-08-27T04:56:34.076231Z","iopub.execute_input":"2021-08-27T04:56:34.076611Z","iopub.status.idle":"2021-08-27T04:56:34.132278Z","shell.execute_reply.started":"2021-08-27T04:56:34.076573Z","shell.execute_reply":"2021-08-27T04:56:34.131344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base","metadata":{"id":"ouiXM4x_ETVE","outputId":"e1225cb2-877a-4fc3-e29f-013b5ae00efa","execution":{"iopub.status.busy":"2021-08-27T04:56:34.134256Z","iopub.execute_input":"2021-08-27T04:56:34.134651Z","iopub.status.idle":"2021-08-27T04:56:34.169803Z","shell.execute_reply.started":"2021-08-27T04:56:34.134612Z","shell.execute_reply":"2021-08-27T04:56:34.169174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base.describe()","metadata":{"id":"D8bv8asZPSIU","outputId":"28b4fbfa-7464-4d14-8ade-cd11318ce8c5","execution":{"iopub.status.busy":"2021-08-27T04:56:34.171234Z","iopub.execute_input":"2021-08-27T04:56:34.1715Z","iopub.status.idle":"2021-08-27T04:56:34.201355Z","shell.execute_reply.started":"2021-08-27T04:56:34.171475Z","shell.execute_reply":"2021-08-27T04:56:34.200372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making sense of Data using Pandas Profiling","metadata":{"id":"BkLA6w_9c3k3"}},{"cell_type":"code","source":"import pandas_profiling as pp\nprofile = pp.ProfileReport(base)\nprofile.to_file(\"output.html\")","metadata":{"id":"b4SFJYAwQIyh","outputId":"4c883e00-b58c-4cc2-91db-b9e446c41902","execution":{"iopub.status.busy":"2021-08-27T04:56:34.202488Z","iopub.execute_input":"2021-08-27T04:56:34.202748Z","iopub.status.idle":"2021-08-27T04:56:51.058568Z","shell.execute_reply.started":"2021-08-27T04:56:34.202724Z","shell.execute_reply":"2021-08-27T04:56:51.057417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"profile","metadata":{"id":"ekfkDQuJckrk","outputId":"a67ead95-b5ce-46a9-de4d-df7338f57d44","execution":{"iopub.status.busy":"2021-08-27T04:56:51.059851Z","iopub.execute_input":"2021-08-27T04:56:51.060156Z","iopub.status.idle":"2021-08-27T04:56:51.163846Z","shell.execute_reply.started":"2021-08-27T04:56:51.060127Z","shell.execute_reply":"2021-08-27T04:56:51.162678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Converting date column to a 'Datetime' object.","metadata":{"id":"0mKhwwYDdFEl"}},{"cell_type":"code","source":"base['Date'] = pd.to_datetime(base['Date'])","metadata":{"id":"FOvfVMwOXhmv","execution":{"iopub.status.busy":"2021-08-27T04:56:51.165268Z","iopub.execute_input":"2021-08-27T04:56:51.165592Z","iopub.status.idle":"2021-08-27T04:56:51.178218Z","shell.execute_reply.started":"2021-08-27T04:56:51.165563Z","shell.execute_reply":"2021-08-27T04:56:51.177531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Grouping data by 'Date' to find cumulative sum of cases in India.","metadata":{"id":"pbR9mcpOdS2S"}},{"cell_type":"code","source":"data = base.groupby(by=['Date']).sum().diff()","metadata":{"id":"Dq9V1lMYUv6s","execution":{"iopub.status.busy":"2021-08-27T04:56:51.180741Z","iopub.execute_input":"2021-08-27T04:56:51.181192Z","iopub.status.idle":"2021-08-27T04:56:51.195447Z","shell.execute_reply.started":"2021-08-27T04:56:51.181163Z","shell.execute_reply":"2021-08-27T04:56:51.194627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"id":"Dvu9j_OSETVG","outputId":"127ca0da-269c-4160-c52a-21eee297bbc1","execution":{"iopub.status.busy":"2021-08-27T04:56:51.197046Z","iopub.execute_input":"2021-08-27T04:56:51.197469Z","iopub.status.idle":"2021-08-27T04:56:51.216803Z","shell.execute_reply.started":"2021-08-27T04:56:51.197441Z","shell.execute_reply":"2021-08-27T04:56:51.216153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Removing 'NAN' values and replacing with 0.","metadata":{"id":"cIdQUU1idlS9"}},{"cell_type":"code","source":"data.fillna(0,inplace=True)\ndata.rename(columns={\"Confirmed\":\"Cases\"},inplace=True)","metadata":{"id":"tpZWOe-VETVI","execution":{"iopub.status.busy":"2021-08-27T04:56:51.217753Z","iopub.execute_input":"2021-08-27T04:56:51.218136Z","iopub.status.idle":"2021-08-27T04:56:51.222457Z","shell.execute_reply.started":"2021-08-27T04:56:51.218106Z","shell.execute_reply":"2021-08-27T04:56:51.221762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"id":"s8SarndzeWRo","outputId":"ac20a7d9-a140-4f4d-f45a-bd5a03cb6d10","execution":{"iopub.status.busy":"2021-08-27T04:56:51.223445Z","iopub.execute_input":"2021-08-27T04:56:51.223858Z","iopub.status.idle":"2021-08-27T04:56:51.249054Z","shell.execute_reply.started":"2021-08-27T04:56:51.22383Z","shell.execute_reply":"2021-08-27T04:56:51.24815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting time series of 3 Variables.\n1. Cases\n2. Deaths\n3. Cured","metadata":{"id":"x1oLiVd1eyut"}},{"cell_type":"code","source":"figure, axes = plt.subplots(3,sharex=True)\ndata['Cases'].plot(ax=axes[0],title='Cases',figsize=plotsize)\ndata['Deaths'].plot(ax=axes[1],title='Deaths',figsize=plotsize)\ndata['Cured'].plot(ax=axes[2],title='Cured',figsize=plotsize)","metadata":{"id":"9pai7cqbETVJ","outputId":"b74a3e11-9229-4f6c-f3fb-7fe6e45e305f","execution":{"iopub.status.busy":"2021-08-27T04:56:51.250157Z","iopub.execute_input":"2021-08-27T04:56:51.250448Z","iopub.status.idle":"2021-08-27T04:56:51.802858Z","shell.execute_reply.started":"2021-08-27T04:56:51.250421Z","shell.execute_reply":"2021-08-27T04:56:51.80204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resampling number of cases by:\n1. Weekly data\n2. Monthly data","metadata":{"id":"n1QjzVspfto3"}},{"cell_type":"code","source":"cases_weekly = data['Cases'].resample('W').sum()\ncases_weekly.plot(title='Weekly cases')","metadata":{"id":"DzcXwjn9ETVK","outputId":"cc42a66d-5ef0-416d-9379-46afff71c987","execution":{"iopub.status.busy":"2021-08-27T04:56:51.804004Z","iopub.execute_input":"2021-08-27T04:56:51.804269Z","iopub.status.idle":"2021-08-27T04:56:52.019065Z","shell.execute_reply.started":"2021-08-27T04:56:51.804244Z","shell.execute_reply":"2021-08-27T04:56:52.018103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cases_monthly = data['Cases'].resample('M').sum()\ncases_monthly.plot(title='Monthly cases')","metadata":{"id":"kql5e3UCETVL","outputId":"4bd64bd1-609e-4817-9471-6b6ce973ec23","execution":{"iopub.status.busy":"2021-08-27T04:56:52.020425Z","iopub.execute_input":"2021-08-27T04:56:52.020804Z","iopub.status.idle":"2021-08-27T04:56:52.233925Z","shell.execute_reply.started":"2021-08-27T04:56:52.020762Z","shell.execute_reply":"2021-08-27T04:56:52.233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setting up helper functions for forecasting\n\n1. get_n_last_days : Extract last n_days of a time series.\n2. plot_n_last_days : Plot last n_days of a time series","metadata":{"id":"oDz_hvGMgc6Z"}},{"cell_type":"code","source":"def get_n_last_days(df, series_name, n_days):\n\n    return df[series_name][-(n_days):] \n\ndef plot_n_last_days(df, series_name, n_days):\n\n    plt.figure(figsize = (10,5))   \n    plt.plot(get_n_last_days(df, series_name, n_days), 'k-')\n    plt.title('{0} - {1} days'\n              .format(series_name, n_days))\n    plt.xlabel('Recorded day')\n    plt.ylabel('Reading')\n    plt.grid(alpha=0.3)","metadata":{"id":"0ahCxfnPETVL","execution":{"iopub.status.busy":"2021-08-27T04:56:52.235102Z","iopub.execute_input":"2021-08-27T04:56:52.235411Z","iopub.status.idle":"2021-08-27T04:56:52.241813Z","shell.execute_reply.started":"2021-08-27T04:56:52.235382Z","shell.execute_reply":"2021-08-27T04:56:52.240859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_n_last_days(data,'Cases',200)","metadata":{"id":"wNKz3NzuETVM","outputId":"5b437582-9aba-4ecb-ed12-e13e9660c6c1","execution":{"iopub.status.busy":"2021-08-27T04:56:52.243289Z","iopub.execute_input":"2021-08-27T04:56:52.243672Z","iopub.status.idle":"2021-08-27T04:56:52.453886Z","shell.execute_reply.started":"2021-08-27T04:56:52.243632Z","shell.execute_reply":"2021-08-27T04:56:52.452653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Some more helper functions\n1. get_keras_format_series :  Convert a series to a numpy array of shape \n    [n_samples, time_steps, features]\n\n\n\n\n2. get_train_test_data : Utility processing function that splits an hourly time series into train and test with keras-friendly format, according to user-specified choice of shape.  \n    \n    arguments\n    ---------\n    df (dataframe): dataframe with time series columns.\n\n    series_name (string): column name in df.\n\n    series_days (int): total days to extract.\n\n    input_days (int): length of sequence input to network.\n\n    test_days (int): length of held-out terminal sequence.\n    \n    sample_gap (int): step size between start of train sequences; default 5\n    \n    returns\n    ---------\n    tuple: train_X, test_X_init, train_y, test_y     ","metadata":{"id":"an0tE_Schz-C"}},{"cell_type":"code","source":"def get_keras_format_series(series):\n\n    series = np.array(series)\n    return series.reshape(series.shape[0],series.shape[1],1)\n\n\n\ndef get_train_test_data(df, series_name, series_days, input_hours, \n                        test_hours, sample_gap=3):\n\n    forecast_series = get_n_last_days(df, series_name, series_days).values # reducing our forecast series to last n days\n\n    train = forecast_series[:-test_hours] # training data is remaining days until amount of test_hours\n    test = forecast_series[-test_hours:] # test data is the remaining test_hours\n\n    train_X, train_y = [], []\n\n    # range 0 through # of train samples - input_hours by sample_gap. \n    # This is to create many samples with corresponding\n    for i in range(0, train.shape[0]-input_hours, sample_gap): \n        train_X.append(train[i:i+input_hours]) # each training sample is of length input hours\n        train_y.append(train[i+input_hours]) # each y is just the next step after training sample\n\n    train_X = get_keras_format_series(train_X) # format our new training set to keras format\n    train_y = np.array(train_y) # make sure y is an array to work properly with keras\n    \n    # The set that we had held out for testing (must be same length as original train input)\n    test_X_init = test[:input_hours] \n    test_y = test[input_hours:] # test_y is remaining values from test set\n    \n    return train_X, test_X_init, train_y, test_y","metadata":{"id":"jCrjYPvgETVM","execution":{"iopub.status.busy":"2021-08-27T04:56:52.455615Z","iopub.execute_input":"2021-08-27T04:56:52.456004Z","iopub.status.idle":"2021-08-27T04:56:52.464558Z","shell.execute_reply.started":"2021-08-27T04:56:52.455968Z","shell.execute_reply":"2021-08-27T04:56:52.463645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"series_days = 600\ninput_days = 5\ntest_days = 10\n\ntrain_X, test_X_init, train_y, test_y = \\\n    (get_train_test_data(data, 'Cases', series_days, \n                         input_days, test_days))","metadata":{"id":"MN-RrEHvETVN","execution":{"iopub.status.busy":"2021-08-27T04:56:52.466087Z","iopub.execute_input":"2021-08-27T04:56:52.466459Z","iopub.status.idle":"2021-08-27T04:56:52.478565Z","shell.execute_reply.started":"2021-08-27T04:56:52.466421Z","shell.execute_reply":"2021-08-27T04:56:52.477662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Training input shape: {}'.format(train_X.shape))\nprint('Training output shape: {}'.format(train_y.shape))\nprint('Test input shape: {}'.format(test_X_init.shape))\nprint('Test output shape: {}'.format(test_y.shape))","metadata":{"id":"J4DR8C7YETVN","outputId":"c0566446-8b53-4975-96dd-c3080e04a604","execution":{"iopub.status.busy":"2021-08-27T04:56:52.479797Z","iopub.execute_input":"2021-08-27T04:56:52.48023Z","iopub.status.idle":"2021-08-27T04:56:52.489227Z","shell.execute_reply.started":"2021-08-27T04:56:52.480183Z","shell.execute_reply":"2021-08-27T04:56:52.488265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining model architecture\n\n1. LSTM\n\n    Fit LSTM to data train_X, train_y .\n    \n    arguments\n\n    train_X (array): input sequence samples for training.\n\n    train_y (list): next step in sequence targets.\n\n    cell_units (int): number of hidden units for LSTM cells.\n\n    epochs (int): number of training epochs   \n   \n","metadata":{"id":"rhHUtmPmwYta"}},{"cell_type":"code","source":"def fit_LSTM(X_train, y_train, epochs):\n    \n    # initialize model\n    regressor = Sequential()\n\n    # Adding the first LSTM layer and some Dropout regularisation\n    regressor.add(LSTM(units = 45, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n    regressor.add(Dropout(0.2))\n\n    # Adding a second LSTM layer nd some Dropout regularisation\n    regressor.add(LSTM(units = 45, return_sequences = True))\n    regressor.add(Dropout(0.2))\n\n    # Adding a third LSTM layer and some Dropout regularisation\n    regressor.add(LSTM(units = 45, return_sequences = True))\n    regressor.add(Dropout(0.2))\n\n    # Adding a fourth LSTM layer and some Dropout regularisation\n    regressor.add(LSTM(units = 45))\n    regressor.add(Dropout(0.2))\n\n    # Adding the output layer\n    regressor.add(Dense(units = 1))\n    # define the loss function / optimization strategy, and fit\n    # the model with the desired number of passes over the data (epochs) \n    regressor.compile(loss='mean_squared_error', optimizer='adam')\n    regressor.fit(train_X, train_y, epochs=epochs, batch_size=64, verbose=1)\n    \n    return regressor","metadata":{"id":"6YYuB_oSC-MO","execution":{"iopub.status.busy":"2021-08-27T04:56:52.490538Z","iopub.execute_input":"2021-08-27T04:56:52.490832Z","iopub.status.idle":"2021-08-27T04:56:52.500576Z","shell.execute_reply.started":"2021-08-27T04:56:52.490804Z","shell.execute_reply":"2021-08-27T04:56:52.499423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = fit_LSTM(train_X, train_y, epochs=1000)","metadata":{"id":"U0G-OPTSC_dR","outputId":"132b3375-62f6-4765-f143-f503219e3874","execution":{"iopub.status.busy":"2021-08-27T04:56:52.502317Z","iopub.execute_input":"2021-08-27T04:56:52.502771Z","iopub.status.idle":"2021-08-27T04:57:42.387689Z","shell.execute_reply.started":"2021-08-27T04:56:52.502706Z","shell.execute_reply":"2021-08-27T04:57:42.386868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making predictions.\n\nFunctions used\n1. predict :  Given an input series matching the model's expected format generates model's predictions for next n_steps in the series.\n\n2. predict_and_plot: Given an input series matching the model's expected format generates model's predictions for next n_steps in the series, and plots these predictions against the ground truth for those steps \n    \n    arguments\n\n    X_init (array): initial sequence, must match model's input shape.\n\n    y (array): true sequence values to predict, follow X_init.\n\n    model (keras.models.Sequential): trained neural network.\n\n    title (string): plot title.  ","metadata":{"id":"vxBdbOTdxChX"}},{"cell_type":"code","source":"def mse(observations, estimates):\n\n    # check arg types\n    assert type(observations) == type(np.array([])), \"'observations' must be a numpy array\"\n    assert type(estimates) == type(np.array([])), \"'estimates' must be a numpy array\"\n    # check length of arrays equal\n    assert len(observations) == len(estimates), \"Arrays must be of equal length\"\n    \n    # calculations\n    difference = observations - estimates\n    sq_diff = difference ** 2\n    mse = sum(sq_diff)\n    \n    return mse","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(X_init, n_steps, model):\n\n    \n    X_init = X_init.copy().reshape(1,-1,1)\n    preds = []\n    \n    # iteratively take current input sequence, generate next step pred,\n    # and shift input sequence forward by a step (to end with latest pred).\n    # collect preds as we go.\n    for _ in range(n_steps):\n        pred = model.predict(X_init)\n        preds.append(pred)\n        X_init[:,:-1,:] = X_init[:,1:,:]\n        X_init[:,-1,:] = pred \n    \n    preds = np.array(preds).reshape(-1,1)\n    \n    return preds\n\ndef predict_and_plot(X_init, y, model, title):\n\n    y_preds = predict(test_X_init, n_steps=len(y), model=model) # predict through length of y\n    # Below ranges are to set x-axes\n    start_range = range(1, test_X_init.shape[0]+1) #starting at one through to length of test_X_init to plot X_init\n    predict_range = range(test_X_init.shape[0], test_days)  #predict range is going to be from end of X_init to length of test_hours\n    \n    #using our ranges we plot X_init\n    plt.plot(start_range, test_X_init)\n    #and test and actual preds\n    plt.plot(predict_range, test_y, color='orange')\n    plt.plot(predict_range, y_preds, color='teal', linestyle='--')\n    \n    plt.title(title)\n    plt.legend(['Initial Series','Target Series','Predictions'])\n    print(y_preds)\n    print(\"MSE:{}\".format(np.mean(mse(y,y_preds))))","metadata":{"id":"DVnK--lgETVd","execution":{"iopub.status.busy":"2021-08-27T05:30:29.247119Z","iopub.execute_input":"2021-08-27T05:30:29.247494Z","iopub.status.idle":"2021-08-27T05:30:29.257106Z","shell.execute_reply.started":"2021-08-27T05:30:29.247465Z","shell.execute_reply":"2021-08-27T05:30:29.25631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_and_plot(test_X_init, test_y, model1,\n                 'Test Data and LSTM Predictions')","metadata":{"id":"jDYi19seETVt","execution":{"iopub.status.busy":"2021-08-27T05:30:29.463263Z","iopub.execute_input":"2021-08-27T05:30:29.463784Z","iopub.status.idle":"2021-08-27T05:30:29.860478Z","shell.execute_reply.started":"2021-08-27T05:30:29.463741Z","shell.execute_reply":"2021-08-27T05:30:29.859535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The deep learning model fails to learn due to small number of training instances.","metadata":{}},{"cell_type":"markdown","source":"# Decomposing the Time series.","metadata":{}},{"cell_type":"markdown","source":"Any time series has 3 components associated with it:\n1. Trend\n2. Seasonality\n3. Residual","metadata":{}},{"cell_type":"markdown","source":"Analysing Number of cases","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\ndata.drop(columns=['Cured','Deaths'],inplace=True)\ndata.columns = ['ds', 'y']\nss_decomposition = seasonal_decompose(x=data['y'], model='additive',freq=7)\nestimated_trend = ss_decomposition.trend\nestimated_seasonal = ss_decomposition.seasonal\nestimated_residual = ss_decomposition.resid","metadata":{"id":"hi3x9SCOXMkr","execution":{"iopub.status.busy":"2021-08-27T04:57:59.183549Z","iopub.execute_input":"2021-08-27T04:57:59.183908Z","iopub.status.idle":"2021-08-27T04:57:59.300217Z","shell.execute_reply.started":"2021-08-27T04:57:59.18388Z","shell.execute_reply":"2021-08-27T04:57:59.299431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(4, 1)\nfig.set_figheight(10)\nfig.set_figwidth(15)\n\naxes[0].plot(data['y'], label='Original')\naxes[0].legend(loc='upper left');\n\naxes[1].plot(estimated_trend, label='Trend')\naxes[1].legend(loc='upper left');\n\naxes[2].plot(estimated_seasonal, label='Seasonality')\naxes[2].legend(loc='upper left');\n\naxes[3].plot(estimated_residual, label='Residuals')\naxes[3].legend(loc='upper left');","metadata":{"execution":{"iopub.status.busy":"2021-08-27T04:57:59.425515Z","iopub.execute_input":"2021-08-27T04:57:59.426084Z","iopub.status.idle":"2021-08-27T04:58:00.247074Z","shell.execute_reply.started":"2021-08-27T04:57:59.426048Z","shell.execute_reply":"2021-08-27T04:58:00.245972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting Auto-Corellation function","metadata":{}},{"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf\nplot_acf(data['y'])","metadata":{"execution":{"iopub.status.busy":"2021-08-27T04:58:00.248615Z","iopub.execute_input":"2021-08-27T04:58:00.248984Z","iopub.status.idle":"2021-08-27T04:58:00.685091Z","shell.execute_reply.started":"2021-08-27T04:58:00.248944Z","shell.execute_reply":"2021-08-27T04:58:00.68412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_sequence_plot(x, y, title, xlabel=\"time\", ylabel=\"series\"):\n    plt.plot(x, y, 'k-')\n    plt.title(title)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.grid(alpha=0.3);","metadata":{"execution":{"iopub.status.busy":"2021-08-27T04:58:00.686776Z","iopub.execute_input":"2021-08-27T04:58:00.687082Z","iopub.status.idle":"2021-08-27T04:58:00.692373Z","shell.execute_reply.started":"2021-08-27T04:58:00.687053Z","shell.execute_reply":"2021-08-27T04:58:00.691298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dividing the dataset into chunks to analyze data in specific time periods","metadata":{}},{"cell_type":"code","source":"chunks = np.split(data['y'], indices_or_sections=7)\nprint(\"{} | {:7} | {}\".format(\"Chunk\", \"Mean\", \"Variance\"))\nprint(\"-\" * 26)\nfor i, chunk in enumerate(chunks, 1):\n    print(\"{:5} | {:.6} | {:.6}\".format(i, np.mean(chunk), np.var(chunk)))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T04:58:00.693807Z","iopub.execute_input":"2021-08-27T04:58:00.694127Z","iopub.status.idle":"2021-08-27T04:58:00.707678Z","shell.execute_reply.started":"2021-08-27T04:58:00.694098Z","shell.execute_reply":"2021-08-27T04:58:00.706631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series(data['y']).hist();","metadata":{"execution":{"iopub.status.busy":"2021-08-27T04:58:00.709252Z","iopub.execute_input":"2021-08-27T04:58:00.709683Z","iopub.status.idle":"2021-08-27T04:58:00.876155Z","shell.execute_reply.started":"2021-08-27T04:58:00.709641Z","shell.execute_reply":"2021-08-27T04:58:00.87507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Augmented Dickey Fuller test (ADF Test) is a common statistical test used to test whether a given Time series is stationary or not. ","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\nadf, pvalue, usedlag, nobs, critical_values, icbest = adfuller(data['y'])","metadata":{"execution":{"iopub.status.busy":"2021-08-27T04:58:00.877529Z","iopub.execute_input":"2021-08-27T04:58:00.8779Z","iopub.status.idle":"2021-08-27T04:58:00.918036Z","shell.execute_reply.started":"2021-08-27T04:58:00.877854Z","shell.execute_reply":"2021-08-27T04:58:00.917015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"ADF:{}\".format(adf))\nprint(\"Pvalue:{}\".format(pvalue))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T04:58:00.919945Z","iopub.execute_input":"2021-08-27T04:58:00.920514Z","iopub.status.idle":"2021-08-27T04:58:00.926874Z","shell.execute_reply.started":"2021-08-27T04:58:00.92047Z","shell.execute_reply":"2021-08-27T04:58:00.925815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"p-value obtained is greater than significance level. Hence we cannot reject the null hypothesis. Therefore, We conclude the Time series is non-stationary.","metadata":{}},{"cell_type":"code","source":"print(estimated_residual)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T04:58:01.011821Z","iopub.execute_input":"2021-08-27T04:58:01.012299Z","iopub.status.idle":"2021-08-27T04:58:01.020622Z","shell.execute_reply.started":"2021-08-27T04:58:01.012257Z","shell.execute_reply":"2021-08-27T04:58:01.01971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adf_after, pvalue_after, usedlag_, nobs_, critical_values_, icbest_ = adfuller(estimated_residual[3:-3])\nprint(\"ADF: \", adf_after)\nprint(\"p-value: \", pvalue_after)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T04:58:01.215594Z","iopub.execute_input":"2021-08-27T04:58:01.215906Z","iopub.status.idle":"2021-08-27T04:58:01.246723Z","shell.execute_reply.started":"2021-08-27T04:58:01.21588Z","shell.execute_reply":"2021-08-27T04:58:01.245582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_hetero = data['y'] + 38\nrun_sequence_plot(data.index, new_hetero,\n                  title=\"Nonstationary Data w/Heteroscedasticity\")","metadata":{"execution":{"iopub.status.busy":"2021-08-27T05:14:10.053149Z","iopub.execute_input":"2021-08-27T05:14:10.053523Z","iopub.status.idle":"2021-08-27T05:14:10.296165Z","shell.execute_reply.started":"2021-08-27T05:14:10.053494Z","shell.execute_reply":"2021-08-27T05:14:10.295203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_new_hetero = np.log(new_hetero)\nrun_sequence_plot(data.index, log_new_hetero,\n                  title=\"Nonstationary Data w/Heteroscedasticity\")","metadata":{"execution":{"iopub.status.busy":"2021-08-27T05:14:27.937428Z","iopub.execute_input":"2021-08-27T05:14:27.937779Z","iopub.status.idle":"2021-08-27T05:14:28.159027Z","shell.execute_reply.started":"2021-08-27T05:14:27.937752Z","shell.execute_reply":"2021-08-27T05:14:28.158148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_diff = data['y'].diff()\ndf_diff","metadata":{"execution":{"iopub.status.busy":"2021-08-27T05:14:47.135065Z","iopub.execute_input":"2021-08-27T05:14:47.135399Z","iopub.status.idle":"2021-08-27T05:14:47.144144Z","shell.execute_reply.started":"2021-08-27T05:14:47.135371Z","shell.execute_reply":"2021-08-27T05:14:47.143454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_sequence_plot(data.index,df_diff,\n                  title=\"dataset(differenced)\")","metadata":{"execution":{"iopub.status.busy":"2021-08-27T05:14:55.088777Z","iopub.execute_input":"2021-08-27T05:14:55.089308Z","iopub.status.idle":"2021-08-27T05:14:55.332693Z","shell.execute_reply.started":"2021-08-27T05:14:55.089271Z","shell.execute_reply":"2021-08-27T05:14:55.331824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dividing Time series into Train and test for predictions.","metadata":{}},{"cell_type":"markdown","source":"We will be making predictions for 30 days","metadata":{}},{"cell_type":"code","source":"train = np.array(data['y'][1:-30])\ntest = np.array(data['y'][-30:])","metadata":{"execution":{"iopub.status.busy":"2021-08-27T07:27:28.776622Z","iopub.execute_input":"2021-08-27T07:27:28.777062Z","iopub.status.idle":"2021-08-27T07:27:28.812956Z","shell.execute_reply.started":"2021-08-27T07:27:28.777028Z","shell.execute_reply":"2021-08-27T07:27:28.811484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.api import SimpleExpSmoothing\n\nsingle = SimpleExpSmoothing(train).fit(optimized=True)\nsingle_preds = single.forecast(len(test))\nsingle_mse = mse(test, single_preds)\nprint(\"Predictions: \", single_preds)\nprint(\"MSE: \", single_mse)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T05:19:30.867264Z","iopub.execute_input":"2021-08-27T05:19:30.867784Z","iopub.status.idle":"2021-08-27T05:19:30.887861Z","shell.execute_reply.started":"2021-08-27T05:19:30.867751Z","shell.execute_reply":"2021-08-27T05:19:30.886944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(data.index[1:-30], train, 'b--', label=\"train\")\nplt.plot(data.index[-30:], test, color='orange', linestyle=\"--\", label=\"test\")\nplt.plot(data.index[-30:], single_preds, 'r--', label=\"predictions\")\nplt.legend(loc='upper left')\nplt.title(\"Simple Exponential Smoothing\")\nplt.grid(alpha=0.3);","metadata":{"execution":{"iopub.status.busy":"2021-08-27T05:19:37.301603Z","iopub.execute_input":"2021-08-27T05:19:37.301938Z","iopub.status.idle":"2021-08-27T05:19:37.564709Z","shell.execute_reply.started":"2021-08-27T05:19:37.30191Z","shell.execute_reply":"2021-08-27T05:19:37.563553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.api import Holt\n\ndouble = Holt(train).fit(optimized=True)\ndouble_preds = double.forecast(len(test))\ndouble_mse = mse(test, double_preds)\nprint(\"Predictions: \", double_preds)\nprint(\"MSE: \", double_mse)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T05:19:45.347481Z","iopub.execute_input":"2021-08-27T05:19:45.347862Z","iopub.status.idle":"2021-08-27T05:19:45.406196Z","shell.execute_reply.started":"2021-08-27T05:19:45.347824Z","shell.execute_reply":"2021-08-27T05:19:45.405241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(data.index[1:-30], train, 'b--', label=\"train\")\nplt.plot(data.index[-30:], test, color='orange', linestyle=\"--\", label=\"test\")\nplt.plot(data.index[-30:], double_preds, 'r--', label=\"predictions\")\nplt.legend(loc='upper left')\nplt.title(\"Double Exponential Smoothing\")\nplt.grid(alpha=0.3);","metadata":{"execution":{"iopub.status.busy":"2021-08-27T05:20:43.717082Z","iopub.execute_input":"2021-08-27T05:20:43.717514Z","iopub.status.idle":"2021-08-27T05:20:43.966075Z","shell.execute_reply.started":"2021-08-27T05:20:43.717486Z","shell.execute_reply":"2021-08-27T05:20:43.965373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.api import ExponentialSmoothing\n\ntriple = ExponentialSmoothing(train,\n                              trend=\"additive\",\n                              seasonal=\"additive\",\n                              seasonal_periods=13).fit(optimized=True)\ntriple_preds = triple.forecast(len(test))\ntriple_mse = mse(test, triple_preds)\nprint(\"Predictions: \", triple_preds)\nprint(\"MSE: \", triple_mse)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T05:24:11.918459Z","iopub.execute_input":"2021-08-27T05:24:11.918772Z","iopub.status.idle":"2021-08-27T05:24:12.145638Z","shell.execute_reply.started":"2021-08-27T05:24:11.918746Z","shell.execute_reply":"2021-08-27T05:24:12.144721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(data.index[1:-30], train, 'b--', label=\"train\")\nplt.plot(data.index[-30:], test, color='orange', linestyle=\"--\", label=\"test\")\nplt.plot(data.index[-30:], triple_preds, 'r--', label=\"predictions\")\nplt.legend(loc='upper left')\nplt.title(\"Triple Exponential Smoothing\")\nplt.grid(alpha=0.3);","metadata":{"execution":{"iopub.status.busy":"2021-08-27T05:24:12.146964Z","iopub.execute_input":"2021-08-27T05:24:12.147294Z","iopub.status.idle":"2021-08-27T05:24:12.443373Z","shell.execute_reply.started":"2021-08-27T05:24:12.147265Z","shell.execute_reply":"2021-08-27T05:24:12.442451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Comparing the results of the 3 statistical models.","metadata":{}},{"cell_type":"code","source":"print(\"Single MSE :{}\".format(single_mse))\nprint(\"Double MSE :{}\".format(double_mse))\nprint(\"Triple MSE :{}\".format(triple_mse))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T07:03:28.782357Z","iopub.execute_input":"2021-08-27T07:03:28.783026Z","iopub.status.idle":"2021-08-27T07:03:28.865057Z","shell.execute_reply.started":"2021-08-27T07:03:28.782897Z","shell.execute_reply":"2021-08-27T07:03:28.863541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Please Upvote if you appreciate the work. It would be really Helpful :)","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}