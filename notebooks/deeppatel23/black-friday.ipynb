{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Black Friday ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Problem: Predict purchase amount.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Step 1 : Import important libraries.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 2 : Import Data file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/black-friday/train.csv')\ndf_backup = pd.read_csv('../input/black-friday/train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 3 : Data Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We saw that inly 2 columns have nan values.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## (i) Gender","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib as plt\nfrom matplotlib import pyplot\n\nplt.pyplot.hist(df[\"Gender\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is found that man purchase 3 times as women.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dftemp = df[['Gender', 'Purchase']].groupby(['Gender'], as_index=False)\ndfG = dftemp.sum()\ndfG","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfG.plot(kind='bar')\nplt.xlabel = ('Gender')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<u>Thus, in terms of gender it is found that more man prefer to purchase than women on black friday, also man used to buy more expensive products on that day. So, man total purchase is almost 4 times than women.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## (ii) Age","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pyplot.hist(df[\"Age\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"26-35 years of people maximum buy products on this day.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## (iii) Occupation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Occupation'].plot(kind='hist', figsize=(20, 5), bins=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftemp = df[['Occupation', 'Purchase']].groupby(['Occupation'], as_index=False)\ndfO = dftemp.sum()\ndfO","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfO.plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We found that 0, 4 occupation were maximum among the people. Thus thier purchase (in terms of occupation) is maximum.\nI dont think we should use occupation for final training data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## (iv) City_Category","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pyplot.hist(df[\"City_Category\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftemp = df[['City_Category', 'Purchase']].groupby(['City_Category'], as_index=False)\ndfCity = dftemp.sum()\ndfCity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfCity.plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We found that category B has maximum frequency thus maximum purchase.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## (v) Stay_In_Current_City_Years","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pyplot.hist(df[\"Stay_In_Current_City_Years\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftemp = df[['Stay_In_Current_City_Years', 'Purchase']].groupby(['Stay_In_Current_City_Years'], as_index=False)\ndfStay = dftemp.sum()\ndfStay","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfStay.plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## (vi) Marital_Status ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pyplot.hist(df[\"Marital_Status\"], bins = 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftemp = df[['Marital_Status', 'Purchase']].groupby(['Marital_Status'], as_index=False)\ndfMarried = dftemp.sum()\ndfMarried","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's found that most of non-married person bought the products on Black Friday.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## (vii) Product_Category_1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pyplot.hist(df[\"Product_Category_1\"], bins = 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## (viii) Product_Category_2 ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Product_Category_2'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pyplot.hist(df[\"Product_Category_2\"], bins = 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Product_Category_2\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We found that some categories has highest frequency. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Product_Category_2'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we will fill nan values with top three highest occuring values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# here we filled null values with most frequently occuring values\ncnt=0\nfor i,j in df.iterrows():\n    if pd.isnull(j['Product_Category_2']):\n        if cnt <= 70000:\n            df['Product_Category_2'][i] = '8.0'\n            cnt+=1\n        elif cnt <=130000:\n            df['Product_Category_2'][i] = '14.0'\n            cnt+=1\n        else :\n            df['Product_Category_2'][i] = '2.0'\n            cnt+=1\n        print(cnt)\n                \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Product_Category_2']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Product_Category_2'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, no nan values remaining. Changing data-type of column in necessary to uniform training.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Product_Category_2'] = df['Product_Category_2'].astype(int)\ndf['Product_Category_2'].dtype","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## (ix) Product_Category_3","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Product_Category_3'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, in this column we will perform steps similar to performed in previous column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Product_Category_3\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Product_Category_3'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnt=0\nfor i,j in df.iterrows():\n    if pd.isnull(j['Product_Category_3']):\n        if cnt <= 125000:\n            df['Product_Category_3'][i] = '16.0'\n            cnt+=1\n        elif cnt <=240000:\n            df['Product_Category_3'][i] = '15.0'\n            cnt+=1\n        elif cnt <= 300000 :\n            df['Product_Category_3'][i] = '14.0'\n            cnt+=1\n        elif cnt <= 345000 :\n            df['Product_Category_3'][i] = '17.0'\n            cnt+=1\n        else :\n            df['Product_Category_3'][i] = '5.0'\n            cnt+=1\n        print(cnt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Product_Category_3'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Product_Category_3'] = df['Product_Category_3'].astype(int)\ndf['Product_Category_3'].dtype","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, no nan values remaining.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 4 : Preparing Data for model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_data = df['Purchase'].copy()\nx_data = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Removing unnecessary columns.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_data.drop(['Purchase', 'User_ID', 'Product_ID'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Converting category columns to labels is necessary.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.preprocessing import LabelEncoder\ncategorical_column = ['Gender','Age','City_Category','Stay_In_Current_City_Years']\nle = LabelEncoder()\nfor i in categorical_column:\n    x_data[i] = le.fit_transform(x_data[i])\nx_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.20, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 5 : Trying different regression technique","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlm = LinearRegression()\nlm.fit(x_train, y_train)\n\ntest_y_hat = lm.predict(x_test)\nprint(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_hat - y_test)))\nprint(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_hat - y_test) ** 2))\n\nfrom sklearn.metrics import r2_score\nprint(\"R2-score: %.2f\" % r2_score(test_y_hat , y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nmodel = DecisionTreeRegressor()\nmodel.fit(x_train, y_train)\n\ntest_y_hat = model.predict(x_test)\nprint(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_hat - y_test)))\nprint(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_hat - y_test) ** 2))\n\nfrom sklearn.metrics import r2_score\nprint(\"R2-score: %.2f\" % r2_score(test_y_hat , y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score\nfrom xgboost import XGBRegressor\n\nmy_model = XGBRegressor(n_estimators=1000, learning_rate=0.05, objective ='reg:linear')\nmy_model.fit(x_train,y_train)\npredictions = my_model.predict(x_test)\n\nfrom sklearn.metrics import mean_absolute_error\nprint(\"Mean absolute error: %.2f\" % np.mean(np.absolute(predictions - y_test)))\nprint(\"Residual sum of squares (MSE): %.2f\" % np.mean((predictions - y_test) ** 2))\nprint(\"Accuracy of train dataset is : \",my_model.score(x_train,y_train))\nprint(\"Accuracy of test dataset is : \",my_model.score(x_test,y_test))\n\nfrom sklearn.metrics import r2_score\nprint(\"R2-score: %.2f\" % r2_score(predictions, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Trying different ways to increase accuracy.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_data_new = x_data.copy()\nx_data_new.drop(['Stay_In_Current_City_Years', 'Marital_Status', 'Occupation'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train_n, x_test_n, y_train_n, y_test_n = train_test_split(x_data_new, y_data, test_size=0.20, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nmodel = DecisionTreeRegressor()\nmodel.fit(x_train_n, y_train_n)\n\ntest_y_hat = model.predict(x_test_n)\nprint(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_hat - y_test_n)))\nprint(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_hat - y_test_n) ** 2))\n\nfrom sklearn.metrics import r2_score\nprint(\"R2-score: %.2f\" % r2_score(test_y_hat , y_test_n))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score\nfrom xgboost import XGBRegressor\n\nmy_model = XGBRegressor(n_estimators=1000, learning_rate=0.05, objective ='reg:linear')\nmy_model.fit(x_train_n,y_train_n)\npredictions = my_model.predict(x_test_n)\n\nfrom sklearn.metrics import mean_absolute_error\nprint(\"Mean absolute error: %.2f\" % np.mean(np.absolute(predictions - y_test_n)))\nprint(\"Residual sum of squares (MSE): %.2f\" % np.mean((predictions - y_test_n) ** 2))\nprint(\"Accuracy of train dataset is : \",my_model.score(x_train_n,y_train_n))\nprint(\"Accuracy of test dataset is : \",my_model.score(x_test_n,y_test_n))\n\nfrom sklearn.metrics import r2_score\nprint(\"R2-score: %.2f\" % r2_score(predictions, y_test_n))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 6 : Deriving result for test dataset.csv ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_final = x_data.copy()\ny_train_final = y_data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_final = pd.read_csv('../input/black-friday/test.csv')\nx_test_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_final.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to deal with missimg values in test df.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_final[\"Product_Category_2\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_final[\"Product_Category_2\"].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# here we filled null values with most frequently occuring values\ncnt=0\nfor i,j in x_test_final.iterrows():\n    if pd.isnull(j['Product_Category_2']):\n        if cnt <= 35000:\n            x_test_final['Product_Category_2'][i] = '8.0'\n            cnt+=1\n        elif cnt <=60000:\n            x_test_final['Product_Category_2'][i] = '14.0'\n            cnt+=1\n        else :\n            x_test_final['Product_Category_2'][i] = '2.0'\n            cnt+=1\n        print(cnt)\n                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_final['Product_Category_2'] = x_test_final['Product_Category_2'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\ncategorical_column = ['Gender','Age','City_Category','Stay_In_Current_City_Years']\nle = LabelEncoder()\nfor i in categorical_column:\n    x_test_final[i] = le.fit_transform(x_test_final[i])\nx_test_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_final.drop(['User_ID', 'Product_ID'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Due to lots of missing values, I decided to drop this column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_final.drop('Product_Category_3', axis=1, inplace=True)\nx_test_final.drop('Product_Category_3', axis=1, inplace=True)\nx_test_final.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_final.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score\nfrom xgboost import XGBRegressor\n\nmy_model = XGBRegressor(n_estimators=1000, learning_rate=0.05)\nmy_model.fit(x_train_final,y_train_final)\npredictions = my_model.predict(x_test_final)\nprint(predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preparing Dataframe for submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"col_list = ['User_ID', 'Product_ID']\ndf_submission = pd.read_csv('../input/black-friday/test.csv',usecols=col_list)\ndf_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission['Purchase'] = predictions\ndf_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission.set_index('Purchase', inplace=True)\ndf_submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Saving our dataframe to file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission.to_csv(\"submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# END","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}