{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center>Heart Disease Prediction</center>\n\n## 1. Introduction\n\n**Objective:** <br/>\n<p align=\"justify\">Amongst all the organs, The heart is a significant part of our body. The heart beats about 2.5 billion times over the average lifetime, pushing millions of gallons of blood to every part of the body.<br/>In this era, the heart disease is increasing day by day due to the modern lifestyle and food. The diagnosis of heart disease is a challenging task. This classification model will predict whether the patient has heart disease or not based on various conditions/symptoms of their body.</p>\n\n**Data Description:** <br/>\nThe dataset contains 13 independent features and 1 target feature as described below.<br/>\n> 1. age \n> 2. sex \n> 3. cp (chest pain type) (4 values) \n> 4. trestbps (resting blood pressure)\n> 5. chol (serum cholestoral in mg/dl)\n> 6. fbs (fasting blood sugar) > 120 mg/dl\n> 7. restecg (resting electrocardiographic results) (values 0,1,2)\n> 8. thalach (maximum heart rate achieved)\n> 9. exang (exercise induced angina)\n> 10. oldpeak = ST depression induced by exercise relative to rest \n> 11. the slope of the peak exercise ST segment \n> 12. ca - number of major vessels (0-3) colored by flourosopy \n> 13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n> 14. target - is the binary target variable, 0 indicates that the patient has heart disease, the value is 1 if not.","metadata":{"_uuid":"8847586ebe81234033e035791f2f39ad7bca7b8f"}},{"cell_type":"markdown","source":"## 2. Exploratory Data Analysis (EDA)","metadata":{"_uuid":"0afd7074767e4f2cc1a705b3ac288036d9fc8a77","trusted":true}},{"cell_type":"markdown","source":"### 2.1 Import Libraries","metadata":{"_uuid":"4fba225ba1ef9a0c40bdad8e1f360b5552db6995"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random as rnd\nimport os\nimport warnings\n\nfrom operator import add\n\nMEDIUM_SIZE = 10\nSMALL_SIZE = 8\nMEDIUM_SIZE = 10\nBIGGER_SIZE = 12\n\n%matplotlib inline\nwarnings.filterwarnings('ignore')\n\nprint(os.listdir(\"../input\"))\nos.chdir(\"../input\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-31T14:58:12.62907Z","iopub.execute_input":"2021-08-31T14:58:12.629353Z","iopub.status.idle":"2021-08-31T14:58:13.87641Z","shell.execute_reply.started":"2021-08-31T14:58:12.629307Z","shell.execute_reply":"2021-08-31T14:58:13.875413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2 Import Dataset","metadata":{"_uuid":"a5ebbc200d9829bc1e04dbdd92b2499a331c1293"}},{"cell_type":"code","source":"df = pd.read_csv('heart.csv')\ndf.head()","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-08-31T14:58:13.877959Z","iopub.execute_input":"2021-08-31T14:58:13.878482Z","iopub.status.idle":"2021-08-31T14:58:14.055202Z","shell.execute_reply.started":"2021-08-31T14:58:13.878418Z","shell.execute_reply":"2021-08-31T14:58:14.054066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Dataset contains {df.shape[0]} samples, {df.shape[1] - 1} independent features 1 target continuous variable.')","metadata":{"_uuid":"55740eef21d18da6068479e5bfc2e02760e848de","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-31T14:58:14.056665Z","iopub.execute_input":"2021-08-31T14:58:14.057052Z","iopub.status.idle":"2021-08-31T14:58:14.062918Z","shell.execute_reply.started":"2021-08-31T14:58:14.056982Z","shell.execute_reply":"2021-08-31T14:58:14.06201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.3 Basic Analysis","metadata":{"_uuid":"ffc0ef500be8dbb926143d3ec6fd491edf065ddd"}},{"cell_type":"code","source":"print(df.info())\nmissing_values = (df.isnull().sum() / len(df)) * 100\nprint(\"\\nFeatures with missing values: \\n\", missing_values[missing_values > 0])","metadata":{"_uuid":"5508a1899ea7c549052df3819db33df3cce4bd93","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-31T14:58:14.064332Z","iopub.execute_input":"2021-08-31T14:58:14.064876Z","iopub.status.idle":"2021-08-31T14:58:14.213891Z","shell.execute_reply.started":"2021-08-31T14:58:14.064811Z","shell.execute_reply":"2021-08-31T14:58:14.212944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* All the independent features in the dataset are numeric.\n* The target variable is numeric.\n* There is no feature with missing values.","metadata":{"_uuid":"ac2223b46b889f1555d618c203cfc5310f36e862"}},{"cell_type":"code","source":"df.describe()","metadata":{"_uuid":"58165679f227e18bd541d508cf2d46d86c67d34b","execution":{"iopub.status.busy":"2021-08-31T14:58:14.215288Z","iopub.execute_input":"2021-08-31T14:58:14.215844Z","iopub.status.idle":"2021-08-31T14:58:14.298243Z","shell.execute_reply.started":"2021-08-31T14:58:14.215758Z","shell.execute_reply":"2021-08-31T14:58:14.297267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* No outliers seen in the data.","metadata":{"_uuid":"e245a525440c61ab951bb3fb4b5f4086bd3b4a68"}},{"cell_type":"code","source":"print(np.char.center(\" Unique values of categorical variables \", 60, fillchar = \"*\"))\nprint(\"\\nSex: \", df.sex.unique())\nprint(\"Cp: \", sorted(df.cp.unique()))\nprint(\"fbs: \", sorted(df.fbs.unique()))\nprint(\"restecg: \", sorted(df.restecg.unique()))\nprint(\"exang: \", sorted(df.exang.unique()))\nprint(\"slope: \", sorted(df.slope.unique()))\nprint(\"ca: \", sorted(df.ca.unique()))\nprint(\"thal: \", sorted(df.thal.unique()))\nprint(\"target: \", sorted(df.target.unique()))","metadata":{"_uuid":"016b75639943d256b879f17c30840b9f80d967da","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-31T14:58:14.29969Z","iopub.execute_input":"2021-08-31T14:58:14.300251Z","iopub.status.idle":"2021-08-31T14:58:14.314016Z","shell.execute_reply.started":"2021-08-31T14:58:14.300188Z","shell.execute_reply":"2021-08-31T14:58:14.312897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Sex is a nominal variable. 1 - Male, 0 - Famale\n* Cp - Chest pain type is a nominal variable, unique values are 0, 1, 2 and 3\n* fbs - fasting blood sugar is a binary variable. Value is **1** f (fasting blood sugar) > 120 mg/dl, otherwise **0**\n* restecg - resting electrocardiographic results - is a nominal variable, unique values are 0, 1 and 2\n* exang - exercise induced angina is a binary variable, Value is **1** is induced, **0** if not\n* slope - the slope of the peak exercise ST segment is a nominal variable, unique values are 0, 1 and 2\n* ca - number of major vessels (0-3) colored by flourosopy is an ordinal variable, values are 0, 1, 2, 3 and 4\n* thal - 3 = normal; 6 = fixed defect; 7 = reversable defect is an nominal variable, values are 0, 1, 2 and 3","metadata":{"_uuid":"cab2314affac153d78022252b9b261d1a2d14d9d"}},{"cell_type":"markdown","source":"### 2.4 Detailed Analysis","metadata":{"_uuid":"3888010d7a902c0d8b688cf3d650399632480c96"}},{"cell_type":"code","source":"def draw_semi_pie_chart(data, column, fig, renamed_index_dict, title):\n    default_colors = ['#66b3ff', '#ff9999', '#99ff99', '#ffcc99', '#c2c2f0', '#ffb3e6', '#ff6666']\n    rnd.shuffle(default_colors)\n    ax = df[column].value_counts().rename(index = renamed_index_dict).plot.pie(colors = default_colors, autopct='%1.1f%%', startangle=90, title = title)\n    ax.set_ylabel('')\n    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] + ax.get_xticklabels() + ax.get_yticklabels()):\n        item.set_fontsize(20)\n        \n    centre_circle = plt.Circle((0,0), 0.70, fc='white')\n    fig.gca().add_artist(centre_circle)","metadata":{"_kg_hide-input":true,"_uuid":"5234e28d34d8b0c5aa73fcb4276688619e06d105","execution":{"iopub.status.busy":"2021-08-31T14:58:14.315427Z","iopub.execute_input":"2021-08-31T14:58:14.315781Z","iopub.status.idle":"2021-08-31T14:58:14.324161Z","shell.execute_reply.started":"2021-08-31T14:58:14.315695Z","shell.execute_reply":"2021-08-31T14:58:14.322942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Categorical Feature Value Ratio**","metadata":{"_uuid":"88edde160c09ea78935736e6c23590df73713e3c"}},{"cell_type":"code","source":"fig = plt.gcf()\nfig.set_size_inches(18, 17)\ngrid_rows = 3\ngrid_cols = 3\n\n# Draw Sex Pie chart\nplt.subplot(grid_rows, grid_cols, 1)\ndraw_semi_pie_chart(df, 'sex', fig, {0: 'Female', 1: 'Male'}, 'Sex')\n\n# Draw Chest pain type chart\nplt.subplot(grid_rows, grid_cols, 2)\ndraw_semi_pie_chart(df, 'cp', fig, {0:'Typical Angina', 1:'Atypical Angina', 2:'Non-anginal Pain',3:'Asymptomatic'}, 'Chest Pain Type')\n\n# Draw Fasting blood sugar chart\nplt.subplot(grid_rows, grid_cols, 3)\ndraw_semi_pie_chart(df, 'fbs', fig, {0:'True', 1:'False'}, 'Fasting Blood Sugar')\n\n# Draw restecg - resting electrocardiographic results\nplt.subplot(grid_rows, grid_cols, 4)\ndraw_semi_pie_chart(df, 'restecg', fig, {0:'Normal', 1:'Abnormality', 2:'Left Ventricular Hypertrophy'}, 'Resting Electrocardiographic Results')\n\n# Draw exang - exercise induced angina\nplt.subplot(grid_rows, grid_cols, 5)\ndraw_semi_pie_chart(df, 'exang', fig, {0:'Not Induced', 1:'Induced'}, 'Exercise Induced Angina')\n\n# Draw exang - exercise induced angina\nplt.subplot(grid_rows, grid_cols, 6)\ndraw_semi_pie_chart(df, 'slope', fig, {0:'Upsloping', 1:'Flat', 2:'Downsloping'}, 'Slope')\n\n# Draw ca\nplt.subplot(grid_rows, grid_cols, 7)\ndraw_semi_pie_chart(df, 'ca', fig, {0:'0', 1:'1', 2:'2', 3:'3', 4:'4'}, 'CA')\n\n# Draw thal\nplt.subplot(grid_rows, grid_cols, 8)\ndraw_semi_pie_chart(df, 'thal', fig, {0:'0', 1:'1', 2:'2', 3:'3'}, 'Thal')\n\nfig.tight_layout()\nplt.show()","metadata":{"_uuid":"4ccb4ba15b4a705ae6c4ea63a3fdf8a96a63dc1a","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-31T14:58:14.325886Z","iopub.execute_input":"2021-08-31T14:58:14.326315Z","iopub.status.idle":"2021-08-31T14:58:15.531245Z","shell.execute_reply.started":"2021-08-31T14:58:14.326237Z","shell.execute_reply":"2021-08-31T14:58:15.530296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Categorical features are not well balanced in the dataset.\n* Dataset contains more male patients than female.\n* Typical Angina and Non-Anginal is the common Chest pain type.\n* Most of the patients has Fasting Blood Sugar > 120 mg/dl.\n* Left Ventricular Hypertrophy is observed least in Resting Electrocardiographics Results.\n* Excersize didn't induce Angina for more than 60%+ patients.\n* Unslopping is least observed in the Slope.\n* Least type of CA is 4 and most type is 0\n* Least type of Thal is 0 and most type is 2","metadata":{"_uuid":"9e59ecccb86ee87bb1189b35c7b6fc29e4d2c53f"}},{"cell_type":"code","source":"def create_percent_stacked_barchart(data, title = None, ylabel = None, xlabel = None):\n    default_colors = ['#019600', '#3C5F5A', '#219AD8']\n    # From raw value to percentage\n    totals = data.sum(axis=1)\n    bars = ((data.T / totals) * 100).T\n    r = list(range(data.index.size))\n\n    # Plot\n    barWidth = 0.95\n    names = data.index.tolist()\n    bottom = [0] * bars.shape[0]\n\n    # Create bars\n    color_index = 0\n    plots = []\n    for bar in bars.columns:\n        plots.append(plt.bar(r, bars[bar], bottom=bottom, color=default_colors[color_index], edgecolor='white', width=barWidth))\n        bottom = list(map(add, bottom, bars[bar]))\n        color_index = 0 if color_index >= len(default_colors) else color_index + 1\n\n    # Custom x axis\n    plt.title(title)\n    plt.xticks(r, names)\n    plt.xlabel(data.index.name if xlabel is None else xlabel)\n    plt.ylabel(data.columns.name if ylabel is None else ylabel)\n    ax = plt.gca()\n        \n    y_labels = ax.get_yticks()\n    ax.set_yticklabels([str(y) + '%' for y in y_labels])\n\n    flat_list = [item for sublist in data.T.values for item in sublist]\n    for i, d in zip(ax.patches, flat_list):\n        data_label = str(d) + \" (\" + str(round(i.get_height(), 2)) + \"%)\"\n        ax.text(i.get_x() + 0.45, i.get_y() + 5, data_label, horizontalalignment='center', verticalalignment='center', fontdict = dict(color = 'white', size = 20))\n\n    for item in ([ax.title]):\n        item.set_fontsize(27)\n        \n    for item in ([ax.xaxis.label, ax.yaxis.label] + ax.get_xticklabels() + ax.get_yticklabels()):\n        item.set_fontsize(24)\n    \n    legend = ax.legend(plots, bars.columns.tolist(), fancybox=True)\n    plt.setp(legend.get_texts(), fontsize='20')","metadata":{"_uuid":"2711b6a973fdf4d6d7bb1d87e4e94a09ea7950f9","_kg_hide-input":true,"scrolled":true,"execution":{"iopub.status.busy":"2021-08-31T14:58:15.532554Z","iopub.execute_input":"2021-08-31T14:58:15.532813Z","iopub.status.idle":"2021-08-31T14:58:15.546042Z","shell.execute_reply.started":"2021-08-31T14:58:15.532758Z","shell.execute_reply":"2021-08-31T14:58:15.545293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Categorical Feature Value Ratio against Target**","metadata":{"_uuid":"ce69a90c8b74801095df4a1f319d5f4549c26033"}},{"cell_type":"code","source":"fig = plt.gcf()\nfig.set_size_inches(25, 35)\ngrid_rows = 4\ngrid_cols = 2\n\n# Draw Disease Status vs Sex chart\nplt.subplot(grid_rows, grid_cols, 1)\ntemp = df[['sex','target']].groupby(['sex','target']).size().unstack('target')\ntemp.rename(index={0:'Female', 1:'Male'}, columns={0:'No Disease', 1:'Has Disease'}, inplace = True)\ncreate_percent_stacked_barchart(temp, title = 'Disease Status vs Sex', ylabel = 'Population')\n\n# Draw Disease Status vs Chest pain type chart\nplt.subplot(grid_rows, grid_cols, 2)\ntemp = df[['cp','target']].groupby(['cp','target']).size().unstack('target')\ntemp.rename(index={0:'Typical \\nAngina', 1:'Atypical \\nAngina', 2:'Non-\\nanginal\\nPain',3:'Asymptomatic'}, columns={0:'No Disease', 1:'Has Disease'}, inplace = True)\ncreate_percent_stacked_barchart(temp, title = 'Disease Status vs Chest Pain Type (cp)', ylabel = 'Population', xlabel = 'Chest Pain Type')\n\n# Draw fbs - fasting blood sugar chart\nplt.subplot(grid_rows, grid_cols, 3)\ntemp = df[['fbs','target']].groupby(['fbs','target']).size().unstack('target')\ntemp.rename(index={0:'True', 1:'False'}, columns={0:'No Disease', 1:'Has Disease'}, inplace = True)\ncreate_percent_stacked_barchart(temp, title = 'Disease Status vs Fasting Blood Sugar(fbs)', ylabel = 'Population', xlabel = 'Fasting Blood Sugar > 120 mg/dl')\n\n# Draw restecg - resting electrocardiographic results chart\nplt.subplot(grid_rows, grid_cols, 4)\ntemp = df[['restecg','target']].groupby(['restecg','target']).size().unstack('target')\ntemp.rename(index={0:'Normal', 1:'Abnormality', 2:'Left Ventricular \\nHypertrophy'}, columns={0:'No Disease', 1:'Has Disease'}, inplace = True)\ncreate_percent_stacked_barchart(temp, title = 'Disease Status vs Resting Electrocardiographic Results (restecg)', ylabel = 'Population', xlabel = 'Resting Electrocardiographic Results')\n\n# Draw exang - exercise induced angina chart\nplt.subplot(grid_rows, grid_cols, 5)\ntemp = df[['exang','target']].groupby(['exang','target']).size().unstack('target')\ntemp.rename(index={0:'Not Induced', 1:'Induced'}, columns={0:'No Disease', 1:'Has Disease'}, inplace = True)\ncreate_percent_stacked_barchart(temp, title = 'Disease Status vs Exercise Induced Angina (exang)', ylabel = 'Population', xlabel = 'Exercise Induced Angina')\n\n# Draw slope - the slope of the peak exercise ST segment chart\nplt.subplot(grid_rows, grid_cols, 6)\ntemp = df[['slope','target']].groupby(['slope','target']).size().unstack('target')\ntemp.rename(index={0:'Upsloping', 1:'Flat', 2:'Downsloping'}, columns={0:'No Disease', 1:'Has Disease'}, inplace = True)\ncreate_percent_stacked_barchart(temp, title = 'Disease Status vs Slope', ylabel = 'Population', xlabel = 'Slope')\n\n# Draw ca - number of major vessels (0-3) colored by flourosopy chart\nplt.subplot(grid_rows, grid_cols, 7)\ntemp = df[['ca','target']].groupby(['ca','target']).size().unstack('target')\ntemp.rename(columns={0:'No Disease', 1:'Has Disease'}, inplace = True)\ncreate_percent_stacked_barchart(temp, title = 'Disease Status vs CA', ylabel = 'Population', xlabel = 'CA')\n\n# Draw thal chart\nplt.subplot(grid_rows, grid_cols, 8)\ntemp = df[['thal','target']].groupby(['thal','target']).size().unstack('target')\ntemp.rename(columns={0:'No Disease', 1:'Has Disease'}, inplace = True)\ncreate_percent_stacked_barchart(temp, title = 'Disease Status vs Thal', ylabel = 'Population', xlabel = 'Thal')\nfig.tight_layout()\nplt.show()","metadata":{"_uuid":"858144f110f6f072bf59692ce8245290bc175fe1","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-31T14:58:15.546995Z","iopub.execute_input":"2021-08-31T14:58:15.547461Z","iopub.status.idle":"2021-08-31T14:58:18.613554Z","shell.execute_reply.started":"2021-08-31T14:58:15.54742Z","shell.execute_reply":"2021-08-31T14:58:18.612837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The feature 'sex' is biased in the sample. Hence saying 'most of the Females are tend to have heart disease' is **untrue**.\n* Pain with chest pain types Atypical Angina, Non-Anginal Pain, Asymptomatic more likely to have heart disease.","metadata":{"_uuid":"6ec18e2e053258a50575e1793205e3bfb2f8b95b"}},{"cell_type":"markdown","source":"**Correlation Heat Map**","metadata":{"_uuid":"f491d78304daa0e89349b4661feed3f8eb2f7dab"}},{"cell_type":"code","source":"fig = plt.gcf()\nfig.set_size_inches(15, 8)\nsns.heatmap(df.corr(), annot = True)\nplt.show()","metadata":{"_kg_hide-input":true,"_uuid":"0ed82f30512896067b217b2970f52e7d1622a4f4","execution":{"iopub.status.busy":"2021-08-31T14:58:18.615054Z","iopub.execute_input":"2021-08-31T14:58:18.615321Z","iopub.status.idle":"2021-08-31T14:58:19.706435Z","shell.execute_reply.started":"2021-08-31T14:58:18.61527Z","shell.execute_reply":"2021-08-31T14:58:19.705639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* There is no features with more than **0.5** correlation. This is a sad thing. :(","metadata":{"_uuid":"6c3d356a5234c6b5bdefa88c8254a5764cb4072c"}},{"cell_type":"markdown","source":"**Distributions**","metadata":{"_uuid":"d8813f658e5e21b58c3cac0a67b4b10a156cd4ce"}},{"cell_type":"code","source":"continuous_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'target']\nnumber_of_columns = len(continuous_features)\nnumber_of_rows = 5\nplt.figure(figsize=(23, 18))\n\nfor i, f in enumerate(continuous_features):\n    plt.subplot(number_of_rows + 1, number_of_columns, i + 1)\n    sns.distplot(df[f], kde=True)","metadata":{"_kg_hide-input":true,"_uuid":"174e5e98c27aeb7d96ba823e33bacde8fca32081","execution":{"iopub.status.busy":"2021-08-31T14:58:19.708139Z","iopub.execute_input":"2021-08-31T14:58:19.708471Z","iopub.status.idle":"2021-08-31T14:58:21.310178Z","shell.execute_reply.started":"2021-08-31T14:58:19.708407Z","shell.execute_reply":"2021-08-31T14:58:21.309176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The features Age, trestbps, chol are normally distributed.\n* The likelihood of getting heart disease of more for the people with age 50 - 60.\n* The target variable is balanced.","metadata":{"_uuid":"add8e4d7d439dd5276351d7f1aedac5c4037483a"}},{"cell_type":"markdown","source":"**Pair Plots**","metadata":{"_uuid":"89bbc4d3e982e037cfca1ec7d32c01ffbf917528"}},{"cell_type":"code","source":"sns.pairplot(df, hue = 'target', markers=[\"o\", \"s\"], vars = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak'], palette = sns.color_palette(\"bright\", 10))","metadata":{"_kg_hide-input":true,"_uuid":"307a6fd807ed6debfcf1d760ebfc7150108dbb57","execution":{"iopub.status.busy":"2021-08-31T14:58:21.311868Z","iopub.execute_input":"2021-08-31T14:58:21.312542Z","iopub.status.idle":"2021-08-31T14:58:26.791738Z","shell.execute_reply.started":"2021-08-31T14:58:21.312474Z","shell.execute_reply":"2021-08-31T14:58:26.79073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* There is no feature pair that well seperates the data. :(","metadata":{"_uuid":"8c81d96a8e55ceb7cf0119f8ffda6a76da5f459f"}},{"cell_type":"markdown","source":"## 3. Data Pre Processing","metadata":{"_uuid":"388c2e46bc7b8ee4399f3fc8a239bc987aa36752"}},{"cell_type":"markdown","source":"### 3.1 Extract Independent and Target Variables","metadata":{"_uuid":"6e0653657469a1fa174a98ceebabf6344b6e6039"}},{"cell_type":"markdown","source":"* Here the independet features will be extracted along with OneHotEncoding will be done to the nominal features cp, slope, thal and restecg.\n* The parameter **drop_first = True** as been set in order to avoid dummy variable trap after One hot encoding","metadata":{"_uuid":"77ee7c8f81352141a0a215d6af2989fb5520293c"}},{"cell_type":"code","source":"nominal_features = ['cp', 'slope', 'thal', 'restecg']\nx = pd.get_dummies(df.drop(['target'], axis = 1), columns = nominal_features, drop_first=True).values\ny = df.target.values","metadata":{"_uuid":"f60ce9ed039aabef9f9fe9df80d5ca1f02833eea","execution":{"iopub.status.busy":"2021-08-31T14:58:26.792981Z","iopub.execute_input":"2021-08-31T14:58:26.793252Z","iopub.status.idle":"2021-08-31T14:58:26.809392Z","shell.execute_reply.started":"2021-08-31T14:58:26.793197Z","shell.execute_reply":"2021-08-31T14:58:26.808354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 Split the Data into Train and Test set","metadata":{"_uuid":"fe984548c872c259d079a83ef8b71c0507d54dcc"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","metadata":{"_uuid":"e621d74e594e8614e8915e6bb2cf6df5828847cf","execution":{"iopub.status.busy":"2021-08-31T14:58:26.810669Z","iopub.execute_input":"2021-08-31T14:58:26.810973Z","iopub.status.idle":"2021-08-31T14:58:27.168275Z","shell.execute_reply.started":"2021-08-31T14:58:26.81092Z","shell.execute_reply":"2021-08-31T14:58:27.167603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3 Feature Scalling","metadata":{"_uuid":"c6ba3f3f15fc4dee2564b961f9028f21971abe4d"}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","metadata":{"_uuid":"3bc91ee7162aba2d24ffb9d6bfcc20cd4156ca6e","execution":{"iopub.status.busy":"2021-08-31T14:58:27.169589Z","iopub.execute_input":"2021-08-31T14:58:27.169977Z","iopub.status.idle":"2021-08-31T14:58:27.176957Z","shell.execute_reply.started":"2021-08-31T14:58:27.169906Z","shell.execute_reply":"2021-08-31T14:58:27.176002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Dimensionality Reduction","metadata":{"_uuid":"e5259aba4c040ce401ab703ca6252a679418f6b4"}},{"cell_type":"markdown","source":"Linear Discriminant Analysis (LDA) will be used as dimensionality reduction technique for this dataset since it's a classification problem.","metadata":{"_uuid":"4f38c2581105fa0318cbf4a89a21d9ccb4db73ae"}},{"cell_type":"code","source":"print(\"Shape of X before Dimensionlity Reduction: \", x_train.shape)\n\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nlda = LDA()\nx_train = lda.fit_transform(x_train, y_train)\nx_test = lda.transform(x_test)\n\nprint(\"Shape of X after Dimensionlity Reduction: \", x_train.shape)","metadata":{"_uuid":"9a8cf7b7ba07cc365ec3d69dbba24d15bcefefe5","execution":{"iopub.status.busy":"2021-08-31T14:58:27.17834Z","iopub.execute_input":"2021-08-31T14:58:27.178947Z","iopub.status.idle":"2021-08-31T14:58:27.435628Z","shell.execute_reply.started":"2021-08-31T14:58:27.178888Z","shell.execute_reply":"2021-08-31T14:58:27.434725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Build and Train the Model","metadata":{"_uuid":"0e329ee0f246f36bc3d7ce1f63bbc9dac5e7281a"}},{"cell_type":"markdown","source":"### 5.1 Train the Model with Training Set","metadata":{"_uuid":"5a901dde076bdb8a1bef383710762744ef05622f"}},{"cell_type":"markdown","source":"Support Vector Machine Classifier and K-Nearest Neighbors have been used to compare the model performance.","metadata":{"_uuid":"cbe6f9009784fb28d872432f88d8611700f2e158"}},{"cell_type":"code","source":"# SVM\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(x_train, y_train)\ny_pred_svm = classifier.predict(x_test)\n\n# KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier_knn = KNeighborsClassifier()\nclassifier_knn.fit(x_train, y_train)\ny_pred_knn = classifier_knn.predict(x_test)","metadata":{"_uuid":"59c45177906910387aa543dccd6fc48107274223","execution":{"iopub.status.busy":"2021-08-31T14:58:27.437123Z","iopub.execute_input":"2021-08-31T14:58:27.43773Z","iopub.status.idle":"2021-08-31T14:58:27.449873Z","shell.execute_reply.started":"2021-08-31T14:58:27.43767Z","shell.execute_reply":"2021-08-31T14:58:27.449008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Model Evaluation","metadata":{"_uuid":"6b368a1422ecf5050f35fc42eefa9b8076f1112f"}},{"cell_type":"markdown","source":"### 6.1 Confusion Matrix","metadata":{"_uuid":"6c39f176f7db57963e343fce62d5c9652475bf4f"}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nprint(\"SVM Confusion Matrix\")\ncm = confusion_matrix(y_test, y_pred_svm)\nprint(cm)\n\nprint(\"KNN Confusion Matrix\")\ncm = confusion_matrix(y_test, y_pred_knn)\nprint(cm)","metadata":{"_uuid":"cf4ce2510fa038f4f6d185982f1366c3cf48cb47","execution":{"iopub.status.busy":"2021-08-31T14:58:27.451826Z","iopub.execute_input":"2021-08-31T14:58:27.452258Z","iopub.status.idle":"2021-08-31T14:58:27.464313Z","shell.execute_reply.started":"2021-08-31T14:58:27.452179Z","shell.execute_reply":"2021-08-31T14:58:27.463046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* KNN predicts more false negative than SVM.","metadata":{"_uuid":"3514a5ae4d9753702cbc64e560d04e55a925604a"}},{"cell_type":"markdown","source":"### 6.2 K-Fold Cross Validation","metadata":{"_uuid":"254303051fb8f985c88a8e63cfce7940ff043f58"}},{"cell_type":"markdown","source":"Ten fold cross validation will be performed.","metadata":{"_uuid":"0856939fd96c93b81d17f67bbe79194ff8782542"}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(classifier, x_train, y_train, cv = 10)\nprint(\"Scores: \", scores)\nprint(\"Accuracy: \", round(scores.mean(), 2) * 100, \"%\")\nprint(\"Standard Deviation: +/-\", scores.std())","metadata":{"_uuid":"bb93d164993eb03402810f8e296d81f840e2ad40","execution":{"iopub.status.busy":"2021-08-31T14:58:27.466094Z","iopub.execute_input":"2021-08-31T14:58:27.466681Z","iopub.status.idle":"2021-08-31T14:58:27.496805Z","shell.execute_reply.started":"2021-08-31T14:58:27.466406Z","shell.execute_reply":"2021-08-31T14:58:27.495869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. Model Optimization using Grid Search Technique","metadata":{"_uuid":"26a0922a802ecefdb6ea199af052775d27251ba5"}},{"cell_type":"markdown","source":"Grid search is used to find the best hyperparameter for the model.","metadata":{"_uuid":"50346f7916b9a02e9d827d26a58d7113a50fef29"}},{"cell_type":"markdown","source":"**Grid Search on SVM**","metadata":{"_uuid":"a7045b34aaf3b18ce3aa27e5638611a68d81db33"}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n              {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\ngrid_search = GridSearchCV(estimator = classifier, param_grid = parameters, scoring = 'accuracy', cv = 10, n_jobs = -1)\ngrid_search = grid_search.fit(x_train, y_train)\nbest_accuracy = grid_search.best_score_\nbest_parameters = grid_search.best_params_\n\nprint(\"Best Score: \", best_accuracy)\nprint(\"Best Params: \", best_parameters)","metadata":{"_uuid":"335b46eafe839b1a2b55c3ca21d79554e401dd86","execution":{"iopub.status.busy":"2021-08-31T14:58:27.498107Z","iopub.execute_input":"2021-08-31T14:58:27.498484Z","iopub.status.idle":"2021-08-31T14:58:34.29984Z","shell.execute_reply.started":"2021-08-31T14:58:27.498317Z","shell.execute_reply":"2021-08-31T14:58:34.299063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Grid Search on KNN**","metadata":{"_uuid":"91e389d24618dd9d670eed4140b3d01e8073bf78"}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparameters = {'n_neighbors': np.arange(1, 10)}\ngrid_search = GridSearchCV(estimator = classifier_knn, param_grid = parameters, scoring = 'accuracy', cv = 10, n_jobs = -1)\ngrid_search = grid_search.fit(x_train, y_train)\nbest_accuracy = grid_search.best_score_\nbest_parameters = grid_search.best_params_\n\nprint(\"Best Score: \", best_accuracy)\nprint(\"Best Params: \", best_parameters)","metadata":{"_uuid":"7075a25d75023b677c945a8298f5d9b6d4a9bbe7","execution":{"iopub.status.busy":"2021-08-31T14:58:34.301218Z","iopub.execute_input":"2021-08-31T14:58:34.301721Z","iopub.status.idle":"2021-08-31T14:58:34.470169Z","shell.execute_reply.started":"2021-08-31T14:58:34.301672Z","shell.execute_reply":"2021-08-31T14:58:34.469192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"KNN predicts slight more accurate than SVM, hence KNN will be chosen as the best model.","metadata":{"_uuid":"8570a6b98694261766454b4bc0a45032df34129e"}},{"cell_type":"markdown","source":"**Area Under the Curve (AUC) for SVM**","metadata":{"_uuid":"d14f3d2e940d8b8ce8577d896685ae67d4f9d095"}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', C = 1, random_state = 0, probability = True)\nclassifier.fit(x_train, y_train)\nprobs = classifier.predict_proba(x_test)\n# keep probabilities for the positive outcome only\nprobs = probs[:, 1]\n# calculate AUC\nauc = roc_auc_score(y_test, probs)\nprint('AUC: %.3f' % auc)\n# calculate roc curve\nfpr, tpr, thresholds = roc_curve(y_test, probs)\n# plot no skill\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.plot(fpr, tpr, marker='.')\nplt.show()","metadata":{"_uuid":"52dde5312972962ce182cac72ab43dfb6cca17cf","execution":{"iopub.status.busy":"2021-08-31T14:58:34.471636Z","iopub.execute_input":"2021-08-31T14:58:34.472028Z","iopub.status.idle":"2021-08-31T14:58:34.656659Z","shell.execute_reply.started":"2021-08-31T14:58:34.471957Z","shell.execute_reply":"2021-08-31T14:58:34.655943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8. Conclussion","metadata":{"_uuid":"e57ee70b8c0a3ff0e665ea7e6dde003d7e851731"}},{"cell_type":"markdown","source":"* Linear SVM with C = 1, will be chosen as the best model for this problem.\n* The best accuracy has been obtained as 91.4%","metadata":{"_uuid":"99e3be98ae9b80ca4fabbde22d54979591445024"}}]}