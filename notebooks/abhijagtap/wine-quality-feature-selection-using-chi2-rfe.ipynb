{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook i have done some data expolration & feature analysis using Chi-Square Test for Feature Selection &  SVM-based feature selection algorithm.\n\nThen i used different models to predict the wine quality \n\n1.Random Forest\n2.SVC\n\n**If you find this notebook useful then please upvote.**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#import all the necessary packages\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"winedb=pd.read_csv(r\"/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"winedb.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"winedb.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot the corr plot to see the corelation between variables\n\nd=pd.DataFrame(data=winedb)\ncorr=d.corr()\nf, ax = plt.subplots(figsize=(10, 6))\nhm = sns.heatmap(round(corr,2), annot=True, ax=ax, cmap=\"gray\",fmt='.2f',\n            linewidths=.05)\nf.subplots_adjust(top=0.93)\nt= f.suptitle('Correlation HeatMap', fontsize=14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Alcohoal has the highest positive corelation(0.48) with the quality of the wine ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **Preprocessing of Data Before Modelling**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Make the binary classification on the responce variable as per the tips return in data context\n\nDivide wine into good & Bad by giving the limit for the quality","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The bins parameter tells you the number of bins that your data will be divided into.\nbins = (2, 6.5, 8)\ngroup_names = ['bad', 'good']\nwinedb['quality'] = pd.cut(winedb['quality'], bins = bins, labels = group_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Assign labels\nlabel_quality = LabelEncoder()\n#Bad becomes 0 and good becomes 1 \nwinedb['quality'] = label_quality.fit_transform(winedb['quality'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"winedb['quality'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot the counts \nsns.countplot(winedb['quality'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Seperate the dataset\nY=winedb['quality']\nX = winedb.iloc[:,:11]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create test train split data\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,Y_train,Y_test=train_test_split(X, Y, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature selection using the chi-square test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = SelectKBest(score_func  = chi2, k ='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fitted = test.fit(X,Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(fitted.scores_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colnames =  list(X.columns)\nX  = np.array(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_1 = pd.DataFrame({'Feature_name':list(colnames),'Feature_score':list(fitted.scores_)}) \ndf_1\ndf_1.sort_values(['Feature_score'],ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature selection using the RFE on SVM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE  ##runs on top of some algorithm ..we can run on top of randomforest and DT also)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC #(running on SVM)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm = LinearSVC()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfe= RFE(svm, 10)  ## keep increasing the number to get the importance in order\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfe.fit(X, Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(rfe.support_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = pd.DataFrame( { \"Feature Names\": colnames , \"Importance\" : list(rfe.support_)})\ndf2.sort_values(['Importance'], ascending = False )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Trying the machine learning algorithms\nfrom sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(n_estimators=200)\nrfc.fit(X_train, Y_train)\npred_rfc = rfc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's see how our model performed\nprint(classification_report(Y_test, pred_rfc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(Y_test, pred_rfc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy for Random Forest is 90%","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#SVM\nfrom sklearn.svm import SVC\nsvc = SVC()\nsvc.fit(X_train, Y_train)\npred_svc = svc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(Y_test, pred_svc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracy for the SVC is 86%","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}