{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"8e030f9a-1e80-ee38-275b-a29cf22d434a"},"source":"# Introduction\nOn this notebook I will do several things on the mushroom dataset:\n\n1. Run a simple logistic regression\n2. Fit a model using random forest classifier\n3. Asses the feature importance, and reduce the number of features accordingly\n4. Do some visualization\n\nBefore I fit the model using logistic regression, I will clean and prepare the data first by using one-hot encoder."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"430acb37-ba69-2939-5d68-bf6d98f40e10"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b168892e-b7b4-663f-33c2-cdc28998207e"},"outputs":[],"source":"shroom = pd.read_csv('../input/mushrooms.csv')\nshroom[:3]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8b13353e-8504-7c72-255b-d00badf6a1c7"},"outputs":[],"source":"for feature in shroom.columns:\n    print(feature, ':', shroom[feature].unique())"},{"cell_type":"markdown","metadata":{"_cell_guid":"a690b775-66db-e162-b182-f9f24541c9d3"},"source":"It appears that all have categorical values. I think we need to change them into numerical values. But before that I think I will remove the missing values first, which occurs on the variable 'stalk-root'. I will also drop the 'veil-type' feature since it only consists of one value."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"988aa2b1-4a41-79b2-cec3-0cda1c3265bc"},"outputs":[],"source":"shroom = shroom.drop(shroom[shroom['stalk-root']=='?'].index)\nshroom = shroom.drop('veil-type', axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"10d228f1-8ae7-fcc2-7e91-c5a1f7a44927"},"outputs":[],"source":"# making sure no other missing values\nshroom.isnull().sum().sum()"},{"cell_type":"markdown","metadata":{"_cell_guid":"d0627c05-bb90-db45-a4f3-0e6950fdf174"},"source":"For features with two values I will use `LabelBinarizer`, otherwise I will use `pd.get_dummies`."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"97df719b-93bb-9274-585c-000793cb45d5"},"outputs":[],"source":"from sklearn.preprocessing import LabelBinarizer\nlb = LabelBinarizer()\nfor feature in shroom.columns:\n    if len(shroom[feature].unique()) == 2:\n        shroom[feature] = lb.fit_transform(shroom[feature])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"de0e9668-5a4f-7434-3a7f-8a2a7c7f66a4"},"outputs":[],"source":"features_onehot = []\nfor feature in shroom.columns[1:]:\n    if len(shroom[feature].unique()) > 2:\n        features_onehot.append(feature)\ntemp = pd.get_dummies(shroom[features_onehot])\nshroom = shroom.join(temp)\nshroom = shroom.drop(features_onehot, axis=1)\nshroom[:3]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cff5e407-1cb8-79dc-faee-5d5e4c1e8ff4"},"outputs":[],"source":"# making sure all values are numerical\nnp.unique(shroom.values)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"05872d5c-5b80-c02b-70d9-394465eec297"},"outputs":[],"source":"from sklearn.model_selection import train_test_split\n\nX = shroom.drop('class', axis=1).values\ny = shroom['class'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.3)\nprint('X_train Shape:', X_train.shape)\nprint('X_test Shape:', X_test.shape)\nprint('y_train Shape:', y_train.shape)\nprint('y_test Shape:', y_test.shape)"},{"cell_type":"markdown","metadata":{"_cell_guid":"bc10ef08-148d-ef1e-cb8f-11b0bcb8325b"},"source":"## Logistic Regression\nNow we are ready to train the data."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"94e75ba7-ad69-7013-932f-b2063718d545"},"outputs":[],"source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\nprint('Training Accuracy: %.2f%%' % (lr.score(X_train, y_train)*100))\nprint('Test Accuracy: %.2f%%' % (lr.score(X_test, y_test)*100))"},{"cell_type":"markdown","metadata":{"_cell_guid":"f35184fe-d561-d323-c5d0-fa9df5797fc4"},"source":"With 100% accuracy, it is either the data is actually linearly separable or there is something wrong in my code."},{"cell_type":"markdown","metadata":{"_cell_guid":"ab29b578-5c09-4741-4dcb-5037c7ef1e6d"},"source":"# Random Forest\nNow I will use random forest classifier to fit the model and to find out the feature importance. Since random forest require no one-hot encoding, I will load the data again. This time I will not drop the 'veil-type' feature just to see what will happen."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"de2c8ce5-a8d8-3a80-8261-d5939b6cc1ae"},"outputs":[],"source":"mushroom = pd.read_csv('../input/mushrooms.csv')\nshroom2 = mushroom.drop(mushroom[mushroom['stalk-root']=='?'].index)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f09384ab-e16d-2c96-f212-11dba91ac12b"},"outputs":[],"source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79b8c1d9-3769-e726-f193-70a5a385638d"},"outputs":[],"source":"lbe = LabelEncoder()\nfor feature in shroom2.columns[1:]:\n    shroom2[feature] = lbe.fit_transform(shroom2[feature])\nshroom2[:3]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d7a5521e-4a58-ba48-2654-1672c07d21de"},"outputs":[],"source":"y = shroom2['class'].values\nX = shroom2.drop('class', axis=1).values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b913154b-1811-2cfb-52f3-25b0f5f96bb3"},"outputs":[],"source":"rfc = RandomForestClassifier(n_estimators=500, n_jobs=-1)\nrfc.fit(X_train, y_train)\nprint('Training Score: %.2f%%' % (rfc.score(X_train, y_train) * 100))\nprint('Test Score: %.2f%%' % (rfc.score(X_test, y_test) * 100))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd112687-29b0-4168-3a1c-ca72368d99e0"},"outputs":[],"source":"importances = rfc.feature_importances_\nfeatures = shroom2.columns[1:]\nsort_indices = np.argsort(importances)[::-1]\nsorted_features = []\nfor idx in sort_indices:\n    sorted_features.append(features[idx])\nplt.figure()\nplt.bar(range(len(importances)), importances[sort_indices], align='center');\nplt.xticks(range(len(importances)), sorted_features, rotation='vertical');\nplt.xlim([-1, len(importances)])\nplt.grid(False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"64d5c243-2214-4550-9d0e-bb92a4fdfaed"},"source":"## Dimensionality Reduction\nIt seems that we can fit the model just using the top features. So we will again fit the model using logistic regression and random forest classifier using just those features and see what will happen."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9c1ffd37-83c5-ad8b-53b3-01237a408281"},"outputs":[],"source":"# random forest\ntop_features = sorted_features[:2]\ny = shroom2['class'].values\nX = shroom2[top_features].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\nrfc = RandomForestClassifier(n_estimators=500, n_jobs=-1)\nrfc.fit(X_train, y_train)\nprint('Random Forest with 2 features')\nprint('Training Score: %.2f%%' % (rfc.score(X_train, y_train) * 100))\nprint('Test Score: %.2f%%' % (rfc.score(X_test, y_test) * 100))"},{"cell_type":"markdown","metadata":{"_cell_guid":"03c51b80-ce44-b482-cf75-d9fac525e1e1"},"source":"They looks good enough to me, considering we use much fewer feature than we did previously."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"349f52a3-1ef2-2f04-1553-24f2e137ed69"},"outputs":[],"source":"# logistic regression\ntop_features_2 = [\n    'odor_a', 'odor_c', 'odor_f', 'odor_l', 'odor_m', 'odor_n', 'odor_p', # feature 1\n    'spore-print-color_h', 'spore-print-color_k','spore-print-color_n', # feature 2\n    'spore-print-color_r', 'spore-print-color_u', 'spore-print-color_w',\n]\ny = shroom['class'].values\nX = shroom[top_features_2].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\nprint('Logistic Regression with 2 features')\nprint('Training Accuracy: %.2f%%' % (lr.score(X_train, y_train)*100))\nprint('Test Accuracy: %.2f%%' % (lr.score(X_test, y_test)*100))"},{"cell_type":"markdown","metadata":{"_cell_guid":"47dacd8c-9ac8-c935-1cd9-96eaa320c8b0"},"source":"### What if we just use one variable?"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ae0e68a3-97ce-451f-1f3c-182c751fab90"},"outputs":[],"source":"# random forest\ntop_features = sorted_features[:1]\ny = shroom2['class'].values\nX = shroom2[top_features].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\nrfc = RandomForestClassifier(n_estimators=500, n_jobs=-1)\nrfc.fit(X_train, y_train)\nprint('Random Forest with 1 feature')\nprint('Training Score: %.2f%%' % (rfc.score(X_train, y_train) * 100))\nprint('Test Score: %.2f%%' % (rfc.score(X_test, y_test) * 100))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6ee15c77-3bd4-dab3-786f-b5b870e3d56e"},"outputs":[],"source":"# logistic regression\ntop_features_2 = [\n    'odor_a', 'odor_c', 'odor_f', 'odor_l', 'odor_m', 'odor_n', 'odor_p', # feature 1\n]\ny = shroom['class'].values\nX = shroom[top_features_2].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\nprint('Logistic Regression with 1 feature')\nprint('Training Accuracy: %.2f%%' % (lr.score(X_train, y_train)*100))\nprint('Test Accuracy: %.2f%%' % (lr.score(X_test, y_test)*100))"},{"cell_type":"markdown","metadata":{"_cell_guid":"fd2e35bd-189c-b7de-70e2-c80c1bd0fb94"},"source":"It turns out that one feature is pretty good. Next we'll try to do some visualization."},{"cell_type":"markdown","metadata":{"_cell_guid":"fe7aa863-edd9-ca56-c545-40a8a4427cc9"},"source":"# Data Visualization"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3d43c53b-8a3d-8084-13f8-41f5688ba6db"},"outputs":[],"source":"sns.factorplot('class', col='odor', data=mushroom, kind='count', size=2.5, aspect=0.6, col_wrap=5);"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2919a46d-c083-9652-bf5c-49c488741891"},"outputs":[],"source":"g = sns.factorplot('class', col='spore-print-color', data=mushroom,\n               kind='count', size=2.5, aspect=0.6, col_wrap=5)\ng.set_titles(\"{col_name}\")\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle('spore-print-color');"},{"cell_type":"markdown","metadata":{"_cell_guid":"ddd9262c-7ddd-6be1-7b7d-07d8b14b515b"},"source":"The figures above suggest we can tell the difference between poisonous and edible mushrooms pretty well just by looking at the `odor` and the `spore-print-color`."},{"cell_type":"markdown","metadata":{"_cell_guid":"61d0b735-e557-a1e4-7569-2c223bcacd10"},"source":"### Visualization for feature with low importance\nNow we will see the visualization for the feature that have low importance according to random forest."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8cc894ec-e7b1-a32a-b7f3-5a34fc495322"},"outputs":[],"source":"sns.factorplot('class', col='gill-attachment', data=mushroom, kind='count', size=2.5, aspect=0.6, col_wrap=5);"},{"cell_type":"markdown","metadata":{"_cell_guid":"f3e0f7a3-6d04-d6d2-af77-1566b0c22cec"},"source":"You can see that most mushrooms, either poisonous or not, have `gill-attachment=f`, so it's not useful as a predictor."},{"cell_type":"markdown","metadata":{"_cell_guid":"250288dd-36d5-c071-f46d-ec79345acdaf"},"source":"Enough for now. Thanks for your attention."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}