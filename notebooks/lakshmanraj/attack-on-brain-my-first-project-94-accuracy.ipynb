{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Stroke Prediction Dataset**\nThis dataset is used to predict whether a patient is likely to get stroke based on the input parameters like gender, age, various diseases, and smoking status. Each row in the data provides relavant information about the patient.\n\n**Dataset Information:**\n\nhealthcare-data-stroke-data.csv: The csv contains data related to patients who may have heart disease and various attributes which determine that :\n\n* id: unique identifier\n* gender: \"Male\", \"Female\" or \"Other\"\n* age: age of the patient\n* hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n* heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n* ever_married: \"No\" or \"Yes\"\n* work_type: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n* Residence_type: \"Rural\" or \"Urban\"\n* avg_glucose_level: average glucose level in blood\n* bmi: body mass index\n* smoking_status: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n* stroke: 1 if the patient had a stroke or 0 if not\nNote: \"Unknown\" in smoking_status means that the information is unavailable for this patient\n\n**Objective**\n\nVisualize the relationships between various Healthy and Unhealthy habits to Heart Strokes, and there by predict the stroke probability with best model and hypertuned parameters.\n\n**Assumptions**\n\n1.Smoking can induce Stroke, is it true?\n\n2.Heart with a Heart Disease is prone to Stroke, is it true?\n\n3.Workload(work_type) results in high blood pressure and that could lead to Stroke, is it true?\n\n4.Males are most susceptible to strokes due to high work related stress, is it true?\n\n5.Being Married will increase the risk of having a stroke, is it true?\n\n6.HyperTension, is it one of the reason for a stroke?\n\n**Questions to be answered**\n\n1.Does age has impact on strokes? and How is this parameter distributed?\n\n2.Is there a difference in the rate of heart stroke for smokers and non smokers?\n\n3.Does the type of job, whether stressful or not, contribute to heart stroke?","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataset imported","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Data manipulation libraries\nimport numpy as np\nimport pandas as pd\n\n# Visualization libraries\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\n# Avoid Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\n#Common model helpers\nfrom sklearn.preprocessing import(LabelEncoder)\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (classification_report, accuracy_score, \n                             precision_score,\n                             recall_score,\n                             f1_score, \n                             confusion_matrix)\n\n# imbalance dataset handling\n\n\nfrom imblearn.over_sampling import (SMOTE)\n# model algorithams\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape #-there are total 5110 rows and 12 columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head() #first 5 in the dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail() # Last 5 in the Dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"id,hypertension,heart_disease,stroke these 4 columns are of datatype int\n\nage,avg_glucose_level,bmi are of datatype float\n\ngender,smoking_status,ever_married,work_type and residence_type are of string type","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As per my observation all the columns match with the number of rows in the dataframe except for bmi column.\n\nSo there are missing values in bmi column","metadata":{}},{"cell_type":"code","source":"#lets import missingno package\n#Missingno is a Python library \n#that provides the ability to understand the distribution of missing values through informative visualizations.\nimport missingno as msno","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualizing in barplot\nmsno.bar(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So there are total 201 missing values in bmi column","metadata":{}},{"cell_type":"markdown","source":"# Treating Missing Values","metadata":{}},{"cell_type":"code","source":"per=df.isnull().sum()/len(df)*100\nper","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"only 3.9 percent of the bmi data is missing , so instead of removing the entire column we can replace the missing values with mean","metadata":{}},{"cell_type":"code","source":"df['bmi'].fillna(df['bmi'].mean(),inplace=True)\ndf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"missing values are replaced by the mean","metadata":{}},{"cell_type":"code","source":"#lets see all the categorical features\nfig,axes = plt.subplots(4,2,figsize = (16,16))\nsns.set_style('whitegrid')\nfig.suptitle(\"Count plot for various categorical features\")\n\nsns.countplot(ax=axes[0,0],data=df,x='gender')\nsns.countplot(ax=axes[0,1],data=df,x='hypertension')\nsns.countplot(ax=axes[1,0],data=df,x='heart_disease')\nsns.countplot(ax=axes[1,1],data=df,x='ever_married')\nsns.countplot(ax=axes[2,0],data=df,x='work_type')\nsns.countplot(ax=axes[2,1],data=df,x='Residence_type')\nsns.countplot(ax=axes[3,0],data=df,x='smoking_status')\nsns.countplot(ax=axes[3,1],data=df,x='stroke')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['gender'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#removing unnecessary row\ndf.drop(df[df['gender']=='Other'].index,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['gender'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dropping unnecessary columns\ndf.drop(columns=['id'],inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us check whether gender has a part to play in brain strokes\n\nbefore that lets check the count of people who had a stroke","metadata":{}},{"cell_type":"code","source":"sns.countplot(data=df,x='stroke')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see number of people who got stroke is very much neglegible and due to this we may get underfitting or over fitting","metadata":{}},{"cell_type":"code","source":"stroke_gen = df[df['stroke'] == 1]['gender'].value_counts()\nhealthy_gen = df[df['stroke'] == 0]['gender'].value_counts()\nfemale = df['gender'].value_counts().values[0]\nmale =  df['gender'].value_counts().values[1]\nstroke_male = int(round( stroke_gen.values[1] / male *100, 0))\nstroke_female = int(round (stroke_gen.values[0] / female * 100, 0))\nhealthy_male = int(round(healthy_gen.values[1] / male *100, 0))\nhealthy_female = int(round(healthy_gen.values[0] / female * 100, 0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pywaffle\nfrom pywaffle import Waffle","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"female_per = int(round(female/(female+male) * 100, 0))\nmale_per = int(round(male/(female+male)* 100, 0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(FigureClass = Waffle, \n                 constrained_layout = True,\n                 figsize = (7,7),\n                 facecolor = '#f6f5f5',dpi = 100,\n                 \n                 plots = {'121':\n                          {     \n                           'rows':7,\n                           'columns': 7,\n                           'values' : [healthy_male,stroke_male],\n                            'colors' : ['#512b58','#fe346e'],\n                              'vertical' : True,\n                              'interval_ratio_y': 0.1,\n                              'interval_ratio_x': 0.1,\n                              'icons' : 'male',\n                              'icon_legend': False,\n                               'icon_size':20,\n                              'plot_anchor':'C',\n                              'alpha':0.1\n                          },\n                          \n                          '122' :\n                          { \n                            'rows': 7,\n                            'columns':7,\n                            'values':[healthy_female,stroke_female],         \n                              'colors' : ['#512b58','#fe346e'],\n                              'vertical': True,\n                              'interval_ratio_y': 0.1,\n                              'interval_ratio_x': 0.1,\n                              'icons' : 'female',\n                              'icon_legend' :False,\n                              'icon_size':20,\n                              'plot_anchor':'C',\n                              'alpha':0.1\n                                                      \n                           }\n                         },\n                   \n)\n\n\nfig.text(0., 0.8, 'Gender Risk for Stroke - effect of gender on strokes?', {'font':'Serif', 'size':20, 'color':'black', 'weight':'bold'})\nfig.text(0., 0.73, 'Risk of stroke in both male and female are same,\\nprove our initial assumption is wrong. ', {'font':'Serif', 'size':13, 'color':'black', 'weight':'normal'}, alpha = 0.7)\nfig.text(0.24, 0.22, 'ooo', {'font':'Serif', 'size':16,'weight':'bold' ,'color':'#f6f5f5'})\nfig.text(0.65, 0.22, 'ooo', {'font':'Serif', 'size':16,'weight':'bold', 'color':'#f6f5f5'})\nfig.text(0.23, 0.28, '{}%'.format(healthy_male), {'font':'Serif', 'size':20,'weight':'bold' ,'color':'#512b58'},alpha = 1,)\nfig.text(0.65, 0.28, '{}%'.format(healthy_female), {'font':'Serif', 'size':20,'weight':'bold', 'color':'#512b58'}, alpha = 1)\nfig.text(0.21, 0.67, 'Male ({}%)'.format(male_per), {'font':'Serif', 'size':14,'weight':'bold' ,'color':'black'},alpha = 0.5,)\nfig.text(0.61, 0.67, 'Female({}%)'.format(female_per), {'font':'Serif', 'size':14,'weight':'bold', 'color':'black'}, alpha = 0.5)\n#fig.text(0., 0.8, 'Assumption was proven wrong', {'font':'Serif', 'size':24, 'color':'black', 'weight':'bold'})\n\nfig.text(0.9,0.73, 'Stroke ', {'font': 'Serif','weight':'bold','Size': '16','weight':'bold','style':'normal', 'color':'#fe346e'})\nfig.text(1.02,0.73, '|', {'color':'black' , 'size':'16', 'weight': 'bold'})\nfig.text(1.035,0.73, 'No Stroke', {'font': 'Serif','weight':'bold', 'Size': '16','style':'normal', 'weight':'bold','color':'#512b58'},alpha = 1)\n\n\nfig.show()\n#this plot is taken from https://www.kaggle.com/aditimulye/stroke-prediction-visualization-prediction","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is interesting to note that although the number of males and females are different in the dataset, but, both of them are at equal risk to heart stroke.\nHence proving that our assumption that males are more susciptible to stroke due to work load, as wrong.","metadata":{}},{"cell_type":"code","source":"bmi=list(df['bmi'].values)\nhist_data=[bmi]\ngroup_lables=['bmi']\ncolour=['Red']\nfig=ff.create_distplot(hist_data,group_lables,show_hist=True,colors=colour)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Due to outliers histplot is right skewed\n\nEither the outliers can be removed or the distribution curve can be made less-skewed by mapping the values with a log but both cases will lead to loss of the number of datapoints with Stroke = 1","metadata":{}},{"cell_type":"code","source":"print(\"The shape after removing the BMI outliers : \",df.shape)\ndf.drop(df[df['bmi'] > 47].index, inplace = True)\nprint(\"The shape after removing the BMI outliers : \",df.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bmi=list(df['bmi'].values)\nhist_data=[bmi]\ngroup_lables=['bmi']\ncolour=['Red']\nfig=ff.create_distplot(hist_data,group_lables,show_hist=True,colors=colour)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure(figsize=[8,6])\nfig.patch.set_facecolor('#E0E0E0')\nfig.patch.set_alpha(0.7)\nplt.title(\" worktype vs stroke\")\nsns.countplot(data=df, x=\"work_type\",hue=\"stroke\",edgecolor=\"black\",color=\"#b8c7e1\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Although private employees count is more compared to other workers, it is evident that any\nwork exposes you to more stroke","metadata":{}},{"cell_type":"code","source":"fig=plt.figure(figsize=[8,6])\nfig.patch.set_facecolor('#E0E0E0')\nfig.patch.set_alpha(0.7)\nplt.title(\" smoker vs non smoker\")\nsns.countplot(data=df, x=\"smoking_status\",hue=\"stroke\",edgecolor=\"black\",color=\"#b8c7e1\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Smoking increases the risk","metadata":{}},{"cell_type":"code","source":"fig=plt.figure(figsize=[8,6])\nfig.patch.set_facecolor('#E0E0E0')\nfig.patch.set_alpha(0.7)\nplt.title(\"  Stroke/Hypertension\")\nsns.countplot(data=df, x=\"hypertension\",hue=\"stroke\",edgecolor=\"black\",color=\"#b8c7e1\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"more than 25% of stroke cases They had hypertension","metadata":{}},{"cell_type":"code","source":"fig=plt.figure(figsize=[8,6])\nfig.patch.set_facecolor('#E0E0E0')\nfig.patch.set_alpha(0.7)\nplt.title(\"  Stroke/HeartDisease\")\nsns.countplot(data=df, x=\"heart_disease\",hue=\"stroke\",edgecolor=\"black\",color=\"#b8c7e1\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"here we can see that ppl who are married are having more number of strokes \nbut dont just confirm it yet \nlets see the age of ppl who are married ","metadata":{}},{"cell_type":"code","source":"fig=plt.figure(figsize=[8,6])\nfig.patch.set_facecolor('#E0E0E0')\nfig.patch.set_alpha(0.7)\nplt.title(\"Age according the marital status classes.\")\nsns.boxplot(data=df,y='age',x='ever_married',width=0.4,showfliers=False,color=\"#b8c7e1\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"now we can see that people who are married are mostly of age group 50-70","metadata":{}},{"cell_type":"code","source":"fig = sns.FacetGrid(data=df, hue=\"stroke\", aspect=4)\nfig.map(sns.kdeplot, \"age\", shade=True)\nfig.add_legend()\nplt.savefig('stroke_age.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we already know increase in age will increase the risk of getting stroke, and we proved it.","metadata":{}},{"cell_type":"code","source":"fig = sns.FacetGrid(data=df, hue=\"stroke\", aspect=4)\nfig.map(sns.kdeplot, \"bmi\", shade=True)\nfig.add_legend()\nplt.savefig('bmi.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"mostly overwieghtedpeople have moew risk of getting a stroke","metadata":{}},{"cell_type":"code","source":"#converting categorical columns into numericals\nlabelencoder=LabelEncoder()\ndf['gender']=labelencoder.fit_transform(df['gender'])\ndf['ever_married']=labelencoder.fit_transform(df['ever_married'])\ndf['Residence_type']=labelencoder.fit_transform(df['Residence_type'])\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encode variables with more than 2 Classes\n\ndf = pd.get_dummies(df, columns= [i for i in df.columns if df[i].dtypes=='object'],drop_first=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#correlation between columns\nplt.figure(figsize=(15,15))\nsns.heatmap(df.corr(),annot=True)\nplt.savefig('stroke_corr_heat.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"columns age,hear_disease,hypertension,glucose_level are having positive correlation with respect to stroke","metadata":{}},{"cell_type":"markdown","source":"# Splitting Test and Train data","metadata":{}},{"cell_type":"code","source":"X=df.drop('stroke', axis=1)\ny=df['stroke'].ravel()\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_scale=scaler.fit_transform(X)\nX_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.3, stratify=y, shuffle=True, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr=LogisticRegression(random_state=42)\nlr.fit(X_train,y_train)\ny_pred_lr=lr.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_test,y_pred_lr)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,y_pred_lr))\nprint(confusion_matrix(y_test,y_pred_lr))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(random_state=42)\nrf.fit(X_train, y_train)\nrf_pred = rf.predict(X_test)\nprint(confusion_matrix(rf_pred, y_test))\nprint(classification_report(rf_pred, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With imbalanced data, the accuracy is not a metric that we can take into account because it is based on the the larger part of the target. In other words, this model is very accurate predincting when a people is not having a stroke, which is obviously what we don't need...\n\nThe poor result in class 1 of the target is expected because of the imbalanced dataset as well as the limited correlation among the variables.","metadata":{}},{"cell_type":"code","source":"# Balancing our dataset\n#Using over-sampling method\n\nfrom imblearn.over_sampling import SMOTE\nsm = SMOTE()\nX_oversampled, y_oversampled = sm.fit_resample(X, y)\n\nsns.countplot(x = y_oversampled, data = df)\nplt.savefig('stroke_oversampled.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train again with the new data\n\nX_train, X_test, y_train, y_test = train_test_split(X_oversampled, y_oversampled, test_size = 0.2, random_state = 42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Logistic Regression\nlr=LogisticRegression(random_state=42)\nlr.fit(X_train,y_train)\ny_pred_lr=lr.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,y_pred_lr))\nprint(confusion_matrix(y_pred_lr, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Decision Tree\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\ndt_pred = dt.predict(X_test)\nprint(confusion_matrix(dt_pred, y_test))\nprint(classification_report(dt_pred, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#KNN\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nknn_pred = knn.predict(X_test)\nprint(confusion_matrix(knn_pred, y_test))\nprint(classification_report(knn_pred, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Random forest\nrft = RandomForestClassifier(random_state=42)\nrft.fit(X_train, y_train)\nrft_pred = rft.predict(X_test)\nprint(confusion_matrix(rft_pred, y_test))\nprint(classification_report(rft_pred, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So here we can see that the confusion matrix before balancing is\n\n[[1424   73\n\n[   0    1]]\n\nand after balancing is \n\n[[889  38]\n\n [ 69 903]]\n","metadata":{}},{"cell_type":"markdown","source":"So after checking some of the algorithms , i have found that Random Forest has the highest accuracy ","metadata":{}},{"cell_type":"markdown","source":"Special Thanks to Aditi Mulye\nhttps://www.kaggle.com/aditimulye/stroke-prediction-visualization-prediction\n    Learnt alot from your notebook\n    \nAnd also thanks to many more ppl.\nIts fun to learn new.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}