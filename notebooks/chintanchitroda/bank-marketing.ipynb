{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Chintan Chitroda\n## Logistic Regression VS Random Forest Comparision\n##### Note : Acurracy and F1 score can be increased with use of Boosting Algorithms.\n##### The Notebook Visualize the data from Bank Marketing and predict if the customer will respond positively to the campaign or not, For the target variable is “Deposit”."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nimport os\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/bank-marketing-dataset/bank.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.deposit.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(data.isnull())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### NO null values"},{"metadata":{},"cell_type":"markdown","source":"###### 1  -Describe the pdays column, make note of the mean, median and minimum values. Anything fishy in the values?"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(data['pdays'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('median',data.pdays.median())\nprint('mean:',data.pdays.mean())\nprint('mode:',data.pdays.mode())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2 -\tDescribe the pdays column again, this time limiting yourself to the relevant values of pdays. How different are the mean and the median values?"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.pdays.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataWOP = data[data.pdays != -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(dataWOP.pdays)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('median',dataWOP.pdays.median())\nprint('mean:',dataWOP.pdays.mean())\nprint('mode:',dataWOP.pdays.mode())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### As there are no values for customers who were not approached ( -1). The mean median and mode have changed significantly."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### 3 -\tPlot a horizontal bar graph with the median values of balance for each education level value. Which group has the highest median?"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.balance.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.education.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(data.balance,data.education)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"######  4 - Make a box plot for pdays. Do you see any outliers?"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(data.pdays)\nprint('outliers with -1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(dataWOP.pdays)\nprint('outliers without -1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Yes we can seee there are outliers in pdays"},{"metadata":{},"cell_type":"markdown","source":"### EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\nsns.heatmap(data.corr(),square=True,annot=True,cmap= 'twilight_shifted')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.replace({'deposit': {\"yes\": 1,'no':0}},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### identigyind categorical and numerical columns\ncols = data.columns\nnum_cols= data._get_numeric_data().columns\ncat_cols = list(set(cols) - set(num_cols))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing Categorical Features with Deposit"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data[cat_cols]:\n    sns.barplot(data.deposit,data[i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  Visualizing Numerical Features with Deposit"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data[num_cols]:\n    sns.barplot(data.deposit,data[i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = data.columns\nnum_cols= data._get_numeric_data().columns\ncat_cols = list(set(cols) - set(num_cols))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[cat_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[num_cols]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PreProcessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data[cat_cols].apply(LabelEncoder().fit_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataf = data1.join(data[num_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataf[dataf.pdays == -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataf.pdays.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### More than 70% of pdays have -1."},{"metadata":{"trusted":true},"cell_type":"code","source":"#dataf.drop('pdays',axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### After analyzing the we know that Pdays dones play any important role in model so we keep it as it is.\n##### The -1 or the missing values are kept as it is as we would not be using that in modelling part"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,20))\nsns.heatmap(dataf.corr(),square=True,annot=True,cmap= 'Spectral')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataf.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ML Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import roc_auc_score\nimport statsmodels.api as sm\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### All Single feature with Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in dataf.columns:\n    X = dataf[[i]]\n    y = dataf['deposit']\n    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state=101)\n    lr = LogisticRegression()\n    lr.fit(X_train,y_train)\n    y_pred = lr.predict(X_test)\n    print(\"F1 Score for\", i , f1_score(y_pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## All Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataf.drop('deposit',axis=1)\ny = dataf['deposit']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(random_state=101)\nlr.fit(X_train,y_train)\ny_pred = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Report:\\n',classification_report(y_test, y_pred))\nprint(\"F1 Score:\",f1_score(y_pred,y_test))\nprint('confusion Matrix:\\n',confusion_matrix(y_pred,y_test))\nprint('cross validation:',cross_val_score(lr, X, y, cv=5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = sm.OLS(y, X)\nresults = model.fit()\nstart = \"\\033[1m\" ### for bold text\nprint(start)\nprint(results.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using RFE"},{"metadata":{"trusted":true},"cell_type":"code","source":"### Using Rfe\nfrom sklearn.feature_selection import RFE\nrfe = RFE(lr, 15)\nrfe.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.columns[rfe.support_])\ncols = X_train.columns[rfe.support_]\nlr.fit(X_train[cols],y_train)\ny_pred2 = lr.predict(X_test[cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def logReggResult():\n    print('Report:\\n',classification_report(y_test, y_pred2))\n    print(\"F1 Score:\",f1_score(y_pred2,y_test))\n    print('AUC score:',roc_auc_score(y_test,y_pred2))\n    print('confusion Matrix:\\n',confusion_matrix(y_pred2,y_test))\n    print('kfold cross validation:\\n',cross_val_score(lr, X, y, cv=5))\n    print(\"Acurracy :::>\",accuracy_score(y_pred2,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logReggResult()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Feature Importance\nfrom sklearn.feature_selection import SelectFromModel\nsmf = SelectFromModel(lr)\nsmf.fit(X_train,y_train)\nfeatures = smf.get_support()\nfeature_name = X_train.columns[features]\nfeature_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances=feature_name\nfeature_importances=pd.Series(importances).sort_values(ascending=False)\nsns.barplot(x=feature_importances[0:10], y=feature_importances.index[0:10])\nplt.title('Feature Importance',size=20)\nplt.ylabel(\"Features\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataf.drop('deposit',axis=1)\ny = dataf['deposit']\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=50,max_depth=5, random_state=101,max_leaf_nodes=50)\nrfc.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred1 = rfc.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import export_graphviz\nestimator = rfc.estimators_[5]\n# Export as dot file\nexport_graphviz(estimator, \n                out_file='tree1.dot', \n                feature_names = X_train.columns,\n                class_names = 'deposit',\n                rounded = True, proportion = False, \n                precision = 2, filled = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.system('dot -Tpng tree1.dot -o tree1.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image\nImage(filename = 'tree1.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RF():\n    print('Report:\\n',classification_report(y_test, y_pred1))\n    print(\"F1 Score:\",f1_score(y_pred1,y_test))\n    print('confusion Matrix:\\n',confusion_matrix(y_pred1,y_test))\n    print('cross validation:',cross_val_score(rfc, X, y, cv=5))\n    print('AUC score:',roc_auc_score(y_test,y_pred))\n    print(\"Acurracy :::>\",accuracy_score(y_pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances=rfc.feature_importances_\nfeature_importances=pd.Series(importances, index=X_train.columns).sort_values(ascending=False)\nsns.barplot(x=feature_importances[0:10], y=feature_importances.index[0:10])\nplt.title('Feature Importance',size=20)\nplt.ylabel(\"Features\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Comparision "},{"metadata":{},"cell_type":"markdown","source":"### We choose the F1 Score and Confustion Matrix for the Final comparision of both Models because the Target Variable is imbalanced. So, Precision and Recall can be the main factor for evaluation model and we get the harmonic mean for the same in form of F1 score."},{"metadata":{"trusted":true},"cell_type":"code","source":"print (start + \"############### Random Forest Result: ###############\\n\")\nRF()\nprint(start +'\\n\\n############# Logistic Regression Result: ############\\n')\nlogReggResult()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We see that the Random Forest has Perfomed good in comparision to Logistic Regression."},{"metadata":{},"cell_type":"markdown","source":"### Random Forest has Better F1 score,  AUC,  Confusion Matrix, kfold Cross val and accuracy in compare to Logistic Regression."},{"metadata":{},"cell_type":"markdown","source":"### The Main Features for the both Models/ Algorithm Differs as Random Forest and Logistic Regression Works on different Principal"},{"metadata":{},"cell_type":"markdown","source":"### Please do Upvote if you like kernal."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}