{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/human-activity-recognition-with-smartphones/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/human-activity-recognition-with-smartphones/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('No of duplicates in train: {}'.format(sum(train.duplicated())))\nprint('No of duplicates in test : {}'.format(sum(test.duplicated())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The number of missing values in Training Data:\" , train.isnull().values.sum())\nprint(\"The number of missing values in Testing Data:\" , test.isnull().values.sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Frequency distribution of classes\"\ntrain_outcome = pd.crosstab(index=train[\"Activity\"],  # Make a crosstab\n                              columns=\"count\")      # Name the count column\n\ntrain_outcome","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Static and Dynamic Activities\n\nIn static activities (sit, stand, lie down) motion information will not be very useful.\nIn the dynamic activities (Walking, WalkingUpstairs,WalkingDownstairs) motion info will be significant."},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = train.columns\n\n# Removing '()' from column names\ncolumns = columns.str.replace('[()]','')\ncolumns = columns.str.replace('[-]', '')\ncolumns = columns.str.replace('[,]','')\n\ntrain.columns = columns\ntest.columns = columns\n\ntrain.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = list(train.columns)\naccFeat=[]\nfor feat in features:\n    if feat.find('BodyAcc') != -1 and feat.find('Magmean') !=-1 and feat.find('Freq')==-1:\n        accFeat.append(feat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def boxplot(feature , ylabel):\n    \n    plt.figure(figsize=(5,5))\n    sns.boxplot(x='Activity', y=feature, data=train , showfliers=False )\n    plt.ylabel(ylabel)\n    plt.axhline(y=-0.8, xmin=0.1, xmax=0.9,dashes=(5,5), c='g') #line separating both type of activities\n    plt.xticks(rotation=90)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in accFeat:\n    boxplot(f , f[:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__ Observations__:\n- If tbodyAccMean is < -0.8 then the Activities are either Standing or Sitting or Laying.\n- If tbodyAccMean is > -0.6 then the Activities are either Walking or WalkingDownstairs or WalkingUpstairs.\n- If tbodyAccMean > 0.0 then the Activity is WalkingDownstairs.\n- We can classify 75% of the Acitivity labels with some errors."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='Activity', y='angleXgravityMean', data=train)\nplt.axhline(y=0.08, xmin=0.1, xmax=0.9,c='m',dashes=(5,3))\nplt.title('Angle between X-axis and Gravity_mean', fontsize=15)\nplt.xticks(rotation = 40)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__ Observations__:\n* If angleX,gravityMean > 0 then Activity is Laying.\n> * We can classify all datapoints belonging to Laying activity with just a single if else statement."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='Activity', y='angleYgravityMean', data=train)\nplt.axhline(y=0.1, xmin=0.1, xmax=0.9,c='m',dashes=(5,3))\nplt.title('Angle between X-axis and Gravity_mean', fontsize=15)\nplt.xticks(rotation = 40)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperating Predictors and Outcome values from train and test sets\nX_train = pd.DataFrame(train.drop(['Activity','subject'],axis=1))\nY_train_label = train.Activity.values.astype(object)\nX_test = pd.DataFrame(test.drop(['Activity','subject'],axis=1))\nY_test_label = test.Activity.values.astype(object)\n\n# Dimension of Train and Test set \nprint(\"Dimension of Train set\",X_train.shape)\nprint(\"Dimension of Test set\",X_test.shape,\"\\n\")\n\n# Transforming non numerical labels into numerical labels\nfrom sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\n\n# encoding train labels \nencoder.fit(Y_train_label)\ny_train = encoder.transform(Y_train_label)\n\n# encoding test labels \nencoder.fit(Y_test_label)\ny_test = encoder.transform(Y_test_label)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nplt.rcParams[\"font.family\"] = 'DejaVu Sans'\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\ndef perform_model(model, X_train, y_train, X_test, y_test, class_labels, cm_normalize=True, \\\n                 print_cm=True, cm_cmap=plt.cm.Greens):\n    \n    \n    # to store results at various phases\n    results = dict()\n    \n    # time at which model starts training \n    train_start_time = datetime.now()\n    print('training the model..')\n    model.fit(X_train, y_train)\n    print('Done \\n \\n')\n    train_end_time = datetime.now()\n    results['training_time'] =  train_end_time - train_start_time\n    print('training_time(HH:MM:SS.ms) - {}\\n\\n'.format(results['training_time']))\n    \n    \n    # predict test data\n    print('Predicting test data')\n    test_start_time = datetime.now()\n    y_pred = model.predict(X_test)\n    test_end_time = datetime.now()\n    print('Done \\n \\n')\n    results['testing_time'] = test_end_time - test_start_time\n    print('testing time(HH:MM:SS:ms) - {}\\n\\n'.format(results['testing_time']))\n    results['predicted'] = y_pred\n   \n\n    # calculate overall accuracty of the model\n    accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n    # store accuracy in results\n    results['accuracy'] = accuracy\n    print('---------------------')\n    print('|      Accuracy      |')\n    print('---------------------')\n    print('\\n    {}\\n\\n'.format(accuracy))\n    \n    \n    # confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    results['confusion_matrix'] = cm\n    if print_cm: \n        print('--------------------')\n        print('| Confusion Matrix |')\n        print('--------------------')\n        print('\\n {}'.format(cm))\n        \n    # plot confusin matrix\n    plt.figure(figsize=(8,8))\n    plt.grid(b=False)\n    plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix', cmap = cm_cmap)\n    plt.show()\n    \n    # get classification report\n    print('-------------------------')\n    print('| Classifiction Report |')\n    print('-------------------------')\n    classification_Report = classification_report(y_test, y_pred)\n    # store report in results\n    results['classification_Report'] = classification_Report\n    print(classification_Report)\n    \n    # add the trained  model to the results\n    results['model'] = model\n    \n    return results\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_grid_search_attributes(model):\n    # Estimator that gave highest score among all the estimators formed in GridSearch\n    print('--------------------------')\n    print('|      Best Estimator     |')\n    print('--------------------------')\n    print('\\n\\t{}\\n'.format(model.best_estimator_))\n\n\n    # parameters that gave best results while performing grid search\n    print('--------------------------')\n    print('|     Best parameters     |')\n    print('--------------------------')\n    print('\\tParameters of best estimator : \\n\\n\\t{}\\n'.format(model.best_params_))\n\n\n    #  number of cross validation splits\n    print('---------------------------------')\n    print('|   No of CrossValidation sets   |')\n    print('--------------------------------')\n    print('\\n\\tTotal numbre of cross validation sets: {}\\n'.format(model.n_splits_))\n\n\n    # Average cross validated score of the best estimator, from the Grid Search \n    print('--------------------------')\n    print('|        Best Score       |')\n    print('--------------------------')\n    print('\\n\\tAverage Cross Validate scores of best estimator : \\n\\n\\t{}\\n'.format(model.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels=['LAYING', 'SITTING','STANDING','WALKING','WALKING_DOWNSTAIRS','WALKING_UPSTAIRS']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nparameters = {'max_depth':np.arange(3,10,2)}\ndt = DecisionTreeClassifier()\ndt_grid = GridSearchCV(dt,param_grid=parameters, n_jobs=-1)\ndt_grid_results = perform_model(dt_grid, X_train, y_train, X_test, y_test, class_labels=labels)\nprint_grid_search_attributes(dt_grid_results['model'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nparam_grid = {'reg_lambda': [100,200,500],  \n              'gamma':[100, 150, 200],\n              'min_child_weight':[4,5,6]\n             }\nXgb = XGBClassifier()\nXgb_grid = GridSearchCV(Xgb, param_grid=param_grid, n_jobs=-1)\nXgb_grid_results = perform_model(Xgb_grid, X_train, y_train, X_test, y_test, class_labels=labels)\nprint_grid_search_attributes(Xgb_grid_results['model'])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}