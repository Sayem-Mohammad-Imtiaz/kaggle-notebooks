{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport datetime as dt\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.api import VAR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment = pd.read_csv('/kaggle/input/another-sentiment-bitcoin/cryptopanic_sentiment.csv', index_col = 0)\nsentiment.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_sentiment = sentiment.groupby(['Date']).mean()\nprint(len(mean_sentiment))\nmean_sentiment.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"temp = []\nfor index,x in enumerate(mean_sentiment.values):\n    if index == 0:\n        temp.append(0)\n    else:\n        temp.append(x[0]-mean_sentiment.values[index-1][0])\n\n        \nmean_sentiment['difference'] = temp\nmean_sentiment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/bitcoin-historical-data/bitstampUSD_1-min_data_2012-01-01_to_2020-12-31.csv')\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from dateutil.parser import parse\ntemp = []\nfor x in sentiment.Date:\n    temp.append(parse(x))\nsentiment.Date = temp","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df.Timestamp = pd.to_datetime(df.Timestamp, unit='s')\n\n# Resampling to daily frequency\ndf.index = df.Timestamp\n\ndf = df.resample('D').mean()\n\n# Resampling to monthly frequency\ndf_month = df.resample('M').mean()\n\n# Resampling to annual frequency\ndf_year = df.resample('A-DEC').mean()\n\n# Resampling to quarterly frequency\ndf_Q = df.resample('Q-DEC').mean()\n\ntrain = df.iloc[2130:]\ntrain\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train['sentiment_value'] = sentiment.groupby(['Date']).mean()\ntrain = train.dropna()\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = VAR(train[['Close','sentiment_value']])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(model.select_order(trend='c'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fit = model.fit(ic = 'aic')\n# number of lags\nnum_lag = model_fit.k_ar\nnum_lag","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fit.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fit.forecast(y = train[['Close','sentiment_value']].values, steps = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(data, fitted_model, lag_order, predict_steps):\n    # empty list for our predictions\n    prediction = []\n  \n    # for loop to iterate fitted_model over data\n    for i in range(lag_order, len(data)):\n        # window of lagged data that the model uses to predict next observation\n        window = data.iloc[i - lag_order : i].copy()\n        # results of fitted_model being applied to window\n        results = fitted_model.forecast(y = window.values, steps = predict_steps)\n        # append results to prediction list\n        prediction.append(results)\n        \n    # convert prediction (which is a list of numpy arrays) to a dataframe\n    df = np.vstack(prediction)\n    df = pd.DataFrame(df)\n    # df column names from data\n    df.columns = list(data.columns)\n    # df index from data\n    df.index = data.iloc[len(data) - len(prediction) :].index\n    \n    # return df\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmse(predicted, actual):\n    # formula for rmse\n    residual = predicted - actual\n    residual_sq = residual ** 2\n    mean_sq = np.mean(residual_sq)\n    rmse_value = np.sqrt(mean_sq)\n    # return rmse_value\n    return rmse_value\n\n# mean absolute error\ndef mae(predicted, actual):\n    # formula for mae\n    absolute_residual = np.absolute(predicted - actual)\n    mae_value = np.mean(absolute_residual)\n    # return mae_value\n    return mae_value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_graphs(predicted, actual, title = str):\n    # RMSE\n    rmse_value = rmse(predicted = predicted, actual = actual)\n    # MAE\n    mae_value = mae(predicted = predicted, actual = actual)\n    # start_year (for putting in text box)\n    start_year = predicted.iloc[ : 1].index.copy()\n    # text box in line plot\n    text_str = 'RMSE = ' + str(rmse_value) + '\\n MAE = ' + str(mae_value)\n    # line plot\n    plt.figure(1)\n    plt.plot(actual, color = 'blue', linewidth = 2, label = 'actual')\n    plt.plot(predicted, color = 'red', linewidth = 1, label = 'predicted')\n    plt.legend()\n    plt.title(title + ' Actual vs Predicted')\n    plt.text(x = start_year, y = 0.2, s = text_str)\n    # residual & hist\n    plt.figure(2)\n    residual = actual - predicted\n    plt.hist(residual, bins = 200)\n    plt.title('Distribution of ' + title + ' residual')\n    plt.axvline(residual.mean(), color = 'k', linestyle = 'dashed', linewidth = 1)\n    # show graphics\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def category(x):\n    if x >= 0:\n        return 'up'\n    elif x < 0:\n        return 'down'\n\n# function that returns confusion matrix of model with metrics\ndef confusion_matrix(predicted, actual, title = str):\n    df = pd.DataFrame()\n    df['predicted'] = predicted.apply(category)\n    df['actual'] = actual.apply(category)\n    # code\n    df.loc[(df['predicted'] == 'up') & (df['actual'] == 'up'), 'code'] = 'true_positive'\n    df.loc[(df['predicted'] == 'up') & (df['actual'] == 'down'), 'code'] = 'false_positive'\n    df.loc[(df['predicted'] == 'down') & (df['actual'] == 'down'), 'code'] = 'true_negative'\n    df.loc[(df['predicted'] == 'down') & (df['actual'] == 'up'), 'code'] = 'false_negative'\n    # confusion dictionary\n    z = dict(df['code'].value_counts())\n    # confusion metrics\n    accuracy = (z['true_positive'] + z['true_negative']) / (z['true_positive'] + z['true_negative'] + z['false_positive'] + z['false_negative'])\n    true_positive_rate = z['true_positive'] / (z['true_positive'] + z['false_negative'])\n    false_positive_rate = z['false_positive'] / (z['false_positive'] + z['true_negative'])\n    true_negative_rate = z['true_negative'] / (z['true_negative'] + z['false_positive'])\n    false_negative_rate = z['false_negative'] / (z['false_negative'] + z['true_positive'])\n    # print metrics\n    print('\\nMetrics for [{0}]\\nAccuracy:{1:6.3f} \\nTP Rate:{2:7.3f} \\nFP Rate:{3:7.3f}\\nTN Rate:{4:7.3f} \\nFN Rate:{5:7.3f}'.format(str(title), accuracy, true_positive_rate, false_positive_rate, true_negative_rate, false_negative_rate))\n    # print confusion matrix graph\n    print('\\n'+\n      '            [{title}] Confusion Matrix\\n'.format(title = str(title))+\n      '\\n'+\n      '           |-------------|-------------|\\n'+\n      '  n= {0}  | Predicted:  | Predicted:  |\\n'.format(z['true_positive']+z['false_positive']+z['true_negative']+z['false_negative'])+\n      '           |    Down     |    Up       |\\n'+\n      '|----------|-------------|-------------|------------|\\n'+\n      '| Actual:  |             |             |            |\\n'+\n      '|  Down    |  tn: {0}    |  fp: {1}    |    {2}     |\\n'.format(z['true_negative'], z['false_positive'], z['true_negative']+z['false_positive'])+\n      '|----------|-------------|-------------|------------|\\n'+\n      '| Actual:  |             |             |            |\\n'+\n      '|   UP     |  fn: {0}    |  tp: {1}    |    {2}    |\\n'.format(z['false_negative'], z['true_positive'] ,z['false_negative']+z['true_positive'])+\n      '|----------|-------------|-------------|------------|\\n'+\n      '           |             |             |\\n'+\n      '           |      {0}    |      {1}   |\\n'.format(z['true_negative']+z['false_negative'], z['false_positive']+z['true_positive'])+\n      '           |-------------|-------------|\\n')\n    # return df\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train results\ntrain_predicted = model_fit.fittedvalues.copy()\ntrain_actual = train.iloc[num_lag : len(train)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_predicted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_graphs(predicted = train_predicted['Close'], actual = train_actual['Close'], title = 'Training')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/another-sentiment-bitcoin/jan_cryptopanic.csv')\ntest_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = []\nfor x in test_data.published_at:\n    temp.append(parse(x))\ntest_data['published_at'] = temp\ntest_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['Date'] = temp\nmean_data = test_data[['Date','sentiment_value']].groupby(['Date']).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bitcoinprice2021 = [['2021-02-03', 37646.8],\n ['2021-02-02', 35485.2],\n ['2021-02-01', 33515.7],\n ['2021-01-31', 33108.1],\n ['2021-01-30', 34283.1],\n ['2021-01-29', 34301.8],\n ['2021-01-28', 33374.8],\n ['2021-01-27', 30404.0],\n ['2021-01-26', 32502.1],\n ['2021-01-25', 32252.3],\n ['2021-01-24', 32241.3],\n ['2021-01-23', 32088.9],\n ['2021-01-22', 33000.5],\n ['2021-01-21', 30842.1],\n ['2021-01-20', 35476.3],\n ['2021-01-19', 36002.9],\n ['2021-01-18', 36613.2],\n ['2021-01-17', 35839.6],\n ['2021-01-16', 36019.5],\n ['2021-01-15', 36845.8],\n ['2021-01-14', 39175.7],\n ['2021-01-13', 37382.2],\n ['2021-01-12', 34076.1],\n ['2021-01-11', 35544.3],\n ['2021-01-10', 38192.2],\n ['2021-01-09', 40151.9],\n ['2021-01-08', 40599.3],\n ['2021-01-07', 39460.2]] \ntemp = []\nfor x in bitcoinprice2021:\n    temp.append([parse(x[0]),x[1]])\ndf_2021 = pd.DataFrame(temp,columns=['Date','Close'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2021.index = df_2021['Date']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_data['Close'] = df_2021['Close']\nmean_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_lag = stationary.iloc[len(train) - num_lag :]\ntest_predicted = predict(data = mean_data[['Close','sentiment_value']], fitted_model = model_fit, lag_order = num_lag, predict_steps = 1)\ntest_actual = mean_data[['Close','sentiment_value']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_graphs(predicted = test_predicted['Close'], actual = test_actual['Close'], title = 'Test')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}