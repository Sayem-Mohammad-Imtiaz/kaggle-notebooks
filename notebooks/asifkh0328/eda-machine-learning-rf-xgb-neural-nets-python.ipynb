{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Importing Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# READING THE INPUT CSV FILE\nhotel_review = pd.read_csv('/kaggle/input/hotel-booking-demand/hotel_bookings.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_review.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_review.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting information regarding the data types and number of missing values in the dataset\nhotel_review.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#seperating numerical and categorical columns\ncategorical_columns=[]\nnumerical_columns=[]\nfor col in hotel_review.columns:\n    if hotel_review[col].dtype!='object':\n        numerical_columns.append(col)\n    else:\n        categorical_columns.append(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_review.describe() # for numerical values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_review[categorical_columns].describe()# Statistical relations for categorical values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CHECKING FOR MISSING VALUE\n#As we saw earlier in the info method number of missing values in few of columns.\n#Finding missing values in all columns\nhotel_review.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As company values cannot be filled accurately using any preprocessed techniques we drop the company column we do the same with agent as number of empty obsrevations are large in number fianlly we can remove the empty data observations for the Country column and dropping the columns can create significant impact in the analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting a closer look on the 3 parameter having Missing values\n#Checking for corelation in missing data columns\ncheck_for_corelation = hotel_review[['is_canceled','agent','company']]\ncheck_for_corelation.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping Company column\nhotel_review.drop(columns=['agent', 'company'],inplace=True)\nhotel_review.dropna(axis=0,inplace=True)\nhotel_review.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing the empty observation for country column\nhotel_review.country.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_review.country.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets copy data to check the correlation between variables. \nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\ncorelation_of_data = hotel_review.copy()\nle = LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for variables and thier correlation with other variables.\ncorelation_of_data['meal'] = le.fit_transform(corelation_of_data['meal'])\ncorelation_of_data['distribution_channel'] = le.fit_transform(corelation_of_data['distribution_channel'])\ncorelation_of_data['reserved_room_type'] = le.fit_transform(corelation_of_data['reserved_room_type'])\ncorelation_of_data['assigned_room_type'] = le.fit_transform(corelation_of_data['assigned_room_type'])\ncorelation_of_data['customer_type'] = le.fit_transform(corelation_of_data['customer_type'])\ncorelation_of_data['reservation_status'] = le.fit_transform(corelation_of_data['reservation_status'])\ncorelation_of_data['market_segment'] = le.fit_transform(corelation_of_data['market_segment'])\ncorelation_of_data['deposit_type'] = le.fit_transform(corelation_of_data['deposit_type'])\ncorelation_of_data['reservation_status_date'] = le.fit_transform(corelation_of_data['deposit_type'])\ncorelation_of_data['is_canceled'] = le.fit_transform(corelation_of_data['deposit_type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.heatmap(corelation_of_data.corr(),annot=True,cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corelation_of_data.corr().is_canceled.sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see that reservation_status_date and deposit_type are perfectly correlated to the is_canceled which is our Dependent variable, we need to take care of them seperately later for getting better result we will be handling this at the time of the modeling."},{"metadata":{"trusted":true},"cell_type":"code","source":"#graphical potray of the correlation values\ncorelation_of_data.corr()['is_canceled'][:-1].sort_values().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"EXPLORATORY DATA ANALYSIS"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Having a closer look at the type of values inside different attributes\nhotel_review.reservation_status.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_review.customer_type.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_review.customer_type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nplt.title(label='Cancellation by ADR & Hotel Type')\nsns.barplot(x='hotel',y='adr',hue='is_canceled',data=hotel_review)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nplt.title(label='Cancellation by Market Segments')\nplt.xticks(rotation=45) \nsns.countplot(x='market_segment',hue='is_canceled',data=hotel_review)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CHECKING FOR THE MOST BUSIEST MONTH IN A YEAR"},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_review.arrival_date_month.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.barplot(data = hotel_review, x= 'arrival_date_month',y='adr',hue='hotel')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"most_occupied_month_price = hotel_review.groupby(['arrival_date_month','hotel']).sum().adr\nmost_occupied_month_price","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see that August and July are the most occupied booking month."},{"metadata":{"trusted":true},"cell_type":"code","source":"# next we can look for the number of people and diffenrt variates of people come in\n# combining the adults and children into one category as the expense is relatively the same and excluidng the babies\nhotel_review['Family'] = hotel_review.adults + hotel_review.children ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# droping the existing columns\nhotel_review.drop(columns=['adults','children','babies'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_review['Family'] = hotel_review['Family'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Variation in price with respect to hotels"},{"metadata":{"trusted":true},"cell_type":"code","source":"# now checking for which type of Hotel have more number of cancelations\n# % of cancellations in City Hotel\nhotel_review[hotel_review['hotel']=='City Hotel']['is_canceled'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cancelation with respect to time\nplt.figure(figsize=(12,8))\nplt.title(label='Cancellation by Lead Time')\nsns.barplot(x='hotel',y='lead_time',hue='is_canceled',data=hotel_review)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* MODEL PRE-PROCESSING\nConverting the categorical features in the columns into numerical values, so that it easy and fast for the algorithm to learn the characteristics"},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting hotel and months into numerical value and mapping them\nhotel_review['hotel'] = hotel_review['hotel'].map({'Resort Hotel':0, 'City Hotel':1})\nhotel_review['arrival_date_month'] = hotel_review['arrival_date_month'].map({'January':1, 'February': 2, 'March':3, 'April':4, 'May':5, 'June':6, 'July':7,\n                                                            'August':8, 'September':9, 'October':10, 'November':11, 'December':12})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_review.country.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_review.Family.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_review.deposit_type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#As discussed earlier due to high correlation with these factors we will highly inaccurate results therefore we drop these columns\nhotel_review.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_review.drop(columns=\"reservation_status_date\", inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_review.reservation_status.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_review.drop(columns=['reservation_status'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_review['country'] = le.fit_transform(hotel_review['country'])\nhotel_review['deposit_type'] = le.fit_transform(hotel_review['deposit_type'])\nhotel_review['adr'] = le.fit_transform(hotel_review['adr'])\nhotel_review['market_segment'] = le.fit_transform(hotel_review['market_segment'])\nhotel_review['meal'] = le.fit_transform(hotel_review['meal'])\nhotel_review['distribution_channel'] = le.fit_transform(hotel_review['distribution_channel'])\nhotel_review['reserved_room_type'] = le.fit_transform(hotel_review['reserved_room_type'])\nhotel_review['assigned_room_type'] = le.fit_transform(hotel_review['assigned_room_type'])\nhotel_review['customer_type'] = le.fit_transform(hotel_review['customer_type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hotel_review.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# APPLYING MACHINE LEARNING MODELS\nimport statsmodels.formula.api as smf\n\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix, auc\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\nfrom sklearn.neural_network import MLPClassifier\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = hotel_review[\"is_canceled\"]\nX = hotel_review.drop([\"is_canceled\"], axis=1)\n\n# SPLITTING THE DATA INTO 30 PERCENT TEST AND 70 PERCENT TRAINING DATA\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = DecisionTreeClassifier(max_depth = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model = tree.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = tree_model.predict(X_test)\nprint('Decision Tree Model')\n\nprint('Accuracy Score: {}\\n\\nConfusion Matrix:\\n {}'\n      .format(accuracy_score(y_test,y_pred), confusion_matrix(y_test,y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# APPLYING RANDOM FORREST\nrf_model = RandomForestClassifier(min_samples_leaf = 6, min_samples_split=6,\n                                  n_estimators = 100)\n\n# fitting of the model\nestimator= rf_model.fit(X_train, y_train)\n#Prediction of the Model\npredict_rf = rf_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_matrix = confusion_matrix(y_test, predict_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_matrix = confusion_matrix(y_test, predict_rf)\nax = plt.plot()\nsns.heatmap(RF_matrix,annot=True, fmt=\"d\", cbar=False, cmap=\"Pastel2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, importance in zip(X.columns, rf_model.feature_importances_):\n    print(name, \"=\", importance)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#MODELLING WITH EXTREME GRADIENT BOOST\nD_train = xgb.DMatrix(X_train, label=y_train)\nD_test = xgb.DMatrix(X_test, label=y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {\n    'eta': 0.3, \n    'max_depth': 3,  \n    'objective': 'multi:softprob',  \n    'num_class': 3} \n\nsteps = 20  # The number of training iterations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = xgb.train(param, D_train, steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(D_test)\nbest_preds = np.asarray([np.argmax(line) for line in preds])\n\nprint(\"Precision = {}\".format(precision_score(y_test, best_preds, average='macro')))\nprint(\"Recall = {}\".format(recall_score(y_test, best_preds, average='macro')))\nprint(\"Accuracy = {}\".format(accuracy_score(y_test, best_preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# first neural network with keras \nfrom numpy import loadtxt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import `Sequential` from `keras.models`\nfrom keras.models import Sequential\n\n# Import `Dense` from `keras.layers`\nfrom keras.layers import Dense\n\n# Initialize the constructor\nmodel = Sequential()\n\n# Add an input layer \nmodel.add(Dense(12, activation='relu', input_shape=(25,)))\n\n# Add one hidden layer \nmodel.add(Dense(8, activation='relu'))\n\n# Add an output layer \nmodel.add(Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n                   \nmodel.fit(X_train, y_train,epochs=5, batch_size=1, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(X_test, y_test,verbose=1)\n\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The neural nets can be trained, and effective losses can be calculated.\nOverall the Random Forest algorithm provides the best fit for better decision making on the parameters given.\n"},{"metadata":{},"cell_type":"markdown","source":"The idea here is to understand the questions and train the model accordingly, whereas doing Exploratory data analysis give us a bright idea on the type and how the data is measured.\nAlso, domain experience can play an important role in the analysis therefore, looking at the past and present terms we should understand the behavior of the model then take some meaningful decision on it.\nFinally, we need to be transparent on what is more preferable to our objective whether the precision or the recall is important to us, as there could be tradeoff between the two in most of the cases.\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}