{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,experimental\nfrom tensorflow.keras.optimizers import RMSprop\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import plot_confusion_matrix,confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#---------------Read the data-----------\ntrain=pd.read_csv('//kaggle//input//mnist-in-csv//mnist_train.csv')\ntest=pd.read_csv('//kaggle//input//mnist-in-csv//mnist_test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-----------------Load and QC-------------\nprint (train.columns)\nprint('\\n#---------------------------------------------')\nplt.imshow(test.iloc[0,1:].values.reshape(28,28),cmap='Greys')\nXtrain=(train.iloc[:,1:])\nytrain=(train.iloc[:,0])\nXtest=(test.iloc[:,1:])\nytest=(test.iloc[:,0])\n\nprint(ytrain)\n\n\nprint('\\n#------------------------------------------------------------')\nprint(Xtrain.shape)\nprint(ytrain.shape)\nprint(Xtest.shape)\nprint(ytest.shape)\nplt.figure(figsize=(10,10))\nplt.subplot(1,2,1)\nplt.title('Ytrain')\nsns.countplot(ytrain)\nplt.subplot(1,2,2)\nplt.title('Ytest')\nsns.countplot(ytest)\nplt.ylim(0, 7000)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#----------------Check for null and missing values-------------\nprint(np.unique(Xtrain.isnull().sum()))\nprint(np.unique(Xtest.isnull().sum()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#--------------------Normalized the data-------------------\nXtrain=np.array(Xtrain/255)\nXtrain=Xtrain.reshape(-1,28,28,1)\nXtest=np.array(Xtest/255)\nXtest=Xtest.reshape(-1,28,28,1)\nytrain=np.array(ytrain)\nytest=np.array(ytest)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-----------------------CNN---Build the model--------------------------\n\n#Model 2 layers \nCNN=Sequential([Conv2D(16,3,padding='same',activation='relu'),MaxPool2D(),Conv2D(32,3,padding='same',activation='relu'),MaxPool2D(),Flatten(),Dense(128,activation='relu'),Dense(10,activation='softmax')])\nCNN.compile(optimizer='RMSprop',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN.fit(Xtrain,ytrain,epochs=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#-------------------Model evaluation---------------\nCNN.evaluate(Xtest,ytest)\nypred=CNN.predict_classes(Xtest)\nsns.heatmap(confusion_matrix(ytest,ypred),annot=True,fmt='d')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#--------------------------QC The errors, why can't capture by the model-------------------\n\nlst=list(np.where(ypred!=list(ytest)))[0][:]\nprint(lst)\nplt.figure(figsize=(10,10))\nfor i in range (6):\n    plt.subplot(2,3,i+1)\n    plt.imshow(Xtest[lst[i]],cmap='Greys')\n    plt.title(\"Predicted label :{}\\nTrue label :{}\".format(ypred[lst[i]],list(ytest)[lst[i]]))\nprint('\\n#------------------------------------------------------------------')  \n    \nprint('For those six case, the model is not bad. Some of these errors can also be made by humans, especially for second, the 6 that is very close to a 0, and fourth, 2 is also very misleading, it seems for me that is a 1.')\nprint('\\n#------------------------------------------------------------------')    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}