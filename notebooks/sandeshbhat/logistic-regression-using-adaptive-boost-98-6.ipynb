{"cells":[{"metadata":{"id":"yxbT9sTWshmr"},"cell_type":"markdown","source":"## Breast Cancer Diagnosis using Logistic regression","execution_count":null},{"metadata":{"id":"1AV4hsjysQvg"},"cell_type":"markdown","source":"Importing Libraries","execution_count":null},{"metadata":{"id":"I9h6RAjJakQD","outputId":"7be43b85-f10e-4ee3-9fb7-1ea697802203","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"id":"fETeD8pGsWU9"},"cell_type":"markdown","source":"Importing the file using pandas","execution_count":null},{"metadata":{"id":"ozNMZGEkbmTb","outputId":"0a186c82-9f1c-4146-9329-213b2019aa07","trusted":true},"cell_type":"code","source":"dataframe = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\ndataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"AyJCSLHBsZdh"},"cell_type":"markdown","source":"Analysing the correlation","execution_count":null},{"metadata":{"id":"56Pbv0QGkvPF","outputId":"22439846-a83b-47b1-9109-60ee8777233e","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.heatmap(dataframe.iloc[:,1:32].corr())","execution_count":null,"outputs":[]},{"metadata":{"id":"6rB-l29nsIaq"},"cell_type":"markdown","source":"Depending and Independent variable","execution_count":null},{"metadata":{"id":"ahJVjrGVcAL5","trusted":true},"cell_type":"code","source":"\nX = dataframe.iloc[: ,2:32].values\ny = dataframe.iloc[: ,1].values","execution_count":null,"outputs":[]},{"metadata":{"id":"1QXXzxrRkHAo","outputId":"9afc17ea-084d-4026-80c5-7710498518b1","trusted":true},"cell_type":"code","source":"print(X)","execution_count":null,"outputs":[]},{"metadata":{"id":"8MBqaryOkMqa","outputId":"4f58b2d5-6287-4742-85e1-5fd130ff42fb","trusted":true},"cell_type":"code","source":"print(y)","execution_count":null,"outputs":[]},{"metadata":{"id":"a3aCB9KQsup1"},"cell_type":"markdown","source":"Filling with missing Data","execution_count":null},{"metadata":{"id":"MVgE9tGf0iFs","outputId":"04302184-2976-45d2-cb53-bcc9a850dfce","trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values = np.nan, strategy = \"mean\")\nimputer.fit(X)\nX = imputer.transform(X)\nX","execution_count":null,"outputs":[]},{"metadata":{"id":"auaNQ7Cfs1gL"},"cell_type":"markdown","source":"Encoding Categorical data","execution_count":null},{"metadata":{"id":"5gO100_246BX","outputId":"fa1944b4-7b3c-4584-d717-df29675d5456","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)\ny","execution_count":null,"outputs":[]},{"metadata":{"id":"g9wRKm0Ns6bw"},"cell_type":"markdown","source":"Split the train and test data","execution_count":null},{"metadata":{"id":"NTPBFDLO1Wr8","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"id":"TGTgcL-zs-Yn"},"cell_type":"markdown","source":"Feature Scaling","execution_count":null},{"metadata":{"id":"y0NzaR0G3kAw","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"1Ao2iGZMmVtP","outputId":"e1d4be89-eb9c-4379-fe5c-5d20597fb8da","trusted":true},"cell_type":"code","source":"print(X_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"fLXSJFIQmYsl","outputId":"c3c7fffb-3bd0-4311-c889-43c1579e7fe0","trusted":true},"cell_type":"code","source":"print(X_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"xSXF_zH4tEOk"},"cell_type":"markdown","source":"Train the model using LR and boost the score using Adaptive boost ","execution_count":null},{"metadata":{"id":"-PmSE_VN4HLn","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import AdaBoostClassifier\nclassifier = LogisticRegression()\nclassifier_boost = AdaBoostClassifier(n_estimators = 10, base_estimator = classifier, learning_rate = 1)\nboost = classifier_boost.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"zph14YTktSD5"},"cell_type":"markdown","source":"Train accuracy","execution_count":null},{"metadata":{"id":"d5ytgBGrnChb","outputId":"48eeb32a-7bde-4442-d999-5c49342676ab","trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint(accuracy_score(boost.predict(X_train),y_train))","execution_count":null,"outputs":[]},{"metadata":{"id":"ne7bMuwgtVl9"},"cell_type":"markdown","source":"Test Score","execution_count":null},{"metadata":{"id":"afGM2f4k4i2c","outputId":"594b975b-318a-4bdf-9809-3a6e0909453c","trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\ncm = confusion_matrix(boost.predict(X_test),y_test)\nprint(\"Confusion Matrix: \\n\",cm,\"\\n\")\nprint(\"Score = \",accuracy_score(y_test,boost.predict(X_test)),\"\\n\")\nprint(classification_report(y_test,boost.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.heatmap(cm, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic regression with adaptive boosting gives a total score of 98.6% which is around 1% more than just LR","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}