{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **1. Introduction**","metadata":{}},{"cell_type":"markdown","source":"In this notebook I'm going to use the heart-attack-analysis-prediction dataset to predict a heart attack. The first step is to know the problem we are facing and extract information about the data, then, we start training our model and subsequently evaluate it.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndata = pd.read_csv('/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv')\nwarnings.filterwarnings('ignore') #Avoid print warnings","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:49:13.481679Z","iopub.execute_input":"2021-08-03T06:49:13.482076Z","iopub.status.idle":"2021-08-03T06:49:13.498844Z","shell.execute_reply.started":"2021-08-03T06:49:13.482042Z","shell.execute_reply":"2021-08-03T06:49:13.497427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:49:13.551612Z","iopub.execute_input":"2021-08-03T06:49:13.552139Z","iopub.status.idle":"2021-08-03T06:49:13.557673Z","shell.execute_reply.started":"2021-08-03T06:49:13.552105Z","shell.execute_reply":"2021-08-03T06:49:13.556607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the above code we are showing the size of our dataset, in which we have 303 rows and 14 columns.","metadata":{}},{"cell_type":"code","source":"data.columns","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:49:13.706333Z","iopub.execute_input":"2021-08-03T06:49:13.706679Z","iopub.status.idle":"2021-08-03T06:49:13.713467Z","shell.execute_reply.started":"2021-08-03T06:49:13.706647Z","shell.execute_reply":"2021-08-03T06:49:13.71224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are the name of different columns, we can see that have a column called 'output', this is the variable to predict, then we go to show the different values that can take this variable to see if we are in front of a binary classification problem or a multiclass problem.","metadata":{}},{"cell_type":"code","source":"data['output'].unique()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:49:13.792098Z","iopub.execute_input":"2021-08-03T06:49:13.792467Z","iopub.status.idle":"2021-08-03T06:49:13.799373Z","shell.execute_reply.started":"2021-08-03T06:49:13.792434Z","shell.execute_reply":"2021-08-03T06:49:13.798362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The only two values that the output variable can take are 0 and 1. 0 represents a low probability of suffering a heart attack, 1 represents high probability to suffering a heart attack. We are in front of a binary classification problem.","metadata":{}},{"cell_type":"markdown","source":"# **2. EDA**","metadata":{}},{"cell_type":"markdown","source":"For now we know what type of problem we are faced, but we don't know nothing about the data quality, for this reason, the first job is explore the data to get information about that. A good starting point is getting some general information about our dataset.","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:49:13.882367Z","iopub.execute_input":"2021-08-03T06:49:13.882858Z","iopub.status.idle":"2021-08-03T06:49:13.897846Z","shell.execute_reply.started":"2021-08-03T06:49:13.882826Z","shell.execute_reply":"2021-08-03T06:49:13.896863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the table above we can see that we have 303 entries and 14 columns (information extracted from the first two lines) but we already known this information. In the table we see the different column names, if has or not null values and their data type, and with this information we can make some assumptions like this: \n- We don't have null values, then we don't have to fill this white spaces.\n- All columns are in a numeric type (integer and float), then we don't have to convert the content of these columns in to numeric type or modify the column type to numeric. ","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:49:14.026758Z","iopub.execute_input":"2021-08-03T06:49:14.027149Z","iopub.status.idle":"2021-08-03T06:49:14.042484Z","shell.execute_reply.started":"2021-08-03T06:49:14.027115Z","shell.execute_reply":"2021-08-03T06:49:14.041319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the table above we see the different columns and the content of the first five rows, and also we see that the range of the different values are different, e.g. the sex column contains values that are either 0 or 1 (depend on if the person is male or female) and the column named chol (cholesterol in mg/dL) contains high values, therefore we should standarize the data (modify the ranges of all the columns from -1 to 1) if we want to use algorithms that uses the distance to classify the data. If we would have different ranges in the columns the influence in the output of the columns will be different, this means that the model would take into account the columns with higher values to decide the final result. Before to standarize the model we should see if the columns have some correlation between them and decide if we should or not remove any column. But this standardisation  will take place before to training, now I want to know if there are any correlation between the features.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12,6))\nsns.heatmap(data.corr(),cmap='coolwarm', annot=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:49:14.101319Z","iopub.execute_input":"2021-08-03T06:49:14.10186Z","iopub.status.idle":"2021-08-03T06:49:15.44425Z","shell.execute_reply.started":"2021-08-03T06:49:14.101821Z","shell.execute_reply":"2021-08-03T06:49:15.443116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seeing the correlation between columns we can say that all the columns are necessary, or the same, we don't should remove any column because the correlations are near to 0. If we had two columns with a correlation around 1 or -1 we should remove one of this columns, because a high correlation can lead us to get bad results. Other thing to check is see if we have duplicated values, the duplicated values can lead us to a bad perform.","metadata":{}},{"cell_type":"code","source":"data.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:49:15.446024Z","iopub.execute_input":"2021-08-03T06:49:15.446436Z","iopub.status.idle":"2021-08-03T06:49:15.456293Z","shell.execute_reply.started":"2021-08-03T06:49:15.446391Z","shell.execute_reply":"2021-08-03T06:49:15.455291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have 1 duplicated value, this is not a problem because we can remove this value without lose to much data.","metadata":{}},{"cell_type":"code","source":"data = data.drop_duplicates()\ndata.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:49:15.458745Z","iopub.execute_input":"2021-08-03T06:49:15.459181Z","iopub.status.idle":"2021-08-03T06:49:15.474691Z","shell.execute_reply.started":"2021-08-03T06:49:15.459138Z","shell.execute_reply":"2021-08-03T06:49:15.473801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we don't have duplicated values, the next step is know if we have either balanced or unbalanced data, in case that we don't have a balanced dataset we could have problems to predict the label with few samples. To comprove this we have to count the different entries with output equals to 1 and entries with output equals to 0.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nsns.countplot(data['output']) ","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:49:15.476707Z","iopub.execute_input":"2021-08-03T06:49:15.477163Z","iopub.status.idle":"2021-08-03T06:49:15.617708Z","shell.execute_reply.started":"2021-08-03T06:49:15.477119Z","shell.execute_reply":"2021-08-03T06:49:15.616668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have around 140 samples of no heart attack and around 165 samples of heart attack, this dataset it is balanced because have around 50% for each sample to predict, in case that the dataset contains 70-30 or more, the dataset should considered unbalanced, and in this case the treatment of the data would be dfferent.\n\nOther interesting thing to do is see if we have balanced data but not for the final result, but for sex column. This is a good practice, because we could have problems predict the heart attack for the sex with few samples.","metadata":{}},{"cell_type":"code","source":"fig, ax3 = plt.subplots(figsize=(12,5))\ngrp2 = data.groupby(['sex', 'output'])['output'].count() #Rating mean\ngrp2.plot.bar(ax = ax3)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:49:15.619241Z","iopub.execute_input":"2021-08-03T06:49:15.619654Z","iopub.status.idle":"2021-08-03T06:49:15.779374Z","shell.execute_reply.started":"2021-08-03T06:49:15.61961Z","shell.execute_reply":"2021-08-03T06:49:15.778387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see in the table, we have more samples of the sex 1 than the sex 0, this could be a problem. I don't know if the conditions for having an heart attack are different in men and women, for this reason I go to see the relationship between the probability of suffer a heart attack and the sex.","metadata":{}},{"cell_type":"code","source":"import statsmodels.formula.api as sm\nreg = sm.ols(formula='output ~ sex', data = data).fit()\nprint(reg.summary())","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:49:15.780766Z","iopub.execute_input":"2021-08-03T06:49:15.781188Z","iopub.status.idle":"2021-08-03T06:49:15.802831Z","shell.execute_reply.started":"2021-08-03T06:49:15.781146Z","shell.execute_reply":"2021-08-03T06:49:15.801643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the above table we can see the relationship between the dependent variable (output) and the independent variable (sex). To see if the sex variable is important to predict the output we might observe the p-value (P>|t| in the table). This value tell us if the independent variable is statistically significant or not, in our case this values is 0.000 this means that sex variable has a lot of importance, because the p-value is less than 0.005. So we shouldn't remove the sex variable. Therefore, we could have problems predicting low probability of suffering a heart attack in the sex labeled as 0.","metadata":{}},{"cell_type":"markdown","source":"# **2. Training**","metadata":{}},{"cell_type":"code","source":"x = data.iloc[:, 0:13].values #Independent variables\ny = data.iloc[:, 13].values #Dependent variable","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:49:15.805933Z","iopub.execute_input":"2021-08-03T06:49:15.806227Z","iopub.status.idle":"2021-08-03T06:49:15.812327Z","shell.execute_reply.started":"2021-08-03T06:49:15.8062Z","shell.execute_reply":"2021-08-03T06:49:15.811361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data standarizaton\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx = sc.fit_transform(x)\nx[1]","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:49:15.815039Z","iopub.execute_input":"2021-08-03T06:49:15.815337Z","iopub.status.idle":"2021-08-03T06:49:15.828012Z","shell.execute_reply.started":"2021-08-03T06:49:15.815307Z","shell.execute_reply":"2021-08-03T06:49:15.826934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data has been standarized, now we don't will have problems with the columns influence in the final result. As example we see the values for the different columns in the first row.\n\nNow we need to split the data in a subset for train the model and a subset for test the performance of our model, for this reason we need to use the train_test_split function. Also we need to do this split for the independent variable and for the dependent variable.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:49:15.830102Z","iopub.execute_input":"2021-08-03T06:49:15.83059Z","iopub.status.idle":"2021-08-03T06:49:15.837485Z","shell.execute_reply.started":"2021-08-03T06:49:15.830552Z","shell.execute_reply":"2021-08-03T06:49:15.836291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now it's time to train the model, but for do it we have a lot of models, and a lot of hyperparameters. If we don't know what model can be fitting better we can use the grid search technique. This technique helps us to train the model with more than one classifier (or one if we want) and also we can select some values for their hyperparaments and see the algorithm with better permormance. ","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier \n\npipe = Pipeline(steps = [('estimator', DecisionTreeClassifier())])\n\nparams = [{\n    'estimator' : [XGBClassifier()], \n    'estimator__max_depth' : range(2,8), \n    'estimator__learning_rate' : [0.11, 0.12, 0.13], \n    'estimator__n_estimators' : range(100,106),\n    'estimator__min_child_weight': range(1,4),\n    'estimator__min_split_loss' : range(1,4) \n    },\n    {\n    'estimator' : [RandomForestClassifier()],\n    'estimator__n_estimators' : range(297, 303), \n    'estimator__max_depth' : range(3,7), \n    }]\n\nmodel_grid = GridSearchCV(pipe, cv=5, param_grid = params)\nmodel_grid.fit(x_train, y_train)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-03T06:49:15.838865Z","iopub.execute_input":"2021-08-03T06:49:15.839204Z","iopub.status.idle":"2021-08-03T06:54:24.530751Z","shell.execute_reply.started":"2021-08-03T06:49:15.839173Z","shell.execute_reply":"2021-08-03T06:54:24.529838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_grid.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:54:24.532106Z","iopub.execute_input":"2021-08-03T06:54:24.532418Z","iopub.status.idle":"2021-08-03T06:54:24.539147Z","shell.execute_reply.started":"2021-08-03T06:54:24.532388Z","shell.execute_reply":"2021-08-03T06:54:24.538198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are trained two different models, and the best model is Random Forest, the next step is evaluate the model with different metrics. The first metric that we should check is the accuracy, this metric evalueates the ability of the model for make a prediction. ","metadata":{}},{"cell_type":"code","source":"print(\"Accuracy train: {:.3f}\".format(model_grid.score(x_train, y_train))) #See the accuracy of training set\nprint(\"Accuracy test: {:.3f}\".format(model_grid.score(x_test, y_test))) #Print the accuracy of test set","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:54:24.540416Z","iopub.execute_input":"2021-08-03T06:54:24.540687Z","iopub.status.idle":"2021-08-03T06:54:24.613948Z","shell.execute_reply.started":"2021-08-03T06:54:24.54066Z","shell.execute_reply":"2021-08-03T06:54:24.612908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this case we have an accuracy of 89.6% in the train set (the model is able to predict well the 89.6% of knowed samples) and is able to predict the 82'4% in the test set (data that the model has never seen) The accuracy are differents in both cases, this is quite normal but if we had a very high gap between the accuracies we have two cases: \n- The train model is very higher than the test model: In this case we talk about overffit, the model is able to do well predictions in date previously seen, but don't know how to generalize with data that never had seen.\n\n- The model performs very poorly also in train set, in this case we talk about underfit. \n\nIn our case we don't have any of this cases. ","metadata":{}},{"cell_type":"code","source":"y_pred = model_grid.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:54:24.615218Z","iopub.execute_input":"2021-08-03T06:54:24.615496Z","iopub.status.idle":"2021-08-03T06:54:24.649535Z","shell.execute_reply.started":"2021-08-03T06:54:24.615469Z","shell.execute_reply":"2021-08-03T06:54:24.648397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Another metric to predict is the confusion matrix, the diagonal of the matrix represents the correct predictions, the other values are wrong predicted values. ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncnf = confusion_matrix(y_test, y_pred)\ncnf","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:54:24.650927Z","iopub.execute_input":"2021-08-03T06:54:24.651215Z","iopub.status.idle":"2021-08-03T06:54:24.658917Z","shell.execute_reply.started":"2021-08-03T06:54:24.651184Z","shell.execute_reply":"2021-08-03T06:54:24.658037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have 34 negative cases labeled as negative cases, and 41 positives cases labeled as positives. But our model is not perfect (no model is perfect in reality), we have 11 cases labeled as positives but actually are negatives, the false positive are a problem in healthcare field because we predict that a healthy person has a disease, but the real problem are the false negative, 5 in our case, because we predict that a person is healthy but in reality they are not.\n\nFor this reason the accuracy could give use a false safety when we apply this algorithm to a patient and carry out the predictions. The best metric to to use in this type of problems is the ROC curve, which tells us the relationship between true positives vs false positives.","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\nmetrics.plot_roc_curve(model_grid, x_test, y_test)  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T06:54:24.660278Z","iopub.execute_input":"2021-08-03T06:54:24.660574Z","iopub.status.idle":"2021-08-03T06:54:24.838593Z","shell.execute_reply.started":"2021-08-03T06:54:24.660547Z","shell.execute_reply":"2021-08-03T06:54:24.837598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is the ROC curve, in our model we have a proportion of 0.92 or 92%, this means that the 92% of cases labeled as true positives will actually be true positives.","metadata":{}},{"cell_type":"markdown","source":"# **3. Conclusions**\nWe are trained a model to detect heart attacks, and we are achieved good results. This dataset are very easy to interpret because we don't have null values, unbalanced data, categorical variables and the amount of data is enough for do well predictions. In a real dataset we don't have this type of dataset and neither datasets with few columns with wich is easy to work. In real jobs we spend around the 80% of the time in EDA step, in our case we don't have spend to much time. \n\n\nWe could use other algorithms and other hyperparameters but this is only an example about the power of these algorithms, and what we could do whith them if the humans and the IA worked together.","metadata":{}}]}