{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the dataset\ndata = pd.read_csv(\"../input/heart-attack-analysis-prediction-dataset/heart.csv\")\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['output'].value_counts().plot.bar(figsize = (10,5), color = ['grey','red'])\nplt.xticks(rotation=0)\nplt.title('Quantity of each TARGET class in the dataset', fontsize = 15)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets split the dataset into X and target y","metadata":{}},{"cell_type":"code","source":"X = data.drop(['output'],axis=1)\ny = data[['output']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"lets check their forms:","metadata":{}},{"cell_type":"code","source":"print('features: ', X.shape)\nprint('target: ', y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import libraries\nfrom sklearn.metrics import accuracy_score, classification_report, roc_curve\n\n# Importing Classifier Modules\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression,PassiveAggressiveClassifier,RidgeClassifier,SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier,RadiusNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\nfrom sklearn.svm import LinearSVC, SVC,NuSVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_validate\nfrom time import perf_counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics\n\nfrom IPython.display import Markdown, display\n\ndef printmd(string):\n    # Print with Markdowns    \n    display(Markdown(string))\n\nimport warnings\nwarnings.filterwarnings(action='ignore')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"then let we split their to train and test datasets","metadata":{}},{"cell_type":"code","source":"# creating a copy of df\ndf = data\n\n# define the columns to be encoded and scaled\ncat_cols = ['sex','exng','caa','cp','fbs','restecg','slp','thall']\ncon_cols = [\"age\",\"trtbps\",\"chol\",\"thalachh\",\"oldpeak\"]\n\n# encoding the categorical columns\ndf = pd.get_dummies(df, columns = cat_cols, drop_first = True)\n\n# defining the features and target\nX = df.drop('output', axis=1)\ny = df['output']\n\n# instantiating the scaler\nscaler = StandardScaler()\n\n# scaling the continuous featuree\nX[con_cols] = scaler.fit_transform(X[con_cols])\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 32)\n\nprint('X_train: ', X_train.shape)\nprint('X_test: ', X_test.shape)\nprint('y_train: ', y_train.shape)\nprint('y_test: ', y_test.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross-validation for several alhorithms","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dictionary with the model which will be tested\nmodels = {\n    \"GaussianNB\":{\"model\":GaussianNB()},\n    \"PassiveAggressiveClassifier\":{\"model\":PassiveAggressiveClassifier() },\n    \"RidgeClassifier\":{\"model\":RidgeClassifier() },\n    \"SGDClassifier\":{\"model\":SGDClassifier() },\n    \"KNeighborsClassifier\":{\"model\":KNeighborsClassifier() },\n    \"DecisionTreeClassifier\":{\"model\":DecisionTreeClassifier() },\n    \"ExtraTreeClassifier\":{\"model\":ExtraTreeClassifier() },\n    \"LinearSVC\":{\"model\":LinearSVC() },\n    \"SVC\":{\"model\":SVC() },\n    \"NuSVC\":{\"model\":NuSVC() },\n    \"MLPClassifier\":{\"model\":MLPClassifier() },\n    \"RandomForestClassifier\":{\"model\":RandomForestClassifier() },\n    \"GradientBoostingClassifier\":{\"model\":GradientBoostingClassifier() },\n    \"AdaBoostClassifier\":{\"model\":AdaBoostClassifier() }\n}\n\n# Use the 10-fold cross validation for each model\n# to get the mean validation accuracy and the mean training time\nfor name, m in models.items():\n    # Cross validation of the model\n    model = m['model']\n    result = cross_validate(model, X_train,y_train,cv = 5)\n    \n    # Mean accuracy and mean training time\n    mean_val_accuracy = round( sum(result['test_score']) / len(result['test_score']), 4)\n    mean_fit_time = round( sum(result['fit_time']) / len(result['fit_time']), 4)\n    \n    #y_model_predict = model.predict(X_test)\n    \n    # Add the result to the dictionary with the models\n    m['val_accuracy'] = mean_val_accuracy\n    m['Training time (sec)'] = mean_fit_time\n    \n    # Display the result\n    print(f\"{name:27} mean accuracy using 5-fold cross validation: {mean_val_accuracy*100:.2f}% - mean training time {mean_fit_time} sec\")\n    #print(f\"{name:27} metrics accuracy_score: {metrics.accuracy_score(y_test, y_model_predict)*100:.2f} %\")\n    #metrics.accuracy_score(y_test, y_model_predict)\n    #metrics.precision_score(y_test, y_model_predict)\n    #metrics.recall_score(y_test, y_model_predict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}