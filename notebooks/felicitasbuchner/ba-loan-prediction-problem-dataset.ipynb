{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #comprehensive library for creating static, animated, and interactive visualizations in Python\nimport seaborn as sns #data visualization library based on matplotlib\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run start","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv\")\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/loan-prediction-problem-dataset/test_Y3wMUE5_7gLdaTN.csv\")\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"train_data.info() shows that some values are missing.\n<br>These will be investigated in next code cell","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"missing values in gender, married, dependents, self_employed, loan_amount(crit), loan_amount_term, credit_history(crit).<br>\nFilling the mising values of loan_amount by the mean of all of its values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Mean of LoanAmount:\", train_data['LoanAmount'].mean())\ntrain_data['LoanAmount'] = train_data['LoanAmount'].fillna(train_data['LoanAmount'].mean())\nprint(train_data.loc[:, 'LoanAmount'])\n#pd.notnull(train_data[\"LoanAmount\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating missing Credit_History values by median<br>\nmean doesn't make sense as it is something around 0.8","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Median of Credit_History:\", train_data['Credit_History'].median())\ntrain_data['Credit_History'] = train_data['Credit_History'].fillna(train_data['Credit_History'].median())\nprint(train_data.loc[:, 'Credit_History'])\n#pd.notnull(train_data[\"Credit_History\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"filling the rest of the mising values, always by average value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Gender Male:\", sum(train_data['Gender'] == 'Male'))\nprint(\"Gender Female:\", sum(train_data['Gender'] == 'Female'))\n\ntrain_data['Gender'] = train_data['Gender'].fillna('Male')\n#pd.notnull(train_data[\"Gender\"])\n\nprint(\"Married Yes:\", sum(train_data['Married'] == 'Yes'))\nprint(\"Married No:\", sum(train_data['Married'] == 'No'))\n\ntrain_data['Married'] = train_data['Married'].fillna('Yes')\n#pd.notnull(train_data[\"Gender\"])\n\nprint(\"Dependents 0:\", sum(train_data['Dependents'] == '0'))\nprint(\"Dependents 1:\", sum(train_data['Dependents'] == '1'))\n\ntrain_data['Dependents'] = train_data['Dependents'].fillna('0')\n#pd.notnull(train_data[\"Gender\"])\n\nprint(\"Self_Employed Yes:\", sum(train_data['Self_Employed'] == 'Yes'))\nprint(\"Self_Employed No:\", sum(train_data['Self_Employed'] == 'No'))\n\ntrain_data['Self_Employed'] = train_data['Self_Employed'].fillna('No')\n#pd.notnull(train_data[\"Gender\"])\n\nprint(\"Mean of Loan_Amount_Term:\", train_data['Loan_Amount_Term'].median())\ntrain_data['Loan_Amount_Term'] = train_data['Loan_Amount_Term'].fillna(train_data['Loan_Amount_Term'].median())\n#print(train_data.loc[:, 'Loan_Amount_Term'])\n#pd.notnull(train_data[\"Loan_Amount_Term\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Univariate Analysis</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Gender'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Married'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Education'].value_counts()\n#more graduated people seem to apply for a loan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Self_Employed'].value_counts()\n#Self employed people seem not to apply for a loan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Property_Area'].value_counts()\n#quite balanced","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.boxplot(train_data['ApplicantIncome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.boxplot(train_data['CoapplicantIncome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.boxplot(train_data['LoanAmount'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.boxplot(train_data['Loan_Amount_Term'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.boxplot(train_data['Credit_History'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Bivariate Analysis</h1>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"scatterplots are used for determining the strength between two variables.<br>\nx-axis is the independent variable, y-axis is the dependent variable ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='Property_Area',y='Loan_Status',data=train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.crosstab(train_data['Property_Area'],train_data['Loan_Status']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_data['Property_Area'],hue=train_data['Loan_Status'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>From all semiurban people around 77% get a loan. Thus this feature seems very useful to me.</h3>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='Self_Employed',y='Loan_Status',data=train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='Credit_History',y='Loan_Status',data=train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.crosstab(train_data['Credit_History'],train_data['Loan_Status']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_data['Credit_History'],hue=train_data['Loan_Status'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.crosstab(train_data['Gender'],train_data['Loan_Status']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_data['Gender'],hue=train_data['Loan_Status'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>males seem to have higher chances than females</h3>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.crosstab(train_data['Married'],train_data['Loan_Status']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_data['Married'],hue=train_data['Loan_Status'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>From all married applicants around 72% get a loan.</h3>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.crosstab(train_data['Self_Employed'],train_data['Loan_Status']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_data['Self_Employed'],hue=train_data['Loan_Status'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Out of all <b>not self employed</b> 70% get a loan.<br>\n<s>Out of all  <b>self employed</b> 67% get a loan.</s></h3>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.crosstab(train_data['Education'],train_data['Loan_Status']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train_data['Education'],hue=train_data['Loan_Status'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Out of all graduates around 71% get a loan.</h3>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"now dependent categorial variabls are converted to continous variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Loan_Status'].replace('N',0,inplace=True)\ntrain_data['Loan_Status'].replace('Y',1,inplace=True)\n\n#train_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>.corr() to calculate pearson's r, spearman's rho and kendall's tau</p>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h1>Recoding to numerical values</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nle=LabelEncoder()\nohe=OneHotEncoder()\n\ntrain_data2 = train_data\n\ntrain_data2=train_data2.drop(labels=['Loan_ID'],axis=1)\ntrain_data2['Property_Area']=le.fit_transform(train_data2['Property_Area'])\n# 0 == 'Rural',1 == 'Semiurban', 2 == 'Urban' \ntrain_data2['Dependents']=le.fit_transform(train_data2['Dependents'])\n# 0 == 0, 1 == 1, 2== 2, 3 == '+3'\n\ntrain_data2=pd.get_dummies(train_data2)\n\ntrain_data2.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data2.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-----------------------------------------------------------------","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data2.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Correlation Matrix')\nsns.heatmap(train_data2.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>notice that the dependent variable Loan_Status is dependent only on Credit_History. So this will be kept while all the others which are not related with Loan_Status will be discarded.</h3> ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data3 = train_data2\n\ntrain_data3=train_data3.drop(labels=['ApplicantIncome'],axis=1)\ntrain_data3=train_data3.drop(labels=['CoapplicantIncome'],axis=1)\ntrain_data3=train_data3.drop(labels=['LoanAmount'],axis=1)\ntrain_data3=train_data3.drop(labels=['Loan_Amount_Term'],axis=1)\ntrain_data3=train_data3.drop(labels=['Gender_Female'],axis=1)\ntrain_data3=train_data3.drop(labels=['Married_No'],axis=1)\ntrain_data3=train_data3.drop(labels=['Education_Not Graduate'],axis=1)\ntrain_data3=train_data3.drop(labels=['Self_Employed_Yes'],axis=1)\n\ntrain_data3.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Correlation Matrix (Update)')\nsns.heatmap(train_data3.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loan_Status is most correlated with Credit_History and least correlated with Self_Employed_No, Dependents<br>\nConsider dropping!!!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_data3=train_data3.drop('Self_Employed_No',1)\n#train_data3=train_data3.drop('Dependents',1)\n\n#train_data3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_data3.drop('Loan_Status', 1)\nY = train_data3['Loan_Status']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(X))\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Splitting train and test dataset</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=6)\n\nprint('Shape of x_train is: ',x_train.shape)\nprint('Shape of x_test is: ',x_test.shape)\nprint('Shape of y_train is: ',y_train.shape)\nprint('Shape of y_test is: ',y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Logistic regression</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogreg=LogisticRegression()\nlogreg.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"score() takes a feature matrix X_test and the expected target values y_test. Predictions for X_test are compared with y_test and either accuracy (for classifiers) or R² score (for regression estimators) is returned.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(logreg.score(x_train, y_train))\nacc_log = round(logreg.score(x_train, y_train) * 100, 2)\nprint(round(acc_log,2,), \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting trest dataset\npred = logreg.predict(x_test)\n\nfrom sklearn.metrics import accuracy_score\naccsc_log = round(accuracy_score(y_test,pred) * 100,2)\nprint('The accuracy of Logistic Regression is: ',accsc_log, '%' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>around 84% seems a good acuracy score for first try.</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nlg_cm = metrics.confusion_matrix(y_test, pred)\nlg_cm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"true positives: 89 [1,1]<br>\ntrue negatives: 14 [0,0]<br>\nfalse negatives: 1 [1,0]<br>\nfalse positives: 19 [0,1]<br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay\nlgcm_display = ConfusionMatrixDisplay(lg_cm, display_labels=[0,1]).plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.recall_score(y_test,pred))\nprint(metrics.precision_score(y_test,pred))\nprint(metrics.f1_score(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data={'y_test':y_test,'pred':pred}\npd.DataFrame(data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Linear regression</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlinreg = LinearRegression(normalize=True)\nlinreg.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(linreg.score(x_train,y_train))\nacc_linreg = round(linreg.score(x_train, y_train) * 100, 2)\nprint(round(acc_linreg,2,), \"%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Decision tree</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndt=DecisionTreeClassifier()\ndt.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dt.score(x_train,y_train))\nacc_dt = round(dt.score(x_train, y_train) * 100, 2)\nprint(round(acc_dt,2,), \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred1=dt.predict(x_test)\naccsc_dt = round(accuracy_score(y_test,pred1)* 100, 2)\nprint('The accuracy of Logistic Regression is: ', accsc_dt, '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_cm = metrics.confusion_matrix(y_test,pred1)\ndt_cm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"true positives: 82 [1,1]<br>\ntrue negatives: 16 [0,0]<br>\nfalse negatives: 8 [1,0]<br>\nfalse positives: 17 [0,1]<br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dtcm_display = ConfusionMatrixDisplay(dt_cm, display_labels=[0,1]).plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.f1_score(y_test,pred1))\nprint(metrics.recall_score(y_test,pred1))\nprint(metrics.precision_score(y_test,pred1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>K-NN</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nknn.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(knn.score(x_train,y_train))\nacc_knn = round(knn.score(x_train, y_train) * 100, 2)\nprint(round(acc_knn,2,), \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred2=knn.predict(x_test)\naccsc_knn = round(accuracy_score(y_test,pred2) * 100, 2)\nprint('The accuracy of k-nearest neighbor regression: ', accsc_knn, '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_cm = metrics.confusion_matrix(y_test,pred2)\nknn_cm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"true positives: 86 [1,1]<br>\ntrue negatives: 12 [0,0]<br>\nfalse negatives: 4 [1,0]<br>\nfalse positives: 21 [0,1]<br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"knncm_display = ConfusionMatrixDisplay(knn_cm, display_labels=[0,1]).plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.f1_score(y_test,pred2))\nprint(metrics.recall_score(y_test,pred2))\nprint(metrics.precision_score(y_test,pred2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>SVM</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm = SVC(kernel = 'linear', random_state = 0)\nsvm.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(svm.score(x_train,y_train))\nacc_svm = round(svm.score(x_train, y_train) * 100, 2)\nprint(round(acc_svm,2,), \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred3=svm.predict(x_test)\naccsc_svm = round(accuracy_score(y_test,pred3) * 100, 2)\nprint('The accuracy of support vector machine regression: ', accsc_svm, '%' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svm_cm = metrics.confusion_matrix(y_test,pred3)\nsvm_cm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"true positives: 89 [1,1]<br>\ntrue negatives: 14 [0,0]<br>\nfalse negatives: 1 [1,0]<br>\nfalse positives: 19 [0,1]<br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svmcm_display = ConfusionMatrixDisplay(svm_cm, display_labels=[0,1]).plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.f1_score(y_test,pred3))\nprint(metrics.recall_score(y_test,pred3))\nprint(metrics.precision_score(y_test,pred3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Naives Bayes</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(nb.score(x_train,y_train))\nacc_nb = round(nb.score(x_train, y_train) * 100, 2)\nprint(round(acc_nb,2,), \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred4=nb.predict(x_test)\naccsc_nb = round(accuracy_score(y_test,pred4) * 100, 2)\nprint('The accuracy of naives bayes regression: ', accsc_nb, '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_cm = metrics.confusion_matrix(y_test,pred4)\nnb_cm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"true positives: 89 [1,1]<br>\ntrue negatives: 14 [0,0]<br>\nfalse negatives: 1 [1,0]<br>\nfalse positives: 19 [0,1]<br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"nbcm_display = ConfusionMatrixDisplay(nb_cm, display_labels=[0,1]).plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.f1_score(y_test,pred4))\nprint(metrics.recall_score(y_test,pred4))\nprint(metrics.precision_score(y_test,pred4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Random forest classification</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nrf.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(rf.score(x_train,y_train))\nacc_rf = round(rf.score(x_train, y_train) * 100, 2)\nprint(round(acc_rf,2,), \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_rf = round(rf.score(x_train, y_train) * 100, 2)\nprint(round(acc_rf,2,), \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred5=rf.predict(x_test)\naccsc_rf = round(accuracy_score(y_test,pred4) * 100, 2) \nprint('The accuracy of random forest classification: ', accsc_rf, '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_cm = metrics.confusion_matrix(y_test,pred5)\nrf_cm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"true positives: 85 [1,1]<br>\ntrue negatives: 15 [0,0]<br>\nfalse negatives: 5 [1,0]<br>\nfalse positives: 18 [0,1]<br>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rfcm_display = ConfusionMatrixDisplay(rf_cm, display_labels=[0,1]).plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(metrics.f1_score(y_test,pred5))\nprint(metrics.recall_score(y_test,pred5))\nprint(metrics.precision_score(y_test,pred5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Which is the best model?</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Decision Tree', 'KNN', 'Support Vector Machines', 'Naive Bayes', 'Random Forest',],\n    'Score': [acc_log, acc_dt, acc_knn, acc_svm, acc_nb, acc_rf]})\nresult_df = results.sort_values(by='Score', ascending=False)\nresult_df = result_df.set_index('Score')\nresult_df.head(7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_acc = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Decision Tree', 'KNN', 'Support Vector Machines', 'Naive Bayes', 'Random Forest',],\n    'Score': [accsc_log, accsc_dt, accsc_knn, accsc_svm, accsc_nb, accsc_rf]})\nresult_df = results_acc.sort_values(by='Score', ascending=False)\nresult_df = result_df.set_index('Score')\nresult_df.head(7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>Random Forest seams to be the best option since it provides a good blackbox model.<br>\nNext step will be ckecking random forest when using cross validation.</p>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h1>K-Fold Cross Validation</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(rf, x_train, y_train, cv=10, scoring = \"accuracy\")\n\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>This model has a average accuracy of 74% with a standard deviation of 6%. The standard deviation shows how precise the stimates are.<br>\n   Thus this means that the accurcay of thi model can differ <b>+ - 6%</b><br>\n</p>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h1>Feature importance</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = rf.feature_importances_\nimportance = pd.DataFrame({'Feature':x_train.columns,'Importance':np.round(importances,8)})\nimportance = importance.sort_values('Importance',ascending=False).set_index('Feature')\n\nimportance.head(9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importance.plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score\n\nprint(\"Precision:\", precision_score(y_test, pred5))\nprint(\"Recall:\", recall_score(y_test, pred5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>The model predicts 82% of the time, a given loan correctly (precision). The recall tells us that it predicted the loan status of 94 % of the people who actually got a loan.</p>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h1>OUTPUT</h1>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h1>Adaption of test_data</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['Gender'] = test_data['Gender'].fillna('Male')\ntest_data['Dependents'] = test_data['Dependents'].fillna('0')\ntest_data['Self_Employed'] = test_data['Self_Employed'].fillna('No')\ntest_data['LoanAmount'] = test_data['LoanAmount'].fillna(train_data['LoanAmount'].median())\ntest_data['Loan_Amount_Term'] = test_data['Loan_Amount_Term'].fillna(train_data['Loan_Amount_Term'].median())\ntest_data['Credit_History'] = test_data['Credit_History'].fillna(train_data['Credit_History'].median())\n\ntest_data2 = test_data\n\ntest_data2=test_data2.drop(labels=['Loan_ID'],axis=1)\ntest_data2['Property_Area']=le.fit_transform(test_data2['Property_Area'])\n# 0 == 'Rural',1 == 'Semiurban', 2 == 'Urban' \ntest_data2['Dependents']=le.fit_transform(test_data2['Dependents'])\n# 0 == 0, 1 == 1, 2== 2, 3 == '+3'\n\ntest_data2=pd.get_dummies(test_data2)\n\ntest_data3 = test_data2\n\ntest_data3=test_data3.drop(labels=['ApplicantIncome'],axis=1)\ntest_data3=test_data3.drop(labels=['CoapplicantIncome'],axis=1)\ntest_data3=test_data3.drop(labels=['LoanAmount'],axis=1)\ntest_data3=test_data3.drop(labels=['Loan_Amount_Term'],axis=1)\ntest_data3=test_data3.drop(labels=['Gender_Female'],axis=1)\ntest_data3=test_data3.drop(labels=['Married_No'],axis=1)\ntest_data3=test_data3.drop(labels=['Education_Not Graduate'],axis=1)\ntest_data3=test_data3.drop(labels=['Self_Employed_Yes'],axis=1)\n\ntest_data3['Credit_History'] = test_data3['Credit_History'].fillna(train_data['Credit_History'].median())\n\ntest_data3.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Shap Values of test_data</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap #package used to calculate Shap values\n\n#creates object that can calculate shap values\nexplainer = shap.TreeExplainer(rf, x_train)\n\n#calculates Shap Values\nshap_values_test = explainer.shap_values(test_data3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.shape(shap_values_test[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The shap_values object above is a list with two arrays. The first array is the SHAP values for a negative outcome (doesn't get loan), and the second array is the list of SHAP values for the positive outcome (gets loan). We typically think about predictions in terms of the prediction of a positive outcome, so we'll pull out SHAP values for positive outcomes (pulling out shap_values[1]).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"np.around(shap_values_test[1] * 100 , 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap_test = pd.DataFrame(np.around(shap_values_test[1] * 100 , 2), columns= ['Shap Dependents','Shap Credit_History','Shap Property_Area', 'Shap Gender_Male', 'Shap Married_Yes', 'Shap Education_Graduate', 'Shap Self_Employed_No'])\nshap_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap_test['Shap ApplicantIncome'] = 'null'\nshap_test['Shap CoapplicantIncome'] = 'null'\nshap_test['Shap LoanAmount'] = 'null'\nshap_test['Shap Loan_Amount_Term'] = 'null'\n\nshap_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = rf.predict(test_data3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_proba = rf.predict_proba(test_data3)\ny_pred_proba = y_pred_proba[:,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_proba = np.around(y_pred_proba * 100, 0)\ny_pred_proba","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_proba.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['Gender'].replace('Male','Maennlich',inplace=True)\ntest_data['Gender'].replace('Female','Weiblich',inplace=True)\ntest_data['Married'].replace('Yes','Ja',inplace=True)\ntest_data['Married'].replace('No','Nein',inplace=True)\ntest_data['Education'].replace('Graduate','Abschluss',inplace=True)\ntest_data['Education'].replace('Not Graduate','Kein Abschluss',inplace=True)\ntest_data['Self_Employed'].replace('Yes','Ja',inplace=True)\ntest_data['Self_Employed'].replace('No','Nein',inplace=True)\ntest_data['Credit_History'].replace(1.0,'Vorliegend',inplace=True)\ntest_data['Credit_History'].replace(0.0,'Nicht vorliegend',inplace=True)\ntest_data['Property_Area'].replace('Rural','Laendlich',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame({\n        \"Kredit_ID\": test_data[\"Loan_ID\"],\n        \"Geschlecht\": test_data[\"Gender\"],\n        \"Shap Geschlecht in %\": shap_test[\"Shap Gender_Male\"],\n        \"Verheiratet\": test_data[\"Married\"],\n        \"Shap Verheiratet in %\": shap_test[\"Shap Married_Yes\"],\n        \"Angehoerige\": test_data[\"Dependents\"],\n        \"Shap Angehoerige in %\": shap_test[\"Shap Dependents\"],\n        \"Ausbildung\": test_data[\"Education\"],\n        \"Shap Ausbildung in %\": shap_test[\"Shap Education_Graduate\"],\n        \"Selbstbeschaeftigt\": test_data[\"Self_Employed\"],\n        \"Shap Selbstbeschaeftigt in %\": shap_test[\"Shap Self_Employed_No\"],\n        \"Antragstellereinkommen\": test_data[\"ApplicantIncome\"],\n        \"Shap Antragstellereinkommen in %\": shap_test[\"Shap ApplicantIncome\"],\n        \"Mitantragstellereinkommen\": test_data[\"CoapplicantIncome\"],\n        \"Shap Mitantragstellereinkommen in %\": shap_test[\"Shap CoapplicantIncome\"],\n        \"Kredithoehe\": test_data[\"LoanAmount\"],\n        \"Shap Kredithoehe in %\": shap_test[\"Shap LoanAmount\"],\n        \"Kreditlaufzeit\": test_data[\"Loan_Amount_Term\"],\n        \"Shap Kreditlaufzeit in %\": shap_test[\"Shap Loan_Amount_Term\"],\n        \"Kreditgeschichte\": test_data[\"Credit_History\"],\n        \"Shap Kreditgeschichte in %\": shap_test[\"Shap Credit_History\"],\n        \"Immobilienbereich\": test_data[\"Property_Area\"],\n        \"Shap Immobilienbereich in %\": shap_test[\"Shap Property_Area\"],\n        \"Kreditgewaehrung\": y_pred,\n        \"Kreditgewaehrung_prozentual\": y_pred_proba\n    })\noutput['Kreditgewaehrung'].replace(1,'Ja', inplace=True)\noutput['Kreditgewaehrung'].replace(0,'Nein', inplace=True)\n\noutput.head()\noutput.to_csv('CSV_test.csv', index=False)\noutput.to_excel(\"Excel_test.xlsx\")\noutput.to_json(\"JSON_test.json\", orient='records')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Adaption of train_data</h1>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h1>Shap Values of train_data</h1>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculates Shap Values\nshap_values_train = explainer.shap_values(X)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values_train[0], X, plot_type=\"bar\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values_train[0], X, plot_type=\"dot\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.dependence_plot('Credit_History', shap_values_train[1], X)\nshap.dependence_plot('Property_Area', shap_values_train[1], X)\nshap.dependence_plot('Dependents', shap_values_train[1], X)\nshap.dependence_plot('Married_Yes', shap_values_train[1], X)\nshap.dependence_plot('Gender_Male', shap_values_train[1], X)\nshap.dependence_plot('Education_Graduate', shap_values_train[1], X)\nshap.dependence_plot('Self_Employed_No', shap_values_train[1], X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.shape(shap_values_train[1]))\nprint(np.around(shap_values_train[1] * 100, 2))\nshap_train = pd.DataFrame(np.around(shap_values_train[1] * 100, 2), columns= ['Shap Dependents','Shap Credit_History','Shap Property_Area', 'Shap Gender_Male', 'Shap Married_Yes', 'Shap Education_Graduate', 'Shap Self_Employed_No'])\nshap_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(shap_train['Shap Dependents'].mean())\nprint(shap_train['Shap Credit_History'].mean())\nprint(shap_train['Shap Property_Area'].mean())\nprint(shap_train['Shap Gender_Male'].mean())\nprint(shap_train['Shap Married_Yes'].mean())\nprint(shap_train['Shap Education_Graduate'].mean())\nshap_train['Shap Self_Employed_No'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap_train['Shap ApplicantIncome'] = 'null'\nshap_train['Shap CoapplicantIncome'] = 'null'\nshap_train['Shap LoanAmount'] = 'null'\nshap_train['Shap Loan_Amount_Term'] = 'null'\n\nshap_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_train = rf.predict(X)\ny_pred_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_train_proba = rf.predict_proba(X)\ny_pred_train_proba = y_pred_train_proba[:,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_train_proba = np.around(y_pred_train_proba * 100, 0)\ny_pred_train_proba ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"base value for shap_values_train","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred_train_proba.mean())\nX.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conditions = [\n    (y_pred_train == 1) & (train_data[\"Loan_Status\"] == 1),\n    (y_pred_train == 0) & (train_data[\"Loan_Status\"] == 0),\n    (y_pred_train == 1) & (train_data[\"Loan_Status\"] == 0),\n    (y_pred_train == 0) & (train_data[\"Loan_Status\"] == 1)\n]\nchoices = ['TP', 'TN', 'FP', 'FN']\ntrain_data['ConfusionMatrix'] = np.select(conditions, choices)\ntrain_data['ConfusionMatrix']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Gender'].replace('Male','Maennlich',inplace=True)\ntrain_data['Gender'].replace('Female','Weiblich',inplace=True)\ntrain_data['Married'].replace('Yes','Ja',inplace=True)\ntrain_data['Married'].replace('No','Nein',inplace=True)\ntrain_data['Education'].replace('Graduate','Abschluss',inplace=True)\ntrain_data['Education'].replace('Not Graduate','Kein Abschluss',inplace=True)\ntrain_data['Self_Employed'].replace('Yes','Ja',inplace=True)\ntrain_data['Self_Employed'].replace('No','Nein',inplace=True)\ntrain_data['Credit_History'].replace(1.0,'Vorliegend',inplace=True)\ntrain_data['Credit_History'].replace(0.0,'Nicht vorliegend',inplace=True)\ntrain_data['Property_Area'].replace('Rural','Laendlich',inplace=True)\n\noutput_train_data = pd.DataFrame({\n        \"Kredit_ID\": train_data[\"Loan_ID\"],\n        \"Geschlecht\": train_data[\"Gender\"],\n        \"Shap Geschlecht in %\": shap_train[\"Shap Gender_Male\"],\n        \"Verheiratet\": train_data[\"Married\"],\n        \"Shap Verheiratet in %\": shap_train[\"Shap Married_Yes\"],\n        \"Angehoerige\": train_data[\"Dependents\"],\n        \"Shap Angehoerige in %\": shap_train[\"Shap Dependents\"],\n        \"Ausbildung\": train_data[\"Education\"],\n        \"Shap Ausbildung in %\": shap_train[\"Shap Education_Graduate\"],\n        \"Selbstbeschaeftigt\": train_data[\"Self_Employed\"],\n        \"Shap Selbstbeschaeftigt in %\": shap_train[\"Shap Self_Employed_No\"],\n        \"Antragstellereinkommen\": train_data[\"ApplicantIncome\"],\n        \"Shap Antragstellereinkommen in %\": shap_train[\"Shap ApplicantIncome\"],\n        \"Mitantragstellereinkommen\": train_data[\"CoapplicantIncome\"],\n        \"Shap Mitantragstellereinkommen in %\": shap_train[\"Shap CoapplicantIncome\"],\n        \"Kredithoehe\": train_data[\"LoanAmount\"],\n        \"Shap Kredithoehe in %\": shap_train[\"Shap LoanAmount\"],\n        \"Kreditlaufzeit\": train_data[\"Loan_Amount_Term\"],\n        \"Shap Kreditlaufzeit in %\": shap_train[\"Shap Loan_Amount_Term\"],\n        \"Kreditgeschichte\": train_data[\"Credit_History\"],\n        \"Shap Kreditgeschichte in %\": shap_train[\"Shap Credit_History\"],\n        \"Immobilienbereich\": train_data[\"Property_Area\"],\n        \"Shap Immobilienbereich in %\": shap_train[\"Shap Property_Area\"],\n        \"Kreditgewaehrung\": y_pred_train,\n        \"Kreditgewaehrung_prozentual\": y_pred_train_proba,\n        \"Kreditgewaehrung_Realitaet\": train_data[\"Loan_Status\"],\n        \"ConfusionMatrix\": train_data['ConfusionMatrix']\n        })\n\noutput_train_data['Kreditgewaehrung'].replace(1,'Ja', inplace=True)\noutput_train_data['Kreditgewaehrung'].replace(0,'Nein', inplace=True)\n\noutput_train_data['Kreditgewaehrung_Realitaet'].replace(1,'Ja', inplace=True)\noutput_train_data['Kreditgewaehrung_Realitaet'].replace(0,'Nein', inplace=True)\n\n\noutput_train_data.to_csv(\"CSV_train_data.csv\", index=False)\noutput_train_data.to_excel(\"Excel_train_data.xlsx\")\noutput_train_data.to_json(\"JSON_train_data.json\", orient='records')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_train_data.head(10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}