{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/stigma0617/VoVNet.pytorch.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-04T16:01:49.113686Z","iopub.execute_input":"2021-07-04T16:01:49.113998Z","iopub.status.idle":"2021-07-04T16:01:50.523103Z","shell.execute_reply.started":"2021-07-04T16:01:49.113927Z","shell.execute_reply":"2021-07-04T16:01:50.522217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd VoVNet.pytorch","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:01:50.525603Z","iopub.execute_input":"2021-07-04T16:01:50.525952Z","iopub.status.idle":"2021-07-04T16:01:50.533732Z","shell.execute_reply.started":"2021-07-04T16:01:50.52592Z","shell.execute_reply":"2021-07-04T16:01:50.532747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install livelossplot==0.1.2","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:01:50.535769Z","iopub.execute_input":"2021-07-04T16:01:50.536253Z","iopub.status.idle":"2021-07-04T16:01:59.410523Z","shell.execute_reply.started":"2021-07-04T16:01:50.536211Z","shell.execute_reply":"2021-07-04T16:01:59.409594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch, torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torchvision.datasets as datasets\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nimport torchvision.models as models\nfrom livelossplot import PlotLosses\nimport time, os, copy, numpy as np\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.multiprocessing as mp\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport sys","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:01:59.412453Z","iopub.execute_input":"2021-07-04T16:01:59.412804Z","iopub.status.idle":"2021-07-04T16:02:05.506956Z","shell.execute_reply.started":"2021-07-04T16:01:59.412764Z","shell.execute_reply":"2021-07-04T16:02:05.505595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom collections import OrderedDict\n\n\n__all__ = ['VoVNet', 'vovnet27_slim', 'vovnet39', 'vovnet57']\n\n\nmodel_urls = {\n    'vovnet39': 'https://dl.dropbox.com/s/1lnzsgnixd8gjra/vovnet39_torchvision.pth?dl=1',\n    'vovnet57': 'https://dl.dropbox.com/s/6bfu9gstbwfw31m/vovnet57_torchvision.pth?dl=1'\n}\n\n\ndef conv3x3(in_channels, out_channels, module_name, postfix,\n            stride=1, groups=1, kernel_size=3, padding=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return [\n        ('{}_{}/conv'.format(module_name, postfix),\n            nn.Conv2d(in_channels, out_channels,\n                      kernel_size=kernel_size,\n                      stride=stride,\n                      padding=padding,\n                      groups=groups,\n                      bias=False)),\n        ('{}_{}/norm'.format(module_name, postfix),\n            nn.BatchNorm2d(out_channels)),\n        ('{}_{}/relu'.format(module_name, postfix),\n            nn.ReLU(inplace=True)),\n    ]\n\n\ndef conv1x1(in_channels, out_channels, module_name, postfix,\n            stride=1, groups=1, kernel_size=1, padding=0):\n    \"\"\"1x1 convolution\"\"\"\n    return [\n        ('{}_{}/conv'.format(module_name, postfix),\n            nn.Conv2d(in_channels, out_channels,\n                      kernel_size=kernel_size,\n                      stride=stride,\n                      padding=padding,\n                      groups=groups,\n                      bias=False)),\n        ('{}_{}/norm'.format(module_name, postfix),\n            nn.BatchNorm2d(out_channels)),\n        ('{}_{}/relu'.format(module_name, postfix),\n            nn.ReLU(inplace=True)),\n    ]\n\n\nclass _OSA_module(nn.Module):\n    def __init__(self,\n                 in_ch,\n                 stage_ch,\n                 concat_ch,\n                 layer_per_block,\n                 module_name,\n                 identity=False):\n        super(_OSA_module, self).__init__()\n\n        self.identity = identity\n        self.layers = nn.ModuleList()\n        in_channel = in_ch\n        for i in range(layer_per_block):\n            self.layers.append(nn.Sequential(\n                OrderedDict(conv3x3(in_channel, stage_ch, module_name, i))))\n            in_channel = stage_ch\n\n        # feature aggregation\n        in_channel = in_ch + layer_per_block * stage_ch\n        self.concat = nn.Sequential(\n            OrderedDict(conv1x1(in_channel, concat_ch, module_name, 'concat')))\n\n    def forward(self, x):\n        identity_feat = x\n        output = []\n        output.append(x)\n        for layer in self.layers:\n            x = layer(x)\n            output.append(x)\n        x = torch.cat(output, dim=1)  #Spell by column\n        xt = self.concat(x)\n\n        if self.identity:\n            xt = xt + identity_feat\n\n        return xt\n\n\nclass _OSA_stage(nn.Sequential):\n    def __init__(self,\n                 in_ch,\n                 stage_ch,\n                 concat_ch,\n                 block_per_stage,\n                 layer_per_block,\n                 stage_num):\n        super(_OSA_stage, self).__init__()\n\n        if not stage_num == 2:\n            self.add_module('Pooling',\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True))  #Round up, the default padding is 0\n\n        module_name = f'OSA{stage_num}_1'\n        self.add_module(module_name,\n            _OSA_module(in_ch,\n                        stage_ch,\n                        concat_ch,\n                        layer_per_block,\n                        module_name))\n        for i in range(block_per_stage-1):\n            module_name = f'OSA{stage_num}_{i+2}'\n            self.add_module(module_name,\n                _OSA_module(concat_ch,\n                            stage_ch,\n                            concat_ch,\n                            layer_per_block,\n                            module_name,\n                            identity=True))\n\n\nclass VoVNet(nn.Module):\n    def __init__(self,\n                 config_stage_ch,\n                 config_concat_ch,\n                 block_per_stage,\n                 layer_per_block,\n                 num_classes=275):\n        super(VoVNet, self).__init__()\n\n        # Stem module\n        stem = conv3x3(3,   64, 'stem', '1', 2)\n        stem += conv3x3(64,  64, 'stem', '2', 1)\n        stem += conv3x3(64, 128, 'stem', '3', 2)\n        self.add_module('stem', nn.Sequential(OrderedDict(stem)))\n\n        stem_out_ch = [128]\n        in_ch_list = stem_out_ch + config_concat_ch[:-1]\n        self.stage_names = []\n        for i in range(4): #num_stages\n            name = 'stage%d' % (i+2)\n            self.stage_names.append(name)\n            self.add_module(name,\n                            _OSA_stage(in_ch_list[i],\n                                       config_stage_ch[i],\n                                       config_concat_ch[i],\n                                       block_per_stage[i],\n                                       layer_per_block,\n                                       i+2))\n\n        self.classifier = nn.Linear(config_concat_ch[-1], num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight)\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        x = self.stem(x)\n        for name in self.stage_names:\n            x = getattr(self, name)(x)\n        x = F.adaptive_avg_pool2d(x, (1, 1)).view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n\ndef _vovnet(arch,\n            config_stage_ch,\n            config_concat_ch,\n            block_per_stage,\n            layer_per_block,\n            pretrained,\n            progress,\n            **kwargs):\n    model = VoVNet(config_stage_ch, config_concat_ch,\n                   block_per_stage, layer_per_block,\n                   **kwargs)\n    if pretrained:\n        state_dict = torch.hub.load_state_dict_from_url(model_urls[arch],\n                                              progress=progress)\n        model.load_state_dict(state_dict)\n    return model\n\n\ndef vovnet57(pretrained=False, progress=True, **kwargs):\n    r\"\"\"Constructs a VoVNet-57 model as described in\n    `\"An Energy and GPU-Computation Efficient Backbone Networks\"\n    <https://arxiv.org/abs/1904.09730>`_.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    return _vovnet('vovnet57', [128, 160, 192, 224], [256, 512, 768, 1024],\n                    [1,1,4,3], 5, pretrained, progress, **kwargs)\n\n\ndef vovnet39(pretrained=False, progress=True, **kwargs):\n    r\"\"\"Constructs a VoVNet-39 model as described in\n    `\"An Energy and GPU-Computation Efficient Backbone Networks\"\n    <https://arxiv.org/abs/1904.09730>`_.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    return _vovnet('vovnet39', [128, 160, 192, 224], [256, 512, 768, 1024],\n                    [1,1,2,2], 5, pretrained, progress, **kwargs)\n\n\ndef vovnet27_slim(pretrained=False, progress=True, **kwargs):\n    r\"\"\"Constructs a VoVNet-39 model as described in\n    `\"An Energy and GPU-Computation Efficient Backbone Networks\"\n    <https://arxiv.org/abs/1904.09730>`_.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    return _vovnet('vovnet27_slim', [64, 80, 96, 112], [128, 256, 384, 512],\n                    [1,1,1,1], 5, pretrained, progress, **kwargs)\n\n\nif __name__ == '__main__':\n    model = vovnet57()\n    print(model)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:02:05.509493Z","iopub.execute_input":"2021-07-04T16:02:05.51023Z","iopub.status.idle":"2021-07-04T16:02:06.450964Z","shell.execute_reply.started":"2021-07-04T16:02:05.51019Z","shell.execute_reply":"2021-07-04T16:02:06.449082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n    ]),\n    'test': transforms.Compose([\n        transforms.ToTensor(),\n    ]),\n}\n\ndata_dir = '/kaggle/input/100-bird-species/birds/'\n\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train','test']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n                                             shuffle=True, num_workers=64)\n              for x in ['train','test']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train','test']}","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:02:06.45233Z","iopub.execute_input":"2021-07-04T16:02:06.452692Z","iopub.status.idle":"2021-07-04T16:02:18.610016Z","shell.execute_reply.started":"2021-07-04T16:02:06.452643Z","shell.execute_reply":"2021-07-04T16:02:18.609154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, num_epochs=25):\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    since = time.time()\n    liveloss = PlotLosses()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'test']:\n            if phase == 'train':\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for i,(inputs, labels) in enumerate(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                print(\"\\rIteration: {}/{}, Loss: {}.\".format(i+1, len(dataloaders[phase]), loss.item() * inputs.size(0)), end=\"\")\n\n#                 print( (i+1)*100. / len(dataloaders[phase]), \"% Complete\" )\n                sys.stdout.flush()\n                \n                \n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n            if phase == 'train':\n                avg_loss = epoch_loss\n                t_acc = epoch_acc\n            else:\n                val_loss = epoch_loss\n                val_acc = epoch_acc\n            \n#             print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n#                 phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'test' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n                \n        liveloss.update({\n            'log loss': avg_loss,\n            'val_log loss': val_loss,\n            'accuracy': t_acc,\n            'val_accuracy': val_acc\n        })\n                \n        liveloss.draw()\n        print('Train Loss: {:.4f} Acc: {:.4f}'.format(avg_loss, t_acc))\n        print(  'Val Loss: {:.4f} Acc: {:.4f}'.format(val_loss, val_acc))\n        print('Best Val Accuracy: {}'.format(best_acc))\n        print()\n    \n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:02:18.611349Z","iopub.execute_input":"2021-07-04T16:02:18.611688Z","iopub.status.idle":"2021-07-04T16:02:18.629221Z","shell.execute_reply.started":"2021-07-04T16:02:18.611651Z","shell.execute_reply":"2021-07-04T16:02:18.62841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel_ft = model.to(device)\n#Multi GPU\nmodel_ft = torch.nn.DataParallel(model_ft, device_ids=[0])\n\n#Loss Function\ncriterion = nn.CrossEntropyLoss()\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:02:18.631732Z","iopub.execute_input":"2021-07-04T16:02:18.632006Z","iopub.status.idle":"2021-07-04T16:02:23.924367Z","shell.execute_reply.started":"2021-07-04T16:02:18.631972Z","shell.execute_reply":"2021-07-04T16:02:23.923496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft = train_model(model_ft, dataloaders, dataset_sizes, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=10)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:02:23.925774Z","iopub.execute_input":"2021-07-04T16:02:23.926109Z","iopub.status.idle":"2021-07-04T17:31:57.355099Z","shell.execute_reply.started":"2021-07-04T16:02:23.926074Z","shell.execute_reply":"2021-07-04T17:31:57.354069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model_ft.state_dict(), \"birds_275.pt\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:31:57.357065Z","iopub.execute_input":"2021-07-04T17:31:57.357421Z","iopub.status.idle":"2021-07-04T17:31:57.628589Z","shell.execute_reply.started":"2021-07-04T17:31:57.357377Z","shell.execute_reply":"2021-07-04T17:31:57.627746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}