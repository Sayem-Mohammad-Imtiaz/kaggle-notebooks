{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read the train and test data set first"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train= pd.read_csv('../input/loan-prediction-problem-dataset/train_u6lujuX_CVtuZ9i.csv')\ntest= pd.read_csv('../input/loan-prediction-problem-dataset/test_Y3wMUE5_7gLdaTN.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Will look for the data description "},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print the unique values in the object variables\nprint('Married: ' + str(train['Married'].unique()))\nprint('Dependents: '+ str(train['Dependents'].unique()))\nprint('Education: '+ str(train['Education'].unique()))\nprint('Self_Employed: '+ str(train['Self_Employed'].unique()))\nprint('Property_Area: '+ str(train['Property_Area'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Loan status',train['Loan_Status'].value_counts())\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data set is not balanced in outputs"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking the missing values in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# will look for the missing vlaues in the data\ntrain.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the relatioship between the variables and target \nimport seaborn as sns\n\nsns.countplot(train['Loan_Status'],hue=train['Credit_History'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.crosstab(train['Credit_History'],train['Loan_Status']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Credit_History'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#will impute the missing values by 1 since 1 have the most frequesnt values in the dataset\ntrain['Credit_History']= train['Credit_History'].fillna(1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['Loan_Status'],hue=train['Credit_History'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#next we have self employed column to look \nsns.countplot(train['Loan_Status'],hue=train['Self_Employed'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Self_Employed.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#fill the missing values by No in data set\ntrain['Self_Employed']= train['Self_Employed'].fillna('No')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['Loan_Status'],hue=train['Self_Employed'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we have Loan amount variable to look and since its a numerical variable we will look for scatter plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(train['Loan_Status'],train['LoanAmount'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#will fill the missing values with the mean value\ntrain['LoanAmount']=train['LoanAmount'].fillna(train.LoanAmount.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Dependents'].isnull().sum()/len(train['Dependents'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop the other missing values from the data\ntrain.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Handling the outliers from the dataset "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.boxplot(train['ApplicantIncome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.boxplot(train['CoapplicantIncome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a new variable called total income by adding applicant income + coapplicant income\n\ntrain['TotalIncome']= train['ApplicantIncome']+train['CoapplicantIncome']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='Education',y='ApplicantIncome',data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that graduate people also having same outliers since they are graduate their income must be higher we will chekck the same with coapplicant income"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train.TotalIncome,kde=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain = train.drop(columns=['Loan_ID'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Next, make all other columns numerical as well. \ntrain['Married'] = np.where((train['Married'] == 'Yes'), 1, 0)\ntrain['Gender'] = np.where((train['Gender'] == 'Female'), 1, 0)\ntrain['Education'] = np.where((train['Education'] == 'Graduate'), 1, 0)\ntrain['Self_Employed'] = np.where((train['Self_Employed'] == 'Yes'), 1, 0)\ntrain['Dependents'] = np.where((train['Dependents'] == '0'), 0, 1)\ntrain['Loan_Status'] = np.where((train['Loan_Status'] == 'Y'), 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Property_Area'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Doing label encoding the categorical features\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\ntrain['Property_Area']=le.fit_transform(train['Property_Area'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y= train['Loan_Status']\nX= train.drop(columns=['Loan_Status'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Selecting Important features "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\n#apply SelectKBest class to extract top 10 best features\nbestfeatures = SelectKBest(score_func=chi2, k='all')\nfit = bestfeatures.fit(X,y)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\n#concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Name of the column','Score']  #naming the dataframe columns\nprint(featureScores.nlargest(10,'Score'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = train.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(10,10))\n\n#plot heat map\ng=sns.heatmap(train[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Married,credit history,coapplicantincome,loan amount,total income having high importance in variables list"},{"metadata":{"trusted":true},"cell_type":"code","source":"X= X[['Married','Credit_History','TotalIncome','CoapplicantIncome','LoanAmount','ApplicantIncome']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape,y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"dataset is not balanced so we use smote algorithm to balance the output"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE \nsm = SMOTE(random_state = 2) \nX, y = sm.fit_sample(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#spliiitng the test train\nx_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape,x_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fitting Logistic regression\nfrom sklearn.linear_model import LogisticRegression\nlog=LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#saving my model to pickle file\npickle.dump(log,open('model_pkl','wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = pickle.load(open('model_pkl','rb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q= model.predict([[1,1.0,459.000000,0.000000,25.000000,3459]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log.score(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting test dataset\npred=log.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nmetrics.confusion_matrix(y_test,pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Will try with Decision tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"#decision tree\nfrom sklearn.tree import DecisionTreeClassifier\nclf=DecisionTreeClassifier()\nclf.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred1=clf.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.confusion_matrix(y_test,pred1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test,pred1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic regression performed well out of two models"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}