{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\nimport warnings\n\n\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn = pd.read_csv('/kaggle/input/churn-modelling/Churn_Modelling.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#churn[cat_col].head()\ndf = churn\n# Since surname, consumerid and rownumber does not have any impact w.r.t Exited, dropping.\ndf = churn.drop(['RowNumber','CustomerId','Surname'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking missing values \n#churn.info()\ndef num_cat_features(df):\n    num_cols = []\n    cat_cols = []\n    s= df.dtypes\n    for i in s.index:\n        if (s[i] == 'int64' or s[i] == 'float64'):\n            num_cols.append(i)\n        elif s[i]== 'object':\n            cat_cols.append(i)\n        else:\n            pass\n    return num_cols, cat_cols\n\nnum_col, cat_col = num_cat_features(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[num_col].head()\ndf[cat_col].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dummies in Geography and Gender\ndf_cat = df[cat_col]\ngeo = pd.get_dummies(df_cat['Geography'], prefix = 'Geo')\ngender = pd.get_dummies(df_cat['Gender'])\ndf.drop(cat_col,axis =1, inplace = True)\ndf = pd.concat([geo,gender,df], axis =1 )\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scaling numeric columns\ncols_scale = ['CreditScore','Tenure','Balance','NumOfProducts', 'EstimatedSalary']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,15))\nsns.heatmap(df.corr(), annot = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style = \"darkgrid\")\nfig = plt.figure(figsize = (20,20))\nax1 = fig.add_subplot(3,3,1)\nax1. set_title(\"M vs F\")\n\nax2 = fig.add_subplot(3,3,2)\nax2. set_title(\"M vs F - Exited\")\n\nsns.barplot(x = churn['Gender'].value_counts().sort_index().index,y = churn['Gender'].value_counts().sort_index().values, ax= ax1 )\nsns.countplot(x = 'Exited', hue = 'Gender', data = churn, ax = ax2)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"More females exit than males. "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (20,18))\nax3 = fig.add_subplot(3,3,1)\nax3.set_title(\"Geos\")\n\nax4 = fig.add_subplot(3,3,2)\nax4.set_title(\"Geos - Exited\")\n\nsns.barplot(x = churn['Geography'].value_counts().sort_index().index,y = churn['Geography'].value_counts().sort_index().values, ax = ax3)\nsns.countplot(x = 'Exited', hue = 'Geography', data = churn, ax = ax4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (20,18))\nax5 = fig.add_subplot(3,3,1)\nax5.set_title(\"Product\")\n\nax6 = fig.add_subplot(3,3,2)\nax6.set_title(\"Product - Exited\")\n\nsns.barplot(x = churn['NumOfProducts'].value_counts().sort_index().index,y = churn['NumOfProducts'].value_counts().sort_index().values, ax = ax5)\nsns.countplot(x = 'Exited', hue = 'NumOfProducts', data = churn, ax = ax6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"churn.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,7))\nsns.distplot(churn['Age'], kde = False ,bins = 10)\nplt.ylabel(\"Counts\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop('Exited', axis =1)\ny = df['Exited']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nX = StandardScaler().fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Logistic Regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)\n# Accuracy on Training set\nfrom sklearn.model_selection import cross_val_predict\ny_prob_train_lr = cross_val_predict(log_reg, X_train, y_train, cv = 10, method = 'decision_function')\n\n# y_pred_train_lr = log_reg.predict(X_train)\n# y_prob_train_lr = log_reg.predict_proba(X_train)\n\nfrom sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score ,confusion_matrix\nfpr, tpr, thrshld = roc_curve(y_train, y_prob_train_lr)\nprecision, recall, thrshld = precision_recall_curve(y_train, y_prob_train_lr)\n\nfig = plt.figure(figsize = (70,50))\n# Precision / Recall vs Threshold\nplt.subplot(10,10,1)\nplt.plot(thrshld, precision[:-1], \"b-\", label=\"Precision\")\nplt.plot(thrshld, recall[:-1], \"r-\", label=\"Recall\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Precision / Recall\")\nplt.title(\"Precision / Recall vs Threshold - Logistic Regression - Training\")\nplt.legend()\n\n\n# Precision Vs Recall\nplt.subplot(10,10,2)\nplt.plot(recall, precision, 'b-')\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision vs Recall - Logistic Regression - Training\")\n\n\n# ROC Curve\nplt.subplot(10,10,3)\nplt.plot([[0,0], [1,1]], 'k--')\nplt.plot(fpr, tpr, 'g-')\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC Curve - Logistic Regression - Training\")\n\n\nlr_auc_score_train = roc_auc_score(y_train,y_prob_train_lr ) # 0.76\n# lr_auc_score_train\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Decision Tree Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree Classifier\ndtree_clf = DecisionTreeClassifier()\ndtree_clf.fit(X_train, y_train)\n# Accuracy on Training set\nfrom sklearn.model_selection import cross_val_predict\ny_prob_train_dtree = cross_val_predict(dtree_clf, X_train, y_train, cv = 10, method = 'predict_proba')\n\nfpr, tpr, thrshld = roc_curve(y_train, y_prob_train_dtree[:,-1])\nprecision, recall, thrshld = precision_recall_curve(y_train, y_prob_train_dtree[:,-1])\n\nfig = plt.figure(figsize = (70,50))\n# Precision / Recall vs Threshold\nplt.subplot(10,10,1)\nplt.plot(thrshld, precision[:-1], \"b-\", label=\"Precision\")\nplt.plot(thrshld, recall[:-1], \"r-\", label=\"Recall\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Precision / Recall\")\nplt.title(\"Precision / Recall vs Threshold - Decision Tree Classifier - Training\")\nplt.legend()\n\n\n# Precision Vs Recall\nplt.subplot(10,10,2)\nplt.plot(recall, precision, 'b-')\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision vs Recall -  Decision Tree Classifier - Training\")\n\n\n# ROC Curve\nplt.subplot(10,10,3)\nplt.plot([[0,0], [1,1]], 'k--')\nplt.plot(fpr, tpr, 'g-')\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC Curve - Decision Tree Classifier- Training\")\n\n\ndtree_auc_score_train = roc_auc_score(y_train,y_prob_train_dtree[:,-1] ) # 0.67\n# dtree_auc_score_train ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Linear SVC  Classifier\nsvc_clf = LinearSVC(C = 1.0,random_state = 12, max_iter = 1500, loss = 'squared_hinge')\nsvc_clf.fit(X_train, y_train)\n# Accuracy on Training set\ny_prob_train_svc = cross_val_predict(svc_clf, X_train, y_train, cv = 10, method = 'decision_function')\n\nfpr, tpr, thrshld = roc_curve(y_train, y_prob_train_svc)\nprecision, recall, thrshld = precision_recall_curve(y_train, y_prob_train_svc)\n\nfig = plt.figure(figsize = (70,50))\n# Precision / Recall vs Threshold\nplt.subplot(10,10,1)\nplt.plot(thrshld, precision[:-1], \"b-\", label=\"Precision\")\nplt.plot(thrshld, recall[:-1], \"r-\", label=\"Recall\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Precision / Recall\")\nplt.title(\"Precision / Recall vs Threshold - Linear SVC Classifier - Training\")\nplt.legend()\n\n\n# Precision Vs Recall\nplt.subplot(10,10,2)\nplt.plot(recall, precision, 'b-')\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision vs Recall -  Linear SVC Classifier - Training\")\n\n\n# ROC Curve\nplt.subplot(10,10,3)\nplt.plot([[0,0], [1,1]], 'k--')\nplt.plot(fpr, tpr, 'g-')\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC Curve - Linear SVC Classifier- Training\")\n\n\nsvc_auc_score_train = roc_auc_score(y_train,y_prob_train_svc) # 0.77\n# svc_auc_score_train ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SVM  Classifier\nfrom sklearn.svm import SVC\nsvm_clf = SVC(random_state = 12)\nsvm_clf.fit(X_train, y_train)\n# Accuracy on Training set\ny_prob_train_svm = cross_val_predict(svm_clf, X_train, y_train, cv = 10, method = 'decision_function')\n\nfpr, tpr, thrshld = roc_curve(y_train, y_prob_train_svm)\nprecision, recall, thrshld = precision_recall_curve(y_train, y_prob_train_svm)\n\nfig = plt.figure(figsize = (70,50))\n# Precision / Recall vs Threshold\nplt.subplot(10,10,1)\nplt.plot(thrshld, precision[:-1], \"b-\", label=\"Precision\")\nplt.plot(thrshld, recall[:-1], \"r-\", label=\"Recall\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Precision / Recall\")\nplt.title(\"Precision / Recall vs Threshold - SVM Classifier - Training\")\nplt.legend()\n\n\n# Precision Vs Recall\nplt.subplot(10,10,2)\nplt.plot(recall, precision, 'b-')\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision vs Recall -  SVM Classifier - Training\")\n\n\n# ROC Curve\nplt.subplot(10,10,3)\nplt.plot([[0,0], [1,1]], 'k--')\nplt.plot(fpr, tpr, 'g-')\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC Curve - SVM Classifier- Training\")\n\n\nsvm_auc_score_train = roc_auc_score(y_train,y_prob_train_svm) # 0.82\n# svm_auc_score_train ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest  Classifier\nfrom sklearn.ensemble import RandomForestClassifier\nrdm_frst_clf = RandomForestClassifier(random_state = 12, max_depth = 7, n_estimators=20)\nrdm_frst_clf.fit(X_train, y_train)\n# Accuracy on Training set\ny_prob_train_forst = cross_val_predict(rdm_frst_clf, X_train, y_train, cv = 10, method = 'predict_proba')\n\nfpr, tpr, thrshld = roc_curve(y_train, y_prob_train_forst[:,-1])\nprecision, recall, thrshld = precision_recall_curve(y_train, y_prob_train_forst[:,-1])\n\nfig = plt.figure(figsize = (70,50))\n# Precision / Recall vs Threshold\nplt.subplot(10,10,1)\nplt.plot(thrshld, precision[:-1], \"b-\", label=\"Precision\")\nplt.plot(thrshld, recall[:-1], \"r-\", label=\"Recall\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Precision / Recall\")\nplt.title(\"Precision / Recall vs Threshold - Random Forest Classifier - Training\")\nplt.legend()\n\n\n# Precision Vs Recall\nplt.subplot(10,10,2)\nplt.plot(recall, precision, 'b-')\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision vs Recall -  Random Forest Classifier - Training\")\n\n\n# ROC Curve\nplt.subplot(10,10,3)\nplt.plot([[0,0], [1,1]], 'k--')\nplt.plot(fpr, tpr, 'g-')\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC Curve - Random Forest Classifier - Training\")\n\n\nfrst_auc_score_train = roc_auc_score(y_train,y_prob_train_forst[:,-1]) # 0.85\n# frst_auc_score_train ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stochastic Gradient Descent  Classifier\nfrom sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier(alpha = 1,random_state = 12, penalty = 'l2', loss = 'modified_huber')\nsgd_clf.fit(X_train, y_train)\n# Accuracy on Training set\ny_prob_train_sgd = cross_val_predict(sgd_clf, X_train, y_train, cv = 10, method = 'decision_function')\n\nfpr, tpr, thrshld = roc_curve(y_train, y_prob_train_sgd)\nprecision, recall, thrshld = precision_recall_curve(y_train, y_prob_train_sgd)\n\nfig = plt.figure(figsize = (70,50))\n# Precision / Recall vs Threshold\nplt.subplot(10,10,1)\nplt.plot(thrshld, precision[:-1], \"b-\", label=\"Precision\")\nplt.plot(thrshld, recall[:-1], \"r-\", label=\"Recall\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Precision / Recall\")\nplt.title(\"Precision / Recall vs Threshold - SGD Classifier - Training\")\nplt.legend()\n\n\n# Precision Vs Recall\nplt.subplot(10,10,2)\nplt.plot(recall, precision, 'b-')\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision vs Recall -  SGD Classifier - Training\")\n\n\n# ROC Curve\nplt.subplot(10,10,3)\nplt.plot([[0,0], [1,1]], 'k--')\nplt.plot(fpr, tpr, 'g-')\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC Curve - SGD Classifier - Training\")\n\n\nsgd_auc_score_train = roc_auc_score(y_train,y_prob_train_sgd) # 0.77\n# sgd_auc_score_train ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# KNN  Classifier\nfrom sklearn.neighbors import KNeighborsClassifier\nknn_clf = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n                     weights='distance')\nknn_clf.fit(X_train, y_train)\n# Accuracy on Training set\ny_prob_train_knn = cross_val_predict(knn_clf, X_train, y_train, cv = 10, method = 'predict_proba')\n\nfpr, tpr, thrshld = roc_curve(y_train, y_prob_train_knn[:,-1])\nprecision, recall, thrshld = precision_recall_curve(y_train, y_prob_train_knn[:,-1])\n\nfig = plt.figure(figsize = (70,50))\n# Precision / Recall vs Threshold\nplt.subplot(10,10,1)\nplt.plot(thrshld, precision[:-1], \"b-\", label=\"Precision\")\nplt.plot(thrshld, recall[:-1], \"r-\", label=\"Recall\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Precision / Recall\")\nplt.title(\"Precision / Recall vs Threshold - KNN Classifier - Training\")\nplt.legend()\n\n\n# Precision Vs Recall\nplt.subplot(10,10,2)\nplt.plot(recall, precision, 'b-')\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision vs Recall -  KNN Classifier - Training\")\n\n\n# ROC Curve\nplt.subplot(10,10,3)\nplt.plot([[0,0], [1,1]], 'k--')\nplt.plot(fpr, tpr, 'g-')\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC Curve - KNN Classifier - Training\")\n\n\nknn_auc_score_train = roc_auc_score(y_train,y_prob_train_knn[:,-1]) # 0.78\n# sgd_auc_score_train ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGboost  Classifier\nimport xgboost as xgb\nxgb_clf = xgb.XGBClassifier(random_state = 12)\nxgb_clf.fit(X_train, y_train)\n# Accuracy on Training set\ny_prob_train_xgb = cross_val_predict(xgb_clf, X_train, y_train, cv = 10, method = 'predict_proba')\n\nfpr, tpr, thrshld = roc_curve(y_train, y_prob_train_xgb[:,-1])\nprecision, recall, thrshld = precision_recall_curve(y_train, y_prob_train_xgb[:,-1])\n\nfig = plt.figure(figsize = (70,50))\n# Precision / Recall vs Threshold\nplt.subplot(10,10,1)\nplt.plot(thrshld, precision[:-1], \"b-\", label=\"Precision\")\nplt.plot(thrshld, recall[:-1], \"r-\", label=\"Recall\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Precision / Recall\")\nplt.title(\"Precision / Recall vs Threshold - XGB Classifier - Training\")\nplt.legend()\n\n\n# Precision Vs Recall\nplt.subplot(10,10,2)\nplt.plot(recall, precision, 'b-')\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Precision vs Recall -  XGB Classifier - Training\")\n\n\n# ROC Curve\nplt.subplot(10,10,3)\nplt.plot([[0,0], [1,1]], 'k--')\nplt.plot(fpr, tpr, 'g-')\nplt.xlabel(\"FPR\")\nplt.ylabel(\"TPR\")\nplt.title(\"ROC Curve - XGB Classifier - Training\")\n\n\nxgb_auc_score_train = roc_auc_score(y_train,y_prob_train_xgb[:,-1]) # 0.86\n# xgb_auc_score_train ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Performance on Test data\ny_pred_log = log_reg.predict(X_test)\ncm_log = confusion_matrix(y_test, y_pred_log)\n\ny_pred_dtree = dtree_clf.predict(X_test)\ncm_dtree = confusion_matrix(y_test, y_pred_dtree)\n\ny_pred_lsvc = svc_clf.predict(X_test)\ncm_lsvc = confusion_matrix(y_test, y_pred_lsvc)\n\ny_pred_svm = svm_clf.predict(X_test)\ncm_svm = confusion_matrix(y_test, y_pred_svm)\n\ny_pred_frst = rdm_frst_clf.predict(X_test)\ncm_frst = confusion_matrix(y_test, y_pred_frst)\n\ny_pred_sgd = sgd_clf.predict(X_test)\ncm_sgd = confusion_matrix(y_test, y_pred_sgd)\n\ny_pred_knn = knn_clf.predict(X_test)\ncm_knn = confusion_matrix(y_test, y_pred_knn)\n\ny_pred_xgb = xgb_clf.predict(X_test)\ncm_xgb = confusion_matrix(y_test, y_pred_xgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (15,15))\n\nax1 = fig.add_subplot(3,3,1)\nax1.set_title(\"Logistic Regression\")\n\nax2 = fig.add_subplot(3,3,2)\nax2.set_title(\"Decision Tree Classifier\")\n\nax3 = fig.add_subplot(3,3,3)\nax3.set_title(\"Linear SVC Classifier\")\n\nax4 = fig.add_subplot(3,3,4)\nax4.set_title(\"SVM Classifier\")\n\nax5 = fig.add_subplot(3,3,5)\nax5.set_title(\"Random Forest Classifier\")\n\nax6 = fig.add_subplot(3,3,6)\nax6.set_title(\"SGD Classifier\")\n\nax7 = fig.add_subplot(3,3,7)\nax7.set_title(\"KNN Classifier\")\n\nax8 = fig.add_subplot(3,3,8)\nax8.set_title(\"XGB Classifier\")\n\nsns.heatmap(cm_log, annot = True, cmap = 'RdBu', fmt = 'd', ax = ax1)\nsns.heatmap(cm_dtree, annot = True, cmap = 'RdBu', fmt = 'd', ax = ax2)\nsns.heatmap(cm_lsvc, annot = True, cmap = 'RdBu', fmt = 'd', ax = ax3)\nsns.heatmap(cm_svm, annot = True, cmap = 'RdBu', fmt = 'd', ax = ax4)\nsns.heatmap(cm_frst, annot = True, cmap = 'RdBu', fmt = 'd', ax = ax5)\nsns.heatmap(cm_sgd, annot = True, cmap = 'RdBu', fmt = 'd', ax = ax6)\nsns.heatmap(cm_knn, annot = True, cmap = 'RdBu', fmt = 'd', ax = ax7)\nsns.heatmap(cm_xgb, annot = True, cmap = 'RdBu', fmt = 'd', ax = ax8)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing Scores\nlog_acc =   (cm_log[0,0] + cm_log[1,1]) / cm_log.sum()\ndtree_acc = (cm_dtree[0,0] + cm_dtree[1,1]) / cm_dtree.sum()\nlsvc_acc = (cm_lsvc[0,0] + cm_lsvc[1,1]) / cm_lsvc.sum()\nsvm_acc = (cm_svm[0,0] + cm_svm[1,1]) / cm_svm.sum()\nfrst_acc = (cm_frst[0,0] + cm_frst[1,1]) / cm_frst.sum()\nsgd_acc = (cm_sgd[0,0] + cm_sgd[1,1]) / cm_sgd.sum()\nknn_acc = (cm_knn[0,0] + cm_knn[1,1]) / cm_knn.sum()\nxgb_acc = (cm_xgb[0,0] + cm_xgb[1,1]) / cm_xgb.sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_list = [log_acc,dtree_acc,lsvc_acc,svm_acc,frst_acc,sgd_acc,knn_acc,xgb_acc]\nmodels = ['Logistic Regression', 'Decision Tree Classifier', 'Linear SVC', 'SVM', 'Random Forest Classifier', 'SGDClassifier', 'KNN Classifier','XGboost Classifier']\n\nmodel_accuracy = {}\nmodel_accuracy['Model'] = models\nmodel_accuracy['Scores'] = acc_list\n\naccuracy_df = pd.DataFrame.from_dict(model_accuracy)\naccuracy_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,7))\nax = sns.barplot(x = 'Model', y = 'Scores', data = accuracy_df)\nplt.xticks(rotation='vertical')\nplt.ylim([0,1])\nplt.title(\"Accuracy Scores\")\n\nfor p in ax.patches:\n    ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n             ha='center', va='center', rotation=0, xytext=(0, 20), textcoords='offset points')  #horizontal bars\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}