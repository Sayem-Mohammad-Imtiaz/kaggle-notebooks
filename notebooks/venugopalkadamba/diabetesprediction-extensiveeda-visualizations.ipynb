{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Diabetes Prediction: Extensive EDA, Feature Engineering, Visualizations and Modeling\n\n<div align=\"center\">\n    <img src=\"https://cdn-a.william-reed.com/var/wrbm_gb_food_pharma/storage/images/publications/food-beverage-nutrition/nutraingredients-asia.com/news/regulation-policy/fiji-s-diabetes-epidemic-nation-already-exceeding-who-s-predicted-rate-for-2030/8258832-1-eng-GB/Fiji-s-diabetes-epidemic-Nation-already-exceeding-WHO-s-predicted-rate-for-2030_wrbm_large.jpg\" alt=\"diabetes image\" width=\"500\" height=\"300\" style=\"border-radius:10px;\"/>\n\n</div>\n\n<b>Data Dictionary</b>\n<ul>\n    <li>Pregnancies: Number of times pregnant</li>\n    <li>Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test</li>\n    <li>BloodPressure: Diastolic blood pressure (mm Hg)</li>\n    <li>SkinThickness: Triceps skin fold thickness (mm)</li>\n    <li>Insulin: 2-Hour serum insulin (mu U/ml)</li>\n    <li>BMI: Body mass index (weight in kg/(height in m)^2)</li>\n    <li>DiabetesPedigreeFunction: Diabetes pedigree function</li>\n    <li>Age: Age (years)</li>\n    <li>Outcome: Class variable (0 or 1)</li>\n</ul>","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport imblearn\nfrom imblearn.over_sampling import SMOTE\nfrom collections import Counter\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nimport xgboost\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = \"../input/pima-indians-diabetes-database/diabetes.csv\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(DATA_PATH)\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploring the data","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;background-color:lightgreen;border-radius:10px;padding:20px;\">\n<b>OBSERVATION</b><br/>From the above table we can observe that the minimum values for the features Glucose, BloodPressure, SkinThickness, Insulin, BMI is 0 which is impossible and doesn't make any sense. Thus let us replace the 0 in those feature with NaN, later with which we can deal in Univariate Analysis.\n</div>","metadata":{}},{"cell_type":"code","source":"columns_with_wrong_data = [\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\"]\n\ndef replace_func(x):\n    if x == 0:\n        return np.nan\n    return x\n\nfor column in columns_with_wrong_data:\n    data[column] = data[column].map(replace_func).values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.isnull().sum())\ndata.isnull().sum().plot(kind = \"bar\")\nplt.title(\"NaN values Plot\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Univariate Analysis","metadata":{}},{"cell_type":"markdown","source":"<b>Analyzing Outcome</b>","metadata":{}},{"cell_type":"code","source":"counts = data[\"Outcome\"].value_counts()\ndiag_cols = [\"Non Diabetic\", \"Diabetic\"]\ndiag_counts = [counts[0], counts[1]]\n\nnd = (diag_counts[0] / sum(diag_counts))*100\nd = (diag_counts[1] / sum(diag_counts)) * 100\n\nprint(f\"Diabetic: {d}%\")\nprint(f\"Non Diabetic: {nd}%\")\n\nprint()\n\nplt.figure(figsize = (10, 8))\nsns.barplot(x = diag_cols, y = diag_counts)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;background-color:lightgreen;border-radius:10px;padding:20px;\">\n<b>OBSERVATION</b><br/>From the above plot we can observe that the data is imbalanced. So we need to perform Upsampling.\n</div>","metadata":{}},{"cell_type":"markdown","source":"<b>Analyzing Pregnancies Column</b>","metadata":{}},{"cell_type":"code","source":"print(f\"Number of unique values in Pregnancies: {len(data.Pregnancies.unique())}\")\nprint(f\"Unique values in Pregnancies: {data.Pregnancies.unique()}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(data[\"Pregnancies\"], data[\"Outcome\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby(by=\"Pregnancies\")[\"Outcome\"].sum().sort_values(ascending=False).plot(kind = \"bar\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;background-color:lightgreen;border-radius:10px;padding:20px;\">\n<b>OBSERVATION</b><br/>From the above plot we can observe that the patients with less number of pregnancies ar more prone to diabetes.\n</div>","metadata":{}},{"cell_type":"markdown","source":"<b>Analyzing Glucose Column</b>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"Glucose\"])\nplt.show(\"Glucose distribution plot\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"Glucose\"].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;background-color:lightgreen;border-radius:10px;padding:20px;\">\n<b>OBSERVATION</b><br/>There are 5 missing data points in the Glucose column. From the distribution plot we can observe that there is no much skewness present in the data. So, let us replace the missing values with mean of the data.\n</div>","metadata":{}},{"cell_type":"code","source":"gluc_imputer = SimpleImputer(strategy=\"mean\")\ndata[\"Glucose\"] = gluc_imputer.fit_transform(data[\"Glucose\"].values.reshape(-1, 1)).copy()\ndata[\"Glucose\"].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"Glucose\"])\nplt.show(\"Glucose distribution plot after Imputing with mean\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Analyzing BloodPressure Column</b>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"BloodPressure\"])\nplt.title(\"BloodPressure Distribution Plot\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"BloodPressure\"].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;background-color:lightgreen;border-radius:10px;padding:20px;\">\n<b>OBSERVATION</b><br/>There are 35 missing data points in the BloodPressure column. From the distribution plot we can observe that there is no skewness present in the data. So, let us replace the missing values with mean of the data.\n</div>","metadata":{}},{"cell_type":"code","source":"bp_imputer = SimpleImputer(strategy=\"mean\")\ndata[\"BloodPressure\"] = bp_imputer.fit_transform(data[\"BloodPressure\"].values.reshape(-1, 1)).copy()\ndata[\"BloodPressure\"].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"BloodPressure\"])\nplt.title(\"BloodPressure Distribution Plot after impution\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Analyzing SkinThickness Column</b>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"SkinThickness\"])\nplt.title(\"SkinThickness Distribution Plot\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"SkinThickness\"].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;background-color:lightgreen;border-radius:10px;padding:20px;\">\n<b>OBSERVATION</b><br/>There are 227 missing data points in the SkinThickness column. From the distribution plot we can observe that the SkinThickness data right skewed. So, let us replace the missing values with median of the data.\n</div>","metadata":{}},{"cell_type":"code","source":"skt_imputer = SimpleImputer(strategy=\"median\")\ndata[\"SkinThickness\"] = skt_imputer.fit_transform(data[\"SkinThickness\"].values.reshape(-1, 1)).copy()\ndata[\"SkinThickness\"].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"SkinThickness\"])\nplt.title(\"SkinThickness Distribution Plot after impution\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Analyzing Insulin Column</b>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"Insulin\"])\nplt.title(\"Insulin Distribution Plot\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"Insulin\"].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percent_of_missing = (data[\"Insulin\"].isnull().sum() / data.shape[0]) *100\nprint(f\"{percent_of_missing}% of Insulin data is missing.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"insulin_imputer = SimpleImputer(strategy=\"median\")\ndata[\"Insulin\"] = insulin_imputer.fit_transform(data[\"Insulin\"].values.reshape(-1, 1)).copy()\ndata[\"Insulin\"].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"Insulin\"])\nplt.title(\"Insulin Distribution Plot after imputing\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Analyzing BMI Column</b>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"BMI\"])\nplt.title(\"BMI Distribution Plot\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"BMI\"].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bmi_imputer = SimpleImputer(strategy=\"mean\")\ndata[\"BMI\"] = bmi_imputer.fit_transform(data[\"BMI\"].values.reshape(-1, 1)).copy()\ndata[\"BMI\"].isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"BMI\"])\nplt.title(\"BMI Distribution Plot after imputation\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"DiabetesPedigreeFunction\"])\nplt.title(\"DiabetesPedigreeFunction Distribution Plot\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b>Analyzing Age Column</b>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (7, 4))\nsns.distplot(data[\"Age\"])\nplt.title(\"Age Distribution Plot\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bivariate Analysis","metadata":{}},{"cell_type":"code","source":"continuous_data_cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI', 'DiabetesPedigreeFunction', 'Age']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (11,7))\nsns.heatmap(data[continuous_data_cols].corr(), center = 0, annot = True)\nplt.title(\"Correlation Plot\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;background-color:lightgreen;border-radius:10px;padding:20px;\">\n<b>OBSERVATION</b><br/>There is no multicollinearity problem in this data.\n</div>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (11,7))\nsns.pairplot(data[continuous_data_cols + [\"Outcome\"]], hue = \"Outcome\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_columns = list(data.columns)\nX = data[all_columns[:-1]]\ny = data[all_columns[-1]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Using Cross Validation for Base Model Selection","metadata":{}},{"cell_type":"code","source":"models = {\n    \"xgb_classifier\": XGBClassifier(eval_metric=\"logloss\"),\n    \"rf_model\": RandomForestClassifier(random_state = 18),\n    \"svm_model\":SVC(),\n    \"logistic_regression\":LogisticRegression(),\n    \"ada_boost\": AdaBoostClassifier(RandomForestClassifier(random_state = 18))\n}\n\nfor model_name in models:\n    print(f\"Model Name: {model_name}\")\n    print(\"Cross validation Scores\")\n    cv_scores = cross_val_score(make_pipeline(StandardScaler(), models[model_name]), X, y, cv = 5)\n    print(f\"Min Score: {min(cv_scores)}\")\n    print(f\"Max Score: {max(cv_scores)}\")    \n    print(f\"Mean Score: {np.mean(cv_scores)}\")\n    print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;background-color:lightgreen;border-radius:10px;padding:20px;\">\n<b>OBSERVATION</b><br/>We can notice that Logistic Regression, AdaBoost Model, RandomForest Model are performing better than remaining models.\n</div>","metadata":{}},{"cell_type":"markdown","source":"## Splitting the data into train and test","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size = 0.2, random_state = 0)\nprint(f\"Train Data: {X_train.shape}, {y_train.shape}\")\nprint(f\"Train Data: {X_test.shape}, {y_test.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Upsampling using SMOTE","metadata":{}},{"cell_type":"code","source":"counter = Counter(y_train)\ncounter","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"upsample = SMOTE()\nX_train, y_train = upsample.fit_resample(X_train, y_train)\ncounter = Counter(y_train)\nprint(counter)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Total Data after Upsampling: {len(X_train)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Train Data: {X_train.shape}, {y_train.shape}\")\nprint(f\"Train Data: {X_test.shape}, {y_test.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression","metadata":{}},{"cell_type":"code","source":"logistic_pipeline = make_pipeline(StandardScaler(), LogisticRegression())\nlogistic_pipeline.fit(X_train, y_train)\n\n# Accuray On Test Data\npredictions = logistic_pipeline.predict(X_test)\naccuracy = accuracy_score(y_test, predictions)\nprint(f\"Accuracy on Test Data: {accuracy*100}%\")\nprint(f\"Precision Score: {precision_score(y_test, predictions)}\")\nprint(f\"Recall Score: {recall_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nplot_confusion_matrix(logistic_pipeline, X_test, y_test)\nplt.title(\"Confusion Matrix for Test Data\")\nplt.show()\n\nprint()\n\n# Accuray On Whole Data\npredictions = logistic_pipeline.predict(X.values)\naccuracy = accuracy_score(y, predictions)\nprint(f\"Accuracy on Whole Data: {accuracy*100}%\")\nprint(f\"Precision Score: {precision_score(y, predictions)}\")\nprint(f\"Recall Score: {recall_score(y, predictions)}\")\nprint(f\"F1 Score: {f1_score(y, predictions)}\")\nplot_confusion_matrix(logistic_pipeline, X.values, y)\nplt.title(\"Confusion Matrix for Whole Data\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RandomForest Classifier","metadata":{}},{"cell_type":"code","source":"rf_pipeline = make_pipeline(StandardScaler(), RandomForestClassifier(random_state = 18))\nrf_pipeline.fit(X_train, y_train)\n\n# Accuray On Test Data\npredictions = rf_pipeline.predict(X_test)\naccuracy = accuracy_score(y_test, predictions)\nprint(f\"Accuracy on Test Data: {accuracy*100}%\")\nprint(f\"Precision Score: {precision_score(y_test, predictions)}\")\nprint(f\"Recall Score: {recall_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nplot_confusion_matrix(rf_pipeline, X_test, y_test)\nplt.title(\"Confusion Matrix for Test Data\")\nplt.show()\n\nprint()\n\n# Accuray On Whole Data\npredictions = rf_pipeline.predict(X.values)\naccuracy = accuracy_score(y, predictions)\nprint(f\"Accuracy on Whole Data: {accuracy*100}%\")\nprint(f\"Precision Score: {precision_score(y, predictions)}\")\nprint(f\"Recall Score: {recall_score(y, predictions)}\")\nprint(f\"F1 Score: {f1_score(y, predictions)}\")\nplot_confusion_matrix(rf_pipeline, X.values, y)\nplt.title(\"Confusion Matrix for Whole Data\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Adaboost Classifier","metadata":{}},{"cell_type":"code","source":"ada_pipeline = make_pipeline(StandardScaler(), AdaBoostClassifier(RandomForestClassifier(random_state = 18)))\nada_pipeline.fit(X_train, y_train)\n\n# Accuray On Test Data\npredictions = ada_pipeline.predict(X_test)\naccuracy = accuracy_score(y_test, predictions)\nprint(f\"Accuracy on Test Data: {accuracy*100}%\")\nprint(f\"Precision Score: {precision_score(y_test, predictions)}\")\nprint(f\"Recall Score: {recall_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nplot_confusion_matrix(ada_pipeline, X_test, y_test)\nplt.title(\"Confusion Matrix for Test Data\")\nplt.show()\n\nprint()\n\n# Accuray On Whole Data\npredictions = ada_pipeline.predict(X.values)\naccuracy = accuracy_score(y, predictions)\nprint(f\"Accuracy on Whole Data: {accuracy*100}%\")\nprint(f\"Precision Score: {precision_score(y, predictions)}\")\nprint(f\"Recall Score: {recall_score(y, predictions)}\")\nprint(f\"F1 Score: {f1_score(y, predictions)}\")\nplot_confusion_matrix(ada_pipeline, X.values, y)\nplt.title(\"Confusion Matrix for Whole Data\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:black;background-color:lightblue;border-radius:10px;padding:20px;\">\n<b>RESULT</b><br/>After extensive Data Analysis, Feature Engineering and Modeling. RandomForestClassifier out performed other models with a recall score of 0.80 and accuracy of 82.46% on test data and recall score of 0.96 and accuracy of 96.48% on whole data.\n    \n    \n<div align=\"center\" style=\"color:black;background-color:lightblue\">\n<b>Please do Upvote this notebook if you liked my work.</b>\n</div>\n</div>","metadata":{}}]}