{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load data using pandas\ndata = pd.read_csv('/kaggle/input/heart-disease-uci/heart.csv')\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape         ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe().T    # It describes the dataset statistically","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" data.info()   #Basic info about dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()             # check null values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"## Univariate Analysis","metadata":{}},{"cell_type":"code","source":"for i in data.columns:\n    sns.distplot(data[i])\n    plt.xlabel(i)\n    plt.ylabel('Count')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MULTIVARIATE ","metadata":{}},{"cell_type":"code","source":"sns.pairplot(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.heatmap(data.corr(),annot=True)     # It shows us the correlation between features using heatmap","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Divide the dataset into dependent and independent Features\nX = data.drop(['target'],axis=1)\ny = data['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import libraries and split dataset\nfrom sklearn.model_selection import train_test_split,cross_val_score,RandomizedSearchCV,GridSearchCV\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\nX_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Models\n- DecisionTreeClassifier\n- RandomForestClassifier\n- KNeighborsClassifier\n- XGBClassifier\n- CatBoostClassifier\n- GaussianNB\n- ExtraTreesClassifier\n- AdaBoostClassifier\n- LightGBMClassifier\n- Tuned Xgboostclassifier\n- Artificial Neural Network\n- Tuned LGBMClassifier\n","metadata":{}},{"cell_type":"code","source":"models =[]\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\n\n#Decision Tree\n\ntr = DecisionTreeClassifier(criterion = 'entropy',random_state=1)\ntr.fit(X_train,y_train)\ntr_pred=tr.predict(X_test)\nprint('DecisionTreeClassifier: ',accuracy_score(y_test,tr_pred)*100)\nmodels.append(['DecisionTreeClassifier',accuracy_score(y_test,tr_pred)*100])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#RandomForest\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=50, random_state=42)\nrf.fit(X_train,y_train)\nrf_pred=rf.predict(X_test)\nmodels.append(['RandomForestClassifier: ',accuracy_score(y_test,rf_pred)*100])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# K nearest Neighbors\nfrom sklearn.neighbors import KNeighborsClassifier\n\nkn = KNeighborsClassifier(n_neighbors=6)\nkn.fit(X_train,y_train)\nkn_pred=kn.predict(X_test)\nmodels.append(['KNeighborsClassifier: ',accuracy_score(y_test,kn_pred)*100])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#XGB Classifier\n\nfrom xgboost import XGBClassifier\n\nxgb = XGBClassifier()\n\nxgb.fit(X_train,y_train)\nxgb_pred = xgb.predict(X_test)\nmodels.append(['XGBClassifier: ',accuracy_score(y_test,xgb_pred)*100])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CatBoostClassifier\n\nfrom catboost import CatBoostClassifier\n\ncb = CatBoostClassifier(iterations=50, \n    learning_rate=0.01,depth = 3)\ncb.fit(X_train,y_train)\ncb_pred = cb.predict(X_test)\nmodels.append(['CatBoostClassifier: ',accuracy_score(y_test,cb_pred)*100])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#GaussianNB\nfrom sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\nnb.fit(X_train,y_train)\nnb_pred = nb.predict(X_test)\nmodels.append(['GaussianNB: ',accuracy_score(y_test,nb_pred)*100])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ExtraTreesClassifier\n\nfrom sklearn.ensemble import ExtraTreesClassifier\n\net = ExtraTreesClassifier()\net.fit(X_train,y_train)\net_pred = et.predict(X_test)\nmodels.append(['ExtraTreeClassifier: ',accuracy_score(y_test,et_pred)*100])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#AdaboostClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\nab = AdaBoostClassifier()\nab.fit(X_train,y_train)\nab_pred = ab.predict(X_test)\nmodels.append(['AdaBoostClassifier: ',accuracy_score(y_test,ab_pred)*100])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LightGBM\nfrom lightgbm import LGBMClassifier\n\nlgbm = LGBMClassifier(learning_rate=0.01,n_estimators=40)\nlgbm.fit(X_train,y_train)\nlgbm_pred = lgbm.predict(X_test)\nmodels.append(['LGBMClassifier: ',accuracy_score(y_test,lgbm_pred)*100])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ANN\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Activation,Dropout,Dense,Flatten\n\nimport warnings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(128,activation='relu',input_dim=13))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train,y_train,batch_size=50,epochs=90,validation_data=(X_test,y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models.append(['ANN_Accuracy: ','61.0000000'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Parameter for hyperparameter tuning of XGBOOSTClassifier\nparams={\n    \"learning_rate\" :[0.05,0.10,0.15,0.20,0.25,0.30],\n    \"max_depth\" : [3,4,5,6,7,8,10,12,15],\n    \"min_child_weight\": [1,3,5,7],\n    \"gamma\": [0.0,0.1,0.2,0.3,0.4,0.5],\n    \"colsample_bytree\" :[0.3,0.4,0.5,0.7,0.9]\n}\n\nrandom_search = RandomizedSearchCV(xgb,param_distributions=params,n_iter=5,scoring='roc_auc',cv=5,verbose=3,n_jobs=-1)\n\nrandom_search.fit(X,y)\n\nrandom_search.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier= XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.5, gamma=0.2, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.1, max_delta_step=0, max_depth=8,\n              min_child_weight=5, monotone_constraints='()',\n              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)\n\nscore = cross_val_score(classifier,X,y,cv=5)\n\nmodels.append(['Tunned Xgboost: ', score.mean()*100])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we can see there are two models having heighest score Catboost and LGBMClassifier.So we try hyperparameter tuning using LGBMClassifier.","metadata":{}},{"cell_type":"code","source":"# hyperparameter tuning of LGBMClassifier\nparams={\n    \"learning_rate\" :[0.05,0.10,0.15,0.20,0.25,0.30],\n    \"max_depth\" : [3,4,5,6,7,8,10,12,15],\n    \"min_child_weight\": [1,3,5,7],\n    \"reg_alpha\": [0.0,0.1,0.2,0.3,0.4,0.5],\n    \"reg_lambda\": [0.0,0.1,0.2,0.3,0.4,0.5],\n    \"colsample_bytree\" :[0.3,0.4,0.5,0.7,0.9]\n}\n\nlgbm_class = LGBMClassifier()\nrandom_search_lgbm = RandomizedSearchCV(lgbm_class,param_distributions=params,n_iter=5,scoring='roc_auc',cv=5,verbose=3,n_jobs=-1)\nrandom_search_lgbm.fit(X,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_search_lgbm.best_estimator_\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm_classifiers = LGBMClassifier(colsample_bytree=0.3, learning_rate=0.05, max_depth=7,\n               min_child_weight=3, reg_alpha=0.5, reg_lambda=0.5)\n\nscore = cross_val_score(lgbm_classifiers,X,y,cv=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models.append(['Tuned LGBMClassifier',score.mean()*100])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(models,columns=['Models','Scores'])\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hurray!!!\nKNeighborsClassifier won with score of 90.1639","metadata":{}}]}