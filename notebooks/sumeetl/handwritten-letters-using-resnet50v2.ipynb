{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Introduction**\nI tried this as a learning exercise on transfer learning and the best accuracy I could get this to was in the 70% range which isn't as good as some of the other kernels posted here. I can't figure out how to get any further inspite of trying lots of variations on the model, on data augmentation and on pre-processing the image. If you have any suggestions or if this approach is futile, I'd definitely appreciate your feedback.\n\n# **Setup**\nSetup the imports, data and utility functions"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom IPython.display import Image, display\nfrom learntools.deep_learning.decode_predictions import decode_predictions\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, BatchNormalization, UpSampling2D, Lambda\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.applications import ResNet50, ResNet50V2\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator, array_to_img\nfrom tensorflow.keras import Input\nimport tensorflow as tf\nimport pylab as pl\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimage_size = 224\nnum_letters = 33\nnum_bgs = 2\n\nli = []\nletters1_data = pd.read_csv('/kaggle/input/classification-of-handwritten-letters/letters.csv').sample(frac=1).reset_index(drop=True)\n#letters2_data = pd.read_csv('/kaggle/input/classification-of-handwritten-letters/letters2.csv')\n#letters3_data = pd.read_csv('/kaggle/input/classification-of-handwritten-letters/letters3.csv')\nli.append(letters1_data)\n#li.append(letters2_data)\n#li.append(letters3_data)\nletters_data = pd.concat(li).sample(frac=1).reset_index(drop=True)\n\ndict = {}\nfor i in letters_data.values:\n    dict[i[1]] = i[0]\n\nfiles=[]\nfor file in letters_data.file.values:\n    files.append('/kaggle/input/classification-of-handwritten-letters/letters/' + file)\n\n# plotting of fitting histories for neural networks\ndef history_plot(fit_history):\n    pl.figure(figsize=(12,10)); pl.subplot(211)\n    keys=list(fit_history.history.keys())[0:4]\n    pl.plot(fit_history.history[keys[0]],\n            color='slategray',label='train')\n    pl.plot(fit_history.history[keys[2]],\n            color='#4876ff',label='valid')\n    pl.xlabel(\"Epochs\"); pl.ylabel(\"Loss\")\n    pl.legend(); pl.grid()\n    pl.title('Loss Function')     \n    pl.subplot(212)\n    pl.plot(fit_history.history[keys[1]],\n            color='slategray',label='train')\n    pl.plot(fit_history.history[keys[3]],\n            color='#4876ff',label='valid')\n    pl.xlabel(\"Epochs\"); pl.ylabel(\"Accuracy\")    \n    pl.legend(); pl.grid()\n    pl.title('Accuracy'); pl.show()\n\ndef read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n    imgs = [load_img(img_path, target_size=(img_height, img_width), interpolation=\"bicubic\", color_mode=\"rgb\") for img_path in img_paths]\n    img_array = [img_to_array(img) for img in imgs]\n    output = np.asarray(img_array) / 255\n    return(output)\n\nx = read_and_prep_images(files)\ny = keras.utils.to_categorical(letters_data.label.values-1, num_letters)\nz = keras.utils.to_categorical(letters_data.background.values, num_bgs)\n\n(x_train, x_test, y_train, y_test) = train_test_split(x, y, test_size=0.05)\n(_, _, z_train, z_test) = train_test_split(x, z, test_size=0.05)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Model**\n\nI built the model using ResNet50V2 because ResNet50 was always predicting a single output and was never able to improve it's accuracy. It looks like that might be a bug of some sort and there are several other stackoverflow posts about it."},{"metadata":{"trusted":true},"cell_type":"code","source":"def MyUpSampling2D(size):\n    return Lambda(lambda x: \n        tf.image.resize(x, size, method=tf.image.ResizeMethod.BICUBIC, antialias=True)\n    )\n\ndef MyContrast():\n    return Lambda(lambda x: \n        tf.image.adjust_contrast(x, 2.0)\n    )\n\ndef MyGreyscale():\n    return Lambda(lambda x: \n        tf.image.rgb_to_grayscale(x)\n    )\n\nresnet_model = ResNet50V2(include_top=False, weights='imagenet', layers=tf.keras.layers)\nresnet_model.trainable = False\n\nmy_new_model = Sequential()\n\n# upsample 32x32 images to meet resnets 224x224 resolution\nmy_new_model.add(MyUpSampling2D((224,224)))\nmy_new_model.add(MyContrast())\nmy_new_model.add(resnet_model)\nmy_new_model.add(Dense(256, activation='relu'))\nmy_new_model.add(Dropout(.25))\nmy_new_model.add(BatchNormalization())\nmy_new_model.add(Flatten())\nmy_new_model.add(Dense(num_letters, activation='softmax'))\n\nmy_new_model.compile(optimizer='adam', \n                     loss='categorical_crossentropy', \n                     metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Image data generators**\nWe setup our training to augment the input data by randomly rotating, zooming and shearing it. I also tried shifting horizontally and vertically & various other tensorflow image transforms but they didn't seem to help much."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_generator = ImageDataGenerator(rotation_range=0.25, zoom_range=0.25, shear_range=0.25)\ntrain_generator.fit(x_train, augment=True)\ntrain_generator = train_generator.flow(x_train, y_train, batch_size=100)\n\nvalidation_generator = ImageDataGenerator()\nvalidation_generator.fit(x_test)\nvalidation_generator = validation_generator.flow(x_test, y_test, batch_size=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Train the model**\nTrain the model using the above generators and view it's accuracy history."},{"metadata":{"trusted":true},"cell_type":"code","source":"fit_stats = my_new_model.fit_generator(train_generator,\n                                       steps_per_epoch=15,\n                                       epochs=15,\n                                       validation_data=validation_generator,\n                                       validation_steps=1)\nhistory_plot(fit_stats)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}