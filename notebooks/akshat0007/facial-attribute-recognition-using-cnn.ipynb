{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-13T09:45:32.64233Z","iopub.execute_input":"2021-07-13T09:45:32.642718Z","iopub.status.idle":"2021-07-13T09:45:32.653671Z","shell.execute_reply.started":"2021-07-13T09:45:32.642632Z","shell.execute_reply":"2021-07-13T09:45:32.6526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import PIL\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.preprocessing import image","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:45:32.655496Z","iopub.execute_input":"2021-07-13T09:45:32.655908Z","iopub.status.idle":"2021-07-13T09:45:37.542206Z","shell.execute_reply.started":"2021-07-13T09:45:32.655865Z","shell.execute_reply":"2021-07-13T09:45:37.54125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Defining the path to the datasets\nkey_points_data_path = \"../input/celeba-dataset/list_landmarks_align_celeba.csv\"\nimages_data_path = \"../input/celeba-dataset/img_align_celeba/img_align_celeba\"\n\n# Since, the dataset is very huge. Hence, we will only select 10000K images\nimages_data_size = 10000\n\n# Original image dimensions\nx_org = 178    # original x value\ny_org = 218    # original y value\n\n#Let's scale the images to new dimensions\n\n# New image dimensions\nx_ = 100                            # new value of x\nimage_size_ratio = x_org / y_org    # dimensions ratio\ny_ = int(image_size_ratio * x_)     # new value of y\n\n# Image Sizes\noriginal_image_size = (x_org, y_org)\nnew_image_size = (x_,y_)\n\n# The image size that will be used in the training process\nimage_size_training = new_image_size\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:45:37.545869Z","iopub.execute_input":"2021-07-13T09:45:37.546167Z","iopub.status.idle":"2021-07-13T09:45:37.55355Z","shell.execute_reply.started":"2021-07-13T09:45:37.546138Z","shell.execute_reply":"2021-07-13T09:45:37.55272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the key points data","metadata":{}},{"cell_type":"code","source":"# load the dataset (key points)\ndf_org = pd.read_csv(key_points_data_path)\ndf_org = df_org[:images_data_size]","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:45:37.557208Z","iopub.execute_input":"2021-07-13T09:45:37.557513Z","iopub.status.idle":"2021-07-13T09:45:37.917317Z","shell.execute_reply.started":"2021-07-13T09:45:37.557468Z","shell.execute_reply":"2021-07-13T09:45:37.916349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Converting images into an array","metadata":{}},{"cell_type":"code","source":"images_data = list()\nfor idx in range(df_org.shape[0]):\n    # Retrieving the path based upon the index\n    path = \"{}/{}\".format(str(images_data_path),str(df_org.iloc[idx].image_id))\n    \n    # Reading images using PIL library\n    image = PIL.Image.open(path).resize(image_size_training)\n    image_array = np.asarray(image) / 255\n    \n    # Appending the images to a list\n    images_data.append(image_array)\n    \n# Converting images_data to an array from list\nimages_data = np.array(images_data)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:45:37.919534Z","iopub.execute_input":"2021-07-13T09:45:37.919857Z","iopub.status.idle":"2021-07-13T09:46:27.224395Z","shell.execute_reply.started":"2021-07-13T09:45:37.919815Z","shell.execute_reply":"2021-07-13T09:46:27.223386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plotting a sample image","metadata":{}},{"cell_type":"code","source":"# Plotting a sample image\nplt.imshow(images_data[700])","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:27.225724Z","iopub.execute_input":"2021-07-13T09:46:27.226079Z","iopub.status.idle":"2021-07-13T09:46:27.426152Z","shell.execute_reply.started":"2021-07-13T09:46:27.226045Z","shell.execute_reply":"2021-07-13T09:46:27.42525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Images Data Arrays Shape:\", images_data.shape)\nprint(\"Key Points Data Shape:\", df_org.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:27.428435Z","iopub.execute_input":"2021-07-13T09:46:27.428774Z","iopub.status.idle":"2021-07-13T09:46:27.434187Z","shell.execute_reply.started":"2021-07-13T09:46:27.428735Z","shell.execute_reply":"2021-07-13T09:46:27.433215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_org.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:27.436298Z","iopub.execute_input":"2021-07-13T09:46:27.436904Z","iopub.status.idle":"2021-07-13T09:46:27.451187Z","shell.execute_reply.started":"2021-07-13T09:46:27.436859Z","shell.execute_reply":"2021-07-13T09:46:27.4501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_org.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:27.452828Z","iopub.execute_input":"2021-07-13T09:46:27.45351Z","iopub.status.idle":"2021-07-13T09:46:27.505343Z","shell.execute_reply.started":"2021-07-13T09:46:27.453469Z","shell.execute_reply":"2021-07-13T09:46:27.504247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reading images","metadata":{}},{"cell_type":"code","source":"# function to read images based on index\ndef image_array(index, size=image_size_training, path=images_data_path):\n    \"\"\"\n    This functions is for converting images to arrays to deal with it in the model.\n    \n    Input:  index of the image that we want to convert to array\n            size of the image that we want for the array of the image\n            path of the images data to get the image\n            \n    Output: the image array as numpy array\n    \"\"\"\n    # to get the path based on index\n    path = \"{}/{}\".format(str(path),str(df_org.iloc[index].image_id))\n    \n    # to read the image\n    image = PIL.Image.open(path).resize(size)\n    image_array = np.asarray(image)\n    \n    return image_array","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:27.506917Z","iopub.execute_input":"2021-07-13T09:46:27.507288Z","iopub.status.idle":"2021-07-13T09:46:27.527343Z","shell.execute_reply.started":"2021-07-13T09:46:27.507247Z","shell.execute_reply":"2021-07-13T09:46:27.526135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to get a list of all key points of the face\ndef image_key_points_list(index, df = df_org):\n    \"\"\"\n    This function for getting the key points on the face as list to deal with it in plotting sections\n    \"\"\"\n    # box dictionary\n    points_list = [df.iloc[index].lefteye_x,\n                   df.iloc[index].lefteye_y,\n                   df.iloc[index].righteye_x,\n                   df.iloc[index].righteye_y,\n                   df.iloc[index].nose_x,\n                   df.iloc[index].nose_y,\n                   df.iloc[index].leftmouth_x,\n                   df.iloc[index].leftmouth_y,\n                   df.iloc[index].rightmouth_x,\n                   df.iloc[index].rightmouth_y]\n    \n    return points_list","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:27.529065Z","iopub.execute_input":"2021-07-13T09:46:27.529548Z","iopub.status.idle":"2021-07-13T09:46:27.541038Z","shell.execute_reply.started":"2021-07-13T09:46:27.52951Z","shell.execute_reply":"2021-07-13T09:46:27.539957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to plot the image with green box around the faces\ndef plotting_image_with_box(index, df = df_org, size=original_image_size):\n    \"\"\"\n    This function for plotting the image with points on facial features and box around the face\n    \"\"\"\n    test_image = image_array(index, size)\n    points_list = image_key_points_list(index, df)\n    \n    # face points\n    le_x, le_y, re_x, re_y = points_list[0], points_list[1], points_list[2], points_list[3]\n    n_x, n_y = points_list[4], points_list[5]\n    lm_x, lm_y, rm_x, rm_y = points_list[6], points_list[7], points_list[8], points_list[9]\n    \n    # Create figure and axes\n    fig, ax = plt.subplots()\n    # plot the image\n    ax.imshow(test_image)\n    # plot the points on the face\n    ax.plot([le_x,re_x,n_x,lm_x,rm_x], [le_y,re_y,n_y,lm_y,rm_y], 'bo-')\n    \n    # plot the box around the face\n    width = abs(le_x-rm_x-60)\n    height = abs(le_y-rm_y-75)\n    rect = patches.Rectangle((le_x-30, le_y-40), width, height, linewidth=4, edgecolor='g', facecolor='none')\n    ax.add_patch(rect);","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:27.544236Z","iopub.execute_input":"2021-07-13T09:46:27.544496Z","iopub.status.idle":"2021-07-13T09:46:27.554683Z","shell.execute_reply.started":"2021-07-13T09:46:27.544472Z","shell.execute_reply":"2021-07-13T09:46:27.553761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting the image with facial key points\nplotting_image_with_box(25)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:27.556133Z","iopub.execute_input":"2021-07-13T09:46:27.55662Z","iopub.status.idle":"2021-07-13T09:46:27.73059Z","shell.execute_reply.started":"2021-07-13T09:46:27.556568Z","shell.execute_reply":"2021-07-13T09:46:27.729599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing the data for our Deep Learning","metadata":{}},{"cell_type":"markdown","source":"### Now, we will rescale the keypoints on the basis of rescaled images","metadata":{}},{"cell_type":"code","source":"# copy a version from the data to prepare it for analysis\ndf = df_org.copy()\n\n# check\ndf.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:27.732101Z","iopub.execute_input":"2021-07-13T09:46:27.732457Z","iopub.status.idle":"2021-07-13T09:46:27.74773Z","shell.execute_reply.started":"2021-07-13T09:46:27.73242Z","shell.execute_reply":"2021-07-13T09:46:27.746862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function for updating key points for a new size\ndef rescale_key_points(oldsize=original_image_size, newsize=image_size_training):\n    \"\"\"\n    This function is for rescaling the key points from the original scale to a nwe scale from our chossen and we reduce\n    the image size to make the analysis faster and using lower memory\n    \"\"\"\n    # old and nwe sizes (x,y) values\n    x_axis_old = oldsize[0]\n    y_axis_old = oldsize[1]\n\n    x_axis_new = newsize[0]\n    y_axis_new = newsize[1]\n\n    x_ratio = x_axis_new / x_axis_old\n    y_ratio = y_axis_new / y_axis_old\n    \n    # converting the keypoints values to be trained with the new size of the images\n    keypoints_x = ['lefteye_x', 'righteye_x', 'nose_x', 'leftmouth_x', 'rightmouth_x']\n    keypoints_y = ['lefteye_y', 'righteye_y', 'nose_y', 'leftmouth_y', 'rightmouth_y']\n    \n    df[keypoints_x] = (df[keypoints_x] * x_ratio).astype('int')\n    df[keypoints_y] = (df[keypoints_y] * y_ratio).astype('int')\n    \n    return 0\n\n# call the function\nrescale_key_points()\n\n# check\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:27.749099Z","iopub.execute_input":"2021-07-13T09:46:27.74969Z","iopub.status.idle":"2021-07-13T09:46:27.786492Z","shell.execute_reply.started":"2021-07-13T09:46:27.749651Z","shell.execute_reply":"2021-07-13T09:46:27.785766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images=images_data\nlabels=df","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:27.787721Z","iopub.execute_input":"2021-07-13T09:46:27.788073Z","iopub.status.idle":"2021-07-13T09:46:27.792876Z","shell.execute_reply.started":"2021-07-13T09:46:27.788038Z","shell.execute_reply":"2021-07-13T09:46:27.791883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:27.794603Z","iopub.execute_input":"2021-07-13T09:46:27.795215Z","iopub.status.idle":"2021-07-13T09:46:27.802691Z","shell.execute_reply.started":"2021-07-13T09:46:27.795164Z","shell.execute_reply":"2021-07-13T09:46:27.801738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images,test_images,train_labels,test_labels=train_test_split(images,labels,\n                                                                  test_size=0.3,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:27.805214Z","iopub.execute_input":"2021-07-13T09:46:27.805488Z","iopub.status.idle":"2021-07-13T09:46:28.332201Z","shell.execute_reply.started":"2021-07-13T09:46:27.805449Z","shell.execute_reply":"2021-07-13T09:46:28.331265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test=test_labels.drop([\"image_id\"],axis=1)\ny_train=train_labels.drop([\"image_id\"],axis=1)\n\nX_test=test_images\nX_train=train_images","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:28.335363Z","iopub.execute_input":"2021-07-13T09:46:28.335725Z","iopub.status.idle":"2021-07-13T09:46:28.341863Z","shell.execute_reply.started":"2021-07-13T09:46:28.33569Z","shell.execute_reply":"2021-07-13T09:46:28.34078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Further splitting the test data into validation and test data","metadata":{}},{"cell_type":"code","source":"X_test, X_val, y_test, y_val=train_test_split(X_test, y_test,\n                                              test_size=0.5,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:28.343491Z","iopub.execute_input":"2021-07-13T09:46:28.344144Z","iopub.status.idle":"2021-07-13T09:46:28.490949Z","shell.execute_reply.started":"2021-07-13T09:46:28.344104Z","shell.execute_reply":"2021-07-13T09:46:28.490013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building the CNN-based Deep Learning model","metadata":{}},{"cell_type":"code","source":"# diminsions of the image in the traing process\nx_ = image_size_training[0]\ny_ = image_size_training[1]\n\n# build the model\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=8, kernel_size=(3, 3), padding='same', activation=\"relu\", input_shape=(y_,x_,3)))\nmodel.add(Conv2D(filters=8, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(10, activation='relu'))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:28.492438Z","iopub.execute_input":"2021-07-13T09:46:28.492792Z","iopub.status.idle":"2021-07-13T09:46:30.594451Z","shell.execute_reply.started":"2021-07-13T09:46:28.492753Z","shell.execute_reply":"2021-07-13T09:46:30.59344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Having a quick view of the model architecture","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:30.595872Z","iopub.execute_input":"2021-07-13T09:46:30.596265Z","iopub.status.idle":"2021-07-13T09:46:30.61606Z","shell.execute_reply.started":"2021-07-13T09:46:30.596224Z","shell.execute_reply":"2021-07-13T09:46:30.615179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=\"rmsprop\", loss='mean_squared_error',metrics=[\"mae\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:30.619077Z","iopub.execute_input":"2021-07-13T09:46:30.619362Z","iopub.status.idle":"2021-07-13T09:46:30.636974Z","shell.execute_reply.started":"2021-07-13T09:46:30.619332Z","shell.execute_reply":"2021-07-13T09:46:30.635986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fitting the model with our data\ntraining_process = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val), batch_size=4, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:46:30.638377Z","iopub.execute_input":"2021-07-13T09:46:30.638782Z","iopub.status.idle":"2021-07-13T09:55:17.386563Z","shell.execute_reply.started":"2021-07-13T09:46:30.63874Z","shell.execute_reply":"2021-07-13T09:55:17.385591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing the model","metadata":{}},{"cell_type":"markdown","source":"### Evaluating the model performance on the basis of ","metadata":{}},{"cell_type":"code","source":"model.evaluate(X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T09:58:04.26242Z","iopub.execute_input":"2021-07-13T09:58:04.262803Z","iopub.status.idle":"2021-07-13T09:58:04.904101Z","shell.execute_reply.started":"2021-07-13T09:58:04.26277Z","shell.execute_reply":"2021-07-13T09:58:04.903254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predictions_test_model(index):\n    img = tf.keras.preprocessing.image.load_img(\"{}/0{}.jpg\".format(images_data_path, index),target_size=(y_,x_,3))\n    img = tf.keras.preprocessing.image.img_to_array(img)\n    img = img/255\n    points_list = model.predict(img.reshape(1,y_,x_,3)).astype('int')[0]\n    \n    # converting key points values to the original size\n    x_ratio = 1.05 * (original_image_size[0] / image_size_training[0])\n    y_ratio = 1.085 * (original_image_size[1] / image_size_training[1])\n    \"\"\"\n    In the previous ratios we multiply them by contant to reduce the noise that happened when we rescaled the points in\n    the previous training, there is no meaning for these numbers (i just pick them with trails)\n    \"\"\"\n    \n    points_list[0] = int(points_list[0] * x_ratio)\n    points_list[2] = int(points_list[2] * x_ratio)\n    points_list[4] = int(points_list[4] * x_ratio)\n    points_list[6] = int(points_list[6] * x_ratio)\n    points_list[8] = int(points_list[8] * x_ratio)\n    \n    points_list[1] = int(points_list[1] * y_ratio)\n    points_list[3] = int(points_list[3] * y_ratio)\n    points_list[5] = int(points_list[5] * y_ratio)\n    points_list[7] = int(points_list[7] * y_ratio)\n    points_list[9] = int(points_list[9] * y_ratio)\n    \n    return points_list","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:24:42.503101Z","iopub.execute_input":"2021-07-13T10:24:42.503469Z","iopub.status.idle":"2021-07-13T10:24:42.513808Z","shell.execute_reply.started":"2021-07-13T10:24:42.503437Z","shell.execute_reply":"2021-07-13T10:24:42.512768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to plot the image with green box around the faces\ndef test_image_with_box_plot(index, pred_or_actual = 'pred', pointsColor='bo-' ,boxcolor='g'):\n    img = tf.keras.preprocessing.image.load_img(\"{}/0{}.jpg\".format(images_data_path, index),target_size=(y_org,x_org,3))\n    img = tf.keras.preprocessing.image.img_to_array(img)\n    test_image = img/255\n    \n    # predictions of key points on the face\n    if pred_or_actual == 'pred':\n        points_list = predictions_test_model(index)        # this for predections of the model\n    elif pred_or_actual == 'actual':\n        points_list = image_key_points_list(index)   # this for the actual labels of the test data\n    \n    # face points\n    le_x, le_y, re_x, re_y = points_list[0], points_list[1], points_list[2], points_list[3]\n    n_x, n_y = points_list[4], points_list[5]\n    lm_x, lm_y, rm_x, rm_y = points_list[6], points_list[7], points_list[8], points_list[9]\n\n    # Create figure and axes\n    fig, ax = plt.subplots()\n    # plot the image\n    ax.imshow(test_image)\n    # plot the points on the face\n    ax.plot([le_x,re_x,n_x,lm_x,rm_x], [le_y,re_y,n_y,lm_y,rm_y], pointsColor)\n    \n    # plot the box around the face\n    width = abs(le_x-rm_x-60)\n    height = abs(le_y-rm_y-75)\n    rect = patches.Rectangle((le_x-30, le_y-40), width, height, linewidth=4, edgecolor=boxcolor, facecolor='none')\n    ax.add_patch(rect);\n    return points_list","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:27:21.232632Z","iopub.execute_input":"2021-07-13T10:27:21.233026Z","iopub.status.idle":"2021-07-13T10:27:21.243649Z","shell.execute_reply.started":"2021-07-13T10:27:21.232995Z","shell.execute_reply":"2021-07-13T10:27:21.242551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the model to predict a sample image which doesn't exist in train,test, or validation data\nindex = 34100\nprint('RED box for predections\\n') \nprint('GREEN box for actual labels\\n')\ntest_image_with_box_plot(index, pred_or_actual = 'pred', pointsColor='mo-' ,boxcolor='r')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:27:22.178659Z","iopub.execute_input":"2021-07-13T10:27:22.17904Z","iopub.status.idle":"2021-07-13T10:27:22.391736Z","shell.execute_reply.started":"2021-07-13T10:27:22.179004Z","shell.execute_reply":"2021-07-13T10:27:22.390863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# losses of both training and validation sets\nloss = training_process.history['loss']\nval_loss = training_process.history['val_loss']\n\n# plot both losses\nplt.plot(loss)\nplt.plot(val_loss)\nplt.legend(['loss', 'val_loss']);","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:28:11.738667Z","iopub.execute_input":"2021-07-13T10:28:11.739036Z","iopub.status.idle":"2021-07-13T10:28:11.919068Z","shell.execute_reply.started":"2021-07-13T10:28:11.739003Z","shell.execute_reply":"2021-07-13T10:28:11.917793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving the model for future use","metadata":{}},{"cell_type":"code","source":"model.save(\"model.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:29:02.813278Z","iopub.execute_input":"2021-07-13T10:29:02.813611Z","iopub.status.idle":"2021-07-13T10:29:02.866655Z","shell.execute_reply.started":"2021-07-13T10:29:02.81358Z","shell.execute_reply":"2021-07-13T10:29:02.865799Z"},"trusted":true},"execution_count":null,"outputs":[]}]}