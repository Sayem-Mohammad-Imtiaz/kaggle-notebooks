{"cells":[{"metadata":{},"cell_type":"markdown","source":"# NEURAL NETWORK TO PREDICT CARDIOVASCULAR DISEASES"},{"metadata":{},"cell_type":"markdown","source":"###### *To see our info page (about cardiovascular diseases and info about us), you could visit : https://mailchi.mp/dd56c857ba2e/heartaid*"},{"metadata":{},"cell_type":"markdown","source":"### Uploading packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing\nimport seaborn as sns             # visualizations\nimport matplotlib.pyplot as plt   # visualizations\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import np_utils\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Uploading data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"../input/cardiovascular-disease-dataset/cardio_train.csv\")\ndf=data.from_csv(\"../input/cardiovascular-disease-dataset/cardio_train.csv\", header=0, sep=\";\")\ndfcol=df.columns\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking if the targets are balanced"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[[\"cardio\",\"height\"]].groupby(\"cardio\").count()\nsns.countplot(x=\"cardio\", data=df, palette=\"Set1\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Transform (Scaling to avoid outliers)"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn import preprocessing\nscaler=preprocessing.MinMaxScaler()\ndfscale=scaler.fit_transform(df)\ndfscale2=pd.DataFrame(dfscale, columns=dfcol)\ndfscale2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting data"},{"metadata":{"trusted":true},"cell_type":"code","source":"xdf=dfscale2.iloc[:,0:11]\n#xdf[\"gender\"]=np.where(xdf[\"gender\"]==1,\"0\",\"1\") #Cambiar el 2 por 1, el 1 por 0 (por orden)\n#Aca vendria un posible drop de variables xdf=xdf.drop([\"gender\",\"gluc\"], axis=1)\nydf=dfscale2.iloc[:,-1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_training, x_testing, y_training, y_testing = train_test_split(xdf, ydf, test_size = 0.2, random_state=123, stratify=ydf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(xdf.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Neural Network"},{"metadata":{},"cell_type":"markdown","source":"#### Basic NN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers.core import Dense, Activation\nfrom keras.optimizers import SGD\nfrom keras.layers import Dropout\nfrom keras.constraints import maxnorm\n\nmodel = Sequential()\nmodel.add(Dense(25, input_dim=11, activation='softsign', kernel_constraint=maxnorm(2)))\n#model.add(Dropout(0))\nmodel.add(Dense(5, activation='softsign'))\n#model.add(Dropout(0))\nmodel.add(Dense(3, activation='softsign'))\n#model.add(Dropout(0))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss = 'binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_training, y_training, epochs=50, batch_size=50, verbose=0)\nscore = model.evaluate(x_training, y_training)\nprint(\"\\n Training Accuracy:\", score[1])\nscore = model.evaluate(x_testing, y_testing)\nprint(\"\\n Testing Accuracy:\", score[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Initial Accuracy**= 0.6465 \n* **Final aprox Accuracy**= 0.68-0.719"},{"metadata":{},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"res=model.predict(x_testing)\nres\nresdf=pd.DataFrame(res, index=x_testing.index)\nresdf.columns=[\"Pr\"]\nresdf[\"ID\"]=range(14000)\nresdf[\"y\"]=np.where(resdf[\"Pr\"]>=0.5,\"1\", \"0\")\nresdf\nprediction=resdf.drop([\"Pr\",\"ID\"], axis=1)\npredictionarray=prediction.astype(np.float)\nsns.distplot(resdf[\"Pr\"],  color=\"red\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### How many 1's and 0's predict the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"c1=resdf[['ID','y']].groupby('y').count()\nc1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### How many 1's and 0's are in the test sample"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_testingdf=pd.DataFrame(y_testing, index=y_testing.index)\ny_testingdf[\"ID\"]=range(14000)\ny_test=y_testingdf.drop([\"ID\"], axis=1)\nc2=y_testingdf[['ID','cardio']].groupby('cardio').count()\nc2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test.values, predictionarray)\ncm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Accuracy of the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"Accuracy=cm[0,0]/(cm[0,0]+cm[1,0])\nprint(\"The accuracy of the model is: \"+ str(Accuracy*100) + \" %\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This means that of all the people with Cardiovascular Disease in the Test-DataBase, the model identify **73% (aprox.)** of the total cases."},{"metadata":{},"cell_type":"markdown","source":"# Predicting a single case"},{"metadata":{"trusted":true},"cell_type":"code","source":"#INSERT DATA#\n###############################################################################\n\nday= 25 # day of bith \nmonth= 9 # month of bith (in numbers)\nyear= 1998 # year of bith\ngender= 1 # 0 for women, 1 for men\nheight= 183 # in cm\nweight= 89 # in kilograms\nsystolicbloodpressure= 120 # Systolic blood pressure\ndiastolicbloodpressure= 80 # Diastolic blood pressure\ncholesterol= 1 # 1: normal, 2: above normal, 3: well above normal\ngluc= 1 # 1: normal, 2: above normal, 3: well above normal\nsmoke= 0 # 1 if you smoke, 0 if not\nalco= 0 # 1 if you drink alcohol, 0 if not\nactive= 1 # 1 if you do physical activity, 0 if not\n\n##############################################################################\nfrom datetime import date\nf_date = date(year,month,day)\nl_date = date.today()\ndelta = l_date - f_date\nagedays=delta.days\n\nagedayscale=(agedays-df[\"age\"].min())/(df[\"age\"].max()-df[\"age\"].min())\nheightscale=(height-df[\"height\"].min())/(df[\"height\"].max()-df[\"height\"].min())\nweightscale=(weight-df[\"weight\"].min())/(df[\"weight\"].max()-df[\"weight\"].min())\nsbpscale=(systolicbloodpressure-df[\"ap_hi\"].min())/(df[\"ap_hi\"].max()-df[\"ap_hi\"].min())\ndbpscale=(diastolicbloodpressure-df[\"ap_lo\"].min())/(df[\"ap_lo\"].max()-df[\"ap_lo\"].min())\ncholesterolscale=(cholesterol-df[\"cholesterol\"].min())/(df[\"cholesterol\"].max()-df[\"cholesterol\"].min())\nglucscale=(gluc-df[\"gluc\"].min())/(df[\"gluc\"].max()-df[\"gluc\"].min())\n\nsingle=np.array([agedayscale, gender, heightscale, weightscale, sbpscale, dbpscale, cholesterolscale, glucscale, smoke, alco, active ])\nsingledf=pd.DataFrame(single)\nfinal=singledf.transpose()\nfinal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"finalres=model.predict(final)\nfinalres\nprint(\"The probability of having or to have a Cardiovascular Disease is: \"+ str(round(finalres[0,0]*100,2)) + \"%\")"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import model_from_json\n\n#model.save_weights(\"weights.hdf5\")\njson_string = model.to_json()\nmodeltopredict = model_from_json(json_string)\nmodeltopredict.load_weights(\"../input/weights-nn/weights.hdf5\", by_name=False)\n\nprediction=modeltopredict.predict(final)\n\nif prediction[0,0]>=0.5:\n    print(\"The probability of having or to have a Cardiovascular Disease is: \"+ str(round(prediction[0,0]*100,2)) + \"%\")\n    print(\"You must visit a doctor to check it :(\")\nelif prediction[0,0]<0.5 and prediction[0,0]>=0.3:\n    print(\"The probability of having or to have a Cardiovascular Disease is: \"+ str(round(prediction[0,0]*100,2)) + \"%\")\n    print(\"Probably you are healthy :/ \")\nelse:\n    print(\"The probability of having or to have a Cardiovascular Disease is: \"+ str(round(prediction[0,0]*100,2)) + \"%\")\n    print(\"You are healthy :) \")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tuning hyperparameters to look up for the best NN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom keras.wrappers.scikit_learn import KerasClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Batch Size and Epochs\n\nIn the final kernel, this code is not gonna be available 'cause it takes too much time to run this parts of code.\nThe summary will be written below the function."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def create_model():\n    model = Sequential()\n    model.add(Dense(10, input_dim=11, activation='tanh'))\n    model.add(Dropout(0.1))\n    model.add(Dense(5, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(3, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss = 'binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n    return model\n\n#### create model\nmodel = KerasClassifier(build_fn=create_model, verbose=0)\n\n#### define the parameters to search in grid search \nbatch_size = [10, 50, 100]\nepochs = [10, 50, 100]\nparam_grid = dict(batch_size=batch_size, epochs=epochs)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\ngrid_result = grid.fit(x_training, y_training)\n\n#### summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))"},{"metadata":{},"cell_type":"markdown","source":"**Results:** \n* Best: 0.640893 using {**'batch_size': 50, 'epochs': 50**}\n* 0.638214 (0.003997) with: {'batch_size': 10, 'epochs': 10}\n* 0.640446 (0.006447) with: {'batch_size': 10, 'epochs': 50}\n* 0.613500 (0.060568) with: {'batch_size': 10, 'epochs': 100}\n* 0.617089 (0.012489) with: {'batch_size': 50, 'epochs': 10}\n* 0.640893 (0.004402) with: {'batch_size': 50, 'epochs': 50}\n* 0.640661 (0.003730) with: {'batch_size': 50, 'epochs': 100}\n* 0.613732 (0.017299) with: {'batch_size': 100, 'epochs': 10}\n* 0.635268 (0.005980) with: {'batch_size': 100, 'epochs': 50}\n* 0.639482 (0.007552) with: {'batch_size': 100, 'epochs': 100}"},{"metadata":{},"cell_type":"markdown","source":"## Optimization Algorithm\n\nIn the final kernel, this code is not gonna be available 'cause it takes too much time to run this parts of code.\nThe summary will be written below the function."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#### function to create model\ndef create_model(optimizer='adam'):\n    model = Sequential()\n    model.add(Dense(10, input_dim=11, activation='tanh'))\n    model.add(Dropout(0.1))\n    model.add(Dense(5, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(3, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss = 'binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    return model\n\n#### create model\nmodel = KerasClassifier(build_fn=create_model, epochs=50, batch_size=50, verbose=0)\n\n#### define the parameters to search in grid search \noptimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\nparam_grid = dict(optimizer=optimizer)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\ngrid_result = grid.fit(x_training, y_training)\n\n#### summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))"},{"metadata":{},"cell_type":"markdown","source":"**Results:** \n* Best: 0.708232 using {**'optimizer': 'Nadam'**}\n* 0.639339 (0.003833) with: {'optimizer': 'SGD'}\n* 0.685446 (0.014199) with: {'optimizer': 'RMSprop'}\n* 0.644750 (0.004682) with: {'optimizer': 'Adagrad'}\n* 0.664732 (0.011830) with: {'optimizer': 'Adadelta'}\n* 0.676821 (0.017248) with: {'optimizer': 'Adam'}\n* 0.653625 (0.003463) with: {'optimizer': 'Adamax'}\n* 0.708232 (0.010960) with: {'optimizer': 'Nadam'}"},{"metadata":{},"cell_type":"markdown","source":"## Optimization of SGD algorithm (Learnig Rate and Momentum)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#### function to create model\ndef create_model(learn_rate=0.01, momentum=0):\n    model = Sequential()\n    model.add(Dense(10, input_dim=11, activation='tanh'))\n    model.add(Dropout(0.1))\n    model.add(Dense(5, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(3, activation='relu'))\n    model.add(Dropout(0.1))\n    model.add(Dense(1, activation='sigmoid'))\n    optimizer = SGD(lr=learn_rate, momentum=momentum)\n    model.compile(loss = 'binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    return model\n\n#### create model\nmodel = KerasClassifier(build_fn=create_model, epochs=50, batch_size=50, verbose=0)\n\n#### define the parameters to search in grid search \nlearn_rate = [0.01, 0.1, 0.2]\nmomentum = [0.2, 0.6, 0.9]\nparam_grid = dict(learn_rate=learn_rate, momentum=momentum)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\ngrid_result = grid.fit(x_training, y_training)\n\n#### summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))"},{"metadata":{},"cell_type":"markdown","source":"**Results:** \n* Best: 0.642571 using {**'learn_rate': 0.01, 'momentum': 0.2**}\n* 0.642571 (0.004326) with: {'learn_rate': 0.01, 'momentum': 0.2}\n* 0.642375 (0.003565) with: {'learn_rate': 0.01, 'momentum': 0.6}\n* 0.641786 (0.005498) with: {'learn_rate': 0.01, 'momentum': 0.9}\n* 0.586232 (0.069370) with: {'learn_rate': 0.1, 'momentum': 0.2}\n* 0.642089 (0.004087) with: {'learn_rate': 0.1, 'momentum': 0.6}\n* 0.638589 (0.006434) with: {'learn_rate': 0.1, 'momentum': 0.9}\n* 0.498554 (0.005800) with: {'learn_rate': 0.2, 'momentum': 0.2}\n* 0.587482 (0.071161) with: {'learn_rate': 0.2, 'momentum': 0.6}\n* 0.594286 (0.058599) with: {'learn_rate': 0.2, 'momentum': 0.9}"},{"metadata":{},"cell_type":"markdown","source":"## Activation functions"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def create_model(activation='relu'):\n    model = Sequential()\n    model.add(Dense(10, input_dim=11, activation=activation))\n    model.add(Dropout(0.1))\n    model.add(Dense(5, activation=activation))\n    model.add(Dropout(0.1))\n    model.add(Dense(3, activation=activation))\n    model.add(Dropout(0.1))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss = 'binary_crossentropy', optimizer=\"Nadam\", metrics=['accuracy'])\n    return model\n\n#### create model\nmodel = KerasClassifier(build_fn=create_model, epochs=50, batch_size=50, verbose=0)\n\n#### define the parameters to search in grid search \nactivation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\nparam_grid = dict(activation=activation)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\ngrid_result = grid.fit(x_training, y_training)\n\n#### summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))"},{"metadata":{},"cell_type":"markdown","source":"**Results:** \n* Best: 0.717250 using {**'activation': 'softsign'**}\n* 0.649786 (0.005472) with: {'activation': 'softmax'}\n* 0.649464 (0.005333) with: {'activation': 'softplus'}\n* 0.717250 (0.006675) with: {'activation': 'softsign'}\n* 0.701964 (0.021487) with: {'activation': 'relu'}\n* 0.717179 (0.002289) with: {'activation': 'tanh'}\n* 0.648446 (0.006001) with: {'activation': 'sigmoid'}\n* 0.651750 (0.004286) with: {'activation': 'hard_sigmoid'}\n* 0.709232 (0.015933) with: {'activation': 'linear'}"},{"metadata":{},"cell_type":"markdown","source":"## Dropout Rate and Weight Constraint"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"from keras.layers import Dropout\nfrom keras.constraints import maxnorm\n\n#### function to create model\ndef create_model(dropout_rate=0.0, weight_constraint=0):\n    model = Sequential()\n    model.add(Dense(10, input_dim=11, activation='softsign', kernel_constraint=maxnorm(weight_constraint)))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(5, activation='softsign'))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(3, activation='softsign'))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss = 'binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n    return model\n\n#### create model\nmodel = KerasClassifier(build_fn=create_model, epochs=50, batch_size=50, verbose=0)\n\n#### define the parameters to search in grid search \nweight_constraint = [0, 1, 2]\ndropout_rate = [0.0, 0.1, 0.2]\nparam_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\ngrid_result = grid.fit(x_training, y_training)\n\n#### summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))"},{"metadata":{},"cell_type":"markdown","source":"**Results:**\n* Best: 0.701179 using {**'dropout_rate': 0.0, 'weight_constraint': 2**}\n* 0.500839 (0.005918) with: {'dropout_rate': 0.0, 'weight_constraint': 0}\n* 0.651839 (0.005446) with: {'dropout_rate': 0.0, 'weight_constraint': 1}\n* 0.701179 (0.010650) with: {'dropout_rate': 0.0, 'weight_constraint': 2}\n* 0.500446 (0.005961) with: {'dropout_rate': 0.1, 'weight_constraint': 0}\n* 0.648250 (0.007944) with: {'dropout_rate': 0.1, 'weight_constraint': 1}\n* 0.684536 (0.022927) with: {'dropout_rate': 0.1, 'weight_constraint': 2}\n* 0.500304 (0.005970) with: {'dropout_rate': 0.2, 'weight_constraint': 0}\n* 0.649732 (0.002889) with: {'dropout_rate': 0.2, 'weight_constraint': 1}\n* 0.666893 (0.011692) with: {'dropout_rate': 0.2, 'weight_constraint': 2}"},{"metadata":{},"cell_type":"markdown","source":"## Number of neurons in the first layer"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def create_model(neurons=1):\n    model = Sequential()\n    model.add(Dense(neurons, input_dim=11, activation='softsign', kernel_constraint=maxnorm(2)))\n    model.add(Dropout(0))\n    model.add(Dense(5, activation='softsign'))\n    model.add(Dropout(0))\n    model.add(Dense(3, activation='softsign'))\n    model.add(Dropout(0))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss = 'binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n    return model\n\n#### create model\nmodel = KerasClassifier(build_fn=create_model, epochs=50, batch_size=50, verbose=0)\n\n#### define the parameters to search in grid search \nneurons = [1, 5, 10, 15, 20, 25, 30]\nparam_grid = dict(neurons=neurons)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\ngrid_result = grid.fit(x_training, y_training)\n\n#### summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))"},{"metadata":{},"cell_type":"markdown","source":"**Results:**\n* Best: 0.703107 using {**'neurons': 25**}\n* 0.683607 (0.003922) with: {'neurons': 1}\n* 0.700411 (0.003911) with: {'neurons': 5}\n* 0.694625 (0.009716) with: {'neurons': 10}\n* 0.699536 (0.009807) with: {'neurons': 15}\n* 0.698893 (0.013422) with: {'neurons': 20}\n* 0.703107 (0.014787) with: {'neurons': 25}\n* 0.688821 (0.026863) with: {'neurons': 30}"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}