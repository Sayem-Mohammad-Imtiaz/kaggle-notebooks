{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **HR Analytics: WHO IS LOOKING FOR THE DOOR?**"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://media.giphy.com/media/xThtadLubOnwcA43V6/giphy.gif\">"},{"metadata":{},"cell_type":"markdown","source":"**In this notebook, firstly I will look for any missing variables, fixing tweaks here or there. Secondly, I will visualize the processed data to see the relation between columns, then I will drop the unnecessary columns. Finally I will apply different models to data and we will see how it is going to turn out!**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/hr-analytics-job-change-of-data-scientists/aug_train.csv')\ntest = pd.read_csv('/kaggle/input/hr-analytics-job-change-of-data-scientists/aug_test.csv')\nsample = pd.read_csv('/kaggle/input/hr-analytics-job-change-of-data-scientists/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)\nprint(sample.shape)\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking the null values in the training and test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in train:\n    print(column)\n    print(train[column].isnull().sum().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Okay. Some of the columns we do not have any missing variables but in most of them we have a lot. To continue with our analysis I am going to mark these *null* values as Unknown and look at their effects to the outcome."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.fillna('Unknown', inplace = True)\nfor column in train:\n    print(column)\n    print(train[column].isnull().sum().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***City*** will be important to the decision process, probably. BUT it is not usable with the *'city_xx'* form so I need to strip the *'city_'* from the numbers next to it."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['city'] = train['city'].map(lambda x: x.lstrip('city_'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Also ***experience*** and ***last_new_job*** should be important for the outcome, don't you think? I will delete the *'<,>'* symbols in front of them. I do not think the impact of '<,>' is not that important. And also, we should get rid of the 'never' and 'unknown' labels in the ***last_new_job*** column."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['experience'] = train['experience'].map(lambda x: x.lstrip('<>'))\ntrain['last_new_job'] = train['last_new_job'].map(lambda x: x.lstrip('<>'))\ntrain[\"last_new_job\"]= train[\"last_new_job\"].replace('never', 0)\ntrain[\"last_new_job\"]= train[\"last_new_job\"].replace('Unknown', 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, I will look at each category and its effect to the ***target***. By the way, I like to do this with big graphs."},{"metadata":{},"cell_type":"markdown","source":"I always like to do a prediction on my own about the data before I start to analyze it. SO here it is, I do not think *gender, major,company type* will effect the outcome of this situation. We'll see!"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(25,6)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='city', y='target', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='city_development_index', y='target', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='gender', y='target', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I think I was right about the gender. Although there are differences, they are not as important as other categories."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='relevent_experience', y='target', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='enrolled_university', y='target', hue='education_level', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='major_discipline', y='target', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Two for two everybody. I will be dropping the *major discipline*, as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='experience', y='target', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Experience level is a huge difference. We see that early careers tend to change jobs more often than others."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='company_size', y='target', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='company_type', y='target', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The null values that we had in the beginning are making a huge difference right now. I am going to stick with them and act like that is an another category."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='last_new_job', y='target', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I tought this will effect more, not gonna lie there. But it is still valid."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='training_hours', y='target', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are some spikes here or there. Overall, it seems consistent enough in different values to drop this column."},{"metadata":{},"cell_type":"markdown","source":"SO, I am going to drop *gender, major_discipline and training_hours* columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['gender', 'major_discipline', 'training_hours'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we have every information that we need. But it is not usable for models right now. We need to get rid of the string elements. But when we do that by *pandas.get_dummies*, we will have the same named columns called *Unknown*. First, I need to fix that."},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"enrolled_university\"]= train[\"enrolled_university\"].replace('Unknown', 'Unknown_uni')\ntrain[\"education_level\"]= train[\"education_level\"].replace('Unknown', 'Unknown_level')\ntrain[\"experience\"]= train[\"experience\"].replace('Unknown', 0)\ntrain[\"company_size\"]= train[\"company_size\"].replace('Unknown', 'Unknown_size')\ntrain[\"company_type\"]= train[\"company_type\"].replace('Unknown', 'Unknown_type')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**NOW** we can create dummies."},{"metadata":{"trusted":true},"cell_type":"code","source":"experience = pd.get_dummies(train['relevent_experience'], drop_first=True)\nuniversity = pd.get_dummies(train['enrolled_university'], drop_first=False)\neducation = pd.get_dummies(train['education_level'], drop_first=False)\nc_size = pd.get_dummies(train['company_size'], drop_first=False)\nc_type = pd.get_dummies(train['company_type'], drop_first=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['relevent_experience', 'enrolled_university', 'education_level', 'company_size', 'company_type'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.concat([train, experience, university, education, c_size, c_type], axis=1)\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now, our training data is ready for training. But before I start with that, I need to make exact moves with the test data to make them compatible. This is why it is so important to have a nice structure and pipeline with your notebook because you can get confused very easily if you don't.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in test:\n    print(column)\n    print(test[column].isnull().sum().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both dataset has *null* values in the same columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.fillna('Unknown', inplace = True)\n\ntest['city'] = test['city'].map(lambda x: x.lstrip('city_'))\ntest['experience'] = test['experience'].map(lambda x: x.lstrip('<>'))\ntest['last_new_job'] = test['last_new_job'].map(lambda x: x.lstrip('<>'))\ntest[\"last_new_job\"]= test[\"last_new_job\"].replace('never', 0)\ntest[\"last_new_job\"]= test[\"last_new_job\"].replace('Unknown', 0)\n\ntest = test.drop(['gender', 'major_discipline', 'training_hours'], axis=1)\ntest[\"enrolled_university\"]= test[\"enrolled_university\"].replace('Unknown', 'Unknown_uni')\ntest[\"education_level\"]= test[\"education_level\"].replace('Unknown', 'Unknown_level')\ntest[\"experience\"]= test[\"experience\"].replace('Unknown', 0)\ntest[\"company_size\"]= test[\"company_size\"].replace('Unknown', 'Unknown_size')\ntest[\"company_type\"]= test[\"company_type\"].replace('Unknown', 'Unknown_type')\n\nexperience_test = pd.get_dummies(test['relevent_experience'], drop_first=True)\nuniversity_test = pd.get_dummies(test['enrolled_university'], drop_first=False)\neducation_test = pd.get_dummies(test['education_level'], drop_first=False)\nc_size_test = pd.get_dummies(test['company_size'], drop_first=False)\nc_type_test = pd.get_dummies(test['company_type'], drop_first=False)\n\ntest = test.drop(['relevent_experience', 'enrolled_university', 'education_level', 'company_size', 'company_type'], axis=1)\ntest = pd.concat([test, experience_test, university_test, education_test, c_size_test, c_type_test], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We are good to go.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train.drop(['target'], axis=1)\ny = train['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**LOGISTIC REGRESSION**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogistic = LogisticRegression()\nlogistic.fit(x_train, y_train)\nprediction_lr = logistic.predict(x_test)\nprint(classification_report(y_test,prediction_lr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DECISION TREE**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier()\ntree.fit(x_train, y_train)\nprediction_dt = tree.predict(x_test)\nprint(classification_report(y_test, prediction_dt))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**RANDOM FOREST**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nforest = RandomForestClassifier()\nforest.fit(x_train, y_train)\nprediction_rf = forest.predict(x_test)\nprint(classification_report(y_test, prediction_rf))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although it is clear which model is more successfull. I like to look at their ROC curves to be sure."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(8,5)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.plot_roc_curve(logistic, x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.plot_roc_curve(tree, x_test, y_test) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.plot_roc_curve(forest, x_test, y_test) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I have applied three different machine learning methods to the data. Random Forest Classifier seem to be the most successful out of them. Random Forest achieved %83 precision, %88 recall and 0.78 AUC scores. Which is not perfect but I think we can call it a successful classification."},{"metadata":{},"cell_type":"markdown","source":"**That is it for this notebook. I hope you liked it. Let me know what you think, feedbacks are appreciated.**"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://media.giphy.com/media/xUPOqo6E1XvWXwlCyQ/giphy.gif\">"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}