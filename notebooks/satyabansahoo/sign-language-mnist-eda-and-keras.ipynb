{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Sign Language Alphabets\nSign language is a visual means of communicating through hand signals, gestures, facial expressions, and body language. It’s the main form of communication for the Deaf and Hard-of-Hearing community, but sign language can be useful for other groups of people as well. People with disabilities including Autism, Apraxia of speech, Cerebral Palsy, and Down Syndrome may also find sign language beneficial for communicating.\n\n## Basics of Alphabets and Fingerspelling\nMost people start their sign language journey by learning the A-Z or alphabet equivalent in sign form.\n\nThe use of the hands to represent individual letters of a written alphabet is called ‘fingerspelling’. It’s an important tool that helps signers manually spell out names of people, places and things that don’t have an established sign.\n\nFor example, most sign languages have a specific sign for the word tree, but may not have a specific sign for oak, so o-a-k would be finger spelled to convey that specific meaning.\n\nOf course, not every language uses the Latin alphabet like English, so their sign language alphabet differs as well. Some manual alphabets are one-handed, such as in ASL and French Sign Language, and others use two-hands, like BSL or Auslan. Though there are similarities between some of the different manual alphabets, each sign language has its own style and modifications, and remains unique.\n\n## American Sign Language (ASL)\nAlthough ASL has the same alphabet as English, ASL is not a subset of the English language. American Sign Language was created independently and it has its own linguistic structure. \nSigns are also not expressed in the same order as words are in English. This is due to the unique grammar and visual nature of the sign language. ASL is used by roughly half a million people in the USA.\n\n![Image](https://www.ai-media.tv/wp-content/uploads/2020/09/ASL_Alphabet.jpg)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Loading the packages\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport numpy as np\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading the data\ntrain = pd.read_csv(\"../input/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv\")\ntest = pd.read_csv(\"../input/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting for the label having more than 1200 rows.\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(14,7))\ng = sns.countplot(train['label'], color='lightgrey')\n\nfor p in g.patches:\n    g.annotate('{:.0f}'.format(p.get_height()), (p.get_x(), p.get_height()+10))\n    if p.get_height() > 1200:\n        p.set_color('blue')\ng.set_ylabel('')    \ng.set_xlabel('')\ng.axes.get_yaxis().set_visible(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data splitting and PreProcessing \ntraining_images = train.iloc[:,1:].values\ntraining_labels = train.iloc[:,0].values\n\ntesting_images = test.iloc[:,1:].values\ntesting_labels = test.iloc[:,0].values\n\ntraining_images = training_images.reshape(-1,28,28,1)\ntesting_images = testing_images.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the first 10 images \nfig, ax = plt.subplots(2,5) \nfig.set_size_inches(10, 10)\nk = 0\nfor i in range(2):\n    for j in range(5):\n        ax[i,j].imshow(training_images[k].reshape(28, 28) , cmap = \"gray\")\n        k += 1\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n                                 width_shift_range=0.2,\n                                 height_shift_range=0.2,\n                                 rotation_range=40,\n                                 fill_mode='nearest',\n                                 zoom_range=0.2,\n                                 shear_range=0.2,\n                                 horizontal_flip=True)\n\nvalidation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Building for the data\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\nfrom tensorflow.keras.optimizers import RMSprop\n\nmodel = Sequential([\n    Conv2D(64, (3,3), activation='relu', input_shape=(28,28,1)),\n    MaxPooling2D(2,2),\n    Conv2D(128, (3,3), activation='relu'),\n    Flatten(),\n    Dropout(0.5),\n    Dense(512, activation='relu'),\n    Dense(25,activation='softmax')\n])\n\nmodel.compile(optimizer = 'adam',\n              loss='sparse_categorical_crossentropy',\n             metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow(training_images, training_labels)\nvalid_generator = validation_datagen.flow(testing_images, testing_labels)\n\nhistory = model.fit(train_generator,\n                    epochs=15,\n                    verbose=1,\n                   validation_data = valid_generator)\n\nmodel.evaluate(testing_images, testing_labels, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Here, we are getting an **accuracy - 72%** for the model evaluation."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the chart for accuracy and loss on both training and validation\n%matplotlib inline\nimport matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions \npredictions = model.predict_classes(testing_images)\nfor i in range(len(predictions)):\n    if(predictions[i] >= 9):\n        predictions[i] += 1\npredictions[:5]   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Precision, recall, f1-score for all the classes\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nclasses = [\"Class \" + str(i) for i in range(26) if i != 9]\nprint(classification_report(test['label'], predictions, target_names = classes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion Matrix for the model predictions\ncm = confusion_matrix(test['label'],predictions)\n\nplt.figure(figsize=(12,7))\ng = sns.heatmap(cm, cmap='Reds',annot=True,\n           fmt='')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Here, the predictions have some wrong predictions.\n* Highest predictions - 12 Label"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}