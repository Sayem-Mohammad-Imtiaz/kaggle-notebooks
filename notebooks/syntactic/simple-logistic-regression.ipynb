{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"477baa5d-ead3-4d6f-8472-146251aaf90a"},"source":"This is my first notebook. I'm getting to know scikit-learn and pandas. I've applied no tuning parameters to logistic regression except a value of 100000 for C, the inverse of regularization s"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"24d4258f-ca71-5d0a-1616-5fb393bd8504"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"48939398-725e-e941-06a7-c728af51b191"},"outputs":[],"source":"all_data = pd.read_csv(\"../input/voice.csv\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"28fced8f-4fd6-fa8a-998c-3dbf7736272b"},"source":"Dividing the dataset into train and test\n----------------------------------------"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c2c1e516-fd63-01cc-83c8-165532a2e3dc"},"outputs":[],"source":"rand_indices = np.random.permutation(len(all_data))\nfeatures = [feat for feat in all_data.columns if feat != 'label']\noutput = 'label'\nnum_datapoints = len(all_data)\ntest_total = int(num_datapoints * 0.1)\n\ntest_indices = rand_indices[-test_total:]\ntrain_indices = rand_indices[:-test_total]\n\ntest_data = all_data[features].iloc[test_indices]\ntrain_data = all_data[features].iloc[train_indices]\n\ntest_labels = all_data[output].iloc[test_indices]\ntrain_labels = all_data[output].iloc[train_indices]\n\nprint(num_datapoints, len(train_data), len(test_data))\nprint(features)\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"6be01548-1bcf-d1c7-2116-3def4236e9ef"},"source":"Building the model, examining weights\n====================================="},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b4dd1e71-c101-247a-3f2f-ea6218180c98"},"outputs":[],"source":"from sklearn import linear_model\nlogistic = linear_model.LogisticRegression(C=1e5)\n\nlogistic.fit(train_data, train_labels)\nfor i, f in enumerate(features):\n    print(features[i], logistic.coef_[0][i])"},{"cell_type":"markdown","metadata":{"_cell_guid":"9c10f342-68cb-6929-4e94-7027dabe19ed"},"source":"Calculating Error Rate\n======================"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"afd157fe-f4eb-a7c5-4b41-eb489f03702c"},"outputs":[],"source":"predictions = logistic.predict(test_data)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(test_labels, predictions)\n#[predictions[i] != test_labels.iloc[i] for i in range(len(predictions))]"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}