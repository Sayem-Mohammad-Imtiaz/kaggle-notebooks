{"cells":[{"metadata":{"trusted":true,"collapsed":true,"_uuid":"cc79fa85a72f5c16da265ad3ca6f8d26573449dd"},"cell_type":"markdown","source":"# Overview\nThe notebook shows how to correctly load, process and interpret the information in the DeepLesion study. The notebook also previews some of the images overlayed with the bounding boxes and converts the bounding boxes into segmented regions to allow for the simple experiments to try and automatically detect and segment lesions. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"%matplotlib inline\nfrom glob import glob\nimport os, pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nimport seaborn as sns\nfrom skimage.util.montage import montage2d as montage\nfrom matplotlib.collections import PatchCollection\nfrom matplotlib.patches import Rectangle\n# make the necessary conversion\nread_hu = lambda x: imread(x).astype(np.float32)-32768\nbase_img_dir = '../input/minideeplesion/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3639d62fd4127952e9a71f0b4f9a7a8a78e50713"},"cell_type":"code","source":"patient_df = pd.read_csv('../input/DL_info.csv')\npatient_df['kaggle_dir'] = patient_df.apply(lambda c_row: os.path.join(base_img_dir, \n                                                                        '{Patient_index:06d}_{Study_index:02d}_{Series_ID:02d}'.format(**c_row)), 1)\n\npatient_df['kaggle_path'] = patient_df.apply(lambda c_row: os.path.join('{kaggle_dir}'.format(**c_row),\n                                                                        '{Key_slice_index:03d}.png'.format(**c_row)), 1)\n\nprint('Loaded', patient_df.shape[0], 'cases')\npatient_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f6f2feb8e0d8536779f93989ad580741500e94e"},"cell_type":"code","source":"patient_df['exists'] = patient_df['kaggle_path'].map(os.path.exists)\npatient_df = patient_df[patient_df['exists']].drop('exists', 1)\n# extact the bounding boxes\npatient_df['bbox'] = patient_df['Bounding_boxes'].map(lambda x: np.reshape([float(y) for y in x.split(',')], (-1, 4)))\npatient_df['norm_loc'] = patient_df['Normalized_lesion_location'].map(lambda x: np.reshape([float(y) for y in x.split(',')], (-1)))\npatient_df['Slice_range'] = patient_df['Slice_range'].map(lambda x: [int(y) for y in x.split(',')])\npatient_df['Spacing_mm_px_'] = patient_df['Spacing_mm_px_'].map(lambda x: np.reshape([float(y) for y in x.split(',')], (-1)))\npatient_df['Lesion_diameters_Pixel_'] = patient_df['Lesion_diameters_Pixel_'].map(lambda x: np.reshape([float(y) for y in x.split(',')], (-1)))\npatient_df['Radius_x'] = patient_df.apply(lambda x: x['Lesion_diameters_Pixel_'][0]*x['Spacing_mm_px_'][0], 1)\nfor i, ax in enumerate('xyz'):\n    patient_df[f'{ax}_loc'] = patient_df['norm_loc'].map(lambda x: x[i])\nprint('Found', patient_df.shape[0], 'patients with images')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3955b6c0439d282e37b243eda208e29a1944862b"},"cell_type":"markdown","source":"## Get the 3D information\nSo now we can load the 3D information since each lesion corresponds to a stack of images. We exclude any files that are missing to make our life loading the images later easier."},{"metadata":{"trusted":true,"_uuid":"e35f43a4ee7f372e78ce6c85787e49c3d33d290e"},"cell_type":"code","source":"patient_df['kaggle_stack'] = patient_df.apply(lambda c_row: [os.path.join('{kaggle_dir}'.format(**c_row),\n                                                                        '{:03d}.png'.format(i)) for i in range(c_row['Slice_range'][0],\n                                                                                                              c_row['Slice_range'][1]+1)], 1)\npatient_df['kaggle_stack'] = patient_df['kaggle_stack'].map(lambda file_list: [file_path for file_path in file_list if os.path.exists(file_path)])\n# show the stack size\npatient_df['kaggle_stack'].map(len).hist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"302157c6e4cacde63a358b810cd8d7cccfafa20a"},"cell_type":"markdown","source":"# Draw Image and  Bounding Box\nHere we use basic code to draw the image and the bounding box. We use the Lung window for the CT to make the views as consistent as possible"},{"metadata":{"trusted":true,"_uuid":"83889a0aa9cfb789115ca753c87414207ec2217e","collapsed":true},"cell_type":"code","source":"from skimage.segmentation import mark_boundaries\napply_softwindow = lambda x: (255*plt.cm.gray(0.5*np.clip((x-50)/350, -1, 1)+0.5)[:, :, :3]).astype(np.uint8)\n\ndef create_boxes(in_row):\n    box_list = []\n    for (start_x, start_y, end_x, end_y) in in_row['bbox']:\n        box_list += [Rectangle((start_x, start_y), \n                         np.abs(end_x-start_x),\n                         np.abs(end_y-start_y)\n                         )]\n    return box_list\ndef create_segmentation(in_img, in_row):\n    yy, xx = np.meshgrid(range(in_img.shape[0]),\n               range(in_img.shape[1]),\n               indexing='ij')\n    out_seg = np.zeros_like(in_img)\n    for (start_x, start_y, end_x, end_y) in in_row['bbox']:\n        c_seg = (xx<end_x) & (xx>start_x) & (yy<end_y) & (yy>start_y)\n        out_seg+=c_seg\n    return np.clip(out_seg, 0, 1).astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e6bde5aafa6c87d280f9255bf26fe18f7aa69d9"},"cell_type":"code","source":"_, test_row = next(patient_df.sample(1, random_state=0).iterrows())\nfig, m_axs = plt.subplots(3, 4, figsize = (25, 14))\n[x.axis('off') for x in m_axs.flatten()]\nfor ax1, c_path in zip(m_axs.flatten(), test_row['kaggle_stack']):\n    c_img = read_hu(c_path)\n    ax1.imshow(c_img, vmin = -1200, vmax = 600, cmap = 'gray')\n    ax1.add_collection(PatchCollection(create_boxes(test_row), alpha = 0.25, facecolor = 'red'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e530f8e1175038f286707c2c2b040333f6f0395b"},"cell_type":"markdown","source":"# Collect all Segmentations"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a2021992882dffd7cc819b12f4f0389955f72e5d"},"cell_type":"code","source":"from skimage.transform import resize\nimport warnings\ndef smart_stack(in_list, *args, **kwargs):\n    \"\"\"\n    Use the first element to determine the size for all the results and resize the ones that dont match\n    \"\"\"\n    base_shape = in_list[0].shape\n    return np.stack([x if x.shape==base_shape else resize(x, base_shape, preserve_range=True) for x in in_list], *args, **kwargs)\n# utility functions compied from https://github.com/4Quant/pyqae\ndef _dsum(carr,  # type: np.ndarray\n          cax  # type: int\n          ):\n    # type: (...) -> np.ndarray\n    \"\"\"\n    Sums the values along all other axes but the current\n    \"\"\"\n    return np.sum(carr, tuple(n for n in range(carr.ndim) if n is not cax))\n\ndef get_bbox(in_vol,\n             min_val=0):\n    # type: (np.ndarray, float) -> List[Tuple[int,int]]\n    \"\"\"\n    Calculate a bounding box around an image in every direction\n    \"\"\"\n    ax_slice = []\n    for i in range(in_vol.ndim):\n        c_dim_sum = _dsum(in_vol > min_val, i)\n        wh_idx = np.where(c_dim_sum)[0]\n        c_sl = sorted(wh_idx)\n        if len(wh_idx) == 0:\n            ax_slice += [(0, 0)]\n        else:\n            ax_slice += [(c_sl[0], c_sl[-1] + 1)]\n    return ax_slice\n\n\ndef apply_bbox(in_vol,  # type: np.ndarray\n               bbox_list,  # type: List[Tuple[int,int]]\n               pad_values=False,\n               padding_mode='edge'\n               ):\n    # type: (...) -> np.ndarray\n    \"\"\"\n    Apply a bounding box to an image\n    \"\"\"\n\n    if pad_values:\n        # TODO test padding\n        warnings.warn(\"Padded apply_bbox not fully tested yet\", RuntimeWarning)\n        n_pads = []  # type: List[Tuple[int,int]]\n        n_bbox = []  # type: List[Tuple[int,int]]\n        for dim_idx, ((a, b), dim_size) in enumerate(zip(bbox_list,\n                                                         in_vol.shape)):\n            a_pad = 0 if a >= 0 else -a\n            b_pad = 0 if b < dim_size else b - dim_size + 1\n            n_pads += [(a_pad, b_pad)]\n            n_bbox += [(a + a_pad, b + a_pad)]  # adjust the box\n\n        while len(n_pads)<len(in_vol.shape):\n            n_pads += [(0,0)]\n        # update the volume\n        in_vol = np.pad(in_vol, n_pads, mode=padding_mode)\n        # update the bounding box list\n        bbox_list = n_bbox\n\n    return in_vol.__getitem__([slice(a, b, 1) for (a, b) in bbox_list])\n\n\ndef autocrop(in_vol,  # type: np.ndarray\n             min_val  # type: double\n             ):\n    # type (...) -> np.ndarray\n    \"\"\"\n    Perform an autocrop on an image by keeping all the points above a value\n    \"\"\"\n    return apply_bbox(in_vol, get_bbox(in_vol,\n                                       min_val=min_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92bb43e41e283d3d6ba4b8aaafea24057ba39f1f"},"cell_type":"code","source":"thumb_list = []\nimg_list = []\nseg_list = []\npath_list = []\nfrom tqdm import tqdm_notebook\nimport gc; gc.enable()\nsave_full_imgs = False # do we keep all of the image\nfor (_, c_row) in tqdm_notebook(patient_df.sample(300).iterrows()):\n    \n    c_img = read_hu(c_row['kaggle_path'])\n    c_seg = create_segmentation(c_img, c_row).astype(bool)\n    c_bbox = get_bbox(c_seg)\n    \n    c_img_list = [read_hu(c_path) for c_path in c_row['kaggle_stack']]\n    \n    img_list+=[np.stack(c_img_list,0)]\n    \n    thumb_list+=[np.stack([apply_bbox(cur_image, c_bbox) \n                         for cur_image in c_img_list],0)]\n    if save_full_imgs:\n        seg_list+=[np.stack([c_seg \n                             for c_path in c_row['kaggle_stack']],0)]\n        path_list+=[c_row['File_name']]\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83b37ed0eded33573d52e889dad1dcabf1d17b0e","collapsed":true},"cell_type":"code","source":"fig, m_axs = plt.subplots(5, 5, figsize = (20, 20))\nfor c_ax, c_stack in zip(m_axs.flatten(), thumb_list):\n    c_ax.imshow(montage(c_stack), cmap = 'bone', vmin = -500, vmax = 400)\n    c_ax.axis('off')\nfig.savefig('many_montage.png', dpi = 300)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b734a1f13a67187492c8e4c2a03ff1bccc00244b"},"cell_type":"markdown","source":"## Show all the lesions in one view"},{"metadata":{"trusted":true,"_uuid":"3b878c53d4be83e853d916a1ea6bd3f3bf55f8e1","collapsed":true},"cell_type":"code","source":"all_lesions = smart_stack(thumb_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"541d53f16a2709379f6333bef7a63b3b956fed13","collapsed":true},"cell_type":"code","source":"montage_3d = lambda x: montage(np.stack([montage(y) for y in x], 0))\nfig, ax1 = plt.subplots(1, 1, figsize = (15, 15))\nax1.imshow(montage_3d(all_lesions), cmap = 'bone', vmin = -500, vmax = 400)\nfig.savefig('montage.png', dpi = 300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f057901323520e995f2e3f78bd96d0464fee989","collapsed":true},"cell_type":"code","source":"import h5py\nif save_full_imgs:\n    with h5py.File('deeplesion.h5', 'w') as h:\n        h.create_dataset('image', data=np.expand_dims(smart_stack(img_list, 0), -1), \n                         compression = 5)    \n        h.create_dataset('mask', data=np.expand_dims(smart_stack(seg_list, 0), -1).astype(bool), \n                         compression = 5)    \n        h.create_dataset('file_name', data=[x.encode('ascii') for x in path_list], \n                         compression = 0)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84f9823baab6d69d1bbbf3845e559c7f090ba305","collapsed":true},"cell_type":"code","source":"# check the file\n!ls -lh *.h5\nif save_full_imgs:\n    with h5py.File('deeplesion.h5', 'r') as h:\n        for k in h.keys():\n            print(k, h[k].shape, h[k].dtype, h[k].size/1024**2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}