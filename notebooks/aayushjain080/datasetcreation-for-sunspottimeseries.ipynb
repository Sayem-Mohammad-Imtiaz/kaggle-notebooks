{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **TimeSeries DataCreation**","metadata":{"id":"ETN5KR4BT6O_","papermill":{"duration":0.03002,"end_time":"2021-05-10T13:44:53.148435","exception":false,"start_time":"2021-05-10T13:44:53.118415","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"papermill":{"duration":0.055759,"end_time":"2021-05-10T13:44:53.23198","exception":false,"start_time":"2021-05-10T13:44:53.176221","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**In this notebook I have explained how to create Datasetobject for TimeSeries.\nFor training you can refer my notebook** https://www.kaggle.com/aayushjain080/sunspots-prediction-in-time-series-with-keras-lstm **In this notebook I have trained the model with the help of SimpleDNN and By using LSTM & CONV layers.**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"id":"SDcVO4aLSCuk","papermill":{"duration":6.694479,"end_time":"2021-05-10T13:44:59.95816","exception":false,"start_time":"2021-05-10T13:44:53.263681","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/sunspots/Sunspots.csv')","metadata":{"id":"c7GQcHDHin1t","papermill":{"duration":0.059401,"end_time":"2021-05-10T13:45:00.046394","exception":false,"start_time":"2021-05-10T13:44:59.986993","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_series(time, series, format=\"-\", start=0, end=None):\n    plt.plot(time[start:end], series[start:end], format)\n    plt.xlabel(\"Time\")\n    plt.ylabel(\"Value\")\n    plt.grid(True)","metadata":{"id":"aaqESu_GSifH","papermill":{"duration":0.039296,"end_time":"2021-05-10T13:45:00.114039","exception":false,"start_time":"2021-05-10T13:45:00.074743","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time=df['Unnamed: 0'].values\nseries=df['Monthly Mean Total Sunspot Number'].values","metadata":{"id":"m2YoiXHjSUnO","papermill":{"duration":0.049428,"end_time":"2021-05-10T13:45:00.192682","exception":false,"start_time":"2021-05-10T13:45:00.143254","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplot_series(time,series)","metadata":{"id":"ahCd0oK4SUke","outputId":"680ee6b0-710c-4f67-833d-252dfe9ffc8d","papermill":{"duration":0.274809,"end_time":"2021-05-10T13:45:00.497169","exception":false,"start_time":"2021-05-10T13:45:00.22236","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Creating tensorflow dataset object**","metadata":{"id":"8jQA5bpvnlLG","papermill":{"duration":0.032219,"end_time":"2021-05-10T13:45:00.562499","exception":false,"start_time":"2021-05-10T13:45:00.53028","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"* To create dataset for time series prediction we will be using **tensorflow dataset object.**\n\n* **With the help of one example here I have demonstrated how to create datasetobject** .\n\n* Then Following same steps will create dataset object for our time series sunspot data. ","metadata":{"id":"QQ51K660MbI-","papermill":{"duration":0.03173,"end_time":"2021-05-10T13:45:00.625451","exception":false,"start_time":"2021-05-10T13:45:00.593721","status":"completed"},"tags":[]}},{"cell_type":"code","source":"dataset = tf.data.Dataset.range(10) # Creates a Dataset of a step-separated range of values.\nprint('Dataset element specification:', dataset.element_spec) # Each dataset element is a scalar tensor ","metadata":{"id":"CiXyM7jdlNQR","outputId":"9020542b-c6bf-4ee3-8ad0-07b776da7507","papermill":{"duration":0.069334,"end_time":"2021-05-10T13:45:00.72493","exception":false,"start_time":"2021-05-10T13:45:00.655596","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"elements=list(dataset.as_numpy_iterator())# Dataset object consist of 10 elements printing all of this in form of list\nprint(elements)","metadata":{"id":"4N9Hy6ruoLUL","outputId":"b1e4bf7f-5f00-48e9-b932-08bf1f094f9e","papermill":{"duration":0.097686,"end_time":"2021-05-10T13:45:00.853313","exception":false,"start_time":"2021-05-10T13:45:00.755627","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**How to use Window**\n\n* Combines (nests of) input elements into a dataset of (nests of) windows.\n\n**window(size, shift= Defaults to size, stride=1, drop_remainder=False)**\n\n* A \"window\" is a finite dataset of flat elements of size **\"size\"**\n\n* The stride argument determines the stride of the input elements, and the shift argument determines the shift of the window.","metadata":{"id":"os3175ySqT0F","papermill":{"duration":0.032601,"end_time":"2021-05-10T13:45:00.919308","exception":false,"start_time":"2021-05-10T13:45:00.886707","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Example\ndataset = tf.data.Dataset.range(7).window(2)\nfor window in dataset:\n  print(list(window.as_numpy_iterator()))\nprint()  \n\n\n\ndataset = tf.data.Dataset.range(7).window(3, 2, 1, True)\nfor window in dataset:\n  print(list(window.as_numpy_iterator()))\nprint()\n\n\ndataset = tf.data.Dataset.range(7).window(3, 1, 2, True)\nfor window in dataset:\n  print(list(window.as_numpy_iterator()))","metadata":{"id":"F5b2gN9todr1","outputId":"f906db85-9772-4258-b5a8-7eab7f787141","papermill":{"duration":0.116633,"end_time":"2021-05-10T13:45:01.069779","exception":false,"start_time":"2021-05-10T13:45:00.953146","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = tf.data.Dataset.range(10)\ndataset = dataset.window(5, shift=1, drop_remainder=True)\nfor window_dataset in dataset:\n  for val in window_dataset:\n    print(val.numpy(), end=\" \")\n  print()","metadata":{"id":"7v_hY70rqaoU","outputId":"e8aa497c-aae2-43e0-ade3-aef1f61358c9","papermill":{"duration":0.082871,"end_time":"2021-05-10T13:45:01.186457","exception":false,"start_time":"2021-05-10T13:45:01.103586","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = tf.data.Dataset.range(10)\ndataset = dataset.window(5, shift=1, drop_remainder=True)# dataset consist of 6 elements in which each element is compose of 5 scalar tensors  of shape=()\nfor window in dataset:\n  print(list(window.as_numpy_iterator()))","metadata":{"id":"P-MouK7puPOw","outputId":"5f3d4992-5a1c-445f-98eb-0684741a1fb8","papermill":{"duration":0.07388,"end_time":"2021-05-10T13:45:01.294705","exception":false,"start_time":"2021-05-10T13:45:01.220825","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**flat_map_func**- **across this dataset and flattens the result.**\n\n* Use flat_map if you want to make sure that the order of your dataset stays the same. For example, to flatten a dataset of batches into a dataset of their elements:","metadata":{"id":"awK6wVzKvfVZ","papermill":{"duration":0.034591,"end_time":"2021-05-10T13:45:01.363512","exception":false,"start_time":"2021-05-10T13:45:01.328921","status":"completed"},"tags":[]}},{"cell_type":"code","source":"dataset = dataset.flat_map(lambda window: window.batch(5))# dataset consist of 6 elements in which each element is compose of 1d tensors of shape=(5,)\nfor window in dataset:\n  print(window.numpy())","metadata":{"id":"CR7MVwPJuPMA","outputId":"af303c6a-bfb7-4f75-f1b9-83a7148e2d01","papermill":{"duration":0.146397,"end_time":"2021-05-10T13:45:01.542584","exception":false,"start_time":"2021-05-10T13:45:01.396187","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**map_func**\n\n* This transformation applies map_func to each element of this dataset, and returns a new dataset containing the transformed elements, in the same order as they appeared in the input. **map_func** can be used to change both the values and the structure of a dataset's elements. For example, adding 1 to each element, or projecting a subset of element components.","metadata":{"id":"BAwOBkt_v78A","papermill":{"duration":0.033303,"end_time":"2021-05-10T13:45:01.609819","exception":false,"start_time":"2021-05-10T13:45:01.576516","status":"completed"},"tags":[]}},{"cell_type":"code","source":"dataset = tf.data.Dataset.range(10)\ndataset = dataset.window(5, shift=1, drop_remainder=True)\ndataset = dataset.flat_map(lambda window: window.batch(5))\ndataset = dataset.map(lambda window: (window[:-1], window[-1:]))\ndataset = dataset.shuffle(buffer_size=10)     # Randomly shuffles the elements of this dataset.\nfor x,y in dataset:\n  print(x.numpy(), y.numpy())\n","metadata":{"id":"KopratiQuPGp","outputId":"22d795f6-f86c-4ad5-d893-c75315a69dd0","papermill":{"duration":0.136865,"end_time":"2021-05-10T13:45:01.780763","exception":false,"start_time":"2021-05-10T13:45:01.643898","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Batch**\n* Combines consecutive elements of this dataset into batches.\n\n**drop_remainder** \n* A tf.bool scalar tf.Tensor, representing whether the last batch should be dropped in the case it has fewer than batch_size elements; the default behavior is not to drop the smaller batch.","metadata":{"id":"QIy5GPJ0s0Bw","papermill":{"duration":0.033947,"end_time":"2021-05-10T13:45:01.849724","exception":false,"start_time":"2021-05-10T13:45:01.815777","status":"completed"},"tags":[]}},{"cell_type":"code","source":"dataset=tf.data.Dataset.range(10) \ndataset=dataset.batch(3,drop_remainder=True)         \nfor i in dataset:\n  print(i) ","metadata":{"id":"Cj2aKkgesrmJ","outputId":"90143f80-c74c-42d3-ba9b-e2c11a721daa","papermill":{"duration":0.051745,"end_time":"2021-05-10T13:45:01.936043","exception":false,"start_time":"2021-05-10T13:45:01.884298","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**prefetch**\n* Creates a Dataset that prefetches elements from this dataset.\n\n* Most dataset input pipelines should end with a call to prefetch. This allows later elements to be prepared while the current element is being processed. This often improves latency and throughput, at the cost of using additional memory to store prefetched elements.\n\n**Note:** \n* Like other Dataset methods, prefetch operates on the elements of the input dataset. It has no concept of examples vs. batches. examples.prefetch(2) will prefetch two elements (2 examples), while examples.batch(20).prefetch(2) will prefetch 2 elements (2 batches, of 20 examples each).","metadata":{"id":"V36510-Hws3Z","papermill":{"duration":0.034144,"end_time":"2021-05-10T13:45:02.004239","exception":false,"start_time":"2021-05-10T13:45:01.970095","status":"completed"},"tags":[]}},{"cell_type":"code","source":"dataset = tf.data.Dataset.range(10)\ndataset = dataset.window(5, shift=1, drop_remainder=True)\ndataset = dataset.flat_map(lambda window: window.batch(5))\ndataset = dataset.map(lambda window: (window[:-1], window[-1:]))\ndataset = dataset.shuffle(buffer_size=10)\ndataset = dataset.batch(2).prefetch(1)\nfor x,y in dataset:\n  print(\"x = \", x.numpy())\n  print(x.numpy().shape)\n  print(\"y = \", y.numpy())\n  print(y.numpy().shape)","metadata":{"id":"YNtFCcd6vxGZ","outputId":"abe4e516-b799-43d7-eb84-24efc5d202bf","papermill":{"duration":0.091513,"end_time":"2021-05-10T13:45:02.130988","exception":false,"start_time":"2021-05-10T13:45:02.039475","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_time = 3000\ntime_train = time[:split_time]\nx_train = series[:split_time]\ntime_valid = time[split_time:]\nx_valid = series[split_time:]\n\nwindow_size = 30\nbatch_size = 32\nshuffle_buffer_size = 1000","metadata":{"id":"xC4PV6d1SUe3","papermill":{"duration":0.046656,"end_time":"2021-05-10T13:45:02.214376","exception":false,"start_time":"2021-05-10T13:45:02.16772","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def windowed_dataset(series, window_size, batch_size, shuffle_buffer): # Following the above steps created the tensorflow dataset object.\n  dataset = tf.data.Dataset.from_tensor_slices(series)\n  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n  dataset = dataset.batch(batch_size).prefetch(1)\n  return dataset","metadata":{"id":"NgKeXxmUTWe7","papermill":{"duration":0.047059,"end_time":"2021-05-10T13:45:02.297058","exception":false,"start_time":"2021-05-10T13:45:02.249999","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)","metadata":{"id":"Gpkix9RKTZ5N","papermill":{"duration":0.09905,"end_time":"2021-05-10T13:45:02.432856","exception":false,"start_time":"2021-05-10T13:45:02.333806","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The output shape of one element in dataset object is (32, 30) and (32,)**","metadata":{"id":"SFiHVHKjbb3A","papermill":{"duration":0.034801,"end_time":"2021-05-10T13:45:02.504736","exception":false,"start_time":"2021-05-10T13:45:02.469935","status":"completed"},"tags":[]}},{"cell_type":"code","source":"for x,y in dataset:                              \n  #print(x.numpy(), y.numpy())\n  print(x.numpy().shape)    # (32, 30)\n  print(y.numpy().shape)    # (32,)\n  break","metadata":{"id":"12RxPzisTZ1k","outputId":"0b21e7c4-2887-458b-b017-2a592d408879","papermill":{"duration":0.1231,"end_time":"2021-05-10T13:45:02.662846","exception":false,"start_time":"2021-05-10T13:45:02.539746","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Dataset Creation when using Convolution.**","metadata":{"id":"h24ksUe9XMRv","papermill":{"duration":0.035553,"end_time":"2021-05-10T13:45:02.734488","exception":false,"start_time":"2021-05-10T13:45:02.698935","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n    series = tf.expand_dims(series, axis=-1) # Expanding dimension of series ie making it a 2D array\n    ds = tf.data.Dataset.from_tensor_slices(series)\n    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n    ds = ds.shuffle(shuffle_buffer)\n    ds = ds.map(lambda w: (w[:-1], w[-1]))\n    return ds.batch(batch_size).prefetch(1)","metadata":{"id":"W-zB4YiObDSZ","papermill":{"duration":0.046518,"end_time":"2021-05-10T13:45:02.816119","exception":false,"start_time":"2021-05-10T13:45:02.769601","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Breaking above code into parts-**","metadata":{"id":"rwGwqIP4bKEb","papermill":{"duration":0.034993,"end_time":"2021-05-10T13:45:02.886522","exception":false,"start_time":"2021-05-10T13:45:02.851529","status":"completed"},"tags":[]}},{"cell_type":"code","source":"time=df['Unnamed: 0'].values\nseries=df['Monthly Mean Total Sunspot Number'].values","metadata":{"id":"NEkrt1khXtip","papermill":{"duration":0.043994,"end_time":"2021-05-10T13:45:02.966069","exception":false,"start_time":"2021-05-10T13:45:02.922075","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"series = tf.expand_dims(series, axis=-1) \nseries.shape ","metadata":{"id":"tf1eDLp_jsy9","outputId":"dc585603-8f32-4550-90f4-c16ccf1973c6","papermill":{"duration":0.047849,"end_time":"2021-05-10T13:45:03.05023","exception":false,"start_time":"2021-05-10T13:45:03.002381","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"series","metadata":{"id":"ZLPxiX4Fjw4C","outputId":"1519e127-e37a-46a3-b9ca-fce181d73a5a","papermill":{"duration":0.050109,"end_time":"2021-05-10T13:45:03.137452","exception":false,"start_time":"2021-05-10T13:45:03.087343","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = tf.data.Dataset.from_tensor_slices(series)\nfor i in ds:\n  print(i)\n  break","metadata":{"id":"ACA_pG31j4fI","outputId":"0f094608-5653-49d1-8a3e-7a1fbe4808eb","papermill":{"duration":0.050309,"end_time":"2021-05-10T13:45:03.225805","exception":false,"start_time":"2021-05-10T13:45:03.175496","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\nfor window in ds:\n  print(list(window.as_numpy_iterator()))\n  print(len(list(window.as_numpy_iterator())))\n  break","metadata":{"id":"-wdXL3RKj9Lw","outputId":"e00535eb-3398-4fad-9555-fefb4f3e50f2","papermill":{"duration":0.066007,"end_time":"2021-05-10T13:45:03.330346","exception":false,"start_time":"2021-05-10T13:45:03.264339","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = ds.flat_map(lambda w: w.batch(window_size + 1))\nfor window in ds:\n  print(window.numpy())\n  print(window.numpy().shape)\n  break","metadata":{"id":"w9-2Dw2PkQBw","outputId":"164a5e82-25e0-4427-a8b3-0499f74fc3da","papermill":{"duration":0.083546,"end_time":"2021-05-10T13:45:03.451888","exception":false,"start_time":"2021-05-10T13:45:03.368342","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = ds.map(lambda w: (w[:-1], w[-1]))\nfor x,y in ds:\n  print(x.numpy(), y.numpy())\n  break","metadata":{"id":"pbxfwYydlRvC","outputId":"5137f553-9c38-46dc-f887-4b97d4d572c8","papermill":{"duration":0.095475,"end_time":"2021-05-10T13:45:03.586461","exception":false,"start_time":"2021-05-10T13:45:03.490986","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = ds.batch(batch_size).prefetch(1)","metadata":{"id":"nA00HpRVRaq1","papermill":{"duration":0.049282,"end_time":"2021-05-10T13:45:03.675801","exception":false,"start_time":"2021-05-10T13:45:03.626519","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"id":"tEPE4uyWRak0","outputId":"dc87c13e-867a-47c0-c307-e98aa45fe6e6","papermill":{"duration":0.048895,"end_time":"2021-05-10T13:45:03.764071","exception":false,"start_time":"2021-05-10T13:45:03.715176","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The output shape of one element in dataset object is (32, 30, 1) and (32, 1)**","metadata":{"id":"QAwR64PwYizR","papermill":{"duration":0.038735,"end_time":"2021-05-10T13:45:03.841995","exception":false,"start_time":"2021-05-10T13:45:03.80326","status":"completed"},"tags":[]}},{"cell_type":"code","source":"for x,y in dataset:\n  print(x.numpy(), y.numpy())\n  print(x.numpy().shape)    # (32, 30, 1)\n  print(y.numpy().shape)    # (32, 1)\n  break","metadata":{"id":"2jD98fYgRai2","outputId":"d5cc715e-0498-4790-cce6-1b2884717658","papermill":{"duration":0.095095,"end_time":"2021-05-10T13:45:03.977592","exception":false,"start_time":"2021-05-10T13:45:03.882497","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"7rH3imamRagS","papermill":{"duration":0.042593,"end_time":"2021-05-10T13:45:04.065302","exception":false,"start_time":"2021-05-10T13:45:04.022709","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"yAqpUCulTZzM","papermill":{"duration":0.040875,"end_time":"2021-05-10T13:45:04.148394","exception":false,"start_time":"2021-05-10T13:45:04.107519","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}