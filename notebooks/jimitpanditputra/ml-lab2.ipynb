{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\ndf=pd.read_csv(\"../input/latest-covid19-india-statewise-data/Latest Covid-19 India Status.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:00:33.165763Z","iopub.execute_input":"2021-08-10T06:00:33.166177Z","iopub.status.idle":"2021-08-10T06:00:33.273809Z","shell.execute_reply.started":"2021-08-10T06:00:33.166144Z","shell.execute_reply":"2021-08-10T06:00:33.272805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:00:48.420775Z","iopub.execute_input":"2021-08-10T06:00:48.421342Z","iopub.status.idle":"2021-08-10T06:00:48.467774Z","shell.execute_reply.started":"2021-08-10T06:00:48.421309Z","shell.execute_reply":"2021-08-10T06:00:48.466889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:02:55.150175Z","iopub.execute_input":"2021-08-10T06:02:55.150556Z","iopub.status.idle":"2021-08-10T06:02:55.170795Z","shell.execute_reply.started":"2021-08-10T06:02:55.150526Z","shell.execute_reply":"2021-08-10T06:02:55.169915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Since the dataset doesnâ€™t have null values or missing places no need of handling the\nYet the way to do so is as follows:\n","metadata":{}},{"cell_type":"code","source":"\n\n\ndf['Deaths'].replace(np.NaN,df['Deaths'].mean)","metadata":{"execution":{"iopub.status.busy":"2021-08-10T07:16:50.458466Z","iopub.execute_input":"2021-08-10T07:16:50.459037Z","iopub.status.idle":"2021-08-10T07:16:50.467428Z","shell.execute_reply.started":"2021-08-10T07:16:50.458985Z","shell.execute_reply":"2021-08-10T07:16:50.46666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"raw","source":"#Now Performimg Label Encoding\n","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder=LabelEncoder()  #Creating instance\ndf[\"State_No\"]=labelencoder.fit_transform(df[\"State/UTs\"]) #new numerical column\ndf","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:11:06.36851Z","iopub.execute_input":"2021-08-10T06:11:06.368885Z","iopub.status.idle":"2021-08-10T06:11:07.295228Z","shell.execute_reply.started":"2021-08-10T06:11:06.368851Z","shell.execute_reply":"2021-08-10T06:11:07.294089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now Performing One-Hot Encoding","metadata":{}},{"cell_type":"code","source":"ode_df=pd.get_dummies(df['State/UTs'])\node_df\n","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:30:35.598234Z","iopub.execute_input":"2021-08-10T06:30:35.598606Z","iopub.status.idle":"2021-08-10T06:30:35.63602Z","shell.execute_reply.started":"2021-08-10T06:30:35.598569Z","shell.execute_reply":"2021-08-10T06:30:35.634994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Performimg Standardization","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\ndf2 = df.copy()\nnum_cols = ['Total Cases','Active','Discharged','Deaths'] # numerical features\nfor i in num_cols:  # apply standardization on numerical features\n    scale = StandardScaler().fit(df2[[i]])     # fit on training data column\n    df2[i] = scale.transform(df2[[i]]) # transform the training data column\ndf2  #standardized dataframe\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:50:17.854875Z","iopub.execute_input":"2021-08-10T06:50:17.855219Z","iopub.status.idle":"2021-08-10T06:50:17.916399Z","shell.execute_reply.started":"2021-08-10T06:50:17.855191Z","shell.execute_reply":"2021-08-10T06:50:17.915318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#now Performing Normalization","metadata":{}},{"cell_type":"code","source":"# data normalization with sklearn\nfrom sklearn.preprocessing import MinMaxScaler\ndf3=df[['Total Cases','Active','Discharged','Deaths','State_No']]\n\nnorm = MinMaxScaler().fit(df3)    # fit scaler on data\n# transform data\ndf_norm = norm.transform(df3)\ndf_norm\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-10T06:58:04.396884Z","iopub.execute_input":"2021-08-10T06:58:04.397271Z","iopub.status.idle":"2021-08-10T06:58:04.414045Z","shell.execute_reply.started":"2021-08-10T06:58:04.397241Z","shell.execute_reply":"2021-08-10T06:58:04.412983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}