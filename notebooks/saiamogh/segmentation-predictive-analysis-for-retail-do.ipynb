{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Segmentation & Predictive Analysis For Retail Domain\n\nThis dataset has data from 1/12/2009 to 09/12/2011 (2 Years) and stock is mostly all-occation gift-ware and customers are mostly into wholesale \n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import Packages\n\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import scale,StandardScaler\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Loading the data into dataframe\ndf = pd.read_csv('/kaggle/input/online-retail-ii-uci/online_retail_II.csv',sep=',',\n    header='infer')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing Missing values based on customer id \n\nprint(df.isnull().sum())\ndf.dropna(subset=['Customer ID'],inplace= True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unique values for each column\ndf.nunique().reset_index(name ='Unique Values')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Country distribution by %\n\ncountry_count = df['Country'].value_counts().sort_values(ascending = False).reset_index(name = 'Count').rename(columns = {'index':'Country'})\n\ncountry_count['%'] = country_count['Count'].div(np.sum(country_count['Count']))*100\n\ncountry_count['Major Country Name'] = country_count[['%','Country']].apply( lambda x : 'Others' if( x['%'] < 1) else x['Country'],axis=1)\n\nsns.barplot(y=country_count['Major Country Name'],x=country_count['%'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Price Distribution\n\nsns.distplot(df['Price'],bins = 50,rug=True,hist=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Price range is very varied and there some extream values in prices, So we have to do normalization to reduce the varied effect.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['Quantity','Price']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looks like there -ne quantity values, they may be refunds or data quality issue, I am discarding them for now\n\ndf = df[df['Quantity'] > 0] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['Quantity','Price']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=df['Price'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[(df['Price'] >= 500) & (df['Price'] <= 1000)]['Description'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Droping the above Description variables can be one options but this will lead to data loss\n\ndf['Revenue'] = df['Quantity'] * df['Price']\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Segmentation in retail is usually done quarterly ,half-yearly and yearly.\n## In this usecase,I will do Yearly, Same thing can be appled to others"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ = df[df['InvoiceDate'] < '2010-12-01']\nRFM = pd.DataFrame()\nmax_date = pd.to_datetime(max(df_['InvoiceDate']))\nRFM[['Customer ID','Recency','Frequency','Monetary Value']] = df_[['Customer ID','Revenue','Invoice','InvoiceDate']].groupby('Customer ID').agg({'InvoiceDate':'min','Invoice':'nunique','Revenue':'sum'}).reset_index().rename(columns={'Invoice':'Frequency'})\nRFM['Recency'] = (max_date - pd.to_datetime(RFM['Recency'])).dt.days","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quantiles = RFM.quantile(q=[0.20,0.4,0.6,0.8])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def recency(data,column):\n    rule =[]\n    for row in data[column]:\n        if row <= quantiles[column][0.2]:\n            rule.append(5)\n        elif  row <=  quantiles[column][0.4]:\n            rule.append(4)\n        elif row <=  quantiles[column][0.6]:\n            rule.append(3) \n        elif  row <=  quantiles[column][0.8]:\n            rule.append(2)\n        else:\n            rule.append(1)\n\n    return rule\n\ndef fm(data,column):\n    rule = []\n    for row in data[column]:\n        if row <= quantiles[column][0.2]:\n            rule.append(1)\n        elif  row <= quantiles[column][0.4]:\n            rule.append(2)\n        elif row <= quantiles[column][0.6]:\n            rule.append(3)\n        elif row <= quantiles[column][0.8]:\n            rule.append(4)   \n        else:\n            rule.append(5)\n\n    return rule","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFM['Recency Score'] = recency(data=RFM ,column='Recency')\nRFM['Frequency Score'] = fm(data=RFM ,column='Frequency')\nRFM['Monetary Score'] = fm(data=RFM ,column='Monetary Value')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFM['Score'] = RFM['Recency Score'].map(str) + RFM['Frequency Score'].map(str) + RFM['Monetary Score'].map(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFM.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Two well know clusters Methods are Kmeans & Density Based Cluserting(DBSCAN)\n# I am using kmeans clustering to find the Main Segments\n## Before Doing kmeans we have to normalize the data, to reduce the effect of variation in the data \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"RFM_norm = scale(RFM.iloc[:,1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Elbow ={}\nsilhouette ={}\nfor k in range(2,11):\n    k_mean = KMeans(n_clusters=k, init='k-means++', n_init=10, max_iter=1000, tol=0.0001)\n    k_mean.fit(RFM_norm)\n    lables = k_mean.labels_\n    Elbow[k] = k_mean.inertia_\n    silhouette[k] = silhouette_score(RFM_norm,lables,metric='euclidean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Elbow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# k vs inertia(WSS)\nsns.lineplot(x = [i for i in Elbow.keys()] ,y =[i for i in Elbow.values()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Elbow method :- Calculates the within-cluster-sum-of-squares error (Total Variance for each k value )\n# k = 3 | 4 is unclear so we need to look at another metric called silhouette measure\n# Silhouette measure (b - a) / max(a, b) :- Calculates how similar a point is within the cluster and to other clusters [-1,+1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# k vs silhouette\nsns.lineplot(x = [i for i in silhouette.keys()] ,y =[i for i in silhouette.values()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from the above we can deside that 3 clusters are optimal for this dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k_mean = KMeans(n_clusters=3, init='k-means++', n_init=10, max_iter=1000, tol=0.0001)\nk_mean.fit(RFM_norm)\ny = k_mean.predict(RFM_norm)\nRFM['Cluster'] = y\nRFM['Cluster Names'] = y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFM[RFM['Cluster'] ==0].iloc[:,1:].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFM[RFM['Cluster'] == 1].iloc[:,1:].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RFM[RFM['Cluster'] == 2].iloc[:,1:].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"segt_map = {\n    r'[1-2][1-2][1-5]': 'Hibernating',\n    r'[1-2][3-4][1-5]': 'At risk',\n    r'[1-2]5[1-5]': 'Can\\'t loose',\n    r'3[1-2][1-5]': 'About to sleep',\n    r'33[1-5]': 'Need attention',\n    r'[3-5][4-5][1-5]': 'Loyal customers',\n    r'41[1-5]': 'Active one timers ',\n    r'51[1-5]': 'New customers',\n    r'[4-5][2-3][1-5]': 'Potential loyalists',\n    r'5[4-5][4-5]': 'Champions',\n    r'4[2-5][1-5]': 'Active Customers',\n   \n}\n\n\nRFM['Sub Segment'] = RFM['Score'].replace(segt_map, regex=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nRFM.replace({'Cluster Names':{2:'High FM & High Recency',1:'Avg FM & High Recency',0:'Low FM & Low Recency'}},inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictive analytics:- we can extend the cluster analytics for prediction by adding few customer dimentions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customer_dim= df[['Customer ID','Quantity','Country']].groupby('Customer ID').agg({'Quantity':'sum','Country':'unique'}).reset_index()\nRFM = RFM.merge(customer_dim[['Customer ID','Quantity','Country']])\nRFM['Country']= RFM['Country'].apply(lambda x : str(x).strip('[]'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Label_e = LabelEncoder()\nRFM['Country_Norm'] = Label_e.fit_transform(RFM['Country'])\nRFM['Score_Norm'] = Label_e.fit_transform(RFM['Score'])\nRFM['Sub_Segment_Norm'] = Label_e.fit_transform(RFM['Sub Segment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = RFM[['Recency', 'Frequency', 'Monetary Value',\n       'Recency Score', 'Frequency Score','Monetary Score','Country_Norm', 'Score_Norm','Sub_Segment_Norm']]\ny = RFM['Cluster']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decision_t = DecisionTreeClassifier()\nfold = cross_val_score(estimator=decision_t,X=X,y=y,cv=3)\nprint(fold.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}