{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Netflix Data: Task 1 - What to watch on Netflix?\n\nLast updated: July 13th, 2020\n\nWe create a recommendation engine to suggest similar shows in Netflix.\nThe similarity is calculated using following features of the shows:\n### **Features used:** \nWe select a number of features based on importance.\n* Description \n* Genre\n* Rating\n* Country of Release\n\n### **Approach:**\nEach feature utilizes a different approach for similarity calculation. Eventually, we evaluate the cummulative similarity based on all the features processed to give a single number for the overall similarity score.\n* Description - We filter the description by removing stopwords and punctuations. Then we use TF-IDF to find weight (importance) of each word in the description. Cosine similarity is used to find similarity between descriptions of two shows.\n* Genre - Each show has set of genre types that are applicable as per the content. We match each genre and similarity is calculated as the [intersection/ union] of the genre for given two shows.\n* Rating - As some of the rating titles mean similar categories, we group given ratings into appropriate clusters, e.g., Y, Y7, and Y7-FV are grouped in one cluster. As each rating has a distance from other rating, i.e., Y is closer to PG than R which means that a person who watches Y rated shows is more likely to watch Y or PG shows than R rated shows. Thus, each cluster is trategically placed from other clusters according to the likelihood of closeness.\n* Country of Release - Country of release follows the same approach as that of Genre.\n\n### **Final similarity score:**\n\nWe gave weights to each metric where description had the highest weight of 0.4 while genre, rating and country had equal weights of 0.2 each. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Do the following:\n1. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **Netflix Data EDA**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport seaborn as sns\nfrom scipy import spatial\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data\n# path = \"C:/Users/gunjan/Google Drive/Kaggle/Netflix/data/\"\npath = '/kaggle/input/netflix-shows/netflix_titles.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df = pd.read_csv(path)\ndata_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution of shows over release year","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"year_x = data_df['release_year'].values\nfig = sns.distplot(year_x,kde=False)\nplt.xlabel(\"Year of Release\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Distribution of Netflix Shows over Release Year\")\nplt.show(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution of shows over type (Movie or TV)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.value_counts(data_df['type']).plot(kind=\"bar\")\nplt.xlabel(\"Type of Show\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Distribution of Netflix Shows over Type of Show\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution of shows over Country","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"country=data_df.groupby('country').count()\ncountry.sort_values(by='show_id', inplace=True, ascending=False)\ncountry_top=country.head(10)\n\ncountry_top['show_id'].plot(kind='barh', figsize=(11,15))\nplt.title(\"Distribution of Netflix Shows over Country\")\nplt.xlabel('Frequency')\nplt.ylabel('Country')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Distribution of Shows over Genre","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"genre=data_df.groupby('listed_in').count()\ngenre.sort_values(by='show_id', inplace=True, ascending=False)\ngenre_top=genre.head(10)\n\ngenre_top['show_id'].plot(kind='barh', figsize=(11,15))\nplt.title(\"Distribution of Netflix Shows over Genre\")\nplt.xlabel('Frequency')\nplt.ylabel('Genre')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Content Based Filtering\n\nRecommendation engine is a method to predict what user desires at a given moment in time. It can be divided into two sub-classes:\n\n- Content-based Filtering\n- Collaborative Filtering\n\n#### Content-based Filtering\n\n#### Collaborative Filtering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## CODE","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Recommendation by country","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_country(country_list):\n    for i, country in enumerate(country_list):\n        country_list[i] = country.strip()\n    return set(country_list)\n\ndef find_country_score(movie_1, movie_2):\n    try:\n        country_m1 = movie_1['country'].split(',')\n        country_m2 = movie_2['country'].split(',')\n        country_m1 = clean_country(country_m1)\n        country_m2 = clean_country(country_m2)\n        union = len(country_m1.union(country_m2))\n        inter = len(country_m1.intersection(country_m2)) \n        return inter/union\n    except Exception as e:\n        return 0.0\n    \n# test country similarity\n\ncountry_sim = []\nnum = 50\ntest_data = data_df.head(num)\nfor i, row1 in test_data.iterrows():\n    row_sim = []\n    for j, row2 in test_data.iterrows():\n        row_sim.append(find_country_score(row1, row2))\n    country_sim.append(row_sim)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cm = pd.DataFrame(country_sim, range(num), range(num))\nplt.figure(figsize=(10,10))\nsns.set(font_scale=1.4) # for label size\nsns.heatmap(df_cm, annot=True, cmap=\"Blues\", annot_kws={\"size\": 5}) # font size\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Methodology\n\nThe above confusion matrix represents the similarity score between movies based on the country, the movie was released in. To find the recommendation, we have used intersection by union approach. Initially, we find the intersection of country list between two movies and total number of unique countries between two movies. Once we achieve this, we divide the number of intersected movies by all uniques movies and get our similarity score.  \n\nOur dataset consists of 8% values which nan. We can assume that when we have nan, we can't find similarity and thus the score will be equal to 0. \n\n### Recommendation by Ratings","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings = data_df['rating'].unique()\nreplace_rating = {}\nfor rating in ratings:\n    if rating == 'TV-PG' or rating == 'PG' or rating == 'PG-13' or rating == 'TV-14':\n        replace_rating[rating] = 'PG'\n    \n    elif rating == 'TV-MA' or rating == 'NC-17' or rating == 'R':\n        replace_rating[rating] = 'R'\n    \n    elif rating == 'NR' or rating == 'UR' or rating == 'TV-G' or rating == 'G':\n        replace_rating[rating] = 'U'\n    \n    elif rating == 'TV-Y7-FV' or rating == 'TV-Y7' or rating == 'TV-Y':\n        replace_rating[rating] = 'Y'\n    \n    else:\n        replace_rating[rating] = 'NAN'\nreplace_rating\n\ndata_df['rating'] = data_df['rating'].map(replace_rating)\ndata_df['rating']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_rating_score(movie_1, movie_2):\n    rating_1 = movie_1['rating']\n    rating_2 = movie_2['rating']\n    if rating_1 == 'U':\n        recom = 1.0\n    \n    elif rating_1 == 'Y':\n        if rating_2 == 'R':\n            recom = 0.0\n        elif rating_2 == 'PG':\n            recom = 0.25\n        elif rating_2 == 'U':\n            recom = 1.0\n        else:\n            recom = 0.0\n\n    elif rating_1 == 'PG':\n        if rating_2 == 'R':\n            recom = 0.0\n        elif rating_2 == 'Y':\n            recom = 0.75\n        elif rating_2 == 'U':\n            recom = 1.0\n        else:\n            recom = 0.0\n            \n    elif rating_1 == 'R':\n        if rating_2 == 'Y':\n            recom = 0.25\n        elif rating_2 == 'PG':\n            recom = 0.5\n        elif rating_2 == 'U':\n            recom = 1.0\n        else:\n            recom = 0.0\n    \n    else:\n        recom = 0.0\n    \n    return recom \n\nrating_sim = []\nnum = 50\ntest_data = data_df.head(num)\nfor i, row1 in test_data.iterrows():\n    row_sim = []\n    for j, row2 in test_data.iterrows():\n        row_sim.append(find_rating_score(row1, row2))\n    rating_sim.append(row_sim)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cm = pd.DataFrame(rating_sim, range(num), range(num))\nplt.figure(figsize=(10,10))\nsns.set(font_scale=1.4) # for label size\nsns.heatmap(df_cm, annot=True, cmap=\"Blues\", annot_kws={\"size\": 5}) # font size\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Recommendation by Genre","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"genre = data_df['listed_in']\ngenre = genre.values\nlist_genre = []\nfor g in genre:\n    for i in g.split(','):\n        list_genre.append(i.strip())\n\nlist(set(list_genre))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_genre(genre_list):\n    for i, genre in enumerate(genre_list):\n        genre_list[i] = genre.strip()\n    return set(genre_list) \n\ndef find_genre_score(movie_1, movie_2):\n    try:\n        genre_m1 = movie_1['listed_in'].split(',')\n        genre_m2 = movie_2['listed_in'].split(',')\n        genre_m1 = clean_genre(genre_m1)\n        genre_m2 = clean_genre(genre_m2)\n        union = len(genre_m1.union(genre_m2))\n        inter = len(genre_m1.intersection(genre_m2)) \n        return inter/union\n    except Exception as e:\n        return 0.0\n    \n# test country similarity\n\ngenre_sim = []\nnum = 50\ntest_data = data_df.head(num)\nfor i, row1 in test_data.iterrows():\n    row_sim = []\n    for j, row2 in test_data.iterrows():\n        row_sim.append(find_genre_score(row1, row2))\n    genre_sim.append(row_sim)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cm = pd.DataFrame(genre_sim, range(num), range(num))\nplt.figure(figsize=(10,10))\nsns.set(font_scale=1.4) # for label size\nsns.heatmap(df_cm, annot=True, cmap=\"Blues\", annot_kws={\"size\": 5}) # font size\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Recommendations by Description","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# \"stopwords\" are the words that appear very frequently in a language and have very low importance in determining the context of the sentence. It is a good practice to remove these stopwords before we start processing the description for TF-IDF.\n#  define all the stop words\nstopwords = ['i',\n'me',\n'my',\n'myself',\n'we',\n'our',\n'ours',\n'ourselves',\n'you',\n'your',\n'yours',\n'yourself',\n'yourselves',\n'he',\n'him',\n'his',\n'himself',\n'she',\n'her',\n'hers',\n'herself',\n'it',\n'its',\n'itself',\n'they',\n'them',\n'their',\n'theirs',\n'themselves',\n'what',\n'which',\n'who',\n'whom',\n'this',\n'that',\n'these',\n'those',\n'am',\n'is',\n'are',\n'was',\n'were',\n'be',\n'been',\n'being',\n'have',\n'has',\n'had',\n'having',\n'do',\n'does',\n'did',\n'doing',\n'a',\n'an',\n'the',\n'and',\n'but',\n'if',\n'or',\n'because',\n'as',\n'until',\n'while',\n'of',\n'at',\n'by',\n'for',\n'with',\n'about',\n'against',\n'between',\n'into',\n'through',\n'during',\n'before',\n'after',\n'above',\n'below',\n'to',\n'from',\n'up',\n'down',\n'in',\n'out',\n'on',\n'off',\n'over',\n'under',\n'again',\n'further',\n'then',\n'once',\n'here',\n'there',\n'when',\n'where',\n'why',\n'how',\n'all',\n'any',\n'both',\n'each',\n'few',\n'more',\n'most',\n'other',\n'some',\n'such',\n'no',\n'nor',\n'not',\n'only',\n'own',\n'same',\n'so',\n'than',\n'too',\n'very',\n's',\n't',\n'can',\n'will',\n'just',\n'don',\n'should',\n'now']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# extract all the descriptions\ndescriptions = data_df['description'].values\ndes = list(descriptions)\n\n# cerate the vectorizer with given stopwords\nvectorizer = TfidfVectorizer(stop_words = stopwords)\nX = vectorizer.fit_transform(des)\nXX = X.todense()\nprint(XX.shape)\n## XX is the matrix which stores TFIDF scores for each description","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to calculate similarity score using TFIDF on description\n\ndef find_description_score(movie_1, movie_2):\n    \n    '''\n    INPUT: movie_1 : row2 for features of the show1 given by the User & \n           movie_2 : row2 for features of the show2 we are comparing this show with\n    OUTPUT: Similarity score between the descriptions of show1 and show2\n    '''\n    \n    # extract row numbers\n    index_1 = data_df.index[data_df['title'] == movie_1['title']]\n    index_2 = data_df.index[data_df['title'] == movie_2['title']]\n    \n    a = np.array(XX[index_1])\n    b = np.array(XX[index_2])\n    similarity_score = 1-spatial.distance.cosine(a[0], b[0])\n    \n    return similarity_score\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Combining the Recommendations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"movie_1 = data_df.iloc[17]\nprint(movie_1)\n\ndef find_recommendations(data_df, movie_1):\n    rec_score = []\n    for index, movie_2 in tqdm(data_df.iterrows()):\n        rec_country = find_country_score(movie_1, movie_2)\n        rec_genre = find_genre_score(movie_1, movie_2)\n        rec_rating = find_rating_score(movie_1, movie_2)\n        rec_description = find_description_score(movie_1, movie_2)\n\n        score = 0.2*rec_genre + 0.2*rec_rating + 0.2*rec_country + 0.4*rec_description\n        rec_score.append(score)\n    \n    data_df['score'] = pd.DataFrame(rec_score)   \n    return data_df\n\ndata_df = find_recommendations(data_df, movie_1)\ndata_df.sort_values(by=['score'], ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}