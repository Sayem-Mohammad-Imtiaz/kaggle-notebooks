{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Data Overview"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom scipy.spatial import distance\nfrom nltk.tokenize import sent_tokenize\nimport scipy.spatial\n\n!pip install -U sentence-transformers\n\n# Library from here: https://github.com/UKPLab/sentence-transformers\nfrom sentence_transformers import SentenceTransformer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load DataFrame of Cleaned Documents"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"CLEAN_DATA_PATH = \"../input/cord-19-eda-parse-json-and-generate-clean-csv/\"\n\nbiorxiv_df = pd.read_csv(CLEAN_DATA_PATH + \"biorxiv_clean.csv\")\nclean_pmc = pd.read_csv(CLEAN_DATA_PATH + \"clean_pmc.csv\")\npapers_df = pd.concat([clean_pmc, biorxiv_df], axis=0).reset_index(drop=True)\n\npapers_df.dropna(inplace=True)\npapers_df.drop_duplicates(subset=['title'], keep=False, inplace=True)\n\n# Load Sentence Embedding Model.\nmodel = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"papers_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences = sent_tokenize(papers_df.iloc[0]['text'])\nsentences_df = pd.DataFrame({'id':np.zeros(len(sentences)).astype(int), 'sentences':sentences},index=None)\n\nfor i in range(1, len(papers_df)):\n    paper_sentences = sent_tokenize(papers_df.iloc[i]['text'])\n    paper_sentences_df = pd.DataFrame({'id':(np.ones(len(paper_sentences))*i).astype(int), 'sentences':paper_sentences},index=None)\n    sentences_df = pd.concat([sentences_df, paper_sentences_df], axis=0).reset_index(drop=True)\n    \nsentences = sentences_df['sentences'].str.lower().tolist()\nsentence_embeddings = model.encode(sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question_1 = 'medical health care covid-19 coronavirus'\nquestion_1_embedding = model.encode(question_1)\n\nquestion_sentence_similarity_scores = []\nfor i in range(len(sentence_embeddings)):\n    question_sentence_similarity_scores.append(scipy.spatial.distance.cdist([question_1_embedding[0]], [sentence_embeddings[i]], \"cosine\")[0])\n    \nsentences_df['cosine_score'] = question_sentence_similarity_scores\nsentences_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index, row in sentences_df[sentences_df['cosine_score'] > 1.3].iterrows():\n    print(f\"ID: {index}\\nSentence: {row['sentences']}\", '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load Data and Library\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\nfrom subprocess import check_output\n! pip install wordcloud\nfrom wordcloud import WordCloud, STOPWORDS\n\npapers_df=papers_df.reset_index(drop=True)\n\nMETA_DATA_PATH = \"../input/CORD-19-research-challenge/\"\nmeta_df = pd.read_csv(META_DATA_PATH + \"metadata.csv\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Source\n\ndf_sy=meta_df['source_x'].value_counts(dropna=False)\nprint(df_sy)\n\nplt.barh(df_sy.index, df_sy.values, align='center', alpha=0.5,color='orange')\nplt.ylabel('Quantity')\nplt.title('Number of Literature by Sources')\n\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Literature Text\n\npapers_df.shape\n\nmeta_df.shape\n\npapers_df.shape[0]/meta_df.shape[0]\n\ndf_sy=meta_df['has_pmc_xml_parse'].value_counts(dropna=False)\nprint(df_sy)\n\nplt.pie(df_sy.values,labels=df_sy.index,autopct='%1.1f%%',colors=['lightblue','orange'], shadow = True)\nplt.title('Whether have PMC XML')\nplt.axis('equal')\nplt.show()\n\n\ndf_sy=meta_df['has_pdf_parse'].value_counts(dropna=False)\nprint(df_sy)\n\nplt.pie(df_sy.values,labels=df_sy.index,autopct='%1.1f%%',colors=['orange','lightblue'], shadow = True)\nplt.title('Whether have PDF')\nplt.axis('equal')\nplt.show()\n\n\ndf_sy=meta_df['full_text_file'].value_counts(dropna=False)\nprint(df_sy)\ndf_sy.index = pd.Series(df_sy.index).replace(np.nan, 'NaN')\n\n\nplt.pie(df_sy.values,labels=df_sy.index,autopct='%1.1f%%',shadow = True)\nplt.title('Full Text Source File')\nplt.axis('equal')\nplt.show()\n\nplt.barh(df_sy.index, df_sy.values, align='center', alpha=0.5,color='orange')\nplt.ylabel('Quantity')\nplt.title('Number of Literatures with Full Text File')\n\nplt.show()\n\n### Comments:\n### paper_df only have 38% data of metadata, should we use meta as well?\n### PDF file have more info than PMC, seems like paper_df use PMC\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# License\n\ndf_sy=meta_df['license'].value_counts(dropna=False)\nprint(df_sy)\n\nplt.barh(df_sy.index, df_sy.values, align='center', alpha=0.5,color='orange')\nplt.ylabel('Quantity')\nplt.title('Number of Literatures by License')\n\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Authors\n\nauthors_count=meta_df['authors'].str.count(\";\")+1\n\ndf_sy=authors_count.isna().value_counts(dropna=False)\nprint(df_sy)\n\nplt.pie(df_sy.values,labels=df_sy.index,autopct='%1.1f%%',colors=['lightblue','orange'], shadow = True)\nplt.title('Whether Authors is NA')\nplt.axis('equal')\nplt.show()\n\n\nplot_df_sy = authors_count.dropna()\n\nprint('Top Number of Authors:')\nplot_df_sy.sort_values().tail()\n\nsns.distplot(plot_df_sy, hist = False, kde = True,\n                 kde_kws = {'shade': True, 'linewidth': 3}\n            ).set_title(\"Number of Authors Distribution\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Affiliations\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=stopwords,\n                          max_words=200,\n                          max_font_size=40, \n                          random_state=42\n                         ).generate(str(papers_df['affiliations']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\nfig.savefig(\"wordcloud_affiliations.png\", dpi=1024)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bibliography\n\nwordcloud = WordCloud(\n                          background_color='white',\n                          max_words=200,\n                          max_font_size=40, \n                          random_state=42\n                         ).generate(str(papers_df['bibliography']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\nfig.savefig(\"word_bibliography.png\", dpi=1024)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Time\n\ndf_sy=meta_df['publish_time'].str.slice(0, 4).value_counts(dropna=True)\n\ndf_sy=df_sy.sort_index()\n\nfrom matplotlib.pyplot import figure\nfigure(num=None, figsize=(8, 12), dpi=80, facecolor='w', edgecolor='k')\n\nplt.barh(df_sy.index, df_sy.values)\nplt.title('Number of Literatures by Year')\nplt.ylabel('Year');\nplt.show() \n\n### Comments:\n### Most of the literatures are published in 2020, but there are still a large amount of papers published long time ago, should be cautious how reliable they are as for now\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#journal\nwordcloud = WordCloud(\n                          background_color='white',\n                          max_words=200,\n                          max_font_size=40, \n                          random_state=42\n                         ).generate(str(meta_df['journal']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\nfig.savefig(\"word_journal.png\", dpi=1024)\n\nmeta_df['journal'].value_counts(dropna=False).sort_values().tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Comments:\n### paper_df only have 38% data of metadata, we should use meta as well\n### PDF file have more info than PMC, seems like paper_df only use PMC\n\n\n### Comments:\n### Most of the literatures are published in 2020, but there are still a large amount of papers published long time ago, should be cautious how reliable they are as for now\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}