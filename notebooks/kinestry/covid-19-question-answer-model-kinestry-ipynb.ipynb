{"cells":[{"metadata":{},"cell_type":"markdown","source":"## This is a Developement Notebook for the COVID-19 Dataset. Feel free to post your ideas, text or code here and we can clean and aggregate the work into another Final Notebook in the end. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom scipy.spatial import distance\nfrom nltk.tokenize import sent_tokenize\nimport scipy.spatial\n\n!pip install -U sentence-transformers\n\n# Library from here: https://github.com/UKPLab/sentence-transformers\nfrom sentence_transformers import SentenceTransformer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load DataFrame of Cleaned Documents"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"CLEAN_DATA_PATH = \"../input/cord-19-eda-parse-json-and-generate-clean-csv/\"\n\nbiorxiv_df = pd.read_csv(CLEAN_DATA_PATH + \"biorxiv_clean.csv\")\nclean_pmc = pd.read_csv(CLEAN_DATA_PATH + \"clean_pmc.csv\")\npapers_df = pd.concat([clean_pmc, biorxiv_df], axis=0).reset_index(drop=True)\n\npapers_df.dropna(inplace=True)\npapers_df.drop_duplicates(subset=['title'], keep=False, inplace=True)\n\n# Load Sentence Embedding Model.\nmodel = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\npapers_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences = sent_tokenize(papers_df.iloc[0]['text'])\nsentences_df = pd.DataFrame({'id':np.zeros(len(sentences)).astype(int), 'sentences':sentences},index=None)\n\nfor i in range(1, len(papers_df)):\n    paper_sentences = sent_tokenize(papers_df.iloc[i]['text'])\n    paper_sentences_df = pd.DataFrame({'id':(np.ones(len(paper_sentences))*i).astype(int), 'sentences':paper_sentences},index=None)\n    sentences_df = pd.concat([sentences_df, paper_sentences_df], axis=0).reset_index(drop=True)\n    \nsentences = sentences_df['sentences'].str.lower().tolist()\nsentence_embeddings = model.encode(sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"question_1 = 'medical health care covid-19 coronavirus'\nquestion_1_embedding = model.encode(question_1)\n\nquestion_sentence_similarity_scores = []\nfor i in range(len(sentence_embeddings)):\n    question_sentence_similarity_scores.append(scipy.spatial.distance.cdist([question_1_embedding[0]], [sentence_embeddings[i]], \"cosine\")[0])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"sentences_df['cosine_score'] = question_sentence_similarity_scores\n\nsentences_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index, row in sentences_df[sentences_df['cosine_score'] > 1.25].iterrows():\n    print(f\"ID: {index}\\nSentence: {row['sentences']}\", '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}