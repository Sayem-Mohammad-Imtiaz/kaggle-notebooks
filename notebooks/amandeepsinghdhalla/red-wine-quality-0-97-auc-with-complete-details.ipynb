{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The problem we have to solve is to **help in predicting the quality of wine** with the help of a *classification model*. The dataset is provided for the same to help us in training and testing phase. Altough lets move ahead looking at the dataset.","metadata":{}},{"cell_type":"code","source":"'''Starting off with Importing Important Libraries '''\nimport pandas as pd\nimport numpy as np\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warnings.filterwarnings('ignore')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading and then loading the dataset onto the notebook.\nds = pd.read_csv('../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\nds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EXPLORATORY DATA ANALYSIS\nIn this dataset for the quality prediction, there are **11 attributes and 1 label or target class.** We will have a look at the target variable and see that how many classes or unique values are present in the target variable.","metadata":{}},{"cell_type":"code","source":"print(f\"The number of unique class in target variable are {ds.quality.nunique()}.\\n\"\n      f\"Those unique target variables are {ds.quality.unique()}\")\n\nds.quality.value_counts()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that the quality of Red wine is defined in *6 unique values* starting from 3 all the way upto 8, *3 being the lowest quality and 8 being the highest quality.* The majority of the wine sample are of medium quality (5 or 6 quality score). Rest samples are of either high quality (7 or 8 quality score) or of low quality (3 or 4 quality score.)\n\n**The dataset is heavily imbalanced.** Working on this dataset *can result in overfitting* as the model will learn the majority target variable better that the other and give the same result for the prediction.\n\nWe now have a look at the datatype of the attributes and the target variable. We also check if there are any null values present into the dataset.","metadata":{}},{"cell_type":"code","source":"ds.info()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above results, we get the information that the **dataset consists of no null values** and the *attributes are of float datatype*. The target variable as we learned above has int datatype.\n\nWe can also visualise the presence of null values in data using a heatmap.","metadata":{}},{"cell_type":"code","source":"sb.heatmap(ds.isnull())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we use descriptive statistics on the dataset and try to get some insights from them.","metadata":{}},{"cell_type":"code","source":"ds.iloc[:,0:-1].describe() # excluding the target class","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above values, we can draw some insights for the data.\n\n1 Standard Deviation for the features 'free sulphur dioxide' and and 'total sulphur dioxide' is high. So data spread is \n  present in the features.\n2 The difference between mean and median is large in 'toatl sulphur dioxide' feature. So hte data is skewed in this\n  column.\n3 From the minimum values, we can see that no negative values are present in the dataset.\n4 Some outliers may be present in the features 'residual sugar', 'free sulphur dioxide' and 'total sulphur dioxide'.\nWe will now look at the each feature indivisualy and get information regarding the problem from them.\n\nPlotting the boxplot and distplot of this feature to visualise the data spread in the column.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (12,5))\nplt.subplot(1, 2, 1)\nsb.boxplot(ds['fixed acidity'], color = 'yellow')\nplt.title(\"Box Plot for Fixed Acidity\")\n\nplt.subplot(1, 2, 2)\nsb.distplot(ds['fixed acidity'])\nplt.title(\"Distribution Plot for Fixed Acidity\")\n\nplt.tight_layout(pad = 4)\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above plots, we see that the 'fixed acidity' feature have some outliers present in the column values. Also the data is slightly skewed as seen in distplot.\n\n# Similarly,\nWe can plot the boxplot and check the presence of outliers.","metadata":{}},{"cell_type":"code","source":"clist = ['volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide',\n         'density','pH','sulphates', 'alcohol']\n\nplt.figure(figsize = (16,14))\nfor i in range(0, len(clist)):\n    plt.subplot(4,3, i+1)\n    sb.boxplot(ds[clist[i]], color = 'yellow')\nprint(\"BoxPlots of the features:\")\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Above plots indicate that *there are some outliers present in all the features of the dataset.* They need to be removed as that we can improve the learning of the model.\n\nNow, plotting the distplot for the other features to look at their distribution of data:","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (16, 14))\nfor i in range(0, len(clist)):\n    plt.subplot(4,3, i+1)\n    sb.distplot(ds[clist[i]])\nprint(\"Distplots of the features:\")\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above plots, we can see that **'residual sugar', 'chlorides', 'sulphates', 'free sulfur dioxide' and 'total sulfur dioxide' are positively skewed or right skewed.** *Some skewness is present into the other other data as well.* This skewness can be removed by removing the outliers. If skewness is still present, then we use boxcox or log transform to remove the skewness.\n\nNow, we remove the outliers from the dataset using the z-score:","metadata":{}},{"cell_type":"code","source":"from scipy.stats import zscore\nzabs = np.abs(zscore(ds)) # calculating the absolute z-score\n\n# Removing the outliers\nds_new = ds[(zabs < 3).all(axis = 1)]\nds_new.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above shape of new dataset, we get that *1451 rows are left after removing outliers out of 1599 rows.* So a total of **148 rows have been removed.** *Which is around 9.25% of the total data.*\n\nAfter the removal of outliers, checking if the skewness is treated for the data. For this we compare the old and the new data.","metadata":{}},{"cell_type":"code","source":"clist = ['fixed acidity', 'volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide',\n         'density','pH','sulphates', 'alcohol']\nfor i in range(0, len(clist)):\n    print(f\"The old vs new skewness for feature {clist[i]} is: {ds[clist[i]].skew()} : {ds_new[clist[i]].skew()}\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above values, we can see that the *skewness is significantly reduced for the features after the outliers removal.* Still some skewness is present in the for few columns. **We remove the remaning skewness from those columns using log transform.**","metadata":{}},{"cell_type":"code","source":"nlist = ['fixed acidity','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide', 'sulphates', 'alcohol']\n\nfor i in range(0, len(nlist)):\n    ds_new[nlist[i]] = np.log(ds_new[nlist[i]])\n    \nprint(\"Skeness for new dataset after log transform:\")\nds_new.skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some *skewness is still present in the 'residual sugar' columnn*. So we use **boxcox transform on that feature.**","metadata":{}},{"cell_type":"code","source":"from scipy.stats import boxcox\nds_new['residual sugar'] = boxcox(ds_new['residual sugar'])[0]\nprint(\"Skeness for new dataset after boxcox transform:\")\nds_new.skew()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The **skewness of the dataset is now treated**, we can visualise it again using the distplot.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (16, 14))\nfor i in range(0, len(clist)):\n    plt.subplot(4,3, i+1)\n    sb.distplot(ds_new[clist[i]])\nprint(\"Distplots of the features:\")\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can visualise that the *features are more normally distributed than before and skewness is corrected.*\n\nChecking the **Correlation between the attributes and target class.**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10, 6))\nsb.heatmap(ds_new.corr(), annot = True)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the heatmap, we can see that the *'quality' of Wine samples are highly related to the 'alcohol' and 'sulphates' amount in the wine samples.* 'citric acid' and 'fixed acidity' also have some correlation to the quality of wine. *'free sulfur dioxide' and 'total sulfur dioxide' are highly correlated to each other.* Similarly 'citric acid' and 'density' are highly correlated to 'fixed acidity'\n\nWe can visualise the relation between features and target using the scatter plot.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10, 6))\nsb.scatterplot(x = ds_new['alcohol'], y = ds_new['quality'], hue = ds_new['quality'],\n               size = ds_new['quality'])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that the high quality wine has alcohol content more than 2.28 whereas in low quality wine alcohol content starts from 2.19. Similarly, we can plot a scatter plot for the other features and visualise the relation between them and target variable.\n\nplotting a scatter plot to see the relationship between 'free sulphur dioxide' and 'total sulphur dioxide' and how this varies according to the quality of wine.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10, 6))\nsb.scatterplot(x = ds_new['free sulfur dioxide'], y = ds_new['total sulfur dioxide'], hue = ds_new['quality'],\n               size = ds_new['quality'])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that as the of *free sulfur dioxide increases, total sulfur dioxide also increases.*\n\n# Data Imbalance:\nNow that we have cleaned the data and looked at the correlation between the features and target, we visualise the data imbalance.","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(ds_new, x = 'quality', color = 'quality', opacity = 0.8, nbins = 15)\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see that the **data is heavily imbalanced** and *it can cause overfitting of the model.* In order to avoid overfitting of the model and improve the performance and prediction, *we balance the dataset.*\n\nSince we only have 47 wine samples with 4 quality score and only 10 wine samples with 8 quality score. exact prediction of these values will be hard. So, *setting an arbitrary cutoff for the dependent variable (wine quality) at 7 or higher getting classified as 'good/1' and the remainder as 'not good/0'*. So we **replace quality score values which are less that 7 by 0 and equal to or greater than 7 by 1.**","metadata":{}},{"cell_type":"code","source":"# Replacing quality score 4, 5 and 6 by 0\nds_new['quality'].replace(to_replace = 4, value = 0, inplace = True)\nds_new['quality'].replace(to_replace = 5, value = 0, inplace = True)\nds_new['quality'].replace(to_replace = 6, value = 0, inplace = True)\n\n# Replacing quality score 7 and 8 by 1\nds_new['quality'].replace(to_replace = 7, value = 1, inplace = True)\nds_new['quality'].replace(to_replace = 8, value = 1, inplace = True)\n\nprint(f\"The number of unique class in target variable after replacing\",\n      f\"are {ds_new.quality.nunique()}.\\nThose new unique target variables are {ds_new.quality.unique()}\")\n\nds_new.quality.value_counts()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we **balance the dataset using SMOTE** class. For that we split the new dataset into x and y variables, x being features and y being target.","metadata":{}},{"cell_type":"code","source":"# Splitting into attributes and target\nx = ds_new.iloc[:, 0:-1]\ny = ds_new.iloc[:, -1]\n\n# Data balancing\nfrom imblearn.over_sampling import SMOTE\noversample = SMOTE()\nx_new, y_new = oversample.fit_resample(x, y)\n\n# New Data Visualization\ngood = y_new[y_new == 1] # values where loan were paid\nbad = y_new[y_new == 0] # values where loan were not paid.\n\nfig = go.Figure()\nfig.add_traces(go.Histogram(x = good, name='Good Quality', marker_color='purple', opacity=0.9))\nfig.add_traces(go.Histogram(x = bad, name='Poor Quality', marker_color='thistle', opacity=0.9))\nfig.update_layout(title_text=\"Red Wine Quality Score\", xaxis_title_text='Good or Poor', yaxis_title_text='Value Count')\nfig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above plot, we can visualise that the *number of samples for good wine has been increased using SMOTE algorithm.* As a result, **the data imbalance has been removed** and now we have 1250 samples for both good and poor quality of wine.Now, *we can build a prediction model without the issue of overfitting.*\n\n## Scaling:\nDuring the Exploratory Data Analysis, we found that all the data types are of float datatype. So the scaling of the dataset is not required. Also, there is not a large difference between the maximum and minimun values in the features across the dataset. So, Min-Max scaling can also be avaided for the data.\n\n# MODEL BUILDING:\n## Best Random State:\nIn order to achive high preformance and accuracy, we first find out the best possible random state where the model will give the best possible score. For that, we write a small code which returns us the beat random state possible.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nmax_accuracy = 0\nbest_rs = 0\nfor i in range(1, 150):\n    x_train, x_test, y_train, y_test = train_test_split(x_new, y_new, test_size = 0.25, random_state = i)\n    lg = LogisticRegression()\n    lg.fit(x_train, y_train)\n    pred = lg.predict(x_test)\n    acc = accuracy_score(y_test, pred)\n    if acc > max_accuracy: # after each iteration, acc is replace by the best possible accuracy\n        max_accuracy = acc\n        best_rs = i\nprint(f\"Best Random State is {best_rs}\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Best Random State is 98. From the above result, we can split the data using random state as 98.","metadata":{}},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x_new, y_new, test_size = 0.25, random_state = 98)\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Selection:\nThe problem is a classification problem. So we need to select a model which is a classification model. We find out the best model among *Logistic Regressor, Decision Tree Classifier, KNN Classifier and SVC Classifier.* Since the **datatset is not that huge, we do not need to use bagging or boosting.** We fit the training and testing data one by one into the models and compare their accuracy score.","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\n# For Logistic Regression\nlg = LogisticRegression()\nlg.fit(x_train, y_train)\npred_lg = lg.predict(x_test)\nprint(\"Accuracy Score of Logistic Regression model is\", accuracy_score(y_test, pred_lg)*100)\n\n# For Decision Tree Classifier\ndtc = DecisionTreeClassifier()\ndtc.fit(x_train, y_train)\npred_dtc = dtc.predict(x_test)\nprint(\"Accuracy Score of Decision Tree Classifier model is\", accuracy_score(y_test, pred_dtc)*100)\n\n# For K-Nearest Neighbour Classifier\nknc = KNeighborsClassifier(n_neighbors = 5)\nknc.fit(x_train, y_train)\npred_knc = knc.predict(x_test)\nprint(\"Accuracy Score of K-Nearest Neighbour Classifier model is\", accuracy_score(y_test, pred_knc)*100)\n\n# For Support Vector Classifier\nsvc = SVC(kernel = 'rbf')\nsvc.fit(x_train, y_train)\npred_svc = svc.predict(x_test)\nprint(\"Accuracy Score of Support Vector Classifier model is\", accuracy_score(y_test, pred_svc)*100)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above accuracy scores, we get find out that the *accuracy score for the Decision Tree Classifier is highest. But, this could be the result of overfitting of the model.*\n\n## Cross Validation:\nIn order to check whether the *accuracy score given by the metrics is real and if model is overfitting or not,* **we cross validate the model for scoring criteria as f1-score.** This will tell us if the model is actually performing welll and is ot overfitting. *The model whose difference between accuracy score and mean accuracy given by Cross Validation will be the least will the best model.*","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\nlg_scores = cross_val_score(lg, x_new, y_new, cv = 10) # cross validating the model\nprint(lg_scores) # accuracy scores of each cross validation cycle\nprint(f\"Mean of accuracy scores is for Logistic Regression is {lg_scores.mean()*100}\\n\")\n\ndtc_scores = cross_val_score(dtc, x_new, y_new, cv = 10)\nprint(dtc_scores)\nprint(f\"Mean of accuracy scores is for Decision Tree Classifier is {dtc_scores.mean()*100}\\n\")\n\nknc_scores = cross_val_score(knc, x_new, y_new, cv = 10)\nprint(knc_scores)\nprint(f\"Mean of accuracy scores is for KNN Classifier is {knc_scores.mean()*100}\\n\")\n\nsvc_scores = cross_val_score(svc, x_new, y_new, cv = 10)\nprint(svc_scores)\nprint(f\"Mean of accuracy scores is for KNN Classifier is {svc_scores.mean()*100}\\n\")","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above results, we see that the *least difference between accuracy score and mean accuracy is give by knn classifier.* We can now tune **the SVC model using the hyperparameter tuning.** After that we evaluate the model on basis of auc score, recall and precison.\n\n## Hyper-Parameter Tuning:\n**Tuning the SVC model:**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nsvc = SVC()\nparameters = { 'kernel' : ['rbf', 'linear'], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'C': [0.1, 1, 10, 100, 1000]}\ngs = GridSearchCV(estimator = svc, param_grid = parameters, scoring = 'f1', cv = 5)\ngs.fit(x_train, y_train)\nprint(\"The best parameters for SVC Model are:\")\nprint(gs.best_params_)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Best parameters for SVC Classifier after tuning are C - 1000, gamma - 1, kernel - 'rbf'.**\n\n# MODEL EVALUATION:\n## SVC Evaluation:\nEvaluation of SVC using classification report and AUC score.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import plot_roc_curve\n\nsvc = SVC(kernel = 'rbf', C = 1000, gamma = 1)\nsvc.fit(x_train, y_train)\npred_svc = svc.predict(x_test)\n\nprint(\"Accuracy Score of SVC model is\", accuracy_score(y_test, pred_svc))\nprint(\"Confusion matrix for SVC Model is\")\nprint(confusion_matrix(y_test, pred_svc))\nprint(\"Classification Report of the SVC Model is\")\nprint(classification_report(y_test, pred_svc))","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above classification report, we see that the SVC model has a **f1-score of 0.95 and the precision and recall greater than 0.92.** Now, we plot the ROC Curve and look at the AUC score for the model.","metadata":{}},{"cell_type":"code","source":"plot_roc_curve(svc, x_test, y_test) # arg. are model name, feature testing data, label testing data.\nplt.title(\"Recevier's Operating Characteristic\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above ROC Curve, we visualise that the model has an **AUC score of 0.97.** This means that the prediction model is working effeciently.\n\nWe can also *visualise the performance of the model during testing phase* using the histogram plot as shown below.","metadata":{}},{"cell_type":"code","source":"act_pos = y_test[y_test == 1]\npred_pos = pred_svc[pred_svc == 1]\nact_neg = y_test[y_test == 0]\npred_neg = pred_svc[pred_svc == 0]\n\nfig1 = go.Figure()\n\nfig1.add_traces(go.Histogram(x = act_pos, name='Actual Good', marker_color='springgreen', opacity=0.9))\n\nfig1.add_traces(go.Histogram(x = pred_pos, name='Predicted Good', marker_color='mediumspringgreen', opacity=0.9))\n\nfig1.add_traces(go.Histogram(x = act_neg, name='Actual Poor', marker_color='peru', opacity=0.9))\n\nfig1.add_traces(go.Histogram(x = pred_neg, name='Predicted Poor', marker_color='tan', opacity=0.9))\n\nfig1.update_layout(title_text=\"Model's Wine Quality Prediction Result\", xaxis_title_text='Actual and Predicted',\n                   yaxis_title_text='Counts', bargap=0.1, bargroupgap=0.3)\n\nfig1.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the histogram above, it is clear that the model's **predictions are very accurate**. This model can be used to predict and differentiate the wine between good and poor.\n\n# SERIALISATION:\n## Saving the model-\nThe fitted **model can now be saved as an object outside the notebook** and *used for prediction.*","metadata":{}},{"cell_type":"code","source":"import joblib # used for serialisation\njoblib.dump(svc, 'Wine_Quality_Prediction_Model.obj') # saving the model as an object","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}