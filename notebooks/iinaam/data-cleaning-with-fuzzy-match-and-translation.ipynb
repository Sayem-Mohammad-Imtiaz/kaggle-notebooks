{"cells":[{"metadata":{},"cell_type":"markdown","source":"# In this report,\n### I will present a possible solution to reduce the number of unique city names in dataset.\n\n#### In particular, we will see:\n- How to translate from urdu to english using python modules\n- How to create pandas dataframes from wikipedia tabels\n- What is fuzzy match and how to find a best match for noisy categorical data\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":false,"scrolled":true},"cell_type":"code","source":"import pandas as pd\n%config IPCompleter.use_jedi = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/gufhtugu-publications-dataset-challenge/GP Orders - 5.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"scrolled":true},"cell_type":"code","source":"df.dropna(subset=[\"City\"], inplace=True)\ndf.City.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"City\"] = df.City.astype(str)\nraw_cities = df.iloc[:,[0,4]].copy()\nraw_cities.columns = [\"oid\",\"city\"]\nraw_cities.city.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"N = 150\n\nbefore_ev = raw_cities.city.nunique()\nbefore_ev_p = raw_cities.city.value_counts()[:N].sum()/raw_cities.shape[0]\n\nprint(f\"Initially we have {before_ev} unique values for city names.\")\nprint(f\"Top {N} cities with most ordes are {before_ev_p:.2f}% of the whole dataset\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Translation from Urdu to English"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"mask = raw_cities.city.str.contains(\"[a-zA-Z]\")\nurdu_names= raw_cities[~mask].city.unique()\nurdu_names.shape\nprint(\"we have {} unique city names in urdu, a sample is shown below:\\n{}\".format(len(urdu_names), urdu_names[:10]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Manually translating these names is time consuming, We can use a very famous module TextBlob which provides basic translation.\n"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"from textblob import TextBlob\nfrom time import sleep","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"scrolled":true},"cell_type":"code","source":"to_en = {}\nfor x in urdu_names:\n    # sleep to not exceed the limit of requests\n    sleep(0.5)\n    try:\n        tr = TextBlob(x).translate().string\n        to_en[x] = tr\n#         print(x,\" - \", tr)\n    except:\n        pass\n#         print(x)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"len(to_en), to_en","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### TextBlob was able to translate 122 out of 156 names. As expected, most of the translations are perfect.\nWe can replace these names in raw dataset."},{"metadata":{"trusted":true,"_kg_hide-input":true,"scrolled":true},"cell_type":"code","source":"tr = raw_cities.city.replace(to_en)\nraw_cities[\"city\"] = tr\n\nafter_tr = raw_cities.city.nunique()\nafter_tr_p = raw_cities.city.value_counts()[:N].sum()/raw_cities.shape[0]\n\nprint(f\"After translation, we have {after_tr} unique values for city names.\")\nprint(f\"Top {N} cities with most ordes are {after_tr_p:.2f}% of the whole dataset.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Case Normalization\n#### We will convert all city names in title format to remove any difference w.r.t case sensitivity."},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"raw_cities[\"city\"] = raw_cities.city.str.strip().str.title()\n\nafter_cn = raw_cities.city.nunique()\nafter_cn_p = raw_cities.city.value_counts()[:N].sum()/raw_cities.shape[0]\n\nprint(f\"After case normalization, we have {after_cn} unique values for city names.\")\nprint(f\"Top {N} cities with most ordes are {after_cn_p:.2f}% of the whole dataset.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fuzzy matching\n#### In this section I will try to correct the spelling mistakes and extract city names from detailed address.  \nIn particular, I will  \n- Create a List of cities using Wikipedia articles\n- Match city entries from raw data to newly created list"},{"metadata":{},"cell_type":"markdown","source":"I could not find a way to replace abbreviations of city names with correct names.  \nI will manually replace city names like {\"lhr\", \"khi\"} to their full names."},{"metadata":{"trusted":true},"cell_type":"code","source":"# list names with less than 5 characters\nmask = raw_cities.city.str.len() < 5\nraw_cities[mask].city.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"short_full = {\n    \"Rwp\": \"Rawalpindi\",\n    \"Isb\": \"Islamabad\",\n    \"Fsd\": \"Faisalabad\",\n    \"Khi\": \"Karachi\",\n    \"Lhr\": \"Lahore\",\n    \"D I Khan\": \"Dera ismail khan\",\n    \"G G Khan\": \"Dera ghazi khan\"\n}\n\nraw_cities[\"city\"] = raw_cities.city.replace(short_full)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"from fuzzywuzzy import process, fuzz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"scrolled":true},"cell_type":"code","source":"# Create on dataframe for each province\n\nurls = {\n    \"kpk\": \"https://en.wikipedia.org/wiki/List_of_cities_in_Khyber_Pakhtunkhwa_by_population\",\n    \"balochistan\":\"https://en.wikipedia.org/wiki/List_of_cities_in_Balochistan,_Pakistan_by_population\",\n    \"punjab\":\"https://en.wikipedia.org/wiki/List_of_cities_in_Punjab,_Pakistan_by_population\",\n    \"sindh\": \"https://en.wikipedia.org/wiki/List_of_cities_in_Sindh_by_population\",\n    \"gb\": \"https://en.wikipedia.org/wiki/List_of_cities_in_Gilgit-Baltistan_by_population\"\n}\n\ntabel_idx = {\n    \"kpk\": 0,\n    \"balochistan\":0,\n    \"punjab\":0,\n    \"sindh\": 0,\n    \"gb\": 1\n}\n\ndf_list = {}\nfor pname in urls:\n    df_list[pname] = pd.read_html(urls[pname])[tabel_idx[pname]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"scrolled":true},"cell_type":"code","source":"# Create list of cities and city-to-province mapping\n\ncities = pd.Series(\"Islamabad\",dtype = object)\ncity_prov = {\"Islamabad\":\"Federal\"}\nfor pname in df_list:\n    p = df_list[pname]\n    p.rename(columns = {\"City Name\": \"City\"}, inplace = True)\n    cities = cities.append(p.City, ignore_index=True)\n    city_prov.update({city:pname.title() for city in p.City})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### To match two strings, we will use the weighted ratio score.   (details about Weighted ratio are  [here](https://stackoverflow.com/questions/31806695/when-to-use-which-fuzz-function-to-compare-2-strings))"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"to_city = {}\nfor city in raw_cities.city.unique():\n    res, score, _ = process.extractOne(city, cities, scorer = fuzz.WRatio)\n    to_city[city] = f\"{res};{score}\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"new_names = raw_cities.city.replace(to_city)\nraw_cities[[\"proposed_city_name\", \"similarity_score\"]] = new_names.str.split(\";\", n = 1, expand = True)\nraw_cities[\"similarity_score\"] = raw_cities.similarity_score.astype(int)\n\nraw_cities.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The real magic happens between the scores of 85 and 90, where spelling mistakes are corrected.  \nResults include some errors, which will cause noise in the data.  \nThreshold can be set according to a particular problem, we will rename all the cities where score is above 85."},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [\"city\", \"proposed_city_name\", \"similarity_score\"]\nmask_85 = raw_cities.similarity_score > 85\nmask = mask_85 & (raw_cities.similarity_score < 90)\nraw_cities[mask][cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_cities.loc[mask_85, \"city\"] = raw_cities[mask].proposed_city_name\nraw_cities.loc[mask_85, \"fuzzy_name\"] = True\nraw_cities.loc[~mask_85, \"fuzzy_name\"] = False\n\nprint(\"{} names are mapped to their fuzzy match.\".format(raw_cities.fuzzy_name.sum()))\n\nraw_cities.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"mask = raw_cities.similarity_score > 85\n\nraw_cities.loc[mask, \"city\"] = raw_cities[mask].proposed_city_name\nraw_cities.loc[mask, \"fuzzy_name\"] = True\nraw_cities.loc[~mask, \"fuzzy_name\"] = False\n\nprint(\"{} names are mapped to their fuzzy match.\".format(raw_cities.fuzzy_name.sum()))\nraw_cities","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final = raw_cities.city.nunique()\nfinal_p = raw_cities.city.value_counts()[:N].sum()/raw_cities.shape[0]\n\nprint(f\"Finally, we have {final} unique values for city names.\")\nprint(f\"Top {N} cities are {final_p:.2f}% of the whole dataset.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Results\n\nMore than the fact that we have lesser unique values, it is satisfying to see that almost 88% of the dataset has standard city names.  \nWe have made some errors but those city names were rarely present in our dataset.  \nThe results can be further improved by expanding our search for True values of city names.\n\n\n### If you find this report useful 🧐, please upvote ☝. Adios. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}