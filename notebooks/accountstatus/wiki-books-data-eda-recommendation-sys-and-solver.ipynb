{"cells":[{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family:courier;font-size:300%;color:#184d47;background-color:#e4d3cf;\">Importing Packages</p>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom colorama import Fore as f\nimport cv2\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom wordcloud import WordCloud,STOPWORDS,ImageColorGenerator\nimport re\nimport gc\nfrom warnings import filterwarnings\nimport tensorflow as tf\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom IPython.display import clear_output\nimport plotly.express as px\nfrom nltk.corpus import stopwords as st\nimport nltk\nfrom nltk.corpus import webtext\nfrom nltk.probability import FreqDist\nfrom collections import deque\nimport plotly\nplotly.offline.init_notebook_mode (connected = True)\n\n\nfilterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family:courier;font-size:300%;color:#184d47;background-color:#e4d3cf;\">Importing Data</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/wikibooks-dataset/english-wikibooks/en-books-dataset.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family:courier;font-size:300%;background-color:#e4d3cf;\">What is this data all about ??</p>\n<ul style=\"font-family:courier;font-size:200%;\"><li>Title : Title of the wikibook </li>\n    <li>Url : Link to the wiki book </li>\n    <li>Abstract : A Summary of the wiki book </li>\n    <li>Body text : Content of the wiki book </li>\n    <li> Body html : Html code of the wiki book </li>"},{"metadata":{},"cell_type":"markdown","source":"![](https://upload.wikimedia.org/wikipedia/commons/thumb/6/6a/2011Sendai-NOAA-Energylhvpd9-05.jpg/1280px-2011Sendai-NOAA-Energylhvpd9-05.jpg)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"title=data['title'][200]\nlink=data['url'][200]\nabstract=data['abstract'][200]\nbody=data['body_text'][200]\nprint(f.YELLOW+\"Title : \",f.CYAN,title)\nprint(f.YELLOW+\"Url : \",f.CYAN,link)\nprint(f.YELLOW+\"Abstract : \",f.CYAN,abstract)\nprint(f.YELLOW+\"Body : \",f.CYAN,' '.join(body.split('.')[:2]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family:courier;font-size:300%;background-color:#e4d3cf;\">Wordcloud For The Text Body</p>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"stopwords=list(STOPWORDS)\n# Generate a word cloud image\ndata['body_text']=data['body_text'].apply(lambda x : str(x))\ntext=' '.join(data['body_text'].loc[:1000])\nmask = np.array(Image.open(\"../input/wiki-logo/Wikipedia-logo_%28inverse%29.png\"))\narrow=np.array(Image.open(\"../input/arrowww/8iAj9Xbia.png\"))\narrow=cv2.resize(arrow,(300,300))\nanother_image=np.array(Image.open('../input/multicoloredflower/Multi coloured flower.jpg'))\nmask=cv2.resize(mask,(600,600))\nanother_image=cv2.resize(another_image,(600,600))\nwordcloud_fra = WordCloud(stopwords=stopwords, background_color=\"white\", mode=\"RGBA\", max_words=1000, mask=mask).generate(text)\nfig, ax = plt.subplots(1,3,figsize=(18,8),gridspec_kw={'width_ratios': [3, 1,3]})\nax[0].imshow(mask)\nax[0].set_axis_off()\n\nax[1].imshow(arrow)\nax[1].set_axis_off()\n# create coloring from image\nimage_colors = ImageColorGenerator(another_image)\nax[2].imshow(wordcloud_fra.recolor(color_func=image_colors), interpolation=\"bilinear\")\nax[2].set_axis_off()\n# store to file\nplt.savefig(\"wiki.png\", format=\"png\")\ndel text\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-size:80%\">wikipedia logo from https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Wikipedia-logo_%28inverse%29.png/986px-Wikipedia-logo_%28inverse%29.png</p>"},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family:courier;font-size:300%;background-color:#e4d3cf;\">Top N Words Of The Data</p>"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"tex=' '.join(data['title']).lower()\nstop_words = set(st.words('english')) \ntex=re.sub(r'(?is)[^a-zA-Z0-9 ]','',tex)\ntex=re.sub(r'^[^ ]*', '', tex)\nwith open(\"/usr/share/nltk_data/corpora/webtext/Output.txt\", \"w\") as text_file:\n    text_file.write(tex)\nnltk.download('webtext')\nwt_words = webtext.words('./Output.txt')\ndata_analysis = nltk.FreqDist(wt_words)\n# Let's take the specific words only if their frequency is greater than 3.\nfor i in stop_words :\n    del data_analysis[i]\ndata_analysis = {k: v for k, v in sorted(data_analysis.items(), key=lambda item: item[1],reverse=True)}\nkey=list(data_analysis.keys())[:100]\nitem=list(data_analysis.values())[:100]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family:courier;font-size:150%;background-color:#e4d3cf;\">Would personally recommend running the animation ( Idea taken from solar system) </p>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df=pd.DataFrame(columns=['Words','Count','x','y'])\nradius=12\nto_append=[key[0],item[0]/40,0,0]\na_series = pd.Series(to_append, index = df.columns)\ndf = df.append(a_series, ignore_index=True)\ncount=1\nfor j in range(4) :\n    x=radius*j/4\n    y=radius**2-x**2\n    to_append = [key[count],item[count],x,y]\n    a_series = pd.Series(to_append, index = df.columns)\n    df = df.append(a_series, ignore_index=True)\n    count+=1\nfor j in range(4):\n    x=radius-radius*j/4\n    y=-1*(radius**2-x**2)\n    to_append = [key[count],item[count],x,y]\n    a_series = pd.Series(to_append, index = df.columns)\n    df = df.append(a_series, ignore_index=True)\n    count+=1\nfor j in range(4):\n    x=-1*(radius*j/4)\n    y=-1*(radius**2-x**2)\n    to_append = [key[count],item[count],x,y]\n    a_series = pd.Series(to_append, index = df.columns)\n    df = df.append(a_series, ignore_index=True)\n    count+=1\nfor j in range(4):\n    x=-radius+(radius*j/4)\n    y=radius**2-x**2\n    to_append = [key[count],item[count],x,y]\n    a_series = pd.Series(to_append, index = df.columns)\n    df = df.append(a_series, ignore_index=True)\n    count+=1\n    \ndef rotate_n(df,number):\n    x=[]\n    p=df.iloc[1:].values\n    for i in range(len(p)):\n        x.append([p[i,2],p[i,3]])\n    t=x.copy()\n    time=1\n    ho=len(x)\n    times=[time]*ho\n    for i in range(number-1):\n        time+=1\n        t = deque(t)\n        t.rotate(-1)\n        t = list(t)\n        x.extend(t)\n        times.extend([time]*ho)\n    x=np.array(x)\n    dn=pd.DataFrame()\n    words=[]\n    count=[]\n    for i in range(len(p)):\n        words.append(p[i,0])\n        count.append(p[i,1])\n    words=words*number\n    count=count*number\n    dn['Words']=words\n    dn['Count']=count\n    dn['x']=x[:,0]\n    dn['y']=x[:,1]\n    dn['Time']=times\n    for i in range(1,len(set(times))+1):\n        to_append = [df['Words'][0],df['Count'][0],df['x'][0],df['y'][0],i]\n        a_series = pd.Series(to_append, index = dn.columns)\n        dn = dn.append(a_series, ignore_index=True)\n        \n    return dn\ndf=rotate_n(df,20)\n\n        \n# for i in range(0,len(key)-3,3):\n#     for j in range(k):\n#         x=radius*j/k\n#         y=radius**2-x**2\n#         to_append = [key[i],item[i],x,y,time]\n#         a_series = pd.Series(to_append, index = df.columns)\n#         df = df.append(a_series, ignore_index=True)\n#         y2=0\n#         to_append = [key[i+1],item[i+1],x,y2,time]\n#         a_series = pd.Series(to_append, index = df.columns)\n#         df = df.append(a_series, ignore_index=True)\n#         y3=-1*(radius**2-x**2)\n#         to_append = [key[i+1],item[i+1],x,y3,time]\n#         a_series = pd.Series(to_append, index = df.columns)\n#         df = df.append(a_series, ignore_index=True)\n#     time+=1\n        \n# df['Count']=df['Count'].apply(lambda x : int(x))\nfig=px.scatter(df,x='x',y='y',text='Words',size='Count',size_max=40,color='Count',\n               color_continuous_scale='solar',labels={'x':'','y':''},template='plotly_dark',animation_frame='Time')\nfig.add_layout_image(\n        dict(\n            source=\"https://upload.wikimedia.org/wikipedia/en/thumb/8/80/Wikipedia-logo-v2.svg/1024px-Wikipedia-logo-v2.svg.png\",\n            xref=\"x\",\n            yref=\"y\",\n            x=-8,\n            y=40,\n            sizex=30,\n            sizey=105,\n            opacity=0.5,\n            layer=\"below\")\n)\nfig.add_layout_image(\n        dict(\n            source=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Wikipedia-logo_%28inverse%29.png/986px-Wikipedia-logo_%28inverse%29.png\",\n            xref=\"x\",\n            yref=\"y\",\n            x=2,\n            y=40,\n            sizex=30,\n            sizey=105,\n            opacity=0.5,\n            layer=\"below\")\n)\nfig.update_xaxes(range=[-radius-6,radius+6],showgrid=False)\nfig.update_yaxes(range=[-radius**2-16,radius**2+16],showgrid=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p style=\"font-family:courier;font-size:300%;background-color:#e4d3cf;\">Search Engine</p>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Let's Make a search engine using TFIDF Vectorizer :)\nmodel = TfidfVectorizer(stop_words='english', binary=True, max_features=100_000)\ntext_embeddings = model.fit_transform(data.title).toarray()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def search_it(search,print_n_top=10,return_them=False):\n    n=print_n_top\n    search_embedding=model.transform([search]).toarray()\n    areas=np.matmul(text_embeddings,search_embedding.T).T\n    k=areas[0]\n    k=sorted(k,reverse=True)\n    k=k[:n]\n    k=set(k)\n    idx=[]\n    for j in k :\n        idx.extend(np.where(areas[0,]==j)[0])\n    o=data.iloc[idx].title.values\n    l=[]\n    count=1\n    if len(o)>print_n_top:\n        o=o[:print_n_top]\n    for i in o :\n        print(f.YELLOW,str(count),')',end=' ')\n        print(f.CYAN,i)\n        l.append(i)\n        count+=1\n    if return_them :\n        return l\n         ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss=input(f.YELLOW+'Search : ')\nl=search_it(ss,return_them=True)\ns=input(f.YELLOW+\"Choose Your option\")\ns=l[int(s)-1]\nclear_output(wait=True)\ntitle=data[data['title']==s]['title'].values[0]\nlink=data[data['title']==s]['url'].values[0]\nabstract=data[data['title']==s]['abstract'].values[0]\nbody=data[data['title']==s]['body_text'].values[0]\nprint(f.YELLOW+\"Title : \",f.CYAN,title)\nprint(f.YELLOW+\"Url : \",f.CYAN,link)\nprint(f.YELLOW+\"Abstract : \",f.CYAN,abstract)\nprint(f.YELLOW+\"Body : \",f.CYAN,' '.join(body.split('.')[:2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}