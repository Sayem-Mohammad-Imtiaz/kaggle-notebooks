{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas_profiling as pp \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report, plot_roc_curve\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nimport plotly.express as px\nsns.set_theme(style='darkgrid')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-24T07:04:34.518671Z","iopub.execute_input":"2021-08-24T07:04:34.519114Z","iopub.status.idle":"2021-08-24T07:04:36.39427Z","shell.execute_reply.started":"2021-08-24T07:04:34.519016Z","shell.execute_reply":"2021-08-24T07:04:36.393382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df =pd.read_csv(\"/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:04:36.395901Z","iopub.execute_input":"2021-08-24T07:04:36.396214Z","iopub.status.idle":"2021-08-24T07:04:36.406369Z","shell.execute_reply.started":"2021-08-24T07:04:36.396183Z","shell.execute_reply":"2021-08-24T07:04:36.40533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:04:36.408589Z","iopub.execute_input":"2021-08-24T07:04:36.408996Z","iopub.status.idle":"2021-08-24T07:04:36.431971Z","shell.execute_reply.started":"2021-08-24T07:04:36.408954Z","shell.execute_reply":"2021-08-24T07:04:36.430869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:04:36.433289Z","iopub.execute_input":"2021-08-24T07:04:36.433713Z","iopub.status.idle":"2021-08-24T07:04:36.439342Z","shell.execute_reply.started":"2021-08-24T07:04:36.43368Z","shell.execute_reply":"2021-08-24T07:04:36.438345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:04:36.44073Z","iopub.execute_input":"2021-08-24T07:04:36.441193Z","iopub.status.idle":"2021-08-24T07:04:36.458478Z","shell.execute_reply.started":"2021-08-24T07:04:36.441105Z","shell.execute_reply":"2021-08-24T07:04:36.457673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:04:36.459665Z","iopub.execute_input":"2021-08-24T07:04:36.45993Z","iopub.status.idle":"2021-08-24T07:04:36.469132Z","shell.execute_reply.started":"2021-08-24T07:04:36.459904Z","shell.execute_reply":"2021-08-24T07:04:36.46821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's perform auto EDA using Pandas Profiling as the data set isn't that big.","metadata":{}},{"cell_type":"code","source":"pip install openpyxl","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:04:36.470209Z","iopub.execute_input":"2021-08-24T07:04:36.470493Z","iopub.status.idle":"2021-08-24T07:04:42.644553Z","shell.execute_reply.started":"2021-08-24T07:04:36.470466Z","shell.execute_reply":"2021-08-24T07:04:42.643447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pp.ProfileReport(df)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:04:42.647237Z","iopub.execute_input":"2021-08-24T07:04:42.647549Z","iopub.status.idle":"2021-08-24T07:04:58.800328Z","shell.execute_reply.started":"2021-08-24T07:04:42.647494Z","shell.execute_reply":"2021-08-24T07:04:58.799132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pandas Profiling has provided us some quick insights. \nLuckily, there are no missing values. ","metadata":{}},{"cell_type":"markdown","source":"According to sex let's manually figure out the percentage of male/ female affected by heart attack.","metadata":{}},{"cell_type":"code","source":"# check for how many womens are prone to heart-attack\nwomen_stroke = df.loc[df.sex == 0]['output']\nwomen_stroke_percentage = sum(women_stroke)/len(women_stroke)\nprint('The % of women prone to heart-attack: {}%'.format(women_stroke_percentage*100))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:04:58.802159Z","iopub.execute_input":"2021-08-24T07:04:58.802461Z","iopub.status.idle":"2021-08-24T07:04:58.80938Z","shell.execute_reply.started":"2021-08-24T07:04:58.802421Z","shell.execute_reply":"2021-08-24T07:04:58.808269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Correlation**","metadata":{}},{"cell_type":"code","source":"def find_correlational_map(data):\n    plt.figure(figsize=(16,12))\n    sns.heatmap(data.corr(), annot=True, cmap='OrRd')\n    plt.title('Correlational Map', weight='bold')\n    print('---'*50)\n    print(data.corr().output.sort_values(ascending = False))\n    plt.tight_layout()\n    \nfind_correlational_map(df)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:04:58.810597Z","iopub.execute_input":"2021-08-24T07:04:58.810948Z","iopub.status.idle":"2021-08-24T07:05:00.357216Z","shell.execute_reply.started":"2021-08-24T07:04:58.810914Z","shell.execute_reply":"2021-08-24T07:05:00.356208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Splitting**","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:05:00.358527Z","iopub.execute_input":"2021-08-24T07:05:00.358818Z","iopub.status.idle":"2021-08-24T07:05:00.372681Z","shell.execute_reply.started":"2021-08-24T07:05:00.358787Z","shell.execute_reply":"2021-08-24T07:05:00.371796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.iloc[:,:-1].values\ny = df.iloc[:,-1].values","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:05:00.373894Z","iopub.execute_input":"2021-08-24T07:05:00.374346Z","iopub.status.idle":"2021-08-24T07:05:00.385651Z","shell.execute_reply.started":"2021-08-24T07:05:00.374302Z","shell.execute_reply":"2021-08-24T07:05:00.384592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's split the date into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:05:00.387186Z","iopub.execute_input":"2021-08-24T07:05:00.387718Z","iopub.status.idle":"2021-08-24T07:05:00.400319Z","shell.execute_reply.started":"2021-08-24T07:05:00.387673Z","shell.execute_reply":"2021-08-24T07:05:00.399142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:05:00.401742Z","iopub.execute_input":"2021-08-24T07:05:00.402005Z","iopub.status.idle":"2021-08-24T07:05:00.411458Z","shell.execute_reply.started":"2021-08-24T07:05:00.40198Z","shell.execute_reply":"2021-08-24T07:05:00.410575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model Building**","metadata":{}},{"cell_type":"code","source":"# let's create a pipline \npipeline = make_pipeline(RobustScaler()) # creating pipeline for model building\n\nLR = make_pipeline(pipeline, LogisticRegression(random_state=0)) # LogisticRegression pipeline\nDT = make_pipeline(pipeline, DecisionTreeClassifier(random_state=0)) # DecisionTree Classifier pipeline\nRF = make_pipeline(pipeline, RandomForestClassifier(random_state=0)) # RandomForest Classifier pipeline\nAC = make_pipeline(pipeline, AdaBoostClassifier(random_state=0)) # Adaboost Classifier pipeline\nNB = make_pipeline(pipeline, GaussianNB()) # Naive bayes pipeline\nKN = make_pipeline(pipeline, KNeighborsClassifier()) # KNeighbor pipeline\nSV = make_pipeline(pipeline, SVC(random_state=0)) # Support vector pipeline","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:05:00.412945Z","iopub.execute_input":"2021-08-24T07:05:00.413222Z","iopub.status.idle":"2021-08-24T07:05:00.422604Z","shell.execute_reply.started":"2021-08-24T07:05:00.413197Z","shell.execute_reply":"2021-08-24T07:05:00.421773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating model_dict\nmodel_dictionary = {\n    'Logistic_Regression':LR,\n    'DecisionTree_Classifier':DT,\n    'RandomForest_classifier':RF,\n    'Adaboost_Classifier':AC,\n    'Naivebayes_Classifier':NB,\n    'KNeighbors_classifier':KN,\n    'Support_Vector':SV\n}","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:05:00.423651Z","iopub.execute_input":"2021-08-24T07:05:00.42405Z","iopub.status.idle":"2021-08-24T07:05:00.435459Z","shell.execute_reply.started":"2021-08-24T07:05:00.424016Z","shell.execute_reply":"2021-08-24T07:05:00.43445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model_dictionary)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:05:00.436389Z","iopub.execute_input":"2021-08-24T07:05:00.437022Z","iopub.status.idle":"2021-08-24T07:05:00.473266Z","shell.execute_reply.started":"2021-08-24T07:05:00.436982Z","shell.execute_reply":"2021-08-24T07:05:00.47233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define a function to fit the model and return it's accuracy, classification report and confusion matrix\ndef model_fitting(model):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    print('The accuracy score of the model is: {}%'.format(accuracy_score(y_test, y_pred)* 100))\n    print('-----'*20)\n    print(confusion_matrix(y_test, y_pred))\n    print(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:05:00.474487Z","iopub.execute_input":"2021-08-24T07:05:00.474755Z","iopub.status.idle":"2021-08-24T07:05:00.481309Z","shell.execute_reply.started":"2021-08-24T07:05:00.474729Z","shell.execute_reply":"2021-08-24T07:05:00.480422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Selecting the best model**","metadata":{}},{"cell_type":"code","source":"for name, model in model_dictionary.items():\n    print('---'*10)\n    print(name)\n    model_fitting(model)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:05:00.482901Z","iopub.execute_input":"2021-08-24T07:05:00.48331Z","iopub.status.idle":"2021-08-24T07:05:00.815857Z","shell.execute_reply.started":"2021-08-24T07:05:00.483267Z","shell.execute_reply":"2021-08-24T07:05:00.814621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see:\n\nAda boost has got 90% accuracy with only 6 misclassified classes.\nIt' has a precision of 0.86 for classes 0 and 0.94 for classes 1, which is better than all other algorithms.\n**Let's use Adaboost Model**","metadata":{}},{"cell_type":"code","source":"model = AdaBoostClassifier(random_state=0)\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:05:00.817196Z","iopub.execute_input":"2021-08-24T07:05:00.817482Z","iopub.status.idle":"2021-08-24T07:05:00.901962Z","shell.execute_reply.started":"2021-08-24T07:05:00.817453Z","shell.execute_reply":"2021-08-24T07:05:00.900836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)\naccuracy_score(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:05:00.903403Z","iopub.execute_input":"2021-08-24T07:05:00.90382Z","iopub.status.idle":"2021-08-24T07:05:00.922242Z","shell.execute_reply.started":"2021-08-24T07:05:00.903776Z","shell.execute_reply":"2021-08-24T07:05:00.92103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_confusion_matrix(y_test, y_pred):\n    cm = confusion_matrix(y_test, y_pred)\n    sns.heatmap(cm, annot=True, cmap='OrRd')\n    plt.title('Confusion Matrix', weight='bold')\n    print(classification_report(y_test, y_pred))\n    plot_roc_curve(model, X_test, y_test)\n    \n    \nfind_confusion_matrix(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:05:00.923722Z","iopub.execute_input":"2021-08-24T07:05:00.924054Z","iopub.status.idle":"2021-08-24T07:05:01.378447Z","shell.execute_reply.started":"2021-08-24T07:05:00.924022Z","shell.execute_reply":"2021-08-24T07:05:01.377534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The accuracy of the model is: {}%'.format(round(accuracy_score(y_test, y_pred)*100, 2)))","metadata":{"execution":{"iopub.status.busy":"2021-08-24T07:05:01.380934Z","iopub.execute_input":"2021-08-24T07:05:01.381227Z","iopub.status.idle":"2021-08-24T07:05:01.387441Z","shell.execute_reply.started":"2021-08-24T07:05:01.381196Z","shell.execute_reply":"2021-08-24T07:05:01.386467Z"},"trusted":true},"execution_count":null,"outputs":[]}]}