{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Notebook Goals\n\nModel Customer Churn using features provided in the TeleCo Dataset.\n\nI received inspiration from the following articles and notebooks. If you find it useful, please give them a like and upvote.\n\n* https://towardsdatascience.com/survival-analysis-intuition-implementation-in-python-504fde4fcf8e\n* https://www.kaggle.com/gregoiredc/survival-analysis-or-nn-predict-age\n* https://www.kaggle.com/bryanb/survival-analysis-with-cox-model-implementation","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n%matplotlib inline        \n        \n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"raw_data = pd.read_csv(\"/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv\",low_memory=False)\nraw_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check Data Types","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check for Missing Values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_perc = raw_data.isnull().mean()\nmissing_perc = missing_perc[missing_perc > 0]\n\nmissing_perc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df = raw_data.copy()\npreprocess_df.shape\n\n# Delete raw data.\n# del raw_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Pre-Processing and Cleaning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Yes / No Columns\n\nConvert the features with 'yes/no' responses to 1 and 0","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_n_cols = ['Partner', 'Dependents', 'PhoneService', 'OnlineSecurity',\n            'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n            'StreamingMovies', 'PaperlessBilling', 'MultipleLines']\nyes_no_df = preprocess_df[y_n_cols].copy()\nyes_no_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the most frequently occuring observations in each columns\n\ncols = list(yes_no_df.columns)\nfor col in cols:\n    print(\"Column Name: \" + col)\n    print(preprocess_df[col].value_counts().head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"replacement_dict = {'Yes': 1,\n                    'No': 0,\n                    'No internet service':0,\n                    'No phone service':0}\n\nyes_no_df.replace(replacement_dict, inplace=True)\nyes_no_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = list(yes_no_df.columns)\nfor col in cols:\n    print(\"Column Name: \" + col)\n    print(yes_no_df[col].value_counts().head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df.drop(y_n_cols, axis=1, inplace=True)\nprint(preprocess_df.shape)\npreprocess_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df = pd.concat([preprocess_df, yes_no_df], axis=1, sort=False)\nprint(preprocess_df.shape)\npreprocess_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Internet Service\n\nCreate a new feature of indicating internet service type and remap InternetService values in binary value (0 = no internet service, 1 = internet service)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df['InternetServiceType'] = preprocess_df['InternetService']\npreprocess_df[['InternetService', 'InternetServiceType']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IS_replacement_dict = {'Fiber optic': 1,\n                       'DSL': 1,\n                       'No': 0}\npreprocess_df['InternetService'].replace(IS_replacement_dict, inplace=True)\npreprocess_df['InternetServiceType'].replace('No', 'None', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df['InternetService'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## get_dummies for 'gender', 'Contract', 'PaymentMethod', and 'InternetServiceType'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"make_dummy = ['gender', 'Contract', 'PaymentMethod', 'InternetServiceType']\nmake_dummy_df = preprocess_df[make_dummy].copy()\nmake_dummy_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = list(make_dummy_df.columns)\nfor col in cols:\n    print(\"Column Name: \" + col)\n    print(make_dummy_df[col].value_counts().head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_dummy_df = pd.get_dummies(make_dummy_df)\nmake_dummy_df.drop(['gender_Male'], axis=1, inplace=True)\nmake_dummy_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df.drop(make_dummy, axis=1, inplace=True)\nprint(preprocess_df.shape)\npreprocess_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df = pd.concat([preprocess_df, make_dummy_df], axis=1, sort=False)\nprint(preprocess_df.shape)\npreprocess_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Churn\n\nIndicates with the customer was lost or not. Remap to binary value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"churn_dict = {'No': 0,\n              'Yes': 1}\npreprocess_df['Churn'].replace(churn_dict, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Binning Customer Tenure\n\nTenure is the number months that the customer has/was with TeleCo. Customers are either 1 month, 72 months (5 years), 2, 3, or 4 months.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df['tenure'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create bins for customer tenure with teleco\nbins = [0, 6, 12, 18, 24, 30, 36, 48, 60, 72]\nlabels = ['tenure_0_to_6', 'tenure_6_to_12', 'tenure_12_to_18', 'tenure_18_to_24', 'tenure_24_to_30',\n          'tenure_30_to_36', 'tenure_36_to_48', 'tenure_48_to_60', 'tenure_60_to_72']\n\n# create new feature indicating the customer tenure in months binnned\npreprocess_df['tenure_binned'] = pd.cut(preprocess_df['tenure'], bins, labels=labels)\n\n# print by bin count\npreprocess_df['tenure_binned'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create dataframe of number of customer tenure\ntenure_number = pd.DataFrame(pd.get_dummies(preprocess_df['tenure_binned']))\n\n# add the tenure_binned dummy variables to the dataframe\npreprocess_df = pd.concat([preprocess_df, tenure_number], axis=1, sort=False)\n\n# drop the previously created tenure_binned feature with the get_dummies created\npreprocess_df.drop(['tenure_binned'], axis=1, inplace=True)\npreprocess_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check column datatypes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_df.TotalCharges = pd.to_numeric(preprocess_df.TotalCharges, errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"process_df = preprocess_df.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis and Visualization","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Correlation Among Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sample figsize in inches\nfig, ax = plt.subplots(figsize=(20,10))\n\n# Imbalanced DataFrame Correlation\ncorr = process_df.corr()\nsns.heatmap(corr, cmap='YlGnBu', annot_kws={'size':30}, ax=ax)\nax.set_title(\"Correlation Matrix\", fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# See correlation of 'Churn' with other variables\nplt.figure(figsize=(15,8))\nprocess_df.corr()['Churn'].sort_values(ascending = False).plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Features Positively Correlated with Churn","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = process_df.Churn.value_counts().plot(kind='bar')\nlabels = ['No', 'Yes']\nax.set_xticklabels(labels, rotation='horizontal')\nax.set_ylabel('Number of Customers')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"contract_m2m = pd.crosstab(process_df['Contract_Month-to-month'], process_df['Churn'])\nax = contract_m2m.plot.bar(alpha=0.7)\nax.set_xlabel('Month to Month Contracts')\nlabels = ['NO', 'YES']\nax.set_xticklabels(labels, rotation='horizontal')\nax.set_title('Customer Churn for Customers on Month to Month Contracts')\nax.legend([\"No\", \"Yes\"], title=\"Customer Churn\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IST_fiber = pd.crosstab(process_df['InternetServiceType_Fiber optic'], process_df['Churn'])\nax = IST_fiber.plot.bar(alpha=0.7)\nax.set_xlabel('Fiber Optics')\nlabels = ['NO', 'YES']\nax.set_xticklabels(labels, rotation='horizontal')\nax.set_title('Customer Churn for Customers on Fiber Optics')\nax.legend([\"No\", \"Yes\"], title=\"Customer Churn\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pmt_type_EC = pd.crosstab(process_df['PaymentMethod_Electronic check'], process_df['Churn'])\nax = pmt_type_EC.plot.bar(alpha=0.7)\nax.set_xlabel('Payment Type Electronic Check')\nlabels = ['NO', 'YES']\nax.set_xticklabels(labels, rotation='horizontal')\nax.set_title('Customer Churn for Customers on Electronic Check Payments')\nax.legend([\"No\", \"Yes\"], title=\"Customer Churn\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Features Negatively Correlated with Churn","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"process_df['tenure_0_to_6']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Bin Customer Tenure\n\ncustomer_tenure = process_df[['tenure_0_to_6', 'tenure_6_to_12', 'tenure_12_to_18', 'tenure_18_to_24',\n                              'tenure_24_to_30', 'tenure_30_to_36', 'tenure_36_to_48', 'tenure_48_to_60',\n                              'tenure_60_to_72', 'Churn']]\n\n# See correlation of 'Churn' with Customer Tenure\nplt.figure(figsize=(15,8))\ncustomer_tenure.corr()['Churn'].sort_values(ascending = False).plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"two_year_contract = pd.crosstab(process_df['Contract_Two year'], process_df['Churn'])\nax = two_year_contract.plot.bar(alpha=0.7)\nax.set_xlabel('Two Year Contract')\nlabels = ['NO', 'YES']\nax.set_xticklabels(labels, rotation='horizontal')\nax.set_title('Customer Churn for Customers on Two year Contracts')\nax.legend([\"No\", \"Yes\"], title=\"Customer Churn\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"one_year_contract = pd.crosstab(process_df['Contract_One year'], process_df['Churn'])\nax = one_year_contract.plot.bar(alpha=0.7)\nax.set_xlabel('One Year Contract')\nlabels = ['NO', 'YES']\nax.set_xticklabels(labels, rotation='horizontal')\nax.set_title('Customer Churn for Customers on One Year Contracts')\nax.legend([\"No\", \"Yes\"], title=\"Customer Churn\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression Classifier Modeling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictive_features = ['Contract_One year', 'Contract_Two year','tenure',\n                       'PaymentMethod_Electronic check','InternetServiceType_Fiber optic',\n                       'Contract_Month-to-month']\nmodel_features = process_df[predictive_features]\nmodel_features = pd.concat([model_features, process_df['Churn']], axis=1, sort=False)\nmodel_features.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Training and Testing Sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = model_features.drop(['Churn'], axis=1)\ny = model_features['Churn']\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=123)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create, train, and fitting a model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create, train, and fit a logistic regression model\nfrom sklearn.linear_model import LogisticRegression\nclf_logistic = LogisticRegression(solver='lbfgs').fit(X_train, np.ravel(y_train))\n\n# Create predictions of probability for loan status using test data\n# .predict_proba creates an array of probabilities of default: [[non-defualt, default]]\nlr_preds = clf_logistic.predict_proba(X_test)\n\n# # Create dataframes of predictions and true labels\nlr_preds_df = pd.DataFrame(lr_preds[:,1][0:], columns = ['lr_pred'])\ntrue_df = y_test\n\n# Concatenate and print the two data frames for comparison\nprint(pd.concat([true_df.reset_index(drop = True), lr_preds_df], axis = 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LR Confusion Matrix and Classification Report","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reassign loan status based on the threshold and print the predictions\nlr_preds_df['lr_pred_churn_status_50'] = lr_preds_df['lr_pred'].apply(lambda x: 1 if x > 0.50 else 0)\nprint(\"Churn: Yes / Not Churn predictions at 50% Threshhold: \")\nprint(lr_preds_df['lr_pred_churn_status_50'].value_counts())\n\n# Print the confusion matrix\nfrom sklearn.metrics import confusion_matrix\nprint(\"Confusion Matrix at 50% Threshhold: \")\nprint(confusion_matrix(y_test, lr_preds_df['lr_pred_churn_status_50']))\n\n# Print the classification report\nfrom sklearn.metrics import classification_report\ntarget_names = ['No Churn', 'Yes Churn']\nprint(classification_report(y_test, lr_preds_df['lr_pred_churn_status_50'], target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Plotting AUC for Logistic Regression Classification","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the accuracy score the model\nprint(clf_logistic.score(X_test, y_test))\n\n# Plot the ROC curve of the probabilities of default\nfrom sklearn.metrics import roc_curve\n\nlr_pred_churn = lr_preds[:, 1]\nfallout, sensitivity, thresholds = roc_curve(y_test, lr_pred_churn)\nplt.plot(fallout, sensitivity, color = 'darkorange')\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.title(\"ROC Chart for LR on Churn\")\nplt.xlabel(\"Fall-out\")\nplt.ylabel(\"Sensitivity\")\nplt.show()\n\n# Compute the AUC and store it in a variable\nfrom sklearn.metrics import roc_auc_score\n\nlr_auc = roc_auc_score(y_test, lr_pred_churn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create, train and fit a model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train a model\nimport xgboost as xgb\nclf_gbt = xgb.XGBClassifier().fit(X_train, np.ravel(y_train))\n\n# Predict with a model\n# .predict_proba creates an array of probabilities of default: [['No Churn', 'Churn']]\ngbt_preds = clf_gbt.predict_proba(X_test)\n\n# Create dataframes of first five predictions, and first five true labels\ngbt_preds_df = pd.DataFrame(gbt_preds[:,1][0:], columns = ['gbt_pred_churn'])\ntrue_df = y_test\n\n# Concatenate and print the two data frames for comparison\nprint(pd.concat([true_df.reset_index(drop = True), gbt_preds_df], axis = 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## GBT Confusion Matrix and Classification Report","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reassign loan status based on the threshold and print the predictions\ngbt_preds_df['gbt_pred_churn_status_50'] = gbt_preds_df['gbt_pred_churn'].apply(lambda x: 1 if x > 0.50 else 0)\nprint(\"No Churn / Churn at 50% Threshhold: \")\nprint(gbt_preds_df['gbt_pred_churn_status_50'].value_counts())\n\n# Print the confusion matrix\nprint(\"Confusion Matrix at 50% Threshhold: \")\nprint(confusion_matrix(y_test, gbt_preds_df['gbt_pred_churn_status_50']))\n\n# Print the classification report\ntarget_names = ['No Churn', 'Churn']\nprint(classification_report(y_test, gbt_preds_df['gbt_pred_churn_status_50'], target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting AUC for GBT Classification","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the accuracy score the model\nprint(clf_gbt.score(X_test, y_test))\n\n# Plot the ROC curve of the probabilities of default\nfrom sklearn.metrics import roc_curve\n\nxgb_pred_churn = gbt_preds[:, 1]\nfallout, sensitivity, thresholds = roc_curve(y_test, xgb_pred_churn)\nplt.plot(fallout, sensitivity, color = 'darkorange')\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.title(\"ROC Chart for XGB on Churn\")\nplt.xlabel(\"Fall-out\")\nplt.ylabel(\"Sensitivity\")\nplt.show()\n\n# Compute the AUC and store it in a variable\nfrom sklearn.metrics import roc_auc_score\n\nxgb_auc = roc_auc_score(y_test, xgb_pred_churn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Surival Analysis with KMF","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install lifelines\nfrom lifelines import KaplanMeierFitter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"process_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmf1 = KaplanMeierFitter() ## instantiate the class to create an object\n\ntenure = process_df['tenure']\nevent = process_df['Churn']\n\n## Two Cohorts are compared. Cohort 1. Streaming TV Not Subscribed by users, and Cohort  2. Streaming TV subscribed by the users.\nstreaming_cohorts = process_df['StreamingTV']    \nno_stream_TV = (streaming_cohorts == 0)      ## Cohort WITHOUT streaming TV, having the pandas series  for the 1st cohort\nyes_stream_TV = (streaming_cohorts == 1)     ## Cohort WITH streaming TV, having the pandas series  for the 2nd cohort\n\n\n## fit the model for 1st cohort\nkmf1.fit(tenure[no_stream_TV], event[no_stream_TV], label='Not Subscribed StreamingTV')\na1 = kmf1.plot()\n\n## fit the model for 2nd cohort\nkmf1.fit(tenure[yes_stream_TV], event[yes_stream_TV], label='Subscribed StreamingTV')\nkmf1.plot(ax=a1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tenure[no_stream_TV]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"survival_pred_df = process_df[['tenure', 'Churn', 'MonthlyCharges', 'SeniorCitizen', 'InternetService',\n                               'Partner', 'Dependents', 'PhoneService', 'StreamingTV']]\nsurvival_pred_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lifelines import CoxPHFitter\n\ncph = CoxPHFitter()\n\ncph.fit(survival_pred_df, 'tenure', event_col='Churn')\n\ncph.print_summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 8))\ncph.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## We want to see the Survival curve at the customer level. Therefore, we have selected 6 customers (rows 5 till 9).\n\ntr_rows = survival_pred_df.iloc[5:10, 2:]\ntr_rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets predict the survival curve for the selected customers. \n## Customers can be identified with the help of the number mentioned against each curve.\nsns.set(rc={'figure.figsize':(18,10)})\ncph.predict_survival_function(tr_rows).plot(figsize=(16,8))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}