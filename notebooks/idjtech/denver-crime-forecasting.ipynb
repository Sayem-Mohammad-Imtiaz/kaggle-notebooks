{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nDocumentation for Denver Crime Forecasting using Time Series Analysis\n\nI recently completed the Udemy course: Python for Time Series Analysis and Forecasting with an intense feeling of excitement. On my path to becoming a data scientist, this moment feels like a major milestone. I’ve never felt so eager to apply what I’ve learned.\n\nThis is my first real project and I would welcome efficiency and general improvement suggestions. There is probably a much more elegant way to digitise the data than the method I used, which was cumbersome, but functional.\n\nThis project does two things:\n•\tExamines which crime categories vary seasonally\n•\tMakes forecasts of future crime rates for selected crime categories\n\nHere’s the breakdown\n1.\tA list of references I used during construction\n2.\tLibrary Imports\n3.\tDataFrame creation from the CSV data file\n4.\tSet the index to datetime format\n5.\tDataFrame cleanup – remove unwanted columns\n6.\tDigitisation, Step 1 – create a template for translating the categorical entries to numeric\n7.\tDigitisation, Step 2 – make a time series of the crime category to use as a basis for digitising the individual crime categories\n8.\tDigitisation, Step 2 – make time series for individual crime categories and transform them into digital\n9.\tAdd the digitised crime categories to the DataFrame\n10.\tImport Seasonality data CSV file – I requested the temperature data for a Denver zip code from https://www.climate.gov/maps-data/dataset/past-weather-zip-code-data-table and made a CSV\n11.\tSuspecting burglary is seasonal, I overlaid the two data sets\n12.\tResample the crime category data to a weekly basis to match the temperature data\n13.\tExamine all the crime categories for seasonal variation\n14.\tPreparing for application of forecasting: test for trends and auto-regression/auto-correlation\n15.\tUse StatsModel Seasonal Decomposition to break out the seasonal element\n16.\tTest Larceny against seasonal temperatures (with an 80 point boost to get a good overlap)\n17.\tTest whether Larceny is truly seasonal:\nRemove the seasonal element and test for randomness\n(it should be random if the seasonal influence has been correctly identified and removed)\n18.\tModel the data with ARIMA – use the ACF/PACF plots to select model order\n19.\tTest against other orders to see if we have the best model\n20.\tUse the modelled data to make forecasts\n21.\tTry modelling with STL seasonal decomposition, forecast and test residuals\n22.\tTry Holts-Winters exponential smoothing, forecast and test residuals\n\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed# https://www.kaggle.com/kappa420/districts\n# https://colorado.hometownlocator.com/zip-codes/zipcodes,city,denver.cfm\n# https://www.climate.gov/maps-data/dataset/past-weather-zip-code-data-table\n# https://www.usclimatedata.com/climate/denver/colorado/united-states/usco0105\n# http://benalexkeen.com/resampling-time-series-data-with-pandas/\n# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.resample.html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install stldecompose","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport statsmodels as sm\nimport matplotlib.pylab as plb\n\nfrom pandas.plotting import register_matplotlib_converters\nfrom scipy.stats import norm\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nfrom stldecompose import decompose\nfrom stldecompose import forecast\nfrom stldecompose.forecast_funcs import (naive,\n                                         drift, \n                                         mean, \n                                         seasonal_naive)\n\npd.plotting.register_matplotlib_converters()\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"denverCrime_df = pd.read_csv('../input/denvercrime/DenverCrime.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"denverCrime_df.FIRST_OCCURRENCE_DATE = pd.to_datetime(denverCrime_df.FIRST_OCCURRENCE_DATE)\ndenverCrime_df.index = pd.DatetimeIndex(denverCrime_df[\"FIRST_OCCURRENCE_DATE\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"crimeCats = list(denverCrime_df.OFFENSE_CATEGORY_ID.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"crimes3_df = denverCrime_df.drop(columns=['INCIDENT_ID','OFFENSE_ID','OFFENSE_CODE','OFFENSE_CODE_EXTENSION',\n                                          'OFFENSE_TYPE_ID','OFFENSE_CATEGORY_ID','FIRST_OCCURRENCE_DATE',\n                                          'LAST_OCCURRENCE_DATE','REPORTED_DATE','PRECINCT_ID','DISTRICT_ID',\n                                          'IS_CRIME','IS_TRAFFIC'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Digitisation step 1 - create template\naocSwap={'all-other-crimes':1, 'larceny':0, 'theft-from-motor-vehicle':0, 'traffic-accident':0,\n          'drug-alcohol':0, 'auto-theft':0, 'white-collar-crime':0, 'burglary':0, 'public-disorder':0,\n          'aggravated-assault':0, 'other-crimes-against-persons':0, 'robbery':0, 'sexual-assault':0,\n          'murder':0, 'arson':0}\nlarcSwap={'all-other-crimes':0, 'larceny':1, 'theft-from-motor-vehicle':0, 'traffic-accident':0,\n          'drug-alcohol':0, 'auto-theft':0, 'white-collar-crime':0, 'burglary':0, 'public-disorder':0,\n          'aggravated-assault':0, 'other-crimes-against-persons':0, 'robbery':0, 'sexual-assault':0,\n          'murder':0, 'arson':0}\ntmvSwap={'all-other-crimes':0, 'larceny':0, 'theft-from-motor-vehicle':1, 'traffic-accident':0,\n          'drug-alcohol':0, 'auto-theft':0, 'white-collar-crime':0, 'burglary':0, 'public-disorder':0,\n          'aggravated-assault':0, 'other-crimes-against-persons':0, 'robbery':0, 'sexual-assault':0,\n          'murder':0, 'arson':0}\ntaSwap={'all-other-crimes':0, 'larceny':0, 'theft-from-motor-vehicle':0, 'traffic-accident':1,\n          'drug-alcohol':0, 'auto-theft':0, 'white-collar-crime':0, 'burglary':0, 'public-disorder':0,\n          'aggravated-assault':0, 'other-crimes-against-persons':0, 'robbery':0, 'sexual-assault':0,\n          'murder':0, 'arson':0}\ndaSwap={'all-other-crimes':0, 'larceny':0, 'theft-from-motor-vehicle':0, 'traffic-accident':0,\n          'drug-alcohol':1, 'auto-theft':0, 'white-collar-crime':0, 'burglary':0, 'public-disorder':0,\n          'aggravated-assault':0, 'other-crimes-against-persons':0, 'robbery':0, 'sexual-assault':0,\n          'murder':0, 'arson':0}\natSwap={'all-other-crimes':0, 'larceny':0, 'theft-from-motor-vehicle':0, 'traffic-accident':0,\n          'drug-alcohol':0, 'auto-theft':1, 'white-collar-crime':0, 'burglary':0, 'public-disorder':0,\n          'aggravated-assault':0, 'other-crimes-against-persons':0, 'robbery':0, 'sexual-assault':0,\n          'murder':0, 'arson':0}\nwccSwap={'all-other-crimes':0, 'larceny':0, 'theft-from-motor-vehicle':0, 'traffic-accident':0,\n          'drug-alcohol':0, 'auto-theft':0, 'white-collar-crime':1, 'burglary':0, 'public-disorder':0,\n          'aggravated-assault':0, 'other-crimes-against-persons':0, 'robbery':0, 'sexual-assault':0,\n          'murder':0, 'arson':0}\nburgSwap={'all-other-crimes':0, 'larceny':0, 'theft-from-motor-vehicle':0, 'traffic-accident':0,\n          'drug-alcohol':0, 'auto-theft':0, 'white-collar-crime':0, 'burglary':1, 'public-disorder':0,\n          'aggravated-assault':0, 'other-crimes-against-persons':0, 'robbery':0, 'sexual-assault':0,\n          'murder':0, 'arson':0}\npudiSwap={'all-other-crimes':0, 'larceny':0, 'theft-from-motor-vehicle':0, 'traffic-accident':0,\n          'drug-alcohol':0, 'auto-theft':0, 'white-collar-crime':0, 'burglary':0, 'public-disorder':1,\n          'aggravated-assault':0, 'other-crimes-against-persons':0, 'robbery':0, 'sexual-assault':0,\n          'murder':0, 'arson':0}\nassSwap={'all-other-crimes':0, 'larceny':0, 'theft-from-motor-vehicle':0, 'traffic-accident':0,\n          'drug-alcohol':0, 'auto-theft':0, 'white-collar-crime':0, 'burglary':0, 'public-disorder':0,\n          'aggravated-assault':1, 'other-crimes-against-persons':0, 'robbery':0, 'sexual-assault':0,\n          'murder':0, 'arson':0}\nocpSwap={'all-other-crimes':0, 'larceny':0, 'theft-from-motor-vehicle':0, 'traffic-accident':0,\n          'drug-alcohol':0, 'auto-theft':0, 'white-collar-crime':0, 'burglary':0, 'public-disorder':0,\n          'aggravated-assault':0, 'other-crimes-against-persons':1, 'robbery':0, 'sexual-assault':0,\n          'murder':0, 'arson':0}\nrobSwap={'all-other-crimes':0, 'larceny':0, 'theft-from-motor-vehicle':0, 'traffic-accident':0,\n          'drug-alcohol':0, 'auto-theft':0, 'white-collar-crime':0, 'burglary':0, 'public-disorder':0,\n          'aggravated-assault':0, 'other-crimes-against-persons':0, 'robbery':1, 'sexual-assault':0,\n          'murder':0, 'arson':0}\nsexSwap={'all-other-crimes':0, 'larceny':0, 'theft-from-motor-vehicle':0, 'traffic-accident':0,\n          'drug-alcohol':0, 'auto-theft':0, 'white-collar-crime':0, 'burglary':0, 'public-disorder':0,\n          'aggravated-assault':0, 'other-crimes-against-persons':0, 'robbery':0, 'sexual-assault':1,\n          'murder':0, 'arson':0}\nmurdSwap={'all-other-crimes':0, 'larceny':0, 'theft-from-motor-vehicle':0, 'traffic-accident':0,\n          'drug-alcohol':0, 'auto-theft':0, 'white-collar-crime':0, 'burglary':0, 'public-disorder':0,\n          'aggravated-assault':0, 'other-crimes-against-persons':0, 'robbery':0, 'sexual-assault':0,\n          'murder':1, 'arson':0}\narsSwap={'all-other-crimes':0, 'larceny':0, 'theft-from-motor-vehicle':0, 'traffic-accident':0,\n          'drug-alcohol':0, 'auto-theft':0, 'white-collar-crime':0, 'burglary':0, 'public-disorder':0,\n          'aggravated-assault':0, 'other-crimes-against-persons':0, 'robbery':0, 'sexual-assault':0,\n          'murder':0, 'arson':1}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Digitisation step 2 - create a basis\ndenverCrime_ts=pd.Series(denverCrime_df['OFFENSE_CATEGORY_ID'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Digitisation step 3 - create individual crime_cat time series and transform into digital\n# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.replace.html\naoc_ts = denverCrime_ts.replace(aocSwap)\nlarceny_ts = denverCrime_ts.replace(larcSwap)\ntmv_ts = denverCrime_ts.replace(tmvSwap)\nta_ts = denverCrime_ts.replace(taSwap)\nda_ts = denverCrime_ts.replace(daSwap)\nat_ts = denverCrime_ts.replace(atSwap)\nwcc_ts = denverCrime_ts.replace(wccSwap)\nburg_ts = denverCrime_ts.replace(burgSwap)\npudi_ts = denverCrime_ts.replace(pudiSwap)\nass_ts = denverCrime_ts.replace(assSwap)\nocp_ts = denverCrime_ts.replace(ocpSwap)\nrob_ts = denverCrime_ts.replace(robSwap)\nsex_ts = denverCrime_ts.replace(sexSwap)\nmurd_ts = denverCrime_ts.replace(murdSwap)\nars_ts = denverCrime_ts.replace(arsSwap)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"crimes3_df['AOC'] = aoc_ts\ncrimes3_df['Larc'] = larceny_ts\ncrimes3_df['TfMV'] = tmv_ts\ncrimes3_df['RTA'] = ta_ts\ncrimes3_df['D&A'] = da_ts\ncrimes3_df['GTA'] = at_ts\ncrimes3_df['WCC'] = wcc_ts\ncrimes3_df['Burg'] = burg_ts\ncrimes3_df['PuDi'] = pudi_ts\ncrimes3_df['Ass'] = ass_ts\ncrimes3_df['OCaP'] = ocp_ts\ncrimes3_df['Rob'] = rob_ts\ncrimes3_df['SexAslt'] = sex_ts\ncrimes3_df['Murd'] = murd_ts\ncrimes3_df['Ars'] = ars_ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Denver seasonal temperatures\n# https://www.climate.gov/maps-data/dataset/past-weather-zip-code-data-table\ndenverWeather_df = pd.read_csv('../input/denverweather/DenverWeather2.csv')\ndenverWeather_df.DATE = pd.to_datetime(denverWeather_df.DATE)\ndenverMaxTemps_ts = pd.Series(denverWeather_df['TMAX'].values,\n                 index = pd.DatetimeIndex(data = (tuple(pd.date_range('1/1/2014',\n                                                                      periods = 2042,\n                                                                      freq = 'D'))),\n                                          freq = 'D'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Is Denver burglary seasonal? \nburgSum = crimes3_df.Burg.resample('W').sum()\n\nrollingTmax = denverMaxTemps_ts.rolling(window=30)\nrollingTmax_mean = rollingTmax.mean()\n\nplt.figure(figsize = (15,6))\n\nplt.title('Overall trend of Burglaries in Denver', fontsize=16)\nplt.ylabel('Number of Burglaries')\nplt.xlabel('Year')\nplt.plot(burgSum, label='Burglaries')\nrollingTmax_mean.plot(color='green', label='Avg Temp (degF)')\nplt.grid(True)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resample the data on a weekly basis to match the temperature data\naocSum = crimes3_df.AOC.resample('W').sum()\nlarcSum = crimes3_df.Larc.resample('W').sum()\ntmvSum = crimes3_df.TfMV.resample('W').sum()\nrtaSum = crimes3_df.RTA.resample('W').sum()\ndaSum = crimes3_df['D&A'].resample('W').sum()\natSum = crimes3_df.GTA.resample('W').sum()\nwccSum = crimes3_df.WCC.resample('W').sum()\nburgSum = crimes3_df.Burg.resample('W').sum()\npudiSum = crimes3_df.PuDi.resample('W').sum()\nassSum = crimes3_df.Ass.resample('W').sum()\nocpSum = crimes3_df.OCaP.resample('W').sum()\nrobSum = crimes3_df.Rob.resample('W').sum()\nsexSum = crimes3_df.SexAslt.resample('W').sum()\nmurdSum = crimes3_df.Murd.resample('W').sum()\narsSum = crimes3_df.Ars.resample('W').sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sumList=[aocSum,larcSum,tmvSum,rtaSum,daSum,atSum,wccSum,burgSum,pudiSum,assSum,ocpSum,robSum,sexSum,murdSum,arsSum]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's look at the seasonality of the crime categories\nrollingTmax = denverMaxTemps_ts.rolling(window=30)\nrollingTmax_mean = rollingTmax.mean()\n\nfor i in range(len(sumList)):\n    plt.figure(figsize = (15,6))\n    plt.title('Overall trend of ' +crimeCats[i]+ ' in Denver', fontsize=16)\n    plt.ylabel('Count of ' + crimeCats[i])\n    plt.xlabel('Year')\n    plt.plot(sumList[i], label=crimeCats[i])\n    rollingTmax_mean.plot(color='green', label='Avg Temp (degF)')\n    plt.grid(True)\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets look at larceny...","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test for Stationarity - does the data show a trend?\ndef stationarity_test(timeseries):\n    \"\"\"\"Augmented Dickey-Fuller Test\n    Test for Stationarity\"\"\"\n    print(\"Results of Dickey-Fuller Test:\")\n    df_test = adfuller(timeseries, autolag = \"AIC\")\n    df_output = pd.Series(df_test[0:4],\n                          index = [\"Test Statistic\", \"p-value\", \"#Lags Used\",\n                                   \"Number of Observations Used\"])\n    print(df_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# larceny\ndenverLarc_ts = pd.Series(crimes3_df.Larc.resample('W').sum(),\n                     index = pd.date_range('2014-01-01',\n                                           periods = 288,\n                                           freq = 'W'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stationarity_test(denverLarc_ts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dickey-Fuller results imply stationarity/no trend (p-value is < 0.05)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Is there auto-correlation in raw larceny data?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12,8))\n\nax1 = fig.add_subplot(211)\nfig = plot_acf(denverLarc_ts, lags=40, ax=ax1)\nax2 = fig.add_subplot(212)\nfig = plot_pacf(denverLarc_ts, lags=40, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lots of auto-correlation in the above","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perform seasonal decompostion and explore...","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decompDenverLarc = seasonal_decompose(denverLarc_ts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dplot = decompDenverLarc.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# is larceny seasonality driven by climate?\ndenverLarcSeasonAdj = decompDenverLarc.seasonal+80\nplt.figure(figsize=(12,8))\ndenverLarcSeasonAdj.plot(color='blue', label='Denver larceny seasonality')\nrollingTmax_mean.plot(color='green', label='Avg Temp (degF)')\nplt.grid()\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# but what about when seasonal element removed?\nplt.figure(figsize=(12,8))\n(decompDenverLarc.observed-decompDenverLarc.seasonal).plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# If seasonality is climate-driven (i.e. we have fully identified the dependencies) then the residual should be random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram of the Residuals\n# Importing function for normal distribution\nplt.figure(figsize = (12, 8))\nplt.hist((decompDenverLarc.observed-decompDenverLarc.seasonal), bins = 'auto', density = True, rwidth = 0.85,\n         label = 'De-seasonalised') #density TRUE - norm.dist bell curve\nmu, std = norm.fit((decompDenverLarc.observed-decompDenverLarc.seasonal))\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100) #linspace returns evenly spaced numbers over a specified interval\np = norm.pdf(x, mu, std) #pdf = probability density function\nplt.plot(x, p, 'm', linewidth = 2)\nplt.grid(axis='y', alpha = 0.2)\nplt.xlabel('Residuals')\nplt.ylabel('Density')\nplt.title('De-seasoned Larceny vs Normal Distribution - Mean = '+str(round(mu,2))+', Std = '+str(round(std,2)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# is there auto-correlation with seasonality removed?\nfig = plt.figure(figsize=(12,8))\n\nax1 = fig.add_subplot(211)\nfig = plot_acf((decompDenverLarc.observed-decompDenverLarc.seasonal), lags=40, ax=ax1)\nax2 = fig.add_subplot(212)\nfig = plot_pacf((decompDenverLarc.observed-decompDenverLarc.seasonal), lags=40, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# how to make an ARIMA model for Denver burglaries","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nHere we're looking at p and q arguments for ARIMA: p for the auto-regression, and q for the moving average part.\nThese two interact quite a bit. So how do we test for auto-regression? It is a visual task with ACF and PACF\nplots. The ACF plot excludes the autocorrelation of the shorter lags, the ACF does not.\n\nThe plot sheet shows both ACF and PACF plots. It is not always clear how to best start the parameter\nselection process from these plots. It of course helps if you know the story behind the data.\n\nGenerally the ACF plot tells you the lags for the Moving Average (MA) parameter q, and PACF plot tells\nyou about the auto-regressive parameter p. However both interact with each other. Once you select one\nparameter both the auto-regression and the moving average are affected.\n\nNow in this particular case the ACF plot is outside the threshold, quite a lot. Therefore we should\nstart with the PACF plot which is significant at lags 7 and 13. We will test them\nlater on when you have plots like these, you always start with a plot that shows the least amount of\nlags outside the benchmark.\n\nIt is very important: PACF is the indicator for the auto-regression, p\nACF is the indicator for the moving average part, q\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using ARIMA for the model, with the argument 'order'\n# It is easy to change parameters\nmodel = ARIMA(denverLarc_ts, order=(2, 0, 0))  \nresults_AR = model.fit()\nplt.figure(figsize=(12,8))\nplt.grid(True)\n\nplt.plot(denverLarc_ts, label = 'Original data')\nplt.plot(results_AR.fittedvalues, color='red', label = 'Model data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ARIMA Model Diagnostics\nresults_AR.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nTwo important pieces of data to get from the summary are:\nAIC - Akaike Information Criteria https://en.wikipedia.org/wiki/Akaike_information_criterion\nBIC - Base Informaton Criteria\nThey are measures of model quality and  - the simpler the better to avoid over-fitting\nWhen comparing models, pick the one with the lowest AIC\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ACF on Residuals of Our Model\nfig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = plot_acf(results_AR.resid, lags=40, ax=ax1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# significance still showing at lags 2, 7 and 13 - we can probably improve model therefore\n# lags at the front indicate significant need to improve model. Lags at the end may just be coincidence","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nAN IMPORTANT TEST OF MODEL QUALITY IS THAT THERE SHOULD BE NO PATTERN IN THE RESIDUALS - THEY MUST BE RANDOM\nApply ACF to the residuals to test this\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram of the Residuals\n# Importing function for normal distribution\nplt.figure(figsize = (12, 8))\nplt.hist(results_AR.resid, bins = 'auto', density = True, rwidth = 0.85,\n         label = 'Residuals') #density TRUE - norm.dist bell curve\nmu, std = norm.fit(results_AR.resid)\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100) #linspace returns evenly spaced numbers over a specified interval\np = norm.pdf(x, mu, std) #pdf = probability density function\nplt.plot(x, p, 'm', linewidth = 2)\nplt.grid(axis='y', alpha = 0.2)\nplt.xlabel('Residuals')\nplt.ylabel('Density')\nplt.title('Residuals 2,0,0 vs Normal Distribution - Mean = '+str(round(mu,2))+', Std = '+str(round(std,2)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the above is a little skewed, not a perfect normal distribution, therefore residuals not totally random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can readjust the model as often as we like\n# Repeat the following procedure for models AR(3), AR(4) and AR(5)\n# Which one is the most promising? Look for the lowest AIC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pVar = [3,4,5,6,7]\nfor var in pVar:\n    model = ARIMA(denverLarc_ts, order=(var, 0, 0))  \n    results_AR = model.fit()\n    print(results_AR.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AR 6 looks best. Lets examine the residuals in more detail:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ARIMA(denverLarc_ts, order=(6, 0, 0))  \nresults_AR = model.fit()\n\nfig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = plot_acf(results_AR.resid, lags=40, ax=ax1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# still borderline - lags 7 and 13 still fall outside (1 outlier acceptable)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the randomness of the residuals again\nplt.figure(figsize = (12, 8))\nplt.hist(results_AR.resid, bins = 'auto', density = True, rwidth = 0.85,\n         label = 'Residuals') #density TRUE - norm.dist bell curve\nmu, std = norm.fit(results_AR.resid)\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100) #linspace returns evenly spaced numbers over a specified interval\np = norm.pdf(x, mu, std) #pdf = probability density function\nplt.plot(x, p, 'm', linewidth = 2)\nplt.grid(axis='y', alpha = 0.2)\nplt.xlabel('Residuals')\nplt.ylabel('Density')\nplt.title('Residuals 6,0,0 vs Normal Distribution - Mean = '+str(round(mu,2))+', Std = '+str(round(std,2)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# not much of an improvement over the 2,0,0. Lets have a look at their forecasts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting up an ARIMA(2,0,0) model and storing its fitted values\nmodel_AR200 = ARIMA(denverLarc_ts, order=(2, 0, 0))  \nresults_AR200 = model_AR200.fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Forecast based on the ARIMA(2,0,0) model\nFcast200 = results_AR200.predict(start = '2019',\n                               end = '2021')\n# NOTE: Forecasts have a built-in timestamp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting up an ARIMA(2,0,0) model and storing its fitted values\nmodel_AR600 = ARIMA(denverLarc_ts, order=(6, 0, 0))  \nresults_AR600 = model_AR600.fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Fcast600 = results_AR600.predict(start = '2019',\n                               end = '2021')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparing the forecasts via data visualization\nplt.figure(figsize = (12, 8))\nplt.plot(denverLarc_ts, linewidth = 2, label = \"original\")\nplt.plot(Fcast200, color='red', linewidth = 2,\n         label = \"ARIMA 2 0 0\")\nplt.plot(Fcast600, color='blue', linewidth = 2,\n         label = \"ARIMA 6 0 0\")\nplt.grid()\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Not a great performance with ARIMA :(\n# Does seasonal decomposition do any better?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# seasonal decomposition with stl package","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stl_DenvLarc = decompose(denverLarc_ts, period=52) # 52 because the data has been binned into weeks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stlvisual = stl_DenvLarc.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the randomness of the residuals again\nplt.figure(figsize = (12, 8))\nplt.hist(stl_DenvLarc.resid, bins = 'auto', density = True, rwidth = 0.85,\n         label = 'Residuals') #density TRUE - norm.dist bell curve\nmu, std = norm.fit(stl_DenvLarc.resid)\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100) #linspace returns evenly spaced numbers over a specified interval\np = norm.pdf(x, mu, std) #pdf = probability density function\nplt.plot(x, p, 'm', linewidth = 2)\nplt.grid(axis='y', alpha = 0.2)\nplt.xlabel('Residuals')\nplt.ylabel('Density')\nplt.title('Residuals STL_larceny vs Normal Distribution - Mean = '+str(round(mu,2))+', Std = '+str(round(std,2)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fcast_DenvLarc = forecast(stl_DenvLarc, steps=52, fc_func=seasonal_naive, seasonal = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fcast_DenvLarc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot of the forecast and the original data\nplt.figure(figsize=(12,8))\nplt.plot(denverLarc_ts, label='Denver Larceny')\nplt.plot(fcast_DenvLarc, label=fcast_DenvLarc.columns[0])\nplt.xlim('2014','2021'); plt.ylim(50,240);\nplt.grid(True)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perform exponential smoothing\n# Setting up the exponential smoothing model (A,N,A) - additive level, no trend, additive seasonality\nexpsmodel_DenvLarc = ExponentialSmoothing(denverLarc_ts, seasonal = \"additive\",\n                                 seasonal_periods = 52)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit model\nexpsmodelfit_DenvLarc = expsmodel_DenvLarc.fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Alpha smoothing coefficient\nexpsmodelfit_DenvLarc.params['smoothing_level']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gamma smoothing coefficient\nexpsmodelfit_DenvLarc.params['smoothing_seasonal']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# coeffs are close or equal to zero. Not surprising as larceny data is fairly smooth - no trends","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction with exponential smoothing\nexpsfcast_DenvLarc = expsmodelfit_DenvLarc.predict(start = 281, end = 450)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the predicted values and the original data\nplt.figure(figsize=(12,8))\nplt.plot(denverLarc_ts, label='Denver Larceny')\nplt.plot(expsfcast_DenvLarc, label='HW forecast')\nplt.grid(True)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparing the model to the original values\n# How good is the model fit?\nplt.figure(figsize=(12,8))\nplt.plot(denverLarc_ts, label='Denver Larceny')\nplt.plot(expsmodelfit_DenvLarc.fittedvalues, label='HW model')\nplt.grid(True)\nplt.xlim('2014','2018'); plt.ylim(70,240);\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the randomness of the residuals again\nplt.figure(figsize = (12, 8))\nplt.hist(expsmodelfit_DenvLarc.resid, bins = 'auto', density = True, rwidth = 0.85,\n         label = 'Residuals') #density TRUE - norm.dist bell curve\nmu, std = norm.fit(expsmodelfit_DenvLarc.resid)\nxmin, xmax = plt.xlim()\nx = np.linspace(xmin, xmax, 100) #linspace returns evenly spaced numbers over a specified interval\np = norm.pdf(x, mu, std) #pdf = probability density function\nplt.plot(x, p, 'm', linewidth = 2)\nplt.grid(axis='y', alpha = 0.2)\nplt.xlabel('Residuals')\nplt.ylabel('Density')\nplt.title('Residuals ExpSmooth Larceny vs Normal Distribution - Mean = '+str(round(mu,2))+', Std = '+str(round(std,2)))\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}