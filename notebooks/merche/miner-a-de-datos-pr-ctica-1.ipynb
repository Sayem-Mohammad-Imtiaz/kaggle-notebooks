{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"# Práctica 1: Análisis exploratorio de datos, preprocesamiento y validación de modelos de clasificación\n\n### Minería de Datos: Curso académico 2020-2021\n\n\n* Mª Mercedes Guijarro"},{"metadata":{"_uuid":"8a7623324f8efa406ac9e5a9d0753c872bfdc032"},"cell_type":"markdown","source":"En esta práctica se realizará un informe reproduciendo el estudio hecho con iris en el cuaderno de la Práctica 1, por lo que para ello trabajaremos algunos de los aspectos más importantes del proceso *KDD* :\n\n* Almacenamiento y carga de datos\n* Análisis exploratorio de datos\n* Preprocesamiento de datos\n* Validación de modelos de clasificación\n\n\nEl objetivo de la práctica será aprender a cargar, explorar y preparar nuestros datos, aprender y validar distintos modelos de clasificación y ser capaces de interpretar los resultados obtenidos."},{"metadata":{"_uuid":"35d7e4008f39bffb579a13479097fe83e6a8eb00"},"cell_type":"markdown","source":"# 1. Preliminares"},{"metadata":{},"cell_type":"markdown","source":"Antes de comenzar es necesario cargar las librerías a emplear para que estén disponibles para su posterior uso:"},{"metadata":{"_uuid":"e46dd0285013848672368ecbbe380e83103949c1","trusted":true},"cell_type":"code","source":"# Third party\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Local application\nimport miner_a_de_datos_an_lisis_exploratorio_utilidad as utils\n\nimport pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Además, fijamos una semilla para que los experimentos sean reproducibles:"},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 27912","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c225b530d06a70b6bbf26ec0d593aa42715fa9d8"},"cell_type":"markdown","source":" # 2. Carga de datos Diabetes dataset\n## 1. Diabetes dataset\n     Para comenzar tenemos que hacer la carga del dataset, el cual almacena información sobre ciertas variables predictoras (nº de embarazos, presión sanguínea, glucosa...) para predecir si una persona tiene o no diabetes."},{"metadata":{},"cell_type":"markdown","source":"Comenzamos cargando el conjunto de datos `diabetes`:"},{"metadata":{"_uuid":"6476f218bc9071bd38b06ee77eae9f0e651228a7","trusted":true},"cell_type":"code","source":"filepath = \"../input/pima-indians-diabetes-database/diabetes.csv\"\n\n\ndata = pd.read_csv(filepath, dtype={\"Outcome\": 'category'})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23f95e5c93b4393a2030093eaa21956ac96b88fc"},"cell_type":"markdown","source":"En este caso no tenemos ninguna variable que corresponda con un identificador de casos el conjunto de datos. \nIndicamos la variable clase que en este caso es `Outcome`\n\nUna vez realizada la carga el conjuntod de datos, pasamos a comprobar que se ha realizado correctamente, y que las variables y valores están dentro de lo esperado. \nPara ello podemos usar la función `head` para obtener las `n` primeras instancias del conjunto de datos:\n"},{"metadata":{"_uuid":"40e7c0685585665698306298e77530096dffc559","trusted":true},"cell_type":"code","source":"data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y también podemos utilizar `info` para, además de comprobar que se haya cargado correctamente, ver las columnas (variables) de nuestro conjunto:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aunque hayamos comprobado que se ha cargado correctamente además podemos realizar una muestra aleatoria, ya que la anterior es una muestra sesgada. "},{"metadata":{"_uuid":"9f1a39585fceb516af8ddcf5afd85945b50c418a","trusted":true},"cell_type":"code","source":"data.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a43dd350512365db94a69a5a6f6cf0828e7afb9f"},"cell_type":"markdown","source":"Una vez hemos realizado las comprobaciones sobre la carga del conjunto de datos, pasamos separar nuestro conjunto en dos subconjuntos, uno para las variables predictoras (`X`) y otro con las variables objetivos (`Y`).\n"},{"metadata":{"_uuid":"77c75aa49e6cd91426d1de882b7feaa0a883fcdb","trusted":true},"cell_type":"code","source":"(X, y) = utils.divide_dataset(data, target=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y comprobamos mediante una muestra aleatoria que se haya realizado la separación correctamente:"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"X.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A continuación pasaremos a separar nuestro conjunto de datos en dos (proceso *holdout*) :\n\n* Una muestra de entrenamiento (70%)\n* Una muestra de prueba (30%)\n\nRealizamos un holdout:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 0.7\n\n(X_train, X_test, y_train, y_test) = train_test_split(X, y,\n                                                      stratify=y,\n                                                      random_state=seed,\n                                                      train_size=train_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por defecto se aleatorizan las instancias del conjunto  antes de realizar el *holdout* (`shuffle=True`).\n\nComprobamos que el conjunto de datos se ha dividido correctamente en training y test:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por último, finalizamos con la variable objetivo del conjunto de datos de entrenamiento:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y test:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para facilitar el análisis exploratorio de datos, volvemos a juntar las variables predictoras con la variable clase. Comenzamos con el conjunto de datos de entrenamiento:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = utils.join_dataset(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y continuamos con el conjunto de datos de prueba:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test = utils.join_dataset(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Para asegurarnos de que se han juntado correctamente, obtenemos una muestra aleatoria del conjunto de datos de entrenamiento:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y del conjunto de datos de prueba:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfa6448396ab99305eddfd23cfd958266ad967a8"},"cell_type":"markdown","source":"## 2. Análisis exploratorio de datos"},{"metadata":{},"cell_type":"markdown","source":"Antes de continuar con el preprocesamiento, vamos a observar las propiedades del conjunto de datos, examinando sus variables y la interacción entre estas."},{"metadata":{},"cell_type":"markdown","source":"### Descripción del conjunto de datos"},{"metadata":{},"cell_type":"markdown","source":"Primero debemos conocer nuestro problema y para ello tenemos que saber el número de casos y de variables del conjunto:"},{"metadata":{"_uuid":"2353b44c7a384810e27f487853d000a2edbe543a","trusted":true},"cell_type":"code","source":"data_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como se puede observar, el conjunto de datos de entrenamiento está formado por 537 casos y 9 variables (8 predictoras y 1 variable clase).\n\nPara conocer cuál es el tipo de las variables, recurrimos al método `info`:"},{"metadata":{"_uuid":"015c899c3ec4a2177b1986797554b66dfcaac1ee","trusted":true},"cell_type":"code","source":"data_train.info(memory_usage=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos ver, las variables predictoras son todas númericas, tanto int64 como float64-\nPor el contrario, la variable clase (`Outcome`) es categórica (`category`, especificada al cargar el conjunto de datos) y contiene los siguientes estados:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.cat.categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por lo que nuestra variable clase puede tomar dos estados."},{"metadata":{"_uuid":"f17f376d1ed7405027aebcd226bb6f54d61834ed"},"cell_type":"markdown","source":"### Visualización de las variables"},{"metadata":{},"cell_type":"markdown","source":"Una vez que hemos visto con más detalle nuestro conjunto de datos de entrenamiento, lo siguiente que haremos será representar y analizar las distribuciones de las variables.\nPara ello utilizaremos histogramas para las variables predictoras, ya que son todas numéricas.\n"},{"metadata":{"_uuid":"9ab7ff50c8e596f47f8b1e2bece56de40ad52da9","trusted":true},"cell_type":"code","source":"utils.plot_histogram(data_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4083a4c4c0cf6cfceafe1febbb68be23664931a2"},"cell_type":"markdown","source":"Tal y como se puede observar en la gráfica superior, hay registros en lo que el nivel de glucosa, presión sanguínea, grosor de piel, insulina e índice de masa corporal son 0. Son valores que no tienen sentido, ya que en el caso de no ser erróneos la persona estaría muerta.\nAntes de continuar, vamos a visualizar la proporcion de valores perdidos respecto al total de los casos para determinar si es mejor deshacernos directamente de la columna o no:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train[data_train == 0].count(axis=0)/len(data.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos observar, el mayor porcentaje de casos perdidos lo tiene la insulina (29%). Mantendremos la columna ya que no llega al 30%.\n\nMás adelante procederemos a trataar esos valores perdidos."},{"metadata":{},"cell_type":"markdown","source":"Continuamos visualizando las variables categóricas del problema:"},{"metadata":{"_uuid":"268a87c979078129be8902cc50e24118d7f6254b","trusted":true},"cell_type":"code","source":"utils.plot_barplot(data_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9852797c305df3f69fd5b8a4436509758a57a0d0"},"cell_type":"markdown","source":"Lo que podemos ver en esta gráfica es que la clase 0 de la variable objetivo del problema tiene más número de casos (casi el doble de casos) que la clase 1, por lo que el problema no está balanceado."},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(data_train, target=\"Outcome\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos observar en el gráfico, no hay ninguna par de variables que produzcan una separación más o menos clara de la variable objetivo.\n\nPodemos analizar variables numéricas (valor medio, mínimo, máximo, etc.) con el método describe (include=\"number\"):\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.describe(include=\"number\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y también categóricas (número de casos, estados, etc.) usando igualmente el método describe (include=\"category\"):"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.describe(include=\"category\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Preprocesamiento de datos"},{"metadata":{},"cell_type":"markdown","source":"Vamos a tratar los valores perdidos intrínsecos en las variables vistas anteriormente:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\n\n# Value Imputer\nimp = SimpleImputer(missing_values=0, strategy='mean')\n\n# Preprocessor\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('missing', imp ,[False, True, True, True, True, True, True, True]) \n    ], remainder=\"passthrough\")\n\n# Fitting the column transformer\npreprocessor = preprocessor.fit(X_train)\n\n#Las columnas a las que no se le aplica la transformación se colocan al final del DataFrame\nX_train = pd.DataFrame(preprocessor.transform(X_train), \n                                columns=X_train.columns[1:].append(X_train.columns[:1]))\n\ndata_train = utils.join_dataset(X_train, y_train)\nX_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De esta forma hemos replazado los valores que eran 0 en las variables que no tenía sentido que fueran 0, por la media de los valores que toma esa variable."},{"metadata":{},"cell_type":"markdown","source":"## 4. Algoritmos de clasificación y evaluación de modelos"},{"metadata":{"_uuid":"6151297acf8c00e083680fe07b7bbe732c52b14e"},"cell_type":"markdown","source":"Una vez hemos realizado un análisis exploratorio de los datos y el preprocesamiento de los datos, empezamos con los algoritmos Zero-R y árboles de decisión."},{"metadata":{},"cell_type":"markdown","source":"### Algoritmo *Zero-R*"},{"metadata":{},"cell_type":"markdown","source":"Como sabemos el algoritmo *Zero-R* aprede un clasificador que asigna a los nuevos casos la clase que predomina en el conjunto de entrenamiento, por lo tanto es de esperar que no tenga nada de varianza pero sí mucho sesgo.\n\nPara usar el algoritmo *Zero-R*, recurrimos al estimador `DummyClassifier` de `scikit-learn`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_model = DummyClassifier(strategy=\"most_frequent\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora entreamos y validamos nuestro clasificador, para ello utilizamos la matriz de confusión y  tasa de acierto:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(zero_r_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tal y como se esperaba, zeroR no obtiene muy buenos resultados, aunque el accuracy no es muy malo debido a que una de las clases era más predominante sobre la otra, por eso no tiene tan mala tasa de acierto. \nSi fuera más equilibrada el accuracy podría ser un 50% o incluso menor, por lo tanto zeroR no obtiene buenos resultados para este conjunto de datos."},{"metadata":{},"cell_type":"markdown","source":"### Algoritmo *CART* (*Classification and Regression Trees*): Inducción de árboles de decisión"},{"metadata":{},"cell_type":"markdown","source":"El siguiente algoritmo que probaremos será un árbol de decisión, sin y con discretización.\n\nYa que es un método más complejo y competitivo que el Zero-R lo que se espera es conseguir mejores resultados."},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizer = KBinsDiscretizer(n_bins=3, strategy=\"uniform\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model = DecisionTreeClassifier(random_state=seed)\ntree_model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### *Pipeline*"},{"metadata":{},"cell_type":"markdown","source":"Creamos un *pipeline* para aplicar las transformaciones al conjunto de datos.\nEste pipeline estará formado por por `KBinsDiscretizer` + `DecisionTreeClassifier` y así poder ver los resultados obtenidos sin y con discretización."},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_model = make_pipeline(discretizer, tree_model)\ndiscretize_tree_model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y con el conjunto de datos discretizados:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretize_tree_model,\n               X_train, X_test,\n               y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos observar tampoco se obtienen muy buenos resultados, ya que con discretización obtenemos el mismo accuracy que en ZeroR.\nEsto puede deberse a que como vimos en las gráficas anteriores, ninguna de las variables o ningún par e variables realiza una división relativamente clara de la variable objetivo."},{"metadata":{},"cell_type":"markdown","source":" # 2. Carga de datos Wisconsin dataset\n## 1. Wisconsin dataset  "},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Ahora realizaremos el mismo estudio para el conjunto de datos de Wisconsin."},{"metadata":{},"cell_type":"markdown","source":"Ahora realizaremos el mismo estudio para el conjunto de datos de Wisconsin."},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"../input/breast-cancer-wisconsin-data/data.csv\"\n\n\nindexW = \"id\"\ntargetW = \"diagnosis\"\n\ndataW = utils.load_data(filepath, indexW, targetW)\ndataW.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos observar en la información del conjunto de datos, tenemos 32 columnas, delas cuales la columna Unnamed:32 no tiene ningún tipo de información, por lo que deberíamos eliminarla antes de continuar con el análisis de los datos."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataW=dataW.drop(['Unnamed: 32'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Una vez hemos realizado la carga del conjunto de datos, comprobamos que el proceso se ha realizado correctamente:"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataW.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataW.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Hemos comprobado que los datos se han cargado correctamente, por lo que vamos a continuar separando el conjunto en dos subconjuntos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"(X_w, y_w) = utils.divide_dataset(dataW, target=\"diagnosis\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Y volvemos a comprobar que se haya separado correctamente, primero las variables predictoras y luego la variable clase:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_w.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_w.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Antes de comenzar con el análisis exploratorio vamos a separar nuestro conjunto de datos en entrenamiento y test.\nAplicamos un holdout estratificado y volvemos a comprar que el conjunto de datos se ha dividido correctamente, tanto entrenamiento como test:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = 0.7\n\n(X_train_w, X_test_w, y_train_w, y_test_w) = train_test_split(X_w, y_w,\n                                                      stratify=y_w,\n                                                      random_state=seed,\n                                                      train_size=train_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_w.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_w.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_w.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_w.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Volvemos a juntar las variables predictoras con la variable clase en nuestro conjunto de entrenamiento y de test y lo comprobamos:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_w = utils.join_dataset(X_train_w, y_train_w)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test_w = utils.join_dataset(X_test_w, y_test_w)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_w.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test_w.sample(5, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Análisis exploratorio de datos"},{"metadata":{},"cell_type":"markdown","source":"Antes de continuar con cualquier operación vamos a examninar el número de casos y de variables del conjunto de entrenamiento:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_w.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nuestro conjunto de entrenamiento está formado por 398 casos y 31 variables (30 predictoras y 1 variable clase).\n\nEl tipo de las variables lo hemos visto anteriormente, además hemos eliminado la variable Unnamed:32 ya que no tenía ningún tipo de información.\nY como hemos visto todas las variables son númericas, excepto la variable diagnosis que es categórica y que contiene los siguientes estados:"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_w.cat.categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nuestra variable clase puede tomar dos estados: B y M."},{"metadata":{},"cell_type":"markdown","source":"### Visualización de las variables"},{"metadata":{},"cell_type":"markdown","source":"Después de conocer en detalle el conjunto de entrenamiento, vamos a representar y analizar las distribuciones de las variables y para ello utilizaremos histogramas para las variables numéricas (todas nuestras variables predictoras) y un diagrama de barras para las variables categóricas (nuestra variable clase)."},{"metadata":{},"cell_type":"markdown","source":"Vamos a visualizar primero un histograma con las variables numéricas:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_histogram(data_train_w)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos ver en el histograma la mayoría de las variables tienen una distribución en forma acampanada. Aunque si que es cierto que en general se encuentran sesgadas a la derecha, como podemos ver en las variables concave points_mean, symmetry_mean, symmetry worst ...\nY además, podemos destacar que en algunas variables (como concave points_mean, area_worst, smoothness_se, concavity_se, symmetry_se...) es posible que exista algún valor anómalo, ya que se puede ver en la gráfica que hay valores más alejados."},{"metadata":{},"cell_type":"markdown","source":"Y con respecto a las variables categóricas, en este caso una única variable:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_barplot(data_train_w)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos observar en el diagrama de barras es que la clase B de la variable objetivo del problea tiene más número de casos, por lo que nuestro problema no está balanceado."},{"metadata":{},"cell_type":"markdown","source":"Vamos a estudiar las relaciones que existen entre pares de variables (análisis multivariado), para ver si podemos extraer información:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.plot_pairplot(data_train_w, target=\"diagnosis\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Con este conjunto de datos encontramos un problema que es la dimensionalidad de los datos.\nVisualizando por encima las gráficas y haciendo un poco de zoom en las que vemos que hay más separación para las variables: concave_points_se y fractal_dimension_se principalmente."},{"metadata":{},"cell_type":"markdown","source":"También nos podemos apoyar en el método describe para analizar las variables numéricas:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_w.describe(include=\"number\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos observar el número de instancias para nuestro conjunto de entrenamiento (398) y también algunos valores (como la media,el mín, el máx...) que nos pueden ayudar a detectar valores erróneos o perdidos, y que en este caso parece que no hay."},{"metadata":{},"cell_type":"markdown","source":"Y para la variable categórica:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_w.describe(include=\"category\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como vemos tenemos en nuestro conjunto de entrenamiento 398 casos y al igual que veíamos en el gráfico de barras hay más número de casos de la clase B."},{"metadata":{},"cell_type":"markdown","source":"## 3. Algoritmos de clasificación y evaluación de modelos"},{"metadata":{},"cell_type":"markdown","source":"Una vez hemos realizado un análisis exploratorio de los datos y el preprocesamiento de los datos, empezamos con los algoritmos Zero-R y árboles de decisión."},{"metadata":{},"cell_type":"markdown","source":"### Algoritmo *Zero-R*"},{"metadata":{},"cell_type":"markdown","source":"Usamos el algoritmo *Zero-R* para este conjunto de datos al iugal que para el anterior, y como ya sabemos este algoritmo asigna a los nuevos casos la clase que predomina en el conjunto de entrenamiento. Para nuestro caso la clase que predominaba era la B, por lo que sería de esperar que a los nuevos casos les fuera asignada esta clase.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_r_model_w = DummyClassifier(strategy=\"most_frequent\")\nzero_r_model_w.fit(X_train_w,y_train_w)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora entrenamos y validamos nuestro clasificador, para ello utilizamos la matriz de confusión y tasa de acierto:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(zero_r_model_w,\n               X_train_w, X_test_w,\n               y_train_w, y_test_w)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como esperabamos zeroR no obtiene buenos resultados, aunque si que es cierto queel accuracy no es tan malo, ya que como nos pasaba en el otro conjuto de datos, una clase es más predominante sobre la otra, por eso la mayoría de casos los clasifica correctamente.\nSi fuera un conjunto más balanceado en el que no hubiera una clase mucho más predominante, nuestro accuracy bajaría y obtendríamos peores resultados con este algoritmo."},{"metadata":{},"cell_type":"markdown","source":"### Algoritmo *CART* (*Classification and Regression Trees*): Inducción de árboles de decisión"},{"metadata":{},"cell_type":"markdown","source":"El siguiente algoritmo que probaremos será un árbol de decisión, sin y con discretización.\n\nYa que es un método más complejo y competitivo que el Zero-R lo que se espera es conseguir mejores resultados, además de que como se podía observar en las gráficas anteriores existían variables que realizaban una buena separación de la variable clase."},{"metadata":{"trusted":true},"cell_type":"code","source":"discretizer_w = KBinsDiscretizer(n_bins=3, strategy=\"uniform\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_model_w = DecisionTreeClassifier(random_state=seed)\ntree_model_w.fit(X_train_w,y_train_w)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### *Pipeline*"},{"metadata":{},"cell_type":"markdown","source":"Creamos un *pipeline* para aplicar las transformaciones al conjunto de datos.\nEste pipeline estará formado por por `KBinsDiscretizer` + `DecisionTreeClassifier` y así poder ver los resultados obtenidos sin y con discretización."},{"metadata":{"trusted":true},"cell_type":"code","source":"discretize_tree_model_w = make_pipeline(discretizer, tree_model_w)\ndiscretize_tree_model_w.fit(X_train_w,y_train_w)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora entrenamos y validamos nuestro clasificador, para ello utilizamos la matriz de confusión y tasa de acierto:"},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(tree_model_w,\n               X_train_w, X_test_w,\n               y_train_w, y_test_w)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"utils.evaluate(discretize_tree_model_w,\n               X_train_w, X_test_w,\n               y_train_w, y_test_w)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como era de esperar, obtenemos unos resultados mucho mejores que con un clasificador ZeroR ya que como hemos indicado existe al menos una variable que es capaz de predecir de forma bastante acertada los nuevos casos.\nTambién hay que comentar que el árbol de decisión que ha sido entrenado con el conjunto de datos discretizado obtiene una mayor tasa de acierto que el no discretizado, debido a que la variable numérica utilizada al transformarla en variable categórica consigue que aumente la tasa de acierto."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}