{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv(\"/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above, we can observe that\n\n1. There are 12 cols and 1599 data rows.\n2. The data doesn't contain any null values.\n3. quality col is our class label."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset['quality'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 6 different qualities of wine. "},{"metadata":{},"cell_type":"markdown","source":"## Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dataset['quality'].value_counts())\nsns.countplot(x='quality', data=dataset)\nplt.title('Wine Quality Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The data looks very unbalanced for different wine quality classes. The data is very less for quality 3,4,7,8 as compared to 5,6."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"quality\", y=\"alcohol\", data=dataset)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"quality\", y=\"fixed acidity\", data=dataset)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10)) \nsns.heatmap(dataset.corr(), annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this heatmap we can say that the wine features are not correlated to each other. "},{"metadata":{},"cell_type":"markdown","source":"## Data Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataset.drop(['quality'],axis=1)\nY = dataset['quality']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import f1_score,confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom pandas import DataFrame\nfrom sklearn.svm import SVC\nimport xgboost as xgb\nimport lightgbm as lgbm\nimport catboost as cb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set seed for reproducibility\nSEED = 42","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Since the Red Wine datast is highly imbalanced, we will use oversampling the data so that it's balanced"},{"metadata":{},"cell_type":"markdown","source":"## Over-Sampling the Imbalanced Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"## oversampling\nfrom imblearn.over_sampling import SMOTE\nos=SMOTE()\nX_res,y_res=os.fit_sample(X, Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_res.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### From above we can observe that the wine quality data is now properly balanced."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split dataset into 70% train, 30% test\nX_train, X_test, y_train, y_test= train_test_split(X_res, y_res, test_size=0.2, random_state=SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Scaling"},{"metadata":{},"cell_type":"markdown","source":"### Normalize the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit scaler on training data\nnorm = MinMaxScaler().fit(X_train)\n\n# transform training data\nX_train_norm = norm.transform(X_train)\n\n# transform testing dataabs\nX_test_norm = norm.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Standardize the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit scaler on training data\nstdscale = StandardScaler().fit(X_train)\n\n# transform training data\nX_train_std = stdscale.transform(X_train)\n\n# transform testing dataabs\nX_test_std = stdscale.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Instantiate individual classifiers\nlr = LogisticRegression(max_iter = 500, n_jobs=-1, random_state=SEED)\nknn = KNN()\ndt = DecisionTreeClassifier(random_state=SEED)\nsvc = SVC(random_state=SEED)\nrf = RandomForestClassifier(random_state=SEED)\nxgbc = xgb.XGBClassifier(random_state=SEED)\nlgbmc = lgbm.LGBMClassifier(random_state=SEED)\ncbc = cb.CatBoostClassifier(random_state=SEED, verbose=False)\ngbc = GradientBoostingClassifier(random_state=SEED)\n\n# Define a list called classifier that contains the tuples (classifier_name, classifier)\nclassifiers = [('Logistic Regression', lr),\n('K Nearest Neighbours', knn),\n('SVM', svc),\n('Random Forest Classifier', rf),\n('Decision Tree', dt),\n('XGBClassifier', xgbc),\n('LGBMClassifier', lgbmc),\n('CatBoostClassifier', cbc),\n('GradientBoostingClassifier', gbc)]              ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Models prediction without any normalization or standardization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Iterate over the defined list of tuples containing the classifiers\nfor clf_name, clf in classifiers:\n    #fit clf to the training set\n    clf.fit(X_train, y_train)\n    # Predict the labels of the test set\n    y_pred = clf.predict(X_test)\n    # Evaluate the accuracy of clf on the test set\n    print('{:s} : {:.3f}'.format(clf_name, accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Models prediction with Normalized data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Iterate over the defined list of tuples containing the classifiers\nfor clf_name, clf in classifiers:\n    #fit clf to the training set\n    clf.fit(X_train_norm, y_train)\n    # Predict the labels of the test set\n    y_pred = clf.predict(X_test_norm)\n    # Evaluate the accuracy of clf on the test set\n    print('{:s} : {:.3f}'.format(clf_name, accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Models prediction with Standardized data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Iterate over the defined list of tuples containing the classifiers\nfor clf_name, clf in classifiers:\n    #fit clf to the training set\n    clf.fit(X_train_std, y_train)\n    # Predict the labels of the test set\n    y_pred = clf.predict(X_test_std)\n    # Evaluate the accuracy of clf on the test set\n    print('{:s} : {:.3f}'.format(clf_name, accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can that CatBoost Classifier gives us the best result irrespective of the Normalized or Standardized data"},{"metadata":{},"cell_type":"markdown","source":"## Combining various Models - Voting Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"votingC = VotingClassifier(estimators=[('Random Forest', rf), ('LightGBM', lgbmc), ('Catboost', cbc)], voting='soft', n_jobs=-1)\nvotingC = votingC.fit(X_train, y_train)\n# Predict the labels of the test set\ny_pred = votingC.predict(X_test)\n# Evaluate the accuracy of clf on the test set\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"votingC = VotingClassifier(estimators=[('Random Forest', rf), ('LightGBM', lgbmc), ('Catboost', cbc)], voting='soft', n_jobs=-1)\nvotingC = votingC.fit(X_train_norm, y_train)\n# Predict the labels of the test set\ny_pred = votingC.predict(X_test_norm)\n# Evaluate the accuracy of clf on the test set\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"votingC = VotingClassifier(estimators=[('Random Forest', rf), ('LightGBM', lgbmc), ('Catboost', cbc)], voting='soft', n_jobs=-1)\nvotingC = votingC.fit(X_train_std, y_train)\n# Predict the labels of the test set\ny_pred = votingC.predict(X_test_std)\n# Evaluate the accuracy of clf on the test set\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above we can say that Voting Classifier marginally improves the accuracy compared to the CatBoost Classifier. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}