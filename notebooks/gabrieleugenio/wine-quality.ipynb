{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import *\nfrom sklearn.preprocessing import *\nfrom sklearn.ensemble import *\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import *","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Importing Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# file path of quality wine dataset\nfile_path = os.path.join(dirname, filename)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# importing dataframe\ndf = pd.read_csv(file_path , sep =',')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Exploring Data #"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating new column with total of acidity\ndf['total acidity'] = df['fixed acidity'] + df['volatile acidity']\n\n# plotting correlation matrix of features\nmatrix_corr = df.corr()\n\nsns.heatmap(matrix_corr,\n            xticklabels = matrix_corr.columns,\n            yticklabels = matrix_corr.columns , cmap = 'YlGnBu' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting the count of labels\nsns.countplot(x='quality', data=df)\n# unbalanced dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# separating dataset with majority count, 5 and 6 quality score\nmax_samples = len(df[df['quality']== 5])\n\n# majority dataset\ndf_maj = df[(df['quality'] == 5) | (df['quality'] == 6)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# spliting dataset per quality score\ndf_q3 = df[df['quality'] == 3]\ndf_q4 = df[df['quality'] == 4]\ndf_q7 = df[df['quality'] == 7]\ndf_q8 = df[df['quality'] == 8]\n\n# resampling minoritary datasets\ndfm3 = resample(df_q3 ,\n                replace = True,\n                n_samples= max_samples,\n                random_state=0)\n\ndfm4 = resample(df_q4 ,\n                replace = True,\n                n_samples= max_samples,\n                random_state=0)\n\ndfm7 = resample(df_q7 ,\n                replace = True,\n                n_samples= max_samples,\n                random_state=0)\n\ndfm8 = resample(df_q8 ,\n                replace = True,\n                n_samples= max_samples,\n                random_state=0)\n\n# creating dataset balaced\ndf = pd.concat([df_maj , dfm3 , dfm4 , dfm7 , dfm8])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating PCA features\nfeatures = df.drop('quality' , axis = 1)\nlabel = df['quality']\n\n# normalize dataset features\nscaler_atr = StandardScaler()\n\natb = scaler_atr.fit_transform(features)\n\nX = np.matrix(atb)\nS = np.cov(np.transpose(X)) \n\npca = PCA(n_components=8)\n\npca.fit(X)\n\ncomponents = np.round(pca.explained_variance_ratio_ , 2)\n\npca_1 = pca.transform(X)[:,0]\npca_2 = pca.transform(X)[:,1]\npca_3 = pca.transform(X)[:,2]\npca_4 = pca.transform(X)[:,3]\npca_5 = pca.transform(X)[:,4]\npca_6 = pca.transform(X)[:,5]\npca_7 = pca.transform(X)[:,6]\npca_8 = pca.transform(X)[:,7]\n\n# applying in dataset\ndf['PCA1'] = pca_1\ndf['PCA2'] = pca_2\ndf['PCA3'] = pca_3\ndf['PCA4'] = pca_4\ndf['PCA5'] = pca_5\ndf['PCA6'] = pca_6\ndf['PCA7'] = pca_7\ndf['PCA8'] = pca_8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# showing the new correlation matrix \nmatrix_corr = df.corr()\nmatrix_corr = matrix_corr['quality'].sort_values(ascending=False)\nprint(matrix_corr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# choosing features\nfeatures = df[['PCA2','PCA3','alcohol','volatile acidity','sulphates',\n               'citric acid','total sulfur dioxide','density','chlorides',\n               'fixed acidity','PCA1','PCA4','PCA5','PCA6',\n               'PCA7','PCA8','total acidity','pH']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splinting dataset in train and test\ntrain_features, test_features, train_labels, test_labels = train_test_split(features , label, \n                                                                            test_size = 0.20, \n                                                                            random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating dict with params\nparam_grid = [{'n_estimators':[20,40,45,50,55,60,70,100,150,200,250,300,350,400],\n               'max_depth':[7,8,9,10,11,12,13,15,16,17,18,19,20,22,25,30,35,40],\n               'criterion':['gini','entropy']}]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating Randon Forest Classifier to train the model\nclf = RandomForestClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating exhaustive search over specified parameter values for an estimator\ngs = GridSearchCV(clf, param_grid = param_grid, scoring='accuracy', cv=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train the params of dict: param_grid\ngs.fit(train_features, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best params\nprint(gs.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating classifier with best params found\nclf = RandomForestClassifier(criterion = gs.best_params_['criterion'],\n                             max_depth = gs.best_params_['max_depth'],\n                             n_estimators = gs.best_params_['n_estimators'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# trainning with best params found in gs\nclf.fit(train_features, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# applying model in test dataset\npredictions = clf.predict(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluating the model\nacc = sklearn.metrics.accuracy_score(test_labels, predictions)\nprint('Accuracy: ', acc)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}