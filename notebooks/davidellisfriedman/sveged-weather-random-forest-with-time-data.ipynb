{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# modules we'll use\nimport pandas as pd\nimport numpy as np\n\n# for Box-Cox Transformation\nfrom scipy import stats\n\n# plotting modules\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport time\nfrom sklearn.ensemble import RandomForestRegressor\nimport sklearn","metadata":{"execution":{"iopub.status.busy":"2021-06-12T14:24:44.798403Z","iopub.execute_input":"2021-06-12T14:24:44.798813Z","iopub.status.idle":"2021-06-12T14:24:44.804285Z","shell.execute_reply.started":"2021-06-12T14:24:44.798781Z","shell.execute_reply":"2021-06-12T14:24:44.803108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Background: The data set contains data about the local weather of a town in Hungary between the years of 2006 - 2016. The data comes in the form of a CSV file from Kaggle and can be found by searching Kaggle.com for “Weather in Szeged 2006-2016”. The data set is granular to at least one data point per day.\n\nResearch question: Can we predict the temperature or apparent temperature based on the humidity?\n\nTo start, we'll import the Weather in Szeged 2006-2016 data set.","metadata":{}},{"cell_type":"code","source":"weatherData = pd.read_csv(\"../input/szeged-weather/weatherHistory.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-12T14:24:44.809125Z","iopub.execute_input":"2021-06-12T14:24:44.809627Z","iopub.status.idle":"2021-06-12T14:24:45.123884Z","shell.execute_reply.started":"2021-06-12T14:24:44.809594Z","shell.execute_reply":"2021-06-12T14:24:45.12268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now to get to know the data set, lets look at a summary:","metadata":{}},{"cell_type":"code","source":"weatherData.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T14:24:45.125827Z","iopub.execute_input":"2021-06-12T14:24:45.126108Z","iopub.status.idle":"2021-06-12T14:24:45.189895Z","shell.execute_reply.started":"2021-06-12T14:24:45.126082Z","shell.execute_reply":"2021-06-12T14:24:45.188878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are four categories to account for. Of these, there is a column called \"Formatted Date\" which contains a timestamp for each data point.\n\nThe \"Loud Cover\" column contains only \"0.0\" for each row - not going to be much use in this analysis. \n\nSee a summary of all null and N/A values by running the code below:","metadata":{}},{"cell_type":"code","source":"weatherData.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T14:24:45.192573Z","iopub.execute_input":"2021-06-12T14:24:45.192932Z","iopub.status.idle":"2021-06-12T14:24:45.240643Z","shell.execute_reply.started":"2021-06-12T14:24:45.192903Z","shell.execute_reply":"2021-06-12T14:24:45.239757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The \"Precip Type\" column has a number of \"Nan\" valued rows which we are going to assign a value of \"none\" for this analysis. The justification for using a generic \"none\" value is that we do not know what type of precipitation was recorded for this day, and for 517 out nearly 100,000 data points it is just not worth trying to fill these missing values in. Thus, a value of \"none\" is used to indicate that no precipitation was recorded. Something that I considered doing was trying to forecast this data based on what was recorded for those \"days of the year\" during previous years, but doing so did not improve the performance in the end.","metadata":{}},{"cell_type":"code","source":"weatherData['Precip Type'].fillna('none')","metadata":{"execution":{"iopub.status.busy":"2021-06-12T14:24:45.242089Z","iopub.execute_input":"2021-06-12T14:24:45.2425Z","iopub.status.idle":"2021-06-12T14:24:45.261402Z","shell.execute_reply.started":"2021-06-12T14:24:45.242458Z","shell.execute_reply":"2021-06-12T14:24:45.26035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That wraps up the initial data cleaning, now to generate an initial impression of what columns are correlated to the temperature.\n\nFirst step, lets convert some of the categorical data into category codes:","metadata":{}},{"cell_type":"code","source":"weatherData['Summary']=(weatherData['Summary'].astype('category')).cat.codes\nweatherData['Daily Summary']=(weatherData['Daily Summary'].astype('category')).cat.codes\nweatherData['Precip Type']=(weatherData['Precip Type'].astype('category')).cat.codes","metadata":{"execution":{"iopub.status.busy":"2021-06-12T14:24:45.265924Z","iopub.execute_input":"2021-06-12T14:24:45.266267Z","iopub.status.idle":"2021-06-12T14:24:45.321173Z","shell.execute_reply.started":"2021-06-12T14:24:45.266232Z","shell.execute_reply":"2021-06-12T14:24:45.320002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The 'Formatted Date' column will take more work to transform into a useful form. The plan is to create a \"day of the year,\" \"week of the year,\" \"month of the year,\" and \"instant\" column. The instant column will simply provide a complete time series representation of the data, but will not be used for predictions.\n\nFirst, we have to convert the 'Formatted Date' column data type into a DataType64. I used the pandas to_datetime function to accomplish this:","metadata":{}},{"cell_type":"code","source":"weatherData['Formatted Date']=pd.to_datetime(weatherData['Formatted Date'],format='%Y-%m-%d %H:%M:%S.%f',utc=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T14:24:45.323336Z","iopub.execute_input":"2021-06-12T14:24:45.323696Z","iopub.status.idle":"2021-06-12T14:24:46.461794Z","shell.execute_reply.started":"2021-06-12T14:24:45.323643Z","shell.execute_reply":"2021-06-12T14:24:46.460443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we can easily create new columns containing the month, week, day, and hour numerical data we desire:","metadata":{}},{"cell_type":"code","source":"weatherData['mo']=weatherData['Formatted Date'].dt.month\nweatherData['day']=weatherData['Formatted Date'].dt.dayofyear\nweatherData['wk']=weatherData['Formatted Date'].dt.weekofyear\nweatherData['hour']=weatherData['Formatted Date'].dt.hour","metadata":{"execution":{"iopub.status.busy":"2021-06-12T14:24:46.464755Z","iopub.execute_input":"2021-06-12T14:24:46.465124Z","iopub.status.idle":"2021-06-12T14:24:46.518951Z","shell.execute_reply.started":"2021-06-12T14:24:46.465092Z","shell.execute_reply":"2021-06-12T14:24:46.517997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we will create a column called \"inst\" containing the unix timestamp:","metadata":{}},{"cell_type":"code","source":"weatherData['inst']=weatherData['Formatted Date']\nfor i in range(weatherData['Formatted Date'].size):\n    weatherData[\"inst\"][i]=time.mktime(weatherData['Formatted Date'][i].timetuple())","metadata":{"execution":{"iopub.status.busy":"2021-06-12T14:24:46.52026Z","iopub.execute_input":"2021-06-12T14:24:46.520548Z","iopub.status.idle":"2021-06-12T14:25:42.101796Z","shell.execute_reply.started":"2021-06-12T14:24:46.520519Z","shell.execute_reply":"2021-06-12T14:25:42.100463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we can generate the correlation matrix - giving us an initial impression of what data should be included in the model.","metadata":{}},{"cell_type":"code","source":"weatherData.corr()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T14:25:42.103216Z","iopub.execute_input":"2021-06-12T14:25:42.103513Z","iopub.status.idle":"2021-06-12T14:25:42.216455Z","shell.execute_reply.started":"2021-06-12T14:25:42.103485Z","shell.execute_reply":"2021-06-12T14:25:42.215516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the correlations with the \"Temperature (C)\" column each of the other columns seemingly has a potential contribution, but the most important seem to be the Humidity, Visibility, Daily Summary, Precip Type, and various columns with time data.\n\nUnsurprisingly, plotting each value as a time series reveals a time dependent structure. Since we are focusing on predicting temperature from humidity, I will plot the humidity and temperature/apparent temperature over time.","metadata":{}},{"cell_type":"code","source":"fig,subp = plt.subplots(3)\nfig.suptitle(\"Humidity, Temperature versus time (UTC timestamp)\")\nsubp[0].plot(weatherData['inst'],weatherData[\"Humidity\"],\".\")\nsubp[1].plot(weatherData['inst'],weatherData[\"Temperature (C)\"],\".\")\nsubp[2].plot(weatherData['inst'],weatherData[\"Apparent Temperature (C)\"],\".\")","metadata":{"execution":{"iopub.status.busy":"2021-06-12T14:25:42.21774Z","iopub.execute_input":"2021-06-12T14:25:42.218054Z","iopub.status.idle":"2021-06-12T14:25:42.910404Z","shell.execute_reply.started":"2021-06-12T14:25:42.218027Z","shell.execute_reply":"2021-06-12T14:25:42.909182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Histograms of the temperature and humidity data reveal that the temperature/apparent temperature are relatively normally distributed:","metadata":{}},{"cell_type":"code","source":"sns.distplot(weatherData[\"Temperature (C)\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-12T14:25:42.911899Z","iopub.execute_input":"2021-06-12T14:25:42.912188Z","iopub.status.idle":"2021-06-12T14:25:43.788867Z","shell.execute_reply.started":"2021-06-12T14:25:42.912161Z","shell.execute_reply":"2021-06-12T14:25:43.787612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"However, the humidity data is not:","metadata":{}},{"cell_type":"code","source":"sns.distplot(weatherData[\"Humidity\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-12T14:25:43.790458Z","iopub.execute_input":"2021-06-12T14:25:43.790889Z","iopub.status.idle":"2021-06-12T14:25:44.622699Z","shell.execute_reply.started":"2021-06-12T14:25:43.790845Z","shell.execute_reply":"2021-06-12T14:25:44.621847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Something that was considered as part of this analysis was attempting to normalize the humidity data using a Box - Cox power series transformation; however, this was not productive and did not increase model performance. The skewed nature of the humidity in the area is a physical reality, and it is reasonable to find that the distribution is not normal.","metadata":{}},{"cell_type":"markdown","source":"Since the data is relatively clean, and we do not have any scaling or other transformations to do. Now we can try fiting and testing the random forest regressor.\n\nFirst, I will create a new dataset to contain only the features we want to use in the model.  For now, that will be the humidity data:","metadata":{}},{"cell_type":"code","source":"# Copy the dataset\nweatherDataF=weatherData\n\n# Drop the columns\nweatherDataF=weatherDataF.drop(['Humidity','Formatted Date','Temperature (C)','Apparent Temperature (C)','Summary','Precip Type','Wind Speed (km/h)','Wind Bearing (degrees)','Visibility (km)',\n                                'Loud Cover','Pressure (millibars)','Daily Summary','inst','mo','day','wk'],axis=1)\n# Copy the humidity column\nweatherDataF[\"H\"]=weatherData[\"Humidity\"]\n\n# Temperature (C) will be the predicted data\ntemp=weatherData[\"Temperature (C)\"]\n\n# Create training and test data sets 80/20 split\nxtrain,xtest,ytrain,ytest = sklearn.model_selection.train_test_split(weatherDataF,temp,train_size=0.8)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T14:25:44.62415Z","iopub.execute_input":"2021-06-12T14:25:44.624441Z","iopub.status.idle":"2021-06-12T14:25:44.645705Z","shell.execute_reply.started":"2021-06-12T14:25:44.624413Z","shell.execute_reply":"2021-06-12T14:25:44.644626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now to create a random forest model and score the predictions:","metadata":{}},{"cell_type":"code","source":"# Create the random forest model\nweatherModel=RandomForestRegressor()\n\n# Fit the model\nweatherModel.fit(xtrain,ytrain)\n\n# Generate predictions\npreds=weatherModel.predict(xtest)\n\n# Score the predictions\nscore=sklearn.metrics.r2_score(ytest,preds)\nprint(score)\n\nsns.distplot(preds)\nsns.distplot(ytest)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T14:25:44.647247Z","iopub.execute_input":"2021-06-12T14:25:44.647543Z","iopub.status.idle":"2021-06-12T14:25:49.4633Z","shell.execute_reply.started":"2021-06-12T14:25:44.647513Z","shell.execute_reply":"2021-06-12T14:25:49.462158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not very impressive performance. If we normalize the humidity data, we get an r2 score of about 0.46. It would seem that predicting the temperature based on the humidity alone would be difficult, and likely would not result in a very good prediction.\n\nNow what happens if we include some of the time data that was extracted earlier:","metadata":{}},{"cell_type":"code","source":"weatherDataF[\"M\"]=weatherData[\"mo\"]\nweatherDataF[\"W\"]=weatherData[\"wk\"]\nweatherDataF[\"D\"]=weatherData[\"day\"]\nweatherDataF[\"Hour\"]=weatherData[\"hour\"]","metadata":{"execution":{"iopub.status.busy":"2021-06-12T14:25:49.46486Z","iopub.execute_input":"2021-06-12T14:25:49.465267Z","iopub.status.idle":"2021-06-12T14:25:49.474169Z","shell.execute_reply.started":"2021-06-12T14:25:49.465226Z","shell.execute_reply":"2021-06-12T14:25:49.473103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now to refit the model:","metadata":{}},{"cell_type":"code","source":"# Rebuild the training and test data\nxtrain,xtest,ytrain,ytest = sklearn.model_selection.train_test_split(weatherDataF,temp,train_size=0.8)\n\n# Create the random forest model\nweatherModel=RandomForestRegressor()\n\n# Fit the model\nweatherModel.fit(xtrain,ytrain)\n\n# Generate predictions\npreds=weatherModel.predict(xtest)\n\n# Score the predictions\nscore=sklearn.metrics.r2_score(ytest,preds)\nprint(score)\n\nsns.distplot(preds)\nsns.distplot(ytest)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T14:25:49.475636Z","iopub.execute_input":"2021-06-12T14:25:49.475958Z","iopub.status.idle":"2021-06-12T14:26:12.388635Z","shell.execute_reply.started":"2021-06-12T14:25:49.475929Z","shell.execute_reply":"2021-06-12T14:26:12.387893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pretty big performance gains! However, the model density seems to be pretty strongly bimodal with two large peaks; most likely, reflecting a split between the warmer summer/string temperatures and colder winter/fall temperature. In reality, the data has a more complicated structure that the model is not capturing.\n\nWe can do better by adding more features.  In fact, the model performance continues to improve as we add more features:","metadata":{}},{"cell_type":"code","source":"# Add the rest of the features in the data set\nweatherDataF[\"WS\"]=weatherData[\"Wind Speed (km/h)\"]\nweatherDataF[\"WB\"]=weatherData[\"Wind Bearing (degrees)\"]\nweatherDataF[\"P\"]=weatherData[\"Pressure (millibars)\"]\nweatherDataF[\"Vis\"]=weatherData[\"Visibility (km)\"]\nweatherDataF[\"Sum\"]=weatherData[\"Summary\"]\nweatherDataF[\"DataSum\"]=weatherData[\"Daily Summary\"]\nweatherDataF[\"PT\"]=weatherData[\"Precip Type\"]\n\n# Rebuild the training and test data\nxtrain,xtest,ytrain,ytest = sklearn.model_selection.train_test_split(weatherDataF,temp,train_size=0.8)\n\n# Create the random forest model\nweatherModel=RandomForestRegressor()\n\n# Fit the model\nweatherModel.fit(xtrain,ytrain)\n\n# Generate predictions\npreds=weatherModel.predict(xtest)\n\n# Score the predictions\nscore=sklearn.metrics.r2_score(ytest,preds)\nprint(score)\n\nsns.distplot(preds)\nsns.distplot(ytest)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T14:26:12.389628Z","iopub.execute_input":"2021-06-12T14:26:12.390032Z","iopub.status.idle":"2021-06-12T14:27:12.62966Z","shell.execute_reply.started":"2021-06-12T14:26:12.390003Z","shell.execute_reply":"2021-06-12T14:27:12.628636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"An r2 score of 0.962 is not quite \"cutting edge\" performance, but we have not touched on the question of how well we could expect a model to perform ideally, so it is unclear how well this model performs relative to the ideal. A good next step would be to assess both the ability of the dataset set to predict the temperature, and the shortcomings of the random forest model.","metadata":{}}]}