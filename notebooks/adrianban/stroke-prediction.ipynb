{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%config Completer.use_jedi = False\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(16, 9))\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read and check informations about data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv', index_col='id')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now let's see missing values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"percent = ((data['bmi'].isnull().sum() / data.shape[0]) * 100).round(2)\npercent","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As we can see 4% of bmi data is missing**"},{"metadata":{},"cell_type":"markdown","source":"**I don't want to drop missing rows or column, therefore I fill these NA places with values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_filled = data.fillna(method='bfill')\n#data_filled = data.fillna(data.mean())\n#data_filled = data.fillna(data.median())\ndata_filled.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = (data_filled.dtypes == 'object')\ncat_cols = list(s[s].index)\n\n#num_cols = list(data_filled.select_dtypes(exclude=['object']))\nnum_cols = ['age', 'bmi', 'avg_glucose_level']\n\ncat_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data[num_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"low_cardinality_cols = [col for col in cat_cols if data_filled[col].nunique() < 10]\nlow_cardinality_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_data = pd.DataFrame(OH_encoder.fit_transform(data_filled[cat_cols]))\n\nOH_cols_data.index = data_filled.index\nOH_cols_data\n\ndata_num = data_filled.drop(cat_cols, axis=1)\nOH_data = pd.concat([data_num, OH_cols_data], axis=1)\nOH_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 10))\nsns.boxplot(data=OH_data[num_cols])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Removing outliers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1 = OH_data[num_cols].quantile(0.25)\nQ3 = OH_data[num_cols].quantile(0.75)\nIQR = Q3 - Q1\n\ndata_out = OH_data[~((OH_data[num_cols] < (Q1 - 1.5 * IQR)) |(OH_data[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)]\n\nplt.figure(figsize=(16, 10))\nsns.boxplot(data=data_out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_out","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Splitting the data to train set and test set**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data_out.drop('stroke', axis=1)\ny = data_out.loc[:, 'stroke']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Scaling****"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import Normalizer\nscaler = Normalizer()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\nX_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the next step we will use a for loop to find the best hyperparameter.\nIn the future, we can use gridsearch for that."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\nk_range = range(1, 26)\nscores_list = []\n\nfor k in k_range:\n    knn = KNeighborsClassifier(k)\n    knn.fit(X_train, y_train)\n    y_pred = knn.predict(X_test)\n    scores_list.append(accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 10))\nplt.plot(k_range, scores_list)\nplt.xlabel('Values of K')\nplt.ylabel('Accuracy score')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max(scores_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_list.index(max(scores_list))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best K value is 4 (3 + 1 because loop started from 1 and not 0)"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier(4)\nknn.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier(random_state=1)\n\ntree.fit(X_train, y_train)\ny_pred = tree.predict(X_test)\nscore = accuracy_score(y_test, y_pred)\nscore","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nforest = RandomForestClassifier(n_estimators = 1000, random_state=1)\n\nforest.fit(X_train, y_train)\ny_pred = forest.predict(X_test)\nscore = accuracy_score(y_test, y_pred)\nscore","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlog_model = LogisticRegression()\nlog_model.fit(X_train, y_train)\ny_pred = log_model.predict(X_test)\nscore = accuracy_score(y_test, y_pred)\nscore","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}