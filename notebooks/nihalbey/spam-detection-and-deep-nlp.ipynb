{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Welcome to NLP**\n\nToday we will have done nlp algorithm and we talk about \"how we do nlp from 0\".Firstly I talk you how we do after we do this.PLEASE UPVOTE and FEEDBACK.I hope it is benefit for you.\n"},{"metadata":{},"cell_type":"markdown","source":"**How can do NLp**\n\n* Firstly we throw punctuation(\"\",.:;)\n* Then we split all word\n* Then we return all word lower case\n* We find word root with lemmatizer\n* We make bag of word(It is including the most using word and sentence's info)\n* We make prediction model "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Firstly we read our data\ndata = pd.read_csv(\"../input/SPAM text message 20170820 - Data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We must change category 1 or 0\ndata[\"Category\"] = [1 if each == \"spam\" else 0 for each in data[\"Category\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Example**\n\nIt is example for you learn.I will do one row but ı will have all row in below"},{"metadata":{"trusted":true},"cell_type":"code","source":"#We choose 1 row.And we throw punctuation\nimport re\nnlp_data = str(data.iloc[2,:])\nnlp_data = re.sub(\"[^a-zA-Z]\",\" \",nlp_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#After return lower case\nnlp_data = nlp_data.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we have two choice we can use split methot or tokenize\nimport nltk as nlp\nnlp_data = nlp.word_tokenize(nlp_data)\n#nlp_data = nlp_data.split() or we can do so","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we have to find word root\nlemma = nlp.WordNetLemmatizer()\nnlp_data = [lemma.lemmatize(word) for word in nlp_data]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We join our data\nnlp_data = \" \".join(nlp_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And we have list is including all word now we have to prepare predict model but we will do the rest in below"},{"metadata":{},"cell_type":"markdown","source":"**NLP**\n\nWe do this process to all data with for loop"},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk as nlp\nimport re\ndescription_list = []\nfor description in data[\"Message\"]:\n    description = re.sub(\"[^a-zA-Z]\",\" \",description)\n    description = description.lower()   # buyuk harftan kucuk harfe cevirme\n    description = nlp.word_tokenize(description)\n    #description = [ word for word in description if not word in set(stopwords.words(\"english\"))]\n    lemma = nlp.WordNetLemmatizer()\n    description = [ lemma.lemmatize(word) for word in description]\n    description = \" \".join(description)\n    description_list.append(description) #we hide all word one section","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We make bag of word it is including number of all word's info\nfrom sklearn.feature_extraction.text import CountVectorizer \nmax_features = 3000 #We use the most common word\ncount_vectorizer = CountVectorizer(max_features = max_features, stop_words = \"english\")\nsparce_matrix = count_vectorizer.fit_transform(description_list).toarray()\nprint(\"the most using {} words: {}\".format(max_features,count_vectorizer.get_feature_names()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We separate our data is train and test\ny = data.iloc[:,0].values   # male or female classes\nx = sparce_matrix\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.1, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We make model for predict\nfrom sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train,y_train)\nprint(\"the accuracy of our model: {}\".format(nb.score(x_test,y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(max_iter = 200)\nlr.fit(x_train,y_train)\nprint(\"our accuracy is: {}\".format(lr.score(x_test,y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(x_train,y_train)\n#print('Prediction: {}'.format(prediction))\nprint('With KNN (K=3) accuracy is: ',knn.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = x_test.reshape(558,3000,1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = x_train.reshape(5014,3000,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\n\n# Initialising the RNN\nregressor = Sequential()\n\n# Adding the first LSTM layer and some Dropout regularisation\nregressor.add(LSTM(units = 50, return_sequences = True, input_shape = (x_train.shape[1], 1)))\nregressor.add(Dropout(0.2))\n\n# Adding a second LSTM layer and some Dropout regularisation\nregressor.add(LSTM(units = 50, return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a third LSTM layer and some Dropout regularisation\nregressor.add(LSTM(units = 50, return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a fourth LSTM layer and some Dropout regularisation\nregressor.add(LSTM(units = 50))\nregressor.add(Dropout(0.2))\n\n# Adding the output layer\nregressor.add(Dense(units = 1))\n\n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics=[\"accuracy\"])\n\n# Fitting the RNN to the Training set\nregressor.fit(x_test, y_test, epochs = 3, batch_size = 32)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n\nI hope you like our kernel.If you have questions you ask me i back you.If you UPVOTE me ı will be happy.Stay you good"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}