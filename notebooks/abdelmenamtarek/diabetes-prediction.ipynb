{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"text-align: center\"> Pima Indians Diabetes Database </h1>"},{"metadata":{},"cell_type":"markdown","source":"<p><b><i> first i will do some explaratory data analysis to he data set to get some insights and visulizations</i></b></p>"},{"metadata":{},"cell_type":"markdown","source":"<h4> data wrangling process </h4>\n<ol>\n    <li>data gathering </li>\n    <li>data assesing </li>\n    <li>data cleaing </li>\n</ol>\n<h6> then i will do some analysis </h6>\n<h6> then i will make an classification model"},{"metadata":{"trusted":true},"cell_type":"code","source":"## importing some usfel data\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## data gathering \n- i uploaded it to my nootbok"},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        data = os.path.join(dirname, filename)\n\ndf = pd.read_csv(data)\nprint('the data has {} column and {} rows'.format(df.shape[1] ,df.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## data assesing \n- here i will see the data to get guick overview about the records and know if there any problems "},{"metadata":{},"cell_type":"markdown","source":"#### visual assesment "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- <p style=\"color:red\" > there is some 0 value in the features column and that doesn't make any sense </p>"},{"metadata":{},"cell_type":"markdown","source":"#### visual assesment"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the data type\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- <p style=\"color:red\" >all data types are correct but its clear the the null values represented with 0 not null </p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check duplicate values \nif bool(df.duplicated().sum()) :\n    print('ther is duplicate rows')\nelse :\n    print('ther is no duplicate rows')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### assesing report \nchange the zeros values in <i>Glucose-BloodPressure-SkinThickness-Insulin-BMI</i> with the mean <br> \n<p style=\"text-align: center\" ><b> this is the only problem in the data set that need to clean</b></p>"},{"metadata":{},"cell_type":"markdown","source":"## data cleaning"},{"metadata":{},"cell_type":"markdown","source":"###### define .\n- there is 0 value in some column thet doesn't make any sense so i will convert them to the means value  "},{"metadata":{"trusted":true},"cell_type":"code","source":"(df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] == 0).sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### code"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer \nneed_to_vonvert = df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']]\nImputedModule = SimpleImputer(missing_values = 0 , strategy ='mean') \nImputed = ImputedModule.fit(need_to_vonvert) \ndf[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = Imputed.transform(need_to_vonvert) \n ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### test"},{"metadata":{"trusted":true},"cell_type":"code","source":"(df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] == 0).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1 style=\"text-align: center; color:red\"> EDA </h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import rcParams\n## see outcome counts\nrcParams['figure.figsize'] =(8,6)\nplt.pie(x=df['Outcome'].value_counts().values ,explode = [0.01,0.01] ,\n            labels =['no diabetes', 'diabetes'] , startangle = 90, autopct= '%1.1f%%', counterclock = False);\nplt.title('outcome' ,fontsize=18);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### see the counts of the Pregnancies"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import rcParams\nsns.set(style=\"whitegrid\")\ngroupedvalues = df['Pregnancies'].value_counts()\ng=sns.countplot(x=\"Pregnancies\", data=df,linewidth=5 ,palette=\"Blues_d\");\nrcParams['figure.figsize'] =(15,10)\nfor index, row in zip(groupedvalues.index ,groupedvalues.values):\n    g.text(index ,row, round(row,2), color='black', ha=\"center\" , fontsize=15)\ng.axes.get_yaxis().set_visible(False)\nplt.xlabel('Pregnancies' , fontsize=18);\nplt.title('the count of pregancies values' , fontsize=12);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### the relation between age and diabetes"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"sns.set()\nrcParams['figure.figsize'] =(8,6)\nsns.violinplot(data=df, x='Outcome', y='Age', color=sns.color_palette()[0] , inner='quartile' );\nplt.xlabel('Outcome');\nplt.ylabel('Age');\nplt.title('Age distrubution' , fontsize=18);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### see corelation "},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.set(style=\"ticks\", color_codes=True)\ng= sns.pairplot(df, hue=\"Outcome\", palette=\"husl\" );\nhandles = g._legend_data.values()\nlabels = g._legend_data.keys()\ng.fig.legend(handles=handles, labels=labels, loc='upper center', ncol=1 , fontsize=18);\ng.fig.subplots_adjust(top=0.92, bottom=0.08);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df.corr()\nmask = np.triu(np.ones_like(corr, dtype=bool));\ncmap = sns.diverging_palette(230, 20, as_cmap=True);\nsns.heatmap(corr, mask=mask, cmap=cmap , linewidths=.5);\nplt.title('correlation heatmap' , fontsize=18);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# classification model "},{"metadata":{"trusted":true},"cell_type":"code","source":"#determine x , y\nx = df.drop('Outcome' , axis=1)\ny = df.Outcome\n\nx.shape , y.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### data rescaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler(copy=True, with_mean=True, with_std=True) \nx = scaler.fit_transform(x) \nprint('X \\n' , x[:2]) \nprint('y \\n' , y[:2].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### data splitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\n\npoly = PolynomialFeatures(degree=2)\nx_poly = poly.fit_transform(x)\n\n\n\nx_train, x_test, y_train, y_test = train_test_split(x_poly, y, test_size=0.30, random_state=44, shuffle =True) \n \nprint('X_train shape is ' , x_train.shape) \nprint('X_test shape is ' , x_test.shape) \nprint('y_train shape is ' , y_train.shape) \nprint('y_test shape is ' , y_test.shape) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### logistic regression \"classification\"\n<p style=\"color:red\" > if i try neural_network  it will give similar results as the logistic regression model </p>"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression \n\n\nLogisticRegressionModel = LogisticRegression(penalty='l2',solver='sag' , C=1.0, random_state=33  ) \nLogisticRegressionModel.fit(x_train, y_train) \n \nprint('LogisticRegressionModel Train Score is : ' , LogisticRegressionModel.score(x_train, y_train)) \nprint('LogisticRegressionModel Test Score is : ' , LogisticRegressionModel.score(x_test, y_test)) \nprint('LogisticRegressionModel Classes are : ' , LogisticRegressionModel.classes_)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### calculate some metric about the test prediction "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score ,classification_report , plot_confusion_matrix\n\ny_pred = LogisticRegressionModel.predict(x_test)\nplot_confusion_matrix(LogisticRegressionModel, x_test, y_test ) ;\nplt.show()\n \nF1Score = f1_score(y_test, y_pred, average='micro')\nprint('F1 Score is : ', F1Score)\n\nClassificationReport = classification_report(y_test,y_pred) \nprint('\\nClassification Report is : ', ClassificationReport ) \n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### save the model "},{"metadata":{"trusted":true},"cell_type":"code","source":"import joblib as jb\njb.dump(LogisticRegressionModel , 'saved file.sav') \n ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### try k. nearest Neighbors "},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=44, shuffle =True) \n\nfrom sklearn.neighbors import KNeighborsClassifier \n\nKNNClassifierModel = KNeighborsClassifier(n_neighbors= 5,weights ='distance', algorithm='auto') \nKNNClassifierModel.fit(x_train, y_train)\n\nprint('KNNClassifierModel Train Score is : ' , KNNClassifierModel.score(x_train, y_train)) \nprint('KNNClassifierModel Test Score is : ' , KNNClassifierModel.score(x_test, y_test)) \n\ny_pred = KNNClassifierModel.predict(x_test)\nplot_confusion_matrix(KNNClassifierModel, x_test, y_test ) ;","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" - it very good at the train set but at the test data the logistic regression is better"},{"metadata":{},"cell_type":"markdown","source":"### trying descion tree \n<p style=\"color:red\" ><b> iceasing max_depth will increase the accuracy but will increase the time too </b></p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.tree import DecisionTreeClassifier\n\nDecisionTreeClassifierModel = DecisionTreeClassifier(criterion='entropy',max_depth=10,random_state=33)\nDecisionTreeClassifierModel.fit(x_train, y_train)\n\nprint('DecisionTreeRegressor Train Score is : ' , DecisionTreeClassifier.score(self = DecisionTreeClassifierModel , X= x_train, y= y_train) ) \nprint('DecisionTreeRegressor Test Score is : ' ,DecisionTreeClassifier.score(self = DecisionTreeClassifierModel , X= x_test, y= y_test))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}