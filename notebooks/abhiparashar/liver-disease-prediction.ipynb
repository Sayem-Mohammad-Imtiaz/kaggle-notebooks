{"cells":[{"metadata":{},"cell_type":"markdown","source":"# LIVER DISEASE PREDICTION"},{"metadata":{},"cell_type":"markdown","source":"**In this project, we are going to use the Indian Liver Patient Records dataset from kaggle.**"},{"metadata":{},"cell_type":"markdown","source":"**We are going to predict whether a patient has liver disease or not based on certain features.**"},{"metadata":{},"cell_type":"markdown","source":"**We are going to check with the total proteins,albumin etc whether it is asscoiated with disease or not.**"},{"metadata":{},"cell_type":"markdown","source":"**Importing the Necessary Libraries:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**For the purpose of prediction, we need to import more libraries. As we move on, we will import them.**"},{"metadata":{},"cell_type":"markdown","source":"**Reading the Dataset:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\npatients=pd.read_csv('/kaggle/input/indian-liver-patient-records/indian_liver_patient.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"patients.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"patients.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**So there are 583 rows and 11 columns in our dataset.**"},{"metadata":{},"cell_type":"markdown","source":"**Let us make the Gender column into numerical format:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"patients['Gender']=patients['Gender'].apply(lambda x:1 if x=='Male' else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"patients.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Here there is a column named Dataset which has two values. Here one of the value symbolises that the patient has \ndisease and the other value symbolises that the patient has no disease.**"},{"metadata":{},"cell_type":"markdown","source":"**Let us check the number of male and female using a countplot.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"patients['Gender'].value_counts().plot.bar(color='peachpuff')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**From the above graph, we can see that Number of males are more than the Number of females.**"},{"metadata":{},"cell_type":"markdown","source":"**Let us check the countplot of our Dataset column:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"patients['Dataset'].value_counts().plot.bar(color='blue')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let us check for the null values:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"patients.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see that there are 4 null values in the Albumin and Globulin Ratio column.**"},{"metadata":{},"cell_type":"markdown","source":"**Let us fill these null values by imputing the mean of that column.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"patients['Albumin_and_Globulin_Ratio'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"patients=patients.fillna(0.94)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Yes! Now we have filled the null values with the mean of that column.** "},{"metadata":{"trusted":true},"cell_type":"code","source":"patients.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**So we have removed all the null values and we are ready to go !**"},{"metadata":{},"cell_type":"markdown","source":"**Let us check the age group of the patients.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('darkgrid')\nplt.figure(figsize=(25,10))\npatients['Age'].value_counts().plot.bar(color='darkviolet')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let us view the pairplot of patients based on Gender.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize']=(10,10)\nsns.pairplot(patients,hue='Gender')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(patients)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let us compare the albumin and albumin and globulin ratio by a scatterplot.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(8, 6))\nsns.scatterplot(x=\"Albumin\", y=\"Albumin_and_Globulin_Ratio\",color='mediumspringgreen',data=patients);\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let us compare the Gender based on the Protein Intake.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\npatients.groupby('Gender').sum()[\"Total_Protiens\"].plot.bar(color='coral')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**So protein intake is higher in the case of Male and comparitively less in females.**"},{"metadata":{},"cell_type":"markdown","source":"**Let us compare male and female based on Albumin Level.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\npatients.groupby('Gender').sum()['Albumin'].plot.bar(color='midnightblue')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Albumin Level is higher in the case in the case of male compared to female.**"},{"metadata":{},"cell_type":"markdown","source":"**Finally Let us compare them based on the Bilirubin content.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\npatients.groupby('Gender').sum()['Total_Bilirubin'].plot.bar(color='fuchsia')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can clearly see that males has more bilirubin content compared to females.**"},{"metadata":{},"cell_type":"markdown","source":"**Another point to be noted here is that higher the Bilirubin content, higher the case is prone to Liver disease.**"},{"metadata":{},"cell_type":"markdown","source":"**Let us check the correlation between the features using a heatmap:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr=patients.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10)) \nsns.heatmap(corr,cmap=\"Greens\",annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**So Let us start building our model.**"},{"metadata":{},"cell_type":"markdown","source":"**Inorder to build a successful model we have to train and test the model.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"patients.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now let us define our X and y.**"},{"metadata":{},"cell_type":"markdown","source":"**Here X is our features and y is our target.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=patients[['Age', 'Gender', 'Total_Bilirubin', 'Direct_Bilirubin',\n       'Alkaline_Phosphotase', 'Alamine_Aminotransferase',\n       'Aspartate_Aminotransferase', 'Total_Protiens', 'Albumin',\n       'Albumin_and_Globulin_Ratio']]\ny=patients['Dataset']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=123)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We split the training and testing  in a certain ratio as 70 for training and 30 for testing.**"},{"metadata":{},"cell_type":"markdown","source":"**Now inorder to build our model we use Logistic Regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nlogmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Now, Let us import the cross validation score and Kfold and split them into 5.**"},{"metadata":{},"cell_type":"markdown","source":"**Finally, we are calculating the accuracy of our model.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score\nkfold = KFold(n_splits=5,random_state=42)\nlogmodel = LogisticRegression(C=1, penalty='l1')\nresults = cross_val_score(logmodel, X_train,y_train,cv = kfold)\nprint(results)\nprint(\"Accuracy:\",results.mean()*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Thus we can conclude that our model performed at an accuracy of 71.5%.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, cross_val_score, learning_curve, train_test_split\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score\nrandom_state=42\nimport itertools","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_clf = LogisticRegression(random_state = 42)\nparam_grid = {\n            'penalty' : ['l2','l1'],  \n            'C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n            }\n\nCV_log_clf = GridSearchCV(estimator = log_clf, param_grid = param_grid , scoring = 'accuracy', verbose = 1, n_jobs = -1)\nCV_log_clf.fit(X_train, y_train)\n\nbest_parameters = CV_log_clf.best_params_\nprint('The best parameters for using this model is', best_parameters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix \ndef plot_confusion_matrix(cm, classes,\n                          normalize = False,\n                          title = 'Confusion matrix\"',\n                          cmap = plt.cm.Blues) :\n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation = 0)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])) :\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment = 'center',\n                 color = 'white' if cm[i, j] > thresh else 'black')\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n# Show metrics \ndef show_metrics():\n    tp = cm[1,1]\n    fn = cm[1,0]\n    fp = cm[0,1]\n    tn = cm[0,0]\n    print('Accuracy  =     {:.3f}'.format((tp+tn)/(tp+tn+fp+fn)))\n    print('Precision =     {:.3f}'.format(tp/(tp+fp)))\n    print('Recall    =     {:.3f}'.format(tp/(tp+fn)))\n    print('F1_score  =     {:.3f}'.format(2*(((tp/(tp+fp))*(tp/(tp+fn)))/\n                                                 ((tp/(tp+fp))+(tp/(tp+fn))))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Precision-recall curve\ndef plot_precision_recall():\n    plt.step(recall, precision, color = 'b', alpha = 0.2,\n             where = 'post')\n    plt.fill_between(recall, precision, step ='post', alpha = 0.2,\n                 color = 'b')\n\n    plt.plot(recall, precision, linewidth=2)\n    plt.xlim([0.0,1])\n    plt.ylim([0.0,1.05])\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision Recall Curve')\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ROC curve\ndef plot_roc():\n    plt.plot(fpr, tpr, label = 'ROC curve', linewidth = 2)\n    plt.plot([0,1],[0,1], 'k--', linewidth = 2)\n   # plt.xlim([0.0,0.001])\n   # plt.ylim([0.0,1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Learning curve\ndef plot_learning_curve(estimator, title, X, y, ylim = None, cv = None,\n                        n_jobs = 1, train_sizes = np.linspace(.1, 1.0, 5)):\n    \"\"\"\n    Plots a learning curve. http://scikit-learn.org/stable/modules/learning_curve.html\n    \"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel('Training examples')\n    plt.ylabel('Score')\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv = cv, n_jobs = n_jobs, train_sizes = train_sizes)\n    train_scores_mean = np.mean(train_scores, axis = 1)\n    train_scores_std = np.std(train_scores, axis = 1)\n    test_scores_mean = np.mean(test_scores, axis = 1)\n    test_scores_std = np.std(test_scores, axis = 1)\n    plt.grid()\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha = 0.1, color = \"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color = \"r\",\n             label = \"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color = \"g\",\n             label = \"Cross-validation score\")\n    plt.legend(loc = \"best\")\n    return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross val metric\ndef cross_val_metrics(model) :\n    scores = ['accuracy', 'precision', 'recall']\n    for sc in scores:\n        scores = cross_val_score(model, X, y, cv = 5, scoring = sc)\n        print('[%s] : %0.5f (+/- %0.5f)'%(sc, scores.mean(), scores.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix \nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report \nactual = y_test \npredicted = y_pred \nresults = confusion_matrix(actual, predicted) \nprint(\"Confusion Matrix :\")\nprint(results) \nprint('Accuracy Score :',accuracy_score(actual, predicted)) \nprint('Report : ')\nprint(classification_report(actual, predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics import roc_curve\ndef plot_roc_cur(fper, tper):  \n    plt.plot(fper, tper, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.savefig('roc.png', dpi=500, bbox_inches='tight')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_clf = LogisticRegression(C = best_parameters['C'], \n                                 penalty = best_parameters['penalty'], \n                                 random_state = random_state)\n\nselector = RFE(log_clf)\nselector = selector.fit(X_train, y_train)\n\ny_pred = selector.predict(X_test)\ny_score = selector.predict_proba(X_test)[:,1]\n\n\n# Confusion maxtrix & metrics\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]\nplt.figure()\nplot_confusion_matrix(cm, \n                      classes=class_names, \n                      title='Logistic Confusion matrix')\nplt.show()\n\nshow_metrics()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}