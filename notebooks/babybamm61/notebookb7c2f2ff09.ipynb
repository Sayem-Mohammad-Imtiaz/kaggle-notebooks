{"cells":[{"metadata":{"id":"3ogx5RBXim-J"},"cell_type":"markdown","source":"<center><h1><span style=\"color:Red\">Real or Not? NLP with Disaster Tweets</span></h1>\n    <h2> DSI 206 Multimedia Representation Management</h2>\n     <h3>BY Sukonlaphat Chinnawong 6209656203 <br/>\n        Apiwat Yokyuenyong 6209656237 <br/>\n         Kittisak Thongsi 6209656286<br/></h3></center>"},{"metadata":{"id":"M8e78onHiqRr"},"cell_type":"markdown","source":"# **Introduction**\n\n\n> ในปัจจุบัน สื่อออนไลน์เป็นช่องทางที่บุคคลทั่วไปนิยมใช้ในการกระจายข่าวกันอย่างแพร่หลาย ซึ่งทวิตเตอร์กลายเป็นช่องทางการสื่อสารที่มีความนิยมและสำคัญในยามฉุกเฉิน ผู้คนสามารถประกาศเหตุฉุกเฉินที่พวกเขากำลังเฝ้าสังเกตได้แบบเรียลไทม์ นำมาซึ่งการแข่งขันที่ท้าทายในการแข่งขันประมวลผล NLP"},{"metadata":{},"cell_type":"markdown","source":"![picture](https://www.magisto.com/blog/wp-content/uploads/2019/03/Twitter.jpg)"},{"metadata":{},"cell_type":"markdown","source":"# Data Set\nทางผู้จัดทำได้ให้ข้อมูลมาทั้งหมด 3 ชุดข้อมูลประกอบไปด้วย <br/><br/>\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.) train.csv ตัวข้อมูลประกอบไปด้วยข้อมูลทั้งหมด 7613 ข้อมูล และประกอบไปด้วย attributes ดังนี้ <br/><br/>\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.1) id คือ ลำดับเลขไอดีของผู้ใช้ <br/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.2) keyword คือ คำเฉพาะที่ใช้สำหรับการทำนายจากใน tweet นั้นๆ <br/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.3) location คือ พิกัดของผู้ใช้งาน <br/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.4) text คือ ข้อความที่ผู้ใช้งานโพสต์ลง twitter <br/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.5) target คือ ผลการทำนายว่าเป็นประโยคที่เกี่ยวข้องกับภัยพิบัติหรือไม่ โดยที่ 0 หมายถึง ไม่เกี่ยวข้อง และ 1 หมายถึง เกี่ยวข้อง <br/><br/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.) test.csv ตัวข้อมูลประกอบไปด้วยข้อมูลทั้งหมด 3623 ข้อมูล และประกอบไปด้วย attributes ดังนี้ <br/><br/>\n    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.1) id คือ ลำดับเลขไอดีของผู้ใช้ <br/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2) keyword คือ คำเฉพาะที่ใช้สำหรับการทำนายจากใน tweet นั้นๆ <br/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.3) location คือ พิกัดของผู้ใช้งาน <br/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.4) text คือ ข้อความที่ผู้ใช้งานโพสต์ลง twitter <br/><br/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.) sample_submission.csv ชุดข้อมูลนี้ทำหน้าเก็บข้อมูล id และ target ของข้อความ แต่ละข้อความว่าเกี่ยวข้องกับประโยคภัยพิบัติหรือไม่"},{"metadata":{"id":"lpReiEeJixkR"},"cell_type":"markdown","source":"# Method\n\n   import module ที่ใช้จำเป็นต่อการวิเคราะห์"},{"metadata":{"id":"RlIt2QXVgOvc","outputId":"43febb59-c8ec-4d50-d283-a6dfe2a2ac87","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\n\nimport re \nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport nltk \nfrom sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing\nimport nltk.corpus\nfrom nltk.corpus import stopwords\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('stopwords')\nimport string\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom collections import defaultdict\nfrom collections import  Counter\nplt.style.use('ggplot')\nstop=set(stopwords.words('english'))\nimport re\nfrom nltk.tokenize import word_tokenize\nimport gensim\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom tqdm import tqdm\nfrom keras.models import Sequential\nfrom keras.layers import Embedding,LSTM,Dense,SpatialDropout1D\nfrom keras.initializers import Constant\nfrom sklearn.model_selection import train_test_split\nfrom nltk.stem import PorterStemmer \nfrom nltk.tokenize import word_tokenize\nfrom wordcloud import WordCloud\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport pickle\nimport statsmodels.api as sm","execution_count":null,"outputs":[]},{"metadata":{"id":"gwcK_eFJjApy"},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; import ชุดข้อมูลเข้ามาโดย train_data คือข้อมูลที่ใช้สำหรับฝึก model และ test_data คือข้อมูลที่ใช้สำหรับทดสอบ model ซึ่งหลังจากที่ import ชุดข้อมูลเข้ามาแล้ว จึงทำการเช็คลักษณะของข้อมูลโดยรวม และชนิดของข้อมูลทั้ง 2 ชุดข้อมูล"},{"metadata":{"id":"pwNspbq7jKUM","outputId":"78b27c39-8f0b-4a8d-9d3a-5c31ec371fd9","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/nlp-getting-started/train.csv')\ntest_data  = pd.read_csv('../input/nlp-getting-started/test.csv')\ntrain_data.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"mS9Zqadvjir8","outputId":"393dfa27-87ed-4da8-ca8a-1505d4a90581","trusted":true},"cell_type":"code","source":"train_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"id":"Zb1e9j2EjvL0","outputId":"fd2a31a6-8d5c-41cb-e958-fb90f615057a","trusted":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"a5BjhzvCj738","outputId":"3d700955-8af7-48c9-b4b6-f71703a43dd8","trusted":true},"cell_type":"code","source":"test_data.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"uyLTW28So41g","outputId":"85461293-809d-4657-f4c2-255d00676d83","trusted":true},"cell_type":"code","source":"train_data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"id":"8rKFRBU6o6l7","outputId":"2547353b-206d-4468-d732-a0206ec85e61","trusted":true},"cell_type":"code","source":"test_data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"id":"MasrTt2OjKic"},"cell_type":"markdown","source":"\n\n   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ดูจำนวนของข้อมูลว่าเป็น 0 (ประโยคไม่เกี่ยวกับภัยพิบัติ) และ 1 (ประโยคที่เกี่ยวกับภัยพิบัติ) โดยใช้ funtion value count เพื่อนับจำนวน value 0 กับ 1 ในคอลัมน์ target\nแล้ว plot โดย seaborn barplot\n\n\n"},{"metadata":{"id":"DRixxxILpSmz","outputId":"b0e99a7d-432c-4889-a340-6f74240ce401","trusted":true},"cell_type":"code","source":"x=train_data.target.value_counts()\nsns.barplot(x.index,x)\nplt.title('number of tweet')","execution_count":null,"outputs":[]},{"metadata":{"id":"SF2nj8SFkL0g"},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  แยกสิ่งที่ต้องการเป็น 2 กลุ่ม ได้แก่ tweet_len(target==1 เป็น boolean) และ tweet_len (target==0 เป็น boolean) แล้วนับจำนวน character ทั้งหมดผ่านฟังก์ชั่น len นับจำนวน string character นำมาพล็อตเพื่อดูจำนวน character ในแต่ละกลุ่ม เพื่อดูความแตกต่างของจำนวน character ในแต่ละกลุ่มว่าแตกต่างกันหรือไม่\n\n\n"},{"metadata":{"id":"h44Tr9o7tX1U","outputId":"795a969c-c435-46cb-9106-6e1b46ba7724","trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_len=train_data[train_data['target']==1]['text'].str.len()\nax1.hist(tweet_len,color='blue')\nax1.set_title('disaster tweets')\ntweet_len=train_data[train_data['target']==0]['text'].str.len()\nax2.hist(tweet_len,color='CRIMSON')\nax2.set_title('Not disaster tweets')\nfig.suptitle('Characters in tweets')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"t01vvEBwkmSs"},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  แยกสิ่งที่ต้องการเป็น 2 กลุ่ม ได้แก่ tweet_len(target==1 เป็น boolean) และ tweet_len (target==0 เป็น boolean) แล้วนับจำนวน word ในแต่ละกลุ่มโดยการนำ string มา split เป็น list ของคำนับจำนวนคำใน list โดยใช้ len นำมาพล็อตเพื่อดูจำนวน word ในแต่ละกลุ่ม เพื่อดูความแตกต่าง word ในแต่ละกลุ่มว่ามีจำนวนและการกระจายแตกต่างกันหรือไม่\n"},{"metadata":{"id":"K6S9DHVgunYX","outputId":"29886030-1263-44e2-a23c-305eb53cf610","trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_len=train_data[train_data['target']==1]['text'].str.split().map(lambda x: len(x))\nax1.hist(tweet_len,color='blue')\nax1.set_title('disaster tweets')\ntweet_len=train_data[train_data['target']==0]['text'].str.split().map(lambda x: len(x))\nax2.hist(tweet_len,color='CRIMSON')\nax2.set_title('Not disaster tweets')\nfig.suptitle('Words in a tweet')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"s3YONKfMk2MT"},"cell_type":"markdown","source":"\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; แยกสิ่งที่ต้องการเป็น 2 กลุ่ม ได้แก่ word (target==1 เป็น boolean) และ word (target==0 เป็น boolean) แล้วเก็บความยาวของแต่ละ word ไว้ใน list จากนั้นมาหาค่าเฉลี่ยของความยาวตัวอักษรของคำในแต่ละ index ผ่าน numpy นำค่าเฉลี่ยที่ได้มาพล็อตเพื่อดูความยาวเฉลี่ยของคำในแต่ละกลุ่ม เพื่อดูความแตกต่างของความยาวเฉลี่ยของคำในแต่ละกลุ่มว่ามีจำนวนและการกระจายแตกต่างกันหรือไม่\n\n"},{"metadata":{"id":"CaXBj4PHup2m","outputId":"7ff571d2-5df9-4e51-cfb2-96078ec8c269","trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\nword=train_data[train_data['target']==1]['text'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax1,color='red')\nax1.set_title('disaster')\nword=train_data[train_data['target']==0]['text'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax2,color='green')\nax2.set_title('Not disaster')\nfig.suptitle('Average word length in each tweet')","execution_count":null,"outputs":[]},{"metadata":{"id":"R8EA8CbwlLih"},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  ตั้ง list ว่างชื่อ corpus เพื่อเตรียมเก็บคำที่ต้องการ ใช้ nest loop โดย for loop ใน column ชื่อ text ทุกแถวและนำคำทุกคำไปเก็บไว้ใน list ชื่อ corpus ผ่านการ append"},{"metadata":{"id":"5azuXEenu-X8","trusted":true},"cell_type":"code","source":"corpus=[]\n    \nfor x in train_data['text'].str.split():\n    for i in x:\n        corpus.append(i)","execution_count":null,"outputs":[]},{"metadata":{"id":"7CHOALFwleia"},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ประกาศตัวแปร dic โดยใช้ defaultdict เพื่อป้องกัน key error นับจำนวนคำทุกคำที่ไม่ใช่ stop word ใน corpus โดยให้ key เป็นคำศัพท์และ value เป็นจำนวนคำโดยใช้การ for loop และเพิ่ม value อีก 1 เมื่อคำดังกล่าวเป็นไปตามเงื่อนไขคือ ไม่เป็น stop word จากนั้นนำมาเรียงโดยการ sorted จากมากไปน้อยเพื่อให้ง่ายต่อการดูข้อมูลโดยเรียกดูเพียงแค่ 30 ตัวแรก และนำมาพล็อตกราฟ เพื่อดูว่าคำใดบ้างที่ไม่มีใน stopword และมีจำนวนเท่าใดใน corpus"},{"metadata":{"id":"-Ruzmp2vvId8","outputId":"a5c8f9a1-8fd6-4693-d013-d5bab7228aa8","trusted":true},"cell_type":"code","source":"dic=defaultdict(int)\ndic=defaultdict(int)\nfor word in corpus:\n    if word not in stop:\n        dic[word]+=1\n\ntop=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:30] \n    \n\n\nx,y=zip(*top)\nplt.rcParams[\"figure.figsize\"] = (20,10)\nplt.bar(x,y , color ='red')","execution_count":null,"outputs":[]},{"metadata":{"id":"j2QM-a5yl60k"},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  ประกาศตัวแปร dic โดยใช้ defaultdict เพื่อป้องกัน key error นับจำนวนคำทุกคำที่ เป็น stop word ใน corpus โดยให้ key เป็นคำศัพท์และ value เป็นจำนวนคำโดยใช้การ for loop และเพิ่ม value อีก1 เมื่อคำดังกล่าวเป็นไปตามเงื่อนไขคือ เป็น stop word จากนั้นนำมาเรียงโดยการ sorted จากมากไปน้อยเพื่อให้ง่ายต่อการดูข้อมูลเรียกดูแค่ 30 ตัวแรก และนำมาพล็อตกราฟ เพื่อดูว่าคำใดบ้างที่เป็น stopword และ มีจำนวนเท่าไรใน corpus "},{"metadata":{"id":"nF9-qGKKwHrB","outputId":"51344dc2-1dff-4241-9866-13b2dce1d5ee","trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nstop = stopwords.words('english')\ndic=defaultdict(int)\nfor word in corpus:\n    if word in stop:\n        dic[word]+=1\n\ntop=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:30] \n    \n\n\nx,y=zip(*top)\nplt.rcParams[\"figure.figsize\"] = (20,10)\n#There is also this workaround in case you want to change the size without using the figure environment.\n#So in case you are using plt.plot() for example, you can set a tuple with width and height.\nplt.bar(x,y , color ='green')","execution_count":null,"outputs":[]},{"metadata":{"id":"qBkTvzxSmXiq"},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  ประกาศตัวแปร dic โดยใช้ defaultdict เพื่อป้องกัน key error นับจำนวนคำทุกคำที่เป็น punctuation ใน corpus โดยให้ key เป็น คำศัพท์ และ value เป็นจำนวนคำ โดยใช้การ for loop และเพิ่ม value อีก1 เมื่อคำดังกล่าวเป็นไปตามเงื่อนไข คือ เป็น punctuation จากนั้นนำมาพล็อตกราฟ เพื่อดูว่าคำใดบ้างที่เป็น punctuation และ มีจำนวนเท่าไรใน corpus "},{"metadata":{"id":"pJ2eFgS6wr8J","outputId":"8e46ea7c-4749-4adb-9d5d-da835769df3b","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nimport string\ndic=defaultdict(int)\nspecial = string.punctuation\nfor i in (corpus):\n    if i in special:\n        dic[i]+=1\n      \nx,y=zip(*dic.items())\nplt.barh(x,y ,color = 'purple')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"หลังจากพล็อตกราฟเพื่อดูลักษณะข้อมูลแล้วได้ข้อสรุปดังนี้ <br/><br/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  1.ในการทำ NLP จะไม่นำความยาวของจำนวน Character จำนวนคำความยาวเฉลี่ยของคำ มาใช้ในการทำ model เนื่องจากมีการกระจายและจำนวนที่ไม่แตกต่างกัน ในกลุ่มที่ target เป็น 1 และ target เป็น 0 ซึ่งตอนแรกนั้นผู้จัดทำคาดการว่าตัวแปรเหล่านี้อาจจะมีผลเนื่องจาก หากเป็นการแชร์ข่าวภัยพิบัติก็ควรจะมีความยาวของ character หรือจำนวนคำที่มากกว่า tweet ที่แค่พิมพ์ทั่วไปและคาดว่าหากเป็น tweet ที่เกี่ยวกับภัยพิบัติอาจจะมีคำศัพท์เฉพาะที่มีความยาวเฉลี่ยต่างจาก tweet ทั่วไป <br/><br/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  2.ในการ cleansing data จะต้องตัด punctuation และ stop word เนื่องจากมีจำนวนมากใน corpus ซึ่งอาจจะมีผลกับจำนวน feature ในการทำ tfidf\n"},{"metadata":{"id":"QsWHb69EnGzh"},"cell_type":"markdown","source":"# Cleansing Data\n\n   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ประกาศ dictionary ชื่อ contraction โดยให้ key เป็นคำย่อที่เราสนใจ value เป็นคำเต็มของคำนั้น เพื่อเตรียมที่จะเปลี่ยน format ของคำที่เราสนใจในขั้นตอนต่อไป\n"},{"metadata":{"id":"Fftt4AaMbSvi","trusted":true},"cell_type":"code","source":"contractions = { \n\"ain't\": \"am not\",\n\"aren't\": \"are not\",\n\"can't\": \"cannot\",\n\"can't've\": \"cannot have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he will\",\n\"he's\": \"he is\",\n\"how'd\": \"how did\",\n\"how'll\": \"how will\",\n\"how's\": \"how is\",\n\"i'd\": \"i would\",\n\"i'll\": \"i will\",\n\"i'm\": \"i am\",\n\"i've\": \"i have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it would\",\n\"it'll\": \"it will\",\n\"it's\": \"it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"needn't\": \"need not\",\n\"oughtn't\": \"ought not\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"she'd\": \"she would\",\n\"she'll\": \"she will\",\n\"she's\": \"she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"that'd\": \"that would\",\n\"that's\": \"that is\",\n\"there'd\": \"there had\",\n\"there's\": \"there is\",\n\"they'd\": \"they would\",\n\"they'll\": \"they will\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"wasn't\": \"was not\",\n\"we'd\": \"we would\",\n\"we'll\": \"we will\",\n\"we're\": \"we are\",\n\"we've\": \"we have\",\n\"weren't\": \"were not\",\n\"what'll\": \"what will\",\n\"what're\": \"what are\",\n\"what's\": \"what is\",\n\"what've\": \"what have\",\n\"where'd\": \"where did\",\n\"where's\": \"where is\",\n\"who'll\": \"who will\",\n\"who's\": \"who is\",\n\"won't\": \"will not\",\n\"wouldn't\": \"would not\",\n\"you'd\": \"you would\",\n\"you'll\": \"you will\",\n\"you're\": \"you are\"\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nstop = stopwords.words('english')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  สร้าง function ชื่อ Expand_contraction โดยมี argument เป็นข้อความ(text) ใน function จะมีการ split ข้อความเพื่อแยกคำออกมา แล้วสร้าง list เพื่อเก็บคำชื่อ new_text จากนั้น for loop เพื่อดูว่าคำใดบ้างที่เป็นตรงกับค่า key ใน dictionary contractions หากตรงจะเปลี่ยนให้เป็น value ที่กำหนดไว้แล้วนำไปเก็บไว้ใน litst ชื่อ new_text หากไม่ตรงจะใช้ค่าเดิม แล้วนำไปเก็บไว้ใน list ชื่อ new_text นำคำใน list ชื่อ new text มา join กลับเป็น string อีกครั้ง ได้เป็นข้อความที่แปลงคำที่เป็น contraction word แล้ว"},{"metadata":{"id":"1MnGGCkKbZzj","trusted":true},"cell_type":"code","source":"def Expand_contraction(text):\n  if True:\n        text = text.split()\n        new_text = []\n        for word in text:\n            if word in contractions:\n                new_text.append(contractions[word])\n            else:\n                new_text.append(word)\n        text = \" \".join(new_text)\n  return text\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  สร้าง function ชื่อ clean_text มี argument 3 ตัวได้แค่ df, text_field , new_text_field_name  หลักการคือแปลง text ให้เป็น lower ทั้งหมดก่อน จากนั้นใช้ module หลัก คือ apply lambda มาช่วยเปลี่ยนแปลงค่าในแต่ละแถวให้เป็นค่า format ที่เราต้องการ โดยการใช้ regular expression เพื่อเปลี่ยน string ใน format แบบที่เราสนใจไปเป็น format แบบที่เราต้องการ โดยสิ่งที่เราทำมีดังนี้ <br/><br/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  1.ลบตัวเลขทั้งหมด <br/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  2.Expand_contraction <br/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  3.เอา stop word ออก <br/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  4.เอาสิ่งที่ไม่ใช่เนื้อหา และ punctuation ออก <br/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  5.ลบ html tag <br/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  6.ลบ emoji <br/>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  7.แปลงคำต่างๆเป็น format แบบเดียวกัน ใช้ function clean_text เพื่อ clean ข้อมูลที่จะใช้ทำ model และข้อมูลที่จะทำไปทดสอบ <br/>"},{"metadata":{"id":"zyhJtN2MyvWD","outputId":"aee3a213-beb2-4e29-d5d7-701b9eb449f9","trusted":true,"_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"def  clean_text(df, text_field, new_text_field_name):\n    df[new_text_field_name] = df[text_field].str.lower() #Convert strings in the Series/Index to lowercase.\n    \n    # remove numbers\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text: re.sub(r\"\\d+\", \"\", text))\n    #Expandsion text\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text : Expand_contraction(text))\n    #removestop word\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n    #remove unwanted character\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text: re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text: re.sub(r'\\<a href', ' ', text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text: re.sub(r'&amp;', '', text) )\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text: re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text: re.sub(r'<br />', ' ', text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text: re.sub(r'\\'', ' ', text))\n    #remove HTML tags\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text: re.sub(r\"<.*?>\", \"\", text))\n    #remove emojis \n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text: re.sub(r\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", \"\", text))\n        # Hashtags and usernames\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"IranDeal\", \"Iran Deal\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ArianaGrande\", \"Ariana Grande\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"camilacabello97\", \"camila cabello\", text)) \n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"RondaRousey\", \"Ronda Rousey\", text))     \n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MTVHottest\", \"MTV Hottest\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TrapMusic\", \"Trap Music\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ProphetMuhammad\", \"Prophet Muhammad\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"PantherAttack\", \"Panther Attack\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"StrategicPatience\", \"Strategic Patience\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"socialnews\", \"social news\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NASAHurricane\", \"NASA Hurricane\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"onlinecommunities\", \"online communities\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"humanconsumption\", \"human consumption\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Typhoon-Devastated\", \"Typhoon Devastated\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Meat-Loving\", \"Meat Loving\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"facialabuse\", \"facial abuse\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"LakeCounty\", \"Lake County\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BeingAuthor\", \"Being Author\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"withheavenly\", \"with heavenly\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"thankU\", \"thank you\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"iTunesMusic\", \"iTunes Music\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"OffensiveContent\", \"Offensive Content\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"WorstSummerJob\", \"Worst Summer Job\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"HarryBeCareful\", \"Harry Be Careful\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NASASolarSystem\", \"NASA Solar System\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"animalrescue\", \"animal rescue\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"KurtSchlichter\", \"Kurt Schlichter\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"aRmageddon\", \"armageddon\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Throwingknifes\", \"Throwing knives\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"GodsLove\", \"God's Love\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"bookboost\", \"book boost\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ibooklove\", \"I book love\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NestleIndia\", \"Nestle India\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"realDonaldTrump\", \"Donald Trump\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"DavidVonderhaar\", \"David Vonderhaar\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"CecilTheLion\", \"Cecil The Lion\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"weathernetwork\", \"weather network\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"withBioterrorism&use\", \"with Bioterrorism & use\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Hostage&2\", \"Hostage & 2\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"GOPDebate\", \"GOP Debate\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"RickPerry\", \"Rick Perry\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"frontpage\", \"front page\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NewsInTweets\", \"News In Tweets\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ViralSpell\", \"Viral Spell\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"til_now\", \"until now\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"volcanoinRussia\", \"volcano in Russia\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ZippedNews\", \"Zipped News\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MicheleBachman\", \"Michele Bachman\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"53inch\", \"53 inch\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"KerrickTrial\", \"Kerrick Trial\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"abstorm\", \"Alberta Storm\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Beyhive\", \"Beyonce hive\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"IDFire\", \"Idaho Fire\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"DETECTADO\", \"Detected\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"RockyFire\", \"Rocky Fire\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Listen/Buy\", \"Listen / Buy\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NickCannon\", \"Nick Cannon\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"FaroeIslands\", \"Faroe Islands\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"yycstorm\", \"Calgary Storm\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"IDPs:\", \"Internally Displaced People :\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ArtistsUnited\", \"Artists United\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ClaytonBryant\", \"Clayton Bryant\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"jimmyfallon\", \"jimmy fallon\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"justinbieber\", \"justin bieber\", text))  \n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"UTC2015\", \"UTC 2015\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Time2015\", \"Time 2015\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"djicemoon\", \"dj icemoon\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"LivingSafely\", \"Living Safely\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"FIFA16\", \"Fifa 2016\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"thisiswhywecanthavenicethings\", \"this is why we cannot have nice things\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"bbcnews\", \"bbc news\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"UndergroundRailraod\", \"Underground Railraod\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"c4news\", \"c4 news\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"OBLITERATION\", \"obliteration\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MUDSLIDE\", \"mudslide\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NoSurrender\", \"No Surrender\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NotExplained\", \"Not Explained\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"greatbritishbakeoff\", \"great british bake off\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"LondonFire\", \"London Fire\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"KOTAWeather\", \"KOTA Weather\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"LuchaUnderground\", \"Lucha Underground\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"KOIN6News\", \"KOIN 6 News\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"LiveOnK2\", \"Live On K2\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"9NewsGoldCoast\", \"9 News Gold Coast\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"nikeplus\", \"nike plus\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"david_cameron\", \"David Cameron\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"peterjukes\", \"Peter Jukes\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"JamesMelville\", \"James Melville\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"megynkelly\", \"Megyn Kelly\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"cnewslive\", \"C News Live\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"JamaicaObserver\", \"Jamaica Observer\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TweetLikeItsSeptember11th2001\", \"Tweet like it is september 11th 2001\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"cbplawyers\", \"cbp lawyers\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"fewmoretweets\", \"few more tweets\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BlackLivesMatter\", \"Black Lives Matter\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"cjoyner\", \"Chris Joyner\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ENGvAUS\", \"England vs Australia\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ScottWalker\", \"Scott Walker\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MikeParrActor\", \"Michael Parr\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"4PlayThursdays\", \"Foreplay Thursdays\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TGF2015\", \"Tontitown Grape Festival\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"realmandyrain\", \"Mandy Rain\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"GraysonDolan\", \"Grayson Dolan\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ApolloBrown\", \"Apollo Brown\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"saddlebrooke\", \"Saddlebrooke\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TontitownGrape\", \"Tontitown Grape\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"AbbsWinston\", \"Abbs Winston\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ShaunKing\", \"Shaun King\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MeekMill\", \"Meek Mill\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TornadoGiveaway\", \"Tornado Giveaway\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"GRupdates\", \"GR updates\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"SouthDowns\", \"South Downs\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"braininjury\", \"brain injury\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"auspol\", \"Australian politics\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"PlannedParenthood\", \"Planned Parenthood\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"calgaryweather\", \"Calgary Weather\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"weallheartonedirection\", \"we all heart one direction\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"edsheeran\", \"Ed Sheeran\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TrueHeroes\", \"True Heroes\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"S3XLEAK\", \"sex leak\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ComplexMag\", \"Complex Magazine\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TheAdvocateMag\", \"The Advocate Magazine\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"CityofCalgary\", \"City of Calgary\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"EbolaOutbreak\", \"Ebola Outbreak\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"SummerFate\", \"Summer Fate\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"RAmag\", \"Royal Academy Magazine\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"offers2go\", \"offers to go\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"foodscare\", \"food scare\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MNPDNashville\", \"Metropolitan Nashville Police Department\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TfLBusAlerts\", \"TfL Bus Alerts\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"GamerGate\", \"Gamer Gate\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"IHHen\", \"Humanitarian Relief\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"spinningbot\", \"spinning bot\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ModiMinistry\", \"Modi Ministry\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TAXIWAYS\", \"taxi ways\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Calum5SOS\", \"Calum Hood\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"po_st\", \"po.st\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"scoopit\", \"scoop.it\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"UltimaLucha\", \"Ultima Lucha\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"JonathanFerrell\", \"Jonathan Ferrell\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"aria_ahrary\", \"Aria Ahrary\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"rapidcity\", \"Rapid City\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"OutBid\", \"outbid\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"lavenderpoetrycafe\", \"lavender poetry cafe\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"EudryLantiqua\", \"Eudry Lantiqua\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"15PM\", \"15 PM\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"OriginalFunko\", \"Funko\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"rightwaystan\", \"Richard Tan\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"CindyNoonan\", \"Cindy Noonan\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"RT_America\", \"RT America\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"narendramodi\", \"Narendra Modi\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BakeOffFriends\", \"Bake Off Friends\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TeamHendrick\", \"Hendrick Motorsports\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"alexbelloli\", \"Alex Belloli\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"itsjustinstuart\", \"Justin Stuart\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"gunsense\", \"gun sense\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"DebateQuestionsWeWantToHear\", \"debate questions we want to hear\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"RoyalCarribean\", \"Royal Carribean\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"samanthaturne19\", \"Samantha Turner\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"JonVoyage\", \"Jon Stewart\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"renew911health\", \"renew 911 health\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"SuryaRay\", \"Surya Ray\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"pattonoswalt\", \"Patton Oswalt\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"minhazmerchant\", \"Minhaz Merchant\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TLVFaces\", \"Israel Diaspora Coalition\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"pmarca\", \"Marc Andreessen\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"pdx911\", \"Portland Police\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"jamaicaplain\", \"Jamaica Plain\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Japton\", \"Arkansas\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"RouteComplex\", \"Route Complex\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"INSubcontinent\", \"Indian Subcontinent\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NJTurnpike\", \"New Jersey Turnpike\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Politifiact\", \"PolitiFact\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Hiroshima70\", \"Hiroshima\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"GMMBC\", \"Greater Mt Moriah Baptist Church\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"versethe\", \"verse the\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TubeStrike\", \"Tube Strike\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MissionHills\", \"Mission Hills\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ProtectDenaliWolves\", \"Protect Denali Wolves\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NANKANA\", \"Nankana\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"SAHIB\", \"Sahib\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"PAKPATTAN\", \"Pakpattan\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Newz_Sacramento\", \"News Sacramento\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"gofundme\", \"go fund me\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"pmharper\", \"Stephen Harper\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"IvanBerroa\", \"Ivan Berroa\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"LosDelSonido\", \"Los Del Sonido\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"bancodeseries\", \"banco de series\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"timkaine\", \"Tim Kaine\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"IdentityTheft\", \"Identity Theft\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"AllLivesMatter\", \"All Lives Matter\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"mishacollins\", \"Misha Collins\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BillNeelyNBC\", \"Bill Neely\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BeClearOnCancer\", \"be clear on cancer\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Kowing\", \"Knowing\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ScreamQueens\", \"Scream Queens\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"AskCharley\", \"Ask Charley\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BlizzHeroes\", \"Heroes of the Storm\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BradleyBrad47\", \"Bradley Brad\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"HannaPH\", \"Typhoon Hanna\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"meinlcymbals\", \"MEINL Cymbals\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Ptbo\", \"Peterborough\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"cnnbrk\", \"CNN Breaking News\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"IndianNews\", \"Indian News\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"savebees\", \"save bees\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"GreenHarvard\", \"Green Harvard\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"StandwithPP\", \"Stand with planned parenthood\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"hermancranston\", \"Herman Cranston\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"WMUR9\", \"WMUR-TV\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"RockBottomRadFM\", \"Rock Bottom Radio\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ameenshaikh3\", \"Ameen Shaikh\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ProSyn\", \"Project Syndicate\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Daesh\", \"ISIS\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"s2g\", \"swear to god\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"listenlive\", \"listen live\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"CDCgov\", \"Centers for Disease Control and Prevention\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"FoxNew\", \"Fox News\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"CBSBigBrother\", \"Big Brother\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"JulieDiCaro\", \"Julie DiCaro\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"theadvocatemag\", \"The Advocate Magazine\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"RohnertParkDPS\", \"Rohnert Park Police Department\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"THISIZBWRIGHT\", \"Bonnie Wright\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Popularmmos\", \"Popular MMOs\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"WildHorses\", \"Wild Horses\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"FantasticFour\", \"Fantastic Four\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"HORNDALE\", \"Horndale\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"PINER\", \"Piner\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BathAndNorthEastSomerset\", \"Bath and North East Somerset\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"thatswhatfriendsarefor\", \"that is what friends are for\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"residualincome\", \"residual income\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"YahooNewsDigest\", \"Yahoo News Digest\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MalaysiaAirlines\", \"Malaysia Airlines\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"AmazonDeals\", \"Amazon Deals\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MissCharleyWebb\", \"Charley Webb\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"shoalstraffic\", \"shoals traffic\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"GeorgeFoster72\", \"George Foster\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"pop2015\", \"pop 2015\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"_PokemonCards_\", \"Pokemon Cards\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"DianneG\", \"Dianne Gallagher\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"KashmirConflict\", \"Kashmir Conflict\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BritishBakeOff\", \"British Bake Off\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"FreeKashmir\", \"Free Kashmir\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"mattmosley\", \"Matt Mosley\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BishopFred\", \"Bishop Fred\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"EndConflict\", \"End Conflict\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"EndOccupation\", \"End Occupation\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"UNHEALED\", \"unhealed\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"CharlesDagnall\", \"Charles Dagnall\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Latestnews\", \"Latest news\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"KindleCountdown\", \"Kindle Countdown\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NoMoreHandouts\", \"No More Handouts\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"datingtips\", \"dating tips\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"charlesadler\", \"Charles Adler\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"twia\", \"Texas Windstorm Insurance Association\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"txlege\", \"Texas Legislature\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"WindstormInsurer\", \"Windstorm Insurer\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Newss\", \"News\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"hempoil\", \"hemp oil\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"CommoditiesAre\", \"Commodities are\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"tubestrike\", \"tube strike\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"JoeNBC\", \"Joe Scarborough\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"LiteraryCakes\", \"Literary Cakes\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TI5\", \"The International 5\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"thehill\", \"the hill\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"3others\", \"3 others\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"stighefootball\", \"Sam Tighe\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"whatstheimportantvideo\", \"what is the important video\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ClaudioMeloni\", \"Claudio Meloni\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"DukeSkywalker\", \"Duke Skywalker\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"carsonmwr\", \"Fort Carson\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"offdishduty\", \"off dish duty\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"andword\", \"and word\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"rhodeisland\", \"Rhode Island\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"easternoregon\", \"Eastern Oregon\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"WAwildfire\", \"Washington Wildfire\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"fingerrockfire\", \"Finger Rock Fire\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"57am\", \"57 am\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"fingerrockfire\", \"Finger Rock Fire\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"JacobHoggard\", \"Jacob Hoggard\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"newnewnew\", \"new new new\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"under50\", \"under 50\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"getitbeforeitsgone\", \"get it before it is gone\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"freshoutofthebox\", \"fresh out of the box\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"amwriting\", \"am writing\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Bokoharm\", \"Boko Haram\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Nowlike\", \"Now like\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"seasonfrom\", \"season from\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"epicente\", \"epicenter\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"epicenterr\", \"epicenter\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"sicklife\", \"sick life\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"yycweather\", \"Calgary Weather\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"calgarysun\", \"Calgary Sun\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"approachng\", \"approaching\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"evng\", \"evening\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Sumthng\", \"something\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"EllenPompeo\", \"Ellen Pompeo\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"shondarhimes\", \"Shonda Rhimes\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ABCNetwork\", \"ABC Network\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"SushmaSwaraj\", \"Sushma Swaraj\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"pray4japan\", \"Pray for Japan\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"hope4japan\", \"Hope for Japan\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Illusionimagess\", \"Illusion images\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"SummerUnderTheStars\", \"Summer Under The Stars\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ShallWeDance\", \"Shall We Dance\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TCMParty\", \"TCM Party\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"marijuananews\", \"marijuana news\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"onbeingwithKristaTippett\", \"on being with Krista Tippett\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Beingtweets\", \"Being tweets\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"newauthors\", \"new authors\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"remedyyyy\", \"remedy\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"44PM\", \"44 PM\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"HeadlinesApp\", \"Headlines App\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"40PM\", \"40 PM\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"myswc\", \"Severe Weather Center\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ithats\", \"that is\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"icouldsitinthismomentforever\", \"I could sit in this moment forever\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"FatLoss\", \"Fat Loss\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"02PM\", \"02 PM\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MetroFmTalk\", \"Metro Fm Talk\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Bstrd\", \"bastard\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"bldy\", \"bloody\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MetrofmTalk\", \"Metro Fm Talk\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"terrorismturn\", \"terrorism turn\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BBCNewsAsia\", \"BBC News Asia\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BehindTheScenes\", \"Behind The Scenes\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"GeorgeTakei\", \"George Takei\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"WomensWeeklyMag\", \"Womens Weekly Magazine\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"SurvivorsGuidetoEarth\", \"Survivors Guide to Earth\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"incubusband\", \"incubus band\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Babypicturethis\", \"Baby picture this\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BombEffects\", \"Bomb Effects\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"win10\", \"Windows 10\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"idkidk\", \"I do not know I do not know\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TheWalkingDead\", \"The Walking Dead\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"amyschumer\", \"Amy Schumer\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"crewlist\", \"crew list\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Erdogans\", \"Erdogan\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BBCLive\", \"BBC Live\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TonyAbbottMHR\", \"Tony Abbott\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"paulmyerscough\", \"Paul Myerscough\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"georgegallagher\", \"George Gallagher\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"JimmieJohnson\", \"Jimmie Johnson\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"pctool\", \"pc tool\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"DoingHashtagsRight\", \"Doing Hashtags Right\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ThrowbackThursday\", \"Throwback Thursday\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"SnowBackSunday\", \"Snowback Sunday\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"LakeEffect\", \"Lake Effect\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"RTphotographyUK\", \"Richard Thomas Photography UK\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BigBang_CBS\", \"Big Bang CBS\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"writerslife\", \"writers life\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NaturalBirth\", \"Natural Birth\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"UnusualWords\", \"Unusual Words\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"wizkhalifa\", \"Wiz Khalifa\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"acreativedc\", \"a creative DC\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"vscodc\", \"vsco DC\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"VSCOcam\", \"vsco camera\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TheBEACHDC\", \"The beach DC\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"buildingmuseum\", \"building museum\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"WorldOil\", \"World Oil\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"redwedding\", \"red wedding\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"AmazingRaceCanada\", \"Amazing Race Canada\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"WakeUpAmerica\", \"Wake Up America\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"\\\\Allahuakbar\\\\\", \"Allahu Akbar\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"bleased\", \"blessed\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"nigeriantribune\", \"Nigerian Tribune\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"HIDEO_KOJIMA_EN\", \"Hideo Kojima\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"FusionFestival\", \"Fusion Festival\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"50Mixed\", \"50 Mixed\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NoAgenda\", \"No Agenda\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"WhiteGenocide\", \"White Genocide\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"dirtylying\", \"dirty lying\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"SyrianRefugees\", \"Syrian Refugees\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"changetheworld\", \"change the world\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Ebolacase\", \"Ebola case\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"mcgtech\", \"mcg technologies\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"withweapons\", \"with weapons\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"advancedwarfare\", \"advanced warfare\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"letsFootball\", \"let us Football\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"LateNiteMix\", \"late night mix\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"PhilCollinsFeed\", \"Phil Collins\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"RudyHavenstein\", \"Rudy Havenstein\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"22PM\", \"22 PM\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"54am\", \"54 AM\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"38am\", \"38 AM\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"OldFolkExplainStuff\", \"Old Folk Explain Stuff\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BlacklivesMatter\", \"Black Lives Matter\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"InsaneLimits\", \"Insane Limits\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"youcantsitwithus\", \"you cannot sit with us\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"2k15\", \"2015\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TheIran\", \"Iran\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"JimmyFallon\", \"Jimmy Fallon\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"AlbertBrooks\", \"Albert Brooks\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"defense_news\", \"defense news\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"nuclearrcSA\", \"Nuclear Risk Control Self Assessment\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Auspol\", \"Australia Politics\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NuclearPower\", \"Nuclear Power\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"WhiteTerrorism\", \"White Terrorism\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"truthfrequencyradio\", \"Truth Frequency Radio\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ErasureIsNotEquality\", \"Erasure is not equality\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ProBonoNews\", \"Pro Bono News\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"JakartaPost\", \"Jakarta Post\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"toopainful\", \"too painful\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"melindahaunton\", \"Melinda Haunton\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NoNukes\", \"No Nukes\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"curryspcworld\", \"Currys PC World\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ineedcake\", \"I need cake\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"blackforestgateau\", \"black forest gateau\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BBCOne\", \"BBC One\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"AlexxPage\", \"Alex Page\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"jonathanserrie\", \"Jonathan Serrie\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"SocialJerkBlog\", \"Social Jerk Blog\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ChelseaVPeretti\", \"Chelsea Peretti\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"irongiant\", \"iron giant\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"RonFunches\", \"Ron Funches\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TimCook\", \"Tim Cook\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"sebastianstanisaliveandwell\", \"Sebastian Stan is alive and well\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Madsummer\", \"Mad summer\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NowYouKnow\", \"Now you know\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"concertphotography\", \"concert photography\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TomLandry\", \"Tom Landry\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"showgirldayoff\", \"show girl day off\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Yougslavia\", \"Yugoslavia\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"QuantumDataInformatics\", \"Quantum Data Informatics\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"FromTheDesk\", \"From The Desk\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TheaterTrial\", \"Theater Trial\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"CatoInstitute\", \"Cato Institute\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"EmekaGift\", \"Emeka Gift\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"LetsBe_Rational\", \"Let us be rational\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Cynicalreality\", \"Cynical reality\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"FredOlsenCruise\", \"Fred Olsen Cruise\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NotSorry\", \"not sorry\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"UseYourWords\", \"use your words\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"WordoftheDay\", \"word of the day\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Dictionarycom\", \"Dictionary.com\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TheBrooklynLife\", \"The Brooklyn Life\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"jokethey\", \"joke they\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"nflweek1picks\", \"NFL week 1 picks\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"uiseful\", \"useful\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"JusticeDotOrg\", \"The American Association for Justice\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"autoaccidents\", \"auto accidents\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"SteveGursten\", \"Steve Gursten\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MichiganAutoLaw\", \"Michigan Auto Law\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"birdgang\", \"bird gang\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"nflnetwork\", \"NFL Network\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NYDNSports\", \"NY Daily News Sports\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"RVacchianoNYDN\", \"Ralph Vacchiano NY Daily News\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"EdmontonEsks\", \"Edmonton Eskimos\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"david_brelsford\", \"David Brelsford\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TOI_India\", \"The Times of India\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"hegot\", \"he got\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"SkinsOn9\", \"Skins on 9\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"sothathappened\", \"so that happened\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"LCOutOfDoors\", \"LC Out Of Doors\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NationFirst\", \"Nation First\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"IndiaToday\", \"India Today\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"HLPS\", \"helps\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"HOSTAGESTHROSW\", \"hostages throw\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"SNCTIONS\", \"sanctions\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BidTime\", \"Bid Time\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"crunchysensible\", \"crunchy sensible\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"RandomActsOfRomance\", \"Random acts of romance\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MomentsAtHill\", \"Moments at hill\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"eatshit\", \"eat shit\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"liveleakfun\", \"live leak fun\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"SahelNews\", \"Sahel News\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"abc7newsbayarea\", \"ABC 7 News Bay Area\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"facilitiesmanagement\", \"facilities management\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"facilitydude\", \"facility dude\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"CampLogistics\", \"Camp logistics\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"alaskapublic\", \"Alaska public\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MarketResearch\", \"Market Research\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"AccuracyEsports\", \"Accuracy Esports\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TheBodyShopAust\", \"The Body Shop Australia\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"yychail\", \"Calgary hail\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"yyctraffic\", \"Calgary traffic\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"eliotschool\", \"eliot school\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"TheBrokenCity\", \"The Broken City\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"OldsFireDept\", \"Olds Fire Department\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"RiverComplex\", \"River Complex\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"fieldworksmells\", \"field work smells\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"IranElection\", \"Iran Election\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"glowng\", \"glowing\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"kindlng\", \"kindling\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"riggd\", \"rigged\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"slownewsday\", \"slow news day\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MyanmarFlood\", \"Myanmar Flood\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"abc7chicago\", \"ABC 7 Chicago\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"copolitics\", \"Colorado Politics\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"AdilGhumro\", \"Adil Ghumro\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"netbots\", \"net bots\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"byebyeroad\", \"bye bye road\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"massiveflooding\", \"massive flooding\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"EndofUS\", \"End of United States\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"35PM\", \"35 PM\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"greektheatrela\", \"Greek Theatre Los Angeles\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"76mins\", \"76 minutes\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"publicsafetyfirst\", \"public safety first\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"livesmatter\", \"lives matter\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"myhometown\", \"my hometown\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"tankerfire\", \"tanker fire\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MEMORIALDAY\", \"memorial day\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MEMORIAL_DAY\", \"memorial day\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"instaxbooty\", \"instagram booty\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Jerusalem_Post\", \"Jerusalem Post\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"WayneRooney_INA\", \"Wayne Rooney\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"VirtualReality\", \"Virtual Reality\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"OculusRift\", \"Oculus Rift\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"OwenJones84\", \"Owen Jones\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"jeremycorbyn\", \"Jeremy Corbyn\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"paulrogers002\", \"Paul Rogers\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"mortalkombatx\", \"Mortal Kombat X\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"mortalkombat\", \"Mortal Kombat\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"FilipeCoelho92\", \"Filipe Coelho\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"OnlyQuakeNews\", \"Only Quake News\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"kostumes\", \"costumes\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"YEEESSSS\", \"yes\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ToshikazuKatayama\", \"Toshikazu Katayama\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"IntlDevelopment\", \"Intl Development\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ExtremeWeather\", \"Extreme Weather\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"WereNotGruberVoters\", \"We are not gruber voters\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NewsThousands\", \"News Thousands\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"EdmundAdamus\", \"Edmund Adamus\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"EyewitnessWV\", \"Eye witness WV\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"PhiladelphiaMuseu\", \"Philadelphia Museum\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"DublinComicCon\", \"Dublin Comic Con\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NicholasBrendon\", \"Nicholas Brendon\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Alltheway80s\", \"All the way 80s\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"FromTheField\", \"From the field\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NorthIowa\", \"North Iowa\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"WillowFire\", \"Willow Fire\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MadRiverComplex\", \"Mad River Complex\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"feelingmanly\", \"feeling manly\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"stillnotoverit\", \"still not over it\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"FortitudeValley\", \"Fortitude Valley\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"CoastpowerlineTramTr\", \"Coast powerline\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ServicesGold\", \"Services Gold\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NewsbrokenEmergency\", \"News broken emergency\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Evaucation\", \"evacuation\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"leaveevacuateexitbe\", \"leave evacuate exit be\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"P_EOPLE\", \"PEOPLE\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Tubestrike\", \"tube strike\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"CLASS_SICK\", \"CLASS SICK\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"localplumber\", \"local plumber\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"awesomejobsiri\", \"awesome job siri\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"PayForItHow\", \"Pay for it how\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ThisIsAfrica\", \"This is Africa\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"crimeairnetwork\", \"crime air network\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"KimAcheson\", \"Kim Acheson\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"cityofcalgary\", \"City of Calgary\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"prosyndicate\", \"pro syndicate\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"660NEWS\", \"660 NEWS\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"BusInsMagazine\", \"Business Insurance Magazine\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"wfocus\", \"focus\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"ShastaDam\", \"Shasta Dam\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"go2MarkFranco\", \"Mark Franco\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"StephGHinojosa\", \"Steph Hinojosa\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Nashgrier\", \"Nash Grier\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"NashNewVideo\", \"Nash new video\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"IWouldntGetElectedBecause\", \"I would not get elected because\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"SHGames\", \"Sledgehammer Games\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"bedhair\", \"bed hair\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"JoelHeyman\", \"Joel Heyman\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"viaYouTube\", \"via YouTube\", text))\n           \n    # Urls\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\", \"\", text))\n        \n\n          \n        \n    # Acronyms\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"MH370\", \"Malaysia Airlines Flight 370\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"mÌ¼sica\", \"music\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"okwx\", \"Oklahoma City Weather\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"arwx\", \"Arkansas Weather\", text))    \n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"gawx\", \"Georgia Weather\", text))  \n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"scwx\", \"South Carolina Weather\", text))  \n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"cawx\", \"California Weather\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"tnwx\", \"Tennessee Weather\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"azwx\", \"Arizona Weather\", text))  \n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"alwx\", \"Alabama Weather\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"wordpressdotcom\", \"wordpress\", text))    \n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"usNWSgov\", \"United States National Weather Service\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Suruc\", \"Sanliurfa\", text))   \n    # Grouping same words without embeddings\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"Bestnaijamade\", \"bestnaijamade\", text))\n    df[new_text_field_name] = df[new_text_field_name].apply(lambda text:re.sub(r\"SOUDELOR\", \"Soudelor\", text))\n    \n    return df\ndata_clean = clean_text(train_data, 'text', 'text_clean')\ndata_clean_test = clean_text(test_data,'text', 'text_clean')\ndata_clean","execution_count":null,"outputs":[]},{"metadata":{"id":"VBhsZy743R_-"},"cell_type":"markdown","source":"# Model\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; เก็บ feature text จาก data_clean ไว้ในตัวแปรชื่อ traindata เก็บ feature text จาก data_clean_test ไว้ใน ตัวแปรชื่อ testdata เก็บ feature target จาก data_clean ไว้ในตัวแปรชื่อ y จากนั้นนำ traindata มารวมกับ testdata เป็นตัวแปร X_all เพื่อนำไปทำ tdidf ต่อไป โดยที่นำมารวมกันก่อนเพื่อป้องกันปัญหาเรื่อง shape ของ train และ test ไม่เท่ากัน จากนั้นประกาศตัวแปร lentrain เพื่อนับจำนวนแถวของ data_clean ซึ่งก็คือจำนวน traindata เพื่อใช้เป็นตัวอ้างอิงในการแบ่งข้อมูลในภายหลัง\n\n\n\n"},{"metadata":{"id":"n0KgREpyLU0Q","outputId":"8a5aa319-1df6-4bdc-c0fe-53610cb908ca","trusted":true},"cell_type":"code","source":"traindata = list(np.array(data_clean.iloc[:,5])) #Extracting the text feature alone from the train data\ntestdata = list(np.array(data_clean_test.iloc[:,4]))#Extracting the text feature alone from the test data\ny = np.array(data_clean.iloc[:,4]).astype(int)#Extracting the target varaible from the train data\n\nX_all = traindata + testdata #combining both the test and train data\nlentrain = len(data_clean)\nprint('for Check!')\nprint(traindata[:1])\nprint(y)\nprint('count train data:' ,lentrain)\nprint(len(X_all))","execution_count":null,"outputs":[]},{"metadata":{"id":"mJsG9Oe6PeIN","outputId":"006e9fdb-a61f-4a10-ba61-3adc0e2bb6a1","trusted":true},"cell_type":"code","source":"data_clean_test","execution_count":null,"outputs":[]},{"metadata":{"id":"u0zO-qRQ4r2F"},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ทำ tfidf โดยประกาศ object ชื่อ tfidf โดยมีคุณสมบัติเป็น TfidfVectorizer จากนั้น นำ X_all ไป fit ใน tfidf และ transform เพื่อเตรียมนำไปทำ model โดยเก็บค่าไว้ในชื่อตัวแปร X_all"},{"metadata":{"id":"MaH3JjSYMbwO","outputId":"5db201e6-e277-4a64-99ca-4eb9e0595ad9","trusted":true},"cell_type":"code","source":"# Implementing TFIDF to extract the features from the text\ntfidf = TfidfVectorizer(min_df=3,  max_features=None, strip_accents='unicode',  \n        analyzer='word',token_pattern=r'\\w{1,}',ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1)\n\nprint(\"Implementing TFIDF to both the test and train data\")\ntfidf.fit(X_all)\nprint(\"Transforming the data\")\nX_all = tfidf.transform(X_all)","execution_count":null,"outputs":[]},{"metadata":{"id":"C3N8fLcjMzpE","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"id":"yYfpoVsm8Q2U"},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; นำตัวแปร X_all มาแบ่งโดยการ slicing เพื่อแยกข้อมูลที่จะนำมาทำโมเดลและข้อมูลที่จะนำไปประยุกต์ใช้โมเดลต่อไป โดยข้อมูลที่จะนำมาทำโมเดลชื่อ X และข้อมูลที่จะนำไปประยุกต์ใช้ model ชื่อ X_test_data นำ X และ y มาแบ่งเป็นข้อมูลสำหรับ test และ train model ผ่าน sklearn.model_selection.train_test_split โดยแบ่งเป็นข้อมูลสำหรับทำโมเดล 80% และข้อมูลทดสอบ 20% จากนั้นประกาศตัวแปร log ซึ่งมีคุณสมบัติเป็น logistic regression model และนำข้อมูลสำหรับการทดสอบใส่เข้าไปในโมเดลเก็บไว้ในตัวแปรชื่อ y_pred_X นำไปตรวจสอบ accuracy_score  โดยเทียบระหว่าง y_test และ y_pred_X จากนั้นนำโมเดลที่ได้มาทำนายข้อมูลที่ต้องการ โดยเก็บผลลัพธ์ไว้ในตัวแปรชื่อ prediction"},{"metadata":{"id":"Ho4A2TWBMmEw","outputId":"64b8b259-d140-486a-a04e-3aa6e4fedf2b","trusted":true},"cell_type":"code","source":"\nX = X_all[:lentrain] # Seperating the train data from the entire data\nX_test_data = X_all[lentrain:] # Seperating the test data from the entire data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    stratify=y, \n                                                    test_size=0.2)\nlog = LogisticRegression(penalty='l2',dual=False, tol=0.0001, \n                             C=0.5, fit_intercept=True, intercept_scaling=1.0, \n                             class_weight=None, random_state=None) #initialising the logistic regression function with the respective parameters\n\nprint(\"Training on the train data\")\nlog.fit(X_train,y_train)\n\n#Evaluating with the train data's target variable to obatin the training accuracy!\ny_pred_X=log.predict(X_test)\nprint('Training accuracy is {}'.format(accuracy_score(y_test, y_pred_X)))\n\npredictions = log.predict(X_test_data) #Prediciting the target for the test data\n","execution_count":null,"outputs":[]},{"metadata":{"id":"vQ4OuOBx9gP8"},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ดู classification report"},{"metadata":{"id":"SarLzTThZj5h","outputId":"cc071c23-18e8-4c11-aa85-a36a875665fc","trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred_X))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  model มีค่า accuracy โดยรวมเป็นที่น่าพึงพอใจ แต่ model ได้ทำการ predict ค่า target ที่เป็น 0 ได้แม่นยำกว่าค่า target ที่เป็น 1"},{"metadata":{"id":"YIdVX96p9_o7"},"cell_type":"markdown","source":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; สร้างไฟล์ CSV ที่จะส่งโดยเก็บ id ของ test_data ไว้ในตัวแปรชื่อ test_ids จากนั้นสร้าง DataFrame ชื่อ submission โดยมี index เป็น test_ids และ column เป็น target โดยมีค่าใน column เป็น predictions จากนั้นแปลง file เป็น file csv เป็นอันเสร็จสิ้นการทำโปรเจ็ค"},{"metadata":{"id":"sOB_IeZO0wFN","outputId":"c1489ac1-00fd-4e98-d818-1fc4587df09c","trusted":true},"cell_type":"code","source":"test_ids=test_data['id']\nsubmission = pd.DataFrame(predictions,index=test_ids,columns=['target'])\nsubmission.to_csv('submission.csv')\nprint(\"submission file created..\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}