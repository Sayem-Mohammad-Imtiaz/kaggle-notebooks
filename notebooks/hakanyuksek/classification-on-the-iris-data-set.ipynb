{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Introduction**"},{"metadata":{},"cell_type":"markdown","source":"Hi everyone, in this kernel, we'll use artificial neural network on the iris data set to classify them. The purpose of this study is practising of the artificial neural network to improve myself."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import to_categorical\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's start with the reading the data from IRIS.csv file"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/iris-flower-dataset/IRIS.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before the applying deep learning algorithm to our data, we should see our data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can say that there are 150 sample in our iris data set and we have four features becaues species columns is our class label. We can see that there is not missing value in the data. It's good for us because we don't need to be busy with missing values.  "},{"metadata":{},"cell_type":"markdown","source":"Let's look at the distribution of the class in the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ncolor = {'Iris-setosa': \"r\", 'Iris-versicolor': \"g\", 'Iris-virginica': \"b\"}\ncounts = []\nkinds = []\n\nfor key in color.keys():\n    counts.append(len(data[data[\"species\"]==key].values))\n    kinds.append(key)\ndf = pd.DataFrame({\"Columns of Data Set\":kinds,\"# of Samples\":counts})\nnewIndex = (df[\"# of Samples\"].sort_values(ascending = False)).index.values\nsortedData = df.reindex(newIndex)\n\nplt.figure(figsize = (10,5))\nax = sns.barplot(x = sortedData[\"Columns of Data Set\"],y = sortedData[\"# of Samples\"])\nplt.xticks(rotation = 0)\nplt.ylabel(\"# of Samples\")\nplt.title(\"Distribution of the Data according to class label\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to the bar graph, we can say that our data is dispersed to the three class by equally. It means if we use random function for classification, we would probably obtain 33 % success. Our goal is the increase the success of the classification. To accomplish it, we are gonna use the artificial neural network. But firstly, we have to preprocess the data for the classification algorithm."},{"metadata":{},"cell_type":"markdown","source":"# **Preprocessing**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that their values is not normalized. We should normalize them to use in algorithm. We are gonna normalize between 0 and 1 by using MinMax normalization.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = data[\"species\"]\ndata.drop([\"species\"],axis=1,inplace=True)\ncolumns = data.columns\n\nfor col in columns:\n    min = np.array(data[col].values).min()\n    max = np.array(data[col].values).max()\n    values = []\n    for each in data[col]:\n        each = (each - min) / (max-min)        \n        values.append(each)\n    data[col] = values\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Okay after the normalization, we can encode the class labels."},{"metadata":{"trusted":true},"cell_type":"code","source":"dict = {}\n\nfor each in labels:\n    dict[each] = 1\n    \nclasses = dict.keys()\n\ni = 0\nfor each in classes:\n    dict[each] = i\n    i += 1\ndict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(labels)):\n    labels[i] = dict[labels[i]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Classification**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the keras model\nmodel = Sequential()\nmodel.add(Dense(8, input_dim=4, activation='relu'))\nmodel.add(Dense(3, activation='softmax'))\n# Compile model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nX = data.drop([\"species\"],axis = 1,inplace = False)\nY = labels\nencoder = LabelEncoder()\nencoder.fit(Y)\nencoded_Y = encoder.transform(Y)\n# convert integers to dummy variables (i.e. one hot encoded)\ndummy_y = np_utils.to_categorical(encoded_Y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size=0.33, random_state=42)\n\nhistory = model.fit(X_train, y_train,validation_split=0.33,epochs=150, batch_size=10)\n# evaluate the keras model\nloss, accuracy = model.evaluate(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Performance Results**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize history for accuracy\nplt.figure(figsize=(10,5))\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\nprint('Accuracy: %.2f' % (accuracy*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize history for loss\nplt.figure(figsize=(10,5))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\nprint('Loss: %.2f' % (loss*100))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}