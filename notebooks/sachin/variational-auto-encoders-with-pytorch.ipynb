{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pathlib import Path\nfrom typing import Any, List, Tuple\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pytorch_lightning as pl\nfrom pytorch_lightning.loggers import WandbLogger\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import io, transforms, models\nimport torchvision.transforms.functional as TF\n\n# Wandb login:\nfrom kaggle_secrets import UserSecretsClient\nimport wandb\nuser_secrets = UserSecretsClient()\nsecret_value = user_secrets.get_secret(\"wandb_api_key\")\nwandb.login(key=secret_value)\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-06T01:02:04.557717Z","iopub.execute_input":"2021-09-06T01:02:04.558057Z","iopub.status.idle":"2021-09-06T01:02:04.823483Z","shell.execute_reply.started":"2021-09-06T01:02:04.558025Z","shell.execute_reply":"2021-09-06T01:02:04.82267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FILES = \"/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba/\"\n# TRAIN_FILES = \"/kaggle/input/coco-2017-dataset/coco2017/train2017/\"\n# VALID_FILES = \"/kaggle/input/coco-2017-dataset/coco2017/val2017/\"\nIMAGE_SIZE = 64\nBATCH_SIZE = 64\nEPOCHS = 10\nLR = 1e-3\nCHANNELS = 3\nVALID_IMAGES = 5","metadata":{"execution":{"iopub.status.busy":"2021-09-06T00:48:11.990823Z","iopub.execute_input":"2021-09-06T00:48:11.991165Z","iopub.status.idle":"2021-09-06T00:48:11.997808Z","shell.execute_reply.started":"2021-09-06T00:48:11.991133Z","shell.execute_reply":"2021-09-06T00:48:11.996836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageData(Dataset):\n    def __init__(self, files: List[str]):\n        self.files = files\n        self.resize = transforms.Resize((IMAGE_SIZE, IMAGE_SIZE))\n        \n    def __len__(self):\n        return len(self.files)\n    \n    def __getitem__(self, i):\n        img = io.read_image(self.files[i])\n        img = self.resize(img)\n        \n        if img.shape[0] == 1:\n            img = torch.cat([img]*3)\n\n        return img / 255.0 - 0.5\n\nfiles = [str(file) for file in Path(FILES).glob(\"*.jpg\")]\ntrain_files, valid_files = train_test_split(files, test_size=0.1)\n# train_files = [str(file) for file in Path(TRAIN_FILES).glob(\"*.jpg\")]\n# valid_files = [str(file) for file in Path(VALID_FILES).glob(\"*.jpg\")]\ntrain_ds = ImageData(train_files)\nvalid_ds = ImageData(valid_files)\ntrain_dl = DataLoader(\n    train_ds, \n    BATCH_SIZE, \n    shuffle=True, \n    drop_last=True, \n    num_workers=4,\n    pin_memory=True,\n)\nvalid_dl = DataLoader(\n    valid_ds, \n    BATCH_SIZE*2, \n    shuffle=False, \n    drop_last=False, \n    num_workers=4,\n    pin_memory=True,\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T00:48:14.801024Z","iopub.execute_input":"2021-09-06T00:48:14.801401Z","iopub.status.idle":"2021-09-06T00:48:15.903514Z","shell.execute_reply.started":"2021-09-06T00:48:14.801363Z","shell.execute_reply":"2021-09-06T00:48:15.9026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = next(iter(train_dl))\nlen(train_ds), len(valid_ds), x.shape, x.mean(), x.std()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T00:48:16.774987Z","iopub.execute_input":"2021-09-06T00:48:16.77541Z","iopub.status.idle":"2021-09-06T00:48:19.966551Z","shell.execute_reply.started":"2021-09-06T00:48:16.775373Z","shell.execute_reply":"2021-09-06T00:48:19.965464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class DownSample(nn.Module):\n    def __init__(self, in_channels, out_channels, scale_factor=2):\n        super().__init__()\n        self.conv2d_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n        self.conv2d_2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=2)\n        self.batch_norm = nn.BatchNorm2d(out_channels)\n        \n    def forward(self, x):\n        x = F.gelu(self.conv2d_1(x))\n        x = F.gelu(self.conv2d_2(x))\n        \n        return self.batch_norm(x)\n\nclass Encoder(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.downsampler = nn.ModuleList(\n            [DownSample(c_in, c_out) for c_in, c_out in zip(channels[:-1], channels[1:])]\n        )\n        self.squeeze_wh_1 = nn.Conv2d(channels[-1], channels[-1], kernel_size=2)\n        self.squeeze_wh_2 = nn.Conv2d(channels[-1], channels[-1], kernel_size=2)\n                \n    def forward(self, x):\n        for downsample in self.downsampler:\n            x = downsample(x)\n        \n        mu = self.squeeze_wh_1(x)\n        log_var = self.squeeze_wh_2(x)\n        return mu, log_var","metadata":{"execution":{"iopub.status.busy":"2021-09-06T00:48:32.66763Z","iopub.execute_input":"2021-09-06T00:48:32.667999Z","iopub.status.idle":"2021-09-06T00:48:32.678344Z","shell.execute_reply.started":"2021-09-06T00:48:32.667961Z","shell.execute_reply":"2021-09-06T00:48:32.677451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UpSample(nn.Module):\n    def __init__(self, in_channels, out_channels, scale_factor=2):\n        super().__init__()\n        self.up_sample = nn.Upsample(scale_factor=scale_factor)\n        self.conv2d_1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n        self.conv2d_2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n        self.batch_norm = nn.BatchNorm2d(out_channels)\n        \n    def forward(self, x):\n        out = self.up_sample(x)\n        out = F.gelu(self.conv2d_1(out))\n        out = F.gelu(self.conv2d_2(out))\n        \n        return self.batch_norm(out)\n    \nclass Decoder(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.upsampler = nn.ModuleList(\n            [UpSample(c_in, c_out) for c_in, c_out in zip(channels[:-1], channels[1:])]\n        )\n        self.conv_1 = nn.Conv2d(channels[-1], CHANNELS, kernel_size=1)\n        self.conv_2 = nn.Conv2d(CHANNELS, CHANNELS, kernel_size=1)\n        \n    def forward(self, z):\n        for upsample in self.upsampler:\n            z = upsample(z)\n            \n        z = F.leaky_relu(self.conv_1(z))\n        return torch.sigmoid(self.conv_2(z)) - 0.5","metadata":{"execution":{"iopub.status.busy":"2021-09-06T00:50:51.909114Z","iopub.execute_input":"2021-09-06T00:50:51.909521Z","iopub.status.idle":"2021-09-06T00:50:51.920526Z","shell.execute_reply.started":"2021-09-06T00:50:51.909486Z","shell.execute_reply":"2021-09-06T00:50:51.919417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## KL Divergence\nSee this [stack exchange](https://stats.stackexchange.com/questions/318184/kl-loss-with-a-unit-gaussian) question for definition of KL divergence:","metadata":{}},{"cell_type":"code","source":"def kl_divergence(mu: torch.FloatTensor, log_var: torch.FloatTensor) -> torch.FloatTensor:\n    kl_divergence_per_instance = -0.5 * (1 + log_var - torch.square(mu) - torch.exp(log_var))\n    return kl_divergence_per_instance.mean()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T00:51:02.927758Z","iopub.execute_input":"2021-09-06T00:51:02.928097Z","iopub.status.idle":"2021-09-06T00:51:02.935269Z","shell.execute_reply.started":"2021-09-06T00:51:02.928065Z","shell.execute_reply":"2021-09-06T00:51:02.934358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lightning Trainer","metadata":{}},{"cell_type":"code","source":"def inv_transform(image: torch.FloatTensor):\n    return (image + 0.5)\n\ndef get_wandb_images(image: torch.FloatTensor, reconstruction: torch.FloatTensor):\n    return [\n        wandb.Image(TF.to_pil_image(inv_transform(image))),\n        wandb.Image(TF.to_pil_image(inv_transform(reconstruction))),\n    ]","metadata":{"execution":{"iopub.status.busy":"2021-09-06T00:51:06.82569Z","iopub.execute_input":"2021-09-06T00:51:06.826121Z","iopub.status.idle":"2021-09-06T00:51:06.831622Z","shell.execute_reply.started":"2021-09-06T00:51:06.826086Z","shell.execute_reply":"2021-09-06T00:51:06.830692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LightningModel(pl.LightningModule):\n    def __init__(\n        self,\n        encoder: nn.Module,\n        decoder: nn.Module,\n        learning_rate: float,\n    ):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.learning_rate = learning_rate\n\n    def common_step(\n        self,\n        x: torch.FloatTensor,\n    ) -> torch.FloatTensor:\n        mu, log_var = self.encoder(x)\n        z = mu + torch.exp(0.5 * log_var) * torch.randn(mu.shape).to(mu.device)\n        out = self.decoder(z)\n        \n        kl_loss = kl_divergence(mu, log_var)\n        reconstruction_loss = F.mse_loss(x, out)\n        loss = kl_loss + reconstruction_loss\n        \n        return loss, reconstruction_loss, out\n\n    def training_step(\n        self, x: torch.FloatTensor, *args: List[Any]\n    ) -> torch.Tensor:\n        loss, reconstruction_loss, reconstruction = self.common_step(x)\n        self.log(name=\"Training loss\", value=loss, on_step=True, on_epoch=True)\n        self.log(name=\"Training reconstruction loss\", value=reconstruction_loss, on_step=True, on_epoch=True)\n        return loss\n    \n    def validation_step(\n        self, x: torch.FloatTensor, *args: List[Any]\n    ) -> None:\n        loss, reconstruction_loss, reconstruction = self.common_step(x)\n        self.log(name=\"Validation loss\", value=loss, on_step=True, on_epoch=True)\n        self.log(name=\"Validation reconstruction loss\", value=reconstruction_loss, on_step=True, on_epoch=True)\n        return x.cpu(), reconstruction.cpu()\n        \n    def validation_epoch_end(self, validation_step_outputs):\n        images, preds = zip(*validation_step_outputs)\n        images = torch.cat(images, dim=0)\n        preds = torch.cat(preds, dim=0)\n        columns = [\"image\", \"reconstruction\"]\n        indices = np.random.choice(len(images), VALID_IMAGES, replace=False)\n        rows = [get_wandb_images(images[i], preds[i]) for i in indices]\n        table = wandb.Table(data=rows, columns=columns)\n        self.logger.experiment.log({f\"epoch {self.current_epoch + 1} results\": table})\n        \n    def on_after_backward(self):\n        if self.trainer.global_step % 50 == 0:  # don't make the tf file huge\n            with torch.no_grad():\n                for name, param in self.named_parameters():\n                    if \"weight\" in name and not \"norm\" in name and param.requires_grad:\n                        self.logger.experiment.log({f\"{name}\": wandb.Histogram(param.cpu())})\n                        self.logger.experiment.log({f\"{name}_grad\": wandb.Histogram(param.grad.cpu())})\n                        \n    def configure_optimizers(self) -> torch.optim.Optimizer:\n        return torch.optim.AdamW(self.parameters(), lr=self.learning_rate)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T00:51:08.913665Z","iopub.execute_input":"2021-09-06T00:51:08.914147Z","iopub.status.idle":"2021-09-06T00:51:08.931333Z","shell.execute_reply.started":"2021-09-06T00:51:08.914107Z","shell.execute_reply":"2021-09-06T00:51:08.930222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/working/logs\nencoder = Encoder([3, 4, 8, 16, 32, 64])\ndecoder = Decoder([64, 32, 16, 8, 4, 4, 4])\nlightning_model = LightningModel(encoder, decoder, LR)\nlogger = WandbLogger(\"VAE 2\", \"/kaggle/working/logs/\", project=\"VAE\")\ntrainer = pl.Trainer(\n    max_epochs=EPOCHS,\n    gpus=torch.cuda.device_count(),\n    gradient_clip_val=1.0,\n    logger=logger,\n    precision=16,\n#     auto_lr_find=True,\n#     limit_train_batches=10,\n#     limit_val_batches=10,\n)\ntrainer.fit(lightning_model, train_dl, valid_dl)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T00:51:14.432995Z","iopub.execute_input":"2021-09-06T00:51:14.433355Z","iopub.status.idle":"2021-09-06T00:58:54.780885Z","shell.execute_reply.started":"2021-09-06T00:51:14.43332Z","shell.execute_reply":"2021-09-06T00:58:54.780042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mu, log_var = encoder(x)\nz = mu + torch.exp(0.5*log_var) * torch.randn(mu.shape)\nout = decoder(z)\n\nout.shape, out.mean(), out.std(), out.min(), out.max(), x.min(), x.max()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T00:59:06.685442Z","iopub.execute_input":"2021-09-06T00:59:06.685764Z","iopub.status.idle":"2021-09-06T00:59:06.703612Z","shell.execute_reply.started":"2021-09-06T00:59:06.685733Z","shell.execute_reply":"2021-09-06T00:59:06.702836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 16\nprint(out[i].std(), x[i].std())\nimg1 = TF.to_pil_image(x[i] + 0.5)\nimg2 = TF.to_pil_image(out[i] + 0.5)\nplt.figure(figsize=(12, 5))\nplt.subplot(121)\nplt.imshow(img1)\nplt.subplot(122)\nplt.imshow(img2)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T01:06:51.54933Z","iopub.execute_input":"2021-09-06T01:06:51.549779Z","iopub.status.idle":"2021-09-06T01:06:51.961298Z","shell.execute_reply.started":"2021-09-06T01:06:51.54973Z","shell.execute_reply":"2021-09-06T01:06:51.960486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ","metadata":{}}]}