{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Thank you for opening this notebook!!"},{"metadata":{},"cell_type":"markdown","source":"### In this kernel we will try to predict the price of cars. "},{"metadata":{},"cell_type":"markdown","source":"### Let's begin!"},{"metadata":{},"cell_type":"markdown","source":"### Problem Statement\nA Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts.\n\nThey have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:\n\nWhich variables are significant in predicting the price of a car\nHow well those variables describe the price of a car\nBased on various market surveys, the consulting firm has gathered a large data set of different types of cars across the America market.\n\n### Business Goal\nWe are required to model the price of cars with the available independent variables. It will be used by the management to understand how exactly the prices vary with the independent variables. They can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels. Further, the model will be a good way for management to understand the pricing dynamics of a new market.\n"},{"metadata":{},"cell_type":"markdown","source":"## 1. Import libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.style\nimport matplotlib as mpl\nmpl.style.use('ggplot')\nsns.set_style('whitegrid')\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.base import TransformerMixin\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import metrics\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Check out the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/car-price-prediction/CarPrice_Assignment.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'm going to drop car_ID column from the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('car_ID', axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First we will look at the distribution of the price which is our dependent variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(df['price'] , bins = 20 ,color = 'blue')\nplt.xlabel('price')\nplt.ylabel('no. of cars')\nplt.title('Histogram')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to distribution pf price mean price is around 13276.71. Minimum price of a car is 5118 while maximum price is 45400."},{"metadata":{},"cell_type":"markdown","source":"## 3. Cleaning of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['CarName'] = df['CarName'].str.split(' ',expand=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['CarName'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are typing mistakes in Car company names. Let's rename them."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf['CarName'] = df['CarName'].replace({'maxda': 'mazda', 'nissan': 'Nissan', 'porcshce': 'porsche', 'toyouta': 'toyota', \n                            'vokswagen': 'volkswagen', 'vw': 'volkswagen'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's change the datatype of symboling as it is categorical variable as per dictionary file"},{"metadata":{"trusted":true},"cell_type":"code","source":" df['symboling'] = df['symboling'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check for the duplicates."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df.duplicated()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are good to go! We don't have any duplicate rows."},{"metadata":{},"cell_type":"markdown","source":"## 4. Visualization of data"},{"metadata":{},"cell_type":"markdown","source":"First we'll seperate numerical and categorical variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical = df.select_dtypes(include=['object']).columns\nnumerical = df.select_dtypes(exclude=['object']).columns\ndf_categorical = df[categorical]\ndf_numerical = df[numerical]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_numerical.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next I'm going to check the correlation of price with other variables. Then I'll use the variables with highest correlation to fit our multiple regression model."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()['price'].sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* carlength           0.682920\n* carwidth            0.759325\n* horsepower          0.808139\n* curbweight          0.835305\n* enginesize          0.874145\n* highwaympg         -0.697599\n* citympg            -0.685751\n* carwidth , carlength, curbweight ,enginesize ,horsepower seems to have a poitive correlation with price.\n* citympg , highwaympg seem to have a significant negative correlation with price."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_categorical.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's draw boxplots for all the categorical variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 15))\nplt.subplot(3,3,1)\nsns.boxplot(x = 'doornumber', y = 'price', data = df)\nplt.subplot(3,3,2)\nsns.boxplot(x = 'fueltype', y = 'price', data = df)\nplt.subplot(3,3,3)\nsns.boxplot(x = 'aspiration', y = 'price', data = df)\nplt.subplot(3,3,4)\nsns.boxplot(x = 'carbody', y = 'price', data = df)\nplt.subplot(3,3,5)\nsns.boxplot(x = 'enginelocation', y = 'price', data = df)\nplt.subplot(3,3,6)\nsns.boxplot(x = 'drivewheel', y = 'price', data = df)\nplt.subplot(3,3,7)\nsns.boxplot(x = 'enginetype', y = 'price', data = df)\nplt.subplot(3,3,8)\nsns.boxplot(x = 'cylindernumber', y = 'price', data = df)\nplt.subplot(3,3,9)\nsns.boxplot(x = 'fuelsystem', y = 'price', data = df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The cars with fueltype as diesel are comparatively expensive than the cars with fueltype as gas.\n* The cars with engine location as rear in very expensive than cars with front engine location.\n* The cars with ohcv enginetype seems to be expensive and have a higher range of prices.\n* The price of the car vary with the no. of cylinders.\n* Expensive cars seem to have rwd drivewheel.\n* No. of doors do not influence the price of the car.\n"},{"metadata":{},"cell_type":"markdown","source":"So from both of the analysis of numerical and categorical variables I decided to use the below varibales to fit the multiple linear regression model.\n* price , carwidth , carlength, curbweight ,enginesize ,horsepower ,citympg , highwaympg , CarName , fueltype , enginelocation , enginetype , cylindernumber , drivewheel"},{"metadata":{},"cell_type":"markdown","source":"## 5. Data Preparation"},{"metadata":{},"cell_type":"markdown","source":"First I'm going to drop the variables which are not going to be used for the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_variables = ['symboling' , 'aspiration' ,'doornumber' ,'carbody' ,'fuelsystem' , 'wheelbase' , 'carheight' ,'boreratio' ,'stroke' , 'compressionratio' , 'peakrpm'  ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop( drop_variables , axis = 1, inplace = True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat = [ 'CarName' , 'fueltype' , 'enginelocation' , 'enginetype' , 'cylindernumber' , 'drivewheel' ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First we need to convert the levels of the categorical variables to numeric values. For this we have to use dummy variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_variables = pd.get_dummies(df[cat])\ndummy_variables.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_variables = pd.get_dummies(df[cat], drop_first = True)\ndummy_variables.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then we will add the dummy variables to the original dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df, dummy_variables], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have the dummy variables created for the categirical variables. We can drop the original cateorical variables from the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop( cat, axis = 1, inplace = True)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Multiple linear regression model"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(0)\ntrain, test = train_test_split(df, train_size = 0.7, test_size = 0.3, random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num = ['carlength','carwidth','curbweight','enginesize','horsepower','citympg','highwaympg','price']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's apply standardization except to dummy variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\ntrain[num] = sc.fit_transform(train[num])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20, 20))\nsns.heatmap(train.corr(), cmap=\"Blues\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train.pop('price')\nX_train = train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_1 =model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.coef_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets use RFE to select the independent variables which accurately predict the dependent variable price.\n\n## RFE - Recursive feature elimination \nLet's use Recursive feature elimination since we have too many independent variables."},{"metadata":{},"cell_type":"markdown","source":"Running RFE with the output number of the variable equals to 15."},{"metadata":{"trusted":true},"cell_type":"code","source":"lm = LinearRegression()\nlm.fit(X_train, y_train)\n\nrfe = RFE(lm, 15)             \nrfe = rfe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting the variables which are in support\n\ncol_sup = X_train.columns[rfe.support_]\ncol_sup","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating X_train dataframe with RFE selected variables\n\nX_train_rfe = X_train[col_sup]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding a constant variable and Build a first fitted model\nimport statsmodels.api as sm  \nX_train_rfec = sm.add_constant(X_train_rfe)\nlm_rfe = sm.OLS(y_train,X_train_rfec).fit()\n\n#Summary of linear model\nprint(lm_rfe.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Dropping enginetype_rotor beacuse its p-value is 0.264 and we want p-value less than 0.05."},{"metadata":{},"cell_type":"markdown","source":"Let's rebuild the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe1 = X_train_rfe.drop('enginetype_rotor', 1,)\n\n# Adding a constant variable and Build a second fitted model\n\nX_train_rfe1c = sm.add_constant(X_train_rfe1)\nlm_rfe1 = sm.OLS(y_train, X_train_rfe1c).fit()\n\n#Summary of linear model\nprint(lm_rfe1.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Dropping enginelocation_rear beacuse its p-value is 0.154 and we want p-value less than 0.05."},{"metadata":{},"cell_type":"markdown","source":"Let's rebuild the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping highly correlated variables and insignificant variables\n\nX_train_rfe2 = X_train_rfe1.drop('enginelocation_rear', 1,)\n\n# Adding a constant variable and Build a third fitted model\n\nX_train_rfe2c = sm.add_constant(X_train_rfe2)\nlm_rfe2 = sm.OLS(y_train, X_train_rfe2c).fit()\n\n#Summary of linear model\nprint(lm_rfe2.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train_rfe2.columns\nvif['VIF'] = [variance_inflation_factor(X_train_rfe2.values, i) for i in range(X_train_rfe2.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We generally want a VIF that is less than 5. So let's drop some variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping highly correlated variables and insignificant variables\n\nX_train_rfe3 = X_train_rfe2.drop('fueltype_gas', 1,)\n\n# Adding a constant variable and Build a fourth fitted model\n\nX_train_rfe3c = sm.add_constant(X_train_rfe3)\nlm_rfe3 = sm.OLS(y_train, X_train_rfe3c).fit()\n\n#Summary of linear model\nprint(lm_rfe3.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Dropping cylindernumber_six  beacuse its p-value is 0.684 and we want p-value less than 0.05."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping highly correlated variables and insignificant variables\n\nX_train_rfe4 = X_train_rfe3.drop('cylindernumber_six', 1,)\n\n# Adding a constant variable and Build a fifth fitted model\n\nX_train_rfe4c = sm.add_constant(X_train_rfe4)\nlm_rfe4 = sm.OLS(y_train, X_train_rfe4c).fit()\n\n#Summary of linear model\nprint(lm_rfe4.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Dropping cylindernumber_five  beacuse its p-value is 0.495 and we want p-value less than 0.05."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping highly correlated variables and insignificant variables\n\nX_train_rfe5 = X_train_rfe4.drop('cylindernumber_five', 1,)\n\n# Adding a constant variable and Build a sixth fitted model\n\nX_train_rfe5c = sm.add_constant(X_train_rfe5)\nlm_rfe5 = sm.OLS(y_train, X_train_rfe5c).fit()\n\n#Summary of linear model\nprint(lm_rfe5.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Dropping cylindernumber_four  beacuse its p-value is 0.349 and we want p-value less than 0.05."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping highly correlated variables and insignificant variables\n\nX_train_rfe6 = X_train_rfe5.drop('cylindernumber_four', 1,)\n\n# Adding a constant variable and Build a seventh fitted model\n\nX_train_rfe6c = sm.add_constant(X_train_rfe6)\nlm_rfe6 = sm.OLS(y_train, X_train_rfe6c).fit()\n\n#Summary of linear model\nprint(lm_rfe6.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"R squared value is 0.884"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train_rfe6.columns\nvif['VIF'] = [variance_inflation_factor(X_train_rfe6.values, i) for i in range(X_train_rfe6.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now the VIFs and p-values both are within an acceptable range. Variables are statistically significant."},{"metadata":{},"cell_type":"markdown","source":"## 7. Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\ntest[num] = sc.transform(test[num])\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = test.pop('price')\nX_test = test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding constant\nX_test_1 = sm.add_constant(X_test)\n\nX_test1 = X_test_1[X_train_rfe6c.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predictions = lm_rfe6.predict(X_test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting y_test and y_pred.\nfig = plt.figure()\nplt.scatter(y_test,y_predictions)\nfig.suptitle('y_test vs y_predions', fontsize=20)   \nplt.xlabel('y_test ', fontsize=18)                       \nplt.ylabel('y_predictions', fontsize=16)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2_score(y_test, y_predictions)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The R squared value of training set is 0.884 and test set is 0.87."},{"metadata":{},"cell_type":"markdown","source":"The above will be used to predict the price of cars."},{"metadata":{},"cell_type":"markdown","source":"Multiple linear regression model is,"},{"metadata":{},"cell_type":"markdown","source":"*Price = -0.2346 + 0.557 x horsepower + 0.5820 x Carname_audi + 1.5135 x Carname_bmw + 2.0651 x Carname_buick + 1.8828 X Carname_jaguar + 1.1414 x Carname_porsche + 0.7072 x Carname_volvo - 1.1521 x enginetype_dohcv - 0.9373 x cylindernumber_twelve *"},{"metadata":{},"cell_type":"markdown","source":"## I hope this kernal is helpful for you. Your UPVOTE means alot to me!!"},{"metadata":{},"cell_type":"markdown","source":"## Thank you !! "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}