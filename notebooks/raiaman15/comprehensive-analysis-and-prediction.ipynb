{"cells":[{"metadata":{},"cell_type":"markdown","source":"Analysis and Prediction of Severity of Traffic Accident\n`US Accident Traffic Severity Assessment`"},{"metadata":{},"cell_type":"markdown","source":"## Table of Content"},{"metadata":{},"cell_type":"markdown","source":"1. [Data Preparation](#Data-Preparation \"Goto Data Preparation Section\")\n   - [Importing Libraries](#Importing-Libraries \"Goto Importing Libraries Sub-Section\")\n   - [Data Loading](#Data-Loading \"Goto Data Loading Sub-Section\")\n   - [Data Summarization](#Data-Summarization \"Goto Data Summarization Sub-Section\")\n   - [Data Cleaning](#Data-Cleaning \"Goto Data Cleaning Sub-Section\")\n   - [Feature Engineering](#Feature-Engineering \"Goto Feature Engineering Sub-Section\")\n   - [Outlier Treatment](#Outlier-Treatment \"Goto Outlier Treatment Sub-Section\")\n   \n   \n2. [Exploratory Data Analysis](#Exploratory-Data-Analysis \"Goto Exploratory Data Analysis Section\")\n   - [Importing Libraries for Exploratory Data Analysis](#Importing-Libraries-for-Exploratory-Data-Analysis \"Goto Importing Libraries for Exploratory Data Analysis Sub-Section\")\n   - [Summary Statistics](#Summary-Statistics \"Goto Summary Statistics Sub-Section\")\n   - [Univariate Analysis](#Univariate-Analysis \"Goto Univariate Analysis Sub-Section\")\n   - [Bivariate Analysis](#Bivariate-Analysis \"Goto Bivariate Analysis Sub-Section\")\n   - [Multivariate Analysis](#Multivariate-Analysis \"Goto Multivariate Analysis Sub-Section\")\n   - [Miscellaneous Plots](#Miscellaneous-Plots \"Goto Miscellaneous Plots Sub-Section\")\n   \n   \n3. [Data Pre-processing](#Data-Pre-processing \"Goto Data Pre-processing Section\")\n   - [Importing Libraries for Data Pre-processing](#Importing-Libraries-for-Data-Pre-processing \"Goto Importing Libraries Sub-Section\")\n   - [Selecting Columns](#Selecting-Columns \"Goto Selecting Columns Sub-Section\")\n   - [Splitting State Specific Data](#Splitting-State-Specific-Data \"Goto Splitting State Specific Data Sub-Section\")\n   \n   \n4. [Model Building and Evaluation](#Model-Building-and-Evaluation \"Goto Model Building and Evaluation Section\")\n   - [Building ML Model for State 'CA'](#Building-ML-Model-for-State-'CA' \"Goto Building ML Model for State 'CA' Sub-Section\")\n   - [Building ML Model for State 'TX'](#Building-ML-Model-for-State-'TX' \"Goto Building ML Model for State 'TX' Sub-Section\")\n   - [Building ML Model for State 'FL'](#Building-ML-Model-for-State-'FL' \"Goto Building ML Model for State 'FL' Sub-Section\")\n   - [Building ML Model for State 'SC'](#Building-ML-Model-for-State-'SC' \"Goto Building ML Model for State 'SC' Sub-Section\")\n   - [Building ML Model for State 'NC'](#Building-ML-Model-for-State-'NC' \"Goto Building ML Model for State 'NC' Sub-Section\")\n   \n   \n5. [Combined Results of Models on Datasets of States](#Combined-Results-of-Models-on-Datasets-of-States \"Goto Combined Results of Models on Datasets of States Section\")"},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation"},{"metadata":{},"cell_type":"markdown","source":"### Importing Libraries"},{"metadata":{"trusted":false},"cell_type":"code","source":"!pip install --upgrade pip\n!pip uninstall -y numpy\n!pip install numpy==1.18.2\n!pip uninstall -y pandas\n!pip install pandas==1.0.3\n!pip uninstall -y matplotlib\n!pip install matplotlib==3.2.1\n!pip uninstall -y wordcloud\n!pip install wordcloud==1.6.0\n!pip uninstall -y swifter\n!pip install swifter==0.301\n!pip uninstall -y seaborn\n!pip install seaborn==0.10.0\n!pip uninstall -y plotly\n!pip install plotly==4.5.4\n!pip uninstall -y tensorflow\n!pip install tensorflow==2.0.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Hiding all warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# import numpy, pandas and other necessary libraries\nimport re\nimport numpy as np\nimport pandas as pd\nimport swifter\nfrom wordcloud import STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Optimizing settings and configuraturation\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.options.display.max_columns = 50","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Loading"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Reading the dataset\n\ndata = pd.read_csv('../input/us-accidents/US_Accidents_June20.csv')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Displaying initial data\n\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Understanding the dataset | Meta Data\n\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Understanding the dataset | Data Content\n\ndata.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Summarization"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Displaying the summary of the dataset\n\nprint('Rows     :',data.shape[0])\nprint('Columns  :',data.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Displaying the summary of the dataset\n\nprint('Rows     :',data.shape[0])\nprint('Columns  :',data.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Displaying the attributes in the dataset\n\nprint('\\nAttributes:\\n',data.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Displaying the number of missing values per attribute\n\nprint('Percentage of Missing values:\\n\\n',(100*data.isnull().sum()/data.shape[0]).round(2))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#Displaying the number of unique values per attribute\n\nprint('Unique values per column :',data.nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Displaying the names of the attributes which consists of numerical values\n\ndata.select_dtypes(include=['int','float']).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Displaying the names of the attributes which consists of non-numerical values\n\ndata.select_dtypes(exclude=['int','float']).columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Cleaning"},{"metadata":{},"cell_type":"markdown","source":"#### Addressing Dataset Completeness"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Displaying the list of attributes with high amount of missing values (>20%)\n\nprint('Attributes with > 20% missing values: ', data.columns[(100*data.isnull().sum()/data.shape[0]).round(2)>20].tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is important to note that observation of these attributes revealed the following:\n1. 'TMC' is one of the important attribute which is communicated by the authorities, hence we would not delete it.\n2. 'End_Lat' and 'End_Lng' are missing when the distance of road affected by accident is very small, thus, Start and End location would be almost same and End could be removed.\n3. 'Number', 'Wind_Chill(F)' and 'Precipitation(in)' can be removed due to high percentage of missing values."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Imputing the missing values in TMC to 201, since that means generic 'Accident' and we and not sure of further details.\n\ndata['TMC'].fillna(value=201, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Removing the attributes from the dataset\n\ndata.drop(columns=['End_Lat', 'End_Lng', 'Number', 'Wind_Chill(F)', 'Precipitation(in)'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is important to note that observation of these attributes revealed the following:\n1. 'Wind_Speed(mph)' is missing when the 'Wind_Direction' is calm, thus considering it 0 will be fair.\n2. Other attributes except 'Wind_Speed(mph)' are missing randomly and such records are less than 5% of entire data, thus removing them."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Checking if we still have missing values per attribute in our dataset\n# Displaying the list of attributes with any amount of missing values (>0%)\n\nprint('Attributes with missing values: ', data.columns[(100*data.isnull().sum()/data.shape[0])>0].tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Setting 'Wind_Speed(mph)' as 0 for rows where 'Wind_Direction' is 'Calm', meaning almost no wind.\n\ndata.loc[data['Wind_Direction'] == 'Calm', 'Wind_Speed(mph)'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Checking if we still have missing values in the attribute 'Wind_Speed(mph)'\n\nprint('Percentage of Missing values in attribute Wind_Speed(mph) is: ', (100*data['Wind_Speed(mph)'].isnull().sum()/data.shape[0]).round(2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Checking what percentage of rows will remain after dropping rows with missing values\n\nprint(f'Percentage of rows remaining after removal of rows containing missing values: {(100*data.dropna().shape[0]/data.shape[0]):.4}')\nprint(f'Percentage of rows deleted in order to remove missing values: {100-(100*data.dropna().shape[0]/data.shape[0]):.4}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Dropping all rows with missing values since the less than 30% records gets deleted, and we have huge dataset\n\ndata.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Checking if we still have missing values per attribute in our dataset\n# Displaying the list of attributes with any amount of missing values (>0%)\n\nprint('Attributes with Missing values: ', data.columns[(100*data.isnull().sum()/data.shape[0])>0].tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Addressing Dataset Validity"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Checking for datatypes of the attributes\n\ndata.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Converting datatype for attributes related to datetime.\n\ndata[\"Start_Time\"]= pd.to_datetime(data[\"Start_Time\"]) \ndata[\"End_Time\"]= pd.to_datetime(data[\"End_Time\"])\ndata[\"Weather_Timestamp\"]= pd.to_datetime(data[\"Weather_Timestamp\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Addressing Dataset Consistency"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Checking the percentage of Duplicate records in the dataset\n\nprint(f'Percentage of duplicate records: {100-(100*data.drop_duplicates().shape[0]/data.shape[0])}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Dropping the duplicate records, if any\n\ndata.drop_duplicates(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Adding consistency to the various wind speed direction values\n\ndata['Wind_Direction'].replace({'North': 'N'}, inplace=True)\ndata['Wind_Direction'].replace({'East': 'E'}, inplace=True)\ndata['Wind_Direction'].replace({'West': 'W'}, inplace=True)\ndata['Wind_Direction'].replace({'South': 'S'}, inplace=True)\ndata['Wind_Direction'].replace({'VAR': 'Variable'}, inplace=True)\ndata['Wind_Direction'].replace({'CALM': 'Calm'}, inplace=True)\n\ndata['Wind_Direction'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Addressing Dataset Accuracy"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# 'End_Time' should always be greater than 'Start_Time'\n\ndata.drop(data[data['End_Time']<data['Start_Time']].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Dropping unnecessary attributes"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Since the entire dataset is of one country, we can remove the attribute 'Country' as it contains only one value\n\ndata.drop(columns=['Country'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Since the entire dataset contains single value for 'Turning_Loop' we can remove the attribute 'Turning_Loop'\n\ndata.drop(columns=['Turning_Loop'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Since the ID column is an identifier, we can remove the attribute 'ID'\n\ndata.drop(columns=['ID'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"#### Deriving the attribute 'Time_Duration(min)'"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Deriving the attribute 'Time_Duration(min)'\n\ndata.insert(4,'Time_Duration(min)',(data['End_Time']-data['Start_Time'])//np.timedelta64(1,'m'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data['Time_Duration(min)'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Dropping the attribute 'End_Time' since it is redundant now\n\ndata.drop(columns=['End_Time'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Splitting the 'Start_Time' timestamp to 'Year', 'Month', 'Day', 'Hour' and 'Weekend'"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Breaking 'Start_Time' into 'Year', 'Month', 'Day', 'Hour' and 'Weekend'\n\ndata['Year']=data['Start_Time'].dt.year\ndata['Month']=data['Start_Time'].dt.month\ndata['Day']=data['Start_Time'].dt.day\ndata['Hour']=data['Start_Time'].dt.hour\ndata['Minute']=data['Start_Time'].dt.minute\ndata['Weekday']=data['Start_Time'].dt.weekday\n\ndef weekday_text(w):\n    d = {0:'Monday', 1:'Tuesday', 2:'Wednesday', 3:'Thursday', 4:'Friday', 5:'Saturday', 6:'Sunday'}\n    return d[w]\ndata['Weekday']=data['Weekday'].apply(lambda x:weekday_text(x))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Dropping the attribute 'Start_Time' since it is redundant now\n\ndata.drop(columns=['Start_Time'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Extracting 'Keyword' from 'Description' attribute"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Extrating keywords from the attribute 'Description' using NLP and suggestion from article\n# https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n\ndef clean(text):\n    # lowercase\n    text=text.lower()\n    #remove tags\n    text=re.sub(\"</?.*?>\",\" <> \",text)\n    # remove special characters and digits\n    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n    return text\n\ndata['Description'] = data['Description'].swifter.apply(lambda x:clean(x))\n\n# removing stopwords\ndata['Description'] = data['Description'].swifter.apply(lambda x: ' '.join([item for item in x.split(' ') if item not in STOPWORDS]))\n\n#show the starting few 'Descriptions'\ndata['Description'][:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Getting the Description (text) column \ndocs=data['Description'].tolist()\n\n# Creating a vocabulary of words, Ignoring words that appear in 85% of documents, Eliminating stop words\ncv=CountVectorizer(max_df=0.85,stop_words=STOPWORDS)\nword_count_vector=cv.fit_transform(docs)\n\n# Displaying Shape\nword_count_vector.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Generating TFIDF Transformer\n\ntfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\ntfidf_transformer.fit(word_count_vector)\ntfidf_transformer.idf_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Sorting the feature name based on score\n\ndef sort_coo(coo_matrix):\n    tuples = zip(coo_matrix.col, coo_matrix.data)\n    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)[:3]\n\n# Extracting \ndef extract_top5_from_vector(feature_names, sorted_items):\n    keyword = []\n\n    for idx, score in sorted_items:\n        keyword.append(feature_names[idx])\n\n    return ';'.join(keyword)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Getting actual feature names\n\nfeature_names=cv.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Extracting the 'Keywords' from 'Description' attribute of dataset\n\ndef extract_description_keywords(doc):\n    #generate tf-idf for the given document\n    tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n    #sort the tf-idf vectors by descending order of scores and get features\n    sorted_items=sort_coo(tf_idf_vector.tocoo(copy=False))\n    return extract_top5_from_vector(feature_names,sorted_items)\n\ndata['Keywords'] = data['Description'].swifter.apply(lambda x:extract_description_keywords(x))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Adding an attribute per keyword to be used for modelling\n\ndata['Keyword_1'] = data['Keywords'].swifter.apply(lambda x:str(x.split(';')[0]) if len(x.split(';'))>0 else None)\ndata['Keyword_2'] = data['Keywords'].swifter.apply(lambda x:str(x.split(';')[1]) if len(x.split(';'))>1 else None)\ndata['Keyword_3'] = data['Keywords'].swifter.apply(lambda x:str(x.split(';')[2]) if len(x.split(';'))>2 else None)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Displaying the number of missing values per attribute\n\nprint('Percentage of Missing values:\\n\\n',(100*data.isnull().sum()/data.shape[0]).round(2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Removing records with missing values, i.e. missing 'Keywords' since they are only around 2.5%\n\ndata.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Removing Redundant Column; 'Description' and 'Keywords'\n\ndata.drop(columns=['Description', 'Keywords'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Outlier Treatment"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Removing outliers | Time_Duration\n# Removing records stating duration more than 12 days (since higher than 12 days is not recorded yet)\n\ndata.drop(data[data['Time_Duration(min)'] > (12*1440)].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Removing outliers | Wind_Speed(mph)\n# Removing records wind speed more than 260 mph (since higher than ~253mph is not recorded yet)\n\ndata.drop(data[data['Wind_Speed(mph)'] > 260].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Removing outliers | Distance(mi)\n# Removing records distance(mi) more than 109 miles (since higher than ~109 miles is not recorded yet)\n\ndata.drop(data[data['Distance(mi)'] > 109].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Removing outliers | Temperature(F)\n# Removing records temperature(f) more than 131.4 mph (since higher than ~134.1 F is not recorded yet)\n\ndata.drop(data[data['Temperature(F)'] > 134.1].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Removing outliers | Pressure(in)\n# Removing records pressure(in) less than 25.69 (since lesser than ~25.69 is not recorded yet)\n# Removing records pressure(in) more than 32.03 (since higher than ~32.03 is not recorded yet)\n\ndata.drop(data[data['Pressure(in)'] < 25.69].index, inplace=True)\ndata.drop(data[data['Pressure(in)'] > 32.03].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Removing outliers | Wind_Speed(mph)\n# Removing records visibility(mi) more than 150 miles (since higher than ~150 miles is not recorded yet)\n\ndata.drop(data[data['Visibility(mi)'] > 150].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Checking if none of the value is NaN and all of the values are finite and saving to file\n\nif data.notnull().values.all() and not data.isnull().values.any():\n    data.to_csv(\"/kaggle/working/data.csv\", index=False)\n    print('Data Saved')\nelse:\n    print('Data Not Saved')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"___"},{"metadata":{},"cell_type":"markdown","source":"----"},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"### Importing Libraries for Exploratory Data Analysis"},{"metadata":{"trusted":false},"cell_type":"code","source":"%reset -f\n\n# Hiding all warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# import numpy and pandas\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n# import for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# do an inline so that plt.show() is not required everytime\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Reading the dataset\n\ndata = pd.read_csv('/kaggle/working/data.csv').dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Summary Statistics"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Displaying the summary of the dataset\n\nprint('Rows     :',data.shape[0])\nprint('Columns  :',data.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Displaying all attributes of the dataset\n\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.describe(exclude=[np.object]).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.describe(include=[np.object]).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analysing the 'Severity' attribute\n\n#Textual Representation\nprint(data.groupby(by='Severity').size())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Univariate Analysis"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analysing the 'TMC' attribute\n\n#Pictorial Representation\nfig = plt.figure(figsize = (12, 4))\nsns.countplot(y=\"TMC\", data=data, order=data['TMC'].value_counts().index[:10], palette='Blues_d')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set up the matplotlib figure\nf, axes = plt.subplots(2, 2, figsize=(16, 12))\n\n# Analysing the 'Amenity' attribute\nsns.distplot(data['Year'], ax=axes[0, 0])\n\n# Analysing the 'Amenity' attribute\nsns.distplot(data['Month'], ax=axes[0, 1])\n\n# Analysing the 'Amenity' attribute\nsns.distplot(data['Day'], ax=axes[1, 0])\n\n# Analysing the 'Amenity' attribute\nsns.countplot(data['Weekday'], palette='Blues_d',ax=axes[1, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set up the matplotlib figure\nf, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Analysing the 'Start_Time' Hour, Minute attribute\nsns.distplot(data['Hour'], bins=24, ax=axes[0])\nsns.distplot(data['Minute'], bins=60, ax=axes[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analysing the 'Timestamp' (Year, Month) attribute\n\nfig = plt.figure(figsize = (16, 4))\ndata.groupby(by=['Year', 'Month']).size().plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set up the matplotlib figure\nf, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Analysing the 'Time_Duration(min)' attribute\nsns.distplot(data['Time_Duration(min)']/60, ax=axes[0])\nsns.boxplot(data['Time_Duration(min)'], ax=axes[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set up the matplotlib figure\nf, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Analysing the 'Distance(mi)' attribute\nsns.distplot(data['Distance(mi)'], kde=False, ax=axes[0])\nsns.boxplot(data['Distance(mi)'], ax=axes[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analysing the 'Description' attribute\n\ntext = ' '.join(data['Keyword_1'].to_list())\nwordcloud = WordCloud(width = 400, height = 400, background_color = 'white', stopwords = STOPWORDS).generate(str(text))\nfig = plt.figure(figsize = (5, 5))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analysing the 'Description' attribute\n\ntext = ' '.join(data['Keyword_2'].to_list())\nwordcloud = WordCloud(width = 400, height = 400, background_color = 'white', stopwords = STOPWORDS).generate(str(text))\nfig = plt.figure(figsize = (5, 5))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analysing the 'Description' attribute\n\ntext = ' '.join(data['Keyword_3'].to_list())\nwordcloud = WordCloud(width = 400, height = 400, background_color = 'white', stopwords = STOPWORDS).generate(str(text))\nfig = plt.figure(figsize = (5, 5))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# Analysing the 'State' attribute\n\nfig = plt.figure(figsize = (16, 6))\nsns.countplot(x='State', data=data, order=data['State'].value_counts().index, palette='Blues_d')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data.groupby(by='State').size().sort_values().plot.pie(autopct='%1.1f%%', shadow=True, figsize=(16, 16))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set up the matplotlib figure\nf, axes = plt.subplots(2, 2, figsize=(16, 12))\n\n# Analysing the 'Temperature(F)' attribute\nsns.distplot(data['Temperature(F)'], ax=axes[0, 0])\nsns.distplot(data['Humidity(%)'], ax=axes[0, 1])\nsns.distplot(data['Pressure(in)'], ax=axes[1, 0])\nsns.distplot(data['Wind_Speed(mph)'], ax=axes[1, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analysing the 'Visibility(mi)' attribute\n\nfig = plt.figure(figsize = (16, 6))\nsns.distplot(data['Visibility(mi)'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analysing the 'Wind_Direction' attribute\n\nfig = plt.figure(figsize = (12, 6))\nsns.countplot(y='Wind_Direction', data=data, order=data['Wind_Direction'].value_counts().index, palette='Blues_d')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analysing the 'Weather_Condition' attribute\n\nfig = plt.figure(figsize = (12, 6))\nsns.countplot(y='Weather_Condition', data=data, order=data['Weather_Condition'].value_counts()[:20].index, palette='Blues_d')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set up the matplotlib figure\nf, axes = plt.subplots(3, 4, figsize=(20, 16))\n\n# Analysing the 'Amenity' attribute\nsns.countplot(x='Amenity', data=data, ax=axes[0, 0], palette='Blues_d')\n\n# Analysing the 'Bump' attribute\nsns.countplot(x='Bump', data=data, ax=axes[0, 1], palette='Blues_d')\n\n# Analysing the 'Crossing' attribute\nsns.countplot(x='Crossing', data=data, ax=axes[0, 2], palette='Blues_d')\n\n# Analysing the 'Give_Way' attribute\nsns.countplot(x='Give_Way', data=data, ax=axes[0, 3], palette='Blues_d')\n\n# Analysing the 'Junction' attribute\nsns.countplot(x='Junction', data=data, ax=axes[1, 0], palette='Blues_d')\n\n# Analysing the 'No_Exit' attribute\nsns.countplot(x='No_Exit', data=data, ax=axes[1, 1], palette='Blues_d')\n\n# Analysing the 'Railway' attribute\nsns.countplot(x='Railway', data=data, ax=axes[1, 2], palette='Blues_d')\n\n# Analysing the 'Roundabout' attribute\nsns.countplot(x='Roundabout', data=data, ax=axes[1, 3], palette='Blues_d')\n\n# Analysing the 'Station' attribute\nsns.countplot(x='Station', data=data, ax=axes[2, 0], palette='Blues_d')\n\n# Analysing the 'Stop' attribute\nsns.countplot(x='Stop', data=data, ax=axes[2, 1], palette='Blues_d')\n\n# Analysing the 'Traffic_Calming' attribute\nsns.countplot(x='Traffic_Calming', data=data, ax=axes[2, 2], palette='Blues_d')\n\n# Analysing the 'Traffic_Signal' attribute\nsns.countplot(x='Traffic_Signal', data=data, ax=axes[2, 3], palette='Blues_d')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# Set up the matplotlib figure\nf, axes = plt.subplots(2, 2, figsize=(8, 8))\n\n# Analysing the 'Sunrise_Sunset' attribute\nsns.countplot(x='Sunrise_Sunset', data=data, ax=axes[0, 0], palette='Blues_d')\n\n# Analysing the 'Civil_Twilight' attribute\nsns.countplot(x='Civil_Twilight', data=data, ax=axes[0, 1], palette='Blues_d')\n\n# Analysing the 'Nautical_Twilight' attribute\nsns.countplot(x='Nautical_Twilight', data=data, ax=axes[1, 0], palette='Blues_d')\n\n# Analysing the 'Astronomical_Twilight' attribute\nsns.countplot(x='Astronomical_Twilight', data=data, ax=axes[1, 1], palette='Blues_d')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Bivariate Analysis"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analysing the 'TMC' & 'Severity' attribute\n\ntemp = pd.DataFrame(data.groupby(by='TMC').size())\ntemp = temp.sort_values(by=0, ascending=False).index[:5]\n\n#Pictorial Representation\n\nfig = plt.figure(figsize = (16, 6))\nsns.countplot(y=\"TMC\", data=data, order=temp, hue='Severity', palette='Blues_d')\nplt.legend(loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analysing the 'Year' & 'Severity' attribute\n\nfig = plt.figure(figsize = (16, 4))\nsns.countplot(y=\"Year\", data=data, hue='Severity', palette='Blues_d')\nplt.legend(loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analysing the 'Month' & 'Severity' attribute\n\nfig = plt.figure(figsize = (16, 6))\nsns.countplot(y=\"Month\", data=data, hue='Severity', palette='Blues_d')\nplt.legend(loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analysing the 'Weekday' & 'Severity' attribute\n\nfig = plt.figure(figsize = (16, 6))\nsns.countplot(y=\"Weekday\", data=data, hue='Severity', palette='Blues_d')\nplt.legend(loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set up the matplotlib figure\nf, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Analysing the impact of 'Time_Duration(min)' attribute on 'Severity' attribute | Scatter Plot\ndata.plot.scatter(x='Time_Duration(min)', y='Severity', ax=axes[0])\n\n# Analysing the impact of 'Distance(mi)' attribute on 'Severity' attribute | Scatter Plot\ndata.plot.scatter(x='Distance(mi)', y='Severity', ax=axes[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analysing the 'State' & 'Severity' attribute\n\nfig = plt.figure(figsize = (16, 6))\nsns.countplot(x=\"State\", data=data, order=data['State'].value_counts().index, hue='Severity', palette='Blues_d')\nplt.legend(loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set up the matplotlib figure\nf, axes = plt.subplots(2, 2, figsize=(16, 12))\n\n# Analysing the impact of 'Temperature(F)' attribute on 'Severity' attribute | Scatter Plot\ndata.plot.scatter(x='Temperature(F)', y='Severity', ax=axes[0, 0])\n\n# Analysing the impact of 'Humidity(%)' attribute on 'Severity' attribute | Scatter Plot\ndata.plot.scatter(x='Humidity(%)', y='Severity', ax=axes[0, 1])\n\n# Analysing the impact of 'Pressure(in)' attribute on 'Severity' attribute | Scatter Plot\ndata.plot.scatter(x='Pressure(in)', y='Severity', ax=axes[1, 0])\n\n# Analysing the impact of 'Wind_Speed(mph)' attribute on 'Severity' attribute | Scatter Plot\ndata.plot.scatter(x='Wind_Speed(mph)', y='Severity', ax=axes[1, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analysing the impact of 'Visibility(mi)' attribute on 'Severity' attribute | Scatter Plot\n\nfig = plt.figure(figsize = (8, 6))\ndata.plot.scatter(x='Visibility(mi)', y='Severity')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analysing the 'Side' & 'Severity' attribute\n\nfig = plt.figure(figsize = (16, 6))\nsns.countplot(x=\"Side\", data=data, order=data['Side'].value_counts().index, hue='Severity', palette='Blues_d')\nplt.legend(loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analysing the 'Side' & 'Severity' attribute\n\nfig = plt.figure(figsize = (16, 6))\nsns.countplot(x=\"Wind_Direction\", data=data, order=data['Wind_Direction'].value_counts().index, hue='Severity', palette='Blues_d')\nplt.legend(loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Analysing the 'Weather_Condition' & 'Severity' attribute\n\nfig = plt.figure(figsize = (16, 6))\nsns.countplot(x=\"Weather_Condition\", data=data, order=data['Weather_Condition'].value_counts()[:12].index, hue='Severity', palette='Blues_d')\nplt.legend(loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set up the matplotlib figure\nf, axes = plt.subplots(2, 2, figsize=(16, 6))\n\n# Analysing the impact of 'Sunrise_Sunset' attribute on 'Severity' attribute | Box Plot\nsns.boxplot(x='Sunrise_Sunset', y='Severity', data=data, ax=axes[0, 0], order=data['Sunrise_Sunset'].value_counts()[:10].index)\n\n# Analysing the impact of 'Civil_Twilight' attribute on 'Severity' attribute | Box Plot\nsns.boxplot(x='Civil_Twilight', y='Severity', data=data, ax=axes[0, 1], order=data['Civil_Twilight'].value_counts()[:10].index)\n\n# Analysing the impact of 'Nautical_Twilight' attribute on 'Severity' attribute | Box Plot\nsns.boxplot(x='Nautical_Twilight', y='Severity', data=data, ax=axes[1, 0], order=data['Nautical_Twilight'].value_counts()[:10].index)\n\n# Analysing the impact of 'Astronomical_Twilight' attribute on 'Severity' attribute | Box Plot\nsns.boxplot(x='Astronomical_Twilight', y='Severity', data=data, ax=axes[1, 1], order=data['Astronomical_Twilight'].value_counts()[:10].index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Multivariate Analysis"},{"metadata":{"trusted":false},"cell_type":"code","source":"# plotting correlations on a heatmap\n\nplt.figure(figsize=(16,8))\nsns.heatmap(data.corr(), cmap=\"YlGnBu\", annot=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Miscellaneous Plots"},{"metadata":{"trusted":false},"cell_type":"code","source":"BBox = ((data.Start_Lng.min(), data.Start_Lng.max(), data.Start_Lat.min(), data.Start_Lat.max()))\nBBox","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"map_pic = plt.imread('map/map_pic.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (26,14))\nax.scatter(data[data['Severity']==1].Start_Lng+0.3, data[data['Severity']==1].Start_Lat-0.8, zorder=1, alpha= 0.7, c='blue', s=4)\nax.scatter(data[data['Severity']==2].Start_Lng+0.3, data[data['Severity']==2].Start_Lat-0.8, zorder=1, alpha= 0.7, c='green', s=3)\nax.scatter(data[data['Severity']==3].Start_Lng+0.3, data[data['Severity']==3].Start_Lat-0.8, zorder=1, alpha= 0.7, c='orange', s=2)\nax.scatter(data[data['Severity']==4].Start_Lng+0.3, data[data['Severity']==4].Start_Lat-0.8, zorder=1, alpha= 0.7, c='red', s=1)\n\nax.set_xlim(BBox[0],BBox[1])\nax.set_ylim(BBox[2],BBox[3])\nax.imshow(map_pic, zorder=0, extent = BBox, aspect= 'auto', interpolation='none')\nax.imshow(map_pic, zorder=2, alpha= 0.5, extent = BBox, aspect= 'auto')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"___"},{"metadata":{},"cell_type":"markdown","source":"## Data Pre-Processing"},{"metadata":{},"cell_type":"markdown","source":"### Importing Libraries for Data Pre-processing"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Deleting all data\n%reset -f\n\n# Reloading necessary libraries\n# import numpy and pandas\nimport pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Selecting Columns"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Selecting the features which are likely to be available initially upon the accident, plus target variable 'Severity' for model building.\n\n# Reading the above processed data from disk\ndata= pd.read_csv(\"/kaggle/working/data.csv\").dropna()\n\n# List of all available attributes\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# List of selected attributes based upon fast availability of attributes, considering:\n# 1. the objectibe of the research\n# 2. the non repetition of information (e.g. Complete Address + Zipcode)\n\ncols = [\n        'Source', 'TMC', 'Severity', 'Start_Lat', 'Start_Lng', 'Temperature(F)',\n        'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)', 'Weather_Condition',\n        'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway','Roundabout', 'Station', \n        'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Sunrise_Sunset', 'Civil_Twilight', \n        'Year', 'Month', 'Day', 'Hour', 'Minute','Weekday', \n        'Street', 'Side', 'City', 'County', 'Keyword_1', 'Keyword_2', 'Keyword_3'\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting State Specific Data"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Generating the new dataset with selected columns and dummies for categorical data\n# Checking if none of the value is NaN and all of the values are finite\n# Saving the top 5 state specific dataset to disk and freeing up RAM before building model\n\n# State CA\ndata[data['State']=='CA'][cols].to_csv(\"/kaggle/working/data_CA.csv\", index=False)\n\n# State TX\ndata[data['State']=='TX'][cols].to_csv(\"/kaggle/working/data_TX.csv\", index=False)\n\n# State FL\ndata[data['State']=='FL'][cols].to_csv(\"/kaggle/working/data_FL.csv\", index=False)\n\n# State SC\ndata[data['State']=='SC'][cols].to_csv(\"/kaggle/working/data_SC.csv\", index=False)\n\n# State NC\ndata[data['State']=='NC'][cols].to_csv(\"/kaggle/working/data_NC.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"___"},{"metadata":{},"cell_type":"markdown","source":"## Model Building and Evaluation"},{"metadata":{},"cell_type":"markdown","source":"### Building ML Model for State 'CA'"},{"metadata":{},"cell_type":"markdown","source":"### Importing Libraries"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Deleting all data\n%reset -f\n\n# Reloading necessary libraries\n# import numpy and pandas\nimport pandas as pd\nimport numpy as np\n\n# import for pre-processing\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc\nfrom sklearn.preprocessing import OrdinalEncoder, StandardScaler\n\n# import for visualization\nimport matplotlib.pyplot as plt\n\n# import for model building\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# import for Neural Network based model building\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Building State specific model | State 'CA'\n\nresult = {}\nstate='CA'\nresult['State']=state\nprocessed_data = pd.read_csv(f'/kaggle/working/data_{state}.csv').dropna()\ncols = processed_data.select_dtypes(include='object').columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Class Balancing | Using Up Sampling\n\n# Separate majority and minority classes\ndf_s1 = processed_data[processed_data['Severity']==1]\ndf_s2 = processed_data[processed_data['Severity']==2]\ndf_s3 = processed_data[processed_data['Severity']==3]\ndf_s4 = processed_data[processed_data['Severity']==4]\n\ncount = max(df_s1.count()[0], df_s2.count()[0], df_s3.count()[0], df_s4.count()[0])\n\n# Upsample minority class\ndf_s1 = resample(df_s1, replace=df_s1.count()[0]<count, n_samples=count, random_state=42)\ndf_s2 = resample(df_s2, replace=df_s2.count()[0]<count, n_samples=count, random_state=42)\ndf_s3 = resample(df_s3, replace=df_s3.count()[0]<count, n_samples=count, random_state=42)\ndf_s4 = resample(df_s4, replace=df_s4.count()[0]<count, n_samples=count, random_state=42)\n \n# Combine majority class with upsampled minority class\nprocessed_data = pd.concat([df_s1, df_s2, df_s3, df_s4])\n \n# Display new class counts\nprocessed_data.groupby(by='Severity')['Severity'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set the target for the prediction\ntarget='Severity' \n\n# set X and y\ny = processed_data[target]\nX = processed_data.drop(target, axis=1)\n\n# Create the encoder.\nencoder = OrdinalEncoder()\nX[cols] = encoder.fit_transform(X[cols])\n\n# Split the data set into training and testing data sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n\n# Split the data set into training and validation data sets\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, stratify=y_train, random_state=42)\n\n# Scalling the features of Train Dataset, Validation Dataset and Test Dataset\nscaler = StandardScaler()\n\n# Scaling Train Dataset\nscaler = scaler.fit(X_train)\nX_train = scaler.transform(X_train)\n\n# Scaling Validation Dataset\nscaler = scaler.fit(X_val)\nX_val = scaler.transform(X_val)\n\n# Scaling Test Dataset\nscaler = scaler.fit(X_test)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### VISUALIZING THE DATA ON MAP"},{"metadata":{"trusted":false},"cell_type":"code","source":"BBox = ((processed_data.Start_Lng.min(), processed_data.Start_Lng.max(), processed_data.Start_Lat.min(), processed_data.Start_Lat.max()))\nBBox","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"map_pic = plt.imread('/kaggle/working/map/map_pic_ca.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (27,33))\nax.scatter(processed_data[processed_data['Severity']==1].Start_Lng, processed_data[processed_data['Severity']==1].Start_Lat-.1, zorder=1, c='b', s=4)\nax.scatter(processed_data[processed_data['Severity']==2].Start_Lng, processed_data[processed_data['Severity']==2].Start_Lat-.1, zorder=1, c='g', s=6)\nax.scatter(processed_data[processed_data['Severity']==3].Start_Lng, processed_data[processed_data['Severity']==3].Start_Lat-.1, zorder=1, c='y', s=8)\nax.scatter(processed_data[processed_data['Severity']==4].Start_Lng, processed_data[processed_data['Severity']==4].Start_Lat-.1, zorder=1, c='r', s=10)\n\nax.set_xlim(BBox[0],BBox[1])\nax.set_ylim(BBox[2],BBox[3])\nax.imshow(map_pic, zorder=0, extent = BBox, aspect= 'auto', interpolation='none')\nax.imshow(map_pic, zorder=2, alpha= 0.5, extent = BBox, aspect= 'auto', interpolation='lanczos')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING SUPPORT VECTOR MACHINE"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Support Vector Machine | First Iteration\n\n# Instantiate an object of class SVC()\nclf = SVC(gamma='auto', kernel='rbf', random_state=42)\n\n# Train & Test (limiting rows since SVM takes much time)\nclf.fit(X_train[:10000], y_train[:10000])\ny_pred = clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Support Vector Machine accuracy_score: {:.3f}.\".format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Support Vector Machine | Optimization\n\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'C': [0.1, 0.5, 1],\n    'gamma': ['auto', 'scale']\n}\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(cv=5, estimator = clf, param_grid = param_grid, scoring='balanced_accuracy', n_jobs = -1,verbose = 5)\n\n# Fit the grid search to the Validation Dataset\ngrid_search.fit(X_val[:5000], y_val[:5000])\n\n# printing the optimal accuracy score and hyperparameters\nprint('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Support Vector Machine | Final Evaluation\n\n# Create a SVM Classifier\nclf=SVC(**grid_search.best_params_, kernel='rbf', random_state=42)\n\n# Train & Test\nclf.fit(X_train[:20000], y_train[:20000])\ny_train_pred= clf.predict(X_train[:20000])\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train[:20000], y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# stroring the accuracy score\nresult['Support Vector Machine'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting decent accuracy with SVM, but, the computation time is very high, even with limited dataset."},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING DECISION TREE"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Decision Tree Algorithm | First Iteration\n\n# Instantiate a Decision Tree Classifier\nclf = DecisionTreeClassifier(random_state=42)\n\n# Train & Test\nclf.fit(X_train, y_train)\ny_pred= clf.predict(X_test)\n\n# Print accuracy_entropy\nprint('Decision Tree accuracy_score: {:.3f}.'.format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Decision Tree Algorithm | Optimization\n\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'criterion': ['gini', 'entropy'],\n    'max_depth': [12, 14, 16],\n    'min_samples_split': [1000, 2000, 3000],\n    'min_samples_leaf': [500, 1000, 1500]\n}\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(cv=3, estimator = clf, param_grid = param_grid, scoring='balanced_accuracy', n_jobs = -1,verbose = 5)\n\n# Fit the grid search to the Validation Dataset\ngrid_search.fit(X_val, y_val)\n\n# printing the optimal accuracy score and hyperparameters\nprint('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Decision Tree Algorithm | Final Evaluation\n\n# Instantiate a Decision Tree Classifier with Best Parameters\nclf = DecisionTreeClassifier(**grid_search.best_params_, random_state=42)\n\n# Train & Test\nclf.fit(X_train, y_train)\ny_train_pred= clf.predict(X_train)\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# Highlighting the significance of each of the factors in the model\nfeature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\nprint(\"\\nImportant features:\\n\", feature_imp.sort_values(ascending=False)[:10])\n\n# stroring the accuracy score\nresult['Decision Tree'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting decent accuracy with Decision Tree algorithm and computation time is also comparatively less."},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING RANDOM FOREST"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Random Forest Algorithm | First Iteration\n\n# Create a Random Forest Classifier\nclf=RandomForestClassifier(n_estimators=100, bootstrap=False, min_samples_split=400, min_samples_leaf=100, n_jobs=-1, random_state=42)\n\n# Train & Test\nclf.fit(X_train,y_train)\ny_pred=clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Randon forest algorithm accuracy_score: {:.3f}.\".format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Random Forest Algorithm | Optimization\n\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'n_estimators': [100, 150, 200],\n    'max_depth': [12, 14, 16],\n    'min_samples_split': [200, 300],\n    'min_samples_leaf': [50, 75],\n    'bootstrap': [False]\n}\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(cv=3, estimator = clf, param_grid = param_grid, scoring='balanced_accuracy', n_jobs = -1,verbose = 5)\n\n# Fit the grid search to the Validation Dataset\ngrid_search.fit(X_val[:15000], y_val[:15000])\n\n# printing the optimal accuracy score and hyperparameters\nprint('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Random Forest Algorithm | Final Evaluation\n\n# Create a Random Forest Classifier\nclf=RandomForestClassifier(**grid_search.best_params_, n_jobs=-1, random_state=42)\n\n# Train & Test\nclf.fit(X_train, y_train)\ny_train_pred= clf.predict(X_train)\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# Highlighting the significance of each of the factors in the model\nfeature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\nprint(\"\\nImportant features:\\n\", feature_imp.sort_values(ascending=False)[:10])\n\n# stroring the accuracy score\nresult['Random Forest'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100, 1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting good accuracy with Random Forest algorithm and computation time is also comparatively less."},{"metadata":{},"cell_type":"markdown","source":"#### EVALUATING ADDITIONAL ALGORITHM'S PERFORMANCE"},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING K-NEAREST NEIGHBOR (KNN)"},{"metadata":{"trusted":false},"cell_type":"code","source":"# K-Nearest Neighbor | First Iteration\n\n# Create a k-NN classifier\nclf = KNeighborsClassifier(n_jobs=-1)\n\n# Train & Test\nclf.fit(X_train[:20000], y_train[:20000])\ny_train_pred= clf.predict(X_train[:20000])\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train[:20000], y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# stroring the accuracy score\nresult['K-Nearest Neighbors'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting poor accuracy with K-Nearest Neighbor algorithm and the computation time is very high, even with limited dataset."},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING NEURAL NETWORK"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# Neural Network | First Iteration\n\nmodel = Sequential()\nmodel.add(Dense(128, input_dim=np.size(X_train,1), activation='relu'))\nmodel.add(Dense(64, input_dim=np.size(X_train,1), activation='relu'))\nmodel.add(Dense(5, activation='softmax'))\n\n# compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# build the model\nhistory = model.fit(X_train, to_categorical(y_train.to_numpy()), \n                    epochs=5, validation_data=(X_val, to_categorical(y_val.to_numpy())), \n                    validation_steps=30, verbose=0)\n\n\nloss, train_accuracy = model.evaluate(X_train, to_categorical(y_train.to_numpy()), verbose=0)\nprint(f\"\\nFor Training Dataset: Loss: {loss} and Accuracy: {train_accuracy}\")\n\nloss, test_accuracy = model.evaluate(X_test, to_categorical(y_test.to_numpy()), verbose=0)\nprint(f\"\\nFor Testing Dataset: Loss: {loss} and Accuracy: {test_accuracy}\")\n\n# stroring the accuracy score\nresult['Neural Network'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting decent accuracy with Neural Network and computation time is also comparatively less."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Saving the results in file\n\ndf = pd.DataFrame.from_dict(result)\ndf.set_index(['State'])\ndf.to_csv(f'/kaggle/working/result_{state}.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"___"},{"metadata":{},"cell_type":"markdown","source":"### Building ML Model for State 'TX'"},{"metadata":{},"cell_type":"markdown","source":"### Importing Libraries"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Deleting all data\n%reset -f\n\n# Reloading necessary libraries\n# import numpy and pandas\nimport pandas as pd\nimport numpy as np\n\n# import for pre-processing\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc\nfrom sklearn.preprocessing import OrdinalEncoder, StandardScaler\n\n# import for visualization\nimport matplotlib.pyplot as plt\n\n# import for model building\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# import for Neural Network based model building\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Building State specific model | State 'TX'\n\nresult = {}\nstate='TX'\nresult['State']=state\nprocessed_data = pd.read_csv(f'/kaggle/working/data_{state}.csv').dropna()\ncols = processed_data.select_dtypes(include='object').columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Class Balancing | Using Up Sampling\n\n# Separate majority and minority classes\ndf_s1 = processed_data[processed_data['Severity']==1]\ndf_s2 = processed_data[processed_data['Severity']==2]\ndf_s3 = processed_data[processed_data['Severity']==3]\ndf_s4 = processed_data[processed_data['Severity']==4]\n\ncount = max(df_s1.count()[0], df_s2.count()[0], df_s3.count()[0], df_s4.count()[0])\n\n# Upsample minority class\ndf_s1 = resample(df_s1, replace=df_s1.count()[0]<count, n_samples=count, random_state=42)\ndf_s2 = resample(df_s2, replace=df_s2.count()[0]<count, n_samples=count, random_state=42)\ndf_s3 = resample(df_s3, replace=df_s3.count()[0]<count, n_samples=count, random_state=42)\ndf_s4 = resample(df_s4, replace=df_s4.count()[0]<count, n_samples=count, random_state=42)\n \n# Combine majority class with upsampled minority class\nprocessed_data = pd.concat([df_s1, df_s2, df_s3, df_s4])\n \n# Display new class counts\nprocessed_data.groupby(by='Severity')['Severity'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set the target for the prediction\ntarget='Severity' \n\n# set X and y\ny = processed_data[target]\nX = processed_data.drop(target, axis=1)\n\n# Create the encoder.\nencoder = OrdinalEncoder()\nX[cols] = encoder.fit_transform(X[cols])\n\n# Split the data set into training and testing data sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n\n# Split the data set into training and validation data sets\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, stratify=y_train, random_state=42)\n\n# Scalling the features of Train Dataset, Validation Dataset and Test Dataset\nscaler = StandardScaler()\n\n# Scaling Train Dataset\nscaler = scaler.fit(X_train)\nX_train = scaler.transform(X_train)\n\n# Scaling Validation Dataset\nscaler = scaler.fit(X_val)\nX_val = scaler.transform(X_val)\n\n# Scaling Test Dataset\nscaler = scaler.fit(X_test)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### VISUALIZING THE DATA ON MAP"},{"metadata":{"trusted":false},"cell_type":"code","source":"BBox = ((processed_data.Start_Lng.min(), processed_data.Start_Lng.max(), processed_data.Start_Lat.min(), processed_data.Start_Lat.max()))\nBBox","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"map_pic = plt.imread('/kaggle/working/map/map_pic_tx.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (30,17))\nax.scatter(processed_data[processed_data['Severity']==1].Start_Lng, processed_data[processed_data['Severity']==1].Start_Lat, zorder=1, c='b', s=4)\nax.scatter(processed_data[processed_data['Severity']==2].Start_Lng, processed_data[processed_data['Severity']==2].Start_Lat, zorder=1, c='g', s=6)\nax.scatter(processed_data[processed_data['Severity']==3].Start_Lng, processed_data[processed_data['Severity']==3].Start_Lat, zorder=1, c='y', s=8)\nax.scatter(processed_data[processed_data['Severity']==4].Start_Lng, processed_data[processed_data['Severity']==4].Start_Lat, zorder=1, c='r', s=10)\n\nax.set_xlim(BBox[0],BBox[1])\nax.set_ylim(BBox[2],BBox[3])\nax.imshow(map_pic, zorder=0, extent = BBox, aspect= 'auto', interpolation='none')\nax.imshow(map_pic, zorder=2, alpha= 0.5, extent = BBox, aspect= 'auto', interpolation='lanczos')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING SUPPORT VECTOR MACHINE"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Support Vector Machine | First Iteration\n\n# Instantiate an object of class SVC()\nclf = SVC(gamma='auto', kernel='rbf', random_state=42)\n\n# Train & Test (limiting rows since SVM takes much time)\nclf.fit(X_train[:10000], y_train[:10000])\ny_pred = clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Support Vector Machine accuracy_score: {:.3f}.\".format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Support Vector Machine | Optimization\n\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'C': [0.1, 0.5, 1],\n    'gamma': ['auto', 'scale']\n}\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(cv=5, estimator = clf, param_grid = param_grid, scoring='balanced_accuracy', n_jobs = -1,verbose = 5)\n\n# Fit the grid search to the Validation Dataset\ngrid_search.fit(X_val[:5000], y_val[:5000])\n\n# printing the optimal accuracy score and hyperparameters\nprint('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Support Vector Machine | Final Evaluation\n\n# Create a SVM Classifier\nclf=SVC(**grid_search.best_params_, random_state=42)\n\n# Train & Test\nclf.fit(X_train[:20000], y_train[:20000])\ny_train_pred= clf.predict(X_train[:20000])\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train[:20000], y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# stroring the accuracy score\nresult['Support Vector Machine'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting decent accuracy with SVM, but, the computation time is very high, even with limited dataset."},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING DECISION TREE"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Decision Tree Algorithm | First Iteration\n\n# Instantiate a Decision Tree Classifier\nclf = DecisionTreeClassifier(random_state=42)\n\n# Train & Test\nclf.fit(X_train, y_train)\ny_pred= clf.predict(X_test)\n\n# Print accuracy_entropy\nprint('Decision Tree accuracy_score: {:.3f}.'.format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Decision Tree Algorithm | Optimization\n\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'criterion': ['gini', 'entropy'],\n    'max_depth': [12, 14, 16],\n    'min_samples_split': [600, 1000],\n    'min_samples_leaf': [300, 500]\n}\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(cv=3, estimator = clf, param_grid = param_grid, scoring='balanced_accuracy', n_jobs = -1,verbose = 5)\n\n# Fit the grid search to the Validation Dataset\ngrid_search.fit(X_val, y_val)\n\n# printing the optimal accuracy score and hyperparameters\nprint('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Decision Tree Algorithm | Final Evaluation\n\n# Instantiate a Decision Tree Classifier with Best Parameters\nclf = DecisionTreeClassifier(**grid_search.best_params_, random_state=42)\n\n# Train & Test\nclf.fit(X_train, y_train)\ny_train_pred= clf.predict(X_train)\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# Highlighting the significance of each of the factors in the model\nfeature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\nprint(\"\\nImportant features:\\n\", feature_imp.sort_values(ascending=False)[:10])\n\n# stroring the accuracy score\nresult['Decision Tree'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting decent accuracy with Decision Tree algorithm and computation time is also comparatively less."},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING RANDOM FOREST"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Random Forest Algorithm | First Iteration\n\n# Create a Random Forest Classifier\nclf=RandomForestClassifier(n_estimators=100, bootstrap=False, min_samples_split=400, min_samples_leaf=100, n_jobs=-1, random_state=42)\n\n# Train & Test\nclf.fit(X_train,y_train)\ny_pred=clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Randon forest algorithm accuracy_score: {:.3f}.\".format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Random Forest Algorithm | Optimization\n\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'n_estimators': [100, 150, 200],\n    'max_depth': [14, 16, 18],\n    'min_samples_split': [100, 200],\n    'min_samples_leaf': [25, 50],\n    'bootstrap': [False]\n}\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(cv=5, estimator = clf, param_grid = param_grid, scoring='balanced_accuracy', n_jobs = -1,verbose = 5)\n\n# Fit the grid search to the Validation Dataset\ngrid_search.fit(X_val[:20000], y_val[:20000])\n\n# printing the optimal accuracy score and hyperparameters\nprint('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Random Forest Algorithm | Final Evaluation\n\n# Create a Random Forest Classifier\nclf=RandomForestClassifier(**grid_search.best_params_, n_jobs=-1, random_state=42)\n\n# Train & Test\nclf.fit(X_train, y_train)\ny_train_pred= clf.predict(X_train)\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# Highlighting the significance of each of the factors in the model\nfeature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\nprint(\"\\nImportant features:\\n\", feature_imp.sort_values(ascending=False)[:10])\n\n# stroring the accuracy score\nresult['Random Forest'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting good accuracy with Random Forest algorithm and computation time is also comparatively less."},{"metadata":{},"cell_type":"markdown","source":"#### EVALUATING ADDITIONAL ALGORITHM'S PERFORMANCE"},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING K-NEAREST NEIGHBOR (KNN)"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# K-Nearest Neighbor | First Iteration\n\n# Create a k-NN classifier\nclf = KNeighborsClassifier(n_jobs=-1)\n\n# Train & Test\nclf.fit(X_train[:20000], y_train[:20000])\ny_train_pred= clf.predict(X_train[:20000])\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train[:20000], y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# stroring the accuracy score\nresult['K-Nearest Neighbors'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting poor accuracy with K-Nearest Neighbor algorithm and the computation time is very high, even with limited dataset."},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING NEURAL NETWORK"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# Neural Network | First Iteration\n\nmodel = Sequential()\nmodel.add(Dense(128, input_dim=np.size(X_train,1), activation='relu'))\nmodel.add(Dense(64, input_dim=np.size(X_train,1), activation='relu'))\nmodel.add(Dense(5, activation='softmax'))\n\n# compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# build the model\nhistory = model.fit(X_train, to_categorical(y_train.to_numpy()), \n                    epochs=5, validation_data=(X_val, to_categorical(y_val.to_numpy())), \n                    validation_steps=30, verbose=0)\n\n\nloss, train_accuracy = model.evaluate(X_train, to_categorical(y_train.to_numpy()), verbose=0)\nprint(f\"\\nFor Training Dataset: Loss: {loss} and Accuracy: {train_accuracy}\")\n\nloss, test_accuracy = model.evaluate(X_test, to_categorical(y_test.to_numpy()), verbose=0)\nprint(f\"\\nFor Testing Dataset: Loss: {loss} and Accuracy: {test_accuracy}\")\n\n# stroring the accuracy score\nresult['Neural Network'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting decent accuracy with Neural Network and computation time is also comparatively less."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Saving the results in file\n\ndf = pd.DataFrame.from_dict(result)\ndf.set_index(['State'])\ndf.to_csv(f'/kaggle/working/result_{state}.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"___"},{"metadata":{},"cell_type":"markdown","source":"### Building ML Model for State 'FL'"},{"metadata":{},"cell_type":"markdown","source":"### Importing Libraries"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Deleting all data\n%reset -f\n\n# Reloading necessary libraries\n# import numpy and pandas\nimport pandas as pd\nimport numpy as np\n\n# import for pre-processing\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc\nfrom sklearn.preprocessing import OrdinalEncoder, StandardScaler\n\n# import for visualization\nimport matplotlib.pyplot as plt\n\n# import for model building\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# import for Neural Network based model building\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Building State specific model | State 'FL'\n\nresult = {}\nstate='FL'\nresult['State']=state\nprocessed_data = pd.read_csv(f'/kaggle/working/data_{state}.csv').dropna()\ncols = processed_data.select_dtypes(include='object').columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Class Balancing | Using Up Sampling\n\n# Separate majority and minority classes\ndf_s1 = processed_data[processed_data['Severity']==1]\ndf_s2 = processed_data[processed_data['Severity']==2]\ndf_s3 = processed_data[processed_data['Severity']==3]\ndf_s4 = processed_data[processed_data['Severity']==4]\n\ncount = max(df_s1.count()[0], df_s2.count()[0], df_s3.count()[0], df_s4.count()[0])\n\n# Upsample minority class\ndf_s1 = resample(df_s1, replace=df_s1.count()[0]<count, n_samples=count, random_state=42)\ndf_s2 = resample(df_s2, replace=df_s2.count()[0]<count, n_samples=count, random_state=42)\ndf_s3 = resample(df_s3, replace=df_s3.count()[0]<count, n_samples=count, random_state=42)\ndf_s4 = resample(df_s4, replace=df_s4.count()[0]<count, n_samples=count, random_state=42)\n \n# Combine majority class with upsampled minority class\nprocessed_data = pd.concat([df_s1, df_s2, df_s3, df_s4])\n \n# Display new class counts\nprocessed_data.groupby(by='Severity')['Severity'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set the target for the prediction\ntarget='Severity' \n\n# set X and y\ny = processed_data[target]\nX = processed_data.drop(target, axis=1)\n\n# Create the encoder.\nencoder = OrdinalEncoder()\nX[cols] = encoder.fit_transform(X[cols])\n\n# Split the data set into training and testing data sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n\n# Split the data set into training and validation data sets\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, stratify=y_train, random_state=42)\n\n# Scalling the features of Train Dataset, Validation Dataset and Test Dataset\nscaler = StandardScaler()\n\n# Scaling Train Dataset\nscaler = scaler.fit(X_train)\nX_train = scaler.transform(X_train)\n\n# Scaling Validation Dataset\nscaler = scaler.fit(X_val)\nX_val = scaler.transform(X_val)\n\n# Scaling Test Dataset\nscaler = scaler.fit(X_test)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### VISUALIZING THE DATA ON MAP"},{"metadata":{"trusted":false},"cell_type":"code","source":"BBox = ((processed_data.Start_Lng.min(), processed_data.Start_Lng.max(), processed_data.Start_Lat.min(), processed_data.Start_Lat.max()))\nBBox","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"map_pic = plt.imread('/kaggle/working/map/map_pic_fl.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (30,30))\nax.scatter(processed_data[processed_data['Severity']==1].Start_Lng, processed_data[processed_data['Severity']==1].Start_Lat, zorder=1, c='b', s=4)\nax.scatter(processed_data[processed_data['Severity']==2].Start_Lng, processed_data[processed_data['Severity']==2].Start_Lat, zorder=1, c='g', s=6)\nax.scatter(processed_data[processed_data['Severity']==3].Start_Lng, processed_data[processed_data['Severity']==3].Start_Lat, zorder=1, c='y', s=8)\nax.scatter(processed_data[processed_data['Severity']==4].Start_Lng, processed_data[processed_data['Severity']==4].Start_Lat, zorder=1, c='r', s=10)\n\nax.set_xlim(BBox[0],BBox[1])\nax.set_ylim(BBox[2],BBox[3])\nax.imshow(map_pic, zorder=0, extent = BBox, aspect= 'auto', interpolation='none')\nax.imshow(map_pic, zorder=2, alpha= 0.5, extent = BBox, aspect= 'auto', interpolation='lanczos')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING SUPPORT VECTOR MACHINE"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Support Vector Machine | First Iteration\n\n# Instantiate an object of class SVC()\nclf = SVC(gamma='auto', kernel='rbf', random_state=42)\n\n# Train & Test (limiting rows since SVM takes much time)\nclf.fit(X_train[:10000], y_train[:10000])\ny_pred = clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Support Vector Machine accuracy_score: {:.3f}.\".format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Support Vector Machine | Optimization\n\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'C': [0.1, 0.5, 1],\n    'gamma': ['auto', 'scale']\n}\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(cv=5, estimator = clf, param_grid = param_grid, scoring='balanced_accuracy', n_jobs = -1,verbose = 5)\n\n# Fit the grid search to the Validation Dataset\ngrid_search.fit(X_val[:5000], y_val[:5000])\n\n# printing the optimal accuracy score and hyperparameters\nprint('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Support Vector Machine | Final Evaluation\n\n# Create a SVM Classifier\nclf=SVC(**grid_search.best_params_, random_state=42)\n\n# Train & Test\nclf.fit(X_train[:20000], y_train[:20000])\ny_train_pred= clf.predict(X_train[:20000])\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train[:20000], y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# stroring the accuracy score\nresult['Support Vector Machine'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting decent accuracy with SVM, but, the computation time is very high, even with limited dataset."},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING DECISION TREE"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Decision Tree Algorithm | First Iteration\n\n# Instantiate a Decision Tree Classifier\nclf = DecisionTreeClassifier(random_state=42)\n\n# Train & Test\nclf.fit(X_train, y_train)\ny_pred= clf.predict(X_test)\n\n# Print accuracy_entropy\nprint('Decision Tree accuracy_score: {:.3f}.'.format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# Decision Tree Algorithm | Optimization\n\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'criterion': ['gini', 'entropy'],\n    'max_depth': [12, 14, 16],\n    'min_samples_split': [2000, 4000],\n    'min_samples_leaf': [1000, 2000]\n}\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(cv=3, estimator = clf, param_grid = param_grid, scoring='balanced_accuracy', n_jobs = -1,verbose = 5)\n\n# Fit the grid search to the Validation Dataset\ngrid_search.fit(X_val, y_val)\n\n# printing the optimal accuracy score and hyperparameters\nprint('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Decision Tree Algorithm | Final Evaluation\n\n# Instantiate a Decision Tree Classifier with Best Parameters\nclf = DecisionTreeClassifier(**grid_search.best_params_, random_state=42)\n\n# Train & Test\nclf.fit(X_train, y_train)\ny_train_pred= clf.predict(X_train)\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# Highlighting the significance of each of the factors in the model\nfeature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\nprint(\"\\nImportant features:\\n\", feature_imp.sort_values(ascending=False)[:10])\n\n# stroring the accuracy score\nresult['Decision Tree'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting decent accuracy with Decision Tree algorithm and computation time is also comparatively less."},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING RANDOM FOREST"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Random Forest Algorithm | First Iteration\n\n# Create a Random Forest Classifier\nclf=RandomForestClassifier(n_estimators=100, min_samples_split=400, min_samples_leaf=100, n_jobs=-1, random_state=42)\n\n# Train & Test\nclf.fit(X_train,y_train)\ny_pred=clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Randon forest algorithm accuracy_score: {:.3f}.\".format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Random Forest Algorithm | Optimization\n\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'n_estimators': [100, 150, 200],\n    'max_depth': [14, 16, 18],\n    'min_samples_split': [100, 200],\n    'min_samples_leaf': [25, 50],\n    'bootstrap': [False]\n}\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(cv=5, estimator = clf, param_grid = param_grid, scoring='balanced_accuracy', n_jobs = -1,verbose = 5)\n\n# Fit the grid search to the Validation Dataset\ngrid_search.fit(X_val[:20000], y_val[:20000])\n\n# printing the optimal accuracy score and hyperparameters\nprint('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Random Forest Algorithm | Final Evaluation\n\n# Create a Random Forest Classifier\nclf=RandomForestClassifier(**grid_search.best_params_, n_jobs=-1, random_state=42)\n\n# Train & Test\nclf.fit(X_train, y_train)\ny_train_pred= clf.predict(X_train)\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# Highlighting the significance of each of the factors in the model\nfeature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\nprint(\"\\nImportant features:\\n\", feature_imp.sort_values(ascending=False)[:10])\n\n# stroring the accuracy score\nresult['Random Forest'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting good accuracy with Random Forest algorithm and computation time is also comparatively less."},{"metadata":{},"cell_type":"markdown","source":"#### EVALUATING ADDITIONAL ALGORITHM'S PERFORMANCE"},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING K-NEAREST NEIGHBOR (KNN)"},{"metadata":{"trusted":false},"cell_type":"code","source":"# K-Nearest Neighbor | First Iteration\n\n# Create a k-NN classifier\nclf = KNeighborsClassifier(n_jobs=-1)\n\n# Train & Test\nclf.fit(X_train[:20000], y_train[:20000])\ny_train_pred= clf.predict(X_train[:20000])\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train[:20000], y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# stroring the accuracy score\nresult['K-Nearest Neighbors'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting poor accuracy with K-Nearest Neighbor algorithm and the computation time is very high, even with limited dataset."},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING NEURAL NETWORK"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# Neural Network | First Iteration\n\nmodel = Sequential()\nmodel.add(Dense(128, input_dim=np.size(X_train,1), activation='relu'))\nmodel.add(Dense(64, input_dim=np.size(X_train,1), activation='relu'))\nmodel.add(Dense(5, activation='softmax'))\n\n# compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# build the model\nhistory = model.fit(X_train, to_categorical(y_train.to_numpy()), \n                    epochs=5, validation_data=(X_val, to_categorical(y_val.to_numpy())), \n                    validation_steps=30, verbose=0)\n\n\nloss, train_accuracy = model.evaluate(X_train, to_categorical(y_train.to_numpy()), verbose=0)\nprint(f\"\\nFor Training Dataset: Loss: {loss} and Accuracy: {train_accuracy}\")\n\nloss, test_accuracy = model.evaluate(X_test, to_categorical(y_test.to_numpy()), verbose=0)\nprint(f\"\\nFor Testing Dataset: Loss: {loss} and Accuracy: {test_accuracy}\")\n\n# stroring the accuracy score\nresult['Neural Network'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting decent accuracy with Neural Network and computation time is also comparatively less."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Saving the results in file\n\ndf = pd.DataFrame.from_dict(result)\ndf.set_index(['State'])\ndf.to_csv(f'/kaggle/working/result_{state}.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"___"},{"metadata":{},"cell_type":"markdown","source":"### Building ML Model for State 'SC'"},{"metadata":{},"cell_type":"markdown","source":"### Importing Libraries"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Deleting all data\n%reset -f\n\n# Reloading necessary libraries\n# import numpy and pandas\nimport pandas as pd\nimport numpy as np\n\n# import for pre-processing\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc\nfrom sklearn.preprocessing import OrdinalEncoder, StandardScaler\n\n# import for visualization\nimport matplotlib.pyplot as plt\n\n# import for model building\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# import for Neural Network based model building\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Building State specific model | State 'SC'\n\nresult = {}\nstate='SC'\nresult['State']=state\nprocessed_data = pd.read_csv(f'/kaggle/working/data_{state}.csv').dropna()\ncols = processed_data.select_dtypes(include='object').columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Class Balancing | Using Up Sampling\n\n# Separate majority and minority classes\ndf_s1 = processed_data[processed_data['Severity']==1]\ndf_s2 = processed_data[processed_data['Severity']==2]\ndf_s3 = processed_data[processed_data['Severity']==3]\ndf_s4 = processed_data[processed_data['Severity']==4]\n\ncount = max(df_s1.count()[0], df_s2.count()[0], df_s3.count()[0], df_s4.count()[0])\n\n# Upsample minority class\ndf_s1 = resample(df_s1, replace=df_s1.count()[0]<count, n_samples=count, random_state=42)\ndf_s2 = resample(df_s2, replace=df_s2.count()[0]<count, n_samples=count, random_state=42)\ndf_s3 = resample(df_s3, replace=df_s3.count()[0]<count, n_samples=count, random_state=42)\ndf_s4 = resample(df_s4, replace=df_s4.count()[0]<count, n_samples=count, random_state=42)\n \n# Combine majority class with upsampled minority class\nprocessed_data = pd.concat([df_s1, df_s2, df_s3, df_s4])\n \n# Display new class counts\nprocessed_data.groupby(by='Severity')['Severity'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set the target for the prediction\ntarget='Severity' \n\n# set X and y\ny = processed_data[target]\nX = processed_data.drop(target, axis=1)\n\n# Create the encoder.\nencoder = OrdinalEncoder()\nX[cols] = encoder.fit_transform(X[cols])\n\n# Split the data set into training and testing data sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n\n# Split the data set into training and validation data sets\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, stratify=y_train, random_state=42)\n\n# Scalling the features of Train Dataset, Validation Dataset and Test Dataset\nscaler = StandardScaler()\n\n# Scaling Train Dataset\nscaler = scaler.fit(X_train)\nX_train = scaler.transform(X_train)\n\n# Scaling Validation Dataset\nscaler = scaler.fit(X_val)\nX_val = scaler.transform(X_val)\n\n# Scaling Test Dataset\nscaler = scaler.fit(X_test)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### VISUALIZING THE DATA ON MAP"},{"metadata":{"trusted":false},"cell_type":"code","source":"BBox = ((processed_data.Start_Lng.min(), processed_data.Start_Lng.max(), processed_data.Start_Lat.min(), processed_data.Start_Lat.max()))\nBBox","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"map_pic = plt.imread('/kaggle/working/map/map_pic_sc.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (34,26))\nax.scatter(processed_data[processed_data['Severity']==1].Start_Lng, processed_data[processed_data['Severity']==1].Start_Lat-0.01, zorder=1, c='b', s=4)\nax.scatter(processed_data[processed_data['Severity']==2].Start_Lng, processed_data[processed_data['Severity']==2].Start_Lat-0.01, zorder=1, c='g', s=6)\nax.scatter(processed_data[processed_data['Severity']==3].Start_Lng, processed_data[processed_data['Severity']==3].Start_Lat-0.01, zorder=1, c='y', s=8)\nax.scatter(processed_data[processed_data['Severity']==4].Start_Lng, processed_data[processed_data['Severity']==4].Start_Lat-0.01, zorder=1, c='r', s=10)\n\nax.set_xlim(BBox[0],BBox[1])\nax.set_ylim(BBox[2],BBox[3])\nax.imshow(map_pic, zorder=0, extent = BBox, aspect= 'auto', interpolation='none')\nax.imshow(map_pic, zorder=2, alpha= 0.5, extent = BBox, aspect= 'auto', interpolation='lanczos')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING SUPPORT VECTOR MACHINE"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Support Vector Machine | First Iteration\n\n# Instantiate an object of class SVC()\nclf = SVC(gamma='auto', kernel='rbf', random_state=42)\n\n# Train & Test (limiting rows since SVM takes much time)\nclf.fit(X_train[:10000], y_train[:10000])\ny_pred = clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Support Vector Machine accuracy_score: {:.3f}.\".format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Support Vector Machine | Optimization\n\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'C': [0.1, 0.5, 1],\n    'gamma': ['auto', 'scale']\n}\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(cv=5, estimator = clf, param_grid = param_grid, scoring='balanced_accuracy', n_jobs = -1,verbose = 5)\n\n# Fit the grid search to the Validation Dataset\ngrid_search.fit(X_val[:5000], y_val[:5000])\n\n# printing the optimal accuracy score and hyperparameters\nprint('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Support Vector Machine | Final Evaluation\n\n# Create a SVM Classifier\nclf=SVC(**grid_search.best_params_, random_state=42)\n\n# Train & Test\nclf.fit(X_train[:20000], y_train[:20000])\ny_train_pred= clf.predict(X_train[:20000])\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train[:20000], y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# stroring the accuracy score\nresult['Support Vector Machine'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting decent accuracy with SVM, but, the computation time is very high, even with limited dataset."},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING DECISION TREE"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Decision Tree Algorithm | First Iteration\n\n# Instantiate a Decision Tree Classifier\nclf = DecisionTreeClassifier(random_state=42)\n\n# Train & Test\nclf.fit(X_train, y_train)\ny_pred= clf.predict(X_test)\n\n# Print accuracy_entropy\nprint('Decision Tree accuracy_score: {:.3f}.'.format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Decision Tree Algorithm | Optimization\n\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'criterion': ['gini', 'entropy'],\n    'max_depth': [12, 14, 16],\n    'min_samples_split': [500, 1000],\n    'min_samples_leaf': [250, 500]\n}\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(cv=3, estimator = clf, param_grid = param_grid, scoring='balanced_accuracy', n_jobs = -1,verbose = 5)\n\n# Fit the grid search to the Validation Dataset\ngrid_search.fit(X_val, y_val)\n\n# printing the optimal accuracy score and hyperparameters\nprint('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Decision Tree Algorithm | Final Evaluation\n\n# Instantiate a Decision Tree Classifier with Best Parameters\nclf = DecisionTreeClassifier(**grid_search.best_params_, random_state=42)\n\n# Train & Test\nclf.fit(X_train, y_train)\ny_train_pred= clf.predict(X_train)\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# Highlighting the significance of each of the factors in the model\nfeature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\nprint(\"\\nImportant features:\\n\", feature_imp.sort_values(ascending=False)[:10])\n\n# stroring the accuracy score\nresult['Decision Tree'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting decent accuracy with Decision Tree algorithm and computation time is also comparatively less."},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING RANDOM FOREST"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Random Forest Algorithm | First Iteration\n\n# Create a Random Forest Classifier\nclf=RandomForestClassifier(n_estimators=100, min_samples_split=400, min_samples_leaf=100, n_jobs=-1, random_state=42)\n\n# Train & Test\nclf.fit(X_train,y_train)\ny_pred=clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Randon forest algorithm accuracy_score: {:.3f}.\".format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Random Forest Algorithm | Optimization\n\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'n_estimators': [100, 150, 200],\n    'max_depth': [12, 14, 16],\n    'min_samples_split': [100, 200],\n    'min_samples_leaf': [25, 50],\n    'bootstrap': [False]\n}\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(cv=5, estimator = clf, param_grid = param_grid, scoring='balanced_accuracy', n_jobs = -1,verbose = 5)\n\n# Fit the grid search to the Validation Dataset\ngrid_search.fit(X_val[:20000], y_val[:20000])\n\n# printing the optimal accuracy score and hyperparameters\nprint('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Random Forest Algorithm | Final Evaluation\n\n# Create a Random Forest Classifier\nclf=RandomForestClassifier(**grid_search.best_params_, n_jobs=-1, random_state=42)\n\n# Train & Test\nclf.fit(X_train, y_train)\ny_train_pred= clf.predict(X_train)\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# Highlighting the significance of each of the factors in the model\nfeature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\nprint(\"\\nImportant features:\\n\", feature_imp.sort_values(ascending=False)[:10])\n\n# stroring the accuracy score\nresult['Random Forest'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting good accuracy with Random Forest algorithm and computation time is also comparatively less."},{"metadata":{},"cell_type":"markdown","source":"#### EVALUATING ADDITIONAL ALGORITHM'S PERFORMANCE"},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING K-NEAREST NEIGHBOR (KNN)"},{"metadata":{"trusted":false},"cell_type":"code","source":"# K-Nearest Neighbor | First Iteration\n\n# Create a k-NN classifier\nclf = KNeighborsClassifier(n_jobs=-1)\n\n# Train & Test\nclf.fit(X_train[:20000], y_train[:20000])\ny_train_pred= clf.predict(X_train[:20000])\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train[:20000], y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# stroring the accuracy score\nresult['K-Nearest Neighbors'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting poor accuracy with K-Nearest Neighbor algorithm and the computation time is very high, even with limited dataset."},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING NEURAL NETWORK"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# Neural Network | First Iteration\n\nmodel = Sequential()\nmodel.add(Dense(128, input_dim=np.size(X_train,1), activation='relu'))\nmodel.add(Dense(64, input_dim=np.size(X_train,1), activation='relu'))\nmodel.add(Dense(5, activation='softmax'))\n\n# compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# build the model\nhistory = model.fit(X_train, to_categorical(y_train.to_numpy()), \n                    epochs=5, validation_data=(X_val, to_categorical(y_val.to_numpy())), \n                    validation_steps=30, verbose=0)\n\n\nloss, train_accuracy = model.evaluate(X_train, to_categorical(y_train.to_numpy()), verbose=0)\nprint(f\"\\nFor Training Dataset: Loss: {loss} and Accuracy: {train_accuracy}\")\n\nloss, test_accuracy = model.evaluate(X_test, to_categorical(y_test.to_numpy()), verbose=0)\nprint(f\"\\nFor Testing Dataset: Loss: {loss} and Accuracy: {test_accuracy}\")\n\n# stroring the accuracy score\nresult['Neural Network'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting decent accuracy with Neural Network and computation time is also comparatively less."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Saving the results in file\n\ndf = pd.DataFrame.from_dict(result)\ndf.set_index(['State'])\ndf.to_csv(f'/kaggle/working/result_{state}.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"___"},{"metadata":{},"cell_type":"markdown","source":"### Building ML Model for State 'NC'"},{"metadata":{},"cell_type":"markdown","source":"### Importing Libraries"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Deleting all data\n%reset -f\n\n# Reloading necessary libraries\n# import numpy and pandas\nimport pandas as pd\nimport numpy as np\n\n# import for pre-processing\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc\nfrom sklearn.preprocessing import OrdinalEncoder, StandardScaler\n\n# import for visualization\nimport matplotlib.pyplot as plt\n\n# import for model building\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# import for Neural Network based model building\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Building State specific model | State 'NC'\n\nresult = {}\nstate='NC'\nresult['State']=state\nprocessed_data = pd.read_csv(f'/kaggle/working/data_{state}.csv').dropna()\ncols = processed_data.select_dtypes(include='object').columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Class Balancing | Using Up Sampling\n\n# Separate majority and minority classes\ndf_s1 = processed_data[processed_data['Severity']==1]\ndf_s2 = processed_data[processed_data['Severity']==2]\ndf_s3 = processed_data[processed_data['Severity']==3]\ndf_s4 = processed_data[processed_data['Severity']==4]\n\ncount = max(df_s1.count()[0], df_s2.count()[0], df_s3.count()[0], df_s4.count()[0])\n\n# Upsample minority class\ndf_s1 = resample(df_s1, replace=df_s1.count()[0]<count, n_samples=count, random_state=42)\ndf_s2 = resample(df_s2, replace=df_s2.count()[0]<count, n_samples=count, random_state=42)\ndf_s3 = resample(df_s3, replace=df_s3.count()[0]<count, n_samples=count, random_state=42)\ndf_s4 = resample(df_s4, replace=df_s4.count()[0]<count, n_samples=count, random_state=42)\n \n# Combine majority class with upsampled minority class\nprocessed_data = pd.concat([df_s1, df_s2, df_s3, df_s4])\n \n# Display new class counts\nprocessed_data.groupby(by='Severity')['Severity'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Set the target for the prediction\ntarget='Severity' \n\n# set X and y\ny = processed_data[target]\nX = processed_data.drop(target, axis=1)\n\n# Create the encoder.\nencoder = OrdinalEncoder()\nX[cols] = encoder.fit_transform(X[cols])\n\n# Split the data set into training and testing data sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n\n# Split the data set into training and validation data sets\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, stratify=y_train, random_state=42)\n\n# Scalling the features of Train Dataset, Validation Dataset and Test Dataset\nscaler = StandardScaler()\n\n# Scaling Train Dataset\nscaler = scaler.fit(X_train)\nX_train = scaler.transform(X_train)\n\n# Scaling Validation Dataset\nscaler = scaler.fit(X_val)\nX_val = scaler.transform(X_val)\n\n# Scaling Test Dataset\nscaler = scaler.fit(X_test)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### VISUALIZING THE DATA ON MAP"},{"metadata":{"trusted":false},"cell_type":"code","source":"BBox = ((processed_data.Start_Lng.min(), processed_data.Start_Lng.max(), processed_data.Start_Lat.min(), processed_data.Start_Lat.max()))\nBBox","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"map_pic = plt.imread('/kaggle/working/map/map_pic_nc.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (31,12))\nax.scatter(processed_data[processed_data['Severity']==1].Start_Lng, processed_data[processed_data['Severity']==1].Start_Lat, zorder=1, c='b', s=4)\nax.scatter(processed_data[processed_data['Severity']==2].Start_Lng, processed_data[processed_data['Severity']==2].Start_Lat, zorder=1, c='g', s=6)\nax.scatter(processed_data[processed_data['Severity']==3].Start_Lng, processed_data[processed_data['Severity']==3].Start_Lat, zorder=1, c='y', s=8)\nax.scatter(processed_data[processed_data['Severity']==4].Start_Lng, processed_data[processed_data['Severity']==4].Start_Lat, zorder=1, c='r', s=10)\n\nax.set_xlim(BBox[0],BBox[1])\nax.set_ylim(BBox[2],BBox[3])\nax.imshow(map_pic, zorder=0, extent = BBox, aspect= 'auto', interpolation='none')\nax.imshow(map_pic, zorder=2, alpha= 0.5, extent = BBox, aspect= 'auto', interpolation='lanczos')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING SUPPORT VECTOR MACHINE"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Support Vector Machine | First Iteration\n\n# Instantiate an object of class SVC()\nclf = SVC(gamma='auto', kernel='rbf', random_state=42)\n\n# Train & Test (limiting rows since SVM takes much time)\nclf.fit(X_train[:10000], y_train[:10000])\ny_pred = clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Support Vector Machine accuracy_score: {:.3f}.\".format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Support Vector Machine | Optimization\n\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'C': [0.1, 0.5, 1],\n    'gamma': ['auto', 'scale']\n}\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(cv=5, estimator = clf, param_grid = param_grid, scoring='balanced_accuracy', n_jobs = -1,verbose = 5)\n\n# Fit the grid search to the Validation Dataset\ngrid_search.fit(X_val[:5000], y_val[:5000])\n\n# printing the optimal accuracy score and hyperparameters\nprint('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Support Vector Machine | Final Evaluation\n\n# Create a SVM Classifier\nclf=SVC(**grid_search.best_params_, random_state=42)\n\n# Train & Test\nclf.fit(X_train[:20000], y_train[:20000])\ny_train_pred= clf.predict(X_train[:20000])\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train[:20000], y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# stroring the accuracy score\nresult['Support Vector Machine'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting decent accuracy with SVM, but, the computation time is very high, even with limited dataset."},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING DECISION TREE"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Decision Tree Algorithm | First Iteration\n\n# Instantiate a Decision Tree Classifier\nclf = DecisionTreeClassifier(random_state=42)\n\n# Train & Test\nclf.fit(X_train, y_train)\ny_pred= clf.predict(X_test)\n\n# Print accuracy_entropy\nprint('Decision Tree accuracy_score: {:.3f}.'.format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Decision Tree Algorithm | Optimization\n\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'criterion': ['gini', 'entropy'],\n    'max_depth': [12, 14, 16],\n    'min_samples_split': [1000, 2000],\n    'min_samples_leaf': [500, 1000]\n}\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(cv=3, estimator = clf, param_grid = param_grid, scoring='balanced_accuracy', n_jobs = -1,verbose = 5)\n\n# Fit the grid search to the Validation Dataset\ngrid_search.fit(X_val, y_val)\n\n# printing the optimal accuracy score and hyperparameters\nprint('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Decision Tree Algorithm | Final Evaluation\n\n# Instantiate a Decision Tree Classifier with Best Parameters\nclf = DecisionTreeClassifier(**grid_search.best_params_, random_state=42)\n\n# Train & Test\nclf.fit(X_train, y_train)\ny_train_pred= clf.predict(X_train)\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# Highlighting the significance of each of the factors in the model\nfeature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\nprint(\"\\nImportant features:\\n\", feature_imp.sort_values(ascending=False)[:10])\n\n# stroring the accuracy score\nresult['Decision Tree'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting decent accuracy with Decision Tree algorithm and computation time is also comparatively less."},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING RANDOM FOREST"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Random Forest Algorithm | First Iteration\n\n# Create a Random Forest Classifier\nclf=RandomForestClassifier(n_estimators=100, min_samples_split=400, min_samples_leaf=100, n_jobs=-1, random_state=42)\n\n# Train & Test\nclf.fit(X_train,y_train)\ny_pred=clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\nprint(\"Randon forest algorithm accuracy_score: {:.3f}.\".format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Random Forest Algorithm | Optimization\n\n# Create the parameter grid based on the results of random search \nparam_grid = {\n    'n_estimators': [100, 150, 200],\n    'max_depth': [12, 14, 16],\n    'min_samples_split': [100, 200],\n    'min_samples_leaf': [25, 50],\n    'bootstrap': [False]\n}\n\n# Instantiate the grid search model\ngrid_search = GridSearchCV(cv=5, estimator = clf, param_grid = param_grid, scoring='balanced_accuracy', n_jobs = -1,verbose = 5)\n\n# Fit the grid search to the Validation Dataset\ngrid_search.fit(X_val[:20000], y_val[:20000])\n\n# printing the optimal accuracy score and hyperparameters\nprint('We can get accuracy of',grid_search.best_score_,'using',grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Random Forest Algorithm | Final Evaluation\n\n# Create a Random Forest Classifier\nclf=RandomForestClassifier(**grid_search.best_params_, n_jobs=-1, random_state=42)\n\n# Train & Test\nclf.fit(X_train, y_train)\ny_train_pred= clf.predict(X_train)\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# Highlighting the significance of each of the factors in the model\nfeature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\nprint(\"\\nImportant features:\\n\", feature_imp.sort_values(ascending=False)[:10])\n\n# stroring the accuracy score\nresult['Random Forest'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting good accuracy with Random Forest algorithm and computation time is also comparatively less."},{"metadata":{},"cell_type":"markdown","source":"#### EVALUATING ADDITIONAL ALGORITHM'S PERFORMANCE"},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING K-NEAREST NEIGHBOR (KNN)"},{"metadata":{"trusted":false},"cell_type":"code","source":"# K-Nearest Neighbor | First Iteration\n\n# Create a k-NN classifier\nclf = KNeighborsClassifier(n_jobs=-1)\n\n# Train & Test\nclf.fit(X_train[:20000], y_train[:20000])\ny_train_pred= clf.predict(X_train[:20000])\ny_test_pred= clf.predict(X_test)\n\n# Model Accuracy, how often is the classifier correct?\n# Detailed report of classification done by model\n\ntrain_accuracy, test_accuracy = accuracy_score(y_train[:20000], y_train_pred), accuracy_score(y_test, y_test_pred)\nprint(classification_report(y_test, y_test_pred))\nprint(f'Accuracy for the train dataset {train_accuracy:.1%}')\nprint(f'Accuracy for the test dataset {test_accuracy:.1%}')\n\n# stroring the accuracy score\nresult['K-Nearest Neighbors'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting poor accuracy with K-Nearest Neighbor algorithm and the computation time is very high, even with limited dataset."},{"metadata":{},"cell_type":"markdown","source":"#### BUILDING MODEL USING NEURAL NETWORK"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# Neural Network | First Iteration\n\nmodel = Sequential()\nmodel.add(Dense(128, input_dim=np.size(X_train,1), activation='relu'))\nmodel.add(Dense(64, input_dim=np.size(X_train,1), activation='relu'))\nmodel.add(Dense(5, activation='softmax'))\n\n# compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# build the model\nhistory = model.fit(X_train, to_categorical(y_train.to_numpy()), \n                    epochs=5, validation_data=(X_val, to_categorical(y_val.to_numpy())), \n                    validation_steps=30, verbose=0)\n\n\nloss, train_accuracy = model.evaluate(X_train, to_categorical(y_train.to_numpy()), verbose=0)\nprint(f\"\\nFor Training Dataset: Loss: {loss} and Accuracy: {train_accuracy}\")\n\nloss, test_accuracy = model.evaluate(X_test, to_categorical(y_test.to_numpy()), verbose=0)\nprint(f\"\\nFor Testing Dataset: Loss: {loss} and Accuracy: {test_accuracy}\")\n\n# stroring the accuracy score\nresult['Neural Network'] = ['Train: '+str(round(train_accuracy*100, 1))+', Test: '+str(round(test_accuracy*100,1))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Summary**: We are getting decent accuracy with Neural Network and computation time is also comparatively less."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Saving the results in file\n\ndf = pd.DataFrame.from_dict(result)\ndf.set_index(['State'])\ndf.to_csv(f'/kaggle/working/result_{state}.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"___"},{"metadata":{},"cell_type":"markdown","source":"## Combined Results of Models on Datasets of States"},{"metadata":{"trusted":false},"cell_type":"code","source":"df = pd.concat([\n    pd.read_csv('/kaggle/working/result_CA.csv'),pd.read_csv('/kaggle/working/result_TX.csv'),\n    pd.read_csv('/kaggle/working/result_FL.csv'),pd.read_csv('/kaggle/working/result_SC.csv'),\n    pd.read_csv('/kaggle/working/result_NC.csv')]).set_index(['State'])\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"___"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}