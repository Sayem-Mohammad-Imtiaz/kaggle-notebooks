{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Finance Project: Deep Neural Network","metadata":{}},{"cell_type":"markdown","source":"## Supervised machine learning algorithm using Lending Club dataset.","metadata":{}},{"cell_type":"markdown","source":"# Description:\n### While staring into the future through a crytal ball is a myth, technology can help investors to seek true sight in their investment prospects. It is the financial institutes' dream to grasp the untapped knowledge what is the return on investment in a given project. This is an interesting project to uncover the risky versus the high-profitable loan borrowers in the ocean of dataset. ","metadata":{}},{"cell_type":"markdown","source":"# Project Objective: \n### To develop a supervised machine learning model to identify which borrowers will payoff their loans. The project implications can be beneficial to the financial institute in risk assessments, whether the prospective borrower would default or payoff the loan. Strategy for loan approval and profitable target market can be identified. Ultimately, this model serves as the blueprint to decrease bussiness risks and increase profitability of the organization.","metadata":{}},{"cell_type":"markdown","source":"# Predictive Model: Deep Neural Network\n### Real life dataset by one of the financial powerhouses, Lending Club. Supervised machine learning deep neural network will be used to perform binary classification. In this project, the target feature or y-variable will be \"Loan Status\".  ","metadata":{}},{"cell_type":"markdown","source":"# Process:\n### This project will start off with exploratory data analysis, data visualization, feature-engineering, and preparing the dataset for machine learning. The end result the accuracy of the model to predict payoff or default loan. ","metadata":{}},{"cell_type":"markdown","source":"### Importing libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/lending-club-loan/lending_club_loan_two.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This is a large dataset, which has ~396000 observations as shown below.  Noted that they are float and object data type. ","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing loan payoff vs chargeoff. ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,7))\nsns.set_context(\"paper\")\nsns.countplot(x=\"loan_status\", data=data, palette=\"Spectral\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing the distribution of loan amount borrowed.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,7))\nsns.set_context(\"paper\", font_scale=2)\nsns.distplot(data[\"loan_amnt\"], bins=15, kde=False, color=\"seagreen\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Descriptive analysis and correlation of features. ","metadata":{}},{"cell_type":"code","source":"data.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Noted that loan amount and interest rate has high correlation,, which is expected. Total account & open account also has high correlation. Lastly, public record and bankcruptcies, which also makes sense. ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,7))\nsns.set_context(\"poster\", font_scale=0.5)\nsns.heatmap(data.corr(), annot=True, cmap=\"coolwarm\", alpha=0.6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing the relationship between installment and loan amount.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,7))\nsns.scatterplot(x=\"installment\", y=\"loan_amnt\", data=data, alpha=0.8, hue=\"loan_status\", palette=\"RdYlBu\" )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Noted that there is only a slight difference in full paid and charged off on loan amount. ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,7))\nsns.boxplot(x=\"loan_status\", y=\"loan_amnt\", data=data, palette=\"plasma\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby(\"loan_status\")[\"loan_amnt\"].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Diving in the feature \"grade\", presumably the level of worthiness of the borrowers. ","metadata":{}},{"cell_type":"code","source":"data[\"grade\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing the relationship between the grade and loan status. As expected, borrowers tend to have a higher charged off in lower grade categories. This shows that the grade can potentially be a good indicator if the borrower has the ability to payoff or default.  ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,7))\nsns.set_context(\"paper\", font_scale=2)\nsns.countplot(x=\"grade\", data=data, hue=\"loan_status\", color=\"seagreen\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing in a sorted order of grade gives a better understanding of the impact of grade in loan status. The lower the grade, the higher the ratio in fully paid to charged off.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,7))\nsns.set_context(\"paper\", font_scale=2)\nsorted_grade = sorted(data[\"grade\"].unique())\nsns.countplot(x=\"grade\", data=data, hue=\"loan_status\", color=\"seagreen\", order=sorted_grade)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"loan_status\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"loan_repaid\"] = data[\"loan_status\"].map({\"Fully Paid\":1, \"Charged Off\":0})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[[\"loan_repaid\", \"loan_status\"]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing the correlation between \"loan repaid\" and other features. Noted that interest rate has relatively high correlation compared to the rest. This is expected as the higher the interest rate, the harder it is to pay off a loan.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,7))\ndata.corr()[\"loan_repaid\"].sort_values().drop(\"loan_repaid\").plot(kind=\"bar\", color=\"seagreen\", alpha=0.6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dealing with missing values. The number of features that have missing values is shown below. The number of missing values in each feature will determine the treatment of the feature; to drop or replace it with some other values. ","metadata":{}},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum() / len(data) * 100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"emp_title\"].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"emp_title\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The employment title feature has >170000 unique values. It is not feasible to keep them as a feature to be used in our machine learning model. Will just drop it. ","metadata":{}},{"cell_type":"code","source":"data = data.drop(\"emp_title\", axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted(data[\"emp_length\"].dropna().unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted_emp_length = ['< 1 year',\n '1 year',\n '2 years',\n '3 years',\n '4 years',\n '5 years',\n '6 years',\n '7 years',\n '8 years',\n '9 years',\n '10+ years']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing the employment length feature. It appears that most of the borrowers have >10yrs employment length, meaning most of the borrowers are middle-aged adults and/or matured instead of young adults. ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16,7))\nsns.set_context(\"paper\", font_scale=1.5)\nsns.countplot(x=\"emp_length\", data=data, hue=\"loan_status\", order=sorted_emp_length, palette=\"coolwarm\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emp_co = data[data[\"loan_status\"] == \"Charged Off\"].groupby(\"emp_length\").count()[\"loan_status\"]\nemp_fp = data[data[\"loan_status\"] == \"Fully Paid\"].groupby(\"emp_length\").count()[\"loan_status\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emp_length_graph = emp_co/(emp_co+emp_fp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing the number of charged off and total borrowers in percentage in each intervals of employment length. They are relatively the same across the board shown in the graph below.","metadata":{}},{"cell_type":"code","source":"emp_length_graph.plot(kind=\"bar\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The employment length feature does not really help us to distinguish borrowers who payoff or default. Will just drop. ","metadata":{}},{"cell_type":"code","source":"data = data.drop(\"emp_length\", axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"purpose\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing the loan purpose feature. It is apparent that top reason to borrow loans from Lending Club is debt consolidation as provided by borrowers. This is matches with common perception that people often attempt to pay off high interest rate credit card accounts with unsecured personal loan.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(18,7))\nsns.set_context(\"paper\", font_scale=1)\nsns.countplot(x=\"purpose\", data=data, hue=\"loan_status\", palette=\"seismic\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"title\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### It appears that the feature \"title\" provides the same information as loan purpose. Will drop this feature. ","metadata":{}},{"cell_type":"code","source":"data = data.drop(\"title\", axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"mort_acc\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Recalling that mortage account feature has ~38000 missing values. This is pretty significant as dropping this feature will significantly reduce the size of the dataset. It is probably a good idea to replace the missing values with some other values. After checking out the correlation of mortageg with other features, it is noted that total account has the highest correlation with mortgage account. it is not surprising that people have more mortgages when they have more accounts. ","metadata":{}},{"cell_type":"code","source":"data.corr()[\"mort_acc\"].sort_values()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Decided to replace missing values in mortgage account with the mean value based on the total account. ","metadata":{}},{"cell_type":"code","source":"total_acc_avg = data.groupby(\"total_acc\").mean()[\"mort_acc\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fill_in_mort_acc(total_acc, mort_acc):\n    \n    if np.isnan(mort_acc):\n        return total_acc_avg[total_acc]\n    else:\n        return(mort_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Replacing the missing values with lambda function. ","metadata":{}},{"cell_type":"code","source":"data[\"mort_acc\"] = data.apply(lambda x: fill_in_mort_acc(x[\"total_acc\"], x[\"mort_acc\"]), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Finding out the current standing of our missing values. Since the remaining 2 features have very low missing values, decided to just drop those missing values as it is more time-saving. ","metadata":{}},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.dropna()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dealing with non-numeric type of data","metadata":{}},{"cell_type":"code","source":"data.select_dtypes([\"object\"]).columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"term\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Grabbing the numeric values \"36\" and \"60\".","metadata":{}},{"cell_type":"code","source":"data[\"term\"] = data[\"term\"].apply(lambda term: int(term[:3]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"term\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Since sub-grade provides more information than grade, this featue will be dropped. ","metadata":{}},{"cell_type":"code","source":"data = data.drop(\"grade\", axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preparing the data with binary classification (dummy data).","metadata":{}},{"cell_type":"code","source":"dummy = pd.get_dummies(data[\"sub_grade\"], drop_first=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.concat([data.drop(\"sub_grade\", axis=1), dummy], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"verification_status\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"application_type\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"initial_list_status\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy = pd.get_dummies(data[[\"verification_status\", \"application_type\", \"initial_list_status\", \"purpose\"]], drop_first=True)\ndata = pd.concat([data.drop([\"verification_status\", \"application_type\", \"initial_list_status\", \"purpose\"], axis=1), dummy], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"home_ownership\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"home_ownership\"] = data[\"home_ownership\"].replace([\"NONE\", \"ANY\"], \"OTHER\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"home_ownership\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy = pd.get_dummies(data[\"home_ownership\"], drop_first=True)\ndata = pd.concat([data.drop(\"home_ownership\", axis=1), dummy], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Four more features with object as data type to deal with.","metadata":{}},{"cell_type":"code","source":"data.select_dtypes(\"object\").columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"address\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Address has no values in our machine learning model but the ZIP code may have some sort of influence in the outcome. Grabbing the ZIP code from the address. ","metadata":{}},{"cell_type":"code","source":"data[\"zip_code\"] = data[\"address\"].apply(lambda address: address[-5:])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"zip_code\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Noted that the newly engineered feature of ZIP has only a few unique counts so it is feasible to keep this feature. Getting dummy data on this feature. ","metadata":{}},{"cell_type":"code","source":"dummy = pd.get_dummies(data[\"zip_code\"], drop_first=True)\ndata = pd.concat([data.drop(\"zip_code\", axis=1), dummy], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.drop(\"address\", axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.drop(\"issue_d\", axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"earliest_cr_line\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The feature \"Earliest credit line\" may be a key factor as it provides some sort of a time series information. Grabbing the year as our tim series feature. ","metadata":{}},{"cell_type":"code","source":"data[\"earliest_cr_line\"] = data[\"earliest_cr_line\"].apply(lambda year: int(year[-4:]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"earliest_cr_line\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.select_dtypes(\"object\").columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Recalling that we have converted \"fully paid\" and \"charged off\" with binary digits, it is safe to just drop the original feature. ","metadata":{}},{"cell_type":"code","source":"data = data.drop(\"loan_status\", axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Data cleansing process and feature-engineering complete. The dataset now has 79 features. Now preparing for training data and test data. ","metadata":{}},{"cell_type":"code","source":"data.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Trainning data will be set at 80% of the dataset and test size is 20%. Random state will be set at 42, which is arbitrary - I heard 42 is THE number of universe, life, and everything :)","metadata":{}},{"cell_type":"markdown","source":"#### The target feature or y-variable is \"loan repaid\" (yes = 1; no = 0). ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data.drop(\"loan_repaid\", axis=1).values\ny = data[\"loan_repaid\"].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Scalar is used when preparing the dataset for deep learning so the data will have a more meaningful relationship among features. This can enable the machine to learn the data better. ","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = MinMaxScaler()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = scaler.fit_transform(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = scaler.transform(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preparation is complete. Importing deep neural network libraries. ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.models import Sequential","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Recalling the dataset has ~310000 observations and 78 features. ","metadata":{}},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Setting \"rectified linear unit\" as the activation function in neural network as this is a commonly used activation. Dense will be set at 78, which is an arbitrary number, as the first layer, then followed by half of it and so forth. On the final layer of the neural network, the \"sigmoid\" is used as the activation function, which is sorta similar to logistic regression. For loss function, the binary cross entropy will be used since this is a binary classification model. Optimizer is set as Adam is this is the most commonly used. ","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Dense(78, activation=\"relu\"))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(39, activation=\"relu\"))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(19, activation=\"relu\"))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(1, activation=\"sigmoid\"))\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Setting epochs as 25, which is also an arbitrary number; the batch size is set at 256 (64-bit ~ personal preference).","metadata":{}},{"cell_type":"code","source":"model.fit(X_train, y_train, epochs=25, batch_size=256, validation_data=(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"losses = pd.DataFrame(model.history.history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Loss function graph to see the performance of the deep neural network model. Noted that the loss funtion decreased sharply at the beginning, which is desirable, then trending down slowly below the validation loss. ","metadata":{}},{"cell_type":"code","source":"losses.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evalution of the supervised machine learning deep neural network performance. ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict_classes(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, prediction))\nprint(confusion_matrix(y_test, prediction))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Noted that the recall value is 100% on 1s and precision at 98% on 0s. This model did not do so well in recall on 0s, only at 44%, which is pretty significant. The f1-score on 1 is 94%, which is pretty good. Overall, the prediction against the true positive is 90%, which is pretty good IMO. The overall accuracy yields 89%, which is much better than a random guess. The deep neural network algorithm can be further optimized using Earlystopping and dropout. ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}