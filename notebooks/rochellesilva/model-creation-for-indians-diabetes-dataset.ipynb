{"cells":[{"metadata":{"_uuid":"803b61be78cb757df543512c57fd913c16946d43"},"cell_type":"markdown","source":"# Pima Indians Diabetes dataset from Kaggle\n\n\n### Data & Objective\n\nIn this Kernel I present a short analysis of the \"Pima Indians Diabetes Database\" provided by UCI Machine Learning in Kaggle, which is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. You can download it from [here](https://www.kaggle.com/uciml/pima-indians-diabetes-database/data). All patients from this dataset are females at least 21 years old of Pima Indian heritage.\n\nThe objective is to predict the onset of diabetes based on diagnostic measures present in the dataset provided.\n\nThis Kernel is devided into 3 parts:\n\n### 1. First Insights\n  Get to know the data.\n  - How many samples and features do we have?\n  - What type of features do we have? \n  - How are they distributed?\n  - Do we have null values?\n\n### 2. Model creation & Validation\n   - Before model creation first we need to separate into features and labels. Then check if the features need some pre-processing. For example for this dataset some Scaling could be useful.\n   - Divide dataset into Train/Test. Test set will not be used for model creation keep it aside!! Train set will be used for training and validation using the k-fold cross validation technique.\n   - I will use two classifiers: \n     - **Random Forest**\n     - **Logistic Regression**  \n\n### 3. Test final model with unseen data\n Once you have chosen the final model in step **2.** we will use that same model to predict the labels of the Test set we kept aside. This will allow to evaluate if the model we created is not overfit and can get also good results for unseen data.\n\n\n\n"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"b36b9acf4ae2919eb9e82a7a6773cfc6bc92db6b"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn import cross_validation\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n%matplotlib inline","execution_count":62,"outputs":[]},{"metadata":{"_uuid":"8bcbc6328d4a8a279b38abbfd804dc2b681dda6f"},"cell_type":"markdown","source":"### 1. First Insights"},{"metadata":{"trusted":false,"_uuid":"351fd3c165b296b401c51a0025b40e4da7dd30d6","collapsed":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/diabetes.csv\")\ndf.head()","execution_count":63,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"920152fa236c49979fe8ca37cd788361055cbc63","collapsed":true},"cell_type":"code","source":"df.shape","execution_count":64,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d284a322ae6e381d75856f9856f6010670d1dfbb","collapsed":true},"cell_type":"code","source":"df.describe()","execution_count":65,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c2868bc34a187de11db0fc063dc21599790feceb","collapsed":true},"cell_type":"code","source":"df.info()\ndf.columns","execution_count":66,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ebab71b9c875534375f983feac5841d49594df00","collapsed":true},"cell_type":"code","source":"Counter(df.Outcome)","execution_count":67,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"56ed39a3fffb10fe6c60e3ee194856b540bdccde","collapsed":true},"cell_type":"code","source":"sns.countplot(x='Outcome',data=df)","execution_count":68,"outputs":[]},{"metadata":{"_uuid":"1266a77ae6259d1b022518f24c50c047f3d79106"},"cell_type":"markdown","source":"We have a quite **IMBALANCED DATASET**! Thus, it is really important to check not only **accuracy** but also **sensitivity** (how well it classifies the positive class) and **specificity** (how well it classifies the negative class). In this case, as the negative class is almost double the positive class, we are prone to get high specificity but low sensitivity. So remember this concern when evaluating the model.      "},{"metadata":{"trusted":false,"_uuid":"bbfdec543a10bb8f08bf9a91312f2756b9414821","collapsed":true},"cell_type":"code","source":"df_1 = df[df.Outcome == 1]\ndf_0 = df[df.Outcome == 0]\ncolumns = df.columns[:-1]\n\nplt.subplots(figsize=(16,10))\nnumber_features = len(columns)\nfor i,j,  in zip(columns, range(number_features) ):\n    plt.subplot(3,3,j+1)\n    plt.subplots_adjust(wspace=0.5,hspace=0.5)\n    df_0[i].hist(bins=20, color='b', edgecolor='black')\n    df_1[i].hist(bins=20, color='r', edgecolor='black')\n    plt.title(i)","execution_count":69,"outputs":[]},{"metadata":{"_uuid":"905cae88c472cb8d94d1b71c23f7e68d70d11730"},"cell_type":"markdown","source":"### 2. Model creation"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"27ba82ca54dfe120b2eb14f441fc6d2771b1ef62"},"cell_type":"code","source":"# get features and labels\nX = df.iloc[:,:-1]\nlabels= df.iloc[:,-1]","execution_count":70,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"241ee1c923f6a42286453a2a55c3f4750f1fa6e0"},"cell_type":"code","source":"# Standarize features\nX = StandardScaler().fit_transform(X)","execution_count":71,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"4fcda69cbfae52c3f68a39cf42772df242d6eda7"},"cell_type":"code","source":"# Divide Data into train and test set  (test set will only be used in section 3.)\nX_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=0, stratify=labels)","execution_count":72,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"e97f59f7d6a3530cbf26bcc1b3a1d9be2f572ce9"},"cell_type":"code","source":"# reset y_train index\ny_train= y_train.reset_index(drop=True)","execution_count":73,"outputs":[]},{"metadata":{"_uuid":"f896023b46621da0e6a4210bf3e83d2ee0a936fd"},"cell_type":"markdown","source":"To help our models to handle the imbalanced problem we need to set the input parameter *class_weight=\"balanced\"* . The **“balanced”** mode will make the classes automatically weighted inversely proportional to how frequently they appear in the data. "},{"metadata":{"trusted":false,"_uuid":"e854104aa36ec5bbf991e95b0241fc19fc287da6","collapsed":true},"cell_type":"code","source":"# Random Forest\n\nRF_model = RandomForestClassifier(n_estimators=600, random_state=123456, class_weight=\"balanced\")\n\nacc=[]\nsen=[]\nspe=[]\nkf = KFold(n_splits=5, random_state= 123)\nkf.get_n_splits(X_train)\n\nfor train_index, test_index in kf.split(X_train):\n    Features_train, Features_test = X_train[train_index], X_train[test_index]\n    Labels_train, Labels_test = y_train[train_index], y_train[test_index]\n\n    RF_model.fit(Features_train, Labels_train)\n    cm = confusion_matrix(Labels_test, RF_model.predict(Features_test))\n    tn, fp, fn, tp = confusion_matrix(Labels_test, RF_model.predict(Features_test)).ravel()\n    sensitivity = tp/(tp+fn)\n    specificity  = tn/(tn+fp)\n    accuracy = (tp+tn)/(tp+fp+tn+fn)\n    acc.append(accuracy)\n    sen.append(sensitivity)\n    spe.append(specificity)\n    print(accuracy, sensitivity, specificity)\n\nglobal_acc = np.mean(acc)\nacc_std = np.std(acc)\nglobal_sen = np.mean(sen)\nsen_std = np.std(sen)\nglobal_spe = np.mean(spe)\nspe_std = np.std(spe)\n\nprint(\"_________________________________\")\nprint('Accuracy:', global_acc, \"+/-\", acc_std)\nprint('Sensitivity:', global_sen, \"+/-\", sen_std)\nprint('Specificity:', global_spe, \"+/-\", spe_std)","execution_count":74,"outputs":[]},{"metadata":{"_uuid":"7b5f4f12ad363d8c3b3543d95ae38983c4df242a"},"cell_type":"markdown","source":"Randon Forest still can't get a very good Sentitivity... Lets try using Logistic Regression now."},{"metadata":{"trusted":false,"_uuid":"a3226be7cc296228038cc8f658ed356702f11482","collapsed":true},"cell_type":"code","source":"# Logistic Regression\n\nC_param_range = [0.001,0.01,0.1,1,10,100]\n\nfor i in C_param_range:\n    LR_model = LogisticRegression(random_state=0, C=i, class_weight='balanced')\n    print(\"\\n C= \", i)\n    \n    acc=[]\n    sen=[]\n    spe=[]\n    kf = KFold(n_splits=5, random_state= 123)\n    kf.get_n_splits(X_train)\n\n    for train_index, test_index in kf.split(X_train):\n        Features_train, Features_test = X_train[train_index], X_train[test_index]\n        Labels_train, Labels_test = y_train[train_index], y_train[test_index]\n\n        LR_model.fit(Features_train, Labels_train)\n        cm = confusion_matrix(Labels_test, LR_model.predict(Features_test))\n        tn, fp, fn, tp = confusion_matrix(Labels_test, LR_model.predict(Features_test)).ravel()\n        sensitivity = tp/(tp+fn)\n        specificity  = tn/(tn+fp)\n        accuracy = (tp+tn)/(tp+fp+tn+fn)\n        acc.append(accuracy)\n        sen.append(sensitivity)\n        spe.append(specificity)\n        \n        print(accuracy, sensitivity, specificity)\n      \n\n    global_acc = np.mean(acc)\n    acc_std = np.std(acc)\n    global_sen = np.mean(sen)\n    sen_std = np.std(sen)\n    global_spe = np.mean(spe)\n    spe_std = np.std(spe)\n\n    print(\"_________________________________\")\n    print('Accuracy:', global_acc, \"+/-\", acc_std)\n    print('Sensitivity:', global_sen, \"+/-\", sen_std)\n    print('Specificity:', global_spe, \"+/-\", spe_std, \"\\n\")","execution_count":75,"outputs":[]},{"metadata":{"_uuid":"8946b1921cb80aa99dea3505c883b2ea5a2eb1b6"},"cell_type":"markdown","source":"Much better results for sentitivity this time! Lets use Logistic regression as the final model and see how it performs with the unseen data."},{"metadata":{"_uuid":"e171ecafa5e03031d971d3d10e41422cb1ce60fd"},"cell_type":"markdown","source":"### 2. Test final model with unseen data"},{"metadata":{"trusted":false,"_uuid":"f1f923b3adf36cf3496c132ff47e093453b5f314","collapsed":true},"cell_type":"code","source":"# check how the RF model would perform on the test set\nprint(classification_report(y_test, RF_model.predict(X_test)))","execution_count":79,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7b92dd20c1e3323abd91f1d473076ee92b84c0b9","collapsed":true},"cell_type":"code","source":"# Check results of chosen model (Logistic Regression) for unseen data, i.e. data that was not used for model creation\ncm = confusion_matrix(y_test, LR_model.predict(X_test))\ntn, fp, fn, tp = confusion_matrix(y_test, LR_model.predict(X_test)).ravel()\nsensitivity = tp/(tp+fn)\nspecificity  = tn/(tn+fp)\naccuracy = (tp+tn)/(tp+fp+tn+fn)\n\nprint(\" Sensitivity:\", sensitivity, \"\\n Specificity\", specificity, \"\\n Accuracy:\", accuracy)","execution_count":82,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"32b7135850a5758c88109cdf4dfa247cda17d4d0","collapsed":true},"cell_type":"code","source":"print(classification_report(y_test, LR_model.predict(X_test)))","execution_count":78,"outputs":[]},{"metadata":{"_uuid":"0f83aef1898db999cc5fe30626c5385478df3f03"},"cell_type":"markdown","source":"We can see that Logistic Regression outperformed Random Forest, specially because it was able to handle very well the imbalaced problem. "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}