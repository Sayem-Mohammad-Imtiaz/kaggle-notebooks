{"cells":[{"metadata":{"collapsed":true},"cell_type":"markdown","source":"## Car Price Prediction - RFE + Linear Regression\n<i><b>Author: Anish Mahapatra</b></i>\n<br>\n[LinkedIn Profile](https://www.linkedin.com/in/anishmahapatra/)\n<br>\n[Medium Profile](https://medium.com/@anishmahapatra)\n\n### Expected Outcome:\nBuild a multiple linear regression model to predict car prices.\n\n### Problem Statement:\n<b>Geely Auto</b>, a Chinese automobile company aspires to enter the US market and produce cars. They have hired an automobile consulting company (us) to understand the factors on which the pricing of a car depends on. pecifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:\n- Which variables are significant in predicting the price of a car\n- How well those variables describe the price of a car\n    \n### Business Goals:\nYou are required to model the price of cars with the available independent variables. It will be used by the management to understand how exactly the prices vary with the independent variables. They can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels. Further, the model will be a good way for management to understand the pricing dynamics of a new market. \n\n### Data Preparation to keep in mind\n- CarName is a concatenation of Car Company & Car Model\n- Only Company name is to be considered as the variable for the purpose of model building\n\n### Model Evaluation:\nPost building the model and residual analysis, make sure to do *R-Squared analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing the required modules and packages\n\nimport matplotlib.pyplot as plt\nfrom numpy.random import randn\nfrom numpy.random import seed\nfrom numpy import percentile\nfrom scipy import stats\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\n%matplotlib inline\nimport warnings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing the minimum display columns to 500\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)\n\n# Ignoring warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the required csv from the folder:\ncarData = pd.read_csv('../input/car-price-prediction/CarPrice_Assignment.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sense check of the application data\n\ncarData.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. Pre-Processing:\n- Check the % of missing values\n- Check the data types\n- Outlier Analysis\n\n### 2. EDA - to understand the data\n- Univariate Analysis\n- Make heatmap to understand correlation distribution\n- Perform Bivariate Analysis\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the top 5 rows and headers of the data\ncarData.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at the type of the data frame, data types and the number of rows\ncarData.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the number of rows and columns present in the data\ncarData.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at the data types of the data\ncarData.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making a copy of the application in dataframe df (checkpoint!) \ndf = carData.copy(deep=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Missing Values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculating the percent of missing values in the dataframe\npercentMissing = (df.isnull().sum() / len(df)) * 100\n\n# Making a dataframe with the missing values % and columns into a dataframe (on account of large number of rows) \nmissingValuesDf = pd.DataFrame({'columnName': df.columns,\n                                 'percentMissing': percentMissing})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Viewing the dataframe to ensure that the values have been populated correctly\nmissingValuesDf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, we have been fortunate enough to get a clean dataset with no missing values. So there will be no more imputations or missing value treatment to be carried out.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Outlier Treatment Analysis\nLet us now analyze the numerical variables","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<b>Note:</b> The Boxplots below have been plotted with the standard whiskers of 1.5 x (IQR)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting only the numeric columns to perform correlation analysis\nnumerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ndf_num = df.select_dtypes(include=numerics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Displaying the top 5 rows of only the numerical values\ndf_num.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we notice that symboling is a categorical variable.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removal of the categorical columns\nsymboling = df_num.pop('symboling')\ncar_ID = df_num.pop('car_ID')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We shall analyze the boxplots of the above variables to see if there are any untowardly behavior in the data.\n\nNote: We notice that car_ID is an identifier variable and does not hold significance when it comes","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Outlier Analysis using Box Plots","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making boxplots as sub-plots to understand the trend of the data \nplt.figure(figsize=(15, 6))\nplt.subplot(2,3,1)\nsns.boxplot(x = 'wheelbase', data = df_num)\nplt.subplot(2,3,2)\nsns.boxplot(x = 'carlength', data = df_num)\nplt.subplot(2,3,3)\nsns.boxplot(x = 'carwidth', data = df_num)\nplt.subplot(2,3,4)\nsns.boxplot(x = 'carheight', data = df_num)\nplt.subplot(2,3,5)\nsns.boxplot(x = 'curbweight', data = df_num)\nplt.subplot(2,3,6)\nsns.boxplot(x = 'enginesize', data = df_num)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making boxplots as sub-plots to understand the trend of the data \n\nplt.figure(figsize=(15, 6))\nplt.subplot(2,3,1)\nsns.boxplot(x = 'boreratio', data = df_num)\nplt.subplot(2,3,2)\nsns.boxplot(x = 'stroke', data = df_num)\nplt.subplot(2,3,3)\nsns.boxplot(x = 'compressionratio', data = df_num)\nplt.subplot(2,3,4)\nsns.boxplot(x = 'horsepower', data = df_num)\nplt.subplot(2,3,5)\nsns.boxplot(x = 'peakrpm', data = df_num)\nplt.subplot(2,3,6)\nsns.boxplot(x = 'citympg', data = df_num)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making boxplots as sub-plots to understand the trend of the data \nplt.figure(figsize=(15, 3))\nplt.subplot(1,2,1)\nsns.boxplot(x = 'highwaympg', data = df_num)\nplt.subplot(1,2,2)\nsns.boxplot(x = 'price', data = df_num)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have performed an outlier analysis on the numerical variables of the dataset, we can say that there are a few columns that we can deep drive into with the data:\n\n- <b>citympg</b>: Mileage in the city\n- <b>horsepower</b>: horse power\n- <b>enginesize</b>: Size of the car\n- <b>compressionratio</b>: compression ratio of the car\n- <b>stroke</b>: stroke or volume inside the engine\n- <b>price</b>: price of the car","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Distribution Analysis\n\nLet us now understand the distribution of the numerical and categorical variables.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Analysis of numerical variables\nLet us now analyze the categorical variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to plot histogram for numerical, univariate analysis\ndef plotHistogram(df, colName):\n    '''\n    This function is used to set the style of the plot, name the graph and plot the distribution for the specified column\n    \n    Inputs:\n    @df (dataframe) - The dataframe for which histograms are to be plotted\n    @colName (string) - The numeric column for which histograms is to be plotted\n    \n    Output:\n    Titles distribution plot of specified colName\n    '''\n    sns.set(style=\"whitegrid\")\n    plt.figure(figsize=(20,5)) \n    plt.title(colName)\n    plt.ylabel('Density', fontsize=14)\n    sns.distplot(df[colName], kde=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Histograms of numerical variables","execution_count":null},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Making boxplots as sub-plots to understand the trend of the data \nplt.figure(figsize=(2, 20))\nplotHistogram(df_num, 'wheelbase')\nplotHistogram(df_num, 'carlength')\nplotHistogram(df_num, 'carwidth')\nplotHistogram(df_num, 'carheight')\nplotHistogram(df_num, 'curbweight')\nplotHistogram(df_num, 'enginesize')\nplotHistogram(df_num, 'boreratio')\nplotHistogram(df_num, 'stroke')\nplotHistogram(df_num, 'compressionratio')\nplotHistogram(df_num, 'horsepower')\nplotHistogram(df_num, 'peakrpm')\nplotHistogram(df_num, 'citympg')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we notice that most of the numerical variables follow a normal distribution with minimum skew.\n\nThe variables that does not follow a normal distribution:\n- compression ratio","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Analysis of categorical variables\nLet us now analyze the categorical variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining a function to view the distribution of the categorical variables\ndef plotFrequencyTable(df, catColName):\n    '''\n    This function is used to plot the frequency table of the specified categorical variable\n    @df (dataframe) - Dataframe for which frequency table is to be plotted\n    @catColName (string) - Column name for which frequency table is to be plotted\n    '''\n    sns.countplot(x=catColName, data=df)\n    plt.title(catColName)\n    plt.xticks(rotation = 90)\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Subsetting data to subset categorical variables\ndf_cat = df.select_dtypes(include='object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Viewing the head of the data for a sense-check\ndf_cat.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Frequency Tables of categorical variables to understand trend","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making boxplots as sub-plots to understand the trend of the data \n\n# plt.figure(figsize=(10, 10))\nplt.subplot(2,2,1)\nplotFrequencyTable(df,'enginelocation')\nplt.subplot(2,2,2)\nplotFrequencyTable(df_cat,'fueltype')\nplt.subplot(2,2,3)\nplotFrequencyTable(df_cat,'aspiration')\nplt.subplot(2,2,4)\nplotFrequencyTable(df_cat,'doornumber')\nplt.subplot(2,3,5)\nplotFrequencyTable(df_cat,'carbody')\nplt.subplot(2,3,6)\nplotFrequencyTable(df_cat,'drivewheel')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A couple of observations from the above graph would indicate the following:\n- The engine is mostly located in the <b>front</b> of the car\n- Most of the cars use <b>gas</b> as their fuel\n- The aspiration employed by most vehicles is <b>std</b> (standard)\n- Just over half the cars sold have <b>four</b> doors\n- The most popular car body is <b>sedan</b>\n- Most of the cars have a <b>fwd</b> drive wheel","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Bivariate Analysis\n\nNow, we shall perform bi-variate analysis on the variables with respect to price (dependent variable) ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Correlation Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let us now analyze from the perspective of correlation analysis as to what the most correlated variable are with the <b>price</b> (dependent variable)\n\nLet us now proceed to plot the correlation matrix of the data:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the correlation matrix of the data\ncor = df_num.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation with output variable\ncor_target = abs(cor['price'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Selecting highly correlated features\nrelevant_features = cor_target[cor_target>0.5]\nround(relevant_features.sort_values(ascending = True), 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Heatmap of numerical variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check the correlation coefficients to see which variables are highly correlated\n\nplt.figure(figsize = (16, 10))\nsns.heatmap(df_num.corr(), annot = True, cmap=\"YlGnBu\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Top 10 correlated features with price","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Here, we notice that the top variables that are corrlated with price are as follows:\n- enginesize    0.87\n- curbweight    0.84\n- horsepower    0.81\n- carwidth      0.76\n- highwaympg    0.70\n- citympg       0.69\n- carlength     0.68\n- wheelbase     0.58\n- boreratio     0.55\n\n\nPearson's correlation is considered significant when the variables generally have a correlation > 0.5.\n\nLet us now try to do the business interpretation of the above variables as to why they may have a higher correlation as compared to the other variables:\n- <b>engine size</b>: The more is the engine size of the car, the faster it can go. So, the materials used should be more strong and light which might lead to it being expensive\n- <b>curb weight</b>: As curb weight increases, a more powerful engine would be required to pull the car, which would make the price go up\n- <b>horse power</b>: A higher horse power adds to the cost of the car\n- <b>car width</b>: This is an intersting find. This would imply cars that are wider in girth are an indication of a luxury car\n- <b>highway mpg</b>: Interesting! A lower mileage seems to indicate a more expensive car\n- <b>city mpg</b>: Interesting! A lower mileage seems to indicate a more expensive car\n- <b>car length</b>: This is also interesting as it implies that the more the length of the car, higher is the price of the car\n- <b>wheel base</b>: An equally interesting find, faster and more expensive cars seems to have a higher wheel base\n- <b>bore ratio</b>: Higher the bore ratio implies that it is a faster car, which would in turn imply that the car is expensive","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Bivariate Plots","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Now that we have found the variables that have the highest correlation with the dependent variable - price, we shall now plot the bivariate plots with price.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting pair plots\nsns.pairplot(df)\nplt.figure(figsize=(40, 40))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the highly correlated variables with price to understand the trend\nplt.figure(figsize=(20, 12))\nplt.subplot(2,3,1)\nsns.boxplot(x = 'enginesize', y = 'price', data = df)\n\nplt.subplot(2,3,2)\nsns.boxplot(x = 'curbweight', y = 'price', data = df)\n\nplt.subplot(2,3,3)\nsns.boxplot(x = 'horsepower', y = 'price', data = df)\n\nplt.subplot(2,3,4)\nsns.boxplot(x = 'carwidth', y = 'price', data = df)\n\nplt.subplot(2,3,5)\nsns.boxplot(x = 'highwaympg', y = 'price', data = df)\n\nplt.subplot(2,3,6)\nsns.boxplot(x = 'citympg', y = 'price', data = df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The bivariate distribution can be analyzed. The following trends are observed from the correlated variables: \n- As engine size increases, price increases\n- As curb weight increases, price increases\n- As horse power increases, price increases\n- As the car width increases, price increases\n\nThe following trends are interesting:\n- As the highway mileage increases, the price decreases\n- As the city mileage increases, the price decreases","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing:\n\n- Get the name of the car company\n- Correct the name of the car company\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing the unique identifier of the data\ndf.pop('car_ID').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the name of the brand\ndf['CarName'] = df['CarName'].str.split('-').str[0]\ndf['CarName'] = df['CarName'].str.split(' ').str[0]\n\n# Converting to lowercase\ndf['CarName'] = df['CarName'].str.lower()\n\n# Correcting the mistakes present in the CarName columns like vw to volkswagen, maxda to mazda etc.\ndf['CarName'] = df['CarName'].str.replace('vw','volkswagen')\ndf['CarName'] = df['CarName'].str.replace('maxda','mazda')\ndf['CarName'] = df['CarName'].str.replace('vokswagen','volkswagen')\ndf['CarName'] = df['CarName'].str.replace('toyouta','toyota')\n\n# Replacing occurences of 4wd with fwd as they are the same thing\ndf['drivewheel'] = df['drivewheel'].str.replace('4wd','fwd')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We shall now proceed to convert the categorical variables to dummy variables.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Making a function to make dummy variables\n# def makeDummyVariables(df, colName):\n#     '''\n#     This function is used to make dummy variables, concatenate it to original dataframe and remove the older categorical column.\n    \n#     Inputs:\n#     @colName (string): Name of the categorical column that we wish to make dummy variables for.\n#     @df (dataframe): Dataframe which we would like to make modifications in\n    \n#     Output:\n#     Desired dataframe with dummy varibles with original categorical variable (colName) removed\n    \n#     '''\n#     # Making dummy variables and dropping the first dummy column as n values should have n-1 dummy columns\n#     status = pd.get_dummies(df[colName], drop_first = True)\n    \n#     # Concatenating the dummy variables to the dataframe\n#     df = pd.concat([df, status], axis = 1)\n    \n#     # Dropping the original categorical variable from the dataframe\n#     df.drop([colName], axis = 1, inplace = True)\n\n\n# ---------------- function did not work for some reason. However, an attempt was made------------------------------","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making dummy variables and dropping the first dummy column as n values should have n-1 dummy columns\nstatus = pd.get_dummies(df['CarName'], drop_first = True)\n\n# Concatenating the dummy variables to the dataframe\ndf = pd.concat([df, status], axis = 1)\n\n# Dropping the original categorical variable from the dataframe\ndf.drop(['CarName'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making dummy variables and dropping the first dummy column as n values should have n-1 dummy columns\nstatus = pd.get_dummies(df['fueltype'], drop_first = True)\n\n# Concatenating the dummy variables to the dataframe\ndf = pd.concat([df, status], axis = 1)\n\n# Dropping the original categorical variable from the dataframe\ndf.drop(['fueltype'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making dummy variables and dropping the first dummy column as n values should have n-1 dummy columns\nstatus = pd.get_dummies(df['aspiration'], drop_first = True)\n\n# Concatenating the dummy variables to the dataframe\ndf = pd.concat([df, status], axis = 1)\n\n# Dropping the original categorical variable from the dataframe\ndf.drop(['aspiration'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making dummy variables and dropping the first dummy column as n values should have n-1 dummy columns\nstatus = pd.get_dummies(df['symboling'], drop_first = True)\n\n# Concatenating the dummy variables to the dataframe\ndf = pd.concat([df, status], axis = 1)\n\n# Dropping the original categorical variable from the dataframe\ndf.drop(['symboling'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making dummy variables and dropping the first dummy column as n values should have n-1 dummy columns\nstatus = pd.get_dummies(df['doornumber'], drop_first = True)\n\n# Concatenating the dummy variables to the dataframe\ndf = pd.concat([df, status], axis = 1)\n\n# Dropping the original categorical variable from the dataframe\ndf.drop(['doornumber'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making dummy variables and dropping the first dummy column as n values should have n-1 dummy columns\nstatus = pd.get_dummies(df['carbody'], drop_first = True)\n\n# Concatenating the dummy variables to the dataframe\ndf = pd.concat([df, status], axis = 1)\n\n# Dropping the original categorical variable from the dataframe\ndf.drop(['carbody'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making dummy variables and dropping the first dummy column as n values should have n-1 dummy columns\nstatus = pd.get_dummies(df['drivewheel'], drop_first = True)\n\n# Concatenating the dummy variables to the dataframe\ndf = pd.concat([df, status], axis = 1)\n\n# Dropping the original categorical variable from the dataframe\ndf.drop(['drivewheel'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making dummy variables and dropping the first dummy column as n values should have n-1 dummy columns\nstatus = pd.get_dummies(df['enginelocation'], drop_first = True)\n\n# Concatenating the dummy variables to the dataframe\ndf = pd.concat([df, status], axis = 1)\n\n# Dropping the original categorical variable from the dataframe\ndf.drop(['enginelocation'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making dummy variables and dropping the first dummy column as n values should have n-1 dummy columns\nstatus = pd.get_dummies(df['enginetype'], drop_first = True)\n\n# Concatenating the dummy variables to the dataframe\ndf = pd.concat([df, status], axis = 1)\n\n# Dropping the original categorical variable from the dataframe\ndf.drop(['enginetype'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making dummy variables and dropping the first dummy column as n values should have n-1 dummy columns\nstatus = pd.get_dummies(df['cylindernumber'], drop_first = True)\n\n# Concatenating the dummy variables to the dataframe\ndf = pd.concat([df, status], axis = 1)\n\n# Dropping the original categorical variable from the dataframe\ndf.drop(['cylindernumber'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making dummy variables and dropping the first dummy column as n values should have n-1 dummy columns\nstatus = pd.get_dummies(df['fuelsystem'], drop_first = True)\n\n# Concatenating the dummy variables to the dataframe\ndf = pd.concat([df, status], axis = 1)\n\n# Dropping the original categorical variable from the dataframe\ndf.drop(['fuelsystem'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Sense check of the data\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shape of the data\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting the Data into Training and Testing Sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# We specify this so that the train and test data set always have the same rows, respectively\ndf_train, df_test = train_test_split(df, train_size = 0.7, test_size = 0.3, random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Rescaling the Features \n\nWe will use MinMax scaling. This is done for the numerical variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Obtaining the numerical features and scaling them\nnum_vars = ['wheelbase', 'carlength', 'carwidth', 'carheight', 'curbweight', 'enginesize', \n            'boreratio', 'stroke', 'compressionratio', 'horsepower', 'peakrpm', 'citympg', \n            'highwaympg']\n\n# Scaling the numerical features\ndf_train[num_vars] = scaler.fit_transform(df_train[num_vars])\n\n# Sense check of the data\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dividing into X and Y sets for the model building","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Putting the dependent variable in 'y' \ny_train = df_train.pop('price')\n\n# Putting the rest of the features in 'X'\nX_train = df_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building our model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This time, we will be using the **LinearRegression function from SciKit Learn** for its compatibility with RFE (Recursive Feature Elimination)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### RFE\nRecursive feature elimination","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing RFE and LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running RFE with the output number of the variable equal to 20\n\n# Making a linear regression model object\nlm = LinearRegression()\n\n# Fitting the model on the training dataset\nlm.fit(X_train, y_train)\n\n# Outputting the top 20 features\nrfe = RFE(lm, 20)             \nrfe = rfe.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# listing the relevant features (obtained via Recursive Feature Elimination - RFE)\nlist(zip(X_train.columns,rfe.support_,rfe.ranking_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The features that say `True` are the ones that RFE believes will be relevant to predict the price.\n\n#### The features that say `False` can be given priority, with 1 being the highest, although RFE has implies that the features will not be as relevant for the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# The columns selected by RFE\ncol = X_train.columns[rfe.support_]\ncol","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The columns that were not selected by RFE\nX_train.columns[~rfe.support_]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building model using statsmodel, for the detailed statistics","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating X_test dataframe with RFE selected variables\nX_train_rfe = X_train[col]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Iteration 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding a constant variable as stats models does not have a constant variable\nimport statsmodels.api as sm  \nX_train_rfe = sm.add_constant(X_train_rfe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running the linear model to understand the ordinary least squares\nlm = sm.OLS(y_train,X_train_rfe).fit()   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's see the summary of our linear model\nprint(lm.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Iteration 2","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe = X_train_rfe.drop([\"two\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rebuilding the model without `two`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_train_lm = sm.add_constant(X_train_rfe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm = sm.OLS(y_train,X_train_lm).fit()   # Running the linear model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's see the summary of our linear model\nprint(lm.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Iteration 3","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe = X_train_rfe.drop([\"dohcv\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rebuilding the model without `dohcv`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_train_lm = sm.add_constant(X_train_rfe)\n\n# Running the linear model\nlm = sm.OLS(y_train,X_train_lm).fit()  \n\n#Let's see the summary of our linear model\nprint(lm.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Iteration 4","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe = X_train_rfe.drop([\"peakrpm\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rebuilding the model without `peakrpm`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_train_lm = sm.add_constant(X_train_rfe)\n\n# Running the linear model\nlm = sm.OLS(y_train,X_train_lm).fit()  \n\n#Let's see the summary of our linear model\nprint(lm.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Iteration 5","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe = X_train_rfe.drop([\"horsepower\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rebuilding the model without `horsepower`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_train_lm = sm.add_constant(X_train_rfe)\n\n# Running the linear model\nlm = sm.OLS(y_train,X_train_lm).fit()  \n\n#Let's see the summary of our linear model\nprint(lm.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## VIF - Variance Inflation Factor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe = X_train_rfe.drop(['const'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the VIFs for the new model\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_rfe\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making a copy of the application in dataframe df (checkpoint!) \nX_train_new = X_train_rfe.copy(deep=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_new = X_train_new.drop([\"three\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the VIFs for the new model\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_train_lm = sm.add_constant(X_train_new)\n\n# Running the linear model\nlm = sm.OLS(y_train,X_train_lm).fit()  \n\n#Let's see the summary of our linear model\nprint(lm.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Viewing the final columns to be used in the model\nX_train_new.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We notice that if we remove more columns, the R-Squared gradually reduces.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Residual Analysis of the train data\n\nSo, now to check if the error terms are also normally distributed (which is infact, one of the major assumptions of linear regression), let us plot the histogram of the error terms and see what it looks like.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_price = lm.predict(X_train_lm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_price), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18)                         # X-label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We note that the errors are normally distributed","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Making Predictions","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Applying the scaling on the test sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_vars = ['wheelbase', 'carlength', 'carwidth', 'carheight', 'curbweight', 'enginesize', \n            'boreratio', 'stroke', 'compressionratio', 'horsepower', 'peakrpm', 'citympg', \n            'highwaympg']\n\ndf_test[num_vars] = scaler.transform(df_test[num_vars])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Dividing into X_test and y_test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = df_test.pop('price')\nX_test = df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now let's use our model to make predictions.\n\n# Creating X_test_new dataframe by dropping variables from X_test\nX_test_new = X_test[X_train_new.columns]\n\n# Adding a constant variable \nX_test_new = sm.add_constant(X_test_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making predictions\ny_pred = lm.predict(X_test_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure()\nplt.scatter(y_test,y_pred)\nfig.suptitle('y_test vs y_pred', fontsize=20)              # Plot heading \nplt.xlabel('y_test', fontsize=18)                          # X-label\nplt.ylabel('y_pred', fontsize=16)                          # Y-label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding a constant variable \nimport statsmodels.api as sm  \nX_test_lm = sm.add_constant(X_test_new)\n\n# Running the linear model\nlm = sm.OLS(y_test,X_test_lm).fit()  \n\n#Let's see the summary of our linear model\nprint(lm.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## R-Squared value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\nprint('R-Squared Score for the Car Price Prediction model with Linear Regression + RFE is:\\n', round(r2_score(y_test, y_pred)*100, 2), '%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Hence, the features that can be mentioned as good predictors to model the price are: **Geely Auto** can use are:\n- carwidth\n- curbweight\n- enginesize\n- boreratio\n- stroke\n- bmw\n- mitsubishi\n- peugeot\n- porsche\n- rear\n- l\n- rotor\n- five\n- four\n- twelve","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"A couple of interesting points to note about a care that would have a higher price:\n   - An \"I - Engine type\" is an indicator of the car being more expensive\n   - BMW, Peugeot and Porsche are the more expensive brands\n   - Heavier car and wider cars are more expensive\n   - Higher numer of cylinders is a string indicator of a more expensive car (>4)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Hey, thank you so much for taking the time to go through my notebook. I'm a Data Scientist in top Data Science firm and am pursuing my MS in Data Science. This is one of my first notebooks in Kaggle and I would love some feedback from this wonderful community. \n\nI'm a fun person to connect with, please feel free to connect with me 😄\n<br>\n[LinkedIn Profile](https://www.linkedin.com/in/anishmahapatra/)\n<br>\n[Medium Profile](https://medium.com/@anishmahapatra)\n<br>\n[GitHub Profile](https://github.com/anishmahapatra01/)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}