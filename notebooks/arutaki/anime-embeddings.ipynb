{"cells":[{"metadata":{},"cell_type":"markdown","source":" # **Anime Recommender System**\n \n In this notebook, I am trying to build an anime embeddings based on myanimelist ratings dataset. The dataset is accessible through Kaggle here: https://www.kaggle.com/CooperUnion/anime-recommendations-database.\n\nThis notebook comprises of the following sections:\n1. Data preprocessing.\n2. Model building.\n3. Model training\n4. Results visualization.\n\nWe are going to use collaborative filtering technique to build the recommendation system. We adopt idea from natural language processing, that is the GloVe model to make anime embeddings. From these embeddings, we can give anime recommendation based on similarity with the list of anime you give for further project."},{"metadata":{},"cell_type":"markdown","source":"**Data Preprocessing**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from collections import Counter, defaultdict\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom sklearn.manifold import TSNE","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, we want to see how our data looks like. We sort the list of anime based on its id."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"anime = pd.read_csv(\"../input/anime-recommendations-database/anime.csv\")\nrating = pd.read_csv(\"../input/anime-recommendations-database/rating.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anime = anime.sort_values('anime_id')\nanime","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we want to clean the rating data to fit our purpose. Since we want to have collaborative embedding, we need to make cooccurence matrix of recommended anime. In this case all anime recommended by one person is defined as one \"cooccurence\". Due to limitation of computation power, I suggest that we clean the data under these assumptions:\n\n1. Anime that are not rated are not impressionable enough. Remove any anime that are not watched (rating = -1)\n2. We only want anime that people recommend. Find the mean rating of all anime from all users, keep only ratings higher than the mean.\n3. People who recommended too few anime does not know anime enough, people who recommended too many anime probably watch any anime. We limit the data only from people who gives rating higher than the average from 10 to 20 anime (the number choice is arbitrary).\n\nOnce the data is cleaned, we want to see how the rating looks like."},{"metadata":{"trusted":true},"cell_type":"code","source":"rated = rating[rating.rating >= 0]\nmean = rated[\"rating\"].mean()\nrated = rated[rated.rating > mean]\ntest = rated.groupby(\"user_id\").filter(lambda x:len(x) >= 10)\ntest = test.groupby(\"user_id\").filter(lambda x:len(x) <= 20)\n\ntest","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have significantly decrease the number of rating data (but hopefully representative enough). To make cooccurence matrix, we need cross tabulation with each row corresponding to the individual user and the column for each anime. The value of 1 means that user recommended that anime and 0 means that no recommendation on the anime. We will see mostly zeroes because of the 12294 anime, only 10 to 20  of the row is non-zero entries."},{"metadata":{"trusted":true},"cell_type":"code","source":"cross = pd.crosstab(index = test.user_id, columns = test.anime_id)\ncross","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Representing the cross table as a matrix, we can have the cooccurence matrix by multiplying the matrix with its transpose."},{"metadata":{"trusted":true},"cell_type":"code","source":"cross_int = cross.astype(int)\ncooc = cross_int.T.dot(cross_int)\ncooc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some anime only appear once. We cannot infer its relationship with other anime, remove them."},{"metadata":{"trusted":true},"cell_type":"code","source":"once = [cooc.columns[i] for i in range(len(cooc.columns)) if cooc.iloc[i, i] == 1]\ncooc = cooc.drop(columns = once)\ncooc = cooc.drop(index = once)\ncooc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our data has gone significantly smaller and will be very easy to compute. This is going to be"},{"metadata":{},"cell_type":"markdown","source":"**Model Building**"},{"metadata":{},"cell_type":"markdown","source":"Let us start by making the dataset to be in the format we need. We make a class of Anime Dataset with input of the rating's cooccurence matrix and the anime list that acts as dictionary. The input would be the tokenized id of each anime and the output would be cooccurence number of the two anime."},{"metadata":{"trusted":true},"cell_type":"code","source":"class AnimeDataset:\n    def __init__(self, coocc_matrix, anime_df):\n        self.coocc = coocc_matrix\n        self.anime = anime_df\n        \n        self.good_id = list(self.coocc.columns)        \n        self.namelen = len(self.good_id)\n        \n        self.name = [self.anime.name[self.anime.anime_id == i].values[0] for i in self.good_id if len(self.anime.name[self.anime.anime_id == i].values) != 0]\n        self.newid = list(range(self.namelen))\n        self.id2name = dict(zip(self.newid, self.name))\n        \n        newcol = list(range(self.namelen))\n        \n        self.coocc.columns = newcol\n        self.coocc.index = newcol\n        \n        self._i_idx = list()\n        self._j_idx = list()\n        self._xij = list()\n        \n        for i in range(self.namelen):\n            for j in range(self.namelen):\n                if i != j and self.coocc.loc[i, j] != 0:\n                    self._i_idx.append(i)\n                    self._j_idx.append(j)\n                    self._xij.append(self.coocc.loc[i, j])\n        \n        self._i_idx = torch.LongTensor(self._i_idx).cuda()\n        self._j_idx = torch.LongTensor(self._j_idx).cuda()\n        self._xij = torch.FloatTensor(self._xij).cuda()\n        \n    def get_batches(self, batch_size):\n        #Generate random idx\n        rand_ids = torch.LongTensor(np.random.choice(len(self._xij), len(self._xij), replace=False))\n        \n        for p in range(0, len(rand_ids), batch_size):\n            batch_ids = rand_ids[p:p+batch_size]\n            yield self._xij[batch_ids], self._i_idx[batch_ids], self._j_idx[batch_ids]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We create our dataset object here."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = AnimeDataset(cooc, anime)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we make the model here. We adopt GloVe model from NLP where instead of using kernels that slide along words, a single user's reviews is the entire \"kernel\". However, the anime in the same kernel are given the same weight unlike words that become less related when it is located further from each other."},{"metadata":{"trusted":true},"cell_type":"code","source":"class AnimeGlove(nn.Module):\n    def __init__(self, num_embeddings, embedding_dim):\n        super(AnimeGlove, self).__init__()\n        self.wi = nn.Embedding(num_embeddings, embedding_dim)\n        self.wj = nn.Embedding(num_embeddings, embedding_dim)\n        self.bi = nn.Embedding(num_embeddings, 1)\n        self.bj = nn.Embedding(num_embeddings, 1)\n        \n        self.wi.weight.data.uniform_(-1, 1)\n        self.wj.weight.data.uniform_(-1, 1)\n        self.bi.weight.data.zero_()\n        self.bj.weight.data.zero_()\n        \n    def forward(self, i_indices, j_indices):\n        w_i = self.wi(i_indices)\n        w_j = self.wj(j_indices)\n        b_i = self.bi(i_indices).squeeze()\n        b_j = self.bj(j_indices).squeeze()\n        \n        x = torch.sum(w_i * w_j, dim=1) + b_i + b_j\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model Training**"},{"metadata":{},"cell_type":"markdown","source":"Now we can start training the model. I choose 100 as the embedding dimension and 3014 number of anime we want to give embeddings."},{"metadata":{"trusted":true},"cell_type":"code","source":"EMBED_DIM = 100\nNAME_LEN = len(cooc)\nmodel = AnimeGlove(NAME_LEN, EMBED_DIM)\nmodel.cuda()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we define the weight function according to the paper, loss function, and the optimizer."},{"metadata":{"trusted":true},"cell_type":"code","source":"def weight_func(x, x_max, alpha):\n    wx = (x/x_max)**alpha\n    wx = torch.min(wx, torch.ones_like(wx))\n    return wx.cuda()  \n\ndef wmse_loss(weights, inputs, targets):\n    loss = weights * F.mse_loss(inputs, targets, reduction='none')\n    return torch.mean(loss).cuda()\n\noptimizer = optim.Adagrad(model.parameters(), lr=0.05)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We set up the parameters according to the paper and begin training. "},{"metadata":{"trusted":true},"cell_type":"code","source":"N_EPOCHS = 100\nBATCH_SIZE = 2048\nX_MAX = 100\nALPHA = 0.75\nn_batches = int(len(dataset._xij) / BATCH_SIZE)\nloss_values = list()\nfor e in range(1, N_EPOCHS+1):\n    batch_i = 0\n\n    for x_ij, i_idx, j_idx in dataset.get_batches(BATCH_SIZE):\n\n        batch_i += 1\n\n        optimizer.zero_grad()\n\n        outputs = model(i_idx, j_idx)\n\n        weights_x = weight_func(x_ij, X_MAX, ALPHA)\n\n        loss = wmse_loss(weights_x, outputs, torch.log(x_ij))\n\n        loss.backward()\n\n        optimizer.step()\n\n        loss_values.append(loss.item())\n\n        if batch_i % 100 == 0:\n            print(\"Epoch: {}/{} \\t Batch: {}/{} \\t Loss: {}\".format(e, N_EPOCHS, batch_i, n_batches, np.mean(loss_values[-20:])))  \n    \n    print(\"Saving model...\")\n    torch.save(model.state_dict(), \"anime.pt\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see how the loss values converge to 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(loss_values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Results Visualization**"},{"metadata":{},"cell_type":"markdown","source":"We want to verify if the model works as intended. Let us visualize the anime using t-SNE to reduce the 100 dimension into 2D scatter plot. "},{"metadata":{"trusted":true},"cell_type":"code","source":"emb_i = model.wi.weight.cpu().data.numpy()\nemb_j = model.wj.weight.cpu().data.numpy()\nemb = emb_i + emb_j\ntop_k = 300\ntsne = TSNE(metric='cosine', random_state=123)\nembed_tsne = tsne.fit_transform(emb[:top_k, :])\nfig, ax = plt.subplots(figsize=(14, 14))\nfor idx in range(top_k):\n    plt.scatter(*embed_tsne[idx, :], color='steelblue')\n    plt.annotate(dataset.id2name[idx], (embed_tsne[idx, 0], embed_tsne[idx, 1]), alpha=0.7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While the exact visualization depends on the training results, there are two ways we can see how our training of this embeddings have succeeded.\n\n1. Anime with sequels are located closely together. For example, try to look at the Hunter x Hunter and Initial D. It is reasonable to expect people who like an anime like its sequel too.\n2. The very popular anime are closely located together. Look how Naruto and Bleach are closely located. If you look at the surrounding anime, they are all really popular anime which everyone watches.\n\nFor these two reasons, I think it is sufficient to say that the anime embeddings work pretty well. This embedding can be deployed to make anime recommendation for further project.\n\nReference:\n1. https://nlpython.com/implementing-glove-model-with-pytorch/\n2. https://towardsdatascience.com/collaborative-embeddings-for-lipstick-recommendations-98eccfa816bd"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}