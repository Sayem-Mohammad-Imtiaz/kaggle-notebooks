{"cells":[{"metadata":{},"cell_type":"markdown","source":"#  ============== SBA LOAN DEFAULT PREDICTION ===============\n\nPada notebook ini, saya akan coba memprediksi terkait SBA Loan yakni apakah seseorang atau perusahaan akan mengalami default/tidak mampu bayar atau tidak. Ini adalah project kedua saya, setelah sebelumnya saya mencoba model regressi, kali ini saya akan mencoba model klasifikasi.\nSeperti biasa, notebook ini akan saya bagi menjadi beberapa tahapan sebagai berikut:\n1. Konteks\n2. Data Preprocessing\n3. Modelling \n4. Model Tunning\n5. Deployment\n6. Deployment\n\nArtikel ini tidak terlalu dalam membahas teorinya, namun saya akan memberikan alasan-alasan kenapa saya melakukan langkah-langkah tersebut dan juga saya akan mencantumkan refensinya jika ingin membaca lebih jauh. Mari kita mulai!\n# **1. KONTEKS**\nSmall Business Administration (SBA) adalah sebuah lembaga independen pemerintahan Amerika yang membantu para pengusaha di berbagai macam industri dalam bentuk jaminan dari berbagai lembaga keuangan seperti bank atau landing club yang memberikan pinjamanya. Jadi secara teknis, pengusaha akan meminjam sejumlah uang kepada lembaga keuangan seperti bank, kemudian untuk menjamin bahwa si pengusaha ini benar-benar mampu atau berkualitas, maka diberikan jaminan/garansi dari SBA kepada bank atau si pemberi pinjaman. Jadi SBA ini  ibaratanya seperti asuransi, jadi jika pengusaha gagal bayar ke bank, maka ada jaminan dari SBA, sehingga pihak bank tidak perlu khawatir. \n\n\nPada project ini, kita akan coba memprediksi kemungkinan peminjam/pengusaha ini gagal bayar atau tidak berdasarkan data yang telah dikumpulkan dari tahun 1987â€“2014.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Importing Libraries\n#Basic libraries\nimport pandas as pd\nimport numpy as np\nfrom numpy import argmax\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas_profiling as pp\nimport datetime\nimport math\nfrom datetime import date\nfrom scipy import stats\n\n#Fetaure Selection\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\n\n#Imbalance Dataset\nfrom imblearn.over_sampling import SMOTE\n\nfrom imblearn.over_sampling import SMOTE, ADASYN\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.pipeline import Pipeline\n\n#Model Evaluation\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix, f1_score,auc,roc_curve,roc_auc_score, precision_recall_curve\nimport scikitplot as skplt\n\n#Modelling Algoritm\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load Data\ndata = pd.read_csv('../input/should-this-loan-be-approved-or-denied/SBAnational.csv').drop_duplicates()\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Melihat info dari data yang kita punya seperti jumlah kolom, input, memorti, tipe data dll\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Melihat apakah ada kolom yang inputnya kosong\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **2. DATA PREPROCESSING**\n\nPada tahapa ini, kita akan menyiapkan data sebelum dilakukan pemodelan. Di sini, data akan kita bersihkan dari input-input yang salah, input yang kosong, penyesuaian tipe data, normalisasi data, menghilangkan outliers, exploratory data analysis, melakukan feature engineering, dan feature selcetion, scaling, serta menangani imbalance dataset.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## **2.1 Handling Variabel**\n\nPada bagian ini, kita akan melakukan penyesuain tipe data tiap kolom, inputnya sebelum nanti kita tangani input yang \nkosong. Pada bagian ini kita juga membuat dan mengganti beberapa varibel untuk mempermudah model dalam memprediksi.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kita akan merubah tipe kolom yang memiliki tanggal menjadi tipe date/tanggal\ndate_col = ['ApprovalDate', 'ChgOffDate','DisbursementDate']\ndata[date_col] = pd.to_datetime(data[date_col].stack(),format='%d-%b-%y').unstack()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merubah kolom ApprovalFY menjadi integer, walaupun sebenrnya dia adalah tahun, tapi agar lebih mudah \ndata['ApprovalFY'].replace('1976A', 1976, inplace=True)\ndata['ApprovalFY']= data['ApprovalFY'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merubah Kolom Currency menjadi float\ncurr_col = ['DisbursementGross', 'BalanceGross', 'ChgOffPrinGr', 'GrAppv', 'SBA_Appv']\ndata[curr_col] = data[curr_col].replace('[\\$,]', '', regex=True).astype(float) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merubah input MIS_Status dari string menjadi integer\ndata['MIS_Status'] = data['MIS_Status'].replace({'P I F': 0, 'CHGOFF':1})\ndata.MIS_Status.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merubah input LowDoc yang string menjadi integer dan merubah input yang tidak sesuai menjadi NaN\ndata['LowDoc'] = data['LowDoc'].replace({'[C, S, A, R, 1, 0]':np.nan})\ndata['LowDoc'] = data['LowDoc'].replace({'N': 0, 'Y':1})\ndata['LowDoc'] = np.where((data['LowDoc'] != 0) & (data['LowDoc'] != 1), np.nan, data.LowDoc)\ndata.LowDoc.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Menangani input kolom RevLIneCr menjadi integer dan merubah input yang tidak sesuai di Kolom RevLineCr dengan menganggapnya sebagai NaN\ndata['RevLineCr'] = data['RevLineCr'].replace({'N': 0, 'Y':1, })\ndata['RevLineCr'] = data['RevLineCr'].replace({'0': 0, '1':1, })\ndata['RevLineCr'] = np.where((data['RevLineCr'] != 0) & (data['RevLineCr'] != 1), np.nan, data.RevLineCr)\ndata.RevLineCr.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merubah kolom NewExist menjadi integer dan menangani yang salah input membuat existing business = 0 dan new business = 1\ndata['NewExist'] = data['NewExist'].replace({1.0: 0, 2.0:1, 0:np.nan}).fillna(0).astype(int)\ndata.NewExist.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kolom UrbanRural sudah sesuai, tidak ada yang perlu di ubah. Kita hanya ingin meliat isinya seperti apa\ndata.UrbanRural.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Melihat kolom FranchiseCode, berdasarkan guideline\n#jika kolom FranchiseCode = 0 atau = 1 maka dia tidak ada frnachise, selain itu maka dia ada franchise\ndata['FranchiseCode'] = data['FranchiseCode'].replace(1,0 )\t\ndata['FranchiseCode'] = np.where((data.FranchiseCode != 0 ),1,data.FranchiseCode)\n\n#Merubah nama kolom FranchiseCode menjadi Is_Franchised\ndata.rename(columns={\"FranchiseCode\": \"Is_Franchised\"}, inplace=True)\ndata.Is_Franchised.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pada kolom CreateJob saya akan merubahnya menjadi categorcal\n#jika 0 maka dia tidak membuat job, jika > 0 maka dia membuat job\ndata['CreateJob'] = np.where((data.CreateJob > 0 ),1,data.CreateJob)\ndata.rename(columns={\"CreateJob\": \"Is_CreatedJob\"}, inplace=True)\ndata.Is_CreatedJob.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pad kolom RetainedJob saya akan merubahnya menjadi categorcal\n#jika 0 maka dia tidak memiliki karyawan tetap, maka jika >0 maka dia memiliki karyawan\ndata['RetainedJob'] = np.where((data.RetainedJob > 0 ),1,data.RetainedJob)\ndata.rename(columns={\"RetainedJob\": \"Is_RetainedJob\"}, inplace=True)\ndata.Is_RetainedJob.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loan Term dibagi menjadi 2, yakni yang jangka panjang >= 240 bulan (20 tahun) dan < 240 bulan (20 tahun), \n#ini berdasarkan guideline, jika 20 tahun atau diatasnya maka dia dibackup dengan properti jika kurang, maka sebaliknya\ndata['RealEstate'] = data['Term'].apply(lambda x: 1 if x >= 240 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kita akan membuat kolom baru yakni 'Recession'\n#kolom ini berisi apakah si perusahaan ini aktif pada masa resesi dari (1 des 2007 - 30 jun 2009)\n#jika aktif maka 1, jika tidak maka 0\n\n#Pertama buat kolom perhitungan untuk merubah Kolom Term menjadi Daysterm dan kolom Active dengan menambahkan kolom\n#Daysterm dengan kolom DisbursementDate\ndata['DaysTerm'] =  data['Term']*30\ndata['Active'] = data['DisbursementDate'] + pd.TimedeltaIndex(data['DaysTerm'], unit='D')\n\n#Kedua kita aka membuat kolom Recession\nstartdate = datetime.datetime.strptime('2007-12-1', \"%Y-%m-%d\").date()\nenddate = datetime.datetime.strptime('2009-06-30', \"%Y-%m-%d\").date()\ndata['Recession'] = data['Active'].apply(lambda x: 1 if startdate <= x <= enddate else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Menangani kolom NAICS, kita akan meerubahnya menjadi nama sektornya dan membuat kolom rate default setiap sektornya\n#Berdasarkan guideline, dua  digit di awal adalah kode industrinya\nind_code = data['NAICS']\n\n#Fungsi untuk mengambil ambil 2 digit awal dari kodenya\ndef get_code(ind_code):\n    if ind_code <= 0:\n        return 0\n    return (ind_code // 10 ** (int(math.log(ind_code, 10)) - 1))\n\n#Merubah 2 digit menjadi nama sektor\ndef sector_name(i):\n    def_code = {11:'Agriculture, Forestry, Fishing & Hunting', 21:'Mining, Quarying, Oil & Gas',\n                22:'Utilities', 23:'Constuction', 31:'Manufacturing', 32:'Manufacturing', 33:'Manufacturing',\n                42:'Wholesale Trade', 44:'Retail Trade', 45:'Retail Trade', 48:'Transportation & Warehousing',\n                49:'Transportation & Warehousing', 51:'Information', 52:'Finance & Insurance', \n                53:'Real Estate, Rental & Leasing', 54:'Professional, Scientific & Technical Service',\n                55:'Management of Companies & Enterprise', \n                56:'Administrative, Support, Waste Management & Remediation Service',\n                61:'Educational Service', 62:'Health Care & Social Assistance',\n                71:'Arts, Entertainment & Recreation', 72:'Accomodation & Food Service',\n                81:'Other Servieces (Ex: Public Administration)', 92:'Public Administration'\n               }\n    if i in def_code:\n        return def_code[i]\n    \ndef def_rate(i):\n    sector_default = {21:0.08, 11:0.09, 55:0.10, \n                      62: 0.10, 22:0.14, \n                      92:0.15,54:0.19, \n                      42:0.19,31:0.19,\n                      32:0.16,33:0.14,\n                      81:0.20,71:0.21,\n                      72:0.22,44:0.22,\n                      45:0.23,23:0.23,\n                      56:0.24,61:0.24,\n                      51:0.25,48:0.27,\n                      49:0.23,52:0.28,53:0.29}\n    if i in sector_default:\n        return sector_default[i]\n    return np.nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Membuar kolom baru yaitu ind_code\ndata['ind_code'] = data.NAICS.apply(get_code)\n\n#Memuat kolom baru yaitu Sector_name\ndata['Sector_name'] = data.ind_code.apply(sector_name)\n\n#Membuat kolom baru yaitu Sector_rate\ndata['Sector_rate'] = data.NAICS.apply(get_code).apply(def_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Meliat kolom NAICS, ind_code, Sector_rate, Sector_name untuk memastikan sudah benar atau belum\ndata[['NAICS','ind_code', 'Sector_rate', 'Sector_name']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Berdasarkan guideline, kita akan membuat kolom State_rate karena setiap daerah memiliki default rate yang berbeda-beda\n#Pertama kita hitung dulu default rate tiap daerah\ndef_state = data.groupby(['State', 'MIS_Status'])['State'].count().unstack('MIS_Status')\ndef_state['Def_Percent'] = def_state[1]/(def_state[1] + def_state[0])\ndef_state = def_state.drop(axis=1, columns=[0.0, 1.0]).round(1).to_dict()\n\n#Kedua,membuat fungsi merubah daerah tersebut sesuai dengan default ratenya\ndef state_def_rate(i):\n    def_state = {'AK': 0.1,'AL': 0.2, 'AR': 0.2, 'AZ': 0.2,'CA': 0.2, 'CO': 0.2, 'CT': 0.1, 'DC': 0.2,\n                 'DE': 0.2, 'FL': 0.3, 'GA': 0.2, 'HI': 0.2, 'IA': 0.1, 'ID': 0.1, 'IL': 0.2, 'IN': 0.2, \n                 'KS': 0.1, 'KY': 0.2, 'LA': 0.2, 'MA': 0.1, 'MD': 0.2, 'ME': 0.1, 'MI': 0.2, 'MN': 0.1,\n                 'MO': 0.2, 'MS': 0.2, 'MT': 0.1, 'NC': 0.2, 'ND': 0.1, 'NE': 0.1, 'NH': 0.1, 'NJ': 0.2,\n                 'NM': 0.1, 'NV': 0.2, 'NY': 0.2, 'OH': 0.2, 'OK': 0.2, 'OR': 0.2, 'PA': 0.1, 'RI': 0.1,\n                 'SC': 0.2, 'SD': 0.1, 'TN': 0.2, 'TX': 0.2, 'UT': 0.2, 'VA': 0.2, 'VT': 0.1, 'WA': 0.1,\n                 'WI': 0.1, 'WV': 0.2, 'WY': 0.1}\n\n    if i in def_state:\n        return def_state[i]\n    \n#Ketiga membuat kolom State_rate    \ndata['State_rate'] = data.State.apply(state_def_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Memastikan Kolom State dan State_rate sudah sesuai\ndata[['State', 'State_rate']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Membuat kolom Portion SBA Aproved Loan\n#kolom ini berisi persen antara jaminan yang diberikan dari SBA dibandingkan dengan pinjaman dari bank\ndata['Portion_SBA_Bank'] = data['SBA_Appv'] / data['GrAppv']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Menurut guideline, data ini diambil dari tahun 1987 - 2014, namun karena kita diminta untuk memasukkan\n#atau membuat kolom baru yakni Recession yang artinya pinjamanya harus melewati massa resessi pada tahun 2007 sampai 2009\n#sehingga data yang diambil hanya sampai tahun 2010 karena rerata lama pinjaman hanya selama 5 tahun atau lebih\ndata = data[data['DisbursementDate'] <= pd.Timestamp(2010, 12, 31)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kita melihat lagi semua dataset kita\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **2.2 Handling Missing Values**\n\nPada tahapan ini kita akan mencoba menghilangkan input-input yang kosong pada dataset kita agar tidak terjadi kesalahan pada saatn pemodelan","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Melihat berapa banyak data yang kosong\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kita akan menghilangkan input yang kosong pad kolom NewExist dengan menggunakan kolom Is_Frenchised\n#kita berasumsi jika Is_Franchised = 0 maka dia New Business, karena biasanya usaha baru tidak punya Franchise\n#jika Is_Franchised = 1 maka dia existing business,kemungkinan dia punya franchise \n# sekarang kita cek asumsi kita, apakah benar dengan melihat perbandingan dua kolom tersebut\ndata[['NewExist', 'Is_Franchised']].head(10)\n\n#ternyata asumsi kita salah, sehingga, kita akan drop saja input yang kosong ini, selain asumsi kita salah\n# dana juga input yang kosong terbilang sangat kecil dibanding dengan totoal jumlah data kita","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kita akan mencoba mengisi input yang kosong pada kolom LowDoc\n#berdasrkan guideline, jika pinjaman < 150.000 maka dia 'Yes' dan jika pinjaman > 150.000 maka dia 'No'\n# dan juga ada beberap input yang kami jadikan Nan jika diluar 'Yes' dan 'No'\n#untuk mengisinya, kita akan menggunakan kolom DisbursementGross\n\ndata['LowDoc'] = np.where((data['LowDoc'] == np.nan) & (data['DisbursementGross'] < 150000),1,data.LowDoc)\ndata['LowDoc'] = np.where((data['LowDoc'] == np.nan) & (data['DisbursementGross'] >= 150000),0,data.LowDoc)\n\ndata = data[(data['LowDoc'] == 0) | (data['LowDoc'] == 1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kita cek lagi kolom LowDoc untuk memastikan\ndata.LowDoc.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Mengisi input yang kosong pada MIS_Status dengan menggunakan kolom CghOffDate\n#jika dia ada tanggal di ChgOffDate, maka dia statusnya CHGOFF, jika tidak maka kosong tanggalnya\ndata['MIS_Status'] = np.where((data['MIS_Status'] == 0.0) & (data['ChgOffDate'] == np.nan),0,data.MIS_Status)\ndata['MIS_Status'] = np.where((data['MIS_Status'] == 1.0) & (data['ChgOffDate'] != np.nan),1,data.MIS_Status)\n\ndata = data[(data['MIS_Status'] == 0) | (data['MIS_Status'] == 1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kita cek lagi apakah sudah benar kolom MIS_Status dengan ChgOffDate\nprint(data[['MIS_Status', 'ChgOffDate']].head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cek kembali kolom MIS_status\ndata.MIS_Status.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kita aka drop kolom yang masih ada input yang kosong karena tidak ada gunanya dan sudah digantikan dengan\n#kolom yang lainya untuk dilakukan EDA sebelum dipilih lagi mana kolom yang akan dimasukkan ke model\n#berdasarkan hubunganya dengan target atau seberapa berdampaknya terhadap target\ndata = data.drop(axis=1, columns=['Name','Bank','NAICS', 'BankState',\n                                  'ChgOffDate','ind_code', 'Active', 'DaysTerm'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Input yang hilang pada kolom LowDoc da MIS_Status tidak bisa diinput dengan kondisi yang telah dibuat\n#sehingga kita drop rownya\ndata.dropna(subset=['City', 'State','LowDoc', 'MIS_Status', \n                    'Sector_rate', 'Sector_name', 'RevLineCr'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kita cek kembali apakah masih ada kolom yang inputnya kosong\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **2.3 Data Exploration**\n\nSebelum ke proses selanjutnya yaitu handling outliers, feature selection dan imbalance class, kita akan coba mencari insight atau melihat apa saja, karena jika sudah masuk ke outliers akan ada perubahan-perubahan pada data dan juga mencari info yang mungkin bisa kita ambil dari data yang kita punya dan kita hilangkan outlier dan skewness jika ada","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kita akan menyesuaikan tipe data dengan input datanya\ndata = data.astype({'UrbanRural': 'object', \n                    'RevLineCr': 'int64', \n                    'LowDoc':'int64', \n                    'MIS_Status':'int64'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Membuat plot jumlah pinjaman setiap tahunya\nf, ax = plt.subplots(figsize=(16,9))\nsns.barplot(x=\"ApprovalFY\", y=\"DisbursementGross\", color='Salmon', data=data)\nplt.title('Jumlah Pinjaman Setiap Tahun', fontsize=20)\nplt.xlabel('Tahun', fontsize=15)\nplt.ylabel('Jumlah Pinjaman ($)', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.DisbursementGross.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Grafik di atas adalah jumlah pinjaman yang diberikan bank setiap tahunya kepada pengusaha. Dapan dilihat bahwa ada beberapa kali penurunan pada tahun 1994 dan 2007. Hal ini disebabkan pada tahun-tahun tersebut mengalama krisi global, sehingga bank akan mengurangi pinjaman kepada pengusaha. Untuk rata-rata pinjaman pertahunya sebesar $190.000â€“$200.000. Mari kitalihat lebih detail lagi berdasarkan sektor.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Membuat plot jumlah pinjaman berdasarkan sektornya\nf, ax = plt.subplots(figsize=(16,9))\nsns.barplot(x=\"DisbursementGross\", y=\"Sector_name\", data=data)\nplt.title('Jumlah Pinjaman Berdasarkan Sektor', fontsize=20)\nplt.xlabel('Jumlah Pinjaman ($)', fontsize=15)\nplt.ylabel('Nama Sektor', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('Sector_name')['DisbursementGross'].describe().style.highlight_max(color='green').highlight_min(color='blue')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seperti kita lihat grafik dan tabel di atas, paling banyak yang mendapatkan pinjaman adalah sektor Management Of Companies & Enterprise dan terendah adalah Public Administration. Jumlah data terbanyak ada pada sektro Retail Trade dan paling sedikit pada sektor Public Administration, sehingga untuk analisa seterusnya kemungkinan paling besar dan kecil pada setiap grafik adalah dua sektor tersebut.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Melihat jumlah yang bayar dan gagal bayar setiap tahunya\nf, ax = plt.subplots(figsize=(16,9))\nsns.countplot(x=\"ApprovalFY\", data=data,hue='MIS_Status')\nplt.title('Jumlah Bayar dan Gagal Bayar Setiap Tahun', fontsize=20)\nplt.xlabel('Tahun', fontsize=15)\nplt.ylabel('Jumlah Pinjaman ($)', fontsize=15)\nplt.legend([\"Tidak\", \"Gagal\"],loc='upper right')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bisa kita lihat bawha ada peningkatan gagal bayar mulai tahun 2006-2008 hal ini sesuai dengan keadaan ekonomi dunia saat itu yang mengalami resesi global, sehingga banyak sekali pengusaha atau bisnis yang sulit untuk melakukan pembayaran.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Melihat jumlah yang bayar & gagal bayar pada setiap sektor\nf, ax = plt.subplots(figsize=(16,9))\nsns.countplot(y=\"Sector_name\", hue=\"MIS_Status\", data=data)\nplt.title('Jumlah Gagal Bayar Bedasarkan Sektor', fontsize=20)\nplt.xlabel('Jumlah Gagal Bayar', fontsize=15)\nplt.ylabel('Nama Sektor', fontsize=15)\nplt.legend([\"Tidak\", \"Gagal\"],loc='lower right')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(data.groupby('Sector_name')['MIS_Status'].value_counts()).unstack(level=1).style.highlight_max(color='green').highlight_min(color='blue')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seperti yang kita ketahui bawha data terbanyak adala Retail Trade, sehingga sektor yang paling banyak baik dalam bayar dan gagal bayar adalah sektor tersebut.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Membuat plot sektor yang aktif saat resesi global tahun 2008\nf, ax = plt.subplots(figsize=(16,9))\nsns.countplot(y=\"Sector_name\", hue=\"Recession\", data=data)\nplt.title('Jumlah Aktif Saat Resesi Bedasarkan Sektor', fontsize=20)\nplt.xlabel('Jumlah Aktif', fontsize=15)\nplt.ylabel('Nama Sektor', fontsize=15)\nplt.legend([\"Tidak\", \"Aktif\"],loc='lower right')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Meliat sektor mana saja yang memiliki jaminan properti\nf, ax = plt.subplots(figsize=(16,9))\nsns.countplot(y=\"Sector_name\", hue=\"RealEstate\", data=data)\nplt.title('Jumlah Sector Yang Memiliki Jaminan Properti', fontsize=20)\nplt.xlabel('Jumlah', fontsize=15)\nplt.ylabel('Nama Sektor', fontsize=15)\nplt.legend([\"Tidak\", \"Punya\"],loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Melihat lebih detail sektor dengan jaminan properti\npd.DataFrame(data.groupby('Sector_name')['RealEstate'].value_counts()).unstack(level=1).style.highlight_max(color='green').highlight_min(color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Melihat lama pinjaman\nf, ax = plt.subplots(figsize=(16,9))\nsns.boxplot(data['Term'])\nplt.title('Lama Pinjaman', fontsize=20)\nplt.xlabel('Bulan', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Melihat detail pinjaman\ndata['Term'].describe() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Melihat pinjaman berdasarkan sektor\nf, ax = plt.subplots(figsize=(16,9))\nsns.boxplot(x=\"Term\", y=\"Sector_name\", data=data)\nplt.title('Lama Pinjaman', fontsize=20)\nplt.xlabel('Bulan', fontsize=15)\nplt.ylabel('Nama Sektor', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Detail pinjaman berdasarkan sektor\ndata.groupby('Sector_name')['Term'].describe().style.highlight_max(color='green').highlight_min(color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Melihat jumlah lapangan pekergja setiap tahun\nf, ax = plt.subplots(figsize=(16,9))\nsns.countplot(x=\"ApprovalFY\", data=data,hue='Is_CreatedJob')\nplt.title('Jumlah Pembuat Lapangan Pekerjaan Setiap Tahun', fontsize=20)\nplt.xlabel('Tahun', fontsize=15)\nplt.ylabel('Jumlah Lapangan Pekerjaan', fontsize=15)\nplt.legend([\"Tidak\", \"Membuat\"],loc='upper right')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Jumlah lapangan kera berdasrkan sektor\nf, ax = plt.subplots(figsize=(16,9))\nsns.countplot(y=\"Sector_name\", hue=\"Is_CreatedJob\", data=data)\nplt.title('Jumlah Lapangan Pekerja Berdasarkan Sektor', fontsize=20)\nplt.xlabel('Jumlah Lapangan Pekerja', fontsize=15)\nplt.ylabel('Nama Sektor', fontsize=15)\nplt.legend([\"Tidak\", \"Ada\"],loc='lower right')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Detail Setiap sektor lapangan kerja\npd.DataFrame(data.groupby('Sector_name')['Is_CreatedJob'].value_counts()).unstack(level=1).style.highlight_max(color='green').highlight_min(color='blue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Melihat jumlah bisnis baru dan lama yang ikut SBA setiap tahun\nf, ax = plt.subplots(figsize=(16,9))\nsns.countplot(x=\"ApprovalFY\", data=data,hue='NewExist')\nplt.title('Jumlah Bisnis Baru dan Lama Setiap Tahun', fontsize=20)\nplt.xlabel('Tahun', fontsize=15)\nplt.ylabel('Jumlah Bisnis', fontsize=15)\nplt.legend([\"Lama\", \"Baru\"],loc='upper right')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Membuat plot Jumla bisnis baru dan lama berdasarkan sektor\nf, ax = plt.subplots(figsize=(16,9))\nsns.countplot(y=\"Sector_name\", hue=\"NewExist\", data=data)\nplt.title('Jumlah Bisnis Baru Atau Lama Berdasarkan Sektor', fontsize=20)\nplt.xlabel('Jumlah Bisnis Baru', fontsize=15)\nplt.ylabel('Nama Sektor', fontsize=15)\nplt.legend([\"Lama\", \"Baru\"],loc='lower right')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Detail Jumla bisnis baru dan lama berdasarkn sektor\npd.DataFrame(data.groupby('Sector_name')['NewExist'].value_counts()).unstack(level=1).style.highlight_max(color='green').highlight_min(color='blue')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  **2.4 Handling Outliers**\n\nKita akan melihat apakah ada outlier di data kita dan akan kita coba untuk menanganinya agar tidak teradi sala interpretasi terhadap target varibel kita. Namun kita perlu cek juga apakah outlier ini sala input atau memang dia anomali.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#kita akan membuang kolom-kolom yang danggap tidak penting\n# kolom LoanNr_ChkDgt tidak penting karena hanya id dari peminjam sudah digantikan dengan index\n# kolom City, State, UrbanRural dan ZIP tidak perlu karena sudah kita ubah menjadi state rate\n# kolom bank dan bank satet juga tidak terlalu penting\n# kolom NAICS karen sudah digantikan dengan Sector_rate\n# kolom ApprovalDate dan ApprovalFY karena hanya pencataan tanggal saja\n# kolom Term dihapus karena sudah digantikan dengan RealEstate\n# kolom UrbanRural karena tidak mempengaruhi target\n# kolom LowDoc karena suda ada Disbursement Gross, LowDoc hanya dikelompokkan saja secara administartif\n# kolom Active dan DaysTerm karena sudah digantikan dengan Recession\n# kolom ind_code karena sudah ada Secator_rate\n# kolom ChgOffDate karena dia sebernya sama dengan MIS_Status\n# kolom DisbursementDate karena hanya tanggan pembayaran\n# kolom SBA_Appv karena sudah digatikan dengan Portion_SBA_Bank\n# kolom DisbursementDate sudah tidak digunakan lagi\n# kolom Sector_name suda tidak digunakan lagi\ndata = data.drop(axis =1, columns = ['LoanNr_ChkDgt','City','State', 'Zip', 'UrbanRural', 'LowDoc',\n                                    'ApprovalDate', 'ApprovalFY', 'SBA_Appv','DisbursementDate', \n                                     'Sector_name','BalanceGross', 'ChgOffPrinGr'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kita akan menggunakan Inter Quartile Range untuk menangani ouliers\n#Menentukan Limit\ndef limit(i):\n    Q1 = data[i].quantile(0.25)\n    Q3 = data[i].quantile(0.75)\n    IQR = Q3 - Q1\n    \n    #menentukan upper limit biasa dan upper limit ekstim\n    lower_limit = data[i].quantile(0.25) - (IQR * 1.5)\n    lower_limit_extreme = data[i].quantile(0.25) - (IQR * 3)\n    upper_limit = data[i].quantile(0.75) + (IQR * 1.5)\n    upper_limit_extreme = data[i].quantile(0.75) + (IQR * 3)\n    print('Lower Limit:', lower_limit)\n    print('Lower Limit Extreme:', lower_limit_extreme)\n    print('Upper Limit:', upper_limit)\n    print('Upper Limit Extreme:', upper_limit_extreme)\n\n#Mengitung persen outliers dari data    \ndef percent_outliers(i):\n    Q1 = data[i].quantile(0.25)\n    Q3 = data[i].quantile(0.75)\n    IQR = Q3 - Q1\n    \n    #menentukan upper limit biasa dan upper limit ekstim\n    lower_limit = data[i].quantile(0.25) - (IQR * 1.5)\n    lower_limit_extreme = data[i].quantile(0.25) - (IQR * 3)\n    upper_limit = data[i].quantile(0.75) + (IQR * 1.5)\n    upper_limit_extreme = data[i].quantile(0.75) + (IQR * 3)\n    #melihat persenan outliers terhadap total data\n    print('Lower Limit: {} %'.format(data[(data[i] >= lower_limit)].shape[0]/ data.shape[0]*100))\n    print('Lower Limit Extereme: {} %'.format(data[(data[i] >= lower_limit_extreme)].shape[0]/data.shape[0]*100))\n    print('Upper Limit: {} %'.format(data[(data[i] >= upper_limit)].shape[0]/ data.shape[0]*100))\n    print('Upper Limit Extereme: {} %'.format(data[(data[i] >= upper_limit_extreme)].shape[0]/data.shape[0]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kita cek kolom DisbursemntGross\nf, ax = plt.subplots(figsize=(16,9))\nsns.boxplot(x=data['DisbursementGross'])\nplt.title('DisbursementGross Ouliers', fontsize=20)\nplt.xlabel('Jumlah', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#kita akan cek limit outliers dan berapa persen dari data kita yang melebihi limit tersebut\nprint(limit('DisbursementGross'))\nprint('-'*50)\nprint(percent_outliers('DisbursementGross'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#karena terdapat 10 % dari jumlah data yang kita punya, maka saya coba merubah datanya dengan menggunakan\n#log transformation, karena jika ouliers dihilangkan sangat banyak sekali data yang hilang (10%)\ndata['DisbursementGross'] = np.log(data['DisbursementGross'])\ndata['DisbursementGross'].skew()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#kita akan cek limit outliers dan berapa persen dari data kita yang melebihi limit tersebut\nprint(limit('DisbursementGross'))\nprint('-'*50)\nprint(percent_outliers('DisbursementGross'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ternyata masih ada sekitar 1% outliers, karena jumlahnya terbilang kecil, maka kita drop saja\noutliers1_drop = data[(data['DisbursementGross'] > 14.9)].index\ndata.drop(outliers1_drop, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#kita cek lagi apakah masiha ada outliers\nf, ax = plt.subplots(figsize=(16,9))\nsns.boxplot(x=data['DisbursementGross'])\nplt.title('DisbursementGross Ouliers', fontsize=20)\nplt.xlabel('Jumlah', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#kita cek pada kolom GrAppv apakah ada outliers\nf, ax = plt.subplots(figsize=(16,9))\nsns.boxplot(x=data['GrAppv'])\nplt.title('GrAppv Outliers', fontsize=20)\nplt.xlabel('Jumlah', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#kita akan cek limit outliers dan berapa persen dari data kita yang melebihi limit tersebut\nprint(limit('GrAppv'))\nprint('-'*50)\nprint(percent_outliers('GrAppv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['GrAppv'] = np.log(data['GrAppv'])\ndata['GrAppv'].skew()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#kita akan cek limit outliers dan berapa persen dari data kita yang melebihi limit tersebut\nprint(limit('GrAppv'))\nprint('-'*50)\nprint(percent_outliers('GrAppv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ternyata masih ada sekitar 1% outliers, karena jumlahnya terbilang kecil, maka kita drop saja\noutliers2_drop = data[(data['GrAppv'] < 7.5)].index\ndata.drop(outliers2_drop, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#kita cek lagi pada kolom GrAppv apakah masih ada outliers\nf, ax = plt.subplots(figsize=(16,9))\nsns.boxplot(x=data['GrAppv'])\nplt.title('GrAppv Outliers', fontsize=20)\nplt.xlabel('Jumlah', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#kita cek ouliers pada kolom NoEmp\nf, ax = plt.subplots(figsize=(16,9))\nsns.boxplot(x=data['NoEmp'])\nplt.title('NoEmp Ouliers', fontsize=20)\nplt.xlabel('Jumlah', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#kita akan cek limit outliers dan berapa persen dari data kita yang melebihi limit tersebut\nprint(limit('NoEmp'))\nprint('-'*50)\nprint(percent_outliers('NoEmp'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pada kolom NoEmp, terdapat iput 0, aka saya anggap ini kesalahan, input, karena tidak mungkin sebuah perusahaan\n#tidak memiliki karyawan\nwrong_input = data[(data['NoEmp'] == 0)].index\ndata.drop(wrong_input, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#melakukan boxcox transformasi karena semua metode tela saya coba namun ini yang paling baik hasilnya\ndata['NoEmp']= stats.boxcox(data['NoEmp'])[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['NoEmp'].skew()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#kita akan cek lagi limit outliers dan berapa persen dari data kita yang melebihi limit tersebut\nprint(limit('NoEmp'))\nprint('-'*50)\nprint(percent_outliers('NoEmp'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ternyata masih ada sekitar 0.02% outliers, karena jumlahnya terbilang kecil, maka kita drop saja\noutliers3_drop = data[(data['NoEmp'] > 3.3)].index\ndata.drop(outliers3_drop, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#kita cek ouliers lagi pada kolom NoEmp\nf, ax = plt.subplots(figsize=(16,9))\nsns.boxplot(x=data['NoEmp'])\nplt.title('NoEmp Ouliers', fontsize=20)\nplt.xlabel('Jumlah', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#kita cek ouliers pada kolom Term\nf, ax = plt.subplots(figsize=(16,9))\nsns.boxplot(x=data['Term'])\nplt.title('Term Ouliers', fontsize=20)\nplt.xlabel('Bulan', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Karena terdapat data yang lama pinajamanya 0 bulan dan 43 tahun \n#karena tidak mungkin ada waktu 0 dan 569 bulan (43 tahun) \n#sedangkan pengambilan data yang kita punya hanya dari tahun 1987â€“2010 (23 tahun),\n#sehingga minimal 5 tahun (75 bulan) atau maksimal 23 tahun (276 bulan)\nwrong_input_2 = data[(data['Term'] < 75)].index\nwrong_input_3 = data[(data['Term'] > 276)].index\ndata.drop(wrong_input_2, inplace=True)\ndata.drop(wrong_input_3, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#kita cek lagi ouliers pada kolom Term\nf, ax = plt.subplots(figsize=(16,9))\nsns.boxplot(x=data['Term'])\nplt.title('Term Ouliers', fontsize=20)\nplt.xlabel('Bulan', fontsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#kita akan cek lagi limit outliers dan berapa persen dari data kita yang melebihi limit tersebut\nprint(limit('Term'))\nprint('-'*50)\nprint(percent_outliers('Term'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#kita tidak akan drop outlier ini, karena selain jumlanya banyak (18%) ini belum tentu salah input, karena memang\n#beberapa industri bisa mengambil jangka waktu pinjaman yang lama seperti oil & gas tau mining","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **2.5 Feature Selection**\n\nTahap ini kita akan memilih atau mencari feature mana saja yang paling relefan dengan target kita. Saya suda mencoba dengan menggunakan KBest dan Feature Importance dan saya juga tidak memnggunkan corelation coeficient karena target variabelnya dan ada beberapa independen variabel yang kategorikal. Namun setela dimasukkan ke dalam model yang paling bagus adalah Fetaure Importance.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#karena data memiliki jumlah input yang sangat banyak, maka saya akan menggunakan teknik feature importance pada fetaure selection\n#kita akan memisahkan dulu independen dan dependen featurenya\n#data = data.reset_index(drop=True) #reset index dulu biar urut indexnya\ny = data['MIS_Status']\nX = data.drop(columns=['MIS_Status'], axis=1)\n\n#kita coba menggunakan fetaure importance pada model XGboost\nmodel = XGBClassifier()\nmodel.fit(X,y)\n\n#Kita visualisasi feature yang penting-penting\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nf, ax = plt.subplots(figsize=(16,9))\nfeat_importances.nlargest(10).plot(kind='barh')\nplt.title('Feature Importance', fontsize=20)\nplt.ylabel('Features', fontsize=15)\nplt.xlabel('Score', fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Bisa diliat bahwa ini adala 10 variabel yang memiliki pengaru terhadap target kitag:\n1. Term (Lama Pinjaman) = sangat masuk akal sekali ini menjadi yang tertinggi karena jika sebuah perusahaan meminjam dengan jangka waktu yang lama, kemungkinan untuk kembali mengembaklikanya akan lebih besar dikarenan bunga yang diberikan akan semakin kecil, sehingga memudahkan perusahaan untuk membayarnya dan kestabilan secara ekonomi secara nasional maupun internasional yang tidak terlalu berdampak yang akhirnya membuat perusaaan mengurangi kemungkinan untuk gagal bayar.\n\n\n2. RevLineCr = Revolving Line of credit ini adalah ketika suda minjam terus minjam lagi. Bisa dikatakan bahwa jika dia bisa melakukan Revolving maka pihak bank sudah menilai bahwa perusahaan ini mampu dalam membayar pinjamanya sehingga diberikan pinjaman lagi. Jadi jika perusahaan ini Revolving Line Of Credit juga membuat perusahaan mengurangi kemungkinan untuk gagal bayar.\n\n\n3. Portion_SBA_Bank = Ini merupakan seberapa banyak pihak SBA berani untuk memberikan jaminan dari pijamana yang diberikan oleh Bank. Semakin besar persenenanya otomatis pihak SBA cukup yakin dengan perusahaan tersebut untuk tidak gagal bayar.\n\n\n4. Is_RetainedJob = Apakah perusahaan memiliki karyawan tetap? Karena jika tidak, kemungkinan perusahaan tersebut belum stabil karena belum mampu untuk memiliki karyawan tetap. Jika belum stabil, maka kemungkinan untuk maksimal dalam bisnisnya juga belum, sehingga meningkatkan kemungkinan untuk gagal bayar.\n\n\n5. DisbursementGross = Menjadi sala satu faktor yang penting juga karena jumlah pinjaman yang dibayarkan apakah ada penalti atau sesuai dengan pinjaman diawal, jika lebih maka kemungkinan dia ada penalti.\n\n\n6. State_rate = Perlu diingat bahwa kebijakan setiap daera berbeda-beda dan juga ini dihitung dengan berapa rerata setiap daerah yang gagal bayar dari semua sektor, sehingga semakin tinggi maka semakin kemungkinan dia gagal bayar.\n\n\n7. GrAppv = Merupakan jumlah pinjaman yang diberikan oleh bank. Kita tidak bisa melihat dari satu sisi ini saja karena dari pihak bank juga memiliki ukuran tersendiri. \n\n\n8. Recssion = Jika dia aktif ketika masa-masa sulit sperti resesi, maka kemungkinan bisnisnya stabil, karena pada saat susapun dia tetap aktif, sehingga kemungkinan untuk gagal bayarnya menjadi lebi kecil.\n\n\n9. Sector_rate = seperti halnya State rate, setiap sektor juga memiliki default rate atau persentase kemungkinan gagal bayarnya masing-masing. Karena tidak mungkin bisa disamakan untuk sektor oil& gas, mining disamakan dengan Retail Trade karena resiko dan kestabilan dari bisnisnya berbeda-beda.\n\n\n10. Is_CreatedJob =  Membuka lapangan pekerjaan menjadi perhitungan juga karena dengan membuka lapangan pekerjaan terlihat bahwa perusahaan tersebut berkembang secara operasional dengan meningkatnya karyawan yang direkrut, sehingga jika perusahaan tersebut berkembang maka akan memperkecil kemungkinan dalam gagal bayar.\n\n\nPerlu menjadi catatan bahwa semua variabel ini tidak bisa dilihat hanya dari satu sisi belaka, namun ada kaitan antar variabel. Karena latar belakang saya bukan seoarang banking, ekonom ataupun keuangan maka saya menganalisa ini berdasarkan logika dan guideline yang disediakan SBA. Perlu ada seorang dari business domain yang lebih mampu menjelaskan variabel-variabel ini terhadap kemungkinan gagal bayar.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Berdasarkan feature selection diatas, kita akan pilih, feature-feature tersebut dan membuang\n#feature-feature yang tidak relefan dengan target\ndata = data[['RevLineCr', 'Term', 'Portion_SBA_Bank', 'GrAppv', 'State_rate', 'DisbursementGross',\n            'Is_RetainedJob', 'Sector_rate', 'Recession', 'Is_CreatedJob', 'MIS_Status']]\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## **2.6 Imbalance Dataset**\n \nKarena ini adalah problem klasifikasi dan target variabel pada dataset yang kita miliki ini perbandingan yang sangat jau kerena persentase yang gagal bayar pasti lebih sedikit dibandingkan dengan yang berhasil, sehingga kita perlu menangani hal ini agar ketika nanti masuk ke dalam model tidak teradi bias karena terjadinya perbedaan ration apda target variabel.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kita cek ratio target variabel\nprint(data.MIS_Status.value_counts())\nprint('-'*50)\nprint('MIS_Status (0): {} %'.format(data[(data['MIS_Status'] == 0)].shape[0]/data.shape[0]*100))\nprint('MIS_Status (1): {} %'.format(data[(data['MIS_Status'] == 1)].shape[0]/data.shape[0]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualisasi Imbalance Dataset Sebelum Dibenahi\nsns.countplot(\"MIS_Status\",data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"bisa dilihat bahwa target variabel kita imbalance atau tidak seimbang, 0 (Tidak Default): 94.3% dan 1(Default): 5.7% sehingga kita akan menangani masalah ini, karena jika tidak model akan lebih cenderung memprediksi 0 karena lebih banyak dalam jumlah","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#pertama kita akan membagi data menjadi train dan test, namun perlu diingat, jika target data kita imbalance\n#sehingga kita membagi data di traindan testnya harus sesuai, jadi tidak boleh dalam pembagian datanya ada yang \n#hanya berisi 0 atau yang mayoritas aja, makanya kita menggunakan stratify=y\ny = data['MIS_Status']\nX = data.drop(columns=['MIS_Status'], axis=1)\nscale = StandardScaler()\nX_scaled = scale.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=27, stratify=y) #jangan lupa untuk stratify","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Disini saya mengggunaka SMOTE dan kemudian di undersampling lagi\nover = SMOTE(sampling_strategy='minority')\nunder = RandomUnderSampler()\nsteps = [('o', over), ('u', under)]\npipeline = Pipeline(steps=steps)\n\n#sekarang kita fit ke training data kita\nX_train, y_train = pipeline.fit_resample(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **3. MODELLING**\n\nSetelah semua data sudah bersih dan siap dimasukkan ke dalam model, maka ini saatnya kita membuat model dan mencari model yang paling tetap. Disini saya langsung evaluasii setela membuat model, dilatih dan dites agar memudahkan melihat model mana yang paling optimal.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Membuat fungsi yang nanti sekalin bisa training dan tes kemudian dievalusi\ndef model_eval(algo,X_train,y_train,X_test,y_test):\n    algo.fit(X_train,y_train)\n    y_train_ypred = algo.predict(X_train)\n    y_train_prob = algo.predict_proba(X_train)[:,-1]\n\n    #TEST\n\n    y_test_ypred = algo.predict(X_test)\n    y_test_prob = algo.predict_proba(X_test)[:,-1]\n    y_probas = algo.predict_proba(X_test)\n    \n    #Confussion Matrix\n    plot_confusion_matrix(algo, X_test, y_test)\n    plt.show() \n    print('='*100)\n    print('Classification Report: \\n', classification_report(y_test, y_test_ypred, digits=3))\n    print('='*100)\n    \n    #ROC Curve\n    #fpr,tpr,thresholds = roc_curve(y_test,y_test_prob)\n    skplt.metrics.plot_roc(y_test, y_probas,figsize=(16,9) )\n    \n    #PR Curve\n    skplt.metrics.plot_precision_recall(y_test, y_probas, figsize=(16,9))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using Logistic Regression\nlr = LogisticRegression()\nmodel_eval(lr,X_train,y_train,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sekarang kita coba menggunakan Naive Bayes\nnb = GaussianNB()\nmodel_eval(nb,X_train,y_train,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sekarang kita coba menggunakan KNN\nknn = KNeighborsClassifier()\nmodel_eval(knn,X_train,y_train,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sekarang kita coba Random Forest\nrf = RandomForestClassifier()\nmodel_eval(rf,X_train,y_train,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sekarang kita coba menggunakan XGBoost\nxgb = XGBClassifier()\nmodel_eval(xgb,X_train,y_train,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **4. MODEL TUNNING**\n\nKarena dari model yang di atas bisa kita simpulkan bahwa XGBoost adala yang terbaik namun bisa kita lihat performa Precission dan Recallnya sangat jauh sekali, maka saya meggunakan scoringnya F-1 Score agar keduanya cukup optimal","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#kita membuat function opmitasi, disinia saya menggunakan GridSearchCV\ndef model_opt(clf, params,X_train,y_train,X_test,y_test ):\n    # Load GridSearchCV\n    search = GridSearchCV(estimator=clf,\n                          param_grid=params,\n                          scoring = 'f1',\n                          n_jobs = -1,\n                          cv = 3,\n                          verbose=True)\n\n    # Train search object\n    search.fit(X_train, y_train)\n    \n    best = search.best_estimator_\n    best_model = best.fit(X_train, y_train)\n    \n    #### TEST\n\n    y_test_ypred = best_model.predict(X_test)\n    y_test_prob = best_model.predict_proba(X_test)[:,-1]\n    y_probas = best_model.predict_proba(X_test)\n    \n    print('Best parameters: \\n',search.best_params_)\n    print('='*70)\n    #Confussion Matrix\n    plot_confusion_matrix(algo, X_test, y_test)\n    plt.show() \n    print('='*100)\n    print('Classification Report: \\n', classification_report(y_test, y_test_ypred, digits=3))\n    print('='*100)\n    \n    #ROC Curve\n    #fpr,tpr,thresholds = roc_curve(y_test,y_test_prob)\n    skplt.metrics.plot_roc(y_test, y_probas,figsize=(16,9) )\n    \n    #PR Curve\n    skplt.metrics.plot_precision_recall(y_test, y_probas, figsize=(16,9))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params ={\"learning_rate\"    : [0.05, 0.10, 0.15] ,\n         \"max_depth\"        : [ 3, 4, 5, 6],\n         \"min_child_weight\" : [ 1, 3, 5, 7 ],\n         \"gamma\"            : [ 0.0, 0.1, 0.2 ],\n         \"colsample_bytree\" : [ 0.3, 0.4, 0.5] }\n\n#Saya sudah mencari dengan GridSearcCV dan menemukan parameterterbaik\n{'colsample_bytree': 0.5, 'gamma': 0.0, 'learning_rate': 0.15, 'max_depth': 6, 'min_child_weight': 1}\n\n#sekarnag kita coba pada model setelah ditunning\nxgb = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n                    colsample_bynode=1, colsample_bytree=0.5, gamma=0.0,\n                    learning_rate=0.15, max_delta_step=0, max_depth=6,\n                    min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n                    nthread=None, objective='binary:logistic', random_state=0,\n                    reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n                    silent=None, subsample=1, verbosity=1)\n\nmodel_eval(xgb,X_train,y_train,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ada sedikit peningkatan pada Recall yang sebelumnya 79.5 % sekarang 85.1 %. Memang anatara Recall dan Precission akan teradi trade-off maka saya menggunakan scoring pada GridScearchCV adala F1-Score karena mencoba mengharmonikan keduanya. Perlu diingat kembali bahwa dataset ini imbalance atau tidak seimbang pada target variabelnya.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **5. DEPLOYMENT**\n\nSetelah semua dirasa cukup dan optimal, sekarang waktunya untuk deployment dengan menggunakan Streamlit dan Heroku. Disini saya anya membuat aplikasi sederhana saja. Untuk melihat lebi detail terkait deployment, sila cek di file yang ada di repository atau untuk melihat hasilnya cek di link berikutt:\n\n\nhttps://sba-farras-app.herokuapp.com/","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **6. KESIMPULAN**\n\nDari semua tahapan yang telah kita lewati, ada beberapa kesimpulan yang bisa daimbil dari project kali ini:\n\n1. Model terbaik adalah XGBoost dengan Micro Average PR AUC 98.9%, Recall 85.1%, Precission 51% hasil paramter tunning sebagai berikut:\n  * colsample_bytree: 0.5, \n  * gamma: 0.0, \n  * learning_rate: 0.15, \n  * max_depth: 6, \n  * min_child_weight: 1\n  \n\n2. Variabel yang relefan atau berpengaruh terhadap target adalah: \n  * Term \n  * RevLineCr \n  * Portion_SBA_Bank \n  * Is_RetainedJob \n  * DisbursementGross \n  * State_rate \n  * GrAppv \n  * Recssion \n  * Sector_rate \n  \n\n3. Perlu adanya seoarang yang memeiliki backgroung ataupun domain expertise bidang keuangan atau banking karena penentuan treshold pada model tunning sangat mempengaruhi prediksi\n\n\n4. Dicoba tunning kembali dengan berbagai hyperparamter yang lain, karena kemampuan komputer saya terbatas :)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}