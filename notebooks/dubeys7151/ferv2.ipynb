{"cells":[{"metadata":{"_uuid":"b607aa1f-de2d-4bd5-9d28-9f5c398df0c6","_cell_guid":"075a76a4-502d-4361-965a-8646732c2d93","trusted":true,"scrolled":false},"cell_type":"code","source":"\nfrom keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport cv2 \nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import SGD\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndata= pd.read_csv('../input/fer2013.csv')\n\n\nheight,width,depth = 48,48,1\n\ndata.head()\n\nprint(\"Data Distribution\")\nprint(data.Usage.value_counts())\n\nprint('Samples/emotion:')\nprint(data.emotion.value_counts())\n\nprint('pixels/sample:')\nprint(len(data.pixels[0].split(' ')))\n\nemotion_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\nnum_classes = len(emotion_labels)\n\ndef convert_fer2013(data):\n    pixels = data['pixels'].tolist()\n\n    faces = []\n    for pixel_sq in pixels:\n        face = [int(pixel) for pixel in pixel_sq.split(' ')]\n        face = np.asarray(face).reshape(width, height)\n        face = cv2.resize(face.astype('uint8'), (width, height))\n        face = np.stack((face,)*3, -1)\n        faces.append(face.astype('float32'))\n\n    faces = np.asarray(faces)\n    emotions = pd.get_dummies(data['emotion']).as_matrix()\n\n    return faces, emotions\n\nX, y = convert_fer2013(data)\n\n\ndef normalize(imgs):\n    new_imgs = []\n    for img in imgs:\n        img = img / 255.0\n        new_imgs.append(img)\n\n    return new_imgs\n\nX = np.array(normalize(X))\n\n\ndef overview(start, end, X):\n    fig = plt.figure(figsize=(20,20))\n    for i in range(start, end):\n        input_img = X[i:(i+1),:,:,:]\n        ax = fig.add_subplot(10,10,i+1)\n        ax.imshow(input_img[0,:,:,0], cmap=matplotlib.cm.gray)\n        plt.xticks(np.array([]))\n        plt.yticks(np.array([]))\n        plt.tight_layout()\n    plt.show()\noverview(0,5, X)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.1,\n                                                    random_state=41)\n\ndef transfer_learning(model):\n    for layer in model.layers:\n        layer.trainable = False\n        \nmodel_vgg = VGG16(include_top=False,\n              weights='imagenet',\n              pooling='avg')\nmodel_resnet = ResNet50(include_top=False,\n              weights='imagenet',\n              pooling='avg')\nmodel_inception = InceptionV3(include_top=False,\n              weights='imagenet',\n              pooling='avg')\n\nmodels = [model_vgg,model_resnet,model_inception]\nmodel_name = [\"VGG\",\"RESNET\",\"GoogleNet\"]\n\ndef training_model(para):\n#     i =0;\n#     for model in models:\n    #print(\"Training model \" + model_name[i])\n    model = para;\n    x = model.output\n\n    y = Dense(num_classes,\n            activation='softmax')(x)\n\n    final_model = Model(input=model.input,\n                                output=y)\n        \n    opt = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n\n    final_model.compile(optimizer=opt,\n                                loss=categorical_crossentropy,\n                                metrics=['accuracy'])\n\n\n    final_model.fit(X_train, y_train,\n                        batch_size=32,\n                            epochs=10,\n                            validation_split=0.1,\n                            shuffle=True,\n                            verbose=2)\n\n    for layer in final_model.layers[4:]:\n        layer.trainable = True\n\n    final_model.compile(optimizer=opt,\n                                loss=categorical_crossentropy,\n                                metrics=['accuracy'])\n    scores = final_model.evaluate(X_test, y_test,\n                                  batch_size=32)\n\n    print(\"Loss\"+ str(scores[0]))\n    print(\"Accuracy\"+ str(scores[1]))\n#             i=i+1;\n        \nprint(\"training VGG\")\ntraining_model(model_vgg)\nprint(\"training Resnet\")\ntraining_model(model_resnet)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}