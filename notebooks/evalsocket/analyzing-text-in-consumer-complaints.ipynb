{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"e56de669-20b3-4dd1-8724-0d4c32ee1d65"},"source":"# Analyzing Text in Consumer Complaint Narratives\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ce917388-8c6b-4415-b2e1-c7402d010c42"},"outputs":[],"source":"# Read in data from pandas\nimport pandas as pd\n\n# This is used for fast string concatination\nfrom io import StringIO\n\n# Use nltk for valid words\nimport nltk\n# Need to make hash 'dictionaries' from nltk for fast processing\nimport collections as co\n\n\nimport warnings # current version of seaborn generates a bunch of warnings that we'll ignore\nwarnings.filterwarnings(\"ignore\")\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(style=\"white\", color_codes=True)\n\n# Read the input\nd = pd.read_csv(\"../input/consumer_complaints.csv\") # the consumer dataset is now a Pandas DataFrame\n# Only interested in data with consumer complaints\nd=d[d['consumer_complaint_narrative'].notnull()]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ee5b557b-167f-4a53-89f1-37bfc273db53"},"outputs":[],"source":"# We want a very fast way to concat strings.\n#  Try += if you don't believe this method is faster.\ns=StringIO()\nd['consumer_complaint_narrative'].apply(lambda x: s.write(x))\n\nk=s.getvalue()\ns.close()\nk=k.lower()\nk=k.split()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6a351c77-62ef-4d6c-afe8-d8ac4ccaf566"},"outputs":[],"source":"# Next only want valid strings\nwords = co.Counter(nltk.corpus.words.words())\nstopWords =co.Counter( nltk.corpus.stopwords.words() )\nk=[i for i in k if i in words and i not in stopWords]\ns=\" \".join(k)\nc = co.Counter(k)\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"0c7ba352-e66b-4714-9328-81ca99038ef5"},"source":"## At this point we have k,s and c\n**k** Array of words, with stop words removed\n\n**s** Concatinated string of all comments\n\n**c** Collection of words"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9e2a3790-d300-4390-abbf-b08ee80f2fca"},"outputs":[],"source":"# Take a look at the 14 most common words\nc.most_common(14)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"45e31af4-cc1e-4eac-8676-7614acd46c48"},"outputs":[],"source":"s[0:100]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b7a6c9de-36b1-4203-88e4-f57bcec79bfc"},"outputs":[],"source":"print(k[0:10],\"\\n\\nLength of k %s\" % len(k))"},{"cell_type":"markdown","metadata":{"_cell_guid":"1332f89a-72c1-4af7-861f-f3c0ae5ef3fa"},"source":"## Word Cloud\nAt this point we have some data, so it might be a good idea to take a look at it.\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"90446b6b-50bb-4c1b-b72e-f9f6a349067d"},"outputs":[],"source":"from wordcloud import WordCloud\n\n# Read the whole text.\ntext = s\n\n# Generate a word cloud image\nwordcloud = WordCloud().generate(text)\n\n# Display the generated image:\n# the matplotlib way:\nimport matplotlib.pyplot as plt\n\n\n# take relative word frequencies into account, lower max_font_size\nwordcloud = WordCloud(background_color=\"white\",max_words=len(k),max_font_size=40, relative_scaling=.8).generate(text)\nplt.figure()\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"358caeb2-7350-4444-9690-39c988de2dfe"},"source":"## Taking a look at their stories\nThese stories claim to involve identity theft and or fraud.\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5f1df5c9-1e11-4675-9de2-0c168262ca2c"},"outputs":[],"source":"# Let's get some text involving identity theft\nsearchS='victim of identity theft'\nvi = d[d['consumer_complaint_narrative'].str.find(searchS) >= 0]\nd['victim']=None\nd['e']=1\nd['m']=None  # This will be for 'Closed with monetary relief'\nd['victim'] = d[d['consumer_complaint_narrative'].str.find(searchS) >= 0]\nd['m']=d[d['company_response_to_consumer'] == 'Closed with monetary relief']\n\n\n# Take a look at some sample stories  mindex to mindex_inc\n# Adjust this, to see different stories\nmindex=20\nmindex_inc=5+mindex\nsi=StringIO()\nvi['consumer_complaint_narrative'].iloc[mindex:mindex_inc].apply(lambda x: si.write(x+'\\n___\\n\\n'))\n\nt=si.getvalue()\nsi.close()\nprint(t)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8e3a9478-a1cf-4be0-be1f-a3a48926f842"},"outputs":[],"source":"# We might be missing data on just fraud...\n# Search for all cases of theft or fraud\nsearchS0='victim'\nsearchS1='identity'\nsearchS_OR=['theft','fraud']\n\nvi2 = d[(d['consumer_complaint_narrative'].str.find(searchS0) >= 0) &\n        (d['consumer_complaint_narrative'].str.find(searchS1) >= 0) &\n       ( (d['consumer_complaint_narrative'].str.find(searchS_OR[0]) >= 0) |\n        (d['consumer_complaint_narrative'].str.find(searchS_OR[1]) >= 0))\n        ]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9e85e113-dea5-4d05-bc25-5dffcb72047e"},"outputs":[],"source":"# vi2.count()\n\ng=vi2.groupby(['issue'])\ngg=g.count().reset_index()\ngg.sort_values(by='e',inplace=True)\ngg=g['e','victim','m'].count().reset_index()\ngg.sort_values(by='e',inplace=True, ascending=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4151b22c-a2cb-4e71-bc98-9a068399f2ee"},"outputs":[],"source":"# Taking a look at common complaints\n# Need to format this...but note only 9 cases where it\n# was \"Closed with monetary relief\"  m==1\n\n#gg.head(4)\nwith pd.option_context('display.max_rows', 10, 'display.max_columns', 4):\n    print(gg)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}