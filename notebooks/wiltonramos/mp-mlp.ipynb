{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# IF648EC - Sistemas Inteligentes\nCaderno para a disciplina IF648EC da Universidade Federal de Pernambuco.\nConstruído por Wilton Ramos da Silva","metadata":{}},{"cell_type":"markdown","source":"# 1. Introdução\n\nEste projeto utiliza redes MLPs para tratar um conjunto de dados de Sintomas de Lombalgia. A dor lombar crônica é uma das principais causas de incapacidade em todo o mundo. Dados revelam que a prevalência dessa dor em adultos aumentou mais de 100% na última década e tende a aumentar nas populações mais velhas. Em geral, o diagnóstico de lombalgia é complexo e depende de vários fatores. Por tanto, temos como objetivo criar um sistema capaz de identificar pacientes que possam sofrer dessa doença a partir de determinadas características. ","metadata":{}},{"cell_type":"markdown","source":"# 2. Importar dados e bibliotecas\nInicialmente, importaremos as bibliotecas e os dados necessários.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, plot_confusion_matrix, confusion_matrix","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-12T18:26:17.148702Z","iopub.execute_input":"2021-08-12T18:26:17.149327Z","iopub.status.idle":"2021-08-12T18:26:18.177344Z","shell.execute_reply.started":"2021-08-12T18:26:17.149204Z","shell.execute_reply":"2021-08-12T18:26:18.176335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/lower-back-pain-symptoms-dataset/Dataset_spine.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:18.179231Z","iopub.execute_input":"2021-08-12T18:26:18.179676Z","iopub.status.idle":"2021-08-12T18:26:18.202155Z","shell.execute_reply.started":"2021-08-12T18:26:18.179631Z","shell.execute_reply":"2021-08-12T18:26:18.201212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Agora, iremos visualizar o que temos em data","metadata":{}},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:18.204299Z","iopub.execute_input":"2021-08-12T18:26:18.204705Z","iopub.status.idle":"2021-08-12T18:26:18.25007Z","shell.execute_reply.started":"2021-08-12T18:26:18.204663Z","shell.execute_reply":"2021-08-12T18:26:18.249109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como vemos, o dado que estamos trabalhando é um tabela de 310 linhas e 14 colunas. Contudo, a última coluna (\"Unnamed: 13\") não possui nenhum dado útil. Por isso, iremos retirar essa coluna da tabela.","metadata":{}},{"cell_type":"code","source":"data = data.drop(['Unnamed: 13'], axis = 1)\ndata","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:18.251798Z","iopub.execute_input":"2021-08-12T18:26:18.252093Z","iopub.status.idle":"2021-08-12T18:26:18.286462Z","shell.execute_reply.started":"2021-08-12T18:26:18.252065Z","shell.execute_reply":"2021-08-12T18:26:18.285327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Para poder treinar e testar nossa rede, inicialmente divideremos data em dois conjuntos distintos. Um conjunto y, que possuíra a coluna Class_att; um conjunto x, que possuíra o restante de data. Em seguida, repartiremos 20% para treino e 80% para teste do nosso modelo.","metadata":{}},{"cell_type":"code","source":"y = data['Class_att']\nx = data.drop(['Class_att'], axis = 1)\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 13)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:18.28816Z","iopub.execute_input":"2021-08-12T18:26:18.288488Z","iopub.status.idle":"2021-08-12T18:26:18.298097Z","shell.execute_reply.started":"2021-08-12T18:26:18.288456Z","shell.execute_reply":"2021-08-12T18:26:18.29692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Treino 1\nUtilizaremos a biblioteca SKLearn para criar nossa rede MLP. Inicialmente, utilizaremos os seus parâmetros padrões.","metadata":{}},{"cell_type":"code","source":"MLP_classifier = MLPClassifier(random_state = 13, verbose = False)\nMLP_classifier.get_params()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:18.299506Z","iopub.execute_input":"2021-08-12T18:26:18.299883Z","iopub.status.idle":"2021-08-12T18:26:18.31011Z","shell.execute_reply.started":"2021-08-12T18:26:18.299823Z","shell.execute_reply":"2021-08-12T18:26:18.309439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Iremos, então, treinar nosso modelo utilizando os conjuntos x_test e y_test","metadata":{}},{"cell_type":"code","source":"MLP_classifier.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:18.310992Z","iopub.execute_input":"2021-08-12T18:26:18.311278Z","iopub.status.idle":"2021-08-12T18:26:18.873728Z","shell.execute_reply.started":"2021-08-12T18:26:18.311253Z","shell.execute_reply":"2021-08-12T18:26:18.87261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Resultados do treino 1\nObservaremos os resultados do treino.","metadata":{}},{"cell_type":"code","source":"y_pred = MLP_classifier.predict(x_test)\nMLP_classifier.score(x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:18.877473Z","iopub.execute_input":"2021-08-12T18:26:18.878335Z","iopub.status.idle":"2021-08-12T18:26:18.897883Z","shell.execute_reply.started":"2021-08-12T18:26:18.878279Z","shell.execute_reply":"2021-08-12T18:26:18.8968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Com os parâmetros padrões, obtivemos um modelo com acurácia de 83%.","metadata":{}},{"cell_type":"markdown","source":"Agora, podemos analisar o relatório de classificação:","metadata":{}},{"cell_type":"code","source":"report = classification_report(y_test, y_pred)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:18.90026Z","iopub.execute_input":"2021-08-12T18:26:18.901028Z","iopub.status.idle":"2021-08-12T18:26:18.9194Z","shell.execute_reply.started":"2021-08-12T18:26:18.900954Z","shell.execute_reply":"2021-08-12T18:26:18.918306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Em relação à precisão, para o nosso modelo tivemos 92% para abnormal e 71% para normal. Ou seja, a chance de algum paciente em condições normais ser diagnosticado com lombalgia é de 8%, enquanto que a chance de um paciente com a doença ser classificado erroneamente como saudável é de 29%.","metadata":{}},{"cell_type":"markdown","source":"Também vale comentar sobre a taxa de recall. Conseguimos extrair que 15% das pessoas saudáveis foram erroneamenge classificadas como doentes. Já aqueles que estão doentes, 17% foram classificados como saudáveis.","metadata":{}},{"cell_type":"markdown","source":"# 5. Treino 2\nVamos, agora, ver como o sistema se comporta ao modificar a função de ativação e aumentar o número de iterações","metadata":{}},{"cell_type":"code","source":"MLP_classifier_ID = MLPClassifier(activation = 'identity', max_iter = 500,random_state = 13, verbose = False)\nMLP_classifier_LG = MLPClassifier(activation = 'logistic', max_iter = 500,random_state = 13, verbose = False)\nMLP_classifier_TH = MLPClassifier(activation = 'tanh', max_iter = 500,random_state = 13, verbose = False)\nMLP_classifier_ID.fit(x_train, y_train)\nMLP_classifier_LG.fit(x_train, y_train)\nMLP_classifier_TH.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:18.921264Z","iopub.execute_input":"2021-08-12T18:26:18.922043Z","iopub.status.idle":"2021-08-12T18:26:24.138654Z","shell.execute_reply.started":"2021-08-12T18:26:18.92197Z","shell.execute_reply":"2021-08-12T18:26:24.137444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = MLP_classifier_ID.predict(x_test)\nprint(MLP_classifier_ID.score(x_test, y_test))\nreport = classification_report(y_test, y_pred)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:24.140491Z","iopub.execute_input":"2021-08-12T18:26:24.141033Z","iopub.status.idle":"2021-08-12T18:26:24.166936Z","shell.execute_reply.started":"2021-08-12T18:26:24.140976Z","shell.execute_reply":"2021-08-12T18:26:24.165788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Para a função identity, em que f(x) = x, o modelo obteve uma acurácia de 85%. Em relação à precisão, percebemos 95% para abnormal e 72% para normal. Enquanto que na taxa de recall, nota-se 83% para abnormal e 90% para normal. Vale ressaltar que entre as funções testadas nesta seção, essa foi a única que conseguiu convergir.","metadata":{}},{"cell_type":"code","source":"y_pred = MLP_classifier_LG.predict(x_test)\nprint(MLP_classifier_LG.score(x_test, y_test))\nreport = classification_report(y_test, y_pred)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:24.168409Z","iopub.execute_input":"2021-08-12T18:26:24.169106Z","iopub.status.idle":"2021-08-12T18:26:24.194403Z","shell.execute_reply.started":"2021-08-12T18:26:24.169064Z","shell.execute_reply":"2021-08-12T18:26:24.19341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Já para a função logistic, em que  f(x) = 1 / (1 + exp(-x)), o modelo atingiu o número limite de iterações sem convergir, mas ainda respondeu com uma acurácia de 85%. Em relação à precisão, percebemos 97% para abnormal e 70% para normal. Enquanto que na taxa de recall, nota-se 81% para abnormal e 95% para normal (a maior entre as funções disponíveis).","metadata":{}},{"cell_type":"code","source":"y_pred = MLP_classifier_TH.predict(x_test)\nprint(MLP_classifier_TH.score(x_test, y_test))\nreport = classification_report(y_test, y_pred)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:24.195894Z","iopub.execute_input":"2021-08-12T18:26:24.196469Z","iopub.status.idle":"2021-08-12T18:26:24.221812Z","shell.execute_reply.started":"2021-08-12T18:26:24.196427Z","shell.execute_reply":"2021-08-12T18:26:24.220783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Por fim, a função tanh, em que  f(x) = tanh(x),também atingiu o número limite de iterações sem convergi e obteve uma acurácia de 82%. Em relação à precisão, percebemos 90% para abnormal e 70% para normal. Enquanto que na taxa de recall, nota-se 83% para abnormal e 80% para normal (a mais baixa entre as funções disponíveis).","metadata":{}},{"cell_type":"markdown","source":"# 6. Treino 3\nAqui, iremos utiliza três camadas de unidades de processamento intermediário e a função sigmoidal como função de ativação. Além disso, como no teste anterior a função sigmoidal atingiu o número limite de iterações, iremos aumentá-lo.","metadata":{}},{"cell_type":"code","source":"MLP_classifier_LG = MLPClassifier(hidden_layer_sizes = (100, 100, 100,),activation = 'logistic', max_iter = 1000,random_state = 13, verbose = False)\nMLP_classifier_LG.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:24.223379Z","iopub.execute_input":"2021-08-12T18:26:24.223949Z","iopub.status.idle":"2021-08-12T18:26:29.275637Z","shell.execute_reply.started":"2021-08-12T18:26:24.223908Z","shell.execute_reply":"2021-08-12T18:26:29.274517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = MLP_classifier_LG.predict(x_test)\nprint(MLP_classifier_LG.score(x_test, y_test))\nreport = classification_report(y_test, y_pred)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:29.277261Z","iopub.execute_input":"2021-08-12T18:26:29.277895Z","iopub.status.idle":"2021-08-12T18:26:29.305217Z","shell.execute_reply.started":"2021-08-12T18:26:29.277847Z","shell.execute_reply":"2021-08-12T18:26:29.303862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Com os valores alterados, percebemos um baixa na acurácia do modelo e nos valores de precissão e de recall. Assim, temos que a implementação anterior com essa função apresenta melhores resultados.","metadata":{}},{"cell_type":"markdown","source":"# 7. Limpeza dos dados","metadata":{}},{"cell_type":"markdown","source":"Nesse momento, tentaremos descobrir quais são as melhroes variáveis para utilizar como dados da nossa MLP. Esperamos, assim, maximizar a precisão dos casos.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\nmodel = ExtraTreesClassifier()\nmodel.fit(x,y)\nfeat_importances = pd.Series(model.feature_importances_, index=x.columns)\nfeat_importances.nlargest(12).plot(kind='barh')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:29.306824Z","iopub.execute_input":"2021-08-12T18:26:29.307538Z","iopub.status.idle":"2021-08-12T18:26:29.933188Z","shell.execute_reply.started":"2021-08-12T18:26:29.307496Z","shell.execute_reply":"2021-08-12T18:26:29.932332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nesse gráfico conseguimos observar quais váriaveis impactam mais na classificação dos casos. Vemos que as colunas [7, 12] são as que menos impactam nessa classificação. Devemos, no entanto, focas nas demais variáveis, as que realmente podem causa mudança no resultado.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/lower-back-pain-symptoms-dataset/Dataset_spine.csv')\ndf = df.drop(['Unnamed: 13'], axis=1)\ndf = df.drop(['Col7','Col8','Col9','Col10','Col11','Col12'], axis=1)\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:29.934218Z","iopub.execute_input":"2021-08-12T18:26:29.934487Z","iopub.status.idle":"2021-08-12T18:26:29.960494Z","shell.execute_reply.started":"2021-08-12T18:26:29.934461Z","shell.execute_reply":"2021-08-12T18:26:29.959516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Agora, como vemos, temos as colunas [1,6] e o a coluna [Class_att]. A seguir iremos, dividir novamente esse conjunto em subconjunto de teste e treino.","metadata":{}},{"cell_type":"code","source":"y = df['Class_att']\nx = df.drop(['Class_att'], axis=1)\n\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 13)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:29.96196Z","iopub.execute_input":"2021-08-12T18:26:29.962338Z","iopub.status.idle":"2021-08-12T18:26:29.97019Z","shell.execute_reply.started":"2021-08-12T18:26:29.962308Z","shell.execute_reply":"2021-08-12T18:26:29.969143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = MLPClassifier(hidden_layer_sizes = (100,100,100), random_state = 13, activation = 'logistic', verbose = False, validation_fraction = 0.2)                    \nclf.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:29.971436Z","iopub.execute_input":"2021-08-12T18:26:29.971705Z","iopub.status.idle":"2021-08-12T18:26:31.666432Z","shell.execute_reply.started":"2021-08-12T18:26:29.97168Z","shell.execute_reply":"2021-08-12T18:26:31.665367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = clf.predict(x_test)\nclf.score(x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:31.66802Z","iopub.execute_input":"2021-08-12T18:26:31.668611Z","iopub.status.idle":"2021-08-12T18:26:31.689843Z","shell.execute_reply.started":"2021-08-12T18:26:31.668566Z","shell.execute_reply":"2021-08-12T18:26:31.688835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report = classification_report(y_test, y_pred)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T18:26:31.691352Z","iopub.execute_input":"2021-08-12T18:26:31.691942Z","iopub.status.idle":"2021-08-12T18:26:31.710289Z","shell.execute_reply.started":"2021-08-12T18:26:31.691894Z","shell.execute_reply":"2021-08-12T18:26:31.709148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Com essas modificações, acreditávamos que iríamos obter melhores resultados. No entanto, como é possível notar, o melhor resultado que obtivemos foi com a função 'logistic' sem limpeza do nosso conjunto de dados.","metadata":{}}]}