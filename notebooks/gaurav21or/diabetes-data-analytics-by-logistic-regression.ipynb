{"cells":[{"metadata":{"_uuid":"5d1942aa-e536-4dab-a29b-ba9d2c3cd17a","_cell_guid":"a3d7a931-2cae-4ad7-9b07-1a0b794b75f4","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7be44f5-8072-44af-a0c6-d5bc8abbfcb7","_cell_guid":"75a9a8a6-0742-410b-a3fb-788e0503de70","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4a91fd0-c6d8-44ff-bce9-68c7febd5c30","_cell_guid":"e481dc3f-7c44-4cc2-8f66-0366a0ac2056","trusted":true},"cell_type":"markdown","source":"# Done by Logistic Regression"},{"metadata":{"_uuid":"7cb75f57-f992-4d3c-ade0-69a973bc46c5","_cell_guid":"918857e7-1059-472c-892c-c468440e9337","trusted":true},"cell_type":"code","source":"#Loading the dataset\ndiabetes_data = pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\n\n#Print the first 5 rows of the dataframe.\ndiabetes_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8fa73122-83f0-4b1a-9d94-f37abc050833","_cell_guid":"484e7941-9795-4867-8271-0d71792530fc","trusted":true},"cell_type":"markdown","source":"# Preprocessing\n\n**Exploring the descriptive statistics of the variables**"},{"metadata":{"_uuid":"10029e2e-0d2f-46c3-bed5-5177d87ae510","_cell_guid":"34669034-8862-4a7a-8e59-43fe9b4c8833","trusted":true},"cell_type":"code","source":"# Descriptive statistics are very useful for initial exploration of the variables\ndiabetes_data.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa655f94-1236-47d6-bb2c-214d91212e95","_cell_guid":"5abf9493-974e-4220-9310-b64eb30d0354","trusted":true},"cell_type":"markdown","source":"****Here is we get some information of missing value by analysing of minimum value. Value of zero doesn't make any sense****\n\nFollowing columns or variables have an invalid zero value:\n\n1. Glucose\n2. BloodPressure\n3. SkinThickness\n4. Insulin\n5. BMI"},{"metadata":{"_uuid":"523ea81c-a6b4-4cd6-8d67-727ca66230be","_cell_guid":"9f055a4a-f921-4e8f-83f9-85805a00fe03","trusted":true},"cell_type":"markdown","source":"****It is better to replace zeros with nan since after that counting them would be easier and zeros need to be replaced with suitable values****"},{"metadata":{"_uuid":"4b04d957-c151-490f-bbdf-ed0ea3ae86ab","_cell_guid":"37611b19-0a0b-47cf-a616-33b655102e71","trusted":true},"cell_type":"code","source":"diabetes_data_copy = diabetes_data.copy(deep = True)\ndiabetes_data_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = diabetes_data_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e45a71a-bbdb-4866-ae07-b97bc8acef9b","_cell_guid":"453dbd50-b2ba-4373-b262-36131d9ce447","trusted":true},"cell_type":"markdown","source":" ****Dealing with missing value****"},{"metadata":{"_uuid":"b997ca9b-b6cb-470c-8895-55a0aaabbac5","_cell_guid":"4418a9b4-3695-41b1-92a0-ed0bf4c5660e","trusted":true},"cell_type":"code","source":"# data.isnull() # shows a Diabetes_data_copy with the information whether a data point is null \n# Since True = the data point is missing, while False = the data point is not missing, we can sum them\n# This will give us the total number of missing values feature-wise\ndiabetes_data_copy.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53aa1a54-6834-40f6-ba13-8dfa8c924523","_cell_guid":"13f5e60c-7ae9-437e-868a-7d1ce4279568","trusted":true},"cell_type":"markdown","source":"****To fill the null values , we need to understand the data ****"},{"metadata":{"_uuid":"811d4b38-db60-41d9-b3c8-2b01c3864218","_cell_guid":"622f18f4-cbca-41a3-b262-5783e00ecf76","trusted":true},"cell_type":"code","source":"p = diabetes_data.hist(figsize = (20,20))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88279217-8bb5-4a3c-adf0-be6d52694330","_cell_guid":"78f91186-ce8a-4354-bd07-b204710f0eff","trusted":true},"cell_type":"code","source":"diabetes_data_copy['Glucose'].fillna(diabetes_data_copy['Glucose'].mean(), inplace = True)\ndiabetes_data_copy['BloodPressure'].fillna(diabetes_data_copy['BloodPressure'].mean(), inplace = True)\ndiabetes_data_copy['SkinThickness'].fillna(diabetes_data_copy['SkinThickness'].median(), inplace = True)\ndiabetes_data_copy['Insulin'].fillna(diabetes_data_copy['Insulin'].median(), inplace = True)\ndiabetes_data_copy['BMI'].fillna(diabetes_data_copy['BMI'].median(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b2695950-5256-4ecd-a549-c8449f846692","_cell_guid":"13a02ca6-7b28-430e-b8ca-8f00a88c0348","trusted":true},"cell_type":"code","source":"#plotting after filling null values\np = diabetes_data_copy.hist(figsize = (20,20))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49ffa870-08c6-4771-9b47-22eb37eb1de8","_cell_guid":"985dfb15-4a82-4bcd-9f19-e36bd243904c","trusted":true},"cell_type":"markdown","source":"\n# Screening of Association between Variables to study Bivariate relationship¶\n\n   ****We will use pairplot to study the association between variables – from individual scatter plots****\n   \n   ****Then we will compute pearson correlation coefficient****\n    \n   **** Then we will summarize the same as heatmap****"},{"metadata":{"_uuid":"7a6a4493-f203-49bb-8ab7-ff28c106240d","_cell_guid":"79b00bc5-61ac-47a6-b6f6-bd2848edc4f5","trusted":true},"cell_type":"code","source":"sns.pairplot(diabetes_data_copy, vars=[\"Pregnancies\", \"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\", \"BMI\",\"DiabetesPedigreeFunction\", \"Age\"],hue=\"Outcome\")\nplt.title(\"Pairplot of Variables by Outcome\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2381553e-4df2-4a8e-a07c-3da8513d69bb","_cell_guid":"cd1768b5-03c8-49f4-98c7-6b4c0249670a","trusted":true},"cell_type":"markdown","source":"****The pairs plot builds on two basic figures, the histogram and the scatter plot. The histogram on the diagonal allows us to see the distribution of a single variable while the scatter plots on the upper and lower triangles show the relationship (or lack thereof) between two variables.****"},{"metadata":{"_uuid":"93db027a-eb0e-438b-bd71-a1955e8ccb19","_cell_guid":"796cd6c4-bc26-41e0-916a-9da2fc861583","trusted":true},"cell_type":"markdown","source":"\n# Inference from Pair Plots\n\n*     From scatter plots, to me only BMI & SkinThickness and Pregnancies & Age seem to have positive linear relationships. Another likely       suspect is Glucose and Insulin.\n*     There are no non-linear relationships\n*     Lets check it out with Pearson Correlation and plot heat maps"},{"metadata":{"_uuid":"bbf7d1c9-f224-4407-bf20-e26b515cd4cc","_cell_guid":"1b947d5d-01a5-4d64-afab-47878fcacc71","trusted":true},"cell_type":"markdown","source":"# Pearson's Correlation Coefficient: \n****helps you find out the relationship between two quantities. It gives you the measure of the strength of association between two variables. The value of Pearson's Correlation Coefficient can be between -1 to +1. 1 means that they are highly correlated and 0 means no correlation.****"},{"metadata":{"_uuid":"445d8bb7-4132-490e-bdbf-990108f3700d","_cell_guid":"ad04ddf1-5f0c-477f-be0e-51384831bd4c","trusted":true},"cell_type":"markdown","source":"**** Before cleaning the data****"},{"metadata":{"_uuid":"63e65095-650e-4580-baf6-0ded6ec185be","_cell_guid":"4bebae49-1fbe-414d-b820-844b142f236e","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))  # on this line I just set the size of figure to 12 by 10.\np=sns.heatmap(diabetes_data.corr(), annot=True,cmap ='YlGnBu')  # seaborn has very simple solution for heatmap","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fc35539-3937-431f-9eb3-1e1a0c4f566d","_cell_guid":"d75e6b01-56c7-43ab-8a6a-1d841d354788","trusted":true},"cell_type":"markdown","source":"**** After cleaning the data****"},{"metadata":{"_uuid":"4cba1f3f-99dc-4b8e-ac1a-0f4b8bfe8e8d","_cell_guid":"e2660337-d030-4b7f-aa67-7b91792ae171","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))  # on this line I just set the size of figure to 12 by 10.\np=sns.heatmap(diabetes_data_copy.corr(), annot=True,cmap ='RdYlGn')  # seaborn has very simple solution for heatmap","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97adb7a1-4805-422c-a461-a5a0e75656ca","_cell_guid":"0ba93fa3-7159-4c0e-88a2-4bc4b6564583","trusted":true},"cell_type":"markdown","source":"# Logistic Regression\n\n\n*     A logistic regression is used from the dependent variable is binary, ordinal or nominal and the independent variables are either continuous or discrete\n*     In this scenario, a Logit Model has been used to fit the data\n*    In this case an event is defined as occurance of ‘1’ in outcome\n*     Basically logistic regression uses the odds ratio to build the model"},{"metadata":{"_uuid":"160fe97f-5c89-4913-a2d8-c3d5fd031580","_cell_guid":"d712ab5b-4da3-4e43-8521-015e40efffba","trusted":true},"cell_type":"markdown","source":"****Declare Dependent variable and Independent variables****"},{"metadata":{"_uuid":"f208c5f9-db5c-4f88-85c5-2a1db7a3bd80","_cell_guid":"b17ba0b9-2d37-484c-8409-9a0cce56b872","trusted":true},"cell_type":"code","source":"#independent variables\nx = diabetes_data_copy[['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']]\n\n#dependent variables\ny = diabetes_data_copy['Outcome']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f77e72f0-fecc-479c-a000-ab517cfeb912","_cell_guid":"c83494d4-fcb3-44ad-bea2-3ea0f2817a7e","trusted":true},"cell_type":"code","source":"## Importing stats models for running logistic regression\nimport statsmodels.api as sm\n## Defining the model and assigning Y (Dependent) and X (Independent Variables)\nlogit_model=sm.Logit(y,x)\n## Fitting the model and publishing the results\nresult=logit_model.fit()\nprint(result.summary())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"666cbac2-f0f2-4357-8a38-c02672166da2","_cell_guid":"98e75dbc-1bc3-4820-ad9d-5987649ed6a6","trusted":true},"cell_type":"markdown","source":"# Inference from the Logistic Regression\n*     The R sq value of the model is 58%.. that is this model can explain 58% of the variation in dependent variable\n*     To identify which variables influence the outcome, we will look at the p-value of each variable. We expect the p-value to be less than 0.05(alpha risk)\n*     When p-value<0.05, we can say the variable influences the outcome\n*     Hence we will eliminate Diabetes Pedigree Function, Age, Insulin, SkinThickness and again run the model"},{"metadata":{"_uuid":"1b2c9d77-2106-4a68-9a5c-c75d881ab129","_cell_guid":"da53574a-7582-48cb-8b6b-dab0431bf92f","trusted":true},"cell_type":"markdown","source":"# 2nd itertion of the Logistic Regression with fewer variables"},{"metadata":{"_uuid":"40ed3d8b-bb8e-47e8-b3b0-c52a87b7f39b","_cell_guid":"d383a87e-3224-4cc2-9d33-7fc901ed1181","trusted":true},"cell_type":"code","source":"X1 = diabetes_data_copy[['Pregnancies','Glucose','BloodPressure']]\nlogit_model2 = sm.Logit(y,X1)\nresult2 = logit_model2.fit()\nprint(result2.summary2())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b9b1694-0aa8-4908-af29-f16f4f94cc54","_cell_guid":"9dfb2c13-c775-4178-9f97-dd657e0ea0d4","trusted":true},"cell_type":"markdown","source":"\n# Inference from 2th Run\n*    Now the model is clear. We have 3 variables that influence the Outcome and then are Pregnancies, Glucose and BloodPressure\n*     Luckly, none of these 3 variables are co-correlated. Hence we can safetly assume tha the model is not inflated"},{"metadata":{"_uuid":"b5124bb2-fe8d-4a37-a2f2-e318d2abb949","_cell_guid":"f517515d-0913-4102-9c89-9ddf287a1146","trusted":true},"cell_type":"markdown","source":"# Scaling the data"},{"metadata":{"_uuid":"d3d53388-f19f-4334-bb1d-d98fc42d1e63","_cell_guid":"8968f054-e32c-47dd-bae8-b48e0a85b340","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5491ed41-ee74-4c22-b434-215eb5a09ff8","_cell_guid":"77ece273-430d-47a8-833c-8aea07fa5541","trusted":true},"cell_type":"code","source":"X1_scaled = pd.DataFrame(scaler.transform(X1),columns=['Pregnancies', 'Glucose', 'BloodPressure'])\nX1_scaled.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98146304-9888-46a7-8084-fce58fee26d7","_cell_guid":"322d356e-dfb7-4047-83fd-b6e8151aa55c","trusted":true},"cell_type":"markdown","source":"# Test Train Split and Cross Validation methods\n\n**Train Test Split** : To have unknown datapoints to test the data rather than testing with the same points with which the model was trained. This helps capture the model performance much better.\n\nFor Reference : https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6"},{"metadata":{"_uuid":"f933cac7-8a88-4ec3-b937-89db66915f17","_cell_guid":"5ad73549-c247-4f79-88fb-05201aef6640","trusted":true},"cell_type":"code","source":"# checking the balance of the data\ndiabetes_data_copy['Outcome'].unique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"633a2ca7-a9d0-4c29-b0cf-56566768a7fb","_cell_guid":"2a0589a4-7568-42db-b649-8a1c667c038e","trusted":true},"cell_type":"code","source":"diabetes_data_copy['Outcome'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78340685-b538-4cca-828a-d7aa5e84a8cf","_cell_guid":"370955de-d3e6-4356-b33b-6ad24e919ea8","trusted":true},"cell_type":"markdown","source":"**The above result shows that the data is biased towards datapoints having outcome value as 0 where it means that diabetes was not present actually. The number of non-diabetics is almost twice the number of diabetic patients**"},{"metadata":{"_uuid":"bc0fe431-4b97-4ac4-881e-10fcbbb2ce13","_cell_guid":"adfcc7cb-1cb9-45f4-a80f-7c3ee967a33c","trusted":true},"cell_type":"code","source":"#importing train_test_split\nfrom sklearn.model_selection import train_test_split\nX1 = diabetes_data_copy[['Pregnancies','Glucose','BloodPressure']]\nX_train,X_test,y_train,y_test = train_test_split(X1,y,test_size=0.25,random_state=42, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3f94b64-0ea4-43f8-a044-2d0fe98cf96f","_cell_guid":"107110ed-d928-45bf-a1ae-16a318dc8d17","trusted":true},"cell_type":"code","source":"len(X_train), len(X_test), len(y_train), len(y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abafd362-14c9-43a2-abe7-ccbe78324407","_cell_guid":"af9742f9-2c10-456f-8a1d-59605558c148","trusted":true},"cell_type":"code","source":"#Importing \nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nLreg = LogisticRegression(solver = 'lbfgs')\nLreg.fit(X_train, y_train.ravel())  #ravel( will return 1D array with all the input-array elements)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c7e7019-3f47-4026-ab20-d20c0e183a42","_cell_guid":"55801eb3-7f8e-47c8-912a-8cb9501f5f2e","trusted":true},"cell_type":"code","source":"y_predict = Lreg.predict(X_test)\ny_predict","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfc4f0d1-9b25-49bd-8d01-88d3888cdca0","_cell_guid":"164c4099-ed0d-418a-b254-f6fd730cc6d9","trusted":true},"cell_type":"code","source":"y_predict_train = Lreg.predict(X_train)\ny_predict_train","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8d485f4-0d7c-4b77-82f8-98e8e60d5aea","_cell_guid":"bfb60d8b-c313-4ba4-9c03-1b75f4bf4cf5","trusted":true},"cell_type":"code","source":"y_prob_train = Lreg.predict_proba(X_train)[:, 1]\ny_prob_train.reshape(1,-1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f79b942b-449c-43a4-9bfd-353a60006461","_cell_guid":"4ee93595-afb9-465c-a269-deb6dc3e0554","trusted":true},"cell_type":"code","source":"y_prob= Lreg.predict_proba(X_test)[:,1]\ny_prob.reshape(-1,1)\ny_prob","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf4f8f5b-711d-4161-884d-5054eea74a11","_cell_guid":"6b7868a5-cdcd-4175-a7c6-6152e343cf8a","trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nscore = accuracy_score(y_test,y_predict)\nscore","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6ba4753-29e3-4df9-b8a5-e5ba236ad124","_cell_guid":"da479468-d28f-4888-ab72-3eff3656ab69","trusted":true},"cell_type":"markdown","source":"# Calculating accuracy score using confusin matrix"},{"metadata":{"_uuid":"0cbe97ce-9a46-43ff-969f-44ac59486066","_cell_guid":"84658320-752e-4a09-b809-b4e65a329777","trusted":true},"cell_type":"markdown","source":"**A confusion matrix is a matrix (table) that can be used to measure the performance of an machine learning algorithm, usually a supervised learning one. Each row of the confusion matrix represents the instances of an actual class and each column represents the instances of a predicted class. This is the way we keep it in this chapter of our tutorial, but it can be the other way around as well, i.e. rows for predicted classes and columns for actual classes. The name confusion matrix reflects the fact that it makes it easy for us to see what kind of confusions occur in our classification algorithms. For example the algorithms should have predicted a sample as ci because the actual class is ci, but the algorithm came out with cj. In this case of mislabelling the element cm[i,j] will be incremented by one, when the confusion matrix is constructed.**\n\n**For Reference:**https://www.python-course.eu/confusion_matrix.php"},{"metadata":{"_uuid":"54e086da-1607-465d-86cf-bbd0f0833831","_cell_guid":"2a19b3b4-2ae7-4e8d-9640-af732a834d15","trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test,y_predict)\npd.crosstab(y_test.ravel(),y_predict.ravel(), rownames=['True'], colnames=['Predicted'], margins=True) # #ravel( will return 1D array with all the input-array elements)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6a420bd-30df-426e-abf8-b38d0eb88ee3","_cell_guid":"e534486a-2f17-49e9-987f-4022289c8ff8","trusted":true},"cell_type":"code","source":"tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\nprint('true negatives', tn)\nprint('false positive', fp)\nprint('false negative', fn)\nprint('true positive', tp)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1fd9a868-aec9-479a-9416-ad92d3015da5","_cell_guid":"8e995eca-eb92-4d00-9ea0-531af0ef9149","trusted":true},"cell_type":"markdown","source":"#  Classification Report\n\n1. Prevalence – how often in our sample do we find a yes? (True Positives + False Negatives) / Total of all 4\n2. Accuracy – how often is the classifier correct? = (True Positives + True Negatives) / Total of all 4\n3. False positive rate – when it is actually no, how often does it predict yes? = False Positives / (False Positives + True Negatives)\n4. True Positive rate or Recall – when it is actually yes, how often does it predict yes? = True Positives / (True Positives + False Negatives)\n5. Precision – when it predicts yes, how often is it correct? = True Positives / (True Positives + False Positives)"},{"metadata":{"_uuid":"b78763ba-5ebc-4bac-8ac3-3e3448ff2fe6","_cell_guid":"b418b675-f624-47e6-ab93-86c95391197e","trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_predict))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e83aa409-bc64-482e-9a57-e7950c5d902a","_cell_guid":"fb9f3838-3108-4827-9fd9-2e098d7ce661","trusted":true},"cell_type":"code","source":"Accuracy = (tp+tn)/(tp+tn+fp+fn)\nprint('Accuracy {:0.2f}'.format(Accuracy))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d80c613f-99eb-4dd8-a7da-7b73f6448f1b","_cell_guid":"826a4660-f818-4c75-89c9-edc5d4975a32","trusted":true},"cell_type":"code","source":"Specificity = tn/(tn+fp)\nprint('Specificity {:0.2f}'.format(Specificity))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7db7c51-0957-4da0-ba24-0fafa3e3ea66","_cell_guid":"cd537559-3886-4695-ae9c-74364ba171b3","trusted":true},"cell_type":"code","source":"Sensitivity = tp/(tp+fn)\nprint('Sensitivity {:0.2f}'.format(Sensitivity))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f27f5484-4414-41c9-82d7-d0bb4b6d6f9f","_cell_guid":"f71f7bfe-b6c0-40f7-abea-ecbcb1a834e5","trusted":true},"cell_type":"markdown","source":"# ROC - AUC\n\nROC (Receiver Operating Characteristic) Curve tells us about how good the model can distinguish between two things (e.g If a patient has a disease or no). Better models can accurately distinguish between the two. Whereas, a poor model will have difficulties in distinguishing between the two.\n\nFor Reference: https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/"},{"metadata":{"_uuid":"0756ac03-e909-4aca-b65c-3184a7fd387f","_cell_guid":"6ed78e35-433d-40e2-9d2a-7cfaecc38a21","trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\nlog_ROC_AUC1 = roc_auc_score(y_train, y_predict_train)\nfpr1, tpr1, thresholds1 = roc_curve(y_train, y_prob_train)\nroc_auc1 = auc(fpr1, tpr1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"746f9cc7-7d61-4b95-a3b6-718ac27abefd","_cell_guid":"cc420fa5-0a36-472b-b05f-66eaa9938962","trusted":true},"cell_type":"code","source":"plt.figure()\nplt.plot(fpr1,tpr1, color = 'blue', label =  'ROC curve (area = %0.2f)'% roc_auc1)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('false positive rate')\nplt.ylabel('true positive rate')\n\nplt.legend(loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"698f477a-4a32-48e2-9c1b-498c9394b5ef","_cell_guid":"ab49ed01-9ff3-494e-a32c-5a3e63ec846d","trusted":true},"cell_type":"code","source":"fpr, tpr, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(fpr, tpr)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88c5818f-3b9d-4560-b824-6785e74a761a","_cell_guid":"2673569d-d69a-4de7-9e71-81dd3ccd30a1","trusted":true},"cell_type":"code","source":"print('Area under the roc curve : %f' % roc_auc)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"574c2be9-2c15-41cc-a0e9-466664cb31bd","_cell_guid":"17cf8884-3c8b-4da9-a443-d1afbe60db51","trusted":true},"cell_type":"markdown","source":"# find optimal cutoff point(thresold value)"},{"metadata":{"_uuid":"a78da4b6-f25d-4cf9-9065-cbb15495c7b0","_cell_guid":"b26cf532-af9f-4ec7-87a0-9b857ad5efa2","trusted":true},"cell_type":"code","source":"import numpy as np \ni = np.arange(len(tpr)) #index for df\nroc = pd.DataFrame({'fpr': pd.Series(fpr, index=i), 'tpr': pd.Series(tpr, index=i), '1-fpr':pd.Series(1-fpr, index=i), 'tf':pd.Series(tpr -(1-fpr), index=i), 'thresholds':pd.Series(thresholds, index=i)})\nroc.iloc[(roc.tf-0).abs().argsort()[:1]]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df9ef06c-ff7a-4ade-9fb6-08039f709683","_cell_guid":"9772e791-c555-45e6-bb1c-6b8657b51c19","trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nplt.plot(roc['tpr'])\nplt.plot(roc['1-fpr'], color = 'red')\nplt.xlabel('1-false positive rate')\nplt.ylabel('true positive rate')\nplt.title('receiver operating characteristic')\nax.set_xticklabels([])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46ad24e5-28bb-4d73-926e-d11e48757b7e","_cell_guid":"d53ffcca-6cd5-465e-b984-ecfa3d816d72","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import binarize\ny_predict_class1 = binarize(y_prob.reshape(1, -1),0.341694)[0]\ny_predict_class1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0551f63b-f413-4205-b0c7-0b0921605aa8","_cell_guid":"a7b6c297-a9ed-4ad9-9527-aa8de162dde4","trusted":true},"cell_type":"code","source":"confusion_matrix_1 = confusion_matrix(y_test, y_predict_class1)\nprint(confusion_matrix_1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7267a0d-024f-4ea9-a836-95b68b21c812","_cell_guid":"abbd9ad8-29a1-4901-b37e-99288cabf660","trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_predict_class1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67e0aa24-31d9-4698-9cdc-0bad746c53d6","_cell_guid":"c52ef590-4c62-42dd-8844-83f4d42f4988","trusted":true},"cell_type":"markdown","source":" ****I am a beginner . This is my first project ..Please give me suggestion  if you found any mistake ! Thanks.****"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}