{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/pokemon-challenge/pokemon.csv')\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation map \n# correlation: featurelar arasındaki ilişkiyi anlamamızı sağlayan belli başlı parametrelerimiz vardır.Pozitif(evin oda sayısının artması ile evin fiyatının artması-) vs negatif(evin şehir merkezinden uzaklaştıkça fiyatının azalması) correlate\n# Pozitif = 0<x<1, Negatif=-1<x<0, İlişki yok =0\ndata.corr()  # datanın correlation'ınının excel hali","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, fmt='.1f', ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n# **1. INTRODUCTION TO PYTHON**\n\n\n**MATPLOTLIB**\nMatplot is a python library that help us to plot data. The easiest and basic plots are line, scatter and histogram plots.\n\n   1. **Line** plot is better when x axis is time.\n   2. **Scatter** is better when there is correlation between two variables\n   3. **Histogram** is better when we need to see distribution of numerical data.\n   4. **Customization**: Colors,labels,thickness of line, title, opacity, grid, figsize, ticks of axis and linestyle\n    ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Line Plot\n# color = color, label = label, linewidth = width of line, alpha = opacity, grid = grid, linestyle = sytle of line\ndata.Speed.plot(kind='line', color='g', label='Speed', linewidth=1, alpha=0.5, grid=True, linestyle=':')\ndata.Defense.plot(kind='line', color='r', label='Defense', linewidth=1, alpha=0.5, grid=True, linestyle='-.')\nplt.legend(loc='upper right')  # legend = puts label into plot\nplt.xlabel('x axis')  # label = name of label\nplt.ylabel('y axis')\nplt.title('Line Plot')  # title = title of plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scatter Plot\n# x=attack, y=defense\ndata.plot(kind='scatter', x='Attack', y='Defense', alpha=0.5, color='red')\nplt.xlabel('Attack')  # label= name of label\nplt.ylabel('Defense')\nplt.title('Attack Defense Scatter Plot')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram\n# bins = number of bar in figure\ndata.Speed.plot(kind='hist', bins=50, figsize=(12, 12))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf() = cleans it up again you can start a fresh\ndata.Speed.plot(kind='hist', bins=50)\nplt.clf()\n# We cannot see plot due to clf()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n\n**DICTIONARY**\n\nWhy we need dictionary?\n\n* It has 'key' and 'value'\n* Faster than lists\n* What is key and value. Example: dictionary = {'spain' : 'madrid'}\n* Key is spain.\n* Values is madrid.\n\nIt's that easy.\nLets practice some other properties like keys(), values(), update, add, check, remove key, remove all entries and remove dicrionary.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dictionary = {'spain': 'madrid', 'usa': 'vegas'}\nprint(dictionary.keys())\nprint(dictionary.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keys have to be immutable objects like string, boolean, float, integer or tubles\n# List is not immutable\n# Keys are unique\ndictionary['spain'] = \"barcelona\"  # update existing entry\nprint(dictionary)\ndictionary['france'] = \"paris\"  # add new entry\nprint(dictionary)\ndel dictionary['spain']  # remove entry with key 'spain'\nprint(dictionary)\nprint('france' in dictionary)  # check include or not\ndictionary.clear()  # remove all entries in dict\nprint(dictionary)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In order to run all code you need to take comment this line\n#del dictionary # delete entire dictionary\nprint(dictionary)  # will give  error because dictionary is deleted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PANDAS**\n\nWhat we need to know about pandas?\n\n* CSV: comma - separated values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/pokemon-challenge/pokemon.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"series = data['Defense']  # series\nprint(series)\nprint('------------')\ndata_frame = data[['Defense']]  # data frame\nprint(data_frame)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nBefore continue with pandas, we need to learn **logic, control flow and filtering.**\nComparison operator: ==, <, >, <=\n\nBoolean operators: and, or ,not\n\nFiltering pandas","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparison operator\nprint(3 > 2)\nprint(3 != 2)\n# Boolean operators\nprint(True and False)\nprint(True or False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1 - Filtering Pandas data frame\nx = data['Defense']>200     # There are only 3 pokemons who have higher defense value than 200\ndata[x]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2 - Filtering pandas with logical_and\n# There are only 2 pokemons who have higher defence value than 2oo and higher attack value than 100\ndata[np.logical_and(data['Defense'] > 200, data['Attack'] > 100)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is also same with previous code line. Therefore we can also use '&' for filtering.\ndata[(data['Defense'] > 200) & (data['Attack'] > 100)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**WHILE and FOR LOOPS**\n\nWe will learn most basic while and for loops\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stay in loop if condition ( i is not equal 5) is true\ni = 0\nwhile i != 5:\n    print('i is: ', i)\n    i += 1\nprint('i is equal to 5.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stay in loop if condition( i is not equal 5) is true\nliste = [1, 2, 3, 4, 5]\nfor i in liste:\n    print('i is: ', i)\nprint('')\n\n# Enumerate index and value of liste\n# index : value = 0:1, 1:2, 2:3, 3:4, 4:5\nfor index, value in enumerate(liste):\n    print(index, \" : \", value)\nprint('')\n\n# For dictionaries\n# We can use for loop to achive key and value of dictionary. We learnt key and value at dictionary part.\ndictionary = {'spain': 'madrid', 'france': 'paris'}\nfor key, value in dictionary.items():\n    print(key, \" : \", value)\nprint('')\n\n# For pandas we can achieve index and value\nfor index, value in data[['Attack']][0:10].iterrows():\n    print(index, \" : \", value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nIn this part, you learn:\n\n* how to import csv file\n* plotting line,scatter and histogram\n* basic dictionary features\n* basic pandas features like filtering that is actually something always   used and main for being data scientist\n* While and for loops","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"\n\n\n# 2. PYTHON DATA SCIENCE TOOLBOX\n\n\n**USER DEFINED FUNCTION**\n\nWhat we need to know about functions:\n\n* docstrings: documentation for functions. Example:for f():\n\"\"\"This is docstring for documentation of function f\"\"\"\n* tuble: sequence of immutable python objects.\n    1.  cant modify values\n    2.  tuble uses paranthesis like tuble = (1,2,3)\n    3.  unpack tuble into several variables like a,b,c = tuble","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# example of what we learn above\ndef tuble_ex():\n    \"\"\" return defined t tuble\"\"\"\n    t = (1, 2, 3)\n    return t\n\n\na, b, c = tuble_ex()\nprint(a, b, c)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SCOPE**\n\nWhat we need to know about scope:\n\n* global: defined main body in script\n* local: defined in a function\n* built in scope: names in predefined built in scope module such as print, len\n\nLets make some basic examples","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Global vs Local Scope\nx = 2\n\n\ndef f():\n    x = 3\n    return x\n\n\nprint(x)  # x=2 global scope\nprint(f())  # x=3 local scope\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What if there is no local scope\nx = 5\n\n\ndef f():\n    y = 2 * x  # there is no local scope x\n    return y\n\n\nprint(f())  # it uses gloval scope x\n# First local scope searched, then gloval scope searched, if two of them cannot b found lastly built in scope searched\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How can we learn what is built in scope\nimport builtins\n\ndir(builtins)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**NESTED FUNCTION**\n\n* function inside function.\n* There is a LEGB rule that is search local scope, enclosing function, global and built in scopes, respectively.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# nested function\ndef square():\n    def add():\n        x = 2\n        y = 3\n        z = x + y\n        return z\n\n    return add() ** 2\n\n\nprint(square())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DEFAULT and FLEXIBLE ARGUMENTS**\n\n* Default argument example:\n    def f(a, b=1):\n        \"\"\" b = 1 is default argument\"\"\"\n        \n* Flexible argument example:\n\n    def f(*args):\n        \"\"\" *args can be one or more\"\"\"\n\n    def f(** kwargs)\n        \"\"\" **kwargs is a dictionary\"\"\"\n\n\nlets write some code to practice","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# default arguments\ndef f(a, b=1, c=2):\n    y = a + b + c\n    return y\n\n\nprint(f(5))\n# what if we want to change default arguments\nprint(f(5, 4, 3))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# flexible arguments *args\ndef f(*args):\n    for i in args:\n        print(i)\n\n\nf(1)\nprint('')\nf(1, 2, 3, 4)\n\n\n# flexible arguments **kwargs that is dictionary\ndef f(**kwargs):\n    for key, value in kwargs.items():\n        print(key, ' : ', value)\n\n\nf(country='spain', capital='madrid', population=123456)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**LAMBDA FUNCTION**\n\nFaster way of writing function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# user defined function (long way)\ndef square(x):\n    return x ** 2\n\n\nprint(square(5))\n# lambda function(short way)\nsquare = lambda x: x ** 2  # where x is none of argument\nprint(square(4))\ntotal = lambda x, y, z: x + y + z  # where x,y,z are names of arguments\nprint(total(1, 2, 3))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ANONYMOUS FUNCTION**\n\nLike lambda function but it can take more than one arguments.\n\n* map(func,seq) : applies a function to all the items in a list","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"number_list = [1, 2, 3]\ny = map(lambda x: x ** 2, number_list)\nprint(list(y))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ITERATORS** \n* iterable is an object that can return an iterator\n* iterable: an object with an associated iter() method\n* example: list, strings and dictionaries\n* iterator: produces next value with next() method","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# iteration example\nname = \"ronaldo\"\nit = iter(name)\nprint(next(it))  # print next iteration\nprint(*it)  # print remaining iteration\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**zip() **: zip lists","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"list1 = [1, 2, 3, 4]\nlist2 = [5, 6, 7, 8]\nz = zip(list1, list2)\nprint(z)\nzipList = list(z)\nprint(zipList)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unzip = zip(*zipList)  # unzip the list\nunzipList1, unzipList2 = list(unzip)  # unzip returns table\nprint(unzipList1)\nprint(unzipList2)\nprint(type(unzipList2))\n# tuple to list\nprint(type(list(unzipList2)))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****LIST COMPREHENSION****\n\n**One of the most important topic of this kernel**\n\n* We use list comprehension for data analysis often.\n* **list comprehension**: collapse for loops for building lists into a single line\n\nEx: num1 = [1,2,3] and we want to make it num2 = [2,3,4]. This can be done with for loop. However it is unnecessarily long. We can make it one line code that is list comprehension.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# example of list comprehension\nnum1 = [1, 2, 3]\nnum2 = [i + 1 for i in num1]\nprint(num2)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[i + 1 for i in num1 ]: list of comprehension\n\ni +1: list comprehension syntax\n\nfor i in num1: for loop syntax\n\ni: iterator\n\nnum1: iterable object","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Conditionals on iterable\nnum1 = [5, 10, 15]\nnum2 = [i ** 2 if i == 10 else i - 5 if i < 7 else i + 5 for i in num1]\nprint(num2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets return pokemon csv and make one more list comprehension example\n# lets classify pokemons whether they have high or low speed. Our threshold is average speed.\nthreshold = sum(data.Speed) / len(data.Speed)\ndata[\"speed_level\"] = ['high' if i > threshold else 'low' for i in data.Speed]\ndata.loc[:10, [\"speed_level\", \"Speed\"]]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nUp to now, you learn\n\n* User defined function\n* Scope\n* Nested function\n* Default and flexible arguments\n* Lambda function\n* Anonymous function\n* Iterators\n* List comprehension","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **3.CLEANING DATA**\n\nDIAGNOSE DATA(teşhis etme) for CLEANING\n\nWe need to diagnose and clean data before exploring.\nUnclean data:\n\n*     Column name inconsistency like upper-lower case letter or space between words\n*     Missing data\n*     Different language\n\nWe will use head, tail, columns, shape and info methods to diagnose data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EXPLORATORY DATA ANALYSIS\n\n### value_counts(): Frequency counts\n### outliers(aykırı,  ayrık): the value that is considerably higher or lower from rest of the data\n\n* Lets say value at 75% is Q3 and value at 25% is Q1.\n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n* We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\nWhat is quantile?\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The **median(quantile 50%)** is the number that is in **middle** of the sequence. In this case it would be 11.\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example lets look frequenct of pokemon types\nrint(data['Type 1'].value_counts(dropna=False))  # if there are nonen values that also be counted\n# As it can be seen below there are 112 water pokemon or 98 normal pokemon\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe() # ignore null entries","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VISUAL EXPLORATORY DATA ANALYSIS\n* Box plots: visualize basic statistics like outliers, min/max or quantiles","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example: compare attack of pokemons that are legendary or not\n# Black line at top is max\n# Blue line at top is 75%\n# Green line is median(50%)\n# Bluea line at bottom is 25%\n# Black line at bottom is min\ndata.boxplot(column='Attack', by='Legendary')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### TIDY DATA\nWe tidy data with melt(). Describing melt is confusing. Therefore lets make example to understand it.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Firstly I create a new data from pokemons data to explain melt more easily.\ndataNew = data.head()\nprint(dataNew)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=dataNew, id_vars='Name', value_vars=['Attack', 'Defense', 'Type 1'])\nmelted\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **PIVOTING DATA**\nReverse of melting.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index='Name', columns='variable', values='value')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CONCATENATING DATA\nWe can concatenate two dataframe.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Firstly lets create 2 data frame\n# ignore_index=True : we created new index\n# Vertical Concat\ndata1 = data.head()\ndata2 = data.tail()\nconcateDataColumn = pd.concat([data1, data2], axis=0, ignore_index=True)  # axis =0 : adds dataframes in row\nconcateDataColumn\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Horizontal concat\ndata1 = data['Attack'].head()\ndata2 = data['Defense'].head()\nconcatDataColumn = pd.concat([data1, data2], axis=1)  # axis= 0 : adds dataframes in column\nconcatDataColumn\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### DATA TYPES\nThere are 5 basic data types: object(string),booleab, integer, float and categorical.\n\nWe can make conversion data types like from str to categorical or from int to float\n\nWhy is category important:\n\n* make dataframe smaller in memory\n* can be utilized for anlaysis especially for sklearn(we will learn later)\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets convert object(str) to categorical and int to float\ndata['Type 1'] = data['Type 1'].astype('category')\ndata['Speed'] = data['Speed'].astype('float')\ndata.dtypes\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ### MISSING DATA  and TESTING WITH ASSERT\n If we encounter with missing data, what we can do:\n\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean\n* Assert statement: check that you can turn on or turn off when you are done with your testing of the program","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets look at does pokemon data have nan value\n# As you can see there are 800 entries. However Type 2 has 414 non-null object so it has 386 null object.\ndata.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check type 2\ndata['Type 2'].value_counts(dropna=False)  # with dropna=False; we showed also NaN values in info\n# there are 386 NaN value\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets drop NaN values\ndata1 = data\ndata1['Type 2'].dropna(inplace=True)  # we inplace=True we updated data after drop 'Type 2' column\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check with assert statement\n# assert statement:\nassert 1 == 1  # return nothing because it is true\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In order to run all code, we need to make this line comment\n# assert 1==2 # return error because it is false","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert data['Type 2'].notnull().all()  # returns nothing we drop NaN values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Type 2'].fillna('empty', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert data['Type 2'].notnull().all  # returns nothing because we do not have NaN values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# With assert statement we can check a lot of thing. For example\n# assert data.columns[1] == 'Name'\n# assert data.Speed.dtypes == np.int\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this part, you learn:\n\n* Diagnose data for cleaning\n* Exploratory data analysis\n* Visual exploratory data analysis\n* Tidy data\n* Pivoting data\n* Concatenating data\n* Data types\n* Missing data and testing with assert","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 4. PANDAS FOUNDATION\n\n## REVIEW of PANDAS\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## BUILDING DATA FRAMES FROM SCRATCH¶\n* We can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries\n*     zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# data frames from dictionary\ncountry = [\"Spain\", \"France\"]\npopulation = [\"11\", \"12\"]\nlist_label = [\"country\", \"population\"]\nlist_col = [country, population]\nzipped = list(zip(list_label, list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add new columns\ndf['capital'] = ['madrid', 'paris']\ndf\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Broadcasting\ndf['income'] = 0  # Broadcasting entire column\ndf\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## VISUAL EXPLORATORY DATA ANALYSIS\n* Plot\n* Subplot\n* Histogram:\n    *     bins: number of bins\n    *     range(tuble): min and max values of bins\n    *     normed(boolean): normalize or not\n    *     cumulative(boolean): compute cumulative distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting all data\ndata1 = data.loc[:, [\"Attack\", \"Defense\", \"Speed\"]]\ndata1.plot()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# subplots\ndata1.plot(subplots=True)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scatter plot\ndata1.plot(kind=\"scatter\", x=\"Attack\", y=\"Defense\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hist plot\n# range : range in y axis\ndata1.plot(kind=\"hist\", y=\"Defense\", bins=50, range=(0, 250), normed=True)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2, ncols=1)\ndata1.plot(kind=\"hist\", y=\"Defense\", bins=50, range=(0, 250), normed=True, ax=axes[0])\ndata1.plot(kind=\"hist\", y=\"Defense\", bins=50, range=(0, 250), normed=True, ax=axes[1], cumulative=True)\nplt.savefig('graph.png')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n## STATISTICAL EXPLORATORY DATA ANALYSIS\nI already explained it at previous parts. However lets look at one more time.\n\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n## INDEXING PANDAS TIME SERIES\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"time_list =[\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1])) # As you can see date is string\n# however we want it to be datetime object\ndatetime_object=pd.to_datetime(time_list)\nprint(type(datetime_object))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In order to practice lets take head of pokemon data and add it a time list\ndata2=data.head()\ndate_list=[\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object=pd.to_datetime(date_list)\ndata2[\"date\"]= datetime_object\n# lets make date as index\ndata2=data2.set_index(\"date\")\ndata2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we can select according to our date index\nprint(data2.loc[\"1993-03-16\"])\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## RESAMPLING PANDAS TIME SERIES\n* Resampling: statical method over different time intervals\n    *Needs string to specify frequency like \"M\"= month or \"A\"= year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like daily to hourly\n* Interpolate: Interpolate values according to different methods like 'linear', 'time' or 'index'\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will use data2 that we create at previous part\ndata2.resample(\"A\").mean()\n# data2.resample(\"A\").sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In real life (data is real, not created from us like data2) we can solve this problem with interpolate\n# We can interpolate from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# or we can interpolate with mean ()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. MANIPULATING DATA FRAMES WITH PANDAS\n\n## INDEXING DATA FRAMES\n* Indexing using square brackets\n* Using column attribute and row label\n* Using loc accessor\n* Selecting only some columns\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# change data's index to '#' column\ndata = data.set_index(\"#\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# indexing using square brackets\ndata[\"HP\"][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using loc accessor\ndata.loc[1,[\"HP\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# selecting only some columns\ndata[[\"HP\",\"Attack\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SLICING DATA FRAME\n\n* Difference between selecting columns\n* Series and data frames\n* Slicing and indexing series\n* Reverse slicing\n* From something to end","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"HP\"]))     # series\nprint(type(data[[\"HP\"]]))   # data frames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Slicing and indexing series\ndata.loc[1:10,\"HP\":\"Defense\"]   # 10 and \"Defense\" are inclusive","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reverse slicing \ndata.loc[10:1:-1,\"HP\":\"Defense\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From something to end\ndata.loc[1:10,\"Speed\":]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## FILTERING DATA FRAMES\nCreating boolean series Combining filters Filtering column based others","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating boolean series\nboolean = data.HP > 200\ndata[boolean]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combining filters\nfirst_filter = data.HP > 150\nsecond_filter = data.Speed < 35\ndata[first_filter & second_filter]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filtering column based others\ndata.HP[data.Speed<15]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TRANSFORMING DATA\n    * Plain python functions\n    * Lambda function: to apply arbitrary python function to every element\n    * Defining column using other columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plain python functions\ndef div(n):\n    return n/2\n\ndata.HP.apply(div)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can use lambda function\ndata.HP.apply(lambda n : n/2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining columns using other columns\ndata[\"total_power\"] = data.Attack + data.Defense\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## INDEX OBJECTS ANDA LABELED DATA\nindex: sequnce of label","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# our index name is this:\nprint(data.index.name)\n# lets change it\ndata.index.name = \"index_name\"\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Overrite index\n# if we want to modify index we need to change all of them.\ndata.head()\n# first copy of our data to data2 then change index\ndata2 = data.copy()\n# lets make index start from 100. It is not remarkable change but it is just example\ndata2.index = range(100,900,1)\ndata2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can make one of the column as index. I actually did it at the beginning of manipulating data frames with pandas section\n# It was like this\n# data= data.set_index(\"#\")\n# also you can use \n# data.index = data[\"#\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## HIERARCHICAL INDEXING\n    * Setting indexing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets read data frame one more time to start from beginning\ndata = pd.read_csv('/kaggle/input/pokemon-challenge/pokemon.csv')\ndata.head()\n# As you can see there is index. However we want to set one or more column to be index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting index : Type 1 is outer, Type 2 is inner index\ndata1 = data.set_index([\"Type 1\", \"Type 2\"])\ndata1.head(100)\n# data1.loc[\"Fire\", \"Flying\"] # how to use indexes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PIVOTING DATA FRAMES\n    * Pivoting: reshape tool","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dic = { \"treatment\":[\"A\",\"A\",\"B\",\"B\"], \"gender\":[\"F\",\"M\",\"F\",\"M\"], \"response\": [10, 45, 5, 9], \"age\": [15, 4, 72, 65] }\ndf = pd.DataFrame(dic)\ndf\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pivoting\ndf.pivot(index=\"treatment\",columns=\"gender\",values=\"response\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## STACKING and UNSTACKING DATAFRAME\n* deal with multi label indexes\n* level: position of unstacked index\n1. swaplevel: change inner and outer level index position","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.set_index([\"treatment\",\"gender\"])\ndf1\n# lets unstack it","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# level determines indexes\ndf1.unstack(level=0)\n# we deleted treatment index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.unstack(level=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## MELTING DATA FRAMES\nReverse of pivoting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")\npd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CATEGORICALS AND GROUPBY","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use df\ndf\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# according to treatment take means of other features\ndf.groupby(\"treatment\").mean()   # mean is aggregation / reduction method\n# there are other methods like sum, std,max or min","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can only choose one of the feature\ndf.groupby(\"treatment\").age.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can choose multiple features\ndf.groupby(\"treatment\")[[\"age\",\"response\"]].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()\n# as you can see gender is object\n# However if we use groupby, we can convert it categorical data. \n# Because categorical data uses less memory, speed up operations like groupby\n#df[\"gender\"] = df[\"gender\"].astype(\"category\")\n#df[\"treatment\"] = df[\"treatment\"].astype(\"category\")\n#df.info()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}