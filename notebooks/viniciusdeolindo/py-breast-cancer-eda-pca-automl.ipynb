{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Breast Cancer Wisconsin (Diagnostic) Data Set\n---\n### Target:\n\nPredict breast cancer diagnosis with data from the state of Wisconsin - USA.\n\n### Predict whether the cancer is benign or malignant:\n\nResources are calculated from a scanned image of a fine needle aspirate (PAAF) of a breast mass. They describe characteristics of the cell nuclei present in the image.\n\n### Attribute information:\n\n1) ID number\n\n2) Diagnosis (M = malignant, B = benign)\n\n### Ten resources with real value are calculated for each cell nucleus:\n\na) radius (mean of distances from center to points on the perimeter)\n\nb) texture (standard deviation of gray-scale values)\n\nc) perimeter\n\nd) area\n\ne) smoothness (local variation in radius lengths)\n\nf) compactness (perimeter^2 / area - 1.0)\n\ng) concavity (severity of concave portions of the contour)\n\nh) concave points (number of concave portions of the contour)\n\ni) symmetry\n\nj) fractal dimension (\"coastline approximation\" - 1)\n\n### Preliminary information:\n\nThe mean, standard error and \"worst\" or largest (mean of the three\nlargest values) of these features were computed for each image,\nresulting in 30 features. For instance, field 3 is Mean Radius, field\n13 is Radius SE, field 23 is Worst Radius.\n\nAll feature values are recoded with four significant digits.\n\nMissing attribute values: none\n\nClass distribution: 357 benign, 212 malignant\n\n---","metadata":{}},{"cell_type":"markdown","source":"### Package data analysis:\n---","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.gridspec as gridspec","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inputs:\n___","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/breast-cancer-wisconsin-data/data.csv', header = [0])\nfeature = [feat for feat in list(df) if feat not in ['id','Unnamed: 32']]\ndf1 = df.filter(feature)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exploratory data analysis:\n---","metadata":{}},{"cell_type":"markdown","source":"#### Variable target:","metadata":{}},{"cell_type":"code","source":"print(\"Variable target - Diagnosis\")\nprint(\" \")\nprint(df1.diagnosis.value_counts())\nprint(\"\\nBenign cases represent {:.4f}% in dataset.\\n\".format((df1[df1.diagnosis == 'B'].shape[0] / df1.shape[0]) * 100))\nplt.figure(figsize=(10,8))\nsns.countplot('diagnosis',data=df1)\nplt.title(\"Variable target - Diagnosis\")\nplt.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Descriptive statistics:\n\n* Feature average statistics","metadata":{}},{"cell_type":"code","source":"df1.filter(['radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean',\n            'compactness_mean','concavity_mean','concave points_mean','symmetry_mean','fractal_dimension_mean']).describe()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Feature Standard deviation statistics","metadata":{}},{"cell_type":"code","source":"df1.filter(['radius_se','texture_se','perimeter_se','area_se','smoothness_se',\n            'compactness_se','concavity_se','concave points_se','symmetry_se','fractal_dimension_se']).describe()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Statistics of the worst measures of the characteristics","metadata":{}},{"cell_type":"code","source":"df1.filter(['radius_worst','texture_worst','perimeter_worst','area_worst','smoothness_worst',\n            'compactness_worst','concavity_worst','concave points_worst','symmetry_worst','fractal_dimension_worst']). describe()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Histogram relation of variables with Target:","metadata":{}},{"cell_type":"code","source":"v_features = df1.iloc[:,1:31].columns\nplt.figure(figsize=(12,31*8))\ngs = gridspec.GridSpec(31, 1)\nfor i, cn in enumerate(df1[v_features]):\n    ax = plt.subplot(gs[i])\n    sns.distplot(df1[cn][df1.diagnosis == 'B'], bins=50)\n    sns.distplot(df1[cn][df1.diagnosis == 'M'], bins=50)\n    ax.set_xlabel('')\n    ax.set_title('Histogram relation of variables with Target: ' + str(cn))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Correlation map:","metadata":{}},{"cell_type":"code","source":"sns.set(rc={'figure.figsize':(10,8)})\nsns.heatmap(df1.corr(method='spearman'),fmt = '.2f',cmap='Greens')\nplt.title('Correlação entre variáveis')\nplt.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### PCA modeling to reduce dimensionality:\n---","metadata":{}},{"cell_type":"code","source":"# Package decomposition PCA:\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\n# Feature select:\nfeature = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean',\n 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se',\n 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst',\n 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst']\nx = df1.filter(feature)\n\n# Pre-processing:\nx = StandardScaler().fit_transform(x)\n\n# Decomposition PCA:\npca = PCA(n_components=4)\nprincipalComponents = pca.fit_transform(x)\nvar_explicada = pca.explained_variance_ratio_\nvar_exp_df = pd.DataFrame({\"var_exp\":var_explicada})\nprint(\"The explained variance of the four components: \",(var_exp_df['var_exp'].sum().round(2))*100,\"%\")\n\n# Dataset PCA:\nprincipalDf = pd.DataFrame(data = principalComponents,columns = ['pc1', 'pc2', 'pc3', 'pc4'])\ndf_pca = pd.concat([principalDf, df1['diagnosis']], axis = 1)\nprint(\" \")\nprint(\"Dataset with the main components: \")\nprint(\" \")\nprint(df_pca.head(3))\nprint(\" \")\n\n# Graph PCA - PC1 e PC2:\nplt.figure(figsize=(10,8))\nsns.scatterplot(x=\"pc1\", y=\"pc2\", hue=\"diagnosis\", data=df_pca)\nplt.title(\"Principal Components PC1 and PC2\")\nplt.show()\n\n# Graph PCA - PC1 e PC3:\nplt.figure(figsize=(10,8))\nsns.scatterplot(x=\"pc1\", y=\"pc3\", hue=\"diagnosis\", data=df_pca)\nplt.title(\"Principal Components PC1 and PC3\")\nplt.show()\n\n# Graph PCA - PC1 e PC4:\nplt.figure(figsize=(10,8))\nsns.scatterplot(x=\"pc1\", y=\"pc4\", hue=\"diagnosis\", data=df_pca)\nplt.title(\"Principal Components PC1 and PC4\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Baseline - Logistic regression:\n---","metadata":{}},{"cell_type":"code","source":"# Packages:\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (confusion_matrix,auc,roc_curve,classification_report)\n\n# Data splitting:\nxtr, xval, ytr, yval = train_test_split(df_pca.drop('diagnosis',axis=1),df_pca['diagnosis'],test_size=0.2,random_state=1025)\n\n# Training model:\nbaseline = LogisticRegression()\nbaseline.fit(xtr,ytr)\n\n# Predict:\np = baseline.predict(xval)\n\n# Confusion matrix:\ncmx = confusion_matrix(yval, p)\nsns.set(rc={'figure.figsize':(10,8)})\nsns.set(font_scale=1.4)\nsns.heatmap(cmx,annot=True,annot_kws={\"size\": 14},cmap='Greens')\nplt.title(\"Confusion matrix\")\nplt.show()\n\n# Metrics:\nprint(\"Metrics: \")\nprint(classification_report(yval, p))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### AutoML - H2O:\n---","metadata":{}},{"cell_type":"markdown","source":"#### Start cluster h2o:","metadata":{}},{"cell_type":"code","source":"import h2o\nfrom h2o.automl import H2OAutoML\nh2o.init()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Data splitting:","metadata":{}},{"cell_type":"code","source":"train, test = train_test_split(df1, test_size=0.2)\ntraindf = h2o.H2OFrame(train)\ntestdf = h2o.H2OFrame(test)\ny = \"diagnosis\"\nx = list(traindf.columns)\nx.remove(y)\ntraindf[y] = traindf[y].asfactor()\ntestdf[y] = testdf[y].asfactor()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### AutoML H2O training:","metadata":{}},{"cell_type":"code","source":"aml = H2OAutoML(max_models = 80, max_runtime_secs = 300, seed = 247)\naml.train(x = x, y = y, training_frame = traindf)\nprint(aml.leaderboard)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Test model:","metadata":{}},{"cell_type":"code","source":"predict = aml.predict(testdf)\np = predict.as_data_frame()\nprint(\" \")\ndata = {'actual': test.diagnosis,'predict': p['predict'].tolist()}\ndf = pd.DataFrame(data, columns = ['actual','predict'])\ndf.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Confusion matrix:","metadata":{}},{"cell_type":"code","source":"confusion_matrix = pd.crosstab(df['actual'], df['predict'], rownames=['Actual'], colnames=['Predicted'])\nsns.set(rc={'figure.figsize':(10,8)})\nsns.set(font_scale=1.4)\nsns.heatmap(confusion_matrix,annot=True,annot_kws={\"size\": 16},cmap='Greens')\nplt.title(\"Confusion matrix\")\nplt.show()\nprint(\"Metrics:\")\nprint(classification_report(df['actual'], df['predict']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Shutdown h2o cluster:","metadata":{}},{"cell_type":"code","source":"h2o.cluster().shutdown(prompt = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}