{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing Library","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas_profiling\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Read Data\ndf = pd.read_csv(\"../input/heart-disease-uci/heart.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#First 5 rows of data\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dimension of data\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting the data types of the variable\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#statistical properties of dataset\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#columns present in dataset\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analyse the target variable (Univariate Analysis)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#view the unique value in target variable\ndf['target'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#frequency distribution of target variable\ndf['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#graphical representation of target variable\nf, ax = plt.subplots(figsize=(6, 4))\nax = sns.countplot(x=\"target\", data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Profiling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"profile = pandas_profiling.ProfileReport(df)\nprofile","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From Data profiling, we found that there is no missing value in the data. So we don't have to do missing value treatment.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Bivariate Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation matrix to see how features are correlated with target\nplt.rcParams['figure.figsize'] = (20, 15)\nplt.style.use('ggplot')\n\ncorrmat = df.corr()\nsns.heatmap(corrmat, cmap = 'Wistia', annot=True)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Num=corrmat['target'].sort_values(ascending=False).head(20).to_frame()\n\nNum","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Interpretation of correlation coefficient**\n\n* The correlation coefficient ranges from -1 to +1.\n\n* When it is close to +1, this signifies that there is a strong positive correlation. So, we can see that there is no variable which has strong positive correlation with target variable.\n\n* When it is close to -1, it means that there is a strong negative correlation. So, we can see that there is no variable which has strong negative correlation with target variable.\n\n* When it is close to 0, it means that there is no correlation. So, there is no correlation between target and fbs.\n\nWe can see that the cp and thalach variables are mildly positively correlated with target variable.\nAnd exang, oldpeak, ca, thal are negatively correlated. So, I will analyze the interaction between these positively correlated features and target variable.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#We can visualize the value counts of the cp variable wrt target as follows -\nf, ax = plt.subplots(figsize=(8, 6))\nax = sns.countplot(x=\"cp\", hue=\"target\", data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We can visualize the value counts of the thalach variable wrt target as follows -\nf, ax = plt.subplots(figsize=(8, 6))\nsns.stripplot(x=\"target\", y=\"thalach\", data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's change the names of the  columns for better understanding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns = ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'cholesterol', 'fasting_blood_sugar', 'rest_ecg', 'max_heart_rate_achieved',\n       'exercise_induced_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thalassemia', 'target']\n\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sex'][df['sex'] == 0] = 'female'\ndf['sex'][df['sex'] == 1] = 'male'\n\ndf['chest_pain_type'][df['chest_pain_type'] == 1] = 'typical angina'\ndf['chest_pain_type'][df['chest_pain_type'] == 2] = 'atypical angina'\ndf['chest_pain_type'][df['chest_pain_type'] == 3] = 'non-anginal pain'\ndf['chest_pain_type'][df['chest_pain_type'] == 4] = 'asymptomatic'\n\ndf['fasting_blood_sugar'][df['fasting_blood_sugar'] == 0] = 'lower than 120mg/ml'\ndf['fasting_blood_sugar'][df['fasting_blood_sugar'] == 1] = 'greater than 120mg/ml'\n\ndf['rest_ecg'][df['rest_ecg'] == 0] = 'normal'\ndf['rest_ecg'][df['rest_ecg'] == 1] = 'ST-T wave abnormality'\ndf['rest_ecg'][df['rest_ecg'] == 2] = 'left ventricular hypertrophy'\n\ndf['exercise_induced_angina'][df['exercise_induced_angina'] == 0] = 'no'\ndf['exercise_induced_angina'][df['exercise_induced_angina'] == 1] = 'yes'\n\ndf['st_slope'][df['st_slope'] == 1] = 'upsloping'\ndf['st_slope'][df['st_slope'] == 2] = 'flat'\ndf['st_slope'][df['st_slope'] == 3] = 'downsloping'\n\ndf['thalassemia'][df['thalassemia'] == 1] = 'normal'\ndf['thalassemia'][df['thalassemia'] == 2] = 'fixed defect'\ndf['thalassemia'][df['thalassemia'] == 3] = 'reversable defect'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sex'] = df['sex'].astype('object')\ndf['chest_pain_type'] = df['chest_pain_type'].astype('object')\ndf['fasting_blood_sugar'] = df['fasting_blood_sugar'].astype('object')\ndf['rest_ecg'] = df['rest_ecg'].astype('object')\ndf['exercise_induced_angina'] = df['exercise_induced_angina'].astype('object')\ndf['st_slope'] = df['st_slope'].astype('object')\ndf['thalassemia'] = df['thalassemia'].astype('object')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dummy Variable Creation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.get_dummies(df, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting the Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the dependent and independent variables from the data\n\nx = df.drop('target', axis=1)\ny = df.target\n\n# checking the shapes of x and y\nprint(\"Shape of x:\", x.shape)\nprint(\"Shape of y:\", y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the sets into training and test sets\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n\n# getting the shapes\nprint(\"Shape of x_train :\", x_train.shape)\nprint(\"Shape of x_test :\", x_test.shape)\nprint(\"Shape of y_train :\", y_train.shape)\nprint(\"Shape of y_test :\", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Building","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = LogisticRegression()\nmodel1.fit(x_train, y_train)\nmodel1.score(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Random Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = RandomForestClassifier(n_estimators = 50, max_depth = 5)\nmodel2.fit(x_train, y_train)\nmodel2.score(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. XgBoost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model3 = xgb.XGBClassifier(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213,\n                             random_state =7, nthread = -1)\nmodel3.fit(x_train, y_train)\nmodel3.score(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Voting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier \nestimator = [] \nestimator.append(('LR',  \n                  LogisticRegression(solver ='lbfgs',  \n                                     multi_class ='multinomial',  \n                                     max_iter = 200))) \nestimator.append(('RFC', RandomForestClassifier())) \nestimator.append(('XGB', XGBClassifier())) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Voting Classifier with soft voting \nvot_soft = VotingClassifier(estimators = estimator, voting ='soft') \nvot_soft.fit(x_train, y_train) \ny_pred = vot_soft.predict(x_test) \ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using accuracy_score \nscore = accuracy_score(y_test, y_pred) \nprint(\"Soft Voting Score % d\" % score) ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}