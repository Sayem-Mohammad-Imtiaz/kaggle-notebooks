{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f32b055b4477d59c121194f494921ac2e5336b63"},"cell_type":"code","source":"df_email = pd.read_csv(\"../input/spam.csv\", encoding=\"latin-1\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_email.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df58ce9ba0bc65606652c9cd3de9874b1296d47d"},"cell_type":"code","source":"df_email.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"074f752c3c83c25959daa715780bc3ee79b2e791"},"cell_type":"code","source":"email_dataset = []\nfor index,row in df_email.iterrows():\n    email_dataset.append((row['v2'],row['v1']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0d0c8ba57e4737f5678038ec7052b07f77afde7"},"cell_type":"code","source":"print(email_dataset[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3b1accc9d4f0bc6e5e6ace74b3dd943ba94e2df"},"cell_type":"code","source":"print(len(email_dataset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64233c083e51970b61737acd3f022a41158dec04"},"cell_type":"code","source":"spam_count = len(df_email[df_email['v1'] == 'spam'])\nprint((spam_count/len(email_dataset)) * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b344c63d63ecbc2aa953be49b009118b365c8c40"},"cell_type":"code","source":"ham_count = len(df_email[df_email['v1'] == 'ham'])\nprint((ham_count/len(email_dataset)) * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6f25d09fcf136f76195e5522656e067f3d737ae"},"cell_type":"code","source":"stemmer = PorterStemmer()\nwordnet_lemmatizer = WordNetLemmatizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84d57e8eec98b30ab1ce9494b31e087b5ba9e65d"},"cell_type":"code","source":"def preprocess(document, stem=True):\n    #following changes document to lower case, \n    #and removes stopwords and lemmatizes/stems the remainder of the sentence'\n\n    # change sentence to lower case\n    document = document.lower()\n\n    # tokenize the given document into words\n    words = word_tokenize(document)\n\n    # remove stop words\n    words = [word for word in words if word not in stopwords.words(\"english\")]\n\n    if stem:\n        words = [stemmer.stem(word) for word in words]\n    else:\n        words = [wordnet_lemmatizer.lemmatize(word, pos='v') for word in words]\n\n    # join words to make sentence\n    document = \" \".join(words)\n\n    return document","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbaf8ec9527e2be04827b859a3047be8840179af"},"cell_type":"code","source":"# Performing preprocessing on the messages in the data\nmessages_set =[]\nfor(message,label) in email_dataset :\n    filtered_words = [e.lower() for e in preprocess(message, stem= False).split() if len(e) >3]\n    messages_set.append((filtered_words, label))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"417661665fb1ee8e88697d62a8cc30e75445a5f7"},"cell_type":"code","source":"print(messages_set[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e52a9d2a20d1badb2c25ddff87ad78bc8dac621"},"cell_type":"code","source":"## creating a consolidation list of all the messages we have in the message set\n## in order to select the word feature list in upcoming steps.\n\ndef get_messages(messages) :\n    words =[]\n    for(message,lable) in messages :\n        words.extend(message)\n    return words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfce1b34c7ad087d8dfe537398ad0cba2899570d"},"cell_type":"code","source":"## now creating the word feature list using the FreqDist function\n## FreqDist Method : returns the frequency of the word by calculating the tf-idf scores\n\ndef word_featurs(wordlist) :\n    wordlist = nltk.FreqDist(wordlist)\n    word_features = wordlist.keys()\n    return word_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"708bcb41f5a148245dc397a2a476fe6829558e3d"},"cell_type":"code","source":"word_features = word_featurs(get_messages(messages_set))\nprint(len(word_features))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e19aea30d4c772c84ba4ce5e20be435154f870e3"},"cell_type":"markdown","source":"## Creating the test train set on the dataset"},{"metadata":{"trusted":true,"_uuid":"832bf167278de9fa40b3aa2c8775239823bbf13c"},"cell_type":"code","source":"index = int((len(messages_set) * 0.7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a51ba7cae78aeac377c7a927e2d2de5691018341"},"cell_type":"code","source":"import random\nrandom.shuffle(messages_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"762f51cf1d98e23d455785ca3eec0192b8d2e6a4"},"cell_type":"code","source":"train_messages,test_messages= messages_set[:index],messages_set[index:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7c9f53d7759dc7d943448287e939a0331384d96"},"cell_type":"code","source":"print(len(messages_set))\nprint((len(train_messages)/len(messages_set)) * 100)  # 70%\nprint((len(test_messages)/len(messages_set)) * 100)   # 30%","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92fbbb9b7786a4b31c269bc633b54633c4d13d48"},"cell_type":"code","source":"def extract_features(document) :\n    word_documents = set(document)\n    features = {}\n    for word in word_features:\n        features['contains(%s)' % word] = (word in word_documents)\n    return features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a59a99a0d71fce52bd7e42ef80e4497a1f9c095b"},"cell_type":"code","source":"training_set = nltk.classify.apply_features(extract_features,train_messages)\ntest_set = nltk.classify.apply_features(extract_features,test_messages)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43f17305defdd63f85af7b96707d89060338f75f"},"cell_type":"code","source":"print(training_set[:5])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4eb52fed5d1198f8cf42b8b209ee7f7f2a942fae"},"cell_type":"markdown","source":"## Using Naive Bayes Algorithm to classify whether a given message is SPAM or HAM\n## Using Naive Bayes because it treats 1 feature independent to the other, and is a probabistic identifier\n"},{"metadata":{"trusted":true,"_uuid":"28d3a0ddfa64b731372bc6aa330eac927530fe3b"},"cell_type":"code","source":"spam_Classifier = nltk.NaiveBayesClassifier.train(training_set)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c8f228046aba9a49c227a659c5209eeaeb188fa9"},"cell_type":"markdown","source":"********Evaluating the above model**"},{"metadata":{"trusted":true,"_uuid":"5d6992fef71497f1dc800770377ee1ad6a646bec"},"cell_type":"code","source":"print(nltk.classify.accuracy(spam_Classifier, training_set))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"deba55c519eb4299fd2fc7b9cb98d99f183de9a7"},"cell_type":"code","source":"print(nltk.classify.accuracy(spam_Classifier, test_set))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53b0c2522ccdd6b38c4761dbd5431ed63c7b94e7"},"cell_type":"code","source":"### Printing the important features in the classifier evaluated above\nprint(spam_Classifier.show_most_informative_features(50))\n\n### The below probability \"179 against 1 says that award in a \n### given message has very high probability to be a SPAM\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f1b59004938a9ce2cdf14dc3ff94ea0b81a66d2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a41e5dc7c31b58e3d8288b067fbd69589230926"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbb16b758a46728c57841d8f190557620a241545"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c67f41a6b0010f3d616e383eff6e6a226a4871b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa81c53bb77e8b0b5dd883903ddada62a94231bf"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2433cd8ed14a9315c5ee7947a7ee4fb548c9a9de"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d15843ce6c0ca1846e8499d54a3bffcf37c42bd"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}