{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras import regularizers\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn import model_selection\nimport random\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.models import model_from_json\nimport csv\nfrom keras.callbacks import History\nfrom shutil import copyfile\nimport os\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data_df contains Unnamed: 0\tX_ray_image_name\tLabel\tDataset_type\tLabel_2_Virus_category\tLabel_1_Virus_category\ndata_df = pd.read_csv('../input/coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv')\n# meta_df contains Unnamed: 0\tLabel\tLabel_1_Virus_category\tLabel_2_Virus_category\tImage_Count\nmeta_df = pd.read_csv('../input/coronahack-chest-xraydataset/Chest_xray_Corona_dataset_Summary.csv')\n\ntest_dir ='../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test'\ntrain_dir = '../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train'\n\ntrain_data = data_df[data_df['Dataset_type']=='TRAIN']\ntest_data = data_df[data_df['Dataset_type']=='TEST']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Filtering out the data belonging to the following three labels and shuffling the data\ntrain_data.fillna('NA', inplace = True)\ntrain_dff = train_data[(train_data['Label'] =='Pnemonia') | (train_data['Label'] == 'Normal')]\ntrain_dff = train_dff.sample(frac=1, random_state=8)  # this is to randomise the order of the dataframe\nprint(len(train_dff))\ntrain_dff","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Similar as above for test data\ntest_data.fillna('NA', inplace = True)\ntest_df = test_data[(test_data['Label'] =='Pnemonia') | (test_data['Label'] == 'Normal')]\nprint(len(test_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_validation = model_selection.train_test_split(train_dff, train_size=0.80, test_size=0.20, random_state=8)\nX_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating new folders with split validation and test data\nos.mkdir('/kaggle/working/train')\nfor X_ray in X_train.X_ray_image_name:\n    copyfile('../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train/' + X_ray, \n             '/kaggle/working/train/' + X_ray)\n\nos.mkdir('/kaggle/working/validation')\nfor X_ray in X_validation.X_ray_image_name:\n    copyfile('../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train/' + X_ray, \n             '/kaggle/working/validation/' + X_ray)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '/kaggle/working/train'\nvalidation_dir = '/kaggle/working/validation'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_gen_train = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    brightness_range=None,\n    zoom_range=0.10,\n    channel_shift_range=0.0,\n    fill_mode=\"nearest\",\n    cval=0.0,\n    horizontal_flip=True,\n    rescale=1./255,\n    preprocessing_function=None,\n    dtype=None\n)\n\nimage_gen_valtest = ImageDataGenerator(\n    brightness_range=None,\n    channel_shift_range=0.0,\n    fill_mode=\"nearest\",\n    cval=0.0,\n    rescale=1./255,\n    preprocessing_function=None,\n    dtype=None\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# augmenting the training data\ntraining_generators = []\nfor seed in range(9):\n    train_datagen = image_gen_train.flow_from_dataframe(\n        dataframe=X_train,\n        directory=train_dir,\n        x_col=\"X_ray_image_name\",\n        y_col=\"Label\",\n        classes = ['Normal','Pnemonia'],\n        target_size=(256, 256),\n        color_mode=\"rgb\",\n        class_mode=\"categorical\",\n        batch_size=32,\n        seed=seed,\n        shuffle=True\n    )\n    training_generators.append(train_datagen)\ntraining_generators.append(image_gen_valtest.flow_from_dataframe(\n        dataframe=X_train,\n        directory=train_dir,\n        x_col=\"X_ray_image_name\",\n        y_col=\"Label\",\n        classes = ['Normal','Pnemonia'],\n        target_size=(256, 256),\n        color_mode=\"rgb\",\n        class_mode=\"categorical\",\n        batch_size=32,\n        seed=seed,\n        shuffle=True\n    ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_datagen = image_gen_valtest.flow_from_dataframe( \n    dataframe=X_validation,\n    directory=validation_dir,\n    x_col=\"X_ray_image_name\",\n    y_col=\"Label\",\n    classes = ['Normal','Pnemonia'],\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    batch_size=32,\n    seed=25,\n    shuffle=False\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = image_gen_valtest.flow_from_dataframe(\n    dataframe=test_df,\n    directory=test_dir,\n    x_col=\"X_ray_image_name\",\n    y_col=\"Label\",\n    classes = ['Normal','Pnemonia'],\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    batch_size=32,\n    seed=25,\n    shuffle=False\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(3, 2, figsize=(16, 16))\nfor i,j in enumerate(training_generators[8]):\n    \n    \n    for k in range(6):\n        plt.subplot(3,2,k+1)\n        plt.imshow((j[0])[k])\n        ax[0,0].set_title((j[1])[k])\n        \n        \n    #print(j[1])\n    if i == 0:\n        break ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generateHyperparameters():\n\n    param_grid = {\n        'no_layers': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n        'batch_norm': [True, False],\n        'learning_rate': list(np.logspace(np.log10(0.001), np.log10(0.01), base=10, num=100)),\n        'kernel_size': list(int(x) for x in np.logspace(np.log2(4), np.log2(512), base=2, num=8)),\n        'dropout': [False, True],\n        'dropout_rate': [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5],\n        'pool_size': [2,3,4],\n        'should_channels': [True, False],\n        'kernel_size': [3, 4, 5, 6],\n        'weight_decay':list(np.logspace(np.log10(0.00001), np.log10(0.0005), base=10, num=10))\n    }\n\n\n    no_layers = random.choice(param_grid['no_layers'])\n    kernel_size = random.choice(param_grid['kernel_size'])\n    batch_norm = random.choice(param_grid['batch_norm'])\n    learning_rate = round(random.choice(param_grid['learning_rate']), 5)\n    kernel_size = random.choice(param_grid['kernel_size'])\n    dropout = random.choice(param_grid['dropout'])\n    dropout_rate = random.choice(param_grid['dropout_rate'])\n    pool_size = random.choice(param_grid['pool_size'])\n    should_channels = random.choice(param_grid['should_channels'])\n    weight_decay = round(random.choice(param_grid['weight_decay']), 5)\n    \n\n    while (pool_size > kernel_size):\n        pool_size = random.choice(param_grid['pool_size'])\n    channels = [32] * no_layers\n    if should_channels:\n        for i in range (no_layers):\n            channels[i] = 2 ** (i+5)\n\n    hyper_grid = {\n        'no_layers': no_layers,\n        'batch_norm': batch_norm,\n        'learning_rate': learning_rate,\n        'kernel_size': kernel_size,\n        'dropout': dropout,\n        'dropout_rate': dropout_rate,\n        'pool_size': pool_size,\n        'should_channels': should_channels,\n        'kernel_size': kernel_size,\n        'weight_decay': weight_decay,\n        'channels': channels\n    }\n\n\n    print(hyper_grid)\n    \n    return hyper_grid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def buildModel(hyper_grid):\n    \n    model = Sequential()\n    \n    \n\n    model.add(Conv2D(32, (hyper_grid['kernel_size'],hyper_grid['kernel_size']), padding='same', input_shape=[256,256,3], kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(hyper_grid['weight_decay'])))\n    if hyper_grid['batch_norm']:\n        model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    if hyper_grid['dropout']:\n        model.add(Dropout(hyper_grid['dropout_rate']))\n    model.add(MaxPooling2D(pool_size=(hyper_grid['pool_size'],hyper_grid['pool_size'])))\n\n    for i in range(hyper_grid['no_layers'] - 1):\n        if (model.output_shape[1] > hyper_grid['pool_size']):\n            model.add(Conv2D(hyper_grid['channels'][i], (hyper_grid['kernel_size'],hyper_grid['kernel_size']), padding='same', kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(hyper_grid['weight_decay'])))\n            if hyper_grid['batch_norm']:\n                model.add(BatchNormalization())\n            model.add(Activation('relu'))\n            if hyper_grid['dropout']:\n                model.add(Dropout(hyper_grid['dropout_rate']))\n\n            model.add(MaxPooling2D(pool_size=(hyper_grid['pool_size'],hyper_grid['pool_size'])))\n\n\n\n    model.add(Flatten())\n    model.add(Dense(2, activation='softmax'))\n    model.summary()\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_auc_score(val_labels, X_pred_keras):\n    fpr_keras, tpr_keras, thresholds_keras = roc_curve(val_labels, X_pred_keras)\n    auc_keras = auc(fpr_keras, tpr_keras)\n    return auc_keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def writeToCsv(records, model):\n    \n    history_dict = records.history\n    print(history_dict.keys())\n\n\n    acc = records.history['accuracy']\n    val_acc = records.history['val_accuracy']\n    auc_score = plotRoc(model, valid_datagen, 'simrenModel')\n    \n\n    toPrint = {'Accuracy': acc, 'ValAccuracy': val_acc, 'AUC score': auc_score}\n    print(toPrint)\n    \n    with open ('mycsv.csv', 'a', newline='') as f:\n        thewriter = csv.writer(f)\n        thewriter.writerow(hyper_grid)\n        thewriter.writerow(hyper_grid.values())\n        thewriter.writerow(toPrint)\n        thewriter.writerow(toPrint.values())\n        print(\"wrote to csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training code here\ndef trainModel(training_generators, valid_datagen,hyper_grid, epochs =1):\n    \n    class_weight = {0: 3,  # Normal\n                    1: 1}  # Pneumonia\n    \n    model = buildModel(hyper_grid)\n\n    optimizer = Adam(learning_rate=hyper_grid['learning_rate'])\n    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    callback = EarlyStopping(monitor='val_loss', patience=3)\n    \n    save_records = []\n\n    for train_datagen in training_generators:\n        records = model.fit_generator(train_datagen, epochs=epochs, validation_data=valid_datagen, class_weight=class_weight, callbacks=[callback])\n        save_records.append(records)\n        \n    writeToCsv(records, model)\n    print(\"wrote\")\n    \n    return model, records, save_records","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotRoc(model, datagen, title):\n    \n    X_pred_keras = model.predict(datagen)[:, 1]\n    labels = [l for l in datagen.labels]\n    fpr_keras, tpr_keras, thresholds_keras = roc_curve(labels, X_pred_keras)\n    auc_keras = auc(fpr_keras, tpr_keras)\n\n    plt.figure(1)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.plot(fpr_keras, tpr_keras, label='Simren Model (area = {:.3f})'.format(auc_keras))\n    plt.xlabel('False positive rate')\n    plt.ylabel('True positive rate')\n    plt.title('ROC curve')\n    plt.legend(loc='best')\n    plt.savefig('/kaggle/working/{}.png'.format(title), dpi = 300)\n    # Zoom in view of the upper left corner.\n    plt.figure(2)\n    plt.xlim(0, 0.3)\n    plt.ylim(0.7, 1)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.plot(fpr_keras, tpr_keras, label='Simren Model (area = {:.3f})'.format(auc_keras))\n    plt.xlabel('False positive rate')\n    plt.ylabel('True positive rate')\n    plt.title('ROC curve (zoomed in at top left)')\n    plt.legend(loc='best')\n    plt.savefig('/kaggle/working/{}_zoomed.png'.format(title), dpi = 300)\n    \n    auc_score = get_auc_score(labels, X_pred_keras)\n    \n    return auc_score\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Accuracy Plots for train and validation over epochs\n\ndef accuracyPlot(records):\n    \n    acc = []\n    val_acc = []\n    loss = []\n    val_loss = []\n    \n    fake_acc = []\n    fake_val_acc = []\n    fake_loss = []\n    fake_val_loss = []\n    \n    \n    for i in range (len(records)):\n        fake_acc.append(records[i].history['accuracy'])\n        fake_val_acc.append(records[i].history['val_accuracy'])\n        fake_loss.append(records[i].history['loss'])\n        fake_val_loss.append(records[i].history['val_loss'])\n        \n    for x in range (len(fake_acc)):\n        for y in range (len(fake_acc[x])):\n            acc.append(fake_acc[x][y])\n            val_acc.append(fake_val_acc[x][y])\n            loss.append(fake_loss[x][y])\n            val_loss.append(fake_val_loss[x][y])\n    \n    \n    print(acc)\n    \n    epochs = range(1, len(acc) + 1)\n    \n    print(\"epochs: \"+ str(epochs))\n\n    plt.plot(epochs, acc, 'bo', label='Training acc')\n    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n    plt.savefig('/kaggle/working/epochsAcc.png', dpi = 300)\n    plt.figure()\n    plt.plot(epochs, loss, 'bo', label='Training loss')\n    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n    plt.savefig('/kaggle/working/epochsLoss.png', dpi = 300)\n    plt.show()\n      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Once hyperparameters are decided\ndropout = False\nbatch_norm = False\ndropout_rate = 0.2\nkernel_size = 3\nlearning_rate = 0.00392\nno_layers = 5\npool_size = 3\nchannels = [32] * no_layers\nshould_channels = False\nweight_decay = 0.00004\n\n\nif should_channels:\n    for i in range (no_layers):\n        channels[i] = 2 ** (i+5)\n\nhyper_grid = {\n    'no_layers': no_layers,\n    'batch_norm': batch_norm,\n    'learning_rate': learning_rate,\n    'kernel_size': kernel_size,\n    'dropout': dropout,\n    'dropout_rate': dropout_rate,\n    'pool_size': pool_size,\n    'should_channels': should_channels,\n    'kernel_size': kernel_size,\n    'weight_decay': weight_decay,\n    'channels': channels\n    }\n\n\nmodel, records, save_records = trainModel(training_generators, valid_datagen, hyper_grid, epochs = 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(save_records)\naccuracyPlot(save_records)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#saving model\nmodel_json = model.to_json()\nwith open('/kaggle/working/model_CNN_Simren', 'w') as json_file:\n    json_file.write(model_json)\n# saving the model weight separately\nmodel.save_weights('/kaggle/working/model_weights_CNN_Simren.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test set\n\nlog=model.evaluate(\n    test_datagen,\n    batch_size=32,\n    verbose=1,\n    sample_weight=None,\n    steps=624/32,\n    callbacks=None,\n    max_queue_size=10,\n    workers=1,\n    use_multiprocessing=False,\n    return_dict=False,\n)\n\nplotRoc(model, test_datagen, \"testROC\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}