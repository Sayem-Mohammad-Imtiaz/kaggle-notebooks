{"cells":[{"metadata":{"_uuid":"f172322b-103d-4a33-8715-e844f6fe61d8","_cell_guid":"02ae2eaf-7000-49d7-bcf2-0b6f199ec65e","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"362e8d66-0d8f-49b0-8202-cc4a017bc22a","_cell_guid":"17033a76-a30e-4e8b-a538-8c64eff107aa","trusted":true},"cell_type":"code","source":"train_orig=pd.read_csv(\"/kaggle/input/twitter-sentiment-analysis-hatred-speech/train.csv\")\ntest_nolabel=pd.read_csv(\"/kaggle/input/twitter-sentiment-analysis-hatred-speech/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2ae141d-1fcc-474e-89e1-0fcb600bdf2b","_cell_guid":"41ab1dca-59e7-491b-b322-ce1dffa9d198","trusted":true},"cell_type":"markdown","source":"**Let us do some pre-processing. Without preprocessing results are:  (Avoid looking at these metrics in the beginning, will be explained in the end of notebook)**\n<pre>\n               precision    recall  f1-score   support\n \n            0       0.95      1.00      0.97     14880\n            1       0.85      0.35      0.49      1101\n \n     accuracy                           0.95     15981\n    macro avg       0.90      0.67      0.73     15981\n weighted avg       0.95      0.95      0.94     15981\n \n [[14815    65]\n [  718   383]]\n</pre>"},{"metadata":{"_uuid":"6c4a1dff-2158-443c-ba7e-65396dc978f1","_cell_guid":"9a41bf42-4614-4539-9600-9c3d118678f4","trusted":true},"cell_type":"markdown","source":"**New metric:**\n<pre>\n              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98     14848\n           1       0.88      0.40      0.55      1133\n\n    accuracy                           0.95     15981\n   macro avg       0.92      0.70      0.76     15981\nweighted avg       0.95      0.95      0.95     15981\n\n[[14786    62]\n [  683   450]]\n</pre>"},{"metadata":{"_uuid":"77bda0c1-e028-4975-8774-a3d4bba3b8e7","_cell_guid":"f4d21903-5795-47b5-a29a-4cb774bbf079","trusted":true},"cell_type":"markdown","source":"**New report with stratification enabled. Shows further improvement in results\n**<pre>\n              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98     14860\n           1       0.89      0.42      0.57      1121\n\n    accuracy                           0.96     15981\n   macro avg       0.92      0.71      0.77     15981\nweighted avg       0.95      0.96      0.95     15981\n\n[[14800    60]\n [  650   471]]\n</pre>"},{"metadata":{"_uuid":"c22d26c9-1f3b-44af-a109-88ecc7c6b06a","_cell_guid":"3c3cd4bd-c7f0-4da2-8285-5ff8be0eb422","trusted":true},"cell_type":"markdown","source":"**Classification report after upsampling the minority classes. Look at updated values for label 1**\n<pre>\n              precision    recall  f1-score   support\n\n           0       0.98      0.91      0.94     14860\n           1       0.92      0.98      0.95     14860\n\n    accuracy                           0.94     29720\n   macro avg       0.95      0.94      0.94     29720\nweighted avg       0.95      0.94      0.94     29720\n\n[[13542  1318]\n [  345 14515]]\n</pre>"},{"metadata":{"_uuid":"545ce8e2-b097-4d92-af34-f447bfa73415","_cell_guid":"1c5a28bd-d7b3-4ab9-9196-74a0cd545fa2","trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk import word_tokenize\nimport string\nimport re\nstop_words = set(stopwords.words('english'))\n\ntrain = train_orig\n\ndef remove_stopwords(line):\n    word_tokens = word_tokenize(line)\n    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n    return \" \".join(filtered_sentence)\n\ndef preprocess(line):\n    line = line.lower()  #convert to lowercase\n    line = re.sub(r'\\d+', '', line)  #remove numbers\n    line = line.translate(line.maketrans(\"\",\"\", string.punctuation))  #remove punctuation\n#     line = line.translate(None, string.punctuation)  #remove punctuation\n    line = remove_stopwords(line)\n    return line\nfor i,line in enumerate(train.tweet):\n    train.tweet[i] = preprocess(line)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c00d887a-8462-4a1e-96a8-5a191d58de0a","_cell_guid":"2658bee4-b6f5-42fb-9852-086972f24833","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train['tweet'], train['label'], test_size=0.5, stratify=train['label'])\n\ntrainp=train[train.label==1]\ntrainn=train[train.label==0]\nprint(trainp.info())\ntrainn.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ecbc3e4-9e76-4f59-96a7-4baa3d90bf2d","_cell_guid":"bd02ec0f-5988-4f73-b745-4cfb6e1343a7","trusted":true},"cell_type":"code","source":"# Let us balance the dataset\ntrain_imbalanced = train\nfrom sklearn.utils import resample\ndf_majority = train[train.label==0]\ndf_minority = train[train.label==1]\n \n# Upsample minority class\ndf_minority_upsampled = resample(df_minority, \n                                 replace=True,     # sample with replacement\n                                 n_samples=len(df_majority),    # to match majority class\n                                 random_state=123) # reproducible results\n \n# Combine majority class with upsampled minority class\ndf_upsampled = pd.concat([df_majority, df_minority_upsampled])\n \n# Display new class counts\nprint(\"Before\")\nprint(train.label.value_counts())\nprint(\"After\")\nprint(df_upsampled.label.value_counts())\n\nX_train, X_test, y_train, y_test = train_test_split(df_upsampled['tweet'], df_upsampled['label'], test_size=0.5, stratify=df_upsampled['label'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff6c0358-5e6c-486f-9460-d40bc761f0f7","_cell_guid":"3682bb61-2c9a-4f18-bd72-a260715e3de3","trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nmodel = MultinomialNB()\n# Xtext=train.tweet\n# Xtest=test.tweet\n# y=train.label\n# test\n# ytest=test.label","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f035a950-c9ea-4a0f-9ae8-243da90f61c9","_cell_guid":"e6c832a6-7f29-4437-99c9-4c23bb873a92","trusted":true},"cell_type":"markdown","source":"**Convert text data to numerical data**"},{"metadata":{"_uuid":"21aad3d4-956e-4331-98f0-b7ee7d4d054c","_cell_guid":"5e079ce1-cd21-4a88-ad30-cd4dec1132c4","trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nvect = CountVectorizer()\ntf_train=vect.fit_transform(X_train)  #train the vectorizer, build the vocablury\ntf_test=vect.transform(X_test)  #get same encodings on test data as of vocabulary built","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c6b0cfd-b97c-4a4f-b427-46c5d8335b23","_cell_guid":"0dffb59c-f58c-43c8-b4af-d2d0fb4aa60b","trusted":true},"cell_type":"code","source":"tf_test_nolabel=vect.transform(test_nolabel.tweet)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac3676cd-ab8f-4ad5-af72-301c200d506d","_cell_guid":"56b151f1-8a05-4409-9993-6e9252746a21","trusted":true},"cell_type":"code","source":"# print(tf_train)\n# vect.get_feature_names()[:10] #print few features only to avoid slowing down the notebook","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8509ea7e-dd8a-4368-ab4b-577cafab1b14","_cell_guid":"0a24b22a-d1ff-49eb-a7f2-39df2512f515","trusted":true},"cell_type":"code","source":"model.fit(X=tf_train,y=y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac200f4f-a6f9-4407-a625-e428592806cf","_cell_guid":"02ebf491-c05c-4e34-9c4c-544bcbd8143e","trusted":true},"cell_type":"code","source":"expected = y_test\npredicted=model.predict(tf_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56d1a150-285d-4a31-b751-e8a59c862cc5","_cell_guid":"3e484157-bea8-4dda-9c68-4aa13c793efc","trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nprint(metrics.classification_report(expected, predicted))\nprint(metrics.confusion_matrix(expected, predicted))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7e7ecda5-c3a7-4994-9b3e-59a92d0f17c2","_cell_guid":"b02655b9-6c67-440c-8494-7b8760dc3194","trusted":true},"cell_type":"code","source":"from mlxtend.plotting import plot_confusion_matrix\n\nplot_confusion_matrix(metrics.confusion_matrix(expected, predicted))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e140b35-6886-4824-9e76-12d94747091c","_cell_guid":"8ff430b4-0f2a-4400-8529-03a7293ff197","trusted":true},"cell_type":"code","source":"print(trainp.iloc[:10])\ntrainn.iloc[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4fb6a4a3-1051-4ca1-b824-8e9b6420a143","_cell_guid":"4baa06b4-d676-4777-a8da-20c723932101","trusted":true},"cell_type":"code","source":"gg=X_test.reset_index(drop=True)\n# print(gg)\nfor i, p in enumerate(predicted):\n#     print(i)\n    print (gg[i] + \" - \" + str(p))\n    if i>5:\n        break #to avoid a lot of printing and slowing down the notebook","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c15d7b4b-f9da-4981-8ad2-d805d1adfae2","_cell_guid":"55a8ff07-c090-4ad5-bf92-16c48bce31f5","trusted":true},"cell_type":"code","source":"predicted_nolabel=model.predict(tf_test_nolabel)\nfor i, p in enumerate(tf_test_nolabel):\n#     print(i)\n    print (test_nolabel.tweet[i] + \" - \" + str(predicted_nolabel[i]))\n    if i>5:\n        break #to avoid a lot of printing and slowing down the notebook","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54965345-66b1-4636-aa9d-115a2b5d45cb","_cell_guid":"964674c1-9583-4bd5-bee7-bc91236e9336","trusted":true},"cell_type":"code","source":"test_custom=pd.DataFrame([\"racist\", \"white judge trial\", \"it is a horrible incident\", \"@user #white #supremacists want everyone to see the new â  #birdsâ #movie â and hereâs why\", \" @user #white #supremacists want everyone to see the new â  #birdsâ #movie â and hereâs why\", \"@user  at work: attorneys for white officer who shot #philandocastile remove black judge from presiding over trial. htâ¦\"])\ntf_custom = vect.transform(test_custom[0])\nmodel.predict(tf_custom)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab8504db-2cd9-40ce-ac1c-bea6959f3fbb","_cell_guid":"df829822-e9e2-4181-87b2-7543e3183b59","trusted":true},"cell_type":"code","source":"twit=pd.read_csv(\"../input/godrejtweet/Tweets.csv\")\ntf_twit=vect.transform(twit.tweet)\npredicted_twit=model.predict(tf_twit)\nneg=0\npos=0\n\nfor i, p in enumerate(tf_twit):\n#     print(i)\n    print (twit.tweet[i] + \" - \" + str(predicted_twit[i]))\n    if (predicted_twit[i]==0):\n        pos+=1\n    else:\n        neg+=1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71a41739-dbde-4ead-a9a7-03bf52e4114c","_cell_guid":"1ab2a410-d1f0-4560-843b-28d6495cec91","trusted":true},"cell_type":"code","source":"print (\"Positive Tweets - \",pos)\nprint (\"Negative Tweets - \",neg)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}