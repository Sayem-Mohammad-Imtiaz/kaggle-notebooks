{"cells":[{"metadata":{},"cell_type":"markdown","source":"Contents of this notebook:\n\n   1. [Library loading and installation](#1)\n   2. [How does the number of ratings affect the rating of a book?](#2)\n   3. [Preprocessing](#3)\n   4. [Ordinary Least Squares Linear Regression](#4)\n   5. [Ridge Regression](#5)\n   6. [Lasso](#6)\n  \n       6.1. [Normalizing the data](#7)\n       \n       6.2. [LassoLarsIC](#8)\n       \n       6.3. [LassoCV](#9)\n       \n       6.4. [LassoLarsCV](#10)\n   7. [Elastic-Net](#11)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Citation\n\n[Scikit-learn: Machine Learning in Python](http://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html), Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n\n[API design for machine learning software: experiences from the scikit-learn project](https://arxiv.org/abs/1309.0238), Buitinck et al., 2013.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> # 1. Library loading and installation<a id=\"1\"></a>","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport math\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport seaborn as sns\nfrom scipy.stats import powerlaw\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC, lasso_path, enet_path, BayesianRidge\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.metrics import confusion_matrix\nimport time\nfrom itertools import cycle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install powerlaw","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import powerlaw","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"books = pd.read_csv(\"../input/goodreadsbooks/books.csv\", error_bad_lines = False)\nbooks.rename(columns={\"  num_pages\":'num_pages'}, inplace=True)\nbooks.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # 2. How does the number of ratings affect the rating of a book?<a id=\"2\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"First sort the books by the number of ratings.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"books.sort_values(by='ratings_count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the maximum of the number of ratings.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"max_ratings_count = np.max(books.ratings_count)\nmax_ratings_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# histogram of number of ratings\nratings = books.ratings_count.loc[books.ratings_count < 10000] # >= 10000 outliers\nplt.figure(figsize=(10, 5))\nplt.hist(ratings, bins=10000)\nplt.title('Histogram of the Number of Ratings')\nplt.ylabel('Count')\nplt.xlabel('Number of Ratings')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A sign of power law distribution. Although the maximum ratings count is 4 million, actual rating counts exceeding 10000 are insignificant.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Power Law Distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fit = powerlaw.Fit(ratings+1,xmin=1,discrete=True)\nfit.power_law.plot_pdf(color= 'b',linestyle='--',label='fit ccdf')\nfit.plot_pdf(color= 'b')\nplt.title('Power Law Distribution of ratings_count')\nplt.xlabel('log axis of ratings_count')\nplt.ylabel('log axis of count')\nprint('alpha= ',fit.power_law.alpha,'  sigma= ',fit.power_law.sigma)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How does the flunctuation look like?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ave_ratings = []\nfor i in range(1, len(ratings)):\n    rating = books.average_rating[books.ratings_count == i].values.astype(float)\n    ave_ratings.append(np.average(rating))\nplt.figure(figsize=(20, 10))\nplt.plot(ave_ratings)\nplt.title('Average Ratings for each Ratings Count')\nplt.xlabel('Ratings Count')\nplt.ylabel('Average Rating')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The ratings count does not seem to have a strong effect in the mean of the average rating. However, it does reduce the flunctuation, i.e., the variance, of the average ratings, as the ratings count increases.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ave_ratings = np.array(ave_ratings)\nave_ratings = ave_ratings[ave_ratings >= 0]\naverage_rating = np.average(ave_ratings)\nprint('The average rating of all books: ' + '%.2f' % average_rating)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # 3. Preprocessing<a id='3'></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Only ratings_count, num_pages and text_reviews_count are taken as features.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Overall fitting\nX = books.loc[0:, ['ratings_count', 'num_pages', 'text_reviews_count']].values.astype(float)\ny = books.average_rating.values.astype(float)\n\nbooks.sort_values(by='bookID')\nbooks = books.loc[books.ratings_count < 7000] # >= 7000 outliers\n\n# Training and prediction\ntrain_X = books.loc[0:8000, ['ratings_count', 'num_pages', 'text_reviews_count']].values.astype(float)\ntrain_y = books.loc[0:8000, ['average_rating']].values.astype(float)\ntest_X = books.loc[8000:, ['ratings_count', 'num_pages', 'text_reviews_count']].values.astype(float)\ntest_y = books.loc[8000:, ['average_rating']].values.astype(float)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # 4. Linear Regression<a id=\"4\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = linear_model.LinearRegression()\nreg.fit(X, y)\n\n# The coefficients of each of these features.\nprint('Regression Coefficients:')\nprint(reg.coef_)\nprint('Interception:')\nprint(reg.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg.fit(train_X, train_y)\n\nprint('Regression Coefficients:')\nprint(reg.coef_)\nprint('Interception:')\nprint(reg.intercept_)\n\npred_y = reg.predict(test_X)\n\nprint('Mean Squared Error:')\nprint(mean_squared_error(test_y, pred_y))\n\nprint('r2 score:')\nprint(r2_score(test_y, pred_y))\n\nprint('Sum of Squared Errors:')\nprint(np.sum(np.square(pred_y - test_y)))\n\nfig = plt.figure(figsize = (10, 7)) \nax = plt.axes(projection =\"3d\") \nax.scatter3D(test_X[:, 0], test_X[:, 1], test_y, color = \"b\")\nplt.title(\"ratings_count and num_pages vs average_rating\")\nax.set_xlabel(\"ratings_count\")\nax.set_ylabel(\"num_pages\")\nax.set_zlabel(\"average_rating\")\nax.scatter3D(test_X[:, 0], test_X[:, 1], pred_y, color = \"green\")\nax.legend(['actual', 'predicting'])\n\nplt.show()\n\nfig = plt.figure(figsize = (10, 7)) \nax = plt.axes(projection =\"3d\") \nax.scatter3D(test_X[:, 0], test_X[:, 2], test_y, color = \"b\")\nplt.title(\"ratings_count and text_reviews_count vs average_rating\")\nax.set_xlabel(\"ratings_count\")\nax.set_ylabel(\"text_reviews_count\")\nax.set_zlabel(\"average_rating\")\nax.scatter3D(test_X[:, 0], test_X[:, 2], pred_y, color = \"green\")\nax.legend(['actual', 'predicting'])\n\nplt.show()\n\nfig = plt.figure(figsize = (10, 7)) \nax = plt.axes(projection =\"3d\") \nax.scatter3D(test_X[:, 2], test_X[:, 1], test_y, color = \"b\")\nplt.title(\"text_reivews_count and num_pages vs average_rating\")\nax.set_xlabel(\"text_reviews_count\")\nax.set_ylabel(\"num_pages\")\nax.set_zlabel(\"average_rating\")\nax.scatter3D(test_X[:, 2], test_X[:, 1], pred_y, color = \"green\")\nax.legend(['actual', 'predicting'])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Linear regression with features num_pages, text_reviews_count and ratings_count leaves a high variance unexplained, indicated by a low R2-score.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> # 5. Ridge Regression<a id=\"5\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In ridge regression, penalty on the size of the coefficients is present in order to counterbalance collinearity.\nSee https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression-and-classification for reference.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ran = range(-100000000000000, -999999900000) # range of alpha\nran = ran[0::10000000000] # Reduce runtime and memory.\nalphas = np.logspace(-10, -2, len(ran))\ncoefs = []\nr2s = []\nmses = []\n\nfor a in ran:\n    ridge = linear_model.Ridge(alpha=a, fit_intercept=False)\n    ridge.fit(train_X, train_y)\n    pred_y = reg.predict(test_X)\n    \n    coefs.append(ridge.coef_[0])\n    mses.append(mean_squared_error(test_y, pred_y))\n    \nax = plt.gca()\nax.plot(alphas, coefs)\nax.set_xscale('log')\nax.set_xlim(ax.get_xlim()[::-1])\nplt.xlabel('alpha')\nplt.ylabel('weights')\nplt.title('Ridge coefficients as a function of the regularization')\nplt.legend(['ratings_count', 'num_pages', 'text_reviews_count'])\nplt.axis('tight')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The balance point between a presumably high collinearity and an over-dominating regularization is 10^-5.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The mean squared error and r2 do not change, however.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean Squared Error:')\nprint(mean_squared_error(test_y, pred_y))\n\nprint('r2 score:')\nprint(r2_score(test_y, pred_y))\n\nprint('Sum of Squared Errors:')\nprint(np.sum(np.square(pred_y - test_y)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # 6. Lasso<a id='6'><a/>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Objective function:\n\n$min_w\\frac{1}{2n}\\rVert Xw-y\\rVert^2+\\alpha\\rVert w\\rVert$","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is to avoid division by zero while doing np.log10\nEPSILON = 1e-9","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # 6.1. Normalizing the data<a id='7'></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X /= np.sqrt(np.sum(X ** 2, axis=0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # 6.2. LassoLarsIC: least angle regression with BIC/AIC criterion<a id='8'></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_bic = LassoLarsIC(criterion='bic')\nt1 = time.time()\nreg_bic.fit(X, y)\nt_bic = time.time() - t1\nalpha_bic_ = reg_bic.alpha_\n\nreg_aic = LassoLarsIC(criterion='aic')\nreg_aic.fit(X, y)\nalpha_aic_ = reg_aic.alpha_\n\ndef plot_ic_criterion(reg, name, color):\n    criterion_ = reg.criterion_\n    plt.semilogx(reg.alphas_ + EPSILON, criterion_, '--', color=color,\n                 linewidth=3, label='%s criterion' % name)\n    plt.axvline(reg.alpha_ + EPSILON, color=color, linewidth=3,\n                label='alpha: %s estimate' % name)\n    plt.xlabel(r'$\\alpha$')\n    plt.ylabel('criterion')\n\n\nplt.figure()\nplot_ic_criterion(reg_aic, 'AIC', 'b')\nplot_ic_criterion(reg_bic, 'BIC', 'r')\nplt.legend()\nplt.title('Information-criterion for model selection (training time %.3fs)'\n          % t_bic)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # 6.3. LassoCV: coordinate descent<a id='9'></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute paths\nprint(\"Computing regularization path using the coordinate descent lasso...\")\nt1 = time.time()\nreg = LassoCV(cv=20).fit(X, y) # 20-fold cross-validation\nt_lasso_cv = time.time() - t1\n\n# Display results\nplt.figure()\nymin, ymax = 0.05, 0.175\nplt.semilogx(reg.alphas_ + EPSILON, reg.mse_path_, ':')\nplt.plot(reg.alphas_ + EPSILON, reg.mse_path_.mean(axis=-1), 'k',\n         label='Average across the folds', linewidth=2)\nplt.axvline(reg.alpha_ + EPSILON, linestyle='--', color='k',\n            label='alpha: CV estimate')\n\nplt.legend()\n\nplt.xlabel(r'$\\alpha$')\nplt.ylabel('Mean square error')\nplt.title('Mean square error on each fold: coordinate descent '\n          '(train time: %.2fs)' % t_lasso_cv)\nplt.axis('tight')\nplt.ylim(ymin, ymax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # 6.4. LassoLarsCV: least angle regression <a id='10'></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute paths\nprint(\"Computing regularization path using the Lars lasso...\")\nt1 = time.time()\nreg = LassoLarsCV(cv=20).fit(X, y)\nt_lasso_lars_cv = time.time() - t1\n\n# Display results\nplt.figure()\nplt.semilogx(reg.cv_alphas_ + EPSILON, reg.mse_path_, ':')\nplt.semilogx(reg.cv_alphas_ + EPSILON, reg.mse_path_.mean(axis=-1), 'k',\n             label='Average across the folds', linewidth=2)\nplt.axvline(reg.alpha_, linestyle='--', color='k',\n            label='alpha CV')\nplt.legend()\n\nplt.xlabel(r'$\\alpha$')\nplt.ylabel('Mean square error')\nplt.title('Mean square error on each fold: Lars (train time: %.2fs)'\n          % t_lasso_lars_cv)\nplt.axis('tight')\nplt.ylim(ymin, ymax)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> # 7. Elastic-Net<a id='11'></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Objective function:\n\n$min_w\\frac{1}{2n}\\rVert Xw-y\\rVert^2+\\alpha\\rho\\rVert w\\rVert+\\frac{\\alpha(1-\\rho)}{2}\\rVert w\\rVert^2$","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = books.loc[0:, ['ratings_count', 'num_pages', 'text_reviews_count']].values.astype(float)\ny = books.average_rating.values.astype(float)\n\ndef plot_path(X):\n    X /= X.std(axis=0)  # Standardize data (easier to set the l1_ratio parameter)\n\n    # Compute paths\n\n    eps = 5e-9  # the smaller it is the longer is the path\n\n    print(\"Computing regularization path using the lasso...\")\n    alphas_lasso, coefs_lasso, _ = lasso_path(X, y, eps=eps, fit_intercept=False)\n\n    print(\"Computing regularization path using the positive lasso...\")\n    alphas_positive_lasso, coefs_positive_lasso, _ = lasso_path(\n        X, y, eps=eps, positive=True, fit_intercept=False)\n    print(\"Computing regularization path using the elastic net...\")\n    alphas_enet, coefs_enet, _ = enet_path(\n        X, y, eps=eps, l1_ratio=0.8, fit_intercept=False)\n\n    print(\"Computing regularization path using the positive elastic net...\")\n    alphas_positive_enet, coefs_positive_enet, _ = enet_path(\n        X, y, eps=eps, l1_ratio=0.8, positive=True, fit_intercept=False)\n\n    # Display results\n\n    colors = cycle(['b', 'r', 'g'])\n    plt.figure(1)\n    neg_log_alphas_lasso = -np.log10(alphas_lasso)\n    neg_log_alphas_enet = -np.log10(alphas_enet)\n    for coef_l, coef_e, c in zip(coefs_lasso, coefs_enet, colors):\n        l1 = plt.plot(neg_log_alphas_lasso, coef_l, c=c)\n        l2 = plt.plot(neg_log_alphas_enet, coef_e, linestyle='--', c=c)\n\n    plt.xlabel('-Log(alpha)')\n    plt.ylabel('coefficients')\n    plt.title('Lasso and Elastic-Net Paths')\n    plt.legend((l1[-1], l2[-1]), ('Lasso', 'Elastic-Net'), loc='upper right')\n    plt.axis('tight')\n\n\n    plt.figure(2)\n    neg_log_alphas_positive_lasso = -np.log10(alphas_positive_lasso)\n    for coef_l, coef_pl, c in zip(coefs_lasso, coefs_positive_lasso, colors):\n        l1 = plt.plot(neg_log_alphas_lasso, coef_l, c=c)\n        l2 = plt.plot(neg_log_alphas_positive_lasso, coef_pl, linestyle='--', c=c)\n\n    plt.xlabel('-Log(alpha)')\n    plt.ylabel('coefficients')\n    plt.title('Lasso and positive Lasso')\n    plt.legend((l1[-1], l2[-1]), ('Lasso', 'positive Lasso'), loc='upper right')\n    plt.axis('tight')\n\n\n    plt.figure(3)\n    neg_log_alphas_positive_enet = -np.log10(alphas_positive_enet)\n    for (coef_e, coef_pe, c) in zip(coefs_enet, coefs_positive_enet, colors):\n        l1 = plt.plot(neg_log_alphas_enet, coef_e, c=c)\n        l2 = plt.plot(neg_log_alphas_positive_enet, coef_pe, linestyle='--', c=c)\n\n    plt.xlabel('-Log(alpha)')\n    plt.ylabel('coefficients')\n    plt.title('Elastic-Net and positive Elastic-Net')\n    plt.legend((l1[-1], l2[-1]), ('Elastic-Net', 'positive Elastic-Net'),\n               loc='upper right')\n    plt.axis('tight')\n    plt.show()\n    \nplot_path(X)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}