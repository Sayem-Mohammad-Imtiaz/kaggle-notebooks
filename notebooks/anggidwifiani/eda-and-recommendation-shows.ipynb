{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Netflix is so popular recently. It is a tv and a movie shows that can watch from streaming in tv, mobile phone, and tablet. Users also can watch as much as they like if using subscription. Its show also can be downloaded.\n# Netflix is so interesting to explore, I decided to analysis from Netflix data and to futher analysis please check up my site http://auroradata.id/. In this site, I explained the visualization so you can catch more information."},{"metadata":{},"cell_type":"markdown","source":"# Data Description"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import librries that needed.\n\nimport numpy as np\nimport pandas as pd\nimport warnings\nwarnings.simplefilter(\"ignore\")\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objects as go\ninit_notebook_mode(connected=True)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n!pip install rake-nltk\nfrom rake_nltk import Rake\nfrom sklearn.feature_extraction.text import CountVectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Open the Netflix data \n\ndata = pd.read_csv('/kaggle/input/netflix-shows/netflix_titles.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Cleansing for Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check missing values\n\npd.isnull(data).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check number of rows and columns \n\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check type of columns\n\ndata.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I think delete missing value in date_added dan rating is ok because the data is so small.\n\ndata.dropna(subset=['date_added', 'rating'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop columns that unnecessary for the exploration.\n\ndata = data.drop(['date_added', 'show_id'], axis = 1)\ndata.drop_duplicates(subset=['title'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill missing values in country column, split countries, and make dataframe that only neccessary for the plot.\n\ndata['country'] = data['country'].fillna('Unknown')\ndata['country'] = data.country.str.replace(\", | ,\", \",\")\ndata['listed_in'] = data.listed_in.str.replace(\", | ,\", \",\")\ncountry_data = pd.DataFrame(data.country.str.split(',').tolist(), index=data.type).stack()\ncountry_data = country_data.reset_index([0, 'type'])\ncountry_data.columns = ['types', 'country']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot country column. \n\ndata_countries = country_data['country'].replace(\"US\", \"United States\").value_counts()\n\niplot([go.Choropleth(\n    locationmode='country names',\n    locations=data_countries.index.values,\n    text=data_countries.index,\n    z=data_countries.values\n)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plot types distribution for Netflix shows.\n\nplt.figure(figsize =(10,5))\nsns.set(style=\"dark\")\nsns.countplot(x=\"type\", data=data, palette='twilight')\nplt.title('Netflix Shows Types Distribution', size = 15, color='darkblue')\nplt.xlabel('Types', color='darkblue')\nplt.ylabel('Count', color='darkblue')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make genres counter for Netflix shows.\n\nfrom collections import Counter\n\ngenre = list(data['listed_in'])\n\ngenres = []\n\nfor i in genre:\n    i = list(i.split(\",\"))\n    for j in i:\n        genres.append(j.replace(\" \", \"\"))\n\ngen = Counter(genres)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot genres.\n\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\ngenre_in = list(set(gen))\nplt.rcParams['figure.figsize'] = (15,15)\nwordcloud = WordCloud(max_font_size = 50, max_words = 100, background_color = 'white').generate(str(genre_in))\n\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis('off')\nplt.title('Netflix Shows Genres Distribution', size = 23, color = 'darkblue')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make list of minues in duration.\n\nseason = data[['duration']].apply(lambda x: x.str.contains('Season|Seasons', regex=True)).any(axis=1)\ntime = data[~season]\ntime.index = np.arange(len(time))\ntimes = []\nfor i in time.duration:\n    if i[2] =='m':\n        times.append(int(i[:2]))\n    else:\n        times.append(int(i[:3]))\ntime['duration_'] = times","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show minutes.\n\nplt.figure(figsize =(10,5))\nsns.distplot(time.duration_, kde=False, color = 'blue')\nplt.title('Netflix Shows Duration by Minutes', size = 15, color='darkblue')\nplt.xlabel('Minutes', color='darkblue')\nplt.ylabel('Count', color='darkblue')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make list of seasons in duration.\n\nseasons = data[season]\nseasons.index = np.arange(len(seasons))\nseasons['value'] = seasons.duration.str[:2]\nlists = list(seasons['value'])\nfor i in range (len(lists)):\n    lists[i] = int(lists[i])\nseasons['value'] = lists","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show seasons.\n\nplt.figure(figsize =(10,5))\nsns.countplot(seasons.value)\nplt.title('Netflix Shows Duration by Seasons', size = 15, color='darkblue')\nplt.xlabel('Season', color='darkblue')\nplt.ylabel('Count', color='darkblue')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show rating types distribution.\n\nplt.figure(figsize =(10,5))\nsns.lineplot(x = data.rating.value_counts().index,y = data.rating.value_counts().values)\nplt.title('Rating-types Netflix Shows Distribution', size = 15, color='darkblue')\nplt.ylabel('Count', color='darkblue')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Prediction"},{"metadata":{},"cell_type":"markdown","source":"We use certain columns (title,director, cast, listed in, and description) to make recommended system. Before we put in recommended system, we should clean that up and vectorize the words."},{"metadata":{},"cell_type":"markdown","source":"Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clean unnecessary spaces.\n\nclean_space = []\n\ncols = ['title', 'director', 'cast', 'listed_in','description']\n\nfor i, cols in data.iterrows():\n    if type(cols) == str:\n        if cols.isspace():\n            clean_space.append(i)\n\ndata.drop(clean_space, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change types of certain columns soo we can combine them to vectorize.\n\ndata['director'] = data['director'].astype(str)\ndata['cast'] = data['cast'].astype(str)\ndata['listed_in'] = data['listed_in'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make list of keywords in description column.\n\ndata['desc'] = ''\nfor index, row in data.iterrows():\n    descrip = row['description']\n    r = Rake()\n    r.extract_keywords_from_text(descrip)\n    key_descrip = r.get_word_degrees()\n    row['desc'] = list(key_descrip.keys())\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split word to get more precissely data.\n\ndata['cast'] = data['cast'].map(lambda x: x.split(','))\ndata['listed_in'] = data['listed_in'].map(lambda x: x.split(','))\ndata['director'] = data['director'].map(lambda x: x.split(','))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split director and cast columns so if we combine them, we can't conclude same word in cast and director is same person.\n\nfor index, row in data.iterrows():\n    row['cast'] = [x.lower().replace(' ','') for x in row['cast']]\n    row['director'] = ''.join(row['director']).lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine words to vectorize. This is important because we can have more accurate if we including more words and can being a label.\n\ndata['combined'] = data['director'].astype(str) + ' ' + data['cast'].astype(str) + ' ' + data['listed_in'].astype(str) + ' ' + data['description'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split title from another columns so we can pair titles and labels.\n\ndata.set_index('title', inplace = True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make vector of the label.\n\ncount = CountVectorizer()\ncount_matrix = count.fit_transform(data['combined'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generating the cosine similarity matrix of the label.\nfrom sklearn.metrics.pairwise import cosine_similarity\ncosine_sim = cosine_similarity(count_matrix, count_matrix)\ncosine_sim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make pairwise for the series array above.\n\nindicates = pd.Series(data.index)\nindicates[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Most important step. This is recommendation system.\n\ndef recommendation (Title, cosine_sim = cosine_sim):\n    recommendation_title = []\n    #Calling title for the matching\n    title = indicates[indicates == Title].index[0]\n    #Matching title and the combine values of cosine similarity\n    match = pd.Series(cosine_sim[title]).sort_values(ascending = False)\n    #Select only 10 best matching for the choosing film\n    top_10_film = list(match.iloc[1:11].index)\n    for i in top_10_film:\n        recommendation_title.append(list(data.index)[i])\n    return recommendation_title","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check the functionality of recommendation system.\n\nrecommendation('Transformers: Robots in Disguise')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hope, this is usefull! :)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}