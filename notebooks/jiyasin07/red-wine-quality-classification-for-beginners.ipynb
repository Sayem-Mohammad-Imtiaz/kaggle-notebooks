{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook highlights Red Wine quality classification problem using Decision Tree, Logistic Regression, Random Forest classifier and SVM. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV \nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Loading dataset\ndf = pd.read_csv('../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data visualization \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(15,10))\nsns.heatmap(df.corr(),annot=True,linewidth = 1, cmap=\"rocket_r\")\nplt.title(\"Heatmap Correlation of the Dataset\", fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making binary classificaion for the response variable.\n#Dividing wine as good and bad by giving the limit for the quality\nbins = (2, 6.5, 8)\nlabels = ['bad', 'good']\ndf['quality'] = pd.cut(x = df['quality'], bins = bins, labels = labels)\ndf['quality'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Assigning 0 to bad and 1 to good quality\nle = LabelEncoder()\ndf['quality'] = le.fit_transform(df['quality'])\ndf['quality'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting and scaling the data\nX = df.drop('quality', axis = 1)\nsc = StandardScaler()\nX = sc.fit(X).transform(X)\n\ny = df['quality']\n\n#Train and Test splitting \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression(C=0.8, solver='liblinear', fit_intercept=True, penalty = 'l1')\nlr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_lr = cross_val_score(estimator = lr, X = X_train, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_lr.mean())\n\ny_pred_lr_train = lr.predict(X_train)\naccuracy_lr_train = accuracy_score(y_train, y_pred_lr_train)\nprint(\"Training set: \", accuracy_lr_train)\n\ny_pred_lr_test = lr.predict(X_test)\naccuracy_lr_test = accuracy_score(y_test, y_pred_lr_test)\nprint(\"Test set: \", accuracy_lr_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, y_pred_lr_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"dec_tree_classifier = DecisionTreeClassifier(\n    criterion = 'gini', \n    max_features=8,\n    random_state = 33)\ndec_tree_classifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting Cross Validation Score\ncv_dt = cross_val_score(estimator = dec_tree_classifier, X = X_train, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_dt.mean())\n\ny_pred_dt_train = dec_tree_classifier.predict(X_train)\naccuracy_dt_train = accuracy_score(y_train, y_pred_dt_train)\nprint(\"Training set: \", accuracy_dt_train)\n\ny_pred_dt_test = dec_tree_classifier.predict(X_test)\naccuracy_dt_test = accuracy_score(y_test, y_pred_dt_test)\nprint(\"Test set: \", accuracy_dt_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, y_pred_dt_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfc = RandomForestClassifier(\n    criterion = 'entropy', \n    max_features = 6, \n    n_estimators = 600, \n    random_state=33)\nrfc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting Cross Validation Score\ncv_rf = cross_val_score(estimator = rfc, X = X_train, y = y_train, cv = 10)\nprint(\"CV: \", cv_rf.mean())\n\ny_pred_rf_train = rfc.predict(X_train)\naccuracy_rf_train = accuracy_score(y_train, y_pred_rf_train)\nprint(\"Training set: \", accuracy_rf_train)\n\ny_pred_rf_test = rfc.predict(X_test)\naccuracy_rf_test = accuracy_score(y_test, y_pred_rf_test)\nprint(\"Test set: \", accuracy_rf_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, y_pred_rf_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = svm.SVC(kernel = 'rbf',gamma = 'scale').fit(X_train, y_train) \nsvc.fit(X_train, y_train)\ny_pred_svc_test = svc.predict(X_test)\nprint(classification_report(y_test, y_pred_svc_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting Cross Validation Score\ncv_svc = cross_val_score(estimator = svc, X = X_train, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_dt.mean())\n\ny_pred_svc_train = svc.predict(X_train)\naccuracy_svc_train = accuracy_score(y_train, y_pred_svc_train)\nprint(\"Training set: \", accuracy_svc_train)\n\ny_pred_svc_test = svc.predict(X_test)\naccuracy_svc_test = accuracy_score(y_test, y_pred_svc_test)\nprint(\"Test set: \", accuracy_svc_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, y_pred_svc_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using **Grid search** to improve performance of SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding best parameters for our SVC model\nparams = {\n    'C':[0.01,0.1,0.3,0.8,0.9,1,1.2,1.3,1.4,1.5,10],\n    'kernel':['linear', 'rbf', 'sigmoid'],\n    'gamma':[0.01,0.1,0.3,0.8,0.9,1,1.2,1.3,1.4,1.5,10]\n}\ngrid_svc = GridSearchCV(svc, param_grid = params, scoring = 'accuracy', cv = 10)\ngrid_svc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_svc.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_grid= svm.SVC(C=1.2,kernel = 'rbf',gamma = 0.9).fit(X_train, y_train) \nsvc_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting Cross Validation Score\ncv_svc_grid = cross_val_score(estimator = svc_grid, X = X_train, y = y_train.ravel(), cv = 10)\nprint(\"CV: \", cv_svc.mean())\n\ny_pred_svc_grid_train = svc_grid.predict(X_train)\naccuracy_svc_train = accuracy_score(y_train, y_pred_svc_grid_train)\nprint(\"Training set: \", accuracy_svc_train)\n\ny_pred_svc_grid_test = svc_grid.predict(X_test)\naccuracy_svc_test = accuracy_score(y_test, y_pred_svc_grid_test)\nprint(\"Test set: \", accuracy_svc_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test, y_pred_svc_grid_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy of **SVM** increased from *87.5%* to *89.68%* by using **Grid Search**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}