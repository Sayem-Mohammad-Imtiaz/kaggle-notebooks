{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfake = pd.read_csv(\"../input/fake-and-real-news-dataset/Fake.csv\")\nreal = pd.read_csv(\"../input/fake-and-real-news-dataset/True.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake.drop(['date', 'subject'], axis=1, inplace=True)\nreal.drop(['date', 'subject'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake['class'] = 0 \nreal['class'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news_df = pd.concat([fake, real], ignore_index=True, sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"news_df['text'] = news_df['title'] + news_df['text']\nnews_df.drop('title', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = news_df['text']\ntargets = news_df['class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.20, random_state=18)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(data):\n    normalized = []\n    for i in data:\n        i = i.lower()\n        # get rid of urls\n        i = re.sub('https?://\\S+|www\\.\\S+', '', i)\n        # get rid of non words and extra spaces\n        i = re.sub('\\\\W', ' ', i)\n        i = re.sub('\\n', '', i)\n        i = re.sub(' +', ' ', i)\n        i = re.sub('^ ', '', i)\n        i = re.sub(' $', '', i)\n        normalized.append(i)\n    return normalized\n\nX_train = normalize(X_train)\nX_test = normalize(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_vocab = 10000\ntokenizer = Tokenizer(num_words=max_vocab)\ntokenizer.fit_on_texts(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tokenize the text into vectors \nX_train = tokenizer.texts_to_sequences(X_train)\nX_test = tokenizer.texts_to_sequences(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, padding='post', maxlen=256)\nX_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, padding='post', maxlen=256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(max_vocab, 32),\n    \n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n    \n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n    \n    tf.keras.layers.Dense(64, activation='relu'),\n    \n    tf.keras.layers.Dropout(0.5),\n    \n    tf.keras.layers.Dense(1)\n])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              optimizer=tf.keras.optimizers.Adam(1e-4),\n              metrics=['accuracy'])\n\nhistory = model.fit(X_train, y_train, epochs=10,validation_split=0.1, batch_size=30, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_dict = history.history\n\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\nloss = history_dict['loss']\nval_loss = history_dict['val_loss']\nepochs = history.epoch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(X_test)\n\nbinary_predictions = []\n\nfor i in pred:\n    if i >= 0.5:\n        binary_predictions.append(1)\n    else:\n        binary_predictions.append(0) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy on testing set:', accuracy_score(binary_predictions, y_test))\nprint('Precision on testing set:', precision_score(binary_predictions, y_test))\nprint('Recall on testing set:', recall_score(binary_predictions, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"http://projector.tensorflow.org/"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}