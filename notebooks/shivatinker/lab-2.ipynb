{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Метод $k$ ближайших соседей (kNN)\n\nВ этой части работы вы:\n- научитесь готовить данные к построению модели (предобработка, или препроцессинг данных);\n- познакомитесь с методами ближайших соседей для задач классификации, реализованными в библиотеке scikit-learn ;\n- научитесь оценивать качество модели с помощью отложенной выборки."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/churn-in-telecoms-dataset/bigml_59c28831336c6604c800002a.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Нам нужно научиться предсказывать, будет ли клиент уходить из компании или нет (target - churn). Задача категориальная, нам надо предсказать к какой группе отноится пользователь"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sns.countplot(df['churn'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Большая часть пользователей - лояльные пользователи, следовательно распределение далеко от нормального"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df['state'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Обработать данные штатов будет очень сложно, так как их больше 50, и они категориальные. Поэтому дропнем их.\nАналогично дропнем номера телефонов, вряд ли они несут полезную инфу"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['state', 'phone number'], axis='columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df[\"area code\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Имеем всего три значения area code. Преобразуем их в нормальный вид(0, 1, 2). Аналогично преобразуем в числа булевые столбцы"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['area code'] = df['area code'].map({408: 0, 415: 1, 510: 2})\ndf['voice mail plan'] = df['voice mail plan'].map( {\"no\": 0,\"yes\": 1} )\ndf['international plan'] = df['international plan'].map( {\"no\": 0,\"yes\": 1} )\ndf['churn'] = df['churn'].map( {False: 0, True: 1 })\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Займемся разделением данных от таргета"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX = scaler.fit_transform(df.drop('churn', axis='columns'))\nY = df['churn']\nX_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size = 0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Попробуем натренировать дефолтный KNeighborsClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"kc = KNeighborsClassifier(n_neighbors=1)\nkc.fit(X_train, y_train)\nY_res = kc.predict(X_valid)\nY_res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(y_valid, Y_res)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Вполне неплохо для элементарного алгоритма. Точность 85%. Однако даже давая на все вопросы False, наша модель имела бы приблизительно такой же результат. Давайте проверим модель кросс-валидацией"},{"metadata":{"trusted":true},"cell_type":"code","source":"fold = KFold(n_splits=5, shuffle=True, random_state=42)\nscores = cross_val_score(kc, X, Y,scoring='accuracy', cv=fold)\nprint(scores, scores.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Поэкспериментируем с количеством соседей:"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid = GridSearchCV(kc, {'n_neighbors': np.arange(1, 15)}, scoring='accuracy', cv=fold)\ngrid.fit(X_train, y_train)\nprint(grid.best_params_)\nprint(grid.best_score_)\ngrid_res = pd.DataFrame(grid.cv_results_)\ngrid_res.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как видим, классификатор с гиперпараметром {5 соседей} показал себя лучше всех"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_res.plot(x='param_n_neighbors', y='mean_test_score')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Поэкспериментируем с различными метриками:\n\nК слову, метрика f1, согласно с [этим](https://scikit-learn.org/stable/modules/model_evaluation.html), подходит нам гораздо больше. Посмотрим на результат:"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = cross_val_score(kc, X, Y, scoring='f1', cv=fold)\nprint(scores, scores.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Окей, кажется наша модель выглядит немного туповато на данной метрике, проверим другие:"},{"metadata":{"trusted":true},"cell_type":"code","source":"kc_w = KNeighborsClassifier(n_neighbors=5, weights = 'distance')\nkc_w.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kc_w_grid = GridSearchCV(kc_w, {\"p\": np.linspace(1,10, 20)}, scoring=\"accuracy\", cv = fold)\nkc_w_grid.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(kc_w_grid.best_params_)\nprint(kc_w_grid.best_score_)\ngrid_res = pd.DataFrame(kc_w_grid.cv_results_)\ngrid_res.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_res.plot(x='param_p', y='mean_test_score')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Проверим, как RadiusNeighborsClassifier в плане наших данных:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import RadiusNeighborsClassifier\n\ncf_rad = RadiusNeighborsClassifier(radius=10)\ncf_rad.fit(X_train, y_train)\n\nscores = cross_val_score(cf_rad, X, Y, scoring='accuracy', cv=fold)\nprint(scores, scores.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Не сильно лучше, а учитывая что данная метрика для нашей задачи не очень подходит, то и результатов мы особых не получили)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}