{"cells":[{"metadata":{},"cell_type":"markdown","source":"#Rolling blackouts, rampant unemployment, and unaffordable bread\n\nSince October 2019, the economy had already been in crisis due to rampant government corruption and excessive borrowing, forcing businesses to close and people to lose their jobs.\n\nThe coronavirus pandemic made everything worse. Lebanon is dependent on its imports, and the global production slowdown due to the coronavirus made goods more expensive, making everyday necessities — like bread — too expensive for many citizens to afford.\n\nBusinesses closed for months during the lockdown, and the cost of food skyrocketed — with the price of subsidized bread rising 33 per cent between October and late June, according to Reuters.\n\nResulting job cuts have also been sweeping and ruthless. Unemployment is currently at 33 per cent, 45 per cent of Lebanese people live below the poverty line, as Business Insider reported last month.\n\nRolling blackouts, lasting as many as 22 hours at a time, are also common, due to shortages of the oil and diesel needed to power the grid.\n\nLebanon's politicians have also been slammed for dragging their feet over securing a much-needed rescue package from the IMF. https://www.businessinsider.com/beirut-explosion-lebanon-buckling-economic-crisis-outages-coronavirus-2020-8","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRB8MK_rfhMzrJEUDBR3yZMI9Tq-o4WAFuc9A&usqp=CAU)paxforpeace.nl","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns #visualization\nimport matplotlib.pyplot as plt #visualization\n\n%config InlineBackend.figure_format = 'retina'\n\n# to display all columns and rows:\npd.set_option('display.max_columns', None); pd.set_option('display.max_rows', None);  # to display all columns and rows\npd.set_option('display.float_format', lambda x: '%.2f' % x) # The number of numbers that will be shown after the comma.\n\n\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Hospitals buckling under the weight of COVID-19 and the blast\n\nThe health sector, now given the added task of caring for those injured in the blast, had already been struggling with coronavirus amid the economic crisis.\n\nThere is a dire shortage of personal protective equipment (PPE) and the ventilators desperately needed to keep those most ill with the coronavirus alive.\n\nThere are 600 ventilators in the country, but 2,800 are needed to cope with surge capacity, Jad Berro, a ventilator manufacturer in the country, told Arab News earlier this year.\n\nDaily case data shows that the coronavirus is still on the rise in Lebanon.\n\nTuesday's explosion has been devastating for Beirut's hospitals: many were so badly damaged that they cannot admit any more patients. https://www.businessinsider.com/beirut-explosion-lebanon-buckling-economic-crisis-outages-coronavirus-2020-8","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = pd.read_csv('../input/hackathon/task_2-owid_covid_data-21_June_2020.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Lebanon was already in financial crisis before the explosion in Beirut — and now experts are predicting devastating consequences\n![](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcTe83TPb9XD0AnjZTS3aEuXr278cdBPFshWGQ&usqp=CAU)foxssports640.com\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#Beirut Explosion – EPSU Message of Solidarity and Sympathy to workers and people of Lebanon\n\n(Brussels, 5 August 2020)  The explosion that ravaged the Port and City of Beirut and took the lives of more than hundred people and injured many thousands shocked the world, 4 August 2020. EPSU has expressed its solidarity and sympathy to the unions and working people of Beirut and Lebanon.  They salute the work of the first responders, emergency workers and so many others who seek to save lives and provide safety and basic needs in these very difficult moment. Firefighters, ambulance drivers, medical staff, police and other public service workers are working to keep things going in a city and country so hard hit.\n\nThe country is currently experiencing the impact of COVID19 cases that already stretched its health system. Austerity measures have left many public services crippled with the provision of water and electricity being interrupted. Unions and many others have protested the corruption and failing government with huge protests last year. Economic problems have increased poverty and raised unemployment. And while still recovering from over a decade of civil war, the country has received over 1.5 million refugees that fled the conflicts in Syria. Lebanon relies on the Port of Beirut for many of its imports and especially foods. This new shock sets the country back further.\n\nEPSU has sent a letter of condolences and sympathy to the PSI affiliated trade unions in Lebanon. They include the union of workers in the Port of Beirut.\n\n![](https://epsu.org/sites/default/files/styles/article_banner/public/article/image/Lebanon%20explosion%204%20Aug%202020.jpg?itok=hdyNx82y) https://epsu.org/article/beirut-explosion-epsu-message-solidarity-and-sympathy-workers-and-people-lebanon","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#Codes from yücel ulug  https://www.kaggle.com/ycelulu/churn-prediction-models-yu","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#Data overview","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking dataset\n\nprint (\"Rows     : \" ,df.shape[0])\nprint (\"Columns  : \" ,df.shape[1])\nprint (\"\\nFeatures : \\n\" ,df.columns.tolist())\nprint (\"\\nMissing values :  \", df.isnull().sum().values.sum())\nprint (\"\\nUnique values :  \\n\",df.nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe().T","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"df[\"total_cases\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Separating churn and non churn customers\n#total_cases     = df[df[\"total_cases\"] == 1]\n#not_total-cases = df[df[\"total_cases\"] == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lebanon = df[(df['location']=='Lebanon')].reset_index(drop=True)\nlebanon.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axarr = plt.subplots(2, 3, figsize=(18, 6))\nsns.countplot(x = 'total_deaths', hue = 'total_cases',data = lebanon, ax = axarr[0][0])\nsns.countplot(x = 'total_cases_per_million', hue = 'total_cases',data = lebanon, ax = axarr[0][1])\nsns.countplot(x = 'total_deaths_per_million', hue = 'total_cases',data = lebanon, ax = axarr[0][2])\nsns.countplot(x = 'new_cases', hue = 'total_cases',data = lebanon, ax = axarr[1][0])\nsns.countplot(x = 'new_deaths', hue = 'total_cases',data = lebanon, ax = axarr[1][1])\nsns.countplot(x = 'hospital_beds_per_thousand', hue = 'total_cases',data = lebanon, ax = axarr[1][2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#_, ax = plt.subplots(1, 3, figsize=(18, 6))\n#plt.subplots_adjust(wspace=0.3)\n#sns.swarmplot(x = \"total_deaths\", y = \"aged_65_older\", hue=\"total_cases\", data = lebanon, ax= ax[0])\n#sns.swarmplot(x = \"total_cases_per_million\", y = \"aged_65_older\", data = lebanon, hue=\"total_cases\", ax = ax[1])\n#sns.swarmplot(x = \"new_cases\", y = \"aged_65_older\", hue=\"total_cases\", data = lebanon, ax = ax[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# categorical features\ncategorical_feat = [feature for feature in lebanon.columns if lebanon[feature].dtypes=='O']\nprint('Total categorical features: ', len(categorical_feat))\nprint('\\n',categorical_feat)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Label Encoding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\nlebanon[\"iso_code\"] = encoder.fit_transform(lebanon[\"iso_code\"].fillna('Nan'))\nlebanon[\"continent\"] = encoder.fit_transform(lebanon[\"continent\"].fillna('Nan'))\nlebanon[\"location\"] = encoder.fit_transform(lebanon[\"location\"].fillna('Nan'))\nlebanon[\"date\"] = encoder.fit_transform(lebanon[\"date\"].fillna('Nan'))\nlebanon[\"tests_units\"] = encoder.fit_transform(lebanon[\"tests_units\"].fillna('Nan'))\nlebanon.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"facet = sns.FacetGrid(lebanon, hue = \"population\", aspect = 3)\nfacet.map(sns.kdeplot, \"total_cases\", shade = True, color = \"purple\")\nfacet.set(xlim = (0, lebanon[\"total_cases\"].max()))\nfacet.add_legend()\n\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_cases = np.random.normal(size=100)\nsns.distplot(total_cases, color = \"purple\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\n\ntotal_cases = np.random.normal(0, 1, size=30)\nbandwidth = 1.06 * total_cases.std() * x.size ** (-1 / 5.)\nsupport = np.linspace(-4, 4, 200)\n\nkernels = []\nfor total_cases_i in total_cases:\n\n    kernel = stats.norm(total_cases_i, bandwidth).pdf(support)\n    kernels.append(kernel)\n    plt.plot(support, kernel, color= \"purple\")\n\nsns.rugplot(x, color=\".2\", linewidth=3);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, ax =  plt.subplots(1, 2, figsize = (15, 7))\ncmap = sns.cubehelix_palette(light = 1, as_cmap = True)\nsns.scatterplot(x = \"date\", y = \"total_deaths\", hue = \"total_cases\", cmap = cmap, sizes = (10, 200), data = lebanon, ax = ax[0])\nsns.scatterplot(x = \"date\", y = \"new_cases\", hue = \"total_cases\", cmap = cmap, sizes = (10, 200), data = lebanon, ax = ax[1]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10, 10))\nsns.swarmplot(x = \"new_cases\", y = \"aged_65_older\", data = lebanon, color = \"purple\", hue = \"total_cases\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(total_cases)\nsns.kdeplot(total_cases, bw=.2, label=\"bw: 0.2\")\nsns.kdeplot(total_cases, bw=2, label=\"bw: 2\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = lebanon.corr()\ncorr.style.background_gradient(cmap = 'coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df1 = pd.read_csv('../input/hackathon/task_2-BCG_world_atlas_data-bcg_strain-7July2020.csv', encoding='utf8')\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# categorical features with missing values\ncategorical_nan = [feature for feature in df1.columns if df1[feature].isna().sum()>1 and df1[feature].dtypes=='O']\nprint(categorical_nan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat=df1.select_dtypes(\"object\")\nfor column in cat:\n    df1[column].fillna(df1[column].mode()[0], inplace=True)\n    #dataset[column].fillna(\"NA\", inplace=True)\n\n\n#fl=df.select_dtypes([\"float64\",\"int64\"]).drop(\"bcg_strain_original\",axis=1)\n#for column in fl:\n #   df[column].fillna(df[column].median(), inplace=True)\n    #dataset[column].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"df1.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#No Missing Values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"LBN = df1[(df1['country_name']=='Lebanon')].reset_index(drop=True)\nLBN.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Converting to string values . My 1st Elif.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# NumOfProducts variable is converted to string values.\nis_bcg_mandatory_for_all_children = []\nfor i in df1['is_bcg_mandatory_for_all_children']:\n    if i == 'yes\\t\\t\\t\\t\\t\\t\\t\\t':\n        is_bcg_mandatory_for_all_children.append('A')\n    elif i == 'yes':\n        is_bcg_mandatory_for_all_children.append('B')\n    elif i == 'no':\n        is_bcg_mandatory_for_all_children.append('C')\n    else:\n        is_bcg_mandatory_for_all_children.append('D')\n        \ndf1['is_bcg_mandatory_for_all_children'] = is_bcg_mandatory_for_all_children\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummies = pd.get_dummies(df1[['country_name', 'country_code', 'bcg_policy_first_year_original', 'bcg_policy_last_year_original', 'is_bcg_mandatory_for_all_children', 'vaccination_timing', 'bcg_strain_original', 'were_revaccinations_recommended', 'timing_of_revaccination', 'location_of_administration', 'bcg_strain_id', 'bcg_strain_du_class', 'bcg_strain_t_cell_grp_3']], drop_first = True) \nX_ = df1.drop(['country_name', 'country_code', 'bcg_policy_first_year_original', 'bcg_policy_last_year_original', 'is_bcg_mandatory_for_all_children', 'vaccination_timing', 'bcg_strain_original', 'were_revaccinations_recommended', 'timing_of_revaccination', 'location_of_administration', 'bcg_strain_id', 'bcg_strain_du_class', 'bcg_strain_t_cell_grp_3'], axis = 1)\ndf1_1 = pd.concat([X_, dummies], axis = 1)\ndf1_1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Standardization","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#After Encoding the name of the features changed. Pay attention.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import scale, StandardScaler, RobustScaler, MinMaxScaler\n\n# Standardization on three features\nX_s = pd.DataFrame(df1_1[['bcg_strain_original_BCG Moreau - Rio de Janeiro', 'were_revaccinations_recommended_No', 'bcg_strain_t_cell_grp_3_Yes']], \n                   columns = ['bcg_strain_original_BCG Moreau - Rio de Janeiro', 'were_revaccinations_recommended_No', 'bcg_strain_t_cell_grp_3_Yes'])\n\nMinMax = MinMaxScaler(feature_range = (0, 1)).fit(X_s)\nX_s = MinMax.transform(X_s)\nX_st = pd.DataFrame(X_s, columns = ['bcg_strain_original_BCG Moreau - Rio de Janeiro', 'were_revaccinations_recommended_No', 'bcg_strain_t_cell_grp_3_Yes'])\nX_st.index = X_st.index + 1\nX_st.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We define the dataset with standardized variables as df_2.\ndf_2 = df1_1.drop(['bcg_strain_original_BCG Moreau - Rio de Janeiro', 'were_revaccinations_recommended_No', 'bcg_strain_t_cell_grp_3_Yes'], axis = 1)\ndf_2 = pd.concat([df_2, X_st], axis = 1, ignore_index = False)\ndf_2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"df_2.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After Encoding we have numerical features to handle the missing values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cat=df_2.select_dtypes(\"object\")\nfor column in cat:\n    df_2[column].fillna(df_2[column].mode()[0], inplace=True)\n    #dataset[column].fillna(\"NA\", inplace=True)\n\n\nfl=df_2.select_dtypes([\"float64\",\"int64\"]).drop(\"bcg_strain_original_BCG Moreau - Rio de Janeiro\",axis=1)\nfor column in fl:\n    df_2[column].fillna(df_2[column].median(), inplace=True)\n    #dataset[column].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"df_2.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"cols_to_drop=['bcg_strain_original_BCG Moreau - Rio de Janeiro']\ndf_2=df_2.drop(cols_to_drop,axis=1)\ndf_2.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression  \nfrom sklearn.neighbors import KNeighborsClassifier  \nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.metrics import (plot_confusion_matrix, confusion_matrix, \n                             accuracy_score, mean_squared_error, r2_score, \n                             roc_auc_score, roc_curve, classification_report, \n                             precision_recall_curve, auc, f1_score, \n                             average_precision_score, precision_score, recall_score)\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score, GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"y = df_2['bcg_policy_first_year_original_1927']\nX = df_2.drop('bcg_policy_first_year_original_1927', axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 12345)\nmodels = [\n    LogisticRegression(),\n    KNeighborsClassifier(),\n    SVC(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    GradientBoostingClassifier(),\n    LGBMClassifier(),\n    XGBClassifier()]\n\nresult = []\nresults = pd.DataFrame(columns = [\"Models\",\"Accuracy\"])\n\nfor model in models:\n    names = model.__class__.__name__\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    scores = cross_val_score(model, X_test, y_test, cv = 10, scoring = 'accuracy')\n    result = pd.DataFrame([[names, acc * 100, \n                            np.mean(scores) * 100]], \n                          columns = [\"Models\", \"Accuracy\", \"Avg_Accuracy\"])\n    results = results.append(result)\nresults","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#That's new. LightGBMError: Do not support special JSON characters in feature name","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"ls ../input/hackathon/task_1-google_search_txt_files_v2/LB/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Lebanon = '../input/hackathon/task_1-google_search_txt_files_v2/LB/Lebanon-ar-result-20.txt'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = open(Lebanon, 'r',encoding='utf-8',\n                 errors='ignore').read()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(text[:2000])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The only thing that I understood above was BCG.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#word cloud\nfrom wordcloud import WordCloud, ImageColorGenerator\ntext = \" \".join(str(each) for each in LBN.country_name)\n# Create and generate a word cloud image:\nwordcloud = WordCloud(max_words=200,colormap='Set2', background_color=\"black\").generate(text)\nplt.figure(figsize=(10,6))\nplt.figure(figsize=(15,10))\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.figure(1,figsize=(12, 12))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Das War's, Kaggle Notebook Runner: Marília Prata  @mpwolke ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}