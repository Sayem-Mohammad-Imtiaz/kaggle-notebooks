{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error,roc_auc_score,explained_variance_score\nfrom sklearn.metrics import accuracy_score,confusion_matrix, mean_absolute_error\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reading the Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing=pd.read_csv(r\"../input/california-housing-prices/housing.csv\")\nhousing.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 207 data points not available in total bedrooms. Where the total number of bedrooms are the total number of bedrooms in all houses in the block.Lets drop the rows having null values."},{"metadata":{"trusted":true},"cell_type":"code","source":"housing=housing.dropna()\nhousing.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now all the na values are dropped."},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.median_house_value.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a column ocean_proximity(the type of landscape of the block) which is categorical variable. Lets convert it into numerical variable by label encoding. "},{"metadata":{},"cell_type":"markdown","source":"There are 5 unique values in ocean_proximity."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(housing.ocean_proximity.unique())\nprint(len(housing.ocean_proximity.unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_encoder=preprocessing.LabelEncoder()\nhousing.ocean_proximity= label_encoder.fit_transform(housing.ocean_proximity)\nhousing.ocean_proximity.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here categorical column has changed to numerical column. The numbers were obtained based on alphabetical order."},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"From here, we can conform that all the columns were transformed into Numerical data."},{"metadata":{},"cell_type":"markdown","source":"Standardizing the Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"names=housing.columns\nscaler=preprocessing.StandardScaler()\nscaled_housing=scaler.fit_transform(housing)\nscaled_housing=pd.DataFrame(scaled_housing,columns=names)\nscaled_housing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=scaled_housing.drop(columns=['median_house_value'])\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y=scaled_housing['median_house_value']\nY=pd.DataFrame(Y)\nY.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predictor and response variables( independent and dependent variables) are divided. X represents Predictors and Y represents Response. We have to predict Y using X "},{"metadata":{},"cell_type":"markdown","source":"> Splitting of Train and Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X,test_X,train_Y,test_Y=train_test_split(X,Y,test_size=0.2,random_state=42)\nprint(train_X.shape)\nprint(train_Y.shape)\nprint(test_X.shape)\nprint(test_Y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"80% training dataset and 20% test dataset "},{"metadata":{},"cell_type":"markdown","source":"> Building Models"},{"metadata":{},"cell_type":"markdown","source":"Lets perform Multi Linear Regression "},{"metadata":{"trusted":true},"cell_type":"code","source":"linereg=LinearRegression()\nmodel_linereg=linereg.fit(train_X,train_Y)\npredict_y=model_linereg.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( 'Mean Square Error:',mean_squared_error(predict_y,test_Y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" print('Root Mean Square error:',np.sqrt(mean_squared_error(test_Y, predict_y)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" print('Mean absolute error:',mean_absolute_error(test_Y, predict_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot for residual error \n  \n## setting plot style \nplt.style.use('fivethirtyeight') \n  \n## plotting residual errors in training data \nplt.scatter(linereg.predict(train_X), linereg.predict(train_X) - train_Y, \n            color = \"green\", s = 10, label = 'Train data') \n  \n## plotting residual errors in test data \nplt.scatter(linereg.predict(test_X), linereg.predict(test_X) - test_Y, \n            color = \"blue\", s = 10, label = 'Test data') \n  \n## plotting line for zero residual error \nplt.hlines(y = 0, xmin = 0, xmax = 50, linewidth = 2) \n  \n## plotting legend \nplt.legend(loc = 'upper right') \n  \n## plot title \nplt.title(\"Residual errors\") \n  \n## function to show plot \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print ('Explaines Variance Score:',explained_variance_score(predict_y,test_Y))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, Lets perform Decision Tree Regression "},{"metadata":{"trusted":true},"cell_type":"code","source":"dtreg=DecisionTreeRegressor(random_state=10)\ndtreg_model=dtreg.fit(train_X,train_Y)\npredict_y=dtreg.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean Squared Error:',mean_squared_error(predict_y,test_Y))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"compared to linear regression mean square error , decision tree regression mean square error is some what less. But we can say the mean square errors are almost same"},{"metadata":{"trusted":true},"cell_type":"code","source":" print('Root Mean Square error:',np.sqrt(mean_squared_error(test_Y, predict_y)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean absolute error:',mean_absolute_error(test_Y, predict_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print ('Explaines Variance Score:',explained_variance_score(predict_y,test_Y))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ultimately, The error obtained using decision tree regressor are less than linear regression. But the change in error is negligible"},{"metadata":{},"cell_type":"markdown","source":"Extracting just the median_income column from the independent variables (from X_train and X_test)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=scaled_housing['median_income']\nX=pd.DataFrame(X)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X,test_X,train_Y,test_Y=train_test_split(X,Y,test_size=0.2,random_state=42)\nprint(train_X.shape)\nprint(train_Y.shape)\nprint(test_X.shape)\nprint(test_Y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now lets perform Simple linear regression using only independent variable or predictor. Here the predictor we are using is median_income "},{"metadata":{"trusted":true},"cell_type":"code","source":"linereg=LinearRegression()\nmodel_linereg=linereg.fit(train_X,train_Y)\npredict_y=model_linereg.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot for residual error \n  \n## setting plot style \nplt.style.use('fivethirtyeight') \n  \n## plotting residual errors in training data \nplt.scatter(linereg.predict(train_X), linereg.predict(train_X) - train_Y, \n            color = \"green\", s = 10, label = 'Train data') \n  \n## plotting residual errors in test data \nplt.scatter(linereg.predict(test_X), linereg.predict(test_X) - test_Y, \n            color = \"blue\", s = 10, label = 'Test data') \n  \n## plotting line for zero residual error \nplt.hlines(y = 0, xmin = 0, xmax = 50, linewidth = 2) \n  \n## plotting legend \nplt.legend(loc = 'upper right') \n  \n## plot title \nplt.title(\"Residual errors\") \n  \n## function to show plot \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\", alpha=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print( 'Mean Square Error:',mean_squared_error(predict_y,test_Y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Root Mean Square error:',np.sqrt(mean_squared_error(test_Y, predict_y)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean absolute error:',mean_absolute_error(test_Y, predict_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print ('Explaines Variance Score:',explained_variance_score(predict_y,test_Y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#housing = strat_train_set.copy()\nhousing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4, s=housing[\"population\"]/100, \n             label=\"population\", c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n            )\nplt.legend()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This figure shows where the median_house_value is high and low"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}