{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport nltk\nimport re\n\nfrom nltk import sent_tokenize\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(r\"../input/amazon-music-reviews/Musical_instruments_reviews.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_use=df[['summary']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = [] \nfor value in df[\"overall\"]: \n    if value == 1.0: \n        result.append(\"Negative\") \n    elif value==2.0: \n        result.append(\"Negative\") \n    elif value==3.0: \n        result.append(\"Neutral\")\n    elif value==4.0: \n        result.append(\"Positive\")\n    elif value==5.0: \n        result.append(\"Positive\")\n       \ndf_use[\"Result\"] = result    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_use.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#df_use=df_use.loc[df_use['Result']!='Neutral']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_use.groupby('Result').describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_use.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_use.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_use.tail(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=df_use.iloc[0:-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#test_df=df_df.iloc[[-1]]\n#test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=[['The musical instruments are very good with nice quality','positve']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df=pd.DataFrame(data,columns=['summary','Result'])\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nnumber_of_class_labels=len(train_df['Result'].unique())\nnumber_of_class_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_df['Result'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Count_Row=train_df.shape[0] \nCount_Col=train_df.shape[1] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass_prob_df = pd.DataFrame(columns=['Result', 'probability'], index=range(number_of_class_labels))\nclass_prob_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Result'].value_counts()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=0\nfor val, cnt in train_df['Result'].value_counts().iteritems():\n    print ('value', val, 'was found', cnt, 'times')\n    class_prob_df.loc[i].Result = val\n    class_prob_df.loc[i].probability = cnt/Count_Row\n    i = i +1\n    \nclass_prob_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nnltk.download('punkt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#row.summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['summary'].dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport re\n#nltk.download('punkt')\nfrom nltk import sent_tokenize\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\nall_tokens = []\n\nfor idx, row in train_df.iterrows():\n    for word in word_tokenize(row.summary):\n        all_tokens.append(word)\n    \nprint(len(all_tokens), all_tokens)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get only unique tokens\nall_tokens_unique = set(all_tokens)\nprint(len(all_tokens_unique), all_tokens_unique)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nstop_words = set(stopwords.words('english'))\n\ntokens = [w for w in all_tokens_unique if not w in stop_words]\nprint(len(tokens), tokens)\n\ntokens1=[]\ntokens = [word for word in tokens if word.isalpha()]\nprint(len(tokens), tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word = ['@', 'rr', '!', '$', '@', 'jfjf', '&','(', ')', ',']\nfor word in word:\n    if word.isalpha():\n        print(\"yes it is alpha: \", word)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge documents for each category\nmerged_train_df = train_df.groupby('Result')['summary'].apply(' '.join).reset_index()\n\nmerged_train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx, row in merged_train_df.iterrows():\n    \n    temp1_tokens = []\n    for word in word_tokenize(row.summary):\n        temp1_tokens.append(word)\n    \n    temp1_tokens = set(temp1_tokens)\n         \n    temp2_tokens = []\n    for word in temp1_tokens:\n        if not word in stop_words:\n            temp2_tokens.append(word)           \n    \n    temp3_tokens = []\n    for word in temp2_tokens:\n        if word.isalpha():\n            temp3_tokens.append(word)\n            \n    print(temp3_tokens)\n    temp4_tokens = \" \".join(temp3_tokens)\n    print(temp4_tokens)\n    \n    merged_train_df.at[idx, 'summary'] = temp4_tokens\n    merged_train_df.at[idx, 'no_of_words_in_category'] = len(temp3_tokens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge to get catgory probability\n# merged_train_df\n# class_prob_df\nmerged_train_df = pd.merge(merged_train_df, class_prob_df[['Result', 'probability']], on='Result')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df = pd.DataFrame()\n\nrow_counter = 0\n\nfor idx, row in merged_train_df.iterrows():\n    for token in tokens:\n        # find the number of occurances of the token in the current category of documents\n        no_of_occurances = row.summary.count(token)\n        no_of_words_in_category = row.no_of_words_in_category\n        no_unique_words_all = len(tokens)\n        \n        prob_of_token = (no_of_occurances+ 1)/ (no_of_words_in_category+ no_unique_words_all)\n        #print(row.class_label, token, no_of_occurances, prob_of_token)\n        final_df.at[row_counter, 'Result'] = row.Result\n        final_df.at[row_counter, 'token'] = token\n        final_df.at[row_counter, 'no_of_occurances'] = no_of_occurances\n        final_df.at[row_counter, 'no_of_words_in_category'] = no_of_words_in_category\n        final_df.at[row_counter, 'no_unique_words_all'] = no_unique_words_all\n        final_df.at[row_counter, 'prob_of_token_category'] = prob_of_token\n        \n        row_counter = row_counter + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate P(Category/Document) \n#      = P(Category) * P(Word1/Category) * P(Word2/Category) * P(Word3/Category)\n\n# P(Auto/D6) = P(Auto) * P(Engine/Auto) * P(Noises/Auto) * P(Car/Auto)\nfor idx, row in test_df.iterrows():\n    \n    # tokenize & unique words\n    temp1_tokens = []\n    for word in word_tokenize(row.summary):\n        temp1_tokens.append(word)\n        #temp1_tokens = set(temp1_tokens)\n        \n    # remove stop words\n    temp2_tokens = []\n    for word in temp1_tokens:\n        if not word in stop_words:\n            temp2_tokens.append(word)\n          \n    # remove punctuations\n    temp3_tokens = []\n    for word in temp2_tokens:\n        if word.isalpha():\n            temp3_tokens.append(word)\n            \n    #temp4_tokens = \" \".join(temp3_tokens)\n    #print(temp4_tokens)\n    \n    prob = 1 \n    \n    # process for each class_label\n    for idx1, row1 in merged_train_df.iterrows():\n        print(\"class: \"+ row1.Result)\n        for token in temp3_tokens:\n            # find the token in final_df for the given category, get the probability\n            # row1.class_label & token\n        \n            print(\"      : \"+ token)  \n        \n            temp_df = final_df[(final_df['Result'] == row1.Result) & (final_df['token'] == token)]\n\n            # process for exception\n            if (temp_df.shape[0] == 0):\n                token_prob = 1/(row1.no_of_words_in_category+ no_unique_words_all)\n                print(\"       no token found prob :\", token_prob)\n                prob = prob * token_prob\n            else:\n                token_prob = temp_df.get_value(temp_df.index[0],'prob_of_token_category')\n                print(\"       token prob          :\", token_prob)\n                prob = prob * token_prob\n\n            prob = prob * row1.probability\n\n        col_at = 'prob_'+row1.Result\n\n        test_df.at[idx, col_at] = prob\n\n\ntest_df","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}