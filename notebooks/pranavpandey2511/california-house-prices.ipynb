{"cells":[{"metadata":{"_uuid":"f2b5485436c40466ccf80fa6cb9f7d1ff3a79f73","_cell_guid":"4f503796-7293-41e5-8a67-bd1b886d3b37"},"cell_type":"markdown","source":"This above part creates a datasets/housing directory in the workspace, downloads the housing.tgz file, and extracts the housing.csv from it in this directory."},{"metadata":{"_uuid":"808489aacdbefb07c3fddae33ba08f72a7fd60b0","_cell_guid":"563f8835-0831-4b49-a329-3a454c172f2c","trusted":true},"cell_type":"code","source":"import pandas as pd\n\n\nhousing = pd.read_csv(\"../input/housing.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf836e30f5d9835762ba6dce9d9eee72c9d08691"},"cell_type":"markdown","source":"This is to show 5 rows from the data"},{"metadata":{"_uuid":"518c2ad6b27950a0716e97854e3cacfd138eaa76","_cell_guid":"d8d2ac5a-d779-4b85-ab88-d8d5eff96fa9","trusted":true},"cell_type":"code","source":"housing.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9fcd96a2d230ed487435420c5aa7f41cbac7485e","_cell_guid":"5d60a9ba-83e6-45dc-895d-95cd02e4cde6","trusted":true},"cell_type":"code","source":"housing.info()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ce076dc1fd4d36b35fbf87949dd08fa61dddd7f","_cell_guid":"994becf1-da9f-4d4f-bb60-fa133b0ccd27","trusted":true},"cell_type":"code","source":"housing[\"ocean_proximity\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be44dea0e22eaf0a00e8114253e53b10cccb7491","_cell_guid":"6ef489e0-2914-46e5-b1b0-5bdc8550b0c1","trusted":true},"cell_type":"code","source":"housing.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2a97c3ff7292c23cbc5c5816983f457f9eefd9e","_cell_guid":"671433a4-eebc-49dd-bb53-649629fbc2ee","trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nhousing.hist(bins=50, figsize=(20,20))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab2387045b5dfebb85833111f749681f171eb690","_cell_guid":"b5bf28e6-f858-40d9-a0b1-5e361e99632b","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_set, test_set = train_test_split(housing, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9f282857ee600f9711d46921547a1b7f29aee14","_cell_guid":"0769ac29-d23d-4290-bf2d-2d8a1caebdf8","trusted":true},"cell_type":"code","source":"import numpy as np\nhousing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)\nhousing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3312c9615ed03241b6e512a084fed3da2d2f70e4","_cell_guid":"96ca6695-624c-47ce-a1e4-7ce56b51cbed","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)\nfor train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n    strat_train_set = housing.loc[train_index]\n    strat_test_set = housing.loc[test_index]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e032d30d1cc7734b5316dc589f98b7fa26e01d5a","_cell_guid":"12938bb5-45a2-48a9-9dae-90796eab3df0","trusted":true},"cell_type":"code","source":"housing[\"income_cat\"].value_counts() / len(housing)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87236915a1498675a820c8df94dc63cf138f09d5","_cell_guid":"fb79afeb-a82a-40d9-be3b-97ee3ff92c26","trusted":true},"cell_type":"code","source":"for set_ in(strat_train_set, strat_test_set):\n    set_.drop(\"income_cat\", axis = 1, inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94b85e2e346a1a235df419266cb75fa2fd0064ea","_cell_guid":"e9a1e61b-9e0f-4c50-91f9-4682319e63dc","trusted":true},"cell_type":"code","source":"housing = strat_train_set.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b20d88af55e951e9ca143e8b943c176d8354f6d2","_cell_guid":"43d9d6be-fbd0-4266-a204-48d063f9b15f","trusted":true},"cell_type":"code","source":"housing.plot(kind = \"scatter\", x= \"longitude\", y = \"latitude\", alpha = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45e24c4c032c94f460b03a4895bf73da41800597","_cell_guid":"f5dc549a-50e9-4dcc-bc32-84d3ad76d515","trusted":true},"cell_type":"code","source":"housing.plot(kind = \"scatter\", x= \"longitude\", y = \"latitude\", alpha = 0.4, s = housing[\"population\"]/100, \n             label = \"population\", figsize=(15,10), c= \"median_house_value\", cmap = plt.get_cmap(\"jet\"), colorbar = True)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"490673426e1e219a21bc2319e51508b18e14c3db","_cell_guid":"9afa289c-9f82-434b-8e1d-d1ec13117a68","trusted":true},"cell_type":"code","source":"corr_matrix = housing.corr()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfce0d35241433c35cf5e9fd6a117a1760360272","_cell_guid":"9db0c018-9a6b-44da-8db1-a04948b8334b","trusted":true},"cell_type":"code","source":"corr_matrix[\"median_house_value\"].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92d51b8bcc128e38808f8a4fff8368dd8ad76909","_cell_guid":"9a6f95d5-dd53-479c-a276-881fe794bd11","trusted":true},"cell_type":"code","source":"#Another way to check for correlation b/w attributes is scatter_matrix function using pandas \n#which plots for every numerical attribute to every numerical attribute in this case 11^2 = 121 plots,but here we will use only \n#limited attribute\n\nfrom pandas.tools.plotting import scatter_matrix\n\nattributes = [\"median_house_value\", \"median_income\", \"total_rooms\", \"housing_median_age\" ]\nscatter_matrix(housing[attributes], figsize = (15,10))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b4bc109cfb69b4b0931f37d376a86b35a4b6bbc","_cell_guid":"0d84ad84-d51f-429d-9ce3-812b7a0b464b","trusted":true},"cell_type":"code","source":"#correlation between income and house value is quite high so we zoom in the graphof that\n\nhousing.plot(kind=\"scatter\", x= \"median_income\" , y= \"median_house_value\", alpha = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c727fee3087bedc80900b8c95c0286941c332de","_cell_guid":"1bb8213c-d779-4af0-bd70-01d09132258b","trusted":true},"cell_type":"code","source":"housing[\"room_per_household\"] = housing[\"total_rooms\"] / housing[\"households\"]\nhousing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"] / housing[\"total_rooms\"]\nhousing[\"population_per_household\"] = housing[\"population\"] / housing[\"households\"]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ce535f944b6fa44796aff0f7ed4b4d178718c95","_cell_guid":"2102534c-a219-4a48-a4d8-7a9e6b6ee34b","trusted":true},"cell_type":"code","source":"\ncorr_matrix = housing.corr()\ncorr_matrix[\"median_house_value\"].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5eb78c84810e4d6cf914ca7a655dd305eacd161d","_cell_guid":"4a062c6a-d3a3-4254-8f69-f417b0e4d4cd","trusted":true},"cell_type":"code","source":"housing = strat_train_set.drop(\"median_house_value\", axis = 1)\nhousing_labels = strat_train_set[\"median_house_value\"].copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e076396b7ef74b5d38f28fe72b2efaece7248914","_cell_guid":"d3929035-961f-4b0f-aa0e-f03ef04d6c55","trusted":true},"cell_type":"code","source":"#To deal with missing values in the dataset we need to replace the null values with mean, mediian value or something similar\n#for that scikit-learn provides \"Imputer\"\n\nfrom sklearn.preprocessing import Imputer\n\nimputer = Imputer(strategy=\"median\")\n\n#imputer works only on numerical values, so we remove the non-numeric values from the dataset\n\nhousing_num = housing.drop(\"ocean_proximity\", axis= 1)\nimputer.fit(housing_num)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0067338eb33cbb9dff300cb92caa331ee9643635","_cell_guid":"22411973-6b26-4fa9-85c8-ba0e15912e94","trusted":true},"cell_type":"code","source":"#statistics_ instance variable contains median for each atribute\n\nimputer.statistics_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed3fb8037ce67da0f4e6b58bc2e87d5adcee457a","_cell_guid":"2543da4d-8696-483f-9592-d6c017033ecc","trusted":true},"cell_type":"code","source":"housing_num.median().values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a80aab8375c29426edd70e6fe25325e7266ed34c","_cell_guid":"0bfac8ee-2e5b-48ec-9708-40463dbdd4a3","trusted":true},"cell_type":"code","source":"#Now we use this \"trained\" imputer to replace the missing values by the learned medians\n\nX = imputer.transform(housing_num)\nhousing_tr = pd.DataFrame(X, columns=housing_num.columns,\n                          index = list(housing.index.values))\n\nhousing_tr = pd.DataFrame(X, columns=housing_num.columns)\nhousing_tr.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78b5e31ba9816a387da25502874399bf3846aefd","_cell_guid":"65a68bd1-ee2b-412e-b3a1-9d7f5030b562","trusted":true},"cell_type":"code","source":"housing_cat = housing[\"ocean_proximity\"]\nhousing_cat_encoded, housing_categories = housing_cat.factorize()\nhousing_cat_encoded[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c0baaafddee5d6bfe5bac0b1253dcbea46101a6","_cell_guid":"42bf9078-159c-4355-85b9-f0b680ff87d9","trusted":true},"cell_type":"code","source":"housing_categories","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52ad33ad73bb50ea690fda4a73971e582b266457","_cell_guid":"e7ea28bd-bf8a-4bef-a1b3-dfed2368d6b2","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder()\nhousing_cat_1hot = encoder.fit_transform(housing_cat_encoded.reshape(-1,1))\nhousing_cat_1hot.toarray()\nhousing_cat_1hot","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b673365d0caef2fb885854fd2c406012f9def582","_cell_guid":"0fb504e7-2ede-4d6c-9d87-1699b9af7824","trusted":true},"cell_type":"code","source":"\n# Definition of the CategoricalEncoder class, copied from PR #9151.\n# Just run this cell, or copy it to your code, do not try to understand it (yet).\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.utils import check_array\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy import sparse\n\nclass CategoricalEncoder(BaseEstimator, TransformerMixin):\n    \"\"\"Encode categorical features as a numeric array.\n    The input to this transformer should be a matrix of integers or strings,\n    denoting the values taken on by categorical (discrete) features.\n    The features can be encoded using a one-hot aka one-of-K scheme\n    (``encoding='onehot'``, the default) or converted to ordinal integers\n    (``encoding='ordinal'``).\n    This encoding is needed for feeding categorical data to many scikit-learn\n    estimators, notably linear models and SVMs with the standard kernels.\n    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n    Parameters\n    ----------\n    encoding : str, 'onehot', 'onehot-dense' or 'ordinal'\n        The type of encoding to use (default is 'onehot'):\n        - 'onehot': encode the features using a one-hot aka one-of-K scheme\n          (or also called 'dummy' encoding). This creates a binary column for\n          each category and returns a sparse matrix.\n        - 'onehot-dense': the same as 'onehot' but returns a dense array\n          instead of a sparse matrix.\n        - 'ordinal': encode the features as ordinal integers. This results in\n          a single column of integers (0 to n_categories - 1) per feature.\n    categories : 'auto' or a list of lists/arrays of values.\n        Categories (unique values) per feature:\n        - 'auto' : Determine categories automatically from the training data.\n        - list : ``categories[i]`` holds the categories expected in the ith\n          column. The passed categories are sorted before encoding the data\n          (used categories can be found in the ``categories_`` attribute).\n    dtype : number type, default np.float64\n        Desired dtype of output.\n    handle_unknown : 'error' (default) or 'ignore'\n        Whether to raise an error or ignore if a unknown categorical feature is\n        present during transform (default is to raise). When this is parameter\n        is set to 'ignore' and an unknown category is encountered during\n        transform, the resulting one-hot encoded columns for this feature\n        will be all zeros.\n        Ignoring unknown categories is not supported for\n        ``encoding='ordinal'``.\n    Attributes\n    ----------\n    categories_ : list of arrays\n        The categories of each feature determined during fitting. When\n        categories were specified manually, this holds the sorted categories\n        (in order corresponding with output of `transform`).\n    Examples\n    --------\n    Given a dataset with three features and two samples, we let the encoder\n    find the maximum value per feature and transform the data to a binary\n    one-hot encoding.\n    >>> from sklearn.preprocessing import CategoricalEncoder\n    >>> enc = CategoricalEncoder(handle_unknown='ignore')\n    >>> enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])\n    ... # doctest: +ELLIPSIS\n    CategoricalEncoder(categories='auto', dtype=<... 'numpy.float64'>,\n              encoding='onehot', handle_unknown='ignore')\n    >>> enc.transform([[0, 1, 1], [1, 0, 4]]).toarray()\n    array([[ 1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.],\n           [ 0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]])\n    See also\n    --------\n    sklearn.preprocessing.OneHotEncoder : performs a one-hot encoding of\n      integer ordinal features. The ``OneHotEncoder assumes`` that input\n      features take on values in the range ``[0, max(feature)]`` instead of\n      using the unique values.\n    sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of\n      dictionary items (also handles string-valued features).\n    sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot\n      encoding of dictionary items or strings.\n    \"\"\"\n\n    def __init__(self, encoding='onehot', categories='auto', dtype=np.float64,\n                 handle_unknown='error'):\n        self.encoding = encoding\n        self.categories = categories\n        self.dtype = dtype\n        self.handle_unknown = handle_unknown\n\n    def fit(self, X, y=None):\n        \"\"\"Fit the CategoricalEncoder to X.\n        Parameters\n        ----------\n        X : array-like, shape [n_samples, n_feature]\n            The data to determine the categories of each feature.\n        Returns\n        -------\n        self\n        \"\"\"\n\n        if self.encoding not in ['onehot', 'onehot-dense', 'ordinal']:\n            template = (\"encoding should be either 'onehot', 'onehot-dense' \"\n                        \"or 'ordinal', got %s\")\n            raise ValueError(template % self.handle_unknown)\n\n        if self.handle_unknown not in ['error', 'ignore']:\n            template = (\"handle_unknown should be either 'error' or \"\n                        \"'ignore', got %s\")\n            raise ValueError(template % self.handle_unknown)\n\n        if self.encoding == 'ordinal' and self.handle_unknown == 'ignore':\n            raise ValueError(\"handle_unknown='ignore' is not supported for\"\n                             \" encoding='ordinal'\")\n\n        X = check_array(X, dtype=np.object, accept_sparse='csc', copy=True)\n        n_samples, n_features = X.shape\n\n        self._label_encoders_ = [LabelEncoder() for _ in range(n_features)]\n\n        for i in range(n_features):\n            le = self._label_encoders_[i]\n            Xi = X[:, i]\n            if self.categories == 'auto':\n                le.fit(Xi)\n            else:\n                valid_mask = np.in1d(Xi, self.categories[i])\n                if not np.all(valid_mask):\n                    if self.handle_unknown == 'error':\n                        diff = np.unique(Xi[~valid_mask])\n                        msg = (\"Found unknown categories {0} in column {1}\"\n                               \" during fit\".format(diff, i))\n                        raise ValueError(msg)\n                le.classes_ = np.array(np.sort(self.categories[i]))\n\n        self.categories_ = [le.classes_ for le in self._label_encoders_]\n\n        return self\n\n    def transform(self, X):\n        \"\"\"Transform X using one-hot encoding.\n        Parameters\n        ----------\n        X : array-like, shape [n_samples, n_features]\n            The data to encode.\n        Returns\n        -------\n        X_out : sparse matrix or a 2-d array\n            Transformed input.\n        \"\"\"\n        X = check_array(X, accept_sparse='csc', dtype=np.object, copy=True)\n        n_samples, n_features = X.shape\n        X_int = np.zeros_like(X, dtype=np.int)\n        X_mask = np.ones_like(X, dtype=np.bool)\n\n        for i in range(n_features):\n            valid_mask = np.in1d(X[:, i], self.categories_[i])\n\n            if not np.all(valid_mask):\n                if self.handle_unknown == 'error':\n                    diff = np.unique(X[~valid_mask, i])\n                    msg = (\"Found unknown categories {0} in column {1}\"\n                           \" during transform\".format(diff, i))\n                    raise ValueError(msg)\n                else:\n                    # Set the problematic rows to an acceptable value and\n                    # continue `The rows are marked `X_mask` and will be\n                    # removed later.\n                    X_mask[:, i] = valid_mask\n                    X[:, i][~valid_mask] = self.categories_[i][0]\n            X_int[:, i] = self._label_encoders_[i].transform(X[:, i])\n\n        if self.encoding == 'ordinal':\n            return X_int.astype(self.dtype, copy=False)\n\n        mask = X_mask.ravel()\n        n_values = [cats.shape[0] for cats in self.categories_]\n        n_values = np.array([0] + n_values)\n        indices = np.cumsum(n_values)\n\n        column_indices = (X_int + indices[:-1]).ravel()[mask]\n        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n                                n_features)[mask]\n        data = np.ones(n_samples * n_features)[mask]\n\n        out = sparse.csc_matrix((data, (row_indices, column_indices)),\n                                shape=(n_samples, indices[-1]),\n                                dtype=self.dtype).tocsr()\n        if self.encoding == 'onehot-dense':\n            return out.toarray()\n        else:\n            return out","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"032297f22446193d78542eb597215f1329d304c3","_cell_guid":"91c2f1e3-6fb8-413a-a384-367bf2f76be3","trusted":true},"cell_type":"code","source":"#from sklearn.preprocessing import CategoricalEncoder # in future versions of Scikit-Learn\n\ncat_encoder = CategoricalEncoder()\nhousing_cat_reshaped = housing_cat.values.reshape(-1, 1)\nhousing_cat_1hot = cat_encoder.fit_transform(housing_cat_reshaped)\nhousing_cat_1hot","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86a846d0a27fab62cb8f8e3dc5eed20b4ecfc812","_cell_guid":"f6085091-e5e5-4eef-a5d2-cd42734dd207","trusted":true},"cell_type":"code","source":"housing_cat_1hot.toarray()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2da7e11b3bbbc2ce484d971be7b4baf978a728b7","_cell_guid":"15e5cb66-2476-4b67-b742-140ef20159ed","trusted":true},"cell_type":"code","source":"cat_encoder = CategoricalEncoder(encoding=\"onehot-dense\")\nhousing_cat_1hot = cat_encoder.fit_transform(housing_cat_reshaped)\nhousing_cat_1hot","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"216c0bc5427e1e40e5569b362e894ddd9b1e97da","_cell_guid":"3a30cbf6-9143-4329-bcda-0cd8b0cc534b","trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n\n# column index\nrooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n\nclass CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n        self.add_bedrooms_per_room = add_bedrooms_per_room\n    def fit(self, X, y=None):\n        return self  # nothing else to do\n    def transform(self, X, y=None):\n        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n        population_per_household = X[:, population_ix] / X[:, household_ix]\n        if self.add_bedrooms_per_room:\n            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n            return np.c_[X, rooms_per_household, population_per_household,\n                         bedrooms_per_room]\n        else:\n            return np.c_[X, rooms_per_household, population_per_household]\n\nattr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\nhousing_extra_attribs = attr_adder.transform(housing.values)\n        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3167d32696b0de920e6a73c0cd53decf6418a91c","_cell_guid":"37a48e68-bc96-4157-81f0-ff82c01a2d67","trusted":true},"cell_type":"code","source":"housing_extra_attribs = pd.DataFrame(housing_extra_attribs, columns=list(housing.columns)+[\"rooms_per_household\", \"population_per_household\"])\nhousing_extra_attribs.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"108c60e4808f13422509edd699715665b3b79ea1","_cell_guid":"92ced4f3-bd05-4c25-9fd9-284e0b604c91","trusted":true},"cell_type":"code","source":"#PIPELINING\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nnum_pipeline = Pipeline([('imputer', Imputer(strategy = \"median\")), \n                         ('attribs_adder', CombinedAttributesAdder()), \n                         ('std_scaler', StandardScaler())])\nhousing_num_tr = num_pipeline.fit_transform(housing_num)\nhousing_num_tr","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea3f1e15337df6d214af645c651424dcaef1e56f","_cell_guid":"1fffa3ab-e97e-4a9c-bc9a-7db9130156d8","trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n\n# Create a class to select numerical or categorical columns \n# since Scikit-Learn doesn't handle DataFrames yet\nclass DataFrameSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attribute_names):\n        self.attribute_names = attribute_names\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return X[self.attribute_names].values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3f500ebbb4a9b1cbf357bd02f58eaabdeb605a2","_cell_guid":"0b01c0b1-1686-4a82-b7a0-82dc7aa89823","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer\n\nnum_attribs = list(housing_num)\ncat_attribs = [\"ocean_proximity\"]\n\nnum_pipeline = Pipeline([\n    ('selector', DataFrameSelector(num_attribs)),\n    ('imputer', Imputer(strategy = \"median\")),\n    ('attribs_adder', CombinedAttributesAdder()),\n    ('std_scaler', StandardScaler())\n])\n\ncat_pipeline = Pipeline([\n    ('selector', DataFrameSelector(cat_attribs)),\n    ('cat_encoder', CategoricalEncoder(encoding=\"onehot-dense\"))\n])\n\nfrom sklearn.pipeline import FeatureUnion\n\nfull_pipeline = FeatureUnion(transformer_list = [('num_pipeline', num_pipeline),\n                                                  ('cat_pipeline', cat_pipeline)])\n\nhousing_prepared = full_pipeline.fit_transform(housing)\nhousing_prepared","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c0d630f66251102c49493cc8df1101389bc7a09","_cell_guid":"73aaa70b-ba55-46f6-8b19-a38442b688d4","trusted":true},"cell_type":"code","source":"housing_prepared.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fd8f1c8d524e4f995620e1645cdee9099fad8cc","_cell_guid":"a753804b-c5bd-4f44-b57f-b38b1d0558b3"},"cell_type":"markdown","source":"**Select and Train a model**"},{"metadata":{"_uuid":"de1aec5e193abe2cf8dfeac5da56d6928ebf34ac","_cell_guid":"4d24f579-f9b3-40a5-8b6d-6c6aa0c78b0c","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(housing_prepared, housing_labels)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9df8d14fa368924b4616d3523ba91d64bc15ccab","_cell_guid":"4783c13c-40e9-44f2-86ec-f6adb5a578f6","trusted":true},"cell_type":"code","source":"some_data = housing.iloc[:10]\nsome_labels = housing_labels[:10]\nsome_data_prepared = full_pipeline.transform(some_data)\n\nprint(\"Predictions:\" , lin_reg.predict(some_data_prepared))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a509f99249d0c4922664200746a3dba38aa3d51c","_cell_guid":"63e3f332-7a59-4fb1-9c4b-b9d63af80594"},"cell_type":"markdown","source":"Comapring against actual values,"},{"metadata":{"_uuid":"071358ff65516323c912f9b2f1ac867df4b7956e","_cell_guid":"8be97c35-eb46-4872-ae6f-3a9bd6a4ffda","trusted":true},"cell_type":"code","source":"print(\"Labels:\", list(some_labels))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6184a4163017839b347ffc28960ca7eb30627d40","_cell_guid":"8ba9c6e1-34d3-4e74-9729-70ad77605035","trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nhousing_predictions = lin_reg.predict(housing_prepared)\nlin_mse = mean_squared_error(housing_labels, housing_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da87185239a9a073dc6fa8edbec319b22bef8f30","_cell_guid":"e1bcef22-cff7-4fd0-ae3d-197da6490039","trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ndec_tree = DecisionTreeRegressor()\ndec_tree.fit(housing_prepared, housing_labels)\nprint(\"Prediction:\", dec_tree.predict(some_data_prepared))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5693d38f10128e0c59aa70e1b7878dc2f4afdad6","_cell_guid":"4a4f5ef7-78e1-4e28-9f7b-8ae4ecf9b1cf","trusted":true},"cell_type":"code","source":"print(\"Labels:\", list(some_labels))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c10916df9f2f7ebaa0685c4cab74dd0f47501adb","_cell_guid":"b4f75fb8-5cf2-49f3-8258-eeaec5f60fcb","trusted":true},"cell_type":"code","source":"housing_predictions = dec_tree.predict(housing_prepared)\ndec_mse = mean_squared_error(housing_labels, housing_predictions)\ndec_rmse = np.sqrt(dec_mse)\ndec_rmse","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f55e9eafa7619ad16e4e9697c2c59f8f2a882586","_cell_guid":"8dcaa817-5b97-48cd-811b-5273aa518ccd","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(dec_tree, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\ntree_rmse_scores = np.sqrt(-scores)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6efd6b9282a4054a7a349ad08ecc2b04ce06ed62","_cell_guid":"46cf2ad6-f976-4ee4-a046-a92ea52be217","trusted":true},"cell_type":"code","source":"def display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())\n\ndisplay_scores(tree_rmse_scores)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe75efaa49f07eb7a3b543a43a7f3589228b6a69","_cell_guid":"f69dbb97-5095-46b1-990b-0c78a1653c1a","trusted":true},"cell_type":"code","source":"from sklearn.ensemble  import RandomForestRegressor\n\nran_for = RandomForestRegressor()\nran_for.fit(housing_prepared, housing_labels)\nprint(\"Prediction:\", ran_for.predict(some_data_prepared))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d4b6c6a5969ae1ecc2ac43889f19bd4eb3f8c29","_cell_guid":"e8c93ad3-1f4d-44c8-a9be-591afbcb1f82","trusted":true},"cell_type":"code","source":"print(\"Labels\", list(some_labels))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60d1eb9394c7d1757ad22b798ec25016ffcd52fe","_cell_guid":"a689ec33-9bad-488a-a852-588ad0dbc382","trusted":true},"cell_type":"code","source":"housing_predictions = ran_for.predict(housing_prepared)\nfor_mse = mean_squared_error(housing_labels, housing_predictions)\nfor_rmse = np.sqrt(for_mse)\nprint(for_rmse)\nscores = cross_val_score(ran_for, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\nfor_rmse_scores = np.sqrt(-scores)\ndisplay_scores(for_rmse_scores)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce02a243d2b3c2b00a956eb5b06d7c080a4073c2","_cell_guid":"21e7172e-afeb-46ea-b923-5d94f609ad03","trusted":true},"cell_type":"code","source":"some_labels\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92039aa04faa69f1f3f14749cdc29b7fdaa39cc7","_cell_guid":"26c674d9-6af4-4002-84a7-79f0e9191d88","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    { 'n_estimators': [3, 10, 30], 'max_features': [2, 4, 5, 8]},\n    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]}\n]\n\nforest_reg = RandomForestRegressor()\n\ngrid_search = GridSearchCV(forest_reg, param_grid, cv = 5, scoring = 'neg_mean_squared_error')\n\ngrid_search.fit(housing_prepared, housing_labels)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0452d3e9376ef8f734c485a9d0aa72959c6400b7","_cell_guid":"53ba0a75-29bb-4ae4-bbe9-f6bb388afbc5","trusted":true},"cell_type":"code","source":"grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9cb219b1337ba2a9a019cb1d2f8ce97a243676aa","_cell_guid":"ab2f0bee-0e07-49ba-9707-f861b694f9de","trusted":true},"cell_type":"code","source":"cvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"],cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe229f99953b15da97f53c3af751fe8865db6420","_cell_guid":"b38da9f7-1d3f-471e-977d-5004f47d7a9c","trusted":true},"cell_type":"code","source":"feature_importances = grid_search.best_estimator_.feature_importances_\nfeature_importances","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6ef53330a90ecbd032ab454fbd55adbdf407e8d","_cell_guid":"c4f4fe8b-d6f3-4738-ba58-b19c8260d7d7","trusted":true},"cell_type":"code","source":"extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\ncat_encoder = cat_pipeline.named_steps[\"cat_encoder\"]\ncat_one_hot_attribs = list(cat_encoder.categories_[0])\nattributes = num_attribs + extra_attribs + cat_one_hot_attribs\nsorted(zip(feature_importances, attributes), reverse=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be77ce62d83a6dbf65773b9b53ce4b2a4e6349eb","_cell_guid":"d0c47b05-25a8-4a2e-93dc-29f12404d25e","trusted":true},"cell_type":"code","source":"final_model = grid_search.best_estimator_\n\nX_test = strat_test_set.drop(\"median_house_value\", axis = 1)\ny_test = strat_test_set[\"median_house_value\"].copy()\n\nX_test_prepared = full_pipeline.transform(X_test)\n\nfinal_predictions = final_model.predict(X_test_prepared)\n\nfinal_mse = mean_squared_error(y_test, final_predictions)\nfinal_rmse = np.sqrt(final_mse)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46bbf23d02fb98c2dd9618b801030af62140e601","_cell_guid":"424fb6b0-46c1-4d15-86b8-5f096796e817","trusted":true},"cell_type":"code","source":"final_rmse","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0012bad8b529241255c2b18a080d92ae76520b76","_cell_guid":"de01d311-328a-4d3b-851d-92e4a705ac29","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}