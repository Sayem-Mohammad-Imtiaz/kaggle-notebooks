{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport holoviews as hv\nfrom pprint import pprint\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport holoviews as hv\nhv.extension('bokeh', 'matplotlib', logo=False)\nimport matplotlib.pyplot as plt\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nimport  warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**** Dicionário de Dados\n# * O dicionário de dados das colunas disponíveis abaixo:*****\n\nBAD: 1 = client defaulted on loan 0 = loan repaid\n\nLOAN: Amount of the loan request\n\nMORTDUE: Amount due on existing mortgage\n\nVALUE: Value of current property\n\nREASON: DebtCon = debt consolidation ; HomeImp = home improvement\n\nJOB: Six occupational categories\n\nYOJ: Years at present job\n\nDEROG: Number of major derogatory reports\n\nDELINQ: Number of delinquent credit lines\n\nCLAGE: Age of oldest trade line in months\n\nNINQ: Number of recent credit lines\n\nCLNO: Number of credit lines****"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Carregando os dados\ndf = pd.read_csv('/kaggle/input/hmeq-data/hmeq.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os tipos de dados\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verificando a quantidade de linhas e colunas\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Análisando a base\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Mostrando as colunas // ACHO QUE NÃO PRECISA COLOCA\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Estatistica Descritiva. Vamos incluir TUDO....\ndf.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_feats = [c for c in df.columns if df[c].dtype != 'object' and c not in ['BAD']]\ndf_numeric_feats = df[numeric_feats]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# avaliando as variáveis numéricas\nsns.pairplot(df_numeric_feats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_numeric_feats.hist(figsize=(20,8), bins=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analise Exploratória\ndf[\"BAD\"].value_counts().plot.bar(title='BAD')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizando a variável categorica REASON\nREASON_count= df[\"REASON\"].value_counts().rename_axis('REASON').reset_index(name='Total Count')\ndf[\"REASON\"].value_counts().plot.bar(title='REASON')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#visualizando  a variável categórica JOB\nJOB_count= df[\"JOB\"].value_counts().rename_axis('JOB').reset_index(name='Total Count')\ndf[\"JOB\"].value_counts().plot.bar(title='JOB')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Relação JOB vs BAD\nJOB=pd.crosstab(df['JOB'],df['BAD'])\nJOB.div(JOB.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, title='JOB vs BAD', figsize=(4,4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df = t.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tratando colunas categóricas\n#for col in df.select_dtypes(include='object').columns:\n#    if df[col].isna().sum() > 0:\n#         df[col].fillna(df[col].mode()[0], inplace=True)   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tratando colunas numéricas\n#for col in df.select_dtypes(exclude='object').columns:\n#    if df[col].isna().sum() > 0:\n#        df[col].fillna(-1, inplace=True)      \n#df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def showBalance(df, col):\n    for c in col:\n        print('Distribuição da Coluna: ', c,'\\n',df[c].value_counts(normalize=True),'\\n')\n    else:\n       pass\n        \nshowBalance(df, col=['REASON','JOB','BAD'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Finalmente, o número de linha de crédito aberta (CLNO) parece estatisticamente consistente em ambos os casos,\n# sugerindo que essa variável não possui poder de discriminação significativo.\n# Este método é primariamente baseado nas labels da colunas, porém podemos utilizar com um array booleano também. (Usando o loc)\n# Uma informação importante sobre loc é: quando nenhum item é encontrado ele retorna um KeyError.\ndf.loc[df.BAD == 1, 'STATUS'] = 'DEFAULT'\ndf.loc[df.BAD == 0, 'STATUS'] = 'PAID'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# relação do empréstimo pagos. Pelo que mostra 81% dos empréstimos foram pagos.\n#A discrepância de 4% observada não é estatisticamente significativa, dado o montante de empréstimos no conjunto de dados.\ng = df.groupby('REASON')\ng['STATUS'].value_counts(normalize=True).to_frame().style.format(\"{:.1%}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Matrix de correlação\n\ncorr = df.corr()\n#Plot figsize\nfig, ax = plt.subplots(figsize=(10,8))\n#Generate Color Map\ncolormap = sns.diverging_palette(220, 10, as_cmap=True)\n#Generate Heat Map, allow annotations and place floats in map\nsns.heatmap(corr, cmap=colormap, annot=True, fmt=\".2f\")\n#Apply xticks\nplt.xticks(range(len(corr.columns)), corr.columns);\n#Apply yticks\nplt.yticks(range(len(corr.columns)), corr.columns)\n#show plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verificando os missing \ndf.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criando uma cópia de um novo dataframe e vamos eliminar os NA, \ndf2 = df.copy()\ndf2.dropna(axis=0,how='any',inplace= True)\ndf2.info(), df2.isna().any() \ndf2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analisando como ficou\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tranformando as colunas de object em categoria com codigos #\nfor col in df2.columns:\n    if df2[col].dtype == 'object':\n        df2[col]= df2[col].astype('category').cat.codes\ndf2.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# analisando REASON (MOTIVO)\ndf2['REASON'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"VAMOS TREINAR E ANALISAR O MODELO"},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Separando em Treino e Teste\n\ntreino, teste = train_test_split(df2, random_state=42)\n\n#  Separando o treino e validacao, para refinar o modelo\n\n#treino, validacao = train_test_split(treino, random_state=42)\n\ntreino.shape, teste.shape, #validacao.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# separar as colunas para usar no treino\n\nusadas_treino = [c for c in treino.columns if c not in ['BAD','REASON','JOB','STATUS']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\nrf = RandomForestClassifier(n_estimators=900, random_state=42)\n\nrf.fit(treino[usadas_treino],treino['BAD'])\n#Gerando as predições do modelo\nrf_pred = rf.predict(teste[usadas_treino])\n\naccuracy_score(teste['BAD'], rf_pred), f1_score(teste['BAD'],rf_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Olhando os valores da SITUACAO - TREINO\n\ntreino['BAD'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trabalhando com RandomForest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nrf2 = RandomForestClassifier(n_estimators=900, min_samples_split=5, max_depth=4, random_state=42)\nrf2.fit(treino[usadas_treino],treino['BAD'])\n\n#Gerando as predições do modelo\nrf_pred2 = rf.predict(teste[usadas_treino])\n\naccuracy_score(teste['BAD'], rf_pred2), f1_score(teste['BAD'],rf_pred2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trabalhando com GBM\nfrom sklearn.ensemble import GradientBoostingClassifier\ngbm = GradientBoostingClassifier(n_estimators=200, learning_rate=1.0, max_depth=1, random_state=42)\ngbm.fit(treino[usadas_treino], treino['BAD'])\n\naccuracy_score(validacao['BAD'], gbm.predict(validacao[usadas_treino]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trabalhando com XGBoost\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier(n_estimators=200, learning_rate=0.09, random_state=42)\nxgb.fit(treino[usadas_treino], treino['BAD'])\n\n#Gerando as predições do modelo\naccuracy_score(teste['BAD'], xgb.predict(teste[usadas_treino]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Amostra de cada variável."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando e avaliando a importancia de cada coluna para o modelo RF\n\npd.Series(rf.feature_importances_, index=usadas_treino).sort_values().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# O modelo GBM em cada coluna...\n\npd.Series(gbm.feature_importances_, index=usadas_treino).sort_values().plot.barh()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importando a bilbioteca para plotar o gráfico de Matriz de Confusão\nimport scikitplot as skplt\n\n# Matriz de Confusão - Dados de Validação\nskplt.metrics.plot_confusion_matrix(teste['BAD'], rf_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verificando o desbalanceio da variável dependente\ndf['BAD'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dividindo o DataFrame\nfrom sklearn.model_selection import train_test_split\n\n# Treino e teste\ntreino, test = train_test_split(df, test_size=0.15, random_state=42)\n\n# Veificando o tanho dos DataFrames\ntreino.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}