{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eab03770969674979d2250fedebdb1913684983e"},"cell_type":"markdown","source":"Öncelikle verimizi ekliyoruz."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"data=pd.read_csv('../input/diabetes.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e8386e0a733040bc81bf4ec611e262c67a827de"},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9734eb8d8409f848a3007c4a2d901e0c4eca9258"},"cell_type":"markdown","source":"Verimize ait karar sınıfı olan Outcome sınıfındaki verilerin dağılımına bakıyoruz. Görüldüğü gibi '1' sınıfından 268 '0' sınıfından ise 500 adet veri bulunmakta."},{"metadata":{"trusted":true,"_uuid":"5a556733429a4b5767dfe1c6100ce6242cc54b57"},"cell_type":"code","source":"data.Outcome.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c03c9d1df96776102331fc179bc503cfc5bb33a"},"cell_type":"markdown","source":"Şimdi ise karar sınıfımız ve bu karar sınıfını etkileten özelliklerimizi ayırmaya yani x ve y veri setlerimizi hazırlama aşamasındayız. y bizim karar sınıfımız, x ise karar sınıfı dışında bulunan bütün veri setini temsil etmekte."},{"metadata":{"trusted":true,"_uuid":"45a87d2ae64c0921a72779a8f2799dc046a2f0e7"},"cell_type":"code","source":"y=data.Outcome.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a84b8a81958d7abd650749bab172a9b850177889"},"cell_type":"code","source":"x_data=data.iloc[:,:8]\nx_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"869b472a0d6b9fe030b96b14876bf8219e110fd9"},"cell_type":"markdown","source":"işlemleri yaparken büyük veri değerlerimizin küçük veri değerlerimizden daha fazla baskın olmaması için normalizasyon çalışması yapılmakta. bütün y veri setimizin tamamına normalizasyon işlemi uyguluyoruz."},{"metadata":{"trusted":true,"_uuid":"ec2ba84a17769f7327939f43e1d71ed22f156c84"},"cell_type":"code","source":"x=(x_data-np.min(x_data))/(np.max(x_data)-np.min(x_data))\nx.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0039ae222106b5424342b5444b88989084dd8399"},"cell_type":"markdown","source":"                Veri setimizin belirli bir bölümünü eğitim diğer bölümünü de test veri seti olarak ayırma işlemini sklearn kütüphanesini kullanarak gerçekleştiriyoruz. Burada train_test_split ile verimizin %80'ini eğitim, %20'sini ise test seti olarak kullanacağız ve her seferinde bu veri dağılımı seçilirken rasgele değerler seçiminin önüne geçmek için random_state değerine 42 değerini verdik.\n                Daha sonra ise verimizi bir YSA örneği gibi modelimize vereceğimiz için her özelliğe ait değeri verebilmek için matrisin Transpozunu alacağız. "},{"metadata":{"trusted":true,"_uuid":"dd321a7384dfd2df0f203cf4021d4534b54be0ee"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\nx_train = x_train.T\nx_test = x_test.T\ny_train = y_train.T\ny_test = y_test.T\n\nprint(\"x_train: \",x_train.shape)\nprint(\"x_test: \",x_test.shape)\nprint(\"y_train: \",y_train.shape)\nprint(\"y_test: \",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a9b441f8e4d237dde3eaf873a6709514af800cc"},"cell_type":"markdown","source":"    Aşağıdaki fonksiyon yardımıya weight ve bias değerlerinin başlangıç değerini belirliyoruz. Burada modelimize gelecek olan x girişi sayısını dimension adlı parametre ile almaktayız."},{"metadata":{"trusted":true,"_uuid":"3548d22a8cc5ee80f8abb883ed1995a23c69c1bb"},"cell_type":"code","source":"def initialize_weights_and_bias(dimension):\n    \n    w = np.full((dimension,1),0.01)\n    b = 0.0\n    return w,b\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"59141b7606e6bf800cbc1ea2d5b390a2e99f3a8a"},"cell_type":"markdown","source":"sigmoid fonksiyonu ile w*x+b işlemleri sonucu gelen değerin belirli bir aralıkta olmasını sağlayan işlemimizi gerçekleştiriyoruz."},{"metadata":{"trusted":true,"_uuid":"e5bc6d9fe1fdf498b2c217ecbc1e063f27320dae"},"cell_type":"code","source":"def sigmoid(z):\n    \n    y_head = 1/(1+ np.exp(-z))\n    return y_head\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"706649e69926d6d196e08794f9e6ffa1074575e4"},"cell_type":"markdown","source":"forward_backward_propagation fonksiyonu ile, forward ve backward propagation işlemlerini gerçekleştiriyoruz. Bu fonksiyonu ağırlıkları ve bias değerlerini güncelleme aşamasında kullanacağız. w ve b değerlerinin optimum değerlerine ulaşana kadar sırasıyla ileri-geri yayılım işlemini gerçekleştireceğiz."},{"metadata":{"trusted":true,"_uuid":"53a4775a691c55284b823bdfe115dfbae9c41646"},"cell_type":"code","source":"def forward_backward_propagation(w,b,x_train,y_train):\n    # forward propagation\n    z = np.dot(w.T,x_train) + b\n    y_head = sigmoid(z)\n    loss = -y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head)\n    cost = (np.sum(loss))/x_train.shape[1]      \n    \n    # backward propagation\n    derivative_weight = (np.dot(x_train,((y_head-y_train).T)))/x_train.shape[1] # x_train.shape[1]  is for scaling\n    derivative_bias = np.sum(y_head-y_train)/x_train.shape[1]                 # x_train.shape[1]  is for scaling\n    gradients = {\"derivative_weight\": derivative_weight, \"derivative_bias\": derivative_bias}\n    \n    return cost,gradients\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5aa75b42bd12e9e96a0ccfa4a9714472806de5b"},"cell_type":"markdown","source":"Şimdi sıra geldi w ve b değerlerini güncellemeye. Burada belirlenen iterasyona göre w ve b değerleri güncellenecek ve forward_backward_propagation fonksiyonu kullanılarak loss ve cost değerlerinin minimumuna ulaşılmaya çalışılacaktır."},{"metadata":{"trusted":true,"_uuid":"cbf635a0292922953fae0ac10c12034602d93d93"},"cell_type":"code","source":"def update(w, b, x_train, y_train, learning_rate,number_of_iterarion):\n    cost_list = []\n    cost_list2 = []\n    index = []\n    \n    # updating(learning) parameters is number_of_iterarion times\n    for i in range(number_of_iterarion):\n        # make forward and backward propagation and find cost and gradients\n        cost,gradients = forward_backward_propagation(w,b,x_train,y_train)\n        cost_list.append(cost)\n        # lets update\n        w = w - learning_rate * gradients[\"derivative_weight\"]\n        b = b - learning_rate * gradients[\"derivative_bias\"]\n        if i % 10 == 0:\n            cost_list2.append(cost)\n            index.append(i)\n            print (\"Cost after iteration %i: %f\" %(i, cost))\n            \n    # we update(learn) parameters weights and bias\n    parameters = {\"weight\": w,\"bias\": b}\n    plt.plot(index,cost_list2)\n    plt.xticks(index,rotation='vertical')\n    plt.xlabel(\"Number of Iterarion\")\n    plt.ylabel(\"Cost\")\n    plt.show()\n    return parameters, gradients, cost_list","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7694407d78bdc213fd9ea8121312f067fd2dfe5e"},"cell_type":"markdown","source":"Şimdiye kadar yaptığımız işlem modelimizi oluşturmak için eğitme aşamasıydı. Bundan sonra ise oluşturduğumuz modelin ne kadar verimli bir model olduğunu test aşamasına sıra geldi. Bunun için daha önce ayırdığımız test veri setimizi kullanarak modelimizin daha önce görmediği veride nasıl sonuç üreteceğini test edeceğiz."},{"metadata":{"trusted":true,"_uuid":"55aaedf839bbe239101869c067dd9231b7295f7c"},"cell_type":"code","source":"def predict(w,b,x_test):\n    # x_test is a input for forward propagation\n    z = sigmoid(np.dot(w.T,x_test)+b)\n    Y_prediction = np.zeros((1,x_test.shape[1]))\n    # if z is bigger than 0.5, our prediction is sign one (y_head=1),\n    # if z is smaller than 0.5, our prediction is sign zero (y_head=0),\n    for i in range(z.shape[1]):\n        if z[0,i]<= 0.5:\n            Y_prediction[0,i] = 0\n        else:\n            Y_prediction[0,i] = 1\n\n    return Y_prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0baec1ce75a66d8cc01eea0d6834b0094f2c64d"},"cell_type":"code","source":"def logistic_regression(x_train, y_train, x_test, y_test, learning_rate ,  num_iterations):\n    # initialize\n    dimension =  x_train.shape[0]  # that is 30\n    w,b = initialize_weights_and_bias(dimension)\n    # do not change learning rate\n    parameters, gradients, cost_list = update(w, b, x_train, y_train, learning_rate,num_iterations)\n    \n    y_prediction_test = predict(parameters[\"weight\"],parameters[\"bias\"],x_test)\n\n    # Print test Errors\n    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7f10ec8afdf411d62911ebaf2355a5b2e37e6b5"},"cell_type":"markdown","source":"modelimizi uyguladığımızda hangi iterasyonda nasıl sonuç aldığımızı aşağıda görmekteyiz. Görüldüğü gibi belirli bir iterasyondan sonra aynı sonuçları aldığımız görülmektedir. "},{"metadata":{"trusted":true,"_uuid":"ebcc788d7e360611085014a029b2d0b0c5aa068e"},"cell_type":"code","source":"logistic_regression(x_train, y_train, x_test, y_test,learning_rate = 1, num_iterations = 600)  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6fb5b58d1d0859624c0f0f7a782395b94cb9861"},"cell_type":"code","source":"logistic_regression(x_train, y_train, x_test, y_test,learning_rate = 1, num_iterations = 700) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3df91349ad7e28c89963312d23b649c467ad6e4b"},"cell_type":"code","source":"logistic_regression(x_train, y_train, x_test, y_test,learning_rate = 1, num_iterations = 800) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5db790df4850c882021cbb6a009e4778e864bd80"},"cell_type":"code","source":"logistic_regression(x_train, y_train, x_test, y_test,learning_rate = 1, num_iterations = 830) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"469fc209b3dcfca4d791e6046e280f319f6c1295"},"cell_type":"markdown","source":"Yukarıdaki aşamalarda tamamen işlemleri normal matematik kullanarak gerçekleştirdik. Fakat sklearn kütüphanesinin linear regression classification işlemi için kullanabileceğimiz bir kütüphanesi mevcut. Bu işlem için verimizi eğitim ve test veri seti olarak böldükten sonra doğrudan işlemi gerçekleştirebiliriz. Görüldüğü üzere bizim yukarıda bulduğumuz sonuçlara benzer değer üretilmiştir."},{"metadata":{"trusted":true,"_uuid":"7ff1271af0bd59492c1c37cb33adcca9561fb3f7"},"cell_type":"code","source":"y1=data.Outcome.values\nx1d=data.iloc[:,:8]\nx1=(x1d-np.min(x1d))/(np.max(x1d)-np.min(x1d))\nx_train1,x_test1,y_train1,y_test1=train_test_split(x1,y1,test_size=0.2,random_state=42)\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(x_train1,y_train1)\nprint(lr.get_params())\nprint(\"test accuracy {}\".format(lr.score(x_test1,y_test1)))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}