{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"## Introduction\n\nChronic Kidney disease is the gradual loss of function of the kidney with no symptoms being manifested. <sup>[1](https://en.wikipedia.org/wiki/Chronic_kidney_disease)</sup>  It's difficult to know the burden of the disease since they are no accurate diagnostic tests according to research done [here](https://www.sciencedirect.com/science/article/pii/S2214109X14700026). It could be characterized by [uremic frost](https://en.wikipedia.org/wiki/Uremic_frost); however,  careful diagnosis of the condition should be followed such as testing kidney function URI scan dripstick test for example the specific gravity -- low values(1.01 - 1.010) could mean that the patient has kidney damage, observation of the urine using microscopy and identification of [casts](https://slideplayer.com/slide/4381644/14/images/36/URINE+ANALYSIS+Microscopic+Examination+(Casts)) and other tests can help make a proper diagnosis.  \n\nIn this notebook, we'll use data with 25 features that could be indicative of chronic kidney disease to see if predictive modelling could help us figure out which patients have chronic kidney disease. You can read more about the dataset using this [link](https://www.kaggle.com/mansoordaku/ckdisease). Let's proceed to exploratory data analysis.\n"},{"metadata":{},"cell_type":"markdown","source":"I first import all the packages that could be useful in wrangling, visualization and statistical modelling. I apologise if there's a package here that I have imported but I haven't used it. It may have slipped my mind for some reason."},{"metadata":{"trusted":true,"_uuid":"06ced04fc676edd2e08ff3696fdf1d41ddc45a1c"},"cell_type":"code","source":"import numpy as np # numeric processing\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split  \nfrom IPython.display import HTML\nfrom sklearn.pipeline import Pipeline \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import f1_score, classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom functools import *\nfrom pandas_profiling import ProfileReport\nimport matplotlib.pyplot as plt\nfrom sklearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Turicreate is a machine learning library by apple. There's some functionality that I was interested in that I wanted to try. In future, I may add it to the notebook. If you want more information about the library.  Find for information [here.](https://github.com/apple/turicreate)"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install turicreate -q","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8371076d7acc9551566a43e74b7394e7cee9acf"},"cell_type":"markdown","source":"## Loading data and Exploratory data analysis\nIn this analysis, we'll do predictive modelling in hopes of finding a model which will be able to classify the patients appropriately."},{"metadata":{"trusted":true,"_uuid":"2cc5838ab0f199a55d34c3397cdd4aebacdc7554"},"cell_type":"code","source":"# load the dataset with pandas read_csv function\ndf = pd.read_csv('../input/kidney_disease.csv', index_col=\"id\")\n\n# give the dtypes of the columns if the data was squeeky clean\ndtypes = {\n    'id' : np.int32,\n    'age' : np.int32,\n    'bp' : np.float32,\n    'sg' : np.object, # category\n    'al' : np.object, # category # mistake\n    'su' : np.object, #category  # mistake\n    'rbc' : np.object, # category\n    'pc' : np.object, # category\n    'pcc' : np.object, # category\n    'ba' : np.object, # category\n    'bgr' : np.float32, \n    'bu' : np.int32,\n    'sc' : np.float32,\n    'sod': np.int32,\n    'pot' : np.float32,\n    'hemo' : np.float32,\n    'pcv' : np.int32,\n    'wc' : np.int32,\n    'rc' : np.int32,\n    'htn' : np.object,\n    'dm' : np.object,\n    'cad' : np.object,\n    'appet': np.object,\n    'pe' : np.object,\n    'ane' : np.object,\n    'class': np.object}\n\n# another way of reading in the datasets especially very big files like 1GB big\n# df2 = dd.read_csv('../input/kidney_disease.csv', dtype=dtypes)\n# id                400 non-null int64\n# age               391 non-null float64\n# bp                388 non-null float64\n# sg                353 non-null float64\n# al                354 non-null float64\n# su                351 non-null float64\n# rbc               248 non-null object\n# pc                335 non-null object\n# pcc               396 non-null object\n# ba                396 non-null object\n# bgr               356 non-null float64\n# bu                381 non-null float64\n# sc                383 non-null float64\n# sod               313 non-null float64\n# pot               312 non-null float64\n# hemo              348 non-null float64\n# pcv               330 non-null object\n# wc                295 non-null object\n# rc                270 non-null object\n# htn               398 non-null object\n# dm                398 non-null object\n# cad               398 non-null object\n# appet             399 non-null object\n# pe                399 non-null object\n# ane               399 non-null object\n# classification    400 non-null object","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86f5302202f6c75c3ca267134546b7bfcad2508b"},"cell_type":"code","source":"# see the first couple of observations and transpose 10 observations\n# think of it as rolling over your dataset\ndf.head(10).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8147c0cd06e839c52aefedf7803dfbfb20f59319"},"cell_type":"code","source":"# see the column names  \ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cf8d3a48f8cc2297ea58faeeee863df1d9bb90b"},"cell_type":"code","source":"# see a concise summary of the dataset\ndf.info()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 26 columns and a variable number of observations per feature/variable\n\n* 400 rows for each id - there could be missing data among the rows of the variable"},{"metadata":{"trusted":true,"_uuid":"36deca57707b5e2753f345965f9aa67c128216b8"},"cell_type":"code","source":"# display summary statistics of each column\n# this helps me confirm my assertion on missing data\ndf.describe(include=\"all\").transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at variables interractively \nprofile = ProfileReport(df)\n\nprofile","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff0e248390a7ec2a05f6054018edbdbf960c0ccd"},"cell_type":"markdown","source":"The good news is that we can work with the current state of the columns since they have been labelled consistently. Bad news is that we have a lot of missing data in this dataset. Let's proceed and find out the number of missing values per column and if the classes are balanced or unbalanced. The profiler did the work already but sometimes it is good to confirm it your own way."},{"metadata":{"trusted":true,"_uuid":"ad273d597403dba0a46afe9a3644d7163848c4e4"},"cell_type":"code","source":"# looking for the number of missing observations \n# In the code below a boolean is being tried on each observation asking if the observation is missing or not\n# then add all instances of NaN(Not a number) \nmissing_values = df.isnull().sum()\n\n# calculating the percentage of missing values in the dataframe\n# simply taking the sum of the values we got above dividing by the no of observations in the df\n# you could use len(df) instead df.index.size\nmissing_count_pct = ((missing_values / df.index.size) * 100)\n\n# see how many observations are missing\nprint(missing_count_pct)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c44a8e7918bac76434ac37707cab97de9966e08"},"cell_type":"code","source":"# take the missing count percentage and use boolean mask to filter out columns \n# whose observation threshold is greater than 25 percent \ncolumns_to_drop = missing_count_pct[missing_count_pct > 25].index\n\n# remove columns that meet that threshold and save result in column df_dropped\ndf_dropped = df.drop(columns_to_drop, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7659c4e3b2e99ea036cd87f7f03f729a104b924"},"cell_type":"code","source":"# number of columns remaining after filtering\ndf.columns.size - df_dropped.columns.size\n\n# only three columns are lost","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"799691483bd9f384cb56a1ddee206db7540883f8"},"cell_type":"markdown","source":"I really hate losing a few columns. I won't throw everything away. But, I will keep these columns while we are doing predictive modelling use the different variants of the datasets and see if there will be any boost in results. In the meantime, let's look at the code book to come up with a hypothesis to find out  which columns are the most important and converting the types of each column to another format that will speed up computation during training."},{"metadata":{"trusted":true,"_uuid":"88182665006d1808a0fca15bf498f446e70bd832"},"cell_type":"code","source":"# look at the code book on kaggle and write which columns could be useful here","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a1d351f78d9d05fb100a8bb6551e4ae9a7c3859"},"cell_type":"markdown","source":"According to the original site where we found data [here.](https://archive.ics.uci.edu/ml/datasets/Chronic_Kidney_Disease). I found the identity of the columns rather what the columns mean. I'll put a star on the columns i think are important from my background in medical laboratory science. Then the second run through this notebook we could explore only the columns i think are important and lastly use a technique called singular value decomposition to figure out which ones are the most important.\n\nage - age\n\nbp - blood pressure *\n\nsg - specific gravity *\n\nal - albumin *\n\nsu - sugar *\n\nrbc - red blood cells *\n\npc - pus cell*\n\npcc - pus cell clumps *\n\nba - bacteria*\n\nbgr - blood glucose random\n\nbu - blood urea*\n\nsc - serum creatinine\n\nsod - sodium\n\npot - potassium\n\nhemo - hemoglobin*\n\npcv - packed cell volume\n\nwc - white blood cell count*\n\nrc - red blood cell count*\n\nhtn - hypertension*\n\ndm - diabetes mellitus*\n\ncad - coronary artery disease*\n\nappet - appetite*\n\npe - pedal edema*\n\nane - anemia*\n\nclass - class* "},{"metadata":{"trusted":true,"_uuid":"9aee303f9e589217190e3035b8f79f471145283f"},"cell_type":"code","source":"# checking the types of the column to figure out the best next steps of conversion of data types\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2e921aa1cd5ef348b4029340da98ab6f95548ad"},"cell_type":"markdown","source":"Review the columns from the original codebook to determine the datatypes then make a schema which we can follow as i import the dataset"},{"metadata":{"trusted":true,"_uuid":"c42b729ab34624f3dbe208e66ab949f64e3b60c8"},"cell_type":"code","source":"# fix the columns to be of the categorical type\n# if the value is missing replace the NA with the word miss\nconstant_imputer = SimpleImputer(strategy=\"constant\", fill_value = \"miss\")\n\n# apply it to categorical columns\ndf[[\"rbc\"]] = constant_imputer.fit_transform(df[[\"rbc\"]])\ndf[[\"pcc\"]] = constant_imputer.fit_transform(df[[\"pcc\"]])\n\n# converting the types to be categorical\n# Go ahead and use a function here\ndf['rbc'] = df['rbc'].astype(\"category\")\ndf['pc'] = df['pc'].astype(\"category\")\ndf[\"pcc\"] = df['pcc'].astype(\"category\")\ndf['ba'] = df['ba'].astype(\"category\")\ndf['appet'] = df['appet'].astype(\"category\")\ndf['pe'] = df['pe'].astype(\"category\")\ndf['ane'] = df['ane'].astype(\"category\")\ndf['classification'] = df['classification'].astype(\"category\")\ndf['htn'] = df['htn'].astype(\"category\")\ndf['dm'] = df['dm'].astype(\"category\")\ndf['cad'] = df['cad'].astype(\"category\")\n\n\n# confirm the dtypes now\ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# seeing the columns in list form thinking mode\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make a copy of the whole dataset\ndf_copy = df.copy()\n\n# remove the target column for the other uses in the next steps\n#df = df.drop(\"classification\", axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d71ec390afb6967b15b2d831d97b25238012fee4"},"cell_type":"code","source":"# using a boolean to figure out which columns are of type object and numeric to do other preprocessing \n# in the workflow\nobject_columns = df.dtypes == \"object\"\nnumeric_columns = df.dtypes == \"float64\"\ncategory_columns = df.dtypes == \"category\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use regular expressions to fix it and this is supposed to be one of the first steps after df.dtypes command. If it's categorical \n# you can replace it with anything you want here I use -999 to replace the data entries the tab character to flag them as outliers.\n# I change the dtypes so to 32 bit to save memory\n\ndf['pcv'] = df['pcv'].replace(\"\\t?\",-999).fillna(0).astype(\"int32\") # use  str.replace on column to something meaningful\ndf['wc'] = df['wc'].replace(\"\\t?\", -999).fillna(0).astype(\"int32\") # use  str.replace on column to something meaningful\ndf['rc'] = df['rc'].replace(\"\\t?\", -999).fillna(0).astype(\"float32\") # use  str.replace on column to something meaningful\n\n# exploring another imputation strategy that uses the median \n# mean_imputer = SimpleImputer(strategy=\"median\")\n# df[\"pcv\"] = mean_imputer.fit_transform(df[\"pcv\"])\n# df[\"wc\"] = mean_imputer.fit_transform(df[\"wc\"])\n# df[\"rc\"] = mean_imputer.fit_transform(df[\"rc\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7420853ce27348770e98d5f414c07feb92513eed"},"cell_type":"code","source":"# write code to extract columns of the type object and numeric\n# Make a boolean mask for categorical columns\ncat_mask_obj = (df.dtypes == \"object\") | (df.dtypes == \"category\")\n\n# Get list of categorical column names\ncat_mask_object = df.columns[cat_mask_obj].tolist()\n\n# now for numerical columns\n# anything that was parsed as float64 is numeric: make a boolean mask for that\ncat_mask_numeric = (df.dtypes == \"float64\")\ncat_mask_numeric = df.columns[cat_mask_numeric].tolist()\n\n# see the result in a combined list: to the left categorical and the right we have numeric columns\nprint(cat_mask_object, \"\\n\", cat_mask_numeric)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert all instances of the float 64 to float 32 to speed up computation in the subsequent steps\n# remove all the missing values and make sure that they are all numeric\nnumeric_columns_float32 = df[cat_mask_numeric].astype(\"float32\").fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#it's worked\nnumeric_columns_float32.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Task: split the category columns and object columns to the right type\n# you can import the dataset to have the right types too upon import\n# you can do this the next time you have time to continue working on this add it as comment though","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"They are some columns that are wrongly parsed due to the NAs. They include: pcv(numerical int32), rc(numerical int32). I can either interpolate the missing columns depending how they'll look like in a plot or use mean/median to find the value."},{"metadata":{"trusted":true},"cell_type":"code","source":"# it makes sense that they are some individuals who were not sampled therefore filling the whole dataset with NAs makes sense\n# these two columns have data entry problems\n# use regular expressions to fix it and this is supposed to be one of the first steps after df.dtypes command. If it's categorical \n# you can replace it with anything you want\n#df['pcv'] = df['pcv'].fillna(0, inplace = True)\n#df['rc'] = df['rc'].fillna(0, inplace = True)\n#df['wc'] = df['wc'].fillna(0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# finding the number of null or NA values in the columns\npd.isnull(df).sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the dtypes once more \ndf.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# concatentate the numeric columns with the category columns to build the full dataset and then X and Y\n# remove\ndf[cat_mask_object] = constant_imputer.fit_transform(df[cat_mask_object])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for missing values\nprint(df[cat_mask_object].isnull().sum())\nprint(\"*\" * 100)\nprint(numeric_columns_float32.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# bring the columns together with pd.concat\ndf_clean = pd.concat([numeric_columns_float32, df[cat_mask_object]], axis = 1)\n\n# check the shape of the columns\ndf_clean.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# just see the first 10 observations\ndf_clean.head(10)\n# HTML(df_clean.to_html()) see the whole dataframe in HTML format","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now see the bottom 10\ndf_clean.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"HTML(df.to_html()) # just looking for something I may have missed in the pandas profiling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# some further cleaning is required to remove the \\t characters is a couple of columns replacing the instances with the standard formating \n# classification, cad,  dm\ndf_clean['classification'] = df_clean['classification'].replace(\"ckd\\t\",\"ckd\")\ndf_clean['cad'] = df_clean['cad'].replace(\"\\tno\",\"no\")\ndf_clean['dm'] = df_clean['dm'].replace(\"\\tno\",\"no\")\ndf_clean['dm'] = df_clean['dm'].replace(\"\\tyes\", \"yes\")\ndf_clean['dm'] = df_clean['dm'].replace(\" yes\", \"yes\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# subsetting columns with another boolean mask for categorical columns and object columns\ncat_mask_obj2 = (df_clean.dtypes == \"object\") | (df_clean.dtypes == \"category\")\n\n# Get list of categorical column names\ncat_mask_object2 = df_clean.columns[cat_mask_obj2].tolist()\n\n# remove the column classification \ncat_mask_object2.remove(\"classification\")\n\n# see what columns are left\nprint(cat_mask_object2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# look into the XGBoost course to figure out how the categorical imputer works\n# combine everything and use DictVectorizer for one hot encoding and label encoding\n\n# conversion of our dataframe into a dictionary so as to use DictVectorizer\n# this function is mostly used in text processing\ndf_dict = df_clean[cat_mask_object2].to_dict(\"records\")\n\n# Make a DictVectorizer: use documentation to learn how it works\n# In short, it speeds up one hot encoding with meaningful columns created\n# we don't want a sparse matrix right?\ndv = DictVectorizer(sparse = False)\n\n# Apply fit_transform to our dataset\ndf_encoded = dv.fit_transform(df_dict)\n\n# see 10 rows\nprint (df_encoded[:10,:])\nprint (\"=\" * 100) # just formatting to distinguish outputs\n\n# print the vocabulary that is, the columns of the dataset, note that order changes\n# upon transformation\nprint(dv.vocabulary_)\nprint (\"=\" * 100) # more formatting\n\nprint(df_encoded.shape) # number of rows and columns for the encoded dataset\nprint(df_clean[cat_mask_object2].shape) # number of rows and columns for the original dataset\nprint(\"After doing the transformation the columns increase to 21.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# You can try\n# make a pipeline to merge the encoding as well as the visualization\n# Use t-SNE and or PCA to see the differences between groups this will be the EDA step \n# make a train and test split go through the slides for how to win kaggle competitions and test the ideas\n# make the next step a pipeline object like in the xgboost course and try random forest, xgboost and decision tree classifier\n# later use the ensembling techniques: Try all the ensembling techniques you know.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# see the transformed dataframe with all the missing values imputed\ndf_clean[cat_mask_numeric]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# simply taking the vectorized columns and the numeric columns and bringing them together\n# to make an array for a classifier\nconcat_cols = np.hstack((df_encoded, df_clean[cat_mask_numeric].values))\n\n# another version that is in dataframe format\n# make a dataframe with the encoded features and give the columns names from the dictVectorizer\ndf_cat_var = pd.DataFrame(df_encoded, columns=dv.get_feature_names())\n\n# combine the columns together with the categorical features i.e add columns to the numerical dataframe with other dataframe with the categorical and object data types\nconcat_cols_df = pd.concat([df_clean[cat_mask_numeric], df_cat_var], axis=1)\nconcat_cols.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the final dataframe we'll use for classification\nconcat_cols_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now get the target variable into a numeric form\n# there's a simpler step where you can use map instead  y = df_clean[\"classification\"].map(lambda val1: 1 if val1 == \"ckd\" else 0)\n# y = y.values\ncol_preprocess = df_clean[\"classification\"].replace(\"ckd\", 1) \nfinal_col_preprocess = col_preprocess.replace(\"notckd\", 0)\ny = final_col_preprocess.values\nprint(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confirm if the shape of the vector and matrix\nprint(concat_cols.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now that we have both matrices we can see the distribution of the target variable to know what to do next\n# when it comes to preprocessing \nfinal_col_preprocess.reset_index()[\"classification\"].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The patients with chronic kidney disease are more than those who don't have .63 ckd and .38 for nonckd\n# The dataset is imbalanced, we can't use the regular accuracy as an evaluation metric instead confusion matrix and F1 score\n# we don't want more of the train set in either so I guess stratify is good option\n# I changed the 0.5:0.5 to 0.75:0.25\nx_train, x_test, y_train, y_test = train_test_split(concat_cols_df, y, test_size = 0.25, stratify = y, random_state=1243)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if the dimensionality is the same for the feature and target set (train)\nprint(\"Is the number of rows the same between the features and the target?\") \nassert x_train.shape[0] == y_train.shape[0]\nprint (True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if the dimensionality is the same for the feature and target set (test)\nprint(\"Is the number of rows the same between the features and the target?\") \nassert x_test.shape[0] == y_test.shape[0]\nprint (True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now checking if the target variable is balanced in the train set\npd.Series(y_train).value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# They are still unbalanced now. Therefore, will have to use the f1 score and change the class weight of the algorithms used like logistic regression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# look at the instances of the labels 0 and 1 \npd.Series(y_test).value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normal scikit learn paradigm of specify, fit and predict for logistic regression or continuos perceptron\nclf_lr1 = LogisticRegression(class_weight=\"balanced\", random_state=1243)\n\nclf_lr1.fit(x_train,y_train)\n\npreds1 = clf_lr1.predict(x_test)\n\n# using f1 score instead of other metrics\nscore_vote1 = f1_score(preds1, y_test)\nprint('F1-Score: {:.3f}'.format(score_vote1))\n\n# Calculate the classification report\nreport1 = classification_report(y_test, preds1,target_names=[\"notckd\", \"ckd\"])\nprint(report1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Specify the Decision tree classifier: asks a bunch of if-else statements to come up with a decision\n# adjust the number of min samples leaf based on the game 20 questions (From deep learning for coders by Jeremy Howard)\nclf_dt2 = DecisionTreeClassifier(class_weight = \"balanced\",random_state=1243)\n\nclf_dt2.fit(x_train,y_train)\n\npreds2 = clf_dt2.predict(x_test)\n\nscore_vote2 = f1_score(preds2, y_test)\nprint('F1-Score: {:.3f}'.format(score_vote2))\n\n# Calculate the classification report\nreport2 = classification_report(y_test, preds2, target_names=[\"notckd\", \"ckd\"])\nprint(report2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show model parameters\nclf_dt2.get_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalize data functions\n# log, z scores(standardized_data), dimensionality reduction with PCA(dim_reduction) and making a function that combines another function(compose2)\ndef skew (data):\n    skewed_data = np.log(data)\n    return skewed_data\n\n\ndef standardized_data(data):\n    scaler = StandardScaler()\n    scaler.fit(data)\n    scaled_data = scaler.transform(data)\n    return scaled_data\n\ndef dim_reduction(data):\n    pca = PCA(n_components=2)\n    return pca.fit_transform(data)\n\n\ndef compose2(f, g):\n    return lambda *a, **kw: f(g(*a, **kw))\n\ndef compose(*fs):\n    return reduce(compose2, fs)\n\n\n# returns an error due to the points being too small\nnormalize_data = compose2(skew, standardized_data)\n\n# mean of 0 and a std 1 for all the columns\nscaled_x_train = standardized_data(x_train)\nscaled_x_test = standardized_data(x_test)\n\n# reduce dimensionality to 2\ntransform_data = compose2(standardized_data, dim_reduction)\ndim_red_x_train = transform_data(x_train)\ndim_red_x_test = transform_data(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic regression just a modified perceptron algorithm that uses the sigmoid function therefore an continous perceptron\nclf_lr3 = LogisticRegression(class_weight=\"balanced\",random_state=1243)\n\nclf_lr3.fit(scaled_x_train,y_train)\n\npreds3 = clf_lr3.predict(scaled_x_test)\n\nscore_vote3 = f1_score(preds3, y_test)\nprint('F1-Score: {:.3f}'.format(score_vote3))\n\n# Calculate the classification report\nreport3= classification_report(y_test, preds3,target_names=[\"notckd\", \"ckd\"])\nprint(report3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic regression but the features have been compressed\nclf_lr5 = LogisticRegression(class_weight=\"balanced\",random_state=1243)\n\nclf_lr5.fit(dim_red_x_train,y_train)\n\npreds5 = clf_lr5.predict(dim_red_x_test)\n\nscore_vote5 = f1_score(preds5, y_test)\nprint('F1-Score: {:.3f}'.format(score_vote5))\n\n# Make a classification report\nreport5 = classification_report(y_test, preds5,target_names=[\"notckd\", \"ckd\"])\nprint(report5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision tree classifier but with scaled features\nclf_dt4 = DecisionTreeClassifier(class_weight=\"balanced\", random_state=1243, min_samples_leaf=25)\n\nclf_dt4.fit(scaled_x_train,y_train)\n\npreds4 = clf_dt4.predict(scaled_x_test)\n\nscore_vote4 = f1_score(preds4, y_test)\nprint('F1-Score: {:.3f}'.format(score_vote4))\n\n# Make a classification report\nreport4 = classification_report(y_test, preds4, target_names=[\"notckd\", \"ckd\"],)\nprint(report4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# take the coefficient and see the dimension\nclf_lr1.coef_.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# helps with visualizing the decision function for the classifier\ndef plot_points(features, labels):\n    '''\n    \n    '''\n    X = np.array(features) # convert data into an numpy array: features\n    y = np.array(labels) # convert data into an numpy array: labels\n    ckd = X[np.argwhere(y==1)] # get all instances where the features are for individuals with ckd\n    notckd = X[np.argwhere(y==0)] # get all instances where the features are for individuals without ckd\n    plt.scatter([s[0][0] for s in ckd],\n                [s[0][1] for s in ckd],\n                s = 30,\n                color = 'cyan',\n                edgecolor = 'k',\n                marker = '^')\n    plt.scatter([s[0][0] for s in notckd],\n                [s[0][1] for s in notckd],\n                s = 30,\n                color = 'red',\n                edgecolor = 'k',\n                marker = 's')\n    plt.xlabel('aack')\n    plt.ylabel('beep')\n    plt.legend(['ckd','notckd'])\ndef draw_line(a,b,c, color='black', linewidth=2.0, linestyle='solid', starting=0, ending=3):\n    # Plotting the line ax + by + c = 0\n    x = np.linspace(starting, ending, 1000)\n    plt.plot(x, -c/b - a*x/b, linestyle=linestyle, color=color, linewidth=linewidth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trying to visualize the function but this didn't work so well\nX = np.array(concat_cols)\ny = np.array(y)\nckd = X[np.argwhere(y==0)]\nnotckd = X[np.argwhere(y==1)]\n\nplt.scatter([s[0][0] for s in ckd],\n                [s[0][1] for s in ckd],\n                s = 25,\n                color = 'cyan',\n                edgecolor = 'k',\n                marker = '^')\nplt.scatter([s[0][0] for s in notckd],\n                [s[0][1] for s in notckd],\n                s = 25,\n                color = 'red',\n                edgecolor = 'k',\n                marker = 's')\nplt.xlabel('ckd')\nplt.ylabel('notckd')\nplt.legend(['ckd','notckd'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This needs some fixing: Please ignore this for now.\nplot_points(scaled_x_train, y_train)\ndraw_line(1,1, clf_lr1.fit_intercept)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check this out https://github.com/luisguiserrano/manning/blob/master/Chapter%205%20-%20Logistic%20Regression/Coding%20the%20Logistic%20Regression%20Algorithm.ipynb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting feature importance for the Decision tree\n# grab the column names as a list\nfeatures = concat_cols_df.columns\n\n# get the feature importances\nimportant_features = clf_dt2.feature_importances_\n\n# find the indices of a sorted array\nfeature_indices = np.argsort(important_features)\n\n# make a plot \nplt.title('Feature Importances Decision Tree')\nplt.xticks(fontsize=6, rotation = 45)\nplt.barh(range(len(feature_indices)), important_features[feature_indices], color='g', align='center')\nplt.yticks(range(len(feature_indices)), [features[i] for i in feature_indices], fontsize = 6)\nplt.xlabel('Relative Importance')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reviewing feature importance using the logistic regression and the C parameter\n# grab the coefficients and transpose the array\n# label the C parameter\nplt.plot(np.sort(clf_lr1.coef_.T), 'o', label=\"C=1\",color = \"g\") \nplt.xticks(range(concat_cols_df.shape[1]), concat_cols_df.columns, rotation=90)\nplt.hlines(0, 0, concat_cols_df.shape[1])\nplt.title(\"Examination of feature importance\")\nplt.xlabel(\"Coefficient index\")\nplt.ylabel(\"Coefficient magnitude\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pydotplus -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# draw the decision tree \n# add more comments for this\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\ndot_data = StringIO()\nexport_graphviz(clf_dt2, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True, feature_names = concat_cols_df.columns, class_names =[\"notckd\", \"ckd\"])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \nImage(graph.create_png())\n\n# look at hemo(hemoglobin), sg(specific gravity), al(albumin), sod(sodium), rbc=normal(red blood cells), htn=yes(hypertension), bu(blood urea)\n# dm (diabetes mellitus)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. At the start if the hemoglobin levels were less than or equal to 12.85 on average the samples 300 -- this is every sample of the dataset is split to the left side and hemoglobin levels are less than 12.85 then the level of specific gravity is considered. These features are both looked into the [URI strip](https://en.wikipedia.org/wiki/Urine_test_strip) test done in hospitals can be done at home too. \n\n2. To the left we now see sodium on average less than or equal to 143.5 being considered. Moving along we see that sodium and specific gravity being considered. This also makes sense especially hemoglobin and specific gravity which are part of the tests done on the kidney function test in a URI strip. Sodium and Potassium are reabsorbed mostly by the kidney but here some is seen maybe they are some other conditions the patient is suffering from. Age less than or equal to 43.2 on average for some patients did not have chronic kidney disease whereas, three had it and their age surpassed 43 to a small extent age can be considered as determining factor. Staying on the left side of the tree we see more patients being classified as having chronic disease as an example after the division by specific gravity 141 samples were placed there without any further subdivision -- 141 in number. On the other hand, for those whose hemoglobin levels mean were greater than to 2.9, 21 samples whose samples but the there's something interesting going on since the gini index (measure of diversity in a set) is negative, normally 0 means that the same is pure and you'll find only those with chronic kidney disease here. But on the other side, where rbc=normal, the condition is true that is, the patients have less rbc=normal and the hemoglobin is less than 2.9, we see that 4 patients were placed in group of having chronic kidney disease and the other 2 didn't have it completing the left side of the tree.\n\n3. Let's move to the False subdivision where the hemoglobin for patients in this group was more than 12.85 at the root of the tree. In this group, the specific gravity is still being considered whose mean value 1.017 -- this is normal range if using a URI strip test. But later there's a subdivision less than 0.505, this is very low beyond the normal threshold and as you can see 16 patients were classified as having chronic kidney disease. Another branch looks at if the patient has diabetes mellitus (pancreas cells don't release enough insulin or insulin resistance) less than half of the patients, 5 were classified as not having chronic kidney disease and one had chronic kidney disease. Normally a consequence of diabetes mellitus is chronic kidney disease due to the predisposing symptoms of diabetes mellitus. \n\n4. In the last branch, to the further right we see samples moving from a specific gravity here the specific gravity is greater than 1.017 this is also beyond in the normal threshold then the dm=yes where there are 105 samples, the specific gravity was in the normal range to my knowledge and 104 samples were classified as not having chronic kidney disease and lastly one had chronic kidney disease in the sample.\n\n5. Most of the leaf nodes have a gini index of 0.0 this means the elements in the sample had one of that class in the leaf node this shows that some of the features selected by this decision tree could be really good features to be looked into during diagnosis or progression of a disease to know if the patients could have chronic, acute kidney disease as well as looking at other features like we'll look into when looking at the Logisitic regression classifier. However, the gini index -0.0 is still worrisome because it doesn't make a lot of sense negative 0? it could be a bug in the decision tree implementation or something else. You can find out what's up with that? trying a random forest would be interesting too because the feature dm=yes which means the patient was the group with diabetes mellitus or not seems to be reemerging at some points of the tree."},{"metadata":{"trusted":true},"cell_type":"code","source":"# interpreting the logistic regression model\nclf_lr1.predict(x_test[:1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking out the intercept this means that if every feature is 0 what the prediction would be\nclf_lr1.intercept_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking out the coefficients we'll multiply this by the every value that corresponds to that feature e.g clf_lr1.coef[0] * age[0]\nclf_lr1.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking out the available columns\nconcat_cols_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make a dataframe to help easily grab the coefficients for writing the formula and visualizing the data\n# transpose to see it clearly \nimportant_features2 = clf_lr1.coef_[0]\ncolumn_coef = pd.DataFrame(list(zip(important_features2.T.ravel(\"C\").tolist(), features)),columns = [\"coefficient\", \"feature\"])\ncolumn_coef[\"coefficient\"] = column_coef[\"coefficient\"].astype(\"float32\")\ncolumn_coef.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# arrange the coeffiecients in descending order to know the most likely features\ncolumn_coef.sort_values(by=[\"coefficient\"], axis = 0, inplace=True, ascending=False)\nprint(column_coef.head(10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"missing rbcs was a most important feature. I will not take that since it mostly has missing values in fact 152 sample patient results are missing. I think the best course of action is to get the data from the patients about RBCs or drop the column entirely for modelling -- there's an issue with that rationale since some patients may not come back or can't afford to do the test. al - albumin levels, sc - serum creatinine, dm=yes the patient having diabetes mellitus and htn - hypertension these are all crucial kidney function tests or predisposing features of a patient that could be having chronic kidney disease based on my background. The additional features that have been highlighted are also important but have lower values as compared to the ones mentioned prior."},{"metadata":{},"cell_type":"markdown","source":"In a more technical perspective these features make sense for instance the albumin which is a large protein that is not supposed to pass through as a glomerular filtrate in the proximal convoluted tubule to the urine since the patient could have a high blood pressure yet another predisposing feature that could fuel kidney diseases either acutely or chronicly to the patients being classified as having chronic kidney disease at least for those features. How does hypertension do it? If the blood pressure is high according to the anatomy of the kidney we'll see a faster rate of filtration and the pressure may damage the glomerulus. Imagine trying to use a sieve with a fast flowing liquid and particules just a bit larger than the sieve. Over a long period of time some of those particles may pass through. "},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test[:1] # see all the features in the first column ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test.shape # see the number of rows and columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# writing the logistic regression formula\n# Bo intercept, B1 x1n\n# writing the denominator based on the wikipedia entry https://en.wikipedia.org/wiki/Logistic_regression\n# 1/ np.exp(-(weight * coefn + clf_lr1.intercept_))\nweights_int_bias = clf_lr1.intercept_ + (column_coef.coefficient[0] * 60.0) + (column_coef.coefficient[1] * 60.0) + (column_coef.coefficient[2] * 1.01) + (column_coef.coefficient[3] + 3.0) + (column_coef.coefficient[4] + 1.0) + (column_coef.coefficient[5] * 288) + (column_coef.coefficient[6] * 36.0) + (column_coef.coefficient[7] * 1.7) + (column_coef.coefficient[8] * 130) + (column_coef.coefficient[9] * 3.0) + (column_coef.coefficient[10] * 7.9) + (column_coef.coefficient[11] * 0.0) + (column_coef.coefficient[12] * 0.0) + (column_coef.coefficient[13] * 1.0) + (column_coef.coefficient[14] * 0.0) + (column_coef.coefficient[15] * 0.0) + (column_coef.coefficient[16] * 1.0) + (column_coef.coefficient[17] * 0.0) + (column_coef.coefficient[18] * 1.0) + (column_coef.coefficient[19] * 0.0) + (column_coef.coefficient[20] * 0.0) + (column_coef.coefficient[21] * 1.0) + (column_coef.coefficient[22] * 0.0) + (column_coef.coefficient[23] * 0.0) + (column_coef.coefficient[24] * 1.0) + (column_coef.coefficient[25] * 0.0) +  (column_coef.coefficient[26] * 0.0) + (column_coef.coefficient[27] * 1.0) + (column_coef.coefficient[28] * 1.0) + (column_coef.coefficient[29] * 0.0) + (column_coef.coefficient[30] * 0.0) + (column_coef.coefficient[31] * 0.0) + (column_coef.coefficient[32] * 0.0) + (column_coef.coefficient[33] * 1.0) + (column_coef.coefficient[34] * 0.0) + (column_coef.coefficient[35] * 0.0) + (column_coef.coefficient[36] * 0.0) + (column_coef.coefficient[37] * 0.0) + (column_coef.coefficient[38] * 0.0) + (column_coef.coefficient[39] * 1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add the sigmoid function to make the decision\n# One way to make the loss function\ndef sigmoid(x):\n    return np.exp(x)/(1+np.exp(x))\n\n\nprint(sigmoid(weights_int_bias))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# according to wikipedia implementation: sigmoid function\n1 / (1 + np.exp(-weights_int_bias))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Get a single row of features and add it onto the model above and confirm if you get the same result as above."},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_lr1.predict(x_test[:1]) # has chronic kidney disease for the 147th id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Conclusion:\n---    \nI think I was onto something because if you review the feature importance the **hemoglobin**, **albumin**, **hypertension**, **serum creatinine** and **specific gravity** were the most important features. I've done some tests with a uri strip to figure out if someone has an issue with their kidney and these are the parameters that point out to dysfunction of the kidney. Others like having diabetes mellitus though this is related to pancreatic beta cells issues, sodium levels taken up again by the kidney and age could also be indicators. The decision tree is also interesting but could use some tuning. The intercept says that on default the patient doesn't have chronic disease as well but the decision tree the start was hemoglobin. In future I will update the plots to show how the decision was made better. Otherwise, I'd discuss these results with a medical practitioner like a urologist. What do you think?"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}