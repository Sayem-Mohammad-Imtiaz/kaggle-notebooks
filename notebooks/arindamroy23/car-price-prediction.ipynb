{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Car Price Prediction\n\n##### Hi, \n###### Welcome to this notebook! The objective of this notebook is to best understand linear regression. The data used in this repo has been taken from Kaggle (link below). \nhttps://www.kaggle.com/hellbuoy/car-price-prediction\n\n\n### About project Mechanic of Machine Learning:\nI am a mechanical engineer by education. Now, I want to deep dive in the world of Machine Learning, hence the name, mechanic of ML :D. I have taken up this project to understand the in-depth mathematics involved in regularly used ML algorithms. Under this project, I will be sharing useful material and links as I explore this domain. The objective is to learn and spread the same. Stay tuned to my GitHub for updates!\n\n### Business Case: \nA top manufacturer of automobiles has realized the need to provide real time cost estimates to consumers when configuring their car through their website. Build an ML based model to facilitate this requirement\n### Notebook objectives:\n\n* To understand and implement linear regression \n* To visualize and understand the data\n* To select features which can best predict costs based on attribute-value pair. \n* To derive conclusions from the data and suggest solutions for business.\n\n### References:\n* Linear Regression and Gradient Descent: https://www.youtube.com/watch?v=4b4MUYve_U8&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=2\n* Stochastic Gradient Descent: https://www.youtube.com/watch?v=vMh0zPT0tLI\n* Gradient Descent: https://www.youtube.com/watch?v=sDv4f4s2SB8\n* Notes and source code: https://github.com/ArindamRoy23/Car_Price_Prediction_Linear_Regression_Mechanic-of-ML.git\n"},{"metadata":{},"cell_type":"markdown","source":"## Index:\n1. Exploratory Analysis and Visualization\n2. Observations \n3. Running an initial analysis without removing outlier values\n4. Running an analysis after removing outlier values\n5. Conclusion "},{"metadata":{},"cell_type":"markdown","source":"### Exploratory Analysis and Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing packages\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_df = pd.read_csv('../input/car-price-prediction/CarPrice_Assignment.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(input_df['price'],kde=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Taking only progressing parameters as we only have linear regression models to fit. \ninput_df = input_df[['symboling', 'wheelbase', 'carlength', \n                    'carwidth','carheight',  'curbweight',\n                    'cylindernumber', 'enginesize','boreratio','stroke','compressionratio',\n                    'horsepower', 'peakrpm', 'citympg', 'highwaympg','price']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.show()\n(sns.heatmap(input_df.corr()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(input_df.corr()[input_df.corr().apply(lambda x:x**2 )>.25].fillna(0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('High positive corelation with price:',list(input_df.corr()[(input_df.corr().apply(lambda x:x**2 )>.25 )&(input_df.corr()>0)]['price'].dropna().index))\nprint('High negative corelation with price:',list(input_df.corr()[(input_df.corr().apply(lambda x:x**2 )>.25 )&(input_df.corr()<0)]['price'].dropna().index))\npos_cor_list = list(input_df.corr()[(input_df.corr().apply(lambda x:x**2 )>.25 )&(input_df.corr()>0)]['price'].dropna().index)\nneg_cor_list = list(input_df.corr()[(input_df.corr().apply(lambda x:x**2 )>.25 )&(input_df.corr()<0)]['price'].dropna().index)\nto_keep_list = pos_cor_list + neg_cor_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_df = input_df[to_keep_list]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Observations:\n\n1. Following parameters are highly positively corelated with price:\n    wheelbase, car length/base/height, curb weight, engine size, bore ratio & horsepower\n2. Following parameters are highly negatively corelated with price:\n    citympg,highwaympg\n3. The dataset is relatively small. Thus, loosing data might affect the model prediction. \n"},{"metadata":{},"cell_type":"markdown","source":"### Running an initial analysis without removing outlier values: "},{"metadata":{"trusted":true},"cell_type":"code","source":"X = input_df.drop('price',axis=1)\ny = input_df['price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = LinearRegression().fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = reg.predict(X_test)\nprint('Mean error:',int(mean_absolute_error(y_test, y_pred)))\nprint('Percentage error: ~(+/-)',int((mean_absolute_error(y_test, y_pred)/input_df['price'].mean())*100)/2,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Increasing the test set:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = input_df.drop('price',axis=1)\ny = input_df['price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = LinearRegression().fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = reg.predict(X_test)\nprint('Mean error:',int(mean_absolute_error(y_test, y_pred)))\nprint('Percentage error: ~(+/-)',int((mean_absolute_error(y_test, y_pred)/input_df['price'].mean())*100)/2,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Running an analysis after removing outlier values: "},{"metadata":{"trusted":true},"cell_type":"code","source":"input_df.sort_values('price',ascending=False)\nclean_df = input_df[input_df['price']<input_df['price'].mean()+2*input_df['price'].std()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = clean_df.drop('price',axis=1)\ny = clean_df['price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = LinearRegression().fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = reg.predict(X_test)\nprint('Mean error:',int(mean_absolute_error(y_test, y_pred)))\nprint('Percentage error: ~(+/-)',int((mean_absolute_error(y_test, y_pred)/clean_df['price'].mean())*100)/2,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Increasing the test set:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = clean_df.drop('price',axis=1)\ny = clean_df['price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = LinearRegression().fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = reg.predict(X_test)\nprint('Mean error:',int(mean_absolute_error(y_test, y_pred)))\nprint('Percentage error: ~(+/-)',int((mean_absolute_error(y_test, y_pred)/clean_df['price'].mean())*100)/2,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusions:\n\n1. The model is predicting with an accuracy in the range of (+/-) 10% with orignal data.\n2. The model is predicting in the range of (+/-) 6.5% with cleaned data aftrer removing outlier values.\n3. As expected, shrinking the train size has adverse effect on the predictions as the dataset is small in nature. \n4. This model can further be integrated in the client portal to give a range of predictions to the customers. \n5. More dataponts can help improve the accuracy of the model.\n6. Every run might have a different result with significantly changed output values. This is due to the train test split. More data will help brigge this gap.  "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}