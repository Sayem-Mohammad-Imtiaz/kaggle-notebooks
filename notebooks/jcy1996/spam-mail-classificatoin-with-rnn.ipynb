{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook is made for a light practice in **computational-linguistics class**. Feel free to use! \nI'd also appreciate any comment, feedback, and question :D"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data preparation\nimport pandas as pd\n\ndf = pd.read_csv('../input/sms-spam-collection-dataset/spam.csv', encoding='latin1')\ndf.tail(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[['v1', 'v2']]\ndf.rename({'v1': 'target', 'v2': 'text'}, axis='columns', inplace=True)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[['text']]\ny = df[['target']]\nX.tail(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.tail(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check null data\nprint(df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Check whether this data is imbalanced or not\nplt.figure(figsize=(20, 10))\ndf['target'].value_counts().plot(kind='bar')\nplt.title('Ham versus Spam ratio')\nplt.show()\n\ndf.groupby('target').count().style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# stopwords\nfrom tensorflow.keras.preprocessing.text import Tokenizer\n\ntk = Tokenizer()\ntk.fit_on_texts(X.text)\n\ntotal_count = len(tk.word_index)\nrare_count = 0\n\nfor k, v in tk.word_counts.items():\n    if (v < 2):\n        rare_count = rare_count + 1\n\nprint('total number of words : ', total_count, \n      'number of sparse words : ', rare_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tk = Tokenizer(num_words=total_count-rare_count+1)\ntk.fit_on_texts(X.text) \nX_data = tk.texts_to_sequences(X.text) \nX_data[0][:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vocabularay\n\nsent = [None] * 5\nfor k, v in tk.word_index.items():\n    if v == 50:\n        sent[0] = k\n    if v == 469:\n        sent[1] = k\n    if v == 841:\n        sent[2] = k\n    if v == 751:\n        sent[3] = k\n    if v == 657:\n        sent[4] = k\nprint(sent)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Frequency top5 in spam\nX_spam = df[df['target'] == 'spam']['text']\ntk2 = Tokenizer()\ntk2.fit_on_texts(X_spam)\nsequences = tk2.texts_to_sequences(X_spam)\nrank5 = sorted(tk2.word_counts.items(), key=lambda item: item[1], reverse=True)[:5]\n\nprint('spam Top 5')\nfor i, (w, f) in enumerate(rank5):\n    print('{}위 : '.format(i+1) + w, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Frequency top5 in ham\nX_ham = df[df['target'] == 'ham']['text']\ntk2 = Tokenizer()\ntk2.fit_on_texts(X_ham)\nsequences = tk2.texts_to_sequences(X_ham)\nrank5 = sorted(tk2.word_counts.items(), key=lambda item: item[1], reverse=True)[:5]\n\nprint('ham Top 5')\nfor i, (w, f) in enumerate(rank5):\n    print('{}위 : '.format(i+1) + w, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport seaborn as sns\n\n# visualization\nmail_length = [len(x) for x in X_data] # 중복이 좀 많음\n\nprint('max : ', np.max(mail_length))\nprint('mean : ', np.mean(mail_length))\nprint('-' * 100)\n\nplt.figure(figsize=(10, 6))\nsns.distplot(mail_length, bins=50)\nplt.title('Distribution')\nplt.xlabel('Word count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# last preparation\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n\nX = pd.DataFrame(pad_sequences(X_data, maxlen=183))\ny.target = y.target.factorize()[0]\ny","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Machine Learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.25, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import SimpleRNN, Embedding, Dense\n\n\nmodel = Sequential()\nmodel.add(Embedding(total_count, 32))\nmodel.add(SimpleRNN(32))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('embedding : ', 8920 * 32)\nprint('simple_rnn : ', (32 * 32) + (32 * 32) + 32)\nprint('dense : ', 32 * 1 + 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 10\nhistory = model.fit(train_X, train_y, epochs=epochs, validation_split=0.2, batch_size=64, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_curve():\n    f, axs = plt.subplots(1, 2, figsize=(10, 5))\n    axs[0].plot(history.history['loss'], label='loss')\n    axs[0].plot(history.history['val_loss'], label='val_loss')\n    axs[0].legend()\n    axs[0].set_title('Loss Curve')\n    axs[1].plot(history.history['accuracy'], label='accuracy')\n    axs[1].plot(history.history['val_accuracy'], label='val_accuracy')\n    axs[1].legend()\n    axs[1].set_title('Accuracy Curve')\n    plt.show()\nplot_curve()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(total_count, 32))\nmodel.add(SimpleRNN(32))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n\nepochs = 3\nhistory = model.fit(train_X, train_y, epochs=epochs, validation_split=0.2, batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score\n\nmus = model.predict(test_X)\ny_pred = [np.where(mu >= 0.5, 1, 0) for mu in mus]\nprint(classification_report(test_y, y_pred))\nprint('-' * 100)\nprint('정확도 : ', accuracy_score(test_y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Imbalanced data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X.shape, train_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA \n\npca = PCA(n_components=2)\nX_2d = pca.fit_transform(train_X)\nX_2d = pd.DataFrame(X_2d, columns=['x', 'y'])\n\n\ndf_2d = pd.concat([X_2d, train_y.reset_index(drop=True)], axis=1)\n\nmask0 = df_2d['target'] == 0\nmask0 = df_2d['target'] == 1\n\nplt.figure(figsize=(10, 5))\nsns.scatterplot(x='x', y='y', data=df_2d, hue='target', s=12)\nplt.title('ham + spam')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\ndf_2d.groupby('target').size().plot(kind='bar')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import *\nfrom tensorflow.keras.regularizers import l2\n\n# try oversampling\nblcd_X, blcd_y = SMOTE(random_state=0).fit_resample(train_X, train_y)\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import SimpleRNN, Embedding, Dense\n\nmodel = Sequential()\nmodel.add(Embedding(total_count, 32))\nmodel.add(SimpleRNN(32))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n\nepochs = 10\nhistory = model.fit(blcd_X, blcd_y, epochs=epochs, validation_split=0.2, batch_size=64)\n\nplot_curve()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\nX_2d = pca.fit_transform(blcd_X)\nX_2d = pd.DataFrame(X_2d, columns=['x', 'y'])\n\ndf_2d = pd.concat([X_2d, blcd_y.reset_index(drop=True)], axis=1)\n\nplt.figure(figsize=(10, 5))\nsns.scatterplot(x='x', y='y', data=df_2d, hue='target', alpha=0.8)\nplt.title('ham + spam')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\ndf_2d.groupby('target').size().plot(kind='bar')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mus = model.predict(test_X)\ny_pred = [np.where(mu >= 0.5, 1, 0) for mu in mus]\nprint(classification_report(test_y, y_pred))\n# Check recall rate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = '''\nHow are you doing today? I am Mr. Fong pau teck a staff of a reputable financial institution here in Malaysia.\nAn investment was placed under my management. I need your assistance in investing the fund in your country into a good business.\nIf you are interested reply back, so I can forward you with more details.\n'''\n\ndef predict_spam(text):\n    from math import ceil\n    seq = pd.DataFrame(tk.texts_to_sequences(text)[:183]).fillna(value=0).T\n    prob = model.predict(seq)\n    (result, belief) = ('spam', prob) if prob >= 0.5 else ('ham', 1-prob)\n    \n    print('Belief {}% - {}.'.format(round(float(belief), 2) * 100, result))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_spam(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = '''\nYour business should be accepting Credit Cards from your customers!\nIncrease your sales by 30, 40 even 50 percent by accepting Credit Cards\n'''\n\npredict_spam(text)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}