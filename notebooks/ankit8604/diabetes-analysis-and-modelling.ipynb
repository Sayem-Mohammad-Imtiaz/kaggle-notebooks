{"cells":[{"cell_type":"code","execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n# Any results you write to the current directory are saved as output.","outputs":[],"metadata":{"_uuid":"fca254d846404da00952e62649db4eed83f0e6fa","collapsed":true,"_cell_guid":"e05b7a1e-046b-4d22-94bb-8b6c1fb4efd4"}},{"cell_type":"markdown","source":"<h1 style=\"text-align :center;\"> Pima Indian Diabetes Dataset</h1> \n<img src =\"https://image.freepik.com/free-vector/diabetes-elements-collection_1212-405.jpg\"/>","metadata":{"_uuid":"7c648f75a3e93b07b8718a8cf6753b2fe42dee65","_cell_guid":"000708f7-94de-4dab-88be-3cc1ec6d9734"}},{"cell_type":"markdown","source":"<h2>Diabetes In India</h2>\nOver 30 million have now been diagnosed with diabetes in India. The CPR (Crude prevalence rate) in the urban areas of India is thought to be 9 per cent.\n\nIn rural areas, the prevalence is approximately 3 per cent of the total population.\n\nThe population of India is now more than 1000 million: this helps to give an idea of the scale of the problem.\n\nThe estimate of the actual number of diabetics in India is around 40 million.\n\nThis means that India actually has the highest number of diabetics of any one country in the entire world. IGT (Impaired Glucose Tolerance) is also a mounting problem in India.\n\nThe prevalence of IGT is thought to be around 8.7 per cent in urban areas and 7.9 per cent in rural areas, although this estimate may be too high. It is thought that around 35 per cent of IGT sufferers go on to develop type 2 diabetes, so India is genuinely facing a healthcare crisis.\n\nIn India, the type of diabetes differs considerably from that in the Western world.\n\nType 1 is considerably more rare, and only about 1/3 of type II diabetics are overweight or obese.\n\nDiabetes is also beginning to appear much earlier in life in India, meaning that chronic long-term complications are becoming more common. The implications for the Indian healthcare system are enormous.\n\n","metadata":{"_uuid":"340076e2f564c6b6fcae2fd7a4030ff7f1249ea4","_cell_guid":"8ead94e6-90b5-46b2-84a4-1c28c2d2815e"}},{"cell_type":"code","execution_count":null,"source":"# importing libraries\n# imports \nimport pandas as pd\nimport numpy as np\nnp.random.seed(42)\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,VotingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.cross_validation import train_test_split\nfrom IPython.display import Image\nfrom sklearn.metrics.cluster import fowlkes_mallows_score\nfrom sklearn.metrics import roc_curve,accuracy_score,auc,roc_auc_score,confusion_matrix,precision_score,recall_score,f1_score\nfrom sklearn.grid_search import GridSearchCV\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import cross_val_score,cross_validate,cross_val_predict\nfrom sklearn.preprocessing import StandardScaler","outputs":[],"metadata":{"_uuid":"827be93cabcd6f75659b01922dc27e6fa826e339","collapsed":true,"_cell_guid":"50fe8de4-7877-4de1-bf7f-5a341eb5e38d"}},{"cell_type":"code","execution_count":null,"source":"","outputs":[],"metadata":{"_uuid":"206de22add745c293acde24b7378ca1a7712f01b","collapsed":true,"_cell_guid":"b207fe7e-7197-4d5c-8ae2-ac9f931e3100"}},{"cell_type":"code","execution_count":null,"source":"# reading file\ndataframe = pd.read_csv('../input/diabetes.csv')\ndataframe.head()","outputs":[],"metadata":{"_uuid":"7708ed4f7e2feaa4374d4956cf19f02f609b9d40","collapsed":true,"_cell_guid":"3a5efe17-ea70-43a8-a640-f4f0e3ea6a2e"}},{"cell_type":"markdown","source":"## Now lets analyze which age people are more likely to be diagnosed to be diabetic\n","metadata":{"_uuid":"d601774873229cb33f91cd1f316def6cdaf90336","_cell_guid":"5c9f5cd4-94e4-4420-a157-59bec849b248"}},{"cell_type":"code","execution_count":null,"source":"# dataframe['Age'].hist()\nplt.hist(dataframe['Age'][dataframe['Outcome'] == 1],label=\"Patient vs Age\")","outputs":[],"metadata":{"_uuid":"60387af0d57f551b53fba289710a09d2187a261c","collapsed":true,"_cell_guid":"4db10df0-58e2-475a-a317-7fc036eaecbf"}},{"cell_type":"markdown","source":"**Its seems like people lying in age groups of 20-30 and 40-50 are more prone to diabetes**","metadata":{"_uuid":"eb86f878c94909370945657bf48897757b089b1b","_cell_guid":"08a5569e-6790-4e49-8a3f-0f7248660811"}},{"cell_type":"markdown","source":"**Lets visualize the correlation map to visualize which feauture are most contributing to diagnosing diabetes**","metadata":{"_uuid":"3f1771384106b3ed6e6fe1f8eb980545a6791e09","_cell_guid":"a027d75a-fbb0-4659-bc24-e04ee3212276"}},{"cell_type":"code","execution_count":null,"source":"sns.heatmap(dataframe.corr(),annot=True)","outputs":[],"metadata":{"_uuid":"497020b4a61044d857ce50d545fca07f59adea44","collapsed":true,"_cell_guid":"e4bc8169-3365-44df-8a65-67715883d36a"}},{"cell_type":"markdown","source":"**It seems like high glucose levels in the Blood is the most important factor for diabetic patient with correlation value of 0.47**","metadata":{"_uuid":"7a1208879d6c93635f1aa42d9599bf15368202c5","_cell_guid":"2a139a1e-0b13-4317-8903-dd72d3480990"}},{"cell_type":"markdown","source":"# Now Lets check cleaning data removing Nan and missing values ","metadata":{"_uuid":"d0f3b166d5542efa23cb8a100c9470130061a55a","_cell_guid":"c9c94c9c-3938-422d-b61e-001f3a58c2a5"}},{"cell_type":"code","execution_count":null,"source":"print(dataframe.isnull().sum())\nprint(\"Minimum Bloodpressure\",dataframe['BloodPressure'].min())\nprint(\"Minimum BMI\",dataframe['BMI'].min())","outputs":[],"metadata":{"_uuid":"474167a489e3bc4205113ad0f58f98491a1ea879","collapsed":true,"_cell_guid":"4e54c696-243c-43b3-ae2f-4ffa0753f6af"}},{"cell_type":"markdown","source":"# BMI and BloodPressure can't be Null Values","metadata":{"_uuid":"98d38a044a05cb8e8d6d0335467a055e1810bbab","_cell_guid":"f206209f-1f53-4a5a-b780-5b7c0bb43591"}},{"cell_type":"code","execution_count":null,"source":"dataframe['BMI'] = dataframe['BMI'].replace(0,dataframe['BMI'].mean())\ndataframe['BloodPressure'] = dataframe['BloodPressure'].replace(0,dataframe['BloodPressure'].mean())","outputs":[],"metadata":{"_uuid":"be07ee5870a538492843e603dae518755a5df2bd","collapsed":true,"_cell_guid":"b34fdb0f-0b74-4dad-9004-807670361541"}},{"cell_type":"code","execution_count":null,"source":"dataframe['BloodPressure'].min()","outputs":[],"metadata":{"_uuid":"f761dc7aa2f78b6691e8bbfd7dbc4c1b3de5e48b","collapsed":true,"_cell_guid":"765faa7c-2697-41ce-8ccf-fe9bf0f9fe74"}},{"cell_type":"code","execution_count":null,"source":"Y = dataframe.Outcome\nX = dataframe.drop('Outcome',axis=1)","outputs":[],"metadata":{"_uuid":"c15232f6d0ce4640f2f2e2b40485049c945551ed","collapsed":true,"_cell_guid":"629f3d65-4e9a-4762-b907-18d08414b791"}},{"cell_type":"markdown","source":"##  Now Lets analyze Various Classifiers and train our model  \n1. Random Forest\n<br>\n2. Support Vector Machines\n<br>\n3. Logistic Regression\n<br>\n4. Schotastistic Gradient Classifiers\n<br>\n5. naive Bayes\n<br>\n6.  AdaBoostClassifier\n<br>\n7. ExtraForestClassifier\n<br>\n8. Decision Tree Classifier\n<br>\n9.  Multilayer Perceptron\n<br>\n10. Voting Classifier\n","metadata":{"_uuid":"598ef2ff7410ea6b96ae675941ac739945c9d001","_cell_guid":"b832f80b-42d1-41f2-8943-839c29724988"}},{"cell_type":"code","execution_count":null,"source":"# Now without feauture enginnering and data normalization lets check how our model performs on test and train data\nclassifier = SVC()\nHPoptimizerSVC = GridSearchCV(classifier,param_grid={'C': [1,10],'gamma': [0.0001,0.001,0.01,0.1]})\nclassifiers = {'Random_Forest':RandomForestClassifier(),\n               'Logistic_Reggression':LogisticRegression(),\n               'Decision Tree Classifier' : DecisionTreeClassifier(),\n               'SGDClassifier':SGDClassifier(),\n               'naive_bayes':GaussianNB(),\n               \"Support_vector_Machine\": HPoptimizerSVC,\n               \"AdaBoost\" : AdaBoostClassifier(DecisionTreeClassifier(),n_estimators=10),\n               \"ExtraForestClassifier\" : GradientBoostingClassifier(), \n               'Multilayer Perceptron' : MLPClassifier(hidden_layer_sizes=(100,),momentum=0.9,solver='sgd'),\n               'Voting Classifier' : VotingClassifier(estimators=[('log',LogisticRegression()),('SVM',SVC(C=1000)),('MLP',MLPClassifier(hidden_layer_sizes=(100,)))],voting='hard')\n\n              }\n#Holds accuracy for various models\nAcc= {}\nAcc_Train = {}\nAcc_Test = {}\nPredictions = {}\nROC = {}\nAUC = {}\nConfusion_Matrix = {}\nGmean = {}\nPrecision = {}\nRecall = {}\nF1_score = {}\nmats = pd.DataFrame(Confusion_Matrix)","outputs":[],"metadata":{"_uuid":"05b10983368e5f69cd60679fc992a8e41f8cb000","collapsed":true,"_cell_guid":"20a058b1-f9dc-4033-b421-8eb54209c4c4"}},{"cell_type":"markdown","source":"# **Train Test Split**","metadata":{"_uuid":"948800581dc3d41b9e85e9e6d7aa29ff1e36c934","_cell_guid":"2c0f447a-bb2f-44fc-91f6-578f268d5750"}},{"cell_type":"code","execution_count":null,"source":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n","outputs":[],"metadata":{"_uuid":"df41a0037227af253ad60cee380d2f3823b6f20b","collapsed":true,"_cell_guid":"0a6af65a-b490-496e-9ea9-e3766831db1c"}},{"cell_type":"markdown","source":"# **Data Normalization**","metadata":{"_uuid":"e26e020cbfb7760356e9542ece6b6668c3526797","_cell_guid":"8d08a066-97b6-4561-b3b0-fa62911b7fc5"}},{"cell_type":"code","execution_count":null,"source":"scaler = StandardScaler()\nX = scaler.fit_transform(X)","outputs":[],"metadata":{"_uuid":"f163172612968b13752439daf03273f7373a5d7a","collapsed":true,"_cell_guid":"416ee254-e53d-43f3-aa7b-8e1912cf94b9"}},{"cell_type":"code","execution_count":null,"source":"for clf in classifiers:\n    Acc[clf] = cross_validate(classifiers[clf],X,Y,cv=10,n_jobs=-1,scoring='accuracy',return_train_score=True)\n    Acc_Train[clf] =  Acc[clf]['train_score'].mean()\n    Acc_Test[clf] = Acc[clf]['test_score'].mean()\n    classifiers[clf].fit(scaler.transform(X_train),y_train)\n    pred =  classifiers[clf].predict(scaler.transform(X_test))\n    ROC[clf] = roc_auc_score(y_test,pred)\n    AUC[clf] = auc(y_test,pred,reorder=True)\n    Confusion_Matrix[clf] = confusion_matrix(y_test,pred)\n    Gmean[clf] = fowlkes_mallows_score(y_test,pred)\n    Precision[clf] = precision_score(y_test,pred)\n    Recall[clf] = recall_score(y_test,pred)    \n    F1_score[clf] = f1_score(y_test,pred)","outputs":[],"metadata":{"_uuid":"3e5e28fe96348b9b0ce1bcef8813b1c79d1a24a5","collapsed":true,"_cell_guid":"96424814-b352-4f76-a7a5-bcb73a4a76a0"}},{"cell_type":"code","execution_count":null,"source":"Accuracy_train = pd.DataFrame([Acc_Train[vals]*100 for vals in Acc_Train],columns=['Accuracy_Train'],index=[vals for vals in Acc_Train])\nAccuracy_pred = pd.DataFrame([Acc_Test[vals]*100 for vals in Acc_Test],columns=['Accuracy_Test'],index=[vals for vals in Acc_Test])","outputs":[],"metadata":{"_uuid":"7f13a33af673752ae7de65947b533e18d168fcda","collapsed":true,"_cell_guid":"8c1c3a4c-2043-4c9a-8229-7f2c2c9ddfc8"}},{"cell_type":"code","execution_count":null,"source":"ROC_Area = pd.DataFrame([ROC[vals] for vals in ROC],columns=['ROC(area)'],index=[vals for vals in ROC])\nAUC_Area = pd.DataFrame([AUC[vals] for vals in AUC],columns=['AUC(area)'],index=[vals for vals in AUC])\nGmean = pd.DataFrame([Gmean[vals] for vals in Gmean],columns=['Gmean'],index=[vals for vals in Gmean])\nPrec = pd.DataFrame([Precision[vals] for vals in Precision],columns=['precision'],index=[vals for vals in Precision])\nRec = pd.DataFrame([Recall[vals] for vals in Recall],columns=['recall'],index=[vals for vals in Recall])\nPrec = pd.DataFrame([Precision[vals] for vals in Precision],columns=['precision'],index=[vals for vals in Precision])\nf1 =  pd.DataFrame([F1_score[vals] for vals in F1_score],columns=['f1_score'],index=[vals for vals in F1_score])","outputs":[],"metadata":{"_uuid":"e2123814744d83c147efc43779af35807ea7faba","collapsed":true,"_cell_guid":"7c5fd071-2c26-4cc8-8df6-7bc488cd70b6"}},{"cell_type":"markdown","source":"## Accuracy | ROC  | Area under Curve | Gmean  | Precision | Recall \n## for various Classification\n \n<hr>","metadata":{"_uuid":"28017a8467ab15389872dfae297fa06b18b50e53","_cell_guid":"92b1cee7-b2f9-4727-8ae1-8024e8ba1c1d"}},{"cell_type":"code","execution_count":null,"source":"pd.concat([Accuracy_train,Accuracy_pred,ROC_Area,AUC_Area,Gmean,Prec,Rec,f1], axis=1)","outputs":[],"metadata":{"_uuid":"900c3dbe2a6a33f4beaa2d06820c4777330b85bf","scrolled":true,"collapsed":true,"_cell_guid":"9c287824-2d6c-427c-8611-53a4c96b2b7d"}},{"cell_type":"markdown","source":"**It seems for some classifiers(Ensembles like Random Forest,Decision Tree,ExtraForestClassifiers ) need to tuned as some are overfitting **","metadata":{"_uuid":"64d71f853f2f9558fd9933a8b26aec930d777c87","_cell_guid":"d42e9f90-b99f-4f89-81d1-0d9a0cd6b5ad"}},{"cell_type":"markdown","source":"# **Clearly Logistic Regression proves to be better than other classifiers**","metadata":{"_uuid":"7a80bd103b7ccbdbae1ea608467ab53142c54b88","_cell_guid":"d23b7aa2-0d50-49f7-8ef7-f9ecc872717a"}},{"cell_type":"code","execution_count":null,"source":"CF = {}\nfor mat in Confusion_Matrix:\n    CF[mat] = Confusion_Matrix[mat]\nsns.heatmap(CF['Logistic_Reggression'],annot=True)    ","outputs":[],"metadata":{"_uuid":"4356254c638d9821268879ebd6b9ba20e0b126c8","collapsed":true,"_cell_guid":"f6e95e49-46bf-4c27-b5b2-a69aa44ea215"}},{"cell_type":"markdown","source":"**Thanks !! please upvote if you find this kernel useful.**","metadata":{"_uuid":"048ba0101e6ab3ccd35aa50fce4c5c04f1241981","_cell_guid":"939d0f77-af2e-4493-b0e0-1d748c4bae29"}},{"cell_type":"markdown","source":"","metadata":{"_uuid":"66e874657a004662f5b77ac204f7513d643cbd1b","_cell_guid":"13f23a3a-73f9-4fdb-81c4-8a9a7be1c151"}}],"nbformat_minor":1,"nbformat":4,"metadata":{"language_info":{"name":"python","version":"3.6.3","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}}}