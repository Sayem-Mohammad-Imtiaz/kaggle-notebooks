{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries and Datasets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sn\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wrng=pd.read_csv(\"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\")\nwrng","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\")\nd=df\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Outcome'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,10))\nsn.heatmap(df.corr(),annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r=df[\"Outcome\"]\ndf=df.drop([\"Outcome\"],axis=1)\ndf.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sn.set(font_scale=1.15)\nplt.figure(figsize=(14, 10))\nsn.heatmap(df.corr(), vmax=.8, linewidths=0.01,\n            square=True,annot=True,cmap='YlGnBu',linecolor=\"black\")\nplt.title('Correlation between features');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA using Plotting","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(4,2,figsize=(16,16))\nsn.distplot(d.Age, bins = 20, ax=ax[0,0]) \nsn.distplot(d.Pregnancies, bins = 20, ax=ax[0,1]) \nsn.distplot(d.Glucose, bins = 20, ax=ax[1,0]) \nsn.distplot(d.BloodPressure, bins = 20, ax=ax[1,1]) \nsn.distplot(d.SkinThickness, bins = 20, ax=ax[2,0])\nsn.distplot(d.Insulin, bins = 20, ax=ax[2,1])\nsn.distplot(d.DiabetesPedigreeFunction, bins = 20, ax=ax[3,0]) \nsn.distplot(d.BMI, bins = 20, ax=ax[3,1]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sn.pairplot(d, x_vars=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction', 'Age'], y_vars='Outcome', height=7, aspect=0.7, kind='reg');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x1 in df.columns:\n    for y1 in df.columns:\n        sn.lmplot(x=x1,y=y1,data=d,hue='Outcome')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x2 in d.columns:\n    print (x2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x2 in d.columns:\n    sn.FacetGrid(d, hue = 'Outcome' , size = 5)\\\n      .map(sn.distplot , x2)\\\n      .add_legend()\n    plt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sn.set_style(\"whitegrid\")\nsn.pairplot(d,hue=\"Outcome\",size=3);\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp=pd.cut(d['Age'],[18,30,42,54,66,78,80])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsn.boxplot(x=tmp,y=d['Glucose'],hue=d['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsn.boxplot(x=tmp,y=d['Pregnancies'],hue=d['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsn.boxplot(x=tmp,y=d['BMI'],hue=d['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsn.boxplot(x=tmp,y=d['BloodPressure'],hue=d['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsn.boxplot(x=tmp,y=d['Insulin'],hue=d['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsn.boxplot(x=tmp,y=d['DiabetesPedigreeFunction'],hue=d['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d['SkinThickness'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp=pd.cut(d['SkinThickness'],[0,15,30,45,60,75,90,105])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for y1 in d.columns:\n    plt.figure(figsize=(10,6))\n    sn.boxplot(x=tmp,y=d[y1],hue=d['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Imputation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['SkinThickness']>60]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.loc[(d['SkinThickness'] == 0) , 'SkinThickness' ] = np.nan\nd['SkinThickness'] = d['SkinThickness'].fillna(d['SkinThickness'].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d['BloodPressure'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d['BloodPressure'].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp=pd.cut(d['BloodPressure'],[0,30,60,90,120,150])\nfor y1 in d.columns:\n    plt.figure(figsize=(10,6))\n    sn.boxplot(x=tmp,y=d[y1],hue=d['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.loc[(d['BloodPressure'] < 30) | (d['BloodPressure']>120) , 'BloodPressure' ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.loc[ d['BloodPressure'] == 0 , 'BloodPressure' ] = np.nan\nd['BloodPressure'] = d['BloodPressure'].fillna(d['BloodPressure'].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.loc[(d['BloodPressure'] < 30) | (d['BloodPressure']>120) , 'BloodPressure' ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d[d['BloodPressure']<35]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.loc[d['BMI']==0,'BMI']= np.nan\nd['BMI'] = d['BMI'].fillna(d['BMI'].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d['BMI'].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d['BMI'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.Age.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.Age.min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.Glucose.min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.Glucose.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp=pd.cut(d['Glucose'],[0,30,60,90,120,150,180,210])\nfor y1 in d.columns:\n    plt.figure(figsize=(10,6))\n    sn.boxplot(x=tmp,y=d[y1],hue=d['Outcome'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.loc[d['Glucose']==0,'Glucose']=np.nan\nd['Glucose'] = d['Glucose'].fillna(d['Glucose'].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d.loc[ d['Glucose'] <60 , 'Glucose' ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Models and Evaluating","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom collections import Counter\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_validate\n\n# split the data set into train and test\nx_1, x_test, y_1, y_test = train_test_split(df, r, test_size=0.3, random_state=0)\n\n# split the train data set into cross validation train and cross validation test\nx_tr, x_cv, y_tr, y_cv = train_test_split(x_1, y_1, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1,30,2):\n    # instantiate learning model (k = 30)\n    knn = KNeighborsClassifier(n_neighbors=i)\n\n    # fitting the model on crossvalidation train\n    knn.fit(x_tr, y_tr)\n\n    # predict the response on the crossvalidation train\n    pred = knn.predict(x_cv)\n\n    # evaluate CV accuracy\n    acc = accuracy_score(y_cv, pred, normalize=True) * float(100)\n    print('\\nCV accuracy for k = %d is %d%%' % (i, acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=knn.predict(x_test)\nacc=accuracy_score(y_pred,y_test)*float(100)\nacc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"myList = list(range(0,50))\nneighbors = list(filter(lambda x: x % 2 != 0, myList))\n\ncv_scores=[]\nfor k in neighbors:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(knn, x_tr, y_tr, cv=3, scoring='accuracy')\n    cv_scores.append(scores.mean())\n\n# changing to misclassification error\nMSE = [1 - x for x in cv_scores]\n\n# determining best k\noptimal_k = neighbors[MSE.index(min(MSE))]\nprint('\\nThe optimal number of neighbors is %d.' % optimal_k)\n\n# plot misclassification error vs k \nplt.plot(neighbors, MSE)\n\nfor xy in zip(neighbors, np.round(MSE,3)):\n    plt.annotate('(%s, %s)' % xy, xy=xy, textcoords='data')\n\nplt.xlabel('Number of Neighbors K')\nplt.ylabel('Misclassification Error')\nplt.show()\n\nprint(\"the misclassification error for each k value is : \", np.round(MSE,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_optimal = KNeighborsClassifier(n_neighbors=optimal_k)\n \n# fitting the model\nknn_optimal.fit(x_tr, y_tr)\n\n# predict the response\npred = knn_optimal.predict(x_test)\n\n# evaluate accuracy\nacc = accuracy_score(y_test, pred) * 100\nprint('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k, acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test , pred)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['negative' , 'positive']\ndf_cm = pd.DataFrame(cm , index = labels , columns = labels)\n\nsn.heatmap(df_cm , annot = True , fmt = 'd')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"Actual Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test , pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def k_classifier_brute(X_train , Y_train):\n    neighbors = list(range(5 , 51 , 2))\n    cv_scores = []\n    for i in neighbors:\n        neigh = KNeighborsClassifier(n_neighbors = i,metric='correlation' )\n        scores = cross_val_score(neigh , x_tr , y_tr , cv = 10 , scoring = 'accuracy')\n        cv_scores.append(scores.mean())\n    MSE = [1-x for x in cv_scores]\n    optimal_k = neighbors[MSE.index(min(MSE))]\n    print('Optimal k is {}'.format(optimal_k))\n    print('Misclassification error for each k is {}'.format(np.round(MSE , 3)))\n    plt.plot(neighbors , MSE)\n    plt.xlabel('Number of Neighbors')\n    plt.ylabel('Misclassification Error')\n    plt.title('Neighbors v/s Misclassification Error')\n    plt.show()\n    \n    return optimal_k","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimal_k_pidd = k_classifier_brute(x_tr , y_tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_optimal_for_pidd = KNeighborsClassifier(n_neighbors = optimal_k_pidd , metric = 'correlation')\nknn_optimal_for_pidd.fit(x_tr , y_tr)\npred = knn_optimal_for_pidd.predict(x_test)\naccuracy_score(pred,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test , pred)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['negative' , 'positive']\ndf_cm = pd.DataFrame(cm , index = labels , columns = labels)\n\nsn.heatmap(df_cm , annot = True , fmt = 'd')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"Actual Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test , pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(df, r, random_state=1,test_size=0.2)\nfrom sklearn.naive_bayes import GaussianNB\nnb=GaussianNB()\nnb.fit(X_train,Y_train)\npredic=nb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(predic,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(Y_test , predic)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['negative' , 'positive']\ndf_cm = pd.DataFrame(cm , index = labels , columns = labels)\n\nsn.heatmap(df_cm , annot = True , fmt = 'd')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"Actual Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test , predic))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()\nlr.fit(X_train,Y_train)\npredic=lr.predict(X_test)\naccuracy_score(predic,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(Y_test , predic)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['negative' , 'positive']\ndf_cm = pd.DataFrame(cm , index = labels , columns = labels)\n\nsn.heatmap(df_cm , annot = True , fmt = 'd')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"Actual Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test , predic))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import BernoulliNB\nnb=BernoulliNB()\nnb.fit(X_train,Y_train)\npredic=nb.predict(X_test)\naccuracy_score(predic,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nmodel=MultinomialNB()\nmodel.fit(X_train,Y_train)\npredic=model.predict(X_test)\naccuracy_score(predic,Y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Oversampling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nsmt = SMOTE()\nX_train , Y_train = smt.fit_sample(X_train , Y_train)\nprint(Y_train.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom collections import Counter\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import model_selection\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def k_classifier_brute(X_train , Y_train):\n    neighbors = list(range(5 , 51 , 2))\n    cv_scores = []\n    for i in neighbors:\n        neigh = KNeighborsClassifier(n_neighbors = i,metric='correlation')\n        scores = cross_val_score(neigh , X_train , Y_train , cv = 10 , scoring = 'accuracy')\n        cv_scores.append(scores.mean())\n    MSE = [1-x for x in cv_scores]\n    optimal_k = neighbors[MSE.index(min(MSE))]\n    print('Optimal k is {}'.format(optimal_k))\n    print('Misclassification error for each k is {}'.format(np.round(MSE , 3)))\n    plt.plot(neighbors , MSE)\n    plt.xlabel('Number of Neighbors')\n    plt.ylabel('Misclassification Error')\n    plt.title('Neighbors v/s Misclassification Error')\n    plt.show()\n    \n    return optimal_k","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimal_k_pidd = k_classifier_brute(X_train , Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_optimal_for_pidd = KNeighborsClassifier(n_neighbors = optimal_k_pidd , metric = 'correlation')\nknn_optimal_for_pidd.fit(X_train , Y_train)\npred = knn_optimal_for_pidd.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_acc = knn_optimal_for_pidd.score(X_train , Y_train)\nprint('Training Accurcy = {}'.format(train_acc))\n\ntrain_error = 1 - train_acc\nprint('Training Error = {}'.format(train_error))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = accuracy_score(Y_test , pred)\nprint('The accuracy of the model for k = {} is {}'.format(optimal_k_pidd , accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(Y_test , predic)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['negative' , 'positive']\ndf_cm = pd.DataFrame(cm , index = labels , columns = labels)\n\nsn.heatmap(df_cm , annot = True , fmt = 'd')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"Actual Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test , predic))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb1=GaussianNB()\nnb1.fit(X_train,Y_train)\npredic=nb1.predict(X_test)\naccuracy_score(predic,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(Y_test , predic)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['negative' , 'positive']\ndf_cm = pd.DataFrame(cm , index = labels , columns = labels)\n\nsn.heatmap(df_cm , annot = True , fmt = 'd')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"Actual Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test , predic))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb1=BernoulliNB()\nnb1.fit(X_train,Y_train)\npredic=nb1.predict(X_test)\naccuracy_score(predic,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(Y_test , predic)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['negative' , 'positive']\ndf_cm = pd.DataFrame(cm , index = labels , columns = labels)\n\nsn.heatmap(df_cm , annot = True , fmt = 'd')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"Actual Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test , predic))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr1=LogisticRegression()\nlr1.fit(X_train,Y_train)\npredic=lr1.predict(X_test)\naccuracy_score(predic,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(Y_test , predic)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['negative' , 'positive']\ndf_cm = pd.DataFrame(cm , index = labels , columns = labels)\n\nsn.heatmap(df_cm , annot = True , fmt = 'd')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"Actual Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test , predic))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nmodel=MultinomialNB()\nmodel.fit(X_train,Y_train)\npredic=model.predict(X_test)\naccuracy_score(predic,Y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM and XGBoost Classifiers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nclfr1=svm.SVC(kernel='linear')\nclfr2=svm.SVC(kernel='rbf')\nclfr1.fit(X_train,Y_train)\nclfr2.fit(X_train,Y_train)\npredic1=clfr1.predict(X_test)\npredic2=clfr2.predict(X_test)\nprint(\"The accuracy for SVM model With linear Kernel is {} \", accuracy_score(predic1,Y_test))\nprint(\"The accuracy for SVM model With RBF Kernel is {} \", accuracy_score(predic2,Y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm1 = confusion_matrix(Y_test , predic1)\ncm1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['negative' , 'positive']\ndf_cm = pd.DataFrame(cm1 , index = labels , columns = labels)\n\nsn.heatmap(df_cm , annot = True , fmt = 'd')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"Actual Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm2= confusion_matrix(Y_test , predic2)\ncm2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['negative' , 'positive']\ndf_cm = pd.DataFrame(cm2 , index = labels , columns = labels)\n\nsn.heatmap(df_cm , annot = True , fmt = 'd')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"Actual Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test , predic1))\nprint(classification_report(Y_test , predic2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nxgb_model=xgb.XGBClassifier().fit(X_train,Y_train)\npredictions=xgb_model.predict(X_test)\nactuals=Y_test\nprint(accuracy_score(actuals,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm4= confusion_matrix(actuals,predictions)\ncm4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['negative' , 'positive']\ndf_cm = pd.DataFrame(cm4 , index = labels , columns = labels)\n\nsn.heatmap(df_cm , annot = True , fmt = 'd')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"Actual Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test , predic1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Trees and Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\nclfr3=tree.DecisionTreeClassifier()\ndt_model=clfr3.fit(X_train,Y_train)\npredic3=clfr3.predict(X_test)\naccuracy_score(predic3,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm3= confusion_matrix(Y_test , predic3)\ncm3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['negative' , 'positive']\ndf_cm = pd.DataFrame(cm3 , index = labels , columns = labels)\n\nsn.heatmap(df_cm , annot = True , fmt = 'd')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"Actual Label\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test , predic3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf_mdl=RandomForestClassifier().fit(X_train,Y_train)\npredic5=rf_mdl.predict(X_test)\naccuracy_score(predic5,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm5= confusion_matrix(Y_test , predic5)\ncm5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['negative' , 'positive']\ndf_cm = pd.DataFrame(cm5 , index = labels , columns = labels)\n\nsn.heatmap(df_cm , annot = True , fmt = 'd')\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"Actual Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(Y_test , predic5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fine Tuning Hyperparameters using GridSearchCV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\ntuned_param=[{'c':[10**-4,10**-2,10**0,10**2]}]\nlr1=GridSearchCV(LogisticRegression(),tuned_param)\nlr1.fit(X_train,Y_train)\npredic=lr1.predict(X_test)\naccuracy_score(predic,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lr.best_estimator_)\nprint(model.score(X_test,Y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}