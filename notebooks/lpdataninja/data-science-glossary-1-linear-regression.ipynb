{"cells":[{"metadata":{"_uuid":"35ed619c63eb262853635f03347d141178682bcd"},"cell_type":"markdown","source":"# Problem Statement\n- *To Predict house prices in King County, USA.*\n- *Type: Regression*"},{"metadata":{"_uuid":"862107debaaadccbeb9c1845fa46f9299d2593a5"},"cell_type":"markdown","source":"# About the Data\n- The dataset contains house sale prices of King County which were sold in between May 2014 and May 2015."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Let us start by** Importing Libraries**"},{"metadata":{"trusted":true,"_uuid":"986b6a5f0d1b8f4dd866236111b0f9a9a761edf6"},"cell_type":"code","source":"# For linear algebra,\nimport numpy as np\n\n# Data\nimport pandas as pd\n\n# Visualization\nimport matplotlib.pyplot as plt\n\n# Model building and helper libraries\nimport xgboost\nimport math\nfrom __future__ import division\nfrom scipy.stats import pearsonr\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import model_selection, tree, linear_model\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import explained_variance_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa8c9fe72da026b502e9159e1319bdf3ec0ff383"},"cell_type":"markdown","source":"# 1. Exploratory Data Analysis"},{"metadata":{"trusted":true,"_uuid":"6289f040ac4f3899a9fa1e29c4952fb549ea3cd6"},"cell_type":"code","source":"# Read the data into a data frame\ndata = pd.read_csv('../input/kc_house_data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60e09d4a33f9c6a45ed549d903dc109dfe32a8bb"},"cell_type":"code","source":"# Check the number of data points in the data set\nprint(len(data))\n# Check the number of features in the data set\nprint(len(data.columns))\n# Check the data types\nprint(data.dtypes.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec30f5298fe43448144ea430e3b5f59efc1b3dff"},"cell_type":"code","source":"# Since there are Python objects in the data set, we may have some categorical features. Let's check them.\ndata.select_dtypes(include=['O']).columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ee4290abb12539e2f673e1122b07ed759526ca0"},"cell_type":"markdown","source":"- We only have the date column which is a time stamp which can be ignored."},{"metadata":{"trusted":true,"_uuid":"f40174eb3cce24f09260d6bef964d1cff61ebb9a"},"cell_type":"code","source":"# Check number of columns with NaN\nprint(data.isnull().any().sum(), ' / ', len(data.columns))\n# Check number of data points with NaN\nprint(data.isnull().any(axis=1).sum(), ' / ', len(data))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9972012ba73b42b9b6db1ad7677a18e9b035daac"},"cell_type":"markdown","source":"- The data set is structured and doesn't have any NaN values. So we can jump into finding correlations between the features and the target variable"},{"metadata":{"_uuid":"5c533b9659dd49c9109e347595877245736f79b0"},"cell_type":"markdown","source":"# 2. Correlation between features and target"},{"metadata":{"trusted":true,"_uuid":"152bf9866f110f64ef93843ef96f0b885b878fd0"},"cell_type":"code","source":"# Independent variables also known as features\nfeatures = data.iloc[:,3:].columns.tolist()\n# Dependent Variables also known as target\ntarget = data.iloc[:,2].name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7d3f5a548e48ff30553b9a59c10aa5bd234ad68"},"cell_type":"code","source":"# Dictionary to store correlations key: feature_name, value: correlation between feature and target\ncorrelations = {}\nfor f in features:\n    data_temp = data[[f,target]]\n    x1 = data_temp[f].values\n    x2 = data_temp[target].values\n    key = f + ' vs ' + target\n    correlations[key] = pearsonr(x1,x2)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2ad6831c60c357d516e103569011d51e8573c1b"},"cell_type":"code","source":"data_correlations = pd.DataFrame(correlations, index=['Value']).T\ndata_correlations.loc[data_correlations['Value'].abs().sort_values(ascending=False).index]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d9325458d934a11eae17b8083ac2332faa5448b"},"cell_type":"markdown","source":"### The top 5 features are the most correlated features with the target \"price\""},{"metadata":{"trusted":true,"_uuid":"c430bd37e570c61d482716393648ccdacf084d81"},"cell_type":"code","source":"y = data.loc[:,['sqft_living','grade',target]].sort_values(target, ascending=True).values\nx = np.arange(y.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b189619eb5418ad0e05969b0dabddbfc8649bc64"},"cell_type":"code","source":"%matplotlib inline\nplt.subplot(3,1,1)\nplt.plot(x,y[:,0])\nplt.title('Sqft and Grade vs Price')\nplt.ylabel('Sqft')\n\nplt.subplot(3,1,2)\nplt.plot(x,y[:,1])\nplt.ylabel('Grade')\n\nplt.subplot(3,1,3)\nplt.plot(x,y[:,2],'r')\nplt.ylabel(\"Price\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58124c983e17b05aaf93b387e967220c00ac7750"},"cell_type":"markdown","source":"# 3. Predicting House Prices"},{"metadata":{"trusted":true,"_uuid":"33852d9a09bee86479eb648457351d6774e31586"},"cell_type":"code","source":"# Train a linear regression model\nregr = linear_model.LinearRegression()\nnew_data = data[['sqft_living','grade', 'sqft_above', 'sqft_living15','bathrooms','view',\n                 'sqft_basement','lat','waterfront','yr_built','bedrooms']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abe3a3fd1a65dbe41a31afa4cec922efe0a67ce6"},"cell_type":"code","source":"# X -> Independent variables\n# y -> Dependent variable\nX = new_data.values\ny = data.price.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e24c9e665d07043c02ef4b0d314deff5c0aa9883"},"cell_type":"code","source":"# Splitting the data into train and test\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, \n                                                                    test_size=0.2, \n                                                                    random_state=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4adba965a2fd86c5c517129e1872ed316f6fd21"},"cell_type":"code","source":"# Training the model\nregr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cdeb6a918fccb6ec2be8329eb676b3bccf97044"},"cell_type":"code","source":"# Predicting on test data\npredictions = regr.predict(X_test)\nprint(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93291222ebc31ec4616835c3fc288a38b97af9bc"},"cell_type":"code","source":"print(f'Mean Squared Error: {metrics.mean_squared_error(predictions,y_test)}')\nprint(f'Mean Absolute Error: {metrics.mean_absolute_error(predictions,y_test)}')\nprint(f'Root Mean Squared Error: {np.sqrt(metrics.mean_squared_error(predictions,y_test))}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88903ffd1959ff79f50d1a5266d0a7a6f7b03d03"},"cell_type":"markdown","source":"### Not our best answer, let's use XGBoost."},{"metadata":{"trusted":true,"_uuid":"7b5d937f900bcfd2f25b28506938d1dd876dd3f7"},"cell_type":"code","source":"# Let's try XGboost algorithm to see if we can get better results\nxgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n                           colsample_bytree=1, max_depth=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"2ea817e891a1f088872fbf032f4e6f9505aa46f7"},"cell_type":"code","source":"traindf, testdf = train_test_split(X_train, test_size = 0.3)\nxgb.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7b7d88b841acc7d23ef3202d416ef8b50d7d4dc"},"cell_type":"code","source":"predictions = xgb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f477dc45b2557e242f74b8a0912742cd1ff176d"},"cell_type":"code","source":"print(f'Mean Squared Error: {metrics.mean_squared_error(predictions,y_test)}')\nprint(f'Mean Absolute Error: {metrics.mean_absolute_error(predictions,y_test)}')\nprint(f'Root Mean Squared Error: {np.sqrt(metrics.mean_squared_error(predictions,y_test))}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"224eff4880c9a694b9ebc06ae07a416f6537cfa0"},"cell_type":"markdown","source":"### As the error has dropped significantly making it an  optimal solution."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}