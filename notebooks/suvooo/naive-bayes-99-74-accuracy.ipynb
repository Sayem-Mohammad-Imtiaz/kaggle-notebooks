{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/mushroom-classification/mushrooms.csv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing - convert to numeric data","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = df.apply(func=le.fit_transform) # this will be applied to each column : meaning of apply\nds.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = ds.values # becomes a list\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data[:, 1:] # all colsexcept 1st\ny = data[:, 0] # all rows, just 0 col\nX.shape, y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom Naive Bayes","metadata":{}},{"cell_type":"code","source":"class CustomNB:\n    def fit(self, X, y):\n        self.X_train = X\n        self.y_train = y\n        \n    # label = which class you want this prob for\n    def prior_prob(self, label): \n        total = self.y_train.shape[0]\n        class_examples = np.sum(self.y_train == label)\n        return class_examples / float(total)  # python 2\n    \n    # P(Xi=red|y=label) - ith feature (feature col = i) for a single example\n    def conditional_prob(self, feature_col, feature_val, label):\n        # out of all the examples, what mushrooms have feature as feature_val in the feature_col that belongs to that class label\n        X_filtered = self.X_train[self.y_train==label] # all the examples in class label\n        numerator = np.sum(X_filtered[:, feature_col] == feature_val)\n        denominator = len(X_filtered)\n        return numerator / denominator\n    \n    # we are going to do this for all the 22 features that we have for each example\n    def predict_point(self, X_test):\n        # X_test is a single example with n features\n        classes = np.unique(self.y_train) # By default from 0\n        n_features = self.X_train.shape[1]\n        post_pro = []\n        # post prob for each class\n        for label in classes:\n            # post_prob = prior * likelihood\n            likehood = 1.0\n            for feature in range(n_features):\n                cond = self.conditional_prob(feature, X_test[feature], label)\n                likehood *= cond\n            prior = self.prior_prob(label)\n            post = prior * likehood\n            post_pro.append(post)\n        \n        # ans = max value from all labels\n        return np.argmax(post_pro) # return the index of the largest value in array\n    \n    def predict(self, X_test):\n        result = []\n        for point in X_test:\n            result.append(self.predict_point(point))\n        return np.array(result)\n    \n    def score(self, X_test, y_test):\n        return (self.predict(X_test) == y_test).mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting Data","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CustomNB()\nmodel.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict(X_test[:10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Accuracy","metadata":{}},{"cell_type":"code","source":"ans = model.score(X_test, y_test)\nprint('Accuracy of the custom Naive Bayes model is :',ans * 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}