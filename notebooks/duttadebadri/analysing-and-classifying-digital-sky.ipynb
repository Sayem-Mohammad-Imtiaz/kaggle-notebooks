{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sloan Digital Sky Survey Classification\n\n## Classification of Galaxies, Stars and Quasars based on the RD14 from the SDSS\n","metadata":{"_uuid":"053f434afbccca0aee56d432aed600cd86f4db08"}},{"cell_type":"markdown","source":"--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n### About the notebook\n\nSo here we are going to have some Explaratory Data Analysis along with creating a model which predicts whether it is a galaxy or a star or Quasars with a pretty good accuracy.\n\n\nSo lets get started","metadata":{"_uuid":"97579d581b0a012d7b29206319c23543a94cd7d3"}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport plotly.offline as py\ncolor = sns.color_palette()\nimport plotly.graph_objs as go\npy.init_notebook_mode(connected=True)\nimport plotly.tools as tls\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport pandas as pd\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nSMALL_SIZE = 10\nMEDIUM_SIZE = 12\n\nplt.rc('font', size=SMALL_SIZE)\nplt.rc('axes', titlesize=MEDIUM_SIZE)\nplt.rc('axes', labelsize=MEDIUM_SIZE)\nplt.rcParams['figure.dpi']=150\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-13T07:39:29.586745Z","iopub.execute_input":"2021-06-13T07:39:29.587254Z","iopub.status.idle":"2021-06-13T07:39:31.891426Z","shell.execute_reply.started":"2021-06-13T07:39:29.587182Z","shell.execute_reply":"2021-06-13T07:39:31.890264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('../input/Skyserver_SQL2_27_2018 6_51_39 PM.csv')\ndf.head()","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-13T07:39:31.8938Z","iopub.execute_input":"2021-06-13T07:39:31.894204Z","iopub.status.idle":"2021-06-13T07:39:32.059648Z","shell.execute_reply.started":"2021-06-13T07:39:31.89413Z","shell.execute_reply":"2021-06-13T07:39:32.058468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lets begin with Data Analysis","metadata":{"_uuid":"64bfc112db091086cd9d67ebb286929391cd291c"}},{"cell_type":"code","source":"df.describe()","metadata":{"_kg_hide-input":true,"scrolled":true,"_uuid":"c209eae64f941504f5fc0749fade8170cead267b","execution":{"iopub.status.busy":"2021-06-13T07:39:32.061972Z","iopub.execute_input":"2021-06-13T07:39:32.062479Z","iopub.status.idle":"2021-06-13T07:39:32.162597Z","shell.execute_reply.started":"2021-06-13T07:39:32.062279Z","shell.execute_reply":"2021-06-13T07:39:32.161889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"_kg_hide-input":true,"_uuid":"83c2de191e0bc29c3e8585388673b2213fb23d90","execution":{"iopub.status.busy":"2021-06-13T07:39:32.164151Z","iopub.execute_input":"2021-06-13T07:39:32.164509Z","iopub.status.idle":"2021-06-13T07:39:32.178591Z","shell.execute_reply.started":"2021-06-13T07:39:32.164461Z","shell.execute_reply":"2021-06-13T07:39:32.177665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Lets see if there are any null values in our dataset","metadata":{"_uuid":"d8be097f3dfceaced5d678e2e55881a027915b75"}},{"cell_type":"code","source":"columns = df.columns\npercent_missing = df.isnull().sum() * 100 / len(df)\nmissing_value_df = pd.DataFrame({'column_name': columns,\n                                 'percent_missing': percent_missing})\nmissing_value_df.sort_values('percent_missing')","metadata":{"_kg_hide-input":true,"_uuid":"5af76a12ca74fce15ffe42d1cb9050429374b93b","execution":{"iopub.status.busy":"2021-06-13T07:39:32.179569Z","iopub.execute_input":"2021-06-13T07:39:32.179826Z","iopub.status.idle":"2021-06-13T07:39:32.252566Z","shell.execute_reply.started":"2021-06-13T07:39:32.179773Z","shell.execute_reply":"2021-06-13T07:39:32.251209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we don't have any missing values\n\n#### Next we will see if there are any highly correlated columns and drop it accordingly","metadata":{"_uuid":"2811da130e0afb71db2441533de955e96b9106af"}},{"cell_type":"code","source":"sns.heatmap(df.corr())\ndf.corr()","metadata":{"_kg_hide-input":true,"_uuid":"798c558ef9167be5b037786307a93c032113fe5f","execution":{"iopub.status.busy":"2021-06-13T07:39:32.253999Z","iopub.execute_input":"2021-06-13T07:39:32.254393Z","iopub.status.idle":"2021-06-13T07:39:32.903141Z","shell.execute_reply.started":"2021-06-13T07:39:32.254323Z","shell.execute_reply":"2021-06-13T07:39:32.902054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"But we will drop the ID columns","metadata":{"_uuid":"638172b94d4807b7d6fcaafbc3a089c2050b84e9"}},{"cell_type":"code","source":"df.drop(['specobjid','fiberid'],axis=1,inplace=True)","metadata":{"_uuid":"a5866bacd07a3c3b49de1c431b086a789f1b99dc","execution":{"iopub.status.busy":"2021-06-13T07:39:32.904596Z","iopub.execute_input":"2021-06-13T07:39:32.905268Z","iopub.status.idle":"2021-06-13T07:39:32.913354Z","shell.execute_reply.started":"2021-06-13T07:39:32.905207Z","shell.execute_reply":"2021-06-13T07:39:32.912336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### So lets check out the number of each classes","metadata":{"_uuid":"6ad606936bb3dc5d6ff8d749602ade1cc62801d5"}},{"cell_type":"code","source":"cnt_srs = df['class'].value_counts()\ntrace = go.Bar(\n    y=cnt_srs.index[::-1],\n    x=cnt_srs.values[::-1],\n    orientation = 'h',\n    marker=dict(\n        color=cnt_srs.values[::-1],\n        colorscale = 'Blues',\n        reversescale = True\n    ),\n)\n\nlayout = dict(\n    title='Class distribution',\n    )\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename=\"Ratings\")","metadata":{"_uuid":"ace266a68d2b20288e2e630cf85a27e25c7a4802","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-13T07:39:32.9148Z","iopub.execute_input":"2021-06-13T07:39:32.915467Z","iopub.status.idle":"2021-06-13T07:39:34.214876Z","shell.execute_reply.started":"2021-06-13T07:39:32.915406Z","shell.execute_reply":"2021-06-13T07:39:34.213905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we see that **QSO** is relatively very less in no. We will do some sampling techniques before we fit it into a model.\n\nLets take a look at the redshift.","metadata":{"_uuid":"9498e2e512f1fd99046d34c6782aeea4bf11dd9d"}},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=3,figsize=(16, 4))\nax = sns.distplot(df[df['class']=='STAR'].redshift, bins = 30, ax = axes[0], kde = False)\nax.set_title('Star')\nax = sns.distplot(df[df['class']=='GALAXY'].redshift, bins = 30, ax = axes[1], kde = False)\nax.set_title('Galaxy')\nax = sns.distplot(df[df['class']=='QSO'].redshift, bins = 30, ax = axes[2], kde = False)\nax = ax.set_title('QSO')","metadata":{"_uuid":"0d607fc74dd6794226c47c0fcd24c58a0841a75e","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-13T07:39:34.215969Z","iopub.execute_input":"2021-06-13T07:39:34.216303Z","iopub.status.idle":"2021-06-13T07:39:35.017753Z","shell.execute_reply.started":"2021-06-13T07:39:34.216247Z","shell.execute_reply":"2021-06-13T07:39:35.01666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The redshift can be an estimate(!) for the distance from the earth to a object in space.","metadata":{"_uuid":"1fd100f36f07099150426164005a53c3e8e108b4","trusted":true}},{"cell_type":"markdown","source":"##### **Next we come to the Letter value plot. The Letter value (LV) Plot show us an estimate of the distribution of the data. It shows boxes which relate to the amount of values within the range of values inside the box.**","metadata":{"_uuid":"432058abdd207cf0b571a0b596e488d4f7490627"}},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=1,figsize=(16, 4))\nax = sns.lvplot(x=df['class'], y=df['dec'], palette='coolwarm')\nax.set_title('dec')\n","metadata":{"_uuid":"b30ab15724306f68bf34d8ec1818f0843fff2593","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-13T07:39:35.019253Z","iopub.execute_input":"2021-06-13T07:39:35.019835Z","iopub.status.idle":"2021-06-13T07:39:35.386898Z","shell.execute_reply.started":"2021-06-13T07:39:35.019773Z","shell.execute_reply":"2021-06-13T07:39:35.385312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### So now lets go into feature engg. and removing outliers\n\n#### One of the most popular methods to remove outliers is the boxplot method which we are going to try out first.\n\nBefore we proceed we are goint to separate the \"class\" and drop the \"objid\".","metadata":{"_uuid":"e8c64e7d52c06de4a1f6e26f5d61eb6bd84fbcce","trusted":true}},{"cell_type":"code","source":"di={'STAR':1,'GALAXY':2,'QSO':3}\ndf.replace({'class':di},inplace=True)\n\ny=df['class']\ndf.drop(['objid','class'],axis=1,inplace=True)","metadata":{"_uuid":"3ee10639a00d4786e7807cc592c4d4ddc8f9ed65","execution":{"iopub.status.busy":"2021-06-13T07:39:35.39322Z","iopub.execute_input":"2021-06-13T07:39:35.393988Z","iopub.status.idle":"2021-06-13T07:39:35.417101Z","shell.execute_reply.started":"2021-06-13T07:39:35.393633Z","shell.execute_reply":"2021-06-13T07:39:35.415659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dx=df[['ra','dec','u','g','r','i','z','run','rerun','camcol','field','redshift','plate','mjd']]\nfor i in dx.columns:\n    plt.figure(figsize=(12,8))\n    sns.boxplot(y=i, data=df)\n    plt.ylabel(i+'Distribution', fontsize=12)\n    plt.title(i+\"Distribution\", fontsize=14)\n    plt.xticks(rotation='vertical')\n    plt.show()","metadata":{"_uuid":"ccfc50c7a7fd7c08df7ff76406f434d88b5f18f5","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-13T07:39:35.420436Z","iopub.execute_input":"2021-06-13T07:39:35.421016Z","iopub.status.idle":"2021-06-13T07:39:39.274109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we see for some there are very few or no outliers.","metadata":{"_uuid":"41c750650fbf075ace8aca55f7379cad59d1200b"}},{"cell_type":"markdown","source":"### Dimensional Reduction with U-Map\n\nSo it is probably the best dimensional reduction technique that I've seen. Its much faster and much more better than t-SNE or PCA as fas as I've read.","metadata":{"_uuid":"63e5eae304ca355f9e6aa6b89147822f01dda713","trusted":true}},{"cell_type":"code","source":"import umap\n\nembedding = umap.UMAP(n_neighbors=5,\n                      min_dist=0.3,\n                      metric='correlation').fit_transform(df.iloc[:20000, 1:])\n\nplt.figure(figsize=(12,12))\nplt.scatter(embedding[:20000, 0], embedding[:20000, 1], \n            c=df.iloc[:20000, 0], \n            edgecolor='none', \n            alpha=0.80, \n            s=10)\nplt.axis('off');","metadata":{"_uuid":"8dde2613230098eda4636639a3a2a8aff1c750b1","execution":{"iopub.status.busy":"2021-06-13T07:39:39.275282Z","iopub.execute_input":"2021-06-13T07:39:39.275554Z","iopub.status.idle":"2021-06-13T07:40:09.097489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The dimensions have been reduced and we can visualize the different transformed components. There is very less correlation between the transformed variables. We can see that the correlation between the components obtained from UMAP is quite les. Hence, UMAP tends to give better results. ","metadata":{"_uuid":"a91d515ff1c8c8ef7643877563f2e3a33cb178a3"}},{"cell_type":"code","source":"df.head(1)","metadata":{"_uuid":"039afc413ebcbaedf2b0e737e7dd1a6d2c70e04a","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-13T07:40:09.098739Z","iopub.execute_input":"2021-06-13T07:40:09.099052Z","iopub.status.idle":"2021-06-13T07:40:09.131222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Lets do some Feature Scaling before we apply SVM and KNN, which will be the first algorithms to be applied.","metadata":{"_uuid":"10bca3c9a498f9b19a8d6113c1b5acebae9f1421"}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nsdss = scaler.fit_transform(df)","metadata":{"_uuid":"269ecfab4fa951499080c70aad9f3511d4db17b0","execution":{"iopub.status.busy":"2021-06-13T07:40:09.132542Z","iopub.execute_input":"2021-06-13T07:40:09.132835Z","iopub.status.idle":"2021-06-13T07:40:09.139898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(df, \n                                                    y, test_size=0.33)","metadata":{"_uuid":"44fffaaf0fe73e5bd49466376719336535987296","execution":{"iopub.status.busy":"2021-06-13T07:40:09.14101Z","iopub.execute_input":"2021-06-13T07:40:09.141255Z","iopub.status.idle":"2021-06-13T07:40:09.154273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### KNN","metadata":{"_uuid":"afcaee6a37cb8be6d385c98be4946baf35530141"}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\npreds = knn.predict(X_test)\nacc_knn = (preds == y_test).sum().astype(float) / len(preds)*100\nprint(\"Accuracy of KNN: \", acc_knn)","metadata":{"_uuid":"b298dfd55098f21cd1ccee1936473e5c2918d370","execution":{"iopub.status.busy":"2021-06-13T07:40:09.155255Z","iopub.execute_input":"2021-06-13T07:40:09.155496Z","iopub.status.idle":"2021-06-13T07:40:09.205704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SVM","metadata":{"_uuid":"9e89b5ef060c8cdd0cbf378ac46622edc8e20071"}},{"cell_type":"markdown","source":"We will use GridSearcgCV method for each kernel and check which is giving the highest accuracy.\n\nKernels to be tried are :\n* Radial Basis Function or  RBF Kernel or Gaussian Kernel (widely used, because of non-linear data)\n* Polynomial Kernel \n* Linear Kenel (works best on linear data)","metadata":{"_uuid":"fc76a42b398149e499414b1203c7320ad85fc3b4"}},{"cell_type":"markdown","source":"#### RBF Kernel with GridSearchCV","metadata":{"_uuid":"f717217182182c5d89879593bb9814db3760b187"}},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']} \n\ngrid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n\ngrid.fit(X_train,y_train)","metadata":{"_kg_hide-output":true,"_uuid":"8331c27711c7ac7acbf9fdc59dec6eefcc2912f3","execution":{"iopub.status.busy":"2021-06-13T07:40:09.206773Z","iopub.execute_input":"2021-06-13T07:40:09.207034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid.best_params_","metadata":{"_uuid":"5bbae924e42c658cfdf0b5f0fc0ac24ffb72271d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid.best_estimator_","metadata":{"_uuid":"912d144380709aa2bb114433b00e7f65b8809451","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_predictions = grid.predict(X_test)","metadata":{"_uuid":"b5c65931ab8d0f2c8fef3d2a1c2960f12e11cbb6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc_gv_rbf = (grid_predictions == y_test).sum().astype(float) / len(grid_predictions)*100\nprint(\"Accuracy of KNN: \", acc_gv_rbf)","metadata":{"_uuid":"cf4c8a9a35d025d4eb62e72ccc65f7813d208d4c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Linear Kernel with GridSearchCV","metadata":{"_uuid":"1d7e7b5629e9a8d34b8f1a938b07647486ddd8cf"}},{"cell_type":"code","source":"'''param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['linear']} \n\ngrid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n\ngrid.fit(X_train,y_train)'''","metadata":{"_uuid":"4fc6c2089c60076089fdd9358ece9c67f0cc1359","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Linear Kernel was taking lots of time, that's why had to stop it.","metadata":{"_uuid":"158c53553950864d134c00467db063c6c0bea01d","trusted":true}},{"cell_type":"markdown","source":"#### Naive Bayes","metadata":{"_uuid":"7b971e900abeb8090e345586b88b52cb85ef56b8"}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\ngnb=GaussianNB()\ngnb.fit(X_train,y_train)\npreds2=gnb.predict(X_test)\nacc_gnb=(preds2==y_test).sum().astype(float)/len(preds)*100\nprint(\"Accuracy of Naive Bayes: \",acc_gnb)","metadata":{"_uuid":"5564694fa258994f3c33929eb7ce8d5356d23958","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Random Forest Classifier","metadata":{"_uuid":"23ac779a4a52fcf6e6da0749aa8e758bad5931b0"}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf=RandomForestClassifier()\nrf.fit(X_train,y_train)\npreds3=rf.predict(X_test)\nacc_rf=(preds3==y_test).sum().astype(float)/len(preds)*100\nprint(\"Accuracy of Random Forest Classifier: \",acc_rf)","metadata":{"_uuid":"488d9581dd904c3250921e6af7fe2d547fbb034f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### XGBoost","metadata":{"_uuid":"d68b43617ca6a74b0f05ca5bcf0f2f7ea31508e4"}},{"cell_type":"code","source":"import xgboost as xgb\n\nxgb=xgb.XGBClassifier()\nxgb.fit(X_train,y_train)\npreds4=xgb.predict(X_test)\nacc_xgb=(preds4==y_test).sum().astype(float)/len(preds)*100\nprint(\"Accuracy of XGBoost Classifier: \",acc_xgb)","metadata":{"_uuid":"aa18cfda2c8b82cda8ebbc13cc2d13d289961eec","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### LightGBM","metadata":{"_uuid":"d7848390da81af500d7590cf11674af8e8e79648"}},{"cell_type":"code","source":"import lightgbm as lgb\n\nlgb=lgb.LGBMClassifier()\nlgb.fit(X_train,y_train)\npreds5=lgb.predict(X_test)\nacc_lgb=(preds5==y_test).sum().astype(float)/len(preds)*100\nprint(\"Accuracy of LightGBM Classifier: \",acc_lgb)","metadata":{"_uuid":"b62367ae8784e5d462e3f19220714357900364b5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### I'm not going for SVM. I'm also not trying Neural Networks because data is very less. So we will put up a comparison of the scores of the different algorithms.","metadata":{"_uuid":"d692bdf3884b0563b3d70d32310e45c38b6236ef"}},{"cell_type":"markdown","source":"### Comparison of the Accuracy scores of all the algorithms","metadata":{"_uuid":"9a57d3eda2b3b97f1bfe8b8f4b3a81f8bb4ee7b2","trusted":true}},{"cell_type":"code","source":"trace1 = go.Bar(\n    x=['KNN','Naive Bayes','Random Forest','XGBoost','LightGBM'],\n    y=[acc_knn,acc_gnb,acc_rf,acc_xgb,acc_lgb],\n    name = 'Accuracy Comparisons of the 4 algorithms',\n        marker=dict(\n        color=cnt_srs.values,\n        colorscale = 'Picnic'\n    ),\n)\n\nlayout = go.Layout(\n    title='Accuracy Score Ratio'\n)\n\ndata = [trace1]\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename=\"Ratio\")","metadata":{"_kg_hide-input":true,"_uuid":"09206669c86649265d020a06a3406d70af074f51","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#### Not much of a difference between XGBoost and LightGBM. Lets try out XGBoost with some parameter tuning.\n--------------------------------------------------------------------","metadata":{"_uuid":"37073d9850ea54512ecdf5d5848e409f124a1b6f"}},{"cell_type":"markdown","source":"### XGBoost with Parameter Tuning","metadata":{"_uuid":"bf9a9d211c4e2ca55809a3c1eeec37d241b020fb"}},{"cell_type":"code","source":"from sklearn.cross_validation import *\nfrom sklearn.grid_search import GridSearchCV\n\nparameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n              'objective':['multi:softmax'],\n              'learning_rate': [0.05], #so called `eta` value\n              'max_depth': [6],\n              'min_child_weight': [11],\n              'silent': [1],\n              'subsample': [0.8],\n              'colsample_bytree': [0.7],\n              'n_estimators': [1000], #number of trees, change it to 1000 for better results\n              'missing':[-999],\n              'seed': [1337]}\n\n\nclf = GridSearchCV(xgb, parameters, n_jobs=5, \n                   cv=StratifiedKFold(y_train, n_folds=5, shuffle=True),\n                   verbose=2, refit=True)\n\nclf.fit(X_train, y_train)\npreds6=clf.predict(X_test)\n\nacc_xgbpt=(preds6==y_test).sum().astype(float)/len(preds)*100\nprint(\"Accuracy of XGBoost Classifier after parameter tuning: \",acc_xgbpt)","metadata":{"_uuid":"ef7f8ebd5a5a4b2c2d30147c5c9de9c49670a1bf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets check the difference in the accuracy scores","metadata":{"_uuid":"60f6cde2ca8d719e158aa3abb467c85efb437192"}},{"cell_type":"code","source":"print(\"Accuracy decreased by =\",(acc_xgb-acc_xgbpt),\"% after parameter tuning with GridSearchCV\")","metadata":{"_uuid":"740c531e3c8b8f163b7b227116264eddaad8fc22","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### So it seems that in this case XGBoost with default parameters worked well","metadata":{"_uuid":"93a7d6aeaf9744a9652bdc707e9a0442ceb72bf6"}},{"cell_type":"code","source":"from keras.utils import to_categorical\n\ny_train=to_categorical(y_train)\ny_test=to_categorical(y_test)","metadata":{"_uuid":"f846352b0e30ad83b79e684616289629066fbafd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense,Dropout\n\nmodel=Sequential()\nmodel.add(Dense(50, activation = \"relu\", input_shape=(14, )))\n# Hidden - Layers\nmodel.add(Dropout(0.3, noise_shape=None, seed=None))\nmodel.add(Dense(50, activation = \"relu\"))\nmodel.add(Dropout(0.2, noise_shape=None, seed=None))\nmodel.add(Dense(50, activation = \"relu\"))\n# Output- Layer\nmodel.add(Dense(4, activation = \"softmax\"))\nmodel.summary()","metadata":{"_uuid":"99fe10af1f99590e8552d41a18819978cf8e06a3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n optimizer = \"RMSProp\",\n loss = \"categorical_crossentropy\",\n metrics = [\"accuracy\"]\n)","metadata":{"_uuid":"43affa76d3ad09c8712b454748dbdfe736d577ea","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = model.fit(\n X_train, y_train,\n epochs= 10,\n batch_size = 32,\n validation_data = (X_test, y_test)\n)","metadata":{"_uuid":"53984508d547a3bf76240ff62877cdd06f979666","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### So we see because of the less amount of data, neural networks couldn't perform well.","metadata":{"_uuid":"489e69f75b59dc94bfabb77511437e21ba0a4055"}},{"cell_type":"code","source":"# going to add PyTorch version of deep learning soon","metadata":{"scrolled":true,"_uuid":"bfc207338c9f4a39303320f1e2374a9cf1ecad20","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"b9bbb9b223a652f3a44b67e9e2ce8b8c840934b4","trusted":true},"execution_count":null,"outputs":[]}]}