{"cells":[{"metadata":{"_uuid":"ab74f3e8043f16f2fe17f2c635e42cc2fd83004d"},"cell_type":"markdown","source":"# 1. Import"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# System\nimport os\n\n# Time\nimport time\nimport datetime\n\n# Numerical\nimport numpy as np\nimport pandas as pd\n\n# Tools\nimport itertools\nfrom collections import Counter\n\n# NLP\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize \nfrom nltk.stem import SnowballStemmer\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n# from pywsd.utils import lemmatize_sentence\n\n# Preprocessing\nfrom sklearn import preprocessing\nfrom sklearn.utils import class_weight as cw\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\n\n# Model Selection\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n\n# Machine Learning Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Evaluation Metrics\nfrom sklearn import metrics \nfrom sklearn.metrics import f1_score, accuracy_score,confusion_matrix,classification_report\n\n# Deep Learing Preprocessing - Keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.utils import to_categorical\n\n# Deep Learning Model - Keras\nfrom keras.models import Model\nfrom keras.models import Sequential\n\n# Deep Learning Model - Keras - CNN\nfrom keras.layers import Conv1D, Conv2D, Convolution1D, MaxPooling1D, SeparableConv1D, SpatialDropout1D, \\\n    GlobalAvgPool1D, GlobalMaxPool1D, GlobalMaxPooling1D \nfrom keras.layers.pooling import _GlobalPooling1D\nfrom keras.layers import MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D\n\n# Deep Learning Model - Keras - RNN\nfrom keras.layers import Embedding, LSTM, Bidirectional\n\n# Deep Learning Model - Keras - General\nfrom keras.layers import Input, Add, concatenate, Dense, Activation, BatchNormalization, Dropout, Flatten\nfrom keras.layers import LeakyReLU, PReLU, Lambda, Multiply\n\n\n\n# Deep Learning Parameters - Keras\nfrom keras.optimizers import RMSprop, Adam\n\n# Deep Learning Callbacs - Keras\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"809bef8c82e3e9e04cd915f6c0435d3050039562"},"cell_type":"markdown","source":"# 2. Functions"},{"metadata":{"trusted":true,"_uuid":"caf53e5f5ea79d784d896933501f91f9050d30b8"},"cell_type":"code","source":"# print date and time for given type of representation\ndef date_time(x):\n    if x==1:\n        return 'Timestamp: {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now())\n    if x==2:    \n        return 'Timestamp: {:%Y-%b-%d %H:%M:%S}'.format(datetime.datetime.now())\n    if x==3:  \n        return 'Date now: %s' % datetime.datetime.now()\n    if x==4:  \n        return 'Date today: %s' % datetime.date.today() ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a7581c6f62ed78c0f84155c2e07c099c976949e"},"cell_type":"markdown","source":"# 3. Read Data"},{"metadata":{"trusted":true,"_uuid":"ef89485c83784feeb7ecede608156d389de85807"},"cell_type":"code","source":"input_directory = r\"../input/\"\noutput_directory = r\"../output/\"\n\nif not os.path.exists(output_directory):\n    os.mkdir(output_directory)\n    \nfigure_directory = \"../output/figures\"\nif not os.path.exists(figure_directory):\n    os.mkdir(figure_directory)\n    \n    \nfile_name_pred_batch = figure_directory+r\"/result\"\nfile_name_pred_sample = figure_directory+r\"/sample\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"152c3ec690445b1f9e7b0ff8452fd1a3125b6b4f"},"cell_type":"code","source":"df = pd.read_csv(input_directory + \"spam.csv\", encoding='latin-1')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6893fd589c9e65ecd0dd1fcf6f5e95f0c4879313"},"cell_type":"code","source":"df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1, inplace=True)\ndf = df.rename(columns={\"v1\":\"label\", \"v2\":\"text\"})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"8933484628abcbc1874c92bc94ff6f9cff932e5a"},"cell_type":"code","source":"df_new = df.copy()\ndf_stat = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"c602e992fd619ed67d31304e94c559748432a3ad"},"cell_type":"code","source":"lmm = WordNetLemmatizer()\nporter_stemmer = PorterStemmer()\nsnowball_stemmer = SnowballStemmer('english')\n\nstop_words = set(stopwords.words('english'))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"7d05188f21c41a1ee7264b61bfd26f932896e94e"},"cell_type":"code","source":"# df_new['parsed'] = df_new['text'].apply(lambda x: x.lower())\n# df_new['parsed'] = df_new['parsed'].apply(lambda x: word_tokenize(x))\n\n# df_new['no_stop'] = df_new['parsed'].apply(lambda x: [word for word in str(x).split() if word not in stop_words])\n\n# df_new['stem'] = df_new['no_stop'].apply(lambda x: [snowball_stemmer.stem(word) for word in x])\n# df_new['stem'] =  df_new['stem'].apply(lambda x: \" \".join(x))\n\n# df_new['lemi'] =  df_new['no_stop'].apply(lambda x: \" \".join(x))\n# df_new['lemi'] =  df_new['lemi'].apply(lambda x: lmm.lemmatize(x))\n\n# df_new['parsed'] = df_new['parsed'].apply(lambda x: ' '.join(x))\n# df_new['no_stop'] = df_new['no_stop'].apply(lambda x: ' '.join(x))\n# df_new['stem'] = df_new['stem'].apply(lambda x: ' '.join(x))\n# df_new['lemi'] = df_new['lemi'].apply(lambda x: ' '.join(x))\n\n# df_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64eacf9f0e67ecd843f1a5f3e2aa9b252c8ac3c5"},"cell_type":"code","source":"df_stat[\"text_clean\"] = df_stat[\"text\"].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x.lower()))\n\ndf_stat[\"length\"] = df_stat[\"text\"].apply(lambda x: len(x))\ndf_stat[\"token_count\"] = df_stat[\"text\"].apply(lambda x: len(x.split(\" \")))\ndf_stat[\"unique_token_count\"] = df_stat[\"text\"].apply(lambda x: len(set(x.lower().split(\" \"))))\ndf_stat[\"unique_token_count_percent\"] = df_stat[\"unique_token_count\"]/df_stat[\"token_count\"]\n\ndf_stat[\"length_clean\"] = df_stat[\"text_clean\"].apply(lambda x: len(x))\ndf_stat[\"token_count_clean\"] = df_stat[\"text_clean\"].apply(lambda x: len(x.split(\" \")))\n\ndf_stat.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87cafe9f35c49dda5ff8759e5f9360a8f58674de"},"cell_type":"markdown","source":"# 4 . Visualization"},{"metadata":{"trusted":true,"_uuid":"7e45b35ef0bb615dec12ce7816065e181d1fe075"},"cell_type":"code","source":"sns.set_style(\"ticks\")\nfigsize=(20, 5)\n\nticksize = 18\ntitlesize = ticksize + 8\nlabelsize = ticksize + 5\n\nxlabel = \"Label\"\nylabel = \"Count\"\n\ntitle = \"Number of ham and spam messages\"\n\n\nparams = {'figure.figsize' : figsize,\n          'axes.labelsize' : labelsize,\n          'axes.titlesize' : titlesize,\n          'xtick.labelsize': ticksize,\n          'ytick.labelsize': ticksize}\n\nplt.rcParams.update(params)\n\ncol1 = \"label\"\ncol2 = \"label\"\nsns.countplot(x=df[col1])\nplt.title(title.title())\nplt.xlabel(xlabel)\nplt.ylabel(ylabel)\nplt.xticks(rotation=90)\nplt.plot()\n\ndf.label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efb093444f8c53fe0c3c61892eb37b89a90d95ae"},"cell_type":"code","source":"s1 = df_stat[df_stat['label'] == 'ham']['text'].str.len()\ns2 = df_stat[df_stat['label'] == 'spam']['text'].str.len()\ns3 = df_stat[df_stat['label'] == 'ham']['text_clean'].str.len()\ns4 = df_stat[df_stat['label'] == 'spam']['text_clean'].str.len()\ns5 = df_stat[df_stat['label'] == 'ham']['text'].str.split().str.len()\ns6 = df_stat[df_stat['label'] == 'spam']['text'].str.split().str.len()\ns7 = df_stat[df_stat['label'] == 'ham']['text_clean'].str.split().str.len()\ns8 = df_stat[df_stat['label'] == 'spam']['text_clean'].str.split().str.len()\n\nsns.set()\nsns.set_style(\"ticks\")\n\nfigsize=(20, 15)\n\nticksize = 14\ntitlesize = ticksize + 8\nlabelsize = ticksize + 5\n\nxlabel = \"Length\"\nylabel = \"Count\"\n\ntitle1 = \"Length Distribution\"\ntitle2 = \"Length Distribution (Clean)\"\ntitle3 = \"Word Count Distribution\"\ntitle4 = \"Word Count Distribution (Clean)\"\n\n\n\nparams = {'figure.figsize' : figsize,\n          'axes.labelsize' : labelsize,\n          'axes.titlesize' : titlesize,\n          'xtick.labelsize': ticksize,\n          'ytick.labelsize': ticksize}\n\nplt.rcParams.update(params)\n# fig.subplots_adjust(hspace=0.5, wspace=0.5)\n\ncol1 = \"len\"\ncol2 = \"label\"\nplt.subplot(221)\nsns.distplot(s1, label='Ham')\nsns.distplot(s2, label='Spam')\nplt.title(title1.title())\nplt.xlabel(xlabel)\nplt.ylabel(ylabel)\nplt.legend()\n\nplt.subplot(222)\nsns.distplot(s3, label='Ham (Clean)')\nsns.distplot(s4, label='Spam (Clean)')\nplt.title(title2.title())\nplt.xlabel(xlabel)\nplt.ylabel(ylabel)\nplt.legend()\n\nplt.subplot(223)\nsns.distplot(s5, label='Ham Word')\nsns.distplot(s6, label='Spam Word')\nplt.title(title3.title())\nplt.xlabel(xlabel)\nplt.ylabel(ylabel)\nplt.legend()\n\nplt.subplot(224)\nsns.distplot(s7, label='Ham Word')\nsns.distplot(s8, label='Spam Word')\nplt.title(title4.title())\nplt.xlabel(xlabel)\nplt.ylabel(ylabel)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be3d6a4151bd78e778e029e85ee2252c769e97cf"},"cell_type":"markdown","source":"# 5. Preprocessing"},{"metadata":{"trusted":true,"_uuid":"4acefb98d9509cfa8e68066634d274c7d8559f3f"},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(df[\"text\"],df[\"label\"], test_size = 0.2, random_state = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e01aeb5241fd1bd581ed93aa9b3559d169b384c5"},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a68b24695d1765f4f359ceb8cfb5b1c4d1e8d90"},"cell_type":"markdown","source":"# 6. Feature Extraction"},{"metadata":{"trusted":true,"_uuid":"76d50f7de65db0ca839b31b9b9a48e6b2713549a"},"cell_type":"code","source":"vect = CountVectorizer()\nX_train_df = vect.fit_transform(X_train)\nX_test_df = vect.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23eb2587ac1f3d207b8828ba342a58b6dd624e84"},"cell_type":"code","source":"print(vect.get_feature_names()[0:20])\nprint(vect.get_feature_names()[-20:])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"619adbc023058b64b1ffb82d13d0e6de41543242"},"cell_type":"markdown","source":"# 7. Model Trainning"},{"metadata":{"trusted":true,"_uuid":"deb82a0fff91247b7cb2af97f1289ad038edff54"},"cell_type":"code","source":"models = {\n    \"SVC\": svm.SVC(kernel=\"linear\"),\n    \"MultinomialNB\": MultinomialNB(),\n    \"LogisticRegression\": LogisticRegression(),\n    \"KNeighborsClassifier\": KNeighborsClassifier(),\n    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n    \"RandomForestClassifier\": RandomForestClassifier(),\n    \"AdaBoostClassifier\": AdaBoostClassifier(),\n    \"BaggingClassifier\": BaggingClassifier(),\n    \"ExtraTreesClassifier\": ExtraTreesClassifier()\n}\nprediction = dict()\nscore_map = {}\n\nfor model_name in models:\n    model = models[model_name]\n    model.fit(X_train_df,y_train)\n    prediction[model_name] = model.predict(X_test_df)\n    score = accuracy_score(y_test, prediction[model_name])\n    score_map[model_name] = score\n#     print(\"{}{}{}\".format(model_name, \": \", score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df40f7a8c3d258cec166eb6740284daad3d82255"},"cell_type":"code","source":"result = pd.DataFrame()\nresult[\"model\"] = score_map.keys()\nresult[\"score\"] = score_map.values()\nresult[\"score\"] = result[\"score\"].apply(lambda x: x*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"baedb3c29d16992056c688b192cd1a14a05249f1"},"cell_type":"code","source":"def plot_model_performace(result):\n    sns.set_style(\"ticks\")\n    figsize=(22, 6)\n\n    ticksize = 12\n    titlesize = ticksize + 8\n    labelsize = ticksize + 5\n\n    xlabel = \"Model\"\n    ylabel = \"Score\"\n\n    title = \"Model Performance\"\n\n    params = {'figure.figsize' : figsize,\n              'axes.labelsize' : labelsize,\n              'axes.titlesize' : titlesize,\n              'xtick.labelsize': ticksize,\n              'ytick.labelsize': ticksize}\n\n    plt.rcParams.update(params)\n\n    col1 = \"model\"\n    col2 = \"score\"\n    sns.barplot(x=col1, y=col2, data=result)\n    plt.title(title.title())\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.xticks(rotation=90)\n    plt.grid()\n    plt.plot()\n    plt.show()\n    print(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a301c88c15380dddb20f4e3915bc1e259ec004b7"},"cell_type":"code","source":"plot_model_performace(result)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56851f4965f2277568f09bd58c2e75cf5db08deb"},"cell_type":"markdown","source":"# 8. Hyper Parameter Search"},{"metadata":{"trusted":true,"_uuid":"8b1256cbb7b7f3cf991dfa1cc8fb8a9e62302898","_kg_hide-input":true},"cell_type":"code","source":"param_grid = {\n    \"C\": np.concatenate(\n        [\n            np.arange(0.0001, 0.001, 0.0001),\n            np.arange(0.001, 0.01, 0.001),\n            np.arange(0.01, 0.1, 0.01),\n            np.arange(0.1, 1, 0.1),\n            np.arange(1, 10, 1),\n            np.arange(10, 100, 5)\n        ],\n        axis=None),\n    \n    \"kernel\": (\"linear\", \"rbf\", \"poly\", \"sigmoid\"),\n#     \"kernel\": (\"linear\", \"poly\"),\n#     \"degree\": list(np.arange(1,25, 1)),\n#     \"gamma\": np.concatenate(\n#         [\n#             np.arange(0.0001, 0.001, 0.0001),\n#             np.arange(0.001, 0.01, 0.001),\n#             np.arange(0.01, 0.1, 0.01),\n#             np.arange(0.1, 1, 0.1),\n#             np.arange(1, 10, 1),\n#             np.arange(10, 100, 5)\n#         ],\n#         axis=None)\n}\n# print(param_grid)\n# model = svm.SVC(class_weight=\"balanced\")\n# grid = GridSearchCV(model, param_grid, n_jobs=-1, verbose=1, cv=3)\n# grid.fit(X_train_df,y_train)\n# print(\"{}{}\".format(\"Best Estimator: \", grid.best_estimator_))\n# print(\"{}{}\".format(\"Best Params: \", grid.best_params_))\n# print(\"{}{}\".format(\"Best Scores: \", grid.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c99bed374d4e01c81afd769b2be04d367c5928be"},"cell_type":"code","source":"param_grid = {\n    \"alpha\": np.concatenate(\n        [\n            np.arange(0.0001, 0.001, 0.0001),\n            np.arange(0.001, 0.01, 0.001),\n            np.arange(0.01, 0.1, 0.01),\n            np.arange(0.1, 1, 0.1),\n            np.arange(1, 10, 1),\n            np.arange(10, 100, 5)\n        ]) \n}\n\nmodel = MultinomialNB()\ngrid_cv_model = GridSearchCV(model, param_grid, n_jobs=-1, verbose=3, cv=3)\ngrid_cv_model.fit(X_train_df, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82822fcea3e04e03c07570292c8fa7f0dc06049f"},"cell_type":"markdown","source":"# 9. Evaluation Metrics"},{"metadata":{"trusted":true,"_uuid":"e2d2568b14c2419746e0acc1f25b0322569c5641"},"cell_type":"code","source":"print(\"{}{}\".format(\"Best Estimator: \", grid_cv_model.best_estimator_))\nprint(\"{}{}\".format(\"Best Params:    \", grid_cv_model.best_params_))\nprint(\"{}{}\".format(\"Best Scores:    \", grid_cv_model.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27818bb504dd52c3c68b0164a21c16fda2274cbb"},"cell_type":"code","source":"print(classification_report(y_test, prediction['MultinomialNB'], target_names = [\"Ham\", \"Spam\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ff638a3ec78d59d4a338429617e25746356a9e1"},"cell_type":"code","source":"def plot_confusion_matrix(y_test, y_pred, title=\"\"):\n    conf_mat = confusion_matrix(y_test, y_pred)\n    conf_mat_normalized = conf_mat.astype('float') / conf_mat.sum(axis=1)[:, np.newaxis]\n\n#     sns.set_style(\"ticks\")\n    figsize=(22, 5)\n\n    ticksize = 18\n    titlesize = ticksize + 8\n    labelsize = ticksize + 5\n\n    xlabel = \"Predicted label\"\n    ylabel = \"True label\"\n\n\n    params = {'figure.figsize' : figsize,\n              'axes.labelsize' : labelsize,\n              'axes.titlesize' : titlesize,\n              'xtick.labelsize': ticksize,\n              'ytick.labelsize': ticksize}\n\n    plt.rcParams.update(params)\n\n    plt.subplot(121)\n    sns.heatmap(conf_mat, annot=True)\n    plt.title(title)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n\n    plt.subplot(122)\n    sns.heatmap(conf_mat_normalized, annot=True)\n    plt.title(title)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.show()\n\n\n    print(\"Confusion Matrix:\\n\")\n    print(conf_mat)\n    print(\"\\n\\nConfusion Matrix Normalized:\\n\")\n    print(conf_mat_normalized)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"baf8d38e44666f7f1f19eabf2f14522fa35eb1b0"},"cell_type":"code","source":"plot_confusion_matrix(y_test, prediction['MultinomialNB'], title=\"MultinomialNB\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79992821a4f82f74c50f0e8cbdebfe688d0bcae6"},"cell_type":"code","source":"X_test[y_test < prediction[\"MultinomialNB\"] ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d217ccc21cb3e9dcd8125b12846c0393ff3a0e19"},"cell_type":"code","source":"X_test[y_test > prediction[\"MultinomialNB\"] ]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5510fdeb02df5aa0c2c4f6c20dfb7c4a39f2f60"},"cell_type":"markdown","source":"# 10. Deep Learning"},{"metadata":{"_uuid":"6b65572b0c8139eb37a96226c7c5fc08df49613c"},"cell_type":"markdown","source":"## Output Configuration"},{"metadata":{"trusted":true,"_uuid":"ef9093d656e1945590b25e6b91b1454958dade7a"},"cell_type":"code","source":"main_model_dir = output_directory + r\"models/\"\nmain_log_dir = output_directory + r\"logs/\"\n\ntry:\n    os.mkdir(main_model_dir)\nexcept:\n    print(\"Could not create main model directory\")\n    \ntry:\n    os.mkdir(main_log_dir)\nexcept:\n    print(\"Could not create main log directory\")\n\n\n\nmodel_dir = main_model_dir + time.strftime('%Y-%m-%d %H-%M-%S') + \"/\"\nlog_dir = main_log_dir + time.strftime('%Y-%m-%d %H-%M-%S')\n\n\ntry:\n    os.mkdir(model_dir)\nexcept:\n    print(\"Could not create model directory\")\n    \ntry:\n    os.mkdir(log_dir)\nexcept:\n    print(\"Could not create log directory\")\n    \nmodel_file = model_dir + \"{epoch:02d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.hdf5\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3a846d7e3577bd16fe3b95851b10c501f09b2d1"},"cell_type":"code","source":"print(\"Settting Callbacks\")\n\ncheckpoint = ModelCheckpoint(\n    model_file, \n    monitor='val_acc', \n    save_best_only=True)\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=2,\n    verbose=1,\n    restore_best_weights=True)\n\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.6,\n    patience=1,\n    verbose=1)\n\n\ncallbacks = [checkpoint, reduce_lr, early_stopping]\n\n# callbacks = [early_stopping]\n\nprint(\"Set Callbacks at \", date_time(1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42410b8507438ce15c28b5e9778908515dfaeb51"},"cell_type":"markdown","source":"## 10.1. Preprocessing"},{"metadata":{"trusted":true,"_uuid":"c97ce5c809f58080f13ab1da76fbeff96817a321"},"cell_type":"code","source":"X = df.text\nY = df.label\n\nlabel_encoder = LabelEncoder()\n\nY = label_encoder.fit_transform(Y)\n\nY = Y.reshape(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"972b31926122af0747be40fa2b5d3bf14dcbe16a"},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)\n\nmax_words = len(set(\" \".join(X_train).split()))\nmax_len = X_train.apply(lambda x: len(x)).max()\n\n# max_words = 1000\n# max_len = 150","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f82546a785e1eba0e6df397078497dffc94e902"},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=max_words)\n\ntokenizer.fit_on_texts(X_train)\n\nX_train_seq = tokenizer.texts_to_sequences(X_train)\nX_train_seq = sequence.pad_sequences(X_train_seq, maxlen=max_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15756f1979d321902f18964c00c515fb31342613"},"cell_type":"code","source":"# Calculate Class Weights\ndef get_weight(y):\n    class_weight_current =  cw.compute_class_weight('balanced', np.unique(y), y)\n    return class_weight_current","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f65f33959fa6abe41bfea8c660414a757ac048bf"},"cell_type":"code","source":"class_weight = get_weight(Y_train.flatten())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19a3f4532b9398234b6f78e758688d7903d6b66b"},"cell_type":"markdown","source":"## 10.2 Model"},{"metadata":{"trusted":true,"_uuid":"ffc3ae3a4fb844cd20a9cb33750de42b2c71392d"},"cell_type":"code","source":"def get_rnn_model():\n    model = Sequential()\n    \n    model.add(Embedding(max_words, 50, input_length=max_len))\n    model.add(LSTM(64))\n    \n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(256, activation='relu'))\n    \n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(1, activation='sigmoid'))\n    \n    model.summary()\n    \n    return model\n\n\ndef get_cnn_model():   \n    model = Sequential()\n    \n    model.add(Embedding(max_words, 50, input_length=max_len))\n    \n    model.add(Conv1D(64, 3, padding='valid', activation='relu', strides=1))\n    model.add(GlobalMaxPooling1D())\n    \n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(256, activation='relu'))\n    \n    model.add(Dropout(0.5))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(1, activation='sigmoid'))\n    \n    model.summary()\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5472569b1c7c8f13fe14c9dcac3a7957db1300e"},"cell_type":"code","source":"def plot_performance(history=None, figure_directory=None, ylim_pad=[0, 0]):\n    xlabel = 'Epoch'\n    legends = ['Training', 'Validation']\n\n    plt.figure(figsize=(20, 5))\n\n    y1 = history.history['acc']\n    y2 = history.history['val_acc']\n\n    min_y = min(min(y1), min(y2))-ylim_pad[0]\n    max_y = max(max(y1), max(y2))+ylim_pad[0]\n\n\n    plt.subplot(121)\n\n    plt.plot(y1)\n    plt.plot(y2)\n\n    plt.title('Model Accuracy\\n'+date_time(1), fontsize=17)\n    plt.xlabel(xlabel, fontsize=15)\n    plt.ylabel('Accuracy', fontsize=15)\n    plt.ylim(min_y, max_y)\n    plt.legend(legends, loc='upper left')\n    plt.grid()\n\n    y1 = history.history['loss']\n    y2 = history.history['val_loss']\n\n    min_y = min(min(y1), min(y2))-ylim_pad[1]\n    max_y = max(max(y1), max(y2))+ylim_pad[1]\n\n\n    plt.subplot(122)\n\n    plt.plot(y1)\n    plt.plot(y2)\n\n    plt.title('Model Loss\\n'+date_time(1), fontsize=17)\n    plt.xlabel(xlabel, fontsize=15)\n    plt.ylabel('Loss', fontsize=15)\n    plt.ylim(min_y, max_y)\n    plt.legend(legends, loc='upper left')\n    plt.grid()\n    if figure_directory:\n        plt.savefig(figure_directory+\"/history\")\n\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b424eb9a6e314ef397df89dcfeffc4c9c15839ee"},"cell_type":"code","source":"model1 = get_rnn_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72903b1167548759e416d9b8ba643fdf90305e06"},"cell_type":"code","source":"# loss = 'categorical_crossentropy'\nloss = 'binary_crossentropy'\nmetrics = ['accuracy']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2bd1166ccac602ca7d908e9f9b17c8ffb2a1f92c"},"cell_type":"markdown","source":"## 10.3. Model Trainning"},{"metadata":{"_uuid":"a1ce715c032b60131950b0946776b41040ec97f4"},"cell_type":"markdown","source":"### 10.3.1. RNN"},{"metadata":{"trusted":true,"_uuid":"3499506821ecfcfa499a1195742796152939cc94"},"cell_type":"code","source":"print(\"Starting...\\n\")\n\nstart_time = time.time()\nprint(date_time(1))\n\nprint(\"\\n\\nCompliling Model ...\\n\")\nlearning_rate = 0.001\noptimizer = Adam(learning_rate)\n# optimizer = Adam()\n\nmodel1.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\nverbose = 1\nepochs = 100\nbatch_size = 128\nvalidation_split = 0.2\n\nprint(\"Trainning Model ...\\n\")\n\nhistory1 = model1.fit(\n    X_train_seq,\n    Y_train,\n    batch_size=batch_size,\n    epochs=epochs,\n    verbose=verbose,\n    callbacks=callbacks,\n    validation_split=validation_split,\n    class_weight =class_weight\n    )\n\nelapsed_time = time.time() - start_time\nelapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n\nprint(\"\\nElapsed Time: \" + elapsed_time)\nprint(\"Completed Model Trainning\", date_time(1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"174b2e76795372f6e7d09d6fa48579f782609b78"},"cell_type":"markdown","source":"#### 10.3.1.2  Visualization"},{"metadata":{"trusted":true,"_uuid":"5e6865d7574bb08bfc6e20ce51c8c0a6ab39ef4c"},"cell_type":"code","source":"plot_performance(history=history1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29bb4e66b2f030e88d88ca12d48209a93991647c"},"cell_type":"markdown","source":"### 10.3.1. RNN"},{"metadata":{"trusted":true,"_uuid":"106063a66e2031658fd6649c2bc68ff54a2d6e9a"},"cell_type":"code","source":"model2 = get_cnn_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f15fae20f343530b2e83e9c890fe674fc0d3ea1a"},"cell_type":"code","source":"print(\"Starting...\\n\")\n\nstart_time = time.time()\nprint(date_time(1))\n\nprint(\"\\n\\nCompliling Model ...\\n\")\nlearning_rate = 0.001\noptimizer = Adam(learning_rate)\n# optimizer = Adam()\n\nmodel2.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\nverbose = 1\nepochs = 100\nbatch_size = 128\nvalidation_split = 0.2\n\nprint(\"Trainning Model ...\\n\")\n\nhistory2 = model2.fit(\n    X_train_seq,\n    Y_train,\n    batch_size=batch_size,\n    epochs=epochs,\n    verbose=verbose,\n    callbacks=callbacks,\n    validation_split=validation_split,\n    class_weight =class_weight\n    )\n\nelapsed_time = time.time() - start_time\nelapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n\nprint(\"\\nElapsed Time: \" + elapsed_time)\nprint(\"Completed Model Trainning\", date_time(1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"357b590e09d3e623822c3e68b280ef42db952075"},"cell_type":"markdown","source":"#### 10.3.1.2 Visualization"},{"metadata":{"trusted":true,"_uuid":"50d81ffc4f78b45a59b7f08ec404d008a3c63f94"},"cell_type":"code","source":"plot_performance(history=history2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b64920b6ac5a1bb4e60f1d937245007292dd1681"},"cell_type":"markdown","source":"## 10.5 Inference/ Prediction"},{"metadata":{"trusted":true,"_uuid":"a6e1d8e3639c5e739a67c484b00faf148fa6edd4"},"cell_type":"code","source":"test_X_seq = tokenizer.texts_to_sequences(X_test)\ntest_X_seq = sequence.pad_sequences(test_X_seq, maxlen=max_len)\naccuracy1 = model1.evaluate(test_X_seq, Y_test)\naccuracy2 = model2.evaluate(test_X_seq, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08c78c65d45aaa855de2d16533dc5ddeb1a52c9b"},"cell_type":"markdown","source":"### 10.5.1 Evaluation"},{"metadata":{"trusted":true,"_uuid":"fd3d9e8a332ab50eb69d3995fa0847c642ca942d"},"cell_type":"code","source":"print(\"Model Performance of RNN (Test Accuracy):\")\nprint('Accuracy: {:0.2f}%\\nLoss: {:0.3f}\\n'.format(accuracy1[1]*100, accuracy1[0]))\n\nprint(\"\\nModel Performance of RNN (Test Accuracy):\")\nprint('v: {:0.2f}%\\nLoss: {:0.3f}\\n'.format(accuracy2[1]*100, accuracy2[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68d1b5720cecae415e852c1f35563da08cfea2b5"},"cell_type":"code","source":"ypreds1 = model1.predict_classes(test_X_seq, verbose=1)\nypreds2 = model2.predict_classes(test_X_seq, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc19b344d18b16e4f15d4b21eb86bf6acde8c2f0"},"cell_type":"code","source":"print(classification_report(Y_test, ypreds1, target_names = [\"Ham\", \"Spam\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47e7e60a9e06662083a4971f84589129d307be40"},"cell_type":"code","source":"plot_confusion_matrix(Y_test, ypreds1, title=\"RNN\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fc73dddd076f5c15ff41a9dff2abf47d7126589"},"cell_type":"code","source":"print(classification_report(Y_test, ypreds2, target_names = [\"Ham\", \"Spam\"]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73e7f87fdfb70dd3eddabd607a9eefb96a086831"},"cell_type":"markdown","source":"#### 10.5.1.2 Visualization"},{"metadata":{"trusted":true,"_uuid":"675a75e41d24b34491a9b9e310b30803b90e9188"},"cell_type":"code","source":"plot_confusion_matrix(Y_test, ypreds2, title=\"CNN\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6679f27d3d8d66fcc4c99d3183821051f823f688"},"cell_type":"code","source":"row1 = pd.DataFrame({'model': 'RNN', 'score': accuracy1[1]*100}, index=[-1])\nresult = pd.concat([row1, result.ix[:]]).reset_index(drop=True)\nrow2 = pd.DataFrame({'model': 'CNN', 'score': accuracy2[1]*100}, index=[-1])\nresult = pd.concat([row2, result.ix[:]]).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa8ce5f06a1b2884dd5b1c113dcd041c86aa26bb"},"cell_type":"code","source":"plot_model_performace(result)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abb7d608d7ed5bcd412125d31d176a022d599444"},"cell_type":"markdown","source":"# Reference:\n1. [Text Preprocessing and Machine Learning Modeling](https://www.kaggle.com/futurist/text-preprocessing-and-machine-learning-modeling)\n2. [keras mlp cnn test for text classification](https://www.kaggle.com/jacklinggu/keras-mlp-cnn-test-for-text-classification)"},{"metadata":{"trusted":true,"_uuid":"4508c011e7f7449b027acc000decbf6561e69ca0"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}