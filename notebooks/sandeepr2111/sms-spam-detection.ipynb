{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Importing Libraries","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Reading text based Dataset into pandas DataFrame","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df=pd.read_csv('../input/sms-spam-collection-dataset/spam.csv',encoding='latin-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The datafraem has 5572 Rows and 5 columns, we can check the total Null values in dataframe which is shown below","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Except Column v1 and v2 all columns have large NaN values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df.isnull().mean()*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of unnamed columns have huge value of NaN it's best we drop all the unnamed columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df.dropna(how='any',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df.columns=['Tag','Message']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"spam ='Message which is labelled as Spam'\n\nham = 'Message which is labelled as Not Spam'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Count= Total Count of Tag and Message is 5572.\n\nUnique=In Tag Column there are 2 unique characters and in Message 5169 meesages are unique\n\nTop= Tag Column as ham category as the majority class and in Message column **Sorry, I'll call later** is the Top message\n\nFreq= Ham has occured 4825 times and **Sorry, I'll call later** has occured 30 times ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df.groupby('Tag').describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dataset is imbalanced As the number of ham count is higher than spam count, in such case when the dataset is applied to Machine Learning the Algorithm becomes highly biased\n\nWe have to consider the label which has less count here[ham] and extract the other label[spam] with the exact count so that the Data becomes Balanced.\n\nImbalanced dataset can be checked whether it is balanced or not with the help of DummyClassifier we can check with the dataset later","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since Tag column is Categorical we can convert it into numerical where:\n\nspam=1\n\nham=0","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df['Tag'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df['Tag']=np.where(sms_df['Tag']=='spam',1,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What percentage of Data are Spam?\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df['Tag'].mean()*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before modifing the Message column let's apply MultinomialNB classifier after Counter and TFid Vectorization  and check Accuracy score.\n\nDuring Text processing,cleaning the text[preprocessing] is necessary, the cleaned text have to be converted into numerical format where each word is represented by a matrix. Which is also known as word embedding.\n\nTFIDF[Term frequency Inverse document frequency]  allows us to weight terms based on how important they are to a document.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(sms_df['Message'],sms_df['Tag'],random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CountVectorizer\ncount=CountVectorizer().fit(X_train)\nX_train_Count=count.transform(X_train)\nX_test_count=count.transform(X_test)\n\n#TfidfVectorizer\n\nTfid=TfidfVectorizer().fit(X_train)\nX_train_Tfid=Tfid.transform(X_train)\nX_test_Tfid=Tfid.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"min_df[x]: The minimum number of times the term variable should appear in the document i.e the term variable wil be deleted which appears less than x times\n\nngram_range[min,max]: the grouping is done from min upto max times","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_count=MultinomialNB(alpha=0.1)\nclf_count.fit(X_train_Count,y_train)\npred=clf_count.predict(X_test_count)\nprint('ROC score by applying Countvectorizer:',roc_auc_score(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_Tfid=MultinomialNB(alpha=0.1)\nclf_Tfid.fit(X_train_Tfid,y_train)\npred=clf_Tfid.predict(X_test_Tfid)\nprint('ROC score by applying TfidfVectorizer:',roc_auc_score(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_names=np.array(count.get_feature_names())\ncount_coefficients=clf_count.coef_[0].argsort()\n\nprint('Smallest 20  Count vectorizer coefficients:\\n')\nprint(feature_names[count_coefficients[:20]])\nprint('\\n\\n')\nprint('Largest 20  Count vectorizer coefficients:\\n')\nprint(feature_names[count_coefficients[-21:-1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_names=np.array(Tfid.get_feature_names())\nTfid_coefficients=clf_Tfid.coef_[0].argsort()\n\nprint('Smallest 20  Tfid vectorizer coefficients:\\n')\nprint(feature_names[Tfid_coefficients[:20]])\nprint('\\n\\n')\nprint('Largest 20  Tfid vectorizer coefficients:\\n')\nprint(feature_names[Tfid_coefficients[-21:-1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.dummy import DummyClassifier\n\ndummy=DummyClassifier(strategy='prior').fit(X_train_Count,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_predict=dummy.predict(X_test_count)\nroc_auc_score(y_test,dummy_predict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By checking with the DummyClassifier we can see that the Classifier is performing Good with Provided dataset no modification needs to de done to Dataset. Let's continue Feature Engineering with the same Dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_Count.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum1=X_train_Count.sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(count.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum1.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can get the largest and smallest countvectorizer and Tfid features,  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Countvectorizer Features\n\ndata=[]\n\nfor col,features in enumerate(count.get_feature_names()):\n    data.append([features,sum1[0,col]])\n    \nfeature_data=pd.DataFrame(data,columns=['Feature','Score'])\nfeature_data.sort_values(by='Score',inplace=True)\n\nprint('20 features with lowest score')\n\nprint(feature_data.head(20).sort_values(by='Score',ascending=False))\n\nprint('20 features with highest score')\nprint(feature_data.tail(20).sort_values(by='Score',ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tfidf\n\ndata1=[]\n\nTf_sum=X_train_Tfid.sum(axis=0)\n\nfor col,features in enumerate(Tfid.get_feature_names()):\n    data1.append([features,Tf_sum[0,col]])\n    \nfeature_data=pd.DataFrame(data1,columns=['Feature','Score'])\nfeature_data.sort_values(by='Score',inplace=True)\n\nprint('20 features with lowest score')\nprint('\\n')\n\nprint(feature_data.head(20).sort_values(by='Score',ascending=False))\nprint('\\n\\n')\nprint('20 features with highest score')\nprint('\\n')\nprint(feature_data.tail(20).sort_values(by='Score',ascending=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Making use of stopwords to the Message column to delete all the stopwords,and also checking the length of message length before and after applying **stopwords**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df['Message_length']=sms_df['Message'].apply(lambda x:len(x))\nsms_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nexample_sentence='This is an example showing of stop word filteration.'\nwords=word_tokenize(example_sentence)\nprint('Before applying Stopwords:\\n\\n{}'.format(words))\nstop_words=set(stopwords.words('english'))\n\nw=[]\nfor i in words:\n    if i not in stop_words:\n        w.append(i)\nprint('\\n\\n')\nprint('After applying Stopwords:\\n\\n{}'.format(w))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df['Message_stop']=sms_df['Message'].apply(lambda x: ' '.join([w for w in x.split() if w not in stop_words ]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df['Message_length_stop']=sms_df['Message_stop'].apply(lambda x:len(x))\nsms_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Deleting Message and Message_length column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df.drop(['Message','Message_length'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7,5))\nsns.countplot(x='Tag',data=sms_df)\nplt.title('Total Count of Spam and ham message\\n 1=Spam and 0=ham',size=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also check the total number of digits in Message_stop column and add it as an extra feature","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df['Number_count']=sms_df['Message_stop'].apply(lambda x:len(''.join([n for n in x if n.isdigit()])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df.head(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df['Message_stop'][5] # 6th message contains exactly 4 digits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df[sms_df['Tag']==1].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sms_df[sms_df['Tag']==0].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(1,2,figsize=(15,5))\n\nmsg_length_spam=sms_df.loc[sms_df['Tag']==1,'Message_length_stop']\nmsg_length_ham=sms_df.loc[sms_df['Tag']==0,'Message_length_stop']\n\nsns.distplot(msg_length_spam,ax=ax[0],color='r')\nax[0].set_title('Distribution of Message length of Spam',fontsize=14)\n\n\nsns.distplot(msg_length_ham,ax=ax[1],color='b')\nax[1].set_title('Distribution of Message length of ham',fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Length of messages for Spam is higher than the Ham message which means that the Spam Message has higher number of characters.\n\nSimilarly we can also plot for number_count to check whether the Spam message has high number count.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(1,2,figsize=(15,5))\n\nnumber_count_spam=sms_df.loc[sms_df['Tag']==1,'Number_count']\nnumber_count_ham=sms_df.loc[sms_df['Tag']==0,'Number_count']\n\nsns.distplot(number_count_spam,ax=ax[0],color='r')\nax[0].set_title('Distribution of numbers length of Spam',fontsize=14)\n\n\n\n# try:\n#     sns.distplot(number_count_ham,ax=ax[1],color='b')\n# except RuntimeError as re:\n#     if str(re).startswith(\"Selected KDE bandwidth is 0. Cannot estimate density.\"):\n#         sns.distplot(number_count_ham,ax=ax[1],color='b', kde_kws={'bw': 0.1})\n#         ax[1].set_title('Distribution of numbers length of ham',fontsize=14)\n#     else:\n#         raise re\n\nsns.distplot(number_count_ham,ax=ax[1],color='b', kde_kws={'bw': 0.1})\nax[1].set_title('Distribution of numbers length of ham',fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can see that there are high Count of Numbers in the Spam message than Non spam message. Which means that the spam message are also related to money where it says as winning a lottery or some value of amount will be credited etc.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Evaluate model again with new features and check the accuracy score","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X=sms_df['Message_stop']\ny=sms_df['Tag']\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # CountVectorizer\ncount=CountVectorizer(min_df=5,ngram_range=[3,6],analyzer='char').fit(X_train)\nX_train_Count=count.transform(X_train)\nX_test_Count=count.transform(X_test)\n\n#TfidfVectorizer\n\nTfid=TfidfVectorizer(min_df=5,ngram_range=[3,6],analyzer='char').fit(X_train)\nX_train_Tfid=Tfid.transform(X_train)\nX_test_Tfid=Tfid.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=MultinomialNB(alpha=0.1)\nclf.fit(X_train_Count,y_train)\ntrain_pred=clf.predict(X_train_Count)\nprint('ROC score of Training by applying Countvectorizer:',roc_auc_score(train_pred,y_train))\npred_count=clf.predict(X_test_Count)\nprint('ROC score of Testing by applying Countvectorizer:',roc_auc_score(y_test,pred_count))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions of MultinomialNB using CountVectorization\n\nx=['do you have plans for weekend?, let us meet at our usual place',\n  'Hii, you are our lucky customer, you have won 100000000 Rs, Please provide your account details we will transfer the amount',\n  'Your account is freezed please provide your account details to unfreeze the account',\n  'Hi, Pooja you have been selected for the First round of interview with Wipro, you need to visit our campus on Next Monday']\ndata=pd.Series(x)\ntrans=count.transform(data)\nclf.predict(trans)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf=MultinomialNB(alpha=0.1)\nclf.fit(X_train_Tfid,y_train)\ntrain_pred=clf.predict(X_train_Tfid)\nprint('ROC score of Training by applying TFidVectorizer:',roc_auc_score(train_pred,y_train))\npred_tfid=clf.predict(X_test_Tfid)\nprint('ROC score of Testing by applying TFidVectorizer:',roc_auc_score(y_test,pred_tfid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions of MultinomialNB using TfidVectorization\n\nx=['do you have plans for weekend?, let us meet at our usual place',\n  'Hii, you are our lucky customer, you have won 100000000 Rs, Please provide your account details we will transfer the amount',\n  'Your account is freezed please provide your account details to unfreeze the account',\n  'Hi, Pooja you have been selected for the First round of interview with Wipro, you need to visit our campus on Next Monday for interview process']\ndata=pd.Series(x)\ntrans=Tfid.transform(data)\nclf.predict(trans)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can apply Confusion matrix and check the Performance of a Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('confusion matrix ')\nconf_count=confusion_matrix(y_test,pred_count)\nprint('Confusion matrix for classifier using Countvectorizer:\\n\\n{}'.format(conf_count))\nconf_tfid=confusion_matrix(y_test,pred_tfid)\nprint('Confusion matrix for classifier using TFidVectorizer:\\n\\n{}'.format(conf_tfid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('classification report')\nconf_report=classification_report(y_test,pred_count)\nprint('Classification report for classifier using Countvectorizer:\\n\\n{}'.format(conf_report))\nconf_report=classification_report(y_test,pred_tfid)\nprint('Classification report for classifier using TFidVectorizer:\\n\\n{}'.format(conf_report))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With the message provided the Predicition of MultoMultinomialNB are Correctly predicted for both Count and Tfid Vectorizations\n\nLet's check with the other Classifiers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n#Countvectorizer\nlog_clf=LogisticRegression(C=100)\nlog_clf.fit(X_train_Count,y_train)\ntrain_pred=log_clf.predict(X_train_Count)\nprint(roc_auc_score(train_pred,y_train))\nlog_pre=log_clf.predict(X_test_Count)\nprint(roc_auc_score(y_test,log_pre))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tfid\n\nlog_clf=LogisticRegression(C=100)\nlog_clf.fit(X_train_Tfid,y_train)\ntrain_pred=log_clf.predict(X_train_Tfid)\nprint(roc_auc_score(train_pred,y_train))\nlog_pre=log_clf.predict(X_test_Tfid)\nprint(roc_auc_score(y_test,log_pre))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n#Count\ntree_clf=DecisionTreeClassifier(max_depth=3)\ntree_clf.fit(X_train_Count,y_train)\ntrain_pred=tree_clf.predict(X_train_Count)\nprint(roc_auc_score(train_pred,y_train))\ntest_pred=tree_clf.predict(X_test_Count)\nprint(roc_auc_score(test_pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tfid\ntree_clf=DecisionTreeClassifier(max_depth=2)\ntree_clf.fit(X_train_Tfid,y_train)\ntrain_pred=tree_clf.predict(X_train_Tfid)\nprint(roc_auc_score(train_pred,y_train))\ntest_pred=tree_clf.predict(X_test_Count)\nprint(roc_auc_score(test_pred,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#                 Thank you.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}