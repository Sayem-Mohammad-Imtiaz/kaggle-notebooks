{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Oceanographic Analysis - CalCOFI Capstone"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import IFrame\nembed = \"https://docs.google.com/presentation/d/e/2PACX-1vTFUKkshFjS3SpFm392ru6L5CVemXbfU2Op1NaaEFiW16x4Je70wKbiR0u_TcR0UyqOiINeGCNVUquK/embed?\"\nIFrame(embed,frameborder=\"0\", width=\"900\", align=\"center\", height=\"569\", allowfullscreen=\"true\", mozallowfullscreen=\"true\", webkitallowfullscreen=\"true\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Problem Identification"},{"metadata":{},"cell_type":"markdown","source":"###  <font color='blue'>Problem Statement</font>\n<strong>Help policy makers understand oceanographic trends to make intelligent choices that will save the marine ecosystem.</strong>\n\n### Summary\nThe California Cooperative Oceanic Fisheries Investigations (CalCOFI) are a unique partnership of the California Department of Fish & Wildlife, NOAA Fisheries Service and Scripps Institution of Oceanography. The organization was formed in 1949 to study the ecological aspects of the sardine population collapse off California. Today their focus has shifted to the study of the marine environment off the coast of California, the management of its living resources, and monitoring the indicators of El Nino and climate change. CalCOFI conducts quarterly cruises off southern & central California, collecting a suite of hydrographic and biological data on station and underway.  Data collected at depths down to 500 meters include: temperature, salinity, oxygen, phosphate, silicate, nitrate and nitrite, chlorophyll, transmissometer, PAR, C14 primary productivity, phytoplankton biodiversity, zooplankton biomass, and zooplankton biodiversity.\n\n### Overview\n<p>Oceonography, the study of the biological features of the ocean, is important to determine the factors threatening the ocean and its marine life. Studying the ocean is also importance since it covers more than 70 percent of the surface of our planet.\nAccording to NASA, big shifts in salinity could be a warning that more severe droughts and floods are on their way, or even that global warming is speeding up.\n</p>\n\n### Context\nSince climate changes today has been altering the oceanâ€™s chemistry, it is important to understand the trends that are threatening the ocean and its marine life. The changes in temperature effects the melting of ice, and changes in sea levels and ocean currents.  \nThe migration pattern of marine species disrupts, and some marine species are on the verge of extinction.\n\n### Criteria for Success\nBuild a model that can accurately obtain and predict the factors affecting the ocean.\n\n### Scope of Solution Space\nDetermine the top 5 important features that are useful to predict the factors threatening the ocean.\nBuild additional features out of existing data (Feature Engineering) and perform Exploratory Data Analysis.\n\n### Constraints within Solution Space\nThere are 61 features, but most of them have missing data.\n\n### Data Acquisition and Key Data Sources\nThe data is provided from CalCOFI \n\nhttps://calcofi.org/ccdata/database.html\n\nThe following table includes the most important features of the dataset and their description.\n\n| | <strong>Features</strong> | <strong>Description</strong> |\n|------|------:|------|\n| 1 | Depthm | Depth of ocean in meters|\n| 2 | TempDegF | Temperature of Water in Fahrenheit|\n| 3 | Salinity | Salinity of water|\n| 4 | STheta | Potential Density of Water|\n"},{"metadata":{},"cell_type":"markdown","source":"# 2. Data Wrangling\n- Collect, organize, define, and clean relevant datasets."},{"metadata":{},"cell_type":"markdown","source":"## Data Collection"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import necessary libraries\nimport pandas as pd\nimport numpy as np\n\n# Plotting modules\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Analysing datetime\nfrom datetime import datetime as dt\nfrom datetime import timedelta\n\n# File system manangement\nimport os,sys\n\n# Suppress warnings \nimport warnings\nwarnings.filterwarnings('ignore')\n\n#Interactive Shell\nfrom IPython.core.interactiveshell import InteractiveShell  \nInteractiveShell.ast_node_interactivity = \"all\"\n\n#Pandas profiling\nfrom pandas_profiling import ProfileReport\n\nimport missingno as msno\nimport re \n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Workspace"},{"metadata":{"trusted":true},"cell_type":"code","source":"cwd = os.getcwd()\nprint(cwd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(cwd)\n#os.listdir( os.getcwd() )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load the Data from CSV File"},{"metadata":{"trusted":true},"cell_type":"code","source":"#KAGGLE.com\npath = '/kaggle/input/calcofi/bottle.csv'\nbottle = pd.read_csv(path) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import CSV file and read the dataset\n#path = '../data/calcofi/bottle.csv'\n#bottle = pd.read_csv(path, encoding='latin-1') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show all columns\npd.set_option('max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### First 5 rows "},{"metadata":{"trusted":true},"cell_type":"code","source":"bottle.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Last 3 rows"},{"metadata":{"trusted":true},"cell_type":"code","source":"bottle.tail(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert Celcius to Fahr\ndef cel_to_fahr(x):\n    x = x * 1.8 + 32\n    return float(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dimensions of the dataset. #(samples,features)\nprint(\"There are\", bottle.shape[0], \"Rows(Observations).\")\nprint(\"There are\", bottle.shape[1], \"Columns(Features).\")\nbottle.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"___"},{"metadata":{},"cell_type":"markdown","source":"## Data Organization"},{"metadata":{},"cell_type":"markdown","source":"#### Create SubFolders"},{"metadata":{"trusted":true},"cell_type":"code","source":"newfolder = \"../OceanographicAnalysisCalCOFI/data\"\n\ntry:\n    os.mkdir(newfolder)\nexcept OSError:\n    print (\"Creation of the directory %s failed\" % newfolder)\nelse:\n    print (\"Successfully created the directory %s \" % newfolder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newfolder = \"../OceanographicAnalysisCalCOFI/figures\"\n\ntry:\n    os.mkdir(newfolder)\nexcept OSError:\n    print (\"Creation of the directory %s failed\" % newfolder)\nelse:\n    print (\"Successfully created the directory %s \" % newfolder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newfolder = \"../OceanographicAnalysisCalCOFI/models\"\n\ntry:\n    os.mkdir(newfolder)\nexcept OSError:\n    print (\"Creation of the directory %s failed\" % newfolder)\nelse:\n    print (\"Successfully created the directory %s \" % newfolder)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## Data Definition"},{"metadata":{},"cell_type":"markdown","source":"### Explore the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get DataFrame Information\nbottle.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no missing values. AppointmentDay and ScheduledDay should be converted to datetime. There are 3 objects (Gender, Neighborhood, and No-show)"},{"metadata":{},"cell_type":"markdown","source":"#### Variable Types"},{"metadata":{"trusted":true},"cell_type":"code","source":"bottle.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(bottle.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Handling Missing Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Counts and percentage of null values \ndictionary = {\n    \"NullCount\":bottle.isnull().sum().sort_values(ascending=False),\n    \"NullPercent\":bottle.isnull().sum().sort_values(ascending=False)/len(bottle)*100\n}\n\nna_df = pd.DataFrame(dictionary)\nna_df.columns = ['NullCount','NullPercent']\nna_df[(na_df['NullCount'] > 0)].reset_index()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On line 40 in the previous DataFrame we see that O2ml_L is missing 19.10% of data.  So we will delete all rows that has more than 19% of missing data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"pct_null = bottle.isnull().sum() / len(bottle)\nmissing_features = pct_null[pct_null > 0.19].index\nbottle.drop(missing_features, axis=1, inplace=True)\ndf = bottle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize Missingness\nmsno.matrix(df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print ( df.nunique() / df.shape[0] * 100 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Rename Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.rename(columns = { \n    \"Cst_Cnt\": \"CastCount\",\n    \"Btl_Cnt\": \"BottleCount\",\n    \"Depthm\": \"DepthMeters\",\n    \"T_degC\": \"TempDegC\",\n    \"Salnty\": \"Salinity\",    \n    \"STheta\": \"PDensity\"\n    \n})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Set BottleCount to be Index"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.set_index('BottleCount')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extract Year and Month from Depth_ID "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract Year\nsearch = []    \n\nfor values in df['Depth_ID']:\n    search.append(re.search(r'\\d{2}-\\d{2}', values).group())\n    \ndf['Year'] = search\ndf['Year'] = df['Year'].replace(to_replace='-',value='', regex = True) \n\ndf['Year'] = pd.to_datetime(df['Year']).values.astype('datetime64[Y]')\ndf['Year'] =  pd.DatetimeIndex(df['Year']).year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract Month \nsearch = []    \n\nfor values in df['Depth_ID']:\n    search.append(re.search(r'-\\d+', values).group())\n    \ndf['Month'] = search\ndf['Month'] = df['Month'].str[-2:]\n\ndf['Month'] = df['Month'].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Convert from Celsius to Fahrenheit"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['TempDegF'] = df['TempDegC'].apply(cel_to_fahr)\ndf = df.drop(\"TempDegC\", axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Salinity:', df.Salinity.unique() ) \nprint('TempDegF:', df.TempDegF.unique() ) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset Statistics"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include=\"all\").T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"___"},{"metadata":{},"cell_type":"markdown","source":"## Detect Anomalies & Outliers"},{"metadata":{},"cell_type":"markdown","source":"#### Range of values per column"},{"metadata":{"trusted":true},"cell_type":"code","source":"range = df.aggregate([min, max])\nprint(range)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Year - Month"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='Year',data=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Currently, we are in 2020. We will remove all the years after that including 2093"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Year'] = df['Year'].drop(df[df['Year']>2020].index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset has months of more than 12, so we will drop them too."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Month'] = df['Month'].drop(df[df['Month']>12].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Salinity\"].describe(include=\"all\").T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"TempDegF\"].describe(include=\"all\").T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Check for Duplicated Rows"},{"metadata":{"trusted":true},"cell_type":"code","source":"duplicateRowsDF = df.duplicated() \ndf[duplicateRowsDF]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop_duplicates(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"#  3. EXPLORATORY DATA ANALYSIS"},{"metadata":{},"cell_type":"markdown","source":"#### Categorical columns and their associated levels."},{"metadata":{"trusted":true},"cell_type":"code","source":"dfo = df.select_dtypes(include=['object'], exclude=['datetime'])\ndfo.shape\n#get levels for all variables\nvn = pd.DataFrame(dfo.nunique()).reset_index()\nvn.columns = ['VarName', 'LevelsCount']\nvn.sort_values(by='LevelsCount', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['Depth_ID','Sta_ID'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df.corr()\n\nplt.figure(figsize=(20,10))\nsns.heatmap(corr,\n            linecolor='blue',linewidths=.1, \n            cmap=\"YlGnBu\", annot=True)\nplt.yticks(rotation=0);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"C14A1q, C14A2q, DarkAq, and MeanAq all have a high correlation so we will keep MeanAq. The Reported Depth, Salinity, temp, and R_DYNHT have a positive correlation with the actual findings so we will only keep the Reported Dynamic Height.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['CastCount','R_Depth','R_TEMP', 'R_SALINITY', 'C14A1q', 'C14A2q', 'DarkAq' ], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. PreProcessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SimpleImputer"},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_transformer = Pipeline(\n    steps=[\n        ('imputer', SimpleImputer(strategy='mean')),\n        ('scaler', StandardScaler())\n])\n\nnumeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n\npreprocessor = ColumnTransformer(\n    remainder='passthrough',\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n    ]\n)\n\nsteps = [('preprocessor', preprocessor)]\n\npipeline = Pipeline(steps)\n\npipeline.fit(df[:])\ndf_pipe = pipeline.transform(df[:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pipe = pd.DataFrame(df_pipe)\ndf_pipe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Change the name of columns back to original names.\ndf_pipe.columns = df.columns\n\ndf_pipe.sample()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. MODELING"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import mean_squared_error\n\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_names = [\"Salinity\",\"TempDegF\"]\nsal_temp = df.reindex(columns=column_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sal_temp['Salinity'].fillna((sal_temp['Salinity'].mean()), inplace=True)\nsal_temp['TempDegF'].fillna((sal_temp['TempDegF'].mean()), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Simple Linear Regression:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sal_temp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = sal_temp.Salinity.values\ny = sal_temp.TempDegF.values\n\n# Print the dimensions of X and y before reshaping\nprint(\"Dimensions of y before reshaping: {}\".format(y.shape))\nprint(\"Dimensions of X before reshaping: {}\".format(X.shape))\n\n# Reshape X and y\ny = y.reshape(-1,1)\nX = X.reshape(-1,1)\n\n# Print the dimensions of X and y after reshaping\nprint(\"Dimensions of y after reshaping: {}\".format(y.shape))\nprint(\"Dimensions of X after reshaping: {}\".format(X.shape))\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LinearRegression()\nmodel.fit(X_train, y_train)\n\n#Predict the Test set results\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Visualize the Training set results"},{"metadata":{"trusted":true},"cell_type":"code","source":"_= plt.scatter(X_train, y_train, color = 'red')\n_= plt.plot(X_train, model.predict(X_train), color = 'blue')\n_= plt.title('Temperature vs Salinity (Training set)')\n_= plt.xlabel('Salinity')\n_= plt.ylabel('Temperature')\n_= plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Visualize the Test set results"},{"metadata":{"trusted":true},"cell_type":"code","source":"_= plt.scatter(X_test, y_test, color = 'red')\n_= plt.plot(X_train, model.predict(X_train), color = 'blue')\n_= plt.title('Temperature vs Salinity (Training set)')\n_= plt.xlabel('Salinity')\n_= plt.ylabel('Temperature')\n_= plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split DataSet to Training set and Test set - For entire Pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_pipe.drop(['TempDegF'],axis=1).values\ny = df_pipe.TempDegF.values\n\nSEED = 42\nTS = 0.30\n\n# Create training and test sets\nX_train, X_test, y_train, y_test = \\\n    train_test_split(X, y, test_size = TS, random_state=SEED)\n\n#Feature Scaling to prevent information leakage\n#sc = StandardScaler()\n#X_train = sc.fit_transform(X_train)\n#X_test = sc.transform(X_test)\n\nprint (X_train.shape)\nprint (y_train.shape)\n\nprint (X_test.shape)\nprint (y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Multiple Linear Regression:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create logistic regression model\nlinreg = LinearRegression()\n\n# Train the model using the training sets\nlinreg.fit(X_train, y_train)\n\n# Make predictions using the testing set\ny_pred = linreg.predict(X_test)\n\nlinreg.score(X_test,y_test)\n\nlinreg_training_score = round(linreg.score(X_train, y_train) * 100, 2)\nlinreg_test_score = round(linreg.score(X_test, y_test) * 100, 2)\n\nprint('Linear Regression Training Score: \\n', linreg_training_score)\nprint('Linear Regression Test Score: \\n', linreg_test_score)\n\n# Compute and print R^2 and RMSE\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(\"Root Mean Squared Error: {}\".format(rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 5-fold cross-validation:\ncv_scores_5 = cross_val_score(linreg, X, y, cv=5)\nprint(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores_5)))\n\n\n# 15-fold cross-validation:\ncv_scores_15 = cross_val_score(linreg, X, y, cv=15)\nprint(\"Average 15-Fold CV Score: {}\".format(np.mean(cv_scores_15)))\n\n# 25-fold cross-validation:\ncv_scores_25 = cross_val_score(linreg, X, y, cv=25)\nprint(\"Average 25-Fold CV Score: {}\".format(np.mean(cv_scores_25)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DECISION TREE:"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtr = DecisionTreeRegressor(random_state=42)\nmodel = dtr.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n\n\ndtr_training_score = round(model.score(X_train, y_train) * 100, 2)\ndtr_test_score = round(model.score(X_test, y_test) * 100, 2)\n\nprint('Decision Tree Training Score: \\n', dtr_training_score)\nprint('Decision Test Score: \\n', dtr_test_score)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## RANDOM FOREST:"},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr = RandomForestRegressor(random_state=0, n_jobs=-1)\nmodel = rfr.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\nrfr_training_score = round(model.score(X_train, y_train) * 100, 2)\nrfr_test_score = round(model.score(X_test, y_test) * 100, 2)\n\nprint('Random Forest Training Score: \\n', rfr_training_score)\nprint('Random Forest Test Score: \\n', rfr_test_score)\n\n# We will look at the predicted prices to ensure we have something sensible.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = pd.DataFrame({\n    \n    'Model': [ \n        'Linear Regression',\n        'Decision Tree',\n        'Random Forest',   \n    ],\n             \n    \n    'Training Score': [ \n        linreg_training_score,\n        dtr_training_score, \n        rfr_training_score,\n    ],\n    \n    'Test Score': [ \n        linreg_test_score,\n        dtr_test_score,\n        rfr_test_score,\n    ]})\n\n\nmodels.sort_values(by='Test Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.aggregate([min, max])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. DOCUMENTATION"},{"metadata":{},"cell_type":"markdown","source":"### Summary\nThis is Supervised Regression project to analyze Oceanographic trends.\n\nTemperature (TempDegF) is the target variable. Celsius was converted to Fahrenheit. 34 to 88 degrees F.  \n\nThe bottle samples were the observations and they were collected from 1949 to 2019.\nThe Salinity of the water was between 28 to 37.\nThe depth was between 0 to 5351 meters. \n\n### Data Preprocessing:\nDropped 15 duplicated rows. \nA Pipeline was used to direct the process of first imputing missing data by the mean using 'SimpleImputer', then 'StandardScaler' to scale\nthe dataframe. \nFor simple linear regression, only Salinity and Temperature was used. The pandas fillna method by the mean was implemented for missing values. \n\n\n### Model Performance:\nAccuracy Score: R^2: was used to determine the best model.\n\n### Model Findings:\nThe most important features where: \n- 1. Salinity()\n- 2. Temperature()\n\nThe reported Dynamic Height improved the model was removed then added to model because it improved the R^2 score significantly. "},{"metadata":{},"cell_type":"markdown","source":"## EXPORT DATA..."},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.to_csv('../data/calcofi/wrangle_csv.csv', index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_submission = pd.DataFrame({'Id': df_pipe.index, 'Temperature': print(y_pred)})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}