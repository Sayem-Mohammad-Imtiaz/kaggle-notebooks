{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1d5161f3-f0e6-8df6-27e5-ba703dd4d01e"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport os\nos.listdir(\"../input\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e332d969-80cb-e9ce-5796-aa6508bb23b7"},"outputs":[],"source":"imdb = pd.read_csv(\"../input/movie_metadata.csv\")\nimdb = imdb.reindex(np.random.permutation(imdb.index))\n\n# check dimension dataframe\nprint(imdb.shape)\n# 0 to drop index with na value, 0 to drop column with na value\ndf = imdb.dropna(axis = 0)\nprint(df.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b171687f-856d-5a76-9a10-f81ce8dfb1be"},"outputs":[],"source":"# Make histogram split 25 bins\nimport matplotlib.pyplot as plt\nplt.hist(df['imdb_score'], bins=25)\nplt.title(\"Distribution of IMDB score\")\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1f65af00-91f8-3b6d-94f4-41968cb55e3d"},"outputs":[],"source":"# change all object data type to integer category code\nolist = list(df.select_dtypes(['object']))\nfor col in olist:\n    df[col] = df[col].astype('category').cat.codes"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8dc058c7-0b27-f181-cab2-a541f6127c5f"},"outputs":[],"source":"# split dataset to training and testing\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df.drop(\"imdb_score\",1), df[\"imdb_score\"],test_size=0.20, random_state=42)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"737122ef-9fd4-fe92-5776-27c890d1211f"},"outputs":[],"source":"import pylab\nimport scipy.stats as stats\n\n# function to visualize model accuracy\ndef plot_model(x,y,model):\n    print(\"R^2: %f\" % mod.score(x,y))\n    \n    y_fitted = model.predict(x)\n    residual = y - y_fitted\n\n    plt.figure(figsize=(7,5))\n\n    plt.subplot(221)\n    plt.scatter(y_fitted, y)\n    plt.title(\"fitted value vs actual value\")\n    plt.xlabel(\"fitted value\")\n    plt.ylabel(\"actual value\")\n\n    plt.subplot(222)\n    plt.hist(residual, bins=50)\n    plt.title(\"residual histogram\")\n\n\n    plt.subplot(223)\n    stats.probplot(residual, dist=\"norm\", plot=pylab)\n\n\n    plt.subplot(224)\n    plt.scatter(y_fitted,residual)\n    plt.title(\"fitted value vs residual\")\n    plt.xlabel(\"fitted value\")\n    plt.ylabel(\"residual\")\n\n    plt.tight_layout()\n    plt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"288b7fac-ffbb-513d-4a78-cd9309bb1d5f"},"outputs":[],"source":"from sklearn import linear_model\nmod = linear_model.LinearRegression()\nmod.fit(X_train, y_train)\nplot_model(X_train,y_train,mod)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"901c0cb8-ac9c-bccb-e52f-6a5e81e03173"},"outputs":[],"source":"y_test_fitted = mod.predict(X_test)\nplt.scatter(y_test_fitted, y_test)\nplt.title(\"predicted value vs actual value\")\nplt.xlabel(\"predicted value\")\nplt.ylabel(\"actual value\")\nplt.show()\n\nprint(\"Score: %f\" % mod.score(X_test,y_test))\nprint(\"SSE: %f\" % sum((y_test_fitted-y_test)**2))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3ae55d37-f746-9089-fb7d-7fe9656c0750"},"outputs":[],"source":"imdb_score = np.array(df['imdb_score'])\npercent25 = np.percentile(imdb_score,33)\npercent75 = np.percentile(imdb_score,67)\n\nclean_list = (imdb_score>percent75) + (imdb_score<percent25)\nclassifier_clean_data = df[clean_list]\nclassifier_clean_data = classifier_clean_data.drop(\"imdb_score\",1)\n\nimdb_level = list(df['imdb_score'][clean_list]>percent75)\nimdb_level = [int(i) for i in imdb_level]\n\nx_train, x_test, y_train, y_test = train_test_split(classifier_clean_data, imdb_level, \n                                                    test_size=0.25, random_state=0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cf3dd815-5c70-2369-5f1c-4408709a235d"},"outputs":[],"source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix\nimport itertools\n\n# function to plot testing result\ndef plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = np.round(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis],2)\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d70e4579-53d7-4a00-b975-ef4126d50192"},"outputs":[],"source":"from sklearn.model_selection import cross_val_score\n\navg_score_list = []\nfor i in range(1,20):\n    mod = DecisionTreeClassifier(max_depth = i)\n    scores = cross_val_score(mod, x_train, y_train, cv=20)\n    avg_score_list.append(np.mean(scores))\n    \nplt.plot(range(1,20),avg_score_list,'--',linewidth=3)\nplt.axvline(avg_score_list.index(max(avg_score_list))+1, linewidth=3)\nplt.show()\n\nprint(\"max score reached with depth %d\" % (avg_score_list.index(max(avg_score_list))+1))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ffdd77a7-6408-f6c4-b02d-372b6c536196"},"outputs":[],"source":"def plot_test(x,y,model):\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y, [i[1] for i in model.predict_proba(x)])\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    plt.plot(false_positive_rate, true_positive_rate, \"b\", label='AUC %0.2f' % (roc_auc))\n    plt.title(\"AUC Curve\")\n    plt.show()\n\n    auc_score = roc_auc_score(y, [i[1] for i in mod.predict_proba(x)])\n    cm = confusion_matrix(y,mod.predict(x))\n    plot_confusion_matrix(cm,classes = [\"bad movie\",\"good movie\"],normalize=False)\n    print(\"AUC Score: %f\" % auc_score)\n    print(\"Accuracy: %f\" % (sum(mod.predict(x) == y)/float(len(y))))\n\n\nmod = DecisionTreeClassifier(max_depth = 7)\nmod.fit(x_train,y_train)\nplot_test(x_test,y_test,mod)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}