{"cells":[{"metadata":{"trusted":false,"collapsed":true,"_uuid":"b1f378a8482997d3e1a282bed36dcf2842bf4334"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport nltk\nimport sklearn as sklearn\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n%config InlineBackend.figure_format = 'retina'","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"85654415251956c5ee936206bea41ab2315d9fe5"},"cell_type":"markdown","source":"# Import data "},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"90e42ea034901eaa828bf3a028752ce9ca6b3475"},"cell_type":"code","source":"\ndata = pd.read_csv(\"spam.csv\",encoding='latin-1')\n#Drop column and name change\ndata = data.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\ndata = data.rename(columns={\"v1\":\"label\", \"v2\":\"text\"})\n\nfrom sklearn.preprocessing import LabelEncoder\nle = sklearn.preprocessing.LabelEncoder()\nle.fit(data[\"label\"])\ndata[\"label\"] = le.transform(data[\"label\"])    #change the labels to 0 and 1 ","execution_count":2,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"afeb9bd7633cdd263e12c7ed83c3696498a08857"},"cell_type":"markdown","source":"# Create training and testing set"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"5dfdf9390a8932c74d27b16e7215d4bac1ebfd86"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain,test = train_test_split(data, test_size = 0.3, random_state = 42,\n                                               shuffle=True, stratify= data[\"label\"] )   #select balanced sample\nX_train = train[\"text\"]\nX_test = test[\"text\"]\ny_train = train[\"label\"]\ny_test = test[\"label\"]\n#Separate the training set to \"ham\" and \"spam\" \ntrain_ham = train.loc[train.label == 0]\ntrain_spam = train.loc[train.label == 1]","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"34f0fc87dd07a145baefae31a5155748c63c6925"},"cell_type":"markdown","source":"# Examine words in two categories \nAfter converting all words to lower case, we use the RegexpTokenizer from nltk to tokenize words and remove all punctuations. \nAfter tokenising the words, we use WordNetLemmatizer as the stemming method to convert the words to their lemma and combine similar wordings. \nLastly, we remove stopwords and natural numbers and create a list with all the remaining words. "},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"f876e8a98adc478e67780b9b53e8462764040202"},"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk.tokenize import RegexpTokenizer \ntokenizer = RegexpTokenizer(r'\\w+') #tokenize words while removing punctuations\nfrom nltk.stem import WordNetLemmatizer \nlemmatizer = WordNetLemmatizer() #to combine words of same lemma ","execution_count":4,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false,"collapsed":true,"_uuid":"65a9fa73dadfa45ea3933bc4f8e86e7f771801e2"},"cell_type":"code","source":"hamword = []\nfor i in train_ham.text:\n    words = i.lower()\n    words = tokenizer.tokenize(words)\n    for j in words:\n        if j not in stopwords.words(\"english\"):\n            if not j.isdigit():\n                j = lemmatizer.lemmatize(j)\n                hamword.append(j)\n            \nspamword = []\nfor i in train_spam.text:\n    words = i.lower()\n    words = tokenizer.tokenize(words)\n    for j in words:\n        if j not in stopwords.words(\"english\"):\n            if not j.isdigit():\n                j = lemmatizer.lemmatize(j)\n                spamword.append(j)      ","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"2ec924ffee9550f1c4a9f2b905db172c5a328998"},"cell_type":"markdown","source":"Examine the top 10 words occurring in both \"Spam\" and \"ham\" messages in Xtrain"},{"metadata":{"trusted":false,"_uuid":"6d2edbb2871df0f7dbae3bef75eabac22a32751d"},"cell_type":"code","source":"from collections import Counter\nCounter(hamword).most_common(10)","execution_count":6,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"979bab13e7a0b275fadf56b708b20e90982b66e4"},"cell_type":"code","source":"Counter(spamword).most_common(10)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"7290ca01045b22a8cd4f346ff9202746a14dafde"},"cell_type":"markdown","source":"From the two tables we observe that there are some common terms like \"u\" and \"call\", but there are also words like \"free\", \"text\" and \"stop\" that tend to appear in spam messages.\n\n# Vectorizing Xtrain and Xtest \nTo prepare the training data for model building, we use vectorizer from sklearn.feature_extraction to convert Xtrain and Xtest to Compressed Sparse matrix.\nWe use TfidfVectorizer with stopword, select\"idf\"=True to reduce the weights of frequently occurred words, so that they will have less impact in the model."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"9a550ee18c4ec4afe8dc4960cdab0fe3857833fc"},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(stop_words='english',lowercase=True,use_idf=True)","execution_count":8,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"cf617daace8e2feccbc535c124cf426c3c38c337"},"cell_type":"code","source":"Xtrain = vectorizer.fit_transform(X_train)\nXtest = vectorizer.transform(X_test) #use the fitted vectorizer to transform X_test \nprint(Xtrain.shape,Xtest.shape)","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"68341edc90a9cc1d3f86151bdf5e95a47143a781"},"cell_type":"markdown","source":"# Model Building \n##  Benchmark model: Multinomial Naivebayes \nFor our benchmark model we build a Multinomail naivebayes model and examine the performance metrics.\n\nSide note: From Sklearn documentation, we learnt that BernoulliNaiveBayes is also useful with short documents and binary features. \nBy choosing (\"binary\" = True) and (\"use_idf\"=False) in TfidfVectorizer, we managed to obtain the transformed data \nas occurrence(0 or 1) instead of count. The prediction result is similar to MultinomialNB, and hence we stick to\nMultinomialNB to allow for easier comparisons among models."},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"e26f3fe027f6040e9ae225bb83a6c17e838c2ae8"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,auc","execution_count":10,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"8620b239c4f8746210738bad988c02e2fad4f5d6"},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nNB = MultinomialNB()\nNB.fit(Xtrain,y_train)\nNB_pred = NB.predict(Xtest)\nNB_pred_proba = NB.predict_proba(Xtest)","execution_count":11,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"243a0b5101b0eaacba3062df8e64a187cafa3294"},"cell_type":"code","source":"print (\"prediciton Accuracy : %f\" % accuracy_score(y_test, NB_pred))","execution_count":12,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"a2cd0deae229e43a94f617e6f9ae2692d52c77ed"},"cell_type":"code","source":"#Plot the ROC curve to examine the performance of the model \nimport scikitplot as skplt\nimport matplotlib.pyplot as plt\n\nskplt.metrics.plot_roc_curve(y_test, NB_pred_proba)\nplt.show()\nprint (\"AUC Score : %f\" % sklearn.metrics.roc_auc_score(y_test, NB_pred_proba[:,1]))","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"a9875cc444030040455acc711f8e2b45c8ea27e4"},"cell_type":"markdown","source":"While both prediction accuracy(0.968301) and ROC curve(AUC=0.987751) suggest that the model performs very well in classifying the two messages, we continue to examine the confusion matrix and classification report to analyse the results closely. \nTo visualize these two reports we use two function online. (see reference)"},{"metadata":{"trusted":false,"_uuid":"eae378042a31c5ae82621e4835f31e4ba8a1a3ba"},"cell_type":"code","source":"#Confusion Matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    print('Confusion matrix, without normalization')\n    print(cm)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\nplt.figure()\nplot_confusion_matrix(confusion_matrix(y_test,NB_pred), classes=['0', '1'], normalize=False,\n                      title='Normalized confusion matrix')\nplt.show()","execution_count":14,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"6e99db5bedf6d5bfb1141a42db6d228519e4e9c7"},"cell_type":"code","source":"#Classification table\ndef plot_classification_report(cr, title='Classification report ', with_avg_total=False, cmap=plt.cm.Blues):\n    lines = cr.split('\\n')\n    classes = []\n    plotMat = []\n    for line in lines[2 : (len(lines) - 3)]:\n        t = line.split()\n        classes.append(t[0])\n        v = [float(x) for x in t[1: len(t) - 1]]\n        print(v)\n        plotMat.append(v)\n    if with_avg_total:\n        aveTotal = lines[len(lines) - 1].split()\n        classes.append('avg/total')\n        vAveTotal = [float(x) for x in t[1:len(aveTotal) - 1]]\n        plotMat.append(vAveTotal)\n    plt.imshow(plotMat, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    x_tick_marks = np.arange(3)\n    y_tick_marks = np.arange(len(classes))\n    plt.xticks(x_tick_marks, ['precision', 'recall', 'f1-score'], rotation=45)\n    plt.yticks(y_tick_marks, classes)\n    plt.tight_layout()\n    plt.ylabel('Classes')\n    plt.xlabel('Measures')\nprint(classification_report(y_test, NB_pred, labels=['0', '1']))","execution_count":15,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"3d1217ace27e56f0ffc109704ecd6c300645256d"},"cell_type":"code","source":"plot_classification_report(classification_report(y_test, NB_pred, labels=['0', '1']))","execution_count":16,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"abe34ea89fcf112dc81b32e5d5ff1acb0a6d22f9"},"cell_type":"code","source":"#class ratio:\nprint(\"ham vs spam =\",Counter(y_train)[0]/Counter(y_train)[1])","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"8008aaf5763dc740782254b10dcc015bd4804d19"},"cell_type":"markdown","source":"- From the confusion matrix, we see that all \"ham\" messages are correctly classfied while only 77% of the \"spam\" messages are correctly classified. The low accuracy of predicting \"spam\" is not reflected in the accuracy metric and ROC curve. \n\n- From the classification report, we can tell that the precision of spam is perfect. However, we observe imbalance in the dataset as there are much more \"ham\" messages than \"spam\" messages. Therefore the low prediciton accuracy of \"spam\" messages is mitigated. \n\n- Therefore, during model training, we should adjust the weights of the two categories. \nWe now try to use different models to look for improvement of result. "},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"dfe1d2bad0c9cdbd01db7e7a5a1cf8f297fc8a76"},"cell_type":"code","source":"#define a function for performance metrics\ndef model_eval(model,Xtest,y_test):\n    pred = model.predict(Xtest)\n    if not str(model)[:3] == \"SGD\":\n        pred_proba = model.predict_proba(Xtest)\n        pred_proba_c1 = pred_proba[:,1]\n        print (\"AUC Score : %f\" % sklearn.metrics.roc_auc_score(y_test, pred_proba_c1))\n    print (\"prediciton Accuracy : %f\" % accuracy_score(y_test, pred))\n    print (\"Confusion_matrix : \")\n    print (confusion_matrix(y_test,pred))\n    print (\"classification report : \")\n    print (classification_report(y_test, pred, labels=['0', '1']))","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"508007f13db62c3d43d07f4863604076d53861f3"},"cell_type":"markdown","source":"## Logistic regression (with Cross Validation)"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"5ede932ae309f10834ce4f36054ec7b6a3093693"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegressionCV\n#\"liblinear\" is suitable for small dataset, use L1(Lasso) regularization to reduce dimensions, adjust weights\nLRcv = LogisticRegressionCV(solver=\"liblinear\",penalty = \"l1\",class_weight =\"balanced\")  \nLRcv.fit(Xtrain,y_train)\nmodel_eval(LRcv,Xtest,y_test)","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"57e516b003231e9de2b3766b47e1581541238040"},"cell_type":"markdown","source":"## Random Forest Classifier"},{"metadata":{"scrolled":true,"trusted":false,"collapsed":true,"_uuid":"f2ee6c7f50c43f047175268e22e9a9e969c2e994"},"cell_type":"code","source":"#random forest works well when number of features is huge.\nfrom sklearn.ensemble import RandomForestClassifier\nRF = RandomForestClassifier(n_estimators =100, max_features = \"sqrt\",bootstrap = True, oob_score=True,verbose=0,\n                            class_weight = \"balanced\",random_state=42,max_depth = 40)\nRF.fit(Xtrain,y_train)\nprint(\"RF.oob_score : %f\" % RF.oob_score_)\nmodel_eval(RF,Xtest,y_test)","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"a4909d96fec9543f735b14887059324cb58ccb50"},"cell_type":"markdown","source":"## Gradient Boosting Classifier"},{"metadata":{"scrolled":true,"trusted":false,"collapsed":true,"_uuid":"511e24604fb93b9f8b2041fc243e631f75e326a8"},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nGBC = GradientBoostingClassifier(n_estimators=100, max_features = \"sqrt\", learning_rate=0.25,\n     max_depth=100, subsample= 0.8, random_state=42)\n#create sample_weights array\nsample_weights = [0.15 if x == 0 else 0.85 for x in y_train]\nGBC.fit(Xtrain,y_train,sample_weight = sample_weights)\nmodel_eval(GBC,Xtest,y_test)","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"e149ff24b24bb651143930789ca529e765234e55"},"cell_type":"markdown","source":"## SGD Classifier "},{"metadata":{"scrolled":false,"trusted":false,"collapsed":true,"_uuid":"5c6aa6dc9c6850e495822a35e73a2e6ae865afc2"},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier \n#using SVM with loss=\"hinge\" will automatically deal with the imbalance in the dataset\nSGD = SGDClassifier(loss=\"hinge\", penalty=\"l2\", alpha=0.0001,           \n                    l1_ratio=0.15, fit_intercept=True, \n                    shuffle=True, learning_rate=\"optimal\", n_iter= np.ceil(10**6 / Xtrain.shape[1])) \nSGD.fit(Xtrain,y_train)\nmodel_eval(SGD,Xtest,y_test)","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"7c3c3d89dccca5b170ebca9797279c963c305490"},"cell_type":"markdown","source":"SVM works well even if dimension is greater than sample number. Results of logistic regression are not as good as svm under SGD, w/o LSA/L1/L2/elastic net regularisation.\n\n# SVD/ISA \nIn this session we try to reduce the number of dimensions since the number of features is huge. "},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"559c9de3b77400d2cd16b191168389ddf4f1c036"},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import Normalizer\nsvd = TruncatedSVD(n_components=100, random_state=42)   #dimension 100 as recommended by sklearn documentation\nlsa = make_pipeline(svd, Normalizer(copy=False))\nXtrain_lsa = lsa.fit_transform(Xtrain)\nXtest_lsa = lsa.transform(Xtest)\nprint(svd.explained_variance_ratio_.sum())","execution_count":23,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false,"collapsed":true,"_uuid":"4ff656b429568dc3113477628d533677b6007edc"},"cell_type":"code","source":"#use Gradient Boosting on the transformed data\nGBC_lsa = GradientBoostingClassifier(n_estimators=100, max_features = \"sqrt\", learning_rate=0.25,\n     max_depth=20, subsample= 0.8, random_state=42)\n#create sample_weights array\nsample_weights = [0.15 if x == 0 else 0.85 for x in y_train]\nGBC_lsa.fit(Xtrain_lsa,y_train,sample_weight = sample_weights)\nmodel_eval(GBC_lsa,Xtest_lsa,y_test)","execution_count":24,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"ee1fc69486cc9f90136c0a2f934804f89039be27"},"cell_type":"markdown","source":"The result shows that incorporating too much semantic information may not necessarily help with classification. "},{"metadata":{"_uuid":"20e561485f450af047ac9ddb0e8d5f2855395f26"},"cell_type":"markdown","source":"# Model selection\n\n- All models improved as compared to the benchmark model based on the performances metrics. Logistic regression with Lasso regularization achieves good result with simple method, however, the precision of \"spam\" is not as good as other models. \n- Both random forest and gradient boosting give 100% precision rate for \"spam\", as well as high prediction accuracy. SVM using SGD on the other hand gives a higher prediction accuracy while incorrectly identify two \"ham\" as \"spam\". \n- In our analysis, we should focus on precision of \"spam\" because we do not want to identity \"ham\" messages as \"spam\" messages in real life practice, while letting a small amount of \"spam\" escaping is acceptable. The cost of inaccurately identity a \"ham\" message as \"spam\" message should be higher than the other case. \n- We choose GBC and perform a grid search to improve the prediction result."},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"c8c4bb0f3d2d3b645411641a854c78931fc89a06"},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n#for the first parameter, we try to look for the best n_estimators under learning_rate = 0.1\nparam_test1 = {'n_estimators':range(50,151,10)}\ngsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1,\n                                   min_samples_leaf=10,max_depth=100,max_features='sqrt', \n                                    subsample=0.8,random_state=42), \n                       param_grid = param_test1, scoring='roc_auc',iid=False,cv=5)\ngsearch1.fit(Xtrain,y_train)\ngsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_","execution_count":25,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"dbb4e409680edf53cdf95947d45d0c46bf9e4569"},"cell_type":"code","source":"#We then use the best estimated n_estimators(130) and search for the best max_depth\nparam_test2 = {'max_depth':range(15,51,5)}\ngsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=130, \n                                    min_samples_leaf=10, max_features='sqrt', \n                                        subsample=0.8, random_state=42), \n                   param_grid = param_test2, scoring='roc_auc',iid=False, cv=5)\ngsearch2.fit(Xtrain,y_train)\ngsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_","execution_count":26,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"95e5af27d4294eeb61c3276800ddcc5bd92f00af"},"cell_type":"code","source":"#min_samples_split and min_samples_leaf since these two parameters are related\nparam_test3 = {'min_samples_split':range(100,301,50), 'min_samples_leaf':range(3,24,10)}\ngsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=130,\n                                    max_depth=35,max_features='sqrt', \n                                        subsample=0.8, random_state=42), \n                       param_grid = param_test3, scoring='roc_auc',iid=False, cv=5)\ngsearch3.fit(Xtrain,y_train)\ngsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_","execution_count":27,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"cdbd0ff5cb064d3ff9988e446914471e34555cd6"},"cell_type":"code","source":"#max_features\nparam_test4 = {'max_features':range(40,131,10)}\ngsearch4 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=130,\n                                    max_depth=35, min_samples_leaf =3, min_samples_split =150, \n                                            subsample=0.8, random_state=42), \n                       param_grid = param_test4, scoring='roc_auc',iid=False, cv=5)\ngsearch4.fit(Xtrain,y_train)\ngsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_","execution_count":28,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"12b1e10ddb1fbf785e37e9d7390a4e2f54a5f633"},"cell_type":"code","source":"#subsample\nparam_test5 = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}\ngsearch5 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=130,\n                                    max_depth=35, min_samples_leaf =3, min_samples_split =150, \n                                                max_features=40, random_state=42), \n                       param_grid = param_test5, scoring='roc_auc',iid=False, cv=5)\ngsearch5.fit(Xtrain,y_train)\ngsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_","execution_count":29,"outputs":[]},{"metadata":{"_uuid":"cebd5c9ad61d05fcfc1cb9b3746bb210dc883cff"},"cell_type":"markdown","source":"# Final model\nNow we use all the parameter estimated in the model. Reduce \"learning_rate\" by half and double \"n_estimators\"."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"445e929a539766ae2f190527a79b40688969d78c"},"cell_type":"code","source":"GBC2 = GradientBoostingClassifier(learning_rate=0.05, n_estimators=260,max_depth=35, min_samples_leaf =3, \n               min_samples_split =150, max_features=40, subsample=0.7, random_state=42)\nsample_weights = [0.15 if x == 0 else 0.85 for x in y_train]\nGBC2.fit(Xtrain,y_train,sample_weight = sample_weights)\nmodel_eval(GBC2,Xtest,y_test)","execution_count":30,"outputs":[]},{"metadata":{"_uuid":"e426baad4f10ec96594f887b624bdd158db453c3"},"cell_type":"markdown","source":"Both AUC score and prediciton Accuracy increase from original model\n\n## plot top10 feature importance"},{"metadata":{"scrolled":true,"trusted":false,"collapsed":true,"_uuid":"102d26a7abc61bdd66a831f31467af0e029f36a8"},"cell_type":"code","source":"importances = GBC2.feature_importances_\nstd = np.std([GBC2.feature_importances_ for tree in GBC2.estimators_],axis=0)","execution_count":31,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"b47152ae00bfc9952497e831d1b764c9877bf53c"},"cell_type":"code","source":"#top 10 indices:\nindices = np.argsort(importances)[::-1][0:10]\nfeature_names = vectorizer.get_feature_names()\nprint (\"top10words : \")\nfor i in range(10):\n    print (indices[i],feature_names[indices[i]])\nplt.figure()\nplt.title(\"Feature importances\")\nplt.bar(range(10), importances[indices],\n       color=\"r\", yerr=std[indices], align=\"center\")\nplt.xticks(range(10), indices)\nplt.xlim([-1, 10])\nplt.show()","execution_count":32,"outputs":[]},{"metadata":{"_uuid":"992c8a69b1f11eb3f8ee4f6daedd0ac2c4533c5d"},"cell_type":"markdown","source":"## Further Improvements\n- Study the numbers in the features, compare the results after removing the numbers.\n- Study the wrongly classfied messages for further insights."},{"metadata":{"_uuid":"8e2d9e7b8c472348a644361762849a04318f9972"},"cell_type":"markdown","source":"## Reference\n- confusion matrix http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n- classification table https://stackoverflow.com/questions/28200786/how-to-plot-scikit-learn-classification-report?noredirect=1&lq=1\n- plot feature importance http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}