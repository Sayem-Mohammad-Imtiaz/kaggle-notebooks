{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read and have a look at the data."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/data.csv')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop id, diagnosis and Unnamed: 32 to get our X_ori, which is the original X without data pre-processing."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ori=data\n# y is the labels\ny_ori=X_ori.diagnosis\n# Drop the unrelated colomns\n# X is the instances\ndropping_col = ['id','diagnosis','Unnamed: 32']\nX_ori=X_ori.drop(dropping_col,axis=1)\nprint(X_ori.shape)\nX_ori.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Z-score normalization. Set label 'M' to be 1, label 'B' to be 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize data\n# Normalization (z-score)\nX=(X_ori - X_ori.mean()) / (X_ori.std())\ny=[1 if label=='M' else 0 for label in y_ori]\n#data_nm = (data_ins-data_ins.min())/(data_ins.max()-data_ins.min())\nX.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DataFrame to numpy."},{"metadata":{"trusted":true},"cell_type":"code","source":"# DataFrame to np\nX=X.values\ny=np.array(y)\nattributes=['radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n       'compactness_worst', 'concavity_worst', 'concave points_worst',\n       'symmetry_worst', 'fractal_dimension_worst']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nimport time\n# SVM_linear_kernel\ndef SVM(X_train,y_train,X_test,y_test,C=0.1):       # X,y are numpy\n    clf = SVC(kernel='linear',C=C)\n    clf.fit(X_train, y_train)  \n    # train accuracy\n    pred_train=clf.predict(X_train)\n    res_train=[pred_train==y_train]\n    acc_train=np.mean(np.array(res_train).astype(np.int))\n    # test accuracy\n    pred_test=clf.predict(X_test)\n    res_test= [pred_test==y_test]\n    acc_test=np.mean(np.array(res_test).astype(np.int))\n    return acc_train,acc_test\n\ndef SVM_iter(X,y,k=100,C=0.1):\n    SVM_train_acc=[]\n    SVM_test_acc=[]\n    for _ in range(k):\n        # SVM\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n        acc_train,acc_test=SVM(X_train,y_train, X_test,y_test,C)\n        SVM_train_acc.append(acc_train)\n        SVM_test_acc.append(acc_test)\n    return np.array(SVM_train_acc).mean(),np.array(SVM_test_acc).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SVM\n# start=time.time()\n# train_acc=[]\n# test_acc=[]\n# for i in range(100):\n#     X_train, X_test, y_train, y_test = train_test_split(X_ori, y_ori, test_size=0.3)\n#     acc_train,acc_test=SVM(X_train,y_train, X_test,y_test)\n#     train_acc.append(acc_train)\n#     test_acc.append(acc_test)\n# print(np.array(train_acc).mean())\n# print(np.array(test_acc).mean())\n# print('Original data operation time: %f'%(time.time()-start))\n\nprint()\nstart=time.time()\ntrain_acc=[]\ntest_acc=[]\nfor i in range(100):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n    acc_train,acc_test=SVM(X_train,y_train, X_test,y_test)\n    train_acc.append(acc_train)\n    test_acc.append(acc_test)\nprint(np.array(train_acc).mean())\nprint(np.array(test_acc).mean())\nprint('Normalized data operation time: %f'%(time.time()-start))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\nselector_SVM = RFE(SVC(kernel='linear',C=0.1),1, step=1)\nselector_SVM = selector_SVM.fit(X, y)\nprint(selector_SVM.ranking_)\nprint([attributes[i] for i in np.argsort(selector_SVM.ranking_)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def SVM_Select(X,y):\n    train_acc=[]\n    test_acc=[]\n    for k in range(X.shape[1]):\n        selector_SVM = RFE(SVC(kernel='linear',C=0.1),k+1, step=1)\n        X_trans = selector_SVM.fit(X, y).transform(X)\n        acc_train,acc_test=SVM_iter(X_trans,y)\n        train_acc.append(acc_train)\n        test_acc.append(acc_test)\n    return train_acc,test_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nSVM_train_acc,SVM_test_acc=SVM_Select(X,y)\nplt.plot(SVM_test_acc)\nplt.ylim([0.8,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(SVM_test_acc)\nplt.plot([i+1 for i in range(30)],SVM_train_acc,c='red',label='training accuracy')\nplt.plot([i+1 for i in range(30)],SVM_test_acc,c='green',label='testing accuracy')\nplt.scatter([i+1 for i in range(30)],SVM_train_acc,c='red',s=10)\nplt.scatter([i+1 for i in range(30)],SVM_test_acc,c='green',s=10)\nplt.title('Training & Testing Accuracy for SVM')\nplt.xlabel('features')\nplt.ylabel('accuracy')\nplt.ylim([0.8,1])\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n# SVM\ndef SVM_CM(X,y):       # X,y are numpy\n    matrix=np.array([[0,0],[0,0]])\n    for i in range(100):\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n        clf = SVC(kernel='linear',C=0.1)\n        clf.fit(X_train, y_train)  \n        pred_test=clf.predict(X_test)\n        matrix+=confusion_matrix(y_test, pred_test)\n    \n    tn, fp, fn, tp=matrix.ravel()\n    print(tn, fp, fn, tp)\n    accuracy=(tn+tp)/(tn+fp+fn+tp)\n    precision=(tp)/(tp+fp)\n    recall=tp/(tp+fn)\n    specificity=tn/(tn+fp)\n    f1=(2*precision*recall)/(precision+recall)\n    matrix=(matrix/100+0.5).astype(int)\n    return matrix,np.array([[accuracy,precision,recall,specificity,f1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n# SVM selection -> 14 features\nselector_SVM = RFE(SVC(kernel='linear',C=0.1),14, step=1)\nX_SVM = selector_SVM.fit(X, y).transform(X)\nres,metrics_SVM_trans=SVM_CM(X_SVM,y)\nsns.heatmap(res,annot=True,fmt=\"d\")\nplt.show()\nprint(metrics_SVM_trans)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n# feature selection -> PCA\npca = PCA(n_components=0.99)\npca.fit(X_SVM)\nX_pca_SVM=pca.transform(X_SVM)\nprint(X_SVM.shape)\nprint(X_pca_SVM.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rain_acc=[]\ntest_acc=[]\nfor i in range(100):\n    X_train, X_test, y_train, y_test = train_test_split(X_pca_SVM, y, test_size=0.3)\n    acc_train,acc_test=SVM(X_train,y_train, X_test,y_test)\n    train_acc.append(acc_train)\n    test_acc.append(acc_test)\nprint(np.array(train_acc).mean())\nprint(np.array(test_acc).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, SVM with linear kernels reaches 98.05% testing accuracy with only 9 features."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}