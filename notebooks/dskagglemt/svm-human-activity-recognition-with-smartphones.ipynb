{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Human Activity Recognition with Smartphones\n\nThe Human Activity Recognition database was built from the recordings of 30 study participants performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors. The objective is to classify activities into one of the six activities performed.\n\nRefer to link https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones  for more details.\n\nThe dataset is also available on UCI Machine Learning Repository."},{"metadata":{},"cell_type":"markdown","source":"* Problem Type : Multi-Class Classification\n* Algorithm  : SVM"},{"metadata":{},"cell_type":"markdown","source":"# Import Library"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n%matplotlib inline\n\n# import SVC classifier\nfrom sklearn.svm import SVC\n\n# import metrics to compute accuracy (Evulate)\nfrom sklearn.metrics import accuracy_score, confusion_matrix,classification_report\nfrom sklearn.model_selection import cross_val_score, GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load the Training DataSet"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/human-activity-recognition-with-smartphones/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So the train data set has 563 Columns / features (including the target / class), and 7352 rows or data points.\n\nAlso the target is Activity. As mentioned in the data description it has 6 unique values. Lets check them also in next step."},{"metadata":{},"cell_type":"markdown","source":"## Check for missing values in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Class Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"Activity\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(index = df_train[\"Activity\"],columns=\"count\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize the Class Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nax = sns.countplot(x=\"Activity\", data=df_train)\nplt.xticks(x = df_train['Activity'],  rotation='vertical')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Class distribution looks good.\n\nNext will check for the feature `subject`. \n\nThough feature `subject` is not much useful to us, as it is an identifier of the subject who carried out the experiment.\n\nWe are good to ignore or drop the feature."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"subject\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.DataFrame(df_train.drop(['Activity','subject'],axis=1))\nY = df_train.Activity.values.astype(object)\n\nX.shape, Y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check the data types of each features. \n\nAll features are of float64 type and all 561 are numeric features, except for Class (y). We need to do Label ENcoder and make it into numeirc."},{"metadata":{"trusted":true},"cell_type":"code","source":"X.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Total Number of Continous and Categorical features in the training set\nnum_cols = X._get_numeric_data().columns\nprint(\"Number of numeric features:\",num_cols.size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transforming non numerical labels into numerical labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# encoding train labels \nencoder.fit(Y)\ny = encoder.transform(Y)\ny.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder.classes_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder.classes_[2]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling the feature \nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = scaler.fit_transform(X)\nX[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split X and y into training and validation sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state = 99)\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train the Model"},{"metadata":{},"cell_type":"markdown","source":"## Run SVM with default hyperparameters\nDefault hyperparameter means C=1.0, kernel=rbf and gamma=auto among other parameters."},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate classifier with default hyperparameters\nsvc = SVC() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit classifier to training set\nsvc.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions on test set\ny_pred = svc.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compute and print accuracy score\nprint('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_valid, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, y_valid are the true class labels and y_pred are the predicted class labels in the test-set."},{"metadata":{},"cell_type":"markdown","source":"## Run SVM with rbf kernel and C=100.0\n\nSome time there are outliers in the dataset. In that case, we should increase the value of C as higher C means fewer outliers. So, might run SVM with kernel=rbf and C=100.0.\n\nWe will try playing with various hyper-parameter."},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate classifier with rbf kernel and C=100\nsvc = SVC(C=100.0) \n\n\n# fit classifier to training set\nsvc.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred = svc.predict(X_valid)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with rbf kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_valid, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that we obtain a higher accuracy with C=100.0 as higher C means less outliers. \n\nNow, I will further increase the value of C=1000.0 and check accuracy."},{"metadata":{},"cell_type":"markdown","source":"## Run SVM with rbf kernel and C=1000.0"},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate classifier with rbf kernel and C=1000\nsvc=SVC(C=1000.0) \n\n\n# fit classifier to training set\nsvc.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred=svc.predict(X_valid)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with rbf kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_valid, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this case, we can see that the accuracy had decreased with C=1000.0"},{"metadata":{},"cell_type":"markdown","source":"## Run SVM with linear kernel \nRun SVM with linear kernel and C=1.0"},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate classifier with linear kernel and C=1.0\nlinear_svc=SVC(kernel='linear', C=1.0) \n\n\n# fit classifier to training set\nlinear_svc.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred_test=linear_svc.predict(X_valid)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_valid, y_pred_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Run SVM with linear kernel and C=100.0"},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate classifier with linear kernel and C=100.0\nlinear_svc100=SVC(kernel='linear', C=100.0) \n\n\n# fit classifier to training set\nlinear_svc100.fit(X_train, y_train)\n\n\n# make predictions on test set\ny_pred=linear_svc100.predict(X_valid)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with linear kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_valid, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Run SVM with linear kernel and C=1000.0"},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate classifier with linear kernel and C=1000.0\nlinear_svc1000=SVC(kernel='linear', C=1000.0) \n\n\n# fit classifier to training set\nlinear_svc1000.fit(X_train, y_train)\n\n\n# make predictions on test set\ny_pred=linear_svc1000.predict(X_valid)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with linear kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_valid, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that we can obtain higher accuracy with C=100.0 and C=1000.0 as compared to C=1.0.\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Compare the train-set and test-set accuracy\nNow, I will compare the train-set and test-set accuracy to check for overfitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_train = linear_svc.predict(X_train)\n\ny_pred_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the training set and test-set accuracy are very much comparable."},{"metadata":{},"cell_type":"markdown","source":"# Check for overfitting and underfitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training set score: {:.4f}'.format(linear_svc.score(X_train, y_train)))\n\nprint('Validation set score: {:.4f}'.format(linear_svc.score(X_valid, y_valid)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The training-set accuracy score is 99.71 while the validation-set accuracy to be 98.44. These two values are quite comparable. So, there is no question of overfitting."},{"metadata":{},"cell_type":"markdown","source":"# Compare model accuracy with null accuracy\nSo, the model accuracy is 0.9832. But, we cannot say that our model is very good based on the above accuracy. We must compare it with the null accuracy. Null accuracy is the accuracy that could be achieved by always predicting the most frequent class.\n\nSo, we should first check the class distribution in the validation set."},{"metadata":{"trusted":true},"cell_type":"code","source":"# check class distribution in validation set\n\n# y_valid.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the occurences of most frequent class ---  is ---. So, we can calculate null accuracy by dividing --- by total number of occurences."},{"metadata":{},"cell_type":"markdown","source":"## Run SVM with polynomial kernel\nRun SVM with polynomial kernel and C=1.0"},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate classifier with polynomial kernel and C=1.0\npoly_svc=SVC(kernel='poly', C=1.0) \n\n\n# fit classifier to training set\npoly_svc.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred=poly_svc.predict(X_valid)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with polynomial kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_valid, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Run SVM with polynomial kernel and C=100.0"},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate classifier with polynomial kernel and C=100.0\npoly_svc100=SVC(kernel='poly', C=100.0) \n\n\n# fit classifier to training set\npoly_svc100.fit(X_train, y_train)\n\n\n# make predictions on test set\ny_pred=poly_svc100.predict(X_valid)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with polynomial kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_valid, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Polynomial kernel gives poor performance. It may be overfitting the training set.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Run SVM with sigmoid kernel\nRun SVM with sigmoid kernel and C=1.0"},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate classifier with sigmoid kernel and C=1.0\nsigmoid_svc=SVC(kernel='sigmoid', C=1.0) \n\n\n# fit classifier to training set\nsigmoid_svc.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred=sigmoid_svc.predict(X_valid)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with sigmoid kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_valid, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Run SVM with sigmoid kernel and C=100.0"},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate classifier with sigmoid kernel and C=100.0\nsigmoid_svc100=SVC(kernel='sigmoid', C=100.0) \n\n\n# fit classifier to training set\nsigmoid_svc100.fit(X_train,y_train)\n\n\n# make predictions on test set\ny_pred=sigmoid_svc100.predict(X_valid)\n\n\n# compute and print accuracy score\nprint('Model accuracy score with sigmoid kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_valid, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that sigmoid kernel is also performing poorly just like with polynomial kernel."},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter tuning using grid search and cross validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the parameter grid based on the results of random search \nparams_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n                     'C': [1, 10, 100, 1000]},\n                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Performing CV to tune parameters for best SVM fit \nsvm_model = GridSearchCV(SVC(), params_grid, cv=5)\nsvm_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Confusion Matrix and Accuracy Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"# View the accuracy score\nprint('Best score for training data:', svm_model.best_score_,\"\\n\") \n\n# View the best parameters for the model found using grid search\nprint('Best C:',svm_model.best_estimator_.C,\"\\n\") \nprint('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\nprint('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")\n\nfinal_model = svm_model.best_estimator_\nY_pred = final_model.predict(X_valid)\nY_pred_label = list(encoder.inverse_transform(Y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making the Confusion Matrix\n#print(pd.crosstab(Y_test_label, Y_pred_label, rownames=['Actual Activity'], colnames=['Predicted Activity']))\nprint(confusion_matrix(y_valid,Y_pred))\nprint(\"\\n\")\nprint(classification_report(y_valid,Y_pred))\n\nprint(\"Training set score for SVM: %f\" % final_model.score(X_train , y_train))\nprint(\"Validation set score for SVM: %f\" % final_model.score(X_valid  , y_valid ))\n\n# svm_model.score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Comments\nWe get maximum accuracy with `rbf` and `linear` kernel with C=100.0. and the accuracy is 99%. Based on the above analysis we can conclude that our classification model accuracy is very good. Our model is doing a very good job in terms of predicting the class labels.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}