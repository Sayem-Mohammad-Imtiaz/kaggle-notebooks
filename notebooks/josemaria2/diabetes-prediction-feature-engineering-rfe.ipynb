{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-08T21:23:04.469465Z","iopub.execute_input":"2021-09-08T21:23:04.46981Z","iopub.status.idle":"2021-09-08T21:23:04.477239Z","shell.execute_reply.started":"2021-09-08T21:23:04.469775Z","shell.execute_reply":"2021-09-08T21:23:04.476316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  **PIMA INDIANS DATASET**\n## Looking for the hightest performance with minimum factors.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"tc\"></a>\n### **Table of contents**\n\n1. [Introduction: understanding the problem](#introduction)\n2. [Exploratory data analysis](#eda)\n    - [Data summary](#datasummary)\n    - [Duplicated data](#duplicated)\n    - [Statistical summary](#statisticalsummary)\n    - [Data Cleaning](#datacleaning)\n    - [Outlier presence](#outliers)\n    - [Relationship among numerical variables: correlation](#correlation)\n    - [EDA Conclusions](#edaconclusions)\n3. [Metric selection](#metric)\n4. [Baseline model](#baselinemodel)\n5. [Outlier Impact on performance](#outlierremoval)\n    - [Outlier definition](#outlierdef)\n    - [Custom function](#functiondef)\n    - [Testing the pipeline](#outpipeline)\n    - [Comments of outlier removal](#outremovalcomment)\n6. [Testing different classification models](#testingmodels)\n7. [Feature engineering](#featureengineering)\n8. [Recursive feature extraction](#rfe)\n9. [Conclusions](#conclu)\n10. [Useful links](#links)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"introduction\"></a>\n\n## 1. **Introduction: understanding the problem**\n\nPrior to any library import and coding, we all should first understand the problem and the provided dataset. Thus, I will first read the problem context in order to clearly see what is this problem for: \n\n> *The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset.*\n\nThus, we should come up with a model capable of predicting whether a patient -with PIMA Indian heritage- has diabetes or not.\n\nFrom the previous statement we can say that we will have a variable measuring a 0-1 output or ><0.5 probability. Nevertheless, it is something that we will be seen in a the following sections. \n\nOnce that we know the nature of the problem and the type of model that we may use in order to predict the explained variable, I will perform an exploratory analysis (or EDA) in order to better understad the available variables for the exercise as well as their properties.\n\n*Why the EDA stage should be performed?*\n\nWe never know the data beforehand. It means that most of the time we part from a very general description of the problem. Also, the explanatory variables to be used in our models are different from exercise to exercise. In addition, depending on the variables and their properties, some models and techniques would work better than others. \n\nThus, I will perform an EDA looking for:\n\n* Raw data properties (e.g: number of variables, missing information within columns, nature of the variables (e.g.:numerical, categorical)\n* Variable propoerties:\n    * Numerical: distribution, outliers, basic satistics, how they interact among them.\n    * Categorical: concentration of values on certain classes. \n* Perform basic data cleaning task.\n\n\n[Back to Table of Contents](#tc)\n\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"eda\"></a>\n##  **2. Exploratory Data Analysis**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sbn\nsbn.set_style(\"dark\")","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:04.47919Z","iopub.execute_input":"2021-09-08T21:23:04.479627Z","iopub.status.idle":"2021-09-08T21:23:04.484907Z","shell.execute_reply.started":"2021-09-08T21:23:04.479588Z","shell.execute_reply":"2021-09-08T21:23:04.484001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.read_csv(r\"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:04.486322Z","iopub.execute_input":"2021-09-08T21:23:04.486744Z","iopub.status.idle":"2021-09-08T21:23:04.498351Z","shell.execute_reply.started":"2021-09-08T21:23:04.486711Z","shell.execute_reply":"2021-09-08T21:23:04.497672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"datasummary\"></a>\n### **2.1 Data Summary**","metadata":{}},{"cell_type":"code","source":"dataset.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:04.499748Z","iopub.execute_input":"2021-09-08T21:23:04.500122Z","iopub.status.idle":"2021-09-08T21:23:04.512865Z","shell.execute_reply.started":"2021-09-08T21:23:04.500086Z","shell.execute_reply":"2021-09-08T21:23:04.511748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### From the previous output, we can know that: \n\n* The dataset is composed by 8 numerical (either integer or float types) explanatory variables (#0-#7) and one explained variable called \"Outcome\" (#8) that  indicates whether the patient has diabetes or not.\n\n* No variables contain null values.\n\nOnce that we discard null values, I will check if there are rows that are duplicated and if so, remove them from the dataset:","metadata":{}},{"cell_type":"markdown","source":"<a id=\"duplicated\"></a>\n### **2.2 Duplicated data**","metadata":{}},{"cell_type":"code","source":"dataset.duplicated().unique()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:04.514549Z","iopub.execute_input":"2021-09-08T21:23:04.514949Z","iopub.status.idle":"2021-09-08T21:23:04.52414Z","shell.execute_reply.started":"2021-09-08T21:23:04.514913Z","shell.execute_reply":"2021-09-08T21:23:04.523061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The *.duplicated()* funcion returns an array of the same lenth of the number of rows from the dataset. On it, we could spot wheter any row is duplicated or not. By applying the *.unique()* function, we obtain of many \"different\" values we get from the previous array. Since the above sentence only throws \"False\" values, it means that no rows are duplicated.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"statisticalsummary\"></a>\n### **2.3 Statistical Summary**\n\nOnce that we are sure that the dataset has no duplicated information and not null values, we can run a statistical summary that provides a general \"view\" of the information provided. We first need to separate output variable from explanatory ones:","metadata":{}},{"cell_type":"code","source":"X = dataset.drop([\"Outcome\"], axis = 1)\ny = dataset[\"Outcome\"]","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:04.526103Z","iopub.execute_input":"2021-09-08T21:23:04.526501Z","iopub.status.idle":"2021-09-08T21:23:04.532187Z","shell.execute_reply.started":"2021-09-08T21:23:04.526452Z","shell.execute_reply":"2021-09-08T21:23:04.531029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.describe()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:04.534208Z","iopub.execute_input":"2021-09-08T21:23:04.53464Z","iopub.status.idle":"2021-09-08T21:23:04.570519Z","shell.execute_reply.started":"2021-09-08T21:23:04.534603Z","shell.execute_reply":"2021-09-08T21:23:04.569642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion:** \n\nFrom the previous output we can see that: \n* There is a huge difference between the minimum and maximum values in the columns *Glucose*, *BloodPressure* and *Insuline*.\n* Both *Insulin* and *DiabetesPedigreeFunction* may have outliers. We will check this fact through boxplots later on. \n* Variable standarization will be needed.\n* Minimum of 0 value for columns: *Glucose*, *BloodPressure*, *SkinThickness*, *Insulin* and *BMI*. This fact needs further analysis,","metadata":{}},{"cell_type":"markdown","source":"<a id=\"datacleaning\"></a>\n### **2.4 Data Cleaning**","metadata":{}},{"cell_type":"code","source":"for col in X.columns:\n    if np.min(X[col]) == 0:\n        print(\"Number of rows within {} with zero values {}\".format(col, X[X[col] == 0].shape[0]))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:04.572194Z","iopub.execute_input":"2021-09-08T21:23:04.572601Z","iopub.status.idle":"2021-09-08T21:23:04.585882Z","shell.execute_reply.started":"2021-09-08T21:23:04.572563Z","shell.execute_reply":"2021-09-08T21:23:04.584966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Far from elaborating an in-depth review of how these variables work and their normal levels, I have done som research in order to get a basic understanding of what I am analysing as well as to get a starting point for a further treatment of the following variables:\n\n1. [What will hapen when the blood pressure goes to zero?](https://www.quora.com/What-will-happen-when-the-blood-pressure-goes-zero) Far from bringing medical rigor to this notebook, we have reasonable arguments to state that zero blood pressure cases should be treated for analysis purposes (removal or substituting the zero values by any other statistical measurement).\n2. [Normal and Diabetic Blood levels](https://www.diabetes.co.uk/diabetes_care/blood-sugar-level-ranges.html). One more time, and taking into account only this source of information, we can deduct that Zero glucose in bloodstream is not normal. Thus, we should make a decision regarding how we will deal with such values (removal or substituting the zero values by any other statistical measurement)\n3. [Insulin Basics](https://dtc.ucsf.edu/types-of-diabetes/type2/treatment-of-type-2-diabetes/medications-and-therapies/type-2-insulin-rx/insulin-basics/) Again, and since I haven't found a \"normal\" zero insuline level, we should need to make the same decision as above: removal or substituting the zero values by another statistical measurement).\n4. [About Adult BMI](https://www.cdc.gov/healthyweight/assessing/bmi/adult_bmi/index.html) Regarding BMI, we can say that represents a division of weight / height. Thus, it means that a zero BMI level implies 0 weight or infinite height so we can confidently say that such level is non-sense and should be either substituted or removed.\n5. [Skin Thickness](https://www.histology.leeds.ac.uk/skin/skin_layers.php). This article states that the skin thickness can vary from 0.5mm to 4.0mm depending on the body part. For that reason, It could be reasonable to make the same decision regarding the zero values.\n\n\n**Conclusion:** \nThere are some cases where we could simply remove the affected rows (such as 0 BMI level since there are only 11 cases). Nevertheless, Insuline and SkinThickness have more than 11 zero cases (374 and 227, respectively). For that reason, I consider that I could better substitute such values instead of eliminating them from the original dataset.\n\nIn order to perform the metioned task, I will firsly substitute the zero values by the nan:","metadata":{}},{"cell_type":"code","source":"columns = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\nfor i in range(X.shape[0]):\n    for col in columns:\n        if X[col].iloc[i] == 0:\n            X[col].iloc[i] = np.nan","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:04.587388Z","iopub.execute_input":"2021-09-08T21:23:04.587883Z","iopub.status.idle":"2021-09-08T21:23:04.718804Z","shell.execute_reply.started":"2021-09-08T21:23:04.587845Z","shell.execute_reply":"2021-09-08T21:23:04.718001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once all zero values have been substitued, it's time to give them a better value. In this case, I will opt for the average. \n\nIf we had categorical variables such as sex, place, race, etc. I would calculate the mean value for the different segments of people [like the Titanic exercise](https://www.kaggle.com/josemaria2/titanic-analysis-with-97-accuracy), but since all variables are numerical I cannot do it in the same way.\n\nNevertheless, a good exercise could consist on categorizing the numerical variables and impute the mean or mode from each resulting category. Since all variables here are numeric, we could also use the KNNImputer from the Scikit Learn library. This method calculates the mean value of the K-nearest points from the nan value and substitues it.","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import KNNImputer","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:04.720405Z","iopub.execute_input":"2021-09-08T21:23:04.720735Z","iopub.status.idle":"2021-09-08T21:23:04.724877Z","shell.execute_reply.started":"2021-09-08T21:23:04.720702Z","shell.execute_reply":"2021-09-08T21:23:04.723677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = KNNImputer(n_neighbors = 10, weights = \"distance\")\nX_trans = pd.DataFrame(data = imputer.fit_transform(X), columns = X.columns)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:04.7263Z","iopub.execute_input":"2021-09-08T21:23:04.726642Z","iopub.status.idle":"2021-09-08T21:23:04.772304Z","shell.execute_reply.started":"2021-09-08T21:23:04.726609Z","shell.execute_reply":"2021-09-08T21:23:04.771259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"outliers\"></a>\n### **2.5 Outliers presence** \n\nOutliers within a distribution are values that are much lower or higher than the rest. It also must be stated that there are not defined outlier definitios. It means that the classification between what we could call a \"normal\" or an \"outlier\" value has to do with their relative position within the distribution. \n\nFor that purpose, we could better represent it graphically so we can visually spot the presence of such values:\n\nBoxplots represent outliers with a special mark (such as dots, crosses, etc. depending on the used software). On this example, seaborn [boxplot function](https://seaborn.pydata.org/generated/seaborn.boxplot.html) consider as outliers those points beyond the 1.5 times the IQR.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(2,4, figsize = (15,10), squeeze = False)\nfor i,col in enumerate(X_trans.columns):\n    plt.subplot(2,4,i+1)\n    sbn.boxplot(y = X_trans[col].values, data = X_trans)\n    plt.ylabel(col)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:04.773621Z","iopub.execute_input":"2021-09-08T21:23:04.773928Z","iopub.status.idle":"2021-09-08T21:23:05.630601Z","shell.execute_reply.started":"2021-09-08T21:23:04.773897Z","shell.execute_reply":"2021-09-08T21:23:05.629883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion:** \n\nWe can see from the previous boxplots that, except for *Glucose*, the rest of variables present extreme values. Such outliers will be further treated within a pipeline.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"correlation\"></a>\n### **2.6 Relationship among numerical variables: correlation**\n\nSince all our data is numerical, a question may arise: \"Is there any correlation among our variables?\". For that reason, and in order to answer the previous question, we can run a heatmap where the correlation coefficient is calculated for each combination of variables:","metadata":{}},{"cell_type":"code","source":"sbn.heatmap(X_trans.corr(method = \"pearson\"), annot = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:05.632069Z","iopub.execute_input":"2021-09-08T21:23:05.632406Z","iopub.status.idle":"2021-09-08T21:23:06.162535Z","shell.execute_reply.started":"2021-09-08T21:23:05.632368Z","shell.execute_reply":"2021-09-08T21:23:06.161822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion:** \n1. The hightest correlation values range from 0.54 to 0.65 being one of them the relationship between Pregnancies and Age (with 0.54), which seems quite logical. the second example is the pair Insulin - Glucose and BMI - Skinthickness, with a 0.64 value.\n\nSince there is no correlation beyond 0.70, I decide not to drop any variable based on the correlation coefficient.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"edaconclusions\"></a>\n### **2.7 EDA Conclusions**\n\n1. Presence of outliers: we have considered outliers as points beyond 1.5 * IQR and those will be processed within a pipeline. A different definition may lead to different results. \n2. Non-normal zero values for several variables have been treated with an Knn Imputer.\n3. No variables have been dropped from dataset due to Pearon correlation coefficient.\n\n[Back to Table of Contents](#tc)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"metric\"></a>\n##  **3. Metric selection**\n\nOnce the EDA has been performed, it is time to construct and compare different solutions to our classification problem. \nThere are different metrics that could be used on this exercise, but it is up to the analyst to use a particular metric depending on the purpose of the exercise and the provided information. \n\nBefore selecting the metric, I first check the amount of cases with and without diabetes.","metadata":{}},{"cell_type":"code","source":"sbn.countplot(x = y)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:06.165651Z","iopub.execute_input":"2021-09-08T21:23:06.165916Z","iopub.status.idle":"2021-09-08T21:23:06.271535Z","shell.execute_reply.started":"2021-09-08T21:23:06.165891Z","shell.execute_reply":"2021-09-08T21:23:06.270877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see in the previous plot, there are around 250 of positive cases whereas the number of negative ones are almost double. For this reason, I will use de F-1 Score instead of % Accuracy. \n\n[Back to Table of Contents](#tc)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"baselinemodel\"></a>\n##  **4. Baseline Model**\n\nWe have reached this point having a better understanding of the provided information and with a minimal modification (zeros substitution). \nNow, it is time to create a baseline model(i.e: the very basic model capable of performing the desired classification).\n\nFor that purpose, here I create a basic pipeline that basically standarizes the data (2.3 Statistical summary conclusion) and trains the model.\n\nI will firstly load the necessary libraries not only for the baseline model, but also for the rest of them:","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import FunctionTransformer, StandardScaler, PolynomialFeatures\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score, KFold, GridSearchCV\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:06.272735Z","iopub.execute_input":"2021-09-08T21:23:06.27307Z","iopub.status.idle":"2021-09-08T21:23:06.279373Z","shell.execute_reply.started":"2021-09-08T21:23:06.273043Z","shell.execute_reply":"2021-09-08T21:23:06.278436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pipeline inputs that could be modified: number of splits within cross validation (here I choose 5).\n\nBaseline pipeline and score:","metadata":{}},{"cell_type":"code","source":"trans_steps = [(\"ss\", StandardScaler(), X_trans.columns)]\ncol_trans = ColumnTransformer(transformers = trans_steps)\npipeline = Pipeline(steps = [(\"trans\", col_trans),(\"model\", LogisticRegression())])\nkfold = KFold(n_splits = 4)\ncv_score = cross_val_score(estimator = pipeline, X = X_trans, y = dataset[\"Outcome\"], cv = kfold, scoring = \"f1\")\nprint(\"Baseline model (Logistic Regression) reaches an F1-score of: {} %\".format(round(np.mean(cv_score),3)*100))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:06.280424Z","iopub.execute_input":"2021-09-08T21:23:06.280761Z","iopub.status.idle":"2021-09-08T21:23:06.343005Z","shell.execute_reply.started":"2021-09-08T21:23:06.280725Z","shell.execute_reply":"2021-09-08T21:23:06.342169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[Back to Table of Contents](#tc)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"outlierremoval\"></a>\n##  **5. Outlier removal impact on model**\n\nThe conclusion of the section 2.5 stated that there are many outliers within most of our variables. For that reason, once we have created and cross-validated the baseline model, I think it's time to prove whether an outlier removal step could improve that F1 score of 62.7%.\n\nI will follow the following steps:\n\n* First, I will define what is considered an outlier.\n* Second, I will define the function that will be inserted within the pipeline.\n* Third, I will run the previous pipeline, but this time inserting the outlier removal step.\n* Fourth, I will check and comment any change in model's classification mark.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"outlierdef\"></a>\n### **5.1 Definition of outlier**\n\nI will stick to a very basic definition of outlier. Hence, I will define an outlier as any point within a distribution that is higher or lower than 1.5 times the IQR.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"functiondef\"></a>\n### **5.2 Function creation**","metadata":{}},{"cell_type":"code","source":"def outlier_removal(X, n_iqr = 1.5, lower_perc = 0.25, verbose = False):\n    copia = X.copy()\n    for col in range (copia.shape[1]):\n        column = copia[:,col]\n        perc_low, perc_up = np.quantile(column, lower_perc), np.quantile(column, (1-lower_perc))\n        iqr = perc_up - perc_low\n        cutoff = iqr*n_iqr\n        lower, upper = perc_low-cutoff , perc_up+cutoff\n        ix_lower = np.where(column < lower)[0]\n        if len(ix_lower) > 0:\n            copia[ix_lower, col]  = perc_low\n        ix_upper = np.where(column > upper)[0]\n        if len(ix_upper) > 0:\n            copia[ix_upper, col] = perc_up\n    return copia","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:06.344207Z","iopub.execute_input":"2021-09-08T21:23:06.344561Z","iopub.status.idle":"2021-09-08T21:23:06.351892Z","shell.execute_reply.started":"2021-09-08T21:23:06.344526Z","shell.execute_reply":"2021-09-08T21:23:06.350824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"outpipeline\"></a>\n### **5.3 Testing the new pipeline**","metadata":{}},{"cell_type":"code","source":"trans_steps = [(\"ss\", StandardScaler(), X_trans.columns)]\ncol_trans = ColumnTransformer(transformers = trans_steps)\npipeline = Pipeline(steps = [(\"trans\", col_trans),(\"no_out\",FunctionTransformer(outlier_removal)) ,(\"model\", LogisticRegression())])\nkfold = KFold(n_splits = 4)\ncv_score = cross_val_score(estimator = pipeline, X = X_trans, y = dataset[\"Outcome\"], cv = kfold, scoring = \"f1\")\nprint(\"Baseline model (Logistic Regression) + outlier removal reaches an accuracy of: {} %\".format(round(np.mean(cv_score),4)*100))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:06.353742Z","iopub.execute_input":"2021-09-08T21:23:06.354255Z","iopub.status.idle":"2021-09-08T21:23:06.431994Z","shell.execute_reply.started":"2021-09-08T21:23:06.354217Z","shell.execute_reply":"2021-09-08T21:23:06.431089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"outremovalcomment\"></a>\n### **5.4 Comments on outliers removal**\n\nI have just run a pipeline with a step consisting in dropping the extremely low and high values from the dataset. \nAs a result, I have obtained a model that underperforms the first one in terms of F1-score( 62,7% vs 62,05 %). Nevertheless, there are three levers that can lead us to different results:\n* Number of datasets folds. Here, I have used the quite standard value of four. However, different values may affect the final result. In fact, here I run an example with a final plot where we can see the obtained result for each falue of kfold:","metadata":{}},{"cell_type":"code","source":"kfold_results = []\nfor i in [2,4,5,10,20,50]:\n    trans_steps = [(\"ss\", StandardScaler(), X_trans.columns)]\n    col_trans = ColumnTransformer(transformers = trans_steps)\n    pipeline = Pipeline(steps = [(\"trans\", col_trans),(\"no_out\", FunctionTransformer(outlier_removal)),(\"model\", LogisticRegression())])\n    kfold = KFold(n_splits = i)\n    cv_score = cross_val_score(estimator = pipeline, X = X_trans, y = dataset[\"Outcome\"], cv = kfold, scoring = \"f1\")\n    kfold_results.append(round(np.mean(cv_score),4))    ","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:06.433296Z","iopub.execute_input":"2021-09-08T21:23:06.433722Z","iopub.status.idle":"2021-09-08T21:23:07.928931Z","shell.execute_reply.started":"2021-09-08T21:23:06.433687Z","shell.execute_reply":"2021-09-08T21:23:07.92796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sbn.lineplot(x = [2,4,5,10,20,50], y = kfold_results)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:07.932056Z","iopub.execute_input":"2021-09-08T21:23:07.932359Z","iopub.status.idle":"2021-09-08T21:23:08.110405Z","shell.execute_reply.started":"2021-09-08T21:23:07.932332Z","shell.execute_reply":"2021-09-08T21:23:08.109503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Low proportion of outliers vs non-outliers. In cases where the number of extreme values are low when compared to the rest of registries, their removal may not affect considerably the model classification power.\n* Different definition of outlier. Previously, I stated that there is no *official* definition of what can be considered an extreme value. It could be more dependable of the dataset rather than academia definitions. For convenience, I chose a widely used definition (1.5 time the IQR, using .25 and .75 percentiles to compute that IQR). Nevertheless, different inputs (percentile values and times IQR values) could affect the final result.\n\n","metadata":{}},{"cell_type":"markdown","source":"Modifying percentile values:","metadata":{}},{"cell_type":"code","source":"def outlier_removal2(X, n_iqr = 1.5, lower_perc = 0.20, verbose = False):\n    copia = X.copy()\n    for col in range (copia.shape[1]):\n        column = copia[:,col]\n        perc_low, perc_up = np.quantile(column, lower_perc), np.quantile(column, (1-lower_perc))\n        iqr = perc_up - perc_low\n        cutoff = iqr*n_iqr\n        lower, upper = perc_low-cutoff , perc_up+cutoff\n        ix_lower = np.where(column < lower)[0]\n        if len(ix_lower) > 0:\n            copia[ix_lower, col]  = perc_low\n        ix_upper = np.where(column > upper)[0]\n        if len(ix_upper) > 0:\n            copia[ix_upper, col] = perc_up\n    return copia","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:08.112089Z","iopub.execute_input":"2021-09-08T21:23:08.112484Z","iopub.status.idle":"2021-09-08T21:23:08.120192Z","shell.execute_reply.started":"2021-09-08T21:23:08.112446Z","shell.execute_reply":"2021-09-08T21:23:08.119162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trans_steps = [(\"ss\", StandardScaler(), X_trans.columns)]\ncol_trans = ColumnTransformer(transformers = trans_steps)\npipeline = Pipeline(steps = [(\"trans\", col_trans),(\"no_out\",FunctionTransformer(outlier_removal2)) ,(\"model\", LogisticRegression())])\nkfold = KFold(n_splits = 4)\ncv_score = cross_val_score(estimator = pipeline, X = X_trans, y = dataset[\"Outcome\"], cv = kfold, scoring = \"f1\")\nprint(\"Baseline model (Logistic Regression) + outlier removal reaches an accuracy of: {} %\".format(round(np.mean(cv_score),4)*100))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:08.121808Z","iopub.execute_input":"2021-09-08T21:23:08.122202Z","iopub.status.idle":"2021-09-08T21:23:08.207492Z","shell.execute_reply.started":"2021-09-08T21:23:08.122165Z","shell.execute_reply":"2021-09-08T21:23:08.206457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modifying iqr multiplier:","metadata":{}},{"cell_type":"code","source":"def outlier_removal3(X, n_iqr = 2.5, lower_perc = 0.20, verbose = False):\n    copia = X.copy()\n    for col in range (copia.shape[1]):\n        column = copia[:,col]\n        perc_low, perc_up = np.quantile(column, lower_perc), np.quantile(column, (1-lower_perc))\n        iqr = perc_up - perc_low\n        cutoff = iqr*n_iqr\n        lower, upper = perc_low-cutoff , perc_up+cutoff\n        ix_lower = np.where(column < lower)[0]\n        if len(ix_lower) > 0:\n            copia[ix_lower, col]  = perc_low\n        ix_upper = np.where(column > upper)[0]\n        if len(ix_upper) > 0:\n            copia[ix_upper, col] = perc_up\n    return copia","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:08.208973Z","iopub.execute_input":"2021-09-08T21:23:08.209542Z","iopub.status.idle":"2021-09-08T21:23:08.218195Z","shell.execute_reply.started":"2021-09-08T21:23:08.209497Z","shell.execute_reply":"2021-09-08T21:23:08.216955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trans_steps = [(\"ss\", StandardScaler(), X_trans.columns)]\ncol_trans = ColumnTransformer(transformers = trans_steps)\npipeline = Pipeline(steps = [(\"trans\", col_trans),(\"no_out\",FunctionTransformer(outlier_removal3)) ,(\"model\", LogisticRegression())])\nkfold = KFold(n_splits = 4)\ncv_score = cross_val_score(estimator = pipeline, X = X_trans, y = dataset[\"Outcome\"], cv = kfold, scoring = \"f1\")\nprint(\"Baseline model (Logistic Regression) + outlier removal reaches an accuracy of: {} %\".format(round(np.mean(cv_score),4)*100))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:08.219963Z","iopub.execute_input":"2021-09-08T21:23:08.220697Z","iopub.status.idle":"2021-09-08T21:23:08.308683Z","shell.execute_reply.started":"2021-09-08T21:23:08.220657Z","shell.execute_reply":"2021-09-08T21:23:08.307777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion:** \nIAs we can see in the previous chapter, I have tested several pipelines with different inputs for the pipeline and the arguments for our custom outlier remover function. As a result, I have obtained different results depeding on the inputs. Thus, I will stick with the top performer for future steps in the analysis. \n\n[Back to Table of Contents](#tc)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"testingmodels\"></a>\n### **6. Testing different classification models**\n\nI have only tested one classification algorithm. Nevertheless, there are some other that could even outperform the Logistic Regression. \nAs an exercise, I will test the following functions along with a colection of hyperparameters. The purpose of this step is to obtain the *top performer* algorithm.\nTo do so, I will first create a dictinary containing two elements:\n1. The model itself\n2. *Hyperparameters* that can be modified during the Grid Search.\n\n**Note:** the number of parameters can be quite large since some of them are list of numbers. However, extending the number of parameters can provoke the training phase to be quite large. In order to avoid this, I have choosen a sample of values for some certain parameters which are numbers (either integers of floats). ","metadata":{}},{"cell_type":"code","source":"dict_scores = {}\ndict_scores.update({\"LogReg\":{\"model\":LogisticRegression(), \"param_grid\":{\"model__solver\":[\"newton-cg\", \"sag\", \"saga\", \"lbfgs\"],\"model__C\":[-1,-0.5,-0,1,0,0.10,0.5,1]}}})\ndict_scores.update({\"DecTree\":{\"model\": DecisionTreeClassifier(),\"param_grid\":{\"model__criterion\":[\"gini\", \"entropy\"]}}})\ndict_scores.update({\"RandomForest\":{\"model\": RandomForestClassifier(),\"param_grid\":{\"model__n_estimators\":[10,20,30,50,60,70,80,90,100], \"model__criterion\":[\"gini\", \"entropy\"]}}})\ndict_scores.update({\"KNN\":{\"model\": KNeighborsClassifier(), \"param_grid\":{\"model__n_neighbors\":[5,10,15,20], \"model__p\":[1,2]}}})\ndict_scores.update({\"Naive_bayes\":{\"model\": GaussianNB()}})\ndict_scores.update({\"SVM\":{\"model\":SVC(),\"param_grid\":{\"model__C\":[-1,-0.5,-0,1,0,0.10,0.5,1]}}})","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:08.309958Z","iopub.execute_input":"2021-09-08T21:23:08.310343Z","iopub.status.idle":"2021-09-08T21:23:08.319386Z","shell.execute_reply.started":"2021-09-08T21:23:08.310305Z","shell.execute_reply":"2021-09-08T21:23:08.318437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once the dictionary has been delcared, I will run the following code snippet. What it does is basically in each iteration:\n1. Selects the model\n2. Looks for the best parameters within the grid search\n3. Updates the results (parameters and score) of the previous step","metadata":{}},{"cell_type":"code","source":"for key in dict_scores.keys():\n    if \"param_grid\" in dict_scores[key]:\n        trans_steps = [(\"ss\", StandardScaler(), X_trans.columns)]\n        col_trans = ColumnTransformer(transformers = trans_steps)\n        pipeline = Pipeline(steps = [(\"trans\", col_trans),(\"no_out\", FunctionTransformer(outlier_removal2)),(\"model\", dict_scores[key][\"model\"])])\n        kfold = KFold(n_splits = 4)\n        search = GridSearchCV(estimator = pipeline, param_grid = dict_scores[key][\"param_grid\"], scoring = \"f1\", n_jobs = -1, refit = True, cv = kfold, verbose = 0)\n        search.fit(X_trans, y)\n        dict_scores[key].update({\"best_params\":search.best_params_})\n        dict_scores[key].update({\"best_score\": search.best_score_})\n    else:\n        trans_steps = [(\"ss\", StandardScaler(), X_trans.columns)]\n        col_trans = ColumnTransformer(transformers = trans_steps)\n        pipeline = Pipeline(steps = [(\"trans\", col_trans),(\"no_out\", FunctionTransformer(outlier_removal2)),(\"model\", dict_scores[key][\"model\"])])\n        kfold = KFold(n_splits = 4)\n        cv_score = cross_val_score(estimator = pipeline, X = X_trans, y = dataset[\"Outcome\"], cv = kfold, n_jobs = -1, verbose = 0, scoring = \"f1\")\n        dict_scores[key].update({\"best_params\": \"N/A\"})\n        dict_scores[key].update({\"best_score\": np.mean(cv_score)})\n        ","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:08.321158Z","iopub.execute_input":"2021-09-08T21:23:08.321669Z","iopub.status.idle":"2021-09-08T21:23:19.64354Z","shell.execute_reply.started":"2021-09-08T21:23:08.321541Z","shell.execute_reply":"2021-09-08T21:23:19.642613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for key in dict_scores.keys():\n    print(\"Model: {}. Best score: {}\".format(key,dict_scores[key][\"best_score\"]))","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:19.644758Z","iopub.execute_input":"2021-09-08T21:23:19.645292Z","iopub.status.idle":"2021-09-08T21:23:19.651297Z","shell.execute_reply.started":"2021-09-08T21:23:19.645237Z","shell.execute_reply":"2021-09-08T21:23:19.650403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The best available model is the RandomForest with the following parameters:","metadata":{}},{"cell_type":"code","source":"print(dict_scores[\"RandomForest\"][\"best_params\"])","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:19.652546Z","iopub.execute_input":"2021-09-08T21:23:19.653158Z","iopub.status.idle":"2021-09-08T21:23:19.661879Z","shell.execute_reply.started":"2021-09-08T21:23:19.65312Z","shell.execute_reply":"2021-09-08T21:23:19.661156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[Back to Table of Contents](#tc)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"featureengineering\"></a>\n### **7. Feature Engineering**\n\nNow that I have the top performing model along with its hyperparameters selected, I will try to improve it by providing the model new features consisting in combination of the existing ones. \nFor that purpose, I will use the PolynomialFeatures() function provided by the library Scikit-Learn.\nSince I am working with sklearn Pipelines, I will include this function as an aditional step.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"deg_cv_score = {}\nfor deg in range(1,5):\n    trans_steps = [(\"ss\", StandardScaler(), X_trans.columns),(\"poly\", PolynomialFeatures(degree = deg), X_trans.columns)]\n    col_trans = ColumnTransformer(transformers = trans_steps)\n    pipeline = Pipeline(steps = [(\"trans\", col_trans),(\"no_out\", FunctionTransformer(outlier_removal2)),(\"model\", RandomForestClassifier(criterion = \"entropy\", n_estimators = 50))])\n    kfold = KFold(n_splits = 10)\n    deg_cv_score.update({deg:np.mean(cross_val_score(estimator = pipeline, X = X_trans, y = dataset[\"Outcome\"], cv = kfold, scoring = \"f1\"))})","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:19.663515Z","iopub.execute_input":"2021-09-08T21:23:19.664143Z","iopub.status.idle":"2021-09-08T21:23:37.399819Z","shell.execute_reply.started":"2021-09-08T21:23:19.664105Z","shell.execute_reply":"2021-09-08T21:23:37.399088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"degrees = list(deg_cv_score.keys())\nf1 = list(deg_cv_score.values())\nsbn.lineplot(x = degrees, y = f1)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:23:37.401252Z","iopub.execute_input":"2021-09-08T21:23:37.401591Z","iopub.status.idle":"2021-09-08T21:23:37.576592Z","shell.execute_reply.started":"2021-09-08T21:23:37.401557Z","shell.execute_reply":"2021-09-08T21:23:37.575833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I have tested the *PolynomialFeatures()* function with a range of degrees. Here, the higher the degree, the more complex traning and prone to overfitting.\nAs we can see in the previous graph, the model reaches the highest f1 score with a degree = 3. Beyond that limit, the model starts overfitting. Thus, I will select degree = 3 for the next steps.\n\n[Back to Table of Content](#tc)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"rfe\"></a>\n### **8. Recursive Feature Extraction**","metadata":{}},{"cell_type":"code","source":"rfe_f1 = {}\nfor i in range(1,10):\n    trans_steps = [(\"ss\", StandardScaler(), X_trans.columns),(\"poly\", PolynomialFeatures(degree = 3), X_trans.columns)]\n    col_trans = ColumnTransformer(transformers = trans_steps)\n    pipeline = Pipeline(steps = [(\"trans\", col_trans),(\"no_out\", FunctionTransformer(outlier_removal2)), (\"rfe\",RFE(estimator = RandomForestClassifier(criterion = \"entropy\", n_estimators = 50), n_features_to_select = i)),(\"model\", RandomForestClassifier(criterion = \"entropy\", n_estimators = 50))])\n    kfold = KFold(n_splits = 4)\n    rfe_f1.update({i:np.mean(cross_val_score(estimator = pipeline, X = X_trans, y = dataset[\"Outcome\"], cv = kfold, scoring = \"f1\"))})","metadata":{"execution":{"iopub.status.busy":"2021-09-08T21:48:22.151833Z","iopub.execute_input":"2021-09-08T21:48:22.152154Z","iopub.status.idle":"2021-09-08T22:13:17.811874Z","shell.execute_reply.started":"2021-09-08T21:48:22.152125Z","shell.execute_reply":"2021-09-08T22:13:17.811084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After running the previous pipeline, we can check the performance of each model.Below, we can see both numerical results and a graph with the same information:","metadata":{}},{"cell_type":"code","source":"rfe_f1","metadata":{"execution":{"iopub.status.busy":"2021-09-08T22:15:03.804572Z","iopub.execute_input":"2021-09-08T22:15:03.8049Z","iopub.status.idle":"2021-09-08T22:15:03.812137Z","shell.execute_reply.started":"2021-09-08T22:15:03.804869Z","shell.execute_reply":"2021-09-08T22:15:03.81097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_features = list(rfe_f1.keys())\nnfeat_f1 = list(rfe_f1.values())","metadata":{"execution":{"iopub.status.busy":"2021-09-08T22:15:04.026558Z","iopub.execute_input":"2021-09-08T22:15:04.02685Z","iopub.status.idle":"2021-09-08T22:15:04.031752Z","shell.execute_reply.started":"2021-09-08T22:15:04.026824Z","shell.execute_reply":"2021-09-08T22:15:04.030821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sbn.lineplot(x = num_features, y = nfeat_f1)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T22:13:17.832992Z","iopub.execute_input":"2021-09-08T22:13:17.833398Z","iopub.status.idle":"2021-09-08T22:13:18.030146Z","shell.execute_reply.started":"2021-09-08T22:13:17.833362Z","shell.execute_reply":"2021-09-08T22:13:18.029079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[Back to Table of Contents](#tc)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"conclu\"></a>\n### **9. Conclusion**\n\nAfter defining the problem statement and performing an exploratory data analysis, I better understood both the exercise to be done and the provided dataset. On this part of the kernel, I took some decissions regarding outliers and variables removal prior a baseline model.\n\nOnce I got a baseline, I tested different algorithms along with several parameters for each one in order to find the best posiible model. After this, I measured the F1-score for different digrees of Polynomial Features, finding the value of three the one providing the best results. \n\nSince Polynomial Features provide a hughe amount of variables, I wanted to see if eliminating some of them could result in a sacrifice of performance, through recursive feature extraction. I found that 5 factors is enough to achieve the maximum performance given the decissions made, used techniques and data provided.\nFollowing the previous steps I passed from a 62,7% to a 65,56%.\n\n**Further steps**:\n\nI haven't tested a neural network model on this notebook. Since this type of model can be tuned by modifying the number of perceptrons and layers (as well as activations functions, among others) I will probably part from these results in order to check how good a neural network can perform with this task.\n\n[Back to Table of Contents](#tc)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"links\"></a>\n### **10. Useful notebooks and links:**\n\n* [Create Table of Contents in a Notebook](https://www.kaggle.com/dcstang/create-table-of-contents-in-a-notebook)\n* [Removing Outliers within a Pipeline](https://www.kaggle.com/jonaspalucibarbosa/removing-outliers-within-a-pipeline)\n* [How to remove outliers For Machine Learning](https://machinelearningmastery.com/how-to-use-statistics-to-identify-outliers-in-data/)","metadata":{}}]}