{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TensorFlow Modeling for [LEGO Minifigures Classification](https://www.kaggle.com/ihelon/lego-minifigures-classification) dataset\n\nThis is the guide about using pre-trained models in TensorFlow and Keras frameworks.   \nWe will use the MobileNetV2 model to predict which Minifigure is in the image.   ","metadata":{}},{"cell_type":"markdown","source":"![](https://i.imgur.com/4cPQlEN.jpg)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"top\"></a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:blue; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Quick Navigation</center></h3>\n\n* [1. Configurations](#1)\n* [2. Data reading](#2)\n* [3. Data generator](#3)\n* [4. Augmentations](#4)\n* [5. Train and valid generators](#5)\n* [6. Data visualizations (train samples)](#6)   \n* [7. Data visualizations (valid samples)](#7)   \n* [8. Model initialization](#8)   \n* [9. Checkpoints initialization](#9)\n* [10. Model training](#10)\n* [11. Train logs](#11)\n* [12. Final test score check](#12)\n* [13. Error analysis - Confusion matrix](#13)\n* [14. Error analysis - Misclassified samples](#14)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Configurations<center><h2>","metadata":{}},{"cell_type":"code","source":"import os\nimport math\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport albumentations as A\nimport tensorflow as tf\nfrom tensorflow.keras.applications import mobilenet_v2 as tf_mobilenet_v2\nfrom tensorflow.keras import layers as tf_layers\nfrom tensorflow.keras import models as tf_models\nfrom tensorflow.keras import callbacks as tf_callbacks\nfrom sklearn import metrics as sk_metrics\nfrom sklearn import model_selection as sk_model_selection","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-15T19:33:12.856737Z","iopub.execute_input":"2021-07-15T19:33:12.857114Z","iopub.status.idle":"2021-07-15T19:33:14.977713Z","shell.execute_reply.started":"2021-07-15T19:33:12.857074Z","shell.execute_reply":"2021-07-15T19:33:14.976904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The directory to the dataset","metadata":{}},{"cell_type":"code","source":"BASE_DIR = \"../input/lego-minifigures-classification/\"\nPATH_INDEX = os.path.join(BASE_DIR, \"index.csv\")\nPATH_TEST = os.path.join(BASE_DIR, \"test.csv\")\nPATH_METADATA = os.path.join(BASE_DIR, \"metadata.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:33:14.979637Z","iopub.execute_input":"2021-07-15T19:33:14.980034Z","iopub.status.idle":"2021-07-15T19:33:14.990202Z","shell.execute_reply.started":"2021-07-15T19:33:14.979991Z","shell.execute_reply":"2021-07-15T19:33:14.986956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's define all out configs and parameters in the one place","metadata":{}},{"cell_type":"code","source":"config = {\n    \"seed\": 42,\n    \n    \"valid_size\": 0.3,\n    \n    \"image_size\": (512, 512),\n    \"train_batch_size\": 4,\n    \"valid_batch_size\": 1,\n    \"test_batch_size\": 1,\n    \n    \"model\": \"mobilenet_v2\",\n    \"max_epochs\": 50,\n    \"patience_stop\": 3,\n    \"path_to_save_model\": \"best.hdf5\",\n    \"callbacks_monitor\": \"val_loss\",\n    \n}","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:33:14.992277Z","iopub.execute_input":"2021-07-15T19:33:14.992756Z","iopub.status.idle":"2021-07-15T19:33:14.999732Z","shell.execute_reply.started":"2021-07-15T19:33:14.992711Z","shell.execute_reply":"2021-07-15T19:33:14.998825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Try to set random seet that our experiment repeated between (We have some problem to set seed with GPU in Kaggle)","metadata":{}},{"cell_type":"code","source":"def set_seed(seed_value):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    tf.random.set_seed(seed_value)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed_value)\n    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"true\"\n    \n\nset_seed(config[\"seed\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:33:15.001463Z","iopub.execute_input":"2021-07-15T19:33:15.002107Z","iopub.status.idle":"2021-07-15T19:33:15.010426Z","shell.execute_reply.started":"2021-07-15T19:33:15.001891Z","shell.execute_reply":"2021-07-15T19:33:15.009542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Data reading<center><h2>","metadata":{}},{"cell_type":"code","source":"# Read information about dataset\ndf = pd.read_csv(PATH_INDEX)\n\ntmp_train, tmp_valid = sk_model_selection.train_test_split(\n    df, \n    test_size=config[\"valid_size\"], \n    random_state=config[\"seed\"], \n    stratify=df['class_id'],\n)\n\n\ndef get_paths_and_targets(tmp_df):\n    # Get file paths\n    paths = tmp_df[\"path\"].values\n    # Create full paths (base dir + concrete file name)\n    paths = list(map(lambda x: os.path.join(BASE_DIR, x), paths))\n    # Get labels\n    targets = tmp_df[\"class_id\"].values\n    \n    return paths, targets\n\n\n# Get train file paths and targets\ntrain_paths, train_targets = get_paths_and_targets(tmp_train)\n\n# Get valid file paths and targets\nvalid_paths, valid_targets = get_paths_and_targets(tmp_valid)\n\ndf_test = pd.read_csv(PATH_TEST)\n# Get test file paths and targets\ntest_paths, test_targets = get_paths_and_targets(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:33:15.014635Z","iopub.execute_input":"2021-07-15T19:33:15.014906Z","iopub.status.idle":"2021-07-15T19:33:15.041683Z","shell.execute_reply.started":"2021-07-15T19:33:15.014881Z","shell.execute_reply":"2021-07-15T19:33:15.040977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Total number of classes in the dataset\ndf_metadata = pd.read_csv(PATH_METADATA)\nn_classes = df_metadata.shape[0]\nprint(\"Number of classes: \", n_classes)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:33:15.043627Z","iopub.execute_input":"2021-07-15T19:33:15.04411Z","iopub.status.idle":"2021-07-15T19:33:15.056479Z","shell.execute_reply.started":"2021-07-15T19:33:15.044071Z","shell.execute_reply":"2021-07-15T19:33:15.055781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Data generator<center><h2>","metadata":{}},{"cell_type":"markdown","source":"DataGenerator allows you not to load the entire dataset to memory at once, but to do it in batches     \nEach time we have only one batch of pictures in memory","metadata":{}},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    def __init__(\n        self, paths, targets, image_size=(224, 224), batch_size=64, \n        shuffle=True, transforms=None, preprocess=None,\n    ):\n        # the list of paths to files\n        self.paths = paths\n        # the list with the true labels of each file\n        self.targets = targets\n        # images size\n        self.image_size = image_size\n        # batch size (the number of images)\n        self.batch_size = batch_size\n        # if we need to shuffle order of files\n        # for validation we don't need to shuffle, for training - do\n        self.shuffle = shuffle\n        # Augmentations for our images. It is implemented with albumentations library\n        self.transforms = transforms\n        # Preprocess function for the pretrained model. \n        # CHANGE IT IF USING OTHER THAN MOBILENETV2 MODEL\n        self.preprocess = preprocess\n        \n        # Call function to create and shuffle (if needed) indices of files\n        self.on_epoch_end()\n        \n    def on_epoch_end(self):\n        # This function is called at the end of each epoch while training\n        \n        # Create as many indices as many files we have\n        self.indexes = np.arange(len(self.paths))\n        # Shuffle them if needed\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n            \n    def __len__(self):\n        # We need that this function returns the number of steps in one epoch\n        \n        # How many batches we have\n        return len(self.paths) // self.batch_size\n    \n    \n    def __getitem__(self, index):\n        # This function returns batch of pictures with their labels\n        \n        # Take in order as many indices as our batch size is\n        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n        \n        # Take image file paths that are included in that batch\n        batch_paths = [self.paths[k] for k in indexes]\n        # Take labels for each image\n        batch_y = [self.targets[k] - 1 for k in indexes]\n        batch_X = []\n        for i in range(self.batch_size):\n            # Read the image\n            img = cv2.imread(batch_paths[i])\n            # Resize it to needed shape\n            img = cv2.resize(img, self.image_size)\n            # Convert image colors from BGR to RGB\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            # Apply transforms (see albumentations library)\n            if self.transforms:\n                img = self.transforms(image=img)[\"image\"]\n            # Apply preprocess\n            if self.preprocess:\n                img = self.preprocess(img)\n            \n            batch_X.append(img)\n            \n        return np.array(batch_X), np.array(batch_y)\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-07-15T19:33:15.058143Z","iopub.execute_input":"2021-07-15T19:33:15.058498Z","iopub.status.idle":"2021-07-15T19:33:15.075183Z","shell.execute_reply.started":"2021-07-15T19:33:15.058461Z","shell.execute_reply":"2021-07-15T19:33:15.074326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Augmentations<center><h2>","metadata":{}},{"cell_type":"markdown","source":"Albumentations augmentations for the train data.       \nWe don't need this transformations for the validation.   \n[albumentations-demo](https://albumentations-demo.herokuapp.com/) ","metadata":{}},{"cell_type":"code","source":"def get_train_transforms():\n    return A.Compose(\n        [\n            A.ShiftScaleRotate(\n                p=1.0, \n                shift_limit=(-0.1, 0.1), \n                scale_limit=(-0.2, 0.2), \n                rotate_limit=(-30, 30), \n                border_mode=4\n            ),\n            A.CoarseDropout(\n                p=0.5, \n                max_holes=100, \n                max_height=50, \n                max_width=50, \n                min_holes=10, \n                min_height=10, \n                min_width=10,\n                fill_value=0,\n            ),\n            A.CoarseDropout(\n                p=0.5, \n                max_holes=100, \n                max_height=50, \n                max_width=50, \n                min_holes=10, \n                min_height=10, \n                min_width=10,\n                fill_value=255,\n            ),\n            A.HorizontalFlip(p=0.5),\n            A.RandomContrast(limit=(-0.3, 0.3), p=0.5),\n            A.RandomBrightness(limit=(-0.4, 0.4), p=0.5),\n            A.Blur(p=0.25),\n        ], \n        p=1.0\n    )","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:33:15.077825Z","iopub.execute_input":"2021-07-15T19:33:15.078413Z","iopub.status.idle":"2021-07-15T19:33:15.089678Z","shell.execute_reply.started":"2021-07-15T19:33:15.078373Z","shell.execute_reply":"2021-07-15T19:33:15.088867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"5\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Train and valid generators<center><h2>","metadata":{}},{"cell_type":"code","source":"# Initialize the train data generator\ntrain_generator = DataGenerator(\n    train_paths, \n    train_targets, \n    batch_size=config[\"train_batch_size\"], \n    image_size=config[\"image_size\"],\n    shuffle=True, \n    transforms=get_train_transforms(),\n    preprocess=tf_mobilenet_v2.preprocess_input,\n)\n\n# Initialize the valid data generator\nvalid_generator = DataGenerator(\n    valid_paths, \n    valid_targets, \n    image_size=config[\"image_size\"],\n    batch_size=config[\"valid_batch_size\"], \n    shuffle=False,\n    preprocess=tf_mobilenet_v2.preprocess_input,\n)\n\n# Initialize the test data generator\ntest_generator = DataGenerator(\n    test_paths, \n    test_targets, \n    image_size=config[\"image_size\"],\n    batch_size=config[\"test_batch_size\"], \n    shuffle=False,\n    preprocess=tf_mobilenet_v2.preprocess_input,\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:33:15.091118Z","iopub.execute_input":"2021-07-15T19:33:15.091524Z","iopub.status.idle":"2021-07-15T19:33:15.102124Z","shell.execute_reply.started":"2021-07-15T19:33:15.091485Z","shell.execute_reply":"2021-07-15T19:33:15.101398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"6\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Data visualizations (train samples)<center><h2>","metadata":{}},{"cell_type":"code","source":"def denormalize_image(image):\n    return ((image + 1) * 127.5).astype(int)\n\n# Let's visualize some batches of the train data\nplt.figure(figsize=(16, 16))\nind = 0\nfor i_batch in range(len(train_generator)):\n    images, labels = train_generator[i_batch]\n    for i in range(len(images)):\n        plt.subplot(5, 5, ind + 1)\n        ind += 1\n        plt.imshow(denormalize_image(images[i]))\n        plt.title(f\"class: {labels[i]}\")\n        plt.axis(\"off\")\n        if ind >= 25:\n            break\n    if ind >= 25:\n        break","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:33:15.104019Z","iopub.execute_input":"2021-07-15T19:33:15.104468Z","iopub.status.idle":"2021-07-15T19:33:17.412227Z","shell.execute_reply.started":"2021-07-15T19:33:15.10443Z","shell.execute_reply":"2021-07-15T19:33:17.411318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"7\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Data visualizations (valid samples)<center><h2>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(16, 16))\nind = 0\nfor i_batch in range(len(valid_generator)):\n    images, labels = valid_generator[i_batch]\n    for i in range(len(images)):\n        plt.subplot(5, 5, ind + 1)\n        ind += 1\n        plt.imshow(denormalize_image(images[i]))\n        plt.title(f\"class: {labels[i]}\")\n        plt.axis(\"off\")\n        if ind >= 25:\n            break\n    if ind >= 25:\n        break","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:33:17.413448Z","iopub.execute_input":"2021-07-15T19:33:17.413763Z","iopub.status.idle":"2021-07-15T19:33:19.180554Z","shell.execute_reply.started":"2021-07-15T19:33:17.413732Z","shell.execute_reply":"2021-07-15T19:33:19.179774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"8\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Model initialization<center><h2>","metadata":{}},{"cell_type":"markdown","source":"We use simple MobileNetV2 model as a backbone","metadata":{}},{"cell_type":"code","source":"def init_mobilenet_v2(n_classes):\n    # We take pretrained MobileNetV2 (see Keras docs)\n    base_model = tf_mobilenet_v2.MobileNetV2()\n    x = base_model.layers[-2].output\n    # Take penultimate layer of the MobileNetV2 model and connect this layer with Dropout\n    x = tf_layers.Dropout(.5)(x)\n    # Add additional Dense layer, with number of neurons as number of our classes\n    # Use softmax activation because we have one class classification problem\n    outputs = tf_layers.Dense(n_classes, activation=\"softmax\")(x)\n    # Create model using MobileNetV2 input and our created output\n    model = tf_models.Model(base_model.inputs, outputs)\n    \n    return model\n\n\ndef compile_model(model, optimizer, loss, metrics):\n    # Compile model using Adam optimizer and categorical crossentropy loss\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n    return model\n\n\nmodels_constructor = {\n    \"mobilenet_v2\": init_mobilenet_v2,\n}","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:33:19.181709Z","iopub.execute_input":"2021-07-15T19:33:19.182147Z","iopub.status.idle":"2021-07-15T19:33:19.191638Z","shell.execute_reply.started":"2021-07-15T19:33:19.182111Z","shell.execute_reply":"2021-07-15T19:33:19.190942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"9\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Checkpoints initialization<center><h2>","metadata":{}},{"cell_type":"code","source":"# checkpoint to saving the best model by validation loss\ncallback_save = tf_callbacks.ModelCheckpoint(\n    config[\"path_to_save_model\"],\n    monitor=config[\"callbacks_monitor\"],\n    save_best_only=True,\n)\n\n# checkpoint to stop training if model didn't improve valid loss for 3 epochs\ncallback_early_stopping = tf_callbacks.EarlyStopping(\n    monitor=config[\"callbacks_monitor\"],\n    patience=config[\"patience_stop\"],\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:33:19.193014Z","iopub.execute_input":"2021-07-15T19:33:19.193621Z","iopub.status.idle":"2021-07-15T19:33:19.201737Z","shell.execute_reply.started":"2021-07-15T19:33:19.193586Z","shell.execute_reply":"2021-07-15T19:33:19.200962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"10\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Model training<center><h2>","metadata":{}},{"cell_type":"code","source":"model = models_constructor[config[\"model\"]](n_classes)\ncompile_model(\n    model,\n    tf.keras.optimizers.Adam(0.0001), \n    \"sparse_categorical_crossentropy\", \n    [\"accuracy\"],\n)\n\n# Train model using data generators\nhistory = model.fit(\n    train_generator,\n    validation_data=valid_generator,\n    epochs=config[\"max_epochs\"],\n    callbacks=[callback_save, callback_early_stopping],\n    verbose=1,\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:33:19.203149Z","iopub.execute_input":"2021-07-15T19:33:19.203822Z","iopub.status.idle":"2021-07-15T19:33:48.745876Z","shell.execute_reply.started":"2021-07-15T19:33:19.203785Z","shell.execute_reply":"2021-07-15T19:33:48.744909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"11\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Train logs<center><h2>","metadata":{}},{"cell_type":"code","source":"def plot_history(param=\"loss\"):\n    plt.figure(figsize=(6, 6))\n    if param == \"loss\":\n        plt.plot(history.history[\"loss\"], label=\"train loss\")\n        plt.plot(history.history[\"val_loss\"], label=\"valid loss\")\n        plt.ylabel(\"Loss value\", fontsize=15)\n    elif param == \"accuracy\":\n        plt.plot(history.history[\"accuracy\"], label=\"train acc\")\n        plt.plot(history.history[\"val_accuracy\"], label=\"valid acc\")\n        plt.ylim(0, 1)\n        plt.ylabel(\"Accuracy score\", fontsize=15)\n    plt.xticks(fontsize=14)\n    plt.xlabel(\"Epoch number\", fontsize=15)\n    plt.yticks(fontsize=14)\n    plt.legend(fontsize=15)\n    plt.grid()\n    plt.show()\n\n\n# Visualize train and valid loss \nplot_history(\"loss\")\n# Visualize train and valid accyracy \nplot_history(\"accuracy\")","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:33:48.747825Z","iopub.execute_input":"2021-07-15T19:33:48.748237Z","iopub.status.idle":"2021-07-15T19:33:49.128213Z","shell.execute_reply.started":"2021-07-15T19:33:48.748191Z","shell.execute_reply":"2021-07-15T19:33:49.127227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"12\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Final test check<center><h2>","metadata":{}},{"cell_type":"code","source":"# Load the best model (we create for checkpoint to save the best model)\nmodel = tf_models.load_model(config[\"path_to_save_model\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:33:49.132518Z","iopub.execute_input":"2021-07-15T19:33:49.13289Z","iopub.status.idle":"2021-07-15T19:33:51.551309Z","shell.execute_reply.started":"2021-07-15T19:33:49.132852Z","shell.execute_reply":"2021-07-15T19:33:51.550361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model predictions and true labels\ny_pred = []\ny_test = []\nfor _X_test, _y_test in test_generator:\n    y_pred.extend(model.predict(_X_test).argmax(axis=-1))\n    y_test.extend(_y_test)\n\n# Calculate needed metrics\nprint(f\"Accuracy score on test data: {sk_metrics.accuracy_score(y_test, y_pred)}\")\nprint(f\"Macro F1 score on test data: {sk_metrics.f1_score(y_test, y_pred, average='macro')}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:33:51.553139Z","iopub.execute_input":"2021-07-15T19:33:51.553494Z","iopub.status.idle":"2021-07-15T19:33:55.637713Z","shell.execute_reply.started":"2021-07-15T19:33:51.553456Z","shell.execute_reply":"2021-07-15T19:33:55.636689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"13\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Error analysis - Confusion matrix<center><h2>","metadata":{}},{"cell_type":"code","source":"# Load metadata to get classes people-friendly names\nlabels = df_metadata[\"minifigure_name\"].tolist()\n\n# Calculate confusion matrix\nconfusion_matrix = sk_metrics.confusion_matrix(y_test, y_pred)\ndf_confusion_matrix = pd.DataFrame(confusion_matrix, index=labels, columns=labels)\n\n# Show confusion matrix\nplt.figure(figsize=(12, 12))\nsn.heatmap(df_confusion_matrix, annot=True, cbar=False, cmap=\"Oranges\", linewidths=1, linecolor=\"black\")\nplt.xlabel(\"Predicted labels\", fontsize=15)\nplt.xticks(fontsize=12)\nplt.ylabel(\"True labels\", fontsize=15)\nplt.yticks(fontsize=12);","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:33:55.639013Z","iopub.execute_input":"2021-07-15T19:33:55.639402Z","iopub.status.idle":"2021-07-15T19:33:59.294138Z","shell.execute_reply.started":"2021-07-15T19:33:55.639355Z","shell.execute_reply":"2021-07-15T19:33:59.293252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"14\"></a>\n<h2 style='background:blue; border:0; color:white'><center>Error analysis - Misclassified samples<center><h2>","metadata":{}},{"cell_type":"code","source":"# Save image, label, prediction for false predictions \nerror_images = []\nerror_label = []\nerror_pred = []\nerror_prob = []\nfor _X_test, _y_test in test_generator:\n    pred = model.predict(_X_test).argmax(axis=-1)\n    if pred[0] != _y_test:\n        error_images.extend(_X_test)\n        error_label.extend(_y_test)\n        error_pred.extend(pred)\n        error_prob.extend(model.predict(_X_test).max(axis=-1))","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:33:59.295465Z","iopub.execute_input":"2021-07-15T19:33:59.295837Z","iopub.status.idle":"2021-07-15T19:34:05.790407Z","shell.execute_reply.started":"2021-07-15T19:33:59.295794Z","shell.execute_reply":"2021-07-15T19:34:05.789615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize missclassified samples\nw_size = 3\nh_size = math.ceil(len(error_images) / w_size)\nplt.figure(figsize=(16, h_size * 4))\nfor ind, image in enumerate(error_images):\n    plt.subplot(h_size, w_size, ind + 1)\n    plt.imshow(denormalize_image(image))\n    pred_label = labels[error_pred[ind]]\n    pred_prob = error_prob[ind]\n    true_label = labels[error_label[ind]]\n    plt.title(f\"predict: {pred_label} ({pred_prob:.2f})\\ntrue: {true_label}\", fontsize=12)\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-07-15T19:34:05.792662Z","iopub.execute_input":"2021-07-15T19:34:05.792924Z","iopub.status.idle":"2021-07-15T19:34:11.645754Z","shell.execute_reply.started":"2021-07-15T19:34:05.792897Z","shell.execute_reply":"2021-07-15T19:34:11.644883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}