{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Text Summerization - Encoder Decoder with Attention Mechanism","metadata":{"id":"IEq-oYpmSM5r"}},{"cell_type":"markdown","source":"### Importing Basic libraries","metadata":{"id":"4iFfGxm4XgZl"}},{"cell_type":"code","source":"import re\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nimport contractions\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras import backend as K \nfrom tensorflow.python.keras.layers import Layer\n","metadata":{"id":"lisXNzYrYOoR","outputId":"4ff65cf3-36bb-49c2-a6c3-08070c9233a0","execution":{"iopub.status.busy":"2021-08-18T19:55:16.897146Z","iopub.execute_input":"2021-08-18T19:55:16.897521Z","iopub.status.idle":"2021-08-18T19:55:21.243979Z","shell.execute_reply.started":"2021-08-18T19:55:16.897464Z","shell.execute_reply":"2021-08-18T19:55:21.243069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Importing Data","metadata":{"id":"GSr24NviXqio"}},{"cell_type":"code","source":"#Kaggle\ndata_path = '../input/news-summary/news_summary_more.csv'\ndata = pd.read_csv(data_path)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T19:55:21.245955Z","iopub.execute_input":"2021-08-18T19:55:21.246314Z","iopub.status.idle":"2021-08-18T19:55:22.237538Z","shell.execute_reply.started":"2021-08-18T19:55:21.246274Z","shell.execute_reply":"2021-08-18T19:55:22.23676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop_duplicates(subset=['headlines'],inplace=True)\ndata.reset_index(inplace=True, drop=True)","metadata":{"id":"Mis8W95SAZ5_","execution":{"iopub.status.busy":"2021-08-18T19:55:22.239182Z","iopub.execute_input":"2021-08-18T19:55:22.239553Z","iopub.status.idle":"2021-08-18T19:55:22.283267Z","shell.execute_reply.started":"2021-08-18T19:55:22.239504Z","shell.execute_reply":"2021-08-18T19:55:22.282489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop_words = stopwords.words('english')\n\ndef preprocess(text):\n    text = text.lower()\n    text = ' '.join([contractions.fix(word) for word in text.split(\" \")])    \n    \n    tokens = [w for w in text.split() if not w in stop_words]\n    text = \" \".join(tokens)\n    text = text.replace(\"'s\",'')\n    text = text.replace(\".\",'')\n    text = re.sub(r'\\(.*\\)','',text)\n    text = re.sub(r'[^a-zA-Z0-9. ]',' ',text)\n    text = re.sub(r'\\.','. ',text)\n    text = re.sub(r'\\s+', ' ', text)\n    return text\n","metadata":{"id":"BV8b6w9YYOoa","execution":{"iopub.status.busy":"2021-08-18T19:55:22.28457Z","iopub.execute_input":"2021-08-18T19:55:22.28491Z","iopub.status.idle":"2021-08-18T19:55:22.292504Z","shell.execute_reply.started":"2021-08-18T19:55:22.284875Z","shell.execute_reply":"2021-08-18T19:55:22.291649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['headlines'] = data['headlines'].apply(preprocess)\ndata['text'] = data['text'].apply(preprocess)\ndata['headlines'] = data['headlines'].apply(lambda x : '_START_ '+ x + ' _END_')\n\nfor i in range(2):\n    print('Summary:', data['headlines'][i],'Text:', data['text'][i], sep='\\n')\n    print()","metadata":{"id":"ewSx5cepYOob","outputId":"55b255a6-367f-4443-8184-650066137e32","execution":{"iopub.status.busy":"2021-08-18T19:55:22.294081Z","iopub.execute_input":"2021-08-18T19:55:22.294693Z","iopub.status.idle":"2021-08-18T19:56:05.783002Z","shell.execute_reply.started":"2021-08-18T19:55:22.294656Z","shell.execute_reply":"2021-08-18T19:56:05.782121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"headlines_length = [len(x.split()) for x in data.headlines]\ntext_length = [len(x.split()) for x in data.text]","metadata":{"id":"Tb68xRjGNP8z","execution":{"iopub.status.busy":"2021-08-18T19:56:05.784232Z","iopub.execute_input":"2021-08-18T19:56:05.78476Z","iopub.status.idle":"2021-08-18T19:56:06.078879Z","shell.execute_reply.started":"2021-08-18T19:56:05.784722Z","shell.execute_reply":"2021-08-18T19:56:06.078056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,5))\nax1.hist(headlines_length, bins = 20)\nax2.hist(text_length, bins = 20)\n\nax1.title.set_text(\"Words in Headlines\")\nax2.title.set_text(\"Words in Text\")\nplt.show()","metadata":{"id":"4exx0vZpoZDp","outputId":"4fcef4de-8331-4731-b6af-be6b525e8351","execution":{"iopub.status.busy":"2021-08-18T19:56:06.082585Z","iopub.execute_input":"2021-08-18T19:56:06.082941Z","iopub.status.idle":"2021-08-18T19:56:07.566651Z","shell.execute_reply.started":"2021-08-18T19:56:06.082896Z","shell.execute_reply":"2021-08-18T19:56:07.565908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Embedding Matrix from Glove\n","metadata":{"id":"5J6b2-BXoasR"}},{"cell_type":"code","source":"glove_size = 300\nf = open('../input/glove42b300dtxt/glove.42B.300d.txt')","metadata":{"id":"7vLovzKr0m5S","execution":{"iopub.status.busy":"2021-08-18T19:56:07.568433Z","iopub.execute_input":"2021-08-18T19:56:07.568815Z","iopub.status.idle":"2021-08-18T19:56:07.586166Z","shell.execute_reply.started":"2021-08-18T19:56:07.568778Z","shell.execute_reply":"2021-08-18T19:56:07.585521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings_index = dict()\nfor line in f:\n    values = line.split()\n    embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')\nf.close()","metadata":{"id":"KulasZGc0nDp","execution":{"iopub.status.busy":"2021-08-18T19:56:07.587378Z","iopub.execute_input":"2021-08-18T19:56:07.587729Z","iopub.status.idle":"2021-08-18T19:59:51.031932Z","shell.execute_reply.started":"2021-08-18T19:56:07.587696Z","shell.execute_reply":"2021-08-18T19:59:51.031014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words_source_train = []\nfor i in data['text'] :\n  words_source_train.extend(i.split(' '))\n\nprint(\"all the words in the corpus\", len(words_source_train))\nwords_source_train = set(words_source_train)\nprint(\"the unique words in the corpus\", len(words_source_train))\ninter_words = set(embeddings_index.keys()).intersection(words_source_train)\nprint(\"The number of words that are present in both glove vectors and our corpus are {} which \\\nis nearly {}% \".format(len(inter_words), np.round((float(len(inter_words))/len(words_source_train))\n*100)))\n\nwords_corpus_source_train = {}\nwords_glove = set(embeddings_index.keys())\nfor i in words_source_train:\n  if i in words_glove:\n    words_corpus_source_train[i] = embeddings_index[i]\nprint(\"word 2 vec length\", len(words_corpus_source_train))","metadata":{"id":"7JA07ZzL0nhw","outputId":"5535e162-8446-4832-a2e9-82c5eb2dd588","execution":{"iopub.status.busy":"2021-08-18T19:59:51.033289Z","iopub.execute_input":"2021-08-18T19:59:51.03365Z","iopub.status.idle":"2021-08-18T19:59:52.30707Z","shell.execute_reply.started":"2021-08-18T19:59:51.033613Z","shell.execute_reply":"2021-08-18T19:59:52.30623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(list(words_source_train - inter_words)[:20])","metadata":{"execution":{"iopub.status.busy":"2021-08-18T19:59:52.308308Z","iopub.execute_input":"2021-08-18T19:59:52.3087Z","iopub.status.idle":"2021-08-18T19:59:52.319721Z","shell.execute_reply.started":"2021-08-18T19:59:52.308662Z","shell.execute_reply":"2021-08-18T19:59:52.318697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def num(text):\n  words = [w for w in text.split() if not w in inter_words]\n  return len(words)\n\ndata['unique_words'] = data['text'].apply(num)","metadata":{"id":"hT_Ak7qtkv2_","execution":{"iopub.status.busy":"2021-08-18T19:59:52.321247Z","iopub.execute_input":"2021-08-18T19:59:52.321634Z","iopub.status.idle":"2021-08-18T19:59:52.996671Z","shell.execute_reply.started":"2021-08-18T19:59:52.321586Z","shell.execute_reply":"2021-08-18T19:59:52.995832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['unique_words'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-18T19:59:52.998005Z","iopub.execute_input":"2021-08-18T19:59:52.998354Z","iopub.status.idle":"2021-08-18T19:59:53.145008Z","shell.execute_reply.started":"2021-08-18T19:59:52.998315Z","shell.execute_reply":"2021-08-18T19:59:53.144052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data[data['unique_words'] < 4]\ndata.reset_index(inplace=True, drop=True)","metadata":{"id":"N4RZLvQ00zBN","execution":{"iopub.status.busy":"2021-08-18T19:59:53.146673Z","iopub.execute_input":"2021-08-18T19:59:53.14702Z","iopub.status.idle":"2021-08-18T19:59:53.175341Z","shell.execute_reply.started":"2021-08-18T19:59:53.146983Z","shell.execute_reply":"2021-08-18T19:59:53.174533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"id":"uF08PoBm1N78","outputId":"b54f44b1-d68b-428c-d37d-37f691f00573","execution":{"iopub.status.busy":"2021-08-18T19:59:53.176501Z","iopub.execute_input":"2021-08-18T19:59:53.176872Z","iopub.status.idle":"2021-08-18T19:59:53.192331Z","shell.execute_reply.started":"2021-08-18T19:59:53.176834Z","shell.execute_reply":"2021-08-18T19:59:53.191318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(data['text'], data['headlines'], test_size = 0.2, random_state = 20)\nX_test, X_val, y_test, y_val = train_test_split(X_val, y_val, test_size = 0.5, random_state = 20)","metadata":{"id":"5JaGAWYn7kqR","execution":{"iopub.status.busy":"2021-08-18T19:59:53.194129Z","iopub.execute_input":"2021-08-18T19:59:53.194743Z","iopub.status.idle":"2021-08-18T19:59:53.223894Z","shell.execute_reply.started":"2021-08-18T19:59:53.194704Z","shell.execute_reply":"2021-08-18T19:59:53.223112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length_x = max(text_length)\nmax_length_y = max(headlines_length)","metadata":{"id":"zhoRlF5L_qwa","execution":{"iopub.status.busy":"2021-08-18T19:59:53.225088Z","iopub.execute_input":"2021-08-18T19:59:53.22547Z","iopub.status.idle":"2021-08-18T19:59:53.232865Z","shell.execute_reply.started":"2021-08-18T19:59:53.225396Z","shell.execute_reply":"2021-08-18T19:59:53.231819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_t = Tokenizer()\nx_t.fit_on_texts(data['text'] + data['headlines'])\nx_vocab_size = len(x_t.word_index) + 1\n\nencoded_xtrain = x_t.texts_to_sequences(X_train)\nencoded_xval = x_t.texts_to_sequences(X_val)\nencoded_xtest = x_t.texts_to_sequences(X_test)\n\npadded_xtrain = pad_sequences(encoded_xtrain, maxlen=max_length_x, padding='post')\npadded_xval = pad_sequences(encoded_xval, maxlen=max_length_x, padding='post')\npadded_xtest = pad_sequences(encoded_xtest, maxlen=max_length_x, padding='post')","metadata":{"id":"QXQdLrLK0l5B","execution":{"iopub.status.busy":"2021-08-18T19:59:53.234166Z","iopub.execute_input":"2021-08-18T19:59:53.23475Z","iopub.status.idle":"2021-08-18T20:00:02.078691Z","shell.execute_reply.started":"2021-08-18T19:59:53.234714Z","shell.execute_reply":"2021-08-18T20:00:02.0778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_t = Tokenizer()\ny_t.fit_on_texts(data['headlines'])\ny_vocab_size = len(y_t.word_index) + 1\n\nencoded_ytrain = y_t.texts_to_sequences(y_train)\nencoded_yval = y_t.texts_to_sequences(y_val)\nencoded_ytest = y_t.texts_to_sequences(y_test)\n\npadded_ytrain = pad_sequences(encoded_ytrain, maxlen=max_length_y, padding='post')\npadded_yval = pad_sequences(encoded_yval, maxlen=max_length_y, padding='post')\npadded_ytest = pad_sequences(encoded_ytest, maxlen=max_length_y, padding='post')","metadata":{"id":"n7SVsptTNPtP","execution":{"iopub.status.busy":"2021-08-18T20:00:02.080048Z","iopub.execute_input":"2021-08-18T20:00:02.080399Z","iopub.status.idle":"2021-08-18T20:00:05.307048Z","shell.execute_reply.started":"2021-08-18T20:00:02.080365Z","shell.execute_reply":"2021-08-18T20:00:05.306219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Loaded %s word vectors.' % len(embeddings_index))\n\nembedding_matrix = np.zeros((x_vocab_size, glove_size))\nfor word, i in x_t.word_index.items():\n\tembedding_vector = embeddings_index.get(word)\n\tif embedding_vector is not None:\n\t\tembedding_matrix[i] = embedding_vector","metadata":{"id":"rM-974HV0nKo","outputId":"6aa27890-eaf7-4e0f-e594-8057efa18be6","execution":{"iopub.status.busy":"2021-08-18T20:00:05.308231Z","iopub.execute_input":"2021-08-18T20:00:05.30858Z","iopub.status.idle":"2021-08-18T20:00:05.594122Z","shell.execute_reply.started":"2021-08-18T20:00:05.308545Z","shell.execute_reply":"2021-08-18T20:00:05.5933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building Model","metadata":{"id":"99aPNL7dqnfh"}},{"cell_type":"code","source":"class AttentionLayer(Layer):\n\n    def __init__(self, **kwargs):\n        super(AttentionLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n\n        self.W_a = self.add_weight(name='W_a',\n                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n                                   initializer='uniform',\n                                   trainable=True)\n        self.U_a = self.add_weight(name='U_a',\n                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n                                   initializer='uniform',\n                                   trainable=True)\n        self.V_a = self.add_weight(name='V_a',\n                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n                                   initializer='uniform',\n                                   trainable=True)\n\n        super(AttentionLayer, self).build(input_shape)\n\n    def call(self, inputs):\n        encoder_out_seq, decoder_out_seq = inputs\n\n        def energy_step(inputs, states):\n          \n            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n            de_hidden = inputs.shape[-1]\n\n            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  \n            \n            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n            e_i = K.softmax(e_i)\n\n            return e_i, [e_i]\n\n        def context_step(inputs, states):\n            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n            return c_i, [c_i]\n\n        def create_inital_state(inputs, hidden_size):\n            \n            fake_state = K.zeros_like(inputs)  \n            fake_state = K.sum(fake_state, axis=[1, 2])  \n            fake_state = K.expand_dims(fake_state)  \n            fake_state = K.tile(fake_state, [1, hidden_size])  \n            return fake_state\n\n        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  \n\n        last_out, e_outputs, _ = K.rnn(\n            energy_step, decoder_out_seq, [fake_state_e],\n        )\n\n        last_out, c_outputs, _ = K.rnn(\n            context_step, e_outputs, [fake_state_c],\n        )\n        return c_outputs, e_outputs\n\n    def compute_output_shape(self, input_shape):\n        return [\n            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n        ]\n","metadata":{"id":"GWuQ1AG8OdVL","execution":{"iopub.status.busy":"2021-08-18T20:00:05.595424Z","iopub.execute_input":"2021-08-18T20:00:05.59579Z","iopub.status.idle":"2021-08-18T20:00:05.612983Z","shell.execute_reply.started":"2021-08-18T20:00:05.595752Z","shell.execute_reply":"2021-08-18T20:00:05.612087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"latent_dim=500\n\nK.clear_session() \n\nencoder_inputs = Input(shape=(max_length_x,)) \nenc_emb = Embedding(x_vocab_size, glove_size, weights=[embedding_matrix],input_length=max_length_x, trainable=False)(encoder_inputs) \n\n#LSTM \nencoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \nencoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \nencoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \nencoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \nencoder_lstm3 = LSTM(latent_dim, return_state=True, return_sequences=True) \nencoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n\n# Decoder. \ndecoder_inputs = Input(shape=(None,)) \ndec_emb_layer = Embedding(x_vocab_size, glove_size, weights=[embedding_matrix],input_length=max_length_x, trainable=False) \ndec_emb = dec_emb_layer(decoder_inputs) \n\n#LSTM using encoder_states as initial state\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \ndecoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n\n#Attention Layer\nattn_layer = AttentionLayer(name='attention_layer') \nattn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n\ndecoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\ndecoder_dense = TimeDistributed(Dense(y_vocab_size, activation='softmax')) \ndecoder_outputs = decoder_dense(decoder_concat_input) \n\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs) \nprint(model.summary())","metadata":{"id":"wTukjl0hpPgo","outputId":"6035a9eb-baac-43ff-a123-74e1ae1f02b7","execution":{"iopub.status.busy":"2021-08-18T20:00:05.616696Z","iopub.execute_input":"2021-08-18T20:00:05.617121Z","iopub.status.idle":"2021-08-18T20:00:10.754003Z","shell.execute_reply.started":"2021-08-18T20:00:05.617058Z","shell.execute_reply":"2021-08-18T20:00:10.753148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\ncheckpoint_filepath = './model.{epoch:02d}-{val_loss:.2f}.h5'\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True, save_freq = \"epoch\")\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=1)\nhistory=model.fit([padded_xtrain,padded_ytrain[:,:-1]], padded_ytrain.reshape(padded_ytrain.shape[0],padded_ytrain.shape[1], 1)[:,1:] ,epochs=10,batch_size=512, validation_data=([padded_xval,padded_yval[:,:-1]], padded_yval.reshape(padded_yval.shape[0],padded_yval.shape[1], 1)[:,1:]), callbacks=[es, model_checkpoint_callback])","metadata":{"id":"4fUJoaFAiwUb","outputId":"4bc22143-d3ed-4b87-e2e6-c44f3034a816","execution":{"iopub.status.busy":"2021-08-18T20:00:10.755591Z","iopub.execute_input":"2021-08-18T20:00:10.755925Z","iopub.status.idle":"2021-08-18T20:19:02.357241Z","shell.execute_reply.started":"2021-08-18T20:00:10.75589Z","shell.execute_reply":"2021-08-18T20:19:02.356023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\nmodel.load_weights(\"./model.27-3.27.h5\")\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy')","metadata":{"execution":{"iopub.status.busy":"2021-08-18T17:52:15.168176Z","iopub.execute_input":"2021-08-18T17:52:15.168513Z","iopub.status.idle":"2021-08-18T17:52:15.648228Z","shell.execute_reply.started":"2021-08-18T17:52:15.168479Z","shell.execute_reply":"2021-08-18T17:52:15.647054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"0CULXhQiGpvO"}},{"cell_type":"code","source":"from matplotlib import pyplot \npyplot.plot(history.history['loss'], label='train') \npyplot.plot(history.history['val_loss'], label='test') \npyplot.legend() \npyplot.show()","metadata":{"id":"JQf1v5WhqLLg","outputId":"f5bfa510-79c7-465e-e371-ea5b36198da9","execution":{"iopub.status.busy":"2021-08-18T20:19:17.419931Z","iopub.execute_input":"2021-08-18T20:19:17.42026Z","iopub.status.idle":"2021-08-18T20:19:17.554756Z","shell.execute_reply.started":"2021-08-18T20:19:17.420227Z","shell.execute_reply":"2021-08-18T20:19:17.553986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inference","metadata":{"id":"PZ0W3VZorHVK"}},{"cell_type":"code","source":"reverse_target_word_index = y_t.index_word \nreverse_source_word_index = x_t.index_word \ntarget_word_index = y_t.word_index","metadata":{"id":"UlSTzEbnskcd","execution":{"iopub.status.busy":"2021-08-18T20:19:28.693573Z","iopub.execute_input":"2021-08-18T20:19:28.693891Z","iopub.status.idle":"2021-08-18T20:19:28.698122Z","shell.execute_reply.started":"2021-08-18T20:19:28.693861Z","shell.execute_reply":"2021-08-18T20:19:28.697161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_hidden_state_input = Input(shape=(max_length_x,latent_dim))\n\ndec_emb2= dec_emb_layer(decoder_inputs)\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n\nattn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\ndecoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n\ndecoder_outputs2 = decoder_dense(decoder_inf_concat)\n\ndecoder_model = Model(\n[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n[decoder_outputs2] + [state_h2, state_c2])","metadata":{"id":"thX0Ep0Ssnd1","execution":{"iopub.status.busy":"2021-08-18T20:19:30.268172Z","iopub.execute_input":"2021-08-18T20:19:30.2685Z","iopub.status.idle":"2021-08-18T20:19:30.559818Z","shell.execute_reply.started":"2021-08-18T20:19:30.26847Z","shell.execute_reply":"2021-08-18T20:19:30.559003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_sequence(input_seq):\n    input_seq= input_seq.reshape(1,max_length_x)\n    e_out, e_h, e_c = encoder_model.predict(input_seq)\n    target_seq = np.zeros((1,1))\n    target_seq[0, 0] = target_word_index['start']\n\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_token = reverse_target_word_index[sampled_token_index]\n  \n        if(sampled_token!='end'):\n            decoded_sentence += ' '+sampled_token\n \n        if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_length_y-1)):\n                stop_condition = True\n\n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n        e_h, e_c = h, c\n\n    return decoded_sentence","metadata":{"id":"wtU0wU8gsuz1","execution":{"iopub.status.busy":"2021-08-18T20:19:30.658155Z","iopub.execute_input":"2021-08-18T20:19:30.658452Z","iopub.status.idle":"2021-08-18T20:19:30.665195Z","shell.execute_reply.started":"2021-08-18T20:19:30.658418Z","shell.execute_reply":"2021-08-18T20:19:30.664427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seq2summary(input_seq):\n    newString=''\n    for i in input_seq:\n      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n        newString=newString+reverse_target_word_index[i]+' '\n    return newString\n\ndef seq2text(input_seq):\n    newString=''\n    for i in input_seq:\n      if(i!=0):\n        newString=newString+reverse_source_word_index[i]+' '\n    return newString","metadata":{"id":"cLyRVENRs2Ay","execution":{"iopub.status.busy":"2021-08-18T20:19:31.66896Z","iopub.execute_input":"2021-08-18T20:19:31.669275Z","iopub.status.idle":"2021-08-18T20:19:31.674601Z","shell.execute_reply.started":"2021-08-18T20:19:31.669245Z","shell.execute_reply":"2021-08-18T20:19:31.673603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n  print(\"Review:\",seq2text(padded_xtest[i]))\n  print(\"Original summary:\",seq2summary(padded_ytest[i]))\n  print(\"Predicted summary:\",decode_sequence(padded_xtest[i]))\n  print(\"\\n\")","metadata":{"id":"bXrWSc9Es5Qr","outputId":"08e094bf-5b7a-4d2d-9042-f01c9390c8df","execution":{"iopub.status.busy":"2021-08-18T20:29:52.311192Z","iopub.execute_input":"2021-08-18T20:29:52.311568Z","iopub.status.idle":"2021-08-18T20:29:56.133385Z","shell.execute_reply.started":"2021-08-18T20:29:52.31153Z","shell.execute_reply":"2021-08-18T20:29:56.132541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation","metadata":{"id":"v3Sfc9a422Rg"}},{"cell_type":"markdown","source":"","metadata":{"id":"km13viOn2P4t"}},{"cell_type":"code","source":"def BLEU_Score(y_test, y_pred):\n    references = [[seq2summary(y_test).split(\" \")]]\n    candidates = [decode_sequence(y_pred.reshape(1,max_length_x)).split(\" \")]\n    return corpus_bleu(references, candidates)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-18T20:20:58.514456Z","iopub.execute_input":"2021-08-18T20:20:58.514889Z","iopub.status.idle":"2021-08-18T20:20:58.519962Z","shell.execute_reply.started":"2021-08-18T20:20:58.514845Z","shell.execute_reply":"2021-08-18T20:20:58.51883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.translate.bleu_score import corpus_bleu\nscores=[]\nfor i in range(0,500):\n    scores.append(BLEU_Score(padded_ytest[i],padded_xtest[i]))\n    \nprint(np.mean(scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-18T20:33:00.986297Z","iopub.execute_input":"2021-08-18T20:33:00.986651Z","iopub.status.idle":"2021-08-18T20:33:05.297008Z","shell.execute_reply.started":"2021-08-18T20:33:00.986619Z","shell.execute_reply":"2021-08-18T20:33:05.296122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_hub as hub\nfrom scipy import spatial\nmodule_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" \nsentence_encoder = hub.load(module_url)\nprint (\"module %s loaded\" % module_url)","metadata":{"id":"Z516n1wQSgn1","outputId":"83eac699-47fc-4854-a02e-b39ed8af9f50","execution":{"iopub.status.busy":"2021-08-18T20:30:34.790487Z","iopub.execute_input":"2021-08-18T20:30:34.79086Z","iopub.status.idle":"2021-08-18T20:30:58.270279Z","shell.execute_reply.started":"2021-08-18T20:30:34.79083Z","shell.execute_reply":"2021-08-18T20:30:58.269454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cosine_similarity(padded_xval, padded_yval):\n  scores = []\n  for i in range(len(padded_xval)):\n    \n    str1 = seq2summary(padded_yval[i])\n    str2 = decode_sequence(padded_xval[i])\n    embeddings = sentence_encoder([str1, str2]).numpy()\n    result = 1 - spatial.distance.cosine(embeddings[0], embeddings[1])\n    scores.append(result)\n  return scores","metadata":{"id":"phm5tVv6yCZ9","execution":{"iopub.status.busy":"2021-08-18T20:30:58.273625Z","iopub.execute_input":"2021-08-18T20:30:58.27389Z","iopub.status.idle":"2021-08-18T20:30:58.282078Z","shell.execute_reply.started":"2021-08-18T20:30:58.273864Z","shell.execute_reply":"2021-08-18T20:30:58.281245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = cosine_similarity(padded_xtest[:500],padded_ytest[:500] )\nnp.mean(scores)","metadata":{"id":"SoB-bWnvcNC9","outputId":"a83b5641-48b0-4ac3-916c-7a0b6d62f644","execution":{"iopub.status.busy":"2021-08-18T20:34:02.172554Z","iopub.execute_input":"2021-08-18T20:34:02.172881Z","iopub.status.idle":"2021-08-18T20:34:06.793937Z","shell.execute_reply.started":"2021-08-18T20:34:02.172851Z","shell.execute_reply":"2021-08-18T20:34:06.793153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}