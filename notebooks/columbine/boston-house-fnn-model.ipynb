{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## some utils for our recording & deal with the original data.\n\n1. _normaile(feature, train_size) :\n\n    - used to normalize the original dataset with the mean & std of the train dataset.****"},{"metadata":{"trusted":true},"cell_type":"code","source":"def _normalize(feature, train_size):\n    #\n    feature_t = feature[:train_size]\n    mean = feature_t.mean(axis=0)\n    std = feature_t.std(axis=0)\n    feature_n = (feature - mean) / std\n    return feature_n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Average Class aims to record the error between the ground_truth & the prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. deal with the .csv dataset\n\nInstead of using pd.load_csv, we use our own function to load the datasets. And create the iterator as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_csv(file_path=\"/kaggle/input/boston-house-prices\", file_name='housing.csv'):\n    input = []\n    target = []\n    with open(os.path.join(file_path, file_name)) as f:\n        for line in f.readlines():\n            data_list = line.strip().split()\n            input.append(data_list[:-1])\n            target.append(data_list[-1])\n    input = np.array(input).astype(float)\n    target = np.array(target).astype(float)\n    print(input.shape, target.shape)\n    return input, target\n\ndef construct_data_iter(input, target):\n    input = torch.from_numpy(input).float()\n    target = torch.from_numpy(target).float()\n    print(\"constructing data iterator\", input.shape, target.shape)\n    deal_dataset = TensorDataset(input, target)\n    data_loader = DataLoader(dataset=deal_dataset, batch_size=32, shuffle=True, num_workers=2)\n    return data_loader","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model \n\n- our model was using the linear layer with Relu as activate function, with dropout layer as well.\n\nWe show an example of our model with input_size=13, layers=[100, 50, 20], the framework of our model are as follows:"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class RegressionModel(nn.Module):\n    def __init__(self, input_size: int, dims: list, dropout: float = 0.5):\n        super(RegressionModel, self).__init__()\n        layers = []\n        layers.append(nn.Linear(input_size, dims[0]))\n        layers.append(nn.ReLU())\n        for i in range(len(dims)-2):\n            layers.append(nn.Linear(dims[i], dims[i+1]))\n            layers.append(nn.ReLU())\n        layers.append(nn.Linear(dims[-2], dims[-1]))\n        layers.append(nn.Dropout(dropout))\n        layers.append(nn.ReLU())\n        layers.append(nn.Linear(dims[-1], 1))\n\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        # x = torch.tensor(x, dtype=torch.float32)\n        return self.model(x)\nModel = RegressionModel(13, [100, 50, 20])\nprint(Model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now Train our model !\n\nWe try different criterions as our loss functions. We find that SmoothL1Loss() get better results. "},{"metadata":{},"cell_type":"markdown","source":"We also try on different optimizer as well.\n\nWe find that by using Adam as our optimizer it can get to better model in only a few epoches\n\nAnd Using SGD with momentum=0.9 we can get better model than Adam above."},{"metadata":{"trusted":true},"cell_type":"code","source":"# choose SmoothL1Loss() as our loss function/ criterion.\ncriterion = torch.nn.SmoothL1Loss()\n# show our dataset size.\ntrain_size, valid_size, test_size = 400, 56, 50\ndef main():\n    x, y = load_csv()\n    x = _normalize(x, train_size)\n    train_data_iter = construct_data_iter(x[:train_size], y[:train_size])\n    valid_data_iter = construct_data_iter(x[train_size:train_size+valid_size], y[train_size:train_size+valid_size])\n    Model = RegressionModel(13, [256, 256, 128, 128, 128])\n    ADAM_optimizer = optim.Adam(Model.parameters(), lr=0.0001)\n    SGD_optimizer = optim.SGD(Model.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.001)\n\n    def forward(data, optimizer=None, Training=True):\n        perplexity = AverageMeter()\n        if Training:\n            Model.train()\n        else:\n            Model.eval()\n        for i, (Input, Target) in enumerate(data):\n            pred = Model(Input)\n            err = criterion(pred.squeeze(), Target)\n            perplexity.update(float(err.item()))\n            if Training:\n                optimizer.zero_grad()\n                err.backward()\n                optimizer.step()\n            if i % 15 == 14:\n                print('{phase} - Epoch: [{0}][{1}/{2}]\\t' 'Perplexity {perp.val:.4f} ({perp.avg:.4f})'.format(\n                    epoch, i, len(data),\n                    phase='TRAINING' if Training else 'EVALUATING',\n                    perp=perplexity))\n        return perplexity.avg\n\n    for epoch in range(500):\n        train_prep = forward(train_data_iter, SGD_optimizer, Training=True)\n        # evaluate\n        val_prep = forward(valid_data_iter, Training=False)\n        if epoch % 25 == 0:\n            print('Epoch: {0}\\tTraining Perplexity {1} \\tValidation Perplexity {val_perp:.4f} \\n'.format(epoch + 1, train_prep, val_perp=val_prep))\n\n    print(\"testing our model ...\")\n\n    for i in range(506-test_size, 506):\n        Model.eval()\n        pred = Model.forward(torch.from_numpy(x[i]).float()).squeeze()\n        ground_true = y[i]\n        print(\"test result : \", i, pred.item(), ground_true)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Final Results\n\ntesting our model ... \n\ntest result :  496 17.27041244506836 19.7\n\ntest result :  497 17.986053466796875 18.3\n\ntest result :  498 19.822839736938477 21.2\n\ntest result :  499 18.83315086364746 17.5\n\ntest result :  500 18.011035919189453 16.8\n\ntest result :  501 22.409204483032227 22.4\n\ntest result :  502 20.470056533813477 20.6\n\ntest result :  503 25.977445602416992 23.9\n\ntest result :  504 24.06263542175293 22.0\n\ntest result :  505 19.834854125976562 11.9"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}