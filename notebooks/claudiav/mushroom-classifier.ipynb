{"cells":[{"metadata":{},"cell_type":"markdown","source":"This data set includes descriptions of samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family. The data files were downloaded from the UCI ML data repository. The data set goes back to 1987.\n\nEach mushroom species is identified as definitely edible, definitely poisonous, or of unknown edibility. The class of mushrooms with unknown edibility are combined with the poisonous class in the data set. There is no simple rule for determining the edibility of a mushroom.\n\nThe data is in a comma-separated format. There are 8124 observations, with 23 columns. The first column value is 'p' or 'e' (p: poisonous, e: edible), this is the target value. Missing values are flagged with '?'.\n\nThe objective of this analysis is to create a classifier which predicts whether a given sample represents an edible or a poisonous mushroom. We will use this data set to illustrate how to set up the data and build a Neural Network Classifier.\n\nThe 22 attributes are described below.\nAttribute information: (22 attributes)\n1. cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\n1. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n1. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y\n1. bruises?: bruises=t,no=f\n1. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\n1. gill-attachment: attached=a,descending=d,free=f,notched=n\n1. gill-spacing: close=c,crowded=w,distant=d\n1. gill-size: broad=b,narrow=n\n1. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y\n1. stalk-shape: enlarging=e,tapering=t\n1. stalk-root: bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=?\n1. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n1. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n1. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n1. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n1. veil-type: partial=p,universal=u\n1. veil-color: brown=n,orange=o,white=w,yellow=y\n1. ring-number: none=n,one=o,two=t\n1. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z\n1. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y\n1. population: abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y\n1. habitat: grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We will approach the problem as follows:\n1. Examine the data. Locate any missing information. Decide how to handle the missing information.\n1. Prepare the data. Apply one-hot encoding to the categorical variables.\n1. Build a neural network classifier.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"mushroom_data = pd.read_csv('/kaggle/input/mushroom-classification/mushrooms.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mushroom_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Locate all missing values.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"null_sum = mushroom_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"null_sum","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no remaining null values in the cells. Look for the '?' marker.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for name in mushroom_data.columns:\n    print(name, mushroom_data[mushroom_data[name] == '?'].shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We find that the 'stalk-root' column has 2480 rows with cells flagged with '?' marker for missing values. We will drop this column from the analysis. The assumption is that we will not lose much information from dropping 1 column out of 22 attributes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mushroom_data.drop(['stalk-root'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mushroom_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = mushroom_data['class']\nX = mushroom_data.drop(['class'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apply one-hot encoding to the categorical variables. This is done by creating one binary attribute per category. It is called one-hot encoding because only 1 attribute will be equal to 1 (hot), while the others will be 0 (cold). The new attributes are sometimes called dummy attributes.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_encoder = OneHotEncoder(sparse=False)\nX_1hot = cat_encoder.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_1hot[1:5,]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The target class (p, e) has to be binary encoded.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlbl_encoder = LabelEncoder()\ny_1hot = lbl_encoder.fit_transform(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_1hot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will build the neural network using the keras implementation of tensorflow.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will split the data into a training set, a validation set, and a test set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_full, X_test, y_train_full, y_test = train_test_split(X_1hot, y_1hot, test_size=0.33, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.33, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.models.Sequential()\nmodel.add(Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]))\nmodel.add(Dense(1, activation=\"sigmoid\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs=20, batch_size=25, validation_data=(X_valid, y_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We built a classifier with 100% accuracy!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}