{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re\nimport warnings\npd.options.mode.chained_assignment = None\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-19T21:10:46.016432Z","iopub.execute_input":"2021-08-19T21:10:46.017204Z","iopub.status.idle":"2021-08-19T21:10:47.089913Z","shell.execute_reply.started":"2021-08-19T21:10:46.017147Z","shell.execute_reply":"2021-08-19T21:10:47.088615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/reddit-vaccine-myths/reddit_vm.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:10:47.091458Z","iopub.execute_input":"2021-08-19T21:10:47.091828Z","iopub.status.idle":"2021-08-19T21:10:47.145809Z","shell.execute_reply.started":"2021-08-19T21:10:47.091797Z","shell.execute_reply":"2021-08-19T21:10:47.144695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Pre-processing","metadata":{}},{"cell_type":"markdown","source":"In order to get gain a better understanding of the content, the title and the body columns are combined into a single value","metadata":{}},{"cell_type":"code","source":"df['gp_sent'] = ''\nfor i, row in df.iterrows():\n    if row['title'] == 'Comment':\n        df['gp_sent'][i] =(row['body'])\n    elif row['body']!='':\n        df['gp_sent'][i] =(str(row['title']) + ' ' + str(row['body']))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:10:47.149038Z","iopub.execute_input":"2021-08-19T21:10:47.149409Z","iopub.status.idle":"2021-08-19T21:10:48.079102Z","shell.execute_reply.started":"2021-08-19T21:10:47.149374Z","shell.execute_reply":"2021-08-19T21:10:48.078125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#removing 'nan' values and rows which are empty\nindex = []\nfor i, row in df.iterrows():\n    sent = re.sub('nan', '', row['gp_sent'])\n    if not sent:\n        index.append(i)     ","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:10:48.080792Z","iopub.execute_input":"2021-08-19T21:10:48.081102Z","iopub.status.idle":"2021-08-19T21:10:48.226095Z","shell.execute_reply.started":"2021-08-19T21:10:48.081073Z","shell.execute_reply":"2021-08-19T21:10:48.225229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:10:48.227232Z","iopub.execute_input":"2021-08-19T21:10:48.227655Z","iopub.status.idle":"2021-08-19T21:10:48.235503Z","shell.execute_reply.started":"2021-08-19T21:10:48.227625Z","shell.execute_reply":"2021-08-19T21:10:48.234373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are no empty rows in the dataset","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import words\nfrom nltk.corpus import stopwords\nfrom nltk import WordNetLemmatizer\nfrom spellchecker import SpellChecker\nfrom datetime import datetime\n\nlemmatizer = WordNetLemmatizer()","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:10:48.2369Z","iopub.execute_input":"2021-08-19T21:10:48.237215Z","iopub.status.idle":"2021-08-19T21:10:49.335082Z","shell.execute_reply.started":"2021-08-19T21:10:48.237186Z","shell.execute_reply":"2021-08-19T21:10:49.334039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing websites \n\ndf['processed'] ='' \nwebsite_pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\nfor i, row in df.iterrows():\n    df['processed'][i] = ' '.join([re.sub(website_pattern,'',sent) for sent in re.split(\"[\\(\\[\\)\\]\\\\\\n]\", row['gp_sent'])])\n","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:10:49.336396Z","iopub.execute_input":"2021-08-19T21:10:49.336782Z","iopub.status.idle":"2021-08-19T21:10:50.280041Z","shell.execute_reply.started":"2021-08-19T21:10:49.336749Z","shell.execute_reply":"2021-08-19T21:10:50.27895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since reddit is an informal platform, usage of colloquial spelling/abbreviation is normal. Hence, it is important to rectify such words","metadata":{}},{"cell_type":"code","source":"#identify unique words\n\ndf['cleansed']=''\nstop_words=stopwords.words('english')\n\nunique_words = []\n\nfor i, row in df.iterrows():\n    #check punctuations\n    sent  = re.sub(r'[.]*|[,]*|:|[\\n]*|nan|\\?|\"|[\\*]*|[\\t]*|[\\r]*|&|#|!|<|>|%|[\\^]*|', '', row['processed'])\n    sent = sent.replace('-',' ')\n    # remove numbers\n    sent  = re.sub(r'\\d', '', sent)\n    for word in sent.lower().split(' '):\n        if lemmatizer.lemmatize(word) not in unique_words and len(word)>2 and word not in stop_words:\n            unique_words.append(word)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:10:50.281333Z","iopub.execute_input":"2021-08-19T21:10:50.281639Z","iopub.status.idle":"2021-08-19T21:10:57.849706Z","shell.execute_reply.started":"2021-08-19T21:10:50.281611Z","shell.execute_reply":"2021-08-19T21:10:57.84861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(unique_words)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:10:57.85267Z","iopub.execute_input":"2021-08-19T21:10:57.852984Z","iopub.status.idle":"2021-08-19T21:10:57.859919Z","shell.execute_reply.started":"2021-08-19T21:10:57.852955Z","shell.execute_reply":"2021-08-19T21:10:57.858857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using spell checker to map mis-spelled words to a similar word of highest weightage\n\nmisspelled_map ={}\nspell_checker = SpellChecker()\n\n#adding frequently used new words that didn't exist previously\n#with more research other new terms can also be added \nspell_checker.word_frequency.load_words(['covid', 'coronavirus', 'corona', 'astrazeneca','pfizer'])\nmisspelled_words = spell_checker.unknown(unique_words)\nlen(misspelled_words)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:10:57.862108Z","iopub.execute_input":"2021-08-19T21:10:57.862538Z","iopub.status.idle":"2021-08-19T21:10:58.160977Z","shell.execute_reply.started":"2021-08-19T21:10:57.862491Z","shell.execute_reply":"2021-08-19T21:10:58.159686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Of *7672* unique words, *1264* words are misspelled","metadata":{}},{"cell_type":"code","source":"#correct misspelled words\n# takes a long time to match and identify correct word. So to log progress we have a counter\n\ncount =1\nfor word in misspelled_words:\n    misspelled_map[word] = spell_checker.correction(word)\n    count = count+1\n    if count%100==0:\n        print(count)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:10:58.162664Z","iopub.execute_input":"2021-08-19T21:10:58.163216Z","iopub.status.idle":"2021-08-19T21:16:43.978833Z","shell.execute_reply.started":"2021-08-19T21:10:58.163177Z","shell.execute_reply":"2021-08-19T21:16:43.977744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#replace misspelled words\n\nfor i, row in df.iterrows():\n    df['cleansed'][i] = ' '.join([' '.join([misspelled_map[word] if word in misspelled_words else word for word in sent.split('-')]) for sent in row['processed'].lower().split(' ')])","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:16:43.980498Z","iopub.execute_input":"2021-08-19T21:16:43.980825Z","iopub.status.idle":"2021-08-19T21:16:44.968126Z","shell.execute_reply.started":"2021-08-19T21:16:43.980793Z","shell.execute_reply":"2021-08-19T21:16:44.966988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#converting timestamp into date-time format\ndf['timestamp'] = df['timestamp'].apply(lambda x: datetime.strptime(x[0:10], '%Y-%m-%d'))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:16:44.969623Z","iopub.execute_input":"2021-08-19T21:16:44.969941Z","iopub.status.idle":"2021-08-19T21:16:45.002595Z","shell.execute_reply.started":"2021-08-19T21:16:44.969911Z","shell.execute_reply":"2021-08-19T21:16:45.001229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sentiment Analysis","metadata":{}},{"cell_type":"code","source":"import nltk\nnltk.download('vader_lexicon')\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nsid = SentimentIntensityAnalyzer()","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:16:45.004763Z","iopub.execute_input":"2021-08-19T21:16:45.005214Z","iopub.status.idle":"2021-08-19T21:16:45.320699Z","shell.execute_reply.started":"2021-08-19T21:16:45.005168Z","shell.execute_reply":"2021-08-19T21:16:45.319463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['polarity_scores'] = df['cleansed'].map(lambda x: sid.polarity_scores(x))\ndf['comp_score'] = df['polarity_scores'].map(lambda x: x['compound'])\ndf['polarity'] = df['comp_score'].map(lambda x: 'pos' if x>0 else ('neu' if x==0 else 'neg'))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:16:45.322045Z","iopub.execute_input":"2021-08-19T21:16:45.32235Z","iopub.status.idle":"2021-08-19T21:16:46.474555Z","shell.execute_reply.started":"2021-08-19T21:16:45.322322Z","shell.execute_reply":"2021-08-19T21:16:46.473247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = df.drop(['title','id','url', 'body', 'gp_sent','processed'], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:16:46.475761Z","iopub.execute_input":"2021-08-19T21:16:46.476094Z","iopub.status.idle":"2021-08-19T21:16:46.487283Z","shell.execute_reply.started":"2021-08-19T21:16:46.476058Z","shell.execute_reply":"2021-08-19T21:16:46.485774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets visualize how the polarity has changed with score and comments and overtime","metadata":{}},{"cell_type":"code","source":"colors = [ \"#007000\", \"#D20005\", \"#FFBF00\"]\ncustomPalette = sns.set_palette(sns.color_palette(colors))\nfig, ax = plt.subplots(1, 2, figsize=(15,7))\nsns.histplot(x='comms_num', hue='polarity', data=data[data['comms_num']>0],palette=customPalette, ax=ax[0])\nax[0].set_xlim(1,50)\n\ncolors = [ \"#007000\", \"#FFBF00\",\"#D20005\"]\ncustomPalette = sns.set_palette(sns.color_palette(colors))\n#Change of score wrt polarity\nsns.histplot(x='score', hue='polarity', data=data,palette=customPalette, ax=ax[1])\nax[1].set_xlim(-5,30)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:16:46.488775Z","iopub.execute_input":"2021-08-19T21:16:46.48915Z","iopub.status.idle":"2021-08-19T21:17:17.21203Z","shell.execute_reply.started":"2021-08-19T21:16:46.489117Z","shell.execute_reply":"2021-08-19T21:17:17.210792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clearly, neg polarity is quite prominent garnering more comments and score.","metadata":{}},{"cell_type":"code","source":"# quanitfying the change in score and comments with polarity \n\nnew = data[['score','comms_num','polarity']].groupby('polarity')\nnew.mean()","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:17:17.213724Z","iopub.execute_input":"2021-08-19T21:17:17.214148Z","iopub.status.idle":"2021-08-19T21:17:17.236289Z","shell.execute_reply.started":"2021-08-19T21:17:17.214101Z","shell.execute_reply":"2021-08-19T21:17:17.235095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see than more than tweets with positive and neutral polarity, those with *negative polarity has been more active* and based on its score, *producing a higher impact.*","metadata":{}},{"cell_type":"code","source":"#fig, ax = plt.subplots(figsize=(10,10))\n#sns.lineplot(x=\"timestamp\",hue=\"polarity\",data=data)\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:17:17.238223Z","iopub.execute_input":"2021-08-19T21:17:17.238826Z","iopub.status.idle":"2021-08-19T21:17:17.243406Z","shell.execute_reply.started":"2021-08-19T21:17:17.238775Z","shell.execute_reply":"2021-08-19T21:17:17.242326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NMF Topic Model - Negative Tweets","metadata":{}},{"cell_type":"markdown","source":"Starting with processing negative tweets, to understand better the reason for the apprehensions towards vaccines","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import WordPunctTokenizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import NMF;\n \n#Using WordPunctTokenizer since it accomodates separating punctuations from words\ntokenizer = WordPunctTokenizer()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:17:17.244691Z","iopub.execute_input":"2021-08-19T21:17:17.244981Z","iopub.status.idle":"2021-08-19T21:17:17.286394Z","shell.execute_reply.started":"2021-08-19T21:17:17.244952Z","shell.execute_reply":"2021-08-19T21:17:17.285571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_tweets(df):\n    processed =[]\n    for i, row in df.iterrows():\n        #remove numbers\n        tweet  = re.sub(r'\\d', '', row['cleansed'])\n        #tokenize the text\n        tweet = tokenizer.tokenize(tweet)\n        #remove punctuations and empty string\n        tweet = [word for word in tweet if len(word)>2 and ' ' not in word and 'nan' not in word]\n        #remove stop words\n        tweet = [word for word in tweet if word not in stop_words]\n        # Lemmatize words\n        processed.append([lemmatizer.lemmatize(word) for word in tweet])\n    return processed","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:17:17.287755Z","iopub.execute_input":"2021-08-19T21:17:17.288416Z","iopub.status.idle":"2021-08-19T21:17:17.296964Z","shell.execute_reply.started":"2021-08-19T21:17:17.288368Z","shell.execute_reply":"2021-08-19T21:17:17.295962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vectorize(tweet_list):\n    tfidf_vectorizer = TfidfVectorizer(min_df=3, max_df=0.85, max_features=5000,ngram_range=(1, 2), preprocessor=' '.join)\n    tfidf = tfidf_vectorizer.fit_transform(tweet_list)\n    return tfidf, tfidf_vectorizer","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:17:17.298221Z","iopub.execute_input":"2021-08-19T21:17:17.29858Z","iopub.status.idle":"2021-08-19T21:17:17.309859Z","shell.execute_reply.started":"2021-08-19T21:17:17.298549Z","shell.execute_reply":"2021-08-19T21:17:17.309074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_nmf_topics(model, n_top_words, tfidf_vectorizer):\n    \n    feat_names = tfidf_vectorizer.get_feature_names()\n    \n    word_dict = {};\n    for i in range(n_top_words):\n        words_ids = model.components_[i].argsort()[:-15 - 1:-1]\n        words = [feat_names[key] for key in words_ids]\n        word_dict['Topic # ' + '{:02d}'.format(i+1)] = words;\n    \n    return pd.DataFrame(word_dict);","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:17:17.311102Z","iopub.execute_input":"2021-08-19T21:17:17.31167Z","iopub.status.idle":"2021-08-19T21:17:17.324073Z","shell.execute_reply.started":"2021-08-19T21:17:17.311634Z","shell.execute_reply":"2021-08-19T21:17:17.322927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Modeling with fixed k=5","metadata":{}},{"cell_type":"code","source":"#processing negative tweets\nneg_tweets_df = data[data[\"polarity\"] == \"neg\"]\nneg_list = process_tweets(neg_tweets_df)\nprint(neg_list[0:2])","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:17:17.325593Z","iopub.execute_input":"2021-08-19T21:17:17.326028Z","iopub.status.idle":"2021-08-19T21:17:17.669093Z","shell.execute_reply.started":"2021-08-19T21:17:17.325995Z","shell.execute_reply":"2021-08-19T21:17:17.668005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Running a sample model wit k as 5, before choosing the optimal components\nmodel_neg = NMF(n_components=5, init='nndsvd');\ntfidf_neg, tfidf_vectorizer_neg = vectorize(neg_list)\nmodel_neg.fit_transform(tfidf_neg)\nnmf_df_neg = get_nmf_topics(model_neg, 5,tfidf_vectorizer_neg )\nnmf_df_neg[0:10]","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:17:17.670419Z","iopub.execute_input":"2021-08-19T21:17:17.67078Z","iopub.status.idle":"2021-08-19T21:17:17.978651Z","shell.execute_reply.started":"2021-08-19T21:17:17.670737Z","shell.execute_reply":"2021-08-19T21:17:17.977458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Use Coherence score to identify the optimal number of components","metadata":{}},{"cell_type":"code","source":"from gensim.models.coherencemodel import CoherenceModel\nfrom gensim.corpora.dictionary import Dictionary\nfrom gensim.models.nmf import Nmf\nfrom operator import itemgetter","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:17:17.980578Z","iopub.execute_input":"2021-08-19T21:17:17.981714Z","iopub.status.idle":"2021-08-19T21:17:18.338484Z","shell.execute_reply.started":"2021-08-19T21:17:17.98165Z","shell.execute_reply":"2021-08-19T21:17:18.337661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def coherence_model(tweets):\n    topic_nums = list(np.arange(3,63,3))\n    coherence_scores =[]\n    \n    #get corpus\n    dictionary = Dictionary(tweets)\n    dictionary.filter_extremes(no_below=3,no_above=0.85,keep_n=5000)\n    corpus = [dictionary.doc2bow(word) for word in tweets]\n    \n    #compute coherence model\n    for num in topic_nums:\n        nmf = Nmf(corpus=corpus,num_topics=num,id2word=dictionary,chunksize=2000,passes=5,kappa=.1,\n                  minimum_probability=0.01,w_max_iter=300,w_stop_condition=0.0001,h_max_iter=100,\n                  h_stop_condition=0.001,eval_every=10,normalize=True,random_state=42)\n        cm = CoherenceModel(model=nmf, texts=tweets, dictionary=dictionary, coherence='c_v')\n        coherence_scores.append(round(cm.get_coherence(), 5))\n        if(num%9==0):\n            print(num)\n    return list(zip(topic_nums, coherence_scores))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:17:18.341799Z","iopub.execute_input":"2021-08-19T21:17:18.342414Z","iopub.status.idle":"2021-08-19T21:17:18.352053Z","shell.execute_reply.started":"2021-08-19T21:17:18.342374Z","shell.execute_reply":"2021-08-19T21:17:18.350916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neg_scores = coherence_model(neg_list)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:17:18.353823Z","iopub.execute_input":"2021-08-19T21:17:18.354959Z","iopub.status.idle":"2021-08-19T21:18:52.096009Z","shell.execute_reply.started":"2021-08-19T21:17:18.354913Z","shell.execute_reply":"2021-08-19T21:18:52.094884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neg_df  = pd.DataFrame(neg_scores)\nidmax = neg_df.iloc[:,1].idxmax(axis=1)\nbest_cv_neg, cv_neg = int(neg_df.loc[idmax][0]), neg_df.loc[idmax][1]","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:18:52.099892Z","iopub.execute_input":"2021-08-19T21:18:52.100262Z","iopub.status.idle":"2021-08-19T21:18:52.108456Z","shell.execute_reply.started":"2021-08-19T21:18:52.100232Z","shell.execute_reply":"2021-08-19T21:18:52.107623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Best k:{} and cv_score:{}'.format(best_cv_neg, cv_neg))\n\nfig, ax = plt.subplots(figsize=(8,7))\nsns.lineplot(data=neg_df, x=0, y=1)\nplt.xlabel('Num of components')\nplt.ylabel('CV score')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:18:52.109722Z","iopub.execute_input":"2021-08-19T21:18:52.110213Z","iopub.status.idle":"2021-08-19T21:18:52.298753Z","shell.execute_reply.started":"2021-08-19T21:18:52.110164Z","shell.execute_reply":"2021-08-19T21:18:52.297623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_opt_neg = NMF(n_components=best_cv_neg, init='nndsvd');\ntfidf_opt_neg, tfidf_vectorizer_opt_neg = vectorize(neg_list)\nmodel_opt_neg.fit_transform(tfidf_opt_neg)\nnmf_df_opt_neg = get_nmf_topics(model_opt_neg, best_cv_neg,tfidf_vectorizer_opt_neg )\nnmf_df_opt_neg","metadata":{"execution":{"iopub.status.busy":"2021-08-19T21:18:52.300273Z","iopub.execute_input":"2021-08-19T21:18:52.300647Z","iopub.status.idle":"2021-08-19T21:18:53.001925Z","shell.execute_reply.started":"2021-08-19T21:18:52.300614Z","shell.execute_reply":"2021-08-19T21:18:53.000856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\nEach topic gives an understanding of the reasons behind the negativeness towards vaccines.\n\nFor example,\nTopic 1 can be categorized as 'mercury(thimerosal), sodium content'\nTopic 3 : no trust\nTopic 4 : Cause Autism\nTopic 10 : death fatalities \n.\n.\netc","metadata":{}},{"cell_type":"markdown","source":"Analysing the content of each topic by manually perusal of human beings can be extremely challenging. Methods such as identifying the most important topics based on *residuals* can be adopted to overcome the disadvantage of high time consumption","metadata":{}},{"cell_type":"markdown","source":"This model can be used to gain an idea about the negatives surrounding vaccinations among the general public.","metadata":{}},{"cell_type":"markdown","source":"The same can be replicated with postive tweetsto help understand and amplify the positive opinions on vaccinations","metadata":{}}]}