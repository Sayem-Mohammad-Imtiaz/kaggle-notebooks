{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#import basic module\nimport numpy as np\nimport pandas as pd\nimport matplotlib as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## read data and quick review","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"fake_news = pd. read_csv('../input/fake-and-real-news-dataset/Fake.csv')\ntrue_news = pd.read_csv('../input/fake-and-real-news-dataset/True.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(fake_news.shape)\nprint(true_news.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_news.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true_news.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## compare length of text/subject","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"words = []\nwords.append(list(fake_news['text'].apply(len)))\nwords.append(list(true_news['text'].apply(len)))\nax = sns.boxplot(data=words)\nax.set(xticklabels=['fake', 'true'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words = []\nwords.append(list(fake_news['title'].apply(len)))\nwords.append(list(true_news['title'].apply(len)))\nax = sns.boxplot(data=words)\nax.set(xticklabels=['fake', 'true'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"length of fake news is wider range","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## compare number of unique words","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import collections\ndef calc_unique_words(col: pd.Series):\n    col = list(col)\n    unique = set()\n    for x in col:\n        unique |= set(x.split())\n    return len(unique)\nunique_fake = calc_unique_words(fake_news['text'])\nunique_true = calc_unique_words(true_news['text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(unique_fake, unique_true)\n# fake news have unique words","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Look into subject","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_news['subject'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true_news['subject'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data processing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fake_news['fake_flg'] = 1\ntrue_news['fake_flg'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([fake_news, true_news])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\n# eliminate puctuation\nprint(f'puncuations: {string.punctuation}')\nnopunc = [c for c in df['title'] if c not in string.punctuation]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.notebook import tnrange\ncorpus = []\nfor i in tnrange(len(df)):\n    #elminate number, other signs\n    title = re.sub('[^a-zA-Z]', ' ', nopunc[i]) \n    title = title.lower()\n    title = title.split()\n    \n    #word stemming(\"likes\"->\"like\")\n    ps = PorterStemmer()\n    title = [ps.stem(words) for words in title if not words in set(stopwords.words('english'))]\n\n    title = ' '.join(title)\n    corpus.append(title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus[3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## prepare data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(corpus, df['fake_flg'], test_size = 0.20, random_state = RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import Pipeline \nfrom sklearn.feature_extraction.text import TfidfVectorizer\n#vectorize text with tfidf(https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n\ntfidf = TfidfVectorizer()\ntfidf.fit(X_train) #train should be done only with train data\nX_train = tfidf.transform(X_train)\nX_test = tfidf.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## train and valuate models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#function for easy training and valuation\nfrom sklearn.metrics import classification_report,roc_auc_score\ndef train_and_predict(clf):\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    auc_score = roc_auc_score(y_test, y_pred)\n    print('auc: {:.5}'.format(auc_score))\n    print(classification_report(y_test, y_pred))\n    return clf, y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nclf = MultinomialNB()\ntrain_and_predict(clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nclf = lgb.LGBMClassifier()\ntrain_and_predict(clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#hyper parmerter seach \nfor i in [50, 100, 200, 400, 1000]:\n    print(f'num_leaves: {i}')\n    clf = lgb.LGBMClassifier(num_leaves=i)\n    train_and_predict(clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}