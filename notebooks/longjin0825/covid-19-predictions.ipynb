{"cells":[{"metadata":{},"cell_type":"markdown","source":"I copied the data collection part from this notebook : https://www.kaggle.com/imdevskp/covid-19-analysis-viz-prediction-comparisons","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# importing datasets\nfull_table = pd.read_csv('../input/corona-virus-report/covid_19_clean_complete.csv', \n                         parse_dates=['Date'])\nfull_table.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cleaning Data","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# cases \ncases = ['Confirmed', 'Deaths', 'Recovered', 'Active']\n\n# Active Case = confirmed - deaths - recovered\nfull_table['Active'] = full_table['Confirmed'] - full_table['Deaths'] - full_table['Recovered']\n\n# replacing Mainland china with just China\nfull_table['Country/Region'] = full_table['Country/Region'].replace('Mainland China', 'China')\n\n# filling missing values \nfull_table[['Province/State']] = full_table[['Province/State']].fillna('')\n# full_table[cases] = full_table[cases].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_time_series(country):\n    # for some countries, data is spread over several Provinces\n    if full_table[full_table['Country/Region'] == country]['Province/State'].nunique() > 1:\n        country_table = full_table[full_table['Country/Region'] == country]\n        country_df = pd.DataFrame(pd.pivot_table(country_table, values = ['Confirmed'],\n                              index='Date', aggfunc=sum).to_records())\n        return country_df.set_index('Date')[['Confirmed']]\n    df = full_table[(full_table['Country/Region'] == country) \n                & (full_table['Province/State'].isin(['', country]))]\n    return df.set_index('Date')[['Confirmed']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country = 'France'\ndf = get_time_series(country)\nif len(df) > 1 and df.iloc[-2,0] >= df.iloc[-1,0]:\n    df.drop(df.tail(1).index,inplace=True)\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\ndef model_with_lag(N, a, alpha, lag, t):\n    # we enforce N, a and alpha to be positive numbers using min and max functions\n    lag = min(max(lag, -100), 100) # lag must be less than +/- 100 days \n    return max(N, 0) * (1 - math.e ** (min(-a, 0) * (t - lag))) ** max(alpha, 0)\n\ndef model(N, a, alpha, t):\n    return max(N, 0) * (1 - math.e ** (min(-a, 0) * t)) ** max(alpha, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef model_loss(params):\n#     N, a, alpha, lag = params\n    N, a, alpha = params\n    model_x = []\n    r = 0\n    for t in range(len(df)):\n        r += (model(N, a, alpha, t) - df.iloc[t, 0]) ** 2\n#         r += (math.log(1 + model(N, a, alpha, t)) - math.log(1 + df.iloc[t, 0])) ** 2 \n#         r += (model_with_lag(N, a, alpha, lag, t) - df.iloc[t, 0]) ** 2\n#         print(model(N, a, alpha, t), df.iloc[t, 0])\n    return math.sqrt(r) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we need to explore the 3d parameter space to find a minimum, using gradient descent. There are a number of algorithms to do that in scipy.optimize, I stopped at the first one that seemed to work. Generalized Reduced Gradient as in Excel solver also works.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom scipy.optimize import minimize\nuse_lag_model = False\nif use_lag_model:\n    opt = minimize(model_loss, x0=np.array([200000, 0.05, 15, 0]), method='Nelder-Mead', tol=1e-5).x\nelse:\n    opt = minimize(model_loss, x0=np.array([200000, 0.05, 15]), method='Nelder-Mead', tol=1e-5).x\nopt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nmodel_x = []\nfor t in range(len(df)):\n    model_x.append([df.index[t], model(*opt, t)])\nmodel_sim = pd.DataFrame(model_x, dtype=int)\nmodel_sim.set_index(0, inplace=True)\nmodel_sim.columns = ['model']\npd.concat([model_sim, df], axis=1).plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's extend the prediction curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nstart_date = df.index[0]\nn_days = 150\nextended_model_x = []\nfor t in range(n_days):\n    extended_model_x.append([start_date + datetime.timedelta(days=t), model(*opt, t)])\nextended_model_sim = pd.DataFrame(extended_model_x, dtype=int)\nextended_model_sim.set_index(0, inplace=True)\nextended_model_sim.columns = ['model']\npd.concat([extended_model_sim, df], axis=1).plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's display predictions for future weeks","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.float_format = '{:20,.0f}'.format\nconcat_df = pd.concat([df, extended_model_sim], axis=1)\nconcat_df[concat_df.index.day % 7 == 0].astype({'model': 'int32'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now let's compare the dynamic in different countries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_fit(df, opt, ax):\n    model_x = []\n    for t in range(len(df)):\n        model_x.append([df.index[t], model(*opt, t)])\n    model_sim = pd.DataFrame(model_x, dtype=int)\n    model_sim.set_index(0, inplace=True)\n    model_sim.columns = ['model']\n    return pd.concat([model_sim, df], axis=1).plot(ax=ax, figsize=(12, 8))\n\ndef display_extended_curve(df, opt, ax):\n    start_date = df.index[0]\n    n_days = 140\n    extended_model_x = []\n    for t in range(n_days):\n        extended_model_x.append([start_date + datetime.timedelta(days=t), model(*opt, t)])\n    extended_model_sim = pd.DataFrame(extended_model_x, dtype=int)\n    extended_model_sim.set_index(0, inplace=True)\n    extended_model_sim.columns = ['model -> ' + str(int(opt[0]))]\n    return pd.concat([extended_model_sim, df], axis=1).plot(ax=ax, figsize=(12, 8))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats = []\nfor country in full_table['Country/Region'].unique():\n# for country in ['Sweden']:\n    df = get_time_series(country)\n    # only consider countries with at least 5000 cases (plus Sweden)\n    if len(df) == 0 or (max(df['Confirmed']) < 5000 and country != 'Sweden'): \n        continue\n    df.columns = [df.columns[0] + ' ' + country]\n    # if the last data point repeats the previous one, or is lower, drop it\n    if len(df) > 1 and df.iloc[-2,0] >= df.iloc[-1,0]:\n        df.drop(df.tail(1).index,inplace=True)\n#     if country == 'France':\n#         display(df.tail())\n    opt = minimize(model_loss, x0=np.array([200000, 0.05, 15]), method='Nelder-Mead', tol=1e-5).x\n#     print(country, opt)\n    if min(opt) > 0:\n        stats.append([country, *opt])\n        n_plot = len(stats)\n        plt.figure(1)\n        ax1 = plt.subplot(221)\n        display_fit(df, opt, ax1)\n        ax2 = plt.subplot(222)\n        display_extended_curve(df, opt, ax2)\n        plt.show()\nstats_df = pd.DataFrame(stats)\n# stats_df.columns = ['country', 'N', 'a', 'alpha', 'lag']\nstats_df.columns = ['country', 'N', 'a', 'alpha']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's see if we can make some sense from the parameters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', 500)\npd.options.display.float_format = '{:20,.4f}'.format\nstats_df.astype({'N': 'int'}).sort_values(by='N', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"N is the potential spread in the country if the dynamics since the beginning of the epidemy persist. One problem is that sometimes we're measuring the spread of testing rather than of the epidemy. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = stats_df.plot.scatter(x='alpha', y='a')\n# ax.set_xlim([0, 100])\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}