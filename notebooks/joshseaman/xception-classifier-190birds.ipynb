{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Overview\n\nThis classification assignment will focus on developing a deep learning model to predict the classification of birds using the Kaggle 190 Bird Species dataset.  I want to take a comparative approach in using a basic CNN vs a pre-trained model.  The basic CNN will be comprised of about a dozen hidden layers.  For comparison, I will use the Xception model to train and predict bird images.\n\nThe data set includes over 25K training images, 950 test images, and 950 validation images.The images are color and have a 224x224 pixel dimension.  The curator of the dataset has provided great details about the images included; the images are cropped to focus on the birds themselves rather than including a significant amount of extraineous details not related to the birds.  This should help with model prediction and limit the need for significant transformations with data augmentation.\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport os\nimport cv2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import backend, models, layers, optimizers, regularizers\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.applications import Xception\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below is are a few sample images from the dataset, by type of bird.  The curator of the images indicated that the cropped images to focus on the bird.  The sample images will help me validate if this is true; if true I won't need to apply significant transformations to images within data augmentation in order to ensure that it generalizes well.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"parent_dir = '/kaggle/input/100-bird-species/consolidated'\ncats = os.listdir(path=parent_dir)\n\nsubcats = cats[0:15]\nfig = plt.figure(figsize = [16,12])\nfor category in subcats:\n    img = os.listdir(path=os.path.join(parent_dir,subcats[1]))[1]\n    plt.subplot(3,5,subcats.index(category)+1, title = category)\n    path = os.path.join(parent_dir, category)\n    img_array = cv2.imread(os.path.join(path,img))\n    plt.imshow(img_array)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The images do appear well cropped.  This will be helpful in determing my data augmentation strategy below."},{"metadata":{"trusted":true},"cell_type":"code","source":"base_dir = '/kaggle/input/100-bird-species/'\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'valid')\ntest_dir = os.path.join(base_dir,'test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\nepoch = 100\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(224,224),\n    batch_size=20,\n    class_mode='categorical')\n\nvalidation_generator = train_datagen.flow_from_directory(\n    validation_dir,\n    target_size=(224,224),\n    batch_size=20,\n    class_mode='categorical')\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(224,224),\n    batch_size=20,\n    class_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first model is a basic CNN.  It is made of up three sequential groupings of hidden layers including: 3x3 2DConv Filter, 2x2 MaxPooling, and Batch Normalization. After these convolutions, the model is flattened and connected to a 512 node dense layer.  This is then passed through a dropout layer for regularization prior to the classifier."},{"metadata":{"trusted":true},"cell_type":"code","source":"backend.clear_session()\nmodel = models.Sequential()\n\nmodel.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape=(224,224,3)))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(BatchNormalization())\nmodel.add(layers.Conv2D(32, (3,3), activation = 'relu'))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(BatchNormalization())\nmodel.add(layers.Conv2D(32, (3,3), activation = 'relu'))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(BatchNormalization())\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dropout(0.2))\n\nmodel.add(layers.Dense(len(cats), activation='softmax'))\n\nmodel.compile(optimizer = 'adam',\n             loss = 'categorical_crossentropy',\n             metrics = ['accuracy'])\n\nhistory = model.fit_generator(train_generator,\n                              epochs = epoch,\n                              validation_data = validation_generator,\n                              verbose = 1,\n                              callbacks = [EarlyStopping(monitor='val_accuracy', \n                                                         patience = 5,\n                                                         restore_best_weights=True)])\n\ntest_loss, test_acc = model.evaluate_generator(test_generator)\nprint('base_model_test_acc:', test_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\nepochs = range(1, len(history_dict['accuracy']) + 1)\n\nplt.plot(epochs, loss_values, 'bo', label = 'Training loss')\nplt.plot(epochs, val_loss_values, 'b', label = 'Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.plot(epochs, acc_values, 'bo', label = 'Training accuracy')\nplt.plot(epochs, val_acc_values, 'b', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This model achieved a poor test accuracy of 47%.  It quickly began overfitting on the training data after the second epoch.  Epoch number 3 increased accuract over 20% while validation accuracy essentially leveled off.  \n\nHowever, rather than spend time creating a custom deep learning model, I will opt to use a pre-train neural network to save time.  I've had success with the Xception model in the past so I will attempt this.  I will also use data augmentation to increase the variability in my training data.  I won't tweak the height/width shifting, rotation, or zoom significantly on the images since the data curator has already done a fair amount of work isolating the images of the birds in the images.  I will, however, do horizontal_flips.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch = 50\ntrain_datagen2 = ImageDataGenerator(rescale=1./255,\n                                    rotation_range=10,\n                                    width_shift_range=0.05,\n                                    height_shift_range=0.05,\n                                    zoom_range=0.05,\n                                    horizontal_flip = True,\n                                    fill_mode='nearest')\ntest_datagen2 = ImageDataGenerator(rescale=1./255)\ntrain_generator2 = train_datagen2.flow_from_directory(train_dir,\n                                                     target_size=(224,224),\n                                                     batch_size=20,\n                                                     class_mode='categorical')\nvalidation_generator2 = train_datagen2.flow_from_directory(validation_dir,\n                                                          target_size=(224,224),\n                                                          batch_size=20,\n                                                          class_mode='categorical')\ntest_generator2 = test_datagen2.flow_from_directory(test_dir,\n                                                   target_size=(224,224),\n                                                   batch_size=20,\n                                                   class_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The training model itself will leverage the Xception pre-trained model.\n![](https://miro.medium.com/max/1400/1*hOcAEj9QzqgBXcwUzmEvSg.png)\n\nThe above image shows the Xception model architecture.  I left all of the layers locked to prevent adjustment of weights in the training process; I did unlock the final 6 layers for training.  This will allow Xception to be fine-tuned to the bird image data.  \n\nThe Xception model then connects to a flattening layer and a dense layer of 512 nodes prior to the final classification output layer (using a softmax).  ","attachments":{}},{"metadata":{"trusted":true},"cell_type":"code","source":"backend.clear_session()\nconv_base = Xception (weights = 'imagenet',\n                    include_top = False,\n                    input_shape = (224,224,3))\nfor layer in conv_base.layers[:-6]:\n    layer.trainable = False\n\nmodelx = models.Sequential()\nmodelx.add(conv_base)\nmodelx.add(layers.Flatten())\nmodelx.add(layers.Dense(512, activation = 'relu'))\nmodelx.add(layers.Dense(len(cats), activation = 'softmax'))\n\nmodelx.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n              loss = 'categorical_crossentropy',\n              metrics = ['accuracy'])\n\nhistory = modelx.fit_generator(train_generator2,\n                              epochs = epoch,\n                              validation_data = validation_generator2,\n                              verbose = 1,\n                              callbacks = [EarlyStopping(monitor='val_accuracy',\n                                                        patience = 5,\n                                                        restore_best_weights = True)])\n\ntest_loss, test_acc = modelx.evaluate_generator(test_generator2, steps = 48)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\nepochs = range(1, len(history_dict['accuracy']) + 1)\n\nplt.plot(epochs, loss_values, 'bo', label = 'Training loss')\nplt.plot(epochs, val_loss_values, 'b', label = 'Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.plot(epochs, acc_values, 'bo', label = 'Training accuracy')\nplt.plot(epochs, val_acc_values, 'b', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\nprint('Xception_test_acc:', test_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Xception based model achieved overall test accuracy of 91%.  The validation accuracy gradually increased from 85% to aproximately 90% from the first epoch to the 12th epoch.  After the 12th epoch, overfitting caused a decrease in validation accuracy which caused an early stop to the model.\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}