{"cells":[{"metadata":{},"cell_type":"markdown","source":"https://www.kaggle.com/rajnaruka0698/border-crossing-eda - Thx for the main part.\nhttps://www.kaggle.com/mrvazquez/us-border-crossing-eda-and-forecasting - Thx for forecasting part."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport datetime\n\nimport plotly.graph_objects as go\nimport plotly.express as px","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_non_filtered = pd.read_csv(\"../input/border-crossing-entry-data/Border_Crossing_Entry_Data.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df_non_filtered.query('Border == \"US-Mexico Border\"')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Attribute '+ 'Values')\nfor i in df.columns:\n    print( i,len(df.loc[:,i].unique()) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### There are 116 Port names but 117 port codes. This could be an enry error or there could be two ports with same port names. Let's see this in detail."},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df[['Port Name','Port Code']].drop_duplicates()\ntemp[temp['Port Name'].duplicated(keep=False)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.iloc[[29,217]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Also, there are almost duble the locations than the port codes. This can mean that a port useually has 2 locations asociated with it. Let's see this."},{"metadata":{},"cell_type":"markdown","source":"#### Eastport has two different port codes because there are two differnt ports by the name 'Eastport' in different states."},{"metadata":{"trusted":true},"cell_type":"code","source":"indexes = df['Location'].drop_duplicates().index\ntemp = df.iloc[indexes].groupby(by='Port Code')['Location'].count()\ntemp.value_counts().plot(kind='pie', autopct='%1.1f%%', shadow=True, explode=None,startangle=15)\ndel temp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We have a date column that is in string format we can get better results if we change it to datetime format. Also than we can extract Year and Month from date and see the distribution according to them."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Date'] = pd.to_datetime(df['Date'])\n\ndf['Year'] = df['Date'].apply(lambda x : x.year)\n\nmonth_mapper = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun'\n               ,7:'Jul', 8:'Aug', 9:'Sep' ,10:'Oct', 11:'Nov', 12:'Dec'}\ndf['Month'] = df['Date'].apply(lambda x : x.month).map(month_mapper)\n\ndel month_mapper","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's see number of crossings by Mesures."},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = pd.DataFrame(df.groupby(by='Measure')['Value'].sum().sort_values(ascending=False)).reset_index()\nfig = px.bar(temp, x='Measure', y='Value', height=400)\nfig.show()\ndel temp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Most crossings are done by personal vehicle pessengers and personal vehicles. Let's see if it is likely distributed in both the borders of not."},{"metadata":{"trusted":true},"cell_type":"code","source":"# temp = df.groupby(by=['Border','Measure'])['Value'].sum().reset_index()\n# temp.fillna(0,inplace=True)\n# temp.sort_values(by='Value', inplace=True)\n# fig = px.bar(temp, x='Measure', y='Value', color='Border', barmode='group')\n# fig.show()\n# del temp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### measures are likely distributed in both borders. But, One has higher number of crossings than the other. Let's see that."},{"metadata":{},"cell_type":"markdown","source":"#### Below graph represents total number of crossings from borders."},{"metadata":{"trusted":true},"cell_type":"code","source":"# temp = df.groupby(by='Border')['Value'].sum()\n# fig = go.Figure(data=[go.Pie(labels = temp.index, values=temp.values)])\n# fig.update_traces(textfont_size=15,  marker=dict(line=dict(color='#000000', width=2)))\n# fig.show()\n# del temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.lineplot(data=df, x='Year', y='Value', hue='Measure',legend='full')\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\nplt.title('Measure Values Through Years')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Above chart shows number of crossings throughout years.Crossings have been decreasing since year 2000. There is a slight increment in pedestrians crossing over past few yers."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.lineplot(data=df, x='Month', y='Value',legend='full', hue='Measure')\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\nplt.title('Value by month')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Above graph shows number of crossings by month. July and Aug have highest crossings where Feb has the least number of crossings."},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = pd.DataFrame(df.groupby(by='Port Name')['Value'].sum().sort_values(ascending=False)).reset_index()\npx.bar(temp, x='Port Name', y='Value')\ndel temp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Above graph represents ports and their number of crossings"},{"metadata":{},"cell_type":"markdown","source":"### We can group measures by their size."},{"metadata":{},"cell_type":"markdown","source":"#### Below we have two plots, both showing bar chart showing sum of values of different size of measures by different states."},{"metadata":{"trusted":true},"cell_type":"code","source":"measure_size = {'Trucks' : 'Mid_Size', 'Rail Containers Full' : 'Mid_Size', 'Trains' : 'Big_Size',\n       'Personal Vehicle Passengers':'Small_Size', 'Bus Passengers':'Small_Size',\n       'Truck Containers Empty':'Mid_Size', 'Rail Containers Empty':'Mid_Size',\n       'Personal Vehicles' : 'Small_Size', 'Buses' : 'Mid_Size', 'Truck Containers Full' : 'Mid_Size',\n       'Pedestrians':'Small_Size', 'Train Passengers':'Small_Size'}\n\ndf['Size'] = df['Measure'].map(measure_size)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"temp = df.groupby(by=['Size','State'])['Value'].sum()\ntemp.fillna(0,inplace=True)\ntemp = temp.reset_index()\npx.bar(temp, x='State', y='Value', facet_col='Size')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df.groupby(by=['Size','State'])['Value'].sum().unstack()\ntemp.fillna(0,inplace=True)\n\nplt.figure(figsize=(15,4))\n\nplt.subplot(131)\ntemp.iloc[0].sort_values().plot(kind='bar')\nplt.xticks(rotation=90)\nplt.title('Big_Size')\n\nplt.subplot(132)\ntemp.iloc[1].sort_values().plot(kind='bar')\nplt.xticks(rotation=90)\nplt.title('Mid_Size')\n\nplt.subplot(133)\ntemp.iloc[2].sort_values().plot(kind='bar')\nplt.xticks(rotation=90)\nplt.title('Small_Size')\n\ndel temp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Insights :\n- Minnesota has most number of big_size crossings but has averege on the other two categories.\n- Arizona has good number of small size crossings but average on the other two categories.\n- Ohio, Alaska and Montana has least amount of crossings in all the categories.\n- Michigan has 2nd heighest BIg and Mid size crossings but comparitively less small size crossings.\n- Texas has most mid_size and small size crossings and also, 3rd largest big_size crossings.\n- New York also has good number of crossings in all the three states."},{"metadata":{},"cell_type":"markdown","source":"### Let's see if crossings of different sizes are seasonal or not."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,6))\ng = sns.FacetGrid(data=df, col='Size', sharey=False, height=5, aspect=1)\ng.map(sns.lineplot, 'Month', 'Value')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Insights :\n- Mid_Size crossings are least in dec, jan and jul and most in oct, mar and aug.\n- Big_Size crossings are least in feb and most in oct, mar and aug.\n- Small_Size crossings are least in jan and feb and most in aug and july.\n- Crossing rate per month is negetively correlated with size of crossing."},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\n\npeople = df[df['Measure'].isin(['Personal Vehicle Passengers', 'Bus Passengers','Pedestrians', 'Train Passengers'])]\n\npeople_crossing_series = people[['Date','Value']].groupby('Date').sum()\n\npcsm = people_crossing_series.loc['2011':]\n\n# Multiplicative Decomposition \nres_mul = seasonal_decompose(pcsm, model='multiplicative', extrapolate_trend='freq')\n\n# Additive Decomposition\nres_add = seasonal_decompose(pcsm, model='additive', extrapolate_trend='freq')\n\n# extrapolate_trend='freq' gets rid of NaN values\n# Plot\nfig, axes = plt.subplots(ncols=2, nrows=4, sharex=True, figsize=(15,8))\n\nres_mul.observed.plot(ax=axes[0,0], legend=False)\naxes[0,0].set_ylabel('Observed')\n\nres_mul.trend.plot(ax=axes[1,0], legend=False)\naxes[1,0].set_ylabel('Trend')\n\nres_mul.seasonal.plot(ax=axes[2,0], legend=False)\naxes[2,0].set_ylabel('Seasonal')\n\nres_mul.resid.plot(ax=axes[3,0], legend=False)\naxes[3,0].set_ylabel('Residual')\n\nres_add.observed.plot(ax=axes[0,1], legend=False)\naxes[0,1].set_ylabel('Observed')\n\nres_add.trend.plot(ax=axes[1,1], legend=False)\naxes[1,1].set_ylabel('Trend')\n\nres_add.seasonal.plot(ax=axes[2,1], legend=False)\naxes[2,1].set_ylabel('Seasonal')\n\nres_add.resid.plot(ax=axes[3,1], legend=False)\naxes[3,1].set_ylabel('Residual')\n\naxes[0,0].set_title('Multiplicative')\naxes[0,1].set_title('Additive')\n    \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"des = res_mul.trend * res_mul.resid\ndes.plot(figsize = (15,10))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\n\nresult = adfuller(des.Value.dropna())\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\n\n\nresult_diff = adfuller(des.diff().Value.dropna())\nprint('ADF Statistic: %f' % result_diff[0])\nprint('p-value: %f' % result_diff[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfig, axes = plt.subplots(3, 2, figsize=(16,10))\n\naxes[0, 0].plot(des.Value)\naxes[0, 0].set_title('Original Series')\nplot_pacf(des, ax=axes[0, 1])\n\n# 1st Differencing\naxes[1, 0].plot(des.Value.diff()); axes[1, 0].set_title('1st Order Differencing')\nplot_pacf(des.diff().dropna(), ax=axes[1, 1])\n\n# 2nd Differencing\naxes[2, 0].plot(des.diff().diff()); axes[2, 0].set_title('2nd Order Differencing')\nplot_pacf(des.diff().diff().dropna(), ax=axes[2, 1])\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\n\n# ARIMA(p,d,q) Model \nmodel_1 = ARIMA(des, order=(1,0,1))\nmodel_1_fit = model_1.fit(disp=0)\n\nmodel_2 = ARIMA(des, order=(2,0,1))\nmodel_2_fit = model_2.fit(disp=0)\n\nmodel_3 = ARIMA(des, order=(0,0,2))\nmodel_3_fit = model_3.fit(disp=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"des.head(3)\ndata = des.iloc[1:,]\ndata.head(98)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1_fit.plot_predict()\nplt.title((sum((model_1_fit.fittedvalues -  des['Value']) ** 2)))\nplt.show()\n\nmodel_2_fit.plot_predict()\nplt.title((sum((model_2_fit.fittedvalues -  des['Value']) ** 2)))\nplt.show()\n\nmodel_3_fit.plot_predict()\nplt.title((sum((model_3_fit.fittedvalues -  des['Value']) ** 2)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date_start = people_crossing_series.tail(1).index[0]\ndate_end = '2020-12-01'\ndate_rng = pd.date_range(start=date_start, end=date_end, freq='MS', closed = 'right') # range for forecasting\nn_forecast = len(date_rng) # number of steps to forecast\n\nseasonal = res_mul.seasonal.loc['2018-01-01':'2018-12-01'].values # seasonal component, we take the 2018 ones, but they are all the same.\ntms = pd.Series(np.tile(seasonal.flatten(),11), index = pd.date_range(start='2019-01-01', end = '2029-12-01', freq='MS'))  # This is just a very long series with the seasonality.\n\ndef make_seasonal(ser) :\n    seasonal_series = ser * tms # Include the seasonality\n    seasonal_series = seasonal_series[~seasonal_series.isnull()] # trim extra values\n    return seasonal_series\n    \n# Forecast\n\nmodel = ARIMA(des, order=(2,0,1))\nmodel_fit = model.fit(disp=0)\n\nfc1, se1, conf1 = model_fit.forecast(n_forecast, alpha = 0.0455)  # 2 sigma Confidence Level (95,55% conf)\nfc2, se2, conf2 = model_fit.forecast(n_forecast, alpha = 0.3173)  # 1 sigma Confidence Level (68,27% conf)\n\n# Make as pandas series \nfc1_series = pd.Series(fc1, index = date_rng)\nlower_series1 = pd.Series(conf1[:, 0], index = date_rng)\nupper_series1 = pd.Series(conf1[:, 1], index = date_rng)\n\n# Include seasonality\nfc1_series, lower_series1, upper_series1 = [make_seasonal(fc1_series), make_seasonal(lower_series1), make_seasonal(upper_series1)]\n\nplt.figure(figsize=(12,5), dpi=100)\n\n#plt.plot(des, label='actual')\n#plt.plot(people_crossing_series, label='actual')\nplt.plot(des * res_mul.seasonal, label='data')\nplt.plot(fc1_series , label='forecast')\n\n# Confidence level intervals\nplt.fill_between(lower_series1.index,lower_series1, upper_series1, \n                 color='k', alpha=.15, label='2$\\sigma$ Confidence level (95%)')\nplt.title('Forecast 2019/20')\nplt.legend(loc='upper left', fontsize=8)\n#plt.ylim(10000000, 30000000)\nplt.xlim('2016', '2021')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}