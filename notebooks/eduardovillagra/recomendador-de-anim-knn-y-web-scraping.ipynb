{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Cargando datos y paquetes"},{"metadata":{},"cell_type":"markdown","source":"#### Librerías "},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import zscore\nfrom sklearn.preprocessing import MaxAbsScaler\nfrom sklearn.neighbors import NearestNeighbors\nfrom scipy.stats import randint\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom scrapy import Selector\nimport requests\nfrom scrapy.crawler import CrawlerProcess\nimport scrapy\nfrom scrapy.utils.project import get_project_settings","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cargando Dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"anime = pd.read_csv(\"../input/anime.csv\")\nrating = pd.read_csv(\"../input/rating.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocesamiento data anime"},{"metadata":{},"cell_type":"markdown","source":"### Explorando datos\n\nEn primera instancia se explora la existencia de casos duplicados, también la dimensión de la data y el tipo de dato de cada variable. Se observa que la variable \"episodes\" es de tipo object y no numérico dado que contiene una categoría \"Unknown\" que indica que no se conoce la cantidad de episodios del anime, es por esto, que se procede a cambiar \"Unknown\" por NaN y luego el tipo de dato a numérico.\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(anime.shape)\nprint(anime.drop_duplicates().shape)\nprint(anime.info())\nanime.tail(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"anime.replace(\"Unknown\", np.nan, inplace=True)\nanime[\"episodes\"] = anime[\"episodes\"].astype(float)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Indentificando NaN \n\nPodemos detectar que las variables \"genre\", \"type\", \"episodes\" y \"rating\" poseen datos faltantes, donde \"episodes\" es la variable con más datos faltantes, seguida por \"rating\". Por otro lado, \"genre\" y \"type\" tienen mucho menos de missing. En total la data tiene 464 NaN."},{"metadata":{"trusted":false},"cell_type":"code","source":"print(anime.isnull().sum())\nprint(anime[anime.isnull().any(axis=1)].shape)\nanime[anime.isnull().any(axis=1)].head()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Web Scraping para rellenar valores nulos"},{"metadata":{"trusted":false},"cell_type":"code","source":"nombres= anime[anime.isnull().any(axis=1)]\nnombres = nombres[\"name\"].values.tolist()\n\ntipoAnime=pd.get_dummies(anime[\"type\"]).columns\ntipoAnime=tipoAnime.str.strip().unique().tolist()\n\ngenero=anime[\"genre\"].str.get_dummies(sep=\",\").columns\ngenero=genero.str.strip().unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":false},"cell_type":"code","source":"buscarURL = 'https://myanimelist.net/search/all?q='\nurlAnime = []\nfor i in nombres:\n    urlAnime.append(buscarURL + i)\n\n\nclass AnimeFcSpider(scrapy.Spider):\n    name = 'anime_fc'\n\n    def start_requests(self):  # start_requests method\n        for url2 in urlAnime:\n            yield scrapy.Request(url=url2,\n                                 callback=self.parse_front)\n\n    def parse_front(self, response):  # First parsing method\n        course_links = response.xpath('//div[@class=\"picSurround di-tc thumb\"]/a/@href')\n        yield response.follow(url=course_links[0],\n                              callback=self.parse_pages)\n\n    def parse_pages(self, response):  # Second parsing method\n        crs_name = response.xpath('//h1[@class=\"h1\"]/span/text()').extract_first()\n        crs_episodes = response.xpath('//td[@class=\"spaceit\"]/span[@id=\"curEps\"]/text()').extract_first()\n        crs_rating = response.xpath('//span[@itemprop=\"ratingValue\"]/text()').extract_first()\n        crs_id = response.xpath('//input[@name=\"aid\"]/@value').extract_first()\n\n        crs_genre = response.xpath('//div/a/@title').extract()\n        crs_genre = np.intersect1d(crs_genre, genero)\n        crs_genre = ','.join(map(str, crs_genre))\n\n        crs_type = response.xpath('//div/a/text()').extract()\n        crs_type = np.intersect1d(crs_type,tipoAnime)\n        crs_type = ','.join(map(str, crs_type))\n       \n\n        list_name.append(crs_name)\n        list_genre.append(crs_genre)\n        list_type.append(crs_type)\n        list_episodes.append(crs_episodes)\n        list_rating.append(crs_rating)\n        list_id.append(crs_id)\n\n\n\nlist_name = list()\nlist_genre = list()\nlist_type = list()\nlist_episodes = list()\nlist_rating = list()\nlist_id = list()\n\ns = get_project_settings()\ns['CONCURRENT_REQUESTS_PER_IP'] = 16\ns['CONCURRENT_REQUESTS_PER_DOMAIN '] = 16\ns['DOWNLOAD_DELAY'] = 2.5\ns['CONCURRENT_REQUESTS'] = 32\ns['CONCURRENT_REQUESTS'] = 32\n\n\nprocess = CrawlerProcess(s)  # Run the Spider\nprocess.crawl(AnimeFcSpider)\nprocess.start()\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"DataNa = pd.DataFrame({\"anime_id\":list_id, \"name\":list_name,\"genre\":list_genre,\n                       \"type\":list_type, \"episodes\":list_episodes, \"rating\":list_rating})\n\nDataNa.replace(\"\", np.nan, inplace=True)\nDataNa.replace('?', np.nan, inplace=True)\n\nprint(DataNa.shape)\nprint(DataNa.isnull().sum())\nDataNa.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Preprocesando data obtenida con web scraping\n\nCambiamos el tipo de datos al mismo que la data original"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"DataNa[\"anime_id\"] = DataNa[\"anime_id\"].astype(float)\nDataNa[\"episodes\"] = DataNa[\"episodes\"].astype(float)\nDataNa[\"rating\"] = DataNa[\"rating\"].astype(float)\nDataNa.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cruzamos la data obtenida con la origianal para luego reemplazar los nulos con la información nueva"},{"metadata":{"trusted":false},"cell_type":"code","source":"dataNueva= pd.merge(anime, DataNa,left_on=\"anime_id\",right_on=\"anime_id\", how=\"left\")\ndataNueva.info()\nprint(anime.isnull().sum())\nprint(anime[anime.isnull().any(axis=1)].shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dataNueva.loc[dataNueva[\"genre_x\"].isna(),\"genre_x\"] = dataNueva[\"genre_y\"]\ndataNueva.loc[dataNueva[\"type_x\"].isna(),\"type_x\"] = dataNueva[\"type_y\"]\ndataNueva.loc[dataNueva[\"episodes_x\"].isna(),\"episodes_x\"] = dataNueva[\"episodes_y\"]\ndataNueva.loc[dataNueva[\"rating_x\"].isna(),\"rating_x\"] = dataNueva[\"rating_y\"]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Eliminamos las varibles nuevas dado que ya utilizamos sus valores. "},{"metadata":{"trusted":false},"cell_type":"code","source":"dataNueva.drop([\"name_y\", \"genre_y\", \"type_y\", \"episodes_y\", \"rating_y\"],axis=1,inplace=True)\ndataNueva.columns = dataNueva.columns.str.replace('_x', '')\n\nprint(dataNueva.isnull().sum())\nprint(dataNueva[dataNueva.isnull().any(axis=1)].shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Imputando datos nulos"},{"metadata":{},"cell_type":"markdown","source":"#### Variable \"episodes\"\n\nLa primera variable a imputar es \"episodes\", dado que es la con mayor cantidad de NaN, para esto agruparemos por \"type\" y utilizaremos la mediana() de la cantidad de episodios de cada grupo."},{"metadata":{"trusted":false},"cell_type":"code","source":"anime=dataNueva.copy()\nprint(anime.groupby(\"type\")[\"episodes\"].describe())\n\nanime.loc[(anime[\"type\"]==\"OVA\") & (anime[\"episodes\"].isna()),\"episodes\"] = anime.loc[(anime[\"type\"]==\"OVA\") ,\"episodes\"].median()\nanime.loc[(anime[\"type\"]==\"Movie\") & (anime[\"episodes\"].isna()),\"episodes\"] = anime.loc[(anime[\"type\"]==\"Movie\") ,\"episodes\"].median()\nanime.loc[(anime[\"type\"]==\"Music\") & (anime[\"episodes\"].isna()),\"episodes\"] = anime.loc[(anime[\"type\"]==\"Music\") ,\"episodes\"].median()\nanime.loc[(anime[\"type\"]==\"ONA\") & (anime[\"episodes\"].isna()),\"episodes\"] = anime.loc[(anime[\"type\"]==\"ONA\") ,\"episodes\"].median()\nanime.loc[(anime[\"type\"]==\"Special\") & (anime[\"episodes\"].isna()),\"episodes\"] = anime.loc[(anime[\"type\"]==\"Special\") ,\"episodes\"].median()\nanime.loc[(anime[\"type\"]==\"TV\") & (anime[\"episodes\"].isna()),\"episodes\"] = anime.loc[(anime[\"type\"]==\"TV\") ,\"episodes\"].median()\nanime.loc[(anime[\"type\"].isna()) & (anime[\"episodes\"].isna()),\"episodes\"] = anime[\"episodes\"].median()\n\nprint(anime[anime.isnull().any(axis=1)].shape)\nprint(anime.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Variable \"type\"\n\nEsta variable tiene 9 nulos, podríamos inferir el tipo por la cantidad de capítulos del animé, pero justamente estos 9 animé no tienen esa información por lo que reemplazaremos el dato nulo por \"notype\" para no eliminar la observación y así perder información valiosa. \n"},{"metadata":{"trusted":false},"cell_type":"code","source":"anime[\"type\"].replace(np.nan, \"notype\", inplace=True)\nprint(anime.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Variable \"genre\"\n\nTenemos 45 animé con nulos en genero. pero dado que esta variable es muy importante en la elección del animé (por conocimiento propio) una imputación errónea sería grabe, por lo tanto haremos lo mismo que con \"type\" y crearemos una categoría para los nulos \"nogenre\""},{"metadata":{"trusted":false},"cell_type":"code","source":"anime[\"genre\"].replace(np.nan, \"nogenre\", inplace=True)\nprint(anime.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Variable \"rating\"\n\nPara esta variable haremos una imputación un poco más dirigida, se agrupará por \"type\" y \"epidodes\" y se calculará la mediana de rating con esa agrupación para imputar rating. En caso que los grupos \"type\" y \"episodes\" no tengan una mediana para \"rating\" se agrupará por \"genre\" y \"epidodes\" y si aún así no hay una mediana para \"rating\", entoces los datos nulos se reemplazarán por la mediana global. "},{"metadata":{"trusted":false},"cell_type":"code","source":"def impute_median(series):\n    return series.fillna(series.median())\n\nanime.rating = anime.groupby(['type', 'episodes'])[[\"rating\"]].transform(impute_median)\nanime.rating = anime.groupby(['genre', 'episodes'])[[\"rating\"]].transform(impute_median)\nanime[\"rating\"]=anime[\"rating\"].fillna(anime[\"rating\"].median())\nprint(anime.isnull().sum())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se resetea el índice de la data para no tener problemas en el futuro para buscar filas especificas"},{"metadata":{"trusted":false},"cell_type":"code","source":"anime=anime.reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Construyendo data con variables para análisis"},{"metadata":{},"cell_type":"markdown","source":"#### Re-codificando variables\n\nNo era conveniente tener los géneros apilados como categoría separadas por comas en una única casilla, por lo que se separaron y pasaros a variables dicotómicas al igual que \"type\". Las variables restantes serán escaladas para no tener problemas con los algoritmos futuros, dado que utilizan distancias."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"anime_data = pd.concat([anime[\"genre\"].str.get_dummies(sep=\",\"),\n                           anime[\"type\"].str.get_dummies(sep=\",\"),anime[[\"rating\"]],\n                            anime[[\"members\"]],anime[\"episodes\"]],axis=1)\n\nanime_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"anime_data = MaxAbsScaler().fit_transform(anime_data)\nanime_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Algoritmo no supervisado para encontrar elementos similares \n## Parte 1: Animes similares a un anime especifico"},{"metadata":{},"cell_type":"markdown","source":"### K vecino más cercano (KNN)\n\nEl K-Vecino más cercano es la opción que me pareció más aceptada, dado que es un algoritmo jerárquico por lo cual no tenemos que elegir grupos a priori y es exactamente lo que estamos buscamos, explico: \n\nLo que necesitamos es un algoritmo que tome un anime (cada fila representa un anime diferente) y de acuerdo a sus características (calificación, géneros, tipo y cantidad de episodios) pueda encontrar animes similares. KNN toma la distancia de una observación con cada observación de la data (importante tener los datos en la misma escala) y es exactamente lo que nos interesa rescatar, dado que es un claro indicador de similitud entre animes, además nos da la opción de elegir los k vecinos más próximos al animé buscado. \n\n(El objetivo no es encontrar clúster o grupos de animé, si no desde un punto establecido en el espacio rescatar los puntos más próximos)\n\nParámetros KNN\n\nn_neighbors:\nEl número de vecinos solo nos agrega más elementos en la salida, es decir, n_neighbors=k sólo me indicará que \"índices\" tendrá un vector de k-1 elementos correspondiente los índices de los vecinos más cercano del anime consultado.  \n\n\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"KNNanime = NearestNeighbors(n_neighbors=7, algorithm='ball_tree').fit(anime_data)\ndistances, indices = KNNanime.kneighbors(anime_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def nombres_indices(name):  # Toma el nombre del anime y devuelve su indice correspondiente\n    return anime[anime[\"name\"]==name].index.tolist()[0] \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def recomendados_por_anime(nombre):  # Muestra el grupo de animes más cercanos al consultado\n     found_id = nombres_indices(nombre)\n     for id in indices[found_id][1:]:\n            print(anime.loc[id][\"name\"])\n            \nrecomendados_por_anime(\"Naruto\")\n        \n       ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Parte 2: Animes recomendados para cada usuario\n\nEn la parte 1 sólo conseguimos encontrar animes similares a otros animes, pero no estamos recomendando nada al usuario, es por esto, que utilizaremos la data riting.csv que contiene información del usuario para crear un recomendado de anime según preferencias del usuario utilizando las distancias de similitud obtenidas en la parte 1."},{"metadata":{},"cell_type":"markdown","source":"### Explorando data riting\n\nEsta data contiene un id del usuario (user_id), el id del anime (anime_id) y la calificación que da el usuario al anime (rating).\n\nNo contiene NaN, pero la variable rating contiene el valor -1 que significa que el usuario no calificó el anime, esto puede ser considerado como un dato faltando.\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(rating.shape)\nprint(rating.isnull().sum())\nrating.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"El siguiente paso es cruzar las datas anime y rating por la izquierda, dado que la data \"rating\" puede contener\nanimes que no se encuentran en la data \"anime\" y esto puede ser un problema en el futuro. "},{"metadata":{"trusted":false},"cell_type":"code","source":"merge = pd.merge(anime, rating, on=\"anime_id\", how=\"left\")\nmerge.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Construyendo recomendador\n\nNecesitamos obtener todos los animes vistos por un usuario especifico, dado que según esto podemos capturar sus preferencias, luego de obtenidos los animes vistos por el usuario se procede a guardar en una lista con todos los animes similares a los que a visto el usuario (vecinos del algoritmo KNN ) excluyendo los que ha vistos (para no recomendar un anime que el usuario ya vio). Por último, se toma esta lista y se calcula la frecuencia de los animes que más se repiten en la lista y se ordenan de mayor a menor. \n\nLa función ecomendados_usuario() devuelve los animes recomendados para el usuario.\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"def similar_animes(id_anime):  # Trae todos los id_anime relacionados con un id_anime dado\n    \n    id_list=[]\n    found_id = anime[anime[\"anime_id\"]==id_anime].index.tolist()[0]  # Indice del id ingresado\n    for id in indices[found_id][1:]:\n            id_list.append(anime.loc[id][\"anime_id\"])\n            \n    return id_list  \n        \n            \ndef similar_animes_usuarios(id_user):  # Crea una lista con todos los animes relacionados con los animes visto por el usuario\n    \n    a = merge[merge[\"user_id\"]==id_user].anime_id.values\n    lista = []\n    for i in range(len(a)):\n        lista.append(similar_animes(a[i]))\n    return lista\n            \n        \ndef similar_animes_usuarios_freq(id_user): # Crea una lista con los 6 anime más recomendados del usuario\n    a=similar_animes_usuarios(id_user)\n    r= np.array([])\n    for i in range(5):\n        f1 = pd.Series( (v[i] for v in a))\n        r = np.append(r,f1)\n        \n    gh = merge[merge[\"user_id\"]==id_user].anime_id.values\n    rdiff=np.setdiff1d(r, gh)\n    kk = pd.DataFrame({'Column1':rdiff})\n    pda = pd.crosstab(index=kk[\"Column1\"].astype(int), columns= \"count\")\n    pda2 = pda.sort_values(\"count\", ascending=False).head(6).index.tolist() \n    \n    return pda2\n        \n    \ndef recomendados_usuario(id_user):  # Pasa de anime_id a los nombres de los animé\n    \n    a=similar_animes_usuarios_freq(id_user)\n    for id in a:\n        print(anime[anime[\"anime_id\"]==id][\"name\"].values)\n        \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Utilizando funciones de recomendación"},{"metadata":{},"cell_type":"markdown","source":"#### Animes recomendados por usuario"},{"metadata":{"trusted":false},"cell_type":"code","source":"recomendados_usuario(3454)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"recomendados_usuario(8765)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Animes recomendados por anime"},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"recomendados_por_anime(\"Dragon Ball Z\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"recomendados_por_anime(\"Pokemon\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}