{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this notebook, we will implement a random forest in Python. With machine learning in Python, it's very easy to build a complex model without having any idea how it works. Therefore, we'll start with a single decision tree and a simple problem, and then work our way to a random forest and a real-world problem.\n\nOnce we understand how a single decision tree thinks, we can transfer this knowledge to an entire forest of trees.\nThe problem we’ll solve is a binary classification task with the goal of predicting an individual’s health. The features are socioeconomic and lifestyle characteristics of individuals and the label is 0 for poor health and 1 for good health. This dataset was collected by the Centers for Disease Control and Prevention ","metadata":{}},{"cell_type":"markdown","source":"https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf = pd.read_csv('../input/behavioral-risk-factor-surveillance-system/2015.csv').sample(10000, random_state = 50)\ndf.head()","metadata":{"_cell_guid":"","_uuid":"","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['_RFHLTH'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['_RFHLTH'] = df['_RFHLTH'].replace({2: 0})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['_RFHLTH'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.loc[df['_RFHLTH'].isin([0, 1])].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['_RFHLTH'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.rename(columns = {'_RFHLTH': 'Label'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We won't do any data exploration in this notebook, but in general, exploring the data is a best practice. This can help you for feature engineering (which we also won't do here) or by identifying and correcting anomalies / mistakes in the data.","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percentOfData = df.count()*100/9980","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percentOfData.where(percentOfData<50).dropna()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"badFeatures = percentOfData.where(percentOfData<50).dropna()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove columns with missing values\ndf = df.drop(columns = badFeatures.index.to_list())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove all non float data\ndf = df.select_dtypes(include=['float64'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing few more columns\ndf = df.drop(columns=['SEX','_STATE','FMONTH','SEQNO','DISPCODE','MARITAL','EDUCA','POORHLTH', 'PHYSHLTH', 'GENHLTH', 'HLTHPLN1', 'MENTHLTH'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import HTML\nHTML(pd.DataFrame(df.dtypes).to_html())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Extract the labels\n#labels = np.array(df.pop('Label'))\n\n# 30% examples in test data\ntrain, test, train_labels, test_labels = train_test_split(df, df['Label'], test_size = 0.3, \n                                                          random_state = 50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imputation of missing values\ntrain = train.fillna(train.mean())\ntest = test.fillna(test.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.distplot(train['Label'], kde=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train tree\nfrom sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier(random_state=50, max_depth=60)\ntree.fit(train, train_labels)\nprint(f'Decision tree has {tree.tree_.node_count} nodes with maximum depth {tree.tree_.max_depth}.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make probability predictions\ntrain_probs = tree.predict_proba(train)[:, 1]\nprobs = tree.predict_proba(test)[:, 1]\n\ntrain_predictions = tree.predict(train)\npredictions = tree.predict(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve\n\nprint(f'Train ROC AUC Score: {roc_auc_score(train_labels, train_probs)}')\nprint(f'Test ROC AUC  Score: {roc_auc_score(test_labels, probs)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Baseline ROC AUC: {roc_auc_score(test_labels, [1 for _ in range(len(test_labels))])}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our model does outperform a baseline guess, but we can see it has severely overfit to the training data, acheiving perfect ROC AUC.","metadata":{}},{"cell_type":"code","source":"def evaluate_model(predictions, probs, train_predictions, train_probs):\n    \"\"\"Compare machine learning model to baseline performance.\n    Computes statistics and shows ROC curve.\"\"\"\n    \n    baseline = {}\n    \n    baseline['recall'] = recall_score(test_labels, [1 for _ in range(len(test_labels))])\n    baseline['precision'] = precision_score(test_labels, [1 for _ in range(len(test_labels))])\n    baseline['roc'] = 0.5\n    \n    results = {}\n    \n    results['recall'] = recall_score(test_labels, predictions)\n    results['precision'] = precision_score(test_labels, predictions)\n    results['roc'] = roc_auc_score(test_labels, probs)\n    \n    train_results = {}\n    train_results['recall'] = recall_score(train_labels, train_predictions)\n    train_results['precision'] = precision_score(train_labels, train_predictions)\n    train_results['roc'] = roc_auc_score(train_labels, train_probs)\n    \n    for metric in ['recall', 'precision', 'roc']:\n        print(f'{metric.capitalize()} Baseline: {round(baseline[metric], 2)} Test: {round(results[metric], 2)} Train: {round(train_results[metric], 2)}')\n    \n    # Calculate false positive rates and true positive rates\n    base_fpr, base_tpr, _ = roc_curve(test_labels, [1 for _ in range(len(test_labels))])\n    model_fpr, model_tpr, _ = roc_curve(test_labels, probs)\n\n    plt.figure(figsize = (8, 6))\n    plt.rcParams['font.size'] = 16\n    \n    # Plot both curves\n    plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')\n    plt.plot(model_fpr, model_tpr, 'r', label = 'model')\n    plt.legend();\n    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC Curves');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"TODO: construct ROC curve and confusion matrix","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"from collections import Counter\nprint(Counter(probs))\nprint(Counter(predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_model(predictions, probs, train_predictions, train_probs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Oranges):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    Source: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.figure(figsize = (10, 10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, size = 24)\n    plt.colorbar(aspect=4)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45, size = 14)\n    plt.yticks(tick_marks, classes, size = 14)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    \n    # Labeling the plot\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), fontsize = 20,\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n        \n    plt.grid(None)\n    plt.tight_layout()\n    plt.ylabel('True label', size = 18)\n    plt.xlabel('Predicted label', size = 18)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(test_labels, predictions)\nplot_confusion_matrix(cm, classes = ['Poor Health', 'Good Health'],\n                      title = 'Health Confusion Matrix')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = list(train.columns)\nfi = pd.DataFrame({'feature': features,\n                   'importance': tree.feature_importances_}).\\\n                    sort_values('importance', ascending = False)\nfi.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save tree as dot file\nfrom sklearn.tree import export_graphviz\nfrom subprocess import call\nfrom IPython.display import Image\nexport_graphviz(tree, 'tree_real_data.dot', rounded = True, \n                feature_names = features, max_depth = 6,\n                class_names = ['poor health', 'good health'], filled = True)\n\n# Convert to png\ncall(['dot', '-Tpng', 'tree_real_data.dot', '-o', 'tree_real_data.png', '-Gdpi=200'])\n\n# Visualize\nImage(filename='tree_real_data.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Create the model with 100 trees\nmodel = RandomForestClassifier(n_estimators=100, \n                               random_state=50, \n                               max_features = 'sqrt',\n                               n_jobs=-1, verbose = 1)\n#RSEED = 50\n# Fit on training data\nmodel.fit(train, train_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_nodes = []\nmax_depths = []\n\nfor ind_tree in model.estimators_:\n    n_nodes.append(ind_tree.tree_.node_count)\n    max_depths.append(ind_tree.tree_.max_depth)\n    \nprint(f'Average number of nodes {int(np.mean(n_nodes))}')\nprint(f'Average maximum depth {int(np.mean(max_depths))}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Random Forest Results\ntrain_rf_predictions = model.predict(train)\ntrain_rf_probs = model.predict_proba(train)[:, 1]\n\nrf_predictions = model.predict(test)\nrf_probs = model.predict_proba(test)[:, 1]\nevaluate_model(rf_predictions, rf_probs, train_rf_predictions, train_rf_probs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(test_labels, rf_predictions)\nplot_confusion_matrix(cm, classes = ['Poor Health', 'Good Health'],\n                      title = 'Health Confusion Matrix')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fi_model = pd.DataFrame({'feature': features,\n                   'importance': model.feature_importances_}).\\\n                    sort_values('importance', ascending = False)\nfi_model.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Conclusions\n#In this notebook, we built and used a random forest machine learning model in Python. Rather than just writing the code and not understanding the model, we formed an understanding of the random forest by inspecting an individual decision tree and discussion its limitations. We visualized the decision tree to see how it makes decisions and also saw how one decision tree overfits to the trainig data. To overcome the limitations of a single decision tree, we can train hundreds or thousands of them in a single ensemble model. This model, known as a random forest, trains each tree on a different set of the training observations, and make splits at each node based on a subset of the features leading to a model with reduced variance and better generalization performance on the testing set.\n\n#A few key concepts to take away are\n\n#Individual decision tree: intuitive model that makes decisions based on a flowchart of questions asked about feature values. Has high variance indicated by overfitting to the training data.\n#Gini Impurity: Measure that the decision tree tries to minimize when splitting each node. Represents the probability that a randomly selected sample from a node will be incorreclty classified according to the distribution of samples in the node.\n#Bootstrapping: sampling random sets of observations with replacement. Method used by the random forest for training each decision tree.\n#Random subsets of features: selecting a random set of the features when considering how to split each node in a decision tree.\n#Random Forest: ensemble model made of hundreds or thousands of decision trees using bootstrapping, random subsets of features, and average voting to make predictions.\n#Bias-variance tradeoff: the fundamental issue in machine learning that describes the tradeoff between a model with high complexity that learns the training data very well at the cost of not being able to generalize to the testing data (high variance), and a simple model (high bias) that cannot even learn the training data. A random forest reduces the variance of a single decision tree while also accurately learning the training data leading to better predictions on the testing data.\n#Hopefully this notebook has given you not only the code required to use a random forest, but also the background necessary to understand how the model is making decisions. Machine learning is a powerful tool and it's important to not only know how to use the tool, but also to understand how it works!","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}