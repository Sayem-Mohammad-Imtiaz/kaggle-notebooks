{"cells":[{"cell_type":"markdown","source":"We did this data analysis for our class assignment","metadata":{"_kg_hide-output":false,"_kg_hide-input":false}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport datetime as dt\nimport seaborn as sns #seaborn is already installed\nimport matplotlib.pyplot as plt"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#loading the dataset\ndf = pd.read_csv('../input/data.csv',encoding=\"ISO-8859-1\",dtype={'CustomerID': str,})\nprint(df.shape)\ndf.head(3)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Check any duplicated data set and column formats\nprint(sum(df.duplicated(keep=\"first\")),\"transaction rows affected\")\ndf.dtypes"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#remove duplicate rows from dataset, reformatting columns and defining new fields for data exploration\ndf=df.drop_duplicates()\ndf.InvoiceDate = pd.to_datetime(df.InvoiceDate, format=\"%m/%d/%Y %H:%M\")\ndf.StockCode=df.StockCode.str.upper() #to see if can separate some more\ndf.rename(columns={\"InvoiceDate\":'InvoiceDateTime'}, inplace=True)\ndf['InvoiceDate'] = pd.to_datetime([dt.datetime.date(d) for d in df['InvoiceDateTime']]) #to extract date only from datetime info\n#df['InvoiceTime'] = df['InvoiceDateTime'].dt.time #to extract time only from datetime info\ndf['mth_end_dt'] = df['InvoiceDate']+pd.offsets.MonthEnd(0) #to get month end date position\ndf.shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#summary of the numeric and object columns\nprint(df.describe(percentiles=[.01,.05,.25,.5,.75,.95,.99]))\ndf.describe(include=[np.object])"},{"cell_type":"markdown","source":"\nDiscoveries: \n1.Existence of outliers in Quantity. 99% of data have quantity up until 100 but max and min quantities are 5 figure digits. \n2.Existence of outliers in UnitPrice. Interquartile range of UnitPrices is between 0.42 sterling until 4.13 sterling however min and max UnitPrice are 5 figure digits. \n3.Existence of negative quantities and unitprices. \n4.Number of unique values and in each object columns.","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#We count the negative value of of quantity and Unit Price\nprint(\"The number of rows with negative Quantity:\",sum(n < 0 for n in df.Quantity))\nprint(\"The number of rows with negative UnitPrice:\",sum(n < 0 for n in df.UnitPrice))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#Count Unique value in all dataset columns\ndf.nunique()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#visualising Quantity\n#will someone consider modifying this into boxplot?\n\nplt.figure(figsize=(15,15))\n\nx=df.Quantity.value_counts().reset_index().as_matrix().transpose()\nplt.subplot(411) #1st digit #rows, 2nd digit #columns, 3rd digit plot number\nplt.scatter(x[0], x[1], marker='o')\nplt.title('Quantity plots',fontsize=15)\nplt.ylabel('Occurrence',fontsize=12)\n\nx=df[df['Quantity'].abs()<20000].Quantity.value_counts().reset_index().as_matrix().transpose()\nplt.subplot(412)\nplt.scatter(x[0], x[1], marker='o')\nplt.ylabel('Occurrence')\n\n#Based on 99th percentile\nx=df[df['Quantity'].abs()<100].Quantity.value_counts().reset_index().as_matrix().transpose()\nplt.subplot(413)\nplt.scatter(x[0], x[1], marker='o')\nplt.ylabel('Occurrence',fontsize=12)\n\n#Based on 3rd quartile\nx=df[df['Quantity'].abs()<10].Quantity.value_counts().reset_index().as_matrix().transpose()\nplt.subplot(414)\nplt.scatter(x[0], x[1], marker='o')\nplt.xlabel('Quantity',fontsize=12)\nplt.ylabel('Occurrence',fontsize=12)\n\nplt.show()"},{"cell_type":"markdown","source":"\nDiscovery: \n1.Most abs(Quantity)<20000 range. Each positive range also seem to have a negative equivalent counterpart","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#Identifying what is the equivalent counterpart while taking a look at the outliers.\ndf[df['Quantity'].abs()>60000]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":"\n#1.Quantity outliers due to customer making mistake in their order, and it has been cancelled. Can be removed from the #dataset. \n#2.The mistake order is offset by another transaction, given a different invoicedate and invoiceno. The only common field #shared is the stockcode, customerID and quantity ordered. \n#3. Invoices cancelled will have the letter C in front of the 6 digit invoiceno. "},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#Identifying what is the equivalent counterpart while taking a look at the outliers.\ndf[(df['Quantity'].abs()>5000) & (df['Quantity'].abs()<20000)]"},{"cell_type":"markdown","source":"#Discovery: \n#1.Length of stockcode is not restricted to 5 only. \n#2.Existence of non-existing and weird descriptions in Description field. \n#3.Existence of non-existing CustomerID.","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#Check how NaN values affect the dataset\nprint('Number of rows in each column affected by existence of non-existing values:')\ndf.isnull().sum()"},{"cell_type":"markdown","source":"#It seem like we have Nan of: \n#1454 in Description \n#135037 in Customer ID","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#Now lets check what is in our negative quantity\ndf[df[\"Quantity\"]<=0].head(10)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#Access all the NaN element in the Description discovered earlier when checking number of rows affected with missing values\n#from IPython.display import display, HTML\n#dfNADescription=df[df.Description.isnull()]\nprint('Descriptive statistics of numeric columns:\\n',df[df.Description.isnull()].describe())\nprint('\\nDescriptive statistics of CustomerID columns:\\n',df[df.Description.isnull()].CustomerID.describe())"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#plot price to see outliers\n#since describe reveal that min and max quantities are in the range >10000 as compared to most sections of the dataset\n\nplt.figure(figsize=(15,10))\n\nx=df.UnitPrice.value_counts().reset_index().as_matrix().transpose()\nplt.subplot(411)\nplt.scatter(x[0], x[1], marker='o')\nplt.title('UnitPrice plots',fontsize=15)\nplt.ylabel('Occurrence',fontsize=12)\n\nx=df[df['UnitPrice'].abs()<20000].UnitPrice.value_counts().reset_index().as_matrix().transpose()\nplt.subplot(412)\nplt.scatter(x[0], x[1], marker='o')\nplt.ylabel('Occurrence',fontsize=12)\n\n#99th-percentile\nx=df[df['UnitPrice'].abs()<18].UnitPrice.value_counts().reset_index().as_matrix().transpose()\nplt.subplot(413)\nplt.scatter(x[0], x[1], marker='o')\nplt.ylabel('Occurrence',fontsize=12)\n\n#3rd quartile\nx=df[df['UnitPrice'].abs()<4.13].UnitPrice.value_counts().reset_index().as_matrix().transpose()\nplt.subplot(414)\nplt.scatter(x[0], x[1], marker='o')\nplt.ylabel('Occurrence',fontsize=12)\nplt.xlabel('UnitPrice',fontsize=12)\n\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#Identifying what is the equivalent counterpart while taking a look at the outliers.\ndf[df['UnitPrice'].abs()>10000]"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#The stockcodes aren't linked to any other item purchases - single item per invoice.\ndf[df['InvoiceNo']=='537632']"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#Investigating stockcode and invoiceno fields based on discoveries made\n\n#defining the variables\ndf['length_stockcode']=df.StockCode.str.len()\ndf['length_invoiceno']=df.InvoiceNo.str.len()\ndf['invoiceno_letter1']=df['InvoiceNo'].str[0]\n\nprint(\"length of InvoiceNo:\\n\",df.length_invoiceno.value_counts(sort=True)\\\n      .reset_index(name='no_rows').rename(columns={'index':'length of InvoiceNo'}))\nprint(\"\\nFirst letter for invoice:\\n\",df.invoiceno_letter1.value_counts(sort=True)\\\n      .reset_index(name='no_rows').rename(columns={'index':'invoice first letter'}))\nprint(\"\\nCross table first letter for invoice against invoiceno length:\\n\"\\\n      ,pd.crosstab(df['invoiceno_letter1'],df['length_invoiceno'],margins=True))\nprint(\"\\nlength of StockCode:\\n\",df.length_stockcode.value_counts(sort=True)\\\n      .reset_index(name='no_rows').rename(columns={'index':'length of StockCode'})) "},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":"\n#Discoveries: \n#1.Invoice length is either 6 or 7; those with length 7 will start with letter A or C \n#2.Since most rows have StockCode of length 5 or 6, this is considered the legitimate StockCode referring to item description. \n#4.StockCode length is between 1 to 12 (excl. 10 and 11)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#display what are the unique stockcodes for invoiceno with length below 5 or above 8\nprint(\"\\nDescription for StockCode with length below 5 or above 8 and number of lines affected:\")\n      #\\n\"\\\n#      ,df[(df['length_stockcode']<5) | (df['length_stockcode']>8)]\\\n#      [['length_stockcode','invoiceno_letter1','StockCode','Description']]\\\n#      .groupby(by=['invoiceno_letter1','length_stockcode','StockCode']).Description.value_counts().reset_index(name='Freq'))\n\ndf[(df['length_stockcode']<5) | (df['length_stockcode']>8)]\\\n[['length_stockcode','invoiceno_letter1','StockCode','Description']]\\\n.groupby(by=['length_stockcode','StockCode','invoiceno_letter1']).Description.value_counts().reset_index(name='Freq')"},{"cell_type":"markdown","source":"\n#Descoveries: \n#1.Retailer is dotcomgiftshop. Gift voucher is part of their product offering. Website: https://www.dotcomgiftshop.com \n#2.StockCode with length<=4 have nothing to do with items at all. \n#3.In StockCodes with length 9 or 12, some descriptions does not refer to product item descriptions (AMAZONFEE and BANK CHARGES)","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#analysing stockcode and invoiceno field\n\n#display what are the unique stockcodes for invoiceno of length 7 or 8\nprint(\"\\nDescription for StockCode with length 7 or 8 and number of lines affected:\\n\")\ndf[(df['length_stockcode']==7) | (df['length_stockcode']==8)]\\\n[['length_stockcode','invoiceno_letter1','StockCode','Description']]\\\n.groupby(by=['length_stockcode','StockCode']).Description.value_counts().reset_index(name='freq')"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#From initial assessment, we found out most problematic description contain lower case letter and '?' symbol\ndf[df['Description'].str.contains(\"^[a-z]|\\\\?\",case=True, na=False)].\\\ndrop(['mth_end_dt','length_stockcode','length_invoiceno','invoiceno_letter1'],axis=1).head(20)"},{"cell_type":"markdown","source":"Seems like all the error description have:\n<br>1.null CustomerID \n<br>2.UnitPrice=0 \n<br>Test if using these criteria will only eliminate weird descriptions:","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"print('no of rows affected:',df[(df.CustomerID.isnull()) & (df['UnitPrice']==0)].shape[0])\ndf[(df.CustomerID.isnull()) & (df['UnitPrice']==0)]\\\n.Description.value_counts().reset_index(name='freq').rename(columns={'index':'Description'}).head(20)"},{"cell_type":"markdown","source":"Seems like it also removes some valid product descriptions, but these products have UnitPrices = 0 which is not expected. The file containing these transactions can be passed to data owner for investigation purposes.****","metadata":{}},{"cell_type":"markdown","source":"**DATA CLEANING**","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#perform modification on df1\ndf1=df.copy()\ndf1.shape"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#1. Separate missing description rows\ndf.NAdesc=df1[(df1.Description.isnull())]\nprint(df.NAdesc.shape)\ndf.NAdesc.to_csv('No descriptions.csv',index=False)\ndf1=df1[~(df1.Description.isnull())]\nprint(df1.shape)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#2. Separate length-stockcode<5, StockCode=['AMAZONFEE','BANK CHARGES']\ndf.otherdesc=df1[(df1['length_stockcode']<5) | (df1['StockCode']=='AMAZONFEE') \\\n                       | (df1['StockCode']=='BANK CHARGES')]\nprint(df.otherdesc.shape)\ndf.otherdesc.to_csv('Other descriptions.csv',index=False)\ndf1=df1[~((df1['length_stockcode']<5) | (df1['StockCode']=='AMAZONFEE') \\\n                       | (df1['StockCode']=='BANK CHARGES'))]\nprint(df1.shape)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#3. Remove rows that contain problematic description and UnitPrice=0 into a new file.\ndf.weird=df1[(df1.CustomerID.isnull()) & (df1['UnitPrice']==0)]\nprint(df.weird.shape)\ndf.weird.to_csv('weird description and or unitprice.csv',index=False)\ndf1=df1[~((df1.CustomerID.isnull()) & (df1['UnitPrice']==0))]\nprint(df1.shape)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#4. to remove Cancelled transactions into a separate dataset\ndf.Cancel=df1[df1['invoiceno_letter1']=='C']\nprint(df.Cancel.shape)\ndf.Cancel.to_csv('Cancelled Transactions v2.csv',index=False)\ndf1=df1[df1['invoiceno_letter1']!='C']\nprint(df1.shape)\n#we have 9251 row of cancelled transaction"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#1. Assign value to our missing customerID based on the Invoice Number\ndf1[\"CustomerID\"].fillna(\"R\"+df1[\"InvoiceNo\"], inplace=True)\ndf.CustomerID.value_counts(sort=True)\nNewID = df1.groupby(['CustomerID','Description']).sum()\nNewID.head()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#Check if there is any lowercase letter in stock code\ndf1[df1['StockCode'].str.contains(\"[a-z]\",case=True, na=False)]\n#No lowercase code"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#Now let check of negative Quantity\ndf1[df1[\"Quantity\"]<=0]\n#Our negative quantity is zero as most of our negative quantity are inside Nan Description that we removed earlier"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#we check if our problematic Description got removed by the drop negative and zero unit price\nfrom IPython.display import display, HTML\ndf1.prob=df1[df1['Description'].str.contains(\"^[a-z]|\\\\?\",case=True, na=False)]\ndf1.prob1=df1.prob.Description.str.split(expand=True).stack().value_counts().to_frame().reset_index()\nHTML(df1.prob1.to_html())\n#Our hypothesis is true as all the problematic description also got removed by our previous droping actvities"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#Now let check if the result of our cleaning process\ndf1.describe()\n# We no longer have negative value for our numeric column"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"df1.isnull().sum()\n#All our Nan have been removed from the description"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#Check if our new customer ID that been assigned with \"R\" + InvoiceNo\ndf1[df1['CustomerID'].str.contains(\"R\",case=False, na=False)]"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Check again for any Nan Value\ndf1.isnull().sum()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"df1.nunique()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"df1.StkDsc=df1.groupby(\"StockCode\")['Description'].nunique().reset_index()\ndf1stk=df1.StkDsc[df1.StkDsc[\"Description\"]>1]\ndf1stk.head()\n#We have 215 row of stock code that have more than 1 description"},{"cell_type":"markdown","source":"DATA VISUALIZATION\n","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly\nimport plotly.graph_objs as go\nimport plotly.plotly as py\nimport seaborn as sns\nplotly.tools.set_credentials_file(username='JLLam', api_key='rHULPcQZPrG6MrCNj0VC')\nplotly.tools.set_config_file(world_readable=True,sharing='public')"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":"df2 = df1.copy()\ndf2[\"Revenue\"]=df2[\"Quantity\"]*df2[\"UnitPrice\"]"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#Calculte the total Revenue thorught out the year\ndf2.Revenue.sum()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#Produce total revenue by months by descending value\ndf2.groupby(df2['InvoiceDate'].dt.strftime('%B %Y'))['Revenue'].sum().sort_values()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#Group the data set by days of month\ndf2.groupby(pd.Grouper(key='InvoiceDate', freq='D'))['Revenue'].sum().reset_index().sort_values('InvoiceDate')"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#Visualize visualize Revenue by Month\ntemp = df2.loc[:,('InvoiceDate','Revenue')]\ntemp.InvoiceDate = df2.InvoiceDate.dt.to_period('M')\ntemp = temp.groupby(['InvoiceDate'])['Revenue'].sum()\ntemp = temp.reset_index(drop = False)\n\n\nplt.figure(figsize=(15,5))\nplt.bar(np.arange(len(temp['InvoiceDate'])), temp['Revenue'], align='center', alpha=0.5)\nplt.xticks(np.arange(len(temp['InvoiceDate'])), temp['InvoiceDate'])\nplt.ylabel('Total Revenue',fontsize=14)\nplt.xlabel('Year-Month',fontsize=14)\nplt.title('Total Revenue by Month',fontsize=15)\n \nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#Now group the revenue by week\ndf2.RevWeek=df2.groupby(pd.Grouper(key='InvoiceDate', freq='W-MON'))['Revenue'].sum().reset_index().sort_values('InvoiceDate')\ndf2.RevWeek.head()"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# Now we combine our weekly revenue line chart with weekly revenue bar chart for better visualization\n#On the 4th week, there was no transaction\nRevenue1=df2.RevWeek.Revenue\nTime1 =df2.RevWeek.InvoiceDate\ndf2.RevWeek.plot(kind='bar', title =\"Total Revenue By Week\", figsize=(30, 20), legend=True, fontsize=20)\nplt.title('Total Revenue by Weeks',fontsize=30)\nplt.xlabel(\"Week\",fontsize=25)\nplt.ylabel(\"Revenue\",fontsize=25)\ndf2.RevWeek['Revenue'].plot(secondary_y=True,color=\"#8b0000\")\nplt.show()\n#we found out that our sales start to surge on week 41 onwards"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#We are going to investigate sales by days of the month\ndf_Dmonth=df2.copy()\ndf_Dmonth[\"day\"]=df_Dmonth[\"InvoiceDate\"].dt.day\n\ndf_Dmontha=df_Dmonth.groupby(\"day\")[\"Revenue\"].sum()\ndf_Dmontha.plot(kind='bar', title =\"V comp\", figsize=(30, 20), legend=True, fontsize=20)\nplt.title('Total Revenue by Days of Month',fontsize=30)\nplt.ylabel('Total Revenue', fontsize=30)\nplt.xlabel('Day of the Month', fontsize=30)\nplt.show()\n# we concluded that the sale surge at the earlu of the monthand  dwindle as it reach the end of month"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"#To visualize Revenue by Day of the week\ntemp = df2.loc[:,('InvoiceDate','Revenue','CustomerID','InvoiceNo')]\ntemp2 = temp.groupby(temp['InvoiceDate'].dt.weekday_name)['Revenue'].sum().sort_values()\ntemp2 = temp2.reset_index(drop = False).rename(columns={'InvoiceDate':'Day'})\n\n\nplt.figure(figsize=(20,10))\nplt.bar(np.arange(len(temp2['Day'])), temp2['Revenue'], align='center', alpha=0.5)\nplt.xticks(np.arange(len(temp2['Day'])), temp2['Day'])\nplt.ylabel('Total Revenue')\nplt.xlabel('Day')\nplt.title('Total Revenue by Day')\n \nplt.show()\n#Tuesday and thursday show the highest revenue, No revenue on Saturday"}],"nbformat_minor":1,"metadata":{"language_info":{"file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","version":"3.6.4"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4}