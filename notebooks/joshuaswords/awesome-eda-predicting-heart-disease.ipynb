{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Can we predict who will suffer a Heart Attack?\n\n\nI will first perform **data exploration** to see if there are any variables that look to be indicative of heart disease.\n\nNext, I will attempt to **predict** who will suffer a heart attack, and who will not.\n\n\nI will also go in to **Model interpretability**. This is important in industry as many are still skeptical about 'black-box' models and are hesitant to trust what they do not understand. \n\nLet's go...","metadata":{}},{"cell_type":"code","source":"# Importing libs\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.dates as mdates\nimport matplotlib.pyplot as plt\nfrom textwrap import wrap\nimport seaborn as sns\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport plotly as py\nimport plotly.graph_objs as go\nimport os\npy.offline.init_notebook_mode(connected = True)\n#print(os.listdir(\"../input\"))\nimport datetime as dt\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mtick\nimport matplotlib.gridspec as grid_spec\nimport seaborn as sns\nfrom imblearn.over_sampling import SMOTE\nimport scikitplot as skplt\n\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder\nfrom sklearn.model_selection import train_test_split,cross_val_score\n\n\nfrom sklearn.linear_model import LinearRegression,LogisticRegression\nfrom sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score, recall_score, roc_auc_score, precision_score, f1_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.preprocessing import StandardScaler\n# data splitting\nfrom sklearn.model_selection import train_test_split\n# data modeling\nfrom sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n#ensembling\nfrom mlxtend.classifier import StackingCVClassifier","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/heart-attack-analysis-prediction-dataset/heart.csv')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Blank Data?\n\nThere are no blanks in our dataset","metadata":{}},{"cell_type":"code","source":"data.isnull().sum().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No blanks in the data - we're good to go!","metadata":{}},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Renaming columns for aesthetic purposes","metadata":{}},{"cell_type":"code","source":"# Renaming columns.\ndata.columns = ['Age', 'Sex', 'Chest Pain Type', 'Resting Blood Pressure', 'Cholesterol', 'Fasting Blood Sugar', 'Resting ECG', 'Max. HR Acheived',\n       'Exercise Induced Angina', 'ST Depression', 'ST Slope', 'Num. Major Blood Vessels', 'Thalassemia', 'Condition']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Important:** Features swapped\n\nMy research suggests that the features in this dataset are incorrectly labelled, therefore I will swicth them round.","metadata":{}},{"cell_type":"code","source":"# Swapped targets around as my reserach indicates that these have been labelled incorrectly\n\ndata['Condition'] = data['Condition'].apply(lambda x: 1 if x == 0 else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our conditions are fairly balanced, so we do not need to do any synthetic upsampling","metadata":{}},{"cell_type":"code","source":"data['Condition'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Catergorical & Continuous split\n\n# Ordinarily I'd use this function, however our categorical data is already in encoded form\n# so today it is not applicable \n\n#categorical = [varibale for variable in df.columns if df[variable].dtype=='O']\n# using 4 based on the df.nunique results above\n\ncategorical = data.loc[:,data.nunique()<=4]\ncontinuous = data.loc[:,data.nunique()>4]","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"background_color = \"#fafafa\"\nface_color = '#fafafa'\n\n\nyes_c='#9b1b30'\nno_c='#009473'\nneut_c ='#112e51'\n\nsub_col = '#a49a93'","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"markdown","source":"Can we discover interesting features?\n\nCan we start to understand what causes heart disease?","metadata":{}},{"cell_type":"markdown","source":"**Colors**\n\nI will be using **red** for explicit positive cases, **green** for explicit no cases, and **gold** for neutral, ie. general overviews & observations","metadata":{}},{"cell_type":"code","source":"sns.palplot([yes_c,no_c,'gold'])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=data.groupby(['Condition'])['Condition'].count()\ny=len(data)\nr=((x/y)).round(2)\n\nratio = pd.DataFrame(r).T\n\nfig = plt.figure(figsize=(8, 10), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(5, 1)\ngs.update(wspace=0.02, hspace=0.8)\nax = fig.add_subplot(gs[0, 0])\n\n\n\nax.set_facecolor(background_color)\n\nax.barh(ratio.index, ratio[1.0], color=yes_c, alpha=0.9, label='Condition')\nax.barh(ratio.index, ratio[0.0], left=ratio[1.0], color=no_c, alpha=0.9, label='No Condition')\n\nax.set_xlim(0, 1)\nax.set_xticks([])\nax.set_yticks([])\n#ax.set_yticklabels(mf_ratio.index, fontfamily='serif', fontsize=11)\n\n\nfor i in ratio.index:\n    ax.annotate(f\"{int(ratio[1.0][i]*100)}%\", \n                   xy=(ratio[1.0][i]/2, i),\n                   va = 'center', ha='center',fontsize=32, fontweight='light', fontfamily='monospace',\n                   color='white')\n\n    ax.annotate(\"Condition\", \n                   xy=(ratio[1.0][i]/2, -0.25),\n                   va = 'center', ha='center',fontsize=12, fontweight='light', fontfamily='monospace',\n                   color='white')\n    \n    \nfor i in ratio.index:\n    ax.annotate(f\"{int(ratio[0.0][i]*100)}%\", \n                   xy=(ratio[1.0][i]+ratio[0.0][i]/2, i),\n                   va = 'center', ha='center',fontsize=32, fontweight='light', fontfamily='monospace',\n                   color='white')\n    ax.annotate(\"No Condition\", \n                   xy=(ratio[1.0][i]+ratio[0.0][i]/2, -0.25),\n                   va = 'center', ha='center',fontsize=12, fontweight='light', fontfamily='monospace',\n                   color='white')\n\n\n\n# Title & Subtitle\nax.text(0,0.75,'How many have a heart condition in our dataset?',fontsize=15, fontweight='bold',fontfamily='sansserif')\nax.text(0,0.6,'We see a fairly balanced dataset, but this in itself raises questions.',fontsize=8,fontfamily='monospace')  \n\nfor s in ['top', 'left', 'right', 'bottom']:\n    ax.spines[s].set_visible(False)\n    \n#ax.legend(loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.06))\n\n# Removing legend due to labelled plot\nax.legend().set_visible(False)\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The splits shown above does raise questions. \n\nOn average, approx. 3% of people are affected by heart disease in the USA. Whereas here, it is verginf on 50%. That raises questions as to what population of people we are looking at - this is all important information in our 'data prediction story'","metadata":{}},{"cell_type":"code","source":"!pip install pywaffle","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nimport matplotlib.pyplot as plt\nfrom pywaffle import Waffle\n\nfig = plt.figure(figsize=(5, 5),dpi=150,facecolor=background_color,\n    FigureClass=Waffle,\n    rows=10,\n    values=[3, 97],\n    colors=[yes_c, \"lightgray\"],\n    characters='⬤',\n    font_size=20,vertical=True,\n)\n\nfig.text(0.035,1.06,'People Affected by\\nHeart Disease [USA Average]',fontfamily='sanserif',fontsize=15,fontweight='bold')\nfig.text(0.035,1.01,'In the USA, this is around 3 in 100 people per year.',fontfamily='monospace',fontsize=10)\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Comparing this against our dataset, we see a **huge** difference...","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(5, 5),dpi=150,facecolor=background_color,\n    FigureClass=Waffle,\n    rows=10,\n    values=[46, 54],\n    colors=[yes_c, \"lightgray\"],\n    characters='⬤',\n    font_size=20,vertical=True,\n)\n\nfig.text(0.035,1.09,'People Affected by\\nHeart Disease [Dataset Average]',fontfamily='sanserif',fontsize=15,fontweight='bold')\nfig.text(0.035,1.01,'In our dataset, this is around 46 in 100 people,\\na much higher rate.',fontfamily='monospace',fontsize=10)\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This isn't necessarily a problem, it's just something for us to be aware of.\n\n# Let's view the data as a whole now","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(15, 3), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(1, 6)\ngs.update(wspace=0.1, hspace=0.4)\n\n# for plotting\ndf = data\n\nrun_no = 0\nfor row in range(0, 1):\n    for col in range(0, 6):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        locals()[\"ax\"+str(run_no)].tick_params(axis='y', left=False)\n        locals()[\"ax\"+str(run_no)].get_yaxis().set_visible(False)\n        for s in [\"top\",\"right\",\"left\"]:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\nrun_no = 0\nfor variable in continuous:\n        sns.kdeplot(df[variable] ,ax=locals()[\"ax\"+str(run_no)], color='gold',ec='black', shade=True, linewidth=1.5, alpha=0.9, zorder=3, legend=False)\n        locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='gray', linestyle=':', dashes=(1,5))\n        locals()[\"ax\"+str(run_no)].set_xlabel(variable)\n        run_no += 1\n        \n\nXstart, Xend = ax0.get_xlim()\nYstart, Yend = ax0.get_ylim()\nax0.text(Xstart, Yend+(Yend*0.15), 'Numeric Variable Distribution', fontsize=20, fontweight='bold', fontfamily='sans-serif')\nax0.text(Xstart, Yend+(Yend*0.05), 'Most numeric variables appear to have a positive skew', fontsize=13, fontweight='light', fontfamily='monospace')\n\nplt.show()\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can also add in the condition to see if there is anything we can infer from each of the features.\n\nFor example, is Age important in determining risk of heart disease?","metadata":{}},{"cell_type":"code","source":"\nfig = plt.figure(figsize=(15, 3), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(1, 6)\ngs.update(wspace=0.1, hspace=0.4)\n\n# for plotting\ndf = data\n\nrun_no = 0\nfor row in range(0, 1):\n    for col in range(0, 6):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        locals()[\"ax\"+str(run_no)].tick_params(axis='y', left=False)\n        locals()[\"ax\"+str(run_no)].get_yaxis().set_visible(False)\n        locals()[\"ax\"+str(run_no)].set_axisbelow(True)\n        for s in [\"top\",\"right\",\"left\"]:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\nrun_no = 0\n\nYes = df[df['Condition'] == 1]\nNo = df[df['Condition'] == 0]\n\nfor variable in continuous:\n        sns.kdeplot(Yes[variable], ax=locals()[\"ax\"+str(run_no)], color=yes_c,ec='black', shade=True, linewidth=1.5, alpha=0.9, zorder=3, legend=False)\n        sns.kdeplot(No[variable],ax=locals()[\"ax\"+str(run_no)], color=no_c, shade=True, ec='black',linewidth=1.5, alpha=0.9, zorder=3, legend=False)\n        locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='gray', linestyle=':', dashes=(1,5))\n        locals()[\"ax\"+str(run_no)].set_xlabel(variable)\n        run_no += 1\n        \nXstart, Xend = ax0.get_xlim()\nYstart, Yend = ax0.get_ylim()\nax0.text(Xstart, Yend+(Yend*0.15), 'Numeric Variable Distribution with Condition', fontsize=20, fontweight='bold', fontfamily='sansserif')\nax0.text(Xstart, Yend+(Yend*0.05), 'There appear to be noticeable differences when patients have a heart condition.', fontsize=13, fontweight='light', fontfamily='monospace')\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We do see some differences between conditions. In particularm Num. Major Blood Vessels, Age, & Max. HR Acheived look to be very important.\n\nWe can explore these more later as it does seems like this will be useful for our models.\n\nFirst, I want to zoom in on two noticeable plots...","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 5), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(2, 2)\ngs.update(wspace=0.11, hspace=0.5)\nax0 = fig.add_subplot(gs[0, 0])\nax1 = fig.add_subplot(gs[0, 1])\n\n\nax0.tick_params(axis='y', left=False)\nax0.get_yaxis().set_visible(False)\nax0.set_axisbelow(True)\nax1.tick_params(axis='y', left=False)\nax1.get_yaxis().set_visible(False)\nax1.set_axisbelow(True)\nfor s in [\"top\",\"right\",\"left\"]:\n        ax0.spines[s].set_visible(False)\n        ax1.spines[s].set_visible(False)\n\nax0.set_facecolor(face_color)\nax1.set_facecolor(face_color)\n\n\nsns.kdeplot(Yes['Num. Major Blood Vessels'], ax=ax1, color=yes_c,ec='black', shade=True, linewidth=1.5, alpha=0.9, zorder=3, legend=False)\nsns.kdeplot(No['Num. Major Blood Vessels'],ax=ax1, color=no_c, shade=True, ec='black',linewidth=1.5, alpha=0.9, zorder=3, legend=False)\n \nsns.kdeplot(Yes['Max. HR Acheived'], ax=ax0, color=yes_c,ec='black', shade=True, linewidth=1.5, alpha=0.9, zorder=3, legend=False)\nsns.kdeplot(No['Max. HR Acheived'],ax=ax0, color=no_c, shade=True, ec='black',linewidth=1.5, alpha=0.9, zorder=3, legend=False)\n\n\nax0.grid(which='major', axis='x', zorder=0, color='gray', linestyle=':', dashes=(1,5))\nax1.grid(which='major', axis='x', zorder=0, color='gray', linestyle=':', dashes=(1,5))\n\n\nXstart, Xend = ax0.get_xlim()\nYstart, Yend = ax0.get_ylim()\nax0.text(Xstart, Yend+(Yend*0.2), 'Important Observations', fontsize=15, fontweight='bold', fontfamily='sansserif')\nax0.text(Xstart, Yend+(Yend*0.09), 'Max. HR Acheived & Num. Major Blood Vessels look to be highly indicatvie of heart disease.', fontsize=8, fontweight='light', fontfamily='monospace')\n\nplt.show()    ","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like these two variables have a strong imapct. \n\nThey will likely become important features for our model later on.\n\n# Categorical variables\n\nNow I will explore categorical variables.\n\nFirst, I will view overall counts, then I will split by condition as I did with the continuous variables","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(15, 3), dpi=150, facecolor=background_color)\ngs = fig.add_gridspec(2, 5)\ngs.update(wspace=0.1, hspace=0.7)\n\n\nrun_no = 0\nfor row in range(0, 2):\n    for col in range(0, 4):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        locals()[\"ax\"+str(run_no)].tick_params(axis='y', left=False)\n        locals()[\"ax\"+str(run_no)].get_yaxis().set_visible(False)\n        locals()[\"ax\"+str(run_no)].set_axisbelow(True)\n        for s in [\"top\",\"right\",\"left\"]:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\nrun_no = 0\nfor variable in categorical:\n        sns.countplot(df[variable],data=df,ax=locals()[\"ax\"+str(run_no)], color='gold',ec='black', linewidth=1.5, alpha=1,)\n        locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='gray', linestyle=':', dashes=(1,5))\n        locals()[\"ax\"+str(run_no)].set_xlabel(variable)\n        run_no += 1\n\n\nXstart, Xend = ax0.get_xlim()\nYstart, Yend = ax0.get_ylim()\nax0.text(Xstart, Yend+(Yend*0.6), 'Categorical Variable Distribution', fontsize=20, fontweight='bold', fontfamily='sans-serif')\nax0.text(Xstart, Yend+(Yend*0.3), 'This gives an indication of what we might want to investigate.', fontsize=13, fontweight='light', fontfamily='monospace')\n\n\nplt.show()\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So above we see how common or uncommon certain categories are.\n\nFor example, category 2 of Resting ECG is very uncommon.\n\nBut how does the Condition variable present it self with respect to each of these features? Can we learn anything?","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(15, 3), dpi=150, facecolor=background_color)\ngs = fig.add_gridspec(2, 5)\ngs.update(wspace=0.1, hspace=0.7)\n\n\nrun_no = 0\nfor row in range(0, 2):\n    for col in range(0, 4):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        locals()[\"ax\"+str(run_no)].tick_params(axis='y', left=False)\n        locals()[\"ax\"+str(run_no)].get_yaxis().set_visible(False)\n        locals()[\"ax\"+str(run_no)].set_axisbelow(True)\n        for s in [\"top\",\"right\",\"left\"]:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1\n\nrun_no = 0\nfor variable in categorical:\n        sns.countplot(df[variable],data=df,ax=locals()[\"ax\"+str(run_no)],hue='Condition',palette=[no_c,yes_c],ec='black', linewidth=1.5, alpha=1)\n        locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='gray', linestyle=':', dashes=(1,5))\n        locals()[\"ax\"+str(run_no)].set_xlabel(variable)\n        locals()[\"ax\"+str(run_no)].get_legend().remove()\n        run_no += 1\n\n\nXstart, Xend = ax0.get_xlim()\nYstart, Yend = ax0.get_ylim()\nax0.text(Xstart, Yend+(Yend*0.85), 'Categorical Variable Distribution with Condition', fontsize=20, fontweight='bold', fontfamily='sans-serif')\nax0.text(Xstart, Yend+(Yend*0.3), 'This is very informative; several variables look to be related to the presence\\nof the condition.', fontsize=13, fontweight='light', fontfamily='monospace')\n\n\nplt.show()\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"again, let's now zoom in to a couple of standout observations...","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 5), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(2, 2)\ngs.update(wspace=0.11, hspace=0.5)\nax0 = fig.add_subplot(gs[0, 0])\nax1 = fig.add_subplot(gs[0, 1])\n\n\nax0.tick_params(axis='y', left=False)\nax0.get_yaxis().set_visible(False)\nax0.set_axisbelow(True)\nax1.tick_params(axis='y', left=False)\nax1.get_yaxis().set_visible(False)\nax1.set_axisbelow(True)\nfor s in [\"top\",\"right\",\"left\"]:\n        ax0.spines[s].set_visible(False)\n        ax1.spines[s].set_visible(False)\n\nax0.set_facecolor(face_color)\nax1.set_facecolor(face_color)\n\n\nsns.countplot(df['Thalassemia'], hue=df['Condition'],palette=[no_c,yes_c], ax=ax0, color=yes_c,ec='black', linewidth=1.5, alpha=1)\n \nsns.countplot(df['ST Slope'], hue=df['Condition'],palette=[no_c,yes_c], ax=ax1, color=yes_c,ec='black', linewidth=1.5, alpha=1)\n\n\nax0.grid(which='major', axis='x', zorder=0, color='gray', linestyle=':', dashes=(1,5))\nax1.grid(which='major', axis='x', zorder=0, color='gray', linestyle=':', dashes=(1,5))\n\n\nXstart, Xend = ax0.get_xlim()\nYstart, Yend = ax0.get_ylim()\nax0.text(Xstart, Yend+(Yend*0.3), 'Important Observations', fontsize=15, fontweight='bold', fontfamily='sansserif')\nax0.text(Xstart, Yend+(Yend*0.09), 'Thalassemia & ST Slope values look to be highly indicatvie of heart disease, and indeed of being at lower risk\\nin the case of some values.', fontsize=8, fontweight='light', fontfamily='monospace')\n\nax0.get_legend().remove()\nax1.get_legend().remove()\n\nax0.annotate('Large differences', xy=(1.4, 84), xytext=(0.2, 84), xycoords='data', \n            fontsize=8, ha='center', va='center',fontfamily='monospace',\n            bbox=dict(boxstyle='round', fc='firebrick'),\n            arrowprops=dict(arrowstyle='-[, widthB=4.6, lengthB=1', lw=1, color='black'), color='white')\n\n\nplt.show()     ","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nThis is the power of data visualization, we have been able to tease out important variables and begin to understand **potential** causes of heart disease.\n\n\n# How does risk vary when our variables change?\n\nThe below is a really valuable way of seeing **how risk changes with our variables**, and if there are any inflection points of change.\n","metadata":{}},{"cell_type":"code","source":"\nfig = plt.figure(figsize=(10, 5), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(2, 2)\ngs.update(wspace=0.11, hspace=0.5)\nax0 = fig.add_subplot(gs[0, 0])\nax1 = fig.add_subplot(gs[0, 1])\nax2 = fig.add_subplot(gs[1, 0])\nax3 = fig.add_subplot(gs[1, 1])\n\n\nax0.set_facecolor(face_color)\nax1.set_facecolor(face_color)\nax2.set_facecolor(face_color)\nax3.set_facecolor(face_color)\n\n\ncummulate_survival_ratio = []\n\nfor i in range(data['Resting Blood Pressure'].min(), data['Resting Blood Pressure'].max()):\n    cummulate_survival_ratio.append(data[data['Resting Blood Pressure'] < i]['Condition'].sum() / len(data[data['Resting Blood Pressure'] < i]['Condition']))\n\nsns.lineplot(data=cummulate_survival_ratio,color=yes_c,ax=ax0)\n\n\nimport matplotlib.patches as patches\n    \nXstart, Xend = ax0.get_xlim()\nYstart, Yend = ax0.get_ylim()\n\n\n\n# Create a Rectangle patch\nrect = patches.Rectangle((Xstart-1, 0.5),Xend+100, Yend+10, linewidth=1,\n                         edgecolor='lightgray', facecolor=\"#eeeeee\")\n  \n# Add the patch to the Axes\nax0.add_patch(rect)\n\n\n\n\n#ax0.text(Xstart,Yend+(Yend*0.1),'Resting Blood Pressure',fontfamily='serif',color='black',fontsize=10)\n\n###################\n\ncummulate_survival_ratio = []\n\nfor i in range(data['Cholesterol'].min(), data['Cholesterol'].max()):\n    cummulate_survival_ratio.append(data[data['Cholesterol'] < i]['Condition'].sum() / len(data[data['Cholesterol'] < i]['Condition']))\n\nsns.lineplot(data=cummulate_survival_ratio,color=yes_c,ax=ax1)\n\nXstart, Xend = ax1.get_xlim()\nYstart, Yend = ax1.get_ylim()\n\n# Create a Rectangle patch\nrect = patches.Rectangle((Xstart-1, 0.5),Xend+100, Yend, linewidth=1,\n                         edgecolor='lightgray', facecolor=\"#eeeeee\")\n  \n# Add the patch to the Axes\nax1.add_patch(rect)\n\n\n#ax1.text(Xstart,Yend+(Yend*0.1),'Cholesterol',fontfamily='serif',color='black',fontsize=10)\n\n###################\n\n\ncummulate_survival_ratio = []\n\nfor i in range(data['Max. HR Acheived'].min(), data['Max. HR Acheived'].max()):\n    cummulate_survival_ratio.append(data[data['Max. HR Acheived'] < i]['Condition'].sum() / len(data[data['Max. HR Acheived'] < i]['Condition']))\n\nsns.lineplot(data=cummulate_survival_ratio,color=yes_c,ax=ax2)\n\nXstart, Xend = ax2.get_xlim()\nYstart, Yend = ax2.get_ylim()\n\n# Create a Rectangle patch\nrect = patches.Rectangle((Xstart-1, 0.5),Xend+100, Yend, linewidth=1,\n                         edgecolor='lightgray', facecolor=\"#eeeeee\")\n  \n# Add the patch to the Axes\nax2.add_patch(rect)\n\n#ax2.text(Xstart,1.1,'Max. HR Acheived',fontfamily='serif',color='black',fontsize=10)\n\n\n###################\n\n\ncummulate_survival_ratio = []\n\nfor i in range(data['Age'].min(), data['Age'].max()):\n    cummulate_survival_ratio.append(data[data['Age'] < i]['Condition'].sum() / len(data[data['Age'] < i]['Condition']))\n\nsns.lineplot(data=cummulate_survival_ratio,color=yes_c,ax=ax3)\n\nXstart, Xend = ax3.get_xlim()\nYstart, Yend = ax3.get_ylim()\n\n# Create a Rectangle patch\nrect = patches.Rectangle((Xstart-1, 0.5),Xend+100, Yend+10, linewidth=1,\n                         edgecolor='lightgray', facecolor=\"#eeeeee\")\n  \n# Add the patch to the Axes\nax3.add_patch(rect)\n\n#ax3.text(Xstart,Yend+(Yend*0.1),'Age',fontfamily='serif',color='black',fontsize=10)\n\n###################\n\n\nfor s in [\"top\",\"right\",\"left\"]:\n    ax0.spines[s].set_visible(False)\n    ax1.spines[s].set_visible(False)\n    ax2.spines[s].set_visible(False)\n    ax3.spines[s].set_visible(False)\n    \n\nax0.set_yticks(np.arange(0, 1.25, 0.25))\nax1.set_yticks(np.arange(0, 1.25, 0.25))\nax2.set_yticks(np.arange(0, 1.25, 0.25))\nax3.set_yticks(np.arange(0, 1.25, 0.25))\n\nax0.tick_params(axis='both', which='major', labelsize=8)\nax0.tick_params(axis='both', colors=sub_col)\nax0.tick_params(axis=u'both', which=u'both',length=0)\n\nax1.tick_params(axis='both', which='major', labelsize=8)\nax1.tick_params(axis='both', colors=sub_col)\nax1.tick_params(axis=u'both', which=u'both',length=0)\n\nax2.tick_params(axis='both', which='major', labelsize=8)\nax2.tick_params(axis='both', colors=sub_col)\nax2.tick_params(axis=u'both', which=u'both',length=0)\n\nax3.tick_params(axis='both', which='major', labelsize=8)\nax3.tick_params(axis='both', colors=sub_col)\nax3.tick_params(axis=u'both', which=u'both',length=0)\n\n\n\n\n###############\nax0.set_xlabel(\"Resting Blood Pressure\",loc='left',fontsize=10,fontfamily='sans-serif')\nax1.set_xlabel(\"Cholesterol\",loc='left',fontsize=10,fontfamily='sans-serif')\nax2.set_xlabel(\"Max. HR Acheived\",loc='left',fontsize=10,fontfamily='sans-serif')\nax3.set_xlabel(\"Age\",loc='left',fontsize=10,fontfamily='sans-serif')\n\n\n\n#ax2.set_ylabel(\" \",loc='top',fontsize=sub,color=sub_col)\n\n#title\nax0.text(Xstart,1.4,'How does risk vary by each variable as it changes?',fontfamily='sans-serif',color='black',fontweight='bold',fontsize=15)\nax0.text(Xstart,1.25,\n'''\nThe grey box denotes where risk is greater than 50%.'''\n         \n,fontfamily='monospace',fontsize=8)\n\nax1.set_yticklabels([])\nax3.set_yticklabels([])\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Observations\n\nSo far we have established a few important points.\n\n1 - As resting blood pressure increasres, so to does risk of heart disease\n\n2 - Rising Choloseterol does not appear to be a major indicator\n\n3 - A low Max HR acheived is a big warning sign. \n\n4 - Risk of heart disease increases with age\n\nCan we build a feature that incorporates these observations?\n","metadata":{}},{"cell_type":"markdown","source":"Let's also look how these important variables interact with eachother","metadata":{}},{"cell_type":"code","source":"\nfig = plt.figure(figsize=(10, 5), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(2, 3)\ngs.update(wspace=0.3, hspace=0.5)\nax0 = fig.add_subplot(gs[0, 0])\nax1 = fig.add_subplot(gs[0, 1])\nax2 = fig.add_subplot(gs[0, 2])\n\n\n\nax0.set_facecolor(face_color)\nax1.set_facecolor(face_color)\nax2.set_facecolor(face_color)\n\n\nsns.scatterplot(data=data,x=data['Age'],y=data['Resting Blood Pressure'],hue=data['Condition'],ec='black',ax=ax0,palette=[no_c,yes_c])\nsns.scatterplot(data=data,x=data['Age'],y=data['Max. HR Acheived'],hue=data['Condition'],ec='black',ax=ax1,palette=[no_c,yes_c])\nsns.scatterplot(data=data,x=data['Age'],y=data['Cholesterol'],hue=data['Condition'],ec='black',ax=ax2,palette=[no_c,yes_c])\n\n\nax0.tick_params(axis='both', which='major', labelsize=8)\nax0.tick_params(axis='both', colors=sub_col)\nax0.tick_params(axis=u'both', which=u'both',length=0)\n\nax1.tick_params(axis='both', which='major', labelsize=8)\nax1.tick_params(axis='both', colors=sub_col)\nax1.tick_params(axis=u'both', which=u'both',length=0)\n\nax2.tick_params(axis='both', which='major', labelsize=8)\nax2.tick_params(axis='both', colors=sub_col)\nax2.tick_params(axis=u'both', which=u'both',length=0)\n\n\n\n\n\nfor s in [\"top\",\"right\",\"left\"]:\n    ax0.spines[s].set_visible(False)\n    ax1.spines[s].set_visible(False)\n    ax2.spines[s].set_visible(False)\n\n    \n###############\nax0.set_xlabel(\"Age\",loc='left',fontsize=10,color=sub_col)\nax1.set_xlabel(\"\",loc='left',fontsize=10,color=sub_col)\nax2.set_xlabel(\"\",loc='left',fontsize=10,color=sub_col)\n\nax0.set_ylabel(\"Rest. BP.\",loc='top',fontsize=10,color=sub_col)\nax1.set_ylabel(\"Max. HR.\",loc='top',fontsize=10,color=sub_col)\nax2.set_ylabel(\"Chol.\",loc='top',fontsize=10,color=sub_col)\n\n\nax0.text(20,254,'How do the variables interact?',fontsize=15,fontfamily='sansserif',fontweight='bold')\nax0.text(20,237.5,'The strongest relationship appears to be between Age & Max HR.',fontsize=10,fontfamily='monospace')\n\nax0.get_legend().remove()\nax1.get_legend().remove()\nax2.get_legend().remove()\n\nax0.text(20,220,'Heart Disease',fontsize=8,fontfamily='sansserif',color=yes_c)\nax0.text(40,220,'|',fontsize=8,fontfamily='serif')\nax0.text(41.5,220,'No Heart Disease',fontsize=8,fontfamily='sansserif',color=no_c)\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# What about Gender?","metadata":{}},{"cell_type":"markdown","source":"Are there risk differences between the genders?\n\nWe aren't told in the dataset if Male is 1 or 0, so I will leave the data as 1 or 0. ","metadata":{}},{"cell_type":"code","source":"# Function from Subin An \n# https://www.kaggle.com/subinium/tps-apr-highlighting-the-data\n\ndef age_band(num):\n    for i in range(1, 100):\n        if num < 10*i :  return f'{(i-1) * 10} ~ {i*10}'\n\ndata['Age band'] = data['Age'].apply(age_band)\nhr_age = data[['Age band', 'Condition','Sex']].groupby('Age band')['Condition'].value_counts().sort_index().unstack().fillna(0)\nhr_age['Condition rate'] = hr_age[1] / (hr_age[0] + hr_age[1]) * 100\nage_band = data['Age band'].value_counts().sort_index()\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age_sex_surv = data.groupby(['Sex','Age band'])['Condition'].mean().unstack().T\nfem_mean = age_sex_surv[0].mean()\nmale_mean = age_sex_surv[1].mean()\n\nfig = plt.figure(figsize=(5, 4), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(1, 1)\ngs.update(wspace=0.2, hspace=0.8)\nax0 = fig.add_subplot(gs[0, 0])\n\nax0.set_facecolor(face_color)\n\nfor s in [\"right\", \"top\",\"bottom\",\"left\"]:\n    ax0.spines[s].set_visible(False)\n\nmy_range=range(1,len(age_sex_surv.index)+1)\n \nax0.hlines(y=my_range, xmin=age_sex_surv[1], xmax=age_sex_surv[0], color='gray', alpha=0.4)\nsns.scatterplot(age_sex_surv[1], my_range, color=yes_c, ec='black',alpha=1,s=100, label='male',ax=ax0)\n\nsns.scatterplot(age_sex_surv[0], my_range, color=no_c,ec='black', alpha=1,s=100, label='female',ax=ax0)\nax0.get_legend().remove()\n\nXstart, Xend = ax0.get_xlim()\nYstart, Yend = ax0.get_ylim()\nax0.set_xticks(np.arange(0, 1, 0.1))\nax0.set_yticklabels([' ','20 ~ 30', '30 ~ 40', '40 ~ 50', '50 ~ 60','60 ~ 70', '70 ~ 80', '80 ~ 90'])\n\n\nax0.tick_params(axis='x', which='major', labelsize=8)\nax0.tick_params(axis='both', colors=sub_col)\nax0.tick_params(axis=u'both', which=u'both',length=0)\n\nax0.set_xlabel(\"Risk of having heart disease\",loc='left',fontsize=8,color=sub_col)\n\n\nax0.text(-0.04,7.6,'Condition rates by age & sex',fontsize=15,fontweight='bold',color='black',fontfamily='sansserif')\nax0.text(-0.04,6.7,'The sex is not specified in the data, but it looks to be \\nan important factor, with red being higher risk in all \\ncategories and a higher mean risk.',fontsize=10,fontfamily='monospace')\n\n#ax0.text(0,7,'Male',fontsize=8,fontweight='bold',color=yes_c,fontfamily='serif')\n#ax0.text(0+0.037,7,'|',fontsize=8,fontweight='bold',color='black',fontfamily='serif')\n#ax0.text(0+0.0436,7,'Female',fontsize=8,fontweight='bold',color=no_c,fontfamily='serif')\n\nax0.axvline(male_mean ,color=yes_c, linewidth=0.4, linestyle='dashdot')\nax0.axvline(fem_mean ,color=no_c, linewidth=0.4, linestyle='dashdot')\n\n\n# Show the graph\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the purposes of this project, and using some background research, let's assume the red category is Male.\n","metadata":{}},{"cell_type":"code","source":"data.groupby(['Sex'])['Condition'].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.graphics.mosaicplot import mosaic\n\nfig = plt.figure(figsize=(10, 5), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(2, 2)\ngs.update(wspace=0.11, hspace=0.5)\nax0 = fig.add_subplot(gs[0, 0])\n\nax0.set_facecolor(face_color)\n\nprops = lambda key: {'color': yes_c if 'Condition' in key else  no_c}\n\ngap = [0.01,0.025]\n\ndata_mos = {('Female', 'No Condition'): 0.75, ('Female', 'Condition'): 0.25, ('Male', 'No Condition'): 0.45, ('Male', 'Condition'): 0.55}\nmosaic(data_mos, gap=gap,properties=props,axes_label=False,ax=ax0)\n\n\nax0.text(0,1.23,'Mosaic Plot: Male & Female Risk',fontsize=15, fontweight='bold',fontfamily='sansserif',color='black')\nax0.text(0,1.1,'Male & female split by condition.',fontsize=10, fontfamily='monospace')\n\nax0.annotate('''\nWe see that males have a much higher\nrisk of having heart disease than \ndo females. \n\nThis will likely be an important\nfeature for use in predictive models\nlater on.\n''', xy=(1, 0.5), xytext=(1.4, 0.5), xycoords='data', \n            fontsize=8, ha='center', va='center',fontfamily='monospace',\n            bbox=dict(boxstyle='round', fc='firebrick'),\n            arrowprops=dict(arrowstyle='-[, widthB=7.3, lengthB=1', lw=1, color='black'), color='white')\n\n\n\nplt.show()\n\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Next steps\n\nwe can now use our new-found understanding to start to build a model that will seek to predict who will suffer from heart disease, and who will not...","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"I want to build some features that might help our model.\n\nI'll use the median values to help with this","metadata":{}},{"cell_type":"code","source":"print('Median Values:')\nfor i in continuous:\n    print(i,data[i].median())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Age_gr_med'] = data['Age'].apply(lambda x: 1 if x > data['Age'].median() else 0)\ndata['mhr_lr_med'] = data['Max. HR Acheived'].apply(lambda x: 1 if x < data['Max. HR Acheived'].median() else 0)\n\n\ndata['Age_MaxHR'] = data['Age_gr_med'] + data['mhr_lr_med']\ndata['Age_MaxHR_dum'] = data['Age_MaxHR'].apply(lambda x: 1 if x == 2 else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop('Age_MaxHR',inplace=True, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"code","source":"# model libs\n\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder\nfrom sklearn.model_selection import train_test_split,cross_val_score\n\n\nfrom sklearn.linear_model import LinearRegression,LogisticRegression\nfrom sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score, recall_score, roc_auc_score, precision_score, f1_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.preprocessing import StandardScaler\n# data splitting\nfrom sklearn.model_selection import train_test_split\n# data modeling\nfrom sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n#ensembling\nfrom mlxtend.classifier import StackingCVClassifier","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# spltting the data\n\nX = data[['Age', 'Sex', 'Chest Pain Type', 'Resting Blood Pressure',\n       'Cholesterol', 'Fasting Blood Sugar', 'Resting ECG', 'Max. HR Acheived',\n       'Exercise Induced Angina', 'ST Depression', 'ST Slope',\n       'Num. Major Blood Vessels', 'Thalassemia']]\n\n# I haven't used the new fetures as they actually make the  xgb model perform worse! THough they do improve RF & Log Reg\n\ny = data['Condition']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Log Reg\n\nlr = LogisticRegression()\nmodel = lr.fit(X_train, y_train)\nlr_predict = lr.predict(X_test)\nlr_conf_matrix = confusion_matrix(y_test, lr_predict)\nlr_acc_score = accuracy_score(y_test, lr_predict)\nprint(\"confussion matrix\")\nprint(lr_conf_matrix)\nprint(\"\\n\")\nprint(\"Accuracy of Logistic Regression:\",lr_acc_score*100,'\\n')\nprint(classification_report(y_test,lr_predict))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Great results so far.\n\nIf we change the threshold used for the logistic regression model does that help?","metadata":{}},{"cell_type":"code","source":"#source code: https://www.kaggle.com/prashant111/extensive-analysis-eda-fe-modelling\n# modified\n\nfrom sklearn.preprocessing import binarize\n\nfor i in range(1,8):\n    \n    cm1=0\n    y_pred1 = lr.predict_proba(X_test)[:,1]\n    y_pred1 = y_pred1.reshape(-1,1)\n    y_pred2 = binarize(y_pred1, i/10)\n    y_pred2 = np.where(y_pred2 == 1, 1, 0)\n    cm1 = confusion_matrix(y_test, y_pred2)\n        \n    print ('With',i/10,'threshold the Confusion Matrix is ','\\n\\n',cm1,'\\n\\n',\n            'with',cm1[0,0]+cm1[1,1],'correct predictions, ', '\\n\\n', \n           \n            cm1[0,1],'Type I errors( False Positives), ','\\n\\n',\n           \n            cm1[1,0],'Type II errors( False Negatives), ','\\n\\n',\n           \n           'Accuracy score: ', (accuracy_score(y_test, y_pred2)), '\\n\\n',\n          \n            '====================================================', '\\n\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"no, it appears that the standard 0.5 thereshold is optimal","metadata":{}},{"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=20, random_state=12,max_depth=7)\nrf.fit(X_train,y_train)\nrf_predicted = rf.predict(X_test)\nrf_conf_matrix = confusion_matrix(y_test, rf_predicted)\nrf_acc_score = accuracy_score(y_test, rf_predicted)\nprint(\"confusion matrix\")\nprint(rf_conf_matrix)\nprint(\"\\n\")\nprint(\"Accuracy of Random Forest:\",rf_acc_score*100,'\\n')\nprint(classification_report(y_test,rf_predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nn_estimators =[64,100,128,200]\nmax_features = [2,3,5,7]\nbootstrap = [True,False]\n\nparam_grid = {'n_estimators':n_estimators,\n             'max_features':max_features,\n             'bootstrap':bootstrap}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#rf = RandomForestClassifier()\n\n#grid = GridSearchCV(rf,param_grid)\n\n#grid.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#grid.best_params_\n\n#{'bootstrap': True, 'max_features': 2, 'n_estimators': 200}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's use those params now\n\nrfc = RandomForestClassifier(max_features=2,n_estimators=200,bootstrap=True)\n\nrfc.fit(X_train,y_train)\n\nrfc_tuned_pred = rfc.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nrf_conf_matrix = confusion_matrix(y_test, rfc_tuned_pred)\nrf_acc_score = accuracy_score(y_test, rfc_tuned_pred)\nprint(\"confusion matrix\")\nprint(rf_conf_matrix)\nprint(\"\\n\")\nprint(\"Accuracy of Random Forest:\",rf_acc_score*100,'\\n')\nprint(classification_report(y_test,rfc_tuned_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb = XGBClassifier(learning_rate=0.1, n_estimators=64, max_depth=15,gamma=0.6, subsample=0.52,colsample_bytree=0.6,seed=27, \n                    reg_lambda=2, booster='dart', colsample_bylevel=0.6, colsample_bynode=0.5)\nxgb.fit(X_train, y_train)\nxgb_predicted = xgb.predict(X_test)\nxgb_conf_matrix = confusion_matrix(y_test, xgb_predicted)\nxgb_acc_score = accuracy_score(y_test, xgb_predicted)\nprint(\"confusion matrix\")\nprint(xgb_conf_matrix)\nprint(\"\\n\")\nprint(\"Accuracy of Extreme Gradient Boost:\",xgb_acc_score*100,'\\n')\nprint(classification_report(y_test,xgb_predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model stacking\n\nscv=StackingCVClassifier(classifiers=[xgb,rf,lr],meta_classifier= xgb,random_state=42)\nscv.fit(X_train,y_train)\nscv_predicted = scv.predict(X_test)\nscv_conf_matrix = confusion_matrix(y_test, scv_predicted)\nscv_acc_score = accuracy_score(y_test, scv_predicted)\nprint(\"confussion matrix\")\nprint(scv_conf_matrix)\nprint(\"\\n\")\nprint(\"Accuracy of StackingCVClassifier:\",scv_acc_score*100,'\\n')\nprint(classification_report(y_test,scv_predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The stacking classifier didn't help in this case.\n\nLet's bring the models together and see how they performed","metadata":{}},{"cell_type":"code","source":"model_eval = pd.DataFrame({'Model': ['Logistic Regression','Random Forest','XGBoost'], 'Accuracy': [lr_acc_score,rf_acc_score,xgb_acc_score]})\n\nmodel_eval = model_eval.set_index('Model').sort_values(by='Accuracy',ascending=False).T\n\n\ncmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [yes_c,no_c,no_c,no_c])\n\n\nfig = plt.figure(figsize=(6, 5), dpi=150,facecolor=background_color)\ngs = fig.add_gridspec(2, 1)\ngs.update(wspace=0.5, hspace=1)\nax0 = fig.add_subplot(gs[0, 0])\nax1 = fig.add_subplot(gs[1, 0])\n\n\nsns.heatmap(model_eval, cmap=cmap,annot=True,fmt=\".2%\",yticklabels=False, linewidths=5,cbar=False,ax=ax0,annot_kws={\"fontsize\":12})\nax0.tick_params(axis=u'both', which=u'both',length=0)\n\nax0.tick_params(axis='both')\nax0.tick_params(axis=u'both', which=u'both',length=0)\nax0.set_ylabel('') \n\nax0.text(0,-0.6,'Model performance overview',fontsize=15,fontweight='bold',color='black',fontfamily='sansserif')\nax0.text(0,-0.2,'Both tree-based methods, Random Forest and\\nXGBoost, performed the well. Logistic Regression\\nalso performed well.',fontsize=10,fontfamily='monospace')\nax0.set_xlabel(\"\",loc='left',fontsize=8,color=sub_col)\n\nsns.heatmap(xgb_conf_matrix, linewidths=2.5,yticklabels=['Actual No-Condition','Actual Condition'],xticklabels=['Predicted No-Condition','Predicted Condition'], cmap=cmap, cbar=None,annot=True,fmt='d',ax=ax1,annot_kws={\"fontsize\":15})\n\nax1.text(0,-0.5,'XGB performance overview',fontsize=15,fontweight='bold',color='black',fontfamily='sansserif')\nax1.text(0,-0.2,'The model performs well across all categories.',fontsize=10,fontfamily='monospace')\nax1.tick_params(axis=u'both', which=u'both',length=0)\n\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can also view the confusion matrix to view where the model gets things wrong","metadata":{}},{"cell_type":"markdown","source":"# Model Interpretability\n\nAn important part of data science is explaining how your model works. \n\nWhat are it's strengths & weaknesses?\n\nHow does it make decisions?\n\nWhat factors are the most important in its predictions?\n\nHere I will use SHAP explainer to help answer some of these questions, and hopefully show how you can use this tool to explain your models to stakeholders as required.\n\n\n**Note on visuals:**\nThe visuals will no longer be consistent with the above as SHAP explainer does not allow much customisation when compared to Matplotlib.","metadata":{}},{"cell_type":"code","source":"import shap","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will retrain the model, but without 'Dart' booster method as this is not yet supported by SHAP explainer.\n\nUsing the features we engineered earlier helps ti improve the score though, so we'll re-introduce those","metadata":{}},{"cell_type":"code","source":"# spltting the data\n\nX = data[['Age', 'Sex', 'Chest Pain Type', 'Resting Blood Pressure',\n       'Cholesterol', 'Fasting Blood Sugar', 'Resting ECG', 'Max. HR Acheived',\n       'Exercise Induced Angina', 'ST Depression', 'ST Slope',\n       'Num. Major Blood Vessels', 'Thalassemia','Age_gr_med', 'mhr_lr_med', 'Age_MaxHR_dum']]\n\n# I haven't used the new fetures as they actually make the  xgb model perform worse! THough they do improve RF & Log Reg\n\ny = data['Condition']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb = XGBClassifier(learning_rate=0.1, n_estimators=64, max_depth=15,gamma=0.6, subsample=0.52,colsample_bytree=0.6,seed=27, \n                    reg_lambda=2, colsample_bylevel=0.6, colsample_bynode=0.5)\nxgb.fit(X_train, y_train)\nxgb_predicted = xgb.predict(X_test)\nxgb_conf_matrix = confusion_matrix(y_test, xgb_predicted)\nxgb_acc_score = accuracy_score(y_test, xgb_predicted)\n\n\nprint(\"confusion matrix\")\nprint(xgb_conf_matrix)\nprint(\"\\n\")\nprint(\"Accuracy of Extreme Gradient Boost:\",xgb_acc_score*100,'\\n')\nprint(classification_report(y_test,xgb_predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Interpretability: XGBoost\n\nSo at this point, we can share out results with stakeholders. \n\nBut if questions get asked, such as, \"how does it work?\", that is where tools such as SHAP are invaluable.\n","metadata":{}},{"cell_type":"code","source":"# Custom colors\nimport matplotlib\ncolors = [yes_c, no_c]           \ncmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This can take a while to run, but our sample is small \nexplainer = shap.TreeExplainer(xgb)\nshap_values = explainer.shap_values(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I'll grab a single prediction now and show how it's prediction was made...","metadata":{}},{"cell_type":"code","source":"# Show a single prediction, randomly selected number 24\n\nshap.initjs()\nshap.force_plot(explainer.expected_value, shap_values[24,:], X_test.iloc[24,:],plot_cmap=[yes_c,no_c])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here I have shown how the features interact to produce a single prediction. In this case, the prediction is that the patient will not siffer a heart attack,\n\nSome features add to the risk, while other feature detract from the risk, but on balance, we are left with a result.","metadata":{}},{"cell_type":"code","source":"# Actual result\ny_test.iloc[24]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I'll now show a prediction for heart disease","metadata":{}},{"cell_type":"code","source":"shap.initjs()\nshap.force_plot(explainer.expected_value, shap_values[0,:], X_test.iloc[0,:],plot_cmap=[yes_c,no_c])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Actual result - we are correct!\ny_test.iloc[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above plots make it clear how class predictions differ, and how features interact with eachother to produce a final result.","metadata":{}},{"cell_type":"markdown","source":"# Multiple Samples [Interactive Plot]\n\nRather than viewing each prediction one-by-one, we can also view many data points at a time, in this case 50.\n\nI have ordered this visual by Max. HR Acheived, as we saw this would be an important factor in our visualisations earlier.\n\nWe can see that the lower the Max. HR Acheived, the higher proportion of heart attack patients (shown in red).\n\nConversely, we see that as the Max. HR Acheived rises, the proportion of heart attack patients reduces.\n\n**Feel free to have a go!**\n","metadata":{}},{"cell_type":"code","source":"shap.force_plot(explainer.expected_value, shap_values[:50,:], X_test.iloc[:50,:],plot_cmap=[yes_c,no_c])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"An alternative view is shown below, with the focus on the features themselves.\n\nThe most important feature for our XGB model is Num. Major Blood Vessels.","metadata":{}},{"cell_type":"code","source":"shap.summary_plot(shap_values, X_test,cmap=cmap)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can also view feature importances explicity","metadata":{}},{"cell_type":"code","source":"shap.summary_plot(shap_values, X_train, plot_type=\"bar\",color=yes_c)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can also view the interaction between features. \n\nIn this case, I will use Max. HR Acheived and Age, as these are features that appear to be related.","metadata":{}},{"cell_type":"code","source":"shap.dependence_plot('Max. HR Acheived', shap_values, X_test, interaction_index=\"Age\",cmap=cmap)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that the lower the Max HR Acheived, the higher the SHAP value and therefore more likely it is that a patient will suffer heart disease.\n\nAdditionally, the colours indicate age range. We can see that a higher Max HR is often acheived by lower age groups - which makes sense.","metadata":{}}]}