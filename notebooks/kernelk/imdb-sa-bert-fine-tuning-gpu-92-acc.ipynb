{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IMDB Sentiment Analysis Using BERT Fine-Tuning\n1. Using keras-bert (BERT-Base Model), Tensorflow 2, GPU\n2. Read More: <a href=\"https://pysnacks.com/bert-text-classification-with-fine-tuning/#binary-text-classification-using-bert\" title=\"Binary Text Classification with BERT (IMDB Sentiment Analysis)\" rel=\"dofollow\">Binary Text Classification with BERT Fine Tuning</a>\n\nFor fine-tuning, an additional classification layer (fully-connected dense layer) is added to the models-output NSP-Dense layer.\n<img src=\"https://pysnacks-media.s3.amazonaws.com/images/bert-text-classification-input.width-1280.png\" alt=\"Text-Classification-Using-BERT\" width=\"600\">","attachments":{}},{"metadata":{},"cell_type":"markdown","source":"# Download dependencies\n1. [keras-bert](https://pypi.org/project/keras-bert/): \n> Implementation of the BERT. Official pre-trained models could be loaded for feature extraction and prediction.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q keras-bert keras-rectified-adam scikit-plot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Set Tensorflow Backend\nImport OS, and set TF_KERAS environment variable. It is used needed by *keras-bert***."},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.environ['TF_KERAS'] = '1'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define imports"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import codecs\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\n\n# Import keras\nimport tensorflow as tf\nfrom tensorflow.python import keras\n\n# Keras-bert imports\nfrom keras_radam import RAdam\nfrom keras_bert import Tokenizer\nfrom keras_bert import get_custom_objects\nfrom keras_bert import load_trained_model_from_checkpoint\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"tf.__version__: %s\" % tf.__version__)\nprint(\"Num GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Download BERT Base Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget -q https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n!unzip -o uncased_L-12_H-768_A-12.zip\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define BERT-Base model constants\nAlso define hyperparams for fine-tuning."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bert Model Hyper-params\nSEQ_LEN = 256\nBATCH_SIZE = 16\nEPOCHS = 3\nLR = 2e-5\n\npretrained_path = 'uncased_L-12_H-768_A-12'\nconfig_path = os.path.join(pretrained_path, 'bert_config.json')\ncheckpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\nvocab_path = os.path.join(pretrained_path, 'vocab.txt')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load pre-trained BERT-Base Model, add classification layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"# @title Build Fine-Tuned Bert model\n\n# Load pretrained model\nmodel = load_trained_model_from_checkpoint(\n  config_path,\n  checkpoint_path,\n  training=True,\n  trainable=True,\n  seq_len=SEQ_LEN,\n)\n\n# Add classification layer\ninputs = model.inputs[:2]\ndense = model.get_layer('NSP-Dense').output\noutputs = keras.layers.Dense(units=2, activation='softmax')(dense)\nmodel = keras.models.Model(inputs, outputs)\n\nmodel.compile(\n  RAdam(lr=LR),\n  loss='sparse_categorical_crossentropy',\n  metrics=['sparse_categorical_accuracy'],\n)\n\nprint (model.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build training and test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"token_dict = {}\nwith codecs.open(vocab_path, 'r', 'utf8') as reader:\n    for line in reader:\n        token = line.strip()\n        token_dict[token] = len(token_dict)\ntokenizer = Tokenizer(token_dict)\n\ndef transform_data(reviews, labels, labels_to_ids):\n    \"\"\"\n    Input:\n      reviews: List of review texts.\n      sentiments: Sentiment index-wise for the review.\n      labels_to_ids: Dictionary with label mapped to value\n    Output:\n      Tuple of x and y where\n      x: List having two items viz token_input and seg_input.\n      y: Output labels corresponding to x.\n    \"\"\"\n    global tokenizer\n    indices, sentiments = [], []\n    for x in range(len(reviews)):\n        text = reviews[x]\n        sentiment = labels_to_ids[labels[x]]\n        ids, segments = tokenizer.encode(text, max_len=SEQ_LEN)\n        indices.append(ids)\n        sentiments.append(sentiment)\n    items = list(zip(indices, sentiments))\n    np.random.shuffle(items)\n    indices, sentiments = zip(*items)\n    indices = np.array(indices)\n    mod = indices.shape[0] % BATCH_SIZE\n    if mod > 0:\n        indices, sentiments = indices[:-mod], sentiments[:-mod]\n    return [indices, np.zeros_like(indices)], np.array(sentiments)\n\n\nfilepath = \"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\"\ndataset = pd.read_csv(filepath)\ntrain,test = train_test_split(dataset, test_size = 0.25)\n\nlabels_to_id = {'positive': 1, 'negative': 0}\nid_to_labels = {0: 'negative', 1: 'positive'}\n\ntest_x, test_y = transform_data(\n    test['review'].values,\n    test['sentiment'].values,\n    labels_to_id\n)\n\ntrain_x, train_y = transform_data(\n    train['review'].values,\n    train['sentiment'].values,\n    labels_to_id\n)\n\nprint(\"Training on: %s samples\\nTesting on: %s samples\" % (len(train_y), len(test_y)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train (Fine-Tune) the updated model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# @title Train\nhistory = model.fit(\n    train_x,\n    train_y,\n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE,\n    validation_split=0.20,\n    shuffle=True,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Track model training"},{"metadata":{"trusted":true},"cell_type":"code","source":"#@title Plot model training progress\nimport matplotlib.pyplot as plt\nimport numpy\n%matplotlib inline\n\n# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.subplot(1, 2, 1)\nplt.plot(history.history['val_sparse_categorical_accuracy'])\nplt.plot(history.history['sparse_categorical_accuracy'])\nplt.title('model sparse_categorical_accuracy')\nplt.ylabel('sparse_categorical_accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\n\nplt.subplot(1, 2, 2)\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict using the trained model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#@title Get test set predictions.\npredicts = model.predict(test_x, verbose=True).argmax(axis=-1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate model Performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"#@title Evaluate Model Accuracy and F1 Score\n#! pip install -q scikit-plot\nimport scikitplot as skplt\nfrom sklearn.metrics import accuracy_score, f1_score\naccuracy = accuracy_score(test_y, predicts)\nmacro_f1 = f1_score(test_y, predicts, average='macro')\nmicro_f1 = f1_score(test_y, predicts, average='micro')\nweighted_f1 = f1_score(test_y, predicts, average='weighted')\n\nprint(\"Accuracy: %s\" % accuracy)\nprint ('macro_f1: %s\\nmicro_f1:%s\\nweighted_f1:%s' %(\n    macro_f1, micro_f1, weighted_f1)\n)\n\nskplt.metrics.plot_confusion_matrix(\n    [id_to_labels[x] for x in test_y], \n    [id_to_labels[x] for x in predicts],\n    figsize=(10,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#@title Classifying texts\ntexts = [\n  \"It's a must watch\",\n  \"Can't wait for it's next part!\",\n  'It fell short of expectations.',\n  'Wish there was more to it!',\n  'Just wow!',\n  'Colossial waste of time',\n  'Save youself from this 90 mins trauma!'\n]\nfor text in texts:\n    ids, segments = tokenizer.encode(text, max_len=SEQ_LEN)\n    inpu = np.array(ids).reshape([1, SEQ_LEN])\n    predicted_id = model.predict([inpu,np.zeros_like(inpu)]).argmax(axis=-1)[0]\n    print (\"%s: %s\"% (id_to_labels[predicted_id], text))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}