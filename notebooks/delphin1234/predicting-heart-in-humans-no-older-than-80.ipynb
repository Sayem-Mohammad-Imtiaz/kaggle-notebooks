{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Acknowledgements\n#### This kernel uses such good kernels\n   - https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\n   - https://www.kaggle.com/vbmokin/feature-importance-xgb-lgbm-logreg-linreg\n   - https://www.kaggle.com/nanomathias/feature-engineering-importance-testing\n   - https://www.kaggle.com/startupsci/titanic-data-science-solutions\n   - https://www.kaggle.com/kabure/titanic-eda-model-pipeline-keras-nn\n   - https://www.kaggle.com/vbmokin/used-cars-price-prediction-by-15-models\n   - https://www.kaggle.com/vbmokin/feature-importance-xgb-lgbm-logreg-linreg\\\n   - https://www.kaggle.com/littleraj30/eda-model-building-in-depth-on-heart-disease\n   - https://www.kaggle.com/ahmadjaved097/classifying-heart-disease-patients"},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0.1\"></a>\n\n## Table of Contents\n\n1. [Import libraries](#1)\n1. [Download datasets](#2)\n1. [EDA](#3)\n1. [FE: building the feature importance diagrams](#4)\n    -  [4.1 LGBM](#4.1)\n    -  [4.2 XGB](#4.2) \n    -  [4.3 Logistic Regression](#4.3) \n    -  [4.4 Linear Regression](#4.4)\n1. [Comparison of the all feature importance diagrams ](#5)\n1. [Preparing to modeling](#6)  \n1. [Tuning models and test for all features](#7)\n    -  [Decition Tree Classifiter](#7.1)\n    -  [XGB Classifier](#7.2)\n    -  [Support Vector Machines](#7.3) \n1. [Models evaluation](#8)"},{"metadata":{},"cell_type":"markdown","source":"## 1. Import libraries <a class=\"anchor\" id=\"1\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import copy\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nimport pandas_profiling as pp\n\n# models\nfrom sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier \nfrom sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, VotingClassifier \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\n# NN models\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras import optimizers\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# model tuning\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval\n\nfrom sklearn import preprocessing\n\nfrom sklearn.linear_model import LinearRegression,LogisticRegression, SGDRegressor, RidgeCV\n\n# import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Download datasets <a class=\"anchor\" id=\"2\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/heart-disease-uci/heart.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[data['age'] < 80]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. EDA <a class=\"anchor\" id=\"3\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"pp.ProfileReport(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/ahmadjaved097/classifying-heart-disease-patients\nplt.figure(figsize=(14,8))\nsns.heatmap(data.corr(), annot = True, cmap='coolwarm',linewidths=.1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Thanks to: https://www.kaggle.com/littleraj30/eda-model-building-in-depth-on-heart-disease\nfig,ax=plt.subplots(1,2,figsize=(14,5))\nsns.countplot(x='fbs',data=data,hue='target',palette='Set3',ax=ax[0])\nax[0].set_xlabel(\"0-> fps <120 , 1-> fps>120\",size=12)\ndata.fbs.value_counts().plot.pie(ax=ax[1],autopct='%1.1f%%',shadow=True, explode=[0.1,0],cmap='Blues')\nax[1].set_title(\"0 -> fps <120 , 1 -> fps>120\",size=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Thanks to: https://www.kaggle.com/littleraj30/eda-model-building-in-depth-on-heart-disease\nfig,ax=plt.subplots(1,2,figsize=(14,5))\nsns.countplot(x='restecg',data=data,hue='target',palette='Set3',ax=ax[0])\nax[0].set_xlabel(\"resting electrocardiographic\",size=12)\ndata.restecg.value_counts().plot.pie(ax=ax[1],autopct='%1.1f%%',shadow=True,\n                                     explode=[0.005,0.05,0.05],cmap='Oranges')\nax[1].set_title(\"resting electrocardiographic\",size=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Thanks to: https://www.kaggle.com/littleraj30/eda-model-building-in-depth-on-heart-disease\nfig,ax=plt.subplots(1,2,figsize=(14,5))\nsns.countplot(x='slope',data=data,hue='target',palette='Set1',ax=ax[0])\nax[0].set_xlabel(\"peak exercise ST segment\",size=12)\ndata.slope.value_counts().plot.pie(ax=ax[1],autopct='%1.1f%%',shadow=True,explode=[0.005,0.05,0.05],cmap='Reds')\n\nax[1].set_title(\"peak exercise ST segment \",size=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Thanks to: https://www.kaggle.com/littleraj30/eda-model-building-in-depth-on-heart-disease\nfig,ax=plt.subplots(1,2,figsize=(14,5))\nsns.countplot(x='ca',data=data,hue='target',palette='Set2',ax=ax[0])\nax[0].set_xlabel(\"number of major vessels colored by flourosopy\",size=12)\ndata.ca.value_counts().plot.pie(ax=ax[1],autopct='%1.1f%%',shadow=True,cmap='Oranges')\nax[1].set_title(\"number of major vessels colored by flourosopy\",size=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Thanks to: https://www.kaggle.com/littleraj30/eda-model-building-in-depth-on-heart-disease\nfig,ax=plt.subplots(1,2,figsize=(14,5))\nsns.countplot(x='thal',data=data,hue='target',palette='Set2',ax=ax[0])\nax[0].set_xlabel(\"number of major vessels colored by flourosopy\",size=12)\ndata.thal.value_counts().plot.pie(ax=ax[1],autopct='%1.1f%%',shadow=True,cmap='Greens')\nax[1].set_title(\"number of major vessels colored by flourosopy\",size=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/ahmadjaved097/classifying-heart-disease-patients\nmale =len(data[data['sex'] == 1])\nfemale = len(data[data['sex']== 0])\n\nplt.figure(figsize=(8,6))\n\n# Data to plot\nlabels = 'Male','Female'\nsizes = [male,female]\ncolors = ['pink', 'darkgreen']\nexplode = (0, 0)  # explode 1st slice\n \n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=90)\n \nplt.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/ahmadjaved097/classifying-heart-disease-patients\nplt.figure(figsize=(8,6))\n\n# Data to plot\nlabels = 'Chest Pain Type:0','Chest Pain Type:1','Chest Pain Type:2','Chest Pain Type:3'\nsizes = [len(data[data['cp'] == 0]),len(data[data['cp'] == 1]),\n         len(data[data['cp'] == 2]),\n         len(data[data['cp'] == 3])]\ncolors = ['pink', 'yellowgreen','purple','gold']\nexplode = (0, 0,0,0)  # explode 1st slice\n \n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=180)\n \nplt.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/ahmadjaved097/classifying-heart-disease-patients\nplt.figure(figsize=(8,6))\n\n# Data to plot\nlabels = 'fasting blood sugar < 120 mg/dl','fasting blood sugar > 120 mg/dl'\nsizes = [len(data[data['fbs'] == 0]),len(data[data['cp'] == 1])]\ncolors = ['grey', 'yellowgreen','orange','gold']\nexplode = (0.1, 0)  # explode 1st slice\n \n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=180)\n \nplt.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/ahmadjaved097/classifying-heart-disease-patients\nplt.figure(figsize=(15,6))\nsns.countplot(x='age',data = data, hue = 'target',palette='GnBu')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## 4. FE: building the feature importance diagrams <a class=\"anchor\" id=\"4\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"4.1\"></a>\n### 4.1 LGBM \n[Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clone data for FE \ntrain_fe = copy.deepcopy(data)\ntarget_fe = train_fe['target']\ndel train_fe['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\nX = train_fe\nz = target_fe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\n#%% split training set to validation set\nXtrain, Xval, Ztrain, Zval = train_test_split(X, z, test_size=0.2, random_state=0)\ntrain_set = lgb.Dataset(Xtrain, Ztrain, silent=False)\nvalid_set = lgb.Dataset(Xval, Zval, silent=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\nparams = {\n        'boosting_type':'gbdt',\n        'objective': 'regression',\n        'num_leaves': 31,\n        'learning_rate': 0.05,\n        'max_depth': -1,\n        'subsample': 0.8,\n        'bagging_fraction' : 1,\n        'max_bin' : 5000 ,\n        'bagging_freq': 20,\n        'colsample_bytree': 0.6,\n        'metric': 'rmse',\n        'min_split_gain': 0.5,\n        'min_child_weight': 1,\n        'min_child_samples': 10,\n        'scale_pos_weight':1,\n        'zero_as_missing': True,\n        'seed':0,        \n    }\n\nmodelL = lgb.train(params, train_set = train_set, num_boost_round=1000,\n                   early_stopping_rounds=50,verbose_eval=10, valid_sets=valid_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\nfig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nlgb.plot_importance(modelL,ax = axes,height = 0.5)\nplt.show();plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\nfeature_score = pd.DataFrame(train_fe.columns, columns = ['feature']) \nfeature_score['score_lgb'] = modelL.feature_importance()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"4.2\"></a>\n### 4.2 XGB\n[Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\n#%% split training set to validation set \ndata_tr  = xgb.DMatrix(Xtrain, label=Ztrain)\ndata_cv  = xgb.DMatrix(Xval   , label=Zval)\nevallist = [(data_tr, 'train'), (data_cv, 'valid')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\nparms = {'max_depth':8, #maximum depth of a tree\n         'objective':'reg:squarederror',\n         'eta'      :0.3,\n         'subsample':0.8,#SGD will use this percentage of data\n         'lambda '  :4, #L2 regularization term,>1 more conservative \n         'colsample_bytree ':0.9,\n         'colsample_bylevel':1,\n         'min_child_weight': 10}\nmodelx = xgb.train(parms, data_tr, num_boost_round=200, evals = evallist,\n                  early_stopping_rounds=30, maximize=False, \n                  verbose_eval=10)\n\nprint('score = %1.5f, n_boost_round =%d.'%(modelx.best_score,modelx.best_iteration))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\nfig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nxgb.plot_importance(modelx,ax = axes,height = 0.5)\nplt.show();plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\nfeature_score['score_xgb'] = feature_score['feature'].map(modelx.get_score(importance_type='weight'))\nfeature_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"4.3\"></a>\n### 4.3 Logistic Regression\n[Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\n# Standardization for regression model\ntrain_fe = pd.DataFrame(\n    preprocessing.MinMaxScaler().fit_transform(train_fe),\n    columns=train_fe.columns,\n    index=train_fe.index\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\n# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(train_fe, target_fe)\ncoeff_logreg = pd.DataFrame(train_fe.columns.delete(0))\ncoeff_logreg.columns = ['feature']\ncoeff_logreg[\"score_logreg\"] = pd.Series(logreg.coef_[0])\ncoeff_logreg.sort_values(by='score_logreg', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\n# the level of importance of features is not associated with the sign\ncoeff_logreg[\"score_logreg\"] = coeff_logreg[\"score_logreg\"].abs()\nfeature_score = pd.merge(feature_score, coeff_logreg, on='feature')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"4.4\"></a>\n### 4.4 Linear Regression\n##### [Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\n# Linear Regression\n\nlinreg = LinearRegression()\nlinreg.fit(train_fe, target_fe)\ncoeff_linreg = pd.DataFrame(train_fe.columns.delete(0))\ncoeff_linreg.columns = ['feature']\ncoeff_linreg[\"score_linreg\"] = pd.Series(linreg.coef_)\ncoeff_linreg.sort_values(by='score_linreg', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/used-cars-fe-eda-with-3d\ncoeff_linreg[\"score_linreg\"] = coeff_linreg[\"score_linreg\"].abs()\nfeature_score = pd.merge(feature_score, coeff_linreg, on='feature')\nfeature_score = feature_score.fillna(0)\nfeature_score = feature_score.set_index('feature')\nfeature_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"5\"></a>\n## 5. Comparison of the all feature importance diagrams \n##### [Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: https://www.kaggle.com/vbmokin/feature-importance-xgb-lgbm-logreg-linreg\n# Thanks to: https://www.kaggle.com/nanomathias/feature-engineering-importance-testing\n# MinMax scale all importances\nfeature_score = pd.DataFrame(\n    preprocessing.MinMaxScaler().fit_transform(feature_score),\n    columns=feature_score.columns,\n    index=feature_score.index\n)\n\n# Create mean column\nfeature_score['mean'] = feature_score.mean(axis=1)\n\n# Plot the feature importances\nfeature_score.sort_values('mean', ascending=False).plot(kind='bar', figsize=(20, 10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_score.sort_values('mean', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Thanks to: Thanks to: https://www.kaggle.com/vbmokin/feature-importance-xgb-lgbm-logreg-linreg\n# Create total column with different weights\nfeature_score['total'] = 0.5*feature_score['score_lgb'] + 0.3*feature_score['score_xgb'] \\\n                       + 0.1*feature_score['score_logreg'] + 0.1*feature_score['score_linreg']\n\n# Plot the feature importances\nfeature_score.sort_values('total', ascending=False).plot(kind='bar', figsize=(20, 10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_score.sort_values('total', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## 6. Preparing to modeling <a class=\"anchor\" id=\"6\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"target_name = 'target'\ndata_target = data[target_name]\ndata = data.drop([target_name], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test, target, target_test = train_test_split(data, data_target, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%% split training set to validation set\nXtrain, Xval, Ztrain, Zval = train_test_split(train, target, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7. Tuning models and test for all features <a class=\"anchor\" id=\"7\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{},"cell_type":"markdown","source":"### 7.1 Decition Tree Classifiter <a class=\"anchor\" id=\"7.1\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision Tree Classifier\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(train, target)\nacc_decision_tree = round(decision_tree.score(train, target) * 100, 2)\nacc_decision_tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_test_decision_tree = round(decision_tree.score(test, target_test) * 100, 2)\nacc_test_decision_tree","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 7.2 XGB Classifier <a class=\"anchor\" id=\"7.2\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def hyperopt_xgb_score(params):\n    clf = XGBClassifier(**params)\n    current_score = cross_val_score(clf, train, target, cv=10).mean()\n    print(current_score, params)\n    return current_score \n \nspace_xgb = {\n            'learning_rate': hp.quniform('learning_rate', 0, 0.05, 0.0001),\n            'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n            'eta': hp.quniform('eta', 0.025, 0.5, 0.005),\n            'max_depth':  hp.choice('max_depth', np.arange(2, 12, dtype=int)),\n            'min_child_weight': hp.quniform('min_child_weight', 1, 9, 0.025),\n            'subsample': hp.quniform('subsample', 0.5, 1, 0.005),\n            'gamma': hp.quniform('gamma', 0.5, 1, 0.005),\n            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.005),\n            'eval_metric': 'auc',\n            'objective': 'binary:logistic',\n            'booster': 'gbtree',\n            'tree_method': 'exact',\n            'silent': 1,\n            'missing': None\n        }\n \nbest = fmin(fn=hyperopt_xgb_score, space=space_xgb, algo=tpe.suggest, max_evals=10)\nprint('best:')\nprint(best)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = space_eval(space_xgb, best)\nparams","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XGB_Classifier = XGBClassifier(**params)\nXGB_Classifier.fit(train, target)\nacc_XGB_Classifier = round(XGB_Classifier.score(train, target) * 100, 2)\nacc_XGB_Classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_test_XGB_Classifier = round(XGB_Classifier.score(test, target_test) * 100, 2)\nacc_test_XGB_Classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig =  plt.figure(figsize = (15,15))\naxes = fig.add_subplot(111)\nxgb.plot_importance(XGB_Classifier,ax = axes,height =0.5)\nplt.show();\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 7.3 Support Vector Machines \n<a class=\"anchor\" id=\"7.3\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC()\nsvc.fit(train, target)\nacc_svc = round(svc.score(train, target) * 100, 2)\nacc_svc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_test_svc = round(svc.score(test, target_test) * 100, 2)\nacc_test_svc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 8. Models evaluation <a class=\"anchor\" id=\"8\"></a>\n\n[Back to Table of Contents](#0.1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Decision Tree Classifier','XGBClassifier', 'Support Vector Machines'],\n    \n    'Score_train': [acc_decision_tree, acc_XGB_Classifier, acc_svc],\n    'Score_test': [acc_test_decision_tree, acc_test_XGB_Classifier, acc_test_svc]\n                    })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models.sort_values(by=['Score_train', 'Score_test'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models.sort_values(by=['Score_test', 'Score_train'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models['Score_diff'] = abs(models['Score_train'] - models['Score_test'])\nmodels.sort_values(by=['Score_diff'], ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot\nplt.figure(figsize=[25,6])\nxx = models['Model']\nplt.tick_params(labelsize=14)\nplt.plot(xx, models['Score_train'], label = 'Score_train')\nplt.plot(xx, models['Score_test'], label = 'Score_test')\nplt.legend()\nplt.title('Score of 20 popular models for train and test datasets')\nplt.xlabel('Models')\nplt.ylabel('Score, %')\nplt.xticks(xx, rotation='vertical')\nplt.savefig('graph.png')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}