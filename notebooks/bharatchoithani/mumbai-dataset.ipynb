{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Raading the mumbai dataset\nmumbai = pd.read_csv('../input/housing-prices-in-metropolitan-areas-of-india/Mumbai.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mumbai.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#shape of this dataset\nmumbai.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Description\nmumbai.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Types of features that are given in this dataset\nmumbai.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets look at the correlation of all numerical features with our target variable\nmumbai.corr()['Price'].sort_values(ascending = False)[1:]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We can generate one feature based on the nearest railway line to the location of the apartment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"harbour = ['IT', 'Antop Hill', 'Tardeo', 'Central Avenue', 'Kewale', 'Greater Khanda', 'Mumbai CST',  'Masjid Bunder',  'Sandhurst Road',  'Dockyard Road',  'Reay Road', 'Cotton green', 'Sewri', 'Wadala', 'GTB Nagar', 'Chunabhatti', 'Kurla', 'Tilak Nagar', 'Chembur', 'Govandi', 'Mankhurd', 'Vashi', 'Sanpada', 'Jui Nagar', 'Nerul', 'Seawoods', 'Belapur', 'Kharghar', 'Mansarovar', 'Khandeshwar', 'Panvel', 'Kamothe', 'Koproli', 'Ghansoli', 'Karanjade', 'Airoli', 'Koper Khairane', 'Kopar Khairane']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"central = 'IT  Nashik  Ambarnath  Samata  Balkum  thane  Kharegaon  Beturkar  Pant  Kasheli  Highway  Pokhran  Haware  Shirgaon  Tardeo  Shil kolshet  Sainath  kavesar  Navi  Vikhroli  Palava  Hiranandani  PARSIK  Vartak  taloja  Kalamboli  Vasant  Majiwada  matunga  Dombivli  Bhiwandi  Taloja  Byculla  Chinchpokli  Currey Road  Parel  Dadar  Matunga  Sion  Kurla  Vidyavihar  Ghatkopar  Vikroli  Kanjurmarg  Bhandup  Nahur  Mulund  Thane  Kalwa  Mumbra  Diva  Dombivali  Thakurli  Kalyan  Shahad  Ambivili  Titwala  Khadvali  Vashind  Asangaon  Atgaon  Khardi  Kasara  Kalyan  Ulhasnagar  Ambernath  Badlapur  Vangani  Shelu  Neral  Bhivpuri  Karjat  Palasdhari  Kelavli  Dolavli  Lowjee  Khopoli  Powai'\ncentral = central.split()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"western = 'Churchgate  Bhayander  Naigaon  Vasai  Nalasopara  Virar  Vaitarna  Saphale  Palghar  Umroli  Boisar  Vangaon   Goregaon  Malad  Kandivali  Borivali  Dahisa  Andheri  Jogeshwari  Bandra  Dadar  Mahalaxmi'\nwestern = western.split()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"western1 = ['Mumbai Central', 'Lower Parel', 'Prabhadevi', 'Matunga', 'Mahim', 'Vile Parle', 'Mira Road', 'Ville Parle', 'Nala Sopara', 'Magathane', 'Juhu', 'Dattapada', 'Worli', 'Santacruz', 'Bhayandar', 'Thakur', 'Khar West', 'Rajendra Nagar', 'kandivali', 'vile parle west', 'Tardeo', 'Jankalyan Nagar', 'Jawahar Nagar', 'Marol', 'Hanuman Nagar', 'IT']\nfor i in western1:\n    western.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mumbai['Railway_Line'] = ''\n\nfor i in mumbai.index:\n    for j in harbour:\n        if j in mumbai.loc[i, 'Location']:\n            mumbai.loc[i, 'Railway_Line'] = 'Harbour'\n            break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in mumbai.index:\n    for j in central:\n        if j in mumbai.loc[i, 'Location']:\n            mumbai.loc[i, 'Railway_Line'] = 'Central'\n            break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in mumbai.index:\n    for j in western:\n        if j in mumbai.loc[i, 'Location']:\n            mumbai.loc[i, 'Railway_Line'] = 'Western'\n            break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in [451, 809, 810, 2626, 2681, 3614, 2615]:\n    mumbai.loc[i, 'Railway_Line'] = 'Western'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in mumbai.index:\n    for j in ['Ulwe', 'Uran', 'Ranjanpada', 'Dronagiri']:\n        if j in mumbai.loc[i, 'Location']:\n            mumbai.loc[i, 'Railway_Line'] = 'Nerul-Uran'\n            break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rows with empty values of Railway_Line are for those apartments whose nearest railway lines are unknown to us  \nmumbai['Railway_Line'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets look at the bar plot of our newly created feature 'Railway_Line'\nmumbai['Railway_Line'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now, lets look at the avearage price for each railway line\nmumbai.groupby('Railway_Line')['Price'].mean()[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets convert this string value to numerical values for the machine learning algorithms that we are going to use\nmumbai['Central'] = 0\nmumbai['Harbour'] = 0\nmumbai['Western'] = 0\nmumbai['Nerul-Uran'] = 0\n\nfor i in mumbai.index:\n    if mumbai.loc[i, 'Railway_Line'] == 'Central':\n        mumbai.loc[i, 'Central'] = 1\n    elif mumbai.loc[i, 'Railway_Line'] == 'Harbour':\n        mumbai.loc[i, 'Harbour'] = 1\n    elif mumbai.loc[i, 'Railway_Line'] == 'Western':\n        mumbai.loc[i, 'Western'] = 1\n    elif mumbai.loc[i, 'Railway_Line'] == 'Nerul-Uran':\n        mumbai.loc[i, 'Nerul-Uran'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We know that Kurla comes in both central and harbour lines so we are assigning it to harbour line aswell\nfor i in mumbai.index:\n    if mumbai.loc[i, 'Location'] == 'Kurla':\n        mumbai.loc[i, 'Harbour'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now lets look at the correlation of our newly created features with our target variables\nfor i in ['Central', 'Harbour', 'Western', 'Nerul-Uran']:\n    print(mumbai[i].corr(mumbai['Price']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mumbai.drop('Railway_Line', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#mumbai.drop('Location', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets look at the bar plots for our ordinal features\nfor i in mumbai.columns[3:]:\n    plt.title(i) \n    sns.barplot(mumbai[i].value_counts().index, mumbai[i].value_counts().values)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Earlier, we saw that 'Area' has the higgest correlation with 'Price'. Lets examine this feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Skewness\nmumbai['Area'].skew()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets visualize its skewness\nmean = mumbai['Area'].mean()\nplt.figure(figsize=(10,7))\nplt.axvline(mean, color='r', linestyle='--')\nsns.distplot(mumbai['Area'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#As we can see this feature is positively skewed\n#Lets try different techniques so as to make it somewhat symmetrical\nplt.figure(figsize=(10,7))\nplt.axvline(np.log(mumbai['Area']).mean(), color='r', linestyle='--')\nplt.title('Log')\nsns.distplot(np.log(mumbai['Area']))\nplt.figure(figsize=(10,7))\nplt.axvline(np.sqrt(mumbai['Area']).mean(), color='r', linestyle='--')\nplt.title('Square Root')\nsns.distplot(np.sqrt(mumbai['Area']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We can see that log transformation looks better\nmumbai['Area'] = np.log(mumbai['Area'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We saw that 'No. of Bedrooms' also has a high correlation with 'Price'. Lets examine it","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mumbai.groupby('No. of Bedrooms')['Price'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(mumbai.groupby('No. of Bedrooms')['Price'].mean().index, mumbai.groupby('No. of Bedrooms')['Price'].mean().values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Looks like apartments with 5 bedrooms are the the costliest and apartments with 1 bedroom are the cheapest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets look at the skewness of out target variable\nprint('Skewness =', mumbai['Price'].skew())\nsns.distplot(mumbai['Price'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = mumbai['Location']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mumbai.drop('Location', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets make separate columns for the top locations\n#We will plot a no. of locations vs error graph to determine the no. of locations we need\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nimport xgboost as xgb\nxgb_reg = xgb.XGBRegressor() \n\nloc_count = [i for i in range(10,101,10)]\nerrors = []\n\n\nfor j in loc_count:\n    top_locations = a.value_counts()[:j].index.values\n    for i in top_locations:\n        mumbai[i] = a.apply(lambda x : 1 if i == x else 0)\n    errors.append(-1 * (cross_val_score(xgb_reg, mumbai.drop('Price', axis = 1), mumbai['Price'], cv=3, scoring = 'neg_mean_absolute_error').mean()))\n    mumbai.drop(top_locations, axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Looks like 30 is the best value\nplt.plot(loc_count, errors)\nplt.xticks(loc_count)\nplt.xlabel('No. of Locations')\nplt.ylabel('Error')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_locations = a.value_counts()[:30].index.values\nfor i in top_locations:\n    mumbai[i] = a.apply(lambda x : 1 if i == x else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets split the data into train and test sets\n#We are gonna do a 70-30 train-test split\nfrom sklearn.model_selection import train_test_split\ntrain_x, test_x, train_y, test_y = train_test_split(mumbai.drop('Price', axis = 1), mumbai['Price'], test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now, I have have taken help for the evaluation and hypertuning part from 'https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f' as it has been very cleary explained ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We are gonna use xgboost \nimport xgboost as xgb \n#Lets convert our dataset into dmatrix\ndtrain = xgb.DMatrix(train_x, label = train_y)\ndtest = xgb.DMatrix(test_x, label = test_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    # Parameters that we are going to tune.\n    'max_depth':6,\n    'min_child_weight': 1,\n    'eta':.3,\n    'subsample': 1,\n    'colsample_bytree': 1,\n    #Other parameters\n    'objective':'reg:linear',\n    'eval_metric' : 'mae'\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_boost_round = 999","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cross validation matrix\ncv_results = xgb.cv(\n    params,\n    dtrain,\n    num_boost_round=num_boost_round,\n    seed=42,\n    nfold=5,\n    metrics={'mae'},\n    early_stopping_rounds=10\n)\ncv_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gridsearch_params = [\n    (max_depth, min_child_weight)\n    for max_depth in range(6,15)\n    for min_child_weight in range(2,10)\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tuning max_depth and min_child_weight\nmin_mae = float(\"Inf\")\nbest_params = None\nfor max_depth, min_child_weight in gridsearch_params:\n    print(\"CV with max_depth={}, min_child_weight={}\".format(\n                             max_depth,\n                             min_child_weight))\n    params['max_depth'] = max_depth\n    params['min_child_weight'] = min_child_weight\n    cv_results = xgb.cv(\n        params,\n        dtrain,\n        num_boost_round=num_boost_round,\n        seed=42,\n        nfold=5,\n        metrics={'mae'},\n        early_stopping_rounds=10\n    )\n    mean_mae = cv_results['test-mae-mean'].min()\n    boost_rounds = cv_results['test-mae-mean'].argmin()\n    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n    if mean_mae < min_mae:\n        min_mae = mean_mae\n        best_params = (max_depth,min_child_weight)\nprint(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params['max_depth'] = 12\nparams['min_child_weight'] = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gridsearch_params = [\n    (subsample, colsample)\n    for subsample in [i/10. for i in range(5,11)]\n    for colsample in [i/10. for i in range(5,11)]\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Tuning subsample and colsample\nmin_mae = float(\"Inf\")\nbest_params = None\nfor subsample, colsample in reversed(gridsearch_params):\n    print(\"CV with subsample={}, colsample={}\".format(\n                             subsample,\n                             colsample))\n    params['subsample'] = subsample\n    params['colsample_bytree'] = colsample\n    cv_results = xgb.cv(\n        params,\n        dtrain,\n        num_boost_round=num_boost_round,\n        seed=42,\n        nfold=5,\n        metrics={'mae'},\n        early_stopping_rounds=10\n    )\n    mean_mae = cv_results['test-mae-mean'].min()\n    boost_rounds = cv_results['test-mae-mean'].argmin()\n    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n    if mean_mae < min_mae:\n        min_mae = mean_mae\n        best_params = (subsample,colsample)\nprint(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params['subsample'] = 0.9\nparams['colsample_bytree'] = 0.9","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tuning learning rate\nmin_mae = float(\"Inf\")\nbest_params = None\nfor eta in [.5, .4, .3, .2, .1, .05, .01, .005, .001, .0005]:\n    print(\"CV with eta={}\".format(eta))\n    params['eta'] = eta\n    cv_results = xgb.cv(\n            params,\n            dtrain,\n            num_boost_round=num_boost_round,\n            seed=42,\n            nfold=5,\n            metrics=['mae'],\n            early_stopping_rounds=10\n          )\n    mean_mae = cv_results['test-mae-mean'].min()\n    boost_rounds = cv_results['test-mae-mean'].argmin()\n    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n    if mean_mae < min_mae:\n        min_mae = mean_mae\n        best_params = eta\nprint(\"Best params: {}, MAE: {}\".format(best_params, min_mae))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params['eta'] = 0.005","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets train our model\nmodel = xgb.train(\n    params,\n    dtrain,\n    num_boost_round=num_boost_round,\n    evals=[(dtest, \"Test\")],\n    early_stopping_rounds=10\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best MAE: {:.2f} in {} rounds\".format(model.best_score, model.best_iteration+1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_absolute_error(model.predict(dtest), test_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Features in descending order according to their importance\nplt.figure(figsize=(20,15)) \nxgb.plot_importance(model, ax=plt.gca())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}