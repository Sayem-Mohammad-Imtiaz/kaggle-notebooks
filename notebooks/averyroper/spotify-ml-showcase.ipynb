{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Make data frames from data\ngenres = pd.read_csv('../input/dataset-of-songs-in-spotify/genres_v2.csv')\nplaylists=pd.read_csv('../input/dataset-of-songs-in-spotify/playlists.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##This function was pulled from offline to let me see where any NA values to figure out how I'd deal with them\ndef assess_NA(data):\n    \"\"\"\n    Returns a pandas dataframe denoting the total number of NA values and the percentage of NA values in each column.\n    The column names are noted on the index.\n    \n    Parameters\n    ----------\n    data: dataframe\n    \"\"\"\n    # pandas series denoting features and the sum of their null values\n    null_sum = data.isnull().sum()# instantiate columns for missing data\n    total = null_sum.sort_values(ascending=False)\n    percent = ( ((null_sum / len(data.index))*100).round(2) ).sort_values(ascending=False)\n    \n    # concatenate along the columns to create the complete dataframe\n    df_NA = pd.concat([total, percent], axis=1, keys=['Number of NA', 'Percent NA'])\n    \n    # drop rows that don't have any missing data; omit if you want to keep all rows\n    df_NA = df_NA[ (df_NA.T != 0).any() ]\n    \n    return df_NA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assess_NA(genres)\n#Looking at where NAs are","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Omit 3 columns with 50% NAN values. Separate Predictors from class (genre)"},{"metadata":{"trusted":true},"cell_type":"code","source":"om = ['title','Unnamed: 0','song_name','genre'] #Columns to omit from predictors, based on having too many NAs to be useful\n\nX = genres.drop(om, axis = 1) #create dataframe of predictors\ny = genres['genre'].to_frame() #Creating target class data frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen_trans = preprocessing.OrdinalEncoder().fit(y) #Encoder to turn classes to integers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trans_y = pd.DataFrame(gen_trans.transform(y)) #Turn classes to integers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.columns #Letting myself see what columns are in predictors","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking for diversity of columns. If the values in each row are all the same, or all different then it's not good for predictions. will omit homogeous or overly unique columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"div_check = {} #Checking for diversity of columns. If the values in each row are all the same, or all different then it's not good for predictions. will omit homogeous or overly unique columns.\nfor col in X:\n    l = len(set(X[col]))\n    div_check[col] =(l, l/42305)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"div_check #Looking at diversity","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding columns to omit, and which columns are categorical\nom = []\ncat=[] \n\nfor key in div_check:\n    if div_check[key][1] > .5 or div_check[key][0] == 1:\n        \n        om.append(key)\n    elif div_check[key][0]<50:\n        cat.append(key)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Omitting columns marked for omission\nX_clean = X.drop(om, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Separating categorical and continuous predictors for different preprocessing\ncateg = X_clean[cat]\ncontin = X_clean.drop(cat,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting scaler to continuous predictors\nscaler = preprocessing.StandardScaler().fit(contin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scaling continuous predictors\ncontin_scaled = pd.DataFrame(scaler.transform(contin),columns=contin.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting one hot encoder to categorical predictors\noh_enc = preprocessing.OneHotEncoder().fit(categ)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting names of categorical columns, to put back into encoded dataframe\noh_names = oh_enc.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One hot encoding categorical predictors\ncat_encoded = pd.DataFrame(oh_enc.transform(categ).toarray(),columns = oh_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting scaler to one hot encoded categorical predictors\ncat_scale = preprocessing.StandardScaler().fit(cat_encoded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scaling encoded categorical predictors\ncat_enc_scale = pd.DataFrame(cat_scale.transform(cat_encoded),columns = oh_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Putting categorical and continuous predictors back together, now that they're processed\na=[cat_enc_scale,contin_scaled]\nX_clean_tran = pd.concat(a,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split data into test and training\nX_train, X_test, y_train, y_test = train_test_split(X_clean_tran,trans_y, test_size= .2, random_state = 345)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Just looking at training data\nX_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fit a logistic regression to the training data\nclf = LogisticRegression(random_state=987).fit(X_train,y_train.to_numpy().ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predict test data based on logistic fit\ny_hat_clf = pd.DataFrame(clf.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reset indices for easy concatenation\ny_hat_clf.reset_index(drop=True,inplace=True)\ny_test.reset_index(drop=True,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reversing encoding of test labels and prediction, in case I want to use them later\ny_act = pd.DataFrame(gen_trans.inverse_transform(y_test))\ny_clf = pd.DataFrame(gen_trans.inverse_transform(y_hat_clf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Concatenate logistic prediction and actual labels, naming them appropriately\nresults_df = pd.concat([y_hat_clf,y_test],axis=1)\nresults_df.columns = ['clf', 'actual']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Use crosstab to make a confusion matrix myself\nconf_mat = pd.crosstab(results_df['clf'],results_df['actual'],rownames=['Predicted'],colnames=['Actual'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Looking at confusion matrix\nconf_mat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#A heat map to help visualize results. Bright spots should appear along diagonals, with dark spots everywhere else. This would indicate Perfect categorization. \n#Issue with this is that places with higher raw number of values show up brighter , even if they may have lower percentage of accuracy. I'll scale it to account for this.\npx.imshow(conf_mat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Doing previously mentioned scaling\nscaled_conf_mat = pd.DataFrame(preprocessing.StandardScaler().fit_transform(conf_mat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scaled heat map. Bright spots indicate the most frequent classified thing in each column\n#It's now clear that the most easily classified are class 8 and up. Class 1 is also fairly easily classified, but a lot of things between 0 and 6 are falsely classified as class 7. \n#7 is mostly classified truly positively as well.\nscale_log_map = px.imshow(scaled_conf_mat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scale_log_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#A list of the class labels corresponding to their encoded numbers\npd.DataFrame(gen_trans.inverse_transform(pd.DataFrame(range(15))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculate percentages that were predicted accurately for every class\ncorrect_class = list(np.diag(conf_mat))\nactual_sums = list(conf_mat.sum(axis=0))\ncorr_per = pd.DataFrame(np.divide(correct_class,actual_sums)).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#View confusion matrix with fraction correct tacked onto the bottom\npd.concat([conf_mat,corr_per],axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Categories 6 through 14 are most easily classifiable. Corresponding to:\n6\tTrap Metal\n7\tUnderground Rap\n8\tdnb\n9\thardstyle\n10\tpsytrance\n11\ttechhouse\n12\ttechno\n13\ttrance\n14\ttrap\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Just seeing that I can also do confusion matrix with sklearn metrics, but I already named the axes on the other one\npd.DataFrame(confusion_matrix(y_clf,y_act))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score \nfrom sklearn.metrics import balanced_accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculated for use in ROC score\ny_score = clf.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Balanced accuracy calculated for comparison\nbalanced_accuracy_score(y_test,y_hat_clf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ROC_AUC score calculated. This is a great score, well classified\nroc_auc_score(y_test,y_score,multi_class = 'ovr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#PCA analysis is attempted to see if it'll be possible to visually display the categories on a scatterplot\npca = PCA().fit(X_clean_tran)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Seeing how much variance is explained by each principal component\npca_rat = list(pca.explained_variance_ratio_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting a cumiulative version of the previous variance explainability\ncum_rat = list(itertools.accumulate(pca_rat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing that the first couple of principal components will not be enough to scatterplot easily distinguishable classes. Not enough variability will be captured in them. First 3 principal components\n#only account for 22% of variability. Things will still be jumbled together. It would require 15 values to show comfortably and there's no easy way to show a 15 dimensional graph\npx.bar(cum_rat)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This shows that it requires 15 of the PCA components to explain 80% of the variance, so I won't be able to clearly visualize the distinction by plotting a few PCA values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Boosting\nfrom sklearn.ensemble import GradientBoostingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Running a boosing fit for comparison with logistic regression. Chose boosting over random forest, because maybe the better models will be able to differentiate pop somehow.\nboost_fit = GradientBoostingClassifier(max_depth=4,max_features = 'sqrt',n_estimators = 500).fit(X_train,np.ravel(y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For use in roc auc score\nboost_score=boost_fit.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting scores, to show using confusion matrix and heat map\ny_hat_boost = pd.DataFrame(boost_fit.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#This roc score is even better than the logistic regression one.\nroc_auc_score(y_test,boost_score,multi_class='ovr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding to results dataframe for comparison of models\nresults_df = pd.concat([y_hat_boost,results_df],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Name column appropriately\nresults_df.rename(columns={0:'boost'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Make confusion matrix for boosting model\nboost_conf_mat = pd.crosstab(results_df['boost'],results_df['actual'],rownames=['Predicted'],colnames=['Actual'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Look at confusion matrix\nboost_conf_mat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct_class = list(np.diag(boost_conf_mat))\nactual_sums = list(boost_conf_mat.sum(axis=0))\nboost_corr_per = pd.DataFrame(np.divide(correct_class,actual_sums)).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#A confusion matrox for the boosting with percent correct for each column tacked onto bottom\npd.concat([boost_conf_mat,boost_corr_per],axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The percent correct from each column from the logistic regression, for comparison.\n#It can be seen that almost universally the boosting scores are better. The only thing thats' worse is the class 7 score.\n#The class 8 on the boosting is almost perfect\ncorr_per","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Unscaled heat map.\npx.imshow(boost_conf_mat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scale heat map\nscaled_boost_con =pd.DataFrame(preprocessing.StandardScaler().fit_transform(boost_conf_mat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scaled heat map. Like before bright spots should be along diagonal\nscale_boost_map = px.imshow(scaled_boost_con)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Showing scaled boosting heat map\nscale_boost_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reshowing the heatmap from the logistic regression. While it's somewhat hard to see,the diagonals are a bit brigther, and the upper and lower triangles are a bit darker on the\n#boosting heat map. There is more contrast. This is indicative of the higher accuracy of the boosting model\npx.imshow(scaled_conf_mat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df.to_csv('genre_predictions.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}