{"nbformat_minor":1,"cells":[{"source":"# Hello, I'm proud to upload my first ever Kernel on Kaggle.\nI started from general data cleaning and checking. With every step I was moving into more detailed insights. Starting from monthly transaction split to most commonly sold building types and I ended up analyzing one family dwellings in Manhattan.","metadata":{},"cell_type":"markdown"},{"source":"There are several issues marked in the code where I'd love to get some feedback:\n1. HELP :) correlation\n2. HELP :) code vulnerability\n3. HELP :) Google maps in Jupyter","metadata":{},"cell_type":"markdown"},{"source":"I'm also wondering how to get more data to complete NYC 2017 property sales.","metadata":{},"cell_type":"markdown"},{"source":"import pandas as pd\n\n#load file\nnyc = pd.read_csv('../input/nyc-rolling-sales.csv', sep =',')\n\n#show dataset details\nprint('number of entries:',nyc.shape)\nnyc.dtypes","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"nyc = nyc.rename(columns={'SALE PRICE': 'SALEPRICE'})","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"# Look for irrelevant data to drop\nnyc['SALEPRICE'].value_counts().head(10)","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"# Drop irrelevant transactions (0$, 1$, 10$)\n\nnyc = nyc[nyc.SALEPRICE != '0']\nnyc = nyc[nyc.SALEPRICE != '10']\nnyc = nyc[nyc.SALEPRICE != '1']\nnyc = nyc[nyc.SALEPRICE != ' -  ']\nprint('number of entries:',nyc.shape)","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"nyc['SALEPRICE'] = pd.to_numeric(nyc['SALEPRICE'])\nnyc.dtypes","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"# Dicard rows with empty (NaN) fields\n\nnyc.isnull().any()\nnyc = nyc.dropna()\nnyc.shape","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"#Set SALE DATE as index ID for sorting purposes\n\nnyc['SALE DATE'].dtype\npd.to_datetime(nyc['SALE DATE'])","outputs":[],"execution_count":null,"metadata":{"scrolled":true},"cell_type":"code"},{"source":"# Check how the DF looks like\nnyc.set_index('SALE DATE', inplace=True)","outputs":[],"execution_count":null,"metadata":{"scrolled":true},"cell_type":"code"},{"source":"# Change borough index to borough real name\n\nnyc['BOROUGH'][nyc['BOROUGH'] == 1] = 'Manhattan'\nnyc['BOROUGH'][nyc['BOROUGH'] == 2] = 'Bronx'\nnyc['BOROUGH'][nyc['BOROUGH'] == 3] = 'Brooklyn'\nnyc['BOROUGH'][nyc['BOROUGH'] == 4] = 'Queens'\nnyc['BOROUGH'][nyc['BOROUGH'] == 5] = 'Staten Island'\n","outputs":[],"execution_count":null,"metadata":{"scrolled":true},"cell_type":"code"},{"source":"#Date time index applied\n\nnyc.index","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"THIS IS HOW MY CLEANED DATA LOOKS LIKE","metadata":{},"cell_type":"markdown"},{"source":"#Cleaned data preview\n\nnyc.head(25)","outputs":[],"execution_count":null,"metadata":{"scrolled":true},"cell_type":"code"},{"source":"#Set index data dype to date\n\nnyc.index = pd.to_datetime(nyc.index) \nnyc.index","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"TOP DOWN APPROACH TO SPOT DETAILS IN THE DATA SET","metadata":{},"cell_type":"markdown"},{"source":"#Divide cleaned data into 2017 monthly data sets\n\njan = nyc.loc['2017-1-1':'2017-1-31']\nfeb = nyc.loc['2017-2-1':'2017-2-28']\nmar = nyc.loc['2017-3-1':'2017-3-31']\napr = nyc.loc['2017-4-1':'2017-4-30']\nmay = nyc.loc['2017-5-1':'2017-5-31']\njun = nyc.loc['2017-6-1':'2017-6-30']\njul = nyc.loc['2017-7-1':'2017-7-31']\naug = nyc.loc['2017-8-1':'2017-8-31']\n","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"print(jan.shape)\nprint(feb.shape)\nprint(mar.shape)\nprint(apr.shape)\nprint(may.shape)\nprint(jun.shape)\nprint(jul.shape)\nprint(aug.shape)","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"With 4418 transactions in June and 2995 (the lowest) in August it seems that everybody wants to make the sale before the summer as it is fairly low season. ","metadata":{},"cell_type":"markdown"},{"source":"#Let's see which building class makes the most of market share:\nnyc['BUILDING CLASS CATEGORY'].value_counts().head(10)","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"One family dwellings are most frequently sold in NY.","metadata":{},"cell_type":"markdown"},{"source":"#Let's investigate that deeper and split it into monthky transtactions.\n\njan_dwellings = jan['BUILDING CLASS CATEGORY'].str.contains('01 ONE FAMILY DWELLINGS')\nJAN = jan[jan_dwellings]\nfeb_dwellings = feb['BUILDING CLASS CATEGORY'].str.contains('01 ONE FAMILY DWELLINGS')\nFEB = feb[feb_dwellings]\nmar_dwellings = mar['BUILDING CLASS CATEGORY'].str.contains('01 ONE FAMILY DWELLINGS')\nMAR = mar[mar_dwellings]\napr_dwellings = apr['BUILDING CLASS CATEGORY'].str.contains('01 ONE FAMILY DWELLINGS')\nAPR = apr[apr_dwellings]\nmay_dwellings = may['BUILDING CLASS CATEGORY'].str.contains('01 ONE FAMILY DWELLINGS')\nMAY = may[may_dwellings]\njun_dwellings = jun['BUILDING CLASS CATEGORY'].str.contains('01 ONE FAMILY DWELLINGS')\nJUN = jun[jun_dwellings]\njul_dwellings = jul['BUILDING CLASS CATEGORY'].str.contains('01 ONE FAMILY DWELLINGS')\nJUL = jul[jul_dwellings]\naug_dwellings = aug['BUILDING CLASS CATEGORY'].str.contains('01 ONE FAMILY DWELLINGS')\nAUG = aug[aug_dwellings]\nprint('Number of one family dwellings transactions per month')\nprint('JAN:', len(JAN))\nprint('FEB:', len(FEB))\nprint('MAR:', len(MAR))\nprint('APR:', len(APR))\nprint('MAY:', len(MAY))\nprint('JUN:', len(JUN))\nprint('JUL:', len(JUL))\nprint('AUG:', len(AUG))","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"HELP :) correlation\n1. It would be interesting to see how monthly one family dwellings transactions per month correlate with total number of transactions per month. However, I'm not sure how to code it :P yet.","metadata":{},"cell_type":"markdown"},{"source":"Anyway, let's dive deeper and see how one family dwellings split between Boroughs","metadata":{},"cell_type":"markdown"},{"source":"print('JAN:')\nprint(JAN['BOROUGH'].value_counts())\nprint('FEB:')\nprint(FEB['BOROUGH'].value_counts())\nprint('MAR:')\nprint(MAR['BOROUGH'].value_counts())\nprint('APR:')\nprint(APR['BOROUGH'].value_counts())\nprint('MAY:')\nprint(MAY['BOROUGH'].value_counts())\nprint('JUN:')\nprint(JUN['BOROUGH'].value_counts())\nprint('JUL:')\nprint(JUL['BOROUGH'].value_counts())\nprint('AUG:')\nprint(AUG['BOROUGH'].value_counts())","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"HELP :) code vulnerability\n1. In general, the order remains the same across the months.\n2. The problem is that in August Brooklyn (169) surpassed Staten Island (141)\n3. My code generates an error. Putting all values to fixed lists produces error in the final data frame (August, Brooklyn has the value of Staten Island and vice versa. How to make such value aggregation more flexible?\nCOUPLE OF INSIGHTS:\n1.  The order of boroughs remained the same over the time span.\n2.  There are really few transactions in Manhattan","metadata":{},"cell_type":"markdown"},{"source":"#Let's build a data frame showing number of transactions in Boroughs in different months\n\nJAN_list = JAN['BOROUGH'].value_counts().tolist()\nFEB_list = FEB['BOROUGH'].value_counts().tolist()\nMAR_list = MAR['BOROUGH'].value_counts().tolist()\nAPR_list = APR['BOROUGH'].value_counts().tolist()\nMAY_list = MAY['BOROUGH'].value_counts().tolist()\nJUN_list = JUN['BOROUGH'].value_counts().tolist()\nJUL_list = JUL['BOROUGH'].value_counts().tolist()\nAUG_list = AUG['BOROUGH'].value_counts().tolist()","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"#list of Boroughs for our table\nBOROUGH = ['Queens','Staten Island','Brooklyn','Bronx ','Manhattan']","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"#building the aggregated table from all monthly lists\nborough_sales = pd.DataFrame(\n    {'BOROUGH': BOROUGH,\n     'JANUARY': JAN_list,\n    'FEBRUARY': FEB_list,\n    'MARCH': MAR_list,\n    'APRIL': APR_list,\n    'MAY': MAY_list,\n    'JUNE': JUN_list,\n    'JULY': JUL_list,\n    'AUGUST': AUG_list,\n    }, columns = ['JANUARY','FEBRUARY','MARCH','APRIL','JUNE','JULY','AUGUST','BOROUGH'])\nborough_sales.set_index('BOROUGH', inplace=True)\nborough_sales.head()","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"That's interesting. I want to see exactly what were the features of dwellings sold in Manhattan","metadata":{},"cell_type":"markdown"},{"source":"JAN[JAN['BOROUGH']=='Manhattan'].sort_values(by='SALEPRICE', ascending=0)","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"FINAL INSIGHTS IN THIS PART\n1. The most expensive property cost 41mln dollars(it is also 10th highest transaction in January in NY), the cheapest only 2mln dollars\n2. Both properties were on the same street, built around the same year, lot size fairly similar. What made the difference?\n3. All of the properties are either on WEST street (50%) or on EAST street (50%)\n\nHELP :) Google maps in Jupyter:\n1. I'd like to use google maps to mark the locations, or images of these properties and incorporate that to the Jupyter Notebook. But how? Folium?","metadata":{},"cell_type":"markdown"},{"source":"... and some more analysis","metadata":{},"cell_type":"markdown"},{"source":"","metadata":{},"cell_type":"markdown"},{"source":"# total value of tranactions per building category\n\njan.groupby('BUILDING CLASS CATEGORY').SALEPRICE.sum()","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"# Top Boroughs\n\njan['BOROUGH'].value_counts()","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"# Top Neighborhoods\n\njan['NEIGHBORHOOD'].value_counts().head(20)","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"# Top Building categories\n\njan['BUILDING CLASS CATEGORY'].value_counts().head(20)","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"# Top 10 most expensive properties in January 2017\njan.sort_values('SALEPRICE', ascending=False).head(10)","outputs":[],"execution_count":null,"metadata":{},"cell_type":"code"},{"source":"","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"\n","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"},{"source":"","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","pygments_lexer":"ipython3","mimetype":"text/x-python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","version":"3.6.1"}},"nbformat":4}