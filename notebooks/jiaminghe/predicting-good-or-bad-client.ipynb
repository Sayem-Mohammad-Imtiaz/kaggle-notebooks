{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Predicting Good or Bad From Credit Card Approvals","metadata":{}},{"cell_type":"markdown","source":"Application data contains information from clients when applying for credit card. The credit card data contains information on the length of time the credit card account was opened since the initial approval as well as the status of the loan during each month. The purpose of this machine learning task is to predict whether or not a client is good or bad based on the application/ credit card data. The target variable is not given so we will need to find a method to determine good or bad.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom imblearn.combine import SMOTETomek\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import roc_auc_score, accuracy_score, f1_score","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:10.138457Z","iopub.execute_input":"2021-05-21T22:38:10.138812Z","iopub.status.idle":"2021-05-21T22:38:10.14496Z","shell.execute_reply.started":"2021-05-21T22:38:10.138781Z","shell.execute_reply":"2021-05-21T22:38:10.143378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\napp = pd.read_csv('../input/credit-card-approval-prediction/application_record.csv')\ncredit = pd.read_csv('../input/credit-card-approval-prediction/credit_record.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:10.150523Z","iopub.execute_input":"2021-05-21T22:38:10.150906Z","iopub.status.idle":"2021-05-21T22:38:11.573059Z","shell.execute_reply.started":"2021-05-21T22:38:10.150869Z","shell.execute_reply":"2021-05-21T22:38:11.572095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Brief Exploration of Applications / Credit","metadata":{}},{"cell_type":"code","source":"app.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:11.575892Z","iopub.execute_input":"2021-05-21T22:38:11.576255Z","iopub.status.idle":"2021-05-21T22:38:11.620553Z","shell.execute_reply.started":"2021-05-21T22:38:11.576209Z","shell.execute_reply":"2021-05-21T22:38:11.619482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app.columns","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:11.622001Z","iopub.execute_input":"2021-05-21T22:38:11.622646Z","iopub.status.idle":"2021-05-21T22:38:11.631492Z","shell.execute_reply.started":"2021-05-21T22:38:11.622599Z","shell.execute_reply":"2021-05-21T22:38:11.630281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dropping duplicate rows\napp.drop_duplicates(subset = ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN',\n       'AMT_INCOME_TOTAL', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n       'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'DAYS_BIRTH',\n       'DAYS_EMPLOYED', 'FLAG_MOBIL', 'FLAG_WORK_PHONE', 'FLAG_PHONE',\n       'FLAG_EMAIL', 'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS'], keep = 'first', inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:11.632946Z","iopub.execute_input":"2021-05-21T22:38:11.633269Z","iopub.status.idle":"2021-05-21T22:38:12.052689Z","shell.execute_reply.started":"2021-05-21T22:38:11.633238Z","shell.execute_reply":"2021-05-21T22:38:12.051834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:12.056221Z","iopub.execute_input":"2021-05-21T22:38:12.056883Z","iopub.status.idle":"2021-05-21T22:38:12.062975Z","shell.execute_reply.started":"2021-05-21T22:38:12.056834Z","shell.execute_reply":"2021-05-21T22:38:12.062034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"app.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:12.065948Z","iopub.execute_input":"2021-05-21T22:38:12.066361Z","iopub.status.idle":"2021-05-21T22:38:12.154062Z","shell.execute_reply.started":"2021-05-21T22:38:12.066327Z","shell.execute_reply":"2021-05-21T22:38:12.15327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"credit.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:12.155462Z","iopub.execute_input":"2021-05-21T22:38:12.155798Z","iopub.status.idle":"2021-05-21T22:38:12.167283Z","shell.execute_reply.started":"2021-05-21T22:38:12.155767Z","shell.execute_reply":"2021-05-21T22:38:12.165816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"credit.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:12.169311Z","iopub.execute_input":"2021-05-21T22:38:12.169882Z","iopub.status.idle":"2021-05-21T22:38:12.182029Z","shell.execute_reply.started":"2021-05-21T22:38:12.169811Z","shell.execute_reply":"2021-05-21T22:38:12.180559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"credit.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:12.183686Z","iopub.execute_input":"2021-05-21T22:38:12.184132Z","iopub.status.idle":"2021-05-21T22:38:12.300734Z","shell.execute_reply.started":"2021-05-21T22:38:12.184097Z","shell.execute_reply":"2021-05-21T22:38:12.299659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data frame to analyze length of time since initial approval of credit card\n# Shows number of past dues, paid off and no loan status.\ngrouped = credit.groupby('ID')\n\npivot_tb = credit.pivot(index = 'ID', columns = 'MONTHS_BALANCE', values = 'STATUS')\npivot_tb['open_month'] = grouped['MONTHS_BALANCE'].min()\npivot_tb['end_month'] = grouped['MONTHS_BALANCE'].max()\npivot_tb['window'] = pivot_tb['end_month'] - pivot_tb['open_month']\npivot_tb['window'] += 1 # Adding 1 since month starts at 0.\n\n#Counting number of past dues, paid offs and no loans.\npivot_tb['paid_off'] = pivot_tb[pivot_tb.iloc[:,0:61] == 'C'].count(axis = 1)\npivot_tb['pastdue_1-29'] = pivot_tb[pivot_tb.iloc[:,0:61] == '0'].count(axis = 1)\npivot_tb['pastdue_30-59'] = pivot_tb[pivot_tb.iloc[:,0:61] == '1'].count(axis = 1)\npivot_tb['pastdue_60-89'] = pivot_tb[pivot_tb.iloc[:,0:61] == '2'].count(axis = 1)\npivot_tb['pastdue_90-119'] = pivot_tb[pivot_tb.iloc[:,0:61] == '3'].count(axis = 1)\npivot_tb['pastdue_120-149'] = pivot_tb[pivot_tb.iloc[:,0:61] == '4'].count(axis = 1)\npivot_tb['pastdue_over_150'] = pivot_tb[pivot_tb.iloc[:,0:61] == '5'].count(axis = 1)\npivot_tb['no_loan'] = pivot_tb[pivot_tb.iloc[:,0:61] == 'X'].count(axis = 1)\n#Setting Id column to merge with app data.\npivot_tb['ID'] = pivot_tb.index\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:12.302044Z","iopub.execute_input":"2021-05-21T22:38:12.302319Z","iopub.status.idle":"2021-05-21T22:38:17.607691Z","shell.execute_reply.started":"2021-05-21T22:38:12.302292Z","shell.execute_reply":"2021-05-21T22:38:17.606719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pivot_tb.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:17.609347Z","iopub.execute_input":"2021-05-21T22:38:17.609707Z","iopub.status.idle":"2021-05-21T22:38:17.641567Z","shell.execute_reply.started":"2021-05-21T22:38:17.60967Z","shell.execute_reply":"2021-05-21T22:38:17.639714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Cleansing","metadata":{}},{"cell_type":"code","source":"def data_cleansing(data):\n    # Adding number of family members with number of children to get overall family members.\n    data['CNT_FAM_MEMBERS'] = data['CNT_FAM_MEMBERS'] + data['CNT_CHILDREN']\n    dropped_cols = ['FLAG_MOBIL', 'FLAG_WORK_PHONE', 'FLAG_PHONE',\n       'FLAG_EMAIL','OCCUPATION_TYPE','CNT_CHILDREN']\n    data = data.drop(dropped_cols, axis = 1)\n    \n    #converting birth years and days employed to years.\n    data['DAYS_BIRTH'] = np.abs(data['DAYS_BIRTH']/365)\n    data['DAYS_EMPLOYED'] = data['DAYS_EMPLOYED']/365 \n    \n    #Cleaning up categorical values to lower the count of dummy variables.\n    housing_type = {'House / apartment' : 'House / apartment',\n                   'With parents': 'With parents',\n                    'Municipal apartment' : 'House / apartment',\n                    'Rented apartment': 'House / apartment',\n                    'Office apartment': 'House / apartment',\n                    'Co-op apartment': 'House / apartment'}\n              \n    income_type = {'Commercial associate':'Working',\n                  'State servant':'Working',\n                  'Working':'Working',\n                  'Pensioner':'Pensioner',\n                  'Student':'Student'}\n    education_type = {'Secondary / secondary special':'secondary',\n                     'Lower secondary':'secondary',\n                     'Higher education':'Higher education',\n                     'Incomplete higher':'Higher education',\n                     'Academic degree':'Academic degree'}\n    family_status = {'Single / not married':'Single',\n                     'Separated':'Single',\n                     'Widow':'Single',\n                     'Civil marriage':'Married',\n                    'Married':'Married'}\n    data['NAME_HOUSING_TYPE'] = data['NAME_HOUSING_TYPE'].map(housing_type)\n    data['NAME_INCOME_TYPE'] = data['NAME_INCOME_TYPE'].map(income_type)\n    data['NAME_EDUCATION_TYPE']=data['NAME_EDUCATION_TYPE'].map(education_type)\n    data['NAME_FAMILY_STATUS']=data['NAME_FAMILY_STATUS'].map(family_status)\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:17.643148Z","iopub.execute_input":"2021-05-21T22:38:17.643427Z","iopub.status.idle":"2021-05-21T22:38:17.661498Z","shell.execute_reply.started":"2021-05-21T22:38:17.643399Z","shell.execute_reply":"2021-05-21T22:38:17.660373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleansed_app = data_cleansing(app)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:17.662759Z","iopub.execute_input":"2021-05-21T22:38:17.663209Z","iopub.status.idle":"2021-05-21T22:38:17.749828Z","shell.execute_reply.started":"2021-05-21T22:38:17.663165Z","shell.execute_reply":"2021-05-21T22:38:17.74877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"A ratio based method was used to create the target variable. For example, given a client with a time period of 60 months, if the client had paid off loan 40 times and was late 20 times, this would be considered a fairly good client given that there were more loans that were paid off on time compared to late payments. If a client had no loans throughout the initial approval of the credit card account, by default, this would be considered a good client as well. To identify a bad client, the number of past dues would exceed the number of loans paid off  or if the client only has past dues.","metadata":{}},{"cell_type":"code","source":"def feature_engineering_target(data):\n    good_or_bad = []\n    for index, row in data.iterrows():\n        paid_off = row['paid_off']\n        over_1 = row['pastdue_1-29']\n        over_30 = row['pastdue_30-59']\n        over_60 = row['pastdue_60-89'] \n        over_90 = row['pastdue_90-119']\n        over_120 = row['pastdue_120-149'] + row['pastdue_over_150']\n        no_loan = row['no_loan']\n            \n        overall_pastdues = over_1+over_30+over_60+over_90+over_120    \n            \n        if overall_pastdues == 0:\n            if paid_off >= no_loan or paid_off <= no_loan:\n                good_or_bad.append(1)\n            elif paid_off == 0 and no_loan == 1:\n                good_or_bad.append(1)\n        \n        elif overall_pastdues != 0:\n            if paid_off > overall_pastdues:\n                good_or_bad.append(1)\n            elif paid_off <= overall_pastdues:\n                good_or_bad.append(0)\n        \n        elif paid_off == 0 and no_loan != 0:\n            if overall_pastdues <= no_loan or overall_pastdues >= no_loan:\n                good_or_bad.append(0)\n\n        else:\n            good_or_bad.append(1)\n                \n        \n    return good_or_bad","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:17.751325Z","iopub.execute_input":"2021-05-21T22:38:17.751799Z","iopub.status.idle":"2021-05-21T22:38:17.762878Z","shell.execute_reply.started":"2021-05-21T22:38:17.751754Z","shell.execute_reply":"2021-05-21T22:38:17.761827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is data on clients in the credit data that intersect with the application data. the following is a merge between the two data frames given on the data of clients that exist in both data sets. Featured engineered additional columns from the credit data.","metadata":{}},{"cell_type":"code","source":"target = pd.DataFrame()\ntarget['ID'] = pivot_tb.index\ntarget['paid_off'] = pivot_tb['paid_off'].values\ntarget['#_of_pastdues'] = pivot_tb['pastdue_1-29'].values+ pivot_tb['pastdue_30-59'].values + pivot_tb['pastdue_60-89'].values +pivot_tb['pastdue_90-119'].values+pivot_tb['pastdue_120-149'].values +pivot_tb['pastdue_over_150'].values\ntarget['no_loan'] = pivot_tb['no_loan'].values\ntarget['target'] = feature_engineering_target(pivot_tb)\ncredit_app = cleansed_app.merge(target, how = 'inner', on = 'ID')\ncredit_app.drop('ID', axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:17.764764Z","iopub.execute_input":"2021-05-21T22:38:17.765077Z","iopub.status.idle":"2021-05-21T22:38:23.682343Z","shell.execute_reply.started":"2021-05-21T22:38:17.765047Z","shell.execute_reply":"2021-05-21T22:38:23.680739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = credit_app[credit_app.drop('target', axis = 1).columns]\ny = credit_app['target']\nxtrain, xtest, ytrain, ytest = train_test_split(x,y, train_size = 0.8, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:23.683709Z","iopub.execute_input":"2021-05-21T22:38:23.684012Z","iopub.status.idle":"2021-05-21T22:38:23.700027Z","shell.execute_reply.started":"2021-05-21T22:38:23.683981Z","shell.execute_reply":"2021-05-21T22:38:23.698463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_engineering_dummies(train, test):\n    ohe = OneHotEncoder(drop = 'if_binary')\n    xtrain_cat = train.select_dtypes(['object'])\n    xtest_cat = test.select_dtypes(['object'])\n    \n    train_dummies = pd.DataFrame(ohe.fit_transform(xtrain_cat).todense(), \n                              columns = ohe.get_feature_names(xtrain_cat.columns))\n    test_dummies = pd.DataFrame(ohe.transform(xtest_cat).todense(), \n                                columns = ohe.get_feature_names(xtest_cat.columns))\n    train_dummies.index = train.index\n    test_dummies.index = test.index\n    \n    train_with_dummies = pd.concat([train,train_dummies], axis = 1)\n    train_with_dummies.drop(xtrain_cat.columns, axis = 1, inplace = True)\n    \n    test_with_dummies = pd.concat([test,test_dummies], axis = 1)\n    test_with_dummies.drop(xtest_cat.columns, axis = 1, inplace = True)\n    \n    return train_with_dummies, test_with_dummies","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:23.701836Z","iopub.execute_input":"2021-05-21T22:38:23.70221Z","iopub.status.idle":"2021-05-21T22:38:23.711988Z","shell.execute_reply.started":"2021-05-21T22:38:23.702179Z","shell.execute_reply":"2021-05-21T22:38:23.710334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtrain_with_dummies, xtest_with_dummies = feature_engineering_dummies(xtrain,xtest)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:23.713497Z","iopub.execute_input":"2021-05-21T22:38:23.714208Z","iopub.status.idle":"2021-05-21T22:38:23.790192Z","shell.execute_reply.started":"2021-05-21T22:38:23.714149Z","shell.execute_reply":"2021-05-21T22:38:23.788589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(ytrain.value_counts())\nprint(ytest.value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:23.791871Z","iopub.execute_input":"2021-05-21T22:38:23.792211Z","iopub.status.idle":"2021-05-21T22:38:23.803475Z","shell.execute_reply.started":"2021-05-21T22:38:23.792178Z","shell.execute_reply":"2021-05-21T22:38:23.802119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Imported SMOTE in case of high imbalance of target variable. However, it does not seem to be highly imbalanced so it is fine not to use an imbalanced technique. ","metadata":{}},{"cell_type":"markdown","source":"## Machine Learning with Random Forest","metadata":{}},{"cell_type":"code","source":"n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 2)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\n\ngrid_rf = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\nrf = RandomForestClassifier()\ngrid = RandomizedSearchCV(rf, grid_rf, cv = 5,verbose = True, n_jobs = -1)\ngrid.fit(xtrain_with_dummies,ytrain)\nparams = grid.best_params_\nprint(params)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:38:23.805866Z","iopub.execute_input":"2021-05-21T22:38:23.80653Z","iopub.status.idle":"2021-05-21T22:38:35.342365Z","shell.execute_reply.started":"2021-05-21T22:38:23.806477Z","shell.execute_reply":"2021-05-21T22:38:35.341232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_grid = RandomForestClassifier(n_estimators = 10, min_samples_split = 2, min_samples_leaf = 1, max_features = 'sqrt',\n                                 max_depth = 50, bootstrap = False, random_state = 0)\nrf.fit(xtrain_with_dummies, ytrain)\npredictions_train = rf.predict(xtrain_with_dummies)\nroc_auc_train = roc_auc_score(ytrain, predictions_train)\naccuracy_train = accuracy_score(ytrain, predictions_train)\nf1_train = f1_score(ytrain, predictions_train)\npredictions_test = rf.predict(xtest_with_dummies)\nroc_auc_test = roc_auc_score(ytest,predictions_test)\naccuracy_test = accuracy_score(ytest,predictions_test)\nf1_test = f1_score(ytest, predictions_test)\n\nprint('roc_auc train: ', roc_auc_train)\nprint('accuracy train: ', accuracy_train)\nprint('f1 train: ', f1_train)\nprint('roc_auc test: ', roc_auc_test)\nprint('accuracy test: ', accuracy_test)\nprint('f1 test: ', f1_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T22:39:28.783372Z","iopub.execute_input":"2021-05-21T22:39:28.783767Z","iopub.status.idle":"2021-05-21T22:39:29.742293Z","shell.execute_reply.started":"2021-05-21T22:39:28.783734Z","shell.execute_reply":"2021-05-21T22:39:29.74093Z"},"trusted":true},"execution_count":null,"outputs":[]}]}