{"cells":[{"metadata":{"hideCode":true,"hidePrompt":true,"_uuid":"c004b8c8924094d497547335cf43fa98e9ac1fa4"},"cell_type":"markdown","source":"This dataset consists of a survey of 649 students taking their portugese class in Portugal. The author of the survey wanted to see if there is a link between certain criteria and school performance (http://www3.dsi.uminho.pt/pcortez/student.pdf). \n\nI will use this dataset to analyze probability of past class failures, based on final grade of the current portuguese class. We will be using Pymc3 for this. \n\nThank you to Cam Davidson. Much of which is taken from: \n(nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter2_MorePyMC/Ch2_MorePyMC_PyMC3.ipynb)"},{"metadata":{"hideCode":true,"hidePrompt":true,"trusted":true,"_uuid":"c290aea88b7b59370edc838b98a23149cb7e37b8"},"cell_type":"code","source":"import pymc3 as pm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nimport theano.tensor as tt\n\n%matplotlib inline","execution_count":5,"outputs":[]},{"metadata":{"hideCode":true,"hidePrompt":true,"trusted":true,"_uuid":"62786f444c30ec1c656c75f8359722d0a1aab78e"},"cell_type":"code","source":"df = pd.read_csv(\"../input/student-por.csv\")","execution_count":6,"outputs":[]},{"metadata":{"hideCode":false,"hidePrompt":true,"trusted":true,"collapsed":true,"_uuid":"bc4eefc91e055375d01e95f82a1a05ddbb0e5a36"},"cell_type":"code","source":"df['failed'] = 0\ndf.loc[df.failures>0, 'failed'] = 1 # if student had more than zero failures in the past, add 1 to total_fa. column","execution_count":7,"outputs":[]},{"metadata":{"hideCode":false,"hidePrompt":true,"trusted":true,"_uuid":"2b0a29b13dfc4e8d0b6c5c882c6325d527f4d31e"},"cell_type":"code","source":"print(\"100 current students had failures in past classes\")\ndf.failed.value_counts()","execution_count":8,"outputs":[]},{"metadata":{"hideCode":false,"hidePrompt":true,"trusted":true,"_uuid":"bcb72fe15056afbd8fb2e5c9628a8c1ac4dc2467"},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.barplot(df.failed, df.G3)\nplt.title(\"Failed versus average grade\")\nplt.ylabel(\"Average final grade\")\nplt.xlabel(\"Failed or not in past classes\")\nplt.grid()\nplt.show()\nprint(\"Apparently, for students that had past failures in other classes, their avg. final grade in portuguese class ~ 8.5\")","execution_count":9,"outputs":[]},{"metadata":{"hideCode":false,"hideOutput":true,"hidePrompt":true,"trusted":true,"_uuid":"d45bd5df392d810efb1de316f3c3d72d372533ac"},"cell_type":"code","source":"plt.scatter(df.G3, df.failed)\nplt.ylabel(\"Failed or Not\")\nplt.xlabel(\"Final Grade\")\nplt.show()\nprint(\"We can see that past failures in other classes (1) has some correlation with lower final grade \\\nin this portuguese class.\")","execution_count":10,"outputs":[]},{"metadata":{"hideCode":false,"hidePrompt":true,"_uuid":"bc156a2c9eac61d64d823574bfdb90390933657c"},"cell_type":"markdown","source":"# Build the model"},{"metadata":{"hideCode":true,"hidePrompt":true,"_uuid":"5b2b4012d42064ba1af00d2576f7d1087562e6b0"},"cell_type":"markdown","source":"We will use pymc3 to calculate the probability that a student failed past classes, based on their final grade in Portuguese class. \n\nTo do this, we need a function of final grade, call it p(fg), that is bounded between 0 and 1 (so as to model a probability) and changes from 1 to 0 as grades increase. There are many such functions, but the most popular choice is the logistic function. \n\n`p(fg)= 1/ (1+e**((β*final_grade)+α))`"},{"metadata":{"hideCode":false,"hidePrompt":true,"_uuid":"416588254801f9052d12001a086f303884266fcc"},"cell_type":"markdown","source":"This function has two parameters: β,α. These parameters have no reason to be positive, bounded or relatively large, so they are best modeled by a Normal random variable. For more information on these parameters, please see the \"Challenger Space Shuttle Disaster\", in: http://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter2_MorePyMC/Ch2_MorePyMC_PyMC3.ipynb"},{"metadata":{"hideCode":false,"hidePrompt":true,"trusted":true,"collapsed":true,"_uuid":"3ac217708f155698fa523e6f6bca3086a23a642a"},"cell_type":"code","source":"final_grade = np.array(df.G3) # final grade\nfailed_past_classes = np.array(df.failed)  # failed past classes (1) or not (0)?\n\n# We have to set the values of beta and alpha to 0. The reason for this is that if beta and alpha are very large, \n# they make p equal to 1 or 0. Unfortunately, pm.Bernoulli does not like probabilities of exactly 0 or 1, though \n# they are mathematically well-defined probabilities. So by setting the coefficient values to 0, we set the variable \n# p to be a reasonable starting value. This has no effect on our results, nor does it mean we are including any \n# additional information in our prior. It is simply a computational caveat in PyMC3\n\nwith pm.Model() as model:\n    # when τ=0.001 (precision), the variance is 1/τ (AKA, σ**2 or std**2), which is 1000\n    beta = pm.Normal(\"beta\", mu=0, tau=0.001, testval=0)  \n    alpha = pm.Normal(\"alpha\", mu=0, tau=0.001, testval=0)\n    p = pm.Deterministic(\"p\", 1.0/(1. + tt.exp((beta*final_grade) + alpha))) # p(fg)= 1/ (1+e**((β*final_grade)+α))","execution_count":11,"outputs":[]},{"metadata":{"hideCode":true,"hidePrompt":true,"_uuid":"f405741ff33bfc557ad260853e6e697a5bf634c8"},"cell_type":"markdown","source":"Below is a sample of possible values for beta and alpha, based on the Normal distribution and the hyperparameters that we are using."},{"metadata":{"hideCode":false,"hidePrompt":true,"trusted":true,"_uuid":"d5a21be9367b2a303b8fc274a18be575dc601a87"},"cell_type":"code","source":"np.random.seed(seed=13)\nnorm = pm.Normal.dist(mu=0, sd=31.622).random(size=500)\nsns.kdeplot(norm)\nplt.show()","execution_count":12,"outputs":[]},{"metadata":{"hideCode":false,"hidePrompt":true,"_uuid":"04cc96fce1117fa88368923c2e3cb2f50b26197f"},"cell_type":"markdown","source":"Now, we'll connect the probabilities in `p` with our observations through a Bernoulli random variable. A Bernoulli random variable with parameter p, denoted Ber(p), is a random variable that takes value 1 with probability p, and 0 else. Thus, our model can look like:\n\n`Past Failures, PFi∼Ber(p(FINAL_GRADEi)), i=1..N`"},{"metadata":{"hideCode":false,"hidePrompt":true,"trusted":true,"_uuid":"064e85477608bfbfa0410c509be79c0ea59ce9c1"},"cell_type":"code","source":"with model:\n    observed = pm.Bernoulli(\"bernoulli_obs\", p, observed=failed_past_classes)\n    start = pm.find_MAP()\n    step = pm.Metropolis()\n    trace = pm.sample(120000, step=step, start=start)\n    burned_trace = trace[100000::2]","execution_count":13,"outputs":[]},{"metadata":{"hideCode":false,"hidePrompt":true,"scrolled":true,"trusted":true,"_uuid":"a3c1e3d77c9d16f9164155ef925ae56d4ee0db45"},"cell_type":"code","source":"pm.summary(burned_trace, varnames=['alpha','beta'])","execution_count":25,"outputs":[]},{"metadata":{"hideCode":false,"hidePrompt":true,"_uuid":"57fd851cafbb8b03107261ec36de3a53c7e1537e"},"cell_type":"markdown","source":"Above, we can see the average mean for alpha and beta."},{"metadata":{"hideCode":false,"hidePrompt":true,"trusted":true,"_uuid":"2965f8b49d39e5219f48a28af3a24c242e473c11"},"cell_type":"code","source":"pm.traceplot(burned_trace)\nplt.show()","execution_count":26,"outputs":[]},{"metadata":{"hideCode":false,"hidePrompt":true,"trusted":true,"_uuid":"a528375c4daa786bfcc222a959f3912a47e23661"},"cell_type":"code","source":"pm.plot_posterior(burned_trace,\n                  varnames=['beta','alpha'], \n                  color='#87ceeb')\nplt.show()","execution_count":27,"outputs":[]},{"metadata":{"hideCode":false,"hidePrompt":true,"_uuid":"949088b0e59b32563574bcd8e56488be163777dc"},"cell_type":"markdown","source":"All samples of β are greater than 0. If instead the posterior was centered around 0, we may suspect that β=0, implying that the final grade has no effect on the probability of past failures.\n\nSimilarly, all α posterior values are negative and far away from 0, implying that it is correct to believe that α is significantly less than 0."},{"metadata":{"hideCode":true,"hidePrompt":true,"_uuid":"8c3c76836250345faf1390cb259db4361b086b71"},"cell_type":"markdown","source":"**Next, let's look at the expected value line and the associated 95% intervals for each final grade.** That is, we average over all samples from the posterior to get a likely value for p(FINAL_GRADEi). "},{"metadata":{"hideCode":false,"hidePrompt":true,"trusted":true,"collapsed":true,"_uuid":"3cfad642aa58c545fff46d8b142f40e6fe05975a"},"cell_type":"code","source":"alpha_samples = burned_trace[\"alpha\"][:, None]  # best to make them 1d\nbeta_samples = burned_trace[\"beta\"][:, None]\n\ndef logistic(x, beta, alpha=0):\n    return 1.0 / (1.0 + np.exp(np.dot(beta, x) + alpha)) #same as (1.0/(1. + tt.exp(beta*temperature + alpha)))\n\nt = np.linspace(final_grade.min() - 1, final_grade.max()+1, 50)[:, None]\np_t = logistic(t.T, beta_samples, alpha_samples) #t.T changes shape from (50,1) to (1,50)\n\nmean_prob_t = p_t.mean(axis=0)","execution_count":28,"outputs":[]},{"metadata":{"hideCode":false,"hidePrompt":true,"trusted":true,"_uuid":"827aaae184a21d401b8a1c193cd03d0696652999"},"cell_type":"code","source":"from scipy.stats.mstats import mquantiles\n\nplt.figure(figsize=(12.5, 4))\n\n# vectorized bottom and top 2.5% quantiles for \"confidence interval\"\nqs = mquantiles(p_t, [0.025, 0.975], axis=0)\nplt.fill_between(t[:, 0], *qs, alpha=0.7,\n                 color=\"#7A68A6\")\n\nplt.plot(t[:, 0], qs[0], label=\"95% CI\", color=\"#7A68A6\", alpha=0.7)\n\nplt.plot(t, mean_prob_t, lw=1, ls=\"--\", color=\"k\",\n         label=\"average posterior \\nprobability of past failure\")\n\nplt.xlim(t.min(), t.max())\nplt.ylim(-0.02, 1.02)\nplt.legend(loc=\"lower left\")\nplt.scatter(final_grade, failed_past_classes, color=\"k\", s=50, alpha=0.5)\nplt.xlabel(\"Final grade\")\n\nplt.ylabel(\"Probability estimate\")\nplt.title(\"Posterior probability estimates given final grade\")\nplt.grid()\nplt.show()","execution_count":29,"outputs":[]},{"metadata":{"_uuid":"7d2c207a8255bd1cc1350b12cbb80376c7a56eca"},"cell_type":"markdown","source":"The 95% credible interval, or 95% CI, painted in purple, represents the interval, for each final grade, that contains 95% of the distribution. For example, at 10 final grade, we can be 95% sure that the probability of past failures in other classes lies between 0.18 and 0.25. At 5 final grade, the probability is between 0.58 and 0.82\n\nMore generally, we can see that as the final grades nears 6, the CI experiences a bigger probability spread. As we pass 10 final grade, the CI's tighten again. This can give us insight about how to proceed next: we should probably test more students with final grades between 5.0 and 7.5 to get a better estimate of probabilities in that range."},{"metadata":{"hideCode":false,"hidePrompt":true,"trusted":true,"_uuid":"c379d2ce5774f3ccb0c9843d5665ea5fe1728416"},"cell_type":"code","source":"plt.figure(figsize=(12.5, 2.5))\n\nprob_6 = logistic(6, beta_samples, alpha_samples)\n\n# plt.xlim(0.995, 1) # expand this if temperature is higher\nplt.hist(prob_6, bins=1000, normed=True, histtype='stepfilled')\nplt.title(\"Posterior distribution of probability of past failures, given $final grade = 6$\")\nplt.xlabel(\"probability of past failures in other classes occurring with this student\");","execution_count":30,"outputs":[]},{"metadata":{"_uuid":"79e1bbf2ac01ad5f6f6943b886ef64a9cac30ef9"},"cell_type":"markdown","source":"Above, we can check for probabilites of past failures, based on a particular final grade. For example, we see above that a student that received a final grade of 6 in current portuguese class, had a 0.5 to 0.7 probability of having failed past classes."}],"metadata":{"hide_code_all_hidden":true,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}