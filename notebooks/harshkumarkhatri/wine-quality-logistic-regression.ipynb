{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import linear_model\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"dataset=pd.read_csv(\"/kaggle/input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")\ndataset.head(3)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"dataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"dataset.dtypes.sample(12)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"dataset[\"quality\"].unique()\ny=dataset[\"quality\"]\nx=dataset.drop(\"quality\",axis=1)\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"reg=linear_model.LogisticRegression()\nreg.fit(x_train,y_train)\ny_predict=reg.predict(x_test)\nprint(y_predict)\n","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score,confusion_matrix\naccuracy_score(y_predict,y_test)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# Now i have seen few kernals where they have used Stochastic gradient descent classifier\n# to increase the accuracy for the model\n\nreg2=linear_model.SGDClassifier(penalty=None)\nreg2.fit(x_train,y_train)\ny_pred=reg2.predict(x_test)\naccuracy_score(y_pred,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the cells above we have used SGDC and LR to classify the output.\nNow we will be splitting the output in two parts,either good or bad\n\n","execution_count":null},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"bins=(2,5,8)\ngroup_name=[\"bad\",\"good\"]\ndataset[\"quality\"]=pd.cut(dataset[\"quality\"],bins=bins,labels=group_name)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"dataset[\"quality\"].head()\nfrom sklearn.preprocessing import LabelEncoder\nlabel_quality=LabelEncoder()\ndataset[\"quality\"]=label_quality.fit_transform(dataset[\"quality\"])\n","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"dataset[\"quality\"].head()\n\n# Splitting the dataset again\ny=dataset[\"quality\"]\nx=dataset.drop(\"quality\",axis=1)\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33)\nreg.fit(x_train,y_train)\ny_predict=reg.predict(x_test)\nprint(y_predict)\naccuracy_score(y_predict,y_test)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"confusion_matrix(y_predict,y_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"sns.pairplot(dataset)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"sns.pairplot(dataset,hue=\"quality\")","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"# Trying to see it accuracy greater than the previous one can be achieved with SGDC\nreg2.fit(x_train,y_train)\ny_pred=reg2.predict(x_test)\nprint(y_pred)\naccuracy_score(y_pred,y_test)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test,y_pred)\n\n","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%% md\n"}},"cell_type":"markdown","source":"We can see that for logisti regression there was a huge jump in the accuracy after we have made ranges and provided labels\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}