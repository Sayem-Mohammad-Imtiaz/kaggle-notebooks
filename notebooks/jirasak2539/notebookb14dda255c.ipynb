{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# import library\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import dataset\n\n# From plant 1\n# Generation\ndf1_1 = pd.read_csv(r'../input/solar-power-generation-data/Plant_1_Generation_Data.csv')\n# Weather\ndf1_2 = pd.read_csv(r'../input/solar-power-generation-data/Plant_1_Weather_Sensor_Data.csv')\n\n# From plant 2\n# Generation\ndf2_1 = pd.read_csv(r'../input/solar-power-generation-data/Plant_2_Generation_Data.csv')\n# Weather\ndf2_2 = pd.read_csv(r'../input/solar-power-generation-data/Plant_2_Weather_Sensor_Data.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert the date \"DATE_TIME\" column to proper datetime object\n# match to the proper format for each data\ndf1_1['DATE_TIME'] = pd.to_datetime(df1_1['DATE_TIME'],format='%d-%m-%Y %H:%M')\n\ndf2_1['DATE_TIME'] = pd.to_datetime(df2_1['DATE_TIME'],format='%Y-%m-%d %H:%M:%S')\ndf1_2['DATE_TIME'] = pd.to_datetime(df1_2['DATE_TIME'],format='%Y-%m-%d %H:%M:%S')\ndf2_2['DATE_TIME'] = pd.to_datetime(df2_2['DATE_TIME'],format='%Y-%m-%d %H:%M:%S')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge df1_1 and df1_2 together\ndf1 = pd.merge(df1_1,df1_2,left_on = 'DATE_TIME',right_on = 'DATE_TIME',how = 'outer')\n# merge df2_1 and df2_2 together\ndf2 = pd.merge(df2_1,df2_2,left_on = 'DATE_TIME',right_on = 'DATE_TIME',how = 'outer')\n\ndf = pd.concat([df1,df2])\n# remove an unnecessary and duplicate column\ndf = df.drop(['PLANT_ID_y','SOURCE_KEY_y'],axis = 1)\n\n# rename some column back\ndf = df.rename(columns = {'PLANT_ID_x':'PLANT_ID',\n                    'SOURCE_KEY_x':'SOURCE_KEY'})\n\n# reset index back\ndf = df.reset_index().drop(['index'],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove the hour and minute from the data\ndf['DATE'] = df['DATE_TIME'].dt.strftime('%Y-%m-%d')\n\n# groupby the DataFrame, summarise the feature to be day by day\ngroupby_df = df.groupby(['DATE','SOURCE_KEY']).agg({'DAILY_YIELD':'max',\n                                       'DC_POWER':'sum',\n                                       'AC_POWER':'sum',\n                                       'AMBIENT_TEMPERATURE':'mean',\n                                       'MODULE_TEMPERATURE':'mean',\n                                       'IRRADIATION':'mean',\n                                        'PLANT_ID':'mean'})\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"groupby_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change groupby object back to DataFrame\ngroupby_df = groupby_df.reset_index()\n\n# rearrange the column\ngroupby_df = groupby_df[['DATE', 'SOURCE_KEY', 'PLANT_ID', 'DAILY_YIELD', 'DC_POWER', 'AC_POWER',\n       'AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change \"DATE\" column into datetime object\ngroupby_df['DATE'] = pd.to_datetime(groupby_df['DATE'],format = '%Y-%m-%d')\n# set the \"DATE\" column to be index\ngroupby_df = groupby_df.set_index(['DATE'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change \"PLANT_ID\" to int object\ngroupby_df['PLANT_ID'] = groupby_df['PLANT_ID'].astype('int')\n\n# change \"SOURCE_KEY\" to categorical object\nle = LabelEncoder()\ngroupby_df['SOURCE_KEY'] = le.fit_transform(groupby_df['SOURCE_KEY'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"groupby_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define a function to create dataset with past information\ndef create_prev_day_column(dataset,day_num):\n    delta = pd.Timedelta(1,\"D\")\n    original_copy = dataset.copy()\n    for day in range(1,day_num+1):\n        prev_data = original_copy.copy()\n        prev_data = prev_data.shift(day,freq = 'D')\n        dataset = pd.merge(dataset,prev_data,how = 'left',on = [\"DATE\",\"SOURCE_KEY\",\"PLANT_ID\"],suffixes=['','_' + str(day)])\n        dataset.replace(np.nan,0,inplace = True)\n    \n    return dataset\n\n# define a function to create a dictionary for K fold validation\ndef KFold(dataset,fold_num=10):\n    datasets = {}\n    n = len(dataset)\n    for i in range(fold_num):\n        datasets[i] = dataset[i:n:fold_num]\n    return datasets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import additional library\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for 3 days\ndf = create_prev_day_column(groupby_df,3)\n\nrf_RMSE_score_3day = []\nlr_RMSE_score_3day = []\ndataset_10_fold = KFold(df)\nfolds = 10\nfor fold in range(folds):\n    train_data = pd.DataFrame()\n    for j in range(folds):\n        if j == fold:\n            pass\n        else:\n            train_data = pd.concat([train_data,dataset_10_fold[j]])\n    \n    test_data = dataset_10_fold[fold]\n    \n    X_train = train_data.drop(['DAILY_YIELD'],axis = 1)\n    Y_train = train_data['DAILY_YIELD']\n    \n    X_test = test_data.drop(['DAILY_YIELD'],axis = 1)\n    Y_test = test_data['DAILY_YIELD']\n    \n    rf = RandomForestRegressor()\n    rf.fit(X_train,Y_train)\n    Y_pred = rf.predict(X_test)\n    rmse_score = np.sqrt(metrics.mean_squared_error(Y_test,Y_pred))\n    rf_RMSE_score_3day.append(rmse_score)\n    \n    lr = LinearRegression()\n    lr.fit(X_train,Y_train)\n    Y_pred = lr.predict(X_test)\n    rmse_score = np.sqrt(metrics.mean_squared_error(Y_test,Y_pred))\n    lr_RMSE_score_3day.append(rmse_score)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The mean of RMSE from 10 fold cross validation for Random Forest model with 3 days past data is  ')\nprint(np.mean(rf_RMSE_score_3day))\n\nprint('\\nThe mean of RMSE from 10 fold cross validation for Logistic Regression model with 3 days past data is  ')\nprint(np.mean(lr_RMSE_score_3day))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for 7 days\ndf = create_prev_day_column(groupby_df,7)\n\nrf_RMSE_score_7day = []\nlr_RMSE_score_7day = []\ndataset_10_fold = KFold(df)\nfolds = 10\nfor fold in range(folds):\n    train_data = pd.DataFrame()\n    for j in range(folds):\n        if j == fold:\n            pass\n        else:\n            train_data = pd.concat([train_data,dataset_10_fold[j]])\n    \n    test_data = dataset_10_fold[fold]\n    \n    X_train = train_data.drop(['DAILY_YIELD'],axis = 1)\n    Y_train = train_data['DAILY_YIELD']\n    \n    X_test = test_data.drop(['DAILY_YIELD'],axis = 1)\n    Y_test = test_data['DAILY_YIELD']\n    \n    rf = RandomForestRegressor()\n    rf.fit(X_train,Y_train)\n    Y_pred = rf.predict(X_test)\n    rmse_score = np.sqrt(metrics.mean_squared_error(Y_test,Y_pred))\n    rf_RMSE_score_7day.append(rmse_score)\n    \n    lr = LinearRegression()\n    lr.fit(X_train,Y_train)\n    Y_pred = lr.predict(X_test)\n    rmse_score = np.sqrt(metrics.mean_squared_error(Y_test,Y_pred))\n    lr_RMSE_score_7day.append(rmse_score)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The mean of RMSE from 10 fold cross validation for Random Forest model with 7 days past data is  ')\nprint(np.mean(rf_RMSE_score_7day))\n\nprint('\\nThe mean of RMSE from 10 fold cross validation for Logistic Regression model with 7 days past data is  ')\nprint(np.mean(lr_RMSE_score_7day))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}