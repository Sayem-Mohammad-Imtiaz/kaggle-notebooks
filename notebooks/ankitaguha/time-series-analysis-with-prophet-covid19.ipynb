{"cells":[{"metadata":{},"cell_type":"markdown","source":"# EDA & Time Series Analysis: Using Prophet"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"# Libraries Required\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom mpl_toolkits.mplot3d import Axes3D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading Datasets\n#confirmed = pd.read_csv(\"../input/novel-corona-virus-2019-dataset/time_series_covid_19_confirmed.csv\")\n#deaths = pd.read_csv(\"../input/novel-corona-virus-2019-dataset/time_series_covid_19_deaths.csv\")\n#recovered = pd.read_csv(\"../input/novel-corona-virus-2019-dataset/time_series_covid_19_recovered.csv\")\n\n# Load Data (Source: https://github.com/CSSEGISandData/COVID-19)\nconfirmed = pd.read_csv(\"../input/covid19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\")\nrecovered = pd.read_csv(\"../input/covid19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv\")\ndeaths = pd.read_csv(\"../input/covid19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Overview of Data with Confirmed, Death & Recovered Cases\nconfirmed.head(10)\n#deaths.head(10)\n#recovered.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Melting the Confirmed Cases Dataframe:\nconfirmed2=pd.melt(confirmed,id_vars=['Province/State','Country/Region','Lat','Long'],var_name='Dates', value_name='Confirmed Cases')\nconfirmed2\n\n# Exploring Confirmed Cases Dataframe:\nconfirmed2.info()\n\n# Converting Dates to Datetime Format:\nconfirmed2['Dates'] = pd.to_datetime(confirmed2['Dates'], infer_datetime_format=True)\n\n# Converted from Object to Datetime\nconfirmed2.info()\n\nconfirmed2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Melting the Death Cases Dataframe:\ndeaths2=pd.melt(deaths,id_vars=['Province/State','Country/Region','Lat','Long'],var_name='Dates', value_name='Death Cases')\n#deaths2\n\n# Exploring Deaths Cases Dataframe:\ndeaths2.info()\n\n# Converting Dates to Datetime Format:\ndeaths2['Dates'] = pd.to_datetime(deaths2['Dates'], infer_datetime_format=True)\n\n# Converted from Object to Datetime\ndeaths2.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Melting the Recovered Cases Dataframe:\nrecovered2=pd.melt(recovered,id_vars=['Province/State','Country/Region','Lat','Long'],var_name='Dates', value_name='Recovered Cases')\nrecovered2\n\n# Exploring Deaths Cases Dataframe:\nrecovered2.info()\n\n# Converting Dates to Datetime Format:\nrecovered2['Dates'] = pd.to_datetime(recovered2['Dates'], infer_datetime_format=True)\n\n#Converted from Object to Datetime\nrecovered2.info()\nrecovered2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merging Confirmed, Death and Recovered Cases Together:\nconfirmed2['Death Cases'] = pd.Series(deaths2['Death Cases'])\nconfirmed2['Recovered Cases'] = pd.Series(recovered2['Recovered Cases'])\n\n# View the Final Merged Dataframe with All 3 Cases (Confirmed, Death and Recovered Cases):\ncovid19 = confirmed2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sneek Peak Into Some of the Data Variables\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Descriptive Stats of All Variables\ncovid19.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Descriptive Stats of Variables with Available Data\ncovid19.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Writing the Dataframe to CSV File\ncovid19.to_csv(\"covid19_timeseries.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Relationship Amongst Variables\n\nFrom the Correlation Heatmap it can be seen that:\n * With increase in Latitude & increase in Longitude Confirmed Cases increases.\n * With increase in Latitude & decrease in Longitude Death Cases increases.\n * With increase in Latitude & decrease in Longitude Recovereed Cases increases.\n\nIn other words:\n * The **Confirmed Cases** peaks with increase in Longitude, and then drops with decrease in  Longitude and increase in Latitude.\n * The **Death Cases** peaks with decrease in Longitude, and then drops further with decrease in Longitude, (clearly indicating some other factors that might have influenced)\n * The **Recovered Cases** peaks wth decrease in Longitude and drops with increase in Lat & Long. \n"},{"metadata":{},"cell_type":"markdown","source":"## Correlation Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#sns.pairplot(train_data)\ncorr = covid19.corr()\nfig, (ax) = plt.subplots(1, 1, figsize=(7,6))\n\nhm = sns.heatmap(corr, \n                 ax=ax,           # Axes in which to draw the plot, otherwise use the currently-active Axes.\n                 cmap=\"coolwarm\", # Color Map.\n                 #square=True,    # If True, set the Axes aspect to “equal” so each cell will be square-shaped.\n                 annot=True, \n                 fmt='.2f',       # String formatting code to use when adding annotations.\n                 #annot_kws={\"size\": 14},\n                 linewidths=.05)\n\nfig.subplots_adjust(top=0.93)\nfig.suptitle('COVID19 Cases Correlation Heatmap with Lat Long', \n              fontsize=14, \n              fontweight='bold')\nplt.figure()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pairwise Plots\nFrom the Pairwise Plots, it look the number of Death Cases are either not that high in the dataset as compared to Confirmed & Recovered Cases."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pairplot for just numerical variables\n# Attributes of interest\nplt.rcParams.update({'figure.max_open_warning': 0})\ncols = ['Confirmed Cases', \n        'Recovered Cases', \n        'Death Cases']\n\n\npp = sns.pairplot(covid19[cols],palette=\"Set3\",\n                  diag_kws=dict(shade=True),\n                  diag_kind=\"kde\", # use \"kde\" for diagonal plots\n                  kind=\"reg\")\n\nfig = pp.fig \nfig.subplots_adjust(top=0.97, wspace=0.4)\nfig.suptitle('COVID19 Cases Attributes Pairwise Plots', fontsize=14, fontweight='bold')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting Univariate Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns; \nsns.set(style=\"ticks\", color_codes=True)\n#sns.pairplot(covid19)\n\n#Using Kernel Density for Univariate Plot\nsns.pairplot(covid19, diag_kind=\"kde\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Confirmed Cases Across Time with & without 95% CI Around Mean\n\nSince the default behaviour in seaborn is to aggregate the multiple measurements at each x value by plotting the mean and the 95% cofidence interval around the mean."},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.set(style=\"darkgrid\")\n\n# Plot the responses for different events and regions\nsns.lineplot(x=\"Dates\", y=\"Confirmed Cases\", data=covid19)\n\nimport matplotlib.pyplot as plt\n# control x and y limits\nplt.xticks(x=\"Dates\", rotation='vertical')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Confirmed Cases Across Time without Confidence Interval Around Mean\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.relplot(x=\"Dates\", y=\"Confirmed Cases\", ci=None, kind=\"line\", data=covid19);\nplt.xticks(x=\"Dates\", rotation='vertical')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Recovered Cases Across Time with 95% CI Around Mean\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.set(style=\"darkgrid\")\n\n# Plot the responses for different events and regions\nsns.lineplot(x=\"Dates\", y=\"Recovered Cases\", data=covid19)\n\nimport matplotlib.pyplot as plt\n# control x and y limits\nplt.xticks(x=\"Dates\", rotation='vertical')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Recovered Cases Across Time without Confidence Interval Around Mean"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.relplot(x=\"Dates\", y=\"Recovered Cases\", ci=None, kind=\"line\", data=covid19);\nplt.xticks(x=\"Dates\", rotation='vertical')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Death Cases Across Time with 95% CI Around Mean"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.set(style=\"darkgrid\")\n\n# Plot the responses for different events and regions\nsns.lineplot(x=\"Dates\", y=\"Death Cases\", data=covid19)\n\nimport matplotlib.pyplot as plt\n# control x and y limits\nplt.xticks(x=\"Dates\", rotation='vertical')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Death Cases Across Time without Confidence Interval Around Mean\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.relplot(x=\"Dates\", y=\"Death Cases\", ci=None, kind=\"line\", data=covid19);\nplt.xticks(x=\"Dates\", rotation='vertical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select only Relevant Columns:\ncovid19cases_subset = covid19.loc[:, ['Dates', 'Confirmed Cases', 'Recovered Cases', 'Death Cases']]\ncovid19cases_subset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visual Comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib\nsns.set()\n#%matplotlib inline\nplt.style.use('fivethirtyeight')\n#matplotlib.rcParams['axes.labelsize'] = 14\n#matplotlib.rcParams['xtick.labelsize'] = 12\n#matplotlib.rcParams['ytick.labelsize'] = 12\n#matplotlib.rcParams['text.color'] = 'k'\n\nplt.figure(figsize=(15, 10))\nsns.lineplot(covid19cases_subset['Dates'], covid19cases_subset['Confirmed Cases'].tolist(), label = 'CONFIRMED')\nsns.lineplot(covid19cases_subset['Dates'], covid19cases_subset['Death Cases'].tolist(), label = 'DEATH')\nsns.lineplot(covid19cases_subset['Dates'], covid19cases_subset['Recovered Cases'].tolist(), label = 'RECOVERED')\n\nplt.xlabel('Date'); plt.ylabel('Cases Number'); plt.title('All Cases Over Time')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping Rows where No Cases are Reported\n#covid19cases_subset.head(100)\n#covid19cases_subset.shape()\ncovid19cases_subset = covid19cases_subset.loc[~((covid19cases_subset['Confirmed Cases']==0) | (covid19cases_subset['Recovered Cases']==0.0) | ((covid19cases_subset['Death Cases']==0)))]\ncovid19cases_subset.head(100)\ncovid19cases_subset.tail(1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Kernel Density Function\n\nThe Kernel Density Function gives an interesting sneak peak to understand the Probability Density Fucntion of the Cases across the Confirmed, Recovered and Death Cases in the entire dataset. At least for the **Confirmed Cases** and the **Recovered Cases** the data seems to be Skewed to the Right, indicating that the Mean of the Cases Distribution would be lower than the Median and the Mode. We need to deep dive into the **Death Cases** because that seems to Right Skewed too but with some intermittent high spikes. The number of **Confirmed Cases** are also spanned over a larger number than both the Recovered and the Death Cases, that could be an interesting reason for why most of the initial cases were ignored by most of the countries.\nSeems like the Probability Density Distribution for the Death Cases were at least 2 times higher than that of the Confirmed Cases. And the Confirmed and Recovered Cases were almost going hand in hand in terms of their Probability Density Function."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Density Plot\nfig = plt.figure(figsize=(30,8))\ntitle = fig.suptitle(\"Cases Distribution\", fontsize=14)\nfig.subplots_adjust(top=0.85, wspace=0.3)\n\nax1 = fig.add_subplot(1,2,1)\nax1.set_title(\"Confirmed Cases Distribution\")\nax1.set_xlabel(\"Confirmed Cases\")\nax1.set_ylabel(\"Probability Density\") \nsns.kdeplot(covid19['Confirmed Cases'], kernel='gau', bw=.000000000000029000000, ax=ax1, shade=True, color='b') # .00000000000005\n\nax3 = fig.add_subplot(1,2,2)\nax3.set_title(\"Death Cases Distribution\")\nax3.set_xlabel(\"Death Cases\")\nax3.set_ylabel(\"Probability Density\") \nsns.kdeplot(covid19['Death Cases'], kernel='gau', bw=.000000000000029000000, ax=ax3, shade=True, color='r')\n\n# Density Plot\nfig = plt.figure(figsize=(30,8))\ntitle = fig.suptitle(\"Cases Distribution\", fontsize=14)\nfig.subplots_adjust(top=0.85, wspace=0.3)\n\nax1 = fig.add_subplot(1,2,1)\nax1.set_title(\"Recovered Cases Distribution\")\nax1.set_xlabel(\"Recovered Cases\")\nax1.set_ylabel(\"Probability Density\") \nsns.kdeplot(covid19['Recovered Cases'], kernel='gau', bw=.000000000000029000000, ax=ax1, shade=True, color='g')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Time Series Analysis using Prophet"},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"# Loading Datasets\n#import os\n#for dirname, _, filenames in os.walk('../output'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        \n#covid19 = pd.read_csv(\"../input/covid19-timeseries/covid19_timeseries.csv\")\n#../input/covid19-timeseries/covid19_timeseries.csv\n#./\n#./\n#./\n#./covid19_timeseries.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Work From Here. Not Replacing the Previous Data File\nimport os\nfor dirname, _, filenames in os.walk('../output/kaggle/working/covid19_timeseries.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ncovid19 = pd.read_csv(\"../input/covid19-timeseries/covid19_timeseries.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Libraries Required\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom mpl_toolkits.mplot3d import Axes3D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Libraries for Forecasting\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nplt.style.use('fivethirtyeight')\nfrom fbprophet import Prophet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Additive & Multiplicative Prophet Models\n\nProphet with The Additive Model, that we used here for the purpose of building the Model: y(t) = g(t) + s(t) + h(t) + e(t),\nwhere: \n* g(t) represents trend\n* s(t) represents periodic component\n* h(t) holiday related events or may be social distancing in this case. \n* e(t) is the error\nProphet with **The Multiplicative Model**: y(t) = g(t) * s(t) * h(t) * e(t)\n\nFor the purpose of understanding the data, ran the Models with both Additive and Multiplicative Models. Usually **Multiplicative Models** are used when the magnitude of the seasonal pattern in the data depends on the magnitude of the data. Whereas **Additive Models** are usually used when the magnitude of seasonality does not change in relation to time. In this case so far we are still in the Initial Stage of the Data and we are yet to see the actual seasonal change over the behaviour on the data. So, it is a better practise to go with a Model that won't overfit the Model's Performance. \n"},{"metadata":{},"cell_type":"markdown","source":"## Confirmed Cases Forecasting"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prophet Models\ncovid19.head()\n#covid19.head(100)\n\n# Prophet Requires columns ds (Dates) and y (value)\ncovid19confirmedcases = covid19.rename(columns={'Dates': 'ds', 'Confirmed Cases': 'y'})\n\n# Let's Drop columns Death Cases & Recovered Cases for this dataframe\ncovid19confirmedcases.drop(['Death Cases', 'Recovered Cases'], axis=1, inplace=True)\ncovid19confirmedcases.head()\n\n# Fitting Model\n# changepoint_prior_scale can help to achieve a better fit by reducing uncertainty, Prophet Documentation suggest the scale at 0.5\nmc=Prophet(changepoint_prior_scale=0.001, seasonality_mode='additive', daily_seasonality=True, yearly_seasonality=True)\nmc.fit(covid19confirmedcases)\n\n# Future dataframe with 1 year of data for each day\nfuture_covid19confirmedcases=mc.make_future_dataframe(periods=90, freq='D')\n#Checking how the dataframe looks like\n#future_covid19confirmedcases.tail()\n\n# Make predictions\nforecast_covid19confirmedcases=mc.predict(future_covid19confirmedcases)\n\n#interval_width=0.95\n#forecast_covid19confirmedcases = (interval_width).fit(m).predict(future)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction Plot for Confirmed Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet.plot import add_changepoints_to_plot\n\n# Helps in addressing the Type Error for dates\npd.plotting.register_matplotlib_converters()\n\n# Plotting\nfig_confirmed = mc.plot(forecast_covid19confirmedcases, uncertainty=True, xlabel = 'Dates', ylabel = 'Confirmed Cases')\nplt.title('Forecasting of Confirmed Cases')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Seasonal Components in Forecasting of Confirmed Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plot Model Components\nfig = mc.plot_components(forecast_covid19confirmedcases)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Uncertainty in Models\nThe Model Uncertainty shows the Predicted value in terms of 'yhat'. This forecast model definitely consists of a lot of uncertainty in terms of the predicted interval as well as the upper and lower predicted uncertainty intervals. Definitely a good time to find a way to DECREASE uncertainty. First we will try by increasing the changepoint prior scale.There are 3 main sources of Uncertainty in the Forecast:\n1. Uncertainty in Trend\n2. Uncertainty in Seasonality Estimates.\n3. Additional Observation Noise.\n\nBy default, Prophet returns uncertainty in Trend and Observation Noise. To capture uncertainty in seasonality we need to perform a full Bayesian Sampling taking into consideration data for the last 6 months."},{"metadata":{},"cell_type":"markdown","source":"## Model Uncertainty in Confirmed Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking Model Uncertainty\n#forecast_covid19confirmedcases.head()\nforecast_covid19confirmedcases[['ds', 'trend', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\nforecast_covid19confirmedcases.rename(columns={'trend':'y'}, inplace=True)\n#forecast_covid19confirmedcases.head()\n\n\n# Uncertainty in Trend\nforecast_covid19confirmedcases_trenduncertainty = Prophet(interval_width=0.95).fit(forecast_covid19confirmedcases).predict(covid19confirmedcases)\n\n\n# Uncertainty in Seasonality: Considering Samples from 6 Months Data\nmc = Prophet(mcmc_samples=300)\nforecast_covid19confirmedcases_seasonaluncertainty = mc.fit(forecast_covid19confirmedcases).predict(covid19confirmedcases)\n\nfig = mc.plot_components(forecast_covid19confirmedcases_seasonaluncertainty)\n\n#fig_confirmed = m.plot(forecast, uncertainty=False, xlabel = 'Dates', ylabel = 'Confirmed Cases')\n#plt.title('Forecasting of Confirmed Cases')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Death Cases Forecasting"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prophet Models\ncovid19.head()\n\n# Prophet Requires columns ds (Dates) and y (value)\ncovid19deathcases = covid19.rename(columns={'Dates': 'ds', 'Death Cases': 'y'})\n\n# Let's Drop columns Death Cases & Recovered Cases for this dataframe\ncovid19deathcases.drop(['Confirmed Cases', 'Recovered Cases'], axis=1, inplace=True)\ncovid19deathcases.head()\n\n# Fitting Model\n# changepoint_prior_scale can help to achieve a better fit by reducing uncertainty, Prophet Documentation suggest the scale at 0.5\nmd=Prophet(changepoint_prior_scale=0.25, seasonality_mode='additive', daily_seasonality=True, yearly_seasonality=True)\nmd.fit(covid19deathcases)\n\n# Future dataframe with 1 year of data for each day; Periods tell the Number of Days till when we would like to see the Forecast\nfuture_covid19deathcases=md.make_future_dataframe(periods=90, freq='D')\n#Checking how the dataframe looks like\n#future_covid19confirmedcases.tail()\n# Make predictions\nforecast_covid19deathcases=md.predict(future_covid19deathcases)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction Plot for Death Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet.plot import add_changepoints_to_plot\n\n# Helps in addressing the Type Error for dates\npd.plotting.register_matplotlib_converters()\n\n# Plotting\nfig_death = md.plot(forecast_covid19deathcases, uncertainty=True, xlabel = 'Dates', ylabel = 'Death Cases')\nplt.title('Forecasting of Death Cases')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Seasonal Components in Forecasting of Death Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plot Model Components\nfig1 = md.plot_components(forecast_covid19deathcases)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Uncertainty for Death Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking Model Uncertainty\nforecast_covid19deathcases[['ds', 'trend', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\nforecast_covid19deathcases.rename(columns={'trend':'y'}, inplace=True)\n#forecast_covid19confirmedcases.head()\n\n\n# Uncertainty in Trend\nforecast_covid19deathcases_trenduncertainty = Prophet(interval_width=0.95).fit(forecast_covid19deathcases).predict(covid19deathcases)\n\n\n# Uncertainty in Seasonality: Considering Samples from 6 Months Data\nmd = Prophet(mcmc_samples=300)\nforecast_covid19deathcases_seasonaluncertainty = md.fit(forecast_covid19deathcases).predict(covid19deathcases)\n\nfig = md.plot_components(forecast_covid19deathcases_seasonaluncertainty)\n\n#fig_confirmed = m.plot(forecast, uncertainty=False, xlabel = 'Dates', ylabel = 'Confirmed Cases')\n#plt.title('Forecasting of Confirmed Cases')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Recovered Cases Forecasting"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prophet Models\ncovid19.head()\n\n# Prophet Requires columns ds (Dates) and y (value)\ncovid19recoveredcases = covid19.rename(columns={'Dates': 'ds', 'Recovered Cases': 'y'})\n\n# Let's Drop columns Death Cases & Recovered Cases for this dataframe\ncovid19recoveredcases.drop(['Confirmed Cases', 'Death Cases'], axis=1, inplace=True)\ncovid19recoveredcases.head()\n\n# Fitting Model\n# changepoint_prior_scale can help to achieve a better fit by reducing uncertainty, Prophet Documentation suggest the scale at 0.5\nmr=Prophet(changepoint_prior_scale=0.25, seasonality_mode='additive', daily_seasonality=True, yearly_seasonality=True)\nmr.fit(covid19recoveredcases)\n\n# Future dataframe with 1 year of data for each day\nfuture_covid19recoveredcases=mr.make_future_dataframe(periods=90, freq='D')\n#Checking how the dataframe looks like\n#future_covid19confirmedcases.tail()\n# Make predictions\nforecast_covid19recoveredcases=mr.predict(future_covid19recoveredcases)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction Plot for Recovered Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet.plot import add_changepoints_to_plot\n\n# Helps in addressing the Type Error for dates\npd.plotting.register_matplotlib_converters()\n\n# Plotting\nfig_death = mr.plot(forecast_covid19recoveredcases, xlabel = 'Dates', ylabel = 'Recovered Cases')\nplt.title('Forecasting of Recovered Cases')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Seasonal Components of Recovered Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plot Model Components\nfig1 = mr.plot_components(forecast_covid19recoveredcases)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Uncertainty for Recovered Cases\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking Model Uncertainty\nforecast_covid19recoveredcases[['ds', 'trend', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\nforecast_covid19recoveredcases.rename(columns={'trend':'y'}, inplace=True)\n#forecast_covid19confirmedcases.head()\n\n\n# Uncertainty in Trend\nforecast_covid19recoveredcases_trenduncertainty = Prophet(interval_width=0.95).fit(forecast_covid19recoveredcases).predict(covid19recoveredcases)\n\n\n# Uncertainty in Seasonality: Considering Samples from 6 Months Data\nmr = Prophet(mcmc_samples=300)\nforecast_covid19recoveredcases_seasonaluncertainty = mr.fit(forecast_covid19recoveredcases).predict(covid19recoveredcases)\n\nfig = mr.plot_components(forecast_covid19recoveredcases_seasonaluncertainty)\n\n#fig_confirmed = m.plot(forecast, uncertainty=False, xlabel = 'Dates', ylabel = 'Confirmed Cases')\n#plt.title('Forecasting of Confirmed Cases')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fourier Order In Seasonalities For Recovered Cases\nThe default seasonality is 10. However to fit higher frequency changes the variable can be increased, depending on the frequnecy of the data reporting."},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet.plot import plot_yearly\nmr = Prophet(yearly_seasonality=40).fit(covid19recoveredcases)\na = plot_yearly(mr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Weekly & Monthly Seasonality with Fourier Transform\nConsidering both the Weekly as well as Monthly Seasonality in the data to make sure we consider all the uncertainties in the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Considering Weekly & Monthly Seasonality\nmr = Prophet(weekly_seasonality=True)\nmr.add_seasonality(name='monthly', period=30.5, fourier_order=6)\nforecast = mr.fit(covid19recoveredcases).predict(forecast_covid19recoveredcases_trenduncertainty)\nfig = mr.plot_components(forecast)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Combined Forecasting for Confirmed, Death & Recovered Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmedcases_names = ['confirmedcases_%s' % column for column in forecast_covid19confirmedcases.columns]\ndeathcases_names = ['deathcases_%s' % column for column in forecast_covid19deathcases.columns]\nrecoveredcases_names = ['recoveredcases_%s' % column for column in forecast_covid19recoveredcases.columns]\n\n# Dataframes to merge\nmerge_confirmedcases_forecast = forecast_covid19confirmedcases.copy()\nmerge_deathcases_forecast = forecast_covid19deathcases.copy()\nmerge_recoveredcases_forecast = forecast_covid19recoveredcases.copy()\n\n# Rename the columns\nmerge_confirmedcases_forecast.columns = confirmedcases_names\nmerge_deathcases_forecast.columns = deathcases_names\nmerge_recoveredcases_forecast.columns = recoveredcases_names\n\n# Renaming the Date Columns\nconfirmedcases_forecast = merge_confirmedcases_forecast.rename(columns={'confirmedcases_ds': 'Date'})\ndeathcases_forecast = merge_deathcases_forecast.rename(columns={'deathcases_ds': 'Date'})\nrecoveredcases_forecast = merge_recoveredcases_forecast.rename(columns={'recoveredcases_ds': 'Date'})\n\n# Dropping some of the Columns \nconfirmedcases_forecast.drop(confirmedcases_forecast.iloc[:, 2:21], inplace = True, axis = 1)\ndeathcases_forecast.drop(deathcases_forecast.iloc[:, 2:21], inplace = True, axis = 1)\nrecoveredcases_forecast.drop(recoveredcases_forecast.iloc[:, 2:21], inplace = True, axis = 1)\n\n#confirmedcases_forecast.head(10)\ndeathcases_forecast.tail(1000)\nrecoveredcases_forecast.tail(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Comparing Trend & Prediction Value for Confirmed Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nplt.style.use('fivethirtyeight')\n\nplt.figure(figsize=(10, 8))\nplt.plot(confirmedcases_forecast['Date'], confirmedcases_forecast['confirmedcases_y'], 'b-', label = 'Trend')\nplt.plot(confirmedcases_forecast['Date'], confirmedcases_forecast['confirmedcases_yhat'], 'r-', label = 'Prediction')\nplt.legend(); plt.xlabel('Date'); plt.ylabel('Confirmed Cases'); \nplt.title('Trend vs. Prediction for Confirmed Cases'); ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Comparing Trend and Prediction Value for Death Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 8))\nplt.plot(deathcases_forecast['Date'], deathcases_forecast['deathcases_y'], 'b-', label = 'Trend')\nplt.plot(deathcases_forecast['Date'], deathcases_forecast['deathcases_yhat'], 'r-', label = 'Prediction')\nplt.legend(); plt.xlabel('Date'); plt.ylabel('Death Cases'); \nplt.title('Trend vs. Prediction for Death Cases'); ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Comparing Trend and Prediction Value for Recovered Cases "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 8))\nplt.plot(recoveredcases_forecast['Date'], recoveredcases_forecast['recoveredcases_y'], 'b-', label = 'Trend')\nplt.plot(recoveredcases_forecast['Date'], recoveredcases_forecast['recoveredcases_yhat'], 'r-', label = 'Prediction')\nplt.legend(); plt.xlabel('Date'); plt.ylabel('Recovered Cases'); \nplt.title('Trend vs. Prediction for Recovered Cases'); ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cross Validation\n\nCross Validation just automates the process of Model Performance. The first parameter given is the trained model m (not the data). Then the next parameter prediction horizon - how frequently we want to predict (in this case '30 days'). Then give an ***initial*** (how long to train before starting the tests) and a ***period*** (how frequently to stop and do a prediction). If we don't provide these parameter values, Prophet will assign defaults of **initial = 3 * horizon, and cutoffs every half a horizon**."},{"metadata":{},"cell_type":"markdown","source":" ## 1. Model Cross Validation for Confirmed Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet.diagnostics import cross_validation\ndfconfirmed = cross_validation(mc, initial='60 days', period='7 days', horizon='30 days') # 30, 30, 100; 60, 30, 100; 60, 30, 200; 60, 90, 100 less error\n#df_cv.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Performance Evaluation\n\nThe performance_metrics utility can be used to compute some useful statistics of the prediction performance (yhat, yhat_lower, and yhat_upper compared to y), as a function of the distance from the cutoff (how far into the future the prediction was). The statistics computed are mean squared error (MSE), root mean squared error (RMSE), mean absolute error (MAE), mean absolute percent error (MAPE), and coverage of the yhat_lower and yhat_upper estimates. These are computed on a rolling window of the predictions in df after sorting by horizon (ds minus cutoff). "},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet.diagnostics import performance_metrics\nfrom fbprophet.plot import plot_cross_validation_metric\n\ndf_pconfirmed = performance_metrics(dfconfirmed, rolling_window = 0.1)\ndf_pconfirmed.head()\n\n#performance_metrics(df, metrics = NULL, rolling_window = 0.1) https://rdrr.io/cran/prophet/man/performance_metrics.html","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Error Visualization\n\nCross Validation Performance Metrics can be visualized with plot_cross_validation_metric, here shown for MSE, RMSE, MAE, MAPE. The blue line shows the MAPE, where the mean is taken over a rolling window of the dots. There is almost zero errors uptil 1 month, and then seems like the error would gradually increase with the number of days. The *MAPE* measures the deviation from the actual data in terms of percentage. \n*RMSE* is more accurate in terms of aggressive towards big errors."},{"metadata":{"trusted":true},"cell_type":"code","source":"# With RMSE\nfrom fbprophet.plot import plot_cross_validation_metric\nfig = plot_cross_validation_metric(dfconfirmed, metric='rmse')\n\n# With MAPE\nfrom fbprophet.plot import plot_cross_validation_metric\nfig = plot_cross_validation_metric(dfconfirmed, metric='mape')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Model Cross Validation for Death Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet.diagnostics import cross_validation\ndfdeath = cross_validation(md, initial='60 days', period='7 days', horizon='30 days') # 30, 30, 100; 60, 30, 100; 60, 30, 200; 60, 90, 100 less error\n#df_cv.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Performance Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet.diagnostics import performance_metrics\nfrom fbprophet.plot import plot_cross_validation_metric\n\ndf_pdeath = performance_metrics(dfdeath, rolling_window = 0.1)\ndf_pdeath.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Error Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# With RMSE\nfrom fbprophet.plot import plot_cross_validation_metric\nfig = plot_cross_validation_metric(dfdeath, metric='rmse')\n\n# With MAPE\nfrom fbprophet.plot import plot_cross_validation_metric\nfig = plot_cross_validation_metric(dfdeath, metric='mape')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Model Cross Validation for Recovered Cases"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet.diagnostics import cross_validation\ndfrecovered = cross_validation(mr, initial='60 days', period='7 days', horizon='30 days') # 30, 30, 100; 60, 30, 100; 60, 30, 200; 60, 90, 100 less error\n#df_cv.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Performance Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet.diagnostics import performance_metrics\nfrom fbprophet.plot import plot_cross_validation_metric\n\ndf_precovered = performance_metrics(dfrecovered, rolling_window = 0.1)\ndf_precovered.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Error Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# With RMSE\nfrom fbprophet.plot import plot_cross_validation_metric\nfig = plot_cross_validation_metric(dfrecovered, metric='rmse')\n\n# With MDAPE (Median Abs Percentage Error)\nfrom fbprophet.plot import plot_cross_validation_metric\nfig = plot_cross_validation_metric(dfrecovered, metric='mdape')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}