{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://nnimgt-a.akamaihd.net/transform/v1/crop/frm/5Q2j7ezUfQBfUJsaqK3gfB/8119e2b2-63e5-48a7-8fa6-eff00e9ab4ab.jpg/r0_179_3504_2157_w1200_h678_fmax.jpg)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndf1 = pd.read_csv('/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['RainToday'].replace({'No':0,'Yes':1},inplace = True)    \ndf1['RainTomorrow'].replace({'No':0,'Yes':1},inplace = True)   # replacing label's values\ndf = df1.drop(['Date'],axis=1)  # unsignificance feature\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's find categorical variables for label encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_features = df.select_dtypes(include = [\"object\"]).columns\ncategorical_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create dummy variable for every categorical column "},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.get_dummies(df,columns=categorical_features,drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have lot of null values here but as out primary focus is to perform PCA so let's just fill mean values wherever null values occured "},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.fillna(df.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Scaling all the values from dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler \n\nscaler = StandardScaler() \n\nscaled = scaler.fit_transform(df) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Need of PCA\nMachine learning needs a good amount of data to train and test. But having large or good amount of data has its own pitfall, which is curse of dimensionality as huge amount of data can have lots of inconsistencies of features which may increase computation time and increase chances of making model bad. Hence to get rid of this curse of dimensionality a technique named Principal Component Analysis (PCA) is introduced.\n## Principal Component Analysis (PCA)\nPCA is unsupervised linear dimensionality reduction technique to extract information from high dimensional space to lower dimensional sub space by preserving most significance variation of data. PCA allows to identify correlations and patterns among features in data so that it can be transformed into less dimensionality and with only most number of significance features without an important loss in data. Principal components are eigenvectors of a covariance matrix. The data which is to be analysed has to be scaled as results are highly sensitive <br>\n<br>\n**PCA consist of three main steps** \n1. Computing covariance matrix of data\n2. Computing eigen values and vectors of covariance matrix\n3. Using these eigen values and vectors to reduce dimensions and transform data \t\n\nThese steps were had to be done individually until sklearn released PCA, now these all \nsteps has one stop solution predefined in PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA \n  \npca_model = PCA(n_components = 2) \npca = pca_model.fit_transform(scaled)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"But we dont know if the component value is suitable with 2 or any other number.<br>\nLet's check for n_components=2 [(reference)](http://stackoverflow.com/questions/57293716/sklearn-pca-explained-variance-and-explained-variance-ratio-difference)"},{"metadata":{"trusted":true},"cell_type":"code","source":"variance=np.var(pca,axis=0)\nvariance_ratio = variance/np.sum(variance)\nprint(variance_ratio)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The variance ratio by rounding off gives value of 0.99 which is almost best so we can continue with n_components=2"},{"metadata":{},"cell_type":"markdown","source":"## Visualisation\nFind corelation between both the components"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize =(8, 6)) \n  \nplt.scatter(pca[:, 0], pca[:, 1], c = df1['RainTomorrow'], cmap ='plasma') \n  \nplt.xlabel('First Principal Component') \nplt.ylabel('Second Principal Component') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find correlation between both components as how close their covariance are."},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\ndf_comp = pd.DataFrame(pca_model.components_, columns = df.columns)\n  \nplt.figure(figsize =(14, 6)) \n  \nsns.heatmap(df_comp) \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try out training this new dataset into algorithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = df.copy()\ntest = test[\"RainTomorrow\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split \n\nX_train, X_test, y_train, y_test = train_test_split(pca, test, test_size = 0.25) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBoost\nXGBoost is an implementation of gradient boosted decision trees designed for speed and performance."},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb \nxgb = xgb.XGBClassifier() \nxgb.fit(X_train, y_train) \ny_pred = xgb.predict(X_test) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Predictions**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(\"RMSE: %f\" % (rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy: %.2f\" % (accuracy * 100.0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RMSE & Accuracy Score is pretty well !!. Hence PCA can be used whenever we have more number of dimensions or we can say features"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}